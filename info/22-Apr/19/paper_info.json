[
  {
    "id": "arXiv:2204.07579",
    "title": "Interpretable Fault Diagnosis of Rolling Element Bearings with Temporal  Logic Neural Network",
    "abstract": "Machine learning-based methods have achieved successful applications in\nmachinery fault diagnosis. However, the main limitation that exists for these\nmethods is that they operate as a black box and are generally not\ninterpretable. This paper proposes a novel neural network structure, called\ntemporal logic neural network (TLNN), in which the neurons of the network are\nlogic propositions. More importantly, the network can be described and\ninterpreted as a weighted signal temporal logic. TLNN not only keeps the nice\nproperties of traditional neuron networks but also provides a formal\ninterpretation of itself with formal language. Experiments with real datasets\nshow the proposed neural network can obtain highly accurate fault diagnosis\nresults with good computation efficiency. Additionally, the embedded formal\nlanguage of the neuron network can provide explanations about the decision\nprocess, thus achieve interpretable fault diagnosis.",
    "descriptor": "",
    "authors": [
      "Gang Chen",
      "Yu Lu",
      "Rong Su",
      "Zhaodan Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07579"
  },
  {
    "id": "arXiv:2204.07580",
    "title": "mGPT: Few-Shot Learners Go Multilingual",
    "abstract": "Recent studies report that autoregressive language models can successfully\nsolve many NLP tasks via zero- and few-shot learning paradigms, which opens up\nnew possibilities for using the pre-trained language models. This paper\nintroduces two autoregressive GPT-like models with 1.3 billion and 13 billion\nparameters trained on 60 languages from 25 language families using Wikipedia\nand Colossal Clean Crawled Corpus. We reproduce the GPT-3 architecture using\nGPT-2 sources and the sparse attention mechanism; Deepspeed and Megatron\nframeworks allow us to parallelize the training and inference steps\neffectively. The resulting models show performance on par with the recently\nreleased XGLM models by Facebook, covering more languages and enhancing NLP\npossibilities for low resource languages of CIS countries and Russian small\nnations. We detail the motivation for the choices of the architecture design,\nthoroughly describe the data preparation pipeline, and train five small\nversions of the model to choose the most optimal multilingual tokenization\nstrategy. We measure the model perplexity in all covered languages and evaluate\nit on the wide spectre of multilingual tasks, including classification,\ngenerative, sequence labeling and knowledge probing. The models were evaluated\nwith the zero-shot and few-shot methods. Furthermore, we compared the\nclassification tasks with the state-of-the-art multilingual model XGLM. source\ncode and the mGPT XL model are publicly released.",
    "descriptor": "",
    "authors": [
      "Oleh Shliazhko",
      "Alena Fenogenova",
      "Maria Tikhonova",
      "Vladislav Mikhailov",
      "Anastasia Kozlova",
      "Tatiana Shavrina"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07580"
  },
  {
    "id": "arXiv:2204.07581",
    "title": "Time-Variant System Reliability with Infinite Delay Based on Girsanov's  Transformation",
    "abstract": "This work addresses the reliability of time-variant system appreciation\nmodels of dynamic systems, where regulatory equations are expressed as an\ninfinite delay collection of stochastic functional differential equations\n(SFDEwID). Reliability estimation forms of series and parallel systems tackled\ndepending on Monte Carlo simulations based on extends Girsanov's transformation\nfor infinite delay SFDEs.",
    "descriptor": "",
    "authors": [
      "Hussein K. Asker"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2204.07581"
  },
  {
    "id": "arXiv:2204.07600",
    "title": "In-BoXBART: Get Instructions into Biomedical Multi-Task Learning",
    "abstract": "Single-task models have proven pivotal in solving specific tasks; however,\nthey have limitations in real-world applications where multi-tasking is\nnecessary and domain shifts are exhibited. Recently, instructional prompts have\nshown significant improvement towards multi-task generalization; however, the\neffect of instructional prompts and Multi-Task Learning (MTL) has not been\nsystematically studied in the biomedical domain. Motivated by this, this paper\nexplores the impact of instructional prompts for biomedical MTL. We introduce\nthe BoX, a collection of 32 instruction tasks for Biomedical NLP across (X)\nvarious categories. Using this meta-dataset, we propose a unified model termed\nIn-BoXBART, that can jointly learn all tasks of the BoX without any\ntask-specific modules. To the best of our knowledge, this is the first attempt\nto propose a unified model in the biomedical domain and use instructions to\nachieve generalization across several biomedical tasks. Experimental results\nindicate that the proposed model: 1) outperforms the single-task baseline by\n~3% and multi-task (without instruction) baseline by ~18% on an average, and 2)\nshows ~23% improvement compared to the single-task baseline in few-shot\nlearning (i.e., 32 instances per task) on an average. Our analysis indicates\nthat there is significant room for improvement across tasks in the BoX,\nimplying the scope for future research direction.",
    "descriptor": "\nComments: NAACL 2022 Findings\n",
    "authors": [
      "Mihir Parmar",
      "Swaroop Mishra",
      "Mirali Purohit",
      "Man Luo",
      "M. Hassan Murad",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07600"
  },
  {
    "id": "arXiv:2204.07601",
    "title": "Energy-Efficient Data Transfer Optimization via Decision-Tree Based  Uncertainty Reduction",
    "abstract": "The increase and rapid growth of data produced by scientific instruments, the\nInternet of Things (IoT), and social media is causing data transfer performance\nand resource consumption to garner much attention in the research community.\nThe network infrastructure and end systems that enable this extensive data\nmovement use a substantial amount of electricity, measured in terawatt-hours\nper year. Managing energy consumption within the core networking infrastructure\nis an active research area, but there is a limited amount of work on reducing\npower consumption at the end systems during active data transfers. This paper\npresents a novel two-phase dynamic throughput and energy optimization model\nthat utilizes an offline decision-search-tree based clustering technique to\nencapsulate and categorize historical data transfer log information and an\nonline search optimization algorithm to find the best application and kernel\nlayer parameter combination to maximize the achieved data transfer throughput\nwhile minimizing the energy consumption. Our model also incorporates an\nensemble method to reduce aleatoric uncertainty in finding optimal application\nand kernel layer parameters during the offline analysis phase. The experimental\nevaluation results show that our decision-tree based model outperforms the\nstate-of-the-art solutions in this area by achieving 117% higher throughput on\naverage and also consuming 19% less energy at the end systems during active\ndata transfers.",
    "descriptor": "\nComments: 10 pages submitted to IEEE ICCCN2022\n",
    "authors": [
      "Hasibul Jamil",
      "Lavone Rodolph",
      "Jacob Goldverg",
      "Tevfik Kosar"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2204.07601"
  },
  {
    "id": "arXiv:2204.07603",
    "title": "Learning to Adapt Domain Shifts of Moral Values via Instance Weighting",
    "abstract": "Classifying moral values in user-generated text from social media is critical\nin understanding community cultures and interpreting user behaviors of social\nmovements. Moral values and language usage can change across the social\nmovements; however, text classifiers are usually trained in source domains of\nexisting social movements and tested in target domains of new social issues\nwithout considering the variations. In this study, we examine domain shifts of\nmoral values and language usage, quantify the effects of domain shifts on the\nmorality classification task, and propose a neural adaptation framework via\ninstance weighting to improve cross-domain classification tasks. The\nquantification analysis suggests a strong correlation between morality shifts,\nlanguage usage, and classification performance. We evaluate the neural\nadaptation framework on a public Twitter data across 7 social movements and\ngain classification improvements up to 12.1\\%. Finally, we release a new data\nof the COVID-19 vaccine labeled with moral values and evaluate our approach on\nthe new target domain. For the case study of the COVID-19 vaccine, our\nadaptation framework achieves up to 5.26\\% improvements over neural baselines.",
    "descriptor": "\nComments: Accepted at 33rd ACM Conference on Hypertext and Social Media\n",
    "authors": [
      "Xiaolei Huang",
      "Alexandra Wormley",
      "Adam Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.07603"
  },
  {
    "id": "arXiv:2204.07609",
    "title": "Server Free Wireless Federated Learning: Architecture, Algorithm, and  Analysis",
    "abstract": "We demonstrate that merely analog transmissions and match filtering can\nrealize the function of an edge server in federated learning (FL). Therefore, a\nnetwork with massively distributed user equipments (UEs) can achieve\nlarge-scale FL without an edge server. We also develop a training algorithm\nthat allows UEs to continuously perform local computing without being\ninterrupted by the global parameter uploading, which exploits the full\npotential of UEs' processing power. We derive convergence rates for the\nproposed schemes to quantify their training efficiency. The analyses reveal\nthat when the interference obeys a Gaussian distribution, the proposed\nalgorithm retrieves the convergence rate of a server-based FL. But if the\ninterference distribution is heavy-tailed, then the heavier the tail, the\nslower the algorithm converges. Nonetheless, the system run time can be largely\nreduced by enabling computation in parallel with communication, whereas the\ngain is particularly pronounced when communication latency is high. These\nfindings are corroborated via excessive simulations.",
    "descriptor": "",
    "authors": [
      "Howard H. Yang",
      "Zihan Chen",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07609"
  },
  {
    "id": "arXiv:2204.07610",
    "title": "Sources of Irreproducibility in Machine Learning: A Review",
    "abstract": "Lately, several benchmark studies have shown that the state of the art in\nsome of the sub-fields of machine learning actually has not progressed despite\nprogress being reported in the literature. The lack of progress is partly\ncaused by the irreproducibility of many model comparison studies. Model\ncomparison studies are conducted that do not control for many known sources of\nirreproducibility. This leads to results that cannot be verified by third\nparties. Our objective is to provide an overview of the sources of\nirreproducibility that are reported in the literature. We review the literature\nto provide an overview and a taxonomy in addition to a discussion on the\nidentified sources of irreproducibility. Finally, we identify three lines of\nfurther inquiry.",
    "descriptor": "",
    "authors": [
      "Odd Erik Gundersen",
      "Kevin Coakley",
      "Christine Kirkpatrick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07610"
  },
  {
    "id": "arXiv:2204.07612",
    "title": "Contextualizing Artificially Intelligent Morality: A Meta-Ethnography of  Top-Down, Bottom-Up, and Hybrid Models for Theoretical and Applied Ethics in  Artificial Intelligence",
    "abstract": "In this meta-ethnography, we explore three different angles of Ethical AI\ndesign and implementation in a top-down/bottom-up framework, including the\nphilosophical ethical viewpoint, the technical perspective, and framing through\na political lens. We will discuss the values and drawbacks of individual and\nhybrid approaches within this framework. Examples of approaches include ethics\neither being determined by corporations and governments (coming from the top),\nor ethics being called for by the people (coming from the bottom), as well as\ntop-down, bottom-up, and hybrid technicalities of how AI is developed within a\nmoral construct, in consideration of its developers and users, with expected\nand unexpected consequences and long-term impact. This investigation includes\nreal-world case studies, philosophical debate, and theoretical future thought\nexperimentation based on historical facts, current world circumstances, and\npossible ensuing realities.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Jennafer S. Roberts",
      "Laura N. Montoya"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "General Literature (cs.GL)",
      "Human-Computer Interaction (cs.HC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.07612"
  },
  {
    "id": "arXiv:2204.07614",
    "title": "DeepCSI: Rethinking Wi-Fi Radio Fingerprinting Through MU-MIMO CSI  Feedback Deep Learning",
    "abstract": "We present DeepCSI, a novel approach to Wi-Fi radio fingerprinting (RFP)\nwhich leverages standard-compliant beamforming feedback matrices to\nauthenticate MU-MIMO Wi-Fi devices on the move. By capturing unique\nimperfections in off-the-shelf radio circuitry, RFP techniques can identify\nwireless devices directly at the physical layer, allowing low-latency\nlow-energy cryptography-free authentication. However, existing Wi-Fi RFP\ntechniques are based on software-defined radio (SDRs), which may ultimately\nprevent their widespread adoption. Moreover, it is unclear whether existing\nstrategies can work in the presence of MU-MIMO transmitters - a key technology\nin modern Wi-Fi standards. Conversely from prior work, DeepCSI does not require\nSDR technologies and can be run on any low-cost Wi-Fi device to authenticate\nMU-MIMO transmitters. Our key intuition is that imperfections in the\ntransmitter's radio circuitry percolate onto the beamforming feedback matrix,\nand thus RFP can be performed without explicit channel state information (CSI)\ncomputation. DeepCSI is robust to inter-stream and inter-user interference\nbeing the beamforming feedback not affected by those phenomena. We extensively\nevaluate the performance of DeepCSI through a massive data collection campaign\nperformed in the wild with off-the-shelf equipment, where 10 MU-MIMO Wi-Fi\nradios emit signals in different positions. Experimental results indicate that\nDeepCSI correctly identifies the transmitter with an accuracy of up to 98%. The\nidentification accuracy remains above 82% when the device moves within the\nenvironment. To allow replicability and provide a performance benchmark, we\npledge to share the 800 GB datasets - collected in static and, for the first\ntime, dynamic conditions - and the code database with the community.",
    "descriptor": "\nComments: To be presented at the 42nd IEEE International Conference on Distributed Computing Systems (ICDCS), Bologna, Italy, July 10-13, 2022\n",
    "authors": [
      "Francesca Meneghello",
      "Michele Rossi",
      "Francesco Restuccia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07614"
  },
  {
    "id": "arXiv:2204.07615",
    "title": "Resource-Constrained Neural Architecture Search on Tabular Datasets",
    "abstract": "The best neural architecture for a given machine learning problem depends on\nmany factors: not only the complexity and structure of the dataset, but also on\nresource constraints including latency, compute, energy consumption, etc.\nNeural architecture search (NAS) for tabular datasets is an important but\nunder-explored problem. Previous NAS algorithms designed for image search\nspaces incorporate resource constraints directly into the reinforcement\nlearning rewards. In this paper, we argue that search spaces for tabular NAS\npose considerable challenges for these existing reward-shaping methods, and\npropose a new reinforcement learning (RL) controller to address these\nchallenges. Motivated by rejection sampling, when we sample candidate\narchitectures during a search, we immediately discard any architecture that\nviolates our resource constraints. We use a Monte-Carlo-based correction to our\nRL policy gradient update to account for this extra filtering step. Results on\nseveral tabular datasets show TabNAS, the proposed approach, efficiently finds\nhigh-quality models that satisfy the given resource constraints.",
    "descriptor": "\nComments: 26 pages, 15 figures, 4 tables\n",
    "authors": [
      "Chengrun Yang",
      "Gabriel Bender",
      "Hanxiao Liu",
      "Pieter-Jan Kindermans",
      "Madeleine Udell",
      "Yifeng Lu",
      "Quoc Le",
      "Da Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07615"
  },
  {
    "id": "arXiv:2204.07616",
    "title": "Multi-Frame Self-Supervised Depth with Transformers",
    "abstract": "Multi-frame depth estimation improves over single-frame approaches by also\nleveraging geometric relationships between images via feature matching, in\naddition to learning appearance-based features. In this paper we revisit\nfeature matching for self-supervised monocular depth estimation, and propose a\nnovel transformer architecture for cost volume generation. We use\ndepth-discretized epipolar sampling to select matching candidates, and refine\npredictions through a series of self- and cross-attention layers. These layers\nsharpen the matching probability between pixel features, improving over\nstandard similarity metrics prone to ambiguities and local minima. The refined\ncost volume is decoded into depth estimates, and the whole pipeline is trained\nend-to-end from videos using only a photometric objective. Experiments on the\nKITTI and DDAD datasets show that our DepthFormer architecture establishes a\nnew state of the art in self-supervised monocular depth estimation, and is even\ncompetitive with highly specialized supervised single-frame architectures. We\nalso show that our learned cross-attention network yields representations\ntransferable across datasets, increasing the effectiveness of pre-training\nstrategies. Project page: https://sites.google.com/tri.global/depthformer",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Vitor Guizilini",
      "Rares Ambrus",
      "Dian Chen",
      "Sergey Zakharov",
      "Adrien Gaidon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07616"
  },
  {
    "id": "arXiv:2204.07619",
    "title": "Transfer Importance Sampling $\\unicode{x2013}$ How Testing Automated  Vehicles in Multiple Test Setups Helps With the Bias-Variance Tradeoff",
    "abstract": "The promise of increased road safety is a key motivator for the development\nof automated vehicles (AV). Yet, demonstrating that an AV is as safe as, or\neven safer than, a human-driven vehicle has proven to be challenging. Should an\nAV be examined purely virtually, allowing large numbers of fully controllable\ntests? Or should it be tested under real environmental conditions on a proving\nground? Since different test setups have different strengths and weaknesses, it\nis still an open question how virtual and real tests should be combined. On the\nway to answer this question, this paper proposes transfer importance sampling\n(TIS), a risk estimation method linking different test setups. Fusing the\nconcepts of transfer learning and importance sampling, TIS uses a scalable,\ncost-effective test setup to comprehensively explore an AV's behavior. The\ninsights gained then allow parameterizing tests in a more trustworthy test\nsetup accurately reflecting risks. We show that when using a trustworthy test\nsetup alone is prohibitively expensive, linking it to a scalable test setup can\nincrease efficiency $\\unicode{x2013}$ without sacrificing the result's\nvalidity. Thus, the test setups' individual deficiencies are compensated for by\ntheir systematic linkage.",
    "descriptor": "\nComments: 6 pages, 5 figures, 1 table, submitted to IEEE ITSC 2022\n",
    "authors": [
      "Max Winkelmann",
      "Constantin Vasconi",
      "Steffen M\u00fcller"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07619"
  },
  {
    "id": "arXiv:2204.07623",
    "title": "Active Mapping via Gradient Ascent Optimization of Shannon Mutual  Information over Continuous SE(3) Trajectories",
    "abstract": "The problem of active mapping aims to plan an informative sequence of sensing\nviews given a limited budget such as distance traveled. This paper consider\nactive occupancy grid mapping using a range sensor, such as LiDAR or depth\ncamera. State-of-the-art methods optimize information-theoretic measures\nrelating the occupancy grid probabilities with the range sensor measurements.\nThe non-smooth nature of ray-tracing within a grid representation makes the\nobjective function non-differentiable, forcing existing methods to search over\na discrete space of candidate trajectories. This work proposes a differentiable\napproximation of the Shannon mutual information between a grid map and\nray-based observations that enables gradient ascent optimization in the\ncontinuous space of SE(3) sensor poses. Our gradient-based formulation leads to\nmore informative sensing trajectories, while avoiding occlusions and\ncollisions. The proposed method is demonstrated in simulated and real-world\nexperiments in 2-D and 3-D environments.",
    "descriptor": "",
    "authors": [
      "Arash Asgharivaskasi",
      "Shumon Koga",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07623"
  },
  {
    "id": "arXiv:2204.07628",
    "title": "On short-time stability notions for nonlinear systems",
    "abstract": "This paper introduces the notions of annular settling and output annular\nsettling for general nonlinear systems. Also, we propose conditions for annular\nshort-time stability, short time boundedness with a nonzero initial state,\nannular settling, and output annular settling for generalized Persidskii\nsystems with an essentially bounded input. These conditions are based on the\nverification of linear matrix inequalities. An application to recurrent neural\nnetworks illustrates the usefulness of the proposed notions and conditions.",
    "descriptor": "",
    "authors": [
      "Wenjie Mei",
      "Denis Efimov",
      "Rosane Ushirobira"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.07628"
  },
  {
    "id": "arXiv:2204.07630",
    "title": "Prismatic Soft Actuator Augments the Workspace of Soft Continuum Robots",
    "abstract": "Soft robots are promising for manipulation tasks thanks to their compliance,\nsafety, and high degree of freedom. However, the commonly used bidirectional\ncontinuum segment design means soft robotic manipulators only function in a\nlimited hemispherical workspace. This work increases a soft robotic arm's\nworkspace by designing, fabricating, and controlling an additional soft\nprismatic actuator at the base of the soft arm. This actuator consists of\npneumatic artificial muscles and a piston, making the actuator back-driveable.\nWe increase the task space volume by 116\\%, and we are now able to perform\nmanipulation tasks that were previously impossible for soft robots, such as\npicking and placing objects at different positions on a surface and grabbing an\nobject out of a container. By combining a soft robotic arm with a prismatic\njoint, we greatly increase the usability of soft robots for object\nmanipulation. This work promotes the use of integrated and modular soft robotic\nsystems for practical manipulation applications in human-centered environments.",
    "descriptor": "",
    "authors": [
      "Philipp Wand",
      "Oliver Fischer",
      "Robert K. Katzschmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07630"
  },
  {
    "id": "arXiv:2204.07631",
    "title": "Evaluating the Effectiveness of Corrective Demonstrations and a Low-Cost  Sensor for Dexterous Manipulation",
    "abstract": "Imitation learning is a promising approach to help robots acquire dexterous\nmanipulation capabilities without the need for a carefully-designed reward or a\nsignificant computational effort. However, existing imitation learning\napproaches require sophisticated data collection infrastructure and struggle to\ngeneralize beyond the training distribution. One way to address this limitation\nis to gather additional data that better represents the full operating\nconditions. In this work, we investigate characteristics of such additional\ndemonstrations and their impact on performance. Specifically, we study the\neffects of corrective and randomly-sampled additional demonstrations on\nlearning a policy that guides a five-fingered robot hand through a\npick-and-place task. Our results suggest that corrective demonstrations\nconsiderably outperform randomly-sampled demonstrations, when the proportion of\nadditional demonstrations sampled from the full task distribution is larger\nthan the number of original demonstrations sampled from a restrictive training\ndistribution. Conversely, when the number of original demonstrations are higher\nthan that of additional demonstrations, we find no significant differences\nbetween corrective and randomly-sampled additional demonstrations. These\nresults provide insights into the inherent trade-off between the effort\nrequired to collect corrective demonstrations and their relative benefits over\nrandomly-sampled demonstrations. Additionally, we show that inexpensive\nvision-based sensors, such as LeapMotion, can be used to dramatically reduce\nthe cost of providing demonstrations for dexterous manipulation tasks. Our code\nis available at\nhttps://github.com/GT-STAR-Lab/corrective-demos-dexterous-manipulation.",
    "descriptor": "\nComments: Accepted in the Machine Learning in Human-Robot Collaboration Workshop at the 17th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI 2022). The first two authors contributed equally. 6 pages, 7 figures\n",
    "authors": [
      "Abhineet Jain",
      "Jack Kolb",
      "J.M. Abbess IV",
      "Harish Ravichandar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07631"
  },
  {
    "id": "arXiv:2204.07636",
    "title": "Lagrangian Motion Magnification with Double Sparse Optical Flow  Decomposition",
    "abstract": "Motion magnification techniques aim at amplifying and hence revealing subtle\nmotion in videos. There are basically two main approaches to reach this goal,\nnamely via Eulerian or Lagrangian techniques. While the first one magnifies\nmotion implicitly by operating directly on image pixels, the Lagrangian\napproach uses optical flow techniques to extract and amplify pixel\ntrajectories. Microexpressions are fast and spatially small facial expressions\nthat are difficult to detect. In this paper, we propose a novel approach for\nlocal Lagrangian motion magnification of facial micromovements. Our\ncontribution is three-fold: first, we fine-tune the recurrent all-pairs field\ntransforms for optical flows (RAFT) deep learning approach for faces by adding\nground truth obtained from the variational dense inverse search (DIS) for\noptical flow algorithm applied to the CASME II video set of faces. This enables\nus to produce optical flows of facial videos in an efficient and sufficiently\naccurate way. Second, since facial micromovements are both local in space and\ntime, we propose to approximate the optical flow field by sparse components\nboth in space and time leading to a double sparse decomposition. Third, we use\nthis decomposition to magnify micro-motions in specific areas of the face,\nwhere we introduce a new forward warping strategy using a triangular splitting\nof the image grid and barycentric interpolation of the RGB vectors at the\ncorners of the transformed triangles. We demonstrate the very good performance\nof our approach by various examples.",
    "descriptor": "",
    "authors": [
      "Philipp Flotho",
      "Cosmas Heiss",
      "Gabriele Steidl",
      "Daniel J. Strauss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07636"
  },
  {
    "id": "arXiv:2204.07637",
    "title": "Towards a Stronger Theory for Permutation-based Evolutionary Algorithms",
    "abstract": "While the theoretical analysis of evolutionary algorithms (EAs) has made\nsignificant progress for pseudo-Boolean optimization problems in the last 25\nyears, only sporadic theoretical results exist on how EAs solve\npermutation-based problems.\nTo overcome the lack of permutation-based benchmark problems, we propose a\ngeneral way to transfer the classic pseudo-Boolean benchmarks into benchmarks\ndefined on sets of permutations. We then conduct a rigorous runtime analysis of\nthe permutation-based $(1+1)$ EA proposed by Scharnow, Tinnefeld, and Wegener\n(2004) on the analogues of the \\textsc{LeadingOnes} and \\textsc{Jump}\nbenchmarks. The latter shows that, different from bit-strings, it is not only\nthe Hamming distance that determines how difficult it is to mutate a\npermutation $\\sigma$ into another one $\\tau$, but also the precise cycle\nstructure of $\\sigma \\tau^{-1}$. For this reason, we also regard the more\nsymmetric scramble mutation operator. We observe that it not only leads to\nsimpler proofs, but also reduces the runtime on jump functions with odd jump\nsize by a factor of $\\Theta(n)$. Finally, we show that a heavy-tailed version\nof the scramble operator, as in the bit-string case, leads to a speed-up of\norder $m^{\\Theta(m)}$ on jump functions with jump size~$m$.%",
    "descriptor": "\nComments: To appear in the proceedings of GECCO 2022. This version contains the proofs omitted in the proceedings version for reasons of space\n",
    "authors": [
      "Benjamin Doerr",
      "Yassine Ghannane",
      "Marouane Ibn Brahim"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07637"
  },
  {
    "id": "arXiv:2204.07640",
    "title": "Event-aided Direct Sparse Odometry",
    "abstract": "We introduce EDS, a direct monocular visual odometry using events and frames.\nOur algorithm leverages the event generation model to track the camera motion\nin the blind time between frames. The method formulates a direct probabilistic\napproach of observed brightness increments. Per-pixel brightness increments are\npredicted using a sparse number of selected 3D points and are compared to the\nevents via the brightness increment error to estimate camera motion. The method\nrecovers a semi-dense 3D map using photometric bundle adjustment. EDS is the\nfirst method to perform 6-DOF VO using events and frames with a direct\napproach. By design, it overcomes the problem of changing appearance in\nindirect methods. We also show that, for a target error performance, EDS can\nwork at lower frame rates than state-of-the-art frame-based VO solutions. This\nopens the door to low-power motion-tracking applications where frames are\nsparingly triggered \"on demand\" and our method tracks the motion in between. We\nrelease code and datasets to the public.",
    "descriptor": "\nComments: 16 pages, 14 Figures, Page: this https URL\n",
    "authors": [
      "Javier Hidalgo-Carri\u00f3",
      "Guillermo Gallego",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07640"
  },
  {
    "id": "arXiv:2204.07641",
    "title": "Investigating Positive and Negative Qualities of Human-in-the-Loop  Optimization for Designing Interaction Techniques",
    "abstract": "Designers reportedly struggle with design optimization tasks where they are\nasked to find a combination of design parameters that maximizes a given set of\nobjectives. In HCI, design optimization problems are often exceedingly complex,\ninvolving multiple objectives and expensive empirical evaluations. Model-based\ncomputational design algorithms assist designers by generating design examples\nduring design, however they assume a model of the interaction domain. Black box\nmethods for assistance, on the other hand, can work with any design problem.\nHowever, virtually all empirical studies of this human-in-the-loop approach\nhave been carried out by either researchers or end-users. The question stands\nout if such methods can help designers in realistic tasks. In this paper, we\nstudy Bayesian optimization as an algorithmic method to guide the design\noptimization process. It operates by proposing to a designer which design\ncandidate to try next, given previous observations. We report observations from\na comparative study with 40 novice designers who were tasked to optimize a\ncomplex 3D touch interaction technique. The optimizer helped designers explore\nlarger proportions of the design space and arrive at a better solution, however\nthey reported lower agency and expressiveness. Designers guided by an optimizer\nreported lower mental effort but also felt less creative and less in charge of\nthe progress. We conclude that human-in-the-loop optimization can support\nnovice designers in cases where agency is not critical.",
    "descriptor": "\nComments: CHI 2022\n",
    "authors": [
      "Liwei Chan",
      "Yi-Chi Liao",
      "George B. Mo",
      "John J. Dudley",
      "Chun-Lien Cheng",
      "Per Ola Kristensson",
      "Antti Oulasvirta"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07641"
  },
  {
    "id": "arXiv:2204.07644",
    "title": "Identifying Ethical Issues in AI Partners in Human-AI Co-Creation",
    "abstract": "Human-AI co-creativity involves humans and AI collaborating on a shared\ncreative product as partners. In many existing co-creative systems, users\ncommunicate with the AI using buttons or sliders. However, typically, the AI in\nco-creative systems cannot communicate back to humans, limiting their potential\nto be perceived as partners. This paper starts with an overview of a\ncomparative study with 38 participants to explore the impact of AI-to-human\ncommunication on user perception and engagement in co-creative systems and the\nresults show improved collaborative experience and user engagement with the\nsystem incorporating AI-to-human communication. The results also demonstrate\nthat users perceive co-creative AI as more reliable, personal and intelligent\nwhen it can communicate with the users. The results indicate a need to identify\npotential ethical issues from an engaging communicating co-creative AI. Later\nin the paper, we present some potential ethical issues in human-AI co-creation\nand propose to use participatory design fiction as the research methodology to\ninvestigate the ethical issues associated with a co-creative AI that\ncommunicates with users.",
    "descriptor": "",
    "authors": [
      "Jeba Rezwana",
      "Mary Lou Maher"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07644"
  },
  {
    "id": "arXiv:2204.07649",
    "title": "MultiEarth 2022 -- Multimodal Learning for Earth and Environment  Workshop and Challenge",
    "abstract": "The Multimodal Learning for Earth and Environment Challenge (MultiEarth 2022)\nwill be the first competition aimed at the monitoring and analysis of\ndeforestation in the Amazon rainforest at any time and in any weather\nconditions. The goal of the Challenge is to provide a common benchmark for\nmultimodal information processing and to bring together the earth and\nenvironmental science communities as well as multimodal representation learning\ncommunities to compare the relative merits of the various multimodal learning\nmethods to deforestation estimation under well-defined and strictly comparable\nconditions. MultiEarth 2022 will have three sub-challenges: 1) matrix\ncompletion, 2) deforestation estimation, and 3) image-to-image translation.\nThis paper presents the challenge guidelines, datasets, and evaluation metrics\nfor the three sub-challenges. Our challenge website is available at\nhttps://sites.google.com/view/rainforest-challenge.",
    "descriptor": "",
    "authors": [
      "Miriam Cha",
      "Kuan Wei Huang",
      "Morgan Schmidt",
      "Gregory Angelides",
      "Mark Hamilton",
      "Sam Goldberg",
      "Armando Cabrera",
      "Phillip Isola",
      "Taylor Perron",
      "Bill Freeman",
      "Yen-Chen Lin",
      "Brandon Swenson",
      "Jean Piou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07649"
  },
  {
    "id": "arXiv:2204.07651",
    "title": "Learning time-dependent PDE solver using Message Passing Graph Neural  Networks",
    "abstract": "One of the main challenges in solving time-dependent partial differential\nequations is to develop computationally efficient solvers that are accurate and\nstable. Here, we introduce a graph neural network approach to finding efficient\nPDE solvers through learning using message-passing models. We first introduce\ndomain invariant features for PDE-data inspired by classical PDE solvers for an\nefficient physical representation. Next, we use graphs to represent PDE-data on\nan unstructured mesh and show that message passing graph neural networks\n(MPGNN) can parameterize governing equations, and as a result, efficiently\nlearn accurate solver schemes for linear/nonlinear PDEs. We further show that\nthe solvers are independent of the initial trained geometry, i.e. the trained\nsolver can find PDE solution on different complex domains. Lastly, we show that\na recurrent graph neural network approach can find a temporal sequence of\nsolutions to a PDE.",
    "descriptor": "",
    "authors": [
      "Pourya Pilva",
      "Ahmad Zareei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07651"
  },
  {
    "id": "arXiv:2204.07653",
    "title": "Bayesian Updating of Seismic Ground Failure Estimates via Causal  Graphical Models and Satellite Imagery",
    "abstract": "Earthquake-induced secondary ground failure hazards, such as liquefaction and\nlandslides, result in catastrophic building and infrastructure damage as well\nas human fatalities. To facilitate emergency responses and mitigate losses, the\nU.S. Geological Survey provides a rapid hazard estimation system for\nearthquake-triggered landslides and liquefaction using geospatial\nsusceptibility proxies and ShakeMap ground motion estimates. In this study, we\ndevelop a generalized causal graph-based Bayesian network that models the\nphysical interdependencies between geospatial features, seismic ground\nfailures, and building damage, as well as DPMs. Geospatial features provide\nphysical insights for estimating ground failure occurrence while DPMs contain\nevent-specific surface change observations. This physics-informed causal graph\nincorporates these variables with complex physical relationships in one\nholistic Bayesian updating scheme to effectively fuse information from both\ngeospatial models and remote sensing data. This framework is scalable and\nflexible enough to deal with highly complex multi-hazard combinations. We then\ndevelop a stochastic variational inference algorithm to jointly update the\nintractable posterior probabilities of unobserved landslides, liquefaction, and\nbuilding damage at different locations efficiently. In addition, a local\ngraphical model pruning algorithm is presented to reduce the computational cost\nof large-scale seismic ground failure estimation. We apply this framework to\nthe September 2018 Hokkaido Iburi-Tobu, Japan (M6.6) earthquake and January\n2020 Southwest Puerto Rico (M6.4) earthquake to evaluate the performance of our\nalgorithm.",
    "descriptor": "\nComments: The 17th World Conference on Earthquake Engineering, Sendai, Japan, Sep. 2021\n",
    "authors": [
      "Susu Xu",
      "Joshua Dimasaka",
      "David J. Wald",
      "Hae Young Noh"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.07653"
  },
  {
    "id": "arXiv:2204.07655",
    "title": "Deep Unlearning via Randomized Conditionally Independent Hessians",
    "abstract": "Recent legislation has led to interest in machine unlearning, i.e., removing\nspecific training samples from a predictive model as if they never existed in\nthe training dataset. Unlearning may also be required due to\ncorrupted/adversarial data or simply a user's updated privacy requirement. For\nmodels which require no training (k-NN), simply deleting the closest original\nsample can be effective. But this idea is inapplicable to models which learn\nricher representations. Recent ideas leveraging optimization-based updates\nscale poorly with the model dimension d, due to inverting the Hessian of the\nloss function. We use a variant of a new conditional independence coefficient,\nL-CODEC, to identify a subset of the model parameters with the most semantic\noverlap on an individual sample level. Our approach completely avoids the need\nto invert a (possibly) huge matrix. By utilizing a Markov blanket selection, we\npremise that L-CODEC is also suitable for deep unlearning, as well as other\napplications in vision. Compared to alternatives, L-CODEC makes approximate\nunlearning possible in settings that would otherwise be infeasible, including\nvision models used for face recognition, person re-identification and NLP\nmodels that may require unlearning samples identified for exclusion. Code can\nbe found at https://github.com/vsingh-group/LCODEC-deep-unlearning/",
    "descriptor": "\nComments: Accepted to IEEE Computer Vision and Pattern Recognition, CVPR 2022\n",
    "authors": [
      "Ronak Mehta",
      "Sourav Pal",
      "Vikas Singh",
      "Sathya N. Ravi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07655"
  },
  {
    "id": "arXiv:2204.07657",
    "title": "Accurate detection of sepsis at ED triage using machine learning with  clinical natural language processing",
    "abstract": "Sepsis is a life-threatening condition with organ dysfunction and is a\nleading cause of death and critical illness worldwide. Accurate detection of\nsepsis during emergency department triage would allow early initiation of lab\nanalysis, antibiotic administration, and other sepsis treatment protocols. The\npurpose of this study was to determine whether EHR data can be extracted and\nsynthesized with the latest machine learning algorithms (KATE Sepsis) and\nclinical natural language processing to produce accurate sepsis models, and\ncompare KATE Sepsis performance with existing sepsis screening protocols, such\nas SIRS and qSOFA. A machine learning model (KATE Sepsis) was developed using\npatient encounters with triage data from 16 participating hospitals. KATE\nSepsis, SIRS, standard screening (SIRS with source of infection) and qSOFA were\ntested in three settings. Cohort-A was a retrospective analysis on medical\nrecords from a single Site 1. Cohort-B was a prospective analysis of Site 1.\nCohort-C was a retrospective analysis on Site 1 with 15 additional sites.\nAcross all cohorts, KATE Sepsis demonstrates an AUC of 0.94-0.963 with\n73-74.87% TPR and 3.76-7.17% FPR. Standard screening demonstrates an AUC of\n0.682-0.726 with 39.39-51.19% TPR and 2.9-6.02% FPR. The qSOFA protocol\ndemonstrates an AUC of 0.544-0.56, with 10.52-13.18% TPR and 1.22-1.68% FPR.\nFor severe sepsis, across all cohorts, KATE Sepsis demonstrates an AUC of\n0.935-0.972 with 70-82.26% TPR and 4.64-8.62% FPR. For septic shock, across all\ncohorts, KATE Sepsis demonstrates an AUC of 0.96-0.981 with 85.71-89.66% TPR\nand 4.85-8.8% FPR. SIRS, standard screening, and qSOFA demonstrate low AUC and\nTPR for severe sepsis and septic shock detection. KATE Sepsis provided\nsubstantially better sepsis detection performance in triage than commonly used\nscreening protocols.",
    "descriptor": "\nComments: 35 pages, 1 figure, 6 tables, 7 supplementary tables\n",
    "authors": [
      "Oleksandr Ivanov",
      "Karen Molander",
      "Robert Dunne",
      "Stephen Liu",
      "Kevin Masek",
      "Erica Lewis",
      "Lisa Wolf",
      "Debbie Travers",
      "Deena Brecher",
      "Deb Delaney",
      "Kyla Montgomery",
      "Christian Reilly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07657"
  },
  {
    "id": "arXiv:2204.07660",
    "title": "It is Okay to Not Be Okay: Overcoming Emotional Bias in Affective Image  Captioning by Contrastive Data Collection",
    "abstract": "Datasets that capture the connection between vision, language, and affection\nare limited, causing a lack of understanding of the emotional aspect of human\nintelligence. As a step in this direction, the ArtEmis dataset was recently\nintroduced as a large-scale dataset of emotional reactions to images along with\nlanguage explanations of these chosen emotions. We observed a significant\nemotional bias towards instance-rich emotions, making trained neural speakers\nless accurate in describing under-represented emotions. We show that collecting\nnew data, in the same way, is not effective in mitigating this emotional bias.\nTo remedy this problem, we propose a contrastive data collection approach to\nbalance ArtEmis with a new complementary dataset such that a pair of similar\nimages have contrasting emotions (one positive and one negative). We collected\n260,533 instances using the proposed method, we combine them with ArtEmis,\ncreating a second iteration of the dataset. The new combined dataset, dubbed\nArtEmis v2.0, has a balanced distribution of emotions with explanations\nrevealing more fine details in the associated painting. Our experiments show\nthat neural speakers trained on the new dataset improve CIDEr and METEOR\nevaluation metrics by 20% and 7%, respectively, compared to the biased dataset.\nFinally, we also show that the performance per emotion of neural speakers is\nimproved across all the emotion categories, significantly on under-represented\nemotions. The collected dataset and code are available at\nhttps://artemisdataset-v2.org.",
    "descriptor": "\nComments: 8 pages, Accepted at CVPR 22, for more details see this https URL\n",
    "authors": [
      "Youssef Mohamed",
      "Faizan Farooq Khan",
      "Kilichbek Haydarov",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07660"
  },
  {
    "id": "arXiv:2204.07661",
    "title": "Fairly Accurate: Learning Optimal Accuracy vs. Fairness Tradeoffs for  Hate Speech Detection",
    "abstract": "Recent work has emphasized the importance of balancing competing objectives\nin model training (e.g., accuracy vs. fairness, or competing measures of\nfairness). Such trade-offs reflect a broader class of multi-objective\noptimization (MOO) problems in which optimization methods seek Pareto optimal\ntrade-offs between competing goals. In this work, we first introduce a\ndifferentiable measure that enables direct optimization of group fairness\n(specifically, balancing accuracy across groups) in model training. Next, we\ndemonstrate two model-agnostic MOO frameworks for learning Pareto optimal\nparameterizations over different groups of neural classification models. We\nevaluate our methods on the specific task of hate speech detection, in which\nprior work has shown lack of group fairness across speakers of different\nEnglish dialects. Empirical results across convolutional, sequential, and\ntransformer-based neural architectures show superior empirical accuracy vs.\nfairness trade-offs over prior work. More significantly, our measure enables\nthe Pareto machinery to ensure that each architecture achieves the best\npossible trade-off between fairness and accuracy w.r.t. the dataset, given\nuser-prescribed error tolerance bounds.",
    "descriptor": "",
    "authors": [
      "Venelin Kovatchev",
      "Soumyajit Gupta",
      "Matthew Lease"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07661"
  },
  {
    "id": "arXiv:2204.07662",
    "title": "A Catalogue of Concerns for Specifying Machine Learning-Enabled Systems",
    "abstract": "Requirements engineering (RE) activities for Machine Learning (ML) are not\nwell-established and researched in the literature. Many issues and challenges\nexist when specifying, designing, and developing ML-enabled systems. Adding\nmore focus on RE for ML can help to develop more reliable ML-enabled systems.\nBased on insights collected from previous work and industrial experiences, we\npropose a catalogue of 45 concerns to be considered when specifying ML-enabled\nsystems, covering five different perspectives we identified as relevant for\nsuch systems: objectives, user experience, infrastructure, model, and data.\nExamples of such concerns include the execution engine and telemetry for the\ninfrastructure perspective, and explainability and reproducibility for the\nmodel perspective. We conducted a focus group session with eight software\nprofessionals with experience developing ML-enabled systems to validate the\nimportance, quality and feasibility of using our catalogue. The feedback\nallowed us to improve the catalogue and confirmed its practical relevance. The\nmain research contribution of this work consists in providing a validated set\nof concerns grouped into perspectives that can be used by requirements\nengineers to support the specification of ML-enabled systems.",
    "descriptor": "",
    "authors": [
      "Hugo Villamizar",
      "Marcos Kalinowski",
      "Helio lopes"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.07662"
  },
  {
    "id": "arXiv:2204.07663",
    "title": "Spanish Abstract Meaning Representation: Annotation of a General Corpus",
    "abstract": "The Abstract Meaning Representation (AMR) formalism, designed originally for\nEnglish, has been adapted to a number of languages. We build on previous work\nproposing the annotation of AMR in Spanish, which resulted in the release of 50\nSpanish AMR annotations for the fictional text \"The Little Prince.\" In this\nwork, we present the first sizable, general annotation project for Spanish\nAbstract Meaning Representation. Our approach to annotation makes use of\nSpanish rolesets from the AnCora-Net lexicon and extends English AMR with\nsemantic features specific to Spanish. In addition to our guidelines, we\nrelease an annotated corpus (586 annotations total, for 486 unique sentences)\nof multiple genres of documents from the \"Abstract Meaning Representation 2.0 -\nFour Translations\" sembank. This corpus is commonly used for evaluation of AMR\nparsing and generation, but does not include gold AMRs; we hope that providing\ngold annotations for this dataset can result in a more complete approach to\ncross-lingual AMR parsing. Finally, we perform a disagreement analysis and\ndiscuss the implications of our work on the adaptability of AMR to languages\nother than English.",
    "descriptor": "",
    "authors": [
      "Shira Wein",
      "Lucia Donatelli",
      "Ethan Ricker",
      "Calvin Engstrom",
      "Alex Nelson",
      "Nathan Schneider"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07663"
  },
  {
    "id": "arXiv:2204.07664",
    "title": "Conditional Injective Flows for Bayesian Imaging",
    "abstract": "Most deep learning models for computational imaging regress a single\nreconstructed image. In practice, however, ill-posedness, nonlinearity, model\nmismatch, and noise often conspire to make such point estimates misleading or\ninsufficient. The Bayesian approach models images and (noisy) measurements as\njointly distributed random vectors and aims to approximate the posterior\ndistribution of unknowns. Recent variational inference methods based on\nconditional normalizing flows are a promising alternative to traditional MCMC\nmethods, but they come with drawbacks: excessive memory and compute demands for\nmoderate to high resolution images and underwhelming performance on hard\nnonlinear problems. In this work, we propose C-Trumpets -- conditional\ninjective flows specifically designed for imaging problems, which greatly\ndiminish these challenges. Injectivity reduces memory footprint and training\ntime while low-dimensional latent space together with architectural innovations\nlike fixed-volume-change layers and skip-connection revnet layers, C-Trumpets\noutperform regular conditional flow models on a variety of imaging and image\nrestoration tasks, including limited-view CT and nonlinear inverse scattering,\nwith a lower compute and memory budget. C-Trumpets enable fast approximation of\npoint estimates like MMSE or MAP as well as physically-meaningful uncertainty\nquantification.",
    "descriptor": "\nComments: 23 pages, 23 figures\n",
    "authors": [
      "AmirEhsan Khorashadizadeh",
      "Konik Kothari",
      "Leonardo Salsi",
      "Ali Aghababaei Harandi",
      "Maarten de Hoop",
      "Ivan Dokmani'c"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07664"
  },
  {
    "id": "arXiv:2204.07665",
    "title": "Higher-Order SGFEM for One-Dimensional Interface Elliptic Problems with  Discontinuous Solutions",
    "abstract": "We study a class of enriched unfitted finite element or generalized finite\nelement methods (GFEM) to solve a larger class of interface problems, that is,\n1D elliptic interface problems with discontinuous solutions, including those\nhaving implicit or Robin-type interface jump conditions. The major challenge of\nGFEM development is to construct enrichment functions that capture the imposed\ndiscontinuity of the solution while keeping the condition number from fast\ngrowth. The linear stable generalized finite element method (SGFEM) was\nrecently developed using one enrichment function. We generalized it to an\narbitrary degree using two simple discontinuous one-sided enrichment functions.\nOptimal order convergence in the $L^2$ and broken $H^1$-norms are established.\nSo is the optimal order convergence at all nodes. To prove the efficiency of\nthe SGFEM, the enriched linear, quadratic, and cubic elements are applied to a\nmulti-layer wall model for drug-eluting stents in which zero-flux jump\nconditions and implicit concentration interface conditions are both present.",
    "descriptor": "",
    "authors": [
      "Champike Attanayake",
      "So-Hsiang Chou",
      "Quanling Deng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07665"
  },
  {
    "id": "arXiv:2204.07666",
    "title": "Designing Creative AI Partners with COFI: A Framework for Modeling  Interaction in Human-AI Co-Creative Systems",
    "abstract": "Human-AI co-creativity involves both humans and AI collaborating on a shared\ncreative product as partners. In a creative collaboration, interaction\ndynamics, such as turn-taking, contribution type, and communication, are the\ndriving forces of the co-creative process. Therefore the interaction model is a\ncritical and essential component for effective co-creative systems. There is\nrelatively little research about interaction design in the co-creativity field,\nwhich is reflected in a lack of focus on interaction design in many existing\nco-creative systems. The primary focus of co-creativity research has been on\nthe abilities of the AI. This paper focuses on the importance of interaction\ndesign in co-creative systems with the development of the Co-Creative Framework\nfor Interaction design (COFI) that describes the broad scope of possibilities\nfor interaction design in co-creative systems. Researchers can use COFI for\nmodeling interaction in co-creative systems by exploring alternatives in this\ndesign space of interaction. COFI can also be beneficial while investigating\nand interpreting the interaction design of existing co-creative systems. We\ncoded a dataset of existing 92 co-creative systems using COFI and analyzed the\ndata to show how COFI provides a basis to categorize the interaction models of\nexisting co-creative systems. We identify opportunities to shift the focus of\ninteraction models in co-creativity to enable more communication between the\nuser and AI leading to human-AI partnerships.",
    "descriptor": "\nComments: This paper appears in the ACM Transactions on Computer-Human Interaction. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission from permissions@acm.org\n",
    "authors": [
      "Jeba Rezwana",
      "Mary Lou Maher"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07666"
  },
  {
    "id": "arXiv:2204.07667",
    "title": "Just Fine-tune Twice: Selective Differential Privacy for Large Language  Models",
    "abstract": "With the increasing adoption of NLP models in real-world products, it becomes\nmore and more important to protect these models from privacy leakage. Because\nprivate information in language data is sparse, previous research formalized a\nSelective-Differential-Privacy (SDP) notion to provide protection for sensitive\ntokens detected by policy functions, and prove its effectiveness on RNN-based\nmodels. But the previous mechanism requires separating the private and public\nmodel parameters and thus cannot be applied on large attention-based models. In\nthis paper, we propose a simple yet effective just-fine-tune-twice privacy\nmechanism to first fine-tune on in-domain redacted data and then on in-domain\nprivate data, to achieve SDP for large Transformer-based language models. We\nalso design explicit and contextual policy functions to provide protections at\ndifferent levels. Experiments show that our models achieve strong performance\nwhile staying robust to the canary insertion attack. We further show that even\nunder low-resource settings with a small amount of in-domain data, SDP can\nstill improve the model utility. We will release the code, data and models to\nfacilitate future research.",
    "descriptor": "",
    "authors": [
      "Weiyan Shi",
      "Si Chen",
      "Chiyuan Zhang",
      "Ruoxi Jia",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.07667"
  },
  {
    "id": "arXiv:2204.07669",
    "title": "Investigating the Impact of Forgetting in Software Development",
    "abstract": "Context: Forgetting is defined as a gradual process of losing information.\nEven though there are many studies demonstrating the effect of forgetting in\nsoftware development, to the best of our knowledge, no study explores the\nimpact of forgetting in software development using a controlled experiment\napproach. Objective: We would like to provide insights on the impact of\nforgetting in software development projects. We want to examine whether the\nrecency & frequency of interaction impact forgetting in software development.\nMethods: We will conduct an experiment that examines the impact of forgetting\nin software development. Participants will first do an initial task. According\nto their initial task performance, they will be assigned to either the\nexperiment or the control group. The experiment group will then do two\nadditional tasks to enhance their exposure to the code. Both groups will then\ndo a final task to see if additional exposure to the code benefits the\nexperiment group's performance in the final task. Finally, we will conduct a\nsurvey and a recall task with the same participants to collect data about their\nperceptions of forgetting and quantify their memory performance, respectively.",
    "descriptor": "\nComments: 8 pages, 6 figures, accepted at the MSR 2022 Registered Reports Track as a Continuity Acceptance (CA)\n",
    "authors": [
      "Utku \u00dcnal",
      "Eray T\u00fcz\u00fcn",
      "Tamer Gezici",
      "Ausaf Ahmed Farooqui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.07669"
  },
  {
    "id": "arXiv:2204.07673",
    "title": "Self-Similarity Priors: Neural Collages as Differentiable Fractal  Representations",
    "abstract": "Many patterns in nature exhibit self-similarity: they can be compactly\ndescribed via self-referential transformations. Said patterns commonly appear\nin natural and artificial objects, such as molecules, shorelines, galaxies and\neven images. In this work, we investigate the role of learning in the automated\ndiscovery of self-similarity and in its utilization for downstream tasks. To\nthis end, we design a novel class of implicit operators, Neural Collages, which\n(1) represent data as the parameters of a self-referential, structured\ntransformation, and (2) employ hypernetworks to amortize the cost of finding\nthese parameters to a single forward pass. We investigate how to leverage the\nrepresentations produced by Neural Collages in various tasks, including data\ncompression and generation. Neural Collages image compressors are orders of\nmagnitude faster than other self-similarity-based algorithms during encoding\nand offer compression rates competitive with implicit methods. Finally, we\nshowcase applications of Neural Collages for fractal art and as deep generative\nmodels.",
    "descriptor": "",
    "authors": [
      "Michael Poli",
      "Winnie Xu",
      "Stefano Massaroli",
      "Chenlin Meng",
      "Kuno Kim",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07673"
  },
  {
    "id": "arXiv:2204.07674",
    "title": "CILDA: Contrastive Data Augmentation using Intermediate Layer Knowledge  Distillation",
    "abstract": "Knowledge distillation (KD) is an efficient framework for compressing\nlarge-scale pre-trained language models. Recent years have seen a surge of\nresearch aiming to improve KD by leveraging Contrastive Learning, Intermediate\nLayer Distillation, Data Augmentation, and Adversarial Training. In this work,\nwe propose a learning based data augmentation technique tailored for knowledge\ndistillation, called CILDA. To the best of our knowledge, this is the first\ntime that intermediate layer representations of the main task are used in\nimproving the quality of augmented samples. More precisely, we introduce an\naugmentation technique for KD based on intermediate layer matching using\ncontrastive loss to improve masked adversarial data augmentation. CILDA\noutperforms existing state-of-the-art KD approaches on the GLUE benchmark, as\nwell as in an out-of-domain evaluation.",
    "descriptor": "",
    "authors": [
      "Md Akmal Haidar",
      "Mehdi Rezagholizadeh",
      "Abbas Ghaddar",
      "Khalil Bibi",
      "Philippe Langlais",
      "Pascal Poupart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07674"
  },
  {
    "id": "arXiv:2204.07675",
    "title": "MoEBERT: from BERT to Mixture-of-Experts via Importance-Guided  Adaptation",
    "abstract": "Pre-trained language models have demonstrated superior performance in various\nnatural language processing tasks. However, these models usually contain\nhundreds of millions of parameters, which limits their practicality because of\nlatency requirements in real-world applications. Existing methods train small\ncompressed models via knowledge distillation. However, performance of these\nsmall models drops significantly compared with the pre-trained models due to\ntheir reduced model capacity. We propose MoEBERT, which uses a\nMixture-of-Experts structure to increase model capacity and inference speed. We\ninitialize MoEBERT by adapting the feed-forward neural networks in a\npre-trained model into multiple experts. As such, representation power of the\npre-trained model is largely retained. During inference, only one of the\nexperts is activated, such that speed can be improved. We also propose a\nlayer-wise distillation method to train MoEBERT. We validate the efficiency and\neffectiveness of MoEBERT on natural language understanding and question\nanswering tasks. Results show that the proposed method outperforms existing\ntask-specific distillation algorithms. For example, our method outperforms\nprevious approaches by over 2% on the MNLI (mismatched) dataset. Our code is\npublicly available at https://github.com/SimiaoZuo/MoEBERT.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Simiao Zuo",
      "Qingru Zhang",
      "Chen Liang",
      "Pengcheng He",
      "Tuo Zhao",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07675"
  },
  {
    "id": "arXiv:2204.07679",
    "title": "DialAug: Mixing up Dialogue Contexts in Contrastive Learning for Robust  Conversational Modeling",
    "abstract": "Retrieval-based conversational systems learn to rank response candidates for\na given dialogue context by computing the similarity between their vector\nrepresentations. However, training on a single textual form of the multi-turn\ncontext limits the ability of a model to learn representations that generalize\nto natural perturbations seen during inference. In this paper we propose a\nframework that incorporates augmented versions of a dialogue context into the\nlearning objective. We utilize contrastive learning as an auxiliary objective\nto learn robust dialogue context representations that are invariant to\nperturbations injected through the augmentation method. We experiment with four\nbenchmark dialogue datasets and demonstrate that our framework combines well\nwith existing augmentation methods and can significantly improve over baseline\nBERT-based ranking architectures. Furthermore, we propose a novel data\naugmentation method, ConMix, that adds token level perturbations through\nstochastic mixing of tokens from other contexts in the batch. We show that our\nproposed augmentation method outperforms previous data augmentation approaches,\nand provides dialogue representations that are more robust to common\nperturbations seen during inference.",
    "descriptor": "",
    "authors": [
      "Lahari Poddar",
      "Peiyao Wang",
      "Julia Reinspach"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07679"
  },
  {
    "id": "arXiv:2204.07682",
    "title": "Data-Centric Distrust Quantification for Responsible AI: When  Data-driven Outcomes Are Not Reliable",
    "abstract": "At the same time that AI and machine learning are becoming central to human\nlife, their potential harms become more vivid. In the presence of such\ndrawbacks, a critical question one needs to address before using these\ndata-driven technologies to make a decision is whether to trust their outcomes.\nAligned with recent efforts on data-centric AI, this paper proposes a novel\napproach to address the trust question through the lens of data, by associating\ndata sets with distrust quantification that specify their scope of use for\npredicting future query points. The distrust values raise warning signals when\na prediction based on a dataset is questionable and are valuable alongside\nother techniques for trustworthy AI. We propose novel algorithms for computing\nthe distrust values in the neighborhood of a query point efficiently and\neffectively. Learning the necessary components of the measures from the data\nitself, our sub-linear algorithms scale to very large and multi-dimensional\nsettings. Besides demonstrating the efficiency of our algorithms, our extensive\nexperiments reflect a consistent correlation between distrust values and model\nperformance. This underscores the message that when the distrust value of a\nquery point is high, the prediction outcome should be discarded or at least not\nconsidered for critical decisions.",
    "descriptor": "",
    "authors": [
      "Nima Shahbazi",
      "Abolfazl Asudeh"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2204.07682"
  },
  {
    "id": "arXiv:2204.07683",
    "title": "Safe Self-Refinement for Transformer-based Domain Adaptation",
    "abstract": "Unsupervised Domain Adaptation (UDA) aims to leverage a label-rich source\ndomain to solve tasks on a related unlabeled target domain. It is a challenging\nproblem especially when a large domain gap lies between the source and target\ndomains. In this paper we propose a novel solution named SSRT (Safe\nSelf-Refinement for Transformer-based domain adaptation), which brings\nimprovement from two aspects. First, encouraged by the success of vision\ntransformers in various vision tasks, we arm SSRT with a transformer backbone.\nWe find that the combination of vision transformer with simple adversarial\nadaptation surpasses best reported Convolutional Neural Network (CNN)-based\nresults on the challenging DomainNet benchmark, showing its strong transferable\nfeature representation. Second, to reduce the risk of model collapse and\nimprove the effectiveness of knowledge transfer between domains with large\ngaps, we propose a Safe Self-Refinement strategy. Specifically, SSRT utilizes\npredictions of perturbed target domain data to refine the model. Since the\nmodel capacity of vision transformer is large and predictions in such\nchallenging tasks can be noisy, a safe training mechanism is designed to\nadaptively adjust learning configuration. Extensive evaluations are conducted\non several widely tested UDA benchmarks and SSRT achieves consistently the best\nperformances, including 85.43% on Office-Home, 88.76% on VisDA-2017 and 45.2%\non DomainNet.",
    "descriptor": "\nComments: To appear in CVPR 2022\n",
    "authors": [
      "Tao Sun",
      "Cheng Lu",
      "Tianshuo Zhang",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07683"
  },
  {
    "id": "arXiv:2204.07684",
    "title": "Circuit-theoretic Line Outage Distribution Factor",
    "abstract": "This work presents the design of AC line outage distribution factor created\nfrom the circuit-theoretic power flow models. Experiment results are shown to\ndemonstrate its efficacy in quantifying the impact of line outages on the grid,\nand its resulting potential for fast contingency screening.",
    "descriptor": "",
    "authors": [
      "Shimiao Li",
      "Amritanshu Pandey",
      "Larry Pileggi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07684"
  },
  {
    "id": "arXiv:2204.07689",
    "title": "Sparsely Activated Mixture-of-Experts are Robust Multi-Task Learners",
    "abstract": "Traditional multi-task learning (MTL) methods use dense networks that use the\nsame set of shared weights across several different tasks. This often creates\ninterference where two or more tasks compete to pull model parameters in\ndifferent directions. In this work, we study whether sparsely activated\nMixture-of-Experts (MoE) improve multi-task learning by specializing some\nweights for learning shared representations and using the others for learning\ntask-specific information. To this end, we devise task-aware gating functions\nto route examples from different tasks to specialized experts which share\nsubsets of network weights conditioned on the task. This results in a sparsely\nactivated multi-task model with a large number of parameters, but with the same\ncomputational cost as that of a dense model. We demonstrate such sparse\nnetworks to improve multi-task learning along three key dimensions: (i)\ntransfer to low-resource tasks from related tasks in the training mixture; (ii)\nsample-efficient generalization to tasks not seen during training by making use\nof task-aware routing from seen related tasks; (iii) robustness to the addition\nof unrelated tasks by avoiding catastrophic forgetting of existing tasks.",
    "descriptor": "",
    "authors": [
      "Shashank Gupta",
      "Subhabrata Mukherjee",
      "Krishan Subudhi",
      "Eduardo Gonzalez",
      "Damien Jose",
      "Ahmed H. Awadallah",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07689"
  },
  {
    "id": "arXiv:2204.07692",
    "title": "FedVQCS: Federated Learning via Vector Quantized Compressed Sensing",
    "abstract": "In this paper, a new communication-efficient federated learning (FL)\nframework is proposed, inspired by vector quantized compressed sensing. The\nbasic strategy of the proposed framework is to compress the local model update\nat each device by applying dimensionality reduction followed by vector\nquantization. Subsequently, the global model update is reconstructed at a\nparameter server (PS) by applying a sparse signal recovery algorithm to the\naggregation of the compressed local model updates. By harnessing the benefits\nof both dimensionality reduction and vector quantization, the proposed\nframework effectively reduces the communication overhead of local update\ntransmissions. Both the design of the vector quantizer and the key parameters\nfor the compression are optimized so as to minimize the reconstruction error of\nthe global model update under the constraint of wireless link capacity. By\nconsidering the reconstruction error, the convergence rate of the proposed\nframework is also analyzed for a smooth loss function. Simulation results on\nthe MNIST and CIFAR-10 datasets demonstrate that the proposed framework\nprovides more than a 2.5% increase in classification accuracy compared to\nstate-of-art FL frameworks when the communication overhead of the local model\nupdate transmission is less than 0.1 bit per local model entry.",
    "descriptor": "",
    "authors": [
      "Yongjeong Oh",
      "Yo-Seb Jeon",
      "Mingzhe Chen",
      "Walid Saad"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.07692"
  },
  {
    "id": "arXiv:2204.07693",
    "title": "Calibrating Trust of Multi-Hop Question Answering Systems with  Decompositional Probes",
    "abstract": "Multi-hop Question Answering (QA) is a challenging task since it requires an\naccurate aggregation of information from multiple context paragraphs and a\nthorough understanding of the underlying reasoning chains. Recent work in\nmulti-hop QA has shown that performance can be boosted by first decomposing the\nquestions into simpler, single-hop questions. In this paper, we explore one\nadditional utility of the multi-hop decomposition from the perspective of\nexplainable NLP: to create explanation by probing a neural QA model with them.\nWe hypothesize that in doing so, users will be better able to construct a\nmental model of when the underlying QA system will give the correct answer.\nThrough human participant studies, we verify that exposing the decomposition\nprobes and answers to the probes to users can increase their ability to predict\nsystem performance on a question instance basis. We show that decomposition is\nan effective form of probing QA systems as well as a promising approach to\nexplanation generation. In-depth analyses show the need for improvements in\ndecomposition systems.",
    "descriptor": "",
    "authors": [
      "Kaige Xie",
      "Sarah Wiegreffe",
      "Mark Riedl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07693"
  },
  {
    "id": "arXiv:2204.07696",
    "title": "Efficient Reinforcement Learning for Unsupervised Controlled Text  Generation",
    "abstract": "Controlled text generation tasks such as unsupervised text style transfer\nhave increasingly adopted the use of Reinforcement Learning (RL). A major\nchallenge in applying RL to such tasks is the sparse reward, which is available\nonly after the full text is generated. Sparse rewards, combined with a large\naction space make RL training sample-inefficient and difficult to converge.\nRecently proposed reward-shaping strategies to address this issue have shown\nonly negligible gains. In contrast, this work proposes a novel approach that\nprovides dense rewards to each generated token. We evaluate our approach by its\nusage in unsupervised text style transfer. Averaged across datasets, our style\ntransfer system improves upon current state-of-art systems by 21\\% on human\nevaluation and 12\\% on automatic evaluation. Upon ablated comparison with the\ncurrent reward shaping approach (the `roll-out strategy'), using dense rewards\nimproves the overall style transfer quality by 22\\% based on human evaluation.\nFurther the RL training is 2.5 times as sample efficient, and 7 times faster.",
    "descriptor": "\nComments: 10 pages, 2 figures, 4 tables\n",
    "authors": [
      "Bhargav Upadhyay",
      "Akhilesh Sudhakar",
      "Arjun Maheswaran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07696"
  },
  {
    "id": "arXiv:2204.07697",
    "title": "Theory of Graph Neural Networks: Representation and Learning",
    "abstract": "Graph Neural Networks (GNNs), neural network architectures targeted to\nlearning representations of graphs, have become a popular learning model for\nprediction tasks on nodes, graphs and configurations of points, with wide\nsuccess in practice. This article summarizes a selection of the emerging\ntheoretical results on approximation and learning properties of widely used\nmessage passing GNNs and higher-order GNNs, focusing on representation,\ngeneralization and extrapolation. Along the way, it summarizes mathematical\nconnections.",
    "descriptor": "",
    "authors": [
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07697"
  },
  {
    "id": "arXiv:2204.07701",
    "title": "BLCU-ICALL at SemEval-2022 Task 1: Cross-Attention Multitasking  Framework for Definition Modeling",
    "abstract": "This paper describes the BLCU-ICALL system used in the SemEval-2022 Task 1\nComparing Dictionaries and Word Embeddings, the Definition Modeling subtrack,\nachieving 1st on Italian, 2nd on Spanish and Russian, and 3rd on English and\nFrench. We propose a transformer-based multitasking framework to explore the\ntask. The framework integrates multiple embedding architectures through the\ncross-attention mechanism, and captures the structure of glosses through a\nmasking language model objective. Additionally, we also investigate a simple\nbut effective model ensembling strategy to further improve the robustness. The\nevaluation results show the effectiveness of our solution. We release our code\nat: https://github.com/blcuicall/SemEval2022-Task1-DM.",
    "descriptor": "",
    "authors": [
      "Cunliang Kong",
      "Yujie Wang",
      "Ruining Chong",
      "Liner Yang",
      "Hengyuan Zhang",
      "Erhong Yang",
      "Yaping Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07701"
  },
  {
    "id": "arXiv:2204.07703",
    "title": "TeleGraph: A Benchmark Dataset for Hierarchical Link Prediction",
    "abstract": "Link prediction is a key problem for network-structured data, attracting\nconsiderable research efforts owing to its diverse applications. The current\nlink prediction methods focus on general networks and are overly dependent on\neither the closed triangular structure of networks or node attributes. Their\nperformance on sparse or highly hierarchical networks has not been well\nstudied. On the other hand, the available tree-like benchmark datasets are\neither simulated, with limited node information, or small in scale. To bridge\nthis gap, we present a new benchmark dataset TeleGraph, a highly sparse and\nhierarchical telecommunication network associated with rich node attributes,\nfor assessing and fostering the link inference techniques. Our empirical\nresults suggest that most of the algorithms fail to produce a satisfactory\nperformance on a nearly tree-like dataset, which calls for special attention\nwhen designing or deploying the link prediction algorithm in practice.",
    "descriptor": "\nComments: Accepted by GLB 2022 @TheWebConf 2022;Data and codes are available at this https URL\n",
    "authors": [
      "Min Zhou",
      "Bisheng Li",
      "Menglin Yang",
      "Lujia Pan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07703"
  },
  {
    "id": "arXiv:2204.07704",
    "title": "Technical Report: Hybrid Autonomous Intersection Management",
    "abstract": "This document provides technical details regarding the Hybrid-AIM simulator\nthat was used in Sharon and Stone (2017).",
    "descriptor": "",
    "authors": [
      "Aaron Parks-Young",
      "Guni Sharon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07704"
  },
  {
    "id": "arXiv:2204.07705",
    "title": "Benchmarking Generalization via In-Context Instructions on 1,600+  Language Tasks",
    "abstract": "How can we measure the generalization of models to a variety of unseen tasks\nwhen provided with their language instructions? To facilitate progress in this\ngoal, we introduce Natural-Instructions v2, a collection of 1,600+ diverse\nlanguage tasks and their expert written instructions. More importantly, the\nbenchmark covers 70+ distinct task types, such as tagging, in-filling, and\nrewriting. This benchmark is collected with contributions of NLP practitioners\nin the community and through an iterative peer review process to ensure their\nquality. This benchmark enables large-scale evaluation of cross-task\ngeneralization of the models -- training on a subset of tasks and evaluating on\nthe remaining unseen ones. For instance, we are able to rigorously quantify\ngeneralization as a function of various scaling parameters, such as the number\nof observed tasks, the number of instances, and model sizes. As a by-product of\nthese experiments. we introduce Tk-Instruct, an encoder-decoder Transformer\nthat is trained to follow a variety of in-context instructions (plain language\ntask definitions or k-shot examples) which outperforms existing larger models\non our benchmark. We hope this benchmark facilitates future progress toward\nmore general-purpose language understanding models.",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Yizhong Wang",
      "Swaroop Mishra",
      "Pegah Alipoormolabashi",
      "Yeganeh Kordi",
      "Amirreza Mirzaei",
      "Anjana Arunkumar",
      "Arjun Ashok",
      "Arut Selvan Dhanasekaran",
      "Atharva Naik",
      "David Stap",
      "Eshaan Pathak",
      "Giannis Karamanolakis",
      "Haizhi Gary Lai",
      "Ishan Purohit",
      "Ishani Mondal",
      "Jacob Anderson",
      "Kirby Kuznia",
      "Krima Doshi",
      "Maitreya Patel",
      "Kuntal Kumar Pal",
      "Mehrad Moradshahi",
      "Mihir Parmar",
      "Mirali Purohit",
      "Neeraj Varshney",
      "Phani Rohitha Kaza",
      "Pulkit Verma",
      "Ravsehaj Singh Puri",
      "Rushang Karia",
      "Shailaja Keyur Sampat",
      "Savan Doshi",
      "Siddhartha Mishra",
      "Sujan Reddy",
      "Sumanta Patro",
      "Tanay Dixit",
      "Xudong Shen",
      "Chitta Baral",
      "Yejin Choi",
      "Hannaneh Hajishirzi",
      "Noah A. Smith",
      "Daniel Khashabi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07705"
  },
  {
    "id": "arXiv:2204.07707",
    "title": "Privacy-Preserving Image Classification Using Isotropic Network",
    "abstract": "In this paper, we propose a privacy-preserving image classification method\nthat uses encrypted images and an isotropic network such as the vision\ntransformer. The proposed method allows us not only to apply images without\nvisual information to deep neural networks (DNNs) for both training and testing\nbut also to maintain a high classification accuracy. In addition, compressible\nencrypted images, called encryption-then-compression (EtC) images, can be used\nfor both training and testing without any adaptation network. Previously, to\nclassify EtC images, an adaptation network was required before a classification\nnetwork, so methods with an adaptation network have been only tested on small\nimages. To the best of our knowledge, previous privacy-preserving image\nclassification methods have never considered image compressibility and patch\nembedding-based isotropic networks. In an experiment, the proposed\nprivacy-preserving image classification was demonstrated to outperform\nstate-of-the-art methods even when EtC images were used in terms of\nclassification accuracy and robustness against various attacks under the use of\ntwo isotropic networks: vision transformer and ConvMixer.",
    "descriptor": "",
    "authors": [
      "AprilPyone MaungMaung",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.07707"
  },
  {
    "id": "arXiv:2204.07709",
    "title": "Easy-Sec: PUF-Based Rapid and Robust Authentication Framework for the  Internet of Vehicles",
    "abstract": "With the rapid growth of new technological paradigms such as the Internet of\nThings (IoT), it opens new doors for many applications in the modern era for\nthe betterment of human life. One of the recent applications of the IoT is the\nInternet of Vehicles (IoV) which helps to see unprecedented growth of connected\nvehicles on the roads. The IoV is gaining attention due to enhancing traffic\nsafety and providing low route information. One of the most important and major\nrequirements of the IoV is preserving security and privacy under strict\nlatency. Moreover, vehicles are required to be authenticated frequently and\nfast considering limited bandwidth, high mobility, and density of the vehicles.\nTo address the security vulnerabilities and data integrity, an ultralight\nauthentication scheme has been proposed in this article. Physical Unclonable\nFunction (PUF) and XOR function are used to authenticate both server and\nvehicle in two message flow which makes the proposed scheme ultralight, and\nless computation is required. The proposed Easy-Sec can authenticate vehicles\nmaintaining low latency and resisting known security threats. Furthermore, the\nproposed Easy-Sec needs low overhead so that it does not increase the burden of\nthe IoV network. Computational ( around 4 ms) and Communication (32 bytes)\noverhead shows the feasibility, efficiency, and also security features are\ndepicted using formal analysis, Burrows, Abadi, and Needham (BAN) logic, and\ninformal analysis to show the robustness of the proposed mechanisms against\nsecurity threats.",
    "descriptor": "",
    "authors": [
      "Pintu Kumar Sadhu",
      "Venkata P. Yanambaka",
      "Saraju P. Mohanty",
      "Elias Kougianos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.07709"
  },
  {
    "id": "arXiv:2204.07713",
    "title": "GAUSS: Guided Encoder-Decoder Architecture for Hyperspectral Unmixing  with Spatial Smoothness",
    "abstract": "In recent hyperspectral unmixing (HU) literature, the application of deep\nlearning (DL) has become more prominent, especially with the autoencoder (AE)\narchitecture. We propose a split architecture and use a pseudo-ground truth for\nabundances to guide the `unmixing network' (UN) optimization. Preceding the UN,\nan `approximation network' (AN) is proposed, which will improve the association\nbetween the centre pixel and its neighbourhood. Hence, it will accentuate\nspatial correlation in the abundances as its output is the input to the UN and\nthe reference for the `mixing network' (MN). In the Guided Encoder-Decoder\nArchitecture for Hyperspectral Unmixing with Spatial Smoothness (GAUSS), we\nproposed using one-hot encoded abundances as the pseudo-ground truth to guide\nthe UN; computed using the k-means algorithm to exclude the use of prior HU\nmethods. Furthermore, we release the single-layer constraint on MN by\nintroducing the UN generated abundances in contrast to the standard AE for HU.\nSecondly, we experimented with two modifications on the pre-trained network\nusing the GAUSS method. In GAUSS$_\\textit{blind}$, we have concatenated the UN\nand the MN to back-propagate the reconstruction error gradients to the encoder.\nThen, in the GAUSS$_\\textit{prime}$, abundance results of a signal processing\n(SP) method with reliable abundance results were used as the pseudo-ground\ntruth with the GAUSS architecture. According to quantitative and graphical\nresults for four experimental datasets, the three architectures either\ntranscended or equated the performance of existing HU algorithms from both DL\nand SP domains.",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Yasiru Ranasinghe",
      "Kavinga Weerasooriya",
      "Roshan Godaliyadda",
      "Vijitha Herath",
      "Parakrama Ekanayake",
      "Dhananjaya Jayasundara",
      "Lakshitha Ramanayake",
      "Neranjan Senarath",
      "Dulantha Wickramasinghe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.07713"
  },
  {
    "id": "arXiv:2204.07714",
    "title": "Pushing the Performance Limit of Scene Text Recognizer without Human  Annotation",
    "abstract": "Scene text recognition (STR) attracts much attention over the years because\nof its wide application. Most methods train STR model in a fully supervised\nmanner which requires large amounts of labeled data. Although synthetic data\ncontributes a lot to STR, it suffers from the real-tosynthetic domain gap that\nrestricts model performance. In this work, we aim to boost STR models by\nleveraging both synthetic data and the numerous real unlabeled images,\nexempting human annotation cost thoroughly. A robust consistency regularization\nbased semi-supervised framework is proposed for STR, which can effectively\nsolve the instability issue due to domain inconsistency between synthetic and\nreal images. A character-level consistency regularization is designed to\nmitigate the misalignment between characters in sequence recognition. Extensive\nexperiments on standard text recognition benchmarks demonstrate the\neffectiveness of the proposed method. It can steadily improve existing STR\nmodels, and boost an STR model to achieve new state-of-the-art results. To our\nbest knowledge, this is the first consistency regularization based framework\nthat applies successfully to STR.",
    "descriptor": "\nComments: 10 pages, 5 figures, accepted by CVPR-2022\n",
    "authors": [
      "Caiyuan Zheng",
      "Hui Li",
      "Seon-Min Rhee",
      "Seungju Han",
      "Jae-Joon Han",
      "Peng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07714"
  },
  {
    "id": "arXiv:2204.07718",
    "title": "Interactiveness Field in Human-Object Interactions",
    "abstract": "Human-Object Interaction (HOI) detection plays a core role in activity\nunderstanding. Though recent two/one-stage methods have achieved impressive\nresults, as an essential step, discovering interactive human-object pairs\nremains challenging. Both one/two-stage methods fail to effectively extract\ninteractive pairs instead of generating redundant negative pairs. In this work,\nwe introduce a previously overlooked interactiveness bimodal prior: given an\nobject in an image, after pairing it with the humans, the generated pairs are\neither mostly non-interactive, or mostly interactive, with the former more\nfrequent than the latter. Based on this interactiveness bimodal prior we\npropose the \"interactiveness field\". To make the learned field compatible with\nreal HOI image considerations, we propose new energy constraints based on the\ncardinality and difference in the inherent \"interactiveness field\" underlying\ninteractive versus non-interactive pairs. Consequently, our method can detect\nmore precise pairs and thus significantly boost HOI detection performance,\nwhich is validated on widely-used benchmarks where we achieve decent\nimprovements over state-of-the-arts. Our code is available at\nhttps://github.com/Foruck/Interactiveness-Field.",
    "descriptor": "\nComments: To appear in CVPR2022\n",
    "authors": [
      "Xinpeng Liu",
      "Yong-Lu Li",
      "Xiaoqian Wu",
      "Yu-Wing Tai",
      "Cewu Lu",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07718"
  },
  {
    "id": "arXiv:2204.07719",
    "title": "Stress-Testing LiDAR Registration",
    "abstract": "Point cloud registration (PCR) is an important task in many fields including\nautonomous driving with LiDAR sensors. PCR algorithms have improved\nsignificantly in recent years, by combining deep-learned features with robust\nestimation methods. These algorithms succeed in scenarios such as indoor scenes\nand object models registration. However, testing in the automotive LiDAR\nsetting, which presents its own challenges, has been limited. The standard\nbenchmark for this setting, KITTI-10m, has essentially been saturated by recent\nalgorithms: many of them achieve near-perfect recall.\nIn this work, we stress-test recent PCR techniques with LiDAR data. We\npropose a method for selecting balanced registration sets, which are\nchallenging sets of frame-pairs from LiDAR datasets. They contain a balanced\nrepresentation of the different relative motions that appear in a dataset, i.e.\nsmall and large rotations, small and large offsets in space and time, and\nvarious combinations of these.\nWe perform a thorough comparison of accuracy and run-time on these\nbenchmarks. Perhaps unexpectedly, we find that the fastest and simultaneously\nmost accurate approach is a version of advanced RANSAC. We further improve\nresults with a novel pre-filtering method.",
    "descriptor": "",
    "authors": [
      "Amnon Drory",
      "Shai Avidan",
      "Raja Giryes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07719"
  },
  {
    "id": "arXiv:2204.07720",
    "title": "DMCS : Density Modularity based Community Search",
    "abstract": "Community Search, or finding a connected subgraph (known as a community)\ncontaining the given query nodes in a social network, is a fundamental problem.\nMost of the existing community search models only focus on the internal\ncohesiveness of a community. However, a high-quality community often has high\nmodularity, which means dense connections inside communities and sparse\nconnections to the nodes outside the community. In this paper, we conduct a\npioneer study on searching a community with high modularity. We point out that\nwhile modularity has been popularly used in community detection (without query\nnodes), it has not been adopted for community search, surprisingly, and its\napplication in community search (related to query nodes) brings in new\nchallenges. We address these challenges by designing a new graph modularity\nfunction named Density Modularity. To the best of our knowledge, this is the\nfirst work on the community search problem using graph modularity. The\ncommunity search based on the density modularity, termed as DMCS, is to find a\ncommunity in a social network that contains all the query nodes and has high\ndensity-modularity. We prove that the DMCS problem is NP-hard. To efficiently\naddress DMCS, we present new algorithms that run in log-linear time to the\ngraph size. We conduct extensive experimental studies in real-world and\nsynthetic networks, which offer insights into the efficiency and effectiveness\nof our algorithms. In particular, our algorithm achieves up to 8.5 times higher\naccuracy in terms of NMI than baseline algorithms.",
    "descriptor": "",
    "authors": [
      "Junghoon Kim",
      "Siqiang Luo",
      "Gao Cong",
      "Wenyuan Yu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.07720"
  },
  {
    "id": "arXiv:2204.07721",
    "title": "TVShowGuess: Character Comprehension in Stories as Speaker Guessing",
    "abstract": "We propose a new task for assessing machines' skills of understanding\nfictional characters in narrative stories. The task, TVShowGuess, builds on the\nscripts of TV series and takes the form of guessing the anonymous main\ncharacters based on the backgrounds of the scenes and the dialogues. Our human\nstudy supports that this form of task covers comprehension of multiple types of\ncharacter persona, including understanding characters' personalities, facts and\nmemories of personal experience, which are well aligned with the psychological\nand literary theories about the theory of mind (ToM) of human beings on\nunderstanding fictional characters during reading. We further propose new model\narchitectures to support the contextualized encoding of long scene texts.\nExperiments show that our proposed approaches significantly outperform\nbaselines, yet still largely lag behind the (nearly perfect) human performance.\nOur work serves as a first step toward the goal of narrative character\ncomprehension.",
    "descriptor": "\nComments: Accepted at NAACL 2022\n",
    "authors": [
      "Yisi Sang",
      "Xiangyang Mou",
      "Mo Yu",
      "Shunyu Yao",
      "Jing Li",
      "Jeffrey Stanton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07721"
  },
  {
    "id": "arXiv:2204.07722",
    "title": "Searching Intrinsic Dimensions of Vision Transformers",
    "abstract": "It has been shown by many researchers that transformers perform as well as\nconvolutional neural networks in many computer vision tasks. Meanwhile, the\nlarge computational costs of its attention module hinder further studies and\napplications on edge devices. Some pruning methods have been developed to\nconstruct efficient vision transformers, but most of them have considered image\nclassification tasks only. Inspired by these results, we propose SiDT, a method\nfor pruning vision transformer backbones on more complicated vision tasks like\nobject detection, based on the search of transformer dimensions. Experiments on\nCIFAR-100 and COCO datasets show that the backbones with 20\\% or 40\\%\ndimensions/parameters pruned can have similar or even better performance than\nthe unpruned models. Moreover, we have also provided the complexity analysis\nand comparisons with the previous pruning methods.",
    "descriptor": "",
    "authors": [
      "Fanghui Xue",
      "Biao Yang",
      "Yingyong Qi",
      "Jack Xin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07722"
  },
  {
    "id": "arXiv:2204.07723",
    "title": "Local multiscale model reduction using discontinuous Galerkin coupling  for elasticity problems",
    "abstract": "In this paper, we consider the constrained energy minimizing generalized\nmultiscale finite element method (CEM-GMsFEM) with discontinuous Galerkin (DG)\ncoupling for the linear elasticity equations in highly heterogeneous and high\ncontrast media. We will introduce the construction of a DG version of the\nCEM-GMsFEM, such as auxiliary basis functions and offline basis functions. The\nDG version of the method offers some advantages such as flexibility in coarse\ngrid construction and sparsity of resulting discrete systems. Moreover, to our\nbest knowledge, this is the first time where the proof of the convergence of\nthe CEM-GMsFEM in the DG form is given. Some numerical examples will be\npresented to illustrate the performance of the method.",
    "descriptor": "",
    "authors": [
      "Zhongqian Wang",
      "Shubin Fu",
      "Eric Chung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.07723"
  },
  {
    "id": "arXiv:2204.07724",
    "title": "Semantic interpretation for convolutional neural networks: What makes a  cat a cat?",
    "abstract": "The interpretability of deep neural networks has attracted increasing\nattention in recent years, and several methods have been created to interpret\nthe \"black box\" model. Fundamental limitations remain, however, that impede the\npace of understanding the networks, especially the extraction of understandable\nsemantic space. In this work, we introduce the framework of semantic\nexplainable AI (S-XAI), which utilizes row-centered principal component\nanalysis to obtain the common traits from the best combination of superpixels\ndiscovered by a genetic algorithm, and extracts understandable semantic spaces\non the basis of discovered semantically sensitive neurons and visualization\ntechniques. Statistical interpretation of the semantic space is also provided,\nand the concept of semantic probability is proposed for the first time. Our\nexperimental results demonstrate that S-XAI is effective in providing a\nsemantic interpretation for the CNN, and offers broad usage, including\ntrustworthiness assessment and semantic sample searching.",
    "descriptor": "\nComments: 33 pages, 11 figures\n",
    "authors": [
      "Hao Xu",
      "Yuntian Chen",
      "Dongxiao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07724"
  },
  {
    "id": "arXiv:2204.07725",
    "title": "Is Blockchain for Internet of Medical Things a Panacea for COVID-19  Pandemic?",
    "abstract": "The outbreak of the COVID-19 pandemic has deeply influenced the lifestyle of\nthe general public and the healthcare system of the society. As a promising\napproach to address the emerging challenges caused by the epidemic of\ninfectious diseases like COVID-19, Internet of Medical Things (IoMT) deployed\nin hospitals, clinics, and healthcare centers can save the diagnosis time and\nimprove the efficiency of medical resources though privacy and security\nconcerns of IoMT stall the wide adoption. In order to tackle the privacy,\nsecurity, and interoperability issues of IoMT, we propose a framework of\nblockchain-enabled IoMT by introducing blockchain to incumbent IoMT systems. In\nthis paper, we review the benefits of this architecture and illustrate the\nopportunities brought by blockchain-enabled IoMT. We also provide use cases of\nblockchain-enabled IoMT on fighting against the COVID-19 pandemic, including\nthe prevention of infectious diseases, location sharing and contact tracing,\nand the supply chain of injectable medicines. We also outline future work in\nthis area.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Xuran Li",
      "Bishenghui Tao",
      "Hong-Ning Dai",
      "Muhammad Imran",
      "Dehuan Wan",
      "Dengwang Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.07725"
  },
  {
    "id": "arXiv:2204.07726",
    "title": "A Hierarchical Terminal Recognition Approach based on Network Traffic  Analysis",
    "abstract": "Recognizing the type of connected devices to a network helps to perform\nsecurity policies. In smart grids, identifying massive number of grid metering\nterminals based on network traffic analysis is almost blank and existing\nresearch has not proposed a targeted end-to-end model to solve the flow\nclassification problem. Therefore, we proposed a hierarchical terminal\nrecognition approach that applies the details of grid data. We have formed a\ntwo-level model structure by segmenting the grid data, which uses the\nstatistical characteristics of network traffic and the specific behavior\ncharacteristics of grid metering terminals. Moreover, through the selection and\nreconstruction of features, we combine three algorithms to achieve accurate\nidentification of terminal types that transmit network traffic. We conduct\nextensive experiments on a real dataset containing three types of grid metering\nterminals, and the results show that our research has improved performance\ncompared to common recognition models. The combination of an autoencoder,\nK-Means and GradientBoost algorithm achieved the best recognition rate with F1\nvalue of 98.3%.",
    "descriptor": "\nComments: 8 pages,6 figures\n",
    "authors": [
      "Lingzi Kong",
      "Daoqi Han",
      "Junmei Ding",
      "Mingrui Fan",
      "Yueming Lu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07726"
  },
  {
    "id": "arXiv:2204.07727",
    "title": "The Tree Loss: Improving Generalization with Many Classes",
    "abstract": "Multi-class classification problems often have many semantically similar\nclasses. For example, 90 of ImageNet's 1000 classes are for different breeds of\ndog. We should expect that these semantically similar classes will have similar\nparameter vectors, but the standard cross entropy loss does not enforce this\nconstraint.\nWe introduce the tree loss as a drop-in replacement for the cross entropy\nloss. The tree loss re-parameterizes the parameter matrix in order to guarantee\nthat semantically similar classes will have similar parameter vectors. Using\nsimple properties of stochastic gradient descent, we show that the tree loss's\ngeneralization error is asymptotically better than the cross entropy loss's. We\nthen validate these theoretical results on synthetic data, image data\n(CIFAR100, ImageNet), and text data (Twitter).",
    "descriptor": "\nComments: Accepted paper to AISTATS 2022\n",
    "authors": [
      "Yujie Wang",
      "Mike Izbicki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07727"
  },
  {
    "id": "arXiv:2204.07728",
    "title": "Fault-Tolerant Multiparty Session Types (Technical Report)",
    "abstract": "Multiparty session types are designed to abstractly capture the structure of\ncommunication protocols and verify behavioural properties. One important such\nproperty is progress, i.e., the absence of deadlock. Distributed algorithms\noften resemble multiparty communication protocols. But proving their\nproperties, in particular termination that is closely related to progress, can\nbe elaborate. Since distributed algorithms are often designed to cope with\nfaults, a first step towards using session types to verify distributed\nalgorithms is to integrate fault-tolerance.\nWe extend multiparty session types to cope with system failures such as\nunreliable communication and process crashes. Moreover, we augment the\nsemantics of processes by failure patterns that can be used to represent system\nrequirements (as, e.g., failure detectors). To illustrate our approach we\nanalyse a variant of the well-known rotating coordinator algorithm by Chandra\nand Toueg. This technical report presents the proofs and some additional\nmaterial to extend [30].",
    "descriptor": "",
    "authors": [
      "Kirstin Peters",
      "Uwe Nestmann",
      "Christoph Wagner"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.07728"
  },
  {
    "id": "arXiv:2204.07729",
    "title": "Efficient Bayesian Policy Reuse with a Scalable Observation Model in  Deep Reinforcement Learning",
    "abstract": "Bayesian policy reuse (BPR) is a general policy transfer framework for\nselecting a source policy from an offline library by inferring the task belief\nbased on some observation signals and a trained observation model. In this\npaper, we propose an improved BPR method to achieve more efficient policy\ntransfer in deep reinforcement learning (DRL). First, most BPR algorithms use\nthe episodic return as the observation signal that contains limited information\nand cannot be obtained until the end of an episode. Instead, we employ the\nstate transition sample, which is informative and instantaneous, as the\nobservation signal for faster and more accurate task inference. Second, BPR\nalgorithms usually require numerous samples to estimate the probability\ndistribution of the tabular-based observation model, which may be expensive and\neven infeasible to learn and maintain, especially when using the state\ntransition sample as the signal. Hence, we propose a scalable observation model\nbased on fitting state transition functions of source tasks from only a small\nnumber of samples, which can generalize to any signals observed in the target\ntask. Moreover, we extend the offline-mode BPR to the continual learning\nsetting by expanding the scalable observation model in a plug-and-play fashion,\nwhich can avoid negative transfer when faced with new unknown tasks.\nExperimental results show that our method can consistently facilitate faster\nand more efficient policy transfer.",
    "descriptor": "\nComments: 16 pages, 6 figures, under review\n",
    "authors": [
      "Donghan Xie",
      "Zhi Wang",
      "Chunlin Chen",
      "Daoyi Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07729"
  },
  {
    "id": "arXiv:2204.07730",
    "title": "Bidirectional Self-Training with Multiple Anisotropic Prototypes for  Domain Adaptive Semantic Segmentation",
    "abstract": "A thriving trend for domain adaptive segmentation endeavors to generate the\nhigh-quality pseudo labels for target domain and retrain the segmentor on them.\nUnder this self-training paradigm, some competitive methods have sought to the\nlatent-space information, which establishes the feature centroids (a.k.a\nprototypes) of the semantic classes and determines the pseudo label candidates\nby their distances from these centroids. In this paper, we argue that the\nlatent space contains more information to be exploited thus taking one step\nfurther to capitalize on it. Firstly, instead of merely using the source-domain\nprototypes to determine the target pseudo labels as most of the traditional\nmethods do, we bidirectionally produce the target-domain prototypes to degrade\nthose source features which might be too hard or disturbed for the adaptation.\nSecondly, existing attempts simply model each category as a single and\nisotropic prototype while ignoring the variance of the feature distribution,\nwhich could lead to the confusion of similar categories. To cope with this\nissue, we propose to represent each category with multiple and anisotropic\nprototypes via Gaussian Mixture Model, in order to fit the de facto\ndistribution of source domain and estimate the likelihood of target samples\nbased on the probability density. We apply our method on GTA5->Cityscapes and\nSynthia->Cityscapes tasks and achieve 61.2 and 62.8 respectively in terms of\nmean IoU, substantially outperforming other competitive self-training methods.\nNoticeably, in some categories which severely suffer from the categorical\nconfusion such as \"truck\" and \"bus\", our method achieves 56.4 and 68.8\nrespectively, which further demonstrates the effectiveness of our design.",
    "descriptor": "",
    "authors": [
      "Yulei Lu",
      "Yawei Luo",
      "Li Zhang",
      "Zheyang Li",
      "Yi Yang",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07730"
  },
  {
    "id": "arXiv:2204.07731",
    "title": "Efficient Linear Attention for Fast and Accurate Keypoint Matching",
    "abstract": "Recently Transformers have provided state-of-the-art performance in sparse\nmatching, crucial to realize high-performance 3D vision applications. Yet,\nthese Transformers lack efficiency due to the quadratic computational\ncomplexity of their attention mechanism. To solve this problem, we employ an\nefficient linear attention for the linear computational complexity. Then, we\npropose a new attentional aggregation that achieves high accuracy by\naggregating both the global and local information from sparse keypoints. To\nfurther improve the efficiency, we propose the joint learning of feature\nmatching and description. Our learning enables simpler and faster matching than\nSinkhorn, often used in matching the learned descriptors from Transformers. Our\nmethod achieves competitive performance with only 0.84M learnable parameters\nagainst the bigger SOTAs, SuperGlue (12M parameters) and SGMNet (30M\nparameters), on three benchmarks, HPatch, ETH, and Aachen Day-Night.",
    "descriptor": "\nComments: To be published in ACM ICMR 2022\n",
    "authors": [
      "Suwichaya Suwanwimolkul",
      "Satoshi Komorita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07731"
  },
  {
    "id": "arXiv:2204.07733",
    "title": "GitNet: Geometric Prior-based Transformation for Birds-Eye-View  Segmentation",
    "abstract": "Birds-eye-view (BEV) semantic segmentation is critical for autonomous driving\nfor its powerful spatial representation ability. It is challenging to estimate\nthe BEV semantic maps from monocular images due to the spatial gap, since it is\nimplicitly required to realize both the perspective-to-BEV transformation and\nsegmentation. We present a novel two-stage Geometry Prior-based Transformation\nframework named GitNet, consisting of (i) the geometry-guided pre-alignment and\n(ii) ray-based transformer. In the first stage, we decouple the BEV\nsegmentation into the perspective image segmentation and geometric prior-based\nmapping, with explicit supervision by projecting the BEV semantic labels onto\nthe image plane to learn visibility-aware features and learnable geometry to\ntranslate into BEV space. Second, the pre-aligned coarse BEV features are\nfurther deformed by ray-based transformers to take visibility knowledge into\naccount. GitNet achieves the leading performance on the challenging nuScenes\nand Argoverse Datasets. The code will be publicly available.",
    "descriptor": "",
    "authors": [
      "Shi Gong",
      "Xiaoqing Ye",
      "Xiao Tan",
      "Jingdong Wang",
      "Errui Ding",
      "Yu Zhou",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07733"
  },
  {
    "id": "arXiv:2204.07738",
    "title": "MMV-Based Sequential AoA and AoD Estimation for Millimeter Wave MIMO  Channels",
    "abstract": "The fact that the millimeter-wave (mmWave) multiple-input multiple-output\n(MIMO) channel has sparse support in the spatial domain has motivated recent\ncompressed sensing (CS)-based mmWave channel estimation methods, where the\nangles of arrivals (AoAs) and angles of departures (AoDs) are quantized using\nangle dictionary matrices. However, the existing CS-based methods usually\nobtain the estimation result through one-stage channel sounding that have two\nlimitations: (i) the requirement of large-dimensional dictionary and (ii)\nunresolvable quantization error. These two drawbacks are irreconcilable;\nimprovement of the one implies deterioration of the other. To address these\nchallenges, we propose, in this paper, a two-stage method to estimate the AoAs\nand AoDs of mmWave channels. In the proposed method, the channel estimation\ntask is divided into two stages, Stage I and Stage II. Specifically, in Stage\nI, the AoAs are estimated by solving a multiple measurement vectors (MMV)\nproblem. In Stage II, based on the estimated AoAs, the receive sounders are\ndesigned to estimate AoDs. The dimension of the angle dictionary in each stage\ncan be reduced, which in turn reduces the computational complexity\nsubstantially. We then analyze the successful recovery probability (SRP) of the\nproposed method, revealing the superiority of the proposed framework over the\nexisting one-stage CS-based methods. We further enhance the reconstruction\nperformance by performing resource allocation between the two stages. We also\novercome the unresolvable quantization error issue present in the prior\ntechniques by applying the atomic norm minimization method to each stage of the\nproposed two-stage approach. The simulation results illustrate the\nsubstantially improved performance with low complexity of the proposed\ntwo-stage method.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Communications\n",
    "authors": [
      "Wei Zhang",
      "Miaomiao Dong",
      "Taejoon Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.07738"
  },
  {
    "id": "arXiv:2204.07741",
    "title": "Persua: A Visual Interactive System to Enhance the Persuasiveness of  Arguments in Online Discussion",
    "abstract": "Persuading people to change their opinions is a common practice in online\ndiscussion forums on topics ranging from political campaigns to relationship\nconsultation. Enhancing people's ability to write persuasive arguments could\nnot only practice their critical thinking and reasoning but also contribute to\nthe effectiveness and civility in online communication. It is, however, not an\neasy task in online discussion settings where written words are the primary\ncommunication channel. In this paper, we derived four design goals for a tool\nthat helps users improve the persuasiveness of arguments in online discussions\nthrough a survey with 123 online forum users and interviews with five debating\nexperts. To satisfy these design goals, we analyzed and built a labeled dataset\nof fine-grained persuasive strategies (i.e., logos, pathos, ethos, and\nevidence) in 164 arguments with high ratings on persuasiveness from\nChangeMyView, a popular online discussion forum. We then designed an\ninteractive visual system, Persua, which provides example-based guidance on\npersuasive strategies to enhance the persuasiveness of arguments. In\nparticular, the system constructs portfolios of arguments based on different\npersuasive strategies applied to a given discussion topic. It then presents\nconcrete examples based on the difference between the portfolios of user input\nand high-quality arguments in the dataset. A between-subjects study shows\nsuggestive evidence that Persua encourages users to submit more times for\nfeedback and helps users improve more on the persuasiveness of their arguments\nthan a baseline system. Finally, a set of design considerations was summarized\nto guide future intelligent systems that improve the persuasiveness in text.",
    "descriptor": "\nComments: This paper will appear in CSCW 2022\n",
    "authors": [
      "Meng Xia",
      "Qian Zhu",
      "Xingbo Wang",
      "Fei Nei",
      "Huamin Qu",
      "Xiaojuan Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07741"
  },
  {
    "id": "arXiv:2204.07742",
    "title": "DRFLM: Distributionally Robust Federated Learning with Inter-client  Noise via Local Mixup",
    "abstract": "Recently, federated learning has emerged as a promising approach for training\na global model using data from multiple organizations without leaking their raw\ndata. Nevertheless, directly applying federated learning to real-world tasks\nfaces two challenges: (1) heterogeneity in the data among different\norganizations; and (2) data noises inside individual organizations.\nIn this paper, we propose a general framework to solve the above two\nchallenges simultaneously. Specifically, we propose using distributionally\nrobust optimization to mitigate the negative effects caused by data\nheterogeneity paradigm to sample clients based on a learnable distribution at\neach iteration. Additionally, we observe that this optimization paradigm is\neasily affected by data noises inside local clients, which has a significant\nperformance degradation in terms of global model prediction accuracy. To solve\nthis problem, we propose to incorporate mixup techniques into the local\ntraining process of federated learning. We further provide comprehensive\ntheoretical analysis including robustness analysis, convergence analysis, and\ngeneralization ability. Furthermore, we conduct empirical studies across\ndifferent drug discovery tasks, such as ADMET property prediction and\ndrug-target affinity prediction.",
    "descriptor": "",
    "authors": [
      "Bingzhe Wu",
      "Zhipeng Liang",
      "Yuxuan Han",
      "Yatao Bian",
      "Peilin Zhao",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07742"
  },
  {
    "id": "arXiv:2204.07746",
    "title": "Unsupervised Attention-based Sentence-Level Meta-Embeddings from  Contextualised Language Models",
    "abstract": "A variety of contextualised language models have been proposed in the NLP\ncommunity, which are trained on diverse corpora to produce numerous Neural\nLanguage Models (NLMs). However, different NLMs have reported different levels\nof performances in downstream NLP applications when used as text\nrepresentations. We propose a sentence-level meta-embedding learning method\nthat takes independently trained contextualised word embedding models and\nlearns a sentence embedding that preserves the complementary strengths of the\ninput source NLMs. Our proposed method is unsupervised and is not tied to a\nparticular downstream task, which makes the learnt meta-embeddings in principle\napplicable to different tasks that require sentence representations.\nSpecifically, we first project the token-level embeddings obtained by the\nindividual NLMs and learn attention weights that indicate the contributions of\nsource embeddings towards their token-level meta-embeddings. Next, we apply\nmean and max pooling to produce sentence-level meta-embeddings from token-level\nmeta-embeddings. Experimental results on semantic textual similarity benchmarks\nshow that our proposed unsupervised sentence-level meta-embedding method\noutperforms previously proposed sentence-level meta-embedding methods as well\nas a supervised baseline.",
    "descriptor": "",
    "authors": [
      "Keigo Takahashi",
      "Danushka Bollegala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07746"
  },
  {
    "id": "arXiv:2204.07749",
    "title": "From Parental Control to Joint Family Oversight: Can Parents and Teens  Manage Mobile Online Safety and Privacy as Equals?",
    "abstract": "Our research aims to highlight and alleviate the complex tensions around\nonline safety, privacy, and smartphone usage in families so that parents and\nteens can work together to better manage mobile privacy and security-related\nrisks. We developed a mobile application (\"app\") for Community Oversight of\nPrivacy and Security (\"CO-oPS\") and had parents and teens assess whether it\nwould be applicable for use with their families. CO-oPS is an Android app that\nallows a group of users to co-monitor the apps installed on one another's\ndevices and the privacy permissions granted to those apps. We conducted a study\nwith 19 parent-teen (ages 13-17) pairs to understand how they currently managed\nmobile safety and app privacy within their family and then had them install,\nuse, and evaluate the CO-oPS app. We found that both parents and teens gave\nlittle consideration to online safety and privacy before installing new apps or\ngranting privacy permissions. When using CO-oPS, participants liked how the app\nincreased transparency into one another's devices in a way that facilitated\ncommunication, but were less inclined to use features for in-app messaging or\nto hide apps from one another. Key themes related to power imbalances between\nparents and teens surfaced that made co-management challenging. Parents were\nmore open to collaborative oversight than teens, who felt that it was not their\nplace to monitor their parents, even though both often believed parents lacked\nthe technological expertise to monitor themselves. Our study sheds light on why\ncollaborative practices for managing online safety and privacy within families\nmay be beneficial but also quite difficult to implement in practice. We provide\nrecommendations for overcoming these challenges based on the insights gained\nfrom our study.",
    "descriptor": "",
    "authors": [
      "Mamtaj Akter",
      "Amy Godfrey",
      "Jess Kropczynski",
      "Heather Lipford",
      "Pamela Wisniewski"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.07749"
  },
  {
    "id": "arXiv:2204.07751",
    "title": "A User Study to Evaluate a Web-based Prototype for Smart Home Internet  of Things Device Management",
    "abstract": "With the growing advances in the Internet of Things (IoT) technology, IoT\ndevice management platforms are becoming increasingly important. We conducted a\nweb-based survey and usability study with 43 participants who use IoT devices\nfrequently to: 1) examine their smart home IoT usage patterns and privacy\npreferences, and 2) evaluate a web-based prototype for smart home IoT device\nmanagement. We found that participants perceived privacy as more important than\nthe convenience afforded by the IoT devices. Based on their average scores of\nprivacy vs. convenience importance, participants with low privacy and low\nconvenience significantly reported less privacy control and convenience\npreferences than participants with high privacy and high convenience. Overall,\nall participants were satisfied with the proposed website prototype and their\nactual usability evaluation demonstrated a good understanding of the website\nfeatures. This paper provides an empirical examination of the privacy versus\nconvenience trade-offs smart home users make when managing their IoT devices.",
    "descriptor": "",
    "authors": [
      "Leena Alghamdi",
      "Ashwaq Alsoubai",
      "Mamtaj Akter",
      "Faisal Alghamdi",
      "Pamela Wisniewski"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.07751"
  },
  {
    "id": "arXiv:2204.07752",
    "title": "Homomorphic Encryption and Federated Learning based Privacy-Preserving  CNN Training: COVID-19 Detection Use-Case",
    "abstract": "Medical data is often highly sensitive in terms of data privacy and security\nconcerns. Federated learning, one type of machine learning techniques, has been\nstarted to use for the improvement of the privacy and security of medical data.\nIn the federated learning, the training data is distributed across multiple\nmachines, and the learning process is performed in a collaborative manner.\nThere are several privacy attacks on deep learning (DL) models to get the\nsensitive information by attackers. Therefore, the DL model itself should be\nprotected from the adversarial attack, especially for applications using\nmedical data. One of the solutions for this problem is homomorphic\nencryption-based model protection from the adversary collaborator. This paper\nproposes a privacy-preserving federated learning algorithm for medical data\nusing homomorphic encryption. The proposed algorithm uses a secure multi-party\ncomputation protocol to protect the deep learning model from the adversaries.\nIn this study, the proposed algorithm using a real-world medical dataset is\nevaluated in terms of the model performance.",
    "descriptor": "\nComments: European Interdisciplinary Cybersecurity Conference (EICC) 2022 publication\n",
    "authors": [
      "Febrianti Wibawa",
      "Ferhat Ozgur Catak",
      "Salih Sarp",
      "Murat Kuzlu",
      "Umit Cali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07752"
  },
  {
    "id": "arXiv:2204.07756",
    "title": "Visual Attention Methods in Deep Learning: An In-Depth Survey",
    "abstract": "Inspired by the human cognitive system, attention is a mechanism that\nimitates the human cognitive awareness about specific information, amplifying\ncritical details to focus more on the essential aspects of data. Deep learning\nhas employed attention to boost performance for many applications.\nInterestingly, the same attention design can suit processing different data\nmodalities and can easily be incorporated into large networks. Furthermore,\nmultiple complementary attention mechanisms can be incorporated in one network.\nHence, attention techniques have become extremely attractive. However, the\nliterature lacks a comprehensive survey specific to attention techniques to\nguide researchers in employing attention in their deep models. Note that,\nbesides being demanding in terms of training data and computational resources,\ntransformers only cover a single category in self-attention out of the many\ncategories available. We fill this gap and provide an in-depth survey of 50\nattention techniques categorizing them by their most prominent features. We\ninitiate our discussion by introducing the fundamental concepts behind the\nsuccess of attention mechanism. Next, we furnish some essentials such as the\nstrengths and limitations of each attention category, describe their\nfundamental building blocks, basic formulations with primary usage, and\napplications specifically for computer vision. We also discuss the challenges\nand open questions related to attention mechanism in general. Finally, we\nrecommend possible future research directions for deep attention.",
    "descriptor": "",
    "authors": [
      "Mohammed Hassanin",
      "Saeed Anwar",
      "Ibrahim Radwan",
      "Fahad S Khan",
      "Ajmal Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.07756"
  },
  {
    "id": "arXiv:2204.07761",
    "title": "Language-Grounded Indoor 3D Semantic Segmentation in the Wild",
    "abstract": "Recent advances in 3D semantic segmentation with deep neural networks have\nshown remarkable success, with rapid performance increase on available\ndatasets. However, current 3D semantic segmentation benchmarks contain only a\nsmall number of categories -- less than 30 for ScanNet and SemanticKITTI, for\ninstance, which are not enough to reflect the diversity of real environments\n(e.g., semantic image understanding covers hundreds to thousands of classes).\nThus, we propose to study a larger vocabulary for 3D semantic segmentation with\na new extended benchmark on ScanNet data with 200 class categories, an order of\nmagnitude more than previously studied. This large number of class categories\nalso induces a large natural class imbalance, both of which are challenging for\nexisting 3D semantic segmentation methods. To learn more robust 3D features in\nthis context, we propose a language-driven pre-training method to encourage\nlearned 3D features that might have limited training examples to lie close to\ntheir pre-trained text embeddings. Extensive experiments show that our approach\nconsistently outperforms state-of-the-art 3D pre-training for 3D semantic\nsegmentation on our proposed benchmark (+9% relative mIoU), including\nlimited-data scenarios with +25% relative mIoU using only 5% annotations.",
    "descriptor": "\nComments: 23 pages, 8 figures, project page: this https URL\n",
    "authors": [
      "David Rozenberszki",
      "Or Litany",
      "Angela Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07761"
  },
  {
    "id": "arXiv:2204.07763",
    "title": "UFRC: A Unified Framework for Reliable COVID-19 Detection on  Crowdsourced Cough Audio",
    "abstract": "We suggested a unified system with core components of data augmentation,\nImageNet-pretrained ResNet-50, cost-sensitive loss, deep ensemble learning, and\nuncertainty estimation to quickly and consistently detect COVID-19 using\nacoustic evidence. To increase the model's capacity to identify a minority\nclass, data augmentation and cost-sensitive loss are incorporated (infected\nsamples). In the COVID-19 detection challenge, ImageNet-pretrained ResNet-50\nhas been found to be effective. The unified framework also integrates deep\nensemble learning and uncertainty estimation to integrate predictions from\nvarious base classifiers for generalisation and reliability. We ran a series of\ntests using the DiCOVA2021 challenge dataset to assess the efficacy of our\nproposed method, and the results show that our method has an AUC-ROC of 85.43\npercent, making it a promising method for COVID-19 detection. The unified\nframework also demonstrates that audio may be used to quickly diagnose\ndifferent respiratory disorders.",
    "descriptor": "\nComments: Accepted for presentation at the 44th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC'22)\n",
    "authors": [
      "Jiangeng Chang",
      "Yucheng Ruan",
      "Cui Shaoze",
      "John Soong Tshon Yit",
      "Mengling Feng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.07763"
  },
  {
    "id": "arXiv:2204.07764",
    "title": "Biometric verification of humans by means of hand geometry",
    "abstract": "This paper describes a hand geometry biometric identification system. We have\nacquired a database of 22 people, 10 acquisitions per person, using a\nconventional document scanner. We propose a feature extraction and classifier.\nThe experimental results reveal a maximum identification rate equal to 93.64%,\nand a minimum value of the detection cost function equal to 2.92% using a multi\nlayer perceptron classifier.",
    "descriptor": "\nComments: 8 pages, published in Proceedings 39th Annual 2005 International Carnahan Conference on Security Technology ICCST2005 Las Palmas, Spain. arXiv admin note: substantial text overlap with arXiv:2204.03925\n",
    "authors": [
      "Marcos Faundez-Zanuy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.07764"
  },
  {
    "id": "arXiv:2204.07766",
    "title": "An Integrated Programmable CPG with Bounded Output",
    "abstract": "Cyclic motions are fundamental patterns in robotic applications including\nindustrial manipulation and legged robot locomotion. This paper proposes an\napproach for the online modulation of cyclic motions in robotic applications.\nFor this purpose, we present an integrated programmable Central Pattern\nGenerator (CPG) for the online generation of the reference joint trajectory of\na robotic system out of a library of desired periodic motions. The reference\ntrajectory is then followed by the lower-level controller of the robot. The\nproposed CPG generates a smooth reference joint trajectory convergence to the\ndesired one while preserving the position and velocity joint limits of the\nrobot. The integrated programmable CPG consists of one novel bounded output\nprogrammable oscillator. We design the programmable oscillator for encoding the\ndesired multidimensional periodic trajectory as a stable limit cycle. We also\nuse the state transformation method to ensure that the oscillator's output and\nits first-time derivative preserve the joint position and velocity limits of\nthe robot. With the help of Lyapunov-based arguments, We prove that the\nproposed CPG provides the global stability and convergence of the desired\ntrajectory. The effectiveness of the proposed integrated CPG for trajectory\ngeneration is shown in a passive rehabilitation scenario on the Kuka iiwa robot\narm, and also in a walking simulation on a seven-link bipedal robot.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Venus Pasandi",
      "Hamid Sadeghian",
      "Mehdi Keshmiri",
      "Daniele Pucci"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2204.07766"
  },
  {
    "id": "arXiv:2204.07767",
    "title": "A Distributed and Elastic Aggregation Service for Scalable Federated  Learning Systems",
    "abstract": "Federated Learning has promised a new approach to resolve the challenges in\nmachine learning by bringing computation to the data. The popularity of the\napproach has led to rapid progress in the algorithmic aspects and the emergence\nof systems capable of simulating Federated Learning. State of art systems in\nFederated Learning support a single node aggregator that is insufficient to\ntrain a large corpus of devices or train larger-sized models. As the model size\nor the number of devices increase the single node aggregator incurs memory and\ncomputation burden while performing fusion tasks. It also faces communication\nbottlenecks when a large number of model updates are sent to a single node. We\nclassify the workload for the aggregator into categories and propose a new\naggregation service for handling each load. Our aggregation service is based on\na holistic approach that chooses the best solution depending on the model\nupdate size and the number of clients. Our system provides a fault-tolerant,\nrobust and efficient aggregation solution utilizing existing parallel and\ndistributed frameworks. Through evaluation, we show the shortcomings of the\nstate of art approaches and how a single solution is not suitable for all\naggregation requirements. We also provide a comparison of current frameworks\nwith our system through extensive experiments.",
    "descriptor": "\nComments: 10 pages, 14 figures, 1 table\n",
    "authors": [
      "Ahmad Khan",
      "Yuze Li",
      "Ali Anwar",
      "Yue Cheng",
      "Thang Hoang",
      "Nathalie Baracaldo",
      "Ali Butt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.07767"
  },
  {
    "id": "arXiv:2204.07770",
    "title": "UniGDD: A Unified Generative Framework for Goal-Oriented  Document-Grounded Dialogue",
    "abstract": "The goal-oriented document-grounded dialogue aims at responding to the user\nquery based on the dialogue context and supporting document. Existing studies\ntackle this problem by decomposing it into two sub-tasks: knowledge\nidentification and response generation. However, such pipeline methods would\nunavoidably suffer from the error propagation issue. This paper proposes to\nunify these two sub-tasks via sequentially generating the grounding knowledge\nand the response. We further develop a prompt-connected multi-task learning\nstrategy to model the characteristics and connections of different tasks and\nintroduce linear temperature scheduling to reduce the negative effect of\nirrelevant document information. Experimental results demonstrate the\neffectiveness of our framework.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Chang Gao",
      "Wenxuan Zhang",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07770"
  },
  {
    "id": "arXiv:2204.07772",
    "title": "SETTI: A Self-supervised Adversarial Malware Detection Architecture in  an IoT Environment",
    "abstract": "In recent years, malware detection has become an active research topic in the\narea of Internet of Things (IoT) security. The principle is to exploit\nknowledge from large quantities of continuously generated malware. Existing\nalgorithms practice available malware features for IoT devices and lack\nreal-time prediction behaviors. More research is thus required on malware\ndetection to cope with real-time misclassification of the input IoT data.\nMotivated by this, in this paper we propose an adversarial self-supervised\narchitecture for detecting malware in IoT networks, SETTI, considering samples\nof IoT network traffic that may not be labeled. In the SETTI architecture, we\ndesign three self-supervised attack techniques, namely Self-MDS, GSelf-MDS and\nASelf-MDS. The Self-MDS method considers the IoT input data and the adversarial\nsample generation in real-time. The GSelf-MDS builds a generative adversarial\nnetwork model to generate adversarial samples in the self-supervised structure.\nFinally, ASelf-MDS utilizes three well-known perturbation sample techniques to\ndevelop adversarial malware and inject it over the self-supervised\narchitecture. Also, we apply a defence method to mitigate these attacks, namely\nadversarial self-supervised training to protect the malware detection\narchitecture against injecting the malicious samples. To validate the attack\nand defence algorithms, we conduct experiments on two recent IoT datasets:\nIoT23 and NBIoT. Comparison of the results shows that in the IoT23 dataset, the\nSelf-MDS method has the most damaging consequences from the attacker's point of\nview by reducing the accuracy rate from 98% to 74%. In the NBIoT dataset, the\nASelf-MDS method is the most devastating algorithm that can plunge the accuracy\nrate from 98% to 77%.",
    "descriptor": "\nComments: 20 pages, 6 figures, 2 Tables, Submitted to ACM Transactions on Multimedia Computing, Communications, and Applications\n",
    "authors": [
      "Marjan Golmaryami",
      "Rahim Taheri",
      "Zahra Pooranian",
      "Mohammad Shojafar",
      "Pei Xiao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07772"
  },
  {
    "id": "arXiv:2204.07773",
    "title": "FedCau: A Proactive Stop Policy for Communication and Computation  Efficient Federated Learning",
    "abstract": "This paper investigates efficient distributed training of a Federated\nLearning~(FL) model over a wireless network of wireless devices. The\ncommunication iterations of the distributed training algorithm may be\nsubstantially deteriorated or even blocked by the effects of the devices'\nbackground traffic, packet losses, congestion, or latency. We abstract the\ncommunication-computation impacts as an `iteration cost' and propose a\ncost-aware causal FL algorithm~(FedCau) to tackle this problem. We propose an\niteration-termination method that trade-offs the training performance and\nnetworking costs. We apply our approach when clients use the slotted-ALOHA, the\ncarrier-sense multiple access with collision avoidance~(CSMA/CA), and the\northogonal frequency-division multiple access~(OFDMA) protocols. We show that,\ngiven a total cost budget, the training performance degrades as either the\nbackground communication traffic or the dimension of the training problem\nincreases. Our results demonstrate the importance of proactively designing\noptimal cost-efficient stopping criteria to avoid unnecessary\ncommunication-computation costs to achieve only a marginal FL training\nimprovement. We validate our method by training and testing FL over the MNIST\ndataset. Finally, we apply our approach to existing communication efficient FL\nmethods from the literature, achieving further efficiency. We conclude that\ncost-efficient stopping criteria are essential for the success of practical FL\nover wireless networks.",
    "descriptor": "",
    "authors": [
      "Afsaneh Mahmoudi",
      "Hossein S. Ghadikolaei",
      "Jos\u00e9 Mairton Barros Da Silva J\u00fanior",
      "Carlo Fischione"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07773"
  },
  {
    "id": "arXiv:2204.07775",
    "title": "TASTEset -- Recipe Dataset and Food Entities Recognition Benchmark",
    "abstract": "Food Computing is currently a fast-growing field of research. Natural\nlanguage processing (NLP) is also increasingly essential in this field,\nespecially for recognising food entities. However, there are still only a few\nwell-defined tasks that serve as benchmarks for solutions in this area. We\nintroduce a new dataset -- called \\textit{TASTEset} -- to bridge this gap. In\nthis dataset, Named Entity Recognition (NER) models are expected to find or\ninfer various types of entities helpful in processing recipes, e.g.~food\nproducts, quantities and their units, names of cooking processes, physical\nquality of ingredients, their purpose, taste.\nThe dataset consists of 700 recipes with more than 13,000 entities to\nextract. We provide a few state-of-the-art baselines of named entity\nrecognition models, which show that our dataset poses a solid challenge to\nexisting models. The best model achieved, on average, 0.95 $F_1$ score,\ndepending on the entity type -- from 0.781 to 0.982. We share the dataset and\nthe task to encourage progress on more in-depth and complex information\nextraction from recipes.",
    "descriptor": "",
    "authors": [
      "Ania Wr\u00f3blewska",
      "Agnieszka Kaliska",
      "Maciej Paw\u0142owski",
      "Dawid Wi\u015bniewski",
      "Witold Sosnowski",
      "Agnieszka \u0141awrynowicz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07775"
  },
  {
    "id": "arXiv:2204.07776",
    "title": "Learning to Fill the Seam by Vision: Sub-millimeter Peg-in-hole on  Unseen Shapes in Real World",
    "abstract": "In the peg insertion task, human pays attention to the seam between the peg\nand the hole and tries to fill it continuously with visual feedback. By\nimitating the human behavior, we design architectures with position and\norientation estimators based on the seam representation for pose alignment,\nwhich proves to be general to the unseen peg geometries. By putting the\nestimators into the closed-loop control with reinforcement learning, we further\nachieve higher or comparable success rate, efficiency, and robustness compared\nwith the baseline methods. The policy is trained totally in simulation without\nany manual intervention. To achieve sim- to-real, a learnable segmentation\nmodule with automatic data collecting and labeling can be easily trained to\ndecouple the perception and the policy, which helps the model trained in\nsimulation quickly adapting to the real world with negligible effort. Results\nare presented in simulation and on a physical robot. Code, videos, and\nsupplemental material are available at https://github.com/xieliang555/SFN.git",
    "descriptor": "",
    "authors": [
      "Liang Xie",
      "Hongxiang Yu",
      "Yinghao Zhao",
      "Haodong Zhang",
      "Zhongxiang Zhou",
      "Minhang Wang",
      "Yue Wang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07776"
  },
  {
    "id": "arXiv:2204.07779",
    "title": "SimpleBERT: A Pre-trained Model That Learns to Generate Simple Words",
    "abstract": "Pre-trained models are widely used in the tasks of natural language\nprocessing nowadays. However, in the specific field of text simplification, the\nresearch on improving pre-trained models is still blank. In this work, we\npropose a continued pre-training method for text simplification. Specifically,\nwe propose a new masked language modeling (MLM) mechanism, which does not\nrandomly mask words but only masks simple words. The new mechanism can make the\nmodel learn to generate simple words. We use a small-scale simple text dataset\nfor continued pre-training and employ two methods to identify simple words from\nthe texts. We choose BERT, a representative pre-trained model, and continue\npre-training it using our proposed method. Finally, we obtain SimpleBERT, which\nsurpasses BERT in both lexical simplification and sentence simplification tasks\nand has achieved state-of-the-art results on multiple datasets. What's more,\nSimpleBERT can replace BERT in existing simplification models without\nmodification.",
    "descriptor": "",
    "authors": [
      "Renliang Sun",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07779"
  },
  {
    "id": "arXiv:2204.07780",
    "title": "Towards Lightweight Transformer via Group-wise Transformation for  Vision-and-Language Tasks",
    "abstract": "Despite the exciting performance, Transformer is criticized for its excessive\nparameters and computation cost. However, compressing Transformer remains as an\nopen problem due to its internal complexity of the layer designs, i.e.,\nMulti-Head Attention (MHA) and Feed-Forward Network (FFN). To address this\nissue, we introduce Group-wise Transformation towards a universal yet\nlightweight Transformer for vision-and-language tasks, termed as\nLW-Transformer. LW-Transformer applies Group-wise Transformation to reduce both\nthe parameters and computations of Transformer, while also preserving its two\nmain properties, i.e., the efficient attention modeling on diverse subspaces of\nMHA, and the expanding-scaling feature transformation of FFN. We apply\nLW-Transformer to a set of Transformer-based networks, and quantitatively\nmeasure them on three vision-and-language tasks and six benchmark datasets.\nExperimental results show that while saving a large number of parameters and\ncomputations, LW-Transformer achieves very competitive performance against the\noriginal Transformer networks for vision-and-language tasks. To examine the\ngeneralization ability, we also apply our optimization strategy to a recently\nproposed image Transformer called Swin-Transformer for image classification,\nwhere the effectiveness can be also confirmed",
    "descriptor": "",
    "authors": [
      "Gen Luo",
      "Yiyi Zhou",
      "Xiaoshuai Sun",
      "Yan Wang",
      "Liujuan Cao",
      "Yongjian Wu",
      "Feiyue Huang",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07780"
  },
  {
    "id": "arXiv:2204.07781",
    "title": "Towards Unification of Discourse Annotation Frameworks",
    "abstract": "Discourse information is difficult to represent and annotate. Among the major\nframeworks for annotating discourse information, RST, PDTB and SDRT are widely\ndiscussed and used, each having its own theoretical foundation and focus.\nCorpora annotated under different frameworks vary considerably. To make better\nuse of the existing discourse corpora and achieve the possible synergy of\ndifferent frameworks, it is worthwhile to investigate the systematic relations\nbetween different frameworks and devise methods of unifying the frameworks.\nAlthough the issue of framework unification has been a topic of discussion for\na long time, there is currently no comprehensive approach which considers\nunifying both discourse structure and discourse relations and evaluates the\nunified framework intrinsically and extrinsically. We plan to use automatic\nmeans for the unification task and evaluate the result with structural\ncomplexity and downstream tasks. We will also explore the application of the\nunified framework in multi-task learning and graphical models.",
    "descriptor": "\nComments: accepted at ACL SRW 2022\n",
    "authors": [
      "Yingxue Fu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07781"
  },
  {
    "id": "arXiv:2204.07782",
    "title": "Multihop Optical Wireless Communication Over ${\\cal{F}}$-Turbulence  Channels and Generalized Pointing Errors with Fog-Induced Fading",
    "abstract": "Multihop relaying is a potential technique to mitigate channel impairments in\noptical wireless communications (OWC). In this paper, multiple fixed-gain\namplify-and-forward (AF) relays are employed to enhance the OWC performance\nunder the combined effect of atmospheric turbulence, pointing errors, and fog.\nWe consider a long-range OWC link by modeling the atmospheric turbulence by the\nFisher-Snedecor ${\\cal{F}}$ distribution, pointing errors by the generalized\nnon-zero boresight model, and random path loss due to fog. We also consider a\nshort-range OWC system by ignoring the impact of atmospheric turbulence. We\nderive novel upper bounds on the probability density function (PDF) and\ncumulative distribution function (CDF) of the end-to-end signal-to-noise ratio\n(SNR) for both short and long-range multihop OWC systems by developing exact\nstatistical results for a single-hop OWC system under the combined effect of\n${\\cal{F}}$-turbulence channels, non-zero boresight pointing errors, and\nfog-induced fading. Based on these expressions, we present analytical\nexpressions of outage probability (OP) and average bit-error-rate (ABER)\nperformance for the considered OWC systems involving single-variate Fox's H and\nMeijer's G functions. Moreover, asymptotic expressions of the outage\nprobability in high SNR region are developed using simpler Gamma functions to\nprovide insights on the effect of channel and system parameters. The derived\nanalytical expressions are validated through Monte-Carlo simulations, and the\nscaling of the OWC performance with the number of relay nodes is demonstrated\nwith a comparison to the single-hop transmission.",
    "descriptor": "\nComments: This paper has been submitted in IEEE for possible publication\n",
    "authors": [
      "Ziyaur Rahman",
      "S. M. Zafaruddin",
      "V. K. Chaubey"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.07782"
  },
  {
    "id": "arXiv:2204.07786",
    "title": "Approaching sales forecasting using recurrent neural networks and  transformers",
    "abstract": "Accurate and fast demand forecast is one of the hot topics in supply chain\nfor enabling the precise execution of the corresponding downstream processes\n(inbound and outbound planning, inventory placement, network planning, etc). We\ndevelop three alternatives to tackle the problem of forecasting the customer\nsales at day/store/item level using deep learning techniques and the\nCorporaci\\'on Favorita data set, published as part of a Kaggle competition. Our\nempirical results show how good performance can be achieved by using a simple\nsequence to sequence architecture with minimal data preprocessing effort.\nAdditionally, we describe a training trick for making the model more time\nindependent and hence improving generalization over time. The proposed solution\nachieves a RMSLE of around 0.54, which is competitive with other more specific\nsolutions to the problem proposed in the Kaggle competition.",
    "descriptor": "\nComments: Accepted for publication in Expert Systems and Applications\n",
    "authors": [
      "Iv\u00e1n Vall\u00e9s-P\u00e9rez",
      "Emilio Soria-Olivas",
      "Marcelino Mart\u00ednez-Sober",
      "Antonio J. Serrano-L\u00f3pez",
      "Juan G\u00f3mez-Sanch\u00eds",
      "Fernando Mateo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2204.07786"
  },
  {
    "id": "arXiv:2204.07789",
    "title": "Contrastive Learning with Hard Negative Entities for Entity Set  Expansion",
    "abstract": "Entity Set Expansion (ESE) is a promising task which aims to expand entities\nof the target semantic class described by a small seed entity set. Various NLP\nand IR applications will benefit from ESE due to its ability to discover\nknowledge. Although previous ESE methods have achieved great progress, most of\nthem still lack the ability to handle hard negative entities (i.e., entities\nthat are difficult to distinguish from the target entities), since two entities\nmay or may not belong to the same semantic class based on different granularity\nlevels we analyze on. To address this challenge, we devise an entity-level\nmasked language model with contrastive learning to refine the representation of\nentities. In addition, we propose the ProbExpan, a novel probabilistic ESE\nframework utilizing the entity representation obtained by the aforementioned\nlanguage model to expand entities. Extensive experiments and detailed analyses\non three datasets show that our method outperforms previous state-of-the-art\nmethods. The source codes of this paper are available at\nhttps://github.com/geekjuruo/ProbExpan.",
    "descriptor": "\nComments: Accepted by SIGIR 2022 (Full Paper)\n",
    "authors": [
      "Yinghui Li",
      "Yangning Li",
      "Yuxin He",
      "Tianyu Yu",
      "Ying Shen",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.07789"
  },
  {
    "id": "arXiv:2204.07791",
    "title": "UAMD-Net: A Unified Adaptive Multimodal Neural Network for Dense Depth  Completion",
    "abstract": "Depth prediction is a critical problem in robotics applications especially\nautonomous driving. Generally, depth prediction based on binocular stereo\nmatching and fusion of monocular image and laser point cloud are two mainstream\nmethods. However, the former usually suffers from overfitting while building\ncost volume, and the latter has a limited generalization due to the lack of\ngeometric constraint. To solve these problems, we propose a novel multimodal\nneural network, namely UAMD-Net, for dense depth completion based on fusion of\nbinocular stereo matching and the weak constrain from the sparse point clouds.\nSpecifically, the sparse point clouds are converted to sparse depth map and\nsent to the multimodal feature encoder (MFE) with binocular image, constructing\na cross-modal cost volume. Then, it will be further processed by the multimodal\nfeature aggregator (MFA) and the depth regression layer. Furthermore, the\nexisting multimodal methods ignore the problem of modal dependence, that is,\nthe network will not work when a certain modal input has a problem. Therefore,\nwe propose a new training strategy called Modal-dropout which enables the\nnetwork to be adaptively trained with multiple modal inputs and inference with\nspecific modal inputs. Benefiting from the flexible network structure and\nadaptive training method, our proposed network can realize unified training\nunder various modal input conditions. Comprehensive experiments conducted on\nKITTI depth completion benchmark demonstrate that our method produces robust\nresults and outperforms other state-of-the-art methods.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Guancheng Chen",
      "Junli Lin",
      "Huabiao Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07791"
  },
  {
    "id": "arXiv:2204.07793",
    "title": "Compressive Sensing-Based Recovery of Molecular Mixtures with  Cross-Reactive Receptor Arrays",
    "abstract": "In this paper, we propose a novel concept for engineered molecular\ncommunication (MC) systems inspired by animal olfaction. We focus on a\nmulti-user scenario where transmitters employ unique mixtures of different\ntypes of signaling molecules to convey their messages to a central receiver,\nwhich is equipped with an array comprising $R$ different types of receptors to\ndetect the emitted molecule mixtures. The hardware complexity of an MC system\nemploying \\textit{orthogonal} molecule-receptor pairs would linearly scale with\nthe number of signaling molecule types $Q$ (i.e., $R=Q$). Natural olfaction\nsystems avoid such high complexity by employing arrays of\n\\textit{cross-reactive} receptors, where each type of molecule activates\nmultiple types of receptors and each type of receptor is predominantly\nactivated by multiple types of molecules albeit with different activation\nstrengths. For instance, the human olfactory system is believed to discriminate\nseveral thousands of chemicals using only a few hundred receptor types, i.e.,\n$Q\\gg R$. Motivated by this observation, we first develop an end-to-end MC\nchannel model that accounts for the key properties of olfaction. Subsequently,\nwe formulate the molecule mixture recovery as a convex compressive sensing (CS)\nproblem which can be efficiently solved via available numerical solvers. Our\nsimulation results confirm the efficiency of the proposed CS problem for the\nrecovery of the molecular mixture signal and quantify the system performance\nfor various system parameters.",
    "descriptor": "\nComments: Conference version of arXiv:2203.04225\n",
    "authors": [
      "Vahid Jamali",
      "Helene M. Loos",
      "Andrea Buettner",
      "Robert Schober",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.07793"
  },
  {
    "id": "arXiv:2204.07796",
    "title": "Fuzzy-based Robust Precision Consensus Tracking for Uncertain Networked  Systems with Cooperative-Antagonistic Interactions",
    "abstract": "In bipartite consensus tracking (BCT) tasks for nonlinear multiagent systems,\nstochastic disturbances and actuator faults are regarded as essential factors\nthat hamper effective controller formulation and tracking precision\nimprovement. To address these difficulties, we design an improved finitetime\nperformance function (FTPF) for a fuzzy fault-tolerant distributed cooperative\ncontrol scheme to achieve finite-time robust precision BCT tasks for nonlinear\nmultiagent systems. The parameter selection range of the improved FTPF is\nrelaxed, which renders systems to achieve better transient performance.\nBenefitting from stochastic Lyapunov stability theory, it is shown that all\nsignals of systems are semi-global uniformly ultimately bounded in probability,\nand bipartite consensus errors can satisfy the arbitrary precision with\nprobability in the predefined time. Finally, to verify its effectiveness, the\nproposed control scheme is applied to BCT tasks of a group of vehicles, which\nmanifests anticipated control performance under various uncertainties.",
    "descriptor": "\nComments: 13pages 16figures\n",
    "authors": [
      "Amorey Lewis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2204.07796"
  },
  {
    "id": "arXiv:2204.07799",
    "title": "Scheduling Coflows for Minimizing the Total Weighted Completion Time in  Heterogeneous Parallel Networks",
    "abstract": "Coflow is a network abstraction used to represent communication patterns in\ndata centers. The coflow scheduling problem in large data centers is one of the\nmost important $NP$-hard problems. Many previous studies on coflow scheduling\nmainly focus on the single-core model. However, with the growth of data\ncenters, this single-core model is no longer sufficient. This paper considers\nthe coflow scheduling problem in heterogeneous parallel networks. The\nheterogeneous parallel network is an architecture based on multiple network\ncores running in parallel. In this paper, two polynomial-time approximation\nalgorithms are developed for scheduling divisible and indivisible coflows in\nheterogeneous parallel networks, respectively. Both algorithms achieve an\napproximation ratio of $O(\\log m/ \\log \\log m)$ with arbitrary release times.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2204.02651\n",
    "authors": [
      "Chi-Yeh Chen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.07799"
  },
  {
    "id": "arXiv:2204.07803",
    "title": "Logical Inference for Counting on Semi-structured Tables",
    "abstract": "Recently, the Natural Language Inference (NLI) task has been studied for\nsemi-structured tables that do not have a strict format. Although neural\napproaches have achieved high performance in various types of NLI, including\nNLI between semi-structured tables and texts, they still have difficulty in\nperforming a numerical type of inference, such as counting. To handle a\nnumerical type of inference, we propose a logical inference system for\nreasoning between semi-structured tables and texts. We use logical\nrepresentations as meaning representations for tables and texts and use model\nchecking to handle a numerical type of inference between texts and tables. To\nevaluate the extent to which our system can perform inference with numerical\ncomparatives, we make an evaluation protocol that focuses on numerical\nunderstanding between semi-structured tables and texts in English. We show that\nour system can more robustly perform inference between tables and texts that\nrequires numerical understanding compared with current neural approaches.",
    "descriptor": "\nComments: 13 pages. To appear in the Proceedings of the Association for Computational Linguistics: Student Research Workshop (ACL-SRW 2022)\n",
    "authors": [
      "Tomoya Kurosawa",
      "Hitomi Yanaka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07803"
  },
  {
    "id": "arXiv:2204.07804",
    "title": "Learning to Classify Open Intent via Soft Labeling and Manifold Mixup",
    "abstract": "Open intent classification is a practical yet challenging task in dialogue\nsystems. Its objective is to accurately classify samples of known intents while\nat the same time detecting those of open (unknown) intents. Existing methods\nusually use outlier detection algorithms combined with K-class classifier to\ndetect open intents, where K represents the class number of known intents.\nDifferent from them, in this paper, we consider another way without using\noutlier detection algorithms. Specifically, we directly train a (K+1)-class\nclassifier for open intent classification, where the (K+1)-th class represents\nopen intents. To address the challenge that training a (K+1)-class classifier\nwith training samples of only K classes, we propose a deep model based on Soft\nLabeling and Manifold Mixup (SLMM). In our method, soft labeling is used to\nreshape the label distribution of the known intent samples, aiming at reducing\nmodel's overconfident on known intents. Manifold mixup is used to generate\npseudo samples for open intents, aiming at well optimizing the decision\nboundary of open intents. Experiments on four benchmark datasets demonstrate\nthat our method outperforms previous methods and achieves state-of-the-art\nperformance. All the code and data of this work can be obtained at\nhttps://github.com/zifengcheng/SLMM.",
    "descriptor": "\nComments: Accepted by IEEE/ACM Transactions on Audio Speech and Language\n",
    "authors": [
      "Zifeng Cheng",
      "Zhiwei Jiang",
      "Yafeng Yin",
      "Cong Wang",
      "Qing Gu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07804"
  },
  {
    "id": "arXiv:2204.07805",
    "title": "Universal Solution Manifold Networks (USM-Nets): non-intrusive mesh-free  surrogate models for problems in variable domains",
    "abstract": "We introduce Universal Solution Manifold Network (USM-Net), a novel surrogate\nmodel, based on Artificial Neural Networks (ANNs), which applies to\ndifferential problems whose solution depends on physical and geometrical\nparameters. Our method employs a mesh-less architecture, thus overcoming the\nlimitations associated with image segmentation and mesh generation required by\ntraditional discretization methods. Indeed, we encode geometrical variability\nthrough scalar landmarks, such as coordinates of points of interest. In\nbiomedical applications, these landmarks can be inexpensively processed from\nclinical images. Our approach is non-intrusive and modular, as we select a\ndata-driven loss function. The latter can also be modified by considering\nadditional constraints, thus leveraging available physical knowledge. Our\napproach can also accommodate a universal coordinate system, which supports the\nUSM-Net in learning the correspondence between points belonging to different\ngeometries, boosting prediction accuracy on unobserved geometries. Finally, we\npresent two numerical test cases in computational fluid dynamics involving\nvariable Reynolds numbers as well as computational domains of variable shape.\nThe results show that our method allows for inexpensive but accurate\napproximations of velocity and pressure, avoiding computationally expensive\nimage segmentation, mesh generation, or re-training for every new instance of\nphysical parameters and shape of the domain.",
    "descriptor": "",
    "authors": [
      "Francesco Regazzoni",
      "Stefano Pagani",
      "Alfio Quarteroni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.07805"
  },
  {
    "id": "arXiv:2204.07818",
    "title": "Graph-incorporated Latent Factor Analysis for High-dimensional and  Sparse Matrices",
    "abstract": "A High-dimensional and sparse (HiDS) matrix is frequently encountered in a\nbig data-related application like an e-commerce system or a social network\nservices system. To perform highly accurate representation learning on it is of\ngreat significance owing to the great desire of extracting latent knowledge and\npatterns from it. Latent factor analysis (LFA), which represents an HiDS matrix\nby learning the low-rank embeddings based on its observed entries only, is one\nof the most effective and efficient approaches to this issue. However, most\nexisting LFA-based models perform such embeddings on a HiDS matrix directly\nwithout exploiting its hidden graph structures, thereby resulting in accuracy\nloss. To address this issue, this paper proposes a graph-incorporated latent\nfactor analysis (GLFA) model. It adopts two-fold ideas: 1) a graph is\nconstructed for identifying the hidden high-order interaction (HOI) among nodes\ndescribed by an HiDS matrix, and 2) a recurrent LFA structure is carefully\ndesigned with the incorporation of HOI, thereby improving the representa-tion\nlearning ability of a resultant model. Experimental results on three real-world\ndatasets demonstrate that GLFA outperforms six state-of-the-art models in\npredicting the missing data of an HiDS matrix, which evidently supports its\nstrong representation learning ability to HiDS data.",
    "descriptor": "",
    "authors": [
      "Di Wu",
      "Yi He",
      "Xin Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07818"
  },
  {
    "id": "arXiv:2204.07819",
    "title": "A Multi-Metric Latent Factor Model for Analyzing High-Dimensional and  Sparse data",
    "abstract": "High-dimensional and sparse (HiDS) matrices are omnipresent in a variety of\nbig data-related applications. Latent factor analysis (LFA) is a typical\nrepresentation learning method that extracts useful yet latent knowledge from\nHiDS matrices via low-rank approximation. Current LFA-based models mainly focus\non a single-metric representation, where the representation strategy designed\nfor the approximation Loss function, is fixed and exclusive. However,\nreal-world HiDS matrices are commonly heterogeneous and inclusive and have\ndiverse underlying patterns, such that a single-metric representation is most\nlikely to yield inferior performance. Motivated by this, we in this paper\npropose a multi-metric latent factor (MMLF) model. Its main idea is two-fold:\n1) two vector spaces and three Lp-norms are simultaneously employed to develop\nsix variants of LFA model, each of which resides in a unique metric\nrepresentation space, and 2) all the variants are ensembled with a tailored,\nself-adaptive weighting strategy. As such, our proposed MMLF enjoys the merits\noriginated from a set of disparate metric spaces all at once, achieving the\ncomprehensive and unbiased representation of HiDS matrices. Theoretical study\nguarantees that MMLF attains a performance gain. Extensive experiments on eight\nreal-world HiDS datasets, spanning a wide range of industrial and science\ndomains, verify that our MMLF significantly outperforms ten state-of-the-art,\nshallow and deep counterparts.",
    "descriptor": "",
    "authors": [
      "Di Wu",
      "Peng Zhang",
      "Yi He",
      "Xin Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07819"
  },
  {
    "id": "arXiv:2204.07820",
    "title": "FCL-GAN: A Lightweight and Real-Time Baseline for Unsupervised Blind  Image Deblurring",
    "abstract": "Blind image deblurring (BID) remains a challenging and significant task.\nBenefiting from the strong fitting ability of deep learning, paired data-driven\nsupervised BID method has obtained great progress. However, paired data are\nusually synthesized by hand, and the realistic blurs are more complex than\nsynthetic ones, which makes the supervised methods inept at modeling realistic\nblurs and hinders their real-world applications. As such, unsupervised deep BID\nmethod without paired data offers certain advantages, but current methods still\nsuffer from some drawbacks, e.g., bulky model size, long inference time, and\nstrict image resolution and domain requirements. In this paper, we propose a\nlightweight and real-time unsupervised BID baseline, termed Frequency-domain\nContrastive Loss Constrained Lightweight CycleGAN (shortly, FCL-GAN), with\nattractive properties, i.e., no image domain limitation, no image resolution\nlimitation, 25x lighter than SOTA, and 5x faster than SOTA. To guarantee the\nlightweight property and performance superiority, two new collaboration units\ncalled lightweight domain conversion unit(LDCU) and parameter-free\nfrequency-domain contrastive unit(PFCU) are designed. LDCU mainly implements\ninter-domain conversion in lightweight manner. PFCU further explores the\nsimilarity measure, external difference and internal connection between the\nblurred domain and sharp domain images in frequency domain, without involving\nextra parameters. Extensive experiments on several image datasets demonstrate\nthe effectiveness of our FCL-GAN in terms of performance, model size and\nreference time.",
    "descriptor": "",
    "authors": [
      "Suiyi Zhao",
      "Zhao Zhang",
      "Richang Hong",
      "Mingliang Xu",
      "Yi Yang",
      "Meng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07820"
  },
  {
    "id": "arXiv:2204.07827",
    "title": "Local treewidth of random and noisy graphs with applications to stopping  contagion in networks",
    "abstract": "We study the notion of local treewidth in sparse random graphs: the maximum\ntreewidth over all $k$-vertex subgraphs of an $n$-vertex graph. When $k$ is not\ntoo large, we give nearly tight bounds for this local treewidth parameter; we\nalso derive tight bounds for the local treewidth of noisy trees, trees where\nevery non-edge is added independently with small probability. We apply our\nupper bounds on the local treewidth to obtain fixed parameter tractable\nalgorithms (on random graphs and noisy trees) for edge-removal problems\ncentered around containing a contagious process evolving over a network. In\nthese problems, our main parameter of study is $k$, the number of \"infected\"\nvertices in the network. For a certain range of parameters the running time of\nour algorithms on $n$-vertex graphs is $2^{o(k)}\\textrm{poly}(n)$, improving\nupon the $2^{\\Omega(k)}\\textrm{poly}(n)$ performance of the best-known\nalgorithms designed for worst-case instances of these edge deletion problems.",
    "descriptor": "",
    "authors": [
      "Hermish Mehta",
      "Daniel Reichman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.07827"
  },
  {
    "id": "arXiv:2204.07832",
    "title": "A Contrastive Cross-Channel Data Augmentation Framework for Aspect-based  Sentiment Analysis",
    "abstract": "Aspect-Based Sentiment Analysis is a fine-grained sentiment analysis task,\nwhich focuses on detecting the sentiment polarity towards the aspect in a\nsentence. However, it is always sensitive to the multi-aspect challenge, where\nfeatures of multiple aspects in a sentence will affect each other. To mitigate\nthis issue, we design a novel training framework, called Contrastive\nCross-Channel Data Augmentation (C3DA). A source sentence will be fed a\ndomain-specific generator to obtain some synthetic sentences and is\nconcatenated with these generated sentences to conduct supervised training and\nproposed contrastive training. To be specific, considering the limited ABSA\nlabeled data, we also introduce some parameter-efficient approaches to complete\nsentences generation. This novel generation method consists of an Aspect\nAugmentation Channel (AAC) to generate aspect-specific sentences and a Polarity\nAugmentation (PAC) to generate polarity-inverted sentences. According to our\nextensive experiments, our C3DA framework can outperform those baselines\nwithout any augmentations by about 1\\% on accuracy and Macro-F1.",
    "descriptor": "",
    "authors": [
      "Bing Wang",
      "Liang Ding",
      "Qihuang Zhong",
      "Ximing Li",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07832"
  },
  {
    "id": "arXiv:2204.07834",
    "title": "Bridging Cross-Lingual Gaps During Leveraging the Multilingual  Sequence-to-Sequence Pretraining for Text Generation",
    "abstract": "For multilingual sequence-to-sequence pretrained language models\n(multilingual Seq2Seq PLMs), e.g. mBART, the self-supervised pretraining task\nis trained on a wide range of monolingual languages, e.g. 25 languages from\ncommoncrawl, while the downstream cross-lingual tasks generally progress on a\nbilingual language subset, e.g. English-German, making there exists the\ncross-lingual data discrepancy, namely \\textit{domain discrepancy}, and\ncross-lingual learning objective discrepancy, namely \\textit{task discrepancy},\nbetween the pretrain and finetune stages. To bridge the above cross-lingual\ndomain and task gaps, we extend the vanilla pretrain-finetune pipeline with\nextra code-switching restore task. Specifically, the first stage employs the\nself-supervised code-switching restore task as a pretext task, allowing the\nmultilingual Seq2Seq PLM to acquire some in-domain alignment information. And\nfor the second stage, we continuously fine-tune the model on labeled data\nnormally. Experiments on a variety of cross-lingual NLG tasks, including 12\nbilingual translation tasks, 36 zero-shot translation tasks, and cross-lingual\nsummarization tasks show our model outperforms the strong baseline mBART\nconsistently. Comprehensive analyses indicate our approach could narrow the\ncross-lingual sentence representation distance and improve low-frequency word\ntranslation with trivial computational cost.",
    "descriptor": "",
    "authors": [
      "Changtong Zan",
      "Liang Ding",
      "Li Shen",
      "Yu Cao",
      "Weifeng Liu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07834"
  },
  {
    "id": "arXiv:2204.07835",
    "title": "What If: Generating Code to Answer Simulation Questions",
    "abstract": "Many texts, especially in chemistry and biology, describe complex processes.\nWe focus on texts that describe a chemical reaction process and questions that\nask about the process's outcome under different environmental conditions. To\nanswer questions about such processes, one needs to understand the interactions\nbetween the different entities involved in the process and to simulate their\nstate transitions during the process execution under different conditions. A\nstate transition is defined as the memory modification the program does to the\nvariables during the execution. We hypothesize that generating code and\nexecuting it to simulate the process will allow answering such questions. We,\ntherefore, define a domain-specific language (DSL) to represent processes. We\ncontribute to the community a unique dataset curated by chemists and annotated\nby computer scientists. The dataset is composed of process texts, simulation\nquestions, and their corresponding computer codes represented by the DSL.We\npropose a neural program synthesis approach based on reinforcement learning\nwith a novel state-transition semantic reward. The novel reward is based on the\nrun-time semantic similarity between the predicted code and the reference code.\nThis allows simulating complex process transitions and thus answering\nsimulation questions. Our approach yields a significant boost in accuracy for\nsimulation questions: 88\\% accuracy as opposed to 83\\% accuracy of the\nstate-of-the-art neural program synthesis approaches and 54\\% accuracy of\nstate-of-the-art end-to-end text-based approaches.",
    "descriptor": "",
    "authors": [
      "Gal Peretz",
      "Kira Radinsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07835"
  },
  {
    "id": "arXiv:2204.07837",
    "title": "BLISS: Robust Sequence-to-Sequence Learning via Self-Supervised Input  Representation",
    "abstract": "Data augmentations (DA) are the cores to achieving robust\nsequence-to-sequence learning on various natural language processing (NLP)\ntasks. However, most of the DA approaches force the decoder to make predictions\nconditioned on the perturbed input representation, underutilizing supervised\ninformation provided by perturbed input. In this work, we propose a\nframework-level robust sequence-to-sequence learning approach, named BLISS, via\nself-supervised input representation, which has the great potential to\ncomplement the data-level augmentation approaches. The key idea is to supervise\nthe sequence-to-sequence framework with both the \\textit{supervised}\n(\"input$\\rightarrow$output\") and \\textit{self-supervised} (\"perturbed\ninput$\\rightarrow$input\") information. We conduct comprehensive experiments to\nvalidate the effectiveness of BLISS on various tasks, including machine\ntranslation, grammatical error correction, and text summarization. The results\nshow that BLISS outperforms significantly the vanilla Transformer and\nconsistently works well across tasks than the other five contrastive baselines.\nExtensive analyses reveal that BLISS learns robust representations and rich\nlinguistic knowledge, confirming our claim. Source code will be released upon\npublication.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1904.03092, arXiv:1904.03100 by other authors\n",
    "authors": [
      "Zheng Zhang",
      "Liang Ding",
      "Dazhao Cheng",
      "Xuebo Liu",
      "Min Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07837"
  },
  {
    "id": "arXiv:2204.07839",
    "title": "A Logical Analysis of Dynamic Dependence",
    "abstract": "Many forms of dependence manifest themselves over time, with behavior of\nvariables in dynamical systems as a paradigmatic example. This paper studies\ntemporal dependence in dynamical systems from a logical perspective, by\nextending a minimal modal base logic of static functional dependencies. We\ndefine a logic for dynamical systems with single time steps, provide a complete\naxiomatic proof calculus, and show the decidability of the satisfiability\nproblem for a substantial fragment. The system comes in two guises: modal and\nfirst-order, that naturally complement each other. Next, we consider a timed\nsemantics for our logic, as an intermediate between state spaces and temporal\nuniverses for the unfoldings of a dynamical system. We prove completeness and\ndecidability by combining techniques from dynamic-epistemic logic and modal\nlogic of functional dependencies with complex terms for objects. Also, we\nextend these results to the timed logic with functional symbols and term\nidentity. Finally, we conclude with a brief outlook on how the system proposed\nhere connects with richer temporal logics of system behavior, and with dynamic\ntopological logic.",
    "descriptor": "",
    "authors": [
      "Alexandru Baltag",
      "Johan van Benthem",
      "Dazhu Li"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.07839"
  },
  {
    "id": "arXiv:2204.07840",
    "title": "A Robust and Scalable Attention Guided Deep Learning Framework for  Movement Quality Assessment",
    "abstract": "Physical rehabilitation programs frequently begin with a brief stay in the\nhospital and continue with home-based rehabilitation. Lack of feedback on\nexercise correctness is a significant issue in home-based rehabilitation.\nAutomated movement quality assessment (MQA) using skeletal movement data\n(hereafter referred to as skeletal data) collected via depth imaging devices\ncan assist with home-based rehabilitation by providing the necessary\nquantitative feedback. This paper aims to use recent advances in deep learning\nto address the problem of MQA. Movement quality score generation is an\nessential component of MQA. We propose three novel skeletal data augmentation\nschemes. We show that using the proposed augmentations for generating movement\nquality scores result in significant performance boosts over existing methods.\nFinally, we propose a novel transformer based architecture for MQA. Four novel\nfeature extractors are proposed and studied that allow the transformer network\nto operate on skeletal data. We show that adding the attention mechanism in the\ndesign of the proposed feature extractor allows the transformer network to pay\nattention to specific body parts that make a significant contribution towards\nexecuting a movement. We report an improvement in movement quality score\nprediction of 12% on UI-PRMD dataset and 21% on KIMORE dataset compared to the\nexisting methods.",
    "descriptor": "",
    "authors": [
      "Aditya Kanade",
      "Mansi Sharma",
      "Manivannan Muniyandi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07840"
  },
  {
    "id": "arXiv:2204.07841",
    "title": "Multimodal Few-Shot Object Detection with Meta-Learning Based  Cross-Modal Prompting",
    "abstract": "We study multimodal few-shot object detection (FSOD) in this paper, using\nboth few-shot visual examples and class semantic information for detection.\nMost of previous works focus on either few-shot or zero-shot object detection,\nignoring the complementarity of visual and semantic information. We first show\nthat meta-learning and prompt-based learning, the most commonly-used methods\nfor few-shot learning and zero-shot transferring from pre-trained\nvision-language models to downstream tasks, are conceptually similar. They both\nreformulate the objective of downstream tasks the same as the pre-training\ntasks, and mostly without tuning the parameters of pre-trained models. Based on\nthis observation, we propose to combine meta-learning with prompt-based\nlearning for multimodal FSOD without fine-tuning, by learning transferable\nclass-agnostic multimodal FSOD models over many-shot base classes.\nSpecifically, to better exploit the pre-trained vision-language models, the\nmeta-learning based cross-modal prompting is proposed to generate soft prompts\nand further used to extract the semantic prototype, conditioned on the few-shot\nvisual examples. Then, the extracted semantic prototype and few-shot visual\nprototype are fused to generate the multimodal prototype for detection. Our\nmodels can efficiently fuse the visual and semantic information at both\ntoken-level and feature-level. We comprehensively evaluate the proposed\nmultimodal FSOD models on multiple few-shot object detection benchmarks,\nachieving promising results.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Guangxing Han",
      "Jiawei Ma",
      "Shiyuan Huang",
      "Long Chen",
      "Rama Chellappa",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.07841"
  },
  {
    "id": "arXiv:2204.07845",
    "title": "Shape-guided Object Inpainting",
    "abstract": "Previous works on image inpainting mainly focus on inpainting background or\npartially missing objects, while the problem of inpainting an entire missing\nobject remains unexplored. This work studies a new image inpainting task, i.e.\nshape-guided object inpainting. Given an incomplete input image, the goal is to\nfill in the hole by generating an object based on the context and implicit\nguidance given by the hole shape. Since previous methods for image inpainting\nare mainly designed for background inpainting, they are not suitable for this\ntask. Therefore, we propose a new data preparation method and a novel\nContextual Object Generator (CogNet) for the object inpainting task. On the\ndata side, we incorporate object priors into training data by using object\ninstances as holes. The CogNet has a two-stream architecture that combines the\nstandard bottom-up image completion process with a top-down object generation\nprocess. A predictive class embedding module bridges the two streams by\npredicting the class of the missing object from the bottom-up features, from\nwhich a semantic object map is derived as the input of the top-down stream.\nExperiments demonstrate that the proposed method can generate realistic objects\nthat fit the context in terms of both visual appearance and semantic meanings.\nCode can be found at the project page\n\\url{https://zengxianyu.github.io/objpaint}",
    "descriptor": "",
    "authors": [
      "Yu Zeng",
      "Zhe Lin",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.07845"
  },
  {
    "id": "arXiv:2204.07846",
    "title": "On Safety Testing, Validation, and Characterization with  Scenario-Sampling: A Case Study of Legged Robots",
    "abstract": "The dynamic response of the legged robot locomotion is non-Lipschitz and can\nbe stochastic due to environmental uncertainties. To test, validate, and\ncharacterize the safety performance of legged robots, existing solutions on\nobserved and inferred risk can be incomplete and sampling inefficient. Some\nformal verification methods suffer from the model precision and other surrogate\nassumptions. In this paper, we propose a scenario sampling based testing\nframework that characterizes the overall safety performance of a legged robot\nby specifying (i) where (in terms of a set of states) the robot is potentially\nsafe, and (ii) how safe the robot is within the specified set. The framework\ncan also help certify the commercial deployment of the legged robot in\nreal-world environment along with human and compare safety performance among\nlegged robots with different mechanical structures and dynamic properties. The\nproposed framework is further deployed to evaluate a group of state-of-the-art\nlegged robot locomotion controllers from various model-based, deep neural\nnetwork involved, and reinforcement learning based methods in the literature.\nAmong a series of intended work domains of the studied legged robots (e.g.\ntracking speed on sloped surface, with abrupt changes on demanded velocity, and\nagainst adversarial push-over disturbances), we show that the method can\nadequately capture the overall safety characterization and the subtle\nperformance insights. Many of the observed safety outcomes, to the best of our\nknowledge, have never been reported by the existing work in the legged robot\nliterature.",
    "descriptor": "",
    "authors": [
      "Bowen Weng",
      "Guillermo A. Castillo",
      "Wei Zhang",
      "Ayonga Hereid"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07846"
  },
  {
    "id": "arXiv:2204.07848",
    "title": "STRATA: Word Boundaries & Phoneme Recognition From Continuous Urdu  Speech using Transfer Learning, Attention, & Data Augmentation",
    "abstract": "Phoneme recognition is a largely unsolved problem in NLP, especially for\nlow-resource languages like Urdu. The systems that try to extract the phonemes\nfrom audio speech require hand-labeled phonetic transcriptions. This requires\nexpert linguists to annotate speech data with its relevant phonetic\nrepresentation which is both an expensive and a tedious task. In this paper, we\npropose STRATA, a framework for supervised phoneme recognition that overcomes\nthe data scarcity issue for low resource languages using a seq2seq neural\narchitecture integrated with transfer learning, attention mechanism, and data\naugmentation. STRATA employs transfer learning to reduce the network loss in\nhalf. It uses attention mechanism for word boundaries and frame alignment\ndetection which further reduces the network loss by 4% and is able to identify\nthe word boundaries with 92.2% accuracy. STRATA uses various data augmentation\ntechniques to further reduce the loss by 1.5% and is more robust towards new\nsignals both in terms of generalization and accuracy. STRATA is able to achieve\na Phoneme Error Rate of 16.5% and improves upon the state of the art by 1.1%\nfor TIMIT dataset (English) and 11.5% for CSaLT dataset (Urdu).",
    "descriptor": "",
    "authors": [
      "Saad Naeem",
      "Omer Beg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.07848"
  },
  {
    "id": "arXiv:2204.07851",
    "title": "COVIBOT: A Smart Chatbot for Assistance and E-Awareness during COVID-19  Pandemic",
    "abstract": "The coronavirus pandemic has spread over the past two years in our highly\nconnected and information-dense society. Nonetheless, disseminating accurate\nand up-to-date information on the spread of this pandemic remains a challenge.\nIn this context, opting for a solution based on conversational artificial\nintelligence, also known under the name of the chatbot, is proving to be an\nunavoidable solution, especially since it has already shown its effectiveness\nin fighting the coronavirus crisis in several countries. This work proposes to\ndesign and implement a smart chatbot on the theme of COVID-19, called COVIBOT,\nwhich will be useful in the context of Saudi Arabia. COVIBOT is a\ngenerative-based contextual chatbot, which is built using machine learning APIs\nthat are offered by the cloud-based Azure Cognitive Services. Two versions of\nCOVIBOT are offered: English and Arabic versions. Use cases of COVIBOT are\ntested and validated using a scenario-based approach.",
    "descriptor": "\nComments: SMARTTECH 2022: The Second International Conference of Smart Systems and Emerging Technologies\n",
    "authors": [
      "Maha Driss",
      "Iman Almomani",
      "Leen Alahmadi",
      "Linah Alhajjam",
      "Raghad Alharbi",
      "Shahad Alanazi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07851"
  },
  {
    "id": "arXiv:2204.07852",
    "title": "Traffic-Aware Mean-Field Power Allocation for Ultra-Dense NB-IoT  Networks",
    "abstract": "The Narrowband Internet of Things (NB-IoT) is a cellular technology\nintroduced by the Third Generation Partnership Project (3GPP) to provide\nconnectivity to a large number of low-cost IoT devices with strict energy\nconsumption limitations. However, in an ultra-dense small cell network\nemploying NB-IoT technology, inter-cell interference can be a problem, raising\nserious concerns regarding the performance of NB-IoT, particularly in uplink\ntransmission. Thus, a power allocation method must be established to analyze\nuplink performance, control and predict inter-cell interference, and avoid\nexcessive energy waste during transmission. Unfortunately, standard power\nallocation techniques become inappropriate as their computational complexity\ngrows in an ultra-dense environment. Furthermore, the performance of NB-IoT is\nstrongly dependent on the traffic generated by IoT devices. In order to tackle\nthese challenges, we provide a consistent and distributed uplink power\nallocation solution under spatiotemporal fluctuation incorporating NB-IoT\nfeatures such as the number of repetitions and the data rate, as well as the\nIoT device's energy budget, packet size, and traffic intensity, by leveraging\nstochastic geometry analysis and Mean-Field Game (MFG) theory. The\neffectiveness of our approach is illustrated via extensive numerical analysis,\nand many insightful discussions are presented.",
    "descriptor": "\nComments: 14 pages, 7 figures, 4 tables. This work has been submitted to the IEEE Internet of Things Journal for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sami Nadif",
      "Essaid Sabir",
      "Halima Elbiaze",
      "Abdelkrim Haqiq"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07852"
  },
  {
    "id": "arXiv:2204.07853",
    "title": "nigam@COLIEE-22: Legal Case Retrieval and Entailment using Cascading of  Lexical and Semantic-based models",
    "abstract": "This paper describes our submission to the Competition on Legal Information\nExtraction/Entailment 2022 (COLIEE-2022) workshop on case law competition for\ntasks 1 and 2. Task 1 is a legal case retrieval task, which involves reading a\nnew case and extracting supporting cases from the provided case law corpus to\nsupport the decision. Task 2 is the legal case entailment task, which involves\nthe identification of a paragraph from existing cases that entails the decision\nin a relevant case. We employed the neural models Sentence-BERT and Sent2Vec\nfor semantic understanding and the traditional retrieval model BM25 for exact\nmatching in both tasks. As a result, our team (\"nigam\") ranked 5th among all\nthe teams in Tasks 1 and 2. Experimental results indicate that the traditional\nretrieval model BM25 still outperforms neural network-based models.",
    "descriptor": "\nComments: COLIEE-2022 Workshop paper run in association with the International Workshop in Juris-Informatics (JURISIN 2022)\n",
    "authors": [
      "Shubham Kumar Nigam",
      "Navansh Goel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07853"
  },
  {
    "id": "arXiv:2204.07854",
    "title": "IIFNet: A Fusion based Intelligent Service for Noisy Preamble Detection  in 6G",
    "abstract": "In this article, we present our vision of preamble detection in a physical\nrandom access channel for next-generation (Next-G) networks using machine\nlearning techniques. Preamble detection is performed to maintain communication\nand synchronization between devices of the Internet of Everything (IoE) and\nnext-generation nodes. Considering the scalability and traffic density, Next-G\nnetworks have to deal with preambles corrupted by noise due to channel\ncharacteristics or environmental constraints. We show that when injecting 15%\nrandom noise, the detection performance degrades to 48%. We propose an\ninformative instance-based fusion network (IIFNet) to cope with random noise\nand to improve detection performance, simultaneously. A novel sampling strategy\nfor selecting informative instances from feature spaces has also been explored\nto improve detection performance. The proposed IIFNet is tested on a real\ndataset for preamble detection that was collected with the help of a reputable\ncompany (AZCOM Technology).",
    "descriptor": "\nComments: 8 pages, 3 figures, 2 tables, Accepted Article\n",
    "authors": [
      "Sunder Ali Khowaja",
      "Kapal Dev",
      "Parus Khuwaja",
      "Quoc-Viet Pham",
      "Nawab Muhammad Faseeh Qureshi",
      "Paolo Bellavista",
      "Maurizio Magarini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.07854"
  },
  {
    "id": "arXiv:2204.07855",
    "title": "Towards a Deeper Understanding of Skeleton-based Gait Recognition",
    "abstract": "Gait recognition is a promising biometric with unique properties for\nidentifying individuals from a long distance by their walking patterns. In\nrecent years, most gait recognition methods used the person's silhouette to\nextract the gait features. However, silhouette images can lose fine-grained\nspatial information, suffer from (self) occlusion, and be challenging to obtain\nin real-world scenarios. Furthermore, these silhouettes also contain other\nvisual clues that are not actual gait features and can be used for\nidentification, but also to fool the system. Model-based methods do not suffer\nfrom these problems and are able to represent the temporal motion of body\njoints, which are actual gait features. The advances in human pose estimation\nstarted a new era for model-based gait recognition with skeleton-based gait\nrecognition. In this work, we propose an approach based on Graph Convolutional\nNetworks (GCNs) that combines higher-order inputs, and residual networks to an\nefficient architecture for gait recognition. Extensive experiments on the two\npopular gait datasets, CASIA-B and OUMVLP-Pose, show a massive improvement (3x)\nof the state-of-the-art (SotA) on the largest gait dataset OUMVLP-Pose and\nstrong temporal modeling capabilities. Finally, we visualize our method to\nunderstand skeleton-based gait recognition better and to show that we model\nreal gait features.",
    "descriptor": "\nComments: 8 Pages, 5 figures, Accepted at 17th IEEE Computer Society Workshop on Biometrics 2022 (CVPRW'22)\n",
    "authors": [
      "Torben Teepe",
      "Johannes Gilg",
      "Fabian Herzog",
      "Stefan H\u00f6rmann",
      "Gerhard Rigoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07855"
  },
  {
    "id": "arXiv:2204.07863",
    "title": "ZeroIn: Characterizing the Data Distributions of Commits in Software  Repositories",
    "abstract": "Modern software development is based on a series of rapid incremental changes\ncollaboratively made to large source code repositories by developers with\nvarying experience and expertise levels. The ZeroIn project is aimed at\nanalyzing the metadata of these dynamic phenomena, including the data on\nrepositories, commits, and developers, to rapidly and accurately mark the\nquality of commits as they arrive at the repositories. In this context, the\npresent article presents a characterization of the software development\nmetadata in terms of distributions of data that best captures the trends in the\ndatasets. Multiple datasets are analyzed for this purpose, including Stack\nOverflow on developers' features and GitHub data on over 452 million\nrepositories with 16 million commits. This characterization is intended to make\nit possible to generate multiple synthetic datasets that can be used in\ntraining and testing novel machine learning-based solutions to improve the\nreliability of software even as it evolves. It is also aimed at serving the\ndevelopment process to exploit the latent correlations among many key feature\nvectors across the aggregate space of repositories and developers. The data\ncharacterization of this article is designed to feed into the machine learning\ncomponents of ZeroIn, including the application of binary classifiers for early\nflagging of buggy software commits and the development of graph-based learning\nmethods to exploit sparse connectivity among the sets of repositories, commits,\nand developers.",
    "descriptor": "\nComments: 42 pages, 68 figures, 7 tables\n",
    "authors": [
      "Kalyan Perumalla",
      "Aradhana Soni",
      "Rupam Dey",
      "Steven Rich"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.07863"
  },
  {
    "id": "arXiv:2204.07865",
    "title": "Enabling Relative Localization for Nanodrone Swarm Platooning",
    "abstract": "Nanodrone swarm is formulated by multiple light-weight and low-cost\nnanodrones to perform the tasks in very challenging environments. Therefore, it\nis essential to estimate the relative position of nanodrones in the swarm for\naccurate and safe platooning in inclement indoor environment. However, the\nvision and infrared sensors are constrained by the line-of-sight perception,\nand instrumenting extra motion sensors on drone's body is constrained by the\nnanodrone's form factor and energy-efficiency.\nThis paper presents the design, implementation and evaluation of RFDrone, a\nsystem that can sense the relative position of nanodrone in the swarm using\nwireless signals, which can naturally identify each individual nanodrone. To do\nso, each light-weight nanodrone is attached with a RF sticker (i.e., called\nRFID tag), which will be localized by the external RFID reader in the inclement\nindoor environment. Instead of accurately localizing each RFID-tagged\nnanodrone, we propose to estimate the relative position of all the RFID-tagged\nnanodrones in the swarm based on the spatial-temporal phase profiling. We\nimplement an end-to-end physical prototype of RFDrone. Our experimental results\nshow that RFDrone can accurately estimate the relative position of nanodrones\nin the swarm with average relative localization accuracy of around 0.95 across\nx, y and z axis, and average accuracy of around 0.93 for nanodrone swarm's\ngeometry estimation.",
    "descriptor": "",
    "authors": [
      "Wei Sun"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.07865"
  },
  {
    "id": "arXiv:2204.07868",
    "title": "Alternating Channel Estimation and Prediction for Cell-Free mMIMO with  Channel Aging: A Deep Learning Based Scheme",
    "abstract": "In large scale dynamic wireless networks, the amount of overhead caused by\nchannel estimation (CE) is becoming one of the main performance bottlenecks.\nThis is due to the large number users whose channels should be estimated, the\nuser mobility, and the rapid channel change caused by the usage of the\nhigh-frequency spectrum (e.g. millimeter wave). In this work, we propose a new\nhybrid channel estimation/prediction (CEP) scheme to reduce overhead in\ntime-division duplex (TDD) wireless cell-free massive\nmultiple-input-multiple-output (mMIMO) systems. The scheme proposes sending a\npilot signal from each user only once in a given number (window) of coherence\nintervals (CIs). Then minimum mean-square error (MMSE) estimation is used to\nestimate the channel of this CI, while a deep neural network (DNN) is used to\npredict the channels of the remaining CIs in the window. The DNN exploits the\ntemporal correlation between the consecutive CIs and the received pilot signals\nto improve the channel prediction accuracy. By doing so, CE overhead is reduced\nby at least 50 percent at the expense of negligible CE error for practical user\nmobility settings. Consequently, the proposed CEP scheme improves the spectral\nefficiency compared to the conventional MMSE CE approach, especially when the\nnumber of users is large, which is demonstrated numerically.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Mohanad Obeed",
      "Yasser Al-Eryani",
      "Anas Chaaban"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07868"
  },
  {
    "id": "arXiv:2204.07874",
    "title": "Ergo, SMIRK is Safe: A Safety Case for a Machine Learning Component in a  Pedestrian Automatic Emergency Brake System",
    "abstract": "Integration of Machine Learning (ML) components in critical applications\nintroduces novel challenges for software certification and verification. New\nsafety standards and technical guidelines are under development to support the\nsafety of ML-based systems, e.g., ISO 21448 SOTIF for the automotive domain and\nthe Assurance of Machine Learning for use in Autonomous Systems (AMLAS)\nframework. SOTIF and AMLAS provide high-level guidance but the details must be\nchiseled out for each specific case. We report results from an\nindustry-academia collaboration on safety assurance of SMIRK, an ML-based\npedestrian automatic emergency braking demonstrator running in an\nindustry-grade simulator. We present the outcome of applying AMLAS on SMIRK for\na minimalistic operational design domain, i.e., a complete safety case for its\nintegrated ML-based component. Finally, we report lessons learned and provide\nboth SMIRK and the safety case under an open-source licence for the research\ncommunity to reuse.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Markus Borg",
      "Jens Henriksson",
      "Kasper Socha",
      "Olof Lennartsson",
      "Elias Sonnsj\u00f6 L\u00f6negren",
      "Thanh Bui",
      "Piotr Tomaszewski",
      "Sankar Raman Sathyamoorthy",
      "Sebastian Brink",
      "Mahshid Helali Moghadam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07874"
  },
  {
    "id": "arXiv:2204.07875",
    "title": "Station Reallocation and Rebalancing Strategy for Bike-Sharing Systems:  A Case Study of Washington DC",
    "abstract": "Bike-sharing is becoming increasingly popular as an urban traffic mode while\nincreasing the affordability, flexibility, and reliability of interconnected\npublic transportation systems (i.e., interconnected light rail, buses,\nmicro-mobility, and ride-sharing modes of transportation). From the consumers\nperspective, 1) finding a bike station in convenient locations where demand\nusually occurs and 2) the availability of bikes at rush hours with a lesser\nprobability of encountering empty docks (for fixed-station bike-share systems)\nare two key concerns. Some stations are more likely to be empty or full,\nreflecting an imbalance in bike supply and demand. Accordingly, it is essential\nto understand a bike-share system's demand pattern to select the optimal\nlocations and reallocate bikes to the right stations to increase the\nutilization rate and reduce the number of unserved customers (i.e., potential\ndemand). The Capital Bikeshare in the Washington DC Metropolitan Area is one of\nthe prominent bike-share systems in the USA - with more than 4,300 bikes\navailable at 654 stations across seven jurisdictions. This study provides a\nsystematic analysis of a bike-sharing system's Capital Bikeshare system usage\npattern. Our study intends to create an optimization strategy formulated as a\ndeterministic integer programming for reallocating bike stations daily and\nrebalancing the bike supply system. From an operational perspective, such a\nstrategy will allow overnight preparations to answer the rush-hour morning\ndemand and during special events in Washington D.C.",
    "descriptor": "",
    "authors": [
      "Pedram Beigi",
      "Michel Khoueiry",
      "Mohammad Sadra Rajabi",
      "Samer Hamdar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07875"
  },
  {
    "id": "arXiv:2204.07876",
    "title": "Lodestar: Supporting Independent Learning and Rapid Experimentation  Through Data-Driven Analysis Recommendations",
    "abstract": "Keeping abreast of current trends, technologies, and best practices in\nvisualization and data analysis is becoming increasingly difficult, especially\nfor fledgling data scientists. In this paper, we propose Lodestar, an\ninteractive computational notebook that allows users to quickly explore and\nconstruct new data science workflows by selecting from a list of automated\nanalysis recommendations. We derive our recommendations from directed graphs of\nknown analysis states, with two input sources: one manually curated from online\ndata science tutorials, and another extracted through semi-automatic analysis\nof a corpus of over 6,000 Jupyter notebooks. We evaluate Lodestar in a\nformative study guiding our next set of improvements to the tool. Our results\nsuggest that users find Lodestar useful for rapidly creating data science\nworkflows.",
    "descriptor": "\nComments: This paper was presented as part of the workshop called Visualization in Data Science (at ACM KDD and IEEE VIS)\n",
    "authors": [
      "Deepthi Raghunandan",
      "Zhe Cui",
      "Kartik Krishnan",
      "Segen Tirfe",
      "Shenzhi Shi",
      "Tejaswi Darshan Shrestha",
      "Leilani Battle",
      "Niklas Elmqvist"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07876"
  },
  {
    "id": "arXiv:2204.07877",
    "title": "Assessing Differentially Private Variational Autoencoders under  Membership Inference",
    "abstract": "We present an approach to quantify and compare the privacy-accuracy trade-off\nfor differentially private Variational Autoencoders. Our work complements\nprevious work in two aspects. First, we evaluate the the strong reconstruction\nMI attack against Variational Autoencoders under differential privacy. Second,\nwe address the data scientist's challenge of setting privacy parameter epsilon,\nwhich steers the differential privacy strength and thus also the\nprivacy-accuracy trade-off. In our experimental study we consider image and\ntime series data, and three local and central differential privacy mechanisms.\nWe find that the privacy-accuracy trade-offs strongly depend on the dataset and\nmodel architecture. We do rarely observe favorable privacy-accuracy trade-off\nfor Variational Autoencoders, and identify a case where LDP outperforms CDP.",
    "descriptor": "",
    "authors": [
      "Daniel Bernau",
      "Jonas Robl",
      "Florian Kerschbaum"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07877"
  },
  {
    "id": "arXiv:2204.07878",
    "title": "3D Human Pose Estimation for Free-from and Moving Activities Using WiFi",
    "abstract": "This paper presents GoPose, a 3D skeleton-based human pose estimation system\nthat uses WiFi devices at home. Our system leverages the WiFi signals reflected\noff the human body for 3D pose estimation. In contrast to prior systems that\nneed specialized hardware or dedicated sensors, our system does not require a\nuser to wear or carry any sensors and can reuse the WiFi devices that already\nexist in a home environment for mass adoption. To realize such a system, we\nleverage the 2D AoA spectrum of the signals reflected from the human body and\nthe deep learning techniques. In particular, the 2D AoA spectrum is proposed to\nlocate different parts of the human body as well as to enable\nenvironment-independent pose estimation. Deep learning is incorporated to model\nthe complex relationship between the 2D AoA spectrums and the 3D skeletons of\nthe human body for pose tracking. Our evaluation results show GoPose achieves\naround 4.7cm of accuracy under various scenarios including tracking unseen\nactivities and under NLoS scenarios.",
    "descriptor": "",
    "authors": [
      "Yili Ren",
      "Jie Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.07878"
  },
  {
    "id": "arXiv:2204.07879",
    "title": "Polynomial-time sparse measure recovery",
    "abstract": "How to recover a probability measure with sparse support from particular\nmoments? This problem has been the focus of research in theoretical computer\nscience and neural computing. However, there is no polynomial-time algorithm\nfor the recovery. The best algorithm for the recovery requires\n$O(2^{\\text{poly}(1/\\epsilon)})$ for $\\epsilon$-accurate recovery. We propose\nthe first poly-time recovery method from carefully designed moments that only\nrequires $O(\\log(1/\\epsilon)/\\epsilon^2)$ computations for an\n$\\epsilon$-accurate recovery. This method relies on the recovery of a planted\ntwo-layer neural network with two-dimensional inputs, a finite width, and\nzero-one activation. For such networks, we establish the first global\nconvergence of gradient descent and demonstrate its application in sparse\nmeasure recovery.",
    "descriptor": "",
    "authors": [
      "Hadi Daneshmand",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07879"
  },
  {
    "id": "arXiv:2204.07883",
    "title": "An Overview of Query Processing on Crowdsourced Databases",
    "abstract": "Crowd-sourcing is a powerful solution for finding correct answers to\nexpensive and unanswered queries in databases, including those with uncertain\nand incomplete data. Attempts to use crowd-sourcing to exploit human abilities\nto process these expensive queries using human workers have helped to provide\naccurate results by utilising the available data in the crowd. Crowd-sourcing\ndatabase systems (CSDBs) combine the knowledge of the crowd with a relational\ndatabase by using some variant of a relational database with minor changes.\nThis paper surveys the leading studies conducted in the area of query\nprocessing with regard to both traditional and preference queries in CSDBs. The\nfocus of this work is on highlighting the strengths and the weakness of each\napproach. A detailed discussion of current and future trends research\nassociated with query processing in the area of CSDBs is also presented.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Marwa B. Swidan",
      "Ali A. Alwan",
      "Yonis Gulzar",
      "Abedallah Zaid Abualkishik"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2204.07883"
  },
  {
    "id": "arXiv:2204.07886",
    "title": "Gender-Wise Perception of Students Towards Blended Learning in Higher  Education: Pakistan",
    "abstract": "Blended learning (BL) is a recent tread among many options that can best fit\nlearners' needs, regardless of time and place. This study aimed to discover\nstudents' perceptions of BL and the challenges faced by them while using\ntechnology. This quantitative study used data gathered from 300 students\nenrolled in four public universities in the Sindh province of Pakistan. the\nfinding shows that students were compatible with the use of technology, and it\nhas a positive effect on their academic experience. The study also showed that\nthe use of technology encourages peer collaboration. The challenges found\ninclude: neither teacher support nor a training program was provided to the\nstudents for the course which needed to shift from a traditional face to face\nparadigm to a blended format, a lake of space lies with skills in a laboratory\nassistants for the courses with a blended format and as shortage of high tech\ncomputer laboratories / computer units to run these courses. Therefore, it is\nrecommended that the authorities must develop and incorporate a comprehensive\nmechanism for the effective implementation of BL in the learning\nteaching-learning process heads of the departments should also provide\nadditional computing infrastructure to their departments.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Saira Soomro",
      "Arjumand Bano Soomro",
      "Tarique Bhatti",
      "Yonis Gulzar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.07886"
  },
  {
    "id": "arXiv:2204.07887",
    "title": "Mapping LiDAR and Camera Measurements in a Dual Top-View Grid  Representation Tailored for Automated Vehicles",
    "abstract": "We present a generic evidential grid mapping pipeline designed for imaging\nsensors such as LiDARs and cameras. Our grid-based evidential model contains\nsemantic estimates for cell occupancy and ground separately. We specify the\nestimation steps for input data represented by point sets, but mainly focus on\ninput data represented by images such as disparity maps or LiDAR range images.\nInstead of relying on an external ground segmentation only, we deduce occupancy\nevidence by analyzing the surface orientation around measurements. We conduct\nexperiments and evaluate the presented method using LiDAR and stereo camera\ndata recorded in real traffic scenarios. Our method estimates cell occupancy\nrobustly and with a high level of detail while maximizing efficiency and\nminimizing the dependency to external processing modules.",
    "descriptor": "",
    "authors": [
      "Sven Richter",
      "Frank Bieder",
      "Sascha Wirges",
      "Christoph Stiller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07887"
  },
  {
    "id": "arXiv:2204.07889",
    "title": "SymForce: Symbolic Computation and Code Generation for Robotics",
    "abstract": "We present SymForce, a fast symbolic computation and code generation library\nfor robotics applications like computer vision, state estimation, motion\nplanning, and controls. SymForce combines the development speed and flexibility\nof symbolic mathematics with the performance of autogenerated, highly optimized\ncode in C++ or any target runtime language. SymForce provides geometry and\ncamera types, Lie group operations, and branchless singularity handling for\ncreating and analyzing complex symbolic expressions in Python, built on top of\nSymPy. Generated functions can be integrated as factors into our tangent space\nnonlinear optimizer, which is highly optimized for real-time production use. We\nintroduce novel methods to automatically compute tangent space Jacobians,\neliminating the need for bug-prone handwritten derivatives. This workflow\nenables faster runtime code, faster development time, and fewer lines of\nhandwritten code versus the state-of-the-art. Our experiments demonstrate that\nour approach can yield order of magnitude speedups on computational tasks core\nto robotics. Code is available at https://github.com/symforce-org/symforce .",
    "descriptor": "\nComments: 10 pages, 5 figures. RSS 2022\n",
    "authors": [
      "Hayk Martiros",
      "Aaron Miller",
      "Nathan Bucki",
      "Bradley Solliday",
      "Ryan Kennedy",
      "Jack Zhu",
      "Tung Dang",
      "Dominic Pattison",
      "Harrison Zheng",
      "Teo Tomic",
      "Peter Henry",
      "Gareth Cross",
      "Josiah VanderMey",
      "Alvin Sun",
      "Samuel Wang",
      "Kristen Holtz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2204.07889"
  },
  {
    "id": "arXiv:2204.07892",
    "title": "Video Action Detection: Analysing Limitations and Challenges",
    "abstract": "Beyond possessing large enough size to feed data hungry machines (eg,\ntransformers), what attributes measure the quality of a dataset? Assuming that\nthe definitions of such attributes do exist, how do we quantify among their\nrelative existences? Our work attempts to explore these questions for video\naction detection. The task aims to spatio-temporally localize an actor and\nassign a relevant action class. We first analyze the existing datasets on video\naction detection and discuss their limitations. Next, we propose a new dataset,\nMulti Actor Multi Action (MAMA) which overcomes these limitations and is more\nsuitable for real world applications. In addition, we perform a biasness study\nwhich analyzes a key property differentiating videos from static images: the\ntemporal aspect. This reveals if the actions in these datasets really need the\nmotion information of an actor, or whether they predict the occurrence of an\naction even by looking at a single frame. Finally, we investigate the widely\nheld assumptions on the importance of temporal ordering: is temporal ordering\nimportant for detecting these actions? Such extreme experiments show existence\nof biases which have managed to creep into existing methods inspite of careful\nmodeling.",
    "descriptor": "\nComments: CVPRW'22\n",
    "authors": [
      "Rajat Modi",
      "Aayush Jung Rana",
      "Akash Kumar",
      "Praveen Tirupattur",
      "Shruti Vyas",
      "Yogesh Singh Rawat",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07892"
  },
  {
    "id": "arXiv:2204.07893",
    "title": "On Reporting Performance and Accuracy Bugs for Deep Learning Frameworks:  An Exploratory Study from GitHub",
    "abstract": "The tremendous success of Deep Learning (DL) has significantly boosted the\nnumber of open-sourced DL frameworks hosted on GitHub. Among others,\nperformance and accuracy bugs are critical factors that affect the reputation\nof these DL frameworks, therefore understanding the practice of discovering and\ninvestigating them for DL is important. In this paper, we conduct an\nexploratory study on the nature of reporting performance and accuracy bugs bugs\nfor DL frameworks, aiming to improve our knowledge on this topic. Our study\ncovers 10 most popular open-sourced DL frameworks on GitHub (e.g., TensorFlow,\nKeras, and PyTorch), based on which we sample 664 representative performance\nand accuracy bugs bug reports out of a total population of 22,522. Through\nsystematic analysis of these samples, our key findings are: (1) low speed is\nthe primary reason that a performance bug related report is submitted but we\nsee no consistent pattern for accuracy related ones; (2) most of the reports\nare about issues encountered in the training stage; (3) only a small proportion\nof the reports provide insufficient information to investigate; (4) the\nmajority of the performance and accuracy bugs bug reports (from 69% to 100%)\nare not related to the actual bug or regarded as unclassified; (5) around 50%\nof the performance and accuracy bug reports, which indeed reveal bugs, are not\nresolved by direct patches. Deriving from the above, we discuss a set of\nactionable implications to the researchers, maintainers, and report submitters\non this subject. To promote open science, the labeled dataset has been made\npublicly available at https://tinyurl.com/4x3tap9w.",
    "descriptor": "\nComments: Accepted at EASE 2022\n",
    "authors": [
      "Guoming Long",
      "Tao Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.07893"
  },
  {
    "id": "arXiv:2204.07895",
    "title": "New conforming finite element divdiv complexes in three dimensions",
    "abstract": "In this paper, the first family of conforming finite element divdiv complexes\non cuboid grids in three dimensions is constructed. Besides, a new family of\nconforming finite element divdiv complexes with enhanced smoothness on\ntetrahedral grids is presented. These complexes are exact in the sense that the\nrange of each discrete map is the kernel space of the succeeding one.",
    "descriptor": "",
    "authors": [
      "Jun Hu",
      "Yizhou Liang",
      "Rui Ma",
      "Min Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07895"
  },
  {
    "id": "arXiv:2204.07897",
    "title": "Making Hidden Bias Visible: Designing a Feedback Ecosystem for Primary  Care Providers",
    "abstract": "Implicit bias may perpetuate healthcare disparities for marginalized patient\npopulations. Such bias is expressed in communication between patients and their\nproviders. We design an ecosystem with guidance from providers to make this\nbias explicit in patient-provider communication. Our end users are providers\nseeking to improve their quality of care for patients who are Black,\nIndigenous, People of Color (BIPOC) and/or Lesbian, Gay, Bisexual, Transgender,\nand Queer (LGBTQ). We present wireframes displaying communication metrics that\nnegatively impact patient-centered care divided into the following categories:\ndigital nudge, dashboard, and guided reflection. Our wireframes provide\nquantitative, real-time, and conversational feedback promoting provider\nreflection on their interactions with patients. This is the first design\niteration toward the development of a tool to raise providers' awareness of\ntheir own implicit biases.",
    "descriptor": "\nComments: 6 pages, 2 figures, 2 tables, CHI 2022 Workshop Publication (Complex Health Ecosystems)\n",
    "authors": [
      "Naba Rizvi",
      "Harshini Ramaswamy",
      "Reggie Casanova-Perez",
      "Andrea Hartzler",
      "Nadir Weibel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.07897"
  },
  {
    "id": "arXiv:2204.07899",
    "title": "QTBIPOC PD: Exploring the Intersections of Race, Gender, and Sexual  Orientation in Participatory Design",
    "abstract": "As Human-Computer Interaction (HCI) research aims to be inclusive and\nrepresentative of many marginalized identities, there is still a lack of\navailable literature and research on intersectional considerations of race,\ngender, and sexual orientation, especially when it comes to participatory\ndesign. We aim to create a space to generate community recommendations for\neffectively and appropriately engaging Queer, Transgender, Black, Indigenous,\nPeople of Color (QTBIPOC) populations in participatory design, and discuss\nmethods of dissemination for recommendations. Workshop participants will engage\nwith critical race theory, queer theory, and feminist theory to reflect on\ncurrent exclusionary HCI and participatory design methods and practices.",
    "descriptor": "\nComments: 6 pages, 2 tables, CHI 2022 Workshop\n",
    "authors": [
      "Naba Rizvi",
      "Reggie Casanova-Perez",
      "Harshini Ramaswamy",
      "Emily Bascom",
      "Lisa Dirks",
      "Nadir Weibel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.07899"
  },
  {
    "id": "arXiv:2204.07900",
    "title": "Using HCI to Tackle Race and Gender Bias in ADHD Diagnosis",
    "abstract": "Attention Deficit Hyperactivity Disorder (ADHD) is a behavioral disorder that\nimpacts an individual's education, relationships, career, and ability to\nacquire fair and just police interrogations. Yet, traditional methods used to\ndiagnose ADHD in children and adults are known to have racial and gender bias.\nIn recent years, diagnostic technology has been studied by both HCI and ML\nresearchers. However, these studies fail to take into consideration racial and\ngender stereotypes that may impact the accuracy of their results. We highlight\nthe importance of taking race and gender into consideration when creating\ndiagnostic technology for ADHD and provide HCI researchers with suggestions for\nfuture studies.",
    "descriptor": "\nComments: 6 pages, CHI 2020 workshop submission\n",
    "authors": [
      "Naba Rizvi",
      "Khalil Mrini"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.07900"
  },
  {
    "id": "arXiv:2204.07905",
    "title": "Probabilistic Charging Power Forecast of EVCS: Reinforcement Learning  Assisted Deep Learning Approach",
    "abstract": "The electric vehicle (EV) and electric vehicle charging station (EVCS) have\nbeen widely deployed with the development of large-scale transportation\nelectrifications. However, since charging behaviors of EVs show large\nuncertainties, the forecasting of EVCS charging power is non-trivial. This\npaper tackles this issue by proposing a reinforcement learning assisted deep\nlearning framework for the probabilistic EVCS charging power forecasting to\ncapture its uncertainties. Since the EVCS charging power data are not standard\ntime-series data like electricity load, they are first converted to the\ntime-series format. On this basis, one of the most popular deep learning\nmodels, the long short-term memory (LSTM) is used and trained to obtain the\npoint forecast of EVCS charging power. To further capture the forecast\nuncertainty, a Markov decision process (MDP) is employed to model the change of\nLSTM cell states, which is solved by our proposed adaptive exploration proximal\npolicy optimization (AePPO) algorithm based on reinforcement learning. Finally,\nexperiments are carried out on the real EVCSs charging data from Caltech, and\nJet Propulsion Laboratory, USA, respectively. The results and comparative\nanalysis verify the effectiveness and outperformance of our proposed framework.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Intelligent Vehicles\n",
    "authors": [
      "Yuanzheng Li",
      "Shangyang He",
      "Yang Li",
      "Leijiao Ge",
      "Suhua Lou",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07905"
  },
  {
    "id": "arXiv:2204.07908",
    "title": "MST++: Multi-stage Spectral-wise Transformer for Efficient Spectral  Reconstruction",
    "abstract": "Existing leading methods for spectral reconstruction (SR) focus on designing\ndeeper or wider convolutional neural networks (CNNs) to learn the end-to-end\nmapping from the RGB image to its hyperspectral image (HSI). These CNN-based\nmethods achieve impressive restoration performance while showing limitations in\ncapturing the long-range dependencies and self-similarity prior. To cope with\nthis problem, we propose a novel Transformer-based method, Multi-stage\nSpectral-wise Transformer (MST++), for efficient spectral reconstruction. In\nparticular, we employ Spectral-wise Multi-head Self-attention (S-MSA) that is\nbased on the HSI spatially sparse while spectrally self-similar nature to\ncompose the basic unit, Spectral-wise Attention Block (SAB). Then SABs build up\nSingle-stage Spectral-wise Transformer (SST) that exploits a U-shaped structure\nto extract multi-resolution contextual information. Finally, our MST++,\ncascaded by several SSTs, progressively improves the reconstruction quality\nfrom coarse to fine. Comprehensive experiments show that our MST++\nsignificantly outperforms other state-of-the-art methods. In the NTIRE 2022\nSpectral Reconstruction Challenge, our approach won the First place. Code and\npre-trained models are publicly available at\nhttps://github.com/caiyuanhao1998/MST-plus-plus.",
    "descriptor": "\nComments: Winner of NTIRE 2022 Challenge on Spectral Reconstruction from RGB; The First Transformer-based Method for Spectral Reconstruction\n",
    "authors": [
      "Yuanhao Cai",
      "Jing Lin",
      "Zudi Lin",
      "Haoqian Wang",
      "Yulun Zhang",
      "Hanspeter Pfister",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07908"
  },
  {
    "id": "arXiv:2204.07909",
    "title": "Quantifiable Assurance: From IPs to Platforms",
    "abstract": "Hardware vulnerabilities are generally considered more difficult to fix than\nsoftware ones because they are persistent after fabrication. Thus, it is\ncrucial to assess the security and fix the vulnerabilities at earlier design\nphases, such as Register Transfer Level (RTL) and gate level. The focus of the\nexisting security assessment techniques is mainly twofold. First, they check\nthe security of Intellectual Property (IP) blocks separately. Second, they aim\nto assess the security against individual threats considering the threats are\northogonal. We argue that IP-level security assessment is not sufficient.\nEventually, the IPs are placed in a platform, such as a system-on-chip (SoC),\nwhere each IP is surrounded by other IPs connected through glue logic and\nshared/private buses. Hence, we must develop a methodology to assess the\nplatform-level security by considering both the IP-level security and the\nimpact of the additional parameters introduced during platform integration.\nAnother important factor to consider is that the threats are not always\northogonal. Improving security against one threat may affect the security\nagainst other threats. Hence, to build a secure platform, we must first answer\nthe following questions: What additional parameters are introduced during the\nplatform integration? How do we define and characterize the impact of these\nparameters on security? How do the mitigation techniques of one threat impact\nothers? This paper aims to answer these important questions and proposes\ntechniques for quantifiable assurance by quantitatively estimating and\nmeasuring the security of a platform at the pre-silicon stages. We also touch\nupon the term security optimization and present the challenges for future\nresearch directions.",
    "descriptor": "",
    "authors": [
      "Bulbul Ahmed",
      "Md Kawser Bepary",
      "Nitin Pundir",
      "Mike Borza",
      "Oleg Raikhman",
      "Amit Garg",
      "Dale Donchin",
      "Adam Cron",
      "Mohamed A Abdel-moneum",
      "Farimah Farahmandi",
      "Fahim Rahman",
      "Mark Tehranipoor"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.07909"
  },
  {
    "id": "arXiv:2204.07913",
    "title": "What Goes beyond Multi-modal Fusion in One-stage Referring Expression  Comprehension: An Empirical Study",
    "abstract": "Most of the existing work in one-stage referring expression comprehension\n(REC) mainly focuses on multi-modal fusion and reasoning, while the influence\nof other factors in this task lacks in-depth exploration. To fill this gap, we\nconduct an empirical study in this paper. Concretely, we first build a very\nsimple REC network called SimREC, and ablate 42 candidate designs/settings,\nwhich covers the entire process of one-stage REC from network design to model\ntraining. Afterwards, we conduct over 100 experimental trials on three\nbenchmark datasets of REC. The extensive experimental results not only show the\nkey factors that affect REC performance in addition to multi-modal fusion,\ne.g., multi-scale features and data augmentation, but also yield some findings\nthat run counter to conventional understanding. For example, as a vision and\nlanguage (V&L) task, REC does is less impacted by language prior. In addition,\nwith a proper combination of these findings, we can improve the performance of\nSimREC by a large margin, e.g., +27.12% on RefCOCO+, which outperforms all\nexisting REC methods. But the most encouraging finding is that with much less\ntraining overhead and parameters, SimREC can still achieve better performance\nthan a set of large-scale pre-trained models, e.g., UNITER and VILLA,\nportraying the special role of REC in existing V&L research.",
    "descriptor": "",
    "authors": [
      "Gen Luo",
      "Yiyi Zhou",
      "Jiamu Sun",
      "Shubin Huang",
      "Xiaoshuai Sun",
      "Qixiang Ye",
      "Yongjian Wu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07913"
  },
  {
    "id": "arXiv:2204.07916",
    "title": "An $n H_k$-compressed searchable partial-sums data structure for static  sequences of sublogarithmic positive integers",
    "abstract": "We consider the space needed to store a searchable partial-sums data\nstructure with constant query time for a static sequence $S$ of $n$ positive\nintegers in $o \\left( \\frac{\\log n}{(\\log \\log n)^2} \\right)$. Arroyuelo and\nRaman (2022) recently showed that such a structure can fit in $n H_0 (S) + o\n(n)$ bits. Starting with Ferragina and Venturini's (2007) $n H_k$-compressed\nrepresentation of strings that supports fast random access, and augmenting it\nwith sublinear data structures reminiscent of those Raman, Raman and Rao (2002)\nused in their succinct bitvectors, we slightly improve Arroyuelo and Raman's\nbound to $n H_k (S) + o (n)$ bits for $k \\in o \\left( \\frac{\\log n}{(\\log \\log\nn)^2} \\right)$.",
    "descriptor": "",
    "authors": [
      "Travis Gagie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.07916"
  },
  {
    "id": "arXiv:2204.07918",
    "title": "Convergence analysis of a two-grid method for nonsymmetric positive  definite problems",
    "abstract": "Multigrid is a powerful solver for large-scale linear systems arising from\ndiscretized partial differential equations. The convergence theory of multigrid\nmethods for symmetric positive definite problems has been well developed over\nthe past decades, while, for nonsymmetric problems, such theory is still not\nmature. As a foundation for multigrid analysis, two-grid convergence theory\nplays an important role in motivating multigrid algorithms. Regarding two-grid\nmethods for nonsymmetric problems, most previous works focus on the spectral\nradius of iteration matrix or rely on convergence measures that are typically\ndifficult to compute in practice. Moreover, the existing results are confined\nto two-grid methods with exact solution of the coarse-grid system. In this\npaper, we analyze the convergence of a two-grid method for nonsymmetric\npositive definite problems (e.g., linear systems arising from the\ndiscretizations of convection-diffusion equations). In the case of exact coarse\nsolver, we establish an elegant identity for characterizing two-grid\nconvergence factor, which is measured by a smoother-induced norm. The identity\ncan be conveniently used to derive a class of optimal restriction operators and\nanalyze how the convergence factor is influenced by restriction. More\ngenerally, we present some convergence estimates for an inexact variant of the\ntwo-grid method, in which both linear and nonlinear coarse solvers are\nconsidered.",
    "descriptor": "",
    "authors": [
      "Xuefeng Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07918"
  },
  {
    "id": "arXiv:2204.07919",
    "title": "Cognitive Architecture for Decision-Making Based on Brain Principles  Programming",
    "abstract": "We describe a cognitive architecture intended to solve a wide range of\nproblems based on the five identified principles of brain activity, with their\nimplementation in three subsystems: logical-probabilistic inference,\nprobabilistic formal concepts, and functional systems theory. Building an\narchitecture involves the implementation of a task-driven approach that allows\ndefining the target functions of applied applications as tasks formulated in\nterms of the operating environment corresponding to the task, expressed in the\napplied ontology. We provide a basic ontology for a number of practical\napplications as well as for the subject domain ontologies based upon it,\ndescribe the proposed architecture, and give possible examples of the execution\nof these applications in this architecture.",
    "descriptor": "\nComments: 13 pages, 5 figures, submitted for presentation at 2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence\n",
    "authors": [
      "Anton Kolonin",
      "Andrey Kurpatov",
      "Artem Molchanov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.07919"
  },
  {
    "id": "arXiv:2204.07921",
    "title": "Fast Multi-grid Methods for Minimizing Curvature Energy",
    "abstract": "The geometric high-order regularization methods such as mean curvature and\nGaussian curvature, have been intensively studied during the last decades due\nto their abilities in preserving geometric properties including image edges,\ncorners, and image contrast. However, the dilemma between restoration quality\nand computational efficiency is an essential roadblock for high-order methods.\nIn this paper, we propose fast multi-grid algorithms for minimizing both mean\ncurvature and Gaussian curvature energy functionals without sacrificing the\naccuracy for efficiency. Unlike the existing approaches based on operator\nsplitting and the Augmented Lagrangian method (ALM), no artificial parameters\nare introduced in our formulation, which guarantees the robustness of the\nproposed algorithm. Meanwhile, we adopt the domain decomposition method to\npromote parallel computing and use the fine-to-coarse structure to accelerate\nthe convergence. Numerical experiments are presented on both image denoising\nand CT reconstruction problem to demonstrate the ability to recover image\ntexture and the efficiency of the proposed method.",
    "descriptor": "",
    "authors": [
      "Zhenwei Zhang",
      "Ke Chen",
      "Yuping Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07921"
  },
  {
    "id": "arXiv:2204.07922",
    "title": "A Survey on Efficient Processing of Similarity Queries over Neural  Embeddings",
    "abstract": "Similarity query is the family of queries based on some similarity metrics.\nUnlike the traditional database queries which are mostly based on value\nequality, similarity queries aim to find targets \"similar enough to\" the given\ndata objects, depending on some similarity metric, e.g., Euclidean distance,\ncosine similarity and so on. To measure the similarity between data objects,\ntraditional methods normally work on low level or syntax features(e.g., basic\nvisual features on images or bag-of-word features of text), which makes them\nweak to compute the semantic similarities between objects. So for measuring\ndata similarities semantically, neural embedding is applied. Embedding\ntechniques work by representing the raw data objects as vectors (so called\n\"embeddings\" or \"neural embeddings\" since they are mostly generated by neural\nnetwork models) that expose the hidden semantics of the raw data, based on\nwhich embeddings do show outstanding effectiveness on capturing data\nsimilarities, making it one of the most widely used and studied techniques in\nthe state-of-the-art similarity query processing research. But there are still\nmany open challenges on the efficiency of embedding based similarity query\nprocessing, which are not so well-studied as the effectiveness. In this survey,\nwe first provide an overview of the \"similarity query\" and \"similarity query\nprocessing\" problems. Then we talk about recent approaches on designing the\nindexes and operators for highly efficient similarity query processing on top\nof embeddings (or more generally, high dimensional data). Finally, we\ninvestigate the specific solutions with and without using embeddings in\nselected application domains of similarity queries, including entity resolution\nand information retrieval. By comparing the solutions, we show how neural\nembeddings benefit those applications.",
    "descriptor": "",
    "authors": [
      "Yifan Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.07922"
  },
  {
    "id": "arXiv:2204.07924",
    "title": "StyleT2F: Generating Human Faces from Textual Description Using  StyleGAN2",
    "abstract": "AI-driven image generation has improved significantly in recent years.\nGenerative adversarial networks (GANs), like StyleGAN, are able to generate\nhigh-quality realistic data and have artistic control over the output, as well.\nIn this work, we present StyleT2F, a method of controlling the output of\nStyleGAN2 using text, in order to be able to generate a detailed human face\nfrom textual description. We utilize StyleGAN's latent space to manipulate\ndifferent facial features and conditionally sample the required latent code,\nwhich embeds the facial features mentioned in the input text. Our method proves\nto capture the required features correctly and shows consistency between the\ninput text and the output images. Moreover, our method guarantees\ndisentanglement on manipulating a wide range of facial features that\nsufficiently describes a human face.",
    "descriptor": "",
    "authors": [
      "Mohamed Shawky Sabae",
      "Mohamed Ahmed Dardir",
      "Remonda Talaat Eskarous",
      "Mohamed Ramzy Ebbed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07924"
  },
  {
    "id": "arXiv:2204.07927",
    "title": "In Defense of Subspace Tracker: Orthogonal Embedding for Visual Tracking",
    "abstract": "The paper focuses on a classical tracking model, subspace learning, grounded\non the fact that the targets in successive frames are considered to reside in a\nlow-dimensional subspace or manifold due to the similarity in their\nappearances. In recent years, a number of subspace trackers have been proposed\nand obtained impressive results. Inspired by the most recent results that the\ntracking performance is boosted by the subspace with discrimination capability\nlearned over the recently localized targets and their immediately surrounding\nbackground, this work aims at solving such a problem: how to learn a robust\nlow-dimensional subspace to accurately and discriminatively represent these\ntarget and background samples. To this end, a discriminative approach, which\nreliably separates the target from its surrounding background, is injected into\nthe subspace learning by means of joint learning, achieving a\ndimension-adaptive subspace with superior discrimination capability. The\nproposed approach is extensively evaluated and compared with the\nstate-of-the-art trackers on four popular tracking benchmarks. The experimental\nresults demonstrate that the proposed tracker performs competitively against\nits counterparts. In particular, it achieves more than 9% performance increase\ncompared with the state-of-the-art subspace trackers.",
    "descriptor": "",
    "authors": [
      "Yao Sui",
      "Guanghui Wang",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07927"
  },
  {
    "id": "arXiv:2204.07930",
    "title": "A Modified Nonlinear Conjugate Gradient Algorithm for Functions with  Non-Lipschitz Gradient",
    "abstract": "In this paper, we propose a modified nonlinear conjugate gradient (NCG)\nmethod for functions with a non-Lipschitz continuous gradient. First, we\npresent a new formula for the conjugate coefficient \\beta_k in NCG, conducting\na search direction that provides an adequate function decrease. We can derive\nthat our NCG algorithm guarantees strongly convergent for continuous\ndifferential functions without Lipschitz continuous gradient. Second, we\npresent a simple interpolation approach that could automatically achieve\nshrinkage, generating a step length satisfying the standard Wolfe conditions in\neach step. Our framework considerably broadens the applicability of NCG and\npreserves the superior numerical performance of the PRP-type methods.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.08048\n",
    "authors": [
      "Bingjie Li",
      "Tianhao Ni",
      "Zhenyue Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07930"
  },
  {
    "id": "arXiv:2204.07931",
    "title": "On the Origin of Hallucinations in Conversational Models: Is it the  Datasets or the Models?",
    "abstract": "Knowledge-grounded conversational models are known to suffer from producing\nfactually invalid statements, a phenomenon commonly called hallucination. In\nthis work, we investigate the underlying causes of this phenomenon: is\nhallucination due to the training data, or to the models? We conduct a\ncomprehensive human study on both existing knowledge-grounded conversational\nbenchmarks and several state-of-the-art models. Our study reveals that the\nstandard benchmarks consist of >60% hallucinated responses, leading to models\nthat not only hallucinate but even amplify hallucinations. Our findings raise\nimportant questions on the quality of existing datasets and models trained\nusing them. We make our annotations publicly available for future research.",
    "descriptor": "\nComments: NAACL 2022, 14 pages\n",
    "authors": [
      "Nouha Dziri",
      "Sivan Milton",
      "Mo Yu",
      "Osmar Zaiane",
      "Siva Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07931"
  },
  {
    "id": "arXiv:2204.07932",
    "title": "Towards Comprehensive Testing on the Robustness of Cooperative  Multi-agent Reinforcement Learning",
    "abstract": "While deep neural networks (DNNs) have strengthened the performance of\ncooperative multi-agent reinforcement learning (c-MARL), the agent policy can\nbe easily perturbed by adversarial examples. Considering the safety critical\napplications of c-MARL, such as traffic management, power management and\nunmanned aerial vehicle control, it is crucial to test the robustness of c-MARL\nalgorithm before it was deployed in reality. Existing adversarial attacks for\nMARL could be used for testing, but is limited to one robustness aspects (e.g.,\nreward, state, action), while c-MARL model could be attacked from any aspect.\nTo overcome the challenge, we propose MARLSafe, the first robustness testing\nframework for c-MARL algorithms. First, motivated by Markov Decision Process\n(MDP), MARLSafe consider the robustness of c-MARL algorithms comprehensively\nfrom three aspects, namely state robustness, action robustness and reward\nrobustness. Any c-MARL algorithm must simultaneously satisfy these robustness\naspects to be considered secure. Second, due to the scarceness of c-MARL\nattack, we propose c-MARL attacks as robustness testing algorithms from\nmultiple aspects. Experiments on \\textit{SMAC} environment reveals that many\nstate-of-the-art c-MARL algorithms are of low robustness in all aspect,\npointing out the urgent need to test and enhance robustness of c-MARL\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Jun Guo",
      "Yonghong Chen",
      "Yihang Hao",
      "Zixin Yin",
      "Yin Yu",
      "Simin Li"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07932"
  },
  {
    "id": "arXiv:2204.07935",
    "title": "Causal Intervention for Subject-Deconfounded Facial Action Unit  Recognition",
    "abstract": "Subject-invariant facial action unit (AU) recognition remains challenging for\nthe reason that the data distribution varies among subjects. In this paper, we\npropose a causal inference framework for subject-invariant facial action unit\nrecognition. To illustrate the causal effect existing in AU recognition task,\nwe formulate the causalities among facial images, subjects, latent AU semantic\nrelations, and estimated AU occurrence probabilities via a structural causal\nmodel. By constructing such a causal diagram, we clarify the causal effect\namong variables and propose a plug-in causal intervention module, CIS, to\ndeconfound the confounder \\emph{Subject} in the causal diagram. Extensive\nexperiments conducted on two commonly used AU benchmark datasets, BP4D and\nDISFA, show the effectiveness of our CIS, and the model with CIS inserted,\nCISNet, has achieved state-of-the-art performance.",
    "descriptor": "\nComments: Accepted by AAAI2022\n",
    "authors": [
      "Yingjie Chen",
      "Diqi Chen",
      "Tao Wang",
      "Yizhou Wang",
      "Yun Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07935"
  },
  {
    "id": "arXiv:2204.07936",
    "title": "Robust Task Planning for Assembly Lines with Human-Robot Collaboration",
    "abstract": "Efficient and robust task planning for a human-robot collaboration (HRC)\nsystem remains challenging. The human-aware task planner needs to assign jobs\nto both robots and human workers so that they can work collaboratively to\nachieve better time efficiency. However, the complexity of the tasks and the\nstochastic nature of the human collaborators bring challenges to such task\nplanning. To reduce the complexity of the planning problem, we utilize the\nhierarchical task model, which explicitly captures the sequential and parallel\nrelationships of the task. We model human movements with the sigma-lognormal\nfunctions to account for human-induced uncertainties. A human action model\nadaptation scheme is applied during run-time, and it provides a measure for\nmodeling the human-induced uncertainties. We propose a sampling-based method to\nestimate human job completion time uncertainties. Next, we propose a robust\ntask planner, which formulates the planning problem as a robust optimization\nproblem by considering the task structure and the uncertainties. We conduct\nsimulations of a robot arm collaborating with a human worker in an electronics\nassembly setting. The results show that our proposed planner can reduce task\ncompletion time when human-induced uncertainties occur compared to the baseline\nplanner.",
    "descriptor": "",
    "authors": [
      "Jessica Leu",
      "Yujiao Cheng",
      "Changliu Liu",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07936"
  },
  {
    "id": "arXiv:2204.07937",
    "title": "Unsupervised Cross-Task Generalization via Retrieval Augmentation",
    "abstract": "Humans can perform unseen tasks by recalling relevant skills that are\nacquired previously and then generalizing them to the target tasks, even if\nthere is no supervision at all. In this paper, we aim to improve such\ncross-task generalization ability of massive multi-task language models such as\nT0 (Sanh et al., 2021) in an unsupervised setting. We propose a\nretrieval-augmentation method named ReCross that takes a few unlabelled\nexamples as queries to retrieve a small subset of upstream data and uses them\nto update the multi-task model for better generalization. Our empirical results\nshow that the proposed ReCross consistently outperforms non-retrieval baselines\nby a significant margin.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Bill Yuchen Lin",
      "Kangmin Tan",
      "Chris Miller",
      "Beiwen Tian",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07937"
  },
  {
    "id": "arXiv:2204.07939",
    "title": "Long-Horizon Motion Planning via Sampling and Segmented Trajectory  Optimization",
    "abstract": "This paper presents a hybrid robot motion planner that generates long-horizon\nmotion plans for robot navigation in environments with obstacles. We propose a\nhybrid planner, RRT* with segmented trajectory optimization (RRT*-sOpt), which\ncombines the merits of sampling-based planning, optimization-based planning,\nand trajectory splitting to quickly plan for a collision-free and\ndynamically-feasible motion plan. When generating a plan, the RRT* layer\nquickly samples a semi-optimal path and sets it as an initial reference path.\nThen, the sOpt layer splits the reference path and performs optimization on\neach segment. It then splits the new trajectory again and repeats the process\nuntil the whole trajectory converges. We also propose to reduce the number of\nsegments before convergence with the aim of further reducing computation time.\nSimulation results show that RRT*-sOpt benefits from the hybrid structure with\ntrajectory splitting and performs robustly in various robot platforms and\nscenarios.",
    "descriptor": "",
    "authors": [
      "Jessica Leu",
      "Michael Wang",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07939"
  },
  {
    "id": "arXiv:2204.07940",
    "title": "WhyGen: Explaining ML-powered Code Generation by Referring to Training  Examples",
    "abstract": "Deep learning has demonstrated great abilities in various code generation\ntasks. However, despite the great convenience for some developers, many are\nconcerned that the code generators may recite or closely mimic copyrighted\ntraining data without user awareness, leading to legal and ethical concerns. To\nease this problem, we introduce a tool, named WhyGen, to explain the generated\ncode by referring to training examples. Specifically, we first introduce a data\nstructure, named inference fingerprint, to represent the decision process of\nthe model when generating a prediction. The fingerprints of all training\nexamples are collected offline and saved to a database. When the model is used\nat runtime for code generation, the most relevant training examples can be\nretrieved by querying the fingerprint database. Our experiments have shown that\nWhyGen is able to precisely notify the users about possible recitations and\nhighly similar imitations with a top-10 accuracy of 81.21%. The demo video can\nbe found at https://youtu.be/EtoQP6850To.",
    "descriptor": "\nComments: 5 pages,accept by ICSE 2022 Demo track\n",
    "authors": [
      "Weixiang Yan",
      "Yuanchun Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.07940"
  },
  {
    "id": "arXiv:2204.07943",
    "title": "Global-Supervised Contrastive Loss and View-Aware-Based Post-Processing  for Vehicle Re-Identification",
    "abstract": "In this paper, we propose a Global-Supervised Contrastive loss and a\nview-aware-based post-processing (VABPP) method for the field of vehicle\nre-identification. The traditional supervised contrastive loss calculates the\ndistances of features within the batch, so it has the local attribute. While\nthe proposed Global-Supervised Contrastive loss has new properties and has good\nglobal attributes, the positive and negative features of each anchor in the\ntraining process come from the entire training set. The proposed VABPP method\nis the first time that the view-aware-based method is used as a post-processing\nmethod in the field of vehicle re-identification. The advantages of VABPP are\nthat, first, it is only used during testing and does not affect the training\nprocess. Second, as a post-processing method, it can be easily integrated into\nother trained re-id models. We directly apply the view-pair distance scaling\ncoefficient matrix calculated by the model trained in this paper to another\ntrained re-id model, and the VABPP method greatly improves its performance,\nwhich verifies the feasibility of the VABPP method.",
    "descriptor": "",
    "authors": [
      "Zhijun Hu",
      "Yong Xu",
      "Jie Wen",
      "Xianjing Cheng",
      "Zaijun Zhang",
      "Lilei Sun",
      "Yaowei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07943"
  },
  {
    "id": "arXiv:2204.07945",
    "title": "DR-GAN: Distribution Regularization for Text-to-Image Generation",
    "abstract": "This paper presents a new Text-to-Image generation model, named Distribution\nRegularization Generative Adversarial Network (DR-GAN), to generate images from\ntext descriptions from improved distribution learning. In DR-GAN, we introduce\ntwo novel modules: a Semantic Disentangling Module (SDM) and a Distribution\nNormalization Module (DNM). SDM combines the spatial self-attention mechanism\nand a new Semantic Disentangling Loss (SDL) to help the generator distill key\nsemantic information for the image generation. DNM uses a Variational\nAuto-Encoder (VAE) to normalize and denoise the image latent distribution,\nwhich can help the discriminator better distinguish synthesized images from\nreal images. DNM also adopts a Distribution Adversarial Loss (DAL) to guide the\ngenerator to align with normalized real image distributions in the latent\nspace. Extensive experiments on two public datasets demonstrated that our\nDR-GAN achieved a competitive performance in the Text-to-Image task.",
    "descriptor": "\nComments: Accepted by TNNLS\n",
    "authors": [
      "Hongchen Tan",
      "Xiuping Liu",
      "Baocai Yin",
      "Xin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07945"
  },
  {
    "id": "arXiv:2204.07946",
    "title": "Integrated In-vehicle Monitoring System Using 3D Human Pose Estimation  and Seat Belt Segmentation",
    "abstract": "Recently, along with interest in autonomous vehicles, the importance of\nmonitoring systems for both drivers and passengers inside vehicles has been\nincreasing. This paper proposes a novel in-vehicle monitoring system the\ncombines 3D pose estimation, seat-belt segmentation, and seat-belt status\nclassification networks. Our system outputs various information necessary for\nmonitoring by accurately considering the data characteristics of the in-vehicle\nenvironment. Specifically, the proposed 3D pose estimation directly estimates\nthe absolute coordinates of keypoints for a driver and passengers, and the\nproposed seat-belt segmentation is implemented by applying a structure based on\nthe feature pyramid. In addition, we propose a classification task to\ndistinguish between normal and abnormal states of wearing a seat belt using\nresults that combine 3D pose estimation with seat-belt segmentation. These\ntasks can be learned simultaneously and operate in real-time. Our method was\nevaluated on a private dataset we newly created and annotated. The experimental\nresults show that our method has significantly high performance that can be\napplied directly to real in-vehicle monitoring systems.",
    "descriptor": "\nComments: AAAI 2022 workshop AI for Transportation accepted\n",
    "authors": [
      "Ginam Kim",
      "Hyunsung Kim",
      "Kihun Kim",
      "Sung-Sik Cho",
      "Yeong-Hun Park",
      "Suk-Ju Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07946"
  },
  {
    "id": "arXiv:2204.07953",
    "title": "Learning with Signatures",
    "abstract": "In this work we investigate the use of the Signature Transform in the context\nof Learning. Under this assumption, we advance a supervised framework that\nprovides state-of-the-art classification accuracy with the use of very few\nlabels without the need of credit assignment and with minimal or no\noverfitting. We leverage tools from harmonic analysis by the use of the\nsignature and log-signature and use as a score function RMSE and MAE Signature\nand log-signature. We develop a closed-form equation to compute probably good\noptimal scale factors. Classification is performed at the CPU level orders of\nmagnitude faster than other methods. We report results on AFHQ dataset, Four\nShapes, MNIST and CIFAR10 achieving 100% accuracy on all tasks.",
    "descriptor": "",
    "authors": [
      "J. de Curt\u00f2",
      "I. de Zarz\u00e0",
      "Carlos T. Calafate",
      "Hong Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07953"
  },
  {
    "id": "arXiv:2204.07955",
    "title": "Vision-Language Pre-Training for Multimodal Aspect-Based Sentiment  Analysis",
    "abstract": "As an important task in sentiment analysis, Multimodal Aspect-Based Sentiment\nAnalysis (MABSA) has attracted increasing attention in recent years. However,\nprevious approaches either (i) use separately pre-trained visual and textual\nmodels, which ignore the crossmodal alignment or (ii) use vision-language\nmodels pre-trained with general pre-training tasks, which are inadequate to\nidentify finegrained aspects, opinions, and their alignments across modalities.\nTo tackle these limitations, we propose a task-specific Vision-Language\nPre-training framework for MABSA (VLPMABSA), which is a unified multimodal\nencoder-decoder architecture for all the pretraining and downstream tasks. We\nfurther design three types of task-specific pre-training tasks from the\nlanguage, vision, and multimodal modalities, respectively. Experimental results\nshow that our approach generally outperforms the state-of-the-art approaches on\nthree MABSA subtasks. Further analysis demonstrates the effectiveness of each\npretraining task. The source code is publicly released at\nhttps://github.com/NUSTM/VLP-MABSA.",
    "descriptor": "\nComments: Accepted by ACL 2022 (long paper)\n",
    "authors": [
      "Yan Ling",
      "Jianfei yu",
      "Rui Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.07955"
  },
  {
    "id": "arXiv:2204.07958",
    "title": "On an interior-exterior nonoverlapping domain decomposition method for  the Poisson--Boltzmann equation",
    "abstract": "A nonoverlapping domain decomposition method is studied for the linearized\nPoisson--Boltzmann equation, which is essentially an interior-exterior\ntransmission problem with bounded interior and unbounded exterior. This problem\nis different from the classical Schwarz alternating method for bounded\nnonoverlapping subdomains well studied by Lions in 1990, and is challenging due\nto the existence of unbounded subdomain. To obtain the convergence, a new\nconcept of interior-exterior Sobolev constant is introduced and a spectral\nequivalence of related Dirichlet-to-Neumann operators is established\nafterwards. We prove rigorously that the spectral equivalence results in the\nconvergence of interior-exterior iteration. Some numerical simulations are\nprovided to investigate the optimal stepping parameter of iteration and to\nverify our convergence analysis.",
    "descriptor": "",
    "authors": [
      "Xuanyu Liu",
      "Yvon Maday",
      "Chaoyu Quan",
      "Hui Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07958"
  },
  {
    "id": "arXiv:2204.07962",
    "title": "An Extendable, Efficient and Effective Transformer-based Object Detector",
    "abstract": "Transformers have been widely used in numerous vision problems especially for\nvisual recognition and detection. Detection transformers are the first fully\nend-to-end learning systems for object detection, while vision transformers are\nthe first fully transformer-based architecture for image classification. In\nthis paper, we integrate Vision and Detection Transformers (ViDT) to construct\nan effective and efficient object detector. ViDT introduces a reconfigured\nattention module to extend the recent Swin Transformer to be a standalone\nobject detector, followed by a computationally efficient transformer decoder\nthat exploits multi-scale features and auxiliary techniques essential to boost\nthe detection performance without much increase in computational load. In\naddition, we extend it to ViDT+ to support joint-task learning for object\ndetection and instance segmentation. Specifically, we attach an efficient\nmulti-scale feature fusion layer and utilize two more auxiliary training\nlosses, IoU-aware loss and token labeling loss. Extensive evaluation results on\nthe Microsoft COCO benchmark dataset demonstrate that ViDT obtains the best AP\nand latency trade-off among existing fully transformer-based object detectors,\nand its extended ViDT+ achieves 53.2AP owing to its high scalability for large\nmodels. The source code and trained models are available at\nhttps://github.com/naver-ai/vidt.",
    "descriptor": "\nComments: An extension of the ICLR paper, ViDT: An Efficient and Effective Fully Transformer-based Object Detector. arXiv admin note: substantial text overlap with arXiv:2110.03921\n",
    "authors": [
      "Hwanjun Song",
      "Deqing Sun",
      "Sanghyuk Chun",
      "Varun Jampani",
      "Dongyoon Han",
      "Byeongho Heo",
      "Wonjae Kim",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07962"
  },
  {
    "id": "arXiv:2204.07964",
    "title": "Target-Relevant Knowledge Preservation for Multi-Source Domain Adaptive  Object Detection",
    "abstract": "Domain adaptive object detection (DAOD) is a promising way to alleviate\nperformance drop of detectors in new scenes. Albeit great effort made in single\nsource domain adaptation, a more generalized task with multiple source domains\nremains not being well explored, due to knowledge degradation during their\ncombination. To address this issue, we propose a novel approach, namely\ntarget-relevant knowledge preservation (TRKP), to unsupervised multi-source\nDAOD. Specifically, TRKP adopts the teacher-student framework, where the\nmulti-head teacher network is built to extract knowledge from labeled source\ndomains and guide the student network to learn detectors in unlabeled target\ndomain. The teacher network is further equipped with an adversarial\nmulti-source disentanglement (AMSD) module to preserve source domain-specific\nknowledge and simultaneously perform cross-domain alignment. Besides, a\nholistic target-relevant mining (HTRM) scheme is developed to re-weight the\nsource images according to the source-target relevance. By this means, the\nteacher network is enforced to capture target-relevant knowledge, thus\nbenefiting decreasing domain shift when mentoring object detection in the\ntarget domain. Extensive experiments are conducted on various widely used\nbenchmarks with new state-of-the-art scores reported, highlighting the\neffectiveness.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Jiaxi Wu",
      "Jiaxin Chen",
      "Mengzhe He",
      "Yiru Wang",
      "Bo Li",
      "Bingqi Ma",
      "Weihao Gan",
      "Wei Wu",
      "Yali Wang",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07964"
  },
  {
    "id": "arXiv:2204.07965",
    "title": "Entropy-based Active Learning for Object Detection with Progressive  Diversity Constraint",
    "abstract": "Active learning is a promising alternative to alleviate the issue of high\nannotation cost in the computer vision tasks by consciously selecting more\ninformative samples to label. Active learning for object detection is more\nchallenging and existing efforts on it are relatively rare. In this paper, we\npropose a novel hybrid approach to address this problem, where the\ninstance-level uncertainty and diversity are jointly considered in a bottom-up\nmanner. To balance the computational complexity, the proposed approach is\ndesigned as a two-stage procedure. At the first stage, an Entropy-based\nNon-Maximum Suppression (ENMS) is presented to estimate the uncertainty of\nevery image, which performs NMS according to the entropy in the feature space\nto remove predictions with redundant information gains. At the second stage, a\ndiverse prototype (DivProto) strategy is explored to ensure the diversity\nacross images by progressively converting it into the intra-class and\ninter-class diversities of the entropy-based class-specific prototypes.\nExtensive experiments are conducted on MS COCO and Pascal VOC, and the proposed\napproach achieves state of the art results and significantly outperforms the\nother counterparts, highlighting its superiority.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Jiaxi Wu",
      "Jiaxin Chen",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07965"
  },
  {
    "id": "arXiv:2204.07967",
    "title": "A Survey on Energy Optimization Techniques in UAV-Based Cellular  Networks: From Conventional to Machine Learning Approaches",
    "abstract": "Wireless communication networks have been witnessing an unprecedented demand\ndue to the increasing number of connected devices and emerging bandwidth-hungry\napplications. Albeit many competent technologies for capacity enhancement\npurposes, such as millimeter wave communications and network densification,\nthere is still room and need for further capacity enhancement in wireless\ncommunication networks, especially for the cases of unusual people gatherings,\nsuch as sport competitions, musical concerts, etc. Unmanned aerial vehicles\n(UAVs) have been identified as one of the promising options to enhance the\ncapacity due to their easy implementation, pop up fashion operation, and\ncost-effective nature. The main idea is to deploy base stations on UAVs and\noperate them as flying base stations, thereby bringing additional capacity to\nwhere it is needed. However, because the UAVs mostly have limited energy\nstorage, their energy consumption must be optimized to increase flight time. In\nthis survey, we investigate different energy optimization techniques with a\ntop-level classification in terms of the optimization algorithm employed;\nconventional and machine learning (ML). Such classification helps understand\nthe state of the art and the current trend in terms of methodology. In this\nregard, various optimization techniques are identified from the related\nliterature, and they are presented under the above mentioned classes of\nemployed optimization methods. In addition, for the purpose of completeness, we\ninclude a brief tutorial on the optimization methods and power supply and\ncharging mechanisms of UAVs. Moreover, novel concepts, such as reflective\nintelligent surfaces and landing spot optimization, are also covered to capture\nthe latest trend in the literature.",
    "descriptor": "\nComments: 41 pages, 5 Figures, 6 Tables. Submitted to Open Journal of Communications Society (OJ-COMS)\n",
    "authors": [
      "Attai Ibrahim Abubakar",
      "Iftikhar Ahmad",
      "Kenechi G. Omeke",
      "Metin Ozturk",
      "Cihat Ozturk",
      "Ali Makine Abdel-Salam",
      "Michael S. Mollel",
      "Qammer H. Abbasi",
      "Sajjad Hussain",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07967"
  },
  {
    "id": "arXiv:2204.07969",
    "title": "Augmentation Invariance and Adaptive Sampling in Semantic Segmentation  of Agricultural Aerial Images",
    "abstract": "In this paper, we investigate the problem of Semantic Segmentation for\nagricultural aerial imagery. We observe that the existing methods used for this\ntask are designed without considering two characteristics of the aerial data:\n(i) the top-down perspective implies that the model cannot rely on a fixed\nsemantic structure of the scene, because the same scene may be experienced with\ndifferent rotations of the sensor; (ii) there can be a strong imbalance in the\ndistribution of semantic classes because the relevant objects of the scene may\nappear at extremely different scales (e.g., a field of crops and a small\nvehicle). We propose a solution to these problems based on two ideas: (i) we\nuse together a set of suitable augmentation and a consistency loss to guide the\nmodel to learn semantic representations that are invariant to the photometric\nand geometric shifts typical of the top-down perspective (Augmentation\nInvariance); (ii) we use a sampling method (Adaptive Sampling) that selects the\ntraining images based on a measure of pixel-wise distribution of classes and\nactual network confidence. With an extensive set of experiments conducted on\nthe Agriculture-Vision dataset, we demonstrate that our proposed strategies\nimprove the performance of the current state-of-the-art method.",
    "descriptor": "\nComments: CVPR 2022 Workshop - Agriculture Vision\n",
    "authors": [
      "Antonio Tavera",
      "Edoardo Arnaudo",
      "Carlo Masone",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07969"
  },
  {
    "id": "arXiv:2204.07971",
    "title": "On strong avoiding games",
    "abstract": "Given an increasing graph property $\\cal F$, the strong Avoider-Avoider $\\cal\nF$ game is played on the edge set of a complete graph. Two players, Red and\nBlue, take turns in claiming previously unclaimed edges with Red going first,\nand the player whose graph possesses $\\cal F$ first loses the game. If the\nproperty $\\cal F$ is \"containing a fixed graph $H$\", we refer to the game as\nthe $H$ game.\nWe prove that Blue has a winning strategy in two strong Avoider-Avoider\ngames, $P_4$ game and ${\\cal CC}_{>3}$ game, where ${\\cal CC}_{>3}$ is the\nproperty of having at least one connected component on more than three\nvertices.\nWe also study a variant, the strong CAvoider-CAvoider games, with additional\nrequirement that the graph of each of the players must stay connected\nthroughout the game. We prove that Blue has a winning strategy in the strong\nCAvoider-CAvoider games $S_3$ and $P_4$, as well as in the $Cycle$ game, where\nthe players aim at avoiding all cycles.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Milo\u0161 Stojakovi\u0107",
      "Jelena Stratijev"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.07971"
  },
  {
    "id": "arXiv:2204.07974",
    "title": "Anomaly Detection in Autonomous Driving: A Survey",
    "abstract": "Nowadays, there are outstanding strides towards a future with autonomous\nvehicles on our roads. While the perception of autonomous vehicles performs\nwell under closed-set conditions, they still struggle to handle the unexpected.\nThis survey provides an extensive overview of anomaly detection techniques\nbased on camera, lidar, radar, multimodal and abstract object level data. We\nprovide a systematization including detection approach, corner case level,\nability for an online application, and further attributes. We outline the\nstate-of-the-art and point out current research gaps.",
    "descriptor": "\nComments: Daniel Bogdoll and Maximilian Nitsche contributed equally. Accepted for publication at CVPR 2022 WAD workshop\n",
    "authors": [
      "Daniel Bogdoll",
      "Maximilian Nitsche",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07974"
  },
  {
    "id": "arXiv:2204.07980",
    "title": "Does Recommend-Revise Produce Reliable Annotations? An Analysis on  Missing Instances in DocRED",
    "abstract": "DocRED is a widely used dataset for document-level relation extraction. In\nthe large-scale annotation, a \\textit{recommend-revise} scheme is adopted to\nreduce the workload. Within this scheme, annotators are provided with candidate\nrelation instances from distant supervision, and they then manually supplement\nand remove relational facts based on the recommendations. However, when\ncomparing DocRED with a subset relabeled from scratch, we find that this scheme\nresults in a considerable amount of false negative samples and an obvious bias\ntowards popular entities and relations. Furthermore, we observe that the models\ntrained on DocRED have low recall on our relabeled dataset and inherit the same\nbias in the training data. Through the analysis of annotators' behaviors, we\nfigure out the underlying reason for the problems above: the scheme actually\ndiscourages annotators from supplementing adequate instances in the revision\nphase. We appeal to future research to take into consideration the issues with\nthe recommend-revise scheme when designing new models and annotation schemes.\nThe relabeled dataset is released at\n\\url{https://github.com/AndrewZhe/Revisit-DocRED}, to serve as a more reliable\ntest set of document RE models.",
    "descriptor": "\nComments: ACL 2022 Main Conference\n",
    "authors": [
      "Quzhe Huang",
      "Shibo Hao",
      "Yuan Ye",
      "Shengqi Zhu",
      "Yansong Feng",
      "Dongyan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07980"
  },
  {
    "id": "arXiv:2204.07987",
    "title": "Fair Classification under Covariate Shift and Missing Protected  Attribute -- an Investigation using Related Features",
    "abstract": "This study investigated the problem of fair classification under Covariate\nShift and missing protected attribute using a simple approach based on the use\nof importance-weights to handle covariate-shift and, Related Features\narXiv:2104.14537 to handle missing protected attribute.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Manan Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.07987"
  },
  {
    "id": "arXiv:2204.07992",
    "title": "One RING to Rule Them All: Radon Sinogram for Place Recognition,  Orientation and Translation Estimation",
    "abstract": "LiDAR-based global localization is a fundamental problem for mobile robots.\nIt consists of two stages, place recognition and pose estimation, and yields\nthe current orientation and translation, using only the current scan as query\nand a database of map scans. Inspired by the definition of a recognized place,\nwe consider that a good global localization solution should keep the pose\nestimation accuracy with a lower place density. Following this idea, we propose\na novel framework towards sparse place-based global localization, which\nutilizes a unified and learning-free representation, Radon sinogram (RING), for\nall sub-tasks. Based on the theoretical derivation, a translation invariant\ndescriptor and an orientation invariant metric are proposed for place\nrecognition, achieving certifiable robustness against arbitrary orientation and\nlarge translation between query and map scan. In addition, we also utilize the\nproperty of RING to propose a global convergent solver for both orientation and\ntranslation estimation, arriving at global localization. Evaluation of the\nproposed RING based framework validates the feasibility and demonstrates a\nsuperior performance even under a lower place density.",
    "descriptor": "",
    "authors": [
      "Sha Lu",
      "Xuecheng Xu",
      "Huan Yin",
      "Rong Xiong",
      "Yue Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07992"
  },
  {
    "id": "arXiv:2204.07994",
    "title": "On Effectively Learning of Knowledge in Continual Pre-training",
    "abstract": "Pre-trained language models (PLMs) like BERT have made significant progress\nin various downstream NLP tasks. However, by asking models to do cloze-style\ntests, recent work finds that PLMs are short in acquiring knowledge from\nunstructured text. To understand the internal behaviour of PLMs in retrieving\nknowledge, we first define knowledge-baring (K-B) tokens and knowledge-free\n(K-F) tokens for unstructured text and ask professional annotators to label\nsome samples manually. Then, we find that PLMs are more likely to give wrong\npredictions on K-B tokens and attend less attention to those tokens inside the\nself-attention module. Based on these observations, we develop two solutions to\nhelp the model learn more knowledge from unstructured text in a fully\nself-supervised manner. Experiments on knowledge-intensive tasks show the\neffectiveness of the proposed methods. To our best knowledge, we are the first\nto explore fully self-supervised learning of knowledge in continual\npre-training.",
    "descriptor": "",
    "authors": [
      "Cunxiang Wang",
      "Fuli Luo",
      "Yanyang Li",
      "Runxin Xu",
      "Fei Huang",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07994"
  },
  {
    "id": "arXiv:2204.08005",
    "title": "A Survey on Location-Driven Influence Maximization",
    "abstract": "Influence Maximization (IM), which aims to select a set of users from a\nsocial network to maximize the expected number of influenced users, is an\nevergreen hot research topic. Its research outcomes significantly impact\nreal-world applications such as business marketing. The booming location-based\nnetwork platforms of the last decade appeal to the researchers embedding the\nlocation information into traditional IM research. In this survey, we provide a\ncomprehensive review of the existing location-driven IM studies from the\nperspective of the following key aspects: (1) a review of the application\nscenarios of these works, (2) the diffusion models to evaluate the influence\npropagation, and (3) a comprehensive study of the approaches to deal with the\nlocation-driven IM problems together with a particular focus on the\naccelerating techniques. In the end, we draw prospects into the research\ndirections in future IM research.",
    "descriptor": "",
    "authors": [
      "Taotao Cai",
      "Quan Z.Sheng",
      "Xiangyu Song",
      "Jian Yang",
      "Wei Emma Zhang",
      "Jia Wu",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.08005"
  },
  {
    "id": "arXiv:2204.08006",
    "title": "Nested Named Entity Recognition as Holistic Structure Parsing",
    "abstract": "As a fundamental natural language processing task and one of core knowledge\nextraction techniques, named entity recognition (NER) is widely used to extract\ninformation from texts for downstream tasks. Nested NER is a branch of NER in\nwhich the named entities (NEs) are nested with each other. However, most of the\nprevious studies on nested NER usually apply linear structure to model the\nnested NEs which are actually accommodated in a hierarchical structure. Thus in\norder to address this mismatch, this work models the full nested NEs in a\nsentence as a holistic structure, then we propose a holistic structure parsing\nalgorithm to disclose the entire NEs once for all. Besides, there is no\nresearch on applying corpus-level information to NER currently. To make up for\nthe loss of this information, we introduce Point-wise Mutual Information (PMI)\nand other frequency features from corpus-aware statistics for even better\nperformance by holistic modeling from sentence-level to corpus-level.\nExperiments show that our model yields promising results on widely-used\nbenchmarks which approach or even achieve state-of-the-art. Further empirical\nstudies show that our proposed corpus-aware features can substantially improve\nNER domain adaptation, which demonstrates the surprising advantage of our\nproposed corpus-level holistic structure modeling.",
    "descriptor": "",
    "authors": [
      "Yifei Yang",
      "Zuchao Li",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08006"
  },
  {
    "id": "arXiv:2204.08009",
    "title": "WikiOmnia: generative QA corpus on the whole Russian Wikipedia",
    "abstract": "The General QA field has been developing the methodology referencing the\nStanford Question answering dataset (SQuAD) as the significant benchmark.\nHowever, compiling factual questions is accompanied by time- and\nlabour-consuming annotation, limiting the training data's potential size. We\npresent the WikiOmnia dataset, a new publicly available set of QA-pairs and\ncorresponding Russian Wikipedia article summary sections, composed with a fully\nautomated generative pipeline. The dataset includes every available article\nfrom Wikipedia for the Russian language. The WikiOmnia pipeline is available\nopen-source and is also tested for creating SQuAD-formatted QA on other\ndomains, like news texts, fiction, and social media. The resulting dataset\nincludes two parts: raw data on the whole Russian Wikipedia (7,930,873 QA pairs\nwith paragraphs for ruGPT-3 XL and 7,991,040 QA pairs with paragraphs for\nruT5-large) and cleaned data with strict automatic verification (over 160,000\nQA pairs with paragraphs for ruGPT-3 XL and over 3,400,000 QA pairs with\nparagraphs for ruT5-large).",
    "descriptor": "",
    "authors": [
      "Dina Pisarevskaya",
      "Tatiana Shavrina"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08009"
  },
  {
    "id": "arXiv:2204.08017",
    "title": "PiouCrypt: Decentralized Lattice-based Method for Visual Symmetric  Cryptography",
    "abstract": "In recent years, establishing secure visual communications has turned into\none of the essential problems for security engineers and researchers. However,\nonly limited novel solutions are provided for image encryption, and limiting\nthe visual cryptography to only limited schemes can bring up negative\nconsequences, especially with emerging quantum computational systems. This\npaper presents a novel algorithm for establishing secure private visual\ncommunication. The proposed method has a layered architecture with several\ncohesive components, and corresponded with an NP-hard problem, despite its\nsymmetric structure. This two-step technique is not limited to gray-scale\npictures, and furthermore, utilizing a lattice structure causes to proposed\nmethod has optimal resistance for the post-quantum era, and is relatively\nsecure from the theoretical dimension.",
    "descriptor": "\nComments: 21 pages, 23 figures, for accessing source code, see this https URL\n",
    "authors": [
      "Navid Abapour",
      "Mohsen Ebadpour"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08017"
  },
  {
    "id": "arXiv:2204.08021",
    "title": "Sharper Bounds on Four Lattice Constants",
    "abstract": "The Korkine--Zolotareff (KZ) reduction, and its generalisations, are widely\nused lattice reduction strategies in communications and cryptography. The KZ\nconstant and Schnorr's constant were defined by Schnorr in 1987. The KZ\nconstant can be used to quantify some useful properties of KZ reduced matrices.\nSchnorr's constant can be used to characterize the output quality of his block\n$2k$-reduction and is used to define his semi block $2k$-reduction, which was\nalso developed in 1987. Hermite's constant, which is a fundamental constant\nlattices, has many applications, such as bounding the length of the shortest\nnonzero lattice vector and the orthogonality defect of lattices. Rankin's\nconstant was introduced by Rankin in 1953 as a generalization of Hermite's\nconstant. It plays an important role in characterizing the output quality of\nblock-Rankin reduction, proposed by Gama et al. in 2006. In this paper, we\nfirst develop a linear upper bound on Hermite's constant and then use it to\ndevelop an upper bound on the KZ constant. These upper bounds are sharper than\nthose obtained recently by the authors, and the ratio of the new linear upper\nbound to the nonlinear upper bound, developed by Blichfeldt in 1929, on\nHermite's constant is asymptotically 1.0047. Furthermore, we develop lower and\nupper bounds on Schnorr's constant. The improvement to the lower bound over the\nsharpest existing one developed by Gama et al. is around 1.7 times\nasymptotically, and the improvement to the upper bound over the sharpest\nexisting one which was also developed by Gama et al. is around 4 times\nasymptotically. Finally, we develop lower and upper bounds on Rankin's\nconstant. The improvements of the bounds over the sharpest existing ones, also\ndeveloped by Gama et al., are exponential in the parameter defining the\nconstant.",
    "descriptor": "\nComments: to appear in Designs, Codes and Cryptography. arXiv admin note: text overlap with arXiv:1904.09395\n",
    "authors": [
      "Jinming Wen",
      "Xiao-Wen Chang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08021"
  },
  {
    "id": "arXiv:2204.08023",
    "title": "VDTR: Video Deblurring with Transformer",
    "abstract": "Video deblurring is still an unsolved problem due to the challenging\nspatio-temporal modeling process. While existing convolutional neural\nnetwork-based methods show a limited capacity for effective spatial and\ntemporal modeling for video deblurring. This paper presents VDTR, an effective\nTransformer-based model that makes the first attempt to adapt Transformer for\nvideo deblurring. VDTR exploits the superior long-range and relation modeling\ncapabilities of Transformer for both spatial and temporal modeling. However, it\nis challenging to design an appropriate Transformer-based model for video\ndeblurring due to the complicated non-uniform blurs, misalignment across\nmultiple frames and the high computational costs for high-resolution spatial\nmodeling. To address these problems, VDTR advocates performing attention within\nnon-overlapping windows and exploiting the hierarchical structure for\nlong-range dependencies modeling. For frame-level spatial modeling, we propose\nan encoder-decoder Transformer that utilizes multi-scale features for\ndeblurring. For multi-frame temporal modeling, we adapt Transformer to fuse\nmultiple spatial features efficiently. Compared with CNN-based methods, the\nproposed method achieves highly competitive results on both synthetic and\nreal-world video deblurring benchmarks, including DVD, GOPRO, REDS and BSD. We\nhope such a Transformer-based architecture can serve as a powerful alternative\nbaseline for video deblurring and other video restoration tasks. The source\ncode will be available at \\url{https://github.com/ljzycmd/VDTR}.",
    "descriptor": "",
    "authors": [
      "Mingdeng Cao",
      "Yanbo Fan",
      "Yong Zhang",
      "Jue Wang",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08023"
  },
  {
    "id": "arXiv:2204.08024",
    "title": "The Z-axis, X-axis, Weight and Disambiguation Methods for Constructing  Local Reference Frame in 3D Registration: An Evaluation",
    "abstract": "The local reference frame (LRF), as an independent coordinate system\ngenerated on a local 3D surface, is widely used in 3D local feature descriptor\nconstruction and 3D transformation estimation which are two key steps in the\nlocal method-based surface matching. There are numerous LRF methods have been\nproposed in literatures. In these methods, the x- and z-axis are commonly\ngenerated by different methods or strategies, and some x-axis methods are\nimplemented on the basis of a z-axis being given. In addition, the weight and\ndisambiguation methods are commonly used in these LRF methods. In existing\nevaluations of LRF, each LRF method is evaluated with a complete form. However,\nthe merits and demerits of the z-axis, x-axis, weight and disambiguation\nmethods in LRF construction are unclear. In this paper, we comprehensively\nanalyze the z-axis, x-axis, weight and disambiguation methods in existing LRFs,\nand obtain six z-axis and eight x-axis, five weight and two disambiguation\nmethods. The performance of these methods are comprehensively evaluated on six\nstandard datasets with different application scenarios and nuisances.\nConsidering the evaluation outcomes, the merits and demerits of different\nweight, disambiguation, z- and x-axis methods are analyzed and summarized. The\nexperimental result also shows that some new designed LRF axes present superior\nperformance compared with the state-of-the-art ones.",
    "descriptor": "",
    "authors": [
      "Bao Zhao",
      "Xianyong Fang",
      "Jiahui Yue",
      "Xiaobo Chen",
      "Xinyi Le",
      "Chanjuan Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08024"
  },
  {
    "id": "arXiv:2204.08026",
    "title": "Advances in Thunder Sound Synthesis",
    "abstract": "A recent comparative study evaluated all known thunder synthesis techniques\nin terms of their perceptual realness. The findings concluded that none of the\nsynthesised audio extracts seemed as realistic as the genuine phenomenon. The\nwork presented herein is motivated by those findings, and attempts to create a\nsynthesised sound effect of thunder indistinguishable from a real recording.\nThe technique supplements an existing implementation with physics-inspired,\nsignal-based design elements intended to simulate environmental occurrences. In\na listening test conducted with over 50 participants, this new implementation\nwas perceived as the most realistic synthesised sound, though still\ndistinguishable from a real recording. Further improvements to the model, based\non insights from the listening test, were also implemented and described\nherein.",
    "descriptor": "\nComments: 9 pages, 6 figures, conference paper accepted to the AES Europe Spring 2022 Audio Engineering 152nd Convention\n",
    "authors": [
      "Eva Fineberg",
      "Jack Walters",
      "Joshua Reiss"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.08026"
  },
  {
    "id": "arXiv:2204.08027",
    "title": "Attention Mechanism based Cognition-level Scene Understanding",
    "abstract": "Given a question-image input, the Visual Commonsense Reasoning (VCR) model\ncan predict an answer with the corresponding rationale, which requires\ninference ability from the real world. The VCR task, which calls for exploiting\nthe multi-source information as well as learning different levels of\nunderstanding and extensive commonsense knowledge, is a cognition-level scene\nunderstanding task. The VCR task has aroused researchers' interest due to its\nwide range of applications, including visual question answering, automated\nvehicle systems, and clinical decision support. Previous approaches to solving\nthe VCR task generally rely on pre-training or exploiting memory with long\ndependency relationship encoded models. However, these approaches suffer from a\nlack of generalizability and losing information in long sequences. In this\npaper, we propose a parallel attention-based cognitive VCR network PAVCR, which\nfuses visual-textual information efficiently and encodes semantic information\nin parallel to enable the model to capture rich information for cognition-level\ninference. Extensive experiments show that the proposed model yields\nsignificant improvements over existing methods on the benchmark VCR dataset.\nMoreover, the proposed model provides intuitive interpretation into visual\ncommonsense reasoning.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2108.02924, arXiv:2107.01671\n",
    "authors": [
      "Xuejiao Tang",
      "Tai Le Quy",
      "Eirini Ntoutsi",
      "Kea Turner",
      "Vasile Palade",
      "Israat Haque",
      "Peng Xu",
      "Chris Brown",
      "Wenbin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08027"
  },
  {
    "id": "arXiv:2204.08028",
    "title": "Lie symmetries reduction and spectral methods on the fractional  two-dimensional heat equation",
    "abstract": "In this paper, the Lie symmetry analysis is proposed for a space-time\nconvection-diffusion fractional differential equations with the\nRiemann-Liouville derivative by (2+1) independent variables and one dependent\nvariable. We find a reduction form of our governed fractional differential\nequation using the similarity solution of our Lie symmetry. One-dimensional\noptimal system of Lie symmetry algebras is found. We present a computational\nmethod via the spectral method based on Bernstein's operational matrices to\nsolve the two-dimensional fractional heat equation with some initial\nconditions.",
    "descriptor": "\nComments: Accepted for publication in Mathematics and Computers in Simulation\n",
    "authors": [
      "Rohollah Bakhshandeh-Chamazkoti",
      "Mohsen Alipour"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.08028"
  },
  {
    "id": "arXiv:2204.08029",
    "title": "Deep Learning based Automatic Detection of Dicentric Chromosome",
    "abstract": "Automatic detection of dicentric chromosomes is an essential step to estimate\nradiation exposure and development of end to end emergency bio dosimetry\nsystems. During accidents, a large amount of data is required to be processed\nfor extensive testing to formulate a medical treatment plan for the masses,\nwhich requires this process to be automated. Current approaches require human\nadjustments according to the data and therefore need a human expert to\ncalibrate the system. This paper proposes a completely data driven framework\nwhich requires minimum intervention of field experts and can be deployed in\nemergency cases with relative ease. Our approach involves YOLOv4 to detect the\nchromosomes and remove the debris in each image, followed by a classifier that\ndifferentiates between an analysable chromosome and a non-analysable one.\nImages are extracted from YOLOv4 based on the protocols described by\nWHO-BIODOSNET. The analysable chromosome is classified as Monocentric or\nDicentric and an image is accepted for consideration of dose estimation based\non the analysable chromosome count. We report an accuracy in dicentric\nidentification of 94.33% on a 1:1 split of Dicentric and Monocentric\nChromosomes.",
    "descriptor": "",
    "authors": [
      "Angad Singh Wadhwa",
      "Nikhil Tyagi",
      "Pinaki Roy Chowdhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08029"
  },
  {
    "id": "arXiv:2204.08030",
    "title": "An Adaptive Task-Related Component Analysis Method for SSVEP recognition",
    "abstract": "Steady-state visual evoked potential (SSVEP) recognition methods are equipped\nwith learning from the subject's calibration data, and they can achieve extra\nhigh performance in the SSVEP-based brain-computer interfaces (BCIs), however\ntheir performance deteriorate drastically if the calibration trials are\ninsufficient. This study develops a new method to learn from limited\ncalibration data and it proposes and evaluates a novel adaptive data-driven\nspatial filtering approach for enhancing SSVEPs detection. The spatial filter\nlearned from each stimulus utilizes temporal information from the corresponding\nEEG trials. To introduce the temporal information into the overall procedure,\nan multitask learning approach, based on the bayesian framework, is adopted.\nThe performance of the proposed method was evaluated into two publicly\navailable benchmark datasets, and the results demonstrated that our method\noutperform competing methods by a significant margin.",
    "descriptor": "\nComments: 23 pages, 3 Figures, 6 Tables\n",
    "authors": [
      "Vangelis P. Oikonomou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.08030"
  },
  {
    "id": "arXiv:2204.08032",
    "title": "A Survey of Layer-Two Blockchain Protocols",
    "abstract": "After the success of the Bitcoin blockchain, came several cryptocurrencies\nand blockchain solutions in the last decade. Nonetheless, Blockchain-based\nsystems still suffer from low transaction rates and high transaction processing\nlatencies, which hinder blockchains' scalability. An entire class of solutions,\ncalled Layer-1 scalability solutions, have attempted to incrementally improve\nsuch limitations by adding/modifying fundamental blockchain attributes.\nRecently, a completely different class of works, called Layer-2 protocols, have\nemerged to tackle the blockchain scalability issues using unconventional\napproaches. Layer-2 protocols improve transaction processing rates, periods,\nand fees by minimizing the use of underlying slow and costly blockchains. In\nfact, the main chain acts just as an instrument for trust establishment and\ndispute resolution among Layer-2 participants, where only a few transactions\nare dispatched to the main chain. Thus, Layer-2 blockchain protocols have the\npotential to transform the domain. However, rapid and discrete developments\nhave resulted in diverse branches of Layer-2 protocols. In this work, we\nsystematically create a broad taxonomy of such protocols and implementations.\nWe discuss each Layer-2 protocol class in detail and also elucidate their\nrespective approaches, salient features, requirements, etc. Moreover, we\noutline the issues related to these protocols along with a comparative\ndiscussion. Our thorough study will help further systematize the knowledge\ndispersed in the domain and help the readers to better understand the field of\nLayer-2 protocols.",
    "descriptor": "\nComments: 21 pages, 15 figures, 2 tables\n",
    "authors": [
      "Ankit Gangwal",
      "Haripriya Ravali Gangavalli",
      "Apoorva Thirupathi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.08032"
  },
  {
    "id": "arXiv:2204.08033",
    "title": "RLens: A Computer-aided Visualization System for Supporting Reflection  on Language Learning under Distributed Tutorship",
    "abstract": "With the rise of the gig economy, online language tutoring platforms are\nbecoming increasingly popular. These platforms provide temporary and flexible\njobs for native speakers as tutors and allow language learners to have\none-on-one speaking practices on demand, on which learners occasionally\npractice the language with different tutors. With such distributed tutorship,\nlearners can hold flexible schedules and receive diverse feedback. However,\nlearners face challenges in consistently tracking their learning progress\nbecause different tutors provide feedback from diverse standards and\nperspectives, and hardly refer to learners' previous experiences with other\ntutors. We present RLens, a visualization system for facilitating learners'\nlearning progress reflection by grouping different tutors' feedback, tracking\nhow each feedback type has been addressed across learning sessions, and\nvisualizing the learning progress. We validate our design through a\nbetween-subjects study with 40 real-world learners. Results show that learners\ncan successfully analyze their progress and common language issues under\ndistributed tutorship with RLens, while most learners using the baseline\ninterface had difficulty achieving reflection tasks. We further discuss design\nconsiderations of computer-aided systems for supporting learning under\ndistributed tutorship.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Meng Xia",
      "Yankun Zhao",
      "Jihyeong Hong",
      "Mehmet Hamza Erol",
      "Taewook Kim",
      "Juho Kim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.08033"
  },
  {
    "id": "arXiv:2204.08035",
    "title": "Beta Residuals: Improving Fault-Tolerant Control for Sensory Faults via  Bayesian Inference and Precision Learning",
    "abstract": "Model-based fault-tolerant control (FTC) often consists of two distinct\nsteps: fault detection & isolation (FDI), and fault accommodation. In this work\nwe investigate posing fault-tolerant control as a single Bayesian inference\nproblem. Previous work showed that precision learning allows for stochastic FTC\nwithout an explicit fault detection step. While this leads to implicit fault\nrecovery, information on sensor faults is not provided, which may be essential\nfor triggering other impact-mitigation actions. In this paper, we introduce a\nprecision-learning based Bayesian FTC approach and a novel beta residual for\nfault detection. Simulation results are presented, supporting the use of beta\nresidual against competing approaches.",
    "descriptor": "\nComments: 7 pages, 2 figures. Accepted at the 11th IFAC Symposium on Fault Detection, Supervision and Safety for Technical Processes - SAFEPROCESS 2022\n",
    "authors": [
      "Mohamed Baioumy",
      "William Hartemink",
      "Riccardo M.G. Ferrari",
      "Nick Hawes"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.08035"
  },
  {
    "id": "arXiv:2204.08036",
    "title": "Federated Learning Cost Disparity for IoT Devices",
    "abstract": "Federated learning (FL) promotes predictive model training at the Internet of\nthings (IoT) devices by evading data collection cost in terms of energy, time,\nand privacy. We model the learning gain achieved by an IoT device against its\nparticipation cost as its utility. Due to the device-heterogeneity, the local\nmodel learning cost and its quality, which can be time-varying, differs from\ndevice to device. We show that this variation results in utility unfairness\nbecause the same global model is shared among the devices. By default, the\nmaster is unaware of the local model computation and transmission costs of the\ndevices, thus it is unable to address the utility unfairness problem. Also, a\ndevice may exploit this lack of knowledge at the master to intentionally reduce\nits expenditure and thereby enhance its utility. We propose to control the\nquality of the global model shared with the devices, in each round, based on\ntheir contribution and expenditure. This is achieved by employing differential\nprivacy to curtail global model divulgence based on the learning contribution.\nIn addition, we devise adaptive computation and transmission policies for each\ndevice to control its expenditure in order to mitigate utility unfairness. Our\nresults show that the proposed scheme reduces the standard deviation of the\nenergy cost of devices by 99% in comparison to the benchmark scheme, while the\nstandard deviation of the training loss of devices varies around 0.103.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2109.05267\n",
    "authors": [
      "Sheeraz A. Alvi",
      "Yi Hong",
      "Salman Durrani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.08036"
  },
  {
    "id": "arXiv:2204.08037",
    "title": "Comparison communication protocols",
    "abstract": "We introduce a restriction of the classical 2-party deterministic\ncommunication protocol where Alice and Bob are restricted to using only\ncomparison functions. We show that the complexity of a function in the model\nis, up to a constant factor, determined by a complexity measure analogous to\nYao's tiling number, which we call the geometric tiling number which can be\ncomputed in polynomial time. As a warm-up, we consider an analogous restricted\ndecision tree model and observe a 1-dimensional analog of the above results.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Michael R. Klug"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2204.08037"
  },
  {
    "id": "arXiv:2204.08039",
    "title": "Pathologies of Pre-trained Language Models in Few-shot Fine-tuning",
    "abstract": "Although adapting pre-trained language models with few examples has shown\npromising performance on text classification, there is a lack of understanding\nof where the performance gain comes from. In this work, we propose to answer\nthis question by interpreting the adaptation behavior using post-hoc\nexplanations from model predictions. By modeling feature statistics of\nexplanations, we discover that (1) without fine-tuning, pre-trained models\n(e.g. BERT and RoBERTa) show strong prediction bias across labels; (2) although\nfew-shot fine-tuning can mitigate the prediction bias and demonstrate promising\nprediction performance, our analysis shows models gain performance improvement\nby capturing non-task-related features (e.g. stop words) or shallow data\npatterns (e.g. lexical overlaps). These observations alert that pursuing model\nperformance with fewer examples may incur pathological prediction behavior,\nwhich requires further sanity check on model predictions and careful design in\nmodel evaluations in few-shot fine-tuning.",
    "descriptor": "\nComments: ACL 2022 Workshop on Insights from Negative Results in NLP\n",
    "authors": [
      "Hanjie Chen",
      "Guoqing Zheng",
      "Ahmed Hassan Awadallah",
      "Yangfeng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08039"
  },
  {
    "id": "arXiv:2204.08040",
    "title": "NICO++: Towards Better Benchmarking for Domain Generalization",
    "abstract": "Despite the remarkable performance that modern deep neural networks have\nachieved on independent and identically distributed (I.I.D.) data, they can\ncrash under distribution shifts. Most current evaluation methods for domain\ngeneralization (DG) adopt the leave-one-out strategy as a compromise on the\nlimited number of domains. We propose a large-scale benchmark with extensive\nlabeled domains named NICO++{\\ddag} along with more rational evaluation methods\nfor comprehensively evaluating DG algorithms. To evaluate DG datasets, we\npropose two metrics to quantify covariate shift and concept shift,\nrespectively. Two novel generalization bounds from the perspective of data\nconstruction are proposed to prove that limited concept shift and significant\ncovariate shift favor the evaluation capability for generalization. Through\nextensive experiments, NICO++ shows its superior evaluation capability compared\nwith current DG datasets and its contribution in alleviating unfairness caused\nby the leak of oracle knowledge in model selection.",
    "descriptor": "",
    "authors": [
      "Xingxuan Zhang",
      "Linjun Zhou",
      "Renzhe Xu",
      "Peng Cui",
      "Zheyan Shen",
      "Haoxin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08040"
  },
  {
    "id": "arXiv:2204.08042",
    "title": "BLEWhisperer: Exploiting BLE Advertisements for Data Exfiltration",
    "abstract": "Bluetooth technology has enabled short-range wireless communication for\nbillions of devices. Bluetooth Low-Energy (BLE) variant aims at improving power\nconsumption on battery-constrained devices. BLE-enabled devices broadcast\ninformation (e.g., as beacons) to nearby devices via advertisements.\nUnfortunately, such functionality can become a double-edged sword at the hands\nof attackers. In this paper, we primarily show how an attacker can exploit BLE\nadvertisements to exfiltrate information from BLE-enable devices. In\nparticular, our attack establishes a communication medium between two devices\nwithout requiring any prior authentication or pairing. We develop a\nproof-of-concept attack framework on the Android ecosystem and assess its\nperformance via a thorough set of experiments. Our results indicate that such\nan exfiltration attack is indeed possible though with a low data rate.\nNevertheless, we also demonstrate potential use cases and enhancements to our\nattack that can further its severeness. Finally, we discuss possible\ncountermeasures to prevent such an attack.",
    "descriptor": "\nComments: 20 pages, 6 figures\n",
    "authors": [
      "Ankit Gangwal",
      "Shubham Singh",
      "Riccardo Spolaor",
      "Abhijeet Srivastava"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.08042"
  },
  {
    "id": "arXiv:2204.08044",
    "title": "Interdependent Public Projects",
    "abstract": "In the interdependent values (IDV) model introduced by Milgrom and Weber\n[1982], agents have private signals that capture their information about\ndifferent social alternatives, and the valuation of every agent is a function\nof all agent signals. While interdependence has been mainly studied for\nauctions, it is extremely relevant for a large variety of social choice\nsettings, including the canonical setting of public projects. The IDV model is\nvery challenging relative to standard independent private values, and welfare\nguarantees have been achieved through two alternative conditions known as {\\em\nsingle-crossing} and {\\em submodularity over signals (SOS)}. In either case,\nthe existing theory falls short of solving the public projects setting.\nOur contribution is twofold: (i) We give a workable characterization of\ntruthfulness for IDV public projects for the largest class of valuations for\nwhich such a characterization exists, and term this class \\emph{decomposable\nvaluations}; (ii) We provide possibility and impossibility results for welfare\napproximation in public projects with SOS valuations. Our main impossibility\nresult is that, in contrast to auctions, no universally truthful mechanism\nperforms better for public projects with SOS valuations than choosing a project\nat random. Our main positive result applies to {\\em excludable} public projects\nwith SOS, for which we establish a constant factor approximation similar to\nauctions. Our results suggest that exclusion may be a key tool for achieving\nwelfare guarantees in the IDV model.",
    "descriptor": "",
    "authors": [
      "Avi Cohen",
      "Michal Feldman",
      "Divyarthi Mohan",
      "Inbal Talgam-Cohen"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.08044"
  },
  {
    "id": "arXiv:2204.08046",
    "title": "Evaluating Mixed-initiative Conversational Search Systems via User  Simulation",
    "abstract": "Clarifying the underlying user information need by asking clarifying\nquestions is an important feature of modern conversational search system.\nHowever, evaluation of such systems through answering prompted clarifying\nquestions requires significant human effort, which can be time-consuming and\nexpensive. In this paper, we propose a conversational User Simulator, called\nUSi, for automatic evaluation of such conversational search systems. Given a\ndescription of an information need, USi is capable of automatically answering\nclarifying questions about the topic throughout the search session. Through a\nset of experiments, including automated natural language generation metrics and\ncrowdsourcing studies, we show that responses generated by USi are both inline\nwith the underlying information need and comparable to human-generated answers.\nMoreover, we make the first steps towards multi-turn interactions, where\nconversational search systems asks multiple questions to the (simulated) user\nwith a goal of clarifying the user need. To this end, we expand on currently\navailable datasets for studying clarifying questions, i.e., Qulac and ClariQ,\nby performing a crowdsourcing-based multi-turn data acquisition. We show that\nour generative, GPT2-based model, is capable of providing accurate and natural\nanswers to unseen clarifying questions in the single-turn setting and discuss\ncapabilities of our model in the multi-turn setting. We provide the code, data,\nand the pre-trained model to be used for further research on the topic.",
    "descriptor": "",
    "authors": [
      "Ivan Sekuli\u0107",
      "Mohammad Aliannejadi",
      "Fabio Crestani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.08046"
  },
  {
    "id": "arXiv:2204.08049",
    "title": "Energetically Consistent Model Reduction for Metriplectic Systems",
    "abstract": "The metriplectic formalism is useful for describing complete dynamical\nsystems which conserve energy and produce entropy. This creates challenges for\nmodel reduction, as the elimination of high-frequency information will\ngenerally not preserve the metriplectic structure which governs long-term\nstability of the system. Based on proper orthogonal decomposition, a provably\nconvergent metriplectic reduced-order model is formulated which is guaranteed\nto maintain the algebraic structure necessary for energy conservation and\nentropy formation. Numerical results on benchmark problems show that the\nproposed method is remarkably stable, leading to improved accuracy over long\ntime scales at a moderate increase in cost over naive methods.",
    "descriptor": "",
    "authors": [
      "Anthony Gruber",
      "Max Gunzburger",
      "Lili Ju",
      "Zhu Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.08049"
  },
  {
    "id": "arXiv:2204.08054",
    "title": "Effective numerical computation of $p(x)-$Laplace equations in 2D",
    "abstract": "In this article we implement a method for the computation of a nonlinear\nelliptic problem with nonstandard growth driven by the $p(x)-$Laplacian\noperator. Our implementation is based in the {\\em decomposition--coordination}\nmethod that allows us, via an iterative process, to solve in each step a linear\ndifferential equation and a nonlinear algebraic equation. Our code is\nimplemented in {\\sc MatLab} in 2 dimensions and turns out to be extremely\nefficient from the computational point of view.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Adriana Aragon",
      "Julian Fernandez Bonder",
      "Diana Rubio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2204.08054"
  },
  {
    "id": "arXiv:2204.08057",
    "title": "A fast linear system solution with application to spatial source  separation for the Cosmic Microwave Background",
    "abstract": "Implementation of many statistical methods for large, multivariate data sets\nrequires one to solve a linear system that, depending on the method, is of the\ndimension of the number of observations or each individual data vector. This is\noften the limiting factor in scaling the method with data size and complexity.\nIn this paper we illustrate the use of Krylov subspace methods to address this\nissue in a statistical solution to a source separation problem in cosmology\nwhere the data size is prohibitively large for direct solution of the required\nsystem. Two distinct approaches are described: one that uses the method of\nconjugate gradients directly to the Kronecker-structured problem and another\nthat reformulates the system as a Sylvester matrix equation. We show that both\napproaches produce an accurate solution within an acceptable computation time\nand with practical memory requirements for the data size that is currently\navailable.",
    "descriptor": "\nComments: submitted for publication\n",
    "authors": [
      "Kirk M. Soodhalter",
      "Simon Wilson",
      "Dung Pham"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2204.08057"
  },
  {
    "id": "arXiv:2204.08058",
    "title": "MUGEN: A Playground for Video-Audio-Text Multimodal Understanding and  GENeration",
    "abstract": "Multimodal video-audio-text understanding and generation can benefit from\ndatasets that are narrow but rich. The narrowness allows bite-sized challenges\nthat the research community can make progress on. The richness ensures we are\nmaking progress along the core challenges. To this end, we present a\nlarge-scale video-audio-text dataset MUGEN, collected using the open-sourced\nplatform game CoinRun [11]. We made substantial modifications to make the game\nricher by introducing audio and enabling new interactions. We trained RL agents\nwith different objectives to navigate the game and interact with 13 objects and\ncharacters. This allows us to automatically extract a large collection of\ndiverse videos and associated audio. We sample 375K video clips (3.2s each) and\ncollect text descriptions from human annotators. Each video has additional\nannotations that are extracted automatically from the game engine, such as\naccurate semantic maps for each frame and templated textual descriptions.\nAltogether, MUGEN can help progress research in many tasks in multimodal\nunderstanding and generation. We benchmark representative approaches on tasks\ninvolving video-audio-text retrieval and generation. Our dataset and code are\nreleased at: https://mugen-org.github.io/.",
    "descriptor": "",
    "authors": [
      "Thomas Hayes",
      "Songyang Zhang",
      "Xi Yin",
      "Guan Pang",
      "Sasha Sheng",
      "Harry Yang",
      "Songwei Ge",
      "Isabelle Hu",
      "Devi Parikh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08058"
  },
  {
    "id": "arXiv:2204.08063",
    "title": "Geo-Enabled Business Process Modeling",
    "abstract": "Recent advancements in location-aware analytics have created novel\nopportunities in different domains. In the area of process mining, enriching\nprocess models with geolocation helps to gain a better understanding of how the\nprocess activities are executed in practice. In this paper, we introduce our\nidea of geo-enabled process modeling and report on our industrial experience.\nTo this end, we present a real-world case study to describe the importance of\nconsidering the location in process mining. Then we discuss the shortcomings of\ncurrently available process mining tools and propose our novel approach for\nmodeling geo-enabled processes focusing on 1) increasing process\ninterpretability through geo-visualization, 2) incorporating location-related\nmetadata into process analysis, and 3) using location-based measures for the\nassessment of process performance. Finally, we conclude the paper by future\nresearch directions.",
    "descriptor": "\nComments: accepted and presented in BPM 2020. this https URL\n",
    "authors": [
      "Behshid Behkamal",
      "Asef Pourmasoumi",
      "Mehdi Akbarian Rastaghi",
      "Mohsen Kahani",
      "Hamid Reza Motahari-Nezhad",
      "Mohammad Allahbakhsh",
      "Issa Najafi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2204.08063"
  },
  {
    "id": "arXiv:2204.08069",
    "title": "Self-Aware Personalized Federated Learning",
    "abstract": "In the context of personalized federated learning (FL), the critical\nchallenge is to balance local model improvement and global model tuning when\nthe personal and global objectives may not be exactly aligned. Inspired by\nBayesian hierarchical models, we develop a self-aware personalized FL method\nwhere each client can automatically balance the training of its local personal\nmodel and the global model that implicitly contributes to other clients'\ntraining. Such a balance is derived from the inter-client and intra-client\nuncertainty quantification. A larger inter-client variation implies more\npersonalization is needed. Correspondingly, our method uses uncertainty-driven\nlocal training steps and aggregation rule instead of conventional local\nfine-tuning and sample size-based aggregation. With experimental studies on\nsynthetic data, Amazon Alexa audio data, and public datasets such as MNIST,\nFEMNIST, CIFAR10, and Sent140, we show that our proposed method can achieve\nsignificantly improved personalization performance compared with the existing\ncounterparts.",
    "descriptor": "",
    "authors": [
      "Huili Chen",
      "Jie Ding",
      "Eric Tramel",
      "Shuang Wu",
      "Anit Kumar Sahu",
      "Salman Avestimehr",
      "Tao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08069"
  },
  {
    "id": "arXiv:2204.08070",
    "title": "A Novel ASIC Design Flow using Weight-Tunable Binary Neurons as Standard  Cells",
    "abstract": "In this paper, we describe a design of a mixed signal circuit for a binary\nneuron (a.k.a perceptron, threshold logic gate) and a methodology for\nautomatically embedding such cells in ASICs. The binary neuron, referred to as\nan FTL (flash threshold logic) uses floating gate or flash transistors whose\nthreshold voltages serve as a proxy for the weights of the neuron. Algorithms\nfor mapping the weights to the flash transistor threshold voltages are\npresented. The threshold voltages are determined to maximize both the\nrobustness of the cell and its speed. The performance, power, and area of a\nsingle FTL cell are shown to be significantly smaller (79.4%), consume less\npower (61.6%), and operate faster (40.3%) compared to conventional CMOS logic\nequivalents. Also included are the architecture and the algorithms to program\nthe flash devices of an FTL. The FTL cells are implemented as standard cells,\nand are designed to allow commercial synthesis and P&R tools to automatically\nuse them in synthesis of ASICs. Substantial reductions in area and power\nwithout sacrificing performance are demonstrated on several ASIC benchmarks by\nthe automatic embedding of FTL cells. The paper also demonstrates how FTL cells\ncan be used for fixing timing errors after fabrication.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1910.04910\n",
    "authors": [
      "Ankit Wagle",
      "Gian Singh",
      "Sunil Khatri",
      "Sarma Vrudhula"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.08070"
  },
  {
    "id": "arXiv:2204.08078",
    "title": "A Psycho-linguistic Analysis of BitChute",
    "abstract": "In order to better support researchers, journalist, and practitioners in\ntheir use of the MeLa-BitChute dataset for exploration and investigative\nreporting, we provide new psycho-linguistic metadata for the videos, comments,\nand channels in the dataset using LIWC22. This paper describes that metadata\nand methods to filter the data using the metadata. In addition, we provide\nbasic analysis and comparison of the language on BitChute to other social media\nplatforms. The MeLa-BitChute dataset and LIWC metadata described in this paper\ncan be found at:\nhttps://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/KRD1VS.",
    "descriptor": "\nComments: This paper is a Metadata Supplement to The MeLa BitChute Dataset\n",
    "authors": [
      "Benjamin D. Horne"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.08078"
  },
  {
    "id": "arXiv:2204.08081",
    "title": "Initial state reconstruction on graphs",
    "abstract": "The presence of noise is an intrinsic problem in acquisition processes for\ndigital images. One way to enhance images is to combine the forward and\nbackward diffusion equations. However, the latter problem is well known to be\nexponentially unstable with respect to any small perturbations on the final\ndata. In this scenario, the final data can be regarded as a blurred image\nobtained from the forward process, and that image can be pixelated as a\nnetwork. Therefore, we study in this work a regularization framework for the\nbackward diffusion equation on graphs. Our aim is to construct a spectral\ngraph-based solution based upon a cut-off projection. Stability and convergence\nresults are provided together with some numerical experiments.",
    "descriptor": "\nComments: 12 pages, 42 figures, 2 tables\n",
    "authors": [
      "Vo Anh Khoa",
      "Mai Thanh Nhat Truong",
      "Imhotep Hogan",
      "Roselyn Williams"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.08081"
  },
  {
    "id": "arXiv:2204.08083",
    "title": "\u00cct\u00e0k\u00far\u00f2so: Exploiting Cross-Lingual Transferability for Natural  Language Generation of Dialogues in Low-Resource, African Languages",
    "abstract": "We investigate the possibility of cross-lingual transfer from a\nstate-of-the-art (SoTA) deep monolingual model (DialoGPT) to 6 African\nlanguages and compare with 2 baselines (BlenderBot 90M, another SoTA, and a\nsimple Seq2Seq). The languages are Swahili, Wolof, Hausa, Nigerian Pidgin\nEnglish, Kinyarwanda & Yor\\`ub\\'a. Generation of dialogues is known to be a\nchallenging task for many reasons. It becomes more challenging for African\nlanguages which are low-resource in terms of data. Therefore, we translate a\nsmall portion of the English multi-domain MultiWOZ dataset for each target\nlanguage. Besides intrinsic evaluation (i.e. perplexity), we conduct human\nevaluation of single-turn conversations by using majority votes and measure\ninter-annotator agreement (IAA). The results show that the hypothesis that deep\nmonolingual models learn some abstractions that generalise across languages\nholds. We observe human-like conversations in 5 out of the 6 languages. It,\nhowever, applies to different degrees in different languages, which is\nexpected. The language with the most transferable properties is the Nigerian\nPidgin English, with a human-likeness score of 78.1%, of which 34.4% are\nunanimous. The main contributions of this paper include the representation\n(through the provision of high-quality dialogue data) of under-represented\nAfrican languages and demonstrating the cross-lingual transferability\nhypothesis for dialogue systems. We also provide the datasets and host the\nmodel checkpoints/demos on the HuggingFace hub for public access.",
    "descriptor": "\nComments: 14 pages, 1 figure, 7 tables\n",
    "authors": [
      "Tosin Adewumi",
      "Mofetoluwa Adeyemi",
      "Aremu Anuoluwapo",
      "Bukola Peters",
      "Happy Buzaaba",
      "Oyerinde Samuel",
      "Amina Mardiyyah Rufai",
      "Benjamin Ajibade",
      "Tajudeen Gwadabe",
      "Mory Moussou Koulibaly Traore",
      "Tunde Ajayi",
      "Shamsuddeen Muhammad",
      "Ahmed Baruwa",
      "Paul Owoicho",
      "Tolulope Ogunremi",
      "Phylis Ngigi",
      "Orevaoghene Ahia",
      "Ruqayya Nasir",
      "Foteini Liwicki",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08083"
  },
  {
    "id": "arXiv:2204.08084",
    "title": "Learning 3D Semantics from Pose-Noisy 2D Images with Hierarchical Full  Attention Network",
    "abstract": "We propose a novel framework to learn 3D point cloud semantics from 2D\nmulti-view image observations containing pose error. On the one hand, directly\nlearning from the massive, unstructured and unordered 3D point cloud is\ncomputationally and algorithmically more difficult than learning from\ncompactly-organized and context-rich 2D RGB images. On the other hand, both\nLiDAR point cloud and RGB images are captured in standard automated-driving\ndatasets. This motivates us to conduct a \"task transfer\" paradigm so that 3D\nsemantic segmentation benefits from aggregating 2D semantic cues, albeit pose\nnoises are contained in 2D image observations. Among all difficulties, pose\nnoise and erroneous prediction from 2D semantic segmentation approaches are the\nmain challenges for the task transfer. To alleviate the influence of those\nfactor, we perceive each 3D point using multi-view images and for each single\nimage a patch observation is associated. Moreover, the semantic labels of a\nblock of neighboring 3D points are predicted simultaneously, enabling us to\nexploit the point structure prior to further improve the performance. A\nhierarchical full attention network~(HiFANet) is designed to sequentially\naggregates patch, bag-of-frames and inter-point semantic cues, with\nhierarchical attention mechanism tailored for different level of semantic cues.\nAlso, each preceding attention block largely reduces the feature size before\nfeeding to the next attention block, making our framework slim. Experiment\nresults on Semantic-KITTI show that the proposed framework outperforms existing\n3D point cloud based methods significantly, it requires much less training data\nand exhibits tolerance to pose noise. The code is available at\nhttps://github.com/yuhanghe01/HiFANet.",
    "descriptor": "\nComments: Point Cloud Semantic Segmentation, Semantic Aggregation from Images, Pose Noise\n",
    "authors": [
      "Yuhang He",
      "Lin Chen",
      "Junkun Xie",
      "Long Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08084"
  },
  {
    "id": "arXiv:2204.08085",
    "title": "CPFair: Personalized Consumer and Producer Fairness Re-ranking for  Recommender Systems",
    "abstract": "Recently, there has been a rising awareness that when machine learning (ML)\nalgorithms are used to automate choices, they may treat/affect individuals\nunfairly, with legal, ethical, or economic consequences. Recommender systems\nare prominent examples of such ML systems that assist users in making\nhigh-stakes judgments. A common trend in the previous literature research on\nfairness in recommender systems is that the majority of works treat user and\nitem fairness concerns separately, ignoring the fact that recommender systems\noperate in a two-sided marketplace. In this work, we present an\noptimization-based re-ranking approach that seamlessly integrates fairness\nconstraints from both the consumer and producer-side in a joint objective\nframework. We demonstrate through large-scale experiments on 8 datasets that\nour proposed method is capable of improving both consumer and producer fairness\nwithout reducing overall recommendation quality, demonstrating the role\nalgorithms may play in minimizing data biases.",
    "descriptor": "\nComments: SIGIR 2022\n",
    "authors": [
      "Mohammadmehdi Naghiaei",
      "Hossein A. Rahmani",
      "Yashar Deldjoo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08085"
  },
  {
    "id": "arXiv:2204.08090",
    "title": "Learning Compositional Representations for Effective Low-Shot  Generalization",
    "abstract": "We propose Recognition as Part Composition (RPC), an image encoding approach\ninspired by human cognition. It is based on the cognitive theory that humans\nrecognize complex objects by components, and that they build a small compact\nvocabulary of concepts to represent each instance with. RPC encodes images by\nfirst decomposing them into salient parts, and then encoding each part as a\nmixture of a small number of prototypes, each representing a certain concept.\nWe find that this type of learning inspired by human cognition can overcome\nhurdles faced by deep convolutional networks in low-shot generalization tasks,\nlike zero-shot learning, few-shot learning and unsupervised domain adaptation.\nFurthermore, we find a classifier using an RPC image encoder is fairly robust\nto adversarial attacks, that deep neural networks are known to be prone to.\nGiven that our image encoding principle is based on human cognition, one would\nexpect the encodings to be interpretable by humans, which we find to be the\ncase via crowd-sourcing experiments. Finally, we propose an application of\nthese interpretable encodings in the form of generating synthetic attribute\nannotations for evaluating zero-shot learning methods on new datasets.",
    "descriptor": "",
    "authors": [
      "Samarth Mishra",
      "Pengkai Zhu",
      "Venkatesh Saligrama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08090"
  },
  {
    "id": "arXiv:2204.08092",
    "title": "The Existence and Uniqueness of Solutions for Kernel-Based System  Identification",
    "abstract": "The notion of reproducing kernel Hilbert space (RKHS) has emerged in system\nidentification during the past decade. In the resulting framework, the impulse\nresponse estimation problem is formulated as a regularized optimization defined\non an infinite-dimensional RKHS consisting of stable impulse responses. The\nconsequent estimation problem is well-defined under the central assumption that\nthe convolution operators restricted to the RKHS are continuous linear\nfunctionals. Moreover, according to this assumption, the representer theorem\nhold, and therefore, the impulse response can be estimated by solving a\nfinite-dimensional program. Thus, the continuity feature plays a significant\nrole in kernel-based system identification. This paper shows that this central\nassumption is guaranteed to be satisfied in considerably general situations,\nnamely when the kernel is an integrable function and the input signal is\nbounded. Furthermore, the strong convexity of the optimization problem and the\ncontinuity property of the convolution operators imply that the kernel-based\nsystem identification admits a unique solution. Consequently, it follows that\nkernel-based system identification is a well-defined approach.",
    "descriptor": "",
    "authors": [
      "Mohammad Khosravi",
      "Roy S. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.08092"
  },
  {
    "id": "arXiv:2204.08095",
    "title": "Mixed Isogeometric Discretizations for Planar Linear Elasticity",
    "abstract": "In this article we suggest two discretization methods based on isogeometric\nanalysis (IGA) for planar linear elasticity. On the one hand, we apply the\nwell-known ansatz of weakly imposed symmetry for the stress tensor and obtain a\nwell-posed mixed formulation. Such modified mixed problems have been already\nstudied by different authors. But we concentrate on the exploitation of IGA\nresults to handle also curved boundary geometries. On the other hand, we\nconsider the more complicated situation of strong symmetry, i.e. we discretize\nthe mixed weak form determined by the so-called Hellinger-Reissner variational\nprinciple. We show the existence of suitable approximate fields leading to an\ninf-sup stable saddle-point problem. For both discretization approaches we\nprove convergence statements and in case of weak symmetry we illustrate the\napproximation behavior by means of several numerical experiments.",
    "descriptor": "",
    "authors": [
      "Jeremias Arf",
      "Bernd Simeon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.08095"
  },
  {
    "id": "arXiv:2204.08096",
    "title": "Dataset for Analyzing Various Gaze Zones and Distracted Behaviors of a  Driver",
    "abstract": "This article presents a synthetic dataset for machine learning models to\ndetect and analyze drivers' various distracted behavior and different gaze\nzones. We collected the data in a stationary vehicle using three in-vehicle\ncameras positioned at locations: on the dashboard, near the rearview mirror,\nand on the top right-side window corner. The dataset contains two activity\ntypes: distracted activities, and gaze zones for each participant and each\nactivity type has two sets: without appearance blocks and with appearance\nblocks such as wearing a hat or sunglasses. The order and duration of each\nactivity for each participant are random. In addition, the dataset contains\nmanual annotations for each activity, having its start and end time annotated.\nResearchers could use this dataset to evaluate the performance of machine\nlearning algorithms for the classification of various distracting activities\nand gaze zones of drivers.",
    "descriptor": "",
    "authors": [
      "Mohammed Shaiqur Rahman",
      "Archana Venkatachalapathy",
      "Anuj Sharma",
      "Jiyang Wang",
      "Senem Velipasalar Gursoy",
      "David Anastasiu",
      "Shuo Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08096"
  },
  {
    "id": "arXiv:2204.08102",
    "title": "kpfriends at SemEval-2022 Task 2: NEAMER -- Named Entity Augmented  Multi-word Expression Recognizer",
    "abstract": "We present NEAMER -- Named Entity Augmented Multi-word Expression Recognizer.\nThis system is inspired by non-compositionality characteristics shared between\nNamed Entity and Idiomatic Expressions. We utilize transfer learning and\nlocality features to enhance idiom classification task. This system is our\nsubmission for SemEval Task 2: Multilingual Idiomaticity Detection and Sentence\nEmbedding Subtask A OneShot shared task. We achieve SOTA with F1 0.9395 during\npost-evaluation phase. We also observe improvement in training stability.\nLastly, we experiment with non-compositionality knowledge transfer,\ncross-lingual fine-tuning and locality features, which we also introduce in\nthis paper.",
    "descriptor": "",
    "authors": [
      "Min Sik Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08102"
  },
  {
    "id": "arXiv:2204.08103",
    "title": "Should Young Computer Scientists Stop Collaborating with their Doctoral  Advisors?",
    "abstract": "One of the first steps in an academic career, and perhaps the pillar thereof,\nis completing a PhD under the supervision of a doctoral advisor. While prior\nwork has examined the advisor-advisee relationship and its potential effects on\nthe prospective academic success of the advisee, very little is known on the\npossibly continued relationship after the advisee has graduated. We harnessed\nthree genealogical and scientometric datasets to identify 3 distinct groups of\ncomputer scientists: Highly independent, who cease collaborating with their\nadvisors (almost) instantly upon graduation; Moderately independent, who\n(quickly) reduce the collaboration rate over ~5 years; and Weakly independent\nwho continue collaborating with their advisors for at least 10 years\npost-graduation. We find that highly independent researchers are more\nacademically successful than their peers in terms of H-index, i10-index and\ntotal number of citations throughout their careers. Moderately independent\nresearchers perform, on average, better than weakly independent researchers,\nyet the differences are not found to be statistically significant. In addition,\nboth highly and moderately independent researchers are found to have longer\nacademic careers. Interestingly, weakly independent researchers tend to be\nsupervised by more academically successful advisors.",
    "descriptor": "\nComments: Communications of the ACM (to appear)\n",
    "authors": [
      "Ariel Rosenfeld",
      "Oleg Maksimov"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2204.08103"
  },
  {
    "id": "arXiv:2204.08105",
    "title": "Monte Carlo Tree Search for Interpreting Stress in Natural Language",
    "abstract": "Natural language processing can facilitate the analysis of a person's mental\nstate from text they have written. Previous studies have developed models that\ncan predict whether a person is experiencing a mental health condition from\nsocial media posts with high accuracy. Yet, these models cannot explain why the\nperson is experiencing a particular mental state. In this work, we present a\nnew method for explaining a person's mental state from text using Monte Carlo\ntree search (MCTS). Our MCTS algorithm employs trained classification models to\nguide the search for key phrases that explain the writer's mental state in a\nconcise, interpretable manner. Furthermore, our algorithm can find both\nexplanations that depend on the particular context of the text (e.g., a recent\nbreakup) and those that are context-independent. Using a dataset of Reddit\nposts that exhibit stress, we demonstrate the ability of our MCTS algorithm to\nidentify interpretable explanations for a person's feeling of stress in both a\ncontext-dependent and context-independent manner.",
    "descriptor": "\nComments: Second Workshop on LT-EDI at ACL 2022\n",
    "authors": [
      "Kyle Swanson",
      "Joy Hsu",
      "Mirac Suzgun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08105"
  },
  {
    "id": "arXiv:2204.08106",
    "title": "A New Dynamic Algorithm for Densest Subhypergraphs",
    "abstract": "Computing a dense subgraph is a fundamental problem in graph mining, with a\ndiverse set of applications ranging from electronic commerce to community\ndetection in social networks. In many of these applications, the underlying\ncontext is better modelled as a weighted hypergraph that keeps evolving with\ntime.\nThis motivates the problem of maintaining the densest subhypergraph of a\nweighted hypergraph in a {\\em dynamic setting}, where the input keeps changing\nvia a sequence of updates (hyperedge insertions/deletions). Previously, the\nonly known algorithm for this problem was due to Hu et al. [HWC17]. This\nalgorithm worked only on unweighted hypergraphs, and had an approximation ratio\nof $(1+\\epsilon)r^2$ and an update time of $O(\\text{poly} (r, \\log n))$, where\n$r$ denotes the maximum rank of the input across all the updates.\nWe obtain a new algorithm for this problem, which works even when the input\nhypergraph is weighted. Our algorithm has a significantly improved\n(near-optimal) approximation ratio of $(1+\\epsilon)$ that is independent of\n$r$, and a similar update time of $O(\\text{poly} (r, \\log n))$. It is the first\n$(1+\\epsilon)$-approximation algorithm even for the special case of weighted\nsimple graphs.\nTo complement our theoretical analysis, we perform experiments with our\ndynamic algorithm on large-scale, real-world data-sets. Our algorithm\nsignificantly outperforms the state of the art [HWC17] both in terms of\naccuracy and efficiency.",
    "descriptor": "\nComments: Extended abstract appears in TheWebConf (previously WWW) 2022\n",
    "authors": [
      "Suman K. Bera",
      "Sayan Bhattacharya",
      "Jayesh Choudhari",
      "Prantar Ghosh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.08106"
  },
  {
    "id": "arXiv:2204.08107",
    "title": "Exploiting Embodied Simulation to Detect Novel Object Classes Through  Interaction",
    "abstract": "In this paper we present a novel method for a naive agent to detect novel\nobjects it encounters in an interaction. We train a reinforcement learning\npolicy on a stacking task given a known object type, and then observe the\nresults of the agent attempting to stack various other objects based on the\nsame trained policy. By extracting embedding vectors from a convolutional\nneural net trained over the results of the aforementioned stacking play, we can\ndetermine the similarity of a given object to known object types, and determine\nif the given object is likely dissimilar enough to the known types to be\nconsidered a novel class of object. We present the results of this method on\ntwo datasets gathered using two different policies and demonstrate what\ninformation the agent needs to extract from its environment to make these\nnovelty judgments.",
    "descriptor": "",
    "authors": [
      "Nikhil Krishnaswamy",
      "Sadaf Ghaffari"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08107"
  },
  {
    "id": "arXiv:2204.08108",
    "title": "How are Software Repositories Mined? A Systematic Literature Review of  Workflows, Methodologies, Reproducibility, and Tools",
    "abstract": "With the advent of open source software, a veritable treasure trove of\npreviously proprietary software development data was made available. This\nopened the field of empirical software engineering research to anyone in\nacademia. Data that is mined from software projects, however, requires\nextensive processing and needs to be handled with utmost care to ensure valid\nconclusions. Since the software development practices and tools have changed\nover two decades, we aim to understand the state-of-the-art research workflows\nand to highlight potential challenges. We employ a systematic literature review\nby sampling over one thousand papers from leading conferences and by analyzing\nthe 286 most relevant papers from the perspective of data workflows,\nmethodologies, reproducibility, and tools. We found that an important part of\nthe research workflow involving dataset selection was particularly problematic,\nwhich raises questions about the generality of the results in existing\nliterature. Furthermore, we found a considerable number of papers provide\nlittle or no reproducibility instructions -- a substantial deficiency for a\ndata-intensive field. In fact, 33% of papers provide no information on how\ntheir data was retrieved. Based on these findings, we propose ways to address\nthese shortcomings via existing tools and also provide recommendations to\nimprove research workflows and the reproducibility of research.",
    "descriptor": "\nComments: 11 Pages\n",
    "authors": [
      "Adam Tutko",
      "Austin Z. Henley",
      "Audris Mockus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.08108"
  },
  {
    "id": "arXiv:2204.08109",
    "title": "ArcaneQA: Dynamic Program Induction and Contextualized Encoding for  Knowledge Base Question Answering",
    "abstract": "Question answering on knowledge bases (KBQA) poses a unique challenge for\nsemantic parsing research due to two intertwined factors: large search space\nand ambiguities in schema linking. The predominant ranking-based KBQA models,\nwhich rely on a candidate enumeration step to reduce the search space, struggle\nwith flexibility and have impractical online running time. In this paper, we\npresent ArcaneQA, a novel generation-based model that addresses both the large\nsearch space and schema linking in a unified framework with two mutually\nboosting ingredients: we use dynamic program induction to tackle the large\nsearch space and dynamic contextualized encoding to enhance schema linking.\nExperiment results on multiple popular KBQA datasets demonstrate the highly\ncompetitive performance of ArcaneQA in both effectiveness and efficiency.",
    "descriptor": "",
    "authors": [
      "Yu Gu",
      "Yu Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08109"
  },
  {
    "id": "arXiv:2204.08110",
    "title": "Language Contamination Explains the Cross-lingual Capabilities of  English Pretrained Models",
    "abstract": "English pretrained language models, which make up the backbone of many modern\nNLP systems, require huge amounts of unlabeled training data. These models are\ngenerally presented as being trained only on English text but have been found\nto transfer surprisingly well to other languages. We investigate this\nphenomenon and find that common English pretraining corpora actually contain\nsignificant amounts of non-English text: even when less than 1% of data is not\nEnglish (well within the error rate of strong language classifiers), this leads\nto hundreds of millions of foreign language tokens in large-scale datasets. We\nthen demonstrate that even these small percentages of non-English data\nfacilitate cross-lingual transfer for models trained on them, with target\nlanguage performance strongly correlated to the amount of in-language data seen\nduring pretraining. In light of these findings, we argue that no model is truly\nmonolingual when pretrained at scale, which should be considered when\nevaluating cross-lingual transfer.",
    "descriptor": "",
    "authors": [
      "Terra Blevins",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08110"
  },
  {
    "id": "arXiv:2204.08114",
    "title": "A Distributed control framework for the optimal operation of DC  microgrids",
    "abstract": "In this paper we propose an original distributed control framework for DC\nmcirogrids. We first formulate the (optimal) control objectives as an\naggregative game suitable for the energy trading market. Then, based on the\ndual theory, we analyze the equivalent distributed optimal condition for the\nproposed aggregative game and design a distributed control scheme to solve it.\nBy interconnecting the DC mcirogrid and the designed distributed control system\nin a power preserving way, we steer the DC microgrid's state to the desired\noptimal equilibrium, satisfying a predefined set of local and coupling\nconstraints. Finally, based on the singular perturbation system theory, we\nanalyze the convergence of the closed-loop system. The simulation results show\nexcellent performance of the proposed control framework.",
    "descriptor": "",
    "authors": [
      "Zao Fu",
      "Michele Cucuzzella",
      "Carlo Cenedese",
      "Wenwu Yu",
      "Jacquelien M. A. Scherpen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.08114"
  },
  {
    "id": "arXiv:2204.08115",
    "title": "HFT-ONLSTM: Hierarchical and Fine-Tuning Multi-label Text Classification",
    "abstract": "Many important classification problems in the real-world consist of a large\nnumber of closely related categories in a hierarchical structure or taxonomy.\nHierarchical multi-label text classification (HMTC) with higher accuracy over\nlarge sets of closely related categories organized in a hierarchy or taxonomy\nhas become a challenging problem. In this paper, we present a hierarchical and\nfine-tuning approach based on the Ordered Neural LSTM neural network,\nabbreviated as HFT-ONLSTM, for more accurate level-by-level HMTC. First, we\npresent a novel approach to learning the joint embeddings based on parent\ncategory labels and textual data for accurately capturing the joint features of\nboth category labels and texts. Second, a fine tuning technique is adopted for\ntraining parameters such that the text classification results in the upper\nlevel should contribute to the classification in the lower one. At last, the\ncomprehensive analysis is made based on extensive experiments in comparison\nwith the state-of-the-art hierarchical and flat multi-label text classification\napproaches over two benchmark datasets, and the experimental results show that\nour HFT-ONLSTM approach outperforms these approaches, in particular reducing\ncomputational costs while achieving superior performance.",
    "descriptor": "\nComments: 31 pages, 8 tables, 4 figures\n",
    "authors": [
      "Pengfei Gao",
      "Jingpeng Zhao",
      "Yinglong Ma",
      "Ahmad Tanvir",
      "Beihong Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08115"
  },
  {
    "id": "arXiv:2204.08117",
    "title": "Fully-Decentralized Alternating Projected Gradient Descent for Low Rank  column-wise Compressive Sensing",
    "abstract": "This work develops a provably accurate fully-decentralized fast and\ncommunication-efficient alternating projected gradient descent (Dec-AltProjGD)\nalgorithm for solving the following low-rank (LR) matrix recovery problem:\nrecover an LR matrix from independent columnwise linear projections (LR\ncolumn-wise Compressive Sensing). To our best knowledge, this work is the first\nattempt to develop a provably correct decentralized algorithm for any problem\ninvolving use of an alternating projected GD algorithm and one in which the\nconstraint set to be projected to is a non-convex set.",
    "descriptor": "",
    "authors": [
      "Shana Moothedath",
      "Namrata Vaswani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08117"
  },
  {
    "id": "arXiv:2204.08118",
    "title": "On the Differential Properties of the Power Mapping $x^{p^m+2}$",
    "abstract": "Let $m$ be a positive integer and $p$ a prime. In this paper, we investigate\nthe differential properties of the power mapping $x^{p^m+2}$ over\n$\\mathbb{F}_{p^n}$, where $n=2m$ or $n=2m-1$. For the case $n=2m$, by\ntransforming the derivative equation of $x^{p^m+2}$ and studying some related\nequations, we completely determine the differential spectrum of this power\nmapping. For the case $n=2m-1$, the derivative equation can be transformed to a\npolynomial of degree $p+3$. The problem is more difficult and we obtain partial\nresults about the differential spectrum of $x^{p^m+2}$.",
    "descriptor": "",
    "authors": [
      "Yuying Man",
      "Yongbo Xia",
      "Chunlei Li",
      "Tor Helleseth"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08118"
  },
  {
    "id": "arXiv:2204.08119",
    "title": "Split Learning over Wireless Networks: Parallel Design and Resource  Management",
    "abstract": "Split learning (SL) is a collaborative learning framework, which can train an\nartificial intelligence (AI) model between a device and an edge server by\nsplitting the AI model into a device-side model and a server-side model at a\ncut layer. The existing SL approach conducts the training process sequentially\nacross devices, which incurs significant training latency especially when the\nnumber of devices is large. In this paper, we design a novel SL scheme to\nreduce the training latency, named Cluster-based Parallel SL (CPSL) which\nconducts model training in a \"first-parallel-then-sequential\" manner.\nSpecifically, the CPSL is to partition devices into several clusters,\nparallelly train device-side models in each cluster and aggregate them, and\nthen sequentially train the whole AI model across clusters, thereby\nparallelizing the training process and reducing training latency. Furthermore,\nwe propose a resource management algorithm to minimize the training latency of\nCPSL considering device heterogeneity and network dynamics in wireless\nnetworks. This is achieved by stochastically optimizing the cut layer\nselection, real-time device clustering, and radio spectrum allocation. The\nproposed two-timescale algorithm can jointly make the cut layer selection\ndecision in a large timescale and device clustering and radio spectrum\nallocation decisions in a small timescale. Extensive simulation results on\nnon-independent and identically distributed data demonstrate that the proposed\nsolutions can greatly reduce the training latency as compared with the existing\nSL benchmarks, while adapting to network dynamics.",
    "descriptor": "\nComments: The paper has been submitted to IEEE Journal on Selected Areas in Communications\n",
    "authors": [
      "Wen Wu",
      "Mushu Li",
      "Kaige Qu",
      "Conghao Zhou",
      "Xuemin",
      "Shen",
      "Weihua Zhuang",
      "Xu Li",
      "Weisen Shi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.08119"
  },
  {
    "id": "arXiv:2204.08120",
    "title": "Neural Gaits: Learning Bipedal Locomotion via Control Barrier Functions  and Zero Dynamics Policies",
    "abstract": "This work presents Neural Gaits, a method for learning dynamic walking gaits\nthrough the enforcement of set invariance that can be refined episodically\nusing experimental data from the robot. We frame walking as a set invariance\nproblem enforceable via control barrier functions (CBFs) defined on the\nreduced-order dynamics quantifying the underactuated component of the robot:\nthe zero dynamics. Our approach contains two learning modules: one for learning\na policy that satisfies the CBF condition, and another for learning a residual\ndynamics model to refine imperfections of the nominal model. Importantly,\nlearning only over the zero dynamics significantly reduces the dimensionality\nof the learning problem while using CBFs allows us to still make guarantees for\nthe full-order system. The method is demonstrated experimentally on an\nunderactuated bipedal robot, where we are able to show agile and dynamic\nlocomotion, even with partially unknown dynamics.",
    "descriptor": "",
    "authors": [
      "Ivan Dario Jimenez Rodriguez",
      "Noel Csomay-Shanklin",
      "Yisong Yue",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.08120"
  },
  {
    "id": "arXiv:2204.08121",
    "title": "End-to-end Dense Video Captioning as Sequence Generation",
    "abstract": "Dense video captioning aims to identify the events of interest in an input\nvideo, and generate descriptive captions for each event. Previous approaches\nusually follow a two-stage generative process, which first proposes a segment\nfor each event, then renders a caption for each identified segment. Recent\nadvances in large-scale sequence generation pretraining have seen great success\nin unifying task formulation for a great variety of tasks, but so far, more\ncomplex tasks such as dense video captioning are not able to fully utilize this\npowerful paradigm. In this work, we show how to model the two subtasks of dense\nvideo captioning jointly as one sequence generation task, and simultaneously\npredict the events and the corresponding descriptions. Experiments on YouCook2\nand ViTT show encouraging results and indicate the feasibility of training\ncomplex tasks such as end-to-end dense video captioning integrated into\nlarge-scale pre-trained models.",
    "descriptor": "",
    "authors": [
      "Wanrong Zhu",
      "Bo Pang",
      "Ashish Thapliyal",
      "William Yang Wang",
      "Radu Soricut"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08121"
  },
  {
    "id": "arXiv:2204.08123",
    "title": "Non-Parallel Text Style Transfer with Self-Parallel Supervision",
    "abstract": "The performance of existing text style transfer models is severely limited by\nthe non-parallel datasets on which the models are trained. In non-parallel\ndatasets, no direct mapping exists between sentences of the source and target\nstyle; the style transfer models thus only receive weak supervision of the\ntarget sentences during training, which often leads the model to discard too\nmuch style-independent information, or utterly fail to transfer the style. In\nthis work, we propose LaMer, a novel text style transfer framework based on\nlarge-scale language models. LaMer first mines the roughly parallel expressions\nin the non-parallel datasets with scene graphs, and then employs MLE training,\nfollowed by imitation learning refinement, to leverage the intrinsic\nparallelism within the data. On two benchmark tasks (sentiment & formality\ntransfer) and a newly proposed challenging task (political stance transfer),\nour model achieves qualitative advances in transfer accuracy, content\npreservation, and fluency. Further empirical and human evaluations demonstrate\nthat our model not only makes training more efficient, but also generates more\nreadable and diverse expressions than previous models.",
    "descriptor": "\nComments: In ICLR 2022\n",
    "authors": [
      "Ruibo Liu",
      "Chongyang Gao",
      "Chenyan Jia",
      "Guangxuan Xu",
      "Soroush Vosoughi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08123"
  },
  {
    "id": "arXiv:2204.08125",
    "title": "FedKL: Tackling Data Heterogeneity in Federated Reinforcement Learning  by Penalizing KL Divergence",
    "abstract": "As a distributed learning paradigm, Federated Learning (FL) faces the\ncommunication bottleneck issue due to many rounds of model synchronization and\naggregation. Heterogeneous data further deteriorates the situation by causing\nslow convergence. Although the impact of data heterogeneity on supervised FL\nhas been widely studied, the related investigation for Federated Reinforcement\nLearning (FRL) is still in its infancy. In this paper, we first define the type\nand level of data heterogeneity for policy gradient based FRL systems. By\ninspecting the connection between the global and local objective functions, we\nprove that local training can benefit the global objective, if the local update\nis properly penalized by the total variation (TV) distance between the local\nand global policies. A necessary condition for the global policy to be\nlearn-able from the local policy is also derived, which is directly related to\nthe heterogeneity level. Based on the theoretical result, a Kullback-Leibler\n(KL) divergence based penalty is proposed, which, different from the\nconventional method that penalizes the model divergence in the parameter space,\ndirectly constrains the model outputs in the distribution space. By jointly\npenalizing the divergence of the local policy from the global policy with a\nglobal penalty and constraining each iteration of the local training with a\nlocal penalty, the proposed method achieves a better trade-off between training\nspeed (step size) and convergence. Experiment results on two popular RL\nexperiment platforms demonstrate the advantage of the proposed algorithm over\nexisting methods in accelerating and stabilizing the training process with\nheterogeneous data.",
    "descriptor": "",
    "authors": [
      "Zhijie Xie",
      "S.H. Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08125"
  },
  {
    "id": "arXiv:2204.08128",
    "title": "Less is More: Learning to Refine Dialogue History for Personalized  Dialogue Generation",
    "abstract": "Personalized dialogue systems explore the problem of generating responses\nthat are consistent with the user's personality, which has raised much\nattention in recent years. Existing personalized dialogue systems have tried to\nextract user profiles from dialogue history to guide personalized response\ngeneration. Since the dialogue history is usually long and noisy, most existing\nmethods truncate the dialogue history to model the user's personality. Such\nmethods can generate some personalized responses, but a large part of dialogue\nhistory is wasted, leading to sub-optimal performance of personalized response\ngeneration. In this work, we propose to refine the user dialogue history on a\nlarge scale, based on which we can handle more dialogue history and obtain more\nabundant and accurate persona information. Specifically, we design an MSP model\nwhich consists of three personal information refiners and a personalized\nresponse generator. With these multi-level refiners, we can sparsely extract\nthe most valuable information (tokens) from the dialogue history and leverage\nother similar users' data to enhance personalization. Experimental results on\ntwo real-world datasets demonstrate the superiority of our model in generating\nmore informative and personalized responses.",
    "descriptor": "\nComments: Accepted by NAACL 2022 Main Conference\n",
    "authors": [
      "Hanxun Zhong",
      "Zhicheng Dou",
      "Yutao Zhu",
      "Hongjin Qian",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08128"
  },
  {
    "id": "arXiv:2204.08129",
    "title": "Animal Kingdom: A Large and Diverse Dataset for Animal Behavior  Understanding",
    "abstract": "Understanding animals' behaviors is significant for a wide range of\napplications. However, existing animal behavior datasets have limitations in\nmultiple aspects, including limited numbers of animal classes, data samples and\nprovided tasks, and also limited variations in environmental conditions and\nviewpoints. To address these limitations, we create a large and diverse\ndataset, Animal Kingdom, that provides multiple annotated tasks to enable a\nmore thorough understanding of natural animal behaviors. The wild animal\nfootages used in our dataset record different times of the day in extensive\nrange of environments containing variations in backgrounds, viewpoints,\nillumination and weather conditions. More specifically, our dataset contains 50\nhours of annotated videos to localize relevant animal behavior segments in long\nvideos for the video grounding task, 30K video sequences for the fine-grained\nmulti-label action recognition task, and 33K frames for the pose estimation\ntask, which correspond to a diverse range of animals with 850 species across 6\nmajor animal classes. Such a challenging and comprehensive dataset shall be\nable to facilitate the community to develop, adapt, and evaluate various types\nof advanced methods for animal behavior analysis. Moreover, we propose a\nCollaborative Action Recognition (CARe) model that learns general and specific\nfeatures for action recognition with unseen new animals. This method achieves\npromising performance in our experiments. Our dataset can be found at\nhttps://sutdcv.github.io/Animal-Kingdom.",
    "descriptor": "\nComments: Accepted by CVPR2022 (Oral). Dataset: this https URL\n",
    "authors": [
      "Xun Long Ng",
      "Kian Eng Ong",
      "Qichen Zheng",
      "Yun Ni",
      "Si Yong Yeo",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08129"
  },
  {
    "id": "arXiv:2204.08134",
    "title": "A Practical Cross-Device Federated Learning Framework over 5G Networks",
    "abstract": "The concept of federated learning (FL) was first proposed by Google in 2016.\nThereafter, FL has been widely studied for the feasibility of application in\nvarious fields due to its potential to make full use of data without\ncompromising the privacy. However, limited by the capacity of wireless data\ntransmission, the employment of federated learning on mobile devices has been\nmaking slow progress in practical. The development and commercialization of the\n5th generation (5G) mobile networks has shed some light on this. In this paper,\nwe analyze the challenges of existing federated learning schemes for mobile\ndevices and propose a novel cross-device federated learning framework, which\nutilizes the anonymous communication technology and ring signature to protect\nthe privacy of participants while reducing the computation overhead of mobile\ndevices participating in FL. In addition, our scheme implements a\ncontribution-based incentive mechanism to encourage mobile users to participate\nin FL. We also give a case study of autonomous driving. Finally, we present the\nperformance evaluation of the proposed scheme and discuss some open issues in\nfederated learning.",
    "descriptor": "\nComments: This paper has been accepted by IEEE Wireless Communications\n",
    "authors": [
      "Wenti Yang",
      "Naiyu Wang",
      "Zhitao Guan",
      "Longfei Wu",
      "Xiaojiang Du",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.08134"
  },
  {
    "id": "arXiv:2204.08135",
    "title": "On Secure NOMA-Aided Semi-Grant-Free Systems",
    "abstract": "Semi-grant-free (SGF) transmission scheme enables grant-free (GF) users to\nutilize resource blocks allocated for grant-based (GB) users while maintaining\nthe quality of service of GB users. This work investigates the secrecy\nperformance of non-orthogonal multiple access (NOMA)-aided SGF systems. First,\nanalytical expressions for the exact and asymptotic secrecy outage probability\n(SOP) of NOMA-aided SGF systems with a single GF user are derived. Then, the\nSGF systems with multiple GF users and a best-user scheduling scheme is\nconsidered. By utilizing order statistics theory, closed-form expressions for\nthe exact and asymptotic SOP are derived. Monte Carlo simulation results\ndemonstrate the effects of system parameters on the SOP of the considered\nsystem and verify the accuracy of the developed analytical results. The results\nindicate that both the outage target rate for GB and the secure target rate for\nGF are the main factors of the secrecy performance of SGF systems.",
    "descriptor": "",
    "authors": [
      "Hongjiang Lei",
      "Fangtao Yang",
      "Hongwu Liu",
      "Imran Shafique Ansari",
      "Kyeong Jin Kim",
      "Theodoros A. Tsiftsis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08135"
  },
  {
    "id": "arXiv:2204.08136",
    "title": "Trinary Tools for Continuously Valued Binary Classifiers",
    "abstract": "Classification methods for binary (yes/no) tasks often produce a continuously\nvalued score. Machine learning practitioners must perform model selection,\ncalibration, discretization, performance assessment, tuning, and fairness\nassessment. Such tasks involve examining classifier results, typically using\nsummary statistics and manual examination of details. In this paper, we provide\nan interactive visualization approach to support such continuously-valued\nclassifier examination tasks. Our approach addresses the three phases of these\ntasks: calibration, operating point selection, and examination. We enhance\nstandard views and introduce task-specific views so that they can be integrated\ninto a multi-view coordination (MVC) system. We build on an existing\ncomparison-based approach, extending it to continuous classifiers by treating\nthe continuous values as trinary (positive, unsure, negative) even if the\nclassifier will not ultimately use the 3-way classification. We provide use\ncases that demonstrate how our approach enables machine learning practitioners\nto accomplish key tasks.",
    "descriptor": "\nComments: Author's version of journal paper accepted to appear\n",
    "authors": [
      "Michael Gleicher",
      "Xinyi Yu",
      "Yuheng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.08136"
  },
  {
    "id": "arXiv:2204.08137",
    "title": "Ingredient Extraction from Text in the Recipe Domain",
    "abstract": "In recent years, there has been an increase in the number of devices with\nvirtual assistants (e.g: Siri, Google Home, Alexa) in our living rooms and\nkitchens. As a result of this, these devices receive several queries about\nrecipes. All these queries will contain terms relating to a \"recipe-domain\"\ni.e: they will contain dish-names, ingredients, cooking times, dietary\npreferences etc. Extracting these recipe-relevant aspects from the query thus\nbecomes important when it comes to addressing the user's information need. Our\nproject focuses on extracting ingredients from such plain-text user utterances.\nOur best performing model was a fine-tuned BERT which achieved an F1-score of\n$95.01$. We have released all our code in a GitHub repository.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Arkin Dharawat",
      "Chris Doan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08137"
  },
  {
    "id": "arXiv:2204.08139",
    "title": "A Deep Learning Galerkin Method for the Closed-Loop Geothermal System",
    "abstract": "There has been an arising trend of adopting deep learning methods to study\npartial differential equations (PDEs). This article is to propose a Deep\nLearning Galerkin Method (DGM) for the closed-loop geothermal system, which is\na new coupled multi-physics PDEs and mainly consists of a framework of\nunderground heat exchange pipelines to extract the geothermal heat from the\ngeothermal reservoir. This method is a natural combination of Galerkin Method\nand machine learning with the solution approximated by a neural network instead\nof a linear combination of basis functions. We train the neural network by\nrandomly sampling the spatiotemporal points and minimize loss function to\nsatisfy the differential operators, initial condition, boundary and interface\nconditions. Moreover, the approximate ability of the neural network is proved\nby the convergence of the loss function and the convergence of the neural\nnetwork to the exact solution in L^2 norm under certain conditions. Finally,\nsome numerical examples are carried out to demonstrate the approximation\nability of the neural networks intuitively.",
    "descriptor": "\nComments: 29 pages, 7 figures, 1 tables\n",
    "authors": [
      "Wen Zhang",
      "Jian Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.08139"
  },
  {
    "id": "arXiv:2204.08140",
    "title": "Pricing Real-time Stochastic Storage Operations",
    "abstract": "Pricing storage operation in the real-time market under demand and generation\nstochasticities is considered. A scenario-based stochastic rolling-window\ndispatch model is formulated for the real-time market, consisting of\nconventional generators, utility-scale storage, and distributed energy resource\naggregators. We show that uniform pricing mechanisms require discriminative\nout-of-the-market uplifts, making settlements under locational marginal pricing\n(LMP) discriminative. It is shown that the temporal locational marginal pricing\n(TLMP) that adds nonuniform shadow prices of ramping and state-of-charge to LMP\nremoves the need for out-of-the-market uplifts. Truthful bidding incentives are\nalso established for price-taking participants under TLMP. Revenue adequacy and\nuplifts are evaluated in numerical simulations.",
    "descriptor": "\nComments: 8 pages, 4 figures, 2022 Power Systems Computation Conference (PSCC)\n",
    "authors": [
      "Cong Chen",
      "Lang Tong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.08140"
  },
  {
    "id": "arXiv:2204.08142",
    "title": "Dynamic Position Encoding for Transformers",
    "abstract": "Recurrent models have been dominating the field of neural machine translation\n(NMT) for the past few years. Transformers \\citep{vaswani2017attention}, have\nradically changed it by proposing a novel architecture that relies on a\nfeed-forward backbone and self-attention mechanism. Although Transformers are\npowerful, they could fail to properly encode sequential/positional information\ndue to their non-recurrent nature. To solve this problem, position embeddings\nare defined exclusively for each time step to enrich word information. However,\nsuch embeddings are fixed after training regardless of the task and the word\nordering system of the source or target language.\nIn this paper, we propose a novel architecture with new position embeddings\ndepending on the input text to address this shortcoming by taking the order of\ntarget words into consideration. Instead of using predefined position\nembeddings, our solution \\textit{generates} new embeddings to refine each\nword's position information. Since we do not dictate the position of source\ntokens and learn them in an end-to-end fashion, we refer to our method as\n\\textit{dynamic} position encoding (DPE). We evaluated the impact of our model\non multiple datasets to translate from English into German, French, and Italian\nand observed meaningful improvements in comparison to the original Transformer.",
    "descriptor": "",
    "authors": [
      "Joyce Zheng",
      "Mehdi Rezagholizadeh",
      "Peyman Passban"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08142"
  },
  {
    "id": "arXiv:2204.08143",
    "title": "Detect Rumors in Microblog Posts for Low-Resource Domains via  Adversarial Contrastive Learning",
    "abstract": "Massive false rumors emerging along with breaking news or trending topics\nseverely hinder the truth. Existing rumor detection approaches achieve\npromising performance on the yesterday`s news, since there is enough corpus\ncollected from the same domain for model training. However, they are poor at\ndetecting rumors about unforeseen events especially those propagated in\ndifferent languages due to the lack of training data and prior knowledge (i.e.,\nlow-resource regimes). In this paper, we propose an adversarial contrastive\nlearning framework to detect rumors by adapting the features learned from\nwell-resourced rumor data to that of the low-resourced. Our model explicitly\novercomes the restriction of domain and/or language usage via language\nalignment and a novel supervised contrastive training paradigm. Moreover, we\ndevelop an adversarial augmentation mechanism to further enhance the robustness\nof low-resource rumor representation. Extensive experiments conducted on two\nlow-resource datasets collected from real-world microblog platforms demonstrate\nthat our framework achieves much better performance than state-of-the-art\nmethods and exhibits a superior capacity for detecting rumors at early stages.",
    "descriptor": "\nComments: The first study for the low-resource rumor detection on social media in cross-domain and cross-lingual settings\n",
    "authors": [
      "Hongzhan Lin",
      "Jing Ma",
      "Liangliang Chen",
      "Zhiwei Yang",
      "Mingfei Cheng",
      "Guang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08143"
  },
  {
    "id": "arXiv:2204.08146",
    "title": "PrivateRec: Differentially Private Training and Serving for Federated  News Recommendation",
    "abstract": "Privacy protection is an essential issue in personalized news recommendation,\nand federated learning can potentially mitigate the privacy concern by training\npersonalized news recommendation models over decentralized user data.For a\ntheoretical privacy guarantee, differential privacy is necessary. However,\napplying differential privacy to federated recommendation training and serving\nconventionally suffers from the unsatisfactory trade-off between privacy and\nutility due to the high-dimensional characteristics of model gradients and\nhidden representations. In addition, there is no formal privacy guarantee for\nboth training and serving in federated recommendation. In this paper, we\npropose a unified federated news recommendation method for effective and\nprivacy-preserving model training and online serving with differential privacy\nguarantees. We first clarify the notion of differential privacy over users'\nbehavior data for both model training and online serving in the federated\nrecommendation scenario. Next, we propose a privacy-preserving online serving\nmechanism under this definition with differentially private user interest\ndecomposition. More specifically, it decomposes the high-dimensional and\nprivacy-sensitive user embedding into a combination of public basic vectors and\nadds noise to the combination coefficients. In this way, it can avoid the\ndimension curse and improve the utility by reducing the required noise\nintensity for differential privacy. Besides, we design a federated\nrecommendation model training method with differential privacy, which can avoid\nthe dimension-dependent noise for large models via label permutation and\ndifferentially private attention modules. Experiments on real-world news\nrecommendation datasets validate the effectiveness of our method in achieving a\ngood trade-off between privacy protection and utility for federated news\nrecommendations.",
    "descriptor": "",
    "authors": [
      "Ruixuan Liu",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Yanlin Wang",
      "Yang Cao",
      "Lingjuan Lyu",
      "Weike Pan",
      "Yun Chen",
      "Hong Chen",
      "Xing Xie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.08146"
  },
  {
    "id": "arXiv:2204.08150",
    "title": "Characterizing and Understanding Distributed GNN Training on GPUs",
    "abstract": "Graph neural network (GNN) has been demonstrated to be a powerful model in\nmany domains for its effectiveness in learning over graphs. To scale GNN\ntraining for large graphs, a widely adopted approach is distributed training\nwhich accelerates training using multiple computing nodes. Maximizing the\nperformance is essential, but the execution of distributed GNN training remains\npreliminarily understood. In this work, we provide an in-depth analysis of\ndistributed GNN training on GPUs, revealing several significant observations\nand providing useful guidelines for both software optimization and hardware\noptimization.",
    "descriptor": "\nComments: To Appear in IEEE Computer Architecture Letters (CAL) 2022\n",
    "authors": [
      "Haiyang Lin",
      "Mingyu Yan",
      "Xiaocheng Yang",
      "Mo Zou",
      "Wenming Li",
      "Xiaochun Ye",
      "Dongrui Fan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08150"
  },
  {
    "id": "arXiv:2204.08152",
    "title": "Back to the Future: Bidirectional Information Decoupling Network for  Multi-turn Dialogue Modeling",
    "abstract": "Multi-turn dialogue modeling as a challenging branch of natural language\nunderstanding (NLU), aims to build representations for machines to understand\nhuman dialogues, which provides a solid foundation for multiple downstream\ntasks. Recent studies of dialogue modeling commonly employ pre-trained language\nmodels (PrLMs) to encode the dialogue history as successive tokens, which is\ninsufficient in capturing the temporal characteristics of dialogues. Therefore,\nwe propose Bidirectional Information Decoupling Network (BiDeN) as a universal\ndialogue encoder, which explicitly incorporates both the past and future\ncontexts and can be generalized to a wide range of dialogue-related tasks.\nExperimental results on datasets of different downstream tasks demonstrate the\nuniversality and effectiveness of our BiDeN.",
    "descriptor": "",
    "authors": [
      "Yiyang Li",
      "Hai Zhao",
      "Zhuosheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08152"
  },
  {
    "id": "arXiv:2204.08154",
    "title": "End-to-end Weakly-supervised Multiple 3D Hand Mesh Reconstruction from  Single Image",
    "abstract": "In this paper, we consider the challenging task of simultaneously locating\nand recovering multiple hands from single 2D image. Previous studies either\nfocus on single hand reconstruction or solve this problem in a multi-stage way.\nMoreover, the conventional two-stage pipeline firstly detects hand areas, and\nthen estimates 3D hand pose from each cropped patch. To reduce the\ncomputational redundancy in preprocessing and feature extraction, we propose a\nconcise but efficient single-stage pipeline. Specifically, we design a\nmulti-head auto-encoder structure for multi-hand reconstruction, where each\nhead network shares the same feature map and outputs the hand center, pose and\ntexture, respectively. Besides, we adopt a weakly-supervised scheme to\nalleviate the burden of expensive 3D real-world data annotations. To this end,\nwe propose a series of losses optimized by a stage-wise training scheme, where\na multi-hand dataset with 2D annotations is generated based on the publicly\navailable single hand datasets. In order to further improve the accuracy of the\nweakly supervised model, we adopt several feature consistency constraints in\nboth single and multiple hand settings. Specifically, the keypoints of each\nhand estimated from local features should be consistent with the re-projected\npoints predicted from global features. Extensive experiments on public\nbenchmarks including FreiHAND, HO3D, InterHand2.6M and RHD demonstrate that our\nmethod outperforms the state-of-the-art model-based methods in both\nweakly-supervised and fully-supervised manners.",
    "descriptor": "",
    "authors": [
      "Jinwei Ren",
      "Jianke Zhu",
      "Jialiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08154"
  },
  {
    "id": "arXiv:2204.08156",
    "title": "Interaction Design of Dwell Selection Toward Gaze-based AR/VR  Interaction",
    "abstract": "In this paper, we first position the current dwell selection among gaze-based\ninteractions and its advantages against head-gaze selection, which is the\nmainstream interface for HMDs. Next, we show how dwell selection and head-gaze\nselection are used in an actual interaction situation. By comparing these two\nselection methods, we describe the potential of dwell selection as an essential\nAR/VR interaction.",
    "descriptor": "\nComments: 2 pages, 1 figures\n",
    "authors": [
      "Toshiya Isomoto",
      "Shota Yamanaka",
      "Buntarou Shizuki"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.08156"
  },
  {
    "id": "arXiv:2204.08159",
    "title": "Multi-scale Anomaly Detection for Big Time Series of Industrial Sensors",
    "abstract": "Given a multivariate big time series, can we detect anomalies as soon as they\noccur? Many existing works detect anomalies by learning how much a time series\ndeviates away from what it should be in the reconstruction framework. However,\nmost models have to cut the big time series into small pieces empirically since\noptimization algorithms cannot afford such a long series. The question is\nraised: do such cuts pollute the inherent semantic segments, like incorrect\npunctuation in sentences? Therefore, we propose a reconstruction-based anomaly\ndetection method, MissGAN, iteratively learning to decode and encode naturally\nsmooth time series in coarse segments, and finding out a finer segment from\nlow-dimensional representations based on HMM. As a result, learning from\nmulti-scale segments, MissGAN can reconstruct a meaningful and robust time\nseries, with the help of adversarial regularization and extra conditional\nstates. MissGAN does not need labels or only needs labels of normal instances,\nmaking it widely applicable. Experiments on industrial datasets of real water\nnetwork sensors show our MissGAN outperforms the baselines with scalability.\nBesides, we use a case study on the CMU Motion dataset to demonstrate that our\nmodel can well distinguish unexpected gestures from a given conditional motion.",
    "descriptor": "",
    "authors": [
      "Quan Ding",
      "Shenghua Liu",
      "Bin Zhou",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08159"
  },
  {
    "id": "arXiv:2204.08163",
    "title": "Mapping While Following: 2D LiDAR SLAM in Indoor Dynamic Environments  with a Person Tracker",
    "abstract": "2D LiDAR SLAM (Simultaneous Localization and Mapping) is widely used in\nindoor environments due to its stability and flexibility. However, its mapping\nprocedure is usually operated by a joystick in static environments, while\nindoor environments often are dynamic with moving objects such as people. The\ngenerated map with noisy points due to the dynamic objects is usually\nincomplete and distorted. To address this problem, we propose a framework of\n2D-LiDAR-based SLAM without manual control that effectively excludes dynamic\nobjects (people) and simplify the process for a robot to map an environment.\nThe framework, which includes three parts: people tracking, filtering and\nfollowing. We verify our proposed framework in experiments with two classic\n2D-LiDAR-based SLAM algorithms in indoor environments. The results show that\nthis framework is effective in handling dynamic objects and reducing the\nmapping error.",
    "descriptor": "\nComments: Presented at 2021 IEEE International Conference on Robotics and Biomimetics (ROBIO)\n",
    "authors": [
      "Hanjing Ye",
      "Guangcheng Chen",
      "Weinan Chen",
      "Li He",
      "Yisheng Guan",
      "Hong Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.08163"
  },
  {
    "id": "arXiv:2204.08164",
    "title": "Robust End-to-end Speaker Diarization with Generic Neural Clustering",
    "abstract": "End-to-end speaker diarization approaches have shown exceptional performance\nover the traditional modular approaches. To further improve the performance of\nthe end-to-end speaker diarization for real speech recordings, recently works\nhave been proposed which integrate unsupervised clustering algorithms with the\nend-to-end neural diarization models. However, these methods have a number of\ndrawbacks: 1) The unsupervised clustering algorithms cannot leverage the\nsupervision from the available datasets; 2) The K-means-based unsupervised\nalgorithms that are explored often suffer from the constraint violation\nproblem; 3) There is unavoidable mismatch between the supervised training and\nthe unsupervised inference. In this paper, a robust generic neural clustering\napproach is proposed that can be integrated with any chunk-level predictor to\naccomplish a fully supervised end-to-end speaker diarization model. Also, by\nleveraging the sequence modelling ability of a recurrent neural network, the\nproposed neural clustering approach can dynamically estimate the number of\nspeakers during inference. Experimental show that when integrating an\nattractor-based chunk-level predictor, the proposed neural clustering approach\ncan yield better Diarization Error Rate (DER) than the constrained\nK-means-based clustering approaches under the mismatched conditions.",
    "descriptor": "\nComments: submitted to INTERSPEECH 2022\n",
    "authors": [
      "Chenyu Yang",
      "Yu Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.08164"
  },
  {
    "id": "arXiv:2204.08166",
    "title": "TOD-CNN: An Effective Convolutional Neural Network for Tiny Object  Detection in Sperm Videos",
    "abstract": "The detection of tiny objects in microscopic videos is a problematic point,\nespecially in large-scale experiments. For tiny objects (such as sperms) in\nmicroscopic videos, current detection methods face challenges in fuzzy,\nirregular, and precise positioning of objects. In contrast, we present a\nconvolutional neural network for tiny object detection (TOD-CNN) with an\nunderlying data set of high-quality sperm microscopic videos (111 videos, $>$\n278,000 annotated objects), and a graphical user interface (GUI) is designed to\nemploy and test the proposed model effectively. TOD-CNN is highly accurate,\nachieving $85.60\\%$ AP$_{50}$ in the task of real-time sperm detection in\nmicroscopic videos. To demonstrate the importance of sperm detection technology\nin sperm quality analysis, we carry out relevant sperm quality evaluation\nmetrics and compare them with the diagnosis results from medical doctors.",
    "descriptor": "\nComments: 17 pages, 12 figures\n",
    "authors": [
      "Shuojia Zou",
      "Chen Li",
      "Hongzan Sun",
      "Peng Xu",
      "Jiawei Zhang",
      "Pingli Ma",
      "Yudong Yao",
      "Xinyu Huang",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08166"
  },
  {
    "id": "arXiv:2204.08167",
    "title": "A Study on Prompt-based Few-Shot Learning Methods for Belief State  Tracking in Task-oriented Dialog Systems",
    "abstract": "We tackle the Dialogue Belief State Tracking(DST) problem of task-oriented\nconversational systems. Recent approaches to this problem leveraging\nTransformer-based models have yielded great results. However, training these\nmodels is expensive, both in terms of computational resources and time.\nAdditionally, collecting high quality annotated dialogue datasets remains a\nchallenge for researchers because of the extensive annotation required for\ntraining these models. Driven by the recent success of pre-trained language\nmodels and prompt-based learning, we explore prompt-based few-shot learning for\nDialogue Belief State Tracking. We formulate the DST problem as a 2-stage\nprompt-based language modelling task and train language models for both tasks\nand present a comprehensive empirical analysis of their separate and joint\nperformance. We demonstrate the potential of prompt-based methods in few-shot\nlearning for DST and provide directions for future improvement.",
    "descriptor": "\nComments: 9 pages, 12 figures\n",
    "authors": [
      "Debjoy Saha",
      "Bishal Santra",
      "Pawan Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08167"
  },
  {
    "id": "arXiv:2204.08169",
    "title": "Actions at the Edge: Jointly Optimizing the Resources in Multi-access  Edge Computing",
    "abstract": "Multi-access edge computing (MEC) is an emerging paradigm that pushes\nresources for sensing, communications, computing, storage and intelligence\n(SCCSI) to the premises closer to the end users, i.e., the edge, so that they\ncould leverage the nearby rich resources to improve their quality of experience\n(QoE). Due to the growing emerging applications targeting at intelligentizing\nlife-sustaining cyber-physical systems, this paradigm has become a hot research\ntopic, particularly when MEC is utilized to provide edge intelligence and\nreal-time processing and control. This article is to elaborate the research\nissues along this line, including basic concepts and performance metrics,\nkiller applications, architectural design, modeling approaches and solutions,\nand future research directions. It is hoped that this article provides a quick\nintroduction to this fruitful research area particularly for beginning\nresearchers.",
    "descriptor": "\nComments: 7 pages, 2 figures, accepted by IEEE Wireless Communications\n",
    "authors": [
      "Yiqin Deng",
      "Xianhao Chen",
      "Guangyu Zhu",
      "Yuguang Fang",
      "Zhigang Chen",
      "Xiaoheng Deng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.08169"
  },
  {
    "id": "arXiv:2204.08171",
    "title": "Distributed Neural Precoding for Hybrid mmWave MIMO Communications with  Limited Feedback",
    "abstract": "Hybrid precoding is a cost-efficient technique for millimeter wave (mmWave)\nmassive multiple-input multiple-output (MIMO) communications. This paper\nproposes a deep learning approach by using a distributed neural network for\nhybrid analog-and-digital precoding design with limited feedback. The proposed\ndistributed neural precoding network, called DNet, is committed to achieving\ntwo objectives. First, the DNet realizes channel state information (CSI)\ncompression with a distributed architecture of neural networks, which enables\npractical deployment on multiple users. Specifically, this neural network is\ncomposed of multiple independent sub-networks with the same structure and\nparameters, which reduces both the number of training parameters and network\ncomplexity. Secondly, DNet learns the calculation of hybrid precoding from\nreconstructed CSI from limited feedback. Different from existing black-box\nneural network design, the DNet is specifically designed according to the data\nform of the matrix calculation of hybrid precoding. Simulation results show\nthat the proposed DNet significantly improves the performance up to nearly 50%\ncompared to traditional limited feedback precoding methods under the tests with\nvarious CSI compression ratios.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Kai Wei",
      "Jindan Xu",
      "Wei Xu",
      "Ning Wang",
      "Dong Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.08171"
  },
  {
    "id": "arXiv:2204.08173",
    "title": "TABi: Type-Aware Bi-Encoders for Open-Domain Entity Retrieval",
    "abstract": "Entity retrieval--retrieving information about entity mentions in a query--is\na key step in open-domain tasks, such as question answering or fact checking.\nHowever, state-of-the-art entity retrievers struggle to retrieve rare entities\nfor ambiguous mentions due to biases towards popular entities. Incorporating\nknowledge graph types during training could help overcome popularity biases,\nbut there are several challenges: (1) existing type-based retrieval methods\nrequire mention boundaries as input, but open-domain tasks run on unstructured\ntext, (2) type-based methods should not compromise overall performance, and (3)\ntype-based methods should be robust to noisy and missing types. In this work,\nwe introduce TABi, a method to jointly train bi-encoders on knowledge graph\ntypes and unstructured text for entity retrieval for open-domain tasks. TABi\nleverages a type-enforced contrastive loss to encourage entities and queries of\nsimilar types to be close in the embedding space. TABi improves retrieval of\nrare entities on the Ambiguous Entity Retrieval (AmbER) sets, while maintaining\nstrong overall retrieval performance on open-domain tasks in the KILT benchmark\ncompared to state-of-the-art retrievers. TABi is also robust to incomplete type\nsystems, improving rare entity retrieval over baselines with only 5% type\ncoverage of the training dataset. We make our code publicly available at\nhttps://github.com/HazyResearch/tabi.",
    "descriptor": "\nComments: Accepted to Findings of ACL 2022\n",
    "authors": [
      "Megan Leszczynski",
      "Daniel Y. Fu",
      "Mayee F. Chen",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08173"
  },
  {
    "id": "arXiv:2204.08175",
    "title": "Usage of specific attention improves change point detection",
    "abstract": "The change point is a moment of an abrupt alteration in the data\ndistribution. Current methods for change point detection are based on recurrent\nneural methods suitable for sequential data. However, recent works show that\ntransformers based on attention mechanisms perform better than standard\nrecurrent models for many tasks. The most benefit is noticeable in the case of\nlonger sequences. In this paper, we investigate different attentions for the\nchange point detection task and proposed specific form of attention related to\nthe task at hand. We show that using a special form of attention outperforms\nstate-of-the-art results.",
    "descriptor": "",
    "authors": [
      "Anna Dmitrienko",
      "Evgenia Romanenkova",
      "Alexey Zaytsev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08175"
  },
  {
    "id": "arXiv:2204.08176",
    "title": "HRCF: Enhancing Collaborative Filtering via Hyperbolic Geometric  Regularization",
    "abstract": "In large-scale recommender systems, the user-item networks are generally\nscale-free or expand exponentially. The latent features (also known as\nembeddings) used to describe the user and item are determined by how well the\nembedding space fits the data distribution. Hyperbolic space offers a spacious\nroom to learn embeddings with its negative curvature and metric properties,\nwhich can well fit data with tree-like structures. Recently, several hyperbolic\napproaches have been proposed to learn high-quality representations for the\nusers and items. However, most of them concentrate on developing the hyperbolic\nsimilitude by designing appropriate projection operations, whereas many\nadvantageous and exciting geometric properties of hyperbolic space have not\nbeen explicitly explored. For example, one of the most notable properties of\nhyperbolic space is that its capacity space increases exponentially with the\nradius, which indicates the area far away from the hyperbolic origin is much\nmore embeddable. Regarding the geometric properties of hyperbolic space, we\nbring up a \\textit{Hyperbolic Regularization powered Collaborative Filtering}\n(HRCF) and design a geometric-aware hyperbolic regularizer. Specifically, the\nproposal boosts optimization procedure via the root alignment and origin-aware\npenalty, which is simple yet impressively effective. Through theoretical\nanalysis, we further show that our proposal is able to tackle the\nover-smoothing problem caused by hyperbolic aggregation and also brings the\nmodels a better discriminative ability. We conduct extensive empirical\nanalysis, comparing our proposal against a large set of baselines on several\npublic benchmarks. The empirical results show that our approach achieves highly\ncompetitive performance and surpasses both the leading Euclidean and hyperbolic\nbaselines by considerable margins. Further analysis verifies ...",
    "descriptor": "\nComments: Proceedings of the ACM Web Conference 2022 (WWW '22)\n",
    "authors": [
      "Menglin Yang",
      "Min Zhou",
      "Jiahong Liu",
      "Defu Lian",
      "Irwin King"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08176"
  },
  {
    "id": "arXiv:2204.08179",
    "title": "Real-world Deep Local Motion Deblurring",
    "abstract": "Most existing deblurring methods focus on removing global blur caused by\ncamera shake, while they cannot well handle local blur caused by object\nmovements. To fill the vacancy of local deblurring in real scenes, we establish\nthe first real local motion blur dataset (ReLoBlur), which is captured by a\nsynchronized beam-splitting photographing system and corrected by a\npost-progressing pipeline. Based on ReLoBlur, we propose a Local Blur-Aware\nGated network (LBAG) and several local blur-aware techniques to bridge the gap\nbetween global and local deblurring: 1) a blur detection approach based on\nbackground subtraction to localize blurred regions; 2) a gate mechanism to\nguide our network to focus on blurred regions; and 3) a blur-aware patch\ncropping strategy to address data imbalance problem. Extensive experiments\nprove the reliability of ReLoBlur dataset, and demonstrate that LBAG achieves\nbetter performance than state-of-the-art global deblurring methods without our\nproposed local blur-aware techniques.",
    "descriptor": "",
    "authors": [
      "Haoying Li",
      "Ziran Zhang",
      "Tingting Jiang",
      "Peng Luo",
      "Huajun Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08179"
  },
  {
    "id": "arXiv:2204.08180",
    "title": "A Taxonomy of Error Sources in HPC I/O Machine Learning Models",
    "abstract": "I/O efficiency is crucial to productivity in scientific computing, but the\nincreasing complexity of the system and the applications makes it difficult for\npractitioners to understand and optimize I/O behavior at scale. Data-driven\nmachine learning-based I/O throughput models offer a solution: they can be used\nto identify bottlenecks, automate I/O tuning, or optimize job scheduling with\nminimal human intervention. Unfortunately, current state-of-the-art I/O models\nare not robust enough for production use and underperform after being deployed.\nWe analyze multiple years of application, scheduler, and storage system logs\non two leadership-class HPC platforms to understand why I/O models underperform\nin practice. We propose a taxonomy consisting of five categories of I/O\nmodeling errors: poor application and system modeling, inadequate dataset\ncoverage, I/O contention, and I/O noise. We develop litmus tests to quantify\neach category, allowing researchers to narrow down failure modes, enhance I/O\nthroughput models, and improve future generations of HPC logging and analysis\ntools.",
    "descriptor": "",
    "authors": [
      "Mihailo Isakov",
      "Mikaela Currier",
      "Eliakin del Rosario",
      "Sandeep Madireddy",
      "Prasanna Balaprakash",
      "Philip Carns",
      "Robert B. Ross",
      "Glenn K. Lockwood",
      "Michel A. Kinsy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2204.08180"
  },
  {
    "id": "arXiv:2204.08182",
    "title": "Modality-Balanced Embedding for Video Retrieval",
    "abstract": "Video search has become the main routine for users to discover videos\nrelevant to a text query on large short-video sharing platforms. During\ntraining a query-video bi-encoder model using online search logs, we identify a\nmodality bias phenomenon that the video encoder almost entirely relies on text\nmatching, neglecting other modalities of the videos such as vision, audio. This\nmodality imbalanceresults from a) modality gap: the relevance between a query\nand a video text is much easier to learn as the query is also a piece of text,\nwith the same modality as the video text; b) data bias: most training samples\ncan be solved solely by text matching. Here we share our practices to improve\nthe first retrieval stage including our solution for the modality imbalance\nissue. We propose MBVR (short for Modality Balanced Video Retrieval) with two\nkey components: manually generated modality-shuffled (MS) samples and a dynamic\nmargin (DM) based on visual relevance. They can encourage the video encoder to\npay balanced attentions to each modality. Through extensive experiments on a\nreal world dataset, we show empirically that our method is both effective and\nefficient in solving modality bias problem. We have also deployed our MBVR in a\nlarge video platform and observed statistically significant boost over a highly\noptimized baseline in an A/B test and manual GSB evaluations.",
    "descriptor": "\nComments: Accepted by SIGIR-2022, short paper\n",
    "authors": [
      "Xun Wang",
      "Bingqing Ke",
      "Xuanping Li",
      "Fangyu Liu",
      "Mingyu Zhang",
      "Xiao Liang",
      "Qiushi Xiao",
      "Yue Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.08182"
  },
  {
    "id": "arXiv:2204.08185",
    "title": "Completion Delay of Random Linear Network Coding in Full-Duplex Relay  Networks",
    "abstract": "As the next-generation wireless networks thrive, full-duplex and relaying\ntechniques are combined to improve the network performance. Random linear\nnetwork coding (RLNC) is another popular technique to enhance the efficiency\nand reliability in wireless communications. In this paper, in order to explore\nthe potential of RLNC in full-duplex relay networks, we investigate two\nfundamental perfect RLNC schemes and theoretically analyze their completion\ndelay performance. The first scheme is a straightforward application of\nconventional perfect RLNC studied in wireless broadcast, so it involves no\nadditional process at the relay. Its performance serves as an upper bound among\nall perfect RLNC schemes. The other scheme allows sufficiently large buffer and\nunconstrained linear coding at the relay. It attains the optimal performance\nand serves as a lower bound among all RLNC schemes. For both schemes,\nclosed-form formulae to characterize the expected completion delay at a single\nreceiver as well as for the whole system are derived. Numerical results are\nalso demonstrated to justify the theoretical characterizations, and compare the\ntwo new schemes with the existing one.",
    "descriptor": "",
    "authors": [
      "Rina Su",
      "Qifu Tyler Sun",
      "Zhongshan Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08185"
  },
  {
    "id": "arXiv:2204.08189",
    "title": "Sardino: Ultra-Fast Dynamic Ensemble for Secure Visual Sensing at Mobile  Edge",
    "abstract": "Adversarial example attack endangers the mobile edge systems such as vehicles\nand drones that adopt deep neural networks for visual sensing. This paper\npresents {\\em Sardino}, an active and dynamic defense approach that renews the\ninference ensemble at run time to develop security against the adaptive\nadversary who tries to exfiltrate the ensemble and construct the corresponding\neffective adversarial examples. By applying consistency check and data fusion\non the ensemble's predictions, Sardino can detect and thwart adversarial\ninputs. Compared with the training-based ensemble renewal, we use HyperNet to\nachieve {\\em one million times} acceleration and per-frame ensemble renewal\nthat presents the highest level of difficulty to the prerequisite exfiltration\nattacks. Moreover, the robustness of the renewed ensembles against adversarial\nexamples is enhanced with adversarial learning for the HyperNet. We design a\nrun-time planner that maximizes the ensemble size in favor of security while\nmaintaining the processing frame rate. Beyond adversarial examples, Sardino can\nalso address the issue of out-of-distribution inputs effectively. This paper\npresents extensive evaluation of Sardino's performance in counteracting\nadversarial examples and applies it to build a real-time car-borne traffic sign\nrecognition system. Live on-road tests show the built system's effectiveness in\nmaintaining frame rate and detecting out-of-distribution inputs due to the\nfalse positives of a preceding YOLO-based traffic sign detector.",
    "descriptor": "",
    "authors": [
      "Qun Song",
      "Zhenyu Yan",
      "Wenjie Luo",
      "Rui Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08189"
  },
  {
    "id": "arXiv:2204.08193",
    "title": "I Cannot See Students Focusing on My Presentation; Are They Following  Me? Continuous Monitoring of Student Engagement through \"Stungage\"",
    "abstract": "Monitoring students' engagement and understanding their learning pace in a\nvirtual classroom becomes challenging in the absence of direct eye contact\nbetween the students and the instructor. Continuous monitoring of eye gaze and\ngaze gestures may produce inaccurate outcomes when the students are allowed to\ndo productive multitasking, such as taking notes or browsing relevant content.\nThis paper proposes Stungage - a software wrapper over existing online meeting\nplatforms to monitor students' engagement in real-time by utilizing the facial\nvideo feeds from the students and the instructor coupled with a local on-device\nanalysis of the presentation content. The crux of Stungage is to identify a few\nopportunistic moments when the students should visually focus on the\npresentation content if they can follow the lecture. We investigate these\ninstances and analyze the students' visual, contextual, and cognitive presence\nto assess their engagement during the virtual classroom while not directly\nsharing the video captures of the participants and their screens over the web.\nOur system achieves an overall F2-score of 0.88 for detecting student\nengagement. Besides, we obtain 92 responses from the usability study with an\naverage SU score of 74.18.",
    "descriptor": "",
    "authors": [
      "Snigdha Das",
      "Sandip Chakraborty",
      "Bivas Mitra"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.08193"
  },
  {
    "id": "arXiv:2204.08194",
    "title": "Phishing Fraud Detection on Ethereum using Graph Neural Network",
    "abstract": "Blockchain has widespread applications in the financial field but has also\nattracted increasing cybercrimes. Recently, phishing fraud has emerged as a\nmajor threat to blockchain security, calling for the development of effective\nregulatory strategies. Nowadays network science has been widely used in\nmodeling Ethereum transaction data, further introducing the network\nrepresentation learning technology to analyze the transaction patterns. In this\npaper, we consider phishing detection as a graph classification task and\npropose an end-to-end Phishing Detection Graph Neural Network framework\n(PDGNN). Specifically, we first construct a lightweight Ethereum transaction\nnetwork and extract transaction subgraphs of collected phishing accounts. Then\nwe propose an end-to-end detection model based on Chebyshev-GCN to precisely\ndistinguish between normal and phishing accounts. Extensive experiments on five\nEthereum datasets demonstrate that our PDGNN significantly outperforms general\nphishing detection methods and scales well in large transaction networks.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Panpan Li",
      "Yunyi Xie",
      "Xinyao Xu",
      "Jiajun Zhou",
      "Qi Xuan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.08194"
  },
  {
    "id": "arXiv:2204.08196",
    "title": "Self-Supervised Arbitrary-Scale Point Clouds Upsampling via Implicit  Neural Representation",
    "abstract": "Point clouds upsampling is a challenging issue to generate dense and uniform\npoint clouds from the given sparse input. Most existing methods either take the\nend-to-end supervised learning based manner, where large amounts of pairs of\nsparse input and dense ground-truth are exploited as supervision information;\nor treat up-scaling of different scale factors as independent tasks, and have\nto build multiple networks to handle upsampling with varying factors. In this\npaper, we propose a novel approach that achieves self-supervised and\nmagnification-flexible point clouds upsampling simultaneously. We formulate\npoint clouds upsampling as the task of seeking nearest projection points on the\nimplicit surface for seed points. To this end, we define two implicit neural\nfunctions to estimate projection direction and distance respectively, which can\nbe trained by two pretext learning tasks. Experimental results demonstrate that\nour self-supervised learning based scheme achieves competitive or even better\nperformance than supervised learning based state-of-the-art methods. The source\ncode is publicly available at https://github.com/xnowbzhao/sapcu.",
    "descriptor": "",
    "authors": [
      "Wenbo Zhao",
      "Xianming Liu",
      "Zhiwei Zhong",
      "Junjun Jiang",
      "Wei Gao",
      "Ge Li",
      "Xiangyang Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2204.08196"
  },
  {
    "id": "arXiv:2204.08198",
    "title": "UTNLP at SemEval-2022 Task 6: A Comparative Analysis of Sarcasm  Detection using generative-based and mutation-based data augmentation",
    "abstract": "Sarcasm is a term that refers to the use of words to mock, irritate, or amuse\nsomeone. It is commonly used on social media. The metaphorical and creative\nnature of sarcasm presents a significant difficulty for sentiment analysis\nsystems based on affective computing. The methodology and results of our team,\nUTNLP, in the SemEval-2022 shared task 6 on sarcasm detection are presented in\nthis paper. We put different models, and data augmentation approaches to the\ntest and report on which one works best. The tests begin with traditional\nmachine learning models and progress to transformer-based and attention-based\nmodels. We employed data augmentation based on data mutation and data\ngeneration. Using RoBERTa and mutation-based data augmentation, our best\napproach achieved an F1-sarcastic of 0.38 in the competition's evaluation\nphase. After the competition, we fixed our model's flaws and achieved an\nF1-sarcastic of 0.414.",
    "descriptor": "\nComments: 6 pages, 2 figures, NAACL 2022 Workshop Semeval\n",
    "authors": [
      "Amirhossein Abaskohi",
      "Arash Rasouli",
      "Tanin Zeraati",
      "Behnam Bahrak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08198"
  },
  {
    "id": "arXiv:2204.08200",
    "title": "Understanding Gradual Domain Adaptation: Improved Analysis, Optimal Path  and Beyond",
    "abstract": "The vast majority of existing algorithms for unsupervised domain adaptation\n(UDA) focus on adapting from a labeled source domain to an unlabeled target\ndomain directly in a one-off way. Gradual domain adaptation (GDA), on the other\nhand, assumes a path of $(T-1)$ unlabeled intermediate domains bridging the\nsource and target, and aims to provide better generalization in the target\ndomain by leveraging the intermediate ones. Under certain assumptions, Kumar et\nal. (2020) proposed a simple algorithm, Gradual Self-Training, along with a\ngeneralization bound in the order of $e^{O(T)}\n\\left(\\varepsilon_0+O\\left(\\sqrt{log(T)/n}\\right)\\right)$ for the target domain\nerror, where $\\varepsilon_0$ is the source domain error and $n$ is the data\nsize of each domain. Due to the exponential factor, this upper bound becomes\nvacuous when $T$ is only moderately large. In this work, we analyze gradual\nself-training under more general and relaxed assumptions, and prove a\nsignificantly improved generalization bound as\n$\\widetilde{O}\\left(\\varepsilon_0 + T\\Delta + T/\\sqrt{n} + 1/\\sqrt{nT}\\right)$,\nwhere $\\Delta$ is the average distributional distance between consecutive\ndomains. Compared with the existing bound with an exponential dependency on $T$\nas a multiplicative factor, our bound only depends on $T$ linearly and\nadditively. Perhaps more interestingly, our result implies the existence of an\noptimal choice of $T$ that minimizes the generalization error, and it also\nnaturally suggests an optimal way to construct the path of intermediate domains\nso as to minimize the accumulative path length $T\\Delta$ between the source and\ntarget. To corroborate the implications of our theory, we examine gradual\nself-training on multiple semi-synthetic and real datasets, which confirms our\nfindings. We believe our insights provide a path forward toward the design of\nfuture GDA algorithms.",
    "descriptor": "\nComments: The code will be released at this https URL\n",
    "authors": [
      "Haoxiang Wang",
      "Bo Li",
      "Han Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.08200"
  },
  {
    "id": "arXiv:2204.08206",
    "title": "TigerLily: Finding drug interactions in silico with the Graph",
    "abstract": "Tigerlily is a TigerGraph based system designed to solve the drug interaction\nprediction task. In this machine learning task, we want to predict whether two\ndrugs have an adverse interaction. Our framework allows us to solve this highly\nrelevant real-world problem using graph mining techniques in these steps:\n(a) Using PyTigergraph we create a heterogeneous biological graph of drugs\nand proteins.\n(b) We calculate the personalized PageRank scores of drug nodes in the\nTigerGraph Cloud.\n(c) We embed the nodes using sparse non-negative matrix factorization of the\npersonalized PageRank matrix.\n(d) Using the node embeddings we train a gradient boosting based drug\ninteraction predictor.",
    "descriptor": "",
    "authors": [
      "Benedek Rozemberczki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.08206"
  },
  {
    "id": "arXiv:2204.08209",
    "title": "OMG: Observe Multiple Granularities for Natural Language-Based Vehicle  Retrieval",
    "abstract": "Retrieving tracked-vehicles by natural language descriptions plays a critical\nrole in smart city construction. It aims to find the best match for the given\ntexts from a set of tracked vehicles in surveillance videos. Existing works\ngenerally solve it by a dual-stream framework, which consists of a text\nencoder, a visual encoder and a cross-modal loss function. Although some\nprogress has been made, they failed to fully exploit the information at various\nlevels of granularity. To tackle this issue, we propose a novel framework for\nthe natural language-based vehicle retrieval task, OMG, which Observes Multiple\nGranularities with respect to visual representation, textual representation and\nobjective functions. For the visual representation, target features, context\nfeatures and motion features are encoded separately. For the textual\nrepresentation, one global embedding, three local embeddings and a color-type\nprompt embedding are extracted to represent various granularities of semantic\nfeatures. Finally, the overall framework is optimized by a cross-modal\nmulti-granularity contrastive loss function. Experiments demonstrate the\neffectiveness of our method. Our OMG significantly outperforms all previous\nmethods and ranks the 9th on the 6th AI City Challenge Track2. The codes are\navailable at https://github.com/dyhBUPT/OMG.",
    "descriptor": "\nComments: Camera-ready for CVPR 2022 Workshop\n",
    "authors": [
      "Yunhao Du",
      "Binyu Zhang",
      "Xiangning Ruan",
      "Fei Su",
      "Zhicheng Zhao",
      "Hong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08209"
  },
  {
    "id": "arXiv:2204.08211",
    "title": "How to Attain Communication-Efficient DNN Training? Convert, Compress,  Correct",
    "abstract": "In this paper, we introduce $\\mathsf{CO}_3$, an algorithm for\ncommunication-efficiency federated Deep Neural Network (DNN)\ntraining.$\\mathsf{CO}_3$ takes its name from three processing applied steps\nwhich reduce the communication load when transmitting the local gradients from\nthe remote users to the Parameter Server.Namely:(i) gradient quantization\nthrough floating-point conversion, (ii) lossless compression of the quantized\ngradient, and (iii) quantization error correction.We carefully design each of\nthe steps above so as to minimize the loss in the distributed DNN training when\nthe communication overhead is fixed.In particular, in the design of steps (i)\nand (ii), we adopt the assumption that DNN gradients are distributed according\nto a generalized normal distribution.This assumption is validated numerically\nin the paper. For step (iii), we utilize an error feedback with memory decay\nmechanism to correct the quantization error introduced in step (i). We argue\nthat this coefficient, similarly to the learning rate, can be optimally tuned\nto improve convergence. The performance of $\\mathsf{CO}_3$ is validated through\nnumerical simulations and is shown having better accuracy and improved\nstability at a reduced communication payload.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2203.09044\n",
    "authors": [
      "Zhong-Jing Chen",
      "Eduin E. Hernandez",
      "Yu-Chih Huang",
      "Stefano Rini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08211"
  },
  {
    "id": "arXiv:2204.08214",
    "title": "Hamiltonian Particle-in-Cell methods for Vlasov-Poisson equations",
    "abstract": "In this paper, Particle-in-Cell algorithms for the Vlasov-Poisson system are\npresented based on its Poisson bracket structure. The Poisson equation is\nsolved by finite element methods, in which the appropriate finite element\nspaces are taken to guarantee that the semi-discretized system possesses a well\ndefined discrete Poisson bracket structure. Then, splitting methods are applied\nto the semi-discretized system by decomposing the Hamiltonian function. The\nresulting discretizations are proved to be Poisson bracket preserving.\nMoreover, the conservative quantities of the system are also well preserved. In\nnumerical experiments, we use the presented numerical methods to simulate\nvarious physical phenomena. Due to the huge computational effort of the\npractical computations, we employ the strategy of parallel computing. The\nnumerical results verify the efficiency of the new derived numerical\ndiscretizations.",
    "descriptor": "",
    "authors": [
      "Anjiao Gu",
      "Yang He",
      "Yajuan Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.08214"
  },
  {
    "id": "arXiv:2204.08226",
    "title": "Empirical Evaluation and Theoretical Analysis for Representation  Learning: A Survey",
    "abstract": "Representation learning enables us to automatically extract generic feature\nrepresentations from a dataset to solve another machine learning task.\nRecently, extracted feature representations by a representation learning\nalgorithm and a simple predictor have exhibited state-of-the-art performance on\nseveral machine learning tasks. Despite its remarkable progress, there exist\nvarious ways to evaluate representation learning algorithms depending on the\napplication because of the flexibility of representation learning. To\nunderstand the current representation learning, we review evaluation methods of\nrepresentation learning algorithms and theoretical analyses. On the basis of\nour evaluation survey, we also discuss the future direction of representation\nlearning. Note that this survey is the extended version of Nozawa and Sato\n(2022).",
    "descriptor": "\nComments: The extended version of \"Kento Nozawa and Issei Sato. Evaluation Methods for Representation Learning: A Survey. In IJCAI-ECAI Survey Track, 2022.\"\n",
    "authors": [
      "Kento Nozawa",
      "Issei Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08226"
  },
  {
    "id": "arXiv:2204.08227",
    "title": "The Devil is in the Frequency: Geminated Gestalt Autoencoder for  Self-Supervised Visual Pre-Training",
    "abstract": "The self-supervised Masked Image Modeling (MIM) schema, following\n\"mask-and-reconstruct\" pipeline of recovering contents from masked image, has\nrecently captured the increasing interest in the multimedia community, owing to\nthe excellent ability of learning visual representation from unlabeled data.\nAiming at learning representations with high semantics abstracted, a group of\nworks attempts to reconstruct non-semantic pixels with large-ratio masking\nstrategy, which may suffer from \"over-smoothing\" problem, while others directly\ninfuse semantics into targets in off-line way requiring extra data. Different\nfrom them, we shift the perspective to the Fourier domain which naturally has\nglobal perspective and present a new Masked Image Modeling (MIM), termed\nGeminated Gestalt Autoencoder (Ge$^2$-AE) for visual pre-training.\nSpecifically, we equip our model with geminated decoders in charge of\nreconstructing image contents from both pixel and frequency space, where each\nother serves as not only the complementation but also the reciprocal\nconstraints. Through this way, more robust representations can be learned in\nthe pre-trained encoders, of which the effectiveness is confirmed by the\njuxtaposing experimental results on downstream recognition tasks. We also\nconduct several quantitative and qualitative experiments to investigate the\nlearning behavior of our method. To our best knowledge, this is the first MIM\nwork to solve the visual pre-training through the lens of frequency domain.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Hao Liu",
      "Xinghua Jiang",
      "Xin Li",
      "Antai Guo",
      "Deqiang Jiang",
      "Bo Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08227"
  },
  {
    "id": "arXiv:2204.08229",
    "title": "Preference Enhanced Social Influence Modeling for Network-Aware Cascade  Prediction",
    "abstract": "Network-aware cascade size prediction aims to predict the final reposted\nnumber of user-generated information via modeling the propagation process in\nsocial networks. Estimating the user's reposting probability by social\ninfluence, namely state activation plays an important role in the information\ndiffusion process. Therefore, Graph Neural Networks (GNN), which can simulate\nthe information interaction between nodes, has been proved as an effective\nscheme to handle this prediction task. However, existing studies including\nGNN-based models usually neglect a vital factor of user's preference which\ninfluences the state activation deeply. To that end, we propose a novel\nframework to promote cascade size prediction by enhancing the user preference\nmodeling according to three stages, i.e., preference topics generation,\npreference shift modeling, and social influence activation. Our end-to-end\nmethod makes the user activating process of information diffusion more adaptive\nand accurate. Extensive experiments on two large-scale real-world datasets have\nclearly demonstrated the effectiveness of our proposed model compared to\nstate-of-the-art baselines.",
    "descriptor": "\nComments: SIGIR 2022\n",
    "authors": [
      "Likang Wu",
      "Hao Wang",
      "Enhong Chen",
      "Zhi Li",
      "Hongke Zhao",
      "Jianhui Ma"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.08229"
  },
  {
    "id": "arXiv:2204.08235",
    "title": "Table Enrichment System for Machine Learning",
    "abstract": "Data scientists are constantly facing the problem of how to improve\nprediction accuracy with insufficient tabular data. We propose a table\nenrichment system that enriches a query table by adding external attributes\n(columns) from data lakes and improves the accuracy of machine learning\npredictive models. Our system has four stages, join row search, task-related\ntable selection, row and column alignment, and feature selection and\nevaluation, to efficiently create an enriched table for a given query table and\na specified machine learning task. We demonstrate our system with a web UI to\nshow the use cases of table enrichment.",
    "descriptor": "\nComments: demo paper at SIGIR2022\n",
    "authors": [
      "Yuyang Dong",
      "Masafumi Oyamada"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.08235"
  },
  {
    "id": "arXiv:2204.08237",
    "title": "Modx: Binary Level Partial Imported Third-Party Library Detection  through Program Modularization and Semantic Matching",
    "abstract": "With the rapid growth of software, using third-party libraries (TPLs) has\nbecome increasingly popular. The prosperity of the library usage has provided\nthe software engineers with handful of methods to facilitate and boost the\nprogram development. Unfortunately, it also poses great challenges as it\nbecomes much more difficult to manage the large volume of libraries. Researches\nand studies have been proposed to detect and understand the TPLs in the\nsoftware. However, most existing approaches rely on syntactic features, which\nare not robust when these features are changed or deliberately hidden by the\nadversarial parties. Moreover, these approaches typically model each of the\nimported libraries as a whole, therefore, cannot be applied to scenarios where\nthe host software only partially uses the library code segments.\nTo detect both fully and partially imported TPLs at the semantic level, we\npropose ModX, a framework that leverages novel program modularization\ntechniques to decompose the program into finegrained functionality-based\nmodules. By extracting both syntactic and semantic features, it measures the\ndistance between modules to detect similar library module reuse in the program.\nExperimental results show that ModX outperforms other modularization tools by\ndistinguishing more coherent program modules with 353% higher module quality\nscores and beats other TPL detection tools with on average 17% better in\nprecision and 8% better in recall.",
    "descriptor": "",
    "authors": [
      "Can Yang",
      "Zhengzi Xu",
      "Hongxu Chen",
      "Yang Liu",
      "Xiaorui Gong",
      "Baoxu Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.08237"
  },
  {
    "id": "arXiv:2204.08240",
    "title": "Linear Battery Models for Power Systems Analysis",
    "abstract": "Mathematical models are just models. The desire to describe battery energy\nstorage system (BESS) operation using computationally tractable model\nformulations has motivated a long-standing discussion in both the scientific\nand industrial communities. Linear BESS models are the most widely used so far.\nHowever, finding suitable linear BESS models has been controversial.\nThis paper focuses on the description of linear BESS models. Four linear BESS\nformulations are presented, among the most popularly used. A new formulation is\nalso proposed. The 5 BESS models are tested in 100 random BESS and 1.450 random\nsamples of daily profiles of renewable generation. Two classical problems of\npower systems, namely, the set-point tracking problem and the transmission\nexpansion planning problem, are selected for numerical analysis. Five thousand\nsimulations are used to draw a better interpretation of each linear formulation\npresented and showcase specific challenges of BESS models. Practical\nrecommendations are provided based on the findings.",
    "descriptor": "\nComments: Power Systems Computation Conference (PSCC) 2022\n",
    "authors": [
      "David Pozo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.08240"
  },
  {
    "id": "arXiv:2204.08241",
    "title": "GNN-encoder: Learning a Dual-encoder Architecture via Graph Neural  Networks for Passage Retrieval",
    "abstract": "Recently, retrieval models based on dense representations are dominant in\npassage retrieval tasks, due to their outstanding ability in terms of capturing\nsemantics of input text compared to the traditional sparse vector space models.\nA common practice of dense retrieval models is to exploit a dual-encoder\narchitecture to represent a query and a passage independently. Though\nefficient, such a structure loses interaction between the query-passage pair,\nresulting in inferior accuracy. To enhance the performance of dense retrieval\nmodels without loss of efficiency, we propose a GNN-encoder model in which\nquery (passage) information is fused into passage (query) representations via\ngraph neural networks that are constructed by queries and their top retrieved\npassages. By this means, we maintain a dual-encoder structure, and retain some\ninteraction information between query-passage pairs in their representations,\nwhich enables us to achieve both efficiency and efficacy in passage retrieval.\nEvaluation results indicate that our method significantly outperforms the\nexisting models on MSMARCO, Natural Questions and TriviaQA datasets, and\nachieves the new state-of-the-art on these datasets.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Jiduan Liu",
      "Jiahao Liu",
      "Yang Yang",
      "Jingang Wang",
      "Wei Wu",
      "Dongyan Zhao",
      "Rui Yan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.08241"
  },
  {
    "id": "arXiv:2204.08242",
    "title": "Fast optimization of common basis for matrix set through Common Singular  Value Decomposition",
    "abstract": "SVD (singular value decomposition) is one of the basic tools of machine\nlearning, allowing to optimize basis for a given matrix. However, sometimes we\nhave a set of matrices $\\{A_k\\}_k$ instead, and would like to optimize a single\ncommon basis for them: find orthogonal matrices $U$, $V$, such that $\\{U^T A_k\nV\\}$ set of matrices is somehow simpler. For example DCT-II is orthonormal\nbasis of functions commonly used in image/video compression - as discussed\nhere, this kind of basis can be quickly automatically optimized for a given\ndataset. While also discussed gradient descent optimization might be\ncomputationally costly, there is proposed CSVD (common SVD): fast general\napproach based on SVD. Specifically, we choose $U$ as built of eigenvectors of\n$\\sum_i (w_k)^q (A_k A_k^T)^p$ and $V$ of $\\sum_k (w_k)^q (A_k^T A_k)^p$, where\n$w_k$ are their weights, $p,q>0$ are some chosen powers e.g. 1/2, optionally\nwith normalization e.g. $A \\to A - rc^T$ where $r_i=\\sum_j A_{ij}, c_j =\\sum_i\nA_{ij}$.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Jarek Duda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08242"
  },
  {
    "id": "arXiv:2204.08244",
    "title": "RIS-Assisted Cooperative NOMA with SWIPT",
    "abstract": "This paper studies the application of reconfigurable intelligent surface\n(RIS) to cooperative non-orthogonal multiple access (C-NOMA) networks with\nsimultaneous wireless information and power transfer (SWIPT). We aim for\nmaximizing the rate of the strong user with guaranteed weak user's quality of\nservice (QoS) by jointly optimizing power splitting factors, beamforming\ncoefficients, and RIS reflection coefficients in two transmission phases. The\nformulated problem is difficult to solve due to its complex and non-convex\nconstraints. To tackle this challenging problem, we first use alternating\noptimization (AO) framework to transform it into three subproblems, and then\nuse the penalty-based arithmetic-geometric mean approximation (PBAGM) algorithm\nand the successive convex approximation (SCA)-based method to solve them.\nNumerical results verify the superiority of the proposed algorithm over the\nbaseline schemes.",
    "descriptor": "",
    "authors": [
      "Juanjuan Ren",
      "Xianfu Lei",
      "Zhangjie Peng",
      "Xiaohu Tang",
      "Octavia A. Dobre"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08244"
  },
  {
    "id": "arXiv:2204.08247",
    "title": "Joint Multi-view Unsupervised Feature Selection and Graph Learning",
    "abstract": "Despite the recent progress, the existing multi-view unsupervised feature\nselection methods mostly suffer from two limitations. First, they generally\nutilize either cluster structure or similarity structure to guide the feature\nselection, neglecting the possibility of a joint formulation with mutual\nbenefits. Second, they often learn the similarity structure by either global\nstructure learning or local structure learning, lacking the capability of graph\nlearning with both global and local structural awareness. In light of this,\nthis paper presents a joint multi-view unsupervised feature selection and graph\nlearning (JMVFG) approach. Particularly, we formulate the multi-view feature\nselection with orthogonal decomposition, where each target matrix is decomposed\ninto a view-specific basis matrix and a view-consistent cluster indicator.\nCross-space locality preservation is incorporated to bridge the cluster\nstructure learning in the projected space and the similarity learning (i.e.,\ngraph learning) in the original space. Further, a unified objective function is\npresented to enable the simultaneous learning of the cluster structure, the\nglobal and local similarity structures, and the multi-view consistency and\ninconsistency, upon which an alternating optimization algorithm is developed\nwith theoretically proved convergence. Extensive experiments demonstrate the\nsuperiority of our approach for both multi-view feature selection and graph\nlearning tasks.",
    "descriptor": "",
    "authors": [
      "Si-Guo Fang",
      "Dong Huang",
      "Chang-Dong Wang",
      "Yong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.08247"
  },
  {
    "id": "arXiv:2204.08254",
    "title": "Deterministic Low-Diameter Decompositions for Weighted Graphs and  Distributed and Parallel Applications",
    "abstract": "This paper presents new deterministic and distributed low-diameter\ndecomposition algorithms for weighted graphs. In particular, we show that if\none can efficiently compute approximate distances in a parallel or a\ndistributed setting, one can also efficiently compute low-diameter\ndecompositions. This consequently implies solutions to many fundamental\ndistance based problems using a polylogarithmic number of approximate distance\ncomputations.\nOur low-diameter decomposition generalizes and extends the line of work\nstarting from [Rozho\\v{n}, Ghaffari STOC 2020] to weighted graphs in a very\nmodel-independent manner. Moreover, our clustering results have additional\nuseful properties, including strong-diameter guarantees, separation properties,\nrestricting cluster centers to specified terminals, and more. Applications\ninclude:\n-- The first near-linear work and polylogarithmic depth randomized and\ndeterministic parallel algorithm for low-stretch spanning trees (LSST) with\npolylogarithmic stretch. Previously, the best parallel LSST algorithm required\n$m \\cdot n^{o(1)}$ work and $n^{o(1)}$ depth and was inherently randomized. No\ndeterministic LSST algorithm with truly sub-quadratic work and sub-linear depth\nwas known.\n-- The first near-linear work and polylogarithmic depth deterministic\nalgorithm for computing an $\\ell_1$-embedding into polylogarithmic dimensional\nspace with polylogarithmic distortion. The best prior deterministic algorithms\nfor $\\ell_1$-embeddings either require large polynomial work or are inherently\nsequential.\nEven when we apply our techniques to the classical problem of computing a\nball-carving with strong-diameter $O(\\log^2 n)$ in an unweighted graph, our new\nclustering algorithm still leads to an improvement in round complexity from\n$O(\\log^{10} n)$ rounds [Chang, Ghaffari PODC 21] to $O(\\log^{4} n)$.",
    "descriptor": "",
    "authors": [
      "Michael Elkin",
      "Bernhard Haeupler",
      "V\u00e1clav Rozho\u0148",
      "Christoph Grunau"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.08254"
  },
  {
    "id": "arXiv:2204.08255",
    "title": "LBL System for Underwater Acoustic Positioning: Concept and Equations",
    "abstract": "GNSS (Global Navigation Satellite System) positioning is not available\nunderwater due to the very short range of electromagnetic waves in the sea\nwater medium. In this article a LBL (Long Base Line) acoustic repeater system\nof the GNSS positioning is presented. The system is hyperbolic, i.e., based on\ntime differences and it does not need very accurate atomic clocks to\nsynchronize repeaters.",
    "descriptor": "\nComments: 3 pages, 2 figures, 9 equations\n",
    "authors": [
      "Pablo Otero",
      "\u00c1lvaro Hern\u00e1ndez-Romero",
      "Miguel-\u00c1ngel Luque-Nieto"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2204.08255"
  },
  {
    "id": "arXiv:2204.08261",
    "title": "Visio-Linguistic Brain Encoding",
    "abstract": "Enabling effective brain-computer interfaces requires understanding how the\nhuman brain encodes stimuli across modalities such as visual, language (or\ntext), etc. Brain encoding aims at constructing fMRI brain activity given a\nstimulus. There exists a plethora of neural encoding models which study brain\nencoding for single mode stimuli: visual (pretrained CNNs) or text (pretrained\nlanguage models). Few recent papers have also obtained separate visual and text\nrepresentation models and performed late-fusion using simple heuristics.\nHowever, previous work has failed to explore: (a) the effectiveness of image\nTransformer models for encoding visual stimuli, and (b) co-attentive\nmulti-modal modeling for visual and text reasoning. In this paper, we\nsystematically explore the efficacy of image Transformers (ViT, DEiT, and BEiT)\nand multi-modal Transformers (VisualBERT, LXMERT, and CLIP) for brain encoding.\nExtensive experiments on two popular datasets, BOLD5000 and Pereira, provide\nthe following insights. (1) To the best of our knowledge, we are the first to\ninvestigate the effectiveness of image and multi-modal Transformers for brain\nencoding. (2) We find that VisualBERT, a multi-modal Transformer, significantly\noutperforms previously proposed single-mode CNNs, image Transformers as well as\nother previously proposed multi-modal models, thereby establishing new\nstate-of-the-art. The supremacy of visio-linguistic models raises the question\nof whether the responses elicited in the visual regions are affected implicitly\nby linguistic processing even when passively viewing images. Future fMRI tasks\ncan verify this computational insight in an appropriate experimental setting.",
    "descriptor": "\nComments: 18 pages, 13 figures\n",
    "authors": [
      "Subba Reddy Oota",
      "Jashn Arora",
      "Vijay Rowtula",
      "Manish Gupta",
      "Raju S. Bapi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2204.08261"
  },
  {
    "id": "arXiv:2204.08263",
    "title": "Factual Error Correction for Abstractive Summaries Using Entity  Retrieval",
    "abstract": "Despite the recent advancements in abstractive summarization systems\nleveraged from large-scale datasets and pre-trained language models, the\nfactual correctness of the summary is still insufficient. One line of trials to\nmitigate this problem is to include a post-editing process that can detect and\ncorrect factual errors in the summary. In building such a post-editing system,\nit is strongly required that 1) the process has a high success rate and\ninterpretability and 2) has a fast running time. Previous approaches focus on\nregeneration of the summary using the autoregressive models, which lack\ninterpretability and require high computing resources. In this paper, we\npropose an efficient factual error correction system RFEC based on entities\nretrieval post-editing process. RFEC first retrieves the evidence sentences\nfrom the original document by comparing the sentences with the target summary.\nThis approach greatly reduces the length of text for a system to analyze. Next,\nRFEC detects the entity-level errors in the summaries by considering the\nevidence sentences and substitutes the wrong entities with the accurate\nentities from the evidence sentences. Experimental results show that our\nproposed error correction system shows more competitive performance than\nbaseline methods in correcting the factual errors with a much faster speed.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Hwanhee Lee",
      "Cheoneum Park",
      "Seunghyun Yoon",
      "Trung Bui",
      "Franck Dernoncourt",
      "Juae Kim",
      "Kyomin Jung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08263"
  },
  {
    "id": "arXiv:2204.08265",
    "title": "Configuration-Aware Safe Control for Mobile Robotic Arm with Control  Barrier Functions",
    "abstract": "Collision avoidance is a widely investigated topic in robotic applications.\nWhen applying collision avoidance techniques to a mobile robot, how to deal\nwith the spatial structure of the robot still remains a challenge. In this\npaper, we design a configuration-aware safe control law by solving a Quadratic\nProgramming (QP) with designed Control Barrier Functions (CBFs) constraints,\nwhich can safely navigate a mobile robotic arm to a desired region while\navoiding collision with environmental obstacles. The advantage of our approach\nis that it correctly and in an elegant way incorporates the spatial structure\nof the mobile robotic arm. This is achieved by merging geometric restrictions\namong mobile robotic arm links into CBFs constraints. Simulations on a rigid\nrod and the modeled mobile robotic arm are performed to verify the feasibility\nand time-efficiency of proposed method. Numerical results about the time\nconsuming for different degrees of freedom illustrate that our method scales\nwell with dimension.",
    "descriptor": "\nComments: submitted to Conference of Decision and Control(CDC)\n",
    "authors": [
      "Fan Ding",
      "Jianping He",
      "Yi Ren",
      "Han Wang",
      "Yu Zheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.08265"
  },
  {
    "id": "arXiv:2204.08269",
    "title": "Differentiable Time-Frequency Scattering in Kymatio",
    "abstract": "Joint time-frequency scattering (JTFS) is a convolutional operator in the\ntime-frequency domain which extracts spectrotemporal modulations at various\nrates and scales. It offers an idealized model of spectrotemporal receptive\nfields (STRF) in the primary auditory cortex, and thus may serve as a\nbiological plausible surrogate for human perceptual judgments at the scale of\nisolated audio events. Yet, prior implementations of JTFS and STRF have\nremained outside of the standard toolkit of perceptual similarity measures and\nevaluation methods for audio generation. We trace this issue down to three\nlimitations: differentiability, speed, and flexibility. In this paper, we\npresent an implementation of time-frequency scattering in Kymatio, an\nopen-source Python package for scattering transforms. Unlike prior\nimplementations, Kymatio accommodates NumPy and PyTorch as backends and is thus\nportable on both CPU and GPU. We demonstrate the usefulness of JTFS in Kymatio\nvia three applications: unsupervised manifold learning of spectrotemporal\nmodulations, supervised classification of musical instruments, and texture\nresynthesis of bioacoustic sounds.",
    "descriptor": "\nComments: 8 pages, 6 figures. Submitted to the International Conference on Digital Audio Effects (DAFX) 2022\n",
    "authors": [
      "John Muradeli",
      "Cyrus Vahidi",
      "Changhong Wang",
      "Han Han",
      "Vincent Lostanlen",
      "Mathieu Lagrange",
      "George Fazekas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.08269"
  },
  {
    "id": "arXiv:2204.08270",
    "title": "Lane-Free Crossing of CAVs through Intersections as a Minimum-Time  Optimal Control Problem",
    "abstract": "Unlike conventional cars, connected and autonomous vehicles (CAVs) can cross\nintersections in a lane-free order and utilise the whole area of intersections.\nThis paper presents a minimum-time optimal control problem to centrally control\nthe CAVs to simultaneously cross an intersection in the shortest possible time.\nDual problem theory is employed to convexify the constraints of CAVs to avoid\ncollision with each other and with road boundaries. The developed formulation\nis smooth and solvable by gradient-based algorithms. Simulation results show\nthat the proposed strategy reduces the crossing time of intersections by an\naverage of 52% and 54% as compared to, respectively, the state-of-the-art\nreservation-based and lane-free methods. Furthermore, the crossing time by the\nproposed strategy is fixed to a constant value for an intersection regardless\nof the number of CAVs.",
    "descriptor": "\nComments: 6 pages, 4 figures, conference paper. arXiv admin note: substantial text overlap with arXiv:2204.03550, arXiv:2204.04156\n",
    "authors": [
      "Mahdi Amouzadi",
      "Mobolaji Olawumi Orisatoki",
      "Arash M. Dizqah"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2204.08270"
  },
  {
    "id": "arXiv:2204.08271",
    "title": "Unsupervised domain adaptation and super resolution on drone images for  autonomous dry herbage biomass estimation",
    "abstract": "Herbage mass yield and composition estimation is an important tool for dairy\nfarmers to ensure an adequate supply of high quality herbage for grazing and\nsubsequently milk production. By accurately estimating herbage mass and\ncomposition, targeted nitrogen fertiliser application strategies can be\ndeployed to improve localised regions in a herbage field, effectively reducing\nthe negative impacts of over-fertilization on biodiversity and the environment.\nIn this context, deep learning algorithms offer a tempting alternative to the\nusual means of sward composition estimation, which involves the destructive\nprocess of cutting a sample from the herbage field and sorting by hand all\nplant species in the herbage. The process is labour intensive and time\nconsuming and so not utilised by farmers. Deep learning has been successfully\napplied in this context on images collected by high-resolution cameras on the\nground. Moving the deep learning solution to drone imaging, however, has the\npotential to further improve the herbage mass yield and composition estimation\ntask by extending the ground-level estimation to the large surfaces occupied by\nfields/paddocks. Drone images come at the cost of lower resolution views of the\nfields taken from a high altitude and requires further herbage ground-truth\ncollection from the large surfaces covered by drone images. This paper proposes\nto transfer knowledge learned on ground-level images to raw drone images in an\nunsupervised manner. To do so, we use unpaired image style translation to\nenhance the resolution of drone images by a factor of eight and modify them to\nappear closer to their ground-level counterparts. We then ...\n~\\url{www.github.com/PaulAlbert31/Clover_SSL}.",
    "descriptor": "\nComments: 11 pages, 5 figures. Accepted at the Agriculture-Vision CVPR 2022 Workshop\n",
    "authors": [
      "Paul Albert",
      "Mohamed Saadeldin",
      "Badri Narayanan",
      "Jaime Fernandez",
      "Brian Mac Namee",
      "Deirdre Hennessey",
      "Noel E. O'Connor",
      "Kevin McGuinness"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08271"
  },
  {
    "id": "arXiv:2204.08279",
    "title": "Communication Bounds for Convolutional Neural Networks",
    "abstract": "Convolutional neural networks (CNNs) are important in a wide variety of\nmachine learning tasks and applications, so optimizing their performance is\nessential. Moving words of data between levels of a memory hierarchy or between\nprocessors on a network is much more expensive than the cost of arithmetic, so\nminimizing communication is critical to optimizing performance. In this paper,\nwe present new lower bounds on data movement for mixed precision convolutions\nin both single-processor and parallel distributed memory models, as well as\nalgorithms that outperform current implementations such as Im2Col. We obtain\nperformance figures using GEMMINI, a machine learning accelerator, where our\ntiling provides improvements between 13% and 150% over a vendor supplied\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Anthony Chen",
      "James Demmel",
      "Grace Dinh",
      "Mason Haberle",
      "Olga Holtz"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.08279"
  },
  {
    "id": "arXiv:2204.08280",
    "title": "Non-intrusive reduced-order modeling using convolutional autoencoders",
    "abstract": "The use of reduced-order models (ROMs) in physics-based modeling and\nsimulation almost always involves the use of linear reduced basis (RB) methods\nsuch as the proper orthogonal decomposition (POD). For some nonlinear problems,\nlinear RB methods perform poorly, failing to provide an efficient subspace for\nthe solution space. The use of nonlinear manifolds for ROMs has gained traction\nin recent years, showing increased performance for certain nonlinear problems\nover linear methods. Deep learning has been popular to this end through the use\nof autoencoders for providing a nonlinear trial manifold for the solution\nspace. In this work, we present a non-intrusive ROM framework for steady-state\nparameterized partial differential equations (PDEs) that uses convolutional\nautoencoders (CAEs) to provide a nonlinear solution manifold and is augmented\nby Gaussian process regression (GPR) to approximate the expansion coefficients\nof the reduced model. When applied to a numerical example involving the steady\nincompressible Navier-Stokes equations solving a lid-driven cavity problem, it\nis shown that the proposed ROM offers greater performance in prediction of\nfull-order states when compared to a popular method employing POD and GPR over\na number of ROM dimensions.",
    "descriptor": "",
    "authors": [
      "Rakesh Halder",
      "Krzysztof Fidkowski",
      "Kevin Maki"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.08280"
  },
  {
    "id": "arXiv:2204.08285",
    "title": "Information Theory and Point Processes",
    "abstract": "This paper addresses theoretically correct vs. incorrect ways to apply\ninformation theory to point processes.",
    "descriptor": "\nComments: 4 pages, two columns, no figures, no conference (this is a preprint)\n",
    "authors": [
      "Ronald Mahler"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08285"
  },
  {
    "id": "arXiv:2204.08286",
    "title": "A Novel Multi-Task Learning Empowered Codebook Design for Downlink SCMA  Networks",
    "abstract": "Sparse code multiple access (SCMA) is a promising code-domain non-orthogonal\nmultiple access (NOMA) scheme for the enabling of massive machine-type\ncommunication. In SCMA, the design of good sparse codebooks and efficient\nmultiuser decoding have attracted tremendous research attention in the past few\nyears. This paper aims to leverage deep learning to jointly design the downlink\nSCMA encoder and decoder with the aid of autoencoder. We introduce a novel\nend-to-end learning based SCMA (E2E-SCMA) design framework, under which\nimproved sparse codebooks and low-complexity decoder are obtained. Compared to\nconventional SCMA schemes, our numerical results show that the proposed\nE2E-SCMA leads to significant improvements in terms of error rate and\ncomputational complexity.",
    "descriptor": "",
    "authors": [
      "Qu Luo",
      "Zilong Liu",
      "Gaojie Chen",
      "Yi Ma",
      "Pei Xiao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.08286"
  },
  {
    "id": "arXiv:2204.08287",
    "title": "Autocorrelation Invariance Property of Chaos for Wireless Communication",
    "abstract": "A new feature of the chaotic signal generated by chaotic shape-forming filter\n(CSF) is uncovered in this work. We find that, the autocorrelation function\n(ACF) of the transmitting signal generated by CSF keeps the same as that of the\nbase function of CSF, no matter what information is encoded. We derive the\nanalytical equation to describe the relation between the ACF of the received\nsignal and the wireless channel parameters using the ACF of the transmitted\nsignal as prior knowledge revealed by the finding in this work. This new\nproperty can be utilized together with different wireless communication systems\nto improve the system performance. Specially, to demonstrate the improvement,\nchannel state information (CSI) is identified using the chaotic baseband\nwireless communication as a paradigm. Two significant benefits by using the new\nproperty are 1) the CSI can be identified without the probe information known\nto the receiver as done in the conventional wireless communication systems,\nwhich improves the bandwidth efficiency, especially in the time-varying\nchannel; 2) the correlation operation is insensitive to the channel noise,\nwhich improves the identification accuracy as compared to the commonly used\nmethods.",
    "descriptor": "\nComments: 5 pages,4 figures\n",
    "authors": [
      "Hui-Ping Yin",
      "Hai-Peng Ren",
      "Celso Grebogi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08287"
  },
  {
    "id": "arXiv:2204.08292",
    "title": "StepGame: A New Benchmark for Robust Multi-Hop Spatial Reasoning in  Texts",
    "abstract": "Inferring spatial relations in natural language is a crucial ability an\nintelligent system should possess. The bAbI dataset tries to capture tasks\nrelevant to this domain (task 17 and 19). However, these tasks have several\nlimitations. Most importantly, they are limited to fixed expressions, they are\nlimited in the number of reasoning steps required to solve them, and they fail\nto test the robustness of models to input that contains irrelevant or redundant\ninformation. In this paper, we present a new Question-Answering dataset called\nStepGame for robust multi-hop spatial reasoning in texts. Our experiments\ndemonstrate that state-of-the-art models on the bAbI dataset struggle on the\nStepGame dataset. Moreover, we propose a Tensor-Product based Memory-Augmented\nNeural Network (TP-MANN) specialized for spatial reasoning tasks. Experimental\nresults on both datasets show that our model outperforms all the baselines with\nsuperior generalization and robustness performance.",
    "descriptor": "\nComments: AAAI 2022 Camera Ready\n",
    "authors": [
      "Zhengxiang Shi",
      "Qiang Zhang",
      "Aldo Lipani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08292"
  },
  {
    "id": "arXiv:2204.08304",
    "title": "UMass PCL at SemEval-2022 Task 4: Pre-trained Language Model Ensembles  for Detecting Patronizing and Condescending Language",
    "abstract": "Patronizing and condescending language (PCL) is everywhere, but rarely is the\nfocus on its use by media towards vulnerable communities. Accurately detecting\nPCL of this form is a difficult task due to limited labeled data and how subtle\nit can be. In this paper, we describe our system for detecting such language\nwhich was submitted to SemEval 2022 Task 4: Patronizing and Condescending\nLanguage Detection. Our approach uses an ensemble of pre-trained language\nmodels, data augmentation, and optimizing the threshold for detection.\nExperimental results on the evaluation dataset released by the competition\nhosts show that our work is reliably able to detect PCL, achieving an F1 score\nof 55.47% on the binary classification task and a macro F1 score of 36.25% on\nthe fine-grained, multi-label detection task.",
    "descriptor": "\nComments: 9 pages, 1 figure, accepted to SemEval 2022 Task 4\n",
    "authors": [
      "David Koleczek",
      "Alex Scarlatos",
      "Siddha Karakare",
      "Preshma Linet Pereira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08304"
  },
  {
    "id": "arXiv:2204.08306",
    "title": "A Convergence Analysis of Nesterov's Accelerated Gradient Method in  Training Deep Linear Neural Networks",
    "abstract": "Momentum methods, including heavy-ball~(HB) and Nesterov's accelerated\ngradient~(NAG), are widely used in training neural networks for their fast\nconvergence. However, there is a lack of theoretical guarantees for their\nconvergence and acceleration since the optimization landscape of the neural\nnetwork is non-convex. Nowadays, some works make progress towards understanding\nthe convergence of momentum methods in an over-parameterized regime, where the\nnumber of the parameters exceeds that of the training instances. Nonetheless,\ncurrent results mainly focus on the two-layer neural network, which are far\nfrom explaining the remarkable success of the momentum methods in training deep\nneural networks. Motivated by this, we investigate the convergence of NAG with\nconstant learning rate and momentum parameter in training two architectures of\ndeep linear networks: deep fully-connected linear neural networks and deep\nlinear ResNets. Based on the over-parameterization regime, we first analyze the\nresidual dynamics induced by the training trajectory of NAG for a deep\nfully-connected linear neural network under the random Gaussian initialization.\nOur results show that NAG can converge to the global minimum at a $(1 -\n\\mathcal{O}(1/\\sqrt{\\kappa}))^t$ rate, where $t$ is the iteration number and\n$\\kappa > 1$ is a constant depending on the condition number of the feature\nmatrix. Compared to the $(1 - \\mathcal{O}(1/{\\kappa}))^t$ rate of GD, NAG\nachieves an acceleration over GD. To the best of our knowledge, this is the\nfirst theoretical guarantee for the convergence of NAG to the global minimum in\ntraining deep neural networks. Furthermore, we extend our analysis to deep\nlinear ResNets and derive a similar convergence result.",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Xin Liu",
      "Wei Tao",
      "Zhisong Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.08306"
  },
  {
    "id": "arXiv:2204.08307",
    "title": "Heavy Rain Face Image Restoration: Integrating Physical Degradation  Model and Facial Component Guided Adversarial Learning",
    "abstract": "With the recent increase in intelligent CCTVs for visual surveillance, a new\nimage degradation that integrates resolution conversion and synthetic rain\nmodels is required. For example, in heavy rain, face images captured by CCTV\nfrom a distance have significant deterioration in both visibility and\nresolution. Unlike traditional image degradation models (IDM), such as rain\nremoval and superresolution, this study addresses a new IDM referred to as a\nscale-aware heavy rain model and proposes a method for restoring\nhigh-resolution face images (HR-FIs) from low-resolution heavy rain face images\n(LRHR-FI). To this end, a 2-stage network is presented. The first stage\ngenerates low-resolution face images (LR-FIs), from which heavy rain has been\nremoved from the LRHR-FIs to improve visibility. To realize this, an\ninterpretable IDM-based network is constructed to predict physical parameters,\nsuch as rain streaks, transmission maps, and atmospheric light. In addition,\nthe image reconstruction loss is evaluated to enhance the estimates of the\nphysical parameters. For the second stage, which aims to reconstruct the HR-FIs\nfrom the LR-FIs outputted in the first stage, facial component guided\nadversarial learning (FCGAL) is applied to boost facial structure expressions.\nTo focus on informative facial features and reinforce the authenticity of\nfacial components, such as the eyes and nose, a face-parsing-guided generator\nand facial local discriminators are designed for FCGAL. The experimental\nresults verify that the proposed approach based on physical-based network\ndesign and FCGAL can remove heavy rain and increase the resolution and\nvisibility simultaneously. Moreover, the proposed heavy-rain face image\nrestoration outperforms state-of-the-art models of heavy rain removal,\nimage-to-image translation, and superresolution.",
    "descriptor": "",
    "authors": [
      "Chang-Hwan Son",
      "Da-Hee Jeong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08307"
  },
  {
    "id": "arXiv:2204.08308",
    "title": "Saliency in Augmented Reality",
    "abstract": "With the rapid development of multimedia technology, Augmented Reality (AR)\nhas become a promising next-generation mobile platform. The primary theory\nunderlying AR is human visual confusion, which allows users to perceive the\nreal-world scenes and augmented contents (virtual-world scenes) simultaneously\nby superimposing them together. To achieve good Quality of Experience (QoE), it\nis important to understand the interaction between two scenarios, and\nharmoniously display AR contents. However, studies on how this superimposition\nwill influence the human visual attention are lacking. Therefore, in this\npaper, we mainly analyze the interaction effect between background (BG) scenes\nand AR contents, and study the saliency prediction problem in AR. Specifically,\nwe first construct a Saliency in AR Dataset (SARD), which contains 450 BG\nimages, 450 AR images, as well as 1350 superimposed images generated by\nsuperimposing BG and AR images in pair with three mixing levels. A large-scale\neye-tracking experiment among 60 subjects is conducted to collect eye movement\ndata. To better predict the saliency in AR, we propose a vector quantized\nsaliency prediction method and generalize it for AR saliency prediction. For\ncomparison, three benchmark methods are proposed and evaluated together with\nour proposed method on our SARD. Experimental results demonstrate the\nsuperiority of our proposed method on both of the common saliency prediction\nproblem and the AR saliency prediction problem over benchmark methods. Our data\ncollection methodology, dataset, benchmark methods, and proposed saliency\nmodels will be publicly available to facilitate future research.",
    "descriptor": "",
    "authors": [
      "Huiyu Duan",
      "Wei Shen",
      "Xiongkuo Min",
      "Danyang Tu",
      "Jing Li",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08308"
  },
  {
    "id": "arXiv:2204.08309",
    "title": "Tracking monocular camera pose and deformation for SLAM inside the human  body",
    "abstract": "Monocular SLAM in deformable scenes will open the way to multiple medical\napplications like computer-assisted navigation in endoscopy, automatic drug\ndelivery or autonomous robotic surgery. In this paper we propose a novel method\nto simultaneously track the camera pose and the 3D scene deformation, without\nany assumption about environment topology or shape. The method uses an\nillumination-invariant photometric method to track image features and estimates\ncamera motion and deformation combining reprojection error with spatial and\ntemporal regularization of deformations. Our results in simulated colonoscopies\nshow the method's accuracy and robustness in complex scenes under increasing\nlevels of deformation. Our qualitative results in human colonoscopies from\nEndomapper dataset show that the method is able to successfully cope with the\nchallenges of real endoscopies: deformations, low texture and strong\nillumination changes. We also compare with previous tracking methods in simpler\nscenarios from Hamlyn dataset where we obtain competitive performance, without\nneeding any topological assumption.",
    "descriptor": "\nComments: 8 pages, 3 figures, submitted to IROS 2022\n",
    "authors": [
      "Juan J. Gomez Rodriguez",
      "J.M.M Montiel",
      "Juan D. Tardos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08309"
  },
  {
    "id": "arXiv:2204.08311",
    "title": "Application of Transfer Learning and Ensemble Learning in Image-level  Classification for Breast Histopathology",
    "abstract": "Background: Breast cancer has the highest prevalence in women globally. The\nclassification and diagnosis of breast cancer and its histopathological images\nhave always been a hot spot of clinical concern. In Computer-Aided Diagnosis\n(CAD), traditional classification models mostly use a single network to extract\nfeatures, which has significant limitations. On the other hand, many networks\nare trained and optimized on patient-level datasets, ignoring the application\nof lower-level data labels.\nMethod: This paper proposes a deep ensemble model based on image-level labels\nfor the binary classification of benign and malignant lesions of breast\nhistopathological images. First, the BreakHis dataset is randomly divided into\na training, validation and test set. Then, data augmentation techniques are\nused to balance the number of benign and malignant samples. Thirdly,\nconsidering the performance of transfer learning and the complementarity\nbetween each network, VGG-16, Xception, Resnet-50, DenseNet-201 are selected as\nthe base classifiers.\nResult: In the ensemble network model with accuracy as the weight, the\nimage-level binary classification achieves an accuracy of $98.90\\%$. In order\nto verify the capabilities of our method, the latest Transformer and Multilayer\nPerception (MLP) models have been experimentally compared on the same dataset.\nOur model wins with a $5\\%-20\\%$ advantage, emphasizing the ensemble model's\nfar-reaching significance in classification tasks.\nConclusion: This research focuses on improving the model's classification\nperformance with an ensemble algorithm. Transfer learning plays an essential\nrole in small datasets, improving training speed and accuracy. Our model has\noutperformed many existing approaches in accuracy, providing a method for the\nfield of auxiliary medical diagnosis.",
    "descriptor": "",
    "authors": [
      "Yuchao Zheng",
      "Chen Li",
      "Xiaomin Zhou",
      "Haoyuan Chen",
      "Hao Xu",
      "Yixin Li",
      "Haiqing Zhang",
      "Xiaoyan Li",
      "Hongzan Sun",
      "Xinyu Huang",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08311"
  },
  {
    "id": "arXiv:2204.08312",
    "title": "Optimal Coding Theorems in Time-Bounded Kolmogorov Complexity",
    "abstract": "The classical coding theorem in Kolmogorov complexity states that if an\n$n$-bit string $x$ is sampled with probability $\\delta$ by an algorithm with\nprefix-free domain then K$(x) \\leq \\log(1/\\delta) + O(1)$. In a recent work, Lu\nand Oliveira [LO21] established an unconditional time-bounded version of this\nresult, by showing that if $x$ can be efficiently sampled with probability\n$\\delta$ then rKt$(x) = O(\\log(1/\\delta)) + O(\\log n)$, where rKt denotes the\nrandomized analogue of Levin's Kt complexity. Unfortunately, this result is\noften insufficient when transferring applications of the classical coding\ntheorem to the time-bounded setting, as it achieves a $O(\\log(1/\\delta))$ bound\ninstead of the information-theoretic optimal $\\log(1/\\delta)$.\nWe show a coding theorem for rKt with a factor of $2$. As in previous work,\nour coding theorem is efficient in the sense that it provides a polynomial-time\nprobabilistic algorithm that, when given $x$, the code of the sampler, and\n$\\delta$, it outputs, with probability $\\ge 0.99$, a probabilistic\nrepresentation of $x$ that certifies this rKt complexity bound.\nAssuming the security of cryptographic pseudorandom generators, we show that\nno efficient coding theorem can achieve a bound of the form rKt$(x) \\leq (2 -\no(1)) \\cdot \\log(1/\\delta) +$ poly$(\\log n)$. Under a weaker assumption, we\nexhibit a gap between efficient coding theorems and existential coding theorems\nwith near-optimal parameters.\nWe consider pK$^t$ complexity [GKLO22], a variant of rKt where the randomness\nis public and the time bound is fixed. We observe the existence of an optimal\ncoding theorem for pK$^t$, and employ this result to establish an unconditional\nversion of a theorem of Antunes and Fortnow [AF09] which characterizes the\nworst-case running times of languages that are in average polynomial-time over\nall P-samplable distributions.",
    "descriptor": "\nComments: Full version of a paper to be presented at ICALP 2022\n",
    "authors": [
      "Zhenjian Lu",
      "Igor C. Oliveira",
      "Marius Zimand"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2204.08312"
  },
  {
    "id": "arXiv:2204.08317",
    "title": "An alternative approach for distributed parameter estimation under  Gaussian settings",
    "abstract": "This paper takes a different approach for the distributed linear parameter\nestimation over a multi-agent network. The parameter vector is considered to be\nstochastic with a Gaussian distribution. The sensor measurements at each agent\nare linear and corrupted with additive white Gaussian noise. Under such\nsettings, this paper presents a novel distributed estimation algorithm that\nfuses the the concepts of consensus and innovations by incorporating the\nconsensus terms (of neighboring estimates) into the innovation terms. Under the\nassumption of distributed parameter observability, introduced in this paper, we\ndesign the optimal gain matrices such that the distributed estimates are\nconsistent and achieves fast convergence.",
    "descriptor": "\nComments: 10 pages. arXiv admin note: text overlap with arXiv:2203.03521\n",
    "authors": [
      "Subhro Das"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.08317"
  },
  {
    "id": "arXiv:2204.08319",
    "title": "Backward Reachability Analysis for Neural Feedback Loops",
    "abstract": "The increasing prevalence of neural networks (NNs) in safety-critical\napplications calls for methods to certify their behavior and guarantee safety.\nThis paper presents a backward reachability approach for safety verification of\nneural feedback loops (NFLs), i.e., closed-loop systems with NN control\npolicies. While recent works have focused on forward reachability as a strategy\nfor safety certification of NFLs, backward reachability offers advantages over\nthe forward strategy, particularly in obstacle avoidance scenarios. Prior works\nhave developed techniques for backward reachability analysis for systems\nwithout NNs, but the presence of NNs in the feedback loop presents a unique set\nof problems due to the nonlinearities in their activation functions and because\nNN models are generally not invertible. To overcome these challenges, we use\nexisting forward NN analysis tools to find affine bounds on the control inputs\nand solve a series of linear programs (LPs) to efficiently find an\napproximation of the backprojection (BP) set, i.e., the set of states for which\nthe NN control policy will drive the system to a given target set. We present\nan algorithm to iteratively find BP set estimates over a given time horizon and\ndemonstrate the ability to reduce conservativeness in the BP set estimates by\nup to 88% with low additional computational cost. We use numerical results from\na double integrator model to verify the efficacy of these algorithms and\ndemonstrate the ability to certify safety for a linearized ground robot model\nin a collision avoidance scenario where forward reachability fails.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Nicholas Rober",
      "Michael Everett",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.08319"
  },
  {
    "id": "arXiv:2204.08322",
    "title": "A high-resolution canopy height model of the Earth",
    "abstract": "The worldwide variation in vegetation height is fundamental to the global\ncarbon cycle and central to the functioning of ecosystems and their\nbiodiversity. Geospatially explicit and, ideally, highly resolved information\nis required to manage terrestrial ecosystems, mitigate climate change, and\nprevent biodiversity loss. Here, we present the first global, wall-to-wall\ncanopy height map at 10 m ground sampling distance for the year 2020. No single\ndata source meets these requirements: dedicated space missions like GEDI\ndeliver sparse height data, with unprecedented coverage, whereas optical\nsatellite images like Sentinel-2 offer dense observations globally, but cannot\ndirectly measure vertical structures. By fusing GEDI with Sentinel-2, we have\ndeveloped a probabilistic deep learning model to retrieve canopy height from\nSentinel-2 images anywhere on Earth, and to quantify the uncertainty in these\nestimates. The presented approach reduces the saturation effect commonly\nencountered when estimating canopy height from satellite images, allowing to\nresolve tall canopies with likely high carbon stocks. According to our map,\nonly 5% of the global landmass is covered by trees taller than 30 m. Such data\nplay an important role for conservation, e.g., we find that only 34% of these\ntall canopies are located within protected areas. Our model enables consistent,\nuncertainty-informed worldwide mapping and supports an ongoing monitoring to\ndetect change and inform decision making. The approach can serve ongoing\nefforts in forest conservation, and has the potential to foster advances in\nclimate, carbon, and biodiversity modelling.",
    "descriptor": "",
    "authors": [
      "Nico Lang",
      "Walter Jetz",
      "Konrad Schindler",
      "Jan Dirk Wegner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.08322"
  },
  {
    "id": "arXiv:2204.08324",
    "title": "Hierarchical Optimal Transport for Comparing Histopathology Datasets",
    "abstract": "Scarcity of labeled histopathology data limits the applicability of deep\nlearning methods to under-profiled cancer types and labels. Transfer learning\nallows researchers to overcome the limitations of small datasets by\npre-training machine learning models on larger datasets \\emph{similar} to the\nsmall target dataset. However, similarity between datasets is often determined\nheuristically. In this paper, we propose a principled notion of distance\nbetween histopathology datasets based on a hierarchical generalization of\noptimal transport distances. Our method does not require any training, is\nagnostic to model type, and preserves much of the hierarchical structure in\nhistopathology datasets imposed by tiling. We apply our method to H\\&E stained\nslides from The Cancer Genome Atlas from six different cancer types. We show\nthat our method outperforms a baseline distance in a cancer-type prediction\ntask. Our results also show that our optimal transport distance predicts\ndifficulty of transferability in a tumor vs.~normal prediction setting.",
    "descriptor": "",
    "authors": [
      "Anna Yeaton",
      "Rahul G. Krishnan",
      "Rebecca Mieloszyk",
      "David Alvarez-Melis",
      "Grace Huynh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08324"
  },
  {
    "id": "arXiv:2204.08325",
    "title": "GL-CLeF: A Global-Local Contrastive Learning Framework for Cross-lingual  Spoken Language Understanding",
    "abstract": "Due to high data demands of current methods, attention to zero-shot\ncross-lingual spoken language understanding (SLU) has grown, as such approaches\ngreatly reduce human annotation effort. However, existing models solely rely on\nshared parameters, which can only perform implicit alignment across languages.\nWe present Global--Local Contrastive Learning Framework (GL-CLeF) to address\nthis shortcoming. Specifically, we employ contrastive learning, leveraging\nbilingual dictionaries to construct multilingual views of the same utterance,\nthen encourage their representations to be more similar than negative example\npairs, which achieves to explicitly aligned representations of similar\nsentences across languages. In addition, a key step in GL-CLeF is a proposed\nLocal and Global component, which achieves a fine-grained cross-lingual\ntransfer (i.e., sentence-level Local intent transfer, token-level Local slot\ntransfer, and semantic-level Global transfer across intent and slot).\nExperiments on MultiATIS++ show that GL-CLeF achieves the best performance and\nsuccessfully pulls representations of similar sentences across languages\ncloser.",
    "descriptor": "\nComments: Accepted at ACL2022 Main Conference\n",
    "authors": [
      "Libo Qin",
      "Qiguang Chen",
      "Tianbao Xie",
      "Qixin Li",
      "Jian-Guang Lou",
      "Wanxiang Che",
      "Min-Yen Kan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08325"
  },
  {
    "id": "arXiv:2204.08326",
    "title": "MP2: A Momentum Contrast Approach for Recommendation with Pointwise and  Pairwise Learning",
    "abstract": "Binary pointwise labels (aka implicit feedback) are heavily leveraged by deep\nlearning based recommendation algorithms nowadays. In this paper we discuss the\nlimited expressiveness of these labels may fail to accommodate varying degrees\nof user preference, and thus lead to conflicts during model training, which we\ncall annotation bias. To solve this issue, we find the soft-labeling property\nof pairwise labels could be utilized to alleviate the bias of pointwise labels.\nTo this end, we propose a momentum contrast framework (MP2) that combines\npointwise and pairwise learning for recommendation. MP2 has a three-tower\nnetwork structure: one user network and two item networks. The two item\nnetworks are used for computing pointwise and pairwise loss respectively. To\nalleviate the influence of the annotation bias, we perform a momentum update to\nensure a consistent item representation. Extensive experiments on real-world\ndatasets demonstrate the superiority of our method against state-of-the-art\nrecommendation algorithms.",
    "descriptor": "\nComments: This paper was accepted at SIGIR 2022\n",
    "authors": [
      "Menghan Wang",
      "Yuchen Guo",
      "Zhenqi Zhao",
      "Guangzheng Hu",
      "Yuming Shen",
      "Mingming Gong",
      "Philip Torr"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.08326"
  },
  {
    "id": "arXiv:2204.08327",
    "title": "Automatic Encoding and Repair of Reactive High-Level Tasks with Learned  Abstract Representations",
    "abstract": "We present a framework that, given a set of skills a robot can perform,\nabstracts sensor data into symbols that we use to automatically encode the\nrobot's capabilities in Linear Temporal Logic. We specify reactive high-level\ntasks based on these capabilities, for which a strategy is automatically\nsynthesized and executed on the robot, if the task is feasible. If a task is\nnot feasible given the robot's capabilities, we present two methods, one\nenumeration-based and one synthesis-based, for automatically suggesting\nadditional skills for the robot or modifications to existing skills that would\nmake the task feasible. We demonstrate our framework on a Baxter robot\nmanipulating blocks on a table, a Baxter robot manipulating plates on a table,\nand a Kinova arm manipulating vials, with multiple sensor modalities, including\nraw images.",
    "descriptor": "\nComments: 27 pages, 15 figures, Submitted to The International Journal of Robotics Research (IJRR)\n",
    "authors": [
      "Adam Pacheck",
      "Steven James",
      "George Konidaris",
      "Hadas Kress-Gazit"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.08327"
  },
  {
    "id": "arXiv:2204.08329",
    "title": "A Comprehensive Survey on Data-Efficient GANs in Image Generation",
    "abstract": "Generative Adversarial Networks (GANs) have achieved remarkable achievements\nin image synthesis. These successes of GANs rely on large scale datasets,\nrequiring too much cost. With limited training data, how to stable the training\nprocess of GANs and generate realistic images have attracted more attention.\nThe challenges of Data-Efficient GANs (DE-GANs) mainly arise from three\naspects: (i) Mismatch Between Training and Target Distributions, (ii)\nOverfitting of the Discriminator, and (iii) Imbalance Between Latent and Data\nSpaces. Although many augmentation and pre-training strategies have been\nproposed to alleviate these issues, there lacks a systematic survey to\nsummarize the properties, challenges, and solutions of DE-GANs. In this paper,\nwe revisit and define DE-GANs from the perspective of distribution\noptimization. We conclude and analyze the challenges of DE-GANs. Meanwhile, we\npropose a taxonomy, which classifies the existing methods into three\ncategories: Data Selection, GANs Optimization, and Knowledge Sharing. Last but\nnot the least, we attempt to highlight the current problems and the future\ndirections.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Ziqiang Li",
      "Xintian Wu",
      "Beihao Xia",
      "Jing Zhang",
      "Chaoyue Wang",
      "Bin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08329"
  },
  {
    "id": "arXiv:2204.08331",
    "title": "Practical KMP/BM Style Pattern-Matching on Indeterminate Strings",
    "abstract": "In this paper we describe two simple, fast, space-efficient algorithms for\nfinding all matches of an indeterminate pattern $\\s{p} = \\s{p}[1..m]$ in an\nindeterminate string $\\s{x} = \\s{x}[1..n]$, where both \\s{p} and \\s{x} are\ndefined on a \"small\" ordered alphabet $\\Sigma$ -- say, $\\sigma = |\\Sigma| \\le\n9$. Both algorithms depend on a preprocessing phase that replaces $\\Sigma$ by\nan integer alphabet $\\Sigma_I$ of size $\\sigma_I = \\sigma$ which (reversibly,\nin time linear in string length) maps both \\s{x} and \\s{p} into equivalent\nregular strings \\s{y} and \\s{q}, respectively, on $\\Sigma_I$, whose maximum\n(indeterminate) letter can be expressed in a 32-bit word (for $\\sigma \\le 4$,\nthus for DNA sequences, an 8-bit representation suffices). We first describe an\nefficient version \\textsc{KMP\\_Indet} of the venerable Knuth-Morris-Pratt\nalgorithm to find all occurrences of \\s{q} in \\s{y} (that is, of \\s{p} in\n\\s{x}), but, whenever necessary, using the prefix array, rather than the border\narray, to control shifts of the transformed pattern \\s{q} along the transformed\nstring \\s{y}. %Although requiring $\\O(m^2n)$ time in the theoretical worst\ncase, in cases of practical interest \\textsc{KMP\\_Indet} executes in $\\O(n)$\ntime. We go on to describe a similar efficient version \\textsc{BM\\_Indet} of\nthe Boyer-Moore algorithm that turns out to execute significantly faster than\n\\textsc{KMP\\_Indet} over a wide range of test cases. %A noteworthy feature is\nthat both algorithms require very little additional space: $\\Theta(m)$ words.\nWe conjecture that a similar approach may yield practical and efficient\nindeterminate equivalents to other well-known pattern-matching algorithms, in\nparticular the several variants of Boyer-Moore.",
    "descriptor": "",
    "authors": [
      "Hossein Dehghani",
      "Neerja Mhaskar",
      "W. F. Smyth"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.08331"
  },
  {
    "id": "arXiv:2204.08332",
    "title": "BSRT: Improving Burst Super-Resolution with Swin Transformer and  Flow-Guided Deformable Alignment",
    "abstract": "This work addresses the Burst Super-Resolution (BurstSR) task using a new\narchitecture, which requires restoring a high-quality image from a sequence of\nnoisy, misaligned, and low-resolution RAW bursts. To overcome the challenges in\nBurstSR, we propose a Burst Super-Resolution Transformer (BSRT), which can\nsignificantly improve the capability of extracting inter-frame information and\nreconstruction. To achieve this goal, we propose a Pyramid Flow-Guided\nDeformable Convolution Network (Pyramid FG-DCN) and incorporate Swin\nTransformer Blocks and Groups as our main backbone. More specifically, we\ncombine optical flows and deformable convolutions, hence our BSRT can handle\nmisalignment and aggregate the potential texture information in multi-frames\nmore efficiently. In addition, our Transformer-based structure can capture\nlong-range dependency to further improve the performance. The evaluation on\nboth synthetic and real-world tracks demonstrates that our approach achieves a\nnew state-of-the-art in BurstSR task. Further, our BSRT wins the championship\nin the NTIRE2022 Burst Super-Resolution Challenge.",
    "descriptor": "\nComments: Winner method in NTIRE Burst Super-Resolution Challenge Real-World Track\n",
    "authors": [
      "Ziwei Luo",
      "Youwei Li",
      "Shen Cheng",
      "Lei Yu",
      "Qi Wu",
      "Zhihong Wen",
      "Haoqiang Fan",
      "Jian Sun",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08332"
  },
  {
    "id": "arXiv:2204.08334",
    "title": "Time Series Clustering for Grouping Products Based on Price and Sales  Patterns",
    "abstract": "Developing technology and changing lifestyles have made online grocery\ndelivery applications an indispensable part of urban life. Since the beginning\nof the COVID-19 pandemic, the demand for such applications has dramatically\nincreased, creating new competitors that disrupt the market. An increasing\nlevel of competition might prompt companies to frequently restructure their\nmarketing and product pricing strategies. Therefore, identifying the change\npatterns in product prices and sales volumes would provide a competitive\nadvantage for the companies in the marketplace. In this paper, we investigate\nalternative clustering methodologies to group the products based on the price\npatterns and sales volumes. We propose a novel distance metric that takes into\naccount how product prices and sales move together rather than calculating the\ndistance using numerical values. We compare our approach with traditional\nclustering algorithms, which typically rely on generic distance metrics such as\nEuclidean distance, and image clustering approaches that aim to group data by\ncapturing its visual patterns. We evaluate the performances of different\nclustering algorithms using our custom evaluation metric as well as Calinski\nHarabasz and Davies Bouldin indices, which are commonly used internal validity\nmetrics. We conduct our numerical study using a propriety price dataset from an\nonline food and grocery delivery company, and the publicly available Favorita\nsales dataset. We find that our proposed clustering approach and image\nclustering both perform well for finding the products with similar price and\nsales patterns within large datasets.",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Aysun Bozanta",
      "Sean Berry",
      "Mucahit Cevik",
      "Beste Bulut",
      "Deniz Yigit",
      "Fahrettin F. Gonen",
      "Ay\u015fe Ba\u015far"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08334"
  },
  {
    "id": "arXiv:2204.08339",
    "title": "Migrating Face Swap to Mobile Devices: A lightweight Framework and A  Supervised Training Solution",
    "abstract": "Existing face swap methods rely heavily on large-scale networks for adequate\ncapacity to generate visually plausible results, which inhibits its\napplications on resource-constraint platforms. In this work, we propose\nMobileFSGAN, a novel lightweight GAN for face swap that can run on mobile\ndevices with much fewer parameters while achieving competitive performance. A\nlightweight encoder-decoder structure is designed especially for image\nsynthesis tasks, which is only 10.2MB and can run on mobile devices at a\nreal-time speed. To tackle the unstability of training such a small network, we\nconstruct the FSTriplets dataset utilizing facial attribute editing techniques.\nFSTriplets provides source-target-result training triplets, yielding\npixel-level labels thus for the first time making the training process\nsupervised. We also designed multi-scale gradient losses for efficient\nback-propagation, resulting in faster and better convergence. Experimental\nresults show that our model reaches comparable performance towards\nstate-of-the-art methods, while significantly reducing the number of network\nparameters. Codes and the dataset have been released.",
    "descriptor": "\nComments: Accepted to IEEE International Conference on Multimedia and Expo 2022\n",
    "authors": [
      "Haiming Yu",
      "Hao Zhu",
      "Xiangju Lu",
      "Junhui Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08339"
  },
  {
    "id": "arXiv:2204.08345",
    "title": "Extracting Targeted Training Data from ASR Models, and How to Mitigate  It",
    "abstract": "Recent work has designed methods to demonstrate that model updates in ASR\ntraining can leak potentially sensitive attributes of the utterances used in\ncomputing the updates. In this work, we design the first method to demonstrate\ninformation leakage about training data from trained ASR models. We design\nNoise Masking, a fill-in-the-blank style method for extracting targeted parts\nof training data from trained ASR models. We demonstrate the success of Noise\nMasking by using it in four settings for extracting names from the LibriSpeech\ndataset used for training a SOTA Conformer model. In particular, we show that\nwe are able to extract the correct names from masked training utterances with\n11.8% accuracy, while the model outputs some name from the train set 55.2% of\nthe time. Further, we show that even in a setting that uses synthetic audio and\npartial transcripts from the test set, our method achieves 2.5% correct name\naccuracy (47.7% any name success rate). Lastly, we design Word Dropout, a data\naugmentation method that we show when used in training along with MTR, provides\ncomparable utility as the baseline, along with significantly mitigating\nextraction via Noise Masking across the four evaluated settings.",
    "descriptor": "",
    "authors": [
      "Ehsan Amid",
      "Om Thakkar",
      "Arun Narayanan",
      "Rajiv Mathews",
      "Fran\u00e7oise Beaufays"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.08345"
  },
  {
    "id": "arXiv:2204.08348",
    "title": "Automated Test Generation for REST APIs: No Time to Rest Yet",
    "abstract": "Modern web services routinely provide REST APIs for clients to access their\nfunctionality. These APIs present unique challenges and opportunities for\nautomated testing, driving the recent development of many techniques and tools\nthat generate test cases for API endpoints using various strategies.\nUnderstanding how these techniques compare to one another is difficult, as they\nhave been evaluated on different benchmarks and using different metrics. To\nfill this gap, we performed an empirical study aimed to understand the\nlandscape in automated testing of REST APIs and guide future research in this\narea. We first identified, through a systematic selection process, a set of 10\nstate-of-the-art REST API testing tools that included tools developed by both\nresearchers and practitioners. We then applied these tools to a benchmark of 20\nreal-world open-source RESTful services and analyzed their performance in terms\nof code coverage achieved and unique failures triggered. This analysis allowed\nus to identify strengths, weaknesses, and limitations of the tools considered\nand of their underlying strategies, as well as implications of our findings for\nfuture research in this area.",
    "descriptor": "\nComments: 12 pages, 6 figures, In Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA) 2022\n",
    "authors": [
      "Myeongsoo Kim",
      "Qi Xin",
      "Saurabh Sinha",
      "Alessandro Orso"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.08348"
  },
  {
    "id": "arXiv:2204.08352",
    "title": "MHSCNet: A Multimodal Hierarchical Shot-aware Convolutional Network for  Video Summarization",
    "abstract": "Video summarization intends to produce a concise video summary by effectively\ncapturing and combining the most informative parts of the whole content.\nExisting approaches for video summarization regard the task as a frame-wise\nkeyframe selection problem and generally construct the frame-wise\nrepresentation by combining the long-range temporal dependency with the\nunimodal or bimodal information. However, the optimal video summaries need to\nreflect the most valuable keyframe with its own information, and one with\nsemantic power of the whole content. Thus, it is critical to construct a more\npowerful and robust frame-wise representation and predict the frame-level\nimportance score in a fair and comprehensive manner. To tackle the above\nissues, we propose a multimodal hierarchical shot-aware convolutional network,\ndenoted as MHSCNet, to enhance the frame-wise representation via combining the\ncomprehensive available multimodal information. Specifically, we design a\nhierarchical ShotConv network to incorporate the adaptive shot-aware\nframe-level representation by considering the short-range and long-range\ntemporal dependency. Based on the learned shot-aware representations, MHSCNet\ncan predict the frame-level importance score in the local and global view of\nthe video. Extensive experiments on two standard video summarization datasets\ndemonstrate that our proposed method consistently outperforms state-of-the-art\nbaselines. Source code will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Wujiang Xu",
      "Shaoshuai Li",
      "Qiongxu Ma",
      "Yunan Zhao",
      "Sheng Guo",
      "jeff little Guo",
      "Bing Han",
      "Junchi Yan",
      "Yifei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08352"
  },
  {
    "id": "arXiv:2204.08354",
    "title": "Unveiling User Behavior on Summit Login Nodes as a User",
    "abstract": "We observe and analyze usage of the login nodes of the leadership class\nSummit supercomputer from the perspective of an ordinary user -- not a system\nadministrator -- by periodically sampling user activities (job queues, running\nprocesses, etc.) for two full years (2020-2021). Our findings unveil key usage\npatterns that evidence misuse of the system, including gaming the policies,\nimpairing I/O performance, and using login nodes as a sole computing resource.\nOur analysis highlights observed patterns for the execution of complex\ncomputations (workflows), which are key for processing large-scale\napplications.",
    "descriptor": "\nComments: International Conference on Computational Science (ICCS), 2022\n",
    "authors": [
      "Sean R. Wilkinson",
      "Ketan Maheshwari",
      "Rafael Ferreira da Silva"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.08354"
  },
  {
    "id": "arXiv:2204.08358",
    "title": "AutoMLBench: A Comprehensive Experimental Evaluation of Automated  Machine Learning Frameworks",
    "abstract": "Nowadays, machine learning is playing a crucial role in harnessing the power\nof the massive amounts of data that we are currently producing every day in our\ndigital world. With the booming demand for machine learning applications, it\nhas been recognized that the number of knowledgeable data scientists can not\nscale with the growing data volumes and application needs in our digital world.\nIn response to this demand, several automated machine learning (AutoML)\ntechniques and frameworks have been developed to fill the gap of human\nexpertise by automating the process of building machine learning pipelines. In\nthis study, we present a comprehensive evaluation and comparison of the\nperformance characteristics of six popular AutoML frameworks, namely,\nAuto-Weka, AutoSKlearn, TPOT, Recipe, ATM, and SmartML across 100 data sets\nfrom established AutoML benchmark suites. Our experimental evaluation considers\ndifferent aspects for its comparison including the performance impact of\nseveral design decisions including time budget, size of search space,\nmeta-learning, and ensemble construction. The results of our study reveal\nvarious interesting insights that can significantly guide and impact the design\nof AutoML frameworks.",
    "descriptor": "",
    "authors": [
      "Hassan Eldeeb",
      "Mohamed Maher",
      "Oleh Matsuk",
      "Abdelrahman Aldallal",
      "Radwa Elshawi",
      "Sherif Sak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08358"
  },
  {
    "id": "arXiv:2204.08359",
    "title": "Sleeping is Superefficient: MIS in Exponentially Better Awake Complexity",
    "abstract": "Maximal Independent Set (MIS) is one of the central and most well-studied\nproblems in distributed computing. Even after four decades of intensive\nresearch, the best-known (randomized) MIS algorithms take $O(\\log{n})$\nworst-case rounds on general graphs (where $n$ is the number of nodes), while\nthe best-known lower bound is\n$\\Omega\\left(\\sqrt{\\frac{\\log{n}}{\\log{\\log{n}}}}\\right)$ rounds. Breaking past\nthe $O(\\log{n})$ worst-case bound or showing stronger lower bounds have been\nlongstanding open problems.\nOur main contribution is that we show that MIS can be computed in\n(worst-case) awake complexity of $O(\\log \\log n)$ rounds that is (essentially)\nexponentially better compared to the (traditional) round complexity lower bound\nof $\\Omega\\left(\\sqrt{\\frac{\\log{n}}{\\log{\\log{n}}}}\\right)$. Specifically, we\npresent the following results. (1) We present a randomized distributed (Monte\nCarlo) algorithm for MIS that with high probability computes an MIS and has\n$O(\\log\\log{n})$-rounds awake complexity. This algorithm has (traditional) {\\em\nround complexity} that is $O(poly(n))$. Our bounds hold in the\n$CONGEST(O(polylog n))$ model where only $O(polylog n)$ (specifically $O(\\log^3\nn)$) bits are allowed to be sent per edge per round. (2) We also show that we\ncan drastically reduce the round complexity at the cost of a slight increase in\nawake complexity by presenting a randomized MIS algorithm with $O(\\log \\log n\n\\log^* n )$ awake complexity and $O(\\log^3 n \\log \\log n \\log^*n)$ round\ncomplexity in the $CONGEST(O(polylog n))$ model.",
    "descriptor": "\nComments: Abstract shortened to fit arXiv constraints\n",
    "authors": [
      "Fabien Dufoulon",
      "William K. Moses Jr.",
      "Gopal Pandurangan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.08359"
  },
  {
    "id": "arXiv:2204.08360",
    "title": "Zero-Shot Program Representation Learning",
    "abstract": "Learning program representations has been the core prerequisite of code\nintelligent tasks such as code search and code clone detection. The\nstate-of-the-art pre-trained models such as CodeBERT require the availability\nof large-scale code corpora. However, gathering training samples can be costly\nand infeasible for domain-specific languages such as Solidity for smart\ncontracts. In this paper, we propose Zecoler, a zero-shot learning approach for\ncode representations. Zecoler is built upon a pre-trained programming language\nmodel. In order to elicit knowledge from the pre-trained models efficiently,\nZecoler casts the downstream tasks to the same form of pre-training tasks by\ninserting trainable prompts into the original input. Then, it employs the\nprompt learning technique which optimizes the pre-trained model by merely\nadjusting the original input. This enables the representation model to\nefficiently fit the scarce task-oriented data while reusing pre-trained\nknowledge. We evaluate Zecoler in three code intelligent tasks in two program\nlanguages that have no training samples, namely, Solidity and Go, with model\ntrained in corpora of common languages such as Java. Experimental results show\nthat our approach significantly outperforms baseline models in both zero-shot\nand few-shot settings.",
    "descriptor": "\nComments: In 30th International Conference on Program Comprehension (ICPC 22), May 16 to 17, 2022, Virtual Event, Pittsburgh\n",
    "authors": [
      "Nan Cui",
      "Yuze Jiang",
      "Xiaodong Gu",
      "Beijun Shen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.08360"
  },
  {
    "id": "arXiv:2204.08362",
    "title": "Hardware-algorithm collaborative computing with photonic spiking neuron  chip based on integrated Fabry-P\u00e9rot laser with saturable absorber",
    "abstract": "Photonic neuromorphic computing has emerged as a promising avenue toward\nbuilding a low-latency and energy-efficient non-von-Neuman computing system.\nPhotonic spiking neural network (PSNN) exploits brain-like spatiotemporal\nprocessing to realize high-performance neuromorphic computing. However, the\nnonlinear computation of PSNN remains a significant challenging. Here, we\nproposed and fabricated a photonic spiking neuron chip based on an integrated\nFabry-P\\'erot laser with a saturable absorber (FP-SA) for the first time. The\nnonlinear neuron-like dynamics including temporal integration, threshold and\nspike generation, refractory period, and cascadability were experimentally\ndemonstrated, which offers an indispensable fundamental building block to\nconstruct the PSNN hardware. Furthermore, we proposed time-multiplexed spike\nencoding to realize functional PSNN far beyond the hardware integration scale\nlimit. PSNNs with single/cascaded photonic spiking neurons were experimentally\ndemonstrated to realize hardware-algorithm collaborative computing, showing\ncapability in performing classification tasks with supervised learning\nalgorithm, which paves the way for multi-layer PSNN for solving complex tasks.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Shuiying Xiang",
      "Yuechun Shi",
      "Xingxing Guo",
      "Yahui Zhang",
      "Hongji Wang",
      "Dianzhuang Zheng",
      "Ziwei Song",
      "Yanan Han",
      "Shuang Gao",
      "Shihao Zhao",
      "Biling Gu",
      "Hailing Wang",
      "Xiaojun Zhu",
      "Lianping Hou",
      "Xiangfei Chen",
      "Wanhua Zheng",
      "Xiaohua Ma",
      "Yue Hao"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2204.08362"
  },
  {
    "id": "arXiv:2204.08364",
    "title": "Detecting, Tracking and Counting Motorcycle Rider Traffic Violations on  Unconstrained Roads",
    "abstract": "In many Asian countries with unconstrained road traffic conditions, driving\nviolations such as not wearing helmets and triple-riding are a significant\nsource of fatalities involving motorcycles. Identifying and penalizing such\nriders is vital in curbing road accidents and improving citizens' safety. With\nthis motivation, we propose an approach for detecting, tracking, and counting\nmotorcycle riding violations in videos taken from a vehicle-mounted dashboard\ncamera. We employ a curriculum learning-based object detector to better tackle\nchallenging scenarios such as occlusions. We introduce a novel trapezium-shaped\nobject boundary representation to increase robustness and tackle the\nrider-motorcycle association. We also introduce an amodal regressor that\ngenerates bounding boxes for the occluded riders. Experimental results on a\nlarge-scale unconstrained driving dataset demonstrate the superiority of our\napproach compared to existing approaches and other ablative variants.",
    "descriptor": "\nComments: 10 pages, 9 figures, Accepted at The 5th Workshop and Prize Challenge: Bridging the Gap between Computational Photography and Visual Recognition (UG2+) in conjunction with IEEE CVPR 2022\n",
    "authors": [
      "Aman Goyal",
      "Dev Agarwal",
      "Anbumani Subramanian",
      "C.V. Jawahar",
      "Ravi Kiran Sarvadevabhatla",
      "Rohit Saluja"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08364"
  },
  {
    "id": "arXiv:2204.08367",
    "title": "Online RIS Configuration Learning for Arbitrary Large Numbers of $1$-Bit  Phase Resolution Elements",
    "abstract": "Reinforcement Learning (RL) approaches are lately deployed for orchestrating\nwireless communications empowered by Reconfigurable Intelligent Surfaces\n(RISs), leveraging their online optimization capabilities. Most commonly, in\nRL-based formulations for realistic RISs with low resolution phase-tunable\nelements, each configuration is modeled as a distinct reflection action,\nresulting to inefficient exploration due to the exponential nature of the\nsearch space. In this paper, we consider RISs with 1-bit phase resolution\nelements, and model the action of each of them as a binary vector including the\nfeasible reflection coefficients. We then introduce two variations of the\nwell-established Deep Q-Network (DQN) and Deep Deterministic Policy Gradient\n(DDPG) agents, aiming for effective exploration of the binary action spaces.\nFor the case of DQN, we make use of an efficient approximation of the\nQ-function, whereas a discretization post-processing step is applied to the\noutput of DDPG. Our simulation results showcase that the proposed techniques\ngreatly outperform the baseline in terms of the rate maximization objective,\nwhen large-scale RISs are considered. In addition, when dealing with moderate\nscale RIS sizes, where the conventional DQN based on configuration-based action\nspaces is feasible, the performance of the latter technique is similar to the\nproposed learning approach.",
    "descriptor": "\nComments: 5 pages, 3 figures, submitted to an IEEE conference\n",
    "authors": [
      "Kyriakos Stylianopoulos",
      "George C. Alexandropoulos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2204.08367"
  },
  {
    "id": "arXiv:2204.08373",
    "title": "Learning to execute or ask clarification questions",
    "abstract": "Collaborative tasks are ubiquitous activities where a form of communication\nis required in order to reach a joint goal. Collaborative building is one of\nsuch tasks. We wish to develop an intelligent builder agent in a simulated\nbuilding environment (Minecraft) that can build whatever users wish to build by\njust talking to the agent. In order to achieve this goal, such agents need to\nbe able to take the initiative by asking clarification questions when further\ninformation is needed. Existing works on Minecraft Corpus Dataset only learn to\nexecute instructions neglecting the importance of asking for clarifications. In\nthis paper, we extend the Minecraft Corpus Dataset by annotating all builder\nutterances into eight types, including clarification questions, and propose a\nnew builder agent model capable of determining when to ask or execute\ninstructions. Experimental results show that our model achieves\nstate-of-the-art performance on the collaborative building task with a\nsubstantial improvement. We also define two new tasks, the learning to ask task\nand the joint learning task. The latter consists of solving both collaborating\nbuilding and learning to ask tasks jointly.",
    "descriptor": "\nComments: Findings of NAACL 2022\n",
    "authors": [
      "Zhengxiang Shi",
      "Yue Feng",
      "Aldo Lipani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08373"
  },
  {
    "id": "arXiv:2204.08376",
    "title": "Detecting Deepfakes with Self-Blended Images",
    "abstract": "In this paper, we present novel synthetic training data called self-blended\nimages (SBIs) to detect deepfakes. SBIs are generated by blending pseudo source\nand target images from single pristine images, reproducing common forgery\nartifacts (e.g., blending boundaries and statistical inconsistencies between\nsource and target images). The key idea behind SBIs is that more general and\nhardly recognizable fake samples encourage classifiers to learn generic and\nrobust representations without overfitting to manipulation-specific artifacts.\nWe compare our approach with state-of-the-art methods on FF++, CDF, DFD, DFDC,\nDFDCP, and FFIW datasets by following the standard cross-dataset and\ncross-manipulation protocols. Extensive experiments show that our method\nimproves the model generalization to unknown manipulations and scenes. In\nparticular, on DFDC and DFDCP where existing methods suffer from the domain gap\nbetween the training and test sets, our approach outperforms the baseline by\n4.90% and 11.78% points in the cross-dataset evaluation, respectively.",
    "descriptor": "\nComments: CVPR 2022 Oral. Code: this https URL\n",
    "authors": [
      "Kaede Shiohara",
      "Toshihiko Yamasaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08376"
  },
  {
    "id": "arXiv:2204.08377",
    "title": "Strengthening Subcommunities: Towards Sustainable Growth in AI Research",
    "abstract": "AI's rapid growth has been felt acutely by scholarly venues, leading to\ngrowing pains within the peer review process. These challenges largely center\non the inability of specific subareas to identify and evaluate work that is\nappropriate according to criteria relevant to each subcommunity as determined\nby stakeholders of that subarea. We set forth a proposal that re-focuses\nefforts within these subcommunities through a decentralization of the reviewing\nand publication process. Through this re-centering effort, we hope to encourage\neach subarea to confront the issues specific to their process of academic\npublication and incentivization. This model has historically been successful\nfor several subcommunities in AI, and we highlight those instances as examples\nfor how the broader field can continue to evolve despite its continually\ngrowing size.",
    "descriptor": "\nComments: ICLR 2022 ML Evaluation Standards Workshop\n",
    "authors": [
      "Andi Peng",
      "Jessica Zosa Forde",
      "Yonadav Shavit",
      "Jonathan Frankle"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08377"
  },
  {
    "id": "arXiv:2204.08381",
    "title": "Multiple-environment Self-adaptive Network for Aerial-view  Geo-localization",
    "abstract": "Aerial-view geo-localization tends to determine an unknown position through\nmatching the drone-view image with the geo-tagged satellite-view image. This\ntask is mostly regarded as an image retrieval problem. The key underpinning\nthis task is to design a series of deep neural networks to learn discriminative\nimage descriptors. However, existing methods meet large performance drops under\nrealistic weather, such as rain and fog, since they do not take the domain\nshift between the training data and multiple test environments into\nconsideration. To minor this domain gap, we propose a Multiple-environment\nSelf-adaptive Network (MuSe-Net) to dynamically adjust the domain shift caused\nby environmental changing. In particular, MuSe-Net employs a two-branch neural\nnetwork containing one multiple-environment style extraction network and one\nself-adaptive feature extraction network. As the name implies, the\nmultiple-environment style extraction network is to extract the\nenvironment-related style information, while the self-adaptive feature\nextraction network utilizes an adaptive modulation module to dynamically\nminimize the environment-related style gap. Extensive experiments on two\nwidely-used benchmarks, i.e., University-1652 and CVUSA, demonstrate that the\nproposed MuSe-Net achieves a competitive result for geo-localization in\nmultiple environments. Furthermore, we observe that the proposed method also\nshows great potential to the unseen extreme weather, such as mixing the fog,\nrain and snow.",
    "descriptor": "",
    "authors": [
      "Tingyu Wang",
      "Zhedong Zheng",
      "Yaoqi Sun",
      "Tat-Seng Chua",
      "Yi Yang",
      "Chenggang Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08381"
  },
  {
    "id": "arXiv:2204.08382",
    "title": "Subspace Nonnegative Matrix Factorization for Feature Representation",
    "abstract": "Traditional nonnegative matrix factorization (NMF) learns a new feature\nrepresentation on the whole data space, which means treating all features\nequally. However, a subspace is often sufficient for accurate representation in\npractical applications, and redundant features can be invalid or even harmful.\nFor example, if a camera has some sensors destroyed, then the corresponding\npixels in the photos from this camera are not helpful to identify the content,\nwhich means only the subspace consisting of remaining pixels is worthy of\nattention. This paper proposes a new NMF method by introducing adaptive weights\nto identify key features in the original space so that only a subspace involves\ngenerating the new representation. Two strategies are proposed to achieve this:\nthe fuzzier weighted technique and entropy regularized weighted technique, both\nof which result in an iterative solution with a simple form. Experimental\nresults on several real-world datasets demonstrated that the proposed methods\ncan generate a more accurate feature representation than existing methods. The\ncode developed in this study is available at\nhttps://github.com/WNMF1/FWNMF-ERWNMF.",
    "descriptor": "",
    "authors": [
      "Junhang Li",
      "Jiao Wei",
      "Can Tong",
      "Tingting Shen",
      "Yuchen Liu",
      "Chen Li",
      "Shouliang Qi",
      "Yudong Yao",
      "Yueyang Teng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08382"
  },
  {
    "id": "arXiv:2204.08383",
    "title": "'I think I discovered a military base in the middle of the ocean' --  Null Island, the most real of fictional places",
    "abstract": "This paper explores Null Island, a fictional place located at 0$^\\circ$\nlatitude and 0$^\\circ$ longitude in the WGS84 geographic coordinate system.\nNull Island is erroneously associated with large amounts of geographic data in\na wide variety of location-based services, place databases, social media and\nweb-based maps. While it was originally considered a joke within the geospatial\ncommunity, this article will demonstrate implications of its existence, both\ntechnological and social in nature, promoting Null Island as a fundamental\nissue of geographic information that requires more widespread awareness. The\narticle summarizes error sources that lead to data being associated with Null\nIsland. We identify four evolutionary phases which help explain how this\nfictional place evolved and established itself as an entity reaching beyond the\ngeospatial profession to the point of being discovered by the visual arts and\nthe general population. After providing an accurate account of data that can be\nfound at (0, 0), geospatial, technological and social implications of Null\nIsland are discussed. Guidelines to avoid misplacing data to Null Island are\nprovided. Since data will likely continue to appear at this location, our\ncontribution is aimed at both GIScientists and the general population to\npromote awareness of this error source.",
    "descriptor": "\nComments: Submitted to: International Journal of Geographic Information Science\n",
    "authors": [
      "Levente Juhasz",
      "Peter Mooney"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2204.08383"
  },
  {
    "id": "arXiv:2204.08385",
    "title": "Distributed MST Computation in the Sleeping Model: Awake-Optimal  Algorithms and Lower Bounds",
    "abstract": "We study the distributed minimum spanning tree (MST) problem, a fundamental\nproblem in distributed computing. It is well-known that distributed MST can be\nsolved in $\\tilde{O}(D+\\sqrt{n})$ rounds in the standard CONGEST model (where\n$n$ is the network size and $D$ is the network diameter) and this is\nessentially the best possible round complexity (up to logarithmic factors).\nHowever, in resource-constrained networks such as ad hoc wireless and sensor\nnetworks, nodes spending so much time can lead to significant spending of\nresources such as energy.\nMotivated by the above consideration, we study distributed algorithms for MST\nunder the \\emph{sleeping model} [Chatterjee et al., PODC 2020], a model for\ndesign and analysis of resource-efficient distributed algorithms. In the\nsleeping model, a node can be in one of two modes in any round --\n\\emph{sleeping} or \\emph{awake} (unlike the traditional model where nodes are\nalways awake). Only the rounds in which a node is \\emph{awake} are counted,\nwhile \\emph{sleeping} rounds are ignored. A node spends resources only in the\nawake rounds and hence the main goal is to minimize the \\emph{awake complexity}\nof a distributed algorithm, the worst-case number of rounds any node is awake.\nWe present deterministic and randomized distributed MST algorithms that have\nan \\emph{optimal} awake complexity of $O(\\log n)$ time with a matching lower\nbound. We also show that our randomized awake-optimal algorithm has essentially\nthe best possible round complexity by presenting a lower bound of\n$\\tilde{\\Omega}(n)$ on the product of the awake and round complexity of any\ndistributed algorithm (including randomized) that outputs an MST, where\n$\\tilde{\\Omega}$ hides a $1/(\\text{polylog } n)$ factor.",
    "descriptor": "\nComments: 28 pages, 1 table, 5 figures, abstract modified to fit arXiv constraints\n",
    "authors": [
      "John Augustine",
      "William K. Moses Jr.",
      "Gopal Pandurangan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.08385"
  },
  {
    "id": "arXiv:2204.08387",
    "title": "LayoutLMv3: Pre-training for Document AI with Unified Text and Image  Masking",
    "abstract": "Self-supervised pre-training techniques have achieved remarkable progress in\nDocument AI. Most multimodal pre-trained models use a masked language modeling\nobjective to learn bidirectional representations on the text modality, but they\ndiffer in pre-training objectives for the image modality. This discrepancy adds\ndifficulty to multimodal representation learning. In this paper, we propose\nLayoutLMv3 to pre-train multimodal Transformers for Document AI with unified\ntext and image masking. Additionally, LayoutLMv3 is pre-trained with a\nword-patch alignment objective to learn cross-modal alignment by predicting\nwhether the corresponding image patch of a text word is masked. The simple\nunified architecture and training objectives make LayoutLMv3 a general-purpose\npre-trained model for both text-centric and image-centric Document AI tasks.\nExperimental results show that LayoutLMv3 achieves state-of-the-art performance\nnot only in text-centric tasks, including form understanding, receipt\nunderstanding, and document visual question answering, but also in\nimage-centric tasks such as document image classification and document layout\nanalysis. The code and models are publicly available at\nhttps://aka.ms/layoutlmv3.",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Yupan Huang",
      "Tengchao Lv",
      "Lei Cui",
      "Yutong Lu",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08387"
  },
  {
    "id": "arXiv:2204.08394",
    "title": "CenterNet++ for Object Detection",
    "abstract": "There are two mainstreams for object detection: top-down and bottom-up. The\nstate-of-the-art approaches mostly belong to the first category. In this paper,\nwe demonstrate that the bottom-up approaches are as competitive as the top-down\nand enjoy higher recall. Our approach, named CenterNet, detects each object as\na triplet keypoints (top-left and bottom-right corners and the center\nkeypoint). We firstly group the corners by some designed cues and further\nconfirm the objects by the center keypoints. The corner keypoints equip the\napproach with the ability to detect objects of various scales and shapes and\nthe center keypoint avoids the confusion brought by a large number of\nfalse-positive proposals. Our approach is a kind of anchor-free detector\nbecause it does not need to define explicit anchor boxes. We adapt our approach\nto the backbones with different structures, i.e., the 'hourglass' like networks\nand the the 'pyramid' like networks, which detect objects on a\nsingle-resolution feature map and multi-resolution feature maps, respectively.\nOn the MS-COCO dataset, CenterNet with Res2Net-101 and Swin-Transformer\nachieves APs of 53.7% and 57.1%, respectively, outperforming all existing\nbottom-up detectors and achieving state-of-the-art. We also design a real-time\nCenterNet, which achieves a good trade-off between accuracy and speed with an\nAP of 43.6% at 30.5 FPS. https://github.com/Duankaiwen/PyCenterNet.",
    "descriptor": "\nComments: 11 pages, 9 figures, 8 tables. arXiv admin note: substantial text overlap with arXiv:1904.08189\n",
    "authors": [
      "Kaiwen Duan",
      "Song Bai",
      "Lingxi Xie",
      "Honggang Qi",
      "Qingming Huang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08394"
  },
  {
    "id": "arXiv:2204.08396",
    "title": "StableMoE: Stable Routing Strategy for Mixture of Experts",
    "abstract": "The Mixture-of-Experts (MoE) technique can scale up the model size of\nTransformers with an affordable computational overhead. We point out that\nexisting learning-to-route MoE methods suffer from the routing fluctuation\nissue, i.e., the target expert of the same input may change along with\ntraining, but only one expert will be activated for the input during inference.\nThe routing fluctuation tends to harm sample efficiency because the same input\nupdates different experts but only one is finally used. In this paper, we\npropose StableMoE with two training stages to address the routing fluctuation\nproblem. In the first training stage, we learn a balanced and cohesive routing\nstrategy and distill it into a lightweight router decoupled from the backbone\nmodel. In the second training stage, we utilize the distilled router to\ndetermine the token-to-expert assignment and freeze it for a stable routing\nstrategy. We validate our method on language modeling and multilingual machine\ntranslation. The results show that StableMoE outperforms existing MoE methods\nin terms of both convergence speed and performance.",
    "descriptor": "\nComments: ACL-2022\n",
    "authors": [
      "Damai Dai",
      "Li Dong",
      "Shuming Ma",
      "Bo Zheng",
      "Zhifang Sui",
      "Baobao Chang",
      "Furu Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08396"
  },
  {
    "id": "arXiv:2204.08398",
    "title": "L3Cube-HingCorpus and HingBERT: A Code Mixed Hindi-English Dataset and  BERT Language Models",
    "abstract": "Code-switching occurs when more than one language is mixed in a given\nsentence or a conversation. This phenomenon is more prominent on social media\nplatforms and its adoption is increasing over time. Therefore code-mixed NLP\nhas been extensively studied in the literature. As pre-trained\ntransformer-based architectures are gaining popularity, we observe that real\ncode-mixing data are scarce to pre-train large language models. We present\nL3Cube-HingCorpus, the first large-scale real Hindi-English code mixed data in\na Roman script. It consists of 52.93M sentences and 1.04B tokens, scraped from\nTwitter. We further present HingBERT, HingMBERT, HingRoBERTa, and HingGPT. The\nBERT models have been pre-trained on codemixed HingCorpus using masked language\nmodelling objectives. We show the effectiveness of these BERT models on the\nsubsequent downstream tasks like code-mixed sentiment analysis, POS tagging,\nNER, and LID from the GLUECoS benchmark. The HingGPT is a GPT2 based generative\ntransformer model capable of generating full tweets. We also release\nL3Cube-HingLID Corpus, the largest code-mixed Hindi-English language\nidentification(LID) dataset and HingBERT-LID, a production-quality LID model to\nfacilitate capturing of more code-mixed data using the process outlined in this\nwork. The dataset and models are available at\nhttps://github.com/l3cube-pune/code-mixed-nlp .",
    "descriptor": "",
    "authors": [
      "Ravindra Nayak",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08398"
  },
  {
    "id": "arXiv:2204.08399",
    "title": "Unsupervised Contrastive Domain Adaptation for Semantic Segmentation",
    "abstract": "Semantic segmentation models struggle to generalize in the presence of domain\nshift. In this paper, we introduce contrastive learning for feature alignment\nin cross-domain adaptation. We assemble both in-domain contrastive pairs and\ncross-domain contrastive pairs to learn discriminative features that align\nacross domains. Based on the resulting well-aligned feature representations we\nintroduce a label expansion approach that is able to discover samples from hard\nclasses during the adaptation process to further boost performance. The\nproposed approach consistently outperforms state-of-the-art methods for domain\nadaptation. It achieves 60.2% mIoU on the Cityscapes dataset when training on\nthe synthetic GTA5 dataset together with unlabeled Cityscapes images.",
    "descriptor": "",
    "authors": [
      "Feihu Zhang",
      "Vladlen Koltun",
      "Philip Torr",
      "Ren\u00e9 Ranftl",
      "Stephan R. Richter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08399"
  },
  {
    "id": "arXiv:2204.08400",
    "title": "Dynamic Network Adaptation at Inference",
    "abstract": "Machine learning (ML) inference is a real-time workload that must comply with\nstrict Service Level Objectives (SLOs), including latency and accuracy targets.\nUnfortunately, ensuring that SLOs are not violated in inference-serving systems\nis challenging due to inherent model accuracy-latency tradeoffs, SLO diversity\nacross and within application domains, evolution of SLOs over time,\nunpredictable query patterns, and co-location interference. In this paper, we\nobserve that neural networks exhibit high degrees of per-input activation\nsparsity during inference. . Thus, we propose SLO-Aware Neural Networks which\ndynamically drop out nodes per-inference query, thereby tuning the amount of\ncomputation performed, according to specified SLO optimization targets and\nmachine utilization. SLO-Aware Neural Networks achieve average speedups of\n$1.3-56.7\\times$ with little to no accuracy loss (less than 0.3%). When\naccuracy constrained, SLO-Aware Neural Networks are able to serve a range of\naccuracy targets at low latency with the same trained model. When latency\nconstrained, SLO-Aware Neural Networks can proactively alleviate latency\ndegradation from co-location interference while maintaining high accuracy to\nmeet latency constraints.",
    "descriptor": "",
    "authors": [
      "Daniel Mendoza",
      "Caroline Trippel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2204.08400"
  },
  {
    "id": "arXiv:2204.08401",
    "title": "TranS: Transition-based Knowledge Graph Embedding with Synthetic  Relation Representation",
    "abstract": "Knowledge graph embedding (KGE) aims to learn continuous vectors of relations\nand entities in knowledge graph. Recently, transition-based KGE methods have\nachieved promising performance, where the single relation vector learns to\ntranslate head entity to tail entity. However, this scoring pattern is not\nsuitable for complex scenarios where the same entity pair has different\nrelations. Previous models usually focus on the improvement of entity\nrepresentation for 1-to-N, N-to-1 and N-to-N relations, but ignore the single\nrelation vector. In this paper, we propose a novel transition-based method,\nTranS, for knowledge graph embedding. The single relation vector in traditional\nscoring patterns is replaced with synthetic relation representation, which can\nsolve these issues effectively and efficiently. Experiments on a large\nknowledge graph dataset, ogbl-wikikg2, show that our model achieves\nstate-of-the-art results.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Xuanyu Zhang",
      "Qing Yang",
      "Dongliang Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08401"
  },
  {
    "id": "arXiv:2204.08403",
    "title": "An Iterative Decoupled Algorithm with Unconditional Stability for Biot  Model",
    "abstract": "This paper is concerned with numerical algorithms for Biot model. By\nintroducing an intermediate variable, the classical 2-field Biot model is\nwritten into a 3-field formulation. Based on such a 3-field formulation, we\npropose a coupled algorithm, some time-extrapolation based decoupled\nalgorithms, and an iterative decoupled algorithm. Our focus is the analysis of\nthe iterative decoupled algorithm. It is shown that the convergence of the\niterative decoupled algorithm requires no extra assumptions on physical\nparameters or stabilization parameters. Numerical experiments are provided to\ndemonstrate the accuracy and efficiency of the proposed method.",
    "descriptor": "",
    "authors": [
      "Huipeng Gu",
      "Mingchao Cai",
      "Jingzhi Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.08403"
  },
  {
    "id": "arXiv:2204.08404",
    "title": "Low Degree Testing over the Reals",
    "abstract": "We study the problem of testing whether a function $f: \\mathbb{R}^n \\to\n\\mathbb{R}$ is a polynomial of degree at most $d$ in the\n\\emph{distribution-free} testing model. Here, the distance between functions is\nmeasured with respect to an unknown distribution $\\mathcal{D}$ over\n$\\mathbb{R}^n$ from which we can draw samples. In contrast to previous work, we\ndo not assume that $\\mathcal{D}$ has finite support.\nWe design a tester that given query access to $f$, and sample access to\n$\\mathcal{D}$, makes $(d/\\varepsilon)^{O(1)}$ many queries to $f$, accepts with\nprobability $1$ if $f$ is a polynomial of degree $d$, and rejects with\nprobability at least $2/3$ if every degree-$d$ polynomial $P$ disagrees with\n$f$ on a set of mass at least $\\varepsilon$ with respect to $\\mathcal{D}$. Our\nresult also holds under mild assumptions when we receive only a polynomial\nnumber of bits of precision for each query to $f$, or when $f$ can only be\nqueried on rational points representable using a logarithmic number of bits.\nAlong the way, we prove a new stability theorem for multivariate polynomials\nthat may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Vipul Arora",
      "Arnab Bhattacharyya",
      "Noah Fleming",
      "Esty Kelman",
      "Yuichi Yoshida"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.08404"
  },
  {
    "id": "arXiv:2204.08405",
    "title": "Zero-shot Entity and Tweet Characterization with Designed Conditional  Prompts and Contexts",
    "abstract": "Online news and social media have been the de facto mediums to disseminate\ninformation globally from the beginning of the last decade. However, bias in\ncontent and purpose of intentions are not regulated, and managing bias is the\nresponsibility of content consumers. In this regard, understanding the stances\nand biases of news sources towards specific entities becomes important. To\naddress this problem, we use pretrained language models, which have been shown\nto bring about good results with no task-specific training or few-shot\ntraining. In this work, we approach the problem of characterizing Named\nEntities and Tweets as an open-ended text classification and open-ended fact\nprobing problem.We evaluate the zero-shot language model capabilities of\nGenerative Pretrained Transformer 2 (GPT-2) to characterize Entities and Tweets\nsubjectively with human psychology-inspired and logical conditional prefixes\nand contexts. First, we fine-tune the GPT-2 model on a sufficiently large news\ncorpus and evaluate subjective characterization of popular entities in the\ncorpus by priming with prefixes. Second, we fine-tune GPT-2 with a Tweets\ncorpus from a few popular hashtags and evaluate characterizing tweets by\npriming the language model with prefixes, questions, and contextual synopsis\nprompts. Entity characterization results were positive across measures and\nhuman evaluation.",
    "descriptor": "",
    "authors": [
      "Sharath Srivatsa",
      "Tushar Mohan",
      "Kumari Neha",
      "Nishchay Malakar",
      "Ponnurangam Kumaraguru",
      "Srinath Srinivasa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.08405"
  },
  {
    "id": "arXiv:2204.08409",
    "title": "Caption Feature Space Regularization for Audio Captioning",
    "abstract": "Audio captioning aims at describing the content of audio clips with human\nlanguage. Due to the ambiguity of audio, different people may perceive the same\naudio differently, resulting in caption disparities (i.e., one audio may\ncorrelate to several captions with diverse semantics). For that, general audio\ncaptioning models achieve the one-to-many training by randomly selecting a\ncorrelated caption as the ground truth for each audio. However, it leads to a\nsignificant variation in the optimization directions and weakens the model\nstability. To eliminate this negative effect, in this paper, we propose a\ntwo-stage framework for audio captioning: (i) in the first stage, via the\ncontrastive learning, we construct a proxy feature space to reduce the\ndistances between captions correlated to the same audio, and (ii) in the second\nstage, the proxy feature space is utilized as additional supervision to\nencourage the model to be optimized in the direction that benefits all the\ncorrelated captions. We conducted extensive experiments on two datasets using\nfour commonly used encoder and decoder architectures. Experimental results\ndemonstrate the effectiveness of the proposed method. The code is available at\nhttps://github.com/PRIS-CV/Caption-Feature-Space-Regularization.",
    "descriptor": "",
    "authors": [
      "Yiming Zhang",
      "Hong Yu",
      "Ruoyi Du",
      "Zhanyu Ma",
      "Yuan Dong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.08409"
  },
  {
    "id": "arXiv:2204.08412",
    "title": "Temporally Efficient Vision Transformer for Video Instance Segmentation",
    "abstract": "Recently vision transformer has achieved tremendous success on image-level\nvisual recognition tasks. To effectively and efficiently model the crucial\ntemporal information within a video clip, we propose a Temporally Efficient\nVision Transformer (TeViT) for video instance segmentation (VIS). Different\nfrom previous transformer-based VIS methods, TeViT is nearly convolution-free,\nwhich contains a transformer backbone and a query-based video instance\nsegmentation head. In the backbone stage, we propose a nearly parameter-free\nmessenger shift mechanism for early temporal context fusion. In the head\nstages, we propose a parameter-shared spatiotemporal query interaction\nmechanism to build the one-to-one correspondence between video instances and\nqueries. Thus, TeViT fully utilizes both framelevel and instance-level temporal\ncontext information and obtains strong temporal modeling capacity with\nnegligible extra computational cost. On three widely adopted VIS benchmarks,\ni.e., YouTube-VIS-2019, YouTube-VIS-2021, and OVIS, TeViT obtains\nstate-of-the-art results and maintains high inference speed, e.g., 46.6 AP with\n68.9 FPS on YouTube-VIS-2019. Code is available at\nhttps://github.com/hustvl/TeViT.",
    "descriptor": "\nComments: To appear in CVPR 2022\n",
    "authors": [
      "Shusheng Yang",
      "Xinggang Wang",
      "Yu Li",
      "Yuxin Fang",
      "Jiemin Fang",
      "Wenyu Liu",
      "Xun Zhao",
      "Ying Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08412"
  },
  {
    "id": "arXiv:2204.08414",
    "title": "STONet: A Neural-Operator-Driven Spatio-temporal Network",
    "abstract": "Graph-based spatio-temporal neural networks are effective to model the\nspatial dependency among discrete points sampled irregularly from unstructured\ngrids, thanks to the great expressiveness of graph neural networks. However,\nthese models are usually spatially-transductive -- only fitting the signals for\ndiscrete spatial nodes fed in models but unable to generalize to `unseen'\nspatial points with zero-shot. In comparison, for forecasting tasks on\ncontinuous space such as temperature prediction on the earth's surface, the\n\\textit{spatially-inductive} property allows the model to generalize to any\npoint in the spatial domain, demonstrating models' ability to learn the\nunderlying mechanisms or physics laws of the systems, rather than simply fit\nthe signals. Besides, in temporal domains, \\textit{irregularly-sampled} time\nseries, e.g. data with missing values, urge models to be temporally-continuous.\nMotivated by the two issues, we propose a spatio-temporal framework based on\nneural operators for PDEs, which learn the underlying mechanisms governing the\ndynamics of spatially-continuous physical quantities. Experiments show our\nmodel's improved performance on forecasting spatially-continuous physic\nquantities, and its superior generalization to unseen spatial points and\nability to handle temporally-irregular data.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Haitao Lin",
      "Guojiang Zhao",
      "Lirong Wu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08414"
  },
  {
    "id": "arXiv:2204.08415",
    "title": "Exploring Dimensionality Reduction Techniques in Multilingual  Transformers",
    "abstract": "Both in scientific literature and in industry,, Semantic and context-aware\nNatural Language Processing-based solutions have been gaining importance in\nrecent years. The possibilities and performance shown by these models when\ndealing with complex Language Understanding tasks is unquestionable, from\nconversational agents to the fight against disinformation in social networks.\nIn addition, considerable attention is also being paid to developing\nmultilingual models to tackle the language bottleneck. The growing need to\nprovide more complex models implementing all these features has been\naccompanied by an increase in their size, without being conservative in the\nnumber of dimensions required. This paper aims to give a comprehensive account\nof the impact of a wide variety of dimensional reduction techniques on the\nperformance of different state-of-the-art multilingual Siamese Transformers,\nincluding unsupervised dimensional reduction techniques such as linear and\nnonlinear feature extraction, feature selection, and manifold techniques. In\norder to evaluate the effects of these techniques, we considered the\nmultilingual extended version of Semantic Textual Similarity Benchmark (mSTSb)\nand two different baseline approaches, one using the pre-trained version of\nseveral models and another using their fine-tuned STS version. The results\nevidence that it is possible to achieve an average reduction in the number of\ndimensions of $91.58\\% \\pm 2.59\\%$ and $54.65\\% \\pm 32.20\\%$, respectively.\nThis work has also considered the consequences of dimensionality reduction for\nvisualization purposes. The results of this study will significantly contribute\nto the understanding of how different tuning approaches affect performance on\nsemantic-aware tasks and how dimensional reduction techniques deal with the\nhigh-dimensional embeddings computed for the STS task and their potential for\nhighly demanding NLP tasks",
    "descriptor": "\nComments: 22 pages, 4 figures and 8 tables\n",
    "authors": [
      "\u00c1lvaro Huertas-Garc\u00eda",
      "Alejandro Mart\u00edn",
      "Javier Huertas-Tato",
      "David Camacho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08415"
  },
  {
    "id": "arXiv:2204.08417",
    "title": "Linear codes using simplicial complexes",
    "abstract": "Certain simplicial complexes are used to construct a subset $D$ of\n$\\mathbb{F}_{2^n}^m$ and $D$, in turn, defines the linear code $C_{D}$ over\n$\\mathbb{F}_{2^n}$ that consists of $(v\\cdot d)_{d\\in D}$ for $v\\in\n\\mathbb{F}_{2^n}^m$. Here we deal with the case $n=3$, that is, when $C_{D}$ is\nan octanary code. We establish a relation between $C_{D}$ and its binary\nsubfield code $C_{D}^{(2)}$ with the help of a generator matrix. For a given\nlength and dimension, a code is called distance optimal if it has the highest\npossible distance. With respect to the Griesmer bound, five infinite families\nof distance optimal codes are obtained, and sufficient conditions for certain\nlinear codes to be minimal are established.",
    "descriptor": "",
    "authors": [
      "Vidya Sagar",
      "Ritumoni Sarma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08417"
  },
  {
    "id": "arXiv:2204.08426",
    "title": "CHAI: A CHatbot AI for Task-Oriented Dialogue with Offline Reinforcement  Learning",
    "abstract": "Conventionally, generation of natural language for dialogue agents may be\nviewed as a statistical learning problem: determine the patterns in\nhuman-provided data and generate appropriate responses with similar statistical\nproperties. However, dialogue can also be regarded as a goal directed process,\nwhere speakers attempt to accomplish a specific task. Reinforcement learning\n(RL) algorithms are designed specifically for solving such goal-directed\nproblems, but the most direct way to apply RL -- through trial-and-error\nlearning in human conversations, -- is costly. In this paper, we study how\noffline reinforcement learning can instead be used to train dialogue agents\nentirely using static datasets collected from human speakers. Our experiments\nshow that recently developed offline RL methods can be combined with language\nmodels to yield realistic dialogue agents that better accomplish task goals.",
    "descriptor": "",
    "authors": [
      "Siddharth Verma",
      "Justin Fu",
      "Mengjiao Yang",
      "Sergey Levine"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08426"
  },
  {
    "id": "arXiv:2204.08437",
    "title": "Strolling in Room-Scale VR: Hex-Core-MK1 Omnidirectional Treadmill",
    "abstract": "The natural locomotion interface is critical to the development of many VR\napplications. For household VR applications, there are two basic requirements:\nnatural immersive experience and minimized space occupation. The existing\nlocomotion strategies generally do not simultaneously satisfy these two\nrequirements well. This paper presents a novel omnidirectional treadmill (ODT)\nsystem, named Hex-Core-MK1 (HCMK1). By implementing two kinds of mirror\nsymmetrical spiral rollers to generate the omnidirectional velocity field, this\nproposed system is capable of providing real walking experiences with a\nfull-degree of freedom in an area as small as 1.76 m^2, while delivering great\nadvantages over several existing ODT systems in terms of weight, volume,\nlatency and dynamic performance. Compared with the sizes of Infinadeck and HCP,\nthe two best motor-driven ODTs so far, the 8 cm height of HCMK1 is only 20% of\nInfinadeck and 50% of HCP. In addition, HCMK1 is a lightweight device weighing\nonly 110 kg, which provides possibilities of further expanding VR scenarios,\nsuch as terrain simulation. The latency of HCMK1 is only 23ms. The experiments\nshow that HCMK1 can deliver on a starting acceleration of 16.00 m/s^2 and a\nbraking acceleration of 30.00 m/s^2.",
    "descriptor": "\nComments: 12 pages, 12 figures, TVCG under review\n",
    "authors": [
      "Ziyao Wang",
      "Chiyi Liu",
      "Jialiang Chen",
      "Yao Yao",
      "Dazheng Fang",
      "Zhiyi Shi",
      "Rui Yan",
      "Yiye Wang",
      "KanJian Zhang",
      "Hai Wang",
      "Haikun Wei"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.08437"
  },
  {
    "id": "arXiv:2204.08442",
    "title": "Deep Equilibrium Optical Flow Estimation",
    "abstract": "Many recent state-of-the-art (SOTA) optical flow models use finite-step\nrecurrent update operations to emulate traditional algorithms by encouraging\niterative refinements toward a stable flow estimation. However, these RNNs\nimpose large computation and memory overheads, and are not directly trained to\nmodel such stable estimation. They can converge poorly and thereby suffer from\nperformance degradation. To combat these drawbacks, we propose deep equilibrium\n(DEQ) flow estimators, an approach that directly solves for the flow as the\ninfinite-level fixed point of an implicit layer (using any black-box solver),\nand differentiates through this fixed point analytically (thus requiring $O(1)$\ntraining memory). This implicit-depth approach is not predicated on any\nspecific model, and thus can be applied to a wide range of SOTA flow estimation\nmodel designs. The use of these DEQ flow estimators allows us to compute the\nflow faster using, e.g., fixed-point reuse and inexact gradients, consumes\n$4\\sim6\\times$ times less training memory than the recurrent counterpart, and\nachieves better results with the same computation budget. In addition, we\npropose a novel, sparse fixed-point correction scheme to stabilize our DEQ flow\nestimators, which addresses a longstanding challenge for DEQ models in general.\nWe test our approach in various realistic settings and show that it improves\nSOTA methods on Sintel and KITTI datasets with substantially better\ncomputational and memory efficiency.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Shaojie Bai",
      "Zhengyang Geng",
      "Yash Savani",
      "J. Zico Kolter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08442"
  },
  {
    "id": "arXiv:2204.08444",
    "title": "Network Onion Divergence: Network representation and comparison using  nested configuration models with fixed connectivity, correlation and  centrality patterns",
    "abstract": "Random networks, constrained to reproduce specific features of networks, are\noften used to represent and analyze network data as well as their mathematical\ndescriptions. Chief among them, the configuration model constrains random\nnetworks by their degree distribution and is foundational to many areas of\nnetwork science. However, these representations are often selected based on\nintuition or mathematical and computational simplicity rather than on\nstatistical evidence. To evaluate the quality of a network representation we\nneed to consider both the amount of information required by a random network\nmodel as well as the probability of recovering the original data when using the\nmodel as a generative process. To this end, we calculate the approximate size\nof network ensembles generated by the popular configuration model and its\ngeneralizations that include degree-correlations and centrality layers based on\nthe onion decomposition. We then apply minimum description length as a model\nselection criterion and also introduce the Network Onion Divergence: model\nselection and network comparison over a nested family of configuration models\nwith differing level of structural details. Using over 100 empirical sets of\nnetwork data, we find that a simple Layered Configuration Model offers the most\ncompact representation of the majority of real networks. We hope that our\nresults will continue to motivate the development of intricate random network\nmodels that help capture network structure beyond the simple degree\ndistribution.",
    "descriptor": "\nComments: Comments welcomed at laurent.hebert-dufresne@uvm.edu\n",
    "authors": [
      "Laurent H\u00e9bert-Dufresne",
      "Jean-Gabriel Young",
      "Alexander Daniels",
      "Antoine Allard"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.08444"
  },
  {
    "id": "arXiv:2204.08446",
    "title": "VSA: Learning Varied-Size Window Attention in Vision Transformers",
    "abstract": "Attention within windows has been widely explored in vision transformers to\nbalance the performance, computation complexity, and memory footprint. However,\ncurrent models adopt a hand-crafted fixed-size window design, which restricts\ntheir capacity of modeling long-term dependencies and adapting to objects of\ndifferent sizes. To address this drawback, we propose\n\\textbf{V}aried-\\textbf{S}ize Window \\textbf{A}ttention (VSA) to learn adaptive\nwindow configurations from data. Specifically, based on the tokens within each\ndefault window, VSA employs a window regression module to predict the size and\nlocation of the target window, i.e., the attention area where the key and value\ntokens are sampled. By adopting VSA independently for each attention head, it\ncan model long-term dependencies, capture rich context from diverse windows,\nand promote information exchange among overlapped windows. VSA is an\neasy-to-implement module that can replace the window attention in\nstate-of-the-art representative models with minor modifications and negligible\nextra computational cost while improving their performance by a large margin,\ne.g., 1.1\\% for Swin-T on ImageNet classification. In addition, the performance\ngain increases when using larger images for training and test. Experimental\nresults on more downstream tasks, including object detection, instance\nsegmentation, and semantic segmentation, further demonstrate the superiority of\nVSA over the vanilla window attention in dealing with objects of different\nsizes. The code will be released\nhttps://github.com/ViTAE-Transformer/ViTAE-VSA.",
    "descriptor": "\nComments: 23 pages, 13 tables, and 5 figures\n",
    "authors": [
      "Qiming Zhang",
      "Yufei Xu",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08446"
  },
  {
    "id": "arXiv:2204.08451",
    "title": "Learning to Listen: Modeling Non-Deterministic Dyadic Facial Motion",
    "abstract": "We present a framework for modeling interactional communication in dyadic\nconversations: given multimodal inputs of a speaker, we autoregressively output\nmultiple possibilities of corresponding listener motion. We combine the motion\nand speech audio of the speaker using a motion-audio cross attention\ntransformer. Furthermore, we enable non-deterministic prediction by learning a\ndiscrete latent representation of realistic listener motion with a novel\nmotion-encoding VQ-VAE. Our method organically captures the multimodal and\nnon-deterministic nature of nonverbal dyadic interactions. Moreover, it\nproduces realistic 3D listener facial motion synchronous with the speaker (see\nvideo). We demonstrate that our method outperforms baselines qualitatively and\nquantitatively via a rich suite of experiments. To facilitate this line of\nresearch, we introduce a novel and large in-the-wild dataset of dyadic\nconversations. Code, data, and videos available at\nhttps://evonneng.github.io/learning2listen/.",
    "descriptor": "",
    "authors": [
      "Evonne Ng",
      "Hanbyul Joo",
      "Liwen Hu",
      "Hao Li",
      "Trevor Darrell",
      "Angjoo Kanazawa",
      "Shiry Ginosar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08451"
  },
  {
    "id": "arXiv:2204.08453",
    "title": "Neural Space-filling Curves",
    "abstract": "We present Neural Space-filling Curves (SFCs), a data-driven approach to\ninfer a context-based scan order for a set of images. Linear ordering of pixels\nforms the basis for many applications such as video scrambling, compression,\nand auto-regressive models that are used in generative modeling for images.\nExisting algorithms resort to a fixed scanning algorithm such as Raster scan or\nHilbert scan. Instead, our work learns a spatially coherent linear ordering of\npixels from the dataset of images using a graph-based neural network. The\nresulting Neural SFC is optimized for an objective suitable for the downstream\ntask when the image is traversed along with the scan line order. We show the\nadvantage of using Neural SFCs in downstream applications such as image\ncompression. Code and additional results will be made available at\nhttps://hywang66.github.io/publication/neuralsfc.",
    "descriptor": "",
    "authors": [
      "Hanyu Wang",
      "Kamal Gupta",
      "Larry Davis",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08453"
  },
  {
    "id": "arXiv:2204.08454",
    "title": "Revisiting Consistency Regularization for Semi-supervised Change  Detection in Remote Sensing Images",
    "abstract": "Remote-sensing (RS) Change Detection (CD) aims to detect \"changes of\ninterest\" from co-registered bi-temporal images. The performance of existing\ndeep supervised CD methods is attributed to the large amounts of annotated data\nused to train the networks. However, annotating large amounts of remote sensing\nimages is labor-intensive and expensive, particularly with bi-temporal images,\nas it requires pixel-wise comparisons by a human expert. On the other hand, we\noften have access to unlimited unlabeled multi-temporal RS imagery thanks to\never-increasing earth observation programs. In this paper, we propose a simple\nyet effective way to leverage the information from unlabeled bi-temporal images\nto improve the performance of CD approaches. More specifically, we propose a\nsemi-supervised CD model in which we formulate an unsupervised CD loss in\naddition to the supervised Cross-Entropy (CE) loss by constraining the output\nchange probability map of a given unlabeled bi-temporal image pair to be\nconsistent under the small random perturbations applied on the deep feature\ndifference map that is obtained by subtracting their latent feature\nrepresentations. Experiments conducted on two publicly available CD datasets\nshow that the proposed semi-supervised CD method can reach closer to the\nperformance of supervised CD even with access to as little as 10% of the\nannotated training data. Code available at https://github.com/wgcban/SemiCD.",
    "descriptor": "\nComments: Code available at: this https URL 36 pages\n",
    "authors": [
      "Wele Gedara Chaminda Bandara",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.08454"
  },
  {
    "id": "arXiv:2204.07596",
    "title": "Perfectly Balanced: Improving Transfer and Robustness of Supervised  Contrastive Learning",
    "abstract": "An ideal learned representation should display transferability and\nrobustness. Supervised contrastive learning (SupCon) is a promising method for\ntraining accurate models, but produces representations that do not capture\nthese properties due to class collapse -- when all points in a class map to the\nsame representation. Recent work suggests that \"spreading out\" these\nrepresentations improves them, but the precise mechanism is poorly understood.\nWe argue that creating spread alone is insufficient for better representations,\nsince spread is invariant to permutations within classes. Instead, both the\ncorrect degree of spread and a mechanism for breaking this invariance are\nnecessary. We first prove that adding a weighted class-conditional InfoNCE loss\nto SupCon controls the degree of spread. Next, we study three mechanisms to\nbreak permutation invariance: using a constrained encoder, adding a\nclass-conditional autoencoder, and using data augmentation. We show that the\nlatter two encourage clustering of latent subclasses under more realistic\nconditions than the former. Using these insights, we show that adding a\nproperly-weighted class-conditional InfoNCE loss and a class-conditional\nautoencoder to SupCon achieves 11.1 points of lift on coarse-to-fine transfer\nacross 5 standard datasets and 4.7 points on worst-group robustness on 3\ndatasets, setting state-of-the-art on CelebA by 11.5 points.",
    "descriptor": "",
    "authors": [
      "Mayee F. Chen",
      "Daniel Y. Fu",
      "Avanika Narayan",
      "Michael Zhang",
      "Zhao Song",
      "Kayvon Fatahalian",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07596"
  },
  {
    "id": "arXiv:2204.07613",
    "title": "$\u03a5$-Net: A Spatiospectral Network for Retinal OCT Segmentation",
    "abstract": "Automated segmentation of retinal optical coherence tomography (OCT) images\nhas become an important recent direction in machine learning for medical\napplications. We hypothesize that the anatomic structure of layers and their\nhigh-frequency variation in OCT images make retinal OCT a fitting choice for\nextracting spectral-domain features and combining them with spatial domain\nfeatures. In this work, we present $\\Upsilon$-Net, an architecture that\ncombines the frequency domain features with the image domain to improve the\nsegmentation performance of OCT images. The results of this work demonstrate\nthat the introduction of two branches, one for spectral and one for spatial\ndomain features, brings a very significant improvement in fluid segmentation\nperformance and allows outperformance as compared to the well-known U-Net\nmodel. Our improvement was 13% on the fluid segmentation dice score and 1.9% on\nthe average dice score. Finally, removing selected frequency ranges in the\nspectral domain demonstrates the impact of these features on the fluid\nsegmentation outperformance.",
    "descriptor": "",
    "authors": [
      "Azade Farshad",
      "Yousef Yeganeh",
      "Peter Gehlbach",
      "Nassir Navab"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07613"
  },
  {
    "id": "arXiv:2204.07629",
    "title": "Navigation between states in ecological communities by taking shortcuts,  with application to control",
    "abstract": "Many community ecology problems can be framed in terms of controlling the\ntransition from an initial state to a desired state. However, it is often\nunclear what action sequence (if any) would yield the desired state. Here we\ndevelop a simple approach for navigating to desired states, applicable when the\ncosts and outcomes of actions are known. We find lowest-cost action sequences\n(adding a species, removing a species, changing the environment, waiting) via\nA* search on a state diagram. Lowest-cost sequences usually are indirect and\nleverage waiting for natural transitions caused by competitive exclusion. In\ntests on simulated and empirical data across taxa, our approach provides ~50%\nprobability of substantial cost improvement relative to nominal approaches. As\nan example, numerous successes are predicted in gut microbial communities for\nremoving the pathogen Clostridium difficile. This work thus provides a\nconceptual foundation for efficient state transitions in species-rich\ncommunities.",
    "descriptor": "",
    "authors": [
      "Benjamin W. Blonder",
      "Michael H. Lim",
      "Zachary Sunberg",
      "Claire Tomlin"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07629"
  },
  {
    "id": "arXiv:2204.07634",
    "title": "A generative neural network model for random dot product graphs",
    "abstract": "We present GraphMoE, a novel neural network-based approach to learning\ngenerative models for random graphs. The neural network is trained to match the\ndistribution of a class of random graphs by way of a moment estimator. The\nfeatures used for training are graphlets, subgraph counts of small order. The\nneural network accepts random noise as input and outputs vector representations\nfor nodes in the graph. Random graphs are then realized by applying a kernel to\nthe representations. Graphs produced this way are demonstrated to be able to\nimitate data from chemistry, medicine, and social networks. The produced graphs\nare similar enough to the target data to be able to fool discriminator neural\nnetworks otherwise capable of separating classes of random graphs.",
    "descriptor": "",
    "authors": [
      "Vittorio Loprinzo",
      "Laurent Younes"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07634"
  },
  {
    "id": "arXiv:2204.07670",
    "title": "Twin-width can be exponential in treewidth",
    "abstract": "For any small positive real $\\varepsilon$ and integer $t >\n\\frac{1}{\\varepsilon}$, we build a graph with a vertex deletion set of size $t$\nto a tree, and twin-width greater than $2^{(1-\\varepsilon) t}$. In particular,\nthis shows that the twin-width is sometimes exponential in the treewidth, in\nthe so-called oriented twin-width and grid number, and that adding an apex may\nmultiply the twin-width by at least $2-\\varepsilon$. Except for the one in\noriented twin-width, these lower bounds are essentially tight.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "\u00c9douard Bonnet",
      "Hugues D\u00e9pr\u00e9s"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.07670"
  },
  {
    "id": "arXiv:2204.07680",
    "title": "Space-sequential particle filters for high-dimensional dynamical systems  described by stochastic differential equations",
    "abstract": "We introduce a novel methodology for particle filtering in dynamical systems\nwhere the evolution of the signal of interest is described by a SDE and\nobservations are collected instantaneously at prescribed time instants. The new\napproach includes the discretisation of the SDE and the design of efficient\nparticle filters for the resulting discrete-time state-space model. The\ndiscretisation scheme converges with weak order 1 and it is devised to create a\nsequential dependence structure along the coordinates of the discrete-time\nstate vector. We introduce a class of space-sequential particle filters that\nexploits this structure to improve performance when the system dimension is\nlarge. This is numerically illustrated by a set of computer simulations for a\nstochastic Lorenz 96 system with additive noise. The new space-sequential\nparticle filters attain approximately constant estimation errors as the\ndimension of the Lorenz 96 system is increased, with a computational cost that\nincreases polynomially, rather than exponentially, with the system dimension.\nBesides the new numerical scheme and particle filters, we provide in this\npaper a general framework for discrete-time filtering in continuous-time\ndynamical systems described by a SDE and instantaneous observations. Provided\nthat the SDE is discretised using a weakly-convergent scheme, we prove that the\nmarginal posterior laws of the resulting discrete-time state-space model\nconverge to the posterior marginal posterior laws of the original\ncontinuous-time state-space model under a suitably defined metric. This result\nis general and not restricted to the numerical scheme or particle filters\nspecifically studied in this manuscript.",
    "descriptor": "",
    "authors": [
      "Deniz Akyildiz",
      "Dan Crisan",
      "Joaquin Miguez"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2204.07680"
  },
  {
    "id": "arXiv:2204.07702",
    "title": "On Acceleration of Gradient-Based Empirical Risk Minimization using  Local Polynomial Regression",
    "abstract": "We study the acceleration of the Local Polynomial Interpolation-based\nGradient Descent method (LPI-GD) recently proposed for the approximate solution\nof empirical risk minimization problems (ERM). We focus on loss functions that\nare strongly convex and smooth with condition number $\\sigma$. We additionally\nassume the loss function is $\\eta$-H\\\"older continuous with respect to the\ndata. The oracle complexity of LPI-GD is $\\tilde{O}\\left(\\sigma m^d\n\\log(1/\\varepsilon)\\right)$ for a desired accuracy $\\varepsilon$, where $d$ is\nthe dimension of the parameter space, and $m$ is the cardinality of an\napproximation grid. The factor $m^d$ can be shown to scale as\n$O((1/\\varepsilon)^{d/2\\eta})$. LPI-GD has been shown to have better oracle\ncomplexity than gradient descent (GD) and stochastic gradient descent (SGD) for\ncertain parameter regimes. We propose two accelerated methods for the ERM\nproblem based on LPI-GD and show an oracle complexity of\n$\\tilde{O}\\left(\\sqrt{\\sigma} m^d \\log(1/\\varepsilon)\\right)$. Moreover, we\nprovide the first empirical study on local polynomial interpolation-based\ngradient methods and corroborate that LPI-GD has better performance than GD and\nSGD in some scenarios, and the proposed methods achieve acceleration.",
    "descriptor": "",
    "authors": [
      "Ekaterina Trimbach",
      "Edward Duc Hien Nguyen",
      "C\u00e9sar A. Uribe"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07702"
  },
  {
    "id": "arXiv:2204.07716",
    "title": "FKreg: A MATLAB toolbox for fast Multivariate Kernel Regression",
    "abstract": "Kernel smooth is the most fundamental technique for data density and\nregression estimation. However, time-consuming is the biggest obstacle for the\napplication that the direct evaluation of kernel smooth for $N$ samples needs\n${O}\\left( {{N}^{2}} \\right)$ operations. People have developed fast smooth\nalgorithms using the idea of binning with FFT. Unfortunately, the accuracy is\nnot controllable, and the implementation for multivariable and its bandwidth\nselection for the fast method is not available. Hence, we introduce a new\nMATLAB toolbox for fast multivariate kernel regression with the idea of\nnon-uniform FFT (NUFFT), which implemented the algorithm for $M$ gridding\npoints with ${O}\\left( N+M\\log M \\right)$ complexity and accuracy\ncontrollability. The bandwidth selection problem utilizes the Fast Monte-Carlo\nalgorithm to estimate the degree of freedom (DF), saving enormous\ncross-validation time even better when data share the same grid space for\nmultiple regression. Up to now, this is the first toolbox for fast-binning\nhigh-dimensional kernel regression. Moreover, the estimation for local\npolynomial regression, the conditional variance for the heteroscedastic model,\nand the complex-valued datasets are also implemented in this toolbox. The\nperformance is demonstrated with simulations and an application on the\nquantitive EEG.",
    "descriptor": "",
    "authors": [
      "Ying Wang",
      "Min Li",
      "Deirel Paz-Linares",
      "Maria L. Bringas Vega",
      "Pedro A. Vald\u00e9s-Sosa"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2204.07716"
  },
  {
    "id": "arXiv:2204.07743",
    "title": "Tensor-networks for High-order Polynomial Approximation: A Many-body  Physics Perspective",
    "abstract": "We analyze the problem of high-order polynomial approximation from a\nmany-body physics perspective, and demonstrate the descriptive power of\nentanglement entropy in capturing model capacity and task complexity.\nInstantiated with a high-order nonlinear dynamics modeling problem,\ntensor-network models are investigated and exhibit promising modeling\nadvantages. This novel perspective establish a connection between quantum\ninformation and functional approximation, which worth further exploration in\nfuture research.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Tong Yang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07743"
  },
  {
    "id": "arXiv:2204.07747",
    "title": "A Variational Approach to Bayesian Phylogenetic Inference",
    "abstract": "Bayesian phylogenetic inference is currently done via Markov chain Monte\nCarlo (MCMC) with simple proposal mechanisms. This hinders exploration\nefficiency and often requires long runs to deliver accurate posterior\nestimates. In this paper, we present an alternative approach: a variational\nframework for Bayesian phylogenetic analysis. We propose combining subsplit\nBayesian networks, an expressive graphical model for tree topology\ndistributions, and a structured amortization of the branch lengths over tree\ntopologies for a suitable variational family of distributions. We train the\nvariational approximation via stochastic gradient ascent and adopt gradient\nestimators for continuous and discrete variational parameters separately to\ndeal with the composite latent space of phylogenetic models. We show that our\nvariational approach provides competitive performance to MCMC, while requiring\nmuch less computation due to a more efficient exploration mechanism enabled by\nvariational inference. Experiments on a benchmark of challenging real data\nBayesian phylogenetic inference problems demonstrate the effectiveness and\nefficiency of our methods.",
    "descriptor": "",
    "authors": [
      "Cheng Zhang",
      "Frederick A. Matsen IV"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07747"
  },
  {
    "id": "arXiv:2204.07760",
    "title": "Cannikin's Law in Tensor Modeling: A Rank Study for Entanglement and  Separability in Tensor Complexity and Model Capacity",
    "abstract": "This study clarifies the proper criteria to assess the modeling capacity of a\ngeneral tensor model. The work analyze the problem based on the study of tensor\nranks, which is not a well-defined quantity for higher order tensors. To\nprocess, the author introduces the separability issue to discuss the Cannikin's\nlaw of tensor modeling. Interestingly, a connection between entanglement\nstudied in information theory and tensor analysis is established, shedding new\nlight on the theoretical understanding for modeling capacity problems.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Tong Yang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07760"
  },
  {
    "id": "arXiv:2204.07777",
    "title": "Exploiting Multiple EEG Data Domains with Adversarial Learning",
    "abstract": "Electroencephalography (EEG) is shown to be a valuable data source for\nevaluating subjects' mental states. However, the interpretation of multi-modal\nEEG signals is challenging, as they suffer from poor signal-to-noise-ratio, are\nhighly subject-dependent, and are bound to the equipment and experimental setup\nused, (i.e. domain). This leads to machine learning models often suffer from\npoor generalization ability, where they perform significantly worse on\nreal-world data than on the exploited training data. Recent research heavily\nfocuses on cross-subject and cross-session transfer learning frameworks to\nreduce domain calibration efforts for EEG signals. We argue that multi-source\nlearning via learning domain-invariant representations from multiple\ndata-sources is a viable alternative, as the available data from different EEG\ndata-source domains (e.g., subjects, sessions, experimental setups) grow\nmassively. We propose an adversarial inference approach to learn data-source\ninvariant representations in this context, enabling multi-source learning for\nEEG-based brain-computer interfaces. We unify EEG recordings from different\nsource domains (i.e., emotion recognition datasets SEED, SEED-IV, DEAP,\nDREAMER), and demonstrate the feasibility of our invariant representation\nlearning approach in suppressing data-source-relevant information leakage by\n35% while still achieving stable EEG-based emotion classification performance.",
    "descriptor": "\nComments: 5 pages, 3 figures, IEEE EMBC 2022 full paper\n",
    "authors": [
      "David Bethge",
      "Philipp Hallgarten",
      "Ozan \u00d6zdenizci",
      "Ralf Mikut",
      "Albrecht Schmidt",
      "Tobias Grosse-Puppendahl"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07777"
  },
  {
    "id": "arXiv:2204.07792",
    "title": "Boson sampling cannot be faithfully simulated by only the lower-order  multi-boson interferences",
    "abstract": "To simulate noisy boson sampling approximating it by only the lower-order\nmulti-boson interferences (e.g., by a smaller number of interfering bosons and\nclassical particles) is very popular idea. I show that the output data from any\nsuch classical simulations can be efficiently distinguished from that of the\nquantum device they try to simulate, even with finite noise in the latter. The\ndistinguishing datasets can be the experimental estimates of some large\nprobabilities, a wide class of such is presented. This is a sequel of\n\\textit{Quantum} \\textbf{5}, 423 (2021), where I present more accessible\naccount of the main result enhanced by additional insight on the contribution\nfrom the higher-order multi-boson interferences in presence of noise.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Valery Shchesnovich"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.07792"
  },
  {
    "id": "arXiv:2204.07821",
    "title": "Detection of Small Holes by the Scale-Invariant Robust Density-Aware  Distance (RDAD) Filtration",
    "abstract": "A novel topological-data-analytical (TDA) method is proposed to distinguish,\nfrom noise, small holes surrounded by high-density regions of a probability\ndensity function whose mass is concentrated near a manifold (or more generally,\na CW complex) embedded in a high-dimensional Euclidean space. The proposed\nmethod is robust against additive noise and outliers. In particular, sample\npoints are allowed to be perturbed away from the manifold. Traditional TDA\ntools, like those based on the distance filtration, often struggle to\ndistinguish small features from noise, because of their short persistence. An\nalternative filtration, called Robust Density-Aware Distance (RDAD) filtration,\nis proposed to prolong the persistence of small holes surrounded by\nhigh-density regions. This is achieved by weighting the distance function by\nthe density in the sense of Bell et al. Distance-to-measure is incorporated to\nenhance stability and mitigate noise due to the density estimation. The utility\nof the proposed filtration in identifying small holes, as well as its\nrobustness against noise, are illustrated through an analytical example and\nextensive numerical experiments. Basic mathematical properties of the proposed\nfiltration are proven.",
    "descriptor": "\nComments: 47 pages, 60 figures, GitHub repo: this https URL\n",
    "authors": [
      "Chunyin",
      "Gennady Samorodnitsky",
      "Christina Yu",
      "Andrey Yao"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07821"
  },
  {
    "id": "arXiv:2204.07824",
    "title": "Few-Shot Transfer Learning to improve Chest X-Ray pathology detection  using limited triplets",
    "abstract": "Deep learning approaches applied to medical imaging have reached near-human\nor better-than-human performance on many diagnostic tasks. For instance, the\nCheXpert competition on detecting pathologies in chest x-rays has shown\nexcellent multi-class classification performance. However, training and\nvalidating deep learning models require extensive collections of images and\nstill produce false inferences, as identified by a human-in-the-loop. In this\npaper, we introduce a practical approach to improve the predictions of a\npre-trained model through Few-Shot Learning (FSL). After training and\nvalidating a model, a small number of false inference images are collected to\nretrain the model using \\textbf{\\textit{Image Triplets}} - a false positive or\nfalse negative, a true positive, and a true negative. The retrained FSL model\nproduces considerable gains in performance with only a few epochs and few\nimages. In addition, FSL opens rapid retraining opportunities for\nhuman-in-the-loop systems, where a radiologist can relabel false inferences,\nand the model can be quickly retrained. We compare our retrained model\nperformance with existing FSL approaches in medical imaging that train and\nevaluate models at once.",
    "descriptor": "",
    "authors": [
      "Ananth Reddy Bhimireddy",
      "John Lee Burns",
      "Saptarshi Purkayastha",
      "Judy Wawira Gichoya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07824"
  },
  {
    "id": "arXiv:2204.07826",
    "title": "Beyond L1: Faster and Better Sparse Models with skglm",
    "abstract": "We propose a new fast algorithm to estimate any sparse generalized linear\nmodel with convex or non-convex separable penalties. Our algorithm is able to\nsolve problems with millions of samples and features in seconds, by relying on\ncoordinate descent, working sets and Anderson acceleration. It handles\npreviously unaddressed models, and is extensively shown to improve state-of-art\nalgorithms. We provide a flexible, scikit-learn compatible package, which\neasily handles customized datafits and penalties.",
    "descriptor": "",
    "authors": [
      "Quentin Bertrand",
      "Quentin Klopfenstein",
      "Pierre-Antoine Bannier",
      "Gauthier Gidel",
      "Mathurin Massias"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07826"
  },
  {
    "id": "arXiv:2204.07830",
    "title": "Riemannian optimization using three different metrics for Hermitian PSD  fixed-rank constraints: an extended version",
    "abstract": "We consider smooth optimization problems with a Hermitian positive\nsemi-definite fixed-rank constraint, where a quotient geometry with three\nRiemannian metrics $g^i(\\cdot, \\cdot)$ $(i=1,2,3)$ is used to represent this\nconstraint. By taking the nonlinear conjugate gradient method (CG) as an\nexample, we show that CG on the quotient geometry with metric $g^1$ is\nequivalent to CG on the factor-based optimization framework, which is often\ncalled the Burer--Monteiro approach. We also show that CG on the quotient\ngeometry with metric $g^3$ is equivalent to CG on the commonly-used embedded\ngeometry. We call two CG methods equivalent if they produce an identical\nsequence of iterates $\\{X_k\\}$. In addition, we show that if the limit point of\nthe sequence $\\{X_k\\}$ generated by an algorithm has lower rank, that is\n$X_k\\in \\mathbb C^{n\\times n}, k = 1, 2, \\ldots$ has rank $p$ and the limit\npoint $X_*$ has rank $r < p$, then the condition number of the Riemannian\nHessian with metric $g^1$ can be unbounded, but those of the other two metrics\nstay bounded. Numerical experiments show that the Burer--Monteiro CG method has\nslower local convergence rate if the limit point has a reduced rank, compared\nto CG on the quotient geometry under the other two metrics. This slower\nconvergence rate can thus be attributed to the large condition number of the\nHessian near a minimizer.",
    "descriptor": "",
    "authors": [
      "Shixin Zheng",
      "Wen Huang",
      "Bart Vandereycken",
      "Xiangxiong Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07830"
  },
  {
    "id": "arXiv:2204.07833",
    "title": "Optimizing differential equations to fit data and predict outcomes",
    "abstract": "Many scientific problems focus on observed patterns of change or on how to\ndesign a system to achieve particular dynamics. Those problems often require\nfitting differential equation models to target trajectories. Fitting such\nmodels can be difficult because each evaluation of the fit must calculate the\ndistance between the model and target patterns at numerous points along a\ntrajectory. The gradient of the fit with respect to the model parameters can be\nchallenging. Recent technical advances in automatic differentiation through\nnumerical differential equation solvers potentially change the fitting process\ninto a relatively easy problem, opening up new possibilities to study dynamics.\nHowever, application of the new tools to real data may fail to achieve a good\nfit. This article illustrates how to overcome a variety of common challenges,\nusing the classic ecological data for oscillations in hare and lynx\npopulations. Models include simple ordinary differential equations (ODEs) and\nneural ordinary differential equations (NODEs), which use artificial neural\nnetworks to estimate the derivatives of differential equation systems.\nComparing the fits obtained with ODEs versus NODEs, representing small and\nlarge parameter spaces, and changing the number of variable dimensions provide\ninsight into the geometry of the observed and model trajectories. To analyze\nthe quality of the models for predicting future observations, a\nBayesian-inspired preconditioned stochastic gradient Langevin dynamics (pSGLD)\ncalculation of the posterior distribution of predicted model trajectories\nclarifies the tendency for various models to underfit or overfit the data.\nCoupling fitted differential equation systems with pSGLD sampling provides a\npowerful way to study the properties of optimization surfaces, raising an\nanalogy with mutation-selection dynamics on fitness landscapes.",
    "descriptor": "",
    "authors": [
      "Steven A. Frank"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07833"
  },
  {
    "id": "arXiv:2204.07849",
    "title": "Shift Invariant Algebras, Segre Products and Regular Languages",
    "abstract": "Motivated by results on the rationality of equivariant Hilbert series of some\nhierarchical models in algebraic statistics we introduce the Segre product of\nformal languages and apply it to establish rationality of equivariant Hilbert\nseries in new cases. We also show that every filtration of algebras given as a\ntensor product of families of algebras with a rational equivariant Hilbert\nseries has a rational equivariant Hilbert series. We use the term equivariant\nbroadly to include the action of the monoid of nonnegative integers by shifting\nvariables. Furthermore, we exhibit a filtration of shift invariant monomial\nalgebras that has a rational equivalent Hilbert series, but whose presentation\nideals do not stabilize.",
    "descriptor": "\nComments: 26 pages, comments are welcome!\n",
    "authors": [
      "Aida Maraj",
      "Uwe Nagel"
    ],
    "subjectives": [
      "Commutative Algebra (math.AC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2204.07849"
  },
  {
    "id": "arXiv:2204.07850",
    "title": "Multi-organ Segmentation Network with Adversarial Performance Validator",
    "abstract": "CT organ segmentation on computed tomography (CT) images becomes a\nsignificant brick for modern medical image analysis, supporting clinic\nworkflows in multiple domains. Previous segmentation methods include 2D\nconvolution neural networks (CNN) based approaches, fed by CT image slices that\nlack the structural knowledge in axial view, and 3D CNN-based methods with the\nexpensive computation cost in multi-organ segmentation applications. This paper\nintroduces an adversarial performance validation network into a 2D-to-3D\nsegmentation framework. The classifier and performance validator competition\ncontribute to accurate segmentation results via back-propagation. The proposed\nnetwork organically converts the 2D-coarse result to 3D high-quality\nsegmentation masks in a coarse-to-fine manner, allowing joint optimization to\nimprove segmentation accuracy. Besides, the structural information of one\nspecific organ is depicted by a statistics-meaningful prior bounding box, which\nis transformed into a global feature leveraging the learning process in 3D fine\nsegmentation. The experiments on the NIH pancreas segmentation dataset\ndemonstrate the proposed network achieves state-of-the-art accuracy on small\norgan segmentation and outperforms the previous best. High accuracy is also\nreported on multi-organ segmentation in a dataset collected by ourselves.",
    "descriptor": "",
    "authors": [
      "Haoyu Fang",
      "Yi Fang",
      "Xiaofeng Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07850"
  },
  {
    "id": "arXiv:2204.07862",
    "title": "GHM Wavelet Transform for Deep Image Super Resolution",
    "abstract": "The GHM multi-level discrete wavelet transform is proposed as preprocessing\nfor image super resolution with convolutional neural networks. Previous works\nperform analysis with the Haar wavelet only. In this work, 37 single-level\nwavelets are experimentally analyzed from Haar, Daubechies, Biorthogonal,\nReverse Biorthogonal, Coiflets, and Symlets wavelet families. All single-level\nwavelets report similar results indicating that the convolutional neural\nnetwork is invariant to choice of wavelet in a single-level filter approach.\nHowever, the GHM multi-level wavelet achieves higher quality reconstructions\nthan the single-level wavelets. Three large data sets are used for the\nexperiments: DIV2K, a dataset of textures, and a dataset of satellite images.\nThe approximate high resolution images are compared using seven objective error\nmeasurements. A convolutional neural network based approach using wavelet\ntransformed images has good results in the literature.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Ben Lowe",
      "Hadi Salman",
      "Justin Zhan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07862"
  },
  {
    "id": "arXiv:2204.07867",
    "title": "Analytical Benchmark Problems for Multifidelity Optimization Methods",
    "abstract": "The paper presents a collection of analytical benchmark problems specifically\nselected to provide a set of stress tests for the assessment of multifidelity\noptimization methods. In addition, the paper discusses a comprehensive ensemble\nof metrics and criteria recommended for the rigorous and meaningful assessment\nof the performance of multifidelity strategies and algorithms.",
    "descriptor": "",
    "authors": [
      "L. Mainini",
      "A. Serani",
      "M. P. Rumpfkeil",
      "E. Minisci",
      "D. Quagliarella",
      "H. Pehlivan",
      "S. Yildiz",
      "S. Ficini",
      "R. Pellegrini",
      "F. Di Fiore",
      "D. Bryson",
      "M. Nikbay",
      "M. Diez",
      "P. Beran"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.07867"
  },
  {
    "id": "arXiv:2204.07890",
    "title": "Modeling Complex Interactions in a Disrupted Environment: Relational  Events in the WTC Response",
    "abstract": "When subjected to a sudden, unanticipated threat, human groups\ncharacteristically self-organize to identify the threat, determine potential\nresponses, and act to reduce its impact. Central to this process is the\nchallenge of coordinating information sharing and response activity within a\ndisrupted environment. In this paper, we consider coordination in the context\nof responses to the 2001 World Trade Center disaster. Using records of\ncommunications among 17 organizational units, we examine the mechanisms driving\ncommunication dynamics, with an emphasis on the emergence of coordinating\nroles. We employ relational event models (REMs) to identify the mechanisms\nshaping communications in each unit, finding a consistent pattern of behavior\nacross units with very different characteristics. Using a simulation-based\n\"knock-out\" study, we also probe the importance of different mechanisms for hub\nformation. Our results suggest that, while preferential attachment and\npre-disaster role structure generally contribute to the emergence of hub\nstructure, temporally local conversational norms play a much larger role. We\ndiscuss broader implications for the role of microdynamics in driving\nmacroscopic outcomes, and for the emergence of coordination in other settings.",
    "descriptor": "",
    "authors": [
      "Scott Leo Renshaw",
      "Selena M. Livas",
      "Miruna G. Petrescu-Prahova",
      "Carter T. Butts"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.07890"
  },
  {
    "id": "arXiv:2204.07904",
    "title": "Turing's cascade instability supports the coordination of the mind,  brain, and behavior",
    "abstract": "Turing inspired a computer metaphor of the mind and brain that has been handy\nand has spawned decades of empirical investigation, but he did much more and\noffered behavioral and cognitive sciences another metaphor--that of the\ncascade. The time has come to confront Turing's cascading instability, which\nsuggests a geometrical framework driven by power laws and can be studied using\nmultifractal formalism and multiscale probability density function analysis.\nHere, we review a rapidly growing body of scientific investigations revealing\nsignatures of cascade instability and their consequences for a perceiving,\nacting, and thinking organism. We review work related to executive functioning\n(planning to act), postural control (bodily poise for turning plans into\naction), and effortful perception (action to gather information in a single\nmodality and action to blend multimodal information). We also review findings\non neuronal avalanches in the brain, specifically about neural participation in\nbody-wide cascades. Turing's cascade instability blends the mind, brain, and\nbehavior across space and time scales and provides an alternative to the\ndominant computer metaphor.",
    "descriptor": "\nComments: 53 pages, 13 figures\n",
    "authors": [
      "Damian G. Kelty-Stephen",
      "Madhur Mangalam"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07904"
  },
  {
    "id": "arXiv:2204.07911",
    "title": "A Distributed Online Algorithm for Promoting Energy Sharing Between EV  Charging Stations",
    "abstract": "In recent years, electric vehicle (EV) charging station has experienced an\nincreasing supply-demand mismatch due to its fluctuating renewables and\nunpredictable charging demand. To reduce its operating cost, this paper\nproposes a distributed online algorithm to promote the energy sharing between\ncharging stations. We begin with the offline and centralized version of the EV\ncharging stations operation problem, whose objective is to minimize the\nlong-term time-average total cost. Then, we develop an online implementation\napproach based on the Lyapunov optimization framework. Although the proposed\nonline algorithm runs in a prediction-free manner, we prove that by properly\nchoosing the parameters, the time-coupling constraints remain to be satisfied.\nWe also provide a theoretical bound for the optimality gap between the offline\nand online optimums. Furthermore, an improved alternating direction method of\nmultipliers (ADMM) algorithm with iteration truncation is proposed to enable\ndistributed computation. The proposed algorithm can protect privacy while being\nsuitable for online implementation. Case studies validate the effectiveness of\nthe theoretical results. Comprehensive performance comparisons are carried out\nto demonstrate the advantages of the proposed method.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Dongxiang Yan",
      "Yue Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07911"
  },
  {
    "id": "arXiv:2204.07923",
    "title": "Accelerated MRI With Deep Linear Convolutional Transform Learning",
    "abstract": "Recent studies show that deep learning (DL) based MRI reconstruction\noutperforms conventional methods, such as parallel imaging and compressed\nsensing (CS), in multiple applications. Unlike CS that is typically implemented\nwith pre-determined linear representations for regularization, DL inherently\nuses a non-linear representation learned from a large database. Another line of\nwork uses transform learning (TL) to bridge the gap between these two\napproaches by learning linear representations from data. In this work, we\ncombine ideas from CS, TL and DL reconstructions to learn deep linear\nconvolutional transforms as part of an algorithm unrolling approach. Using\nend-to-end training, our results show that the proposed technique can\nreconstruct MR images to a level comparable to DL methods, while supporting\nuniform undersampling patterns unlike conventional CS methods. Our proposed\nmethod relies on convex sparse image reconstruction with linear representation\nat inference time, which may be beneficial for characterizing robustness,\nstability and generalizability.",
    "descriptor": "\nComments: To be published in 2022 44th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)\n",
    "authors": [
      "Hongyi Gu",
      "Burhaneddin Yaman",
      "Steen Moeller",
      "Il Yong Chun",
      "Mehmet Ak\u00e7akaya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.07923"
  },
  {
    "id": "arXiv:2204.07928",
    "title": "Optimally Reconfiguring List and Correspondence Colourings",
    "abstract": "The reconfiguration graph $\\mathcal{C}_k(G)$ for the $k$-colourings of a\ngraph $G$ has a vertex for each proper $k$-colouring of $G$, and two vertices\nof $\\mathcal{C}_k(G)$ are adjacent precisely when those $k$-colourings differ\non a single vertex of $G$. Much work has focused on bounding the maximum value\nof ${\\rm{diam}}~\\mathcal{C}_k(G)$ over all $n$-vertex graphs $G$. We consider\nthe analogous problems for list colourings and for correspondence colourings.\nWe conjecture that if $L$ is a list-assignment for a graph $G$ with $|L(v)|\\ge\nd(v)+2$ for all $v\\in V(G)$, then ${\\rm{diam}}~\\mathcal{C}_L(G)\\le\nn(G)+\\mu(G)$. We also conjecture that if $(L,H)$ is a correspondence cover for\na graph $G$ with $|L(v)|\\ge d(v)+2$ for all $v\\in V(G)$, then\n${\\rm{diam}}~\\mathcal{C}_{(L,H)}(G)\\le n(G)+\\tau(G)$. (Here $\\mu(G)$ and\n$\\tau(G)$ denote the matching number and vertex cover number of $G$.) For every\ngraph $G$, we give constructions showing that both conjectures are best\npossible. Our first main result proves the upper bounds (for the list and\ncorrespondence versions, respectively) ${\\rm{diam}}~\\mathcal{C}_L(G)\\le\nn(G)+2\\mu(G)$ and ${\\rm{diam}}~\\mathcal{C}_{(L,H)}(G)\\le n(G)+2\\tau(G)$. Our\nsecond main result proves that both conjectured bounds hold, whenever all $v$\nsatisfy $|L(v)|\\ge 2d(v)+1$. We also prove more precise results when $G$ is a\ntree. We conclude by proving one or both conjectures for various classes of\ngraphs such as complete bipartite graphs, subcubic graphs, cactuses, and graphs\nwith bounded maximum average degree.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Stijn Cambie",
      "Wouter Cames van Batenburg",
      "Daniel W. Cranston"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.07928"
  },
  {
    "id": "arXiv:2204.07942",
    "title": "Wound Severity Classification using Deep Neural Network",
    "abstract": "The classification of wound severity is a critical step in wound diagnosis.\nAn effective classifier can help wound professionals categorize wound\nconditions more quickly and affordably, allowing them to choose the best\ntreatment option. This study used wound photos to construct a deep neural\nnetwork-based wound severity classifier that classified them into one of three\nclasses: green, yellow, or red. The green class denotes wounds still in the\nearly stages of healing and are most likely to recover with adequate care.\nWounds in the yellow category require more attention and treatment than those\nin the green category. Finally, the red class denotes the most severe wounds\nthat require prompt attention and treatment. A dataset containing different\ntypes of wound images is designed with the help of wound specialists. Nine deep\nlearning models are used with applying the concept of transfer learning.\nSeveral stacked models are also developed by concatenating these transfer\nlearning models. The maximum accuracy achieved on multi-class classification is\n68.49%. In addition, we achieved 78.79%, 81.40%, and 77.57% accuracies on green\nvs. yellow, green vs. red, and yellow vs. red classifications for binary\nclassifications.",
    "descriptor": "\nComments: 19 pages, 5 figures, 5 tables\n",
    "authors": [
      "D. M. Anisuzzaman",
      "Yash Patel",
      "Jeffrey Niezgoda",
      "Sandeep Gopalakrishnan",
      "Zeyun Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07942"
  },
  {
    "id": "arXiv:2204.07963",
    "title": "AFSC: Adaptive Fourier Space Compression for Anomaly Detection",
    "abstract": "Anomaly Detection (AD) on medical images enables a model to recognize any\ntype of anomaly pattern without lesion-specific supervised learning. Data\naugmentation based methods construct pseudo-healthy images by \"pasting\" fake\nlesions on real healthy ones, and a network is trained to predict healthy\nimages in a supervised manner. The lesion can be found by difference between\nthe unhealthy input and pseudo-healthy output. However, using only manually\ndesigned fake lesions fail to approximate to irregular real lesions, hence\nlimiting the model generalization. We assume by exploring the intrinsic data\nproperty within images, we can distinguish previously unseen lesions from\nhealthy regions in an unhealthy image. In this study, we propose an Adaptive\nFourier Space Compression (AFSC) module to distill healthy feature for AD. The\ncompression of both magnitude and phase in frequency domain addresses the hyper\nintensity and diverse position of lesions. Experimental results on the BraTS\nand MS-SEG datasets demonstrate an AFSC baseline is able to produce promising\ndetection results, and an AFSC module can be effectively embedded into existing\nAD methods.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Haote Xu",
      "Yunlong Zhang",
      "Liyan Sun",
      "Chenxin Li",
      "Yue Huang",
      "Xinghao Ding"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07963"
  },
  {
    "id": "arXiv:2204.07966",
    "title": "MRXCAT-CDTI: A Numerical Cardiac Diffusion Tensor Imaging Phantom",
    "abstract": "Magnetic Resonance cardiac diffusion tensor imaging (cDTI) and cardiac\nintravoxel incoherent motion imaging enables probing of in vivo myofiber\narchitecture and myocardial perfusion surrogates. To study the impact of\nexperimental parameters such as resolution, off-resonances and heart-rate\nvariations, we propose a numerical open-source framework called MRXCAT-CDTI. It\nallows simulating diffusion and perfusion contrast for spin-echo (SE) and\nstimulated echo acquisition mode (STEAM) cDTI sequences. The Fourier encoder\nsupports in-plane and/or through-slice off-resonance effects, as well as T2*\neffects during single-shot image encoding. Optional lesions are included to\nmimic ischemic and infarcted myocardial regions. MRXCAT-CDTI allows assessing\nrealistic influences on data acquisition, and how these affect the data\nencoding process and subsequent data processing. As an example, heart-rate\nvariations lead to differences in partial saturation and relaxation of\nmagnetization that end up in errors of 9 to 30% for cDTI angle metrics if not\naccounted for. For SE echo-planar cDTI, in-plane off-resonance effects more\nadversely affect cDTI metrics compared to through-slice off-resonances. With\nthis work we propose an open-source MRXCAT-CDTI numerical simulation framework\nthat offers realistic image encoding effects found in cardiac diffusion and\nperfusion data to systematically study influences of data encoding,\nreconstruction, and post-processing to promote reproducible research.",
    "descriptor": "\nComments: 43 pages, 8 figures, 4 supplementary figures, 7 supplementary tables. MRXCAT-CDTI and example scripts to simulate the examples shown in this publication are available online via: this https URL\n",
    "authors": [
      "Robbert J. H. van Gorkum",
      "Jonathan L. Weine",
      "William P. Segars",
      "Christian T. Stoeck",
      "Sebastian Kozerke"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07966"
  },
  {
    "id": "arXiv:2204.07986",
    "title": "Penetration trajectory optimization for the hypersonic gliding vehicle  encountering two interceptors",
    "abstract": "The penetration trajectory optimization problem for the hypersonic gliding\nvehicle (HGV) encountering two interceptors is investigated. The HGV\npenetration trajectory optimization problem considering the terminal target\narea is formulated as a nonconvex optimal control problem. The nonconvex\noptimal control problem is transformed into a second-order cone programming\n(SOCP) problem, which can be solved by state-of-the-art interior-point methods.\nIn addition, a penetration strategy that only requires the initial\nline-of-sight angle information of the interceptors is proposed. The convergent\ntrajectory obtained by the proposed method allows the HGV to evade two\ninterceptors and reach the target area successfully. Furthermore, a successive\nSOCP method with a variable trust region is presented, which is critical to\nbalancing the trade-off between time consumption and optimality. Finally, the\neffectiveness and performance of the proposed method are verified by numerical\nsimulations.",
    "descriptor": "\nComments: 34 pages, 18 figures\n",
    "authors": [
      "Zhipeng Shen",
      "Jianglong Yu",
      "Xiwang Dong",
      "Yongzhao Hua",
      "Zhang Ren"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07986"
  },
  {
    "id": "arXiv:2204.07988",
    "title": "Automatic spinal curvature measurement on ultrasound spine images using  Faster R-CNN",
    "abstract": "Ultrasound spine imaging technique has been applied to the assessment of\nspine deformity. However, manual measurements of scoliotic angles on ultrasound\nimages are time-consuming and heavily rely on raters experience. The objectives\nof this study are to construct a fully automatic framework based on Faster\nR-CNN for detecting vertebral lamina and to measure the fitting spinal curves\nfrom the detected lamina pairs. The framework consisted of two closely linked\nmodules: 1) the lamina detector for identifying and locating each lamina pairs\non ultrasound coronal images, and 2) the spinal curvature estimator for\ncalculating the scoliotic angles based on the chain of detected lamina. Two\nhundred ultrasound images obtained from AIS patients were identified and used\nfor the training and evaluation of the proposed method. The experimental\nresults showed the 0.76 AP on the test set, and the Mean Absolute Difference\n(MAD) between automatic and manual measurement which was within the clinical\nacceptance error. Meanwhile the correlation between automatic measurement and\nCobb angle from radiographs was 0.79. The results revealed that our proposed\ntechnique could provide accurate and reliable automatic curvature measurements\non ultrasound spine images for spine deformities.",
    "descriptor": "",
    "authors": [
      "Zhichao Liu",
      "Liyue Qian",
      "Wenke Jing",
      "Desen Zhou",
      "Xuming He",
      "Edmond Lou",
      "Rui Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07988"
  },
  {
    "id": "arXiv:2204.08000",
    "title": "LRH-Net: A Multi-Level Knowledge Distillation Approach for Low-Resource  Heart Network",
    "abstract": "An electrocardiogram (ECG) monitors the electrical activity generated by the\nheart and is used to detect fatal cardiovascular diseases (CVDs).\nConventionally, to capture the precise electrical activity, clinical experts\nuse multiple-lead ECGs (typically 12 leads). But in recent times, large-size\ndeep learning models have been used to detect these diseases. However, such\nmodels require heavy compute resources like huge memory and long inference\ntime. To alleviate these shortcomings, we propose a low-parameter model, named\nLow Resource Heart-Network (LRH-Net), which uses fewer leads to detect ECG\nanomalies in a resource-constrained environment. A multi-level knowledge\ndistillation process is used on top of that to get better generalization\nperformance on our proposed model. The multi-level knowledge distillation\nprocess distills the knowledge to LRH-Net trained on a reduced number of leads\nfrom higher parameter (teacher) models trained on multiple leads to reduce the\nperformance gap. The proposed model is evaluated on the PhysioNet-2020\nchallenge dataset with constrained input. The parameters of the LRH-Net are\n106x less than our teacher model for detecting CVDs. The performance of the\nLRH-Net was scaled up to 3.2% and the inference time scaled down by 75%\ncompared to the teacher model. In contrast to the compute- and\nparameter-intensive deep learning techniques, the proposed methodology uses a\nsubset of ECG leads using the low resource LRH-Net, making it eminently\nsuitable for deployment on edge devices.",
    "descriptor": "",
    "authors": [
      "Ekansh Chauhan",
      "Swathi Guptha",
      "Likith Reddy",
      "Bapi Raju"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.08000"
  },
  {
    "id": "arXiv:2204.08031",
    "title": "Limit theorems of Chatterjee's rank correlation",
    "abstract": "Establishing limiting distributions of Chatterjee's rank correlation for a\ngeneral, possibly non-independent, pair of random variables has been eagerly\nawaited to many. This paper shows that (a) Chatterjee's rank correlation is\nasymptotically normal as long as one variable is not a measurable function of\nthe other, and (b) the corresponding asymptotic variance is uniformly bounded\nby 36. Similar results also hold for Azadkia-Chatterjee's graph-based\ncorrelation coefficient, a multivariate analogue of Chatterjee's original\nproposal. The proof is given by appealing to H\\'ajek representation and\nChatterjee's nearest-neighbor CLT.",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Zhexiao Lin",
      "Fang Han"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2204.08031"
  },
  {
    "id": "arXiv:2204.08043",
    "title": "Continual Hippocampus Segmentation with Transformers",
    "abstract": "In clinical settings, where acquisition conditions and patient populations\nchange over time, continual learning is key for ensuring the safe use of deep\nneural networks. Yet most existing work focuses on convolutional architectures\nand image classification. Instead, radiologists prefer to work with\nsegmentation models that outline specific regions-of-interest, for which\nTransformer-based architectures are gaining traction. The self-attention\nmechanism of Transformers could potentially mitigate catastrophic forgetting,\nopening the way for more robust medical image segmentation. In this work, we\nexplore how recently-proposed Transformer mechanisms for semantic segmentation\nbehave in sequential learning scenarios, and analyse how best to adapt\ncontinual learning strategies for this setting. Our evaluation on hippocampus\nsegmentation shows that Transformer mechanisms mitigate catastrophic forgetting\nfor medical image segmentation compared to purely convolutional architectures,\nand demonstrates that regularising ViT modules should be done with caution.",
    "descriptor": "",
    "authors": [
      "Amin Ranem",
      "Camila Gonz\u00e1lez",
      "Anirban Mukhopadhyay"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08043"
  },
  {
    "id": "arXiv:2204.08073",
    "title": "Intelligent Explorations of the String Theory Landscape",
    "abstract": "The goal of identifying the Standard Model of particle physics and its\nextensions within string theory has been one of the principal driving forces in\nstring phenomenology. Recently, the incorporation of artificial intelligence in\nstring theory and certain theoretical advancements have brought to light\nunexpected solutions to mathematical hurdles that have so far hindered progress\nin this direction. In this review we focus on model building efforts in the\ncontext of the $E_8\\times E_8$ heterotic string compactified on smooth\nCalabi-Yau threefolds and discuss several areas in which machine learning is\nexpected to make a difference.",
    "descriptor": "\nComments: 30 pages, 2 figures; review prepared for the Wold Scientific volume Machine Learning in Theoretical Physics and Pure Mathematics\n",
    "authors": [
      "Andrei Constantin"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08073"
  },
  {
    "id": "arXiv:2204.08094",
    "title": "A Data-Driven Methodology for Considering Feasibility and Pairwise  Likelihood in Deep Learning Based Guitar Tablature Transcription Systems",
    "abstract": "Guitar tablature transcription is an important but understudied problem\nwithin the field of music information retrieval. Traditional signal processing\napproaches offer only limited performance on the task, and there is little\nacoustic data with transcription labels for training machine learning models.\nHowever, guitar transcription labels alone are more widely available in the\nform of tablature, which is commonly shared among guitarists online. In this\nwork, a collection of symbolic tablature is leveraged to estimate the pairwise\nlikelihood of notes on the guitar. The output layer of a baseline tablature\ntranscription model is reformulated, such that an inhibition loss can be\nincorporated to discourage the co-activation of unlikely note pairs. This\nnaturally enforces playability constraints for guitar, and yields tablature\nwhich is more consistent with the symbolic data used to estimate pairwise\nlikelihoods. With this methodology, we show that symbolic tablature can be used\nto shape the distribution of a tablature transcription model's predictions,\neven when little acoustic data is available.",
    "descriptor": "\nComments: Sound and Music Computing Conference (SMC) 2022\n",
    "authors": [
      "Frank Cwitkowitz",
      "Jonathan Driedger",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.08094"
  },
  {
    "id": "arXiv:2204.08127",
    "title": "Parallel Network with Channel Attention and Post-Processing for Carotid  Arteries Vulnerable Plaque Segmentation in Ultrasound Images",
    "abstract": "Carotid arteries vulnerable plaques are a crucial factor in the screening of\natherosclerosis by ultrasound technique. However, the plaques are contaminated\nby various noises such as artifact, speckle noise, and manual segmentation may\nbe time-consuming. This paper proposes an automatic convolutional neural\nnetwork (CNN) method for plaque segmentation in carotid ultrasound images using\na small dataset. First, a parallel network with three independent scale\ndecoders is utilized as our base segmentation network, pyramid dilation\nconvolutions are used to enlarge receptive fields in the three segmentation\nsub-networks. Subsequently, the three decoders are merged to be rectified in\nchannels by SENet. Thirdly, in test stage, the initially segmented plaque is\nrefined by the max contour morphology post-processing to obtain the final\nplaque. Moreover, three loss function Dice loss, SSIM loss and cross-entropy\nloss are compared to segment plaques. Test results show that the proposed\nmethod with dice loss function yields a Dice value of 0.820, an IoU of 0.701,\nAcc of 0.969, and modified Hausdorff distance (MHD) of 1.43 for 30 vulnerable\ncases of plaques, it outperforms some of the conventional CNN-based methods on\nthese metrics. Additionally, we apply an ablation experiment to show the\nvalidity of each proposed module. Our study provides some reference for similar\nresearches and may be useful in actual applications for plaque segmentation of\nultrasound carotid arteries.",
    "descriptor": "\nComments: 16 pages,6 figures\n",
    "authors": [
      "Yanchao Yuan",
      "Cancheng Li",
      "Lu Xu",
      "Ke Zhang",
      "Yang Hua",
      "Jicong Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08127"
  },
  {
    "id": "arXiv:2204.08147",
    "title": "Numerical computation of the equilibrium-reduced density matrix for  strongly coupled open quantum systems",
    "abstract": "We describe a numerical algorithm for approximating the equilibrium-reduced\ndensity matrix and the effective (mean force) Hamiltonian for a set of system\nspins coupled strongly to a set of bath spins when the total system\n(system+bath) is held in canonical thermal equilibrium by weak coupling with a\n\"super-bath\". Our approach is a generalization of now standard typicality\nalgorithms for computing the quantum expectation value of observables of bare\nquantum systems via trace estimators and Krylov subspace methods. In\nparticular, our algorithm makes use of the fact that the reduced system\ndensity, when the bath is measured in a given random state, tends to\nconcentrate about the corresponding thermodynamic averaged reduced system\ndensity. Theoretical error analysis and numerical experiments are given to\nvalidate the accuracy of our algorithm. Further numerical experiments\ndemonstrate the potential of our approach for applications including the study\nof quantum phase transitions and entanglement entropy for long-range\ninteraction systems.",
    "descriptor": "",
    "authors": [
      "Tyler Chen",
      "Yu-Chen Cheng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.08147"
  },
  {
    "id": "arXiv:2204.08155",
    "title": "A dynamical systems based framework for dimension reduction",
    "abstract": "We propose a novel framework for learning a low-dimensional representation of\ndata based on nonlinear dynamical systems, which we call dynamical dimension\nreduction (DDR). In the DDR model, each point is evolved via a nonlinear flow\ntowards a lower-dimensional subspace; the projection onto the subspace gives\nthe low-dimensional embedding. Training the model involves identifying the\nnonlinear flow and the subspace. Following the equation discovery method, we\nrepresent the vector field that defines the flow using a linear combination of\ndictionary elements, where each element is a pre-specified linear/nonlinear\ncandidate function. A regularization term for the average total kinetic energy\nis also introduced and motivated by optimal transport theory. We prove that the\nresulting optimization problem is well-posed and establish several properties\nof the DDR method. We also show how the DDR method can be trained using a\ngradient-based optimization method, where the gradients are computed using the\nadjoint method from optimal control theory. The DDR method is implemented and\ncompared on synthetic and example datasets to other dimension reductions\nmethods, including PCA, t-SNE, and Umap.",
    "descriptor": "\nComments: 26 pages, 7 figures\n",
    "authors": [
      "Ryeongkyung Yoon",
      "Braxton Osting"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.08155"
  },
  {
    "id": "arXiv:2204.08160",
    "title": "On Arbitrary Compression for Decentralized Consensus and Stochastic  Optimization over Directed Networks",
    "abstract": "We study the decentralized consensus and stochastic optimization problems\nwith compressed communications over static directed graphs. We propose an\niterative gradient-based algorithm that compresses messages according to a\ndesired compression ratio. The proposed method provably reduces the\ncommunication overhead on the network at every communication round. Contrary to\nexisting literature, we allow for arbitrary compression ratios in the\ncommunicated messages. We show a linear convergence rate for the proposed\nmethod on the consensus problem. Moreover, we provide explicit convergence\nrates for decentralized stochastic optimization problems on smooth functions\nthat are either (i) strongly convex, (ii) convex, or (iii) non-convex. Finally,\nwe provide numerical experiments to illustrate convergence under arbitrary\ncompression ratios and the communication efficiency of our algorithm.",
    "descriptor": "",
    "authors": [
      "Mohammad Taha Toghani",
      "C\u00e9sar A. Uribe"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.08160"
  },
  {
    "id": "arXiv:2204.08187",
    "title": "Securing Signal-free Intersections against Strategic Jamming Attacks: A  Macroscopic Approach",
    "abstract": "We consider the security-by-design of a signal-free intersection for\nconnected and autonomous vehicles in the face of strategic jamming attacks. We\nuse a fluid model to characterize macroscopic traffic flow through the\nintersection, where the saturation rate is derived from a vehicle coordination\nalgorithm. We model jamming attacks as sudden increase in communication latency\ninduced on vehicle-to-infrastructure connectivity; such latency triggers the\nsafety mode for vehicle coordination and thus reduces the intersection\nsaturation rate. A strategic attacker selects the attacking rate, while a\nsystem operator selects key design parameters, either the saturation rate or\nthe recovery rate. Both players' actions induce technological costs and jointly\ndetermine the mean travel delay. By analyzing the equilibrium of the security\ngame, we study the preferable level of investment in the intersection's nominal\ndischarging capability or recovery capability, for balance between\nhardware/infrastructure cost and security-by-design.",
    "descriptor": "\nComments: Submitted to 61st IEEE Conference on Decision and Control\n",
    "authors": [
      "Yumeng Bai",
      "Saurabh Amin",
      "Xudong Wang",
      "Li Jin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.08187"
  },
  {
    "id": "arXiv:2204.08192",
    "title": "Semi-Supervised Super-Resolution",
    "abstract": "Super-Resolution is the process of generating a high-resolution image from a\nlow-resolution image. A picture may be of lower resolution due to smaller\nspatial resolution, poor camera quality, as a result of blurring, or due to\nother possible degradations. Super-Resolution is the technique to improve the\nquality of a low-resolution photo by boosting its plausible resolution. The\ncomputer vision community has extensively explored the area of\nSuper-Resolution. However, the previous Super-Resolution methods require vast\namounts of data for training. This becomes problematic in domains where very\nfew low-resolution, high-resolution pairs might be available. One of such areas\nis statistical downscaling, where super-resolution is increasingly being used\nto obtain high-resolution climate information from low-resolution data.\nAcquiring high-resolution climate data is extremely expensive and challenging.\nTo reduce the cost of generating high-resolution climate information,\nSuper-Resolution algorithms should be able to train with a limited number of\nlow-resolution, high-resolution pairs. This paper tries to solve the\naforementioned problem by introducing a semi-supervised way to perform\nsuper-resolution that can generate sharp, high-resolution images with as few as\n500 paired examples. The proposed semi-supervised technique can be used as a\nplug-and-play module with any supervised GAN-based Super-Resolution method to\nenhance its performance. We quantitatively and qualitatively analyze the\nperformance of the proposed model and compare it with completely supervised\nmethods as well as other unsupervised techniques. Comprehensive evaluations\nshow the superiority of our method over other methods on different metrics. We\nalso offer the applicability of our approach in statistical downscaling to\nobtain high-resolution climate images.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Ankur Singh",
      "Piyush Rai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08192"
  },
  {
    "id": "arXiv:2204.08205",
    "title": "A Greedy and Optimistic Approach to Clustering with a Specified  Uncertainty of Covariates",
    "abstract": "In this study, we examine a clustering problem in which the covariates of\neach individual element in a dataset are associated with an uncertainty\nspecific to that element. More specifically, we consider a clustering approach\nin which a pre-processing applying a non-linear transformation to the\ncovariates is used to capture the hidden data structure. To this end, we\napproximate the sets representing the propagated uncertainty for the\npre-processed features empirically. To exploit the empirical uncertainty sets,\nwe propose a greedy and optimistic clustering (GOC) algorithm that finds better\nfeature candidates over such sets, yielding more condensed clusters. As an\nimportant application, we apply the GOC algorithm to synthetic datasets of the\norbital properties of stars generated through our numerical simulation\nmimicking the formation process of the Milky Way. The GOC algorithm\ndemonstrates an improved performance in finding sibling stars originating from\nthe same dwarf galaxy. These realistic datasets have also been made publicly\navailable.",
    "descriptor": "\nComments: 20 pages, 27 figures\n",
    "authors": [
      "Akifumi Okuno",
      "Kohei Hattori"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.08205"
  },
  {
    "id": "arXiv:2204.08213",
    "title": "Index Modulation Pattern Design for Non-Orthogonal Multicarrier Signal  Waveforms",
    "abstract": "Spectral efficiency improvement is a key focus in most wireless communication\nsystems and achieved by various means such as using large antenna arrays and/or\nadvanced modulation schemes and signal formats. This work proposes to further\nimprove spectral efficiency through combining non-orthogonal spectrally\nefficient frequency division multiplexing (SEFDM) systems with index modulation\n(IM), which can efficiently make use of the indices of activated subcarriers as\ncommunication information. Recent research has verified that IM may be used\nwith SEFDM to alleviate inter-carrier interference (ICI) and improve error\nperformance. This work proposes new SEFDM signal formats based on novel\nactivation pattern designs, which limit the locations of activated subcarriers\nand enable a variable number of activated subcarriers in each SEFDM subblock.\nSEFDM-IM system designs are developed by jointly considering activation\npatterns, modulation schemes and signal waveform formats, with a set of\nsolutions evaluated under different spectral efficiency scenarios. Detailed\nmodelling of coded systems and simulation studies reveal that the proposed\ndesigns not only lead to better bit error rate (BER) but also lower\npeak-to-average power ratio (PAPR) and reduced computational complexity\nrelative to other reported index-modulated systems.",
    "descriptor": "",
    "authors": [
      "Yinglin Chen",
      "Tongyang Xu",
      "Izzat Darwazeh"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08213"
  },
  {
    "id": "arXiv:2204.08272",
    "title": "A Multidimensional Artistic Approach to Enhance Understanding of Julia  Sets through Computer Programming",
    "abstract": "This article proposes an artistic approach to increase and enrich the\nunderstanding of Julia Sets. This approach includes the mathematical, the\nplayful, the artistic and the computational dimensions. It is argued that these\nfour dimensions are not disjointed or dissociated despite general rejection by\ntraditional academic communities and art critics communities. Also, some\nsignificant collections of Computational Art or Computer-Generated Mathematical\nArt are mentioned. Four artistic creations based on Julia Sets are presented as\nexamples using the CFDG language. Finally, an informal application of the\napproach was carried out and artistic production of students are presented and\ndiscussed.",
    "descriptor": "\nComments: 8 figures, 8 listings\n",
    "authors": [
      "Eduardo Adam Navas-L\u00f3pez"
    ],
    "subjectives": [
      "History and Overview (math.HO)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2204.08272"
  },
  {
    "id": "arXiv:2204.08274",
    "title": "Iterative Hard Thresholding with Adaptive Regularization: Sparser  Solutions Without Sacrificing Runtime",
    "abstract": "We propose a simple modification to the iterative hard thresholding (IHT)\nalgorithm, which recovers asymptotically sparser solutions as a function of the\ncondition number. When aiming to minimize a convex function $f(x)$ with\ncondition number $\\kappa$ subject to $x$ being an $s$-sparse vector, the\nstandard IHT guarantee is a solution with relaxed sparsity $O(s\\kappa^2)$,\nwhile our proposed algorithm, regularized IHT, returns a solution with sparsity\n$O(s\\kappa)$. Our algorithm significantly improves over ARHT which also finds a\nsolution of sparsity $O(s\\kappa)$, as it does not require re-optimization in\neach iteration (and so is much faster), is deterministic, and does not require\nknowledge of the optimal solution value $f(x^*)$ or the optimal sparsity level\n$s$. Our main technical tool is an adaptive regularization framework, in which\nthe algorithm progressively learns the weights of an $\\ell_2$ regularization\nterm that will allow convergence to sparser solutions. We also apply this\nframework to low rank optimization, where we achieve a similar improvement of\nthe best known condition number dependence from $\\kappa^2$ to $\\kappa$.",
    "descriptor": "",
    "authors": [
      "Kyriakos Axiotis",
      "Maxim Sviridenko"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.08274"
  },
  {
    "id": "arXiv:2204.08281",
    "title": "Decision-Dependent Risk Minimization in Geometrically Decaying Dynamic  Environments",
    "abstract": "This paper studies the problem of expected loss minimization given a data\ndistribution that is dependent on the decision-maker's action and evolves\ndynamically in time according to a geometric decay process. Novel algorithms\nfor both the information setting in which the decision-maker has a first order\ngradient oracle and the setting in which they have simply a loss function\noracle are introduced. The algorithms operate on the same underlying principle:\nthe decision-maker repeatedly deploys a fixed decision over the length of an\nepoch, thereby allowing the dynamically changing environment to sufficiently\nmix before updating the decision. The iteration complexity in each of the\nsettings is shown to match existing rates for first and zero order stochastic\ngradient methods up to logarithmic factors. The algorithms are evaluated on a\n\"semi-synthetic\" example using real world data from the SFpark dynamic pricing\npilot study; it is shown that the announced prices result in an improvement for\nthe institution's objective (target occupancy), while achieving an overall\nreduction in parking rates.",
    "descriptor": "\nComments: Accepted at AAAI 2022\n",
    "authors": [
      "Mitas Ray",
      "Dmitriy Drusvyatskiy",
      "Maryam Fazel",
      "Lillian J. Ratliff"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.08281"
  },
  {
    "id": "arXiv:2204.08323",
    "title": "Experimental twin-field quantum key distribution with flawed and  correlated sources",
    "abstract": "The security of quantum key distribution (QKD) is severely threatened by\ndiscrepancies between realistic devices and theoretical assumptions. Recently,\na significant framework called the reference technique was proposed to provide\nsecurity against arbitrary source flaws, including pulse correlations. Here, we\npropose an efficient four-phase twin-field QKD using laser pulses adopting the\nreference technique for security against all possible source imperfections. We\npresent a characterization of source flaws and connect them to experimental\ndata, together with a finite-key analysis. In addition, we demonstrate the\nfeasibility of our protocol through a proof-of-principle experimental\nimplementation and demonstrate a secure key rate of 1.63 kbps with a 20 dB\nchannel loss. Compared with previous QKD protocols with imperfect devices, our\nwork considerably improves both the secure key rate and the transmission\ndistance, and shows application potential in the practical deployment of secure\nQKD with device imperfections.",
    "descriptor": "\nComments: 17 pages, 7 figures, 8 tables. Comments are welcome\n",
    "authors": [
      "Jie Gu",
      "Xiao-Yu Cao",
      "Yao Fu",
      "Zong-Wu He",
      "Ze-Jie Yin",
      "Hua-Lei Yin",
      "Zeng-Bing Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.08323"
  },
  {
    "id": "arXiv:2204.08335",
    "title": "Active Learning with Weak Labels for Gaussian Processes",
    "abstract": "Annotating data for supervised learning can be costly. When the annotation\nbudget is limited, active learning can be used to select and annotate those\nobservations that are likely to give the most gain in model performance. We\npropose an active learning algorithm that, in addition to selecting which\nobservation to annotate, selects the precision of the annotation that is\nacquired. Assuming that annotations with low precision are cheaper to obtain,\nthis allows the model to explore a larger part of the input space, with the\nsame annotation costs. We build our acquisition function on the previously\nproposed BALD objective for Gaussian Processes, and empirically demonstrate the\ngains of being able to adjust the annotation precision in the active learning\nloop.",
    "descriptor": "",
    "authors": [
      "Amanda Olmin",
      "Jakob Lindqvist",
      "Lennart Svensson",
      "Fredrik Lindsten"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08335"
  },
  {
    "id": "arXiv:2204.08353",
    "title": "Stability Analysis and Stabilization of Continuous-Time Linear Systems  with Distributed Delays",
    "abstract": "This book is an extension of my Ph.D. thesis which is devoted to the methods\nfor the stability (dissipativity) analysis and stabilization of linear systems\nwith non-trivial distributed delays based on the application of the Liapunov-\nKrasovski\\u{i} functional (LKF) approach.",
    "descriptor": "\nComments: The contents will be constantly updated to ensure the book can be utilized as a comprehensive reference for the research on distributed delay systems\n",
    "authors": [
      "Qian Feng"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.08353"
  },
  {
    "id": "arXiv:2204.08374",
    "title": "Untangled: A Complete Dynamic Topological Logic",
    "abstract": "Dynamic topological logic ($\\mathbf{DTL}$) is a trimodal logic designed for\nreasoning about dynamic topological systems. It was shown by Fern\\'andez-Duque\nthat the natural set of axioms for $\\mathbf{DTL}$ is incomplete, but he\nprovided a complete axiomatisation in an extended language. In this paper, we\nconsider dynamic topological logic over scattered spaces, which are topological\nspaces where every nonempty subspace has an isolated point. Scattered spaces\nappear in the context of computational logic as they provide semantics for\nprovability and enjoy definable fixed points. We exhibit the first sound and\ncomplete dynamic topological logic in the original trimodal language. In\nparticular, we show that the version of $\\mathbf{DTL}$ based on the class of\nscattered spaces is finitely axiomatisable over the original language, and that\nthe natural axiomatisation is sound and complete.",
    "descriptor": "",
    "authors": [
      "David Fern\u00e1ndez-Duque",
      "Yo\u00e0v Montacute"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.08374"
  },
  {
    "id": "arXiv:2204.08386",
    "title": "Optimal Subsampling for High-dimensional Ridge Regression",
    "abstract": "We investigate the feature compression of high-dimensional ridge regression\nusing the optimal subsampling technique. Specifically, based on the basic\nframework of random sampling algorithm on feature for ridge regression and the\nA-optimal design criterion, we first obtain a set of optimal subsampling\nprobabilities. Considering that the obtained probabilities are uneconomical, we\nthen propose the nearly optimal ones. With these probabilities, a two step\niterative algorithm is established which has lower computational cost and\nhigher accuracy. We provide theoretical analysis and numerical experiments to\nsupport the proposed methods. Numerical results demonstrate the decent\nperformance of our methods.",
    "descriptor": "",
    "authors": [
      "Hanyu Li",
      "Chengmei Niu"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2204.08386"
  },
  {
    "id": "arXiv:2204.08397",
    "title": "Fast and Memory-Efficient Network Towards Efficient Image  Super-Resolution",
    "abstract": "Runtime and memory consumption are two important aspects for efficient image\nsuper-resolution (EISR) models to be deployed on resource-constrained devices.\nRecent advances in EISR exploit distillation and aggregation strategies with\nplenty of channel split and concatenation operations to make full use of\nlimited hierarchical features. In contrast, sequential network operations avoid\nfrequently accessing preceding states and extra nodes, and thus are beneficial\nto reducing the memory consumption and runtime overhead. Following this idea,\nwe design our lightweight network backbone by mainly stacking multiple highly\noptimized convolution and activation layers and decreasing the usage of feature\nfusion. We propose a novel sequential attention branch, where every pixel is\nassigned an important factor according to local and global contexts, to enhance\nhigh-frequency details. In addition, we tailor the residual block for EISR and\npropose an enhanced residual block (ERB) to further accelerate the network\ninference. Finally, combining all the above techniques, we construct a fast and\nmemory-efficient network (FMEN) and its small version FMEN-S, which runs 33%\nfaster and reduces 74% memory consumption compared with the state-of-the-art\nEISR model: E-RFDN, the champion in AIM 2020 efficient super-resolution\nchallenge. Besides, FMEN-S achieves the lowest memory consumption and the\nsecond shortest runtime in NTIRE 2022 challenge on efficient super-resolution.\nCode is available at https://github.com/NJU-Jet/FMEN.",
    "descriptor": "\nComments: Accepted by NTIRE 2022 (CVPR Workshop)\n",
    "authors": [
      "Zongcai Du",
      "Ding Liu",
      "Jie Liu",
      "Jie Tang",
      "Gangshan Wu",
      "Lean Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08397"
  },
  {
    "id": "arXiv:2204.08411",
    "title": "Robust, Nonparametric, Efficient Decomposition of Spectral Peaks under  Distortion and Interference",
    "abstract": "We propose a decomposition method for the spectral peaks in an observed\nfrequency spectrum, which is efficiently acquired by utilizing the Fast Fourier\nTransform. In contrast to the traditional methods of waveform fitting on the\nspectrum, we optimize the problem from a more robust perspective. We model the\npeaks in spectrum as pseudo-symmetric functions, where the only constraint is a\nnonincreasing behavior around a central frequency when the distance increases.\nOur approach is more robust against arbitrary distortion, interference and\nnoise on the spectrum that may be caused by an observation system. The time\ncomplexity of our method is linear, i.e., $O(N)$ per extracted spectral peak.\nMoreover, the decomposed spectral peaks show a pseudo-orthogonal behavior,\nwhere they conform to a power preserving equality.",
    "descriptor": "",
    "authors": [
      "Kaan Gokcesu",
      "Hakan Gokcesu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.08411"
  },
  {
    "id": "arXiv:1709.00944",
    "title": "Audio-Visual Speech Enhancement Using Multimodal Deep Convolutional  Neural Networks",
    "abstract": "Comments: This paper is the same as arXiv:1703.10893v6. Apologies for the inconvenience. arXiv admin note: text overlap with arXiv:1703.10893",
    "descriptor": "\nComments: This paper is the same as arXiv:1703.10893v6. Apologies for the inconvenience. arXiv admin note: text overlap with arXiv:1703.10893\n",
    "authors": [
      "Jen-Cheng Hou",
      "Syu-Siang Wang",
      "Ying-Hui Lai",
      "Yu Tsao",
      "Hsiu-Wen Chang",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1709.00944"
  },
  {
    "id": "arXiv:1806.01796",
    "title": "Stochastic Gradient Descent on Separable Data: Exact Convergence with a  Fixed Learning Rate",
    "abstract": "Comments: Fixed a typo (Eq. (4) - missing \\sigma_{max}^2 term in the denominator)",
    "descriptor": "\nComments: Fixed a typo (Eq. (4) - missing \\sigma_{max}^2 term in the denominator)\n",
    "authors": [
      "Mor Shpigel Nacson",
      "Nathan Srebro",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1806.01796"
  },
  {
    "id": "arXiv:1909.06997",
    "title": "MVDLite: a Fast Validation Algorithm for Model View Definition Rules",
    "abstract": "Comments: Preprint submitted to 29th International Workshop on Intelligent Computing in Engineering (EG-ICE)",
    "descriptor": "\nComments: Preprint submitted to 29th International Workshop on Intelligent Computing in Engineering (EG-ICE)\n",
    "authors": [
      "Han Liu",
      "Ge Gao",
      "Hehua Zhang",
      "Yu-Shen Liu",
      "Yan Song",
      "Ming Gu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/1909.06997"
  },
  {
    "id": "arXiv:1909.08737",
    "title": "BPMR: Bayesian Probabilistic Multivariate Ranking",
    "abstract": "BPMR: Bayesian Probabilistic Multivariate Ranking",
    "descriptor": "",
    "authors": [
      "Nan Wang",
      "Hongning Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1909.08737"
  },
  {
    "id": "arXiv:2002.10821",
    "title": "Convergence of a Fully Discrete and Energy-Dissipating Finite-Volume  Scheme for Aggregation-Diffusion Equations",
    "abstract": "Convergence of a Fully Discrete and Energy-Dissipating Finite-Volume  Scheme for Aggregation-Diffusion Equations",
    "descriptor": "",
    "authors": [
      "Rafael Bailo",
      "Jose A. Carrillo",
      "Hideki Murakawa",
      "Markus Schmidtchen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2002.10821"
  },
  {
    "id": "arXiv:2005.09169",
    "title": "A faster reduction of the dynamic time warping distance to the longest  increasing subsequence length",
    "abstract": "Comments: Accepted for Algorithmica (Previous version appeared in ISAAC 2020)",
    "descriptor": "\nComments: Accepted for Algorithmica (Previous version appeared in ISAAC 2020)\n",
    "authors": [
      "Yoshifumi Sakai",
      "Shunsuke Inenaga"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2005.09169"
  },
  {
    "id": "arXiv:2006.05905",
    "title": "Spatial-Temporal Dynamic Graph Attention Networks for Ride-hailing  Demand Prediction",
    "abstract": "Comments: 11 pages, 6 figures. arXiv admin note: text overlap with arXiv:2006.04089",
    "descriptor": "\nComments: 11 pages, 6 figures. arXiv admin note: text overlap with arXiv:2006.04089\n",
    "authors": [
      "Weiguo Pian",
      "Yingbo Wu",
      "Xiangmou Qu",
      "Junpeng Cai",
      "Ziyi Kou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2006.05905"
  },
  {
    "id": "arXiv:2006.07452",
    "title": "Secure Route Planning Using Dynamic Games with Stopping States",
    "abstract": "Comments: 8 pages, 5 figures. Technical report for the corresponding conference paper accepted at IEEE International Conference on Intelligent Robots and Systems (IROS), 2020",
    "descriptor": "\nComments: 8 pages, 5 figures. Technical report for the corresponding conference paper accepted at IEEE International Conference on Intelligent Robots and Systems (IROS), 2020\n",
    "authors": [
      "Sandeep Banik",
      "Shaunak D. Bopardikar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2006.07452"
  },
  {
    "id": "arXiv:2007.02905",
    "title": "Optimization of Scoring Rules",
    "abstract": "Optimization of Scoring Rules",
    "descriptor": "",
    "authors": [
      "Jason D. Hartline",
      "Yingkai Li",
      "Liren Shan",
      "Yifan Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2007.02905"
  },
  {
    "id": "arXiv:2007.03762",
    "title": "Transfer Learning for Electricity Price Forecasting",
    "abstract": "Transfer Learning for Electricity Price Forecasting",
    "descriptor": "",
    "authors": [
      "Salih Gunduz",
      "Umut Ugurlu",
      "Ilkay Oksuz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.03762"
  },
  {
    "id": "arXiv:2007.14462",
    "title": "Anomaly Awareness",
    "abstract": "Comments: 12 pages, 17 figures",
    "descriptor": "\nComments: 12 pages, 17 figures\n",
    "authors": [
      "Charanjit K. Khosa",
      "Veronica Sanz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.14462"
  },
  {
    "id": "arXiv:2007.15562",
    "title": "Down-step statistics in generalized Dyck paths",
    "abstract": "Down-step statistics in generalized Dyck paths",
    "descriptor": "",
    "authors": [
      "Andrei Asinowski",
      "Benjamin Hackl",
      "Sarah J. Selkirk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2007.15562"
  },
  {
    "id": "arXiv:2008.04015",
    "title": "MHSA-Net: Multi-Head Self-Attention Network for Occluded Person  Re-Identification",
    "abstract": "Comments: Accepted by TNNLS",
    "descriptor": "\nComments: Accepted by TNNLS\n",
    "authors": [
      "Hongchen Tan",
      "Xiuping Liu",
      "Baocai Yin",
      "Xin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.04015"
  },
  {
    "id": "arXiv:2008.07425",
    "title": "Grundy Distinguishes Treewidth from Pathwidth",
    "abstract": "Comments: Conference version appeared in ESA 2020. This is the full version which has been accepted for publication at SIDMA",
    "descriptor": "\nComments: Conference version appeared in ESA 2020. This is the full version which has been accepted for publication at SIDMA\n",
    "authors": [
      "R\u00e9my Belmonte",
      "Eun Jung Kim",
      "Michael Lampis",
      "Valia Mitsou",
      "Yota Otachi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2008.07425"
  },
  {
    "id": "arXiv:2009.09258",
    "title": "Can You Spot the Chameleon? Adversarially Camouflaging Images from  Co-Salient Object Detection",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Ruijun Gao",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Hongkai Yu",
      "Huazhu Fu",
      "Wei Feng",
      "Yang Liu",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.09258"
  },
  {
    "id": "arXiv:2009.11435",
    "title": "Dynamic Approximate Maximum Independent Set on Massive Graphs",
    "abstract": "Dynamic Approximate Maximum Independent Set on Massive Graphs",
    "descriptor": "",
    "authors": [
      "Xiangyu Gao",
      "Jianzhong Li",
      "Dongjing Miao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2009.11435"
  },
  {
    "id": "arXiv:2010.01196",
    "title": "End-to-End Differentiable Molecular Mechanics Force Field Construction",
    "abstract": "End-to-End Differentiable Molecular Mechanics Force Field Construction",
    "descriptor": "",
    "authors": [
      "Yuanqing Wang",
      "Josh Fass",
      "Benjamin Kaminow",
      "John E. Herr",
      "Dominic Rufa",
      "Ivy Zhang",
      "Iv\u00e1n Pulido",
      "Mike Henry",
      "John D. Chodera"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.01196"
  },
  {
    "id": "arXiv:2010.12190",
    "title": "Towards Robust Neural Networks via Orthogonal Diversity",
    "abstract": "Towards Robust Neural Networks via Orthogonal Diversity",
    "descriptor": "",
    "authors": [
      "Kun Fang",
      "Qinghua Tao",
      "Yingwen Wu",
      "Tao Li",
      "Jia Cai",
      "Feipeng Cai",
      "Xiaolin Huang",
      "Jie Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.12190"
  },
  {
    "id": "arXiv:2011.09300",
    "title": "Stretchable Cells Help DARTS Search Better",
    "abstract": "Stretchable Cells Help DARTS Search Better",
    "descriptor": "",
    "authors": [
      "Tao Huang",
      "Shan You",
      "Yibo Yang",
      "Zhuozhuo Tu",
      "Fei Wang",
      "Chen Qian",
      "Changshui Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.09300"
  },
  {
    "id": "arXiv:2012.07288",
    "title": "Semantic Layout Manipulation with High-Resolution Sparse Attention",
    "abstract": "Comments: 19 pages, 22 figures",
    "descriptor": "\nComments: 19 pages, 22 figures\n",
    "authors": [
      "Haitian Zheng",
      "Zhe Lin",
      "Jingwan Lu",
      "Scott Cohen",
      "Jianming Zhang",
      "Ning Xu",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.07288"
  },
  {
    "id": "arXiv:2012.11579",
    "title": "Multi-Agent Online Optimization with Delays: Asynchronicity, Adaptivity,  and Optimism",
    "abstract": "Comments: Accepted by Journal of Machine Learning Research (JMLR)",
    "descriptor": "\nComments: Accepted by Journal of Machine Learning Research (JMLR)\n",
    "authors": [
      "Yu-Guan Hsieh",
      "Franck Iutzeler",
      "J\u00e9r\u00f4me Malick",
      "Panayotis Mertikopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2012.11579"
  },
  {
    "id": "arXiv:2101.03864",
    "title": "Deep Interactive Bayesian Reinforcement Learning via Meta-Learning",
    "abstract": "Comments: Published as an extended abstract at AAMAS 2021",
    "descriptor": "\nComments: Published as an extended abstract at AAMAS 2021\n",
    "authors": [
      "Luisa Zintgraf",
      "Sam Devlin",
      "Kamil Ciosek",
      "Shimon Whiteson",
      "Katja Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2101.03864"
  },
  {
    "id": "arXiv:2101.06846",
    "title": "Exponential Integration for Efficient and Accurate Multi-Body Simulation  with Stiff Viscoelastic Contacts",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Bilal Hammoud",
      "Luca Olivieri",
      "Ludovic Righetti",
      "Justin Carpentier",
      "Andrea Del Prete"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.06846"
  },
  {
    "id": "arXiv:2101.11952",
    "title": "Rethinking Rotated Object Detection with Gaussian Wasserstein Distance  Loss",
    "abstract": "Comments: 15 pages, 6 figures, 9 tables, accepted by ICML21, codes are available at this https URL and this https URL",
    "descriptor": "\nComments: 15 pages, 6 figures, 9 tables, accepted by ICML21, codes are available at this https URL and this https URL\n",
    "authors": [
      "Xue Yang",
      "Junchi Yan",
      "Qi Ming",
      "Wentao Wang",
      "Xiaopeng Zhang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.11952"
  },
  {
    "id": "arXiv:2102.00451",
    "title": "Exponential Savings in Agnostic Active Learning through Abstention",
    "abstract": "Comments: 31 pages, IEEE Transactions on Information Theory",
    "descriptor": "\nComments: 31 pages, IEEE Transactions on Information Theory\n",
    "authors": [
      "Nikita Puchkin",
      "Nikita Zhivotovskiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2102.00451"
  },
  {
    "id": "arXiv:2102.12380",
    "title": "Pre-Training on Dynamic Graph Neural Networks",
    "abstract": "Pre-Training on Dynamic Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Ke-jia Chen",
      "Jiajun Zhang",
      "Linpu Jiang",
      "Yunyun Wang",
      "Yuxuan Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2102.12380"
  },
  {
    "id": "arXiv:2102.13266",
    "title": "Occupation Kernel Hilbert Spaces for Fractional Order Liouville  Operators and Dynamic Mode Decomposition",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Joel A. Rosenfeld",
      "Benjamin Russo",
      "Xiuying Li"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.13266"
  },
  {
    "id": "arXiv:2103.16299",
    "title": "Generalized $b$-symbol weights of Linear Codes and $b$-symbol MDS Codes",
    "abstract": "Generalized $b$-symbol weights of Linear Codes and $b$-symbol MDS Codes",
    "descriptor": "",
    "authors": [
      "Hongwei Liu",
      "Xu Pan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.16299"
  },
  {
    "id": "arXiv:2103.16847",
    "title": "A Novel Deep ML Architecture by Integrating Visual Simultaneous  Localization and Mapping (vSLAM) into Mask R-CNN for Real-time Surgical Video  Analysis",
    "abstract": "Comments: Accepted and Published in ISBI 2022",
    "descriptor": "\nComments: Accepted and Published in ISBI 2022\n",
    "authors": [
      "Ella Selina Lan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.16847"
  },
  {
    "id": "arXiv:2104.01164",
    "title": "Silicon microring synapses enable photonic deep learning beyond 9-bit  precision",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Weipeng Zhang",
      "Chaoran Huang",
      "Hsuan-Tung Peng",
      "Simon Bilodeau",
      "Aashu Jha",
      "Eric Blow",
      "Thomas Ferreira De Lima",
      "Bhavin J. Shastri",
      "Paul Prucnal"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Systems and Control (eess.SY)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2104.01164"
  },
  {
    "id": "arXiv:2104.02935",
    "title": "TSception: Capturing Temporal Dynamics and Spatial Asymmetry from EEG  for Emotion Recognition",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. (Accepted as a regular paper in IEEE Transactions on Affective Computing)",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. (Accepted as a regular paper in IEEE Transactions on Affective Computing)\n",
    "authors": [
      "Yi Ding",
      "Neethu Robinson",
      "Su Zhang",
      "Qiuhao Zeng",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.02935"
  },
  {
    "id": "arXiv:2104.03100",
    "title": "HIH: Towards More Accurate Face Alignment via Heatmap in Heatmap",
    "abstract": "Comments: A large update(v2) for HIH",
    "descriptor": "\nComments: A large update(v2) for HIH\n",
    "authors": [
      "Xing Lan",
      "Qinghao Hu",
      "Qiang Chen",
      "Jian Xue",
      "Jian Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03100"
  },
  {
    "id": "arXiv:2104.04609",
    "title": "Frequency-robust preconditioning of boundary integral equations for  acoustic transmission",
    "abstract": "Frequency-robust preconditioning of boundary integral equations for  acoustic transmission",
    "descriptor": "",
    "authors": [
      "Elwin van 't Wout",
      "Seyyed R. Haqshenas",
      "Pierre G\u00e9lat",
      "Timo Betcke",
      "Nader Saffari"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.04609"
  },
  {
    "id": "arXiv:2104.04805",
    "title": "Non-autoregressive Transformer-based End-to-end ASR using BERT",
    "abstract": "Non-autoregressive Transformer-based End-to-end ASR using BERT",
    "descriptor": "",
    "authors": [
      "Fu-Hao Yu",
      "Kuan-Yu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.04805"
  },
  {
    "id": "arXiv:2104.08677",
    "title": "From Fully Trained to Fully Random Embeddings: Improving Neural Machine  Translation with Compact Word Embedding Tables",
    "abstract": "From Fully Trained to Fully Random Embeddings: Improving Neural Machine  Translation with Compact Word Embedding Tables",
    "descriptor": "",
    "authors": [
      "Krtin Kumar",
      "Peyman Passban",
      "Mehdi Rezagholizadeh",
      "Yiu Sing Lau",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08677"
  },
  {
    "id": "arXiv:2104.09096",
    "title": "Wake Up and Join Me! An Energy-Efficient Algorithm for Maximal Matching  in Radio Networks",
    "abstract": "Comments: 14 pages, 2 figures, 3 algorithms",
    "descriptor": "\nComments: 14 pages, 2 figures, 3 algorithms\n",
    "authors": [
      "Varsha Dani",
      "Aayush Gupta",
      "Thomas P. Hayes",
      "Seth Pettie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.09096"
  },
  {
    "id": "arXiv:2104.09500",
    "title": "Transductive Learning for Abstractive News Summarization",
    "abstract": "Transductive Learning for Abstractive News Summarization",
    "descriptor": "",
    "authors": [
      "Arthur Bra\u017einskas",
      "Mengwen Liu",
      "Ramesh Nallapati",
      "Sujith Ravi",
      "Markus Dreyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09500"
  },
  {
    "id": "arXiv:2105.00373",
    "title": "Investigating the Impact of Multi-LiDAR Placement on Object Detection  for Autonomous Driving",
    "abstract": "Comments: CVPR 2022 camera-ready version:15 pages, 14 figures, 9 tables",
    "descriptor": "\nComments: CVPR 2022 camera-ready version:15 pages, 14 figures, 9 tables\n",
    "authors": [
      "Hanjiang Hu",
      "Zuxin Liu",
      "Sharad Chitlangia",
      "Akhil Agnihotri",
      "Ding Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00373"
  },
  {
    "id": "arXiv:2105.03053",
    "title": "Salient Objects in Clutter",
    "abstract": "Comments: 349 references, 20 pages, survey 201 models, benchmark 100 models. Online benchmark: this https URL",
    "descriptor": "\nComments: 349 references, 20 pages, survey 201 models, benchmark 100 models. Online benchmark: this https URL\n",
    "authors": [
      "Deng-Ping Fan",
      "Jing Zhang",
      "Gang Xu",
      "Ming-Ming Cheng",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03053"
  },
  {
    "id": "arXiv:2105.04588",
    "title": "Partitioning H-Free Graphs of Bounded Diameter",
    "abstract": "Partitioning H-Free Graphs of Bounded Diameter",
    "descriptor": "",
    "authors": [
      "Christoph Brause",
      "Petr Golovach",
      "Barnaby Martin",
      "Dani\u00ebl Paulusma",
      "Siani Smith"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.04588"
  },
  {
    "id": "arXiv:2105.06232",
    "title": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with  Adapters",
    "abstract": "Comments: The first two authors contribute equally; Accepted in ACL 2022 DialDoc Workshop (Best Student Paper Award)",
    "descriptor": "\nComments: The first two authors contribute equally; Accepted in ACL 2022 DialDoc Workshop (Best Student Paper Award)\n",
    "authors": [
      "Yan Xu",
      "Etsuko Ishii",
      "Samuel Cahyawijaya",
      "Zihan Liu",
      "Genta Indra Winata",
      "Andrea Madotto",
      "Dan Su",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.06232"
  },
  {
    "id": "arXiv:2105.07146",
    "title": "GCN-MIF: Graph Convolutional Network with Multi-Information Fusion for  Low-dose CT Denoising",
    "abstract": "Comments: Submitted to TMI with under review",
    "descriptor": "\nComments: Submitted to TMI with under review\n",
    "authors": [
      "Kecheng Chen",
      "Jiayu Sun",
      "Jiang Shen",
      "Jixiang Luo",
      "Xinyu Zhang",
      "Xuelin Pan",
      "Dongsheng Wu",
      "Yue Zhao",
      "Miguel Bento",
      "Yazhou Ren",
      "Xiaorong Pu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07146"
  },
  {
    "id": "arXiv:2105.08057",
    "title": "Analysis for the Overwhelming Success of the Web Compared to Microcosm  and Hyper-G Systems",
    "abstract": "Analysis for the Overwhelming Success of the Web Compared to Microcosm  and Hyper-G Systems",
    "descriptor": "",
    "authors": [
      "Bryar A. Hassan",
      "Shko M. Qader"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2105.08057"
  },
  {
    "id": "arXiv:2105.08496",
    "title": "Combinatorics of minimal absent words for a sliding window",
    "abstract": "Comments: A part of the results of this article appeared in Proc. SOFSEM 2020 (also in arXiv:1909.02804). The results on binary alphabets are the main new material in this article",
    "descriptor": "\nComments: A part of the results of this article appeared in Proc. SOFSEM 2020 (also in arXiv:1909.02804). The results on binary alphabets are the main new material in this article\n",
    "authors": [
      "Tooru Akagi",
      "Yuki Kuhara",
      "Takuya Mieno",
      "Yuto Nakashima",
      "Shunsuke Inenaga",
      "Hideo Bannai",
      "Masayuki Takeda"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.08496"
  },
  {
    "id": "arXiv:2105.08996",
    "title": "Separating Sessions Smoothly",
    "abstract": "Comments: 51 pages",
    "descriptor": "\nComments: 51 pages\n",
    "authors": [
      "Simon Fowler",
      "Wen Kokke",
      "Ornela Dardha",
      "Sam Lindley",
      "J. Garrett Morris"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.08996"
  },
  {
    "id": "arXiv:2105.09624",
    "title": "Semantic segmentation of multispectral photoacoustic images using deep  learning",
    "abstract": "Comments: 8 pages, 7 figures, 3 tables",
    "descriptor": "\nComments: 8 pages, 7 figures, 3 tables\n",
    "authors": [
      "Melanie Schellenberg",
      "Kris Dreher",
      "Niklas Holzwarth",
      "Fabian Isensee",
      "Annika Reinke",
      "Nicholas Schreck",
      "Alexander Seitel",
      "Minu D. Tizabi",
      "Lena Maier-Hein",
      "Janek Gr\u00f6hl"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.09624"
  },
  {
    "id": "arXiv:2105.11122",
    "title": "Heterogeneous Graph Representation Learning with Relation Awareness",
    "abstract": "Comments: Accepted by the TKDE journal",
    "descriptor": "\nComments: Accepted by the TKDE journal\n",
    "authors": [
      "Le Yu",
      "Leilei Sun",
      "Bowen Du",
      "Chuanren Liu",
      "Weifeng Lv",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.11122"
  },
  {
    "id": "arXiv:2105.13010",
    "title": "An error analysis of generative adversarial networks for learning  distributions",
    "abstract": "An error analysis of generative adversarial networks for learning  distributions",
    "descriptor": "",
    "authors": [
      "Jian Huang",
      "Yuling Jiao",
      "Zhen Li",
      "Shiao Liu",
      "Yang Wang",
      "Yunfei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13010"
  },
  {
    "id": "arXiv:2105.14130",
    "title": "3D U-NetR: Low Dose Computed Tomography Reconstruction via Deep Learning  and 3 Dimensional Convolutions",
    "abstract": "Comments: 18 pages, 5 figures",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Doga Gunduzalp",
      "Batuhan Cengiz",
      "Mehmet Ozan Unal",
      "Isa Yildirim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.14130"
  },
  {
    "id": "arXiv:2105.14328",
    "title": "Transfer Learning under High-dimensional Generalized Linear Models",
    "abstract": "Comments: 94 pages, 11 figures",
    "descriptor": "\nComments: 94 pages, 11 figures\n",
    "authors": [
      "Ye Tian",
      "Yang Feng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.14328"
  },
  {
    "id": "arXiv:2106.01263",
    "title": "Panoramic-Encoder: A Fast and Accurate Response Selection Paradigm for  Generation-Based Dialogue Systems",
    "abstract": "Panoramic-Encoder: A Fast and Accurate Response Selection Paradigm for  Generation-Based Dialogue Systems",
    "descriptor": "",
    "authors": [
      "Chiyu Song",
      "Hongliang He",
      "Haofei Yu",
      "Huachuan Qiu",
      "Pengfei Fang",
      "Zhenzhong Lan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01263"
  },
  {
    "id": "arXiv:2106.01883",
    "title": "Learning High-Precision Bounding Box for Rotated Object Detection via  Kullback-Leibler Divergence",
    "abstract": "Comments: 16 pages, 5 figures, 8 tables, accepted by NeurIPS21, codes are available at this https URL and this https URL",
    "descriptor": "\nComments: 16 pages, 5 figures, 8 tables, accepted by NeurIPS21, codes are available at this https URL and this https URL\n",
    "authors": [
      "Xue Yang",
      "Xiaojiang Yang",
      "Jirui Yang",
      "Qi Ming",
      "Wentao Wang",
      "Qi Tian",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01883"
  },
  {
    "id": "arXiv:2106.02405",
    "title": "A Guidance and Maneuvering Control System Design with Anti-collision  Using Stream Functions with Vortex Flows for Autonomous Marine Vessels",
    "abstract": "Comments: 16 pages, 17 figures. This paper is accepted by IEEE Transactions on Control Systems Technology",
    "descriptor": "\nComments: 16 pages, 17 figures. This paper is accepted by IEEE Transactions on Control Systems Technology\n",
    "authors": [
      "Hongyu Zhou",
      "Zhengru Ren",
      "Mathias Marley",
      "Roger Skjetne"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02405"
  },
  {
    "id": "arXiv:2106.04703",
    "title": "Categorical Data Structures for Technical Computing",
    "abstract": "Comments: 27 pages, 7 figures",
    "descriptor": "\nComments: 27 pages, 7 figures\n",
    "authors": [
      "Evan Patterson",
      "Owen Lynch",
      "James Fairbanks"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.04703"
  },
  {
    "id": "arXiv:2106.05492",
    "title": "Learning Adversarially Robust Policies in Multi-Agent Games",
    "abstract": "Learning Adversarially Robust Policies in Multi-Agent Games",
    "descriptor": "",
    "authors": [
      "Eric Zhao",
      "Alexander R. Trott",
      "Caiming Xiong",
      "Stephan Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05492"
  },
  {
    "id": "arXiv:2106.07094",
    "title": "On the Convergence of Differentially Private Federated Learning on  Non-Lipschitz Objectives, and with Normalized Client Updates",
    "abstract": "On the Convergence of Differentially Private Federated Learning on  Non-Lipschitz Objectives, and with Normalized Client Updates",
    "descriptor": "",
    "authors": [
      "Rudrajit Das",
      "Abolfazl Hashemi",
      "Sujay Sanghavi",
      "Inderjit S. Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07094"
  },
  {
    "id": "arXiv:2106.09397",
    "title": "Quantized Federated Learning under Transmission Delay and Outage  Constraints",
    "abstract": "Quantized Federated Learning under Transmission Delay and Outage  Constraints",
    "descriptor": "",
    "authors": [
      "Yanmeng Wang",
      "Yanqing Xu",
      "Qingjiang Shi",
      "Tsung-Hui Chang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09397"
  },
  {
    "id": "arXiv:2106.10829",
    "title": "Two-Stream Consensus Network: Submission to HACS Challenge 2021  Weakly-Supervised Learning Track",
    "abstract": "Comments: Second place solution to the HACS Weakly-Supervised Temporal Action Localization Challenge 2021. arXiv admin note: text overlap with arXiv:2010.11594",
    "descriptor": "\nComments: Second place solution to the HACS Weakly-Supervised Temporal Action Localization Challenge 2021. arXiv admin note: text overlap with arXiv:2010.11594\n",
    "authors": [
      "Yuanhao Zhai",
      "Le Wang",
      "David Doermann",
      "Junsong Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10829"
  },
  {
    "id": "arXiv:2106.11053",
    "title": "Leveraging Language to Learn Program Abstractions and Search Heuristics",
    "abstract": "Comments: appeared in Thirty-eighth International Conference on Machine Learning (ICML 2021)",
    "descriptor": "\nComments: appeared in Thirty-eighth International Conference on Machine Learning (ICML 2021)\n",
    "authors": [
      "Catherine Wong",
      "Kevin Ellis",
      "Joshua B. Tenenbaum",
      "Jacob Andreas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11053"
  },
  {
    "id": "arXiv:2106.13765",
    "title": "\"Zero-Shot\" Point Cloud Upsampling",
    "abstract": "Comments: Accepted at ICME 2022",
    "descriptor": "\nComments: Accepted at ICME 2022\n",
    "authors": [
      "Kaiyue Zhou",
      "Ming Dong",
      "Suzan Arslanturk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13765"
  },
  {
    "id": "arXiv:2107.01832",
    "title": "Provable Convergence of Nesterov's Accelerated Gradient Method for  Over-Parameterized Neural Networks",
    "abstract": "Provable Convergence of Nesterov's Accelerated Gradient Method for  Over-Parameterized Neural Networks",
    "descriptor": "",
    "authors": [
      "Xin Liu",
      "Zhisong Pan",
      "Wei Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01832"
  },
  {
    "id": "arXiv:2107.02086",
    "title": "One-Cycle Pruning: Pruning ConvNets Under a Tight Training Budget",
    "abstract": "Comments: Accepted at Sparsity in Neural Networks (SNN 2021)",
    "descriptor": "\nComments: Accepted at Sparsity in Neural Networks (SNN 2021)\n",
    "authors": [
      "Nathan Hubens",
      "Matei Mancas",
      "Bernard Gosselin",
      "Marius Preda",
      "Titus Zaharia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02086"
  },
  {
    "id": "arXiv:2107.02185",
    "title": "Growing Urban Bicycle Networks",
    "abstract": "Comments: Main text: 14 pages, 7 figures. Website: this http URL",
    "descriptor": "\nComments: Main text: 14 pages, 7 figures. Website: this http URL\n",
    "authors": [
      "Michael Szell",
      "Sayat Mimar",
      "Tyler Perlman",
      "Gourab Ghoshal",
      "Roberta Sinatra"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.02185"
  },
  {
    "id": "arXiv:2107.02451",
    "title": "Integrating Large Circular Kernels into CNNs through Neural Architecture  Search",
    "abstract": "Comments: 20 pages, 10 figures, submitted to a conference",
    "descriptor": "\nComments: 20 pages, 10 figures, submitted to a conference\n",
    "authors": [
      "Kun He",
      "Chao Li",
      "Yixiao Yang",
      "Gao Huang",
      "John E. Hopcroft"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02451"
  },
  {
    "id": "arXiv:2107.05686",
    "title": "The Role of Pretrained Representations for the OOD Generalization of  Reinforcement Learning Agents",
    "abstract": "Comments: Published at ICLR 2022",
    "descriptor": "\nComments: Published at ICLR 2022\n",
    "authors": [
      "Andrea Dittadi",
      "Frederik Tr\u00e4uble",
      "Manuel W\u00fcthrich",
      "Felix Widmaier",
      "Peter Gehler",
      "Ole Winther",
      "Francesco Locatello",
      "Olivier Bachem",
      "Bernhard Sch\u00f6lkopf",
      "Stefan Bauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05686"
  },
  {
    "id": "arXiv:2107.06419",
    "title": "FLAT: An Optimized Dataflow for Mitigating Attention Bottlenecks",
    "abstract": "FLAT: An Optimized Dataflow for Mitigating Attention Bottlenecks",
    "descriptor": "",
    "authors": [
      "Sheng-Chun Kao",
      "Suvinay Subramanian",
      "Gaurav Agrawal",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.06419"
  },
  {
    "id": "arXiv:2107.12724",
    "title": "Quantum Meet-in-the-Middle Attack on Feistel Construction",
    "abstract": "Comments: 18 pages, 3 figures",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Yinsong Xu",
      "Zheng Yuan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.12724"
  },
  {
    "id": "arXiv:2107.13058",
    "title": "On-Demand Delivery from Stores: Dynamic Dispatching and Routing with  Random Demand",
    "abstract": "On-Demand Delivery from Stores: Dynamic Dispatching and Routing with  Random Demand",
    "descriptor": "",
    "authors": [
      "Sheng Liu",
      "Zhixing Luo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.13058"
  },
  {
    "id": "arXiv:2107.13449",
    "title": "Self-learning Emulators and Eigenvector Continuation",
    "abstract": "Comments: 6 + 5 pages (main + supplemental), 5 + 7 figures (main + supplemental), additional discussion, references, and examples added",
    "descriptor": "\nComments: 6 + 5 pages (main + supplemental), 5 + 7 figures (main + supplemental), additional discussion, references, and examples added\n",
    "authors": [
      "Avik Sarkar",
      "Dean Lee"
    ],
    "subjectives": [
      "Nuclear Theory (nucl-th)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.13449"
  },
  {
    "id": "arXiv:2107.14600",
    "title": "MDQE: A More Accurate Direct Pretraining for Machine Translation Quality  Estimation",
    "abstract": "Comments: Just some ideas of my own, not supported by experiments",
    "descriptor": "\nComments: Just some ideas of my own, not supported by experiments\n",
    "authors": [
      "Lei Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.14600"
  },
  {
    "id": "arXiv:2108.00083",
    "title": "Majorization Minimization Methods for Distributed Pose Graph  Optimization",
    "abstract": "Comments: 33 pages",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Taosha Fan",
      "Todd Murphey"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.00083"
  },
  {
    "id": "arXiv:2108.00502",
    "title": "Choice number of Kneser graphs",
    "abstract": "Choice number of Kneser graphs",
    "descriptor": "",
    "authors": [
      "Vera Bulankina",
      "Andrey Kupavskii"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2108.00502"
  },
  {
    "id": "arXiv:2108.00610",
    "title": "Multiple Classifiers Based Maximum Classifier Discrepancy for  Unsupervised Domain Adaptation",
    "abstract": "Multiple Classifiers Based Maximum Classifier Discrepancy for  Unsupervised Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Yiju Yang",
      "Taejoon Kim",
      "Guanghui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.00610"
  },
  {
    "id": "arXiv:2108.03899",
    "title": "A Concise Function Representation for Faster Exact MPE and Constrained  Optimisation in Graphical Models",
    "abstract": "Comments: Submitted to IEEE Transactions on Cybernetics",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Cybernetics\n",
    "authors": [
      "Filippo Bistaffa"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.03899"
  },
  {
    "id": "arXiv:2108.06688",
    "title": "Complex Knowledge Base Question Answering: A Survey",
    "abstract": "Comments: 20 pages, 4 tables, 7 figures. arXiv admin note: text overlap with arXiv:2105.11644",
    "descriptor": "\nComments: 20 pages, 4 tables, 7 figures. arXiv admin note: text overlap with arXiv:2105.11644\n",
    "authors": [
      "Yunshi Lan",
      "Gaole He",
      "Jinhao Jiang",
      "Jing Jiang",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.06688"
  },
  {
    "id": "arXiv:2108.06988",
    "title": "A diffusion-map-based algorithm for gradient computation on manifolds  and applications",
    "abstract": "Comments: New version with applications in inverse problems",
    "descriptor": "\nComments: New version with applications in inverse problems\n",
    "authors": [
      "Alvaro Almeida Gomez",
      "Ant\u00f4nio J. Silva Neto",
      "Jorge P. Zubelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.06988"
  },
  {
    "id": "arXiv:2108.07344",
    "title": "IsoScore: Measuring the Uniformity of Embedding Space Utilization",
    "abstract": "Comments: ACL 2022 camera ready version",
    "descriptor": "\nComments: ACL 2022 camera ready version\n",
    "authors": [
      "William Rudman",
      "Nate Gillman",
      "Taylor Rayne",
      "Carsten Eickhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.07344"
  },
  {
    "id": "arXiv:2108.08233",
    "title": "Research on Gender-related Fingerprint Features",
    "abstract": "Comments: 11 pages, 6 figures, 4 tables",
    "descriptor": "\nComments: 11 pages, 6 figures, 4 tables\n",
    "authors": [
      "Yong Qi",
      "Yanping Li",
      "Huawei Lin",
      "Jiashu Chen",
      "Huaiguang Lei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.08233"
  },
  {
    "id": "arXiv:2108.09831",
    "title": "Energy-adaptive Riemannian optimization on the Stiefel manifold",
    "abstract": "Comments: accepted for publication in M2AN",
    "descriptor": "\nComments: accepted for publication in M2AN\n",
    "authors": [
      "Robert Altmann",
      "Daniel Peterseim",
      "Tatjana Stykel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.09831"
  },
  {
    "id": "arXiv:2108.11345",
    "title": "A Unifying Theory of Thompson Sampling for Continuous Risk-Averse  Bandits",
    "abstract": "Comments: Accepted to the Association for the Advancement of Artificial Intelligence (AAAI) 2022",
    "descriptor": "\nComments: Accepted to the Association for the Advancement of Artificial Intelligence (AAAI) 2022\n",
    "authors": [
      "Joel Q. L. Chang",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.11345"
  },
  {
    "id": "arXiv:2108.12043",
    "title": "Learning Disentangled Representations in the Imaging Domain",
    "abstract": "Comments: Submitted. This paper follows a tutorial style but also surveys a considerable (more than 260 citations) number of works",
    "descriptor": "\nComments: Submitted. This paper follows a tutorial style but also surveys a considerable (more than 260 citations) number of works\n",
    "authors": [
      "Xiao Liu",
      "Pedro Sanchez",
      "Spyridon Thermos",
      "Alison Q. O'Neil",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.12043"
  },
  {
    "id": "arXiv:2109.00732",
    "title": "Coalgebras for Bisimulation of Weighted Automata over Semirings",
    "abstract": "Coalgebras for Bisimulation of Weighted Automata over Semirings",
    "descriptor": "",
    "authors": [
      "Purandar Bhaduri"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.00732"
  },
  {
    "id": "arXiv:2109.05265",
    "title": "RVMDE: Radar Validated Monocular Depth Estimation for Robotics",
    "abstract": "RVMDE: Radar Validated Monocular Depth Estimation for Robotics",
    "descriptor": "",
    "authors": [
      "Muhamamd Ishfaq Hussain",
      "Muhammad Aasim Rafique",
      "Moongu Jeon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05265"
  },
  {
    "id": "arXiv:2109.05710",
    "title": "Robust Stability of Neural-Network Controlled Nonlinear Systems with  Parametric Variability",
    "abstract": "Comments: 15 pages, 7 figures",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Soumyabrata Talukder",
      "Ratnesh Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.05710"
  },
  {
    "id": "arXiv:2109.06049",
    "title": "String Diagram Rewrite Theory III: Confluence with and without Frobenius",
    "abstract": "String Diagram Rewrite Theory III: Confluence with and without Frobenius",
    "descriptor": "",
    "authors": [
      "Filippo Bonchi",
      "Fabio Gadducci",
      "Aleks Kissinger",
      "Pawe\u0142 Soboci\u0144ski",
      "Fabio Zanasi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.06049"
  },
  {
    "id": "arXiv:2109.07783",
    "title": "Towards Non-Line-of-Sight Photography",
    "abstract": "Comments: The proposed method and dataset are required further validations",
    "descriptor": "\nComments: The proposed method and dataset are required further validations\n",
    "authors": [
      "Jiayong Peng",
      "Fangzhou Mu",
      "Ji Hyun Nam",
      "Siddeshwar Raghavan",
      "Yin Li",
      "Andreas Velten",
      "Zhiwei Xiong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07783"
  },
  {
    "id": "arXiv:2109.07999",
    "title": "Learning from Peers: Deep Transfer Reinforcement Learning for Joint  Radio and Cache Resource Allocation in 5G RAN Slicing",
    "abstract": "Comments: Under review of IEEE Transactions on Cognitive Communications and Networking",
    "descriptor": "\nComments: Under review of IEEE Transactions on Cognitive Communications and Networking\n",
    "authors": [
      "Hao Zhou",
      "Melike Erol-Kantarci",
      "Vincent Poor"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.07999"
  },
  {
    "id": "arXiv:2109.08830",
    "title": "Multilingual Molecular Representation Learning via Contrastive  Pre-training",
    "abstract": "Comments: Accepted to ACL 2022 main conference",
    "descriptor": "\nComments: Accepted to ACL 2022 main conference\n",
    "authors": [
      "Zhihui Guo",
      "Pramod Sharma",
      "Andy Martinez",
      "Liang Du",
      "Robin Abraham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.08830"
  },
  {
    "id": "arXiv:2109.12674",
    "title": "MetaDrive: Composing Diverse Driving Scenarios for Generalizable  Reinforcement Learning",
    "abstract": "Comments: Source code, documentation, and demo video are available at this https URL . More research projects based on MetaDrive simulator are listed at this https URL",
    "descriptor": "\nComments: Source code, documentation, and demo video are available at this https URL . More research projects based on MetaDrive simulator are listed at this https URL\n",
    "authors": [
      "Quanyi Li",
      "Zhenghao Peng",
      "Lan Feng",
      "Qihang Zhang",
      "Zhenghai Xue",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.12674"
  },
  {
    "id": "arXiv:2110.00857",
    "title": "FairFed: Enabling Group Fairness in Federated Learning",
    "abstract": "FairFed: Enabling Group Fairness in Federated Learning",
    "descriptor": "",
    "authors": [
      "Yahya H. Ezzeldin",
      "Shen Yan",
      "Chaoyang He",
      "Emilio Ferrara",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.00857"
  },
  {
    "id": "arXiv:2110.04795",
    "title": "Group Signatures and Accountable Ring Signatures from Isogeny-based  Assumptions",
    "abstract": "Group Signatures and Accountable Ring Signatures from Isogeny-based  Assumptions",
    "descriptor": "",
    "authors": [
      "Kai-Min Chung",
      "Yao-Ching Hsieh",
      "Mi-Ying Huang",
      "Yu-Hsuan Huang",
      "Tanja Lange",
      "Bo-Yin Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04795"
  },
  {
    "id": "arXiv:2110.05461",
    "title": "Implicit gradients based novel conservative numerical scheme for  compressible flows",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2106.01738",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.01738\n",
    "authors": [
      "Amareshwara Sainadh Chamarthi",
      "Abhishek Chintagunta",
      "Natan Hoffmann",
      "Hiroaki Nishikawa",
      "Steven H. Frankel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05461"
  },
  {
    "id": "arXiv:2110.06532",
    "title": "Finding Materialized Models for Model Reuse",
    "abstract": "Finding Materialized Models for Model Reuse",
    "descriptor": "",
    "authors": [
      "Minjun Zhao",
      "Lu Chen",
      "Keyu Yang",
      "Yuntao Du",
      "Yunjun Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.06532"
  },
  {
    "id": "arXiv:2110.07520",
    "title": "Comparative Opinion Summarization via Collaborative Decoding",
    "abstract": "Comments: Findings of ACL 2022",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Hayate Iso",
      "Xiaolan Wang",
      "Stefanos Angelidis",
      "Yoshihiko Suhara"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.07520"
  },
  {
    "id": "arXiv:2110.07580",
    "title": "Graph Condensation for Graph Neural Networks",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Wei Jin",
      "Lingxiao Zhao",
      "Shichang Zhang",
      "Yozen Liu",
      "Jiliang Tang",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.07580"
  },
  {
    "id": "arXiv:2110.08101",
    "title": "An Artificial Neural Network-Based Model Predictive Control for  Three-phase Flying Capacitor Multi-Level Inverter",
    "abstract": "Comments: 12 pages, 21 figures, 5 tables",
    "descriptor": "\nComments: 12 pages, 21 figures, 5 tables\n",
    "authors": [
      "Abualkasim Bakeer",
      "Ihab S. Mohamed",
      "Parisa Boodaghi Malidarreh",
      "Intissar Hattabi",
      "Lantao Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08101"
  },
  {
    "id": "arXiv:2110.08837",
    "title": "Category-theoretical Semantics of the Description Logic ALC (extended  version)",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Chan Le Duc"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.08837"
  },
  {
    "id": "arXiv:2110.08951",
    "title": "Nonlinear Reduced DNN Models for State Estimation",
    "abstract": "Nonlinear Reduced DNN Models for State Estimation",
    "descriptor": "",
    "authors": [
      "Wolfgang Dahmen",
      "Min Wang",
      "Zhu Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.08951"
  },
  {
    "id": "arXiv:2110.09264",
    "title": "Intent Classification Using Pre-trained Language Agnostic Embeddings For  Low Resource Languages",
    "abstract": "Intent Classification Using Pre-trained Language Agnostic Embeddings For  Low Resource Languages",
    "descriptor": "",
    "authors": [
      "Hemant Yadav",
      "Akshat Gupta",
      "Sai Krishna Rallabandi",
      "Alan W Black",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09264"
  },
  {
    "id": "arXiv:2110.10124",
    "title": "A Numerical Scheme for Wave Turbulence: 3-Wave Kinetic Equations",
    "abstract": "A Numerical Scheme for Wave Turbulence: 3-Wave Kinetic Equations",
    "descriptor": "",
    "authors": [
      "Steven Walton",
      "Minh-Binh Tran"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.10124"
  },
  {
    "id": "arXiv:2110.11725",
    "title": "Voltage Stabilization of A DC-Microgrid Using ANFIS Controller  Considering EVs, DER, and Transient Storage",
    "abstract": "Comments: 19 pages, 27 figures",
    "descriptor": "\nComments: 19 pages, 27 figures\n",
    "authors": [
      "Hussein Zolfaghari",
      "Hossein Karimi",
      "Hamidreza Momeni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11725"
  },
  {
    "id": "arXiv:2110.11784",
    "title": "Safe rules for the identification of zeros in the solutions of the SLOPE  problem",
    "abstract": "Comments: 26 pages, 3 figures",
    "descriptor": "\nComments: 26 pages, 3 figures\n",
    "authors": [
      "Cl\u00e9ment Elvira",
      "C\u00e9dric Herzet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11784"
  },
  {
    "id": "arXiv:2110.12328",
    "title": "Improving Spectral Clustering Using Spectrum-Preserving Node Reduction",
    "abstract": "Improving Spectral Clustering Using Spectrum-Preserving Node Reduction",
    "descriptor": "",
    "authors": [
      "Yongyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12328"
  },
  {
    "id": "arXiv:2110.12908",
    "title": "Learning to run a power network with trust",
    "abstract": "Learning to run a power network with trust",
    "descriptor": "",
    "authors": [
      "Antoine Marot",
      "Benjamin Donnot",
      "Karim Chaouache",
      "Adrian Kelly",
      "Qiuhua Huang",
      "Ramij-Raja Hossain",
      "Jochen L. Cremer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.12908"
  },
  {
    "id": "arXiv:2110.13711",
    "title": "Hierarchical Transformers Are More Efficient Language Models",
    "abstract": "Hierarchical Transformers Are More Efficient Language Models",
    "descriptor": "",
    "authors": [
      "Piotr Nawrot",
      "Szymon Tworkowski",
      "Micha\u0142 Tyrolski",
      "\u0141ukasz Kaiser",
      "Yuhuai Wu",
      "Christian Szegedy",
      "Henryk Michalewski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13711"
  },
  {
    "id": "arXiv:2110.15442",
    "title": "Scalable Unidirectional Pareto Optimality for Multi-Task Learning with  Constraints",
    "abstract": "Scalable Unidirectional Pareto Optimality for Multi-Task Learning with  Constraints",
    "descriptor": "",
    "authors": [
      "Soumyajit Gupta",
      "Gurpreet Singh",
      "Raghu Bollapragada",
      "Matthew Lease"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15442"
  },
  {
    "id": "arXiv:2110.15547",
    "title": "Does Momentum Help? A Sample Complexity Analysis",
    "abstract": "Does Momentum Help? A Sample Complexity Analysis",
    "descriptor": "",
    "authors": [
      "Swetha Ganesh",
      "Rohan Deb",
      "Gugan Thoppe",
      "Amarjit Budhiraja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15547"
  },
  {
    "id": "arXiv:2110.15702",
    "title": "DeF-DReL: Systematic Deployment of Serverless Functions in Fog and Cloud  environments using Deep Reinforcement Learning",
    "abstract": "Comments: This preprint version is currently under-consideration to submit",
    "descriptor": "\nComments: This preprint version is currently under-consideration to submit\n",
    "authors": [
      "Chinmaya Kumar Dehury",
      "Shivananda Poojara",
      "Satish Narayana Srirama"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15702"
  },
  {
    "id": "arXiv:2111.01869",
    "title": "Towards Very Low-Cost Iterative Prototyping for Fully Printable  Dexterous Soft Robotic Hands",
    "abstract": "Towards Very Low-Cost Iterative Prototyping for Fully Printable  Dexterous Soft Robotic Hands",
    "descriptor": "",
    "authors": [
      "Dominik Bauer",
      "Cornelia Bauer",
      "Arjun Lakshmipathy",
      "Roberto Shu",
      "Nancy S. Pollard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.01869"
  },
  {
    "id": "arXiv:2111.03198",
    "title": "On the Complexity of Dynamic Submodular Maximization",
    "abstract": "On the Complexity of Dynamic Submodular Maximization",
    "descriptor": "",
    "authors": [
      "Xi Chen",
      "Binghui Peng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03198"
  },
  {
    "id": "arXiv:2111.04077",
    "title": "IOHexperimenter: Benchmarking Platform for Iterative Optimization  Heuristics",
    "abstract": "IOHexperimenter: Benchmarking Platform for Iterative Optimization  Heuristics",
    "descriptor": "",
    "authors": [
      "Jacob de Nobel",
      "Furong Ye",
      "Diederick Vermetten",
      "Hao Wang",
      "Carola Doerr",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.04077"
  },
  {
    "id": "arXiv:2111.07213",
    "title": "Numerical methods to evaluate Koopman matrix from system equations",
    "abstract": "Comments: 22 pages, 4 figures",
    "descriptor": "\nComments: 22 pages, 4 figures\n",
    "authors": [
      "Jun Ohkubo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2111.07213"
  },
  {
    "id": "arXiv:2111.09886",
    "title": "SimMIM: A Simple Framework for Masked Image Modeling",
    "abstract": "SimMIM: A Simple Framework for Masked Image Modeling",
    "descriptor": "",
    "authors": [
      "Zhenda Xie",
      "Zheng Zhang",
      "Yue Cao",
      "Yutong Lin",
      "Jianmin Bao",
      "Zhuliang Yao",
      "Qi Dai",
      "Han Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09886"
  },
  {
    "id": "arXiv:2111.10332",
    "title": "DSPoint: Dual-scale Point Cloud Recognition with High-frequency Fusion",
    "abstract": "DSPoint: Dual-scale Point Cloud Recognition with High-frequency Fusion",
    "descriptor": "",
    "authors": [
      "Renrui Zhang",
      "Ziyao Zeng",
      "Ziyu Guo",
      "Xinben Gao",
      "Kexue Fu",
      "Jianbo Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10332"
  },
  {
    "id": "arXiv:2111.11072",
    "title": "Algorithmizing the Multiplicity Schwartz-Zippel Lemma",
    "abstract": "Algorithmizing the Multiplicity Schwartz-Zippel Lemma",
    "descriptor": "",
    "authors": [
      "Siddharth Bhandari",
      "Prahladh Harsha",
      "Mrinal Kumar",
      "Ashutosh Shankar"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.11072"
  },
  {
    "id": "arXiv:2111.11562",
    "title": "Reliable Actors with Retry Orchestration",
    "abstract": "Comments: 25 pages, 6 figures",
    "descriptor": "\nComments: 25 pages, 6 figures\n",
    "authors": [
      "Olivier Tardieu",
      "David Grove",
      "Gheorghe-Teodor Bercea",
      "Paul Castro",
      "Jaroslaw Cwiklik",
      "Edward Epstein"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.11562"
  },
  {
    "id": "arXiv:2111.12009",
    "title": "LEGOStore: A Linearizable Geo-Distributed Store Combining Replication  and Erasure Coding",
    "abstract": "LEGOStore: A Linearizable Geo-Distributed Store Combining Replication  and Erasure Coding",
    "descriptor": "",
    "authors": [
      "Hamidreza Zare",
      "Viveck R. Cadambe",
      "Bhuvan Urgaonkar",
      "Chetan Sharma",
      "Praneet Soni",
      "Nader Alfares",
      "Arif Merchant"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2111.12009"
  },
  {
    "id": "arXiv:2111.12609",
    "title": "GreedyNASv2: Greedier Search with a Greedy Path Filter",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Tao Huang",
      "Shan You",
      "Fei Wang",
      "Chen Qian",
      "Changshui Zhang",
      "Xiaogang Wang",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12609"
  },
  {
    "id": "arXiv:2111.12681",
    "title": "VIOLET : End-to-End Video-Language Transformers with Masked Visual-token  Modeling",
    "abstract": "Comments: Code is available at this https URL",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Tsu-Jui Fu",
      "Linjie Li",
      "Zhe Gan",
      "Kevin Lin",
      "William Yang Wang",
      "Lijuan Wang",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12681"
  },
  {
    "id": "arXiv:2111.13656",
    "title": "Towards Low-Cost and Efficient Malaria Detection",
    "abstract": "Towards Low-Cost and Efficient Malaria Detection",
    "descriptor": "",
    "authors": [
      "Waqas Sultani",
      "Wajahat Nawaz",
      "Syed Javed",
      "Muhammad Sohail Danish",
      "Asma Saadia",
      "Mohsen Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13656"
  },
  {
    "id": "arXiv:2111.13827",
    "title": "Natural Language Processing in-and-for Design Research",
    "abstract": "Natural Language Processing in-and-for Design Research",
    "descriptor": "",
    "authors": [
      "L Siddharth",
      "Lucienne T. M. Blessing",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.13827"
  },
  {
    "id": "arXiv:2112.00246",
    "title": "AdaAfford: Learning to Adapt Manipulation Affordance for 3D Articulated  Objects via Few-shot Interactions",
    "abstract": "AdaAfford: Learning to Adapt Manipulation Affordance for 3D Articulated  Objects via Few-shot Interactions",
    "descriptor": "",
    "authors": [
      "Yian Wang",
      "Ruihai Wu",
      "Kaichun Mo",
      "Jiaqi Ke",
      "Qingnan Fan",
      "Leonidas Guibas",
      "Hao Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00246"
  },
  {
    "id": "arXiv:2112.00718",
    "title": "Improving GAN Equilibrium by Raising Spatial Awareness",
    "abstract": "Improving GAN Equilibrium by Raising Spatial Awareness",
    "descriptor": "",
    "authors": [
      "Jianyuan Wang",
      "Ceyuan Yang",
      "Yinghao Xu",
      "Yujun Shen",
      "Hongdong Li",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.00718"
  },
  {
    "id": "arXiv:2112.03123",
    "title": "An Upwind Generalized Finite Difference Method for Meshless Solution of  Two-phase Porous Flow Equations",
    "abstract": "An Upwind Generalized Finite Difference Method for Meshless Solution of  Two-phase Porous Flow Equations",
    "descriptor": "",
    "authors": [
      "Xiang Rao",
      "Yina Liu",
      "Hui Zhao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.03123"
  },
  {
    "id": "arXiv:2112.03534",
    "title": "Deep Surrogate Assisted MAP-Elites for Automated Hearthstone  Deckbuilding",
    "abstract": "Comments: Accepted to GECCO 2022",
    "descriptor": "\nComments: Accepted to GECCO 2022\n",
    "authors": [
      "Yulun Zhang",
      "Matthew C. Fontaine",
      "Amy K. Hoover",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.03534"
  },
  {
    "id": "arXiv:2112.04088",
    "title": "SASG: Sparsification with Adaptive Stochastic Gradients for  Communication-efficient Distributed Learning",
    "abstract": "Comments: 13 pages, 6 figures",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Xiaoge Deng",
      "Tao Sun",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.04088"
  },
  {
    "id": "arXiv:2112.04150",
    "title": "BA-Net: Bridge Attention for Deep Convolutional Neural Networks",
    "abstract": "BA-Net: Bridge Attention for Deep Convolutional Neural Networks",
    "descriptor": "",
    "authors": [
      "Yue Zhao",
      "Junzhou Chen",
      "Zirui Zhang",
      "Ronghui Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04150"
  },
  {
    "id": "arXiv:2112.04490",
    "title": "A novel multi-view deep learning approach for BI-RADS and density  assessment of mammograms",
    "abstract": "Comments: This paper has been accepted by the 44th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (2022 IEEE EMBC)",
    "descriptor": "\nComments: This paper has been accepted by the 44th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (2022 IEEE EMBC)\n",
    "authors": [
      "Huyen T. X. Nguyen",
      "Sam B. Tran",
      "Dung B. Nguyen",
      "Hieu H. Pham",
      "Ha Q. Nguyen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04490"
  },
  {
    "id": "arXiv:2112.05451",
    "title": "Structure-Preserving Learning Using Gaussian Processes and Variational  Integrators",
    "abstract": "Structure-Preserving Learning Using Gaussian Processes and Variational  Integrators",
    "descriptor": "",
    "authors": [
      "Jan Br\u00fcdigam",
      "Martin Schuck",
      "Alexandre Capone",
      "Stefan Sosnowski",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05451"
  },
  {
    "id": "arXiv:2112.06103",
    "title": "Improving Vision Transformers for Incremental Learning",
    "abstract": "Comments: Add experiments on CIFAR-100, comparison with DER",
    "descriptor": "\nComments: Add experiments on CIFAR-100, comparison with DER\n",
    "authors": [
      "Pei Yu",
      "Yinpeng Chen",
      "Ying Jin",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06103"
  },
  {
    "id": "arXiv:2112.06121",
    "title": "Magnifying Networks for Images with Billions of Pixels",
    "abstract": "Magnifying Networks for Images with Billions of Pixels",
    "descriptor": "",
    "authors": [
      "Neofytos Dimitriou",
      "Ognjen Arandjelovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06121"
  },
  {
    "id": "arXiv:2112.06342",
    "title": "Faster-Than-Native Alternatives for x86 VP2INTERSECT Instructions",
    "abstract": "Faster-Than-Native Alternatives for x86 VP2INTERSECT Instructions",
    "descriptor": "",
    "authors": [
      "Guille D\u00edez-Ca\u00f1as"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2112.06342"
  },
  {
    "id": "arXiv:2112.06363",
    "title": "Risk and optimal policies in bandit experiments",
    "abstract": "Risk and optimal policies in bandit experiments",
    "descriptor": "",
    "authors": [
      "Karun Adusumilli"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06363"
  },
  {
    "id": "arXiv:2112.06395",
    "title": "Consensus-Based Distributed Filtering with Fusion Step Analysis",
    "abstract": "Consensus-Based Distributed Filtering with Fusion Step Analysis",
    "descriptor": "",
    "authors": [
      "Jiachen Qian",
      "Peihu Duan",
      "Zhisheng Duan",
      "Guanrong Chen",
      "Ling Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.06395"
  },
  {
    "id": "arXiv:2112.06447",
    "title": "SVIP: Sequence VerIfication for Procedures in Videos",
    "abstract": "Comments: Accepted by CVPR2022. For the included dataset, see this https URL",
    "descriptor": "\nComments: Accepted by CVPR2022. For the included dataset, see this https URL\n",
    "authors": [
      "Yicheng Qian",
      "Weixin Luo",
      "Dongze Lian",
      "Xu Tang",
      "Peilin Zhao",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06447"
  },
  {
    "id": "arXiv:2112.07577",
    "title": "GPL: Generative Pseudo Labeling for Unsupervised Domain Adaptation of  Dense Retrieval",
    "abstract": "Comments: Accepted at NAACL 2022",
    "descriptor": "\nComments: Accepted at NAACL 2022\n",
    "authors": [
      "Kexin Wang",
      "Nandan Thakur",
      "Nils Reimers",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.07577"
  },
  {
    "id": "arXiv:2112.07820",
    "title": "Value Retrieval with Arbitrary Queries for Form-like Documents",
    "abstract": "Value Retrieval with Arbitrary Queries for Form-like Documents",
    "descriptor": "",
    "authors": [
      "Mingfei Gao",
      "Le Xue",
      "Chetan Ramaiah",
      "Chen Xing",
      "Ran Xu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07820"
  },
  {
    "id": "arXiv:2112.07868",
    "title": "Few-shot Instruction Prompts for Pretrained Language Models to Detect  Social Biases",
    "abstract": "Comments: Submission revised with new results",
    "descriptor": "\nComments: Submission revised with new results\n",
    "authors": [
      "Shrimai Prabhumoye",
      "Rafal Kocielnik",
      "Mohammad Shoeybi",
      "Anima Anandkumar",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07868"
  },
  {
    "id": "arXiv:2112.07917",
    "title": "SPTS: Single-Point Text Spotting",
    "abstract": "SPTS: Single-Point Text Spotting",
    "descriptor": "",
    "authors": [
      "Dezhi Peng",
      "Xinyu Wang",
      "Yuliang Liu",
      "Jiaxin Zhang",
      "Mingxin Huang",
      "Songxuan Lai",
      "Shenggao Zhu",
      "Jing Li",
      "Dahua Lin",
      "Chunhua Shen",
      "Lianwen Jin",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07917"
  },
  {
    "id": "arXiv:2112.08222",
    "title": "Guaranteed Nonlinear Tracking in the Presence of DNN-Learned Dynamics  With Contraction Metrics and Disturbance Estimation",
    "abstract": "Comments: Shorter version submitted to CDC 2022",
    "descriptor": "\nComments: Shorter version submitted to CDC 2022\n",
    "authors": [
      "Pan Zhao",
      "Ziyao Guo",
      "Yikun Cheng",
      "Aditya Gahlawat",
      "Hyungsoo Kang",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08222"
  },
  {
    "id": "arXiv:2112.08288",
    "title": "Improving both domain robustness and domain adaptability in machine  translation",
    "abstract": "Comments: update English-Chinese results",
    "descriptor": "\nComments: update English-Chinese results\n",
    "authors": [
      "Wen Lai",
      "Jind\u0159ich Libovick\u00fd",
      "Alexander Fraser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08288"
  },
  {
    "id": "arXiv:2112.09690",
    "title": "Cross-Model Pseudo-Labeling for Semi-Supervised Action Recognition",
    "abstract": "Comments: CVPR 2022 camera-ready, Project webpage: this https URL",
    "descriptor": "\nComments: CVPR 2022 camera-ready, Project webpage: this https URL\n",
    "authors": [
      "Yinghao Xu",
      "Fangyun Wei",
      "Xiao Sun",
      "Ceyuan Yang",
      "Yujun Shen",
      "Bo Dai",
      "Bolei Zhou",
      "Stephen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09690"
  },
  {
    "id": "arXiv:2112.09786",
    "title": "Distill and De-bias: Mitigating Bias in Face Verification using  Knowledge Distillation",
    "abstract": "Distill and De-bias: Mitigating Bias in Face Verification using  Knowledge Distillation",
    "descriptor": "",
    "authors": [
      "Prithviraj Dhar",
      "Joshua Gleason",
      "Aniket Roy",
      "Carlos D. Castillo",
      "P. Jonathon Phillips",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09786"
  },
  {
    "id": "arXiv:2112.10759",
    "title": "3D-aware Image Synthesis via Learning Structural and Textural  Representations",
    "abstract": "Comments: CVPR 2022 camera-ready, Project page: this https URL",
    "descriptor": "\nComments: CVPR 2022 camera-ready, Project page: this https URL\n",
    "authors": [
      "Yinghao Xu",
      "Sida Peng",
      "Ceyuan Yang",
      "Yujun Shen",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.10759"
  },
  {
    "id": "arXiv:2112.11377",
    "title": "Shape from Polarization for Complex Scenes in the Wild",
    "abstract": "Comments: Accepted to CVPR 2022; Github link: this https URL; Project website: this https URL",
    "descriptor": "\nComments: Accepted to CVPR 2022; Github link: this https URL; Project website: this https URL\n",
    "authors": [
      "Chenyang Lei",
      "Chenyang Qi",
      "Jiaxin Xie",
      "Na Fan",
      "Vladlen Koltun",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11377"
  },
  {
    "id": "arXiv:2201.00767",
    "title": "BDG-Net: Boundary Distribution Guided Network for Accurate Polyp  Segmentation",
    "abstract": "Comments: Accepted by SPIE Medical Imaging 2022",
    "descriptor": "\nComments: Accepted by SPIE Medical Imaging 2022\n",
    "authors": [
      "Zihuan Qiu",
      "Zhichuan Wang",
      "Miaomiao Zhang",
      "Ziyong Xu",
      "Jie Fan",
      "Linfeng Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.00767"
  },
  {
    "id": "arXiv:2201.01647",
    "title": "Relationship extraction for knowledge graph creation from biomedical  literature",
    "abstract": "Comments: Paper submitted to Journal of Semantic Web",
    "descriptor": "\nComments: Paper submitted to Journal of Semantic Web\n",
    "authors": [
      "Nikola Milosevic",
      "Wolfgang Thielemann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.01647"
  },
  {
    "id": "arXiv:2201.02489",
    "title": "Semantic-based Data Augmentation for Math Word Problems",
    "abstract": "Semantic-based Data Augmentation for Math Word Problems",
    "descriptor": "",
    "authors": [
      "Ailisi Li",
      "Jiaqing Liang",
      "Yanghua Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.02489"
  },
  {
    "id": "arXiv:2201.02772",
    "title": "A Comprehensive Empirical Study of Vision-Language Pre-trained Model for  Supervised Cross-Modal Retrieval",
    "abstract": "A Comprehensive Empirical Study of Vision-Language Pre-trained Model for  Supervised Cross-Modal Retrieval",
    "descriptor": "",
    "authors": [
      "Zhixiong Zeng",
      "Wenji Mao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2201.02772"
  },
  {
    "id": "arXiv:2201.04805",
    "title": "Non-Stationary Representation Learning in Sequential Linear Bandits",
    "abstract": "Comments: 24 pages, 7 figures",
    "descriptor": "\nComments: 24 pages, 7 figures\n",
    "authors": [
      "Yuzhen Qin",
      "Tommaso Menara",
      "Samet Oymak",
      "ShiNung Ching",
      "Fabio Pasqualetti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.04805"
  },
  {
    "id": "arXiv:2201.07423",
    "title": "Many Ways to Be Lonely: Fine-Grained Characterization of Loneliness and  Its Potential Changes in COVID-19",
    "abstract": "Many Ways to Be Lonely: Fine-Grained Characterization of Loneliness and  Its Potential Changes in COVID-19",
    "descriptor": "",
    "authors": [
      "Yueyi Jiang",
      "Yunfan Jiang",
      "Liu Leqi",
      "Piotr Winkielman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.07423"
  },
  {
    "id": "arXiv:2201.10168",
    "title": "Explore and Match: A New Paradigm for Temporal Video Grounding with  Natural Language",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Sangmin Woo",
      "Jinyoung Park",
      "Inyong Koo",
      "Sumin Lee",
      "Minki Jeong",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.10168"
  },
  {
    "id": "arXiv:2201.10734",
    "title": "CrossRectify: Leveraging Disagreement for Semi-supervised Object  Detection",
    "abstract": "CrossRectify: Leveraging Disagreement for Semi-supervised Object  Detection",
    "descriptor": "",
    "authors": [
      "Chengcheng Ma",
      "Xingjia Pan",
      "Qixiang Ye",
      "Fan Tang",
      "Weiming Dong",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.10734"
  },
  {
    "id": "arXiv:2201.10758",
    "title": "An Efficient Approximation Algorithm for the Colonel Blotto Game",
    "abstract": "An Efficient Approximation Algorithm for the Colonel Blotto Game",
    "descriptor": "",
    "authors": [
      "Daniel Beaglehole"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2201.10758"
  },
  {
    "id": "arXiv:2201.11006",
    "title": "An Overview of Compressible and Learnable Image Transformation with  Secret Key and Its Applications",
    "abstract": "An Overview of Compressible and Learnable Image Transformation with  Secret Key and Its Applications",
    "descriptor": "",
    "authors": [
      "Hitoshi Kiya",
      "AprilPyone MaungMaung",
      "Yuma Kinoshita",
      "Shoko Imaizumi",
      "Sayaka Shiota"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11006"
  },
  {
    "id": "arXiv:2201.11114",
    "title": "Natural Language Descriptions of Deep Visual Features",
    "abstract": "Comments: To be published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: To be published as a conference paper at ICLR 2022\n",
    "authors": [
      "Evan Hernandez",
      "Sarah Schwettmann",
      "David Bau",
      "Teona Bagashvili",
      "Antonio Torralba",
      "Jacob Andreas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11114"
  },
  {
    "id": "arXiv:2201.12014",
    "title": "Convergence of a continuous Galerkin method for mixed  hyperbolic-parabolic systems",
    "abstract": "Convergence of a continuous Galerkin method for mixed  hyperbolic-parabolic systems",
    "descriptor": "",
    "authors": [
      "Markus Bause",
      "Uwe K\u00f6cher",
      "Florin A. Radu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.12014"
  },
  {
    "id": "arXiv:2201.12129",
    "title": "Impact of Phase-Noise and Spatial Correlation on Double-RIS-Assisted  Multiuser MISO Networks",
    "abstract": "Impact of Phase-Noise and Spatial Correlation on Double-RIS-Assisted  Multiuser MISO Networks",
    "descriptor": "",
    "authors": [
      "Zaid Abdullah",
      "Anastasios Papazafeiropoulos",
      "Steven Kisseleff",
      "Symeon Chatzinotas",
      "Bjorn Ottersten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.12129"
  },
  {
    "id": "arXiv:2201.12450",
    "title": "Finding fault-tolerant Clifford circuits using satisfiability modulo  theories solvers and decoding merged color-surface codes",
    "abstract": "Comments: 24 pages, 9 figures",
    "descriptor": "\nComments: 24 pages, 9 figures\n",
    "authors": [
      "Noah Shutty",
      "Christopher Chamberland"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2201.12450"
  },
  {
    "id": "arXiv:2202.00076",
    "title": "Optimal Estimation of Off-Policy Policy Gradient via Double Fitted  Iteration",
    "abstract": "Optimal Estimation of Off-Policy Policy Gradient via Double Fitted  Iteration",
    "descriptor": "",
    "authors": [
      "Chengzhuo Ni",
      "Ruiqi Zhang",
      "Xiang Ji",
      "Xuezhou Zhang",
      "Mengdi Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00076"
  },
  {
    "id": "arXiv:2202.00630",
    "title": "Covid-19 vaccine hesitancy and mega-influencers",
    "abstract": "Covid-19 vaccine hesitancy and mega-influencers",
    "descriptor": "",
    "authors": [
      "Anna Haensch",
      "Natasa Dragovic",
      "Christoph B\u00f6rgers",
      "Bruce Boghosian"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2202.00630"
  },
  {
    "id": "arXiv:2202.02646",
    "title": "RerrFact: Reduced Evidence Retrieval Representations for Scientific  Claim Verification",
    "abstract": "Comments: Accepted in the AAAI-22 Workshop on Scientific Document Understanding at the Thirty-Sixth AAAI Conference on Artificial Intelligence (SDU@AAAI-22)",
    "descriptor": "\nComments: Accepted in the AAAI-22 Workshop on Scientific Document Understanding at the Thirty-Sixth AAAI Conference on Artificial Intelligence (SDU@AAAI-22)\n",
    "authors": [
      "Ashish Rana",
      "Deepanshu Khanna",
      "Tirthankar Ghosal",
      "Muskaan Singh",
      "Harpreet Singh",
      "Prashant Singh Rana"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02646"
  },
  {
    "id": "arXiv:2202.03851",
    "title": "MetaKG: Meta-learning on Knowledge Graph for Cold-start Recommendation",
    "abstract": "Comments: Accepted to TKDE2022",
    "descriptor": "\nComments: Accepted to TKDE2022\n",
    "authors": [
      "Yuntao Du",
      "Xinjun Zhu",
      "Lu Chen",
      "Ziquan Fang",
      "Yunjun Gao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03851"
  },
  {
    "id": "arXiv:2202.06012",
    "title": "Cloud-based computational model predictive control using a parallel  multi-block ADMM approach",
    "abstract": "Comments: Statements and experiments are flawed",
    "descriptor": "\nComments: Statements and experiments are flawed\n",
    "authors": [
      "Yaling Ma",
      "Runze Gao",
      "Li Dai",
      "Jinxian Wu",
      "Yuanqing Xia"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.06012"
  },
  {
    "id": "arXiv:2202.06172",
    "title": "Efficient Spatial Representation and Routing of Deformable  One-Dimensional Objects for Manipulation",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Azarakhsh Keipour",
      "Maryam Bandari",
      "Stefan Schaal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.06172"
  },
  {
    "id": "arXiv:2202.06602",
    "title": "Neural Re-ranking in Multi-stage Recommender Systems: A Review",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Weiwen Liu",
      "Yunjia Xi",
      "Jiarui Qin",
      "Fei Sun",
      "Bo Chen",
      "Weinan Zhang",
      "Rui Zhang",
      "Ruiming Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.06602"
  },
  {
    "id": "arXiv:2202.09899",
    "title": "Adomian Decomposition Based Numerical Scheme for Flow Simulations",
    "abstract": "Adomian Decomposition Based Numerical Scheme for Flow Simulations",
    "descriptor": "",
    "authors": [
      "Imanol Garcia-Beristain",
      "Lakhdar Remaki"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.09899"
  },
  {
    "id": "arXiv:2202.09971",
    "title": "Deep Feature based Cross-slide Registration",
    "abstract": "Deep Feature based Cross-slide Registration",
    "descriptor": "",
    "authors": [
      "Ruqayya Awan",
      "Shan E Ahmed Raza",
      "Johannes Lotz",
      "Nick Weiss",
      "Nasir M. Rajpoot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.09971"
  },
  {
    "id": "arXiv:2202.10617",
    "title": "An Ensemble Learning Framework for Vehicle Trajectory Prediction in  Interactive Scenarios",
    "abstract": "An Ensemble Learning Framework for Vehicle Trajectory Prediction in  Interactive Scenarios",
    "descriptor": "",
    "authors": [
      "Zirui Li",
      "Yunlong Lin",
      "Cheng Gong",
      "Xinwei Wang",
      "Qi Liu",
      "Jianwei Gong",
      "Chao Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.10617"
  },
  {
    "id": "arXiv:2202.12038",
    "title": "Construction of a bi-infinite power free word with a given factor and a  non-recurrent letter",
    "abstract": "Construction of a bi-infinite power free word with a given factor and a  non-recurrent letter",
    "descriptor": "",
    "authors": [
      "Josef Rukavicka"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.12038"
  },
  {
    "id": "arXiv:2202.12588",
    "title": "Active Learning for Point Cloud Semantic Segmentation via  Spatial-Structural Diversity Reasoning",
    "abstract": "Comments: 9 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 9 pages, 6 figures, 2 tables\n",
    "authors": [
      "Feifei Shao",
      "Yawei Luo",
      "Ping Liu",
      "Jie Chen",
      "Yi Yang",
      "Yulei Lu",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12588"
  },
  {
    "id": "arXiv:2202.13212",
    "title": "Faster One-Sample Stochastic Conditional Gradient Method for Composite  Convex Minimization",
    "abstract": "Comments: Artificial Intelligence and Statistics (AISTATS) 2022",
    "descriptor": "\nComments: Artificial Intelligence and Statistics (AISTATS) 2022\n",
    "authors": [
      "Gideon Dresdner",
      "Maria-Luiza Vladarean",
      "Gunnar R\u00e4tsch",
      "Francesco Locatello",
      "Volkan Cevher",
      "Alp Yurtsever"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.13212"
  },
  {
    "id": "arXiv:2202.13248",
    "title": "Automated Data Augmentations for Graph Classification",
    "abstract": "Automated Data Augmentations for Graph Classification",
    "descriptor": "",
    "authors": [
      "Youzhi Luo",
      "Michael McThrow",
      "Wing Yee Au",
      "Tao Komikado",
      "Kanji Uchino",
      "Koji Maruhashi",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.13248"
  },
  {
    "id": "arXiv:2202.13295",
    "title": "Efficient Attribute Unlearning: Towards Selective Removal of Input  Attributes from Feature Representations",
    "abstract": "Efficient Attribute Unlearning: Towards Selective Removal of Input  Attributes from Feature Representations",
    "descriptor": "",
    "authors": [
      "Tao Guo",
      "Song Guo",
      "Jiewei Zhang",
      "Wenchao Xu",
      "Junxiao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.13295"
  },
  {
    "id": "arXiv:2202.13687",
    "title": "AGMR-Net: Attention Guided Multiscale Recovery framework for stroke  segmentation",
    "abstract": "AGMR-Net: Attention Guided Multiscale Recovery framework for stroke  segmentation",
    "descriptor": "",
    "authors": [
      "Xiuquan Du",
      "Kunpeng Ma",
      "Yuhui Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.13687"
  },
  {
    "id": "arXiv:2202.13785",
    "title": "CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge  Graph Completion",
    "abstract": "Comments: The full version of a long paper accepted to ACL 2022 main conference",
    "descriptor": "\nComments: The full version of a long paper accepted to ACL 2022 main conference\n",
    "authors": [
      "Guanglin Niu",
      "Bo Li",
      "Yongfei Zhang",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.13785"
  },
  {
    "id": "arXiv:2203.00156",
    "title": "Preemptive Motion Planning for Human-to-Robot Indirect Placement  Handovers",
    "abstract": "Comments: 6 pages, 6 figures, to appear in ICRA 2022",
    "descriptor": "\nComments: 6 pages, 6 figures, to appear in ICRA 2022\n",
    "authors": [
      "Andrew Choi",
      "Mohammad Khalid Jawed",
      "Jungseock Joo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.00156"
  },
  {
    "id": "arXiv:2203.00157",
    "title": "Simultaneous Semantic and Instance Segmentation for Colon Nuclei  Identification and Counting",
    "abstract": "Comments: 9 pages; 4 figures",
    "descriptor": "\nComments: 9 pages; 4 figures\n",
    "authors": [
      "Lihao Liu",
      "Chenyang Hong",
      "Angelica I. Aviles-Rivero",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.00157"
  },
  {
    "id": "arXiv:2203.00449",
    "title": "Deep Learning based Prediction of MSI using MMR Markers in Colorectal  Cancer",
    "abstract": "Deep Learning based Prediction of MSI using MMR Markers in Colorectal  Cancer",
    "descriptor": "",
    "authors": [
      "Ruqayya Awan",
      "Mohammed Nimir",
      "Shan E Ahmed Raza",
      "Mohsin Bilal",
      "Johannes Lotz",
      "David Snead",
      "Andrew Robinson",
      "Nasir M. Rajpoot"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.00449"
  },
  {
    "id": "arXiv:2203.00953",
    "title": "Computationally Efficient and Statistically Optimal Robust Low-rank  Matrix Estimation",
    "abstract": "Computationally Efficient and Statistically Optimal Robust Low-rank  Matrix Estimation",
    "descriptor": "",
    "authors": [
      "Yinan Shen",
      "Jingyang Li",
      "Jian-Feng Cai",
      "Dong Xia"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.00953"
  },
  {
    "id": "arXiv:2203.03216",
    "title": "USTC-NELSLIP at SemEval-2022 Task 11: Gazetteer-Adapted Integration  Network for Multilingual Complex Named Entity Recognition",
    "abstract": "Comments: Winner system (USTC-NELSLIP) of SemEval 2022 MultiCoNER shared task on 3 tracks (Chinese, Bangla, Code-mixed)",
    "descriptor": "\nComments: Winner system (USTC-NELSLIP) of SemEval 2022 MultiCoNER shared task on 3 tracks (Chinese, Bangla, Code-mixed)\n",
    "authors": [
      "Beiduo Chen",
      "Jun-Yu Ma",
      "Jiajun Qi",
      "Wu Guo",
      "Zhen-Hua Ling",
      "Quan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.03216"
  },
  {
    "id": "arXiv:2203.03312",
    "title": "SkillNet: A Sparsely Activated Model for General-Purpose Natural  Language Understanding",
    "abstract": "SkillNet: A Sparsely Activated Model for General-Purpose Natural  Language Understanding",
    "descriptor": "",
    "authors": [
      "Duyu Tang",
      "Fan Zhang",
      "Yong Dai",
      "Cong Zhou",
      "Shuangzhi Wu",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03312"
  },
  {
    "id": "arXiv:2203.04741",
    "title": "Modeling and Validating Temporal Rules with Semantic Petri-Net for  Digital Twins",
    "abstract": "Comments: Preprint submitted to 29th International Workshop on Intelligent Computing in Engineering (EG-ICE)",
    "descriptor": "\nComments: Preprint submitted to 29th International Workshop on Intelligent Computing in Engineering (EG-ICE)\n",
    "authors": [
      "Han Liu",
      "Xiaoyu Song",
      "Ge Gao",
      "Hehua Zhang",
      "Yu-Shen Liu",
      "Ming Gu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.04741"
  },
  {
    "id": "arXiv:2203.04961",
    "title": "Sharing Generative Models Instead of Private Data: A Simulation Study on  Mammography Patch Classification",
    "abstract": "Comments: Draft accepted as oral presentation at International Workshop on Breast Imaging (IWBI) 2022. 9 pages, 3 figures",
    "descriptor": "\nComments: Draft accepted as oral presentation at International Workshop on Breast Imaging (IWBI) 2022. 9 pages, 3 figures\n",
    "authors": [
      "Zuzanna Szafranowska",
      "Richard Osuala",
      "Bennet Breier",
      "Kaisar Kushibar",
      "Karim Lekadir",
      "Oliver Diaz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04961"
  },
  {
    "id": "arXiv:2203.05983",
    "title": "PseudoProp: Robust Pseudo-Label Generation for Semi-Supervised Object  Detection in Autonomous Driving Systems",
    "abstract": "Comments: Accepted by the Workshop on Autonomous Driving (WAD) at CVPR 2022",
    "descriptor": "\nComments: Accepted by the Workshop on Autonomous Driving (WAD) at CVPR 2022\n",
    "authors": [
      "Shu Hu",
      "Chun-Hao Liu",
      "Jayanta Dutta",
      "Ming-Ching Chang",
      "Siwei Lyu",
      "Naveen Ramakrishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05983"
  },
  {
    "id": "arXiv:2203.06063",
    "title": "Active Evaluation: Efficient NLG Evaluation with Few Pairwise  Comparisons",
    "abstract": "Comments: Accepted at ACL 2022; 21 pages and 12 figures",
    "descriptor": "\nComments: Accepted at ACL 2022; 21 pages and 12 figures\n",
    "authors": [
      "Akash Kumar Mohankumar",
      "Mitesh M. Khapra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06063"
  },
  {
    "id": "arXiv:2203.06498",
    "title": "The worst of both worlds: A comparative analysis of errors in learning  from data in psychology and machine learning",
    "abstract": "The worst of both worlds: A comparative analysis of errors in learning  from data in psychology and machine learning",
    "descriptor": "",
    "authors": [
      "Jessica Hullman",
      "Sayash Kapoor",
      "Priyanka Nanayakkara",
      "Andrew Gelman",
      "Arvind Narayanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06498"
  },
  {
    "id": "arXiv:2203.06951",
    "title": "Computer Vision and Deep Learning for Fish Classification in Underwater  Habitats: A Survey",
    "abstract": "Comments: Published Online \\c{opyright} 2022 The Authors. Fish and Fisheries published by John Wiley & Sons Ltd",
    "descriptor": "\nComments: Published Online \\c{opyright} 2022 The Authors. Fish and Fisheries published by John Wiley & Sons Ltd\n",
    "authors": [
      "Alzayat Saleh",
      "Marcus Sheaves",
      "Mostafa Rahimi Azghadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06951"
  },
  {
    "id": "arXiv:2203.09227",
    "title": "Non-Elitist Selection among Survivor Configurations can Improve the  Performance of Irace",
    "abstract": "Comments: submitted to GECCO 2022",
    "descriptor": "\nComments: submitted to GECCO 2022\n",
    "authors": [
      "Furong Ye",
      "Diederick L. Vermetten",
      "Carola Doerr",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.09227"
  },
  {
    "id": "arXiv:2203.09228",
    "title": "Re-shaping Post-COVID-19 Teaching and Learning: A Blueprint of  Virtual-Physical Blended Classrooms in the Metaverse Era",
    "abstract": "Comments: 6 pages, 3 figures, accepted in conference SocialMeta2022",
    "descriptor": "\nComments: 6 pages, 3 figures, accepted in conference SocialMeta2022\n",
    "authors": [
      "Yuyang Wang",
      "Lik-Hang Lee",
      "Tristan Braud",
      "Pan Hui"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.09228"
  },
  {
    "id": "arXiv:2203.09420",
    "title": "Deep Unsupervised Hashing with Latent Semantic Components",
    "abstract": "Comments: 9 pages, 15 figures",
    "descriptor": "\nComments: 9 pages, 15 figures\n",
    "authors": [
      "Qinghong Lin",
      "Xiaojun Chen",
      "Qin Zhang",
      "Shaotian Cai",
      "Wenzhe Zhao",
      "Hongfa Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09420"
  },
  {
    "id": "arXiv:2203.11947",
    "title": "CM-GAN: Image Inpainting with Cascaded Modulation GAN and Object-Aware  Training",
    "abstract": "Comments: 32 pages, 18 figures",
    "descriptor": "\nComments: 32 pages, 18 figures\n",
    "authors": [
      "Haitian Zheng",
      "Zhe Lin",
      "Jingwan Lu",
      "Scott Cohen",
      "Eli Shechtman",
      "Connelly Barnes",
      "Jianming Zhang",
      "Ning Xu",
      "Sohrab Amirghodsi",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11947"
  },
  {
    "id": "arXiv:2203.12112",
    "title": "Lymphocyte Classification in Hyperspectral Images of Ovarian Cancer  Tissue Biopsy Samples",
    "abstract": "Comments: There are significant gaps in our discussion of hardware and data sources. Our collaborators are publishing a separate work that acknowledges these factors, and our work is misleading without this context. We will need to withdraw this document and incorporate these findings into future work that appropriately references our collaborators' research",
    "descriptor": "\nComments: There are significant gaps in our discussion of hardware and data sources. Our collaborators are publishing a separate work that acknowledges these factors, and our work is misleading without this context. We will need to withdraw this document and incorporate these findings into future work that appropriately references our collaborators' research\n",
    "authors": [
      "Benjamin Paulson",
      "Theodore Colwell",
      "Natalia Bukowski",
      "Joseph Weller",
      "Andrew Crisler",
      "John Cisler",
      "Alexander Drobek",
      "Alexander Neuwirth"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12112"
  },
  {
    "id": "arXiv:2203.12135",
    "title": "ALT: um software para an\u00e1lise de legibilidade de textos em L\u00edngua  Portuguesa",
    "abstract": "Comments: 22 pages, 13 figures, in Portuguese, see software in this https URL",
    "descriptor": "\nComments: 22 pages, 13 figures, in Portuguese, see software in this https URL\n",
    "authors": [
      "Gleice Carvalho de Lima Moreno",
      "Marco P. M. de Souza",
      "Nelson Hein",
      "Adriana Kroenke Hein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.12135"
  },
  {
    "id": "arXiv:2203.12367",
    "title": "Transformer-based Multimodal Information Fusion for Facial Expression  Analysis",
    "abstract": "Transformer-based Multimodal Information Fusion for Facial Expression  Analysis",
    "descriptor": "",
    "authors": [
      "Wei Zhang",
      "Feng Qiu",
      "Suzhen Wang",
      "Hao Zeng",
      "Zhimeng Zhang",
      "Rudong An",
      "Bowen Ma",
      "Yu Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12367"
  },
  {
    "id": "arXiv:2203.13254",
    "title": "EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for  Monocular Object Pose Estimation",
    "abstract": "Comments: CVPR 2022 Oral, code available at this https URL V3 notes: correct Fig 8 and a few expressions",
    "descriptor": "\nComments: CVPR 2022 Oral, code available at this https URL V3 notes: correct Fig 8 and a few expressions\n",
    "authors": [
      "Hansheng Chen",
      "Pichao Wang",
      "Fan Wang",
      "Wei Tian",
      "Lu Xiong",
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13254"
  },
  {
    "id": "arXiv:2203.14803",
    "title": "MixNN: A design for protecting deep learning models",
    "abstract": "MixNN: A design for protecting deep learning models",
    "descriptor": "",
    "authors": [
      "Chao Liu",
      "Hao Chen",
      "Yusen Wu",
      "Rui Jin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.14803"
  },
  {
    "id": "arXiv:2203.15275",
    "title": "A Multi-size Kernel based Adaptive Convolutional Neural Network for  Bearing Fault Diagnosis",
    "abstract": "Comments: 21 pages, 16 figures",
    "descriptor": "\nComments: 21 pages, 16 figures\n",
    "authors": [
      "Guangwei Yu",
      "Gang Li",
      "Xingtong Si",
      "Zhuoyuan Song"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15275"
  },
  {
    "id": "arXiv:2203.16028",
    "title": "Span Classification with Structured Information for Disfluency Detection  in Spoken Utterances",
    "abstract": "Span Classification with Structured Information for Disfluency Detection  in Spoken Utterances",
    "descriptor": "",
    "authors": [
      "Sreyan Ghosh",
      "Sonal Kumar",
      "Yaman Kumar Singla",
      "Rajiv Ratn Shah",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16028"
  },
  {
    "id": "arXiv:2203.16217",
    "title": "Improved Convergence Rate of Stochastic Gradient Langevin Dynamics with  Variance Reduction and its Application to Optimization",
    "abstract": "Improved Convergence Rate of Stochastic Gradient Langevin Dynamics with  Variance Reduction and its Application to Optimization",
    "descriptor": "",
    "authors": [
      "Yuri Kinoshita",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.16217"
  },
  {
    "id": "arXiv:2203.16318",
    "title": "Near-Field Communications for 6G: Fundamentals, Challenges, Potentials,  and Future Directions",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Mingyao Cui",
      "Zidong Wu",
      "Yu Lu",
      "Xiuhong Wei",
      "Linglong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16318"
  },
  {
    "id": "arXiv:2203.16908",
    "title": "Suffix tree-based linear algorithms for multiple prefixes, single suffix  counting and listing problems",
    "abstract": "Comments: 16 pages, 5 figures",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Laurentius Leonard",
      "Ken Tanaka"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.16908"
  },
  {
    "id": "arXiv:2204.00861",
    "title": "A Differential Evolution-Enhanced Latent Factor Analysis Model for  High-dimensional and Sparse Data",
    "abstract": "A Differential Evolution-Enhanced Latent Factor Analysis Model for  High-dimensional and Sparse Data",
    "descriptor": "",
    "authors": [
      "Jia Chen",
      "Di Wu",
      "Xin Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.00861"
  },
  {
    "id": "arXiv:2204.01057",
    "title": "Learning-Based Approaches for Graph Problems: A Survey",
    "abstract": "Comments: v1: 41 pages; v2: 40 pages",
    "descriptor": "\nComments: v1: 41 pages; v2: 40 pages\n",
    "authors": [
      "Kai Siong Yow",
      "Siqiang Luo"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01057"
  },
  {
    "id": "arXiv:2204.02011",
    "title": "ELECRec: Training Sequential Recommenders as Discriminators",
    "abstract": "Comments: Accepted to SIGIR 2022",
    "descriptor": "\nComments: Accepted to SIGIR 2022\n",
    "authors": [
      "Yongjun Chen",
      "Jia Li",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02011"
  },
  {
    "id": "arXiv:2204.02284",
    "title": "Free gs-monoidal categories and free Markov categories",
    "abstract": "Comments: 35 pages. v2: references updated",
    "descriptor": "\nComments: 35 pages. v2: references updated\n",
    "authors": [
      "Tobias Fritz",
      "Wendong Liang"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2204.02284"
  },
  {
    "id": "arXiv:2204.02441",
    "title": "Imaging Conductivity from Current Density Magnitude using Neural  Networks",
    "abstract": "Comments: 29 pp, 9 figures (several typos are corrected in the new version)",
    "descriptor": "\nComments: 29 pp, 9 figures (several typos are corrected in the new version)\n",
    "authors": [
      "Bangti Jin",
      "Xiyao Li",
      "Xiliang Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.02441"
  },
  {
    "id": "arXiv:2204.02506",
    "title": "Deep Graphic FBSDEs for Opinion Dynamics Stochastic Control",
    "abstract": "Deep Graphic FBSDEs for Opinion Dynamics Stochastic Control",
    "descriptor": "",
    "authors": [
      "Tianrong Chen",
      "Ziyi Wang",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02506"
  },
  {
    "id": "arXiv:2204.02574",
    "title": "FocalClick: Towards Practical Interactive Image Segmentation",
    "abstract": "Comments: CVPR2022",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Xi Chen",
      "Zhiyan Zhao",
      "Yilei Zhang",
      "Manni Duan",
      "Donglian Qi",
      "Hengshuang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02574"
  },
  {
    "id": "arXiv:2204.02670",
    "title": "MDS and AMDS symbol-pair codes are constructed from repeated-root codes",
    "abstract": "Comments: 27 pages. arXiv admin note: text overlap with arXiv:2010.04329 by other authors",
    "descriptor": "\nComments: 27 pages. arXiv admin note: text overlap with arXiv:2010.04329 by other authors\n",
    "authors": [
      "Xiuxin Tang",
      "Rong Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.02670"
  },
  {
    "id": "arXiv:2204.02824",
    "title": "ShowFace: Coordinated Face Inpainting with Memory-Disentangled  Refinement Networks",
    "abstract": "ShowFace: Coordinated Face Inpainting with Memory-Disentangled  Refinement Networks",
    "descriptor": "",
    "authors": [
      "Zhuojie Wu",
      "Xingqun Qi",
      "Zijian Wang",
      "Wanting Zhou",
      "Kun Yuan",
      "Muyi Sun",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02824"
  },
  {
    "id": "arXiv:2204.03163",
    "title": "Low-Dose CT Denoising via Sinogram Inner-Structure Transformer",
    "abstract": "Low-Dose CT Denoising via Sinogram Inner-Structure Transformer",
    "descriptor": "",
    "authors": [
      "Liutao Yang",
      "Zhongnian Li",
      "Rongjun Ge",
      "Junyong Zhao",
      "Haipeng Si",
      "Daoqiang Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03163"
  },
  {
    "id": "arXiv:2204.03355",
    "title": "Event Transformer. A sparse-aware solution for efficient event data  processing",
    "abstract": "Event Transformer. A sparse-aware solution for efficient event data  processing",
    "descriptor": "",
    "authors": [
      "Alberto Sabater",
      "Luis Montesano",
      "Ana C. Murillo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03355"
  },
  {
    "id": "arXiv:2204.03364",
    "title": "A Framework for Distributed Estimation with Reduced Communication via  Event-Based Strategies",
    "abstract": "A Framework for Distributed Estimation with Reduced Communication via  Event-Based Strategies",
    "descriptor": "",
    "authors": [
      "Jiaqi Yan",
      "Yilin Mo",
      "Hideaki Ishii"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03364"
  },
  {
    "id": "arXiv:2204.03433",
    "title": "Machine Learning-Enabled IoT Security: Open Issues and Challenges Under  Advanced Persistent Threats",
    "abstract": "Comments: ACM Computing Surveys, 2022, 35 pages, 10 Figures, 8 Tables",
    "descriptor": "\nComments: ACM Computing Surveys, 2022, 35 pages, 10 Figures, 8 Tables\n",
    "authors": [
      "Zhiyan Chen",
      "Jinxin Liu",
      "Yu Shen",
      "Murat Simsek",
      "Burak Kantarci",
      "Hussein T. Mouftah",
      "Petar Djukic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.03433"
  },
  {
    "id": "arXiv:2204.03597",
    "title": "Imitating, Fast and Slow: Robust learning from demonstrations via  decision-time planning",
    "abstract": "Imitating, Fast and Slow: Robust learning from demonstrations via  decision-time planning",
    "descriptor": "",
    "authors": [
      "Carl Qi",
      "Pieter Abbeel",
      "Aditya Grover"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03597"
  },
  {
    "id": "arXiv:2204.03789",
    "title": "Broadening AI Ethics Narratives: An Indic Art View",
    "abstract": "Broadening AI Ethics Narratives: An Indic Art View",
    "descriptor": "",
    "authors": [
      "Ajay Divakaran",
      "Aparna Sridhar",
      "Ramya Srinivasan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.03789"
  },
  {
    "id": "arXiv:2204.03790",
    "title": "High-Dimensional Geometric Streaming in Polynomial Space",
    "abstract": "Comments: Abstract shortened to meet arXiv limits; v2 fix statements concerning online condition number",
    "descriptor": "\nComments: Abstract shortened to meet arXiv limits; v2 fix statements concerning online condition number\n",
    "authors": [
      "David P. Woodruff",
      "Taisuke Yasuda"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2204.03790"
  },
  {
    "id": "arXiv:2204.04216",
    "title": "Learning Trajectory-Aware Transformer for Video Super-Resolution",
    "abstract": "Comments: CVPR 2022 Oral",
    "descriptor": "\nComments: CVPR 2022 Oral\n",
    "authors": [
      "Chengxu Liu",
      "Huan Yang",
      "Jianlong Fu",
      "Xueming Qian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04216"
  },
  {
    "id": "arXiv:2204.04392",
    "title": "Contrastive Demonstration Tuning for Pre-trained Language Models",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Xiaozhuan Liang",
      "Ningyu Zhang",
      "Siyuan Cheng",
      "Zhen Bi",
      "Zhenru Zhang",
      "Chuanqi Tan",
      "Songfang Huang",
      "Fei Huang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04392"
  },
  {
    "id": "arXiv:2204.04812",
    "title": "OutfitTransformer: Learning Outfit Representations for Fashion  Recommendation",
    "abstract": "OutfitTransformer: Learning Outfit Representations for Fashion  Recommendation",
    "descriptor": "",
    "authors": [
      "Rohan Sarkar",
      "Navaneeth Bodla",
      "Mariya I. Vasileva",
      "Yen-Liang Lin",
      "Anurag Beniwal",
      "Alan Lu",
      "Gerard Medioni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04812"
  },
  {
    "id": "arXiv:2204.04902",
    "title": "NeuS: Neutral Multi-News Summarization for Mitigating Framing Bias",
    "abstract": "Comments: NAACL2022 Long Paper",
    "descriptor": "\nComments: NAACL2022 Long Paper\n",
    "authors": [
      "Nayeon Lee",
      "Yejin Bang",
      "Tiezheng Yu",
      "Andrea Madotto",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04902"
  },
  {
    "id": "arXiv:2204.04903",
    "title": "PICASSO: Unleashing the Potential of GPU-centric Training for  Wide-and-deep Recommender Systems",
    "abstract": "PICASSO: Unleashing the Potential of GPU-centric Training for  Wide-and-deep Recommender Systems",
    "descriptor": "",
    "authors": [
      "Yuanxing Zhang",
      "Langshi Chen",
      "Siran Yang",
      "Man Yuan",
      "Huimin Yi",
      "Jie Zhang",
      "Jiamang Wang",
      "Jianbo Dong",
      "Yunlong Xu",
      "Yue Song",
      "Yong Li",
      "Di Zhang",
      "Wei Lin",
      "Lin Qu",
      "Bo Zheng"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.04903"
  },
  {
    "id": "arXiv:2204.04952",
    "title": "MGIMN: Multi-Grained Interactive Matching Network for Few-shot Text  Classification",
    "abstract": "Comments: 10 pages, 2 figures, 6 tabels",
    "descriptor": "\nComments: 10 pages, 2 figures, 6 tabels\n",
    "authors": [
      "Jianhai Zhang",
      "Mieradilijiang Maimaiti",
      "Xing Gao",
      "Yuanhang Zheng",
      "Ji Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04952"
  },
  {
    "id": "arXiv:2204.05205",
    "title": "Rethinking Machine Learning Model Evaluation in Pathology",
    "abstract": "Comments: ICLR 2022 ML Evaluation Workshop",
    "descriptor": "\nComments: ICLR 2022 ML Evaluation Workshop\n",
    "authors": [
      "Syed Ashar Javed",
      "Dinkar Juyal",
      "Zahil Shanis",
      "Shreya Chakraborty",
      "Harsha Pokkalla",
      "Aaditya Prakash"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05205"
  },
  {
    "id": "arXiv:2204.05376",
    "title": "medXGAN: Visual Explanations for Medical Classifiers through a  Generative Latent Space",
    "abstract": "Comments: 10 pages, 11 figures, accepted to CVPR TCV workshop",
    "descriptor": "\nComments: 10 pages, 11 figures, accepted to CVPR TCV workshop\n",
    "authors": [
      "Amil Dravid",
      "Florian Schiffers",
      "Boqing Gong",
      "Aggelos K. Katsaggelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05376"
  },
  {
    "id": "arXiv:2204.05423",
    "title": "Automated Task Updates of Temporal Logic Specifications for  Heterogeneous Robots",
    "abstract": "Comments: Accepted by IEEE International Conference on Robotics and Automation (ICRA) 2022",
    "descriptor": "\nComments: Accepted by IEEE International Conference on Robotics and Automation (ICRA) 2022\n",
    "authors": [
      "Amy Fang",
      "Hadas Kress-Gazit"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.05423"
  },
  {
    "id": "arXiv:2204.05544",
    "title": "Delving Deep into Regularity: A Simple but Effective Method for Chinese  Named Entity Recognition",
    "abstract": "Comments: Accepted at NAACL 2022 Findings",
    "descriptor": "\nComments: Accepted at NAACL 2022 Findings\n",
    "authors": [
      "Yingjie Gu",
      "Xiaoye Qu",
      "Zhefeng Wang",
      "Yi Zheng",
      "Baoxing Huai",
      "Nicholas Jing Yuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05544"
  },
  {
    "id": "arXiv:2204.05696",
    "title": "Positive definite functions on a regular domain",
    "abstract": "Positive definite functions on a regular domain",
    "descriptor": "",
    "authors": [
      "Martin Buhmann",
      "Yuan Xu"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.05696"
  },
  {
    "id": "arXiv:2204.05841",
    "title": "VoiceFixer: A Unified Framework for High-Fidelity Speech Restoration",
    "abstract": "Comments: Submitted to INTERSPEECH 2022",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Haohe Liu",
      "Xubo Liu",
      "Qiuqiang Kong",
      "Qiao Tian",
      "Yan Zhao",
      "DeLiang Wang",
      "Chuanzeng Huang",
      "Yuxuan Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.05841"
  },
  {
    "id": "arXiv:2204.05999",
    "title": "InCoder: A Generative Model for Code Infilling and Synthesis",
    "abstract": "Comments: 25 pages, 13 figures. v2: added NeoX-20B results & StackOverflow corpus info",
    "descriptor": "\nComments: 25 pages, 13 figures. v2: added NeoX-20B results & StackOverflow corpus info\n",
    "authors": [
      "Daniel Fried",
      "Armen Aghajanyan",
      "Jessy Lin",
      "Sida Wang",
      "Eric Wallace",
      "Freda Shi",
      "Ruiqi Zhong",
      "Wen-tau Yih",
      "Luke Zettlemoyer",
      "Mike Lewis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05999"
  },
  {
    "id": "arXiv:2204.06104",
    "title": "A Tutorial on Solution Properties of State Space Models of Dynamical  Systems",
    "abstract": "A Tutorial on Solution Properties of State Space Models of Dynamical  Systems",
    "descriptor": "",
    "authors": [
      "Bassam Bamieh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Functional Analysis (math.FA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.06104"
  },
  {
    "id": "arXiv:2204.06353",
    "title": "AHP: Learning to Negative Sample for Hyperedge Prediction",
    "abstract": "Comments: To be published in the Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2022)",
    "descriptor": "\nComments: To be published in the Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2022)\n",
    "authors": [
      "Hyunjin Hwang",
      "Seungwoo Lee",
      "Chanyoung Park",
      "Kijung Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.06353"
  },
  {
    "id": "arXiv:2204.06498",
    "title": "SpoofGAN: Synthetic Fingerprint Spoof Images",
    "abstract": "SpoofGAN: Synthetic Fingerprint Spoof Images",
    "descriptor": "",
    "authors": [
      "Steven A. Grosz",
      "Anil K. Jain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.06498"
  },
  {
    "id": "arXiv:2204.06625",
    "title": "CAMERO: Consistency Regularized Ensemble of Perturbed Language Models  with Weight Sharing",
    "abstract": "Comments: Proceedings of ACL 2022",
    "descriptor": "\nComments: Proceedings of ACL 2022\n",
    "authors": [
      "Chen Liang",
      "Pengcheng He",
      "Yelong Shen",
      "Weizhu Chen",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.06625"
  },
  {
    "id": "arXiv:2204.06644",
    "title": "METRO: Efficient Denoising Pretraining of Large Scale Autoencoding  Language Models with Model Generated Signals",
    "abstract": "Comments: Update details in scaled initialization and add acknowledgement",
    "descriptor": "\nComments: Update details in scaled initialization and add acknowledgement\n",
    "authors": [
      "Payal Bajaj",
      "Chenyan Xiong",
      "Guolin Ke",
      "Xiaodong Liu",
      "Di He",
      "Saurabh Tiwary",
      "Tie-Yan Liu",
      "Paul Bennett",
      "Xia Song",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.06644"
  },
  {
    "id": "arXiv:2204.06790",
    "title": "An Exploratory Study of Attestation Mechanisms for Trusted Execution  Environments",
    "abstract": "Comments: This publication incorporates results from the VEDLIoT project, which received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 957197",
    "descriptor": "\nComments: This publication incorporates results from the VEDLIoT project, which received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 957197\n",
    "authors": [
      "J\u00e4mes M\u00e9n\u00e9trey",
      "Christian G\u00f6ttel",
      "Marcelo Pasin",
      "Pascal Felber",
      "Valerio Schiavoni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.06790"
  },
  {
    "id": "arXiv:2204.06831",
    "title": "Double spending prevention of digital Euros using a web-of-trust",
    "abstract": "Double spending prevention of digital Euros using a web-of-trust",
    "descriptor": "",
    "authors": [
      "Atanas Marinov",
      "Jurriaan Den Toonder",
      "Joep de Jong",
      "Pieter Tolsma",
      "Nils van den Honert",
      "Johan Pouwelse"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.06831"
  },
  {
    "id": "arXiv:2204.06938",
    "title": "Flowing the Information from Shannon to Fisher: Towards the Fundamental  Tradeoff in ISAC",
    "abstract": "Comments: 3 figures, 7 pages, submitted to IEEE Globecom 2022",
    "descriptor": "\nComments: 3 figures, 7 pages, submitted to IEEE Globecom 2022\n",
    "authors": [
      "Yifeng Xiong",
      "Fan Liu",
      "Yuanhao Cui",
      "Weijie Yuan",
      "Tony Xiao Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.06938"
  },
  {
    "id": "arXiv:2204.07050",
    "title": "Recent Advances and New Frontiers in Spiking Neural Networks",
    "abstract": "Comments: Accepted at IJCAI2022",
    "descriptor": "\nComments: Accepted at IJCAI2022\n",
    "authors": [
      "Duzhen Zhang",
      "Tielin Zhang",
      "Shuncheng Jia",
      "Qingyu Wang",
      "Bo Xu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07050"
  },
  {
    "id": "arXiv:2204.07121",
    "title": "Facing the Illusion and Reality of Safety in Social VR",
    "abstract": "Comments: (CHI'EA' 2022) In CHI Conference on Human Factors in Computing Systems, Proceedings of the 1st Workshop on Novel Challenges of Safety, Security and Privacy in Extended Reality",
    "descriptor": "\nComments: (CHI'EA' 2022) In CHI Conference on Human Factors in Computing Systems, Proceedings of the 1st Workshop on Novel Challenges of Safety, Security and Privacy in Extended Reality\n",
    "authors": [
      "Qingxiao Zheng",
      "Tue Ngoc Do",
      "Lingqing Wang",
      "Yun Huang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.07121"
  },
  {
    "id": "arXiv:2204.07129",
    "title": "On The Complexity of Matching Cut for Graphs of Bounded Radius and  $H$-Free Graphs",
    "abstract": "On The Complexity of Matching Cut for Graphs of Bounded Radius and  $H$-Free Graphs",
    "descriptor": "",
    "authors": [
      "Felicia Lucke",
      "Dani\u00ebl Paulusma",
      "Bernard Ries"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.07129"
  },
  {
    "id": "arXiv:2204.07439",
    "title": "INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold",
    "abstract": "Comments: 19 pages, 7 figures; excluded axessibility package",
    "descriptor": "\nComments: 19 pages, 7 figures; excluded axessibility package\n",
    "authors": [
      "Changhun Lee",
      "Hyungjun Kim",
      "Eunhyeok Park",
      "Jae-Joon Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07439"
  }
]
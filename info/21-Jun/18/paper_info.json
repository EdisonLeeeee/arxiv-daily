[
  {
    "id": "arXiv:2106.09021",
    "title": "On the training of sparse and dense deep neural networks: less  parameters, same performance",
    "abstract": "Deep neural networks can be trained in reciprocal space, by acting on the\neigenvalues and eigenvectors of suitable transfer operators in direct space.\nAdjusting the eigenvalues, while freezing the eigenvectors, yields a\nsubstantial compression of the parameter space. This latter scales by\ndefinition with the number of computing neurons. The classification scores, as\nmeasured by the displayed accuracy, are however inferior to those attained when\nthe learning is carried in direct space, for an identical architecture and by\nemploying the full set of trainable parameters (with a quadratic dependence on\nthe size of neighbor layers). In this Letter, we propose a variant of the\nspectral learning method as appeared in Giambagli et al {Nat. Comm.} 2021,\nwhich leverages on two sets of eigenvalues, for each mapping between adjacent\nlayers. The eigenvalues act as veritable knobs which can be freely tuned so as\nto (i) enhance, or alternatively silence, the contribution of the input nodes,\n(ii) modulate the excitability of the receiving nodes with a mechanism which we\ninterpret as the artificial analogue of the homeostatic plasticity. The number\nof trainable parameters is still a linear function of the network size, but the\nperformances of the trained device gets much closer to those obtained via\nconventional algorithms, these latter requiring however a considerably heavier\ncomputational cost. The residual gap between conventional and spectral\ntrainings can be eventually filled by employing a suitable decomposition for\nthe non trivial block of the eigenvectors matrix. Each spectral parameter\nreflects back on the whole set of inter-nodes weights, an attribute which we\nshall effectively exploit to yield sparse networks with stunning classification\nabilities, as compared to their homologues trained with conventional means.",
    "descriptor": "",
    "authors": [
      "Lorenzo Chicchi",
      "Lorenzo Giambagli",
      "Lorenzo Buffoni",
      "Timoteo Carletti",
      "Marco Ciavarella",
      "Duccio Fanelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2106.09021"
  },
  {
    "id": "arXiv:2106.09022",
    "title": "A Simple Fix to Mahalanobis Distance for Improving Near-OOD Detection",
    "abstract": "Mahalanobis distance (MD) is a simple and popular post-processing method for\ndetecting out-of-distribution (OOD) inputs in neural networks. We analyze its\nfailure modes for near-OOD detection and propose a simple fix called relative\nMahalanobis distance (RMD) which improves performance and is more robust to\nhyperparameter choice. On a wide selection of challenging vision, language, and\nbiology OOD benchmarks (CIFAR-100 vs CIFAR-10, CLINC OOD intent detection,\nGenomics OOD), we show that RMD meaningfully improves upon MD performance (by\nup to 15% AUROC on genomics OOD).",
    "descriptor": "",
    "authors": [
      "Jie Ren",
      "Stanislav Fort",
      "Jeremiah Liu",
      "Abhijit Guha Roy",
      "Shreyas Padhy",
      "Balaji Lakshminarayanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09022"
  },
  {
    "id": "arXiv:2106.09024",
    "title": "Disentangling Online Chats with DAG-Structured LSTMs",
    "abstract": "Many modern messaging systems allow fast and synchronous textual\ncommunication among many users. The resulting sequence of messages hides a more\ncomplicated structure in which independent sub-conversations are interwoven\nwith one another. This poses a challenge for any task aiming to understand the\ncontent of the chat logs or gather information from them. The ability to\ndisentangle these conversations is then tantamount to the success of many\ndownstream tasks such as summarization and question answering. Structured\ninformation accompanying the text such as user turn, user mentions, timestamps,\nis used as a cue by the participants themselves who need to follow the\nconversation and has been shown to be important for disentanglement. DAG-LSTMs,\na generalization of Tree-LSTMs that can handle directed acyclic dependencies,\nare a natural way to incorporate such information and its non-sequential\nnature. In this paper, we apply DAG-LSTMs to the conversation disentanglement\ntask. We perform our experiments on the Ubuntu IRC dataset. We show that the\nnovel model we propose achieves state of the art status on the task of\nrecovering reply-to relations and it is competitive on other disentanglement\nmetrics.",
    "descriptor": "\nComments: 8 pages, 1 figure. Accepted at *SEM 2021\n",
    "authors": [
      "Duccio Pappadopulo",
      "Lisa Bauer",
      "Marco Farina",
      "Ozan \u0130rsoy",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09024"
  },
  {
    "id": "arXiv:2106.09035",
    "title": "Regularization of Mixture Models for Robust Principal Graph Learning",
    "abstract": "A regularized version of Mixture Models is proposed to learn a principal\ngraph from a distribution of $D$-dimensional data points. In the particular\ncase of manifold learning for ridge detection, we assume that the underlying\nmanifold can be modeled as a graph structure acting like a topological prior\nfor the Gaussian clusters turning the problem into a maximum a posteriori\nestimation. Parameters of the model are iteratively estimated through an\nExpectation-Maximization procedure making the learning of the structure\ncomputationally efficient with guaranteed convergence for any graph prior in a\npolynomial time. We also embed in the formalism a natural way to make the\nalgorithm robust to outliers of the pattern and heteroscedasticity of the\nmanifold sampling coherently with the graph structure. The method uses a graph\nprior given by the minimum spanning tree that we extend using random\nsub-samplings of the dataset to take into account cycles that can be observed\nin the spatial distribution.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Tony Bonnaire",
      "Aur\u00e9lien Decelle",
      "Nabila Aghanim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09035"
  },
  {
    "id": "arXiv:2106.09051",
    "title": "Unsupervised Video Prediction from a Single Frame by Estimating 3D  Dynamic Scene Structure",
    "abstract": "Our goal in this work is to generate realistic videos given just one initial\nframe as input. Existing unsupervised approaches to this task do not consider\nthe fact that a video typically shows a 3D environment, and that this should\nremain coherent from frame to frame even as the camera and objects move. We\naddress this by developing a model that first estimates the latent 3D structure\nof the scene, including the segmentation of any moving objects. It then\npredicts future frames by simulating the object and camera dynamics, and\nrendering the resulting views. Importantly, it is trained end-to-end using only\nthe unsupervised objective of predicting future frames, without any 3D\ninformation nor segmentation annotations. Experiments on two challenging\ndatasets of natural videos show that our model can estimate 3D structure and\nmotion segmentation from a single frame, and hence generate plausible and\nvaried predictions.",
    "descriptor": "",
    "authors": [
      "Paul Henderson",
      "Christoph H. Lampert",
      "Bernd Bickel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09051"
  },
  {
    "id": "arXiv:2106.09060",
    "title": "On the stability of the $L^{2}$ projection and the quasiinterpolant in  the space of smooth periodic splines",
    "abstract": "In this paper we derive stability estimates in $L^{2}$- and $L^{\\infty}$-\nbased Sobolev spaces for the $L^{2}$ projection and a family of\nquasiinterolants in the space of smooth, 1-periodic, polynomial splines defined\non a uniform mesh in $[0,1]$. As a result of the assumed periodicity and the\nuniform mesh, cyclic matrix techniques and suitable decay estimates of the\nelements of the inverse of a Gram matrix associated with the standard basis of\nthe space of splines, are used to establish the stability results.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "D.C. Antonopoulos V.A. Dougalis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09060"
  },
  {
    "id": "arXiv:2106.09063",
    "title": "Specializing Multilingual Language Models: An Empirical Study",
    "abstract": "Contextualized word representations from pretrained multilingual language\nmodels have become the de facto standard for addressing natural language tasks\nin many different languages, but the success of this approach is far from\nuniversal. For languages rarely or never seen by these models, directly using\nsuch models often results in suboptimal representation or use of data,\nmotivating additional model adaptations to achieve reasonably strong\nperformance. In this work, we study the performance, extensibility, and\ninteraction of two such adaptations for this low-resource setting: vocabulary\naugmentation and script transliteration. Our evaluations on a set of three\ntasks in nine diverse low-resource languages yield a mixed result, upholding\nthe viability of these approaches while raising new questions around how to\noptimally adapt multilingual models to low-resource settings.",
    "descriptor": "",
    "authors": [
      "Ethan C. Chau",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09063"
  },
  {
    "id": "arXiv:2106.09064",
    "title": "Automatic Main Character Recognition for Photographic Studies",
    "abstract": "Main characters in images are the most important humans that catch the\nviewer's attention upon first look, and they are emphasized by properties such\nas size, position, color saturation, and sharpness of focus. Identifying the\nmain character in images plays an important role in traditional photographic\nstudies and media analysis, but the task is performed manually and can be slow\nand laborious. Furthermore, selection of main characters can be sometimes\nsubjective. In this paper, we analyze the feasibility of solving the main\ncharacter recognition needed for photographic studies automatically and propose\na method for identifying the main characters. The proposed method uses machine\nlearning based human pose estimation along with traditional computer vision\napproaches for this task. We approach the task as a binary classification\nproblem where each detected human is classified either as a main character or\nnot. To evaluate both the subjectivity of the task and the performance of our\nmethod, we collected a dataset of 300 varying images from multiple sources and\nasked five people, a photographic researcher and four other persons, to\nannotate the main characters. Our analysis showed a relatively high agreement\nbetween different annotators. The proposed method achieved a promising F1 score\nof 0.83 on the full image set and 0.96 on a subset evaluated as most clear and\nimportant cases by the photographic researcher.",
    "descriptor": "\nComments: 6 pages, 4 figures, 2 tables\n",
    "authors": [
      "Mert Seker",
      "Anssi M\u00e4nnist\u00f6",
      "Alexandros Iosifidis",
      "Jenni Raitoharju"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09064"
  },
  {
    "id": "arXiv:2106.09065",
    "title": "SPeCiaL: Self-Supervised Pretraining for Continual Learning",
    "abstract": "This paper presents SPeCiaL: a method for unsupervised pretraining of\nrepresentations tailored for continual learning. Our approach devises a\nmeta-learning objective that differentiates through a sequential learning\nprocess. Specifically, we train a linear model over the representations to\nmatch different augmented views of the same image together, each view presented\nsequentially. The linear model is then evaluated on both its ability to\nclassify images it just saw, and also on images from previous iterations. This\ngives rise to representations that favor quick knowledge retention with minimal\nforgetting. We evaluate SPeCiaL in the Continual Few-Shot Learning setting, and\nshow that it can match or outperform other supervised pretraining approaches.",
    "descriptor": "",
    "authors": [
      "Lucas Caccia",
      "Joelle Pineau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09065"
  },
  {
    "id": "arXiv:2106.09069",
    "title": "Automatic Construction of Evaluation Suites for Natural Language  Generation Datasets",
    "abstract": "Machine learning approaches applied to NLP are often evaluated by summarizing\ntheir performance in a single number, for example accuracy. Since most test\nsets are constructed as an i.i.d. sample from the overall data, this approach\noverly simplifies the complexity of language and encourages overfitting to the\nhead of the data distribution. As such, rare language phenomena or text about\nunderrepresented groups are not equally included in the evaluation. To\nencourage more in-depth model analyses, researchers have proposed the use of\nmultiple test sets, also called challenge sets, that assess specific\ncapabilities of a model. In this paper, we develop a framework based on this\nidea which is able to generate controlled perturbations and identify subsets in\ntext-to-scalar, text-to-text, or data-to-text settings. By applying this\nframework to the GEM generation benchmark, we propose an evaluation suite made\nof 80 challenge sets, demonstrate the kinds of analyses that it enables and\nshed light onto the limits of current generation models.",
    "descriptor": "",
    "authors": [
      "Simon Mille",
      "Kaustubh D. Dhole",
      "Saad Mahamood",
      "Laura Perez-Beltrachini",
      "Varun Gangal",
      "Mihir Kale",
      "Emiel van Miltenburg",
      "Sebastian Gehrmann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09069"
  },
  {
    "id": "arXiv:2106.09070",
    "title": "Identifiability-Guaranteed Simplex-Structured Post-Nonlinear Mixture  Learning via Autoencoder",
    "abstract": "This work focuses on the problem of unraveling nonlinearly mixed latent\ncomponents in an unsupervised manner. The latent components are assumed to\nreside in the probability simplex, and are transformed by an unknown\npost-nonlinear mixing system. This problem finds various applications in signal\nand data analytics, e.g., nonlinear hyperspectral unmixing, image embedding,\nand nonlinear clustering. Linear mixture learning problems are already\nill-posed, as identifiability of the target latent components is hard to\nestablish in general. With unknown nonlinearity involved, the problem is even\nmore challenging. Prior work offered a function equation-based formulation for\nprovable latent component identification. However, the identifiability\nconditions are somewhat stringent and unrealistic. In addition, the\nidentifiability analysis is based on the infinite sample (i.e., population)\ncase, while the understanding for practical finite sample cases has been\nelusive. Moreover, the algorithm in the prior work trades model expressiveness\nwith computational convenience, which often hinders the learning performance.\nOur contribution is threefold. First, new identifiability conditions are\nderived under largely relaxed assumptions. Second, comprehensive sample\ncomplexity results are presented -- which are the first of the kind. Third, a\nconstrained autoencoder-based algorithmic framework is proposed for\nimplementation, which effectively circumvents the challenges in the existing\nalgorithm. Synthetic and real experiments corroborate our theoretical analyses.",
    "descriptor": "",
    "authors": [
      "Qi Lyu",
      "Xiao Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09070"
  },
  {
    "id": "arXiv:2106.09074",
    "title": "Robust a posteriori error analysis for rotation-based formulations of  the elasticity/poroelasticity coupling",
    "abstract": "We develop the \\textit{a posteriori} error analysis of three mixed finite\nelement formulations for rotation-based equations in elasticity,\nporoelasticity, and interfacial elasticity-poroelasticity. The discretisations\nuse $H^1$-conforming finite elements of degree $k+1$ for displacement and fluid\npressure, and discontinuous piecewise polynomials of degree $k$ for rotation\nvector, total pressure, and elastic pressure. Residual-based estimators are\nconstructed, and upper and lower bounds (up to data oscillations) for all\nglobal estimators are rigorously derived. The methods are all robust with\nrespect to the model parameters (in particular, the Lam\\'e constants), they are\nvalid in 2D and 3D, and also for arbitrary polynomial degree $k\\geq 0$. The\nerror behaviour predicted by the theoretical analysis is then demonstrated\nnumerically on a set of computational examples including different geometries\non which we perform adaptive mesh refinement guided by the \\textit{a\nposteriori} error estimators.",
    "descriptor": "",
    "authors": [
      "Ver\u00d3nica Anaya",
      "Arbaz Khan",
      "David Mora",
      "Ricardo Ruiz-Baier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09074"
  },
  {
    "id": "arXiv:2106.09076",
    "title": "Deformation Driven Seq2Seq Longitudinal Tumor and Organs-at-Risk  Prediction for Radiotherapy",
    "abstract": "Purpose: Radiotherapy presents unique challenges and clinical requirements\nfor longitudinal tumor and organ-at-risk (OAR) prediction during treatment. The\nchallenges include tumor inflammation/edema and radiation-induced changes in\norgan geometry, whereas the clinical requirements demand flexibility in\ninput/output sequence timepoints to update the predictions on rolling basis and\nthe grounding of all predictions in relationship to the pre-treatment imaging\ninformation for response and toxicity assessment in adaptive radiotherapy.\nMethods: To deal with the aforementioned challenges and to comply with the\nclinical requirements, we present a novel 3D sequence-to-sequence model based\non Convolution Long Short Term Memory (ConvLSTM) that makes use of series of\ndeformation vector fields (DVF) between individual timepoints and reference\npre-treatment/planning CTs to predict future anatomical deformations and\nchanges in gross tumor volume as well as critical OARs. High-quality DVF\ntraining data is created by employing hyper-parameter optimization on the\nsubset of the training data with DICE coefficient and mutual information\nmetric. We validated our model on two radiotherapy datasets: a publicly\navailable head-and-neck dataset (28 patients with manually contoured pre-,\nmid-, and post-treatment CTs), and an internal non-small cell lung cancer\ndataset (63 patients with manually contoured planning CT and 6 weekly CBCTs).\nResults: The use of DVF representation and skip connections overcomes the\nblurring issue of ConvLSTM prediction with the traditional image\nrepresentation. The mean and standard deviation of DICE for predictions of lung\nGTV at week 4, 5, and 6 were 0.83$\\pm$0.09, 0.82$\\pm$0.08, and 0.81$\\pm$0.10,\nrespectively, and for post-treatment ipsilateral and contralateral parotids,\nwere 0.81$\\pm$0.06 and 0.85$\\pm$0.02.",
    "descriptor": "\nComments: Medical Physics 2021, Saad Nadeem and Yu-Chi Hu contributed equally\n",
    "authors": [
      "Donghoon Lee",
      "Sadegh R Alam",
      "Jue Jiang",
      "Pengpeng Zhang",
      "Saad Nadeem",
      "Yu-Chi Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09076"
  },
  {
    "id": "arXiv:2106.09078",
    "title": "Towards a Rigorous Theoretical Analysis and Evaluation of GNN  Explanations",
    "abstract": "As Graph Neural Networks (GNNs) are increasingly employed in real-world\napplications, it becomes critical to ensure that the stakeholders understand\nthe rationale behind their predictions. While several GNN explanation methods\nhave been proposed recently, there has been little to no work on theoretically\nanalyzing the behavior of these methods or systematically evaluating their\neffectiveness. Here, we introduce the first axiomatic framework for\ntheoretically analyzing, evaluating, and comparing state-of-the-art GNN\nexplanation methods. We outline and formalize the key desirable properties that\nall GNN explanation methods should satisfy in order to generate reliable\nexplanations, namely, faithfulness, stability, and fairness. We leverage these\nproperties to present the first ever theoretical analysis of the effectiveness\nof state-of-the-art GNN explanation methods. Our analysis establishes upper\nbounds on all the aforementioned properties for popular GNN explanation\nmethods. We also leverage our framework to empirically evaluate these methods\non multiple real-world datasets from diverse domains. Our empirical results\ndemonstrate that some popular GNN explanation methods (e.g., gradient-based\nmethods) perform no better than a random baseline and that methods which\nleverage the graph structure are more effective than those that solely rely on\nthe node features.",
    "descriptor": "",
    "authors": [
      "Chirag Agarwal",
      "Marinka Zitnik",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09078"
  },
  {
    "id": "arXiv:2106.09086",
    "title": "Learned Belief Search: Efficiently Improving Policies in Partially  Observable Settings",
    "abstract": "Search is an important tool for computing effective policies in single- and\nmulti-agent environments, and has been crucial for achieving superhuman\nperformance in several benchmark fully and partially observable games. However,\none major limitation of prior search approaches for partially observable\nenvironments is that the computational cost scales poorly with the amount of\nhidden information. In this paper we present \\emph{Learned Belief Search}\n(LBS), a computationally efficient search procedure for partially observable\nenvironments. Rather than maintaining an exact belief distribution, LBS uses an\napproximate auto-regressive counterfactual belief that is learned as a\nsupervised task. In multi-agent settings, LBS uses a novel public-private model\narchitecture for underlying policies in order to efficiently evaluate these\npolicies during rollouts. In the benchmark domain of Hanabi, LBS can obtain 55%\n~ 91% of the benefit of exact search while reducing compute requirements by\n$35.8 \\times$ ~ $4.6 \\times$, allowing it to scale to larger settings that were\ninaccessible to previous search methods.",
    "descriptor": "",
    "authors": [
      "Hengyuan Hu",
      "Adam Lerer",
      "Noam Brown",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09086"
  },
  {
    "id": "arXiv:2106.09094",
    "title": "Impact of Communication Loss on MPC based Cooperative Adaptive Cruise  Control and Platooning",
    "abstract": "Cooperative driving, enabled by communication between automated vehicle\nsystems, is expected to significantly contribute to transportation safety and\nefficiency. Cooperative Adaptive Cruise Control (CACC) and platooning are two\nof the main cooperative driving applications that are currently under study.\nThese applications offer significant improvements over current advanced driver\nassistant systems such as adaptive cruise control (ACC). The primary motivation\nof CACC and Platooning is to reduce traffic congestion and improve traffic\nflow, traffic throughput, and highway capacity. These applications need an\nefficient controller to consider the computational cost and ensure driving\ncomfort and high responsiveness. The advantage of Model Predictive Control is\nthat we can realize high control performance since all constrain for these\napplications can be explicitly dealt with through solving an optimization\nproblem. These applications highly depend on information update and\nCommunication reliability for their safety and stability purposes. In this\npaper, we propose a Model Predictive Control (MPC) based approach for CACC and\nplatooning, and examine the impact of communication loss on the performance and\nrobustness of the control scheme. The results show an improvement in response\ntime and string stability, demonstrating the potential of cooperation to\nattenuate disturbances and improve traffic flow.",
    "descriptor": "",
    "authors": [
      "Mahdi Razzaghpour",
      "Shahriar Shahram",
      "Rodolfo Valiente",
      "Yaser P. Fallah"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09094"
  },
  {
    "id": "arXiv:2106.09104",
    "title": "Improving Inference Lifetime of Neuromorphic Systems via Intelligent  Synapse Mapping",
    "abstract": "Non-Volatile Memories (NVMs) such as Resistive RAM (RRAM) are used in\nneuromorphic systems to implement high-density and low-power analog synaptic\nweights. Unfortunately, an RRAM cell can switch its state after reading its\ncontent a certain number of times. Such behavior challenges the integrity and\nprogram-once-read-many-times philosophy of implementing machine learning\ninference on neuromorphic systems, impacting the Quality-of-Service (QoS).\nElevated temperatures and frequent usage can significantly shorten the number\nof times an RRAM cell can be reliably read before it becomes absolutely\nnecessary to reprogram. We propose an architectural solution to extend the read\nendurance of RRAM-based neuromorphic systems. We make two key contributions.\nFirst, we formulate the read endurance of an RRAM cell as a function of the\nprogrammed synaptic weight and its activation within a machine learning\nworkload. Second, we propose an intelligent workload mapping strategy\nincorporating the endurance formulation to place the synapses of a machine\nlearning model onto the RRAM cells of the hardware. The objective is to extend\nthe inference lifetime, defined as the number of times the model can be used to\ngenerate output (inference) before the trained weights need to be reprogrammed\non the RRAM cells of the system. We evaluate our architectural solution with\nmachine learning workloads on a cycle-accurate simulator of an RRAM-based\nneuromorphic system. Our results demonstrate a significant increase in\ninference lifetime with only a minimal performance impact.",
    "descriptor": "\nComments: Accepted for publication at ASAP 2021\n",
    "authors": [
      "Shihao Song",
      "Twisha Titirsha",
      "Anup Das"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.09104"
  },
  {
    "id": "arXiv:2106.09106",
    "title": "Explainable AI for Natural Adversarial Images",
    "abstract": "Adversarial images highlight how vulnerable modern image classifiers are to\nperturbations outside of their training set. Human oversight might mitigate\nthis weakness, but depends on humans understanding the AI well enough to\npredict when it is likely to make a mistake. In previous work we have found\nthat humans tend to assume that the AI's decision process mirrors their own.\nHere we evaluate if methods from explainable AI can disrupt this assumption to\nhelp participants predict AI classifications for adversarial and standard\nimages. We find that both saliency maps and examples facilitate catching AI\nerrors, but their effects are not additive, and saliency maps are more\neffective than examples.",
    "descriptor": "",
    "authors": [
      "Tomas Folke",
      "ZhaoBin Li",
      "Ravi B. Sojitra",
      "Scott Cheng-Hsin Yang",
      "Patrick Shafto"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09106"
  },
  {
    "id": "arXiv:2106.09109",
    "title": "QuantumFed: A Federated Learning Framework for Collaborative Quantum  Training",
    "abstract": "With the fast development of quantum computing and deep learning, quantum\nneural networks have attracted great attention recently. By leveraging the\npower of quantum computing, deep neural networks can potentially overcome\ncomputational power limitations in classic machine learning. However, when\nmultiple quantum machines wish to train a global model using the local data on\neach machine, it may be very difficult to copy the data into one machine and\ntrain the model. Therefore, a collaborative quantum neural network framework is\nnecessary. In this article, we borrow the core idea of federated learning to\npropose QuantumFed, a quantum federated learning framework to have multiple\nquantum nodes with local quantum data train a mode together. Our experiments\nshow the feasibility and robustness of our framework.",
    "descriptor": "",
    "authors": [
      "Qun Xia",
      "Qun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.09109"
  },
  {
    "id": "arXiv:2106.09110",
    "title": "Safe Reinforcement Learning Using Advantage-Based Intervention",
    "abstract": "Many sequential decision problems involve finding a policy that maximizes\ntotal reward while obeying safety constraints. Although much recent research\nhas focused on the development of safe reinforcement learning (RL) algorithms\nthat produce a safe policy after training, ensuring safety during training as\nwell remains an open problem. A fundamental challenge is performing exploration\nwhile still satisfying constraints in an unknown Markov decision process (MDP).\nIn this work, we address this problem for the chance-constrained setting. We\npropose a new algorithm, SAILR, that uses an intervention mechanism based on\nadvantage functions to keep the agent safe throughout training and optimizes\nthe agent's policy using off-the-shelf RL algorithms designed for unconstrained\nMDPs. Our method comes with strong guarantees on safety during both training\nand deployment (i.e., after training and without the intervention mechanism)\nand policy performance compared to the optimal safety-constrained policy. In\nour experiments, we show that SAILR violates constraints far less during\ntraining than standard safe RL and constrained MDP approaches and converges to\na well-performing policy that can be deployed safely without intervention. Our\ncode is available at https://github.com/nolanwagener/safe_rl.",
    "descriptor": "\nComments: Appearing in ICML 2021. 28 pages, 7 figures\n",
    "authors": [
      "Nolan Wagener",
      "Byron Boots",
      "Ching-An Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09110"
  },
  {
    "id": "arXiv:2106.09111",
    "title": "An Imprecise SHAP as a Tool for Explaining the Class Probability  Distributions under Limited Training Data",
    "abstract": "One of the most popular methods of the machine learning prediction\nexplanation is the SHapley Additive exPlanations method (SHAP). An imprecise\nSHAP as a modification of the original SHAP is proposed for cases when the\nclass probability distributions are imprecise and represented by sets of\ndistributions. The first idea behind the imprecise SHAP is a new approach for\ncomputing the marginal contribution of a feature, which fulfils the important\nefficiency property of Shapley values. The second idea is an attempt to\nconsider a general approach to calculating and reducing interval-valued Shapley\nvalues, which is similar to the idea of reachable probability intervals in the\nimprecise probability theory. A simple special implementation of the general\napproach in the form of linear optimization problems is proposed, which is\nbased on using the Kolmogorov-Smirnov distance and imprecise contamination\nmodels. Numerical examples with synthetic and real data illustrate the\nimprecise SHAP.",
    "descriptor": "",
    "authors": [
      "Lev V. Utkin",
      "Andrei V. Konstantinov",
      "Kirill A. Vishniakov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09111"
  },
  {
    "id": "arXiv:2106.09117",
    "title": "DeepSplit: Scalable Verification of Deep Neural Networks via Operator  Splitting",
    "abstract": "Analyzing the worst-case performance of deep neural networks against input\nperturbations amounts to solving a large-scale non-convex optimization problem,\nfor which several past works have proposed convex relaxations as a promising\nalternative. However, even for reasonably-sized neural networks, these\nrelaxations are not tractable, and so must be replaced by even weaker\nrelaxations in practice. In this work, we propose a novel operator splitting\nmethod that can directly solve a convex relaxation of the problem to high\naccuracy, by splitting it into smaller sub-problems that often have analytical\nsolutions. The method is modular and scales to problem instances that were\npreviously impossible to solve exactly due to their size. Furthermore, the\nsolver operations are amenable to fast parallelization with GPU acceleration.\nWe demonstrate our method in obtaining tighter bounds on the worst-case\nperformance of large convolutional networks in image classification and\nreinforcement learning settings.",
    "descriptor": "",
    "authors": [
      "Shaoru Chen",
      "Eric Wong",
      "J. Zico Kolter",
      "Mahyar Fazlyab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09117"
  },
  {
    "id": "arXiv:2106.09119",
    "title": "Behavioral Priors and Dynamics Models: Improving Performance and Domain  Transfer in Offline RL",
    "abstract": "Offline Reinforcement Learning (RL) aims to extract near-optimal policies\nfrom imperfect offline data without additional environment interactions.\nExtracting policies from diverse offline datasets has the potential to expand\nthe range of applicability of RL by making the training process safer, faster,\nand more streamlined. We investigate how to improve the performance of offline\nRL algorithms, its robustness to the quality of offline data, as well as its\ngeneralization capabilities. To this end, we introduce Offline Model-based RL\nwith Adaptive Behavioral Priors (MABE). Our algorithm is based on the finding\nthat dynamics models, which support within-domain generalization, and\nbehavioral priors, which support cross-domain generalization, are\ncomplementary. When combined together, they substantially improve the\nperformance and generalization of offline RL policies. In the widely studied\nD4RL offline RL benchmark, we find that MABE achieves higher average\nperformance compared to prior model-free and model-based algorithms. In\nexperiments that require cross-domain generalization, we find that MABE\noutperforms prior methods. Our website is available at\nhttps://sites.google.com/berkeley.edu/mabe .",
    "descriptor": "",
    "authors": [
      "Catherine Cang",
      "Aravind Rajeswaran",
      "Pieter Abbeel",
      "Michael Laskin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09119"
  },
  {
    "id": "arXiv:2106.09121",
    "title": "Scaling-up Diverse Orthogonal Convolutional Networks with a Paraunitary  Framework",
    "abstract": "Enforcing orthogonality in neural networks is an antidote for gradient\nvanishing/exploding problems, sensitivity by adversarial perturbation, and\nbounding generalization errors. However, many previous approaches are\nheuristic, and the orthogonality of convolutional layers is not systematically\nstudied: some of these designs are not exactly orthogonal, while others only\nconsider standard convolutional layers and propose specific classes of their\nrealizations. To address this problem, we propose a theoretical framework for\northogonal convolutional layers, which establishes the equivalence between\nvarious orthogonal convolutional layers in the spatial domain and the\nparaunitary systems in the spectral domain. Since there exists a complete\nspectral factorization of paraunitary systems, any orthogonal convolution layer\ncan be parameterized as convolutions of spatial filters. Our framework endows\nhigh expressive power to various convolutional layers while maintaining their\nexact orthogonality. Furthermore, our layers are memory and computationally\nefficient for deep networks compared to previous designs. Our versatile\nframework, for the first time, enables the study of architecture designs for\ndeep orthogonal networks, such as choices of skip connection, initialization,\nstride, and dilation. Consequently, we scale up orthogonal networks to deep\narchitectures, including ResNet, WideResNet, and ShuffleNet, substantially\nincreasing the performance over the traditional shallow orthogonal networks.",
    "descriptor": "",
    "authors": [
      "Jiahao Su",
      "Wonmin Byeon",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09121"
  },
  {
    "id": "arXiv:2106.09127",
    "title": "Planning on a (Risk) Budget: Safe Non-Conservative Planning in  Probabilistic Dynamic Environments",
    "abstract": "Planning in environments with other agents whose future actions are uncertain\noften requires compromise between safety and performance. Here our goal is to\ndesign efficient planning algorithms with guaranteed bounds on the probability\nof safety violation, which nonetheless achieve non-conservative performance. To\nquantify a system's risk, we define a natural criterion called interval risk\nbounds (IRBs), which provide a parametric upper bound on the probability of\nsafety violation over a given time interval or task. We present a novel\nreceding horizon algorithm, and prove that it can satisfy a desired IRB. Our\nalgorithm maintains a dynamic risk budget which constrains the allowable risk\nat each iteration, and guarantees recursive feasibility by requiring a safe set\nto be reachable by a contingency plan within the budget. We empirically\ndemonstrate that our algorithm is both safer and less conservative than strong\nbaselines in two simulated autonomous driving experiments in scenarios\ninvolving collision avoidance with other vehicles, and additionally demonstrate\nour algorithm running on an autonomous class 8 truck.",
    "descriptor": "\nComments: 9 pages, 5 figures, International Conference on Robotics and Automation 2021\n",
    "authors": [
      "Hung-Jui Huang",
      "Kai-Chi Huang",
      "Michal \u010c\u00e1p",
      "Yibiao Zhao",
      "Ying Nian Wu",
      "Chris L. Baker"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09127"
  },
  {
    "id": "arXiv:2106.09129",
    "title": "A Winning Hand: Compressing Deep Networks Can Improve  Out-Of-Distribution Robustness",
    "abstract": "Two crucial requirements for a successful adoption of deep learning (DL) in\nthe wild are: (1) robustness to distributional shifts, and (2) model\ncompactness for achieving efficiency. Unfortunately, efforts towards\nsimultaneously achieving Out-of-Distribution (OOD) robustness and extreme model\ncompactness without sacrificing accuracy have mostly been unsuccessful. This\nraises an important question: \"Is the inability to create compact, accurate,\nand robust deep neural networks (CARDs) fundamental?\" To answer this question,\nwe perform a large-scale analysis for a range of popular model compression\ntechniques which uncovers several intriguing patterns. Notably, in contrast to\ntraditional pruning approaches (e.g., fine tuning and gradual magnitude\npruning), we find that \"lottery ticket-style\" pruning approaches can\nsurprisingly be used to create high performing CARDs. Specifically, we are able\nto create extremely compact CARDs that are dramatically more robust than their\nsignificantly larger and full-precision counterparts while matching (or\nbeating) their test accuracy, simply by pruning and/or quantizing. To better\nunderstand these differences, we perform sensitivity analysis in the Fourier\ndomain for CARDs trained using different data augmentation methods. Motivated\nby our analysis, we develop a simple domain-adaptive test-time ensembling\napproach (CARD-Deck) that uses a gating module to dynamically select an\nappropriate CARD from the CARD-Deck based on their spectral-similarity with\ntest samples. By leveraging complementary frequency biases of different\ncompressed models, the proposed approach builds a \"winning hand\" of CARDs that\nestablishes a new state-of-the-art on CIFAR-10-C accuracies (i.e., 96.8% clean\nand 92.75% robust) with dramatically better memory usage than their\nnon-compressed counterparts. We also present some theoretical evidences\nsupporting our empirical findings.",
    "descriptor": "",
    "authors": [
      "James Diffenderfer",
      "Brian R. Bartoldson",
      "Shreya Chaganti",
      "Jize Zhang",
      "Bhavya Kailkhura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09129"
  },
  {
    "id": "arXiv:2106.09135",
    "title": "EEG-GNN: Graph Neural Networks for Classification of  Electroencephalogram (EEG) Signals",
    "abstract": "Convolutional neural networks (CNN) have been frequently used to extract\nsubject-invariant features from electroencephalogram (EEG) for classification\ntasks. This approach holds the underlying assumption that electrodes are\nequidistant analogous to pixels of an image and hence fails to explore/exploit\nthe complex functional neural connectivity between different electrode sites.\nWe overcome this limitation by tailoring the concepts of convolution and\npooling applied to 2D grid-like inputs for the functional network of electrode\nsites. Furthermore, we develop various graph neural network (GNN) models that\nproject electrodes onto the nodes of a graph, where the node features are\nrepresented as EEG channel samples collected over a trial, and nodes can be\nconnected by weighted/unweighted edges according to a flexible policy\nformulated by a neuroscientist. The empirical evaluations show that our\nproposed GNN-based framework outperforms standard CNN classifiers across ErrP,\nand RSVP datasets, as well as allowing neuroscientific interpretability and\nexplainability to deep learning methods tailored to EEG related classification\nproblems. Another practical advantage of our GNN-based framework is that it can\nbe used in EEG channel selection, which is critical for reducing computational\ncost, and designing portable EEG headsets.",
    "descriptor": "\nComments: 8 pages, 8 figures, under review in EMBC conference\n",
    "authors": [
      "Andac Demir",
      "Toshiaki Koike-Akino",
      "Ye Wang",
      "Masaki Haruna",
      "Deniz Erdogmus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.09135"
  },
  {
    "id": "arXiv:2106.09140",
    "title": "Human-AI Interactions Through A Gricean Lens",
    "abstract": "Grice's Cooperative Principle (1975) describes the implicit maxims that guide\nconversation between humans. As humans begin to interact with non-human\ndialogue systems more frequently and in a broader scope, an important question\nemerges: what principles govern those interactions? The present study addresses\nthis question by evaluating human-AI interactions using Grice's four maxims; we\ndemonstrate that humans do, indeed, apply these maxims to interactions with AI,\neven making explicit references to the AI's performance through a Gricean lens.\nTwenty-three participants interacted with an American English-speaking Alexa\nand rated and discussed their experience with an in-lab researcher. Researchers\nthen reviewed each exchange, identifying those that might relate to Grice's\nmaxims: Quantity, Quality, Manner, and Relevance. Many instances of explicit\nuser frustration stemmed from violations of Grice's maxims. Quantity violations\nwere noted for too little but not too much information, while Quality\nviolations were rare, indicating trust in Alexa's responses. Manner violations\nfocused on speed and humanness. Relevance violations were the most frequent,\nand they appear to be the most frustrating. While the maxims help describe many\nof the issues participants encountered, other issues do not fit neatly into\nGrice's framework. Participants were particularly averse to Alexa initiating\nexchanges or making unsolicited suggestions. To address this gap, we propose\nthe addition of human Priority to describe human-AI interaction. Humans and AIs\nare not conversational equals, and human initiative takes priority. We suggest\nthat the application of Grice's Cooperative Principles to human-AI interactions\nis beneficial both from an AI development perspective and as a tool for\ndescribing an emerging form of interaction.",
    "descriptor": "",
    "authors": [
      "Laura Panfili",
      "Steve Duman",
      "Andrew Nave",
      "Katherine Phelps Ridgeway",
      "Nathan Eversole",
      "Ruhi Sarikaya"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.09140"
  },
  {
    "id": "arXiv:2106.09141",
    "title": "Probing Image-Language Transformers for Verb Understanding",
    "abstract": "Multimodal image-language transformers have achieved impressive results on a\nvariety of tasks that rely on fine-tuning (e.g., visual question answering and\nimage retrieval). We are interested in shedding light on the quality of their\npretrained representations -- in particular, if these models can distinguish\ndifferent types of verbs or if they rely solely on nouns in a given sentence.\nTo do so, we collect a dataset of image-sentence pairs (in English) consisting\nof 421 verbs that are either visual or commonly found in the pretraining data\n(i.e., the Conceptual Captions dataset). We use this dataset to evaluate\npretrained image-language transformers and find that they fail more in\nsituations that require verb understanding compared to other parts of speech.\nWe also investigate what category of verbs are particularly challenging.",
    "descriptor": "",
    "authors": [
      "Lisa Anne Hendricks",
      "Aida Nematzadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09141"
  },
  {
    "id": "arXiv:2106.09144",
    "title": "FORMS: Fine-grained Polarized ReRAM-based In-situ Computation for  Mixed-signal DNN Accelerator",
    "abstract": "Recent works demonstrated the promise of using resistive random access memory\n(ReRAM) as an emerging technology to perform inherently parallel analog domain\nin-situ matrix-vector multiplication -- the intensive and key computation in\nDNNs. With weights stored in the ReRAM crossbar cells as conductance, when the\ninput vector is applied to word lines, the matrix-vector multiplication results\ncan be generated as the current in bit lines. A key problem is that the weight\ncan be either positive or negative, but the in-situ computation assumes all\ncells on each crossbar column with the same sign. The current architectures\neither use two ReRAM crossbars for positive and negative weights, or add an\noffset to weights so that all values become positive. Neither solution is\nideal: they either double the cost of crossbars, or incur extra offset\ncircuity. To better solve this problem, this paper proposes FORMS, a\nfine-grained ReRAM-based DNN accelerator with polarized weights. Instead of\ntrying to represent the positive/negative weights, our key design principle is\nto enforce exactly what is assumed in the in-situ computation -- ensuring that\nall weights in the same column of a crossbar have the same sign. It naturally\navoids the cost of an additional crossbar. Such weights can be nicely generated\nusing alternating direction method of multipliers (ADMM) regularized\noptimization, which can exactly enforce certain patterns in DNN weights. To\nachieve high accuracy, we propose to use fine-grained sub-array columns, which\nprovide a unique opportunity for input zero-skipping, significantly avoiding\nunnecessary computations. It also makes the hardware much easier to implement.\nPutting all together, with the same optimized models, FORMS achieves\nsignificant throughput improvement and speed up in frame per second over ISAAC\nwith similar area cost.",
    "descriptor": "\nComments: In Proceedings of the 48th Annual International Symposium on Computer Architecture (ISCA), 2021\n",
    "authors": [
      "Geng Yuan",
      "Payman Behnam",
      "Zhengang Li",
      "Ali Shafiee",
      "Sheng Lin",
      "Xiaolong Ma",
      "Hang Liu",
      "Xuehai Qian",
      "Mahdi Nazm Bojnordi",
      "Yanzhi Wang",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09144"
  },
  {
    "id": "arXiv:2106.09146",
    "title": "Contrastive Reinforcement Learning of Symbolic Reasoning Domains",
    "abstract": "Abstract symbolic reasoning, as required in domains such as mathematics and\nlogic, is a key component of human intelligence. Solvers for these domains have\nimportant applications, especially to computer-assisted education. But learning\nto solve symbolic problems is challenging for machine learning algorithms.\nExisting models either learn from human solutions or use hand-engineered\nfeatures, making them expensive to apply in new domains. In this paper, we\ninstead consider symbolic domains as simple environments where states and\nactions are given as unstructured text, and binary rewards indicate whether a\nproblem is solved. This flexible setup makes it easy to specify new domains,\nbut search and planning become challenging. We introduce four environments\ninspired by the Mathematics Common Core Curriculum, and observe that existing\nReinforcement Learning baselines perform poorly. We then present a novel\nlearning algorithm, Contrastive Policy Learning (ConPoLe) that explicitly\noptimizes the InfoNCE loss, which lower bounds the mutual information between\nthe current state and next states that continue on a path to the solution.\nConPoLe successfully solves all four domains. Moreover, problem representations\nlearned by ConPoLe enable accurate prediction of the categories of problems in\na real mathematics curriculum. Our results suggest new directions for\nreinforcement learning in symbolic domains, as well as applications to\nmathematics education.",
    "descriptor": "",
    "authors": [
      "Gabriel Poesia",
      "WenXin Dong",
      "Noah Goodman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09146"
  },
  {
    "id": "arXiv:2106.09151",
    "title": "Recovery Guarantees for Time-varying Pairwise Comparison Matrices with  Non-transitivity",
    "abstract": "Pairwise comparison matrices have received substantial attention in a variety\nof applications, especially in rank aggregation, the task of flattening items\ninto a one-dimensional (and thus transitive) ranking. However, non-transitive\npreference cycles can arise in practice due to the fact that making a decision\noften requires a complex evaluation of multiple factors. In some applications,\nit may be important to identify and preserve information about the inherent\nnon-transitivity, either in the pairwise comparison data itself or in the\nlatent feature space. In this work, we develop structured models for\nnon-transitive pairwise comparison matrices that can be exploited to recover\nsuch matrices from incomplete noisy data and thus allow the detection of\nnon-transitivity. Considering that individuals' tastes and items' latent\nfeatures may change over time, we formulate time-varying pairwise comparison\nmatrix recovery as a dynamic skew-symmetric matrix recovery problem by modeling\nchanges in the low-rank factors of the pairwise comparison matrix. We provide\ntheoretical guarantees for the recovery and numerically test the proposed\ntheory with both synthetic and real-world data.",
    "descriptor": "",
    "authors": [
      "Shuang Li",
      "Michael B. Wakin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.09151"
  },
  {
    "id": "arXiv:2106.09153",
    "title": "Selecting for Selection: Learning To Balance Adaptive and Diversifying  Pressures in Evolutionary Search",
    "abstract": "Inspired by natural evolution, evolutionary search algorithms have proven\nremarkably capable due to their dual abilities to radiantly explore through\ndiverse populations and to converge to adaptive pressures. A large part of this\nbehavior comes from the selection function of an evolutionary algorithm, which\nis a metric for deciding which individuals survive to the next generation. In\ndeceptive or hard-to-search fitness landscapes, greedy selection often fails,\nthus it is critical that selection functions strike the correct balance between\ngradient-exploiting adaptation and exploratory diversification. This paper\nintroduces Sel4Sel, or Selecting for Selection, an algorithm that searches for\nhigh-performing neural-network-based selection functions through a\nmeta-evolutionary loop. Results on three distinct bitstring domains indicate\nthat Sel4Sel networks consistently match or exceed the performance of both\nfitness-based selection and benchmarks explicitly designed to encourage\ndiversity. Analysis of the strongest Sel4Sel networks reveals a general\ntendency to favor highly novel individuals early on, with a gradual shift\ntowards fitness-based selection as deceptive local optima are bypassed.",
    "descriptor": "",
    "authors": [
      "Kevin Frans",
      "L.B. Soros",
      "Olaf Witkowski"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.09153"
  },
  {
    "id": "arXiv:2106.09157",
    "title": "Positional Contrastive Learning for VolumetricMedical Image Segmentation",
    "abstract": "The success of deep learning heavily depends on the availability of large\nlabeled training sets. However, it is hard to get large labeled datasets in\nmedical image domain because of the strict privacy concern and costly labeling\nefforts. Contrastive learning, an unsupervised learning technique, has been\nproved powerful in learning image-level representations from unlabeled data.\nThe learned encoder can then be transferred or fine-tuned to improve the\nperformance of downstream tasks with limited labels. A critical step in\ncontrastive learning is the generation of contrastive data pairs, which is\nrelatively simple for natural image classification but quite challenging for\nmedical image segmentation due to the existence of the same tissue or organ\nacross the dataset. As a result, when applied to medical image segmentation,\nmost state-of-the-art contrastive learning frameworks inevitably introduce a\nlot of false-negative pairs and result in degraded segmentation quality. To\naddress this issue, we propose a novel positional contrastive learning (PCL)\nframework to generate contrastive data pairs by leveraging the position\ninformation in volumetric medical images. Experimental results on CT and MRI\ndatasets demonstrate that the proposed PCL method can substantially improve the\nsegmentation performance compared to existing methods in both semi-supervised\nsetting and transfer learning setting.",
    "descriptor": "\nComments: 8 pages, conference\n",
    "authors": [
      "Dewen Zeng",
      "Yawen Wu",
      "Xinrong Hu",
      "Xiaowei Xu",
      "Haiyun Yuan",
      "Meiping Huang",
      "Jian Zhuang",
      "Jingtong Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09157"
  },
  {
    "id": "arXiv:2106.09159",
    "title": "Automatic Curricula via Expert Demonstrations",
    "abstract": "We propose Automatic Curricula via Expert Demonstrations (ACED), a\nreinforcement learning (RL) approach that combines the ideas of imitation\nlearning and curriculum learning in order to solve challenging robotic\nmanipulation tasks with sparse reward functions. Curriculum learning solves\ncomplicated RL tasks by introducing a sequence of auxiliary tasks with\nincreasing difficulty, yet how to automatically design effective and\ngeneralizable curricula remains a challenging research problem. ACED extracts\ncurricula from a small amount of expert demonstration trajectories by dividing\ndemonstrations into sections and initializing training episodes to states\nsampled from different sections of demonstrations. Through moving the reset\nstates from the end to the beginning of demonstrations as the learning agent\nimproves its performance, ACED not only learns challenging manipulation tasks\nwith unseen initializations and goals, but also discovers novel solutions that\nare distinct from the demonstrations. In addition, ACED can be naturally\ncombined with other imitation learning methods to utilize expert demonstrations\nin a more efficient manner, and we show that a combination of ACED with\nbehavior cloning allows pick-and-place tasks to be learned with as few as 1\ndemonstration and block stacking tasks to be learned with 20 demonstrations.",
    "descriptor": "\nComments: Preprint, work in progress\n",
    "authors": [
      "Siyu Dai",
      "Andreas Hofmann",
      "Brian Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09159"
  },
  {
    "id": "arXiv:2106.09161",
    "title": "Mungojerrie: Reinforcement Learning of Linear-Time Objectives",
    "abstract": "Reinforcement learning synthesizes controllers without prior knowledge of the\nsystem. At each timestep, a reward is given. The controllers optimize the\ndiscounted sum of these rewards. Applying this class of algorithms requires\ndesigning a reward scheme, which is typically done manually. The designer must\nensure that their intent is accurately captured. This may not be trivial, and\nis prone to error. An alternative to this manual programming, akin to\nprogramming directly in assembly, is to specify the objective in a formal\nlanguage and have it \"compiled\" to a reward scheme. Mungojerrie\n($\\href{https://plv.colorado.edu/mungojerrie/}{plv.colorado.edu/mungojerrie}$)\nis a tool for testing reward schemes for $\\omega$-regular objectives on finite\nmodels. The tool contains reinforcement learning algorithms and a probabilistic\nmodel checker. Mungojerrie supports models specified in PRISM and\n$\\omega$-automata specified in HOA.",
    "descriptor": "\nComments: Mungojerrie is available at this https URL\n",
    "authors": [
      "Ernst Moritz Hahn",
      "Mateo Perez",
      "Sven Schewe",
      "Fabio Somenzi",
      "Ashutosh Trivedi",
      "Dominik Wojtczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09161"
  },
  {
    "id": "arXiv:2106.09164",
    "title": "mPyPl: Python Monadic Pipeline Library for Complex Functional Data  Processing",
    "abstract": "In this paper, we present a new Python library called mPyPl, which is\nintended to simplify complex data processing tasks using functional approach.\nThis library defines operations on lazy data streams of named dictionaries\nrepresented as generators (so-called multi-field datastreams), and allows\nenriching those data streams with more 'fields' in the process of data\npreparation and feature extraction. Thus, most data preparation tasks can be\nexpressed in the form of neat linear 'pipeline', similar in syntax to UNIX\npipes, or |> functional composition operator in F#.\nWe define basic operations on multi-field data streams, which resemble\nclassical monadic operations, and show similarity of the proposed approach to\nmonads in functional programming. We also show how the library was used in\ncomplex deep learning tasks of event detection in video, and discuss different\nevaluation strategies that allow for different compromises in terms of memory\nand performance.",
    "descriptor": "\nComments: Published in Microsoft Journal of Applied Research, Dec.2019., Vol. 12\n",
    "authors": [
      "Dmitry Soshnikov",
      "Yana Valieva"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09164"
  },
  {
    "id": "arXiv:2106.09166",
    "title": "Work in Progress: Mobile or FPGA? A Comprehensive Evaluation on Energy  Efficiency and a Unified Optimization Framework",
    "abstract": "Efficient deployment of Deep Neural Networks (DNNs) on edge devices (i.e.,\nFPGAs and mobile platforms) is very challenging, especially under a recent\nwitness of the increasing DNN model size and complexity. Although various\noptimization approaches have been proven to be effective in many DNNs on edge\ndevices, most state-of-the-art work focuses on ad-hoc optimizations, and there\nlacks a thorough study to comprehensively reveal the potentials and constraints\nof different edge devices when considering different optimizations. In this\npaper, we qualitatively and quantitatively compare the energy-efficiency of\nFPGA-based and mobile-based DNN executions, and provide detailed analysis.",
    "descriptor": "\nComments: Poster in the 27th IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS), 2021\n",
    "authors": [
      "Geng Yuan",
      "Peiyan Dong",
      "Mengshu Sun",
      "Wei Niu",
      "Zhengang Li",
      "Yuxuan Cai",
      "Jun Liu",
      "Weiwen Jiang",
      "Xue Lin",
      "Bin Ren",
      "Xulong Tang",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2106.09166"
  },
  {
    "id": "arXiv:2106.09170",
    "title": "A Survey on Semi-Supervised Learning for Delayed Partially Labelled Data  Streams",
    "abstract": "Unlabelled data appear in many domains and are particularly relevant to\nstreaming applications, where even though data is abundant, labelled data is\nrare. To address the learning problems associated with such data, one can\nignore the unlabelled data and focus only on the labelled data (supervised\nlearning); use the labelled data and attempt to leverage the unlabelled data\n(semi-supervised learning); or assume some labels will be available on request\n(active learning). The first approach is the simplest, yet the amount of\nlabelled data available will limit the predictive performance. The second\nrelies on finding and exploiting the underlying characteristics of the data\ndistribution. The third depends on an external agent to provide the required\nlabels in a timely fashion. This survey pays special attention to methods that\nleverage unlabelled data in a semi-supervised setting. We also discuss the\ndelayed labelling issue, which impacts both fully supervised and\nsemi-supervised methods. We propose a unified problem setting, discuss the\nlearning guarantees and existing methods, explain the differences between\nrelated problem settings. Finally, we review the current benchmarking practices\nand propose adaptations to enhance them.",
    "descriptor": "",
    "authors": [
      "Heitor Murilo Gomes",
      "Maciej Grzenda",
      "Rodrigo Mello",
      "Jesse Read",
      "Minh Huong Le Nguyen",
      "Albert Bifet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09170"
  },
  {
    "id": "arXiv:2106.09171",
    "title": "LiRA: Learning Visual Speech Representations from Audio through  Self-supervision",
    "abstract": "The large amount of audiovisual content being shared online today has drawn\nsubstantial attention to the prospect of audiovisual self-supervised learning.\nRecent works have focused on each of these modalities separately, while others\nhave attempted to model both simultaneously in a cross-modal fashion. However,\ncomparatively little attention has been given to leveraging one modality as a\ntraining objective to learn from the other. In this work, we propose Learning\nvisual speech Representations from Audio via self-supervision (LiRA).\nSpecifically, we train a ResNet+Conformer model to predict acoustic features\nfrom unlabelled visual speech. We find that this pre-trained model can be\nleveraged towards word-level and sentence-level lip-reading through feature\nextraction and fine-tuning experiments. We show that our approach significantly\noutperforms other self-supervised methods on the Lip Reading in the Wild (LRW)\ndataset and achieves state-of-the-art performance on Lip Reading Sentences 2\n(LRS2) using only a fraction of the total labelled data.",
    "descriptor": "\nComments: Accepted for publication at Interspeech 2021\n",
    "authors": [
      "Pingchuan Ma",
      "Rodrigo Mira",
      "Stavros Petridis",
      "Bj\u00f6rn W. Schuller",
      "Maja Pantic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.09171"
  },
  {
    "id": "arXiv:2106.09173",
    "title": "Cross-Language Code Search using Static and Dynamic Analyses",
    "abstract": "As code search permeates most activities in software development,code-to-code\nsearch has emerged to support using code as a query and retrieving similar code\nin the search results. Applications include duplicate code detection for\nrefactoring, patch identification for program repair, and language translation.\nExisting code-to-code search tools rely on static similarity approaches such as\nthe comparison of tokens and abstract syntax trees (AST) to approximate dynamic\nbehavior, leading to low precision. Most tools do not support cross-language\ncode-to-code search, and those that do, rely on machine learning models that\nrequire labeled training data.\nWe present Code-to-Code Search Across Languages (COSAL), a cross-language\ntechnique that uses both static and dynamic analyses to identify similar code\nand does not require a machine learning model. Code snippets are ranked using\nnon-dominated sorting based on code token similarity, structural similarity,\nand behavioral similarity. We empirically evaluate COSAL on two datasets of\n43,146Java and Python files and 55,499 Java files and find that 1) code search\nbased on non-dominated ranking of static and dynamic similarity measures is\nmore effective compared to single or weighted measures; and 2) COSAL has better\nprecision and recall compared to state-of-the-art within-language and\ncross-language code-to-code search tools. We explore the potential for using\nCOSAL on large open-source repositories and discuss scalability to more\nlanguages and similarity metrics, providing a gateway for\npractical,multi-language code-to-code search.",
    "descriptor": "\nComments: Accepted at FSE 2021; 13 pages, 4 figures, 8 tables\n",
    "authors": [
      "George Mathew",
      "Kathryn T. Stolee"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.09173"
  },
  {
    "id": "arXiv:2106.09174",
    "title": "Can I Be of Further Assistance? Using Unstructured Knowledge Access to  Improve Task-oriented Conversational Modeling",
    "abstract": "Most prior work on task-oriented dialogue systems are restricted to limited\ncoverage of domain APIs. However, users oftentimes have requests that are out\nof the scope of these APIs. This work focuses on responding to these\nbeyond-API-coverage user turns by incorporating external, unstructured\nknowledge sources. Our approach works in a pipelined manner with\nknowledge-seeking turn detection, knowledge selection, and response generation\nin sequence. We introduce novel data augmentation methods for the first two\nsteps and demonstrate that the use of information extracted from dialogue\ncontext improves the knowledge selection and end-to-end performances. Through\nexperiments, we achieve state-of-the-art performance for both automatic and\nhuman evaluation metrics on the DSTC9 Track 1 benchmark dataset, validating the\neffectiveness of our contributions.",
    "descriptor": "\nComments: Presented as a DIALDOC workshop paper at ACL 2021\n",
    "authors": [
      "Di Jin",
      "Seokhwan Kim",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09174"
  },
  {
    "id": "arXiv:2106.09175",
    "title": "Efficient and accurate KAM tori construction for the dissipative  spin-orbit problem using a map reduction",
    "abstract": "We consider the dissipative spin-orbit problem in Celestial Mechanics, which\ndescribes the rotational motion of a triaxial satellite moving on a Keplerian\norbit subject to tidal forcing and \"drift\".\nOur goal is to construct quasi-periodic solutions with fixed frequency,\nsatisfying appropriate conditions.\nWith the goal of applying rigorous KAM theory, we compute such quasi-periodic\nsolution with very high precision. To this end, we have developed a very\nefficient algorithm. The first step is to compute very accurately the return\nmap to a surface of section (using a high order Taylor's method with extended\nprecision). Then, we find an invariant curve for the return map using recent\nalgorithms that take advantage of the geometric features of the problem. This\nmethod is based on a rapidly convergent Newton's method which is guaranteed to\nconverge if the initial error is small enough. So, it is very suitable for a\ncontinuation algorithm.\nThe resulting algorithm is quite efficient. We only need to deal with a one\ndimensional function. If this function is discretized in $N$ points, the\nalgorithm requires $O(N \\log N) $ operations and $O(N) $ storage. The most\ncostly step (the numerical integration of the equation along a turn) is trivial\nto parallelize.\nThe main goal of the paper is to present the algorithms, implementation\ndetails and several sample results of runs.\nWe also present both a rigorous and a numerical comparison of the results of\naveraged and not averaged models.",
    "descriptor": "\nComments: 37 pages, 6 figures\n",
    "authors": [
      "Renato Calleja",
      "Alessandra Celletti",
      "Joan Gimeno",
      "Rafael de la Llave"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2106.09175"
  },
  {
    "id": "arXiv:2106.09177",
    "title": "Insights into Data through Model Behaviour: An Explainability-driven  Strategy for Data Auditing for Responsible Computer Vision Applications",
    "abstract": "In this study, we take a departure and explore an explainability-driven\nstrategy to data auditing, where actionable insights into the data at hand are\ndiscovered through the eyes of quantitative explainability on the behaviour of\na dummy model prototype when exposed to data. We demonstrate this strategy by\nauditing two popular medical benchmark datasets, and discover hidden data\nquality issues that lead deep learning models to make predictions for the wrong\nreasons. The actionable insights gained from this explainability driven data\nauditing strategy is then leveraged to address the discovered issues to enable\nthe creation of high-performing deep learning models with appropriate\nprediction behaviour. The hope is that such an explainability-driven strategy\ncan be complimentary to data-driven strategies to facilitate for more\nresponsible development of machine learning algorithms for computer vision\napplications.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Alexander Wong",
      "Adam Dorfman",
      "Paul McInnis",
      "Hayden Gunraj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09177"
  },
  {
    "id": "arXiv:2106.09178",
    "title": "The Fishnet Open Images Database: A Dataset for Fish Detection and  Fine-Grained Categorization in Fisheries",
    "abstract": "Camera-based electronic monitoring (EM) systems are increasingly being\ndeployed onboard commercial fishing vessels to collect essential data for\nfisheries management and regulation. These systems generate large quantities of\nvideo data which must be reviewed on land by human experts. Computer vision can\nassist this process by automatically detecting and classifying fish species,\nhowever the lack of existing public data in this domain has hindered progress.\nTo address this, we present the Fishnet Open Images Database, a large dataset\nof EM imagery for fish detection and fine-grained categorization onboard\ncommercial fishing vessels. The dataset consists of 86,029 images containing 34\nobject classes, making it the largest and most diverse public dataset of\nfisheries EM imagery to-date. It includes many of the characteristic challenges\nof EM data: visual similarity between species, skewed class distributions,\nharsh weather conditions, and chaotic crew activity. We evaluate the\nperformance of existing detection and classification algorithms and demonstrate\nthat the dataset can serve as a challenging benchmark for development of\ncomputer vision algorithms in fisheries. The dataset is available at\nhttps://www.fishnet.ai/.",
    "descriptor": "\nComments: In 8th Workshop on Fine-Grained Visual Categorization at CVPR 2021\n",
    "authors": [
      "Justin Kay",
      "Matt Merrifield"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09178"
  },
  {
    "id": "arXiv:2106.09179",
    "title": "Amortized Auto-Tuning: Cost-Efficient Transfer Optimization for  Hyperparameter Recommendation",
    "abstract": "With the surge in the number of hyperparameters and training times of modern\nmachine learning models, hyperparameter tuning is becoming increasingly\nexpensive. Although methods have been proposed to speed up tuning via knowledge\ntransfer, they typically require the final performance of hyperparameters and\ndo not focus on low-fidelity information. Nevertheless, this common practice is\nsuboptimal and can incur an unnecessary use of resources. It is more\ncost-efficient to instead leverage the low-fidelity tuning observations to\nmeasure inter-task similarity and transfer knowledge from existing to new tasks\naccordingly. However, performing multi-fidelity tuning comes with its own\nchallenges in the transfer setting: the noise in the additional observations\nand the need for performance forecasting. Therefore, we conduct a thorough\nanalysis of the multi-task multi-fidelity Bayesian optimization framework,\nwhich leads to the best instantiation--amortized auto-tuning (AT2). We further\npresent an offline-computed 27-task hyperparameter recommendation (HyperRec)\ndatabase to serve the community. Extensive experiments on HyperRec and other\nreal-world databases illustrate the effectiveness of our AT2 method.",
    "descriptor": "",
    "authors": [
      "Yuxin Xiao",
      "Eric P. Xing",
      "Willie Neiswanger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09179"
  },
  {
    "id": "arXiv:2106.09180",
    "title": "RHNAS: Realizable Hardware and Neural Architecture Search",
    "abstract": "The rapidly evolving field of Artificial Intelligence necessitates automated\napproaches to co-design neural network architecture and neural accelerators to\nmaximize system efficiency and address productivity challenges. To enable joint\noptimization of this vast space, there has been growing interest in\ndifferentiable NN-HW co-design. Fully differentiable co-design has reduced the\nresource requirements for discovering optimized NN-HW configurations, but fail\nto adapt to general hardware accelerator search spaces. This is due to the\nexistence of non-synthesizable (invalid) designs in the search space of many\nhardware accelerators. To enable efficient and realizable co-design of\nconfigurable hardware accelerators with arbitrary neural network search spaces,\nwe introduce RHNAS. RHNAS is a method that combines reinforcement learning for\nhardware optimization with differentiable neural architecture search. RHNAS\ndiscovers realizable NN-HW designs with 1.84x lower latency and 1.86x lower\nenergy-delay product (EDP) on ImageNet and 2.81x lower latency and 3.30x lower\nEDP on CIFAR-10 over the default hardware accelerator design.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Yash Akhauri",
      "Adithya Niranjan",
      "J. Pablo Mu\u00f1oz",
      "Suvadeep Banerjee",
      "Abhijit Davare",
      "Pasquale Cocchini",
      "Anton A. Sorokin",
      "Ravi Iyer",
      "Nilesh Jain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.09180"
  },
  {
    "id": "arXiv:2106.09184",
    "title": "A fourth-order compact time-splitting method for the Dirac equation with  time-dependent potentials",
    "abstract": "In this paper, we present an approach to deal with the dynamics of the Dirac\nequation with time-dependent electromagnetic potentials using the fourth-order\ncompact time-splitting method ($S_\\text{4c}$). To this purpose, the\ntime-ordering technique for time-dependent Hamiltonians is introduced, so that\nthe influence of the time-dependence could be limited to certain steps which\nare easy to treat. Actually, in the case of the Dirac equation, it turns out\nthat only those steps involving potentials need to be amended, and the scheme\nremains efficient, accurate, as well as easy to implement. Numerical examples\nin 1D and 2D are given to validate the scheme.",
    "descriptor": "\nComments: 24pages, 8 figures\n",
    "authors": [
      "Jia Yin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09184"
  },
  {
    "id": "arXiv:2106.09191",
    "title": "The Biot-Stokes coupling using total pressure: formulation, analysis and  application to interfacial flow in the eye",
    "abstract": "We consider a multiphysics model for the flow of Newtonian fluid coupled with\nBiot consolidation equations through an interface, and incorporating total\npressure as an unknown in the poroelastic region. A new mixed-primal finite\nelement scheme is proposed solving for the pairs fluid velocity - pressure and\ndisplacement - total poroelastic pressure using Stokes-stable elements, and\nwhere the formulation does not require Lagrange multipliers to set up the usual\ntransmission conditions on the interface. The stability and well-posedness of\nthe continuous and semi-discrete problems are analysed in detail. Our numerical\nstudy {is framed in} the context of different interfacial flow regimes in\nCartesian and axisymmetric coordinates that could eventually help describe\nearly morphologic changes associated with glaucoma development in canine\nspecies.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Ricardo Ruiz-Baier",
      "Matteo Taffetani",
      "Hans D. Westermeyer",
      "Ivan Yotov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.09191"
  },
  {
    "id": "arXiv:2106.09196",
    "title": "CoreUI: Interactive Core Training System with 3D Human Shape",
    "abstract": "We present an interactive core training system for core training using a\nmonocular camera image as input in this paper. It is commonly expensive to\ncapture human pose using depth cameras or multiple cameras with conventional\napproaches. To solve this issue, we employ the skinned multi-person linear\nmodel of human shape to recover the 3D human pose from 2D images using pose\nestimation and human mesh recovery approaches. In order to support the user in\nmaintaining the correct postures from target poses in the training, we adopt 3D\nhuman shape estimation for both the target image and input camera video. We\npropose CoreUI, a user interface for providing visual guidance showing the\ndifferences among the estimated targets and current human shapes in core\ntraining, which are visualized by markers at ten body parts with color changes.\nFrom our user studies, the proposed core training system is effective and\nconvenient compared with the conventional guidance of 2D skeletons.",
    "descriptor": "\nComments: 9 pages, 12 figures\n",
    "authors": [
      "Haoran Xie",
      "Atsushi Watatani",
      "Kazunori Miyata"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.09196"
  },
  {
    "id": "arXiv:2106.09198",
    "title": "Learning Perceptual Manifold of Fonts",
    "abstract": "Along the rapid development of deep learning techniques in generative models,\nit is becoming an urgent issue to combine machine intelligence with human\nintelligence to solve the practical applications. Motivated by this\nmethodology, this work aims to adjust the machine generated character fonts\nwith the effort of human workers in the perception study. Although numerous\nfonts are available online for public usage, it is difficult and challenging to\ngenerate and explore a font to meet the preferences for common users. To solve\nthe specific issue, we propose the perceptual manifold of fonts to visualize\nthe perceptual adjustment in the latent space of a generative model of fonts.\nIn our framework, we adopt the variational autoencoder network for the font\ngeneration. Then, we conduct a perceptual study on the generated fonts from the\nmulti-dimensional latent space of the generative model. After we obtained the\ndistribution data of specific preferences, we utilize manifold learning\napproach to visualize the font distribution. In contrast to the conventional\nuser interface in our user study, the proposed font-exploring user interface is\nefficient and helpful in the designated user preference.",
    "descriptor": "\nComments: 9 pages, 16 figures\n",
    "authors": [
      "Haoran Xie",
      "Yuki Fujita",
      "Kazunori Miyata"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09198"
  },
  {
    "id": "arXiv:2106.09199",
    "title": "A Two-stage Multi-modal Affect Analysis Framework for Children with  Autism Spectrum Disorder",
    "abstract": "Autism spectrum disorder (ASD) is a developmental disorder that influences\nthe communication and social behavior of a person in a way that those in the\nspectrum have difficulty in perceiving other people's facial expressions, as\nwell as presenting and communicating emotions and affect via their own faces\nand bodies. Some efforts have been made to predict and improve children with\nASD's affect states in play therapy, a common method to improve children's\nsocial skills via play and games. However, many previous works only used\npre-trained models on benchmark emotion datasets and failed to consider the\ndistinction in emotion between typically developing children and children with\nautism. In this paper, we present an open-source two-stage multi-modal approach\nleveraging acoustic and visual cues to predict three main affect states of\nchildren with ASD's affect states (positive, negative, and neutral) in\nreal-world play therapy scenarios, and achieved an overall accuracy of 72:40%.\nThis work presents a novel way to combine human expertise and machine\nintelligence for ASD affect recognition by proposing a two-stage schema.",
    "descriptor": "\nComments: 8 pages including reference; 8 figures\n",
    "authors": [
      "Jicheng Li",
      "Anjana Bhat",
      "Roghayeh Barmaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.09199"
  },
  {
    "id": "arXiv:2106.09201",
    "title": "Trilateral Attention Network for Real-time Medical Image Segmentation",
    "abstract": "Accurate segmentation of medical images into anatomically meaningful regions\nis critical for the extraction of quantitative indices or biomarkers. The\ncommon pipeline for segmentation comprises regions of interest detection stage\nand segmentation stage, which are independent of each other and typically\nperformed using separate deep learning networks. The performance of the\nsegmentation stage highly relies on the extracted set of spatial features and\nthe receptive fields. In this work, we propose an end-to-end network, called\nTrilateral Attention Network (TaNet), for real-time detection and segmentation\nin medical images. TaNet has a module for region localization, and three\nsegmentation pathways: 1) handcrafted pathway with hand-designed convolutional\nkernels, 2) detail pathway with regular convolutional kernels, and 3) a global\npathway to enlarge the receptive field. The first two pathways encode rich\nhandcrafted and low-level features extracted by hand-designed and regular\nkernels while the global pathway encodes high-level context information. By\njointly training the network for localization and segmentation using different\nsets of features, TaNet achieved superior performance, in terms of accuracy and\nspeed, when evaluated on an echocardiography dataset for cardiac segmentation.\nThe code and models will be made publicly available in TaNet Github page.",
    "descriptor": "",
    "authors": [
      "Ghada Zamzmi",
      "Vandana Sachdev",
      "Sameer Antani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09201"
  },
  {
    "id": "arXiv:2106.09203",
    "title": "Learning from Demonstration without Demonstrations",
    "abstract": "State-of-the-art reinforcement learning (RL) algorithms suffer from high\nsample complexity, particularly in the sparse reward case. A popular strategy\nfor mitigating this problem is to learn control policies by imitating a set of\nexpert demonstrations. The drawback of such approaches is that an expert needs\nto produce demonstrations, which may be costly in practice. To address this\nshortcoming, we propose Probabilistic Planning for Demonstration Discovery\n(P2D2), a technique for automatically discovering demonstrations without access\nto an expert. We formulate discovering demonstrations as a search problem and\nleverage widely-used planning algorithms such as Rapidly-exploring Random Tree\nto find demonstration trajectories. These demonstrations are used to initialize\na policy, then refined by a generic RL algorithm. We provide theoretical\nguarantees of P2D2 finding successful trajectories, as well as bounds for its\nsampling complexity. We experimentally demonstrate the method outperforms\nclassic and intrinsic exploration RL techniques in a range of classic control\nand robotics tasks, requiring only a fraction of exploration samples and\nachieving better asymptotic performance.",
    "descriptor": "\nComments: International Conference on Robotics and Automation (ICRA), 2021. arXiv admin note: substantial text overlap with arXiv:2001.06940\n",
    "authors": [
      "Tom Blau",
      "Gilad Francis",
      "Philippe Morere"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09203"
  },
  {
    "id": "arXiv:2106.09204",
    "title": "An Empirical Study on Hyperparameter Optimization for Fine-Tuning  Pre-trained Language Models",
    "abstract": "The performance of fine-tuning pre-trained language models largely depends on\nthe hyperparameter configuration. In this paper, we investigate the performance\nof modern hyperparameter optimization methods (HPO) on fine-tuning pre-trained\nlanguage models. First, we study and report three HPO algorithms' performances\non fine-tuning two state-of-the-art language models on the GLUE dataset. We\nfind that using the same time budget, HPO often fails to outperform grid search\ndue to two reasons: insufficient time budget and overfitting. We propose two\ngeneral strategies and an experimental procedure to systematically troubleshoot\nHPO's failure cases. By applying the procedure, we observe that HPO can succeed\nwith more appropriate settings in the search space and time budget; however, in\ncertain cases overfitting remains. Finally, we make suggestions for future\nwork. Our implementation can be found in\nhttps://github.com/microsoft/FLAML/tree/main/flaml/nlp/.",
    "descriptor": "\nComments: To appear in ACL-IJCNLP 2021\n",
    "authors": [
      "Xueqing Liu",
      "Chi Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09204"
  },
  {
    "id": "arXiv:2106.09206",
    "title": "QWin: Enforcing Tail Latency SLO at Shared Storage Backend",
    "abstract": "Consolidating latency-critical (LC) and best-effort (BE) tenants at storage\nbackend helps to increase resources utilization. Even if tenants use dedicated\nqueues and threads to achieve performance isolation, threads are still contend\nfor CPU cores. Therefore, we argue that it is necessary to partition cores\nbetween LC and BE tenants, and meanwhile each core is dedicated to run a\nthread. Expect for frequently changing bursty load, fluctuated service time at\nstorage backend also drastically changes the need of cores. In order to\nguarantee tail latency service level objectives (SLOs), the abrupt changing\nneed of cores must be satisfied immediately. Otherwise, tail latency SLO\nviolation happens. Unfortunately, partitioning-based approaches lack the\nability to react the changing need of cores, resulting in extreme spikes in\nlatency and SLO violation happens. In this paper, we present QWin, a tail\nlatency SLO aware core allocation to enforce tail latency SLO at shared storage\nbackend. QWin consists of an SLO-to-core calculation model that accurately\ncalculates the number of cores combining with definitive runtime load\ndetermined by a flexible request-based window, and an autonomous core\nallocation that adjusts cores at adaptive frequency by dynamically changing\ncore policies. When consolidating multiple LC and BE tenants, QWin outperforms\nthe-state-of-the-art approaches in guaranteeing tail latency SLO for LC tenants\nand meanwhile increasing bandwidth of BE tenants by up to 31x.",
    "descriptor": "\nComments: 14 pages, 11 figures\n",
    "authors": [
      "Liuying Ma",
      "Zhenqing Liu",
      "Jin Xiong",
      "Dejun Jiang"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2106.09206"
  },
  {
    "id": "arXiv:2106.09207",
    "title": "On the Power of Preconditioning in Sparse Linear Regression",
    "abstract": "Sparse linear regression is a fundamental problem in high-dimensional\nstatistics, but strikingly little is known about how to efficiently solve it\nwithout restrictive conditions on the design matrix. We consider the\n(correlated) random design setting, where the covariates are independently\ndrawn from a multivariate Gaussian $N(0,\\Sigma)$ with $\\Sigma : n \\times n$,\nand seek estimators $\\hat{w}$ minimizing $(\\hat{w}-w^*)^T\\Sigma(\\hat{w}-w^*)$,\nwhere $w^*$ is the $k$-sparse ground truth. Information theoretically, one can\nachieve strong error bounds with $O(k \\log n)$ samples for arbitrary $\\Sigma$\nand $w^*$; however, no efficient algorithms are known to match these guarantees\neven with $o(n)$ samples, without further assumptions on $\\Sigma$ or $w^*$. As\nfar as hardness, computational lower bounds are only known with worst-case\ndesign matrices. Random-design instances are known which are hard for the\nLasso, but these instances can generally be solved by Lasso after a simple\nchange-of-basis (i.e. preconditioning).\nIn this work, we give upper and lower bounds clarifying the power of\npreconditioning in sparse linear regression. First, we show that the\npreconditioned Lasso can solve a large class of sparse linear regression\nproblems nearly optimally: it succeeds whenever the dependency structure of the\ncovariates, in the sense of the Markov property, has low treewidth -- even if\n$\\Sigma$ is highly ill-conditioned. Second, we construct (for the first time)\nrandom-design instances which are provably hard for an optimally preconditioned\nLasso. In fact, we complete our treewidth classification by proving that for\nany treewidth-$t$ graph, there exists a Gaussian Markov Random Field on this\ngraph such that the preconditioned Lasso, with any choice of preconditioner,\nrequires $\\Omega(t^{1/20})$ samples to recover $O(\\log n)$-sparse signals when\ncovariates are drawn from this model.",
    "descriptor": "\nComments: 73 pages, 5 figures\n",
    "authors": [
      "Jonathan Kelner",
      "Frederic Koehler",
      "Raghu Meka",
      "Dhruv Rohatgi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09207"
  },
  {
    "id": "arXiv:2106.09208",
    "title": "External Service Sensing (ESS): Research Framework, Challenges and  Opportunities",
    "abstract": "The flourish of web-based services gave birth to the research area\n\\textit{services computing}, a rapidly-expanding academic community since\nnearly 20 years ago. Consensus has been reached on a set of representative\nresearch problems in services computing, such as service selection, service\ncomposition, service recommendation, and service quality prediction. An obvious\nfact is that most services keep constant changes to timely adapt to changes of\nexternal business/technical environment and changes of internal development\nstrategies. However, traditional services computing research does not consider\nsuch changes sufficiently. Many works regard services as \\textit{static}\nentities; this leads to the situation that some proposed models/algorithms do\nnot work in real world. Sensing various types of service changes is of great\nsignificance to the practicability and rationality of services computing\nresearch. In this paper, a new research problem \\textit{External Service\nSensing} (ESS) is defined to cope with various changes in services, and a\nresearch framework of ESS is presented to elaborate the scope and boundary of\nESS. This framework is composed of four orthogonal dimensions: sensing objects,\nsensing contents, sensing channels, and sensing techniques. Each concrete ESS\nproblem is defined by combining different values in these dimensions, and\nexisting research work related to service changes can be well adapted to this\nframework. Real-world case studies demonstrate the soundness of ESS and its\nframework. Finally, some challenges and opportunities in ESS research are\nlisted for researchers in the services computing community. To the best of our\nknowledge, this is the first time to systematically define service\nchange-related research as a standard services computing problem, and thus\nbroadening the research scope of services computing.",
    "descriptor": "",
    "authors": [
      "Zhongjie Wang",
      "Mingyi Liu",
      "Zhiying Tu",
      "Xiaofei Xu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.09208"
  },
  {
    "id": "arXiv:2106.09211",
    "title": "Square Root Principal Component Pursuit: Tuning-Free Noisy Robust Matrix  Recovery",
    "abstract": "We propose a new framework -- Square Root Principal Component Pursuit -- for\nlow-rank matrix recovery from observations corrupted with noise and outliers.\nInspired by the square root Lasso, this new formulation does not require prior\nknowledge of the noise level. We show that a single, universal choice of the\nregularization parameter suffices to achieve reconstruction error proportional\nto the (a priori unknown) noise level. In comparison, previous formulations\nsuch as stable PCP rely on noise-dependent parameters to achieve similar\nperformance, and are therefore challenging to deploy in applications where the\nnoise level is unknown. We validate the effectiveness of our new method through\nexperiments on simulated and real datasets. Our simulations corroborate the\nclaim that a universal choice of the regularization parameter yields near\noptimal performance across a range of noise levels, indicating that the\nproposed method outperforms the (somewhat loose) bound proved here.",
    "descriptor": "",
    "authors": [
      "Junhui Zhang",
      "Jingkai Yan",
      "John Wright"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.09211"
  },
  {
    "id": "arXiv:2106.09212",
    "title": "Long-Short Temporal Contrastive Learning of Video Transformers",
    "abstract": "Video transformers have recently emerged as a competitive alternative to 3D\nCNNs for video understanding. However, due to their large number of parameters\nand reduced inductive biases, these models require supervised pretraining on\nlarge-scale image datasets to achieve top performance. In this paper, we\nempirically demonstrate that self-supervised pretraining of video transformers\non video-only datasets can lead to action recognition results that are on par\nor better than those obtained with supervised pretraining on large-scale image\ndatasets, even massive ones such as ImageNet-21K. Since transformer-based\nmodels are effective at capturing dependencies over extended temporal spans, we\npropose a simple learning procedure that forces the model to match a long-term\nview to a short-term view of the same video. Our approach, named Long-Short\nTemporal Contrastive Learning (LSTCL), enables video transformers to learn an\neffective clip-level representation by predicting temporal context captured\nfrom a longer temporal extent. To demonstrate the generality of our findings,\nwe implement and validate our approach under three different self-supervised\ncontrastive learning frameworks (MoCo v3, BYOL, SimSiam) using two distinct\nvideo-transformer architectures, including an improved variant of the Swin\nTransformer augmented with space-time attention. We conduct a thorough ablation\nstudy and show that LSTCL achieves competitive performance on multiple video\nbenchmarks and represents a convincing alternative to supervised image-based\npretraining.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Jue Wang",
      "Gedas Bertasius",
      "Du Tran",
      "Lorenzo Torresani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09212"
  },
  {
    "id": "arXiv:2106.09218",
    "title": "DroidMorph: Are We Ready to Stop the Attack of Android Malware Clones?",
    "abstract": "The number of Android malware variants (clones) are on the rise and, to stop\nthis attack of clones we need to develop new methods and techniques for\nanalysing and detecting them. As a first step, we need to study how these\nmalware clones are generated. This will help us better anticipate and recognize\nthese clones. In this paper we present a new tool named DroidMorph, that\nprovides morphing of Android applications (APKs) at different level of\nabstractions, and can be used to create Android application (malware/benign)\nclones. As a case study we perform testing and evaluating resilience of current\ncommercial anti-malware products against attack of the Android malware clones\ngenerated by DroidMorph. We found that 8 out of 17 leading commercial\nanti-malware programs were not able to detect any of the morphed APKs. We hope\nthat DroidMorph will be used in future research, to improve Android malware\nclones analysis and detection, and help stop them.",
    "descriptor": "",
    "authors": [
      "Shahid Alam",
      "M. Zain ul Abideen",
      "Shahzad Saleem"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09218"
  },
  {
    "id": "arXiv:2106.09219",
    "title": "Decentralised Intelligence, Surveillance, and Reconnaissance in Unknown  Environments with Heterogeneous Multi-Robot Systems",
    "abstract": "We present the design and implementation of a decentralised, heterogeneous\nmulti-robot system for performing intelligence, surveillance and reconnaissance\n(ISR) in an unknown environment. The team consists of functionally specialised\nrobots that gather information and others that perform a mission-specific task,\nand is coordinated to achieve simultaneous exploration and exploitation in the\nunknown environment. We present a practical implementation of such a system,\nincluding decentralised inter-robot localisation, mapping, data fusion and\ncoordination. The system is demonstrated in an efficient distributed\nsimulation. We also describe an UAS platform for hardware experiments, and the\nongoing progress.",
    "descriptor": "\nComments: 7 pages, 6 figures. Presented at ICRA2021 Workshop on Robot Swarms in the Real World: From Design to Deployment\n",
    "authors": [
      "Ki Myung Brian Lee",
      "Felix H. Kong",
      "Ricardo Cannizzaro",
      "Jennifer L. Palmer",
      "David Johnson",
      "Chanyeol Yoo",
      "Robert Fitch"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09219"
  },
  {
    "id": "arXiv:2106.09223",
    "title": "Evaluating the Robustness of Bayesian Neural Networks Against Different  Types of Attacks",
    "abstract": "To evaluate the robustness gain of Bayesian neural networks on image\nclassification tasks, we perform input perturbations, and adversarial attacks\nto the state-of-the-art Bayesian neural networks, with a benchmark CNN model as\nreference. The attacks are selected to simulate signal interference and\ncyberattacks towards CNN-based machine learning systems. The result shows that\na Bayesian neural network achieves significantly higher robustness against\nadversarial attacks generated against a deterministic neural network model,\nwithout adversarial training. The Bayesian posterior can act as the safety\nprecursor of ongoing malicious activities. Furthermore, we show that the\nstochastic classifier after the deterministic CNN extractor has sufficient\nrobustness enhancement rather than a stochastic feature extractor before the\nstochastic classifier. This advises on utilizing stochastic layers in building\ndecision-making pipelines within a safety-critical domain.",
    "descriptor": "",
    "authors": [
      "Yutian Pang",
      "Sheng Cheng",
      "Jueming Hu",
      "Yongming Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09223"
  },
  {
    "id": "arXiv:2106.09225",
    "title": "On the Capabilities of Pointer Networks for Deep Deductive Reasoning",
    "abstract": "The importance of building neural networks that can learn to reason has been\nwell recognized in the neuro-symbolic community. In this paper, we apply neural\npointer networks for conducting reasoning over symbolic knowledge bases. In\ndoing so, we explore the benefits and limitations of encoder-decoder\narchitectures in general and pointer networks in particular for developing\naccurate, generalizable and robust neuro-symbolic reasoners. Based on our\nexperimental results, pointer networks performs remarkably well across multiple\nreasoning tasks while outperforming the previously reported state of the art by\na significant margin. We observe that the Pointer Networks preserve their\nperformance even when challenged with knowledge graphs of the domain/vocabulary\nit has never encountered before. To the best of our knowledge, this is the\nfirst study on neuro-symbolic reasoning using Pointer Networks. We hope our\nimpressive results on these reasoning problems will encourage broader\nexploration of pointer networks' capabilities for reasoning over more complex\nlogics and for other neuro-symbolic problems.",
    "descriptor": "\nComments: 14 pages, 1 figures\n",
    "authors": [
      "Monireh Ebrahimi",
      "Aaron Eberhart",
      "Pascal Hitzler"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09225"
  },
  {
    "id": "arXiv:2106.09226",
    "title": "Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis  of Head and Prompt Tuning",
    "abstract": "Pretrained language models have achieved state-of-the-art performance when\nadapted to a downstream NLP task. However, theoretical analysis of these models\nis scarce and challenging since the pretraining and downstream tasks can be\nvery different. We propose an analysis framework that links the pretraining and\ndownstream tasks with an underlying latent variable generative model of text --\nthe downstream classifier must recover a function of the posterior distribution\nover the latent variables. We analyze head tuning (learning a classifier on top\nof the frozen pretrained model) and prompt tuning in this setting. The\ngenerative model in our analysis is either a Hidden Markov Model (HMM) or an\nHMM augmented with a latent memory component, motivated by long-term\ndependencies in natural language. We show that 1) under certain non-degeneracy\nconditions on the HMM, simple classification heads can solve the downstream\ntask, 2) prompt tuning obtains downstream guarantees with weaker non-degeneracy\nconditions, and 3) our recovery guarantees for the memory-augmented HMM are\nstronger than for the vanilla HMM because task-relevant information is easier\nto recover from the long-term memory. Experiments on synthetically generated\ndata from HMMs back our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Colin Wei",
      "Sang Michael Xie",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09226"
  },
  {
    "id": "arXiv:2106.09227",
    "title": "Current Challenges and Future Directions in Podcast Information Access",
    "abstract": "Podcasts are spoken documents across a wide-range of genres and styles, with\ngrowing listenership across the world, and a rapidly lowering barrier to entry\nfor both listeners and creators. The great strides in search and recommendation\nin research and industry have yet to see impact in the podcast space, where\nrecommendations are still largely driven by word of mouth. In this perspective\npaper, we highlight the many differences between podcasts and other media, and\ndiscuss our perspective on challenges and future research directions in the\ndomain of podcast information access.",
    "descriptor": "\nComments: SIGIR 2021\n",
    "authors": [
      "Rosie Jones",
      "Hamed Zamani",
      "Markus Schedl",
      "Ching-Wei Chen",
      "Sravana Reddy",
      "Ann Clifton",
      "Jussi Karlgren",
      "Helia Hashemi",
      "Aasish Pappu",
      "Zahra Nazari",
      "Longqi Yang",
      "Oguz Semerci",
      "Hugues Bouchard",
      "Ben Carterette"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.09227"
  },
  {
    "id": "arXiv:2106.09229",
    "title": "An Evaluation of Self-Supervised Pre-Training for Skin-Lesion Analysis",
    "abstract": "Self-supervised pre-training appears as an advantageous alternative to\nsupervised pre-trained for transfer learning. By synthesizing annotations on\npretext tasks, self-supervision allows to pre-train models on large amounts of\npseudo-labels before fine-tuning them on the target task. In this work, we\nassess self-supervision for the diagnosis of skin lesions, comparing three\nself-supervised pipelines to a challenging supervised baseline, on five test\ndatasets comprising in- and out-of-distribution samples. Our results show that\nself-supervision is competitive both in improving accuracies and in reducing\nthe variability of outcomes. Self-supervision proves particularly useful for\nlow training data scenarios ($<1\\,500$ and $<150$ samples), where its ability\nto stabilize the outcomes is essential to provide sound results.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Levy Chaves",
      "Alceu Bissoto",
      "Eduardo Valle",
      "Sandra Avila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09229"
  },
  {
    "id": "arXiv:2106.09230",
    "title": "JSI at the FinSim-2 task: Ontology-Augmented Financial Concept  Classification",
    "abstract": "Ontologies are increasingly used for machine reasoning over the last few\nyears. They can provide explanations of concepts or be used for concept\nclassification if there exists a mapping from the desired labels to the\nrelevant ontology. Another advantage of using ontologies is that they do not\nneed a learning process, meaning that we do not need the train data or time\nbefore using them. This paper presents a practical use of an ontology for a\nclassification problem from the financial domain. It first transforms a given\nontology to a graph and proceeds with generalization with the aim to find\ncommon semantic descriptions of the input sets of financial concepts.\nWe present a solution to the shared task on Learning Semantic Similarities\nfor the Financial Domain (FinSim-2 task). The task is to design a system that\ncan automatically classify concepts from the Financial domain into the most\nrelevant hypernym concept in an external ontology - the Financial Industry\nBusiness Ontology. We propose a method that maps given concepts to the\nmentioned ontology and performs a graph search for the most relevant hypernyms.\nWe also employ a word vectorization method and a machine learning classifier to\nsupplement the method with a ranked list of labels for each concept.",
    "descriptor": "",
    "authors": [
      "Timen Stepi\u0161nik Perdih",
      "Senja Pollak",
      "Bla\u017e \\v{Skrlj}"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09230"
  },
  {
    "id": "arXiv:2106.09231",
    "title": "Knowledgeable or Educated Guess? Revisiting Language Models as Knowledge  Bases",
    "abstract": "Previous literatures show that pre-trained masked language models (MLMs) such\nas BERT can achieve competitive factual knowledge extraction performance on\nsome datasets, indicating that MLMs can potentially be a reliable knowledge\nsource. In this paper, we conduct a rigorous study to explore the underlying\npredicting mechanisms of MLMs over different extraction paradigms. By\ninvestigating the behaviors of MLMs, we find that previous decent performance\nmainly owes to the biased prompts which overfit dataset artifacts. Furthermore,\nincorporating illustrative cases and external contexts improve knowledge\nprediction mainly due to entity type guidance and golden answer leakage. Our\nfindings shed light on the underlying predicting mechanisms of MLMs, and\nstrongly question the previous conclusion that current MLMs can potentially\nserve as reliable factual knowledge bases.",
    "descriptor": "\nComments: Accepted to ACL2021(main conference)\n",
    "authors": [
      "Boxi Cao",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun",
      "Lingyong Yan",
      "Meng Liao",
      "Tong Xue",
      "Jin Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09231"
  },
  {
    "id": "arXiv:2106.09232",
    "title": "Text2Event: Controllable Sequence-to-Structure Generation for End-to-end  Event Extraction",
    "abstract": "Event extraction is challenging due to the complex structure of event records\nand the semantic gap between text and event. Traditional methods usually\nextract event records by decomposing the complex structure prediction task into\nmultiple subtasks. In this paper, we propose Text2Event, a\nsequence-to-structure generation paradigm that can directly extract events from\nthe text in an end-to-end manner. Specifically, we design a\nsequence-to-structure network for unified event extraction, a constrained\ndecoding algorithm for event knowledge injection during inference, and a\ncurriculum learning algorithm for efficient model learning. Experimental\nresults show that, by uniformly modeling all tasks in a single model and\nuniversally predicting different labels, our method can achieve competitive\nperformance using only record-level annotations in both supervised learning and\ntransfer learning settings.",
    "descriptor": "\nComments: Accepted to ACL2021 (main conference)\n",
    "authors": [
      "Yaojie Lu",
      "Hongyu Lin",
      "Jin Xu",
      "Xianpei Han",
      "Jialong Tang",
      "Annan Li",
      "Le Sun",
      "Meng Liao",
      "Shaoyi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09232"
  },
  {
    "id": "arXiv:2106.09233",
    "title": "De-biasing Distantly Supervised Named Entity Recognition via Causal  Intervention",
    "abstract": "Distant supervision tackles the data bottleneck in NER by automatically\ngenerating training instances via dictionary matching. Unfortunately, the\nlearning of DS-NER is severely dictionary-biased, which suffers from spurious\ncorrelations and therefore undermines the effectiveness and the robustness of\nthe learned models. In this paper, we fundamentally explain the dictionary bias\nvia a Structural Causal Model (SCM), categorize the bias into intra-dictionary\nand inter-dictionary biases, and identify their causes. Based on the SCM, we\nlearn de-biased DS-NER via causal interventions. For intra-dictionary bias, we\nconduct backdoor adjustment to remove the spurious correlations introduced by\nthe dictionary confounder. For inter-dictionary bias, we propose a causal\ninvariance regularizer which will make DS-NER models more robust to the\nperturbation of dictionaries. Experiments on four datasets and three DS-NER\nmodels show that our method can significantly improve the performance of\nDS-NER.",
    "descriptor": "\nComments: Accepted to ACL2021(main conference)\n",
    "authors": [
      "Wenkai Zhang",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09233"
  },
  {
    "id": "arXiv:2106.09234",
    "title": "Denoising Distantly Supervised Named Entity Recognition via a  Hypergeometric Probabilistic Model",
    "abstract": "Denoising is the essential step for distant supervision based named entity\nrecognition. Previous denoising methods are mostly based on instance-level\nconfidence statistics, which ignore the variety of the underlying noise\ndistribution on different datasets and entity types. This makes them difficult\nto be adapted to high noise rate settings. In this paper, we propose\nHypergeometric Learning (HGL), a denoising algorithm for distantly supervised\nNER that takes both noise distribution and instance-level confidence into\nconsideration. Specifically, during neural network training, we naturally model\nthe noise samples in each batch following a hypergeometric distribution\nparameterized by the noise-rate. Then each instance in the batch is regarded as\neither correct or noisy one according to its label confidence derived from\nprevious training step, as well as the noise distribution in this sampled\nbatch. Experiments show that HGL can effectively denoise the weakly-labeled\ndata retrieved from distant supervision, and therefore results in significant\nimprovements on the trained models.",
    "descriptor": "\nComments: Accepted to AAAI2021\n",
    "authors": [
      "Wenkai Zhang",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun",
      "Huidan Liu",
      "Zhicheng Wei",
      "Nicholas Jing Yuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09234"
  },
  {
    "id": "arXiv:2106.09236",
    "title": "Efficient Conformer with Prob-Sparse Attention Mechanism for  End-to-EndSpeech Recognition",
    "abstract": "End-to-end models are favored in automatic speech recognition (ASR) because\nof their simplified system structure and superior performance. Among these\nmodels, Transformer and Conformer have achieved state-of-the-art recognition\naccuracy in which self-attention plays a vital role in capturing important\nglobal information. However, the time and memory complexity of self-attention\nincreases squarely with the length of the sentence. In this paper, a\nprob-sparse self-attention mechanism is introduced into Conformer to sparse the\ncomputing process of self-attention in order to accelerate inference speed and\nreduce space consumption. Specifically, we adopt a Kullback-Leibler divergence\nbased sparsity measurement for each query to decide whether we compute the\nattention function on this query. By using the prob-sparse attention mechanism,\nwe achieve impressively 8% to 45% inference speed-up and 15% to 45% memory\nusage reduction of the self-attention module of Conformer Transducer while\nmaintaining the same level of error rate.",
    "descriptor": "",
    "authors": [
      "Xiong Wang",
      "Sining Sun",
      "Lei Xie",
      "Long Ma"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.09236"
  },
  {
    "id": "arXiv:2106.09237",
    "title": "Towards Assurance-Driven Architectural Decomposition of Software Systems",
    "abstract": "Computer systems are so complex, so they are usually designed and analyzed in\nterms of layers of abstraction. Complexity is still a challenge facing logical\nreasoning tools that are used to find software design flaws and implementation\nbugs. Abstraction is also a common technique for scaling those tools to more\ncomplex systems. However, the abstractions used in the design phase of systems\nare in many cases different from those used for assurance. In this paper we\nargue that different software quality assurance techniques operate on different\naspects of software systems. To facilitate assurance, and for a smooth\nintegration of assurance tools into the Software Development Lifecycle (SDLC),\nwe present a 4-dimensional meta-architecture that separates computational,\ncoordination, and stateful software artifacts early on in the design stage. We\nenumerate some of the design and assurance challenges that can be addressed by\nthis meta-architecture, and demonstrate it on the high-level design of a simple\nfile system.",
    "descriptor": "\nComments: MAPSOD'21 preprint\n",
    "authors": [
      "Ramy Shahin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.09237"
  },
  {
    "id": "arXiv:2106.09241",
    "title": "CoANE: Modeling Context Co-occurrence for Attributed Network Embedding",
    "abstract": "Attributed network embedding (ANE) is to learn low-dimensional vectors so\nthat not only the network structure but also node attributes can be preserved\nin the embedding space. Existing ANE models do not consider the specific\ncombination between graph structure and attributes. While each node has its\nstructural characteristics, such as highly-interconnected neighbors along with\ntheir certain patterns of attribute distribution, each node's neighborhood\nshould be not only depicted by multi-hop nodes, but consider certain clusters\nor social circles. To model such information, in this paper, we propose a novel\nANE model, Context Co-occurrence-aware Attributed Network Embedding (CoANE).\nThe basic idea of CoANE is to model the context attributes that each node's\ninvolved diverse patterns, and apply the convolutional mechanism to encode\npositional information by treating each attribute as a channel. The learning of\ncontext co-occurrence can capture the latent social circles of each node. To\nbetter encode structural and semantic knowledge of nodes, we devise a three-way\nobjective function, consisting of positive graph likelihood, contextual\nnegative sampling, and attribute reconstruction. We conduct experiments on five\nreal datasets in the tasks of link prediction, node label classification, and\nnode clustering. The results exhibit that CoANE can significantly outperform\nstate-of-the-art ANE models.",
    "descriptor": "\nComments: Accepted to IEEE TKDE 2021. Code can be accessed via this https URL\n",
    "authors": [
      "I-Chung Hsieh",
      "Cheng-Te Li"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09241"
  },
  {
    "id": "arXiv:2106.09242",
    "title": "CoCoFuzzing: Testing Neural Code Models with Coverage-Guided Fuzzing",
    "abstract": "Deep learning-based code processing models have shown good performance for\ntasks such as predicting method names, summarizing programs, and comment\ngeneration. However, despite the tremendous progress, deep learning models are\noften prone to adversarial attacks, which can significantly threaten the\nrobustness and generalizability of these models by leading them to\nmisclassification with unexpected inputs. To address the above issue, many deep\nlearning testing approaches have been proposed, however, these approaches\nmainly focus on testing deep learning applications in the domains of image,\naudio, and text analysis, etc., which cannot be directly applied to neural\nmodels for code due to the unique properties of programs. In this paper, we\npropose a coverage-based fuzzing framework, CoCoFuzzing, for testing deep\nlearning-based code processing models. In particular, we first propose ten\nmutation operators to automatically generate valid and semantically preserving\nsource code examples as tests; then we propose a neuron coverage-based approach\nto guide the generation of tests. We investigate the performance of CoCoFuzzing\non three state-of-the-art neural code models, i.e., NeuralCodeSum, CODE2SEQ,\nand CODE2VEC. Our experiment results demonstrate that CoCoFuzzing can generate\nvalid and semantically preserving source code examples for testing the\nrobustness and generalizability of these models and improve the neuron\ncoverage. Moreover, these tests can be used to improve the performance of the\ntarget neural code models through adversarial retraining.",
    "descriptor": "",
    "authors": [
      "Moshi Wei",
      "Yuchao Huang",
      "Jinqiu Yang",
      "Junjie Wang",
      "Song Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.09242"
  },
  {
    "id": "arXiv:2106.09244",
    "title": "Deep Contrastive Graph Representation via Adaptive Homotopy Learning",
    "abstract": "Homotopy model is an excellent tool exploited by diverse research works in\nthe field of machine learning. However, its flexibility is limited due to lack\nof adaptiveness, i.e., manual fixing or tuning the appropriate homotopy\ncoefficients. To address the problem above, we propose a novel adaptive\nhomotopy framework (AH) in which the Maclaurin duality is employed, such that\nthe homotopy parameters can be adaptively obtained. Accordingly, the proposed\nAH can be widely utilized to enhance the homotopy-based algorithm. In\nparticular, in this paper, we apply AH to contrastive learning (AHCL) such that\nit can be effectively transferred from weak-supervised learning (given label\npriori) to unsupervised learning, where soft labels of contrastive learning are\ndirectly and adaptively learned. Accordingly, AHCL has the adaptive ability to\nextract deep features without any sort of prior information. Consequently, the\naffinity matrix formulated by the related adaptive labels can be constructed as\nthe deep Laplacian graph that incorporates the topology of deep representations\nfor the inputs. Eventually, extensive experiments on benchmark datasets\nvalidate the superiority of our method.",
    "descriptor": "\nComments: 9 pages,4 figures\n",
    "authors": [
      "Rui Zhang",
      "Chengjun Lu",
      "Ziheng Jiao",
      "Xuelong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09244"
  },
  {
    "id": "arXiv:2106.09245",
    "title": "A Material Mask Overlay Strategy for Close to Binary Design-dependent  Pressure-loaded Optimized Topologies",
    "abstract": "This paper presents a Material Mask Overlay Strategy topology optimization\napproach with improved material assignment at the element level for achieving\nclose to black-and-white designs for pressure-loaded problems. Hexagonal\nelements are employed to parametrize the design domain as this tessellation\nprovides nonsingular local connectivity. Elliptical negative masks are used to\nfind the optimized material layout. The material dilation and material erosion\nvariables of each mask are systematically varied in association with a\ngray-scale measure constraint to achieve designs close to 0-1. Darcy's law in\nassociation with a drainage term is used to formulate the pressure field. The\nobtained pressure field is converted into the consistent nodal forces using\nWachspress shape functions. Sensitivities of the objective and pressure load\nare evaluated using the adjoint-variable method. The approach is demonstrated\nby solving various pressure-loaded structures and pressure-actuated compliant\nmechanisms. Compliance is minimized for loadbearing structures, whereas a\nmulticriteria objective is minimized for mechanism designs.",
    "descriptor": "\nComments: 22 pages, 16 figures\n",
    "authors": [
      "Prabhat Kumar",
      "Anupam Saxena"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.09245"
  },
  {
    "id": "arXiv:2106.09246",
    "title": "Federated CycleGAN for Privacy-Preserving Image-to-Image Translation",
    "abstract": "Unsupervised image-to-image translation methods such as CycleGAN learn to\nconvert images from one domain to another using unpaired training data sets\nfrom different domains. Unfortunately, these approaches still require centrally\ncollected unpaired records, potentially violating privacy and security issues.\nAlthough the recent federated learning (FL) allows a neural network to be\ntrained without data exchange, the basic assumption of the FL is that all\nclients have their own training data from a similar domain, which is different\nfrom our image-to-image translation scenario in which each client has images\nfrom its unique domain and the goal is to learn image translation between\ndifferent domains without accessing the target domain data. To address this,\nhere we propose a novel federated CycleGAN architecture that can learn image\ntranslation in an unsupervised manner while maintaining the data privacy.\nSpecifically, our approach arises from a novel observation that CycleGAN loss\ncan be decomposed into the sum of client specific local objectives that can be\nevaluated using only their data. This local objective decomposition allows\nmultiple clients to participate in federated CycleGAN training without\nsacrificing performance. Furthermore, our method employs novel switchable\ngenerator and discriminator architecture using Adaptive Instance Normalization\n(AdaIN) that significantly reduces the band-width requirement of the federated\nlearning. Our experimental results on various unsupervised image translation\ntasks show that our federated CycleGAN provides comparable performance compared\nto the non-federated counterpart.",
    "descriptor": "",
    "authors": [
      "Joonyoung Song",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09246"
  },
  {
    "id": "arXiv:2106.09248",
    "title": "X-FACT: A New Benchmark Dataset for Multilingual Fact Checking",
    "abstract": "In this work, we introduce X-FACT: the largest publicly available\nmultilingual dataset for factual verification of naturally existing real-world\nclaims. The dataset contains short statements in 25 languages and is labeled\nfor veracity by expert fact-checkers. The dataset includes a multilingual\nevaluation benchmark that measures both out-of-domain generalization, and\nzero-shot capabilities of the multilingual models. Using state-of-the-art\nmultilingual transformer-based models, we develop several automated\nfact-checking models that, along with textual claims, make use of additional\nmetadata and evidence from news stories retrieved using a search engine.\nEmpirically, our best model attains an F-score of around 40%, suggesting that\nour dataset is a challenging benchmark for evaluation of multilingual\nfact-checking models.",
    "descriptor": "\nComments: ACL 2021; For data and code, see this https URL\n",
    "authors": [
      "Ashim Gupta",
      "Vivek Srikumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09248"
  },
  {
    "id": "arXiv:2106.09249",
    "title": "Invisible for both Camera and LiDAR: Security of Multi-Sensor Fusion  based Perception in Autonomous Driving Under Physical-World Attacks",
    "abstract": "In Autonomous Driving (AD) systems, perception is both security and safety\ncritical. Despite various prior studies on its security issues, all of them\nonly consider attacks on camera- or LiDAR-based AD perception alone. However,\nproduction AD systems today predominantly adopt a Multi-Sensor Fusion (MSF)\nbased design, which in principle can be more robust against these attacks under\nthe assumption that not all fusion sources are (or can be) attacked at the same\ntime. In this paper, we present the first study of security issues of MSF-based\nperception in AD systems. We directly challenge the basic MSF design assumption\nabove by exploring the possibility of attacking all fusion sources\nsimultaneously. This allows us for the first time to understand how much\nsecurity guarantee MSF can fundamentally provide as a general defense strategy\nfor AD perception.\nWe formulate the attack as an optimization problem to generate a\nphysically-realizable, adversarial 3D-printed object that misleads an AD system\nto fail in detecting it and thus crash into it. We propose a novel attack\npipeline that addresses two main design challenges: (1) non-differentiable\ntarget camera and LiDAR sensing systems, and (2) non-differentiable cell-level\naggregated features popularly used in LiDAR-based AD perception. We evaluate\nour attack on MSF included in representative open-source industry-grade AD\nsystems in real-world driving scenarios. Our results show that the attack\nachieves over 90% success rate across different object types and MSF. Our\nattack is also found stealthy, robust to victim positions, transferable across\nMSF algorithms, and physical-world realizable after being 3D-printed and\ncaptured by LiDAR and camera devices. To concretely assess the end-to-end\nsafety impact, we further perform simulation evaluation and show that it can\ncause a 100% vehicle collision rate for an industry-grade AD system.",
    "descriptor": "\nComments: Accepted by IEEE S&P 2021\n",
    "authors": [
      "Yulong Cao*",
      "Ningfei Wang*",
      "Chaowei Xiao*",
      "Dawei Yang*",
      "Jin Fang",
      "Ruigang Yang",
      "Qi Alfred Chen",
      "Mingyan Liu",
      "Bo Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09249"
  },
  {
    "id": "arXiv:2106.09251",
    "title": "Optical Mouse: 3D Mouse Pose From Single-View Video",
    "abstract": "We present a method to infer the 3D pose of mice, including the limbs and\nfeet, from monocular videos. Many human clinical conditions and their\ncorresponding animal models result in abnormal motion, and accurately measuring\n3D motion at scale offers insights into health. The 3D poses improve\nclassification of health-related attributes over 2D representations. The\ninferred poses are accurate enough to estimate stride length even when the feet\nare mostly occluded. This method could be applied as part of a continuous\nmonitoring system to non-invasively measure animal health.",
    "descriptor": "",
    "authors": [
      "Bo Hu",
      "Bryan Seybold",
      "Shan Yang",
      "David Ross",
      "Avneesh Sud",
      "Graham Ruby",
      "Yi Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09251"
  },
  {
    "id": "arXiv:2106.09252",
    "title": "Temporal Logic Planning for Minimum-Time Positioning of Multiple  Threat-Seduction Decoys",
    "abstract": "Reusable decoys offer a cost-effective alternative to the single-use hardware\ncommonly applied to protect surface assets from threats. Such decoys portray\nfake assets to lure threats away from the true asset. To deceive a threat, a\ndecoy first has to position itself such that it can break the radar lock.\nConsidering multiple simultaneous threats, this paper introduces an approach\nfor controlling multiple decoys to minimise the time required to break the\nlocks of all the threats. The method includes the optimal allocation of one\ndecoy to every threat with an assignment procedure that provides local position\nconstraints to guarantee collision avoidance and thereby decouples the control\nof the decoys. A crude model of a decoy with uncertainty is considered for\nmotion planning. The task of a decoy reaching a state in which the lock of the\nassigned threat can be broken is formulated as a temporal logic specification.\nTo this end, the requirements to complete the task are modelled as time-varying\nset-membership constraints. The temporal and logical combination of the\nconstraints is encoded in a mixed-integer optimisation problem. To demonstrate\nthe results a simulated case study is provided.",
    "descriptor": "",
    "authors": [
      "Tony A. Wood",
      "Mitchell Khoo",
      "Elad Michael",
      "Chris Manzie",
      "Iman Shames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.09252"
  },
  {
    "id": "arXiv:2106.09256",
    "title": "Seeing Differently, Acting Similarly: Imitation Learning with  Heterogeneous Observations",
    "abstract": "In many real-world imitation learning tasks, the demonstrator and the learner\nhave to act in different but full observation spaces. This situation generates\nsignificant obstacles for existing imitation learning approaches to work, even\nwhen they are combined with traditional space adaptation techniques. The main\nchallenge lies in bridging expert's occupancy measures to learner's dynamically\nchanging occupancy measures under the different observation spaces. In this\nwork, we model the above learning problem as Heterogeneous Observations\nImitation Learning (HOIL). We propose the Importance Weighting with REjection\n(IWRE) algorithm based on the techniques of importance-weighting, learning with\nrejection, and active querying to solve the key challenge of occupancy measure\nmatching. Experimental results show that IWRE can successfully solve HOIL\ntasks, including the challenging task of transforming the vision-based\ndemonstrations to random access memory (RAM)-based policies under the Atari\ndomain.",
    "descriptor": "\nComments: 17 pages, 25 figures\n",
    "authors": [
      "Xin-Qiang Cai",
      "Yao-Xiang Ding",
      "Zi-Xuan Chen",
      "Yuan Jiang",
      "Masashi Sugiyama",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09256"
  },
  {
    "id": "arXiv:2106.09257",
    "title": "Learning Robot Exploration Strategy with 4D Point-Clouds-like  Information as Observations",
    "abstract": "Being able to explore unknown environments is a requirement for fully\nautonomous robots. Many learning-based methods have been proposed to learn an\nexploration strategy. In the frontier-based exploration, learning algorithms\ntend to learn the optimal or near-optimal frontier to explore. Most of these\nmethods represent the environments as fixed size images and take these as\ninputs to neural networks. However, the size of environments is usually\nunknown, which makes these methods fail to generalize to real world scenarios.\nTo address this issue, we present a novel state representation method based on\n4D point-clouds-like information, including the locations, frontier, and\ndistance information. We also design a neural network that can process these 4D\npoint-clouds-like information and generate the estimated value for each\nfrontier. Then this neural network is trained using the typical reinforcement\nlearning framework. We test the performance of our proposed method by comparing\nit with other five methods and test its scalability on a map that is much\nlarger than maps in the training set. The experiment results demonstrate that\nour proposed method needs shorter average traveling distances to explore whole\nenvironments and can be adopted in maps with arbitrarily sizes.",
    "descriptor": "",
    "authors": [
      "Zhaoting Li",
      "Tingguang Li",
      "Jiankun Wang",
      "Max Q.-H. Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09257"
  },
  {
    "id": "arXiv:2106.09258",
    "title": "Knowledge Graphs and Machine Learning in biased C4I applications",
    "abstract": "This paper introduces our position on the critical issue of bias that\nrecently appeared in AI applications. Specifically, we discuss the combination\nof current technologies used in AI applications i.e., Machine Learning and\nKnowledge Graphs, and point to their involvement in (de)biased applications of\nthe C4I domain. Although this is a wider problem that currently emerges from\ndifferent application domains, bias appears more critical in C4I than in others\ndue to its security-related nature. While proposing certain actions to be taken\ntowards debiasing C4I applications, we acknowledge the immature aspect of this\ntopic within the Knowledge Graph and Semantic Web communities.",
    "descriptor": "",
    "authors": [
      "Evangelos Paparidis",
      "Konstantinos Kotis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09258"
  },
  {
    "id": "arXiv:2106.09259",
    "title": "A Random CNN Sees Objects: One Inductive Bias of CNN and Its  Applications",
    "abstract": "This paper starts by revealing a surprising finding: without any learning, a\nrandomly initialized CNN can localize objects surprisingly well. That is, a CNN\nhas an inductive bias to naturally focus on objects, named as Tobias (``The\nobject is at sight'') in this paper. This empirical inductive bias is further\nanalyzed and successfully applied to self-supervised learning. A CNN is\nencouraged to learn representations that focus on the foreground object, by\ntransforming every image into various versions with different backgrounds,\nwhere the foreground and background separation is guided by Tobias.\nExperimental results show that the proposed Tobias significantly improves\ndownstream tasks, especially for object detection. This paper also shows that\nTobias has consistent improvements on training sets of different sizes, and is\nmore resilient to changes in image augmentations. Our codes will be available\nat https://github.com/CupidJay/Tobias.",
    "descriptor": "\nComments: 17 pages, 9 figures, 10 tables\n",
    "authors": [
      "Yun-Hao Cao",
      "Jianxin Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09259"
  },
  {
    "id": "arXiv:2106.09260",
    "title": "Joining datasets via data augmentation in the label space for neural  networks",
    "abstract": "Most, if not all, modern deep learning systems restrict themselves to a\nsingle dataset for neural network training and inference. In this article, we\nare interested in systematic ways to join datasets that are made of similar\npurposes. Unlike previous published works that ubiquitously conduct the dataset\njoining in the uninterpretable latent vectorial space, the core to our method\nis an augmentation procedure in the label space. The primary challenge to\naddress the label space for dataset joining is the discrepancy between labels:\nnon-overlapping label annotation sets, different labeling granularity or\nhierarchy and etc. Notably we propose a new technique leveraging artificially\ncreated knowledge graph, recurrent neural networks and policy gradient that\nsuccessfully achieve the dataset joining in the label space. Empirical results\non both image and text classification justify the validity of our approach.",
    "descriptor": "\nComments: Accepted in ICML 2021. Jake Zhao and Mingfeng Ou contributed equally\n",
    "authors": [
      "Jake Zhao",
      "Mingfeng Ou",
      "Linji Xue",
      "Yunkai Cui",
      "Sai Wu",
      "Gang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09260"
  },
  {
    "id": "arXiv:2106.09261",
    "title": "Coded Federated Learning Framework for AI-Based Mobile Application  Services with Privacy-Awareness",
    "abstract": "By encoding computing tasks, coded computing can not only mitigate straggling\nproblems in federated learning (FL), but also preserve privacy of sensitive\ndata uploaded/contributed by participating mobile users (MUs) to the\ncentralized server, owned by a mobile application provider (MAP). However,\nthese advantages come with extra coding cost/complexity and communication\noverhead (referred to as \\emph{privacy cost}) that must be considered given the\nlimited computing/communications resources at MUs/MAP, the rationality and\nincentive competition among MUs in contributing data to the MAP. This article\nproposes a novel coded FL-based framework for a privacy-aware mobile\napplication service to address these challenges. In particular, the MAP first\ndetermines a set of the best MUs for the FL process based on MUs' provided\ninformation/features. Then, each selected MU can propose a contract to the MAP\naccording to its expected trainable local data and privacy-protected coded\ndata. To find the optimal contracts that can maximize utilities of the MAP and\nall the participating MUs while maintaining high learning quality of the whole\nsystem, we first develop a multi-principal one-agent contract-based problem\nleveraging coded FL-based multiple utility functions under the MUs' privacy\ncost, the MAP's limited computing resource, and asymmetric information between\nthe MAP and MUs. Then, we transform the problem into an equivalent\nlow-complexity problem and develop an iterative algorithm to solve it.\nExperiments with a real-world dataset show that our framework can speed up\ntraining time up to 49% and improve prediction accuracy up to 4.6 times while\nenhancing network's social welfare, i.e., total utility of all participating\nentities, up to 114% under the privacy cost consideration compared with those\nof baseline methods.",
    "descriptor": "\nComments: 18 pages (submitted to an IEEE journal)\n",
    "authors": [
      "Yuris Mulya Saputra",
      "Diep N. Nguyen",
      "Dinh Thai Hoang",
      "Eryk Dutkiewicz"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09261"
  },
  {
    "id": "arXiv:2106.09269",
    "title": "Pruning Randomly Initialized Neural Networks with Iterative  Randomization",
    "abstract": "Pruning the weights of randomly initialized neural networks plays an\nimportant role in the context of lottery ticket hypothesis. Ramanujan et al.\n(2020) empirically showed that only pruning the weights can achieve remarkable\nperformance instead of optimizing the weight values. However, to achieve the\nsame level of performance as the weight optimization, the pruning approach\nrequires more parameters in the networks before pruning and thus more memory\nspace. To overcome this parameter inefficiency, we introduce a novel framework\nto prune randomly initialized neural networks with iteratively randomizing\nweight values (IteRand). Theoretically, we prove an approximation theorem in\nour framework, which indicates that the randomizing operations are provably\neffective to reduce the required number of the parameters. We also empirically\ndemonstrate the parameter efficiency in multiple experiments on CIFAR-10 and\nImageNet.",
    "descriptor": "\nComments: Code will be available at this https URL\n",
    "authors": [
      "Daiki Chijiwa",
      "Shin'ya Yamaguchi",
      "Yasutoshi Ida",
      "Kenji Umakoshi",
      "Tomohiro Inoue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09269"
  },
  {
    "id": "arXiv:2106.09274",
    "title": "Cooperative Multi-Agent Reinforcement Learning Based Distributed Dynamic  Spectrum Access in Cognitive Radio Networks",
    "abstract": "With the development of the 5G and Internet of Things, amounts of wireless\ndevices need to share the limited spectrum resources. Dynamic spectrum access\n(DSA) is a promising paradigm to remedy the problem of inefficient spectrum\nutilization brought upon by the historical command-and-control approach to\nspectrum allocation. In this paper, we investigate the distributed DSA problem\nfor multi-user in a typical multi-channel cognitive radio network. The problem\nis formulated as a decentralized partially observable Markov decision process\n(Dec-POMDP), and we proposed a centralized off-line training and distributed\non-line execution framework based on cooperative multi-agent reinforcement\nlearning (MARL). We employ the deep recurrent Q-network (DRQN) to address the\npartial observability of the state for each cognitive user. The ultimate goal\nis to learn a cooperative strategy which maximizes the sum throughput of\ncognitive radio network in distributed fashion without coordination information\nexchange between cognitive users. Finally, we validate the proposed algorithm\nin various settings through extensive experiments. From the simulation results,\nwe can observe that the proposed algorithm can converge fast and achieve almost\nthe optimal performance.",
    "descriptor": "",
    "authors": [
      "Xiang Tan",
      "Li Zhou",
      "Haijun Wang",
      "Yuli Sun",
      "Haitao Zhao",
      "Boon-Chong Seet",
      "Jibo Wei",
      "Victor C.M. Leung"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.09274"
  },
  {
    "id": "arXiv:2106.09279",
    "title": "Field trial on Ocean Estimation for Multi-Vessel Multi-Float-based  Active perception",
    "abstract": "Marine vehicles have been used for various scientific missions where\ninformation over features of interest is collected. In order to maximise\nefficiency in collecting information over a large search space, we should be\nable to deploy a large number of autonomous vehicles that make a decision based\non the latest understanding of the target feature in the environment. In our\nprevious work, we have presented a hierarchical framework for the multi-vessel\nmulti-float (MVMF) problem where surface vessels drop and pick up underactuated\nfloats in a time-minimal way. In this paper, we present the field trial results\nusing the framework with a number of drifters and floats. We discovered a\nnumber of important aspects that need to be considered in the proposed\nframework, and present the potential approaches to address the challenges.",
    "descriptor": "\nComments: 7 pages, 6 figures, presented at \"ICRA2021, 1st Advanced Marine Robotics TC Workshop: Active Perception\"\n",
    "authors": [
      "Giovanni D'urso",
      "James Ju Heon Lee",
      "Ki Myung Brian Lee",
      "Jackson Shields",
      "Brenton Leighton",
      "Oscar Pizarro",
      "Chanyeol Yoo",
      "Robert Fitch"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09279"
  },
  {
    "id": "arXiv:2106.09281",
    "title": "MatES: Web-based Forward Chaining Expert System for Maternal Care",
    "abstract": "The solution to prevent maternal complications are known and preventable by\ntrained health professionals. But in countries like Ethiopia where the patient\nto physician ratio is 1 doctor to 1000 patients, maternal mortality and\nmorbidity rate is high. To fill the gap of highly trained health professionals,\nEthiopia introduced health extension programs. Task shifting to health\nextension workers (HEWs) contributed in decreasing mortality and morbidity rate\nin Ethiopia. Knowledge-gap has been one of the major challenges to HEWs. The\nreasons are trainings are not given in regular manner, there is no midwife,\ngynecologists or doctors around for consultation, and all guidelines are\npaper-based which are easily exposed to damage. In this paper, we describe the\ndesign and implementation of a web-based expert system for maternal care. We\nonly targeted the major 10 diseases and complication of maternal health issues\nseen in Sub-Saharan Africa. The expert system can be accessed through the use\nof web browsers from computers as well as smart phones. Forward chaining\nrule-based expert system is used in order to give suggestions and create a new\nknowledge from the knowledge-base. This expert system can be used to train HEWs\nin the field of maternal health.\nKeywords: expert system, maternal care, forward-chaining, rule-based expert\nsystem, PHLIPS",
    "descriptor": "",
    "authors": [
      "Haile Misgna",
      "Moges Ahmed",
      "Anubhav Kumar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09281"
  },
  {
    "id": "arXiv:2106.09282",
    "title": "Smart Contract Vulnerability Detection: From Pure Neural Network to  Interpretable Graph Feature and Expert Pattern Fusion",
    "abstract": "Smart contracts hold digital coins worth billions of dollars, their security\nissues have drawn extensive attention in the past years. Towards smart contract\nvulnerability detection, conventional methods heavily rely on fixed expert\nrules, leading to low accuracy and poor scalability. Recent deep learning\napproaches alleviate this issue but fail to encode useful expert knowledge. In\nthis paper, we explore combining deep learning with expert patterns in an\nexplainable fashion. Specifically, we develop automatic tools to extract expert\npatterns from the source code. We then cast the code into a semantic graph to\nextract deep graph features. Thereafter, the global graph feature and local\nexpert patterns are fused to cooperate and approach the final prediction, while\nyielding their interpretable weights. Experiments are conducted on all\navailable smart contracts with source code in two platforms, Ethereum and VNT\nChain. Empirically, our system significantly outperforms state-of-the-art\nmethods. Our code is released.",
    "descriptor": "\nComments: This paper has been accepted by IJCAI 2021\n",
    "authors": [
      "Zhenguang Liu",
      "Peng Qian",
      "Xiang Wang",
      "Lei Zhu",
      "Qinming He",
      "Shouling Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.09282"
  },
  {
    "id": "arXiv:2106.09289",
    "title": "MHNF: Multi-hop Heterogeneous Neighborhood information Fusion graph  representation learning",
    "abstract": "Attention mechanism enables the Graph Neural Networks(GNNs) to learn the\nattention weights between the target node and its one-hop neighbors, the\nperformance is further improved. However, the most existing GNNs are oriented\nto homogeneous graphs and each layer can only aggregate the information of\none-hop neighbors. Stacking multi-layer networks will introduce a lot of noise\nand easily lead to over smoothing. We propose a Multi-hop Heterogeneous\nNeighborhood information Fusion graph representation learning method (MHNF).\nSpecifically, we first propose a hybrid metapath autonomous extraction model to\nefficiently extract multi-hop hybrid neighbors. Then, we propose a hop-level\nheterogeneous Information aggregation model, which selectively aggregates\ndifferent-hop neighborhood information within the same hybrid metapath.\nFinally, a hierarchical semantic attention fusion model (HSAF) is proposed,\nwhich can efficiently integrate different-hop and different-path neighborhood\ninformation respectively. This paper can solve the problem of aggregating the\nmulti-hop neighborhood information and can learn hybrid metapaths for target\ntask, reducing the limitation of manually specifying metapaths. In addition,\nHSAF can extract the internal node information of the metapaths and better\nintegrate the semantic information of different levels. Experimental results on\nreal datasets show that MHNF is superior to state-of-the-art methods in node\nclassification and clustering tasks (10.94% - 69.09% and 11.58% - 394.93%\nrelative improvement on average, respectively).",
    "descriptor": "",
    "authors": [
      "Dongjie Zhu",
      "Yundong Sun",
      "Haiwen Du",
      "Zhaoshuo Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09289"
  },
  {
    "id": "arXiv:2106.09291",
    "title": "Towards Understanding Deep Learning from Noisy Labels with Small-Loss  Criterion",
    "abstract": "Deep neural networks need large amounts of labeled data to achieve good\nperformance. In real-world applications, labels are usually collected from\nnon-experts such as crowdsourcing to save cost and thus are noisy. In the past\nfew years, deep learning methods for dealing with noisy labels have been\ndeveloped, many of which are based on the small-loss criterion. However, there\nare few theoretical analyses to explain why these methods could learn well from\nnoisy labels. In this paper, we theoretically explain why the widely-used\nsmall-loss criterion works. Based on the explanation, we reformalize the\nvanilla small-loss criterion to better tackle noisy labels. The experimental\nresults verify our theoretical explanation and also demonstrate the\neffectiveness of the reformalization.",
    "descriptor": "\nComments: Accepted to International Joint Conference on Artificial Intelligence (IJCAI) 2021, includes non-archival supplementary material\n",
    "authors": [
      "Xian-Jin Gui",
      "Wei Wang",
      "Zhang-Hao Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09291"
  },
  {
    "id": "arXiv:2106.09292",
    "title": "CROP: Certifying Robust Policies for Reinforcement Learning through  Functional Smoothing",
    "abstract": "We present the first framework of Certifying Robust Policies for\nreinforcement learning (CROP) against adversarial state perturbations. We\npropose two particular types of robustness certification criteria: robustness\nof per-state actions and lower bound of cumulative rewards. Specifically, we\ndevelop a local smoothing algorithm which uses a policy derived from\nQ-functions smoothed with Gaussian noise over each encountered state to\nguarantee the robustness of actions taken along this trajectory. Next, we\ndevelop a global smoothing algorithm for certifying the robustness of a\nfinite-horizon cumulative reward under adversarial state perturbations.\nFinally, we propose a local smoothing approach which makes use of adaptive\nsearch in order to obtain tight certification bounds for reward. We use the\nproposed RL robustness certification framework to evaluate six methods that\nhave previously been shown to yield empirically robust RL, including\nadversarial training and several forms of regularization, on two representative\nAtari games. We show that RegPGD, RegCVX, and RadialRL achieve high certified\nrobustness among these. Furthermore, we demonstrate that our certifications are\noften tight by evaluating these algorithms against adversarial attacks.",
    "descriptor": "\nComments: 25 pages, 7 figures\n",
    "authors": [
      "Fan Wu",
      "Linyi Li",
      "Zijian Huang",
      "Yevgeniy Vorobeychik",
      "Ding Zhao",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09292"
  },
  {
    "id": "arXiv:2106.09296",
    "title": "Voice2Series: Reprogramming Acoustic Models for Time Series  Classification",
    "abstract": "Learning to classify time series with limited data is a practical yet\nchallenging problem. Current methods are primarily based on hand-designed\nfeature extraction rules or domain-specific data augmentation. Motivated by the\nadvances in deep speech processing models and the fact that voice data are\nunivariate temporal signals, in this paper, we propose Voice2Series (V2S), a\nnovel end-to-end approach that reprograms acoustic models for time series\nclassification, through input transformation learning and output label mapping.\nLeveraging the representation learning power of a large-scale pre-trained\nspeech processing model, on 30 different time series tasks we show that V2S\neither outperforms or is tied with state-of-the-art methods on 20 tasks, and\nimproves their average accuracy by 1.84%. We further provide a theoretical\njustification of V2S by proving its population risk is upper bounded by the\nsource risk and a Wasserstein distance accounting for feature alignment via\nreprogramming. Our results offer new and effective means to time series\nclassification.",
    "descriptor": "\nComments: Accepted to ICML 2021, 16 Pages\n",
    "authors": [
      "Chao-Han Huck Yang",
      "Yun-Yun Tsai",
      "Pin-Yu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.09296"
  },
  {
    "id": "arXiv:2106.09297",
    "title": "Embedding-based Product Retrieval in Taobao Search",
    "abstract": "Nowadays, the product search service of e-commerce platforms has become a\nvital shopping channel in people's life. The retrieval phase of products\ndetermines the search system's quality and gradually attracts researchers'\nattention. Retrieving the most relevant products from a large-scale corpus\nwhile preserving personalized user characteristics remains an open question.\nRecent approaches in this domain have mainly focused on embedding-based\nretrieval (EBR) systems. However, after a long period of practice on Taobao, we\nfind that the performance of the EBR system is dramatically degraded due to\nits: (1) low relevance with a given query and (2) discrepancy between the\ntraining and inference phases. Therefore, we propose a novel and practical\nembedding-based product retrieval model, named Multi-Grained Deep Semantic\nProduct Retrieval (MGDSPR). Specifically, we first identify the inconsistency\nbetween the training and inference stages, and then use the softmax\ncross-entropy loss as the training objective, which achieves better performance\nand faster convergence. Two efficient methods are further proposed to improve\nretrieval relevance, including smoothing noisy training data and generating\nrelevance-improving hard negative samples without requiring extra knowledge and\ntraining procedures. We evaluate MGDSPR on Taobao Product Search with\nsignificant metrics gains observed in offline experiments and online A/B tests.\nMGDSPR has been successfully deployed to the existing multi-channel retrieval\nsystem in Taobao Search. We also introduce the online deployment scheme and\nshare practical lessons of our retrieval system to contribute to the community.",
    "descriptor": "\nComments: 9 pages, accepted by KDD2021\n",
    "authors": [
      "Sen Li",
      "Fuyu Lv",
      "Taiwei Jin",
      "Guli Lin",
      "Keping Yang",
      "Xiaoyi Zeng",
      "Xiao-Ming Wu",
      "Qianli Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.09297"
  },
  {
    "id": "arXiv:2106.09300",
    "title": "Multi-level Motion Attention for Human Motion Prediction",
    "abstract": "Human motion prediction aims to forecast future human poses given a\nhistorical motion. Whether based on recurrent or feed-forward neural networks,\nexisting learning based methods fail to model the observation that human motion\ntends to repeat itself, even for complex sports actions and cooking activities.\nHere, we introduce an attention based feed-forward network that explicitly\nleverages this observation. In particular, instead of modeling frame-wise\nattention via pose similarity, we propose to extract motion attention to\ncapture the similarity between the current motion context and the historical\nmotion sub-sequences. In this context, we study the use of different types of\nattention, computed at joint, body part, and full pose levels. Aggregating the\nrelevant past motions and processing the result with a graph convolutional\nnetwork allows us to effectively exploit motion patterns from the long-term\nhistory to predict the future poses. Our experiments on Human3.6M, AMASS and\n3DPW validate the benefits of our approach for both periodical and\nnon-periodical actions. Thanks to our attention model, it yields\nstate-of-the-art results on all three datasets. Our code is available at\nhttps://github.com/wei-mao-2019/HisRepItself.",
    "descriptor": "\nComments: Accepted by IJCV. arXiv admin note: substantial text overlap with arXiv:2007.11755\n",
    "authors": [
      "Wei Mao",
      "Miaomiao Liu",
      "Mathieu Salzmann",
      "Hongdong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09300"
  },
  {
    "id": "arXiv:2106.09302",
    "title": "How can we learn (more) from challenges? A statistical approach to  driving future algorithm development",
    "abstract": "Challenges have become the state-of-the-art approach to benchmark image\nanalysis algorithms in a comparative manner. While the validation on identical\ndata sets was a great step forward, results analysis is often restricted to\npure ranking tables, leaving relevant questions unanswered. Specifically,\nlittle effort has been put into the systematic investigation on what\ncharacterizes images in which state-of-the-art algorithms fail. To address this\ngap in the literature, we (1) present a statistical framework for learning from\nchallenges and (2) instantiate it for the specific task of instrument instance\nsegmentation in laparoscopic videos. Our framework relies on the semantic meta\ndata annotation of images, which serves as foundation for a General Linear\nMixed Models (GLMM) analysis. Based on 51,542 meta data annotations performed\non 2,728 images, we applied our approach to the results of the Robust Medical\nInstrument Segmentation Challenge (ROBUST-MIS) challenge 2019 and revealed\nunderexposure, motion and occlusion of instruments as well as the presence of\nsmoke or other objects in the background as major sources of algorithm failure.\nOur subsequent method development, tailored to the specific remaining issues,\nyielded a deep learning model with state-of-the-art overall performance and\nspecific strengths in the processing of images in which previous methods tended\nto fail. Due to the objectivity and generic applicability of our approach, it\ncould become a valuable tool for validation in the field of medical image\nanalysis and beyond. and segmentation of small, crossing, moving and\ntransparent instrument(s) (parts).",
    "descriptor": "",
    "authors": [
      "Tobias Ro\u00df",
      "Pierangela Bruno",
      "Annika Reinke",
      "Manuel Wiesenfarth",
      "Lisa Koeppel",
      "Peter M. Full",
      "B\u00fcnyamin Pekdemir",
      "Patrick Godau",
      "Darya Trofimova",
      "Fabian Isensee",
      "Sara Moccia",
      "Francesco Calimeri",
      "Beat P. M\u00fcller-Stich",
      "Annette Kopp-Schneider",
      "Lena Maier-Hein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09302"
  },
  {
    "id": "arXiv:2106.09305",
    "title": "Time Series is a Special Sequence: Forecasting with Sample Convolution  and Interaction",
    "abstract": "Time series is a special type of sequence data, a set of observations\ncollected at even intervals of time and ordered chronologically. Existing deep\nlearning techniques use generic sequence models (e.g., recurrent neural\nnetwork, Transformer model, or temporal convolutional network) for time series\nanalysis, which ignore some of its unique properties. For example, the\ndownsampling of time series data often preserves most of the information in the\ndata, while this is not true for general sequence data such as text sequence\nand DNA sequence. Motivated by the above, in this paper, we propose a novel\nneural network architecture and apply it for the time series forecasting\nproblem, wherein we conduct sample convolution and interaction at multiple\nresolutions for temporal modeling. The proposed architecture, namelySCINet,\nfacilitates extracting features with enhanced predictability. Experimental\nresults show that SCINet achieves significant prediction accuracy improvement\nover existing solutions across various real-world time series forecasting\ndatasets. In particular, it can achieve high fore-casting accuracy for those\ntemporal-spatial datasets without using sophisticated spatial modeling\ntechniques. Our codes and data are presented in the supplemental material.",
    "descriptor": "",
    "authors": [
      "Minhao Liu",
      "Ailing Zeng",
      "Qiuxia Lai",
      "Qiang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09305"
  },
  {
    "id": "arXiv:2106.09306",
    "title": "PEN4Rec: Preference Evolution Networks for Session-based Recommendation",
    "abstract": "Session-based recommendation aims to predict user the next action based on\nhistorical behaviors in an anonymous session. For better recommendations, it is\nvital to capture user preferences as well as their dynamics. Besides, user\npreferences evolve over time dynamically and each preference has its own\nevolving track. However, most previous works neglect the evolving trend of\npreferences and can be easily disturbed by the effect of preference drifting.\nIn this paper, we propose a novel Preference Evolution Networks for\nsession-based Recommendation (PEN4Rec) to model preference evolving process by\na two-stage retrieval from historical contexts. Specifically, the first-stage\nprocess integrates relevant behaviors according to recent items. Then, the\nsecond-stage process models the preference evolving trajectory over time\ndynamically and infer rich preferences. The process can strengthen the effect\nof relevant sequential behaviors during the preference evolution and weaken the\ndisturbance from preference drifting. Extensive experiments on three public\ndatasets demonstrate the effectiveness and superiority of the proposed model.",
    "descriptor": "\nComments: 12 pages, accepted by KSEM 2021\n",
    "authors": [
      "Dou Hu",
      "Lingwei Wei",
      "Wei Zhou",
      "Xiaoyong Huai",
      "Zhiqi Fang",
      "Songlin Hu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09306"
  },
  {
    "id": "arXiv:2106.09307",
    "title": "Design of a prototypical platform for autonomous and connected vehicles",
    "abstract": "Self-driving technology is expected to revolutionize different sectors and is\nseen as the natural evolution of road vehicles. In the last years, real-world\nvalidation of designed and virtually tested solutions is growing in importance\nsince simulated environments will never fully replicate all the aspects that\ncan affect results in the real world. To this end, this paper presents our\nprototype platform for experimental research on connected and autonomous\ndriving projects. In detail, the paper presents the overall architecture of the\nvehicle focusing both on mechanical aspects related to remote actuation and\nsensors set-up and software aspects by means of a comprehensive description of\nthe main algorithms required for autonomous driving as ego-localization,\nenvironment perception, motion planning, and actuation. Finally, experimental\ntests conducted in an urban-like environment are reported to validate and\nassess the performances of the overall system.",
    "descriptor": "",
    "authors": [
      "Stefano Arrigoni",
      "Simone Mentasti",
      "Federico Cheli",
      "Matteo Matteucci",
      "Francesco Braghin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09307"
  },
  {
    "id": "arXiv:2106.09308",
    "title": "Characterization and Mitigation of Electromigration Effects in TSV-Based  Power Delivery Network Enabled 3D-Stacked DRAMs",
    "abstract": "With 3D-stacked DRAM architectures becoming more prevalent, it has become\nimportant to find ways to characterize and mitigate the adverse effects that\ncan hinder their inherent access parallelism and throughput. One example of\nsuch adversities is the electromigration (EM) effects in the through-silicon\nvias (TSVs) of the power delivery network (PDN) of 3D-stacked DRAM\narchitectures. Several prior works have addressed the effects of EM in TSVs of\n3D integrated circuits. However, no prior work has addressed the effects of EM\nin the PDN TSVs on the performance and lifetime of 3D-stacked DRAMs. In this\npaper, we characterize the effects of EM in PDN TSVs on a Hybrid Memory Cube\n(HMC) architecture employing the conventional PDN design with clustered layout\nof power and ground TSVs. We then present a new PDN design with a distributed\nlayout of power and ground TSVs and show that it can mitigate the adverse\neffects of EM on the HMC architecture performance without requiring additional\npower and ground pins. Our benchmark-driven simulation-based analysis shows\nthat compared to the clustered PDN layout, our proposed distributed PDN layout\nimproves the EM-affected lifetime of the HMC architecture by up to 10 years.\nDuring this useful lifetime, the HMC architecture yields up to 1.51 times less\nenergy-delay product (EDP).",
    "descriptor": "\nComments: To appear at IEEE/ACM GLSVLSI 2021\n",
    "authors": [
      "Bobby Bose",
      "Ishan Thakkar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.09308"
  },
  {
    "id": "arXiv:2106.09309",
    "title": "Layer Folding: Neural Network Depth Reduction using Activation  Linearization",
    "abstract": "Despite the increasing prevalence of deep neural networks, their\napplicability in resource-constrained devices is limited due to their\ncomputational load. While modern devices exhibit a high level of parallelism,\nreal-time latency is still highly dependent on networks' depth. Although recent\nworks show that below a certain depth, the width of shallower networks must\ngrow exponentially, we presume that neural networks typically exceed this\nminimal depth to accelerate convergence and incrementally increase accuracy.\nThis motivates us to transform pre-trained deep networks that already exploit\nsuch advantages into shallower forms. We propose a method that learns whether\nnon-linear activations can be removed, allowing to fold consecutive linear\nlayers into one. We apply our method to networks pre-trained on CIFAR-10 and\nCIFAR-100 and find that they can all be transformed into shallower forms that\nshare a similar depth. Finally, we use our method to provide more efficient\nalternatives to MobileNetV2 and EfficientNet-Lite architectures on the ImageNet\nclassification task.",
    "descriptor": "",
    "authors": [
      "Amir Ben Dror",
      "Niv Zehngut",
      "Avraham Raviv",
      "Evgeny Artyomov",
      "Ran Vitek",
      "Roy Jevnisek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09309"
  },
  {
    "id": "arXiv:2106.09315",
    "title": "Fast evaluation of some p-adic transcendental functions",
    "abstract": "We design algorithms for computing values of many p-adic elementary and\nspecial functions, including logarithms, exponentials, polylogarithms, and\nhypergeometric functions. All our algorithms feature a quasi-linear complexity\nwith respect to the target precision and most of them are based on an\nadaptation to the-adic setting of the binary splitting and bit-burst\nstrategies.",
    "descriptor": "",
    "authors": [
      "Xavier Caruso",
      "Marc Mezzarobba",
      "Nobuki Takayama",
      "Tristan Vaccon"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2106.09315"
  },
  {
    "id": "arXiv:2106.09316",
    "title": "Optimized Power Control Design for Over-the-Air Federated Edge Learning",
    "abstract": "This paper investigates the transmission power control in over-the-air\nfederated edge learning (Air-FEEL) system. Different from conventional power\ncontrol designs (e.g., to minimize the individual mean squared error (MSE) of\nthe over-the-air aggregation at each round), we consider a new power control\ndesign aiming at directly maximizing the convergence speed. Towards this end,\nwe first analyze the convergence behavior of Air-FEEL (in terms of the\noptimality gap) subject to aggregation errors at different communication\nrounds. It is revealed that if the aggregation estimates are unbiased, then the\ntraining algorithm would converge exactly to the optimal point with mild\nconditions; while if they are biased, then the algorithm would converge with an\nerror floor determined by the accumulated estimate bias over communication\nrounds. Next, building upon the convergence results, we optimize the power\ncontrol to directly minimize the derived optimality gaps under both biased and\nunbiased aggregations, subject to a set of average and maximum power\nconstraints at individual edge devices. We transform both problems into convex\nforms, and obtain their structured optimal solutions, both appearing in a form\nof regularized channel inversion, by using the Lagrangian duality method.\nFinally, numerical results show that the proposed power control policies\nachieve significantly faster convergence for Air-FEEL, as compared with\nbenchmark policies with fixed power transmission or conventional MSE\nminimization.",
    "descriptor": "\nComments: This is an extended version of a convference paper\n",
    "authors": [
      "Cao Xiaowen",
      "Zhu Guangxu",
      "Xu Jie",
      "Wang Zhiqin",
      "Cui Shuguang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.09316"
  },
  {
    "id": "arXiv:2106.09317",
    "title": "EMOVIE: A Mandarin Emotion Speech Dataset with a Simple Emotional  Text-to-Speech Model",
    "abstract": "Recently, there has been an increasing interest in neural speech synthesis.\nWhile the deep neural network achieves the state-of-the-art result in\ntext-to-speech (TTS) tasks, how to generate a more emotional and more\nexpressive speech is becoming a new challenge to researchers due to the\nscarcity of high-quality emotion speech dataset and the lack of advanced\nemotional TTS model. In this paper, we first briefly introduce and publicly\nrelease a Mandarin emotion speech dataset including 9,724 samples with audio\nfiles and its emotion human-labeled annotation. After that, we propose a simple\nbut efficient architecture for emotional speech synthesis called EMSpeech.\nUnlike those models which need additional reference audio as input, our model\ncould predict emotion labels just from the input text and generate more\nexpressive speech conditioned on the emotion embedding. In the experiment\nphase, we first validate the effectiveness of our dataset by an emotion\nclassification task. Then we train our model on the proposed dataset and\nconduct a series of subjective evaluations. Finally, by showing a comparable\nperformance in the emotional speech synthesis task, we successfully demonstrate\nthe ability of the proposed model.",
    "descriptor": "\nComments: Accepted by Interspeech 2021\n",
    "authors": [
      "Chenye Cui",
      "Yi Ren",
      "Jinglin Liu",
      "Feiyang Chen",
      "Rongjie Huang",
      "Ming Lei",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.09317"
  },
  {
    "id": "arXiv:2106.09320",
    "title": "Multi-Level Transfer Learning from Near-Field to Far-Field Speaker  Verification",
    "abstract": "In far-field speaker verification, the performance of speaker embeddings is\nsusceptible to degradation when there is a mismatch between the conditions of\nenrollment and test speech. To solve this problem, we propose the feature-level\nand instance-level transfer learning in the teacher-student framework to learn\na domain-invariant embedding space. For the feature-level knowledge transfer,\nwe develop the contrastive loss to transfer knowledge from teacher model to\nstudent model, which can not only decrease the intra-class distance, but also\nenlarge the inter-class distance. Moreover, we propose the instance-level\npairwise distance transfer method to force the student model to preserve\npairwise instances distance from the well optimized embedding space of the\nteacher model. On FFSVC 2020 evaluation set, our EER on Full-eval trials is\nrelatively reduced by 13.9% compared with the fusion system result on\nPartial-eval trials of Task2. On Task1, compared with the winner's DenseNet\nresult on Partial-eval trials, our minDCF on Full-eval trials is relatively\nreduced by 6.3%. On Task3, the EER and minDCF of our proposed method on\nFull-eval trials are very close to the result of the fusion system on\nPartial-eval trials. Our results also outperform other competitive domain\nadaptation methods.",
    "descriptor": "",
    "authors": [
      "Li Zhang",
      "Qing Wang",
      "Kong Aik Lee",
      "Lei Xie",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.09320"
  },
  {
    "id": "arXiv:2106.09323",
    "title": "Quantum Software Development Lifecycle",
    "abstract": "With recent advances in the development of more powerful quantum computers,\nthe research area of quantum software engineering is emerging, having the goal\nto provide concepts, principles, and guidelines to develop high-quality quantum\napplications. In classical software engineering, lifecycles are used to\ndocument the process of designing, implementing, maintaining, analyzing, and\nadapting software. Such lifecycles provide a common understanding of how to\ndevelop and operate an application, which is especially important due to the\ninterdisciplinary nature of quantum computing. Since today`s quantum\napplications are, in most cases, hybrid, consisting of quantum and classical\nprograms, the lifecycle for quantum applications must involve the development\nof both kinds of programs. However, the existing lifecycles only target the\ndevelopment of quantum or classical programs in isolation. Additionally, the\nvarious programs must be orchestrated, e.g., using workflows. Thus, the\ndevelopment of quantum applications also incorporates the workflow lifecycle.\nIn this chapter, we analyze the software artifacts usually comprising a quantum\napplication and present their corresponding lifecycles. Furthermore, we\nidentify the points of connection between the various lifecycles and integrate\nthem into the overall quantum software development lifecycle. Therefore, the\nintegrated lifecycle serves as a basis for the development and execution of\nhybrid quantum applications.",
    "descriptor": "\nComments: This is a preprint of the following chapter: Benjamin Weder, Johanna Barzen, Frank Leymann, and Daniel Vietz: Quantum Software Development Lifecycle, published in Quantum Software Engineering, edited by M. Serrano, M. Piattini, and R. Perez-Castillo, 2022, Springer\n",
    "authors": [
      "Benjamin Weder",
      "Johanna Barzen",
      "Frank Leymann",
      "Daniel Vietz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.09323"
  },
  {
    "id": "arXiv:2106.09325",
    "title": "Central Kurdish machine translation: First large scale parallel corpus  and experiments",
    "abstract": "While the computational processing of Kurdish has experienced a relative\nincrease, the machine translation of this language seems to be lacking a\nconsiderable body of scientific work. This is in part due to the lack of\nresources especially curated for this task. In this paper, we present the first\nlarge scale parallel corpus of Central Kurdish-English, Awta, containing\n229,222 pairs of manually aligned translations. Our corpus is collected from\ndifferent text genres and domains in an attempt to build more robust and\nreal-world applications of machine translation. We make a portion of this\ncorpus publicly available in order to foster research in this area. Further, we\nbuild several neural machine translation models in order to benchmark the task\nof Kurdish machine translation. Additionally, we perform extensive experimental\nanalysis of results in order to identify the major challenges that Central\nKurdish machine translation faces. These challenges include language-dependent\nand-independent ones as categorized in this paper, the first group of which are\naware of Central Kurdish linguistic properties on different morphological,\nsyntactic and semantic levels. Our best performing systems achieve 22.72 and\n16.81 in BLEU score for Ku$\\rightarrow$EN and En$\\rightarrow$Ku, respectively.",
    "descriptor": "",
    "authors": [
      "Zhila Amini",
      "Mohammad Mohammadamini",
      "Hawre Hosseini",
      "Mehran Mansouri",
      "Daban Jaff"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09325"
  },
  {
    "id": "arXiv:2106.09326",
    "title": "Towards bio-inspired unsupervised representation learning for indoor  aerial navigation",
    "abstract": "Aerial navigation in GPS-denied, indoor environments, is still an open\nchallenge. Drones can perceive the environment from a richer set of viewpoints,\nwhile having more stringent compute and energy constraints than other\nautonomous platforms. To tackle that problem, this research displays a\nbiologically inspired deep-learning algorithm for simultaneous localization and\nmapping (SLAM) and its application in a drone navigation system. We propose an\nunsupervised representation learning method that yields low-dimensional latent\nstate descriptors, that mitigates the sensitivity to perceptual aliasing, and\nworks on power-efficient, embedded hardware. The designed algorithm is\nevaluated on a dataset collected in an indoor warehouse environment, and\ninitial results show the feasibility for robust indoor aerial navigation.",
    "descriptor": "",
    "authors": [
      "Ni Wang",
      "Ozan Catal",
      "Tim Verbelen",
      "Matthias Hartmann",
      "Bart Dhoedt"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09326"
  },
  {
    "id": "arXiv:2106.09329",
    "title": "Network Science, Homophily and Who Reviews Who in the Linux Kernel?",
    "abstract": "In this research, we investigate peer review in the development of Linux by\ndrawing on network theory and network analysis. We frame an analytical model\nwhich integrates the sociological principle of homophily (i.e., the relational\ntendency of individuals to establish relationships with similar others) with\nprior research on peer-review in general and open-source software in\nparticular. We found a relatively strong homophily tendency for maintainers to\nreview other maintainers, but a comparable tendency is surprisingly absent\nregarding developers' organizational affiliation. Such results mirror the\ndocumented norms, beliefs, values, processes, policies, and social hierarchies\nthat characterize the Linux kernel development. Our results underline the power\nof generative mechanisms from network theory to explain the evolution of peer\nreview networks. Regarding practitioners' concern over the Linux\ncommercialization trend, no relational bias in peer review was found albeit the\nincreasing involvement of firms.",
    "descriptor": "\nComments: As presented at 2020 European Conference on Information Systems (ECIS 2020)\n",
    "authors": [
      "Jos\u00e9 Apolin\u00e1rio Teixeira",
      "Ville Lepp\u00e4nen",
      "Sami Hyrynsalmi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.09329"
  },
  {
    "id": "arXiv:2106.09330",
    "title": "A Simple Generative Network",
    "abstract": "Generative neural networks are able to mimic intricate probability\ndistributions such as those of handwritten text, natural images, etc. Since\ntheir inception several models were proposed. The most successful of these were\nbased on adversarial (GAN), auto-encoding (VAE) and maximum mean discrepancy\n(MMD) relatively complex architectures and schemes. Surprisingly, a very simple\narchitecture (a single feed-forward neural network) in conjunction with an\nobvious optimization goal (Kullback_Leibler divergence) was apparently\noverlooked. This paper demonstrates that such a model (denoted SGN for its\nsimplicity) is able to generate samples visually and quantitatively competitive\nas compared with the fore-mentioned state of the art methods.",
    "descriptor": "",
    "authors": [
      "Daniel N. Nissani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.09330"
  },
  {
    "id": "arXiv:2106.09331",
    "title": "A new robotic hand based on the design of fingers with spatial motions",
    "abstract": "This article presents a new hand architecture with three under-actuated\nfingers. Each finger performs spatial movements to achieve more complex and\nvaried grasping than the existing planar-movement fingers. The purpose of this\nhand is to grasp complex-shaped workpieces as they leave the machining centres.\nAmong the taxonomy of grips, cylindrical and spherical grips are often used to\ngrasp heavy objects. A combination of these two modes makes it possible to\ncapture most of the workpieces machined with 5-axis machines. However, the\nchange in grasping mode requires the fingers to reconfigure themselves to\nperform spatial movements. This solution requires the addition of two or three\nactuators to change the position of the fingers and requires sensors to\nrecognize the shape of the workpiece and determine the type of grasp to be\nused. This article proposes to extend the notion of under-actuated fingers to\nspatial movements. After a presentation of the kinematics of the fingers, the\nproblem of stability is discussed as well as the transmission of forces in this\nmechanism. The complete approach for calculating the stability conditions is\npresented from the study of Jacobian force transmission matrices. CAD\nrepresentations of the hand and its behavior in spherical and cylindrical grips\nare presented.",
    "descriptor": "",
    "authors": [
      "Pol Hamon",
      "Damien Chablat",
      "Franck Plestan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09331"
  },
  {
    "id": "arXiv:2106.09336",
    "title": "THUNDR: Transformer-based 3D HUmaN Reconstruction with Markers",
    "abstract": "We present THUNDR, a transformer-based deep neural network methodology to\nreconstruct the 3d pose and shape of people, given monocular RGB images. Key to\nour methodology is an intermediate 3d marker representation, where we aim to\ncombine the predictive power of model-free-output architectures and the\nregularizing, anthropometrically-preserving properties of a statistical human\nsurface model like GHUM -- a recently introduced, expressive full body\nstatistical 3d human model, trained end-to-end. Our novel transformer-based\nprediction pipeline can focus on image regions relevant to the task, supports\nself-supervised regimes, and ensures that solutions are consistent with human\nanthropometry. We show state-of-the-art results on Human3.6M and 3DPW, for both\nthe fully-supervised and the self-supervised models, for the task of inferring\n3d human shape, joint positions, and global translation. Moreover, we observe\nvery solid 3d reconstruction performance for difficult human poses collected in\nthe wild.",
    "descriptor": "",
    "authors": [
      "Mihai Zanfir",
      "Andrei Zanfir",
      "Eduard Gabriel Bazavan",
      "William T. Freeman",
      "Rahul Sukthankar",
      "Cristian Sminchisescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09336"
  },
  {
    "id": "arXiv:2106.09338",
    "title": "Investigating Misinformation Dissemination on Social Media in Pakistan",
    "abstract": "Fake news and misinformation are one of the most significant challenges\nbrought about by advances in communication technologies. We chose to research\nthe spread of fake news in Pakistan because of some unfortunate incidents that\ntook place during 2020. These included the downplaying of the severity of the\nCOVID-19 pandemic, and protests by right-wing political movements. We observed\nthat fake news and misinformation contributed significantly to these events and\nespecially affected low-literate and low-income populations. We conducted a\ncross-platform comparison of misinformation on WhatsApp, Twitter and YouTube\nwith a primary focus on messages shared in public WhatsApp groups, and analysed\nthe characteristics of misinformation, techniques used to make is believable,\nand how users respond to it. To the best of our knowledge, this is the first\nattempt to compare misinformation on all three platforms in Pakistan. Data\ncollected over a span of eight months helped us identify fake news and\nmisinformation related to politics, religion and health, among other\ncategories. Common elements which were used by fake news creators in Pakistan\nto make false content seem believable included: appeals to emotion, conspiracy\ntheories, political and religious polarization, incorrect facts and\nimpersonation of credible sources.",
    "descriptor": "",
    "authors": [
      "Danyal Haroon",
      "Hammad Arif",
      "Ahmed Abdullah Tariq",
      "fareeda nawaz",
      "Dr. Ihsan Ayyub Qazi",
      "Dr. Maryam mustafa"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.09338"
  },
  {
    "id": "arXiv:2106.09339",
    "title": "Optimal explicit stabilized postprocessed $\u03c4$-leap method for the  simulation of chemical kinetics",
    "abstract": "The simulation of chemical kinetics involving multiple scales constitutes a\nmodeling challenge (from ordinary differential equations to Markov chain) and a\ncomputational challenge (multiple scales, large dynamical systems, time step\nrestrictions). In this paper we propose a new discrete stochastic simulation\nalgorithm: the postprocessed second kind stabilized orthogonal $\\tau$-leap\nRunge-Kutta method (PSK-$\\tau$-ROCK). In the context of chemical kinetics this\nmethod can be seen as a stabilization of Gillespie's explicit $\\tau$-leap\ncombined with a postprocessor. The stabilized procedure allows to simulate\nproblems with multiple scales (stiff), while the postprocessing procedure\nallows to approximate the invariant measure (e.g. mean and variance) of ergodic\nstochastic dynamical systems. We prove stability and accuracy of the\nPSK-$\\tau$-ROCK. Numerical experiments illustrate the high reliability and\nefficiency of the scheme when compared to other $\\tau$-leap methods.",
    "descriptor": "",
    "authors": [
      "Assyr Abdulle",
      "Lia Gander",
      "Giacomo Rosilho de Souza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09339"
  },
  {
    "id": "arXiv:2106.09343",
    "title": "Lost in Interpreting: Speech Translation from Source or Interpreter?",
    "abstract": "Interpreters facilitate multi-lingual meetings but the affordable set of\nlanguages is often smaller than what is needed. Automatic simultaneous speech\ntranslation can extend the set of provided languages. We investigate if such an\nautomatic system should rather follow the original speaker, or an interpreter\nto achieve better translation quality at the cost of increased delay.\nTo answer the question, we release Europarl Simultaneous Interpreting Corpus\n(ESIC), 10 hours of recordings and transcripts of European Parliament speeches\nin English, with simultaneous interpreting into Czech and German. We evaluate\nquality and latency of speaker-based and interpreter-based spoken translation\nsystems from English to Czech. We study the differences in implicit\nsimplification and summarization of the human interpreter compared to a machine\ntranslation system trained to shorten the output to some extent. Finally, we\nperform human evaluation to measure information loss of each of these\napproaches.",
    "descriptor": "\nComments: to be published at INTERSPEECH 2021\n",
    "authors": [
      "Dominik Mach\u00e1\u010dek",
      "Mat\u00fa\u0161 \u017dilinec",
      "Ond\u0159ej Bojar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09343"
  },
  {
    "id": "arXiv:2106.09344",
    "title": "Virtual Reality based Digital Twin System for remote laboratories and  online practical learning",
    "abstract": "There is a need for remote learning and virtual learning applications such as\nvirtual reality (VR) and tablet-based solutions which the current pandemic has\ndemonstrated. Creating complex learning scenarios by developers is highly\ntime-consuming and can take over a year. There is a need to provide a simple\nmethod to enable lecturers to create their own content for their laboratory\ntutorials. Research is currently being undertaken into developing generic\nmodels to enable the semi-automatic creation of a virtual learning application.\nA case study describing the creation of a virtual learning application for an\nelectrical laboratory tutorial is presented.",
    "descriptor": "\nComments: 6 pages, 4 figures, accepted for publication ICMR2021 18th International Conference in Manufacturing Research Virtual Conference hosted by the University of Derby, UK 7 - 10 September 2021\n",
    "authors": [
      "Claire Palmer",
      "Ben Roullier",
      "Muhammad Aamir",
      "Leonardo Stella",
      "Uchenna Diala",
      "Ashiq Anjum",
      "Frank Mcquade",
      "Keith Cox",
      "Alex Calvert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09344"
  },
  {
    "id": "arXiv:2106.09348",
    "title": "Hybrid high-order methods. A primer with application to solid mechanics",
    "abstract": "This book is organized into eight chapters. The first three gently introduce\nthe basic principles of hybrid high-order methods on a linear diffusion\nproblem, the key ideas underlying the mathematical analysis, and some useful\nvariants of the method as well as links to other methods from the literature.\nThe following four present various challenging applications to solid mechanics,\nincluding linear elasticity and hyperelasticity, elastodynamics,\ncontact/friction, and plasticity. The last chapter reviews implementation\naspects. This book is primarily intended for graduate students, researchers (in\napplied mathematics, numerical analysis, and computational mechanics), and\nengineers working in related fields of application. Basic knowledge of the\ndevising and analysis of finite element methods is assumed. Special effort was\nmade to streamline the presentation so as to pinpoint the essential ideas,\naddress key mathematical aspects, present examples, and provide bibliographic\npointers.",
    "descriptor": "\nComments: This is a preprint of the following work: M. Cicuttin, A. Ern, N. Pignet, Hybrid high-order methods. A primer with applications to solid mechanics, Springer, (in press) 2021, reproduced with the permission of the publisher\n",
    "authors": [
      "Matteo Cicuttin",
      "Alexandre Ern",
      "Nicolas Pignet"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09348"
  },
  {
    "id": "arXiv:2106.09349",
    "title": "Blockchain Oracle Design Patterns",
    "abstract": "Blockchain is a form of distributed ledger technology (DLT) where data is\nshared among users connected over the internet. Transactions are data state\nchanges on the blockchain that are permanently recorded in a secure and\ntransparent way without the need of a third party. Besides, the introduction of\nsmart contracts to the blockchain has added programmability to the blockchain\nand revolutionized the software ecosystem leading toward decentralized\napplications (DApps) attracting businesses and organizations to employ this\ntechnology. Although promising, blockchains and smart contracts have no access\nto the external systems (i.e., off-chain) where real-world data and events\nresides; consequently, the usability of smart contracts in terms of performance\nand programmability would be limited to the on-chain data. Hence,\n\\emph{blockchain oracles} are introduced to mitigate the issue and are defined\nas trusted third-party services that send and verify the external information\n(i.e., feedback) and submit it to smart contracts for triggering state changes\nin the blockchain. In this paper, we will study and analyze blockchain oracles\nwith regard to how they provide feedback to the blockchain and smart contracts.\nWe classify the blockchain oracle techniques into two major groups such as\nvoting-based strategies and reputation-based ones. The former mainly relies on\nparticipants' stakes for outcome finalization while the latter considers\nreputation in conjunction with authenticity proof mechanisms for data\ncorrectness and integrity. We then provide a structured description of patterns\nin detail for each classification and discuss research directions in the end.",
    "descriptor": "",
    "authors": [
      "Amirmohammad Pasdar",
      "Zhongli Dong",
      "Young Choon Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.09349"
  },
  {
    "id": "arXiv:2106.09350",
    "title": "Identifiability of AMP chain graph models",
    "abstract": "We study identifiability of Andersson-Madigan-Perlman (AMP) chain graph\nmodels, which are a common generalization of linear structural equation models\nand Gaussian graphical models. AMP models are described by DAGs on chain\ncomponents which themselves are undirected graphs.\nFor a known chain component decomposition, we show that the DAG on the chain\ncomponents is identifiable if the determinants of the residual covariance\nmatrices of the chain components are monotone non-decreasing in topological\norder. This condition extends the equal variance identifiability criterion for\nBayes nets, and it can be generalized from determinants to any super-additive\nfunction on positive semidefinite matrices. When the component decomposition is\nunknown, we describe conditions that allow recovery of the full structure using\na polynomial time algorithm based on submodular function minimization. We also\nconduct experiments comparing our algorithm's performance against existing\nbaselines.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Yuhao Wang",
      "Arnab Bhattacharyya"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09350"
  },
  {
    "id": "arXiv:2106.09352",
    "title": "Large Scale Private Learning via Low-rank Reparametrization",
    "abstract": "We propose a reparametrization scheme to address the challenges of applying\ndifferentially private SGD on large neural networks, which are 1) the huge\nmemory cost of storing individual gradients, 2) the added noise suffering\nnotorious dimensional dependence. Specifically, we reparametrize each weight\nmatrix with two \\emph{gradient-carrier} matrices of small dimension and a\n\\emph{residual weight} matrix. We argue that such reparametrization keeps the\nforward/backward process unchanged while enabling us to compute the projected\ngradient without computing the gradient itself. To learn with differential\nprivacy, we design \\emph{reparametrized gradient perturbation (RGP)} that\nperturbs the gradients on gradient-carrier matrices and reconstructs an update\nfor the original weight from the noisy gradients. Importantly, we use\nhistorical updates to find the gradient-carrier matrices, whose optimality is\nrigorously justified under linear regression and empirically verified with deep\nlearning tasks. RGP significantly reduces the memory cost and improves the\nutility. For example, we are the first able to apply differential privacy on\nthe BERT model and achieve an average accuracy of $83.9\\%$ on four downstream\ntasks with $\\epsilon=8$, which is within $5\\%$ loss compared to the non-private\nbaseline but enjoys much lower privacy leakage risk.",
    "descriptor": "\nComments: Published as a conference paper in International Conference on Machine Learning (ICML 2021). Source code available at this https URL\n",
    "authors": [
      "Da Yu",
      "Huishuai Zhang",
      "Wei Chen",
      "Jian Yin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09352"
  },
  {
    "id": "arXiv:2106.09354",
    "title": "Retrospective Analysis of Controversial Subtopics on COVID-19 in Japan",
    "abstract": "For efficient political decision-making in an emergency situation, a thorough\nrecognition and understanding of the polarized topics is crucial. The cost of\nunmitigated polarization would be extremely high for the society; therefore, it\nis desirable to identify the polarizing issues before they become serious. With\nthis in mind, we conducted a retrospective analysis of the polarized subtopics\nof COVID-19 to obtain insights for future policymaking. To this end, we first\npropose a framework to comprehensively search for controversial subtopics. We\nthen retrospectively analyze subtopics on COVID-19 using the proposed\nframework, with data obtained via Twitter in Japan. The results show that the\nproposed framework can effectively detect controversial subtopics that reflect\ncurrent reality. Controversial subtopics tend to be about the government,\nmedical matters, economy, and education; moreover, the controversy score had a\nlow correlation with the traditional indicators--scale and sentiment of the\nsubtopics--which suggests that the controversy score is a potentially important\nindicator to be obtained. We also discussed the difference between subtopics\nthat became highly controversial and ones that did not despite their large\nscale.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Kunihiro Miyazaki",
      "Takayuki Uchiba",
      "Fujio Toriumi",
      "Kenji Tanaka",
      "Takeshi Sakaki"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.09354"
  },
  {
    "id": "arXiv:2106.09357",
    "title": "Cat-like Jumping and Landing of Legged Robots in Low-gravity Using Deep  Reinforcement Learning",
    "abstract": "In this article, we show that learned policies can be applied to solve legged\nlocomotion control tasks with extensive flight phases, such as those\nencountered in space exploration. Using an off-the-shelf deep reinforcement\nlearning algorithm, we trained a neural network to control a jumping quadruped\nrobot while solely using its limbs for attitude control. We present tasks of\nincreasing complexity leading to a combination of three-dimensional\n(re-)orientation and landing locomotion behaviors of a quadruped robot\ntraversing simulated low-gravity celestial bodies. We show that our approach\neasily generalizes across these tasks and successfully trains policies for each\ncase. Using sim-to-real transfer, we deploy trained policies in the real world\non the SpaceBok robot placed on an experimental testbed designed for\ntwo-dimensional micro-gravity experiments. The experimental results demonstrate\nthat repetitive, controlled jumping and landing with natural agility is\npossible.",
    "descriptor": "\nComments: Published in IEEE Transactions on Robotics: this https URL Video: this https URL\n",
    "authors": [
      "Nikita Rudin",
      "Hendrik Kolvenbach",
      "Vassilios Tsounis",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09357"
  },
  {
    "id": "arXiv:2106.09358",
    "title": "ShuffleBlock: Shuffle to Regularize Deep Convolutional Neural Networks",
    "abstract": "Deep neural networks have enormous representational power which leads them to\noverfit on most datasets. Thus, regularizing them is important in order to\nreduce overfitting and enhance their generalization capabilities. Recently,\nchannel shuffle operation has been introduced for mixing channels in group\nconvolutions in resource efficient networks in order to reduce memory and\ncomputations. This paper studies the operation of channel shuffle as a\nregularization technique in deep convolutional networks. We show that while\nrandom shuffling of channels during training drastically reduce their\nperformance, however, randomly shuffling small patches between channels\nsignificantly improves their performance. The patches to be shuffled are picked\nfrom the same spatial locations in the feature maps such that a patch, when\ntransferred from one channel to another, acts as structured noise for the later\nchannel. We call this method \"ShuffleBlock\". The proposed ShuffleBlock module\nis easy to implement and improves the performance of several baseline networks\non the task of image classification on CIFAR and ImageNet datasets. It also\nachieves comparable and in many cases better performance than many other\nregularization methods. We provide several ablation studies on selecting\nvarious hyperparameters of the ShuffleBlock module and propose a new scheduling\nmethod that further enhances its performance.",
    "descriptor": "",
    "authors": [
      "Sudhakar Kumawat",
      "Gagan Kanojia",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09358"
  },
  {
    "id": "arXiv:2106.09362",
    "title": "Frustratingly Easy Transferability Estimation",
    "abstract": "Transferability estimation has been an essential tool in selecting a\npre-trained model and the layers of it to transfer, so as to maximize the\nperformance on a target task and prevent negative transfer. Existing estimation\nalgorithms either require intensive training on target tasks or have\ndifficulties in evaluating the transferability between layers. We propose a\nsimple, efficient, and effective transferability measure named TransRate. With\nsingle pass through the target data, TransRate measures the transferability as\nthe mutual information between the features of target examples extracted by a\npre-trained model and labels of them. We overcome the challenge of efficient\nmutual information estimation by resorting to coding rate that serves as an\neffective alternative to entropy. TransRate is theoretically analyzed to be\nclosely related to the performance after transfer learning. Despite its\nextraordinary simplicity in 10 lines of codes, TransRate performs remarkably\nwell in extensive evaluations on 22 pre-trained models and 16 downstream tasks.",
    "descriptor": "",
    "authors": [
      "Long-Kai Huang",
      "Ying Wei",
      "Yu Rong",
      "Qiang Yang",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09362"
  },
  {
    "id": "arXiv:2106.09369",
    "title": "Wavelet-Packet Powered Deepfake Image Detection",
    "abstract": "As neural networks become more able to generate realistic artificial images,\nthey have the potential to improve movies, music, video games and make the\ninternet an even more creative and inspiring place. Yet, at the same time, the\nlatest technology potentially enables new digital ways to lie. In response, the\nneed for a diverse and reliable toolbox arises to identify artificial images\nand other content. Previous work primarily relies on pixel-space CNN or the\nFourier transform. To the best of our knowledge, wavelet-based gan analysis and\ndetection methods have been absent thus far. This paper aims to fill this gap\nand describes a wavelet-based approach to gan-generated image analysis and\ndetection. We evaluate our method on FFHQ, CelebA, and LSUN source\nidentification problems and find improved or competitive performance.",
    "descriptor": "\nComments: Source code is available at this https URL\n",
    "authors": [
      "Moritz Wolter",
      "Felix Blanke",
      "Charles Tapley Hoyt",
      "Jochen Garcke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09369"
  },
  {
    "id": "arXiv:2106.09370",
    "title": "Deep generative modeling for probabilistic forecasting in power systems",
    "abstract": "Greater direct electrification of end-use sectors with a higher share of\nrenewables is one of the pillars to power a carbon-neutral society by 2050.\nThis study uses a recent deep learning technique, the normalizing flows, to\nproduce accurate probabilistic forecasts that are crucial for decision-makers\nto face the new challenges in power systems applications. Through comprehensive\nempirical evaluations using the open data of the Global Energy Forecasting\nCompetition 2014, we demonstrate that our methodology is competitive with other\nstate-of-the-art deep learning generative models: generative adversarial\nnetworks and variational autoencoders. The models producing weather-based wind,\nsolar power, and load scenarios are properly compared both in terms of forecast\nvalue, by considering the case study of an energy retailer, and quality using\nseveral complementary metrics.",
    "descriptor": "",
    "authors": [
      "Jonathan Dumas",
      "Antoine Wehenkel Damien Lanaspeze",
      "Bertrand Corn\u00e9lusse",
      "Antonio Sutera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09370"
  },
  {
    "id": "arXiv:2106.09373",
    "title": "Unsupervised Path Representation Learning with Curriculum Negative  Sampling",
    "abstract": "Path representations are critical in a variety of transportation\napplications, such as estimating path ranking in path recommendation systems\nand estimating path travel time in navigation systems. Existing studies often\nlearn task-specific path representations in a supervised manner, which require\na large amount of labeled training data and generalize poorly to other tasks.\nWe propose an unsupervised learning framework Path InfoMax (PIM) to learn\ngeneric path representations that work for different downstream tasks. We first\npropose a curriculum negative sampling method, for each input path, to generate\na small amount of negative paths, by following the principles of curriculum\nlearning. Next, \\emph{PIM} employs mutual information maximization to learn\npath representations from both a global and a local view. In the global view,\nPIM distinguishes the representations of the input paths from those of the\nnegative paths. In the local view, \\emph{PIM} distinguishes the input path\nrepresentations from the representations of the nodes that appear only in the\nnegative paths. This enables the learned path representations to encode both\nglobal and local information at different scales. Extensive experiments on two\ndownstream tasks, ranking score estimation and travel time estimation, using\ntwo road network datasets suggest that PIM significantly outperforms other\nunsupervised methods and is also able to be used as a pre-training method to\nenhance supervised path representation learning.",
    "descriptor": "\nComments: This paper has been accepted by IJCAI-21\n",
    "authors": [
      "Sean Bin Yang",
      "Chenjuan Guo",
      "Jilin Hu",
      "Jian Tang",
      "Bin Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09373"
  },
  {
    "id": "arXiv:2106.09375",
    "title": "Recovery under Side Constraints",
    "abstract": "This paper addresses sparse signal reconstruction under various types of\nstructural side constraints with applications in multi-antenna systems. Side\nconstraints may result from prior information on the measurement system and the\nsparse signal structure. They may involve the structure of the sensing matrix,\nthe structure of the non-zero support values, the temporal structure of the\nsparse representationvector, and the nonlinear measurement structure. First, we\ndemonstrate how a priori information in form of structural side constraints\ninfluence recovery guarantees (null space properties) using L1-minimization.\nFurthermore, for constant modulus signals, signals with row-, block- and\nrank-sparsity, as well as non-circular signals, we illustrate how structural\nprior information can be used to devise efficient algorithms with improved\nrecovery performance and reduced computational complexity. Finally, we address\nthe measurement system design for linear and nonlinear measurements of sparse\nsignals. Moreover, we discuss the linear mixing matrix design based on\ncoherence minimization. Then we extend our focus to nonlinear measurement\nsystems where we design parallel optimization algorithms to efficiently compute\nstationary points in the sparse phase retrieval problem with and without\ndictionary learning.",
    "descriptor": "",
    "authors": [
      "Khaled Ardah",
      "Martin Haardt",
      "Tianyi Liu",
      "Frederic Matter",
      "Marius Pesavento",
      "Marc E. Pfetsch"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.09375"
  },
  {
    "id": "arXiv:2106.09377",
    "title": "A New Dissipativity Condition for Asymptotic Stability of Discounted  Economic MPC",
    "abstract": "Economic Model Predictive Control has recently gained popularity due to its\nability to directly optimize a given performance criterion, while enforcing\nconstraint satisfaction for nonlinear systems. Recent research has developed\nboth numerical algorithms and stability analysis for the undiscounted case. The\nintroduction of a discount factor in the cost, however, can be desirable in\nsome cases of interest, e.g., economics, stochastically terminating processes,\nMarkov decision processes, etc. Unfortunately, the stability theory in this\ncase is still not fully developed. In this paper we propose a new dissipativity\ncondition to prove asymptotic stability in the infinite horizon case and we\nconnect our results with existing ones in the literature on discounted economic\noptimal control. Numerical examples are provided to illustrate the theoretical\nresults.",
    "descriptor": "",
    "authors": [
      "Mario Zanon",
      "S\u00e9bastien Gros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.09377"
  },
  {
    "id": "arXiv:2106.09380",
    "title": "Modeling Realistic Adversarial Attacks against Network Intrusion  Detection Systems",
    "abstract": "The incremental diffusion of machine learning algorithms in supporting\ncybersecurity is creating novel defensive opportunities but also new types of\nrisks. Multiple researches have shown that machine learning methods are\nvulnerable to adversarial attacks that create tiny perturbations aimed at\ndecreasing the effectiveness of detecting threats. We observe that existing\nliterature assumes threat models that are inappropriate for realistic\ncybersecurity scenarios because they consider opponents with complete knowledge\nabout the cyber detector or that can freely interact with the target systems.\nBy focusing on Network Intrusion Detection Systems based on machine learning,\nwe identify and model the real capabilities and circumstances required by\nattackers to carry out feasible and successful adversarial attacks. We then\napply our model to several adversarial attacks proposed in literature and\nhighlight the limits and merits that can result in actual adversarial attacks.\nThe contributions of this paper can help hardening defensive systems by letting\ncyber defenders address the most critical and real issues, and can benefit\nresearchers by allowing them to devise novel forms of adversarial attacks based\non realistic threat models.",
    "descriptor": "",
    "authors": [
      "Giovanni Apruzzese",
      "Mauro Andreolini",
      "Luca Ferretti",
      "Mirco Marchetti",
      "Michele Colajanni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09380"
  },
  {
    "id": "arXiv:2106.09383",
    "title": "Area Optimisation of Two Stage Miller Compensated Op-Amp in 65 nm Using  Hybrid PSO",
    "abstract": "Analog circuit design can be formulated as a non-linear constrained\noptimisation problem that can be solved using any suitable optimisation\nalgorithms. Different optimisation techniques have been reported to reduce the\ndesign time of analog circuits. A hybrid particle swarm optimisation algorithm\nwith linearly decreasing inertia weight for the optimisation of analog circuit\ndesign is proposed in this study. The proposed method is used to design a\ntwo-stage operational amplifier circuit with Miller compensation. The results\nshow that the proposed optimisation method can substantially reduce the design\ntime needed for analog circuits.",
    "descriptor": "",
    "authors": [
      "Ria Rashid",
      "Nandakumar Nambath"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09383"
  },
  {
    "id": "arXiv:2106.09385",
    "title": "On the Dark Side of Calibration for Modern Neural Networks",
    "abstract": "Modern neural networks are highly uncalibrated. It poses a significant\nchallenge for safety-critical systems to utilise deep neural networks (DNNs),\nreliably. Many recently proposed approaches have demonstrated substantial\nprogress in improving DNN calibration. However, they hardly touch upon\nrefinement, which historically has been an essential aspect of calibration.\nRefinement indicates separability of a network's correct and incorrect\npredictions. This paper presents a theoretically and empirically supported\nexposition for reviewing a model's calibration and refinement. Firstly, we show\nthe breakdown of expected calibration error (ECE), into predicted confidence\nand refinement. Connecting with this result, we highlight that regularisation\nbased calibration only focuses on naively reducing a model's confidence. This\nlogically has a severe downside to a model's refinement. We support our claims\nthrough rigorous empirical evaluations of many state of the art calibration\napproaches on standard datasets. We find that many calibration approaches with\nthe likes of label smoothing, mixup etc. lower the utility of a DNN by\ndegrading its refinement. Even under natural data shift, this\ncalibration-refinement trade-off holds for the majority of calibration methods.\nThese findings call for an urgent retrospective into some popular pathways\ntaken for modern DNN calibration.",
    "descriptor": "\nComments: 15 pages including references and supplemental\n",
    "authors": [
      "Aditya Singh",
      "Alessandro Bay",
      "Biswa Sengupta",
      "Andrea Mirabile"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09385"
  },
  {
    "id": "arXiv:2106.09388",
    "title": "Deep Subdomain Adaptation Network for Image Classification",
    "abstract": "For a target task where labeled data is unavailable, domain adaptation can\ntransfer a learner from a different source domain. Previous deep domain\nadaptation methods mainly learn a global domain shift, i.e., align the global\nsource and target distributions without considering the relationships between\ntwo subdomains within the same category of different domains, leading to\nunsatisfying transfer learning performance without capturing the fine-grained\ninformation. Recently, more and more researchers pay attention to Subdomain\nAdaptation which focuses on accurately aligning the distributions of the\nrelevant subdomains. However, most of them are adversarial methods which\ncontain several loss functions and converge slowly. Based on this, we present\nDeep Subdomain Adaptation Network (DSAN) which learns a transfer network by\naligning the relevant subdomain distributions of domain-specific layer\nactivations across different domains based on a local maximum mean discrepancy\n(LMMD). Our DSAN is very simple but effective which does not need adversarial\ntraining and converges fast. The adaptation can be achieved easily with most\nfeed-forward network models by extending them with LMMD loss, which can be\ntrained efficiently via back-propagation. Experiments demonstrate that DSAN can\nachieve remarkable results on both object recognition tasks and digit\nclassification tasks. Our code will be available at:\nhttps://github.com/easezyc/deep-transfer-learning",
    "descriptor": "\nComments: published on TNNLS\n",
    "authors": [
      "Yongchun Zhu",
      "Fuzhen Zhuang",
      "Jindong Wang",
      "Guolin Ke",
      "Jingwu Chen",
      "Jiang Bian",
      "Hui Xiong",
      "Qing He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09388"
  },
  {
    "id": "arXiv:2106.09393",
    "title": "using multiple losses for accurate facial age estimation",
    "abstract": "Age estimation is an essential challenge in computer vision. With the\nadvances of convolutional neural networks, the performance of age estimation\nhas been dramatically improved. Existing approaches usually treat age\nestimation as a classification problem. However, the age labels are ambiguous,\nthus make the classification task difficult. In this paper, we propose a simple\nyet effective approach for age estimation, which improves the performance\ncompared to classification-based methods. The method combines four\nclassification losses and one regression loss representing different class\ngranularities together, and we name it as Age-Granularity-Net. We validate the\nAge-Granularity-Net framework on the CVPR Chalearn 2016 dataset, and extensive\nexperiments show that the proposed approach can reduce the prediction error\ncompared to any individual loss. The source code link is\nhttps://github.com/yipersevere/age-estimation.",
    "descriptor": "",
    "authors": [
      "Yi Zhou",
      "Heikki Huttunen",
      "Tapio Elomaa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09393"
  },
  {
    "id": "arXiv:2106.09394",
    "title": "On temporal homogenization in the numerical simulation of  atherosclerotic plaque growth",
    "abstract": "A temporal homogenization approach for the numerical simulation of\natherosclerotic plaque growth is extended to fully coupled fluid-structure\ninteraction (FSI) simulations. The numerical results indicate that the\ntwo-scale approach yields significantly different results compared to a simple\nheuristic averaging, where only stationary long-scale FSI problems are solved,\nconfirming the importance of incorporating stress variations on small\ntime-scales. In the homogenization approach, a periodic fine-scale problem,\nwhich is periodic with respect to the heart beat, has to be solved for each\nlong-scale time step. Even if no exact initial conditions are available,\nperiodicity can be achieved within only 2-3 heart beats by simple\ntime-stepping.",
    "descriptor": "",
    "authors": [
      "Stefan Frei",
      "Alexander Heinlein",
      "Thomas Richter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09394"
  },
  {
    "id": "arXiv:2106.09395",
    "title": "A Self-supervised Method for Entity Alignment",
    "abstract": "Entity alignment, aiming to identify equivalent entities across different\nknowledge graphs (KGs), is a fundamental problem for constructing large-scale\nKGs. Over the course of its development, supervision has been considered\nnecessary for accurate alignments. Inspired by the recent progress of\nself-supervised learning, we explore the extent to which we can get rid of\nsupervision for entity alignment. Existing supervised methods for this task\nfocus on pulling each pair of positive (labeled) entities close to each other.\nHowever, our analysis suggests that the learning of entity alignment can\nactually benefit more from pushing sampled (unlabeled) negatives far away than\npulling positive aligned pairs close. We present SelfKG by leveraging this\ndiscovery to design a contrastive learning strategy across two KGs. Extensive\nexperiments on benchmark datasets demonstrate that SelfKG without supervision\ncan match or achieve comparable results with state-of-the-art supervised\nbaselines. The performance of SelfKG demonstrates self-supervised learning\noffers great potential for entity alignment in KGs.",
    "descriptor": "",
    "authors": [
      "Xiao Liu",
      "Haoyun Hong",
      "Xinghao Wang",
      "Zeyi Chen",
      "Evgeny Kharlamov",
      "Yuxiao Dong",
      "Jie Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09395"
  },
  {
    "id": "arXiv:2106.09397",
    "title": "Quantized Federated Learning under Transmission Delay and Outage  Constraints",
    "abstract": "Federated learning (FL) has been recognized as a viable distributed learning\nparadigm which trains a machine learning model collaboratively with massive\nmobile devices in the wireless edge while protecting user privacy. Although\nvarious communication schemes have been proposed to expedite the FL process,\nmost of them have assumed ideal wireless channels which provide reliable and\nlossless communication links between the server and mobile clients.\nUnfortunately, in practical systems with limited radio resources such as\nconstraint on the training latency and constraints on the transmission power\nand bandwidth, transmission of a large number of model parameters inevitably\nsuffers from quantization errors (QE) and transmission outage (TO). In this\npaper, we consider such non-ideal wireless channels, and carry out the first\nanalysis showing that the FL convergence can be severely jeopardized by TO and\nQE, but intriguingly can be alleviated if the clients have uniform outage\nprobabilities. These insightful results motivate us to propose a robust FL\nscheme, named FedTOE, which performs joint allocation of wireless resources and\nquantization bits across the clients to minimize the QE while making the\nclients have the same TO probability. Extensive experimental results are\npresented to show the superior performance of FedTOE for a deep learning-based\nclassification task with transmission latency constraints.",
    "descriptor": "\nComments: Submitted for publication\n",
    "authors": [
      "Yanmeng Wang",
      "Yanqing Xu",
      "Qingjiang Shi",
      "Tsung-Hui Chang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09397"
  },
  {
    "id": "arXiv:2106.09398",
    "title": "Episode Adaptive Embedding Networks for Few-shot Learning",
    "abstract": "Few-shot learning aims to learn a classifier using a few labelled instances\nfor each class. Metric-learning approaches for few-shot learning embed\ninstances into a high-dimensional space and conduct classification based on\ndistances among instance embeddings. However, such instance embeddings are\nusually shared across all episodes and thus lack the discriminative power to\ngeneralize classifiers according to episode-specific features. In this paper,\nwe propose a novel approach, namely \\emph{Episode Adaptive Embedding Network}\n(EAEN), to learn episode-specific embeddings of instances. By leveraging the\nprobability distributions of all instances in an episode at each channel-pixel\nembedding dimension, EAEN can not only alleviate the overfitting issue\nencountered in few-shot learning tasks, but also capture discriminative\nfeatures specific to an episode. To empirically verify the effectiveness and\nrobustness of EAEN, we have conducted extensive experiments on three widely\nused benchmark datasets, under various combinations of different generic\nembedding backbones and different classifiers. The results show that EAEN\nsignificantly improves classification accuracy about $10\\%$ to $20\\%$ in\ndifferent settings over the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Fangbing Liu",
      "Qing Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09398"
  },
  {
    "id": "arXiv:2106.09399",
    "title": "Data sharing of computer scientists: an analysis of current research  information system data",
    "abstract": "Without sufficient information about researchers data sharing, there is a\nrisk of mismatching FAIR data service efforts with the needs of researchers.\nThis study describes a methodology where departmental publications are used to\nanalyse the ways in which computer scientists share research data. All journal\narticles published by researchers in the computer science department of the\ncase studys university during 2019 were extracted for scrutiny from the current\nresearch information system. For these 193 articles, a coding framework was\ndeveloped to capture the key elements of acquiring and sharing research data.\nFurthermore, a rudimentary classification of the main study types exhibited in\nthe investigated articles was developed to accommodate the multidisciplinary\nnature of the case departments research agenda. Human interaction and\nintervention studies often collected original data, whereas research on novel\ncomputational methods and life sciences more frequently used openly available\ndata. Articles that made data available for reuse were most often in life\nscience studies, whereas data sharing was least frequent in human interaction\nstudies. The use of open code was most frequent in life science studies and\nnovel computational methods. The findings highlight that multidisciplinary\nresearch organisations may include diverse subfields that have their own\ncultures of data sharing, and suggest that research information system-based\nmethods may be valuable additions to the questionnaire and interview\nmethodologies eliciting insight into researchers data sharing. The collected\ndata and coding framework are provided as open data to facilitate future\nresearch.",
    "descriptor": "",
    "authors": [
      "Antti Mikael Rousi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.09399"
  },
  {
    "id": "arXiv:2106.09402",
    "title": "Class Balancing GAN with a Classifier in the Loop",
    "abstract": "Generative Adversarial Networks (GANs) have swiftly evolved to imitate\nincreasingly complex image distributions. However, majority of the developments\nfocus on performance of GANs on balanced datasets. We find that the existing\nGANs and their training regimes which work well on balanced datasets fail to be\neffective in case of imbalanced (i.e. long-tailed) datasets. In this work we\nintroduce a novel theoretically motivated Class Balancing regularizer for\ntraining GANs. Our regularizer makes use of the knowledge from a pre-trained\nclassifier to ensure balanced learning of all the classes in the dataset. This\nis achieved via modelling the effective class frequency based on the\nexponential forgetting observed in neural networks and encouraging the GAN to\nfocus on underrepresented classes. We demonstrate the utility of our\nregularizer in learning representations for long-tailed distributions via\nachieving better performance than existing approaches over multiple datasets.\nSpecifically, when applied to an unconditional GAN, it improves the FID from\n$13.03$ to $9.01$ on the long-tailed iNaturalist-$2019$ dataset.",
    "descriptor": "\nComments: UAI 2021\n",
    "authors": [
      "Harsh Rangwani",
      "Konda Reddy Mopuri",
      "R. Venkatesh Babu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09402"
  },
  {
    "id": "arXiv:2106.09403",
    "title": "Density of Free Modules over Finite Chain Rings",
    "abstract": "In this paper we focus on modules over a finite chain ring $\\mathcal{R}$ of\nsize $q^s$. We compute the density of free modules of $\\mathcal{R}^n$, where we\nseparately treat the asymptotics in $n,q$ and $s$. In particular, we focus on\ntwo cases: one where we fix the type of the module and one where we fix the\nrank of the module. In both cases, the density results can be bounded by the\nAndrews-Gordon identities. We also study the asymptotic behaviour of modules\ngenerated by random matrices over $\\mathcal{R}$. Since linear codes over\n$\\mathcal{R}$ are submodules of $\\mathcal{R}^n$ we get direct implications for\ncoding theory. For example, we show that random codes achieve the\nGilbert-Varshamov bound with high probability.",
    "descriptor": "",
    "authors": [
      "Eimear Byrne",
      "Anna-Lena Horlemann",
      "Karan Khathuria",
      "Violetta Weger"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.09403"
  },
  {
    "id": "arXiv:2106.09407",
    "title": "A Fait Accompli? An Empirical Study into the Absence of Consent to  Third-Party Tracking in Android~Apps",
    "abstract": "Third-party tracking allows companies to collect users' behavioural data and\ntrack their activity across digital devices. This can put deep insights into\nusers' private lives into the hands of strangers, and often happens without\nusers' awareness or explicit consent. EU and UK data protection law, however,\nrequires consent, both 1) to access and store information on users' devices and\n2) to legitimate the processing of personal data as part of third-party\ntracking, as we analyse in this paper.\nThis paper further investigates whether and to what extent consent is\nimplemented in mobile apps. First, we analyse a representative sample of apps\nfrom the Google Play Store. We find that most apps engage in third-party\ntracking, but few obtained consent before doing so, indicating potentially\nwidespread violations of EU and UK privacy law. Second, we examine the most\ncommon third-party tracking libraries in detail. While most acknowledge that\nthey rely on app developers to obtain consent on their behalf, they typically\nfail to put in place robust measures to ensure this: disclosure of consent\nrequirements is limited; default consent implementations are lacking; and\ncompliance guidance is difficult to find, hard to read, and poorly maintained.",
    "descriptor": "\nComments: This paper will be presented at the 7th Symposium on Usable Privacy and Security (SOUPS 2021), 8th-10th August 2021\n",
    "authors": [
      "Konrad Kollnig",
      "Reuben Binns",
      "Pierre Dewitte",
      "Max Van Kleek",
      "Ge Wang",
      "Daniel Omeiza",
      "Helena Webb",
      "Nigel Shadbolt"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.09407"
  },
  {
    "id": "arXiv:2106.09408",
    "title": "Predicting cognitive scores with graph neural networks through sample  selection learning",
    "abstract": "Analyzing the relation between intelligence and neural activity is of the\nutmost importance in understanding the working principles of the human brain in\nhealth and disease. In existing literature, functional brain connectomes have\nbeen used successfully to predict cognitive measures such as intelligence\nquotient (IQ) scores in both healthy and disordered cohorts using machine\nlearning models. However, existing methods resort to flattening the brain\nconnectome (i.e., graph) through vectorization which overlooks its topological\nproperties. To address this limitation and inspired from the emerging graph\nneural networks (GNNs), we design a novel regression GNN model (namely RegGNN)\nfor predicting IQ scores from brain connectivity. On top of that, we introduce\na novel, fully modular sample selection method to select the best samples to\nlearn from for our target prediction task. However, since such deep learning\narchitectures are computationally expensive to train, we further propose a\n\\emph{learning-based sample selection} method that learns how to choose the\ntraining samples with the highest expected predictive power on unseen samples.\nFor this, we capitalize on the fact that connectomes (i.e., their adjacency\nmatrices) lie in the symmetric positive definite (SPD) matrix cone. Our results\non full-scale and verbal IQ prediction outperforms comparison methods in autism\nspectrum disorder cohorts and achieves a competitive performance for\nneurotypical subjects using 3-fold cross-validation. Furthermore, we show that\nour sample selection approach generalizes to other learning-based methods,\nwhich shows its usefulness beyond our GNN architecture.",
    "descriptor": "",
    "authors": [
      "Martin Hanik",
      "Mehmet Arif Demirta\u015f",
      "Mohammed Amine Gharsallaoui",
      "Islem Rekik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.09408"
  },
  {
    "id": "arXiv:2106.09420",
    "title": "Remote Health-Monitoring of First Responders over TETRA Links",
    "abstract": "In this paper, we present a system for remote health-monitoring of first\nresponders over TETRA radio links. The system features a smart garment that\nperiodically records and sends physiological parameters of first responders to\na remote agent, which processes the recordings and feeds back the health-status\nnotifications and warnings in the form of electrotactile stimuli. The choice of\nTETRA as the connectivity solution is driven by its routine use by first\nresponders all over the world, thus representing a convenient and\neconomically-effective connectivity basis. Although the support for data\ncommunications in TETRA is rather limited and in practice reduced to the Short\nData Service, we show that TETRA can serve the intended purpose in the\nconsidered scenario, achieving tolerable delay and message-loss performance.\nMoreover, when the system is examined and optimized in terms of the peak\nAge-of-Information, a metric suitable to characterize the quasi-periodic nature\nof the monitoring process, its performance becomes rather favorable, enabling\ntimely monitoring of the first responders' health status.",
    "descriptor": "",
    "authors": [
      "Hossam Farag",
      "Aleksandar Vujic",
      "Milos Kostic",
      "Goran Bijelic",
      "Cedomir Stefanovic"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.09420"
  },
  {
    "id": "arXiv:2106.09421",
    "title": "State Estimation with Model Reduction and Shape Variability. Application  to biomedical problems",
    "abstract": "We develop a mathematical and numerical framework to solve state estimation\nproblems for applications that present variations in the shape of the spatial\ndomain. This situation arises typically in a biomedical context where inverse\nproblems are posed on certain organs or portions of the body which inevitably\ninvolve morphological variations. If one wants to provide fast reconstruction\nmethods, the algorithms must take into account the geometric variability. We\ndevelop and analyze a method which allows to take this variability into account\nwithout needing any a priori knowledge on a parametrization of the geometrical\nvariations. For this, we rely on morphometric techniques involving\nMultidimensional Scaling, and couple them with reconstruction algorithms that\nmake use of reduced model spaces pre-computed on a database of geometries. We\nprove the potential of the method on a synthetic test problem inspired from the\nreconstruction of blood flows and quantities of medical interest with Doppler\nultrasound imaging.",
    "descriptor": "",
    "authors": [
      "Felipe Galarce",
      "Damiano Lombardi",
      "Olga Mula"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09421"
  },
  {
    "id": "arXiv:2106.09422",
    "title": "CRIL: Continual Robot Imitation Learning via Generative and Prediction  Model",
    "abstract": "Imitation learning (IL) algorithms have shown promising results for robots to\nlearn skills from expert demonstrations. However, for versatile robots nowadays\nthat need to learn diverse tasks, providing and learning the multi-task\ndemonstrations all at once are both difficult. To solve this problem, in this\nwork we study how to realize continual imitation learning ability that empowers\nrobots to continually learn new tasks one by one, thus reducing the burden of\nmulti-task IL and accelerating the process of new task learning at the same\ntime. We propose a novel trajectory generation model that employs both a\ngenerative adversarial network and a dynamics prediction model to generate\npseudo trajectories from all learned tasks in the new task learning process to\nachieve continual imitation learning ability. Our experiments on both\nsimulation and real world manipulation tasks demonstrate the effectiveness of\nour method.",
    "descriptor": "",
    "authors": [
      "Chongkai Gao",
      "Haichuan Gao",
      "Shangqi Guo",
      "Tianren Zhang",
      "Feng Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09422"
  },
  {
    "id": "arXiv:2106.09424",
    "title": "Interpretable Machine Learning Classifiers for Brain Tumour Survival  Prediction",
    "abstract": "Prediction of survival in patients diagnosed with a brain tumour is\nchallenging because of heterogeneous tumour behaviours and responses to\ntreatment. Better estimations of prognosis would support treatment planning and\npatient support. Advances in machine learning have informed development of\nclinical predictive models, but their integration into clinical practice is\nalmost non-existent. One reasons for this is the lack of interpretability of\nmodels. In this paper, we use a novel brain tumour dataset to compare two\ninterpretable rule list models against popular machine learning approaches for\nbrain tumour survival prediction. All models are quantitatively evaluated using\nstandard performance metrics. The rule lists are also qualitatively assessed\nfor their interpretability and clinical utility. The interpretability of the\nblack box machine learning models is evaluated using two post-hoc explanation\ntechniques, LIME and SHAP. Our results show that the rule lists were only\nslightly outperformed by the black box models. We demonstrate that rule list\nalgorithms produced simple decision lists that align with clinical expertise.\nBy comparison, post-hoc interpretability methods applied to black box models\nmay produce unreliable explanations of local model predictions. Model\ninterpretability is essential for understanding differences in predictive\nperformance and for integration into clinical practice.",
    "descriptor": "",
    "authors": [
      "Colleen E. Charlton",
      "Michael Tin Chung Poon",
      "Paul M. Brennan",
      "Jacques D. Fleuriot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09424"
  },
  {
    "id": "arXiv:2106.09431",
    "title": "NeuroMorph: Unsupervised Shape Interpolation and Correspondence in One  Go",
    "abstract": "We present NeuroMorph, a new neural network architecture that takes as input\ntwo 3D shapes and produces in one go, i.e. in a single feed forward pass, a\nsmooth interpolation and point-to-point correspondences between them. The\ninterpolation, expressed as a deformation field, changes the pose of the source\nshape to resemble the target, but leaves the object identity unchanged.\nNeuroMorph uses an elegant architecture combining graph convolutions with\nglobal feature pooling to extract local features. During training, the model is\nincentivized to create realistic deformations by approximating geodesics on the\nunderlying shape space manifold. This strong geometric prior allows to train\nour model end-to-end and in a fully unsupervised manner without requiring any\nmanual correspondence annotations. NeuroMorph works well for a large variety of\ninput shapes, including non-isometric pairs from different object categories.\nIt obtains state-of-the-art results for both shape correspondence and\ninterpolation tasks, matching or surpassing the performance of recent\nunsupervised and supervised methods on multiple benchmarks.",
    "descriptor": "\nComments: Published at the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2021\n",
    "authors": [
      "Marvin Eisenberger",
      "David Novotny",
      "Gael Kerchenbaum",
      "Patrick Labatut",
      "Natalia Neverova",
      "Daniel Cremers",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09431"
  },
  {
    "id": "arXiv:2106.09432",
    "title": "Unsupervised Training Data Generation of Handwritten Formulas using  Generative Adversarial Networks with Self-Attention",
    "abstract": "The recognition of handwritten mathematical expressions in images and video\nframes is a difficult and unsolved problem yet. Deep convectional neural\nnetworks are basically a promising approach, but typically require a large\namount of labeled training data. However, such a large training dataset does\nnot exist for the task of handwritten formula recognition. In this paper, we\nintroduce a system that creates a large set of synthesized training examples of\nmathematical expressions which are derived from LaTeX documents. For this\npurpose, we propose a novel attention-based generative adversarial network to\ntranslate rendered equations to handwritten formulas. The datasets generated by\nthis approach contain hundreds of thousands of formulas, making it ideal for\npretraining or the design of more complex models. We evaluate our synthesized\ndataset and the recognition approach on the CROHME 2014 benchmark dataset.\nExperimental results demonstrate the feasibility of the approach.",
    "descriptor": "\nComments: Accepted for publication in: ACM International Conference on Multimedia Retrieval (ICMR) Workshop 2021\n",
    "authors": [
      "Matthias Springstein",
      "Eric M\u00fcller-Budack",
      "Ralph Ewerth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09432"
  },
  {
    "id": "arXiv:2106.09433",
    "title": "Towards Heterogeneous Clients with Elastic Federated Learning",
    "abstract": "Federated learning involves training machine learning models over devices or\ndata silos, such as edge processors or data warehouses, while keeping the data\nlocal. Training in heterogeneous and potentially massive networks introduces\nbias into the system, which is originated from the non-IID data and the low\nparticipation rate in reality. In this paper, we propose Elastic Federated\nLearning (EFL), an unbiased algorithm to tackle the heterogeneity in the\nsystem, which makes the most informative parameters less volatile during\ntraining, and utilizes the incomplete local updates. It is an efficient and\neffective algorithm that compresses both upstream and downstream\ncommunications. Theoretically, the algorithm has convergence guarantee when\ntraining on the non-IID data at the low participation rate. Empirical\nexperiments corroborate the competitive performance of EFL framework on the\nrobustness and the efficiency.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Zichen Ma",
      "Yu Lu",
      "Zihan Lu",
      "Wenye Li",
      "Jinfeng Yi",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09433"
  },
  {
    "id": "arXiv:2106.09435",
    "title": "Multi-Agent Training beyond Zero-Sum with Correlated Equilibrium  Meta-Solvers",
    "abstract": "Two-player, constant-sum games are well studied in the literature, but there\nhas been limited progress outside of this setting. We propose Joint\nPolicy-Space Response Oracles (JPSRO), an algorithm for training agents in\nn-player, general-sum extensive form games, which provably converges to an\nequilibrium. We further suggest correlated equilibria (CE) as promising\nmeta-solvers, and propose a novel solution concept Maximum Gini Correlated\nEquilibrium (MGCE), a principled and computationally efficient family of\nsolutions for solving the correlated equilibrium selection problem. We conduct\nseveral experiments using CE meta-solvers for JPSRO and demonstrate convergence\non n-player, general-sum games.",
    "descriptor": "\nComments: ICML 2021, 9 pages, coded implementation available in this https URL (jpsro.py in examples)\n",
    "authors": [
      "Luke Marris",
      "Paul Muller",
      "Marc Lanctot",
      "Karl Tuyls",
      "Thore Grapael"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09435"
  },
  {
    "id": "arXiv:2106.09436",
    "title": "Semi-Autoregressive Transformer for Image Captioning",
    "abstract": "Current state-of-the-art image captioning models adopt autoregressive\ndecoders, \\ie they generate each word by conditioning on previously generated\nwords, which leads to heavy latency during inference. To tackle this issue,\nnon-autoregressive image captioning models have recently been proposed to\nsignificantly accelerate the speed of inference by generating all words in\nparallel. However, these non-autoregressive models inevitably suffer from large\ngeneration quality degradation since they remove words dependence excessively.\nTo make a better trade-off between speed and quality, we introduce a\nsemi-autoregressive model for image captioning~(dubbed as SATIC), which keeps\nthe autoregressive property in global but generates words parallelly in local.\nBased on Transformer, there are only a few modifications needed to implement\nSATIC. Extensive experiments on the MSCOCO image captioning benchmark show that\nSATIC can achieve a better trade-off without bells and whistles. Code is\navailable at {\\color{magenta}\\url{https://github.com/YuanEZhou/satic}}.",
    "descriptor": "",
    "authors": [
      "Yuanen Zhou",
      "Yong Zhang",
      "Zhenzhen Hu",
      "Meng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09436"
  },
  {
    "id": "arXiv:2106.09440",
    "title": "\u00d0Archer: Detecting On-Chain-Off-Chain Synchronization Bugs in  Decentralized Applications",
    "abstract": "Since the emergence of Ethereum, blockchain-based decentralized applications\n(DApps) have become increasingly popular and important. To balance the\nsecurity, performance, and costs, a DApp typically consists of two layers: an\non-chain layer to execute transactions and store crucial data on the blockchain\nand an off-chain layer to interact with users. A DApp needs to synchronize its\noff-chain layer with the on-chain layer proactively. Otherwise, the\ninconsistent data in the off-chain layer could mislead users and cause\nundesirable consequences, e.g., loss of transaction fees. However, transactions\nsent to the blockchain are not guaranteed to be executed and could even be\nreversed after execution due to chain reorganization. Such non-determinism in\nthe transaction execution is unique to blockchain. DApp developers may fail to\nperform the on-chain-off-chain synchronization accurately due to their lack of\nfamiliarity with the complex transaction lifecycle. In this work, we\ninvestigate the challenges of synchronizing on-chain and off-chain data in\nEthereum-based DApps. We present two types of bugs that could result in\ninconsistencies between the on-chain and off-chain layers. To help detect such\non-chain-off-chain synchronization bugs, we introduce a state transition model\nto guide the testing of DApps and propose two effective oracles to facilitate\nthe automatic identification of bugs. We build the first testing framework,\nDArcher, to detect on-chain-off-chain synchronization bugs in DApps. We have\nevaluated DArcher on 11 popular real-world DApps. DArcher achieves high\nprecision (99.3%), recall (87.6%), and accuracy (89.4%) in bug detection and\nsignificantly outperforms the baseline methods. It has found 15 real bugs in\nthe 11 DApps. So far, six of the 15 bugs have been confirmed by the developers,\nand three have been fixed. These promising results demonstrate the usefulness\nof DArcher.",
    "descriptor": "\nComments: Accepted by the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2021)\n",
    "authors": [
      "Wuqi Zhang",
      "Lili Wei",
      "Shuqing Li",
      "Yepang Liu",
      "Shing-Chi Cheung"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.09440"
  },
  {
    "id": "arXiv:2106.09442",
    "title": "Dynamic Metasurface Antennas for Energy Efficient Massive MIMO Uplink  Communications",
    "abstract": "Future wireless communications are largely inclined to deploy a massive\nnumber of antennas at the base stations (BS) by exploiting energy-efficient and\nenvironmentally friendly technologies. An emerging technology called dynamic\nmetasurface antennas (DMAs) is promising to realize such massive antenna arrays\nwith reduced physical size, hardware cost, and power consumption. This paper\naims to optimize the energy efficiency (EE) performance of DMAs-assisted\nmassive MIMO uplink communications. We propose an algorithmic framework for\ndesigning the transmit precoding of each multi-antenna user and the DMAs tuning\nstrategy at the BS to maximize the EE performance, considering the availability\nof the instantaneous and statistical channel state information (CSI),\nrespectively. Specifically, the proposed framework includes Dinkelbach's\ntransform, alternating optimization, and deterministic equivalent methods. In\naddition, we obtain a closed-form solution to the optimal transmit signal\ndirections for the statistical CSI case, which simplifies the corresponding\ntransmission design. The numerical results show good convergence performance of\nour proposed algorithms as well as considerable EE performance gains of the\nDMAs-assisted massive MIMO uplink communications over the baseline schemes.",
    "descriptor": "",
    "authors": [
      "Li You",
      "Jie Xu",
      "George C. Alexandropoulos",
      "Jue Wang",
      "Wenjin Wang",
      "Xiqi Gao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.09442"
  },
  {
    "id": "arXiv:2106.09445",
    "title": "A structure-preserving surrogate model for the closure of the moment  system of the Boltzmann equation using convex deep neural networks",
    "abstract": "Direct simulation of physical processes on a kinetic level is prohibitively\nexpensive in aerospace applications due to the extremely high dimension of the\nsolution spaces. In this paper, we consider the moment system of the Boltzmann\nequation, which projects the kinetic physics onto the hydrodynamic scale. The\nunclosed moment system can be solved in conjunction with the entropy closure\nstrategy. Using an entropy closure provides structural benefits to the physical\nsystem of partial differential equations. Usually computing such closure of the\nsystem spends the majority of the total computational cost, since one needs to\nsolve an ill-conditioned constrained optimization problem. Therefore, we build\na neural network surrogate model to close the moment system, which preserves\nthe structural properties of the system by design, but reduces the\ncomputational cost significantly. Numerical experiments are conducted to\nillustrate the performance of the current method in comparison to the\ntraditional closure.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Steffen Schotth\u00f6fer",
      "Tianbai Xiao",
      "Martin Frank",
      "Cory D. Hauck"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.09445"
  },
  {
    "id": "arXiv:2106.09449",
    "title": "DocNLI: A Large-scale Dataset for Document-level Natural Language  Inference",
    "abstract": "Natural language inference (NLI) is formulated as a unified framework for\nsolving various NLP problems such as relation extraction, question answering,\nsummarization, etc. It has been studied intensively in the past few years\nthanks to the availability of large-scale labeled datasets. However, most\nexisting studies focus on merely sentence-level inference, which limits the\nscope of NLI's application in downstream NLP problems. This work presents\nDocNLI -- a newly-constructed large-scale dataset for document-level NLI.\nDocNLI is transformed from a broad range of NLP problems and covers multiple\ngenres of text. The premises always stay in the document granularity, whereas\nthe hypotheses vary in length from single sentences to passages with hundreds\nof words. Additionally, DocNLI has pretty limited artifacts which unfortunately\nwidely exist in some popular sentence-level NLI datasets. Our experiments\ndemonstrate that, even without fine-tuning, a model pretrained on DocNLI shows\npromising performance on popular sentence-level benchmarks, and generalizes\nwell to out-of-domain NLP tasks that rely on inference at document granularity.\nTask-specific fine-tuning can bring further improvements. Data, code, and\npretrained models can be found at https://github.com/salesforce/DocNLI.",
    "descriptor": "\nComments: ACL'21 Findings Camera-ready\n",
    "authors": [
      "Wenpeng Yin",
      "Dragomir Radev",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09449"
  },
  {
    "id": "arXiv:2106.09450",
    "title": "Simultaneous Transmission and Reflection Reconfigurable Intelligent  Surface Assisted MIMO Systems",
    "abstract": "In this work, we investigate a novel simultaneous transmission and reflection\nreconfigurable intelligent surface (RIS)-assisted multiple-input\nmultiple-output downlink system, where three practical transmission protocols,\nnamely, energy splitting (ES), mode selection (MS), and time splitting (TS),\nare studied. For the system under consideration, we maximize the weighted sum\nrate with multiple coupled variables. To solve this optimization problem, a\nblock coordinate descent algorithm is proposed to reformulate this problem and\ndesign the precoding matrices and the transmitting and reflecting coefficients\n(TARCs) in an alternate manner. Specifically, for the ES scheme, the precoding\nmatrices are solved using the Lagrange dual method, while the TARCs are\nobtained using the penalty concave-convex method. Additionally, the proposed\nmethod is extended to the MS scheme by solving a mixed-integer problem.\nMoreover, we solve the formulated problem for the TS scheme using a\none-dimensional search and the Majorization-Minimization technique. Our\nsimulation results reveal that: 1) Simultaneous transmission and reflection RIS\n(STAR-RIS) can achieve better performance than reflecting-only RIS; 2) In\nunicast communication, TS scheme outperforms the ES and MS schemes, while in\nbroadcast communication, ES scheme outperforms the TS and MS schemes.",
    "descriptor": "",
    "authors": [
      "Hehao Niu",
      "Zheng Chu",
      "Fuhui Zhou",
      "Pei Xiao",
      "Naofal Al-Dhahir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.09450"
  },
  {
    "id": "arXiv:2106.09453",
    "title": "Learning to Associate Every Segment for Video Panoptic Segmentation",
    "abstract": "Temporal correspondence - linking pixels or objects across frames - is a\nfundamental supervisory signal for the video models. For the panoptic\nunderstanding of dynamic scenes, we further extend this concept to every\nsegment. Specifically, we aim to learn coarse segment-level matching and fine\npixel-level matching together. We implement this idea by designing two novel\nlearning objectives. To validate our proposals, we adopt a deep siamese model\nand train the model to learn the temporal correspondence on two different\nlevels (i.e., segment and pixel) along with the target task. At inference time,\nthe model processes each frame independently without any extra computation and\npost-processing. We show that our per-frame inference model can achieve new\nstate-of-the-art results on Cityscapes-VPS and VIPER datasets. Moreover, due to\nits high efficiency, the model runs in a fraction of time (3x) compared to the\nprevious state-of-the-art approach.",
    "descriptor": "\nComments: Accepted to CVPR2021\n",
    "authors": [
      "Sanghyun Woo",
      "Dahun Kim",
      "Joon-Young Lee",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09453"
  },
  {
    "id": "arXiv:2106.09455",
    "title": "Conference proceedings KI4Industry AI for SMEs -- the online congress  for practical entry into AI for SMEs",
    "abstract": "The Institute of Materials and Processes, IMP, of the University of Applied\nSciences in Karlsruhe, Germany in cooperation with VDI Verein Deutscher\nIngenieure e.V, AEN Automotive Engineering Network and their cooperation\npartners present their competences of AI-based solution approaches in the\nproduction engineering field. The online congress KI 4 Industry on November 12\nand 13, 2020, showed what opportunities the use of artificial intelligence\noffers for medium-sized manufacturing companies, SMEs, and where potential\nfields of application lie. The main purpose of KI 4 Industry is to increase the\ntransfer of knowledge, research and technology from universities to small and\nmedium-sized enterprises, to demystify the term AI and to encourage companies\nto use AI-based solutions in their own value chain or in their products.",
    "descriptor": "\nComments: 56 pages, in German. Editors: Matthias Feiner and Manuel Schoellhorn\n",
    "authors": [
      "Matthias Feiner",
      "Manuel Schoellhorn"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09455"
  },
  {
    "id": "arXiv:2106.09460",
    "title": "DravidianCodeMix: Sentiment Analysis and Offensive Language  Identification Dataset for Dravidian Languages in Code-Mixed Text",
    "abstract": "This paper describes the development of a multilingual, manually annotated\ndataset for three under-resourced Dravidian languages generated from social\nmedia comments. The dataset was annotated for sentiment analysis and offensive\nlanguage identification for a total of more than 60,000 YouTube comments. The\ndataset consists of around 44,000 comments in Tamil-English, around 7,000\ncomments in Kannada-English, and around 20,000 comments in Malayalam-English.\nThe data was manually annotated by volunteer annotators and has a high\ninter-annotator agreement in Krippendorff's alpha. The dataset contains all\ntypes of code-mixing phenomena since it comprises user-generated content from a\nmultilingual country. We also present baseline experiments to establish\nbenchmarks on the dataset using machine learning methods. The dataset is\navailable on Github\n(https://github.com/bharathichezhiyan/DravidianCodeMix-Dataset) and Zenodo\n(https://zenodo.org/record/4750858\\#.YJtw0SYo\\_0M).",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Bharathi Raja Chakravarthi",
      "Ruba Priyadharshini",
      "Vigneshwaran Muralidaran",
      "Navya Jose",
      "Shardul Suryawanshi",
      "Elizabeth Sherly",
      "John P. McCrae"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09460"
  },
  {
    "id": "arXiv:2106.09461",
    "title": "Modelling resource allocation in uncertain system environment through  deep reinforcement learning",
    "abstract": "Reinforcement Learning has applications in field of mechatronics, robotics,\nand other resource-constrained control system. Problem of resource allocation\nis primarily solved using traditional predefined techniques and modern deep\nlearning methods. The drawback of predefined and most deep learning methods for\nresource allocation is failing to meet the requirements in cases of uncertain\nsystem environment. We can approach problem of resource allocation in uncertain\nsystem environment alongside following certain criteria using deep\nreinforcement learning. Also, reinforcement learning has ability for adapting\nto new uncertain environment for prolonged period of time. The paper provides a\ndetailed comparative analysis on various deep reinforcement learning methods by\napplying different components to modify architecture of reinforcement learning\nwith use of noisy layers, prioritized replay, bagging, duelling networks, and\nother related combination to obtain improvement in terms of performance and\nreduction of computational cost. The paper identifies problem of resource\nallocation in uncertain environment could be effectively solved using Noisy\nBagging duelling double deep Q network achieving efficiency of 97.7% by\nmaximizing reward with significant exploration in given simulated environment\nfor resource allocation.",
    "descriptor": "\nComments: Accepted at IRMAS'21\n",
    "authors": [
      "Neel Gandhi",
      "Shakti Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09461"
  },
  {
    "id": "arXiv:2106.09462",
    "title": "pysentimiento: A Python Toolkit for Sentiment Analysis and SocialNLP  tasks",
    "abstract": "Extracting opinions from texts has gathered a lot of interest in the last\nyears, as we are experiencing an unprecedented volume of user-generated content\nin social networks and other places. A problem that social researchers find in\nusing opinion mining tools is that they are usually behind commercial APIs and\nunavailable for other languages than English. To address these issues, we\npresent pysentimiento, a multilingual Python toolkit for Sentiment Analysis and\nother Social NLP tasks. This open-source library brings state-of-the-art models\nfor Spanish and English in a black-box fashion, allowing researchers to easily\naccess these techniques.",
    "descriptor": "\nComments: 4 pages, 2 tables Source code at this https URL Submitted to ASAI/JAIIO\n",
    "authors": [
      "Juan Manuel P\u00e9rez",
      "Juan Carlos Giudici",
      "Franco Luque"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09462"
  },
  {
    "id": "arXiv:2106.09467",
    "title": "Algorithmic Bias and Data Bias: Understanding the Relation between  Distributionally Robust Optimization and Data Curation",
    "abstract": "Machine learning systems based on minimizing average error have been shown to\nperform inconsistently across notable subsets of the data, which is not exposed\nby a low average error for the entire dataset. In consequential social and\neconomic applications, where data represent people, this can lead to\ndiscrimination of underrepresented gender and ethnic groups. Given the\nimportance of bias mitigation in machine learning, the topic leads to\ncontentious debates on how to ensure fairness in practice (data bias versus\nalgorithmic bias). Distributionally Robust Optimization (DRO) seemingly\naddresses this problem by minimizing the worst expected risk across\nsubpopulations. We establish theoretical results that clarify the relation\nbetween DRO and the optimization of the same loss averaged on an adequately\nweighted training dataset. The results cover finite and infinite number of\ntraining distributions, as well as convex and non-convex loss functions. We\nshow that neither DRO nor curating the training set should be construed as a\ncomplete solution for bias mitigation: in the same way that there is no\nuniversally robust training set, there is no universal way to setup a DRO\nproblem and ensure a socially acceptable set of results. We then leverage these\ninsights to provide a mininal set of practical recommendations for addressing\nbias with DRO. Finally, we discuss ramifications of our results in other\nrelated applications of DRO, using an example of adversarial robustness. Our\nresults show that there is merit to both the algorithm-focused and the\ndata-focused side of the bias debate, as long as arguments in favor of these\npositions are precisely qualified and backed by relevant mathematics known\ntoday.",
    "descriptor": "",
    "authors": [
      "Agnieszka S\u0142owik",
      "L\u00e9on Bottou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09467"
  },
  {
    "id": "arXiv:2106.09469",
    "title": "A posteriori estimator for the adaptive solution of a quasi-static  fracture phase-field model with irreversibility constraints",
    "abstract": "Within this article, we develop a residual type a posteriori error estimator\nfor a time discrete quasi-static phase-field fracture model. Particular\nemphasize is given to the robustness of the error estimator for the variational\ninequality governing the phase-field evolution with respect to the phase-field\nregularization parameter $\\epsilon$. The article concludes with numerical\nexamples highlighting the performance of the proposed a posteriori error\nestimators on three standard test cases; the single edge notched tension and\nshear test as well as the L-shaped panel test.",
    "descriptor": "",
    "authors": [
      "Mirjam Walloth",
      "Winnifried Wollner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09469"
  },
  {
    "id": "arXiv:2106.09475",
    "title": "Backward Gradient Normalization in Deep Neural Networks",
    "abstract": "We introduce a new technique for gradient normalization during neural network\ntraining. The gradients are rescaled during the backward pass using\nnormalization layers introduced at certain points within the network\narchitecture. These normalization nodes do not affect forward activity\npropagation, but modify backpropagation equations to permit a well-scaled\ngradient flow that reaches the deepest network layers without experimenting\nvanishing or explosion. Results on tests with very deep neural networks show\nthat the new technique can do an effective control of the gradient norm,\nallowing the update of weights in the deepest layers and improving network\naccuracy on several experimental conditions.",
    "descriptor": "",
    "authors": [
      "Alejandro Cabana",
      "Luis F. Lago-Fern\u00e1ndez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09475"
  },
  {
    "id": "arXiv:2106.09482",
    "title": "Elicitation of Adaptive Requirements Using Creativity Triggers: A  Controlled Experiment",
    "abstract": "Adaptive systems react to changes in their environment by changing their\nbehavior. Identifying these needed adaptations is very difficult, but central\nto requirements elicitation for adaptive systems. As the necessary or potential\nadaptations are typically not obvious to the stakeholders, the problem is how\nto effectively elicit adaptation-relevant information. One approach is to use\ncreativity techniques to support the systematic identification and elicitation\nof adaptation requirements. In particular, here, we analyze a set of creativity\ntriggers defined for systematic exploration of potential adaptation\nrequirements. We compare these triggers with brainstorming as a baseline in a\ncontrolled experiment with 85 master students. The results indicate that the\nproposed triggers are suitable for the efficient elicitation of adaptive\nrequirements and that the 15 trigger questions produce significantly more\nrequirements fragments than solo brainstorming.",
    "descriptor": "",
    "authors": [
      "Fabian Kneer",
      "Erik Kamsties",
      "Klaus Schmid"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.09482"
  },
  {
    "id": "arXiv:2106.09485",
    "title": "Secure Multi-Function Computation with Private Remote Sources",
    "abstract": "We consider a distributed function computation problem in which parties\nobserving noisy versions of a remote source facilitate the computation of a\nfunction of their observations at a fusion center through public communication.\nThe distributed function computation is subject to constraints, including not\nonly reliability and storage but also privacy and secrecy. Specifically, 1) the\nremote source should remain private from an eavesdropper and the fusion center,\nmeasured in terms of the information leaked about the remote source; 2) the\nfunction computed should remain secret from the eavesdropper, measured in terms\nof the information leaked about the arguments of the function, to ensure\nsecrecy regardless of the exact function used. We derive the exact rate regions\nfor lossless and lossy single-function computation and illustrate the lossy\nsingle-function computation rate region for an information bottleneck example,\nin which the optimal auxiliary random variables are characterized for\nbinary-input symmetric-output channels. We extend the approach to lossless and\nlossy asynchronous multiple-function computations with joint secrecy and\nprivacy constraints, in which case inner and outer bounds for the rate regions\ndiffering only in the Markov chain conditions imposed are characterized.",
    "descriptor": "\nComments: Shorter version to appear in the IEEE International Symposium on Information Theory 2021\n",
    "authors": [
      "Onur G\u00fcnl\u00fc",
      "Matthieu Bloch",
      "Rafael F. Schaefer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.09485"
  },
  {
    "id": "arXiv:2106.09486",
    "title": "Deep HDR Hallucination for Inverse Tone Mapping",
    "abstract": "Inverse Tone Mapping (ITM) methods attempt to reconstruct High Dynamic Range\n(HDR) information from Low Dynamic Range (LDR) image content. The dynamic range\nof well-exposed areas must be expanded and any missing information due to\nover/under-exposure must be recovered (hallucinated). The majority of methods\nfocus on the former and are relatively successful, while most attempts on the\nlatter are not of sufficient quality, even ones based on Convolutional Neural\nNetworks (CNNs). A major factor for the reduced inpainting quality in some\nworks is the choice of loss function. Work based on Generative Adversarial\nNetworks (GANs) shows promising results for image synthesis and LDR inpainting,\nsuggesting that GAN losses can improve inverse tone mapping results. This work\npresents a GAN-based method that hallucinates missing information from badly\nexposed areas in LDR images and compares its efficacy with alternative\nvariations. The proposed method is quantitatively competitive with\nstate-of-the-art inverse tone mapping methods, providing good dynamic range\nexpansion for well-exposed areas and plausible hallucinations for saturated and\nunder-exposed areas. A density-based normalisation method, targeted for HDR\ncontent, is also proposed, as well as an HDR data augmentation method targeted\nfor HDR hallucination.",
    "descriptor": "",
    "authors": [
      "Demetris Marnerides",
      "Thomas Bashford-Rogers",
      "Kurt Debattista"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.09486"
  },
  {
    "id": "arXiv:2106.09487",
    "title": "Synthesizing Modular Manipulators For Tasks With Time, Obstacle, And  Torque Constraints",
    "abstract": "Modular robots can be tailored to achieve specific tasks and rearranged to\nachieve previously infeasible ones. The challenge is choosing an appropriate\ndesign from a large search space. In this work, we describe a framework that\nautomatically synthesizes the design and controls for a serial chain modular\nmanipulator given a task description. The task includes points to be reached in\nthe 3D space, time constraints, a load to be sustained at the end-effector, and\nobstacles to be avoided in the environment. These specifications are encoded as\na constrained optimization in the robot's kinematics and dynamics and, if a\nsolution is found, the formulation returns the specific design and controls to\nperform the task. Finally, we demonstrate our approach on a complex\nspecification in which the robot navigates a constrained environment while\nholding an object.",
    "descriptor": "",
    "authors": [
      "Thais Campos",
      "Hadas Kress-Gazit"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09487"
  },
  {
    "id": "arXiv:2106.09493",
    "title": "Scalable Approach for Normalizing E-commerce Text Attributes (SANTA)",
    "abstract": "In this paper, we present SANTA, a scalable framework to automatically\nnormalize E-commerce attribute values (e.g. \"Win 10 Pro\") to a fixed set of\npre-defined canonical values (e.g. \"Windows 10\"). Earlier works on attribute\nnormalization focused on fuzzy string matching (also referred as syntactic\nmatching in this paper). In this work, we first perform an extensive study of\nnine syntactic matching algorithms and establish that 'cosine' similarity leads\nto best results, showing 2.7% improvement over commonly used Jaccard index.\nNext, we argue that string similarity alone is not sufficient for attribute\nnormalization as many surface forms require going beyond syntactic matching\n(e.g. \"720p\" and \"HD\" are synonyms). While semantic techniques like\nunsupervised embeddings (e.g. word2vec/fastText) have shown good results in\nword similarity tasks, we observed that they perform poorly to distinguish\nbetween close canonical forms, as these close forms often occur in similar\ncontexts. We propose to learn token embeddings using a twin network with\ntriplet loss. We propose an embedding learning task leveraging raw attribute\nvalues and product titles to learn these embeddings in a self-supervised\nfashion. We show that providing supervision using our proposed task improves\nover both syntactic and unsupervised embeddings based techniques for attribute\nnormalization. Experiments on a real-world attribute normalization dataset of\n50 attributes show that the embeddings trained using our proposed approach\nobtain 2.3% improvement over best string matching and 19.3% improvement over\nbest unsupervised embeddings.",
    "descriptor": "\nComments: Accepted in ECNLP workshop of ACL-IJCNLP 2021 (this https URL)\n",
    "authors": [
      "Ravi Shankar Mishra",
      "Kartik Mehta",
      "Nikhil Rasiwasia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09493"
  },
  {
    "id": "arXiv:2106.09500",
    "title": "Making Sense of Complex Sensor Data Streams",
    "abstract": "This concept paper draws from our previous research on individual grip force\ndata collected from biosensors placed on specific anatomical locations in the\ndominant and non dominant hands of operators performing a robot assisted\nprecision grip task for minimally invasive endoscopic surgery. The specificity\nof the robotic system on the one hand, and that of the 2D image guided task\nperformed in a real world 3D space on the other, constrain the individual hand\nand finger movements during task performance in a unique way. Our previous work\nshowed task specific characteristics of operator expertise in terms of specific\ngrip force profiles, which we were able to detect in thousands of highly\nvariable individual data. This concept paper is focused on two complementary\ndata analysis strategies that allow achieving such a goal. In contrast with\nother sensor data analysis strategies aimed at minimizing variance in the data,\nit is in this case here necessary to decipher the meaning of the full extent of\nintra and inter individual variance in the sensor data by using the appropriate\nstatistical analyses, as shown in the first part of this paper. Then, it is\nexplained how the computation of individual spatio temporal grip force profiles\npermits detecting expertise specific differences between individual users. It\nis concluded that these two analytic strategies are complementary. They enable\ndrawing meaning from thousands of biosensor data reflecting human grip\nperformance and its evolution with training, while fully taking into account\ntheir considerable inter and intra individual variability.",
    "descriptor": "",
    "authors": [
      "Rongrong Liu",
      "Birgitta Dresp-Langley"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09500"
  },
  {
    "id": "arXiv:2106.09501",
    "title": "DeepInsight: Interpretability Assisting Detection of Adversarial Samples  on Graphs",
    "abstract": "With the rapid development of artificial intelligence, a series of machine\nlearning algorithms, e.g., graph neural networks, have been proposed to\nfacilitate network analysis or graph data mining. Unfortunately, recent studies\nindicate that such advanced methods may suffer from adversarial attacks, i.e.,\nthey may lose effectiveness when only a small fraction of links are purposely\nchanged. However, little is known what's the difference between adversarial\nnodes and clean nodes, and what's the preference of each attack method, in\nterms of network structure. In this paper, we theoretically investigate three\nwell-known adversarial attack methods, i.e., Nettack, Meta Attack, and\nGradArgmax, and find that different attack methods have their specific attack\npreferences on changing network structure. Such attack patterns are further\nvalidated by the experimental results on real-world networks, i.e., generally\nthe top 4 most important network attributes on detecting adversarial samples\nare sufficient to explain the preference of each attack method. Based on these\nfindings, we further utilize the network attributes to design machine learning\nmodels for adversarial sample detection and attack method recognition,\nachieving the outstanding performance.",
    "descriptor": "",
    "authors": [
      "Junhao Zhu",
      "Yalu Shan",
      "Jinhuan Wang",
      "Shanqing Yu",
      "Guanrong Chen",
      "Qi Xuan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.09501"
  },
  {
    "id": "arXiv:2106.09502",
    "title": "Biomedical Interpretable Entity Representations",
    "abstract": "Pre-trained language models induce dense entity representations that offer\nstrong performance on entity-centric NLP tasks, but such representations are\nnot immediately interpretable. This can be a barrier to model uptake in\nimportant domains such as biomedicine. There has been recent work on general\ninterpretable representation learning (Onoe and Durrett, 2020), but these\ndomain-agnostic representations do not readily transfer to the important domain\nof biomedicine. In this paper, we create a new entity type system and training\nset from a large corpus of biomedical texts by mapping entities to concepts in\na medical ontology, and from these to Wikipedia pages whose categories are our\ntypes. From this mapping we derive Biomedical Interpretable Entity\nRepresentations(BIERs), in which dimensions correspond to fine-grained entity\ntypes, and values are predicted probabilities that a given entity is of the\ncorresponding type. We propose a novel method that exploits BIER's final sparse\nand intermediate dense representations to facilitate model and entity type\ndebugging. We show that BIERs achieve strong performance in biomedical tasks\nincluding named entity disambiguation and entity label classification, and we\nprovide error analysis to highlight the utility of their interpretability,\nparticularly in low-supervision settings. Finally, we provide our induced 68K\nbiomedical type system, the corresponding 37 million triples of derived data\nused to train BIER models and our best performing model.",
    "descriptor": "\nComments: Accepted into Findings of ACL-IJCNLP 2021\n",
    "authors": [
      "Diego Garcia-Olano",
      "Yasumasa Onoe",
      "Ioana Baldini",
      "Joydeep Ghosh",
      "Byron C. Wallace",
      "Kush R. Varshney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09502"
  },
  {
    "id": "arXiv:2106.09503",
    "title": "The Parity Ray Regularizer for Pacing in Auction Markets",
    "abstract": "Budget-management systems are one of the key components of modern auction\nmarkets. Internet advertising platforms typically offer advertisers the\npossibility to pace the rate at which their budget is depleted, through\nbudget-pacing mechanisms. We focus on multiplicative pacing mechanisms in an\nonline setting in which a bidder is repeatedly confronted with a series of\nadvertising opportunities. After collecting bids, each item is then allocated\nthrough a single-item, second-price auction. If there were no budgetary\nconstraints, bidding truthfully would be an optimal choice for the advertiser.\nHowever, since their budget is limited, the advertiser may want to shade their\nbid downwards in order to preserve their budget for future opportunities, and\nto spread expenditures evenly over time. The literature on online pacing\nproblems mostly focuses on the setting in which the bidder optimizes an\nadditive separable objective, such as the total click-through rate or the\nrevenue of the allocation. In many settings, however, bidders may also care\nabout other objectives which oftentimes are non-separable, and therefore not\namenable to traditional online learning techniques. Building on recent work, we\nstudy the frequent case in which advertisers seek to reach a certain\ndistribution of impressions over a target population of users. We introduce a\nnovel regularizer to achieve this desideratum, and show how to integrate it\ninto an online mirror descent scheme attaining the optimal order of sub-linear\nregret compared to the optimal allocation in hindsight when inputs are drawn\nindependently, from an unknown distribution. Moreover, we show that our\napproach can easily be incorporated in standard existing pacing systems that\nare not usually built for this objective. The effectiveness of our algorithm in\ninternet advertising applications is confirmed by numerical experiments on\nreal-world data.",
    "descriptor": "",
    "authors": [
      "Andrea Celli",
      "Riccardo Colini-Baldeschi",
      "Christian Kroer",
      "Eric Sodomka"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.09503"
  },
  {
    "id": "arXiv:2106.09508",
    "title": "KIT Bus: A Shuttle Model for CARLA Simulator",
    "abstract": "With the continuous development of science and technology, self-driving\nvehicles will surely change the nature of transportation and realize the\nautomotive industry's transformation in the future. Compared with self-driving\ncars, self-driving buses are more efficient in carrying passengers and more\nenvironmentally friendly in terms of energy consumption. Therefore, it is\nspeculated that in the future, self-driving buses will become more and more\nimportant. As a simulator for autonomous driving research, the CARLA simulator\ncan help people accumulate experience in autonomous driving technology faster\nand safer. However, a shortcoming is that there is no modern bus model in the\nCARLA simulator. Consequently, people cannot simulate autonomous driving on\nbuses or the scenarios interacting with buses. Therefore, we built a bus model\nin 3ds Max software and imported it into the CARLA to fill this gap. Our model,\nnamely KIT bus, is proven to work in the CARLA by testing it with the autopilot\nsimulation. The video demo is shown on our Youtube.",
    "descriptor": "\nComments: 6 pages, 12 figures\n",
    "authors": [
      "Yusheng Xiang",
      "Shuo Wang",
      "Tianqing Su",
      "Jun Li",
      "Samuel S. Mao",
      "Marcus Geimer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09508"
  },
  {
    "id": "arXiv:2106.09509",
    "title": "Resurrect3D: An Open and Customizable Platform for Visualizing and  Analyzing Cultural Heritage Artifacts",
    "abstract": "Art and culture, at their best, lie in the act of discovery and exploration.\nThis paper describes Resurrect3D, an open visualization platform for both\ncasual users and domain experts to explore cultural artifacts. To that end,\nResurrect3D takes two steps. First, it provides an interactive cultural\nheritage toolbox, providing not only commonly used tools in cultural heritage\nsuch as relighting and material editing, but also the ability for users to\ncreate an interactive \"story\": a saved session with annotations and\nvisualizations others can later replay. Second, Resurrect3D exposes a set of\nprogramming interfaces to extend the toolbox. Domain experts can develop custom\ntools that perform artifact-specific visualization and analysis.",
    "descriptor": "",
    "authors": [
      "Joshua Romphf",
      "Elias Neuman-Donihue",
      "Gregory Heyworth",
      "Yuhao Zhu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.09509"
  },
  {
    "id": "arXiv:2106.09513",
    "title": "The promise of energy-efficient battery-powered urban aircraft",
    "abstract": "Improvements in rechargeable batteries are enabling several electric urban\nair mobility (UAM) aircraft designs with up to 300 miles of range with payload\nequivalents of up to 7 passengers. We find that novel UAM aircraft consume\nbetween 130 Wh/passenger-mile up to ~1,200 Wh/passenger-mile depending on the\ndesign and utilization, relative to an expected consumption of over 220\nWh/passenger-mi for terrestrial electric vehicles and 1,000 Wh/passenger-mile\nfor combustion engine vehicles. We also find that several UAM aircraft designs\nare approaching technological viability with current Li-ion batteries, based on\nthe specific power-and-energy while rechargeability and lifetime performance\nremain uncertain. These aspects highlight the technological readiness of a new\nsegment of transportation.",
    "descriptor": "\nComments: 3 pages, 2 figures, 1 supplementary information file\n",
    "authors": [
      "Shashank Sripad",
      "Venkatasubramanian Viswanathan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09513"
  },
  {
    "id": "arXiv:2106.09516",
    "title": "Transductive Few-Shot Learning: Clustering is All You Need?",
    "abstract": "We investigate a general formulation for clustering and transductive few-shot\nlearning, which integrates prototype-based objectives, Laplacian regularization\nand supervision constraints from a few labeled data points. We propose a\nconcave-convex relaxation of the problem, and derive a computationally\nefficient block-coordinate bound optimizer, with convergence guarantee. At each\niteration,our optimizer computes independent (parallel) updates for each\npoint-to-cluster assignment. Therefore, it could be trivially distributed for\nlarge-scale clustering and few-shot tasks. Furthermore, we provides a thorough\nconvergence analysis based on point-to-set maps. Were port comprehensive\nclustering and few-shot learning experiments over various data sets, showing\nthat our method yields competitive performances, in term of accuracy and\noptimization quality, while scaling up to large problems. Using standard\ntraining on the base classes, without resorting to complex meta-learning and\nepisodic-training strategies, our approach outperforms state-of-the-art\nfew-shot methods by significant margins, across various models, settings and\ndata sets. Surprisingly, we found that even standard clustering procedures\n(e.g., K-means), which correspond to particular, non-regularized cases of our\ngeneral model, already achieve competitive performances in comparison to the\nstate-of-the-art in few-shot learning. These surprising results point to the\nlimitations of the current few-shot benchmarks, and question the viability of a\nlarge body of convoluted few-shot learning techniques in the recent literature.",
    "descriptor": "",
    "authors": [
      "Imtiaz Masud Ziko",
      "Malik Boudiaf",
      "Jose Dolz",
      "Eric Granger",
      "Ismail Ben Ayed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09516"
  },
  {
    "id": "arXiv:2106.09517",
    "title": "Dynamic Knowledge Distillation with A Single Stream Structure for  RGB-DSalient Object Detection",
    "abstract": "RGB-D salient object detection(SOD) demonstrates its superiority on detecting\nin complex environments due to the additional depth information introduced in\nthe data. Inevitably, an independent stream is introduced to extract features\nfrom depth images, leading to extra computation and parameters. This\nmethodology which sacrifices the model size to improve the detection accuracy\nmay impede the practical application of SOD problems. To tackle this dilemma,\nwe propose a dynamic distillation method along with a lightweight framework,\nwhich significantly reduces the parameters. This method considers the factors\nof both teacher and student performance within the training stage and\ndynamically assigns the distillation weight instead of applying a fixed weight\non the student model. Extensive experiments are conducted on five public\ndatasets to demonstrate that our method can achieve competitive performance\ncompared to 10 prior methods through a 78.2MB lightweight structure.",
    "descriptor": "",
    "authors": [
      "Guangyu Ren",
      "Tania Stathaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09517"
  },
  {
    "id": "arXiv:2106.09518",
    "title": "Multi-Layered Blockchain Governance Game",
    "abstract": "This paper deals with design of an integrated secure Blockchain network\nframework to prevent damages from attackers. The multi-layer concept which\ncould handle multiple number of networks is adapted on the top of Blockchain\nGovernance Game frameworks. This new integrated theoretical model is designed\nto find the best strategies toward preparation for preventing whole network\nsystems malfunction from attackers and it is developed based on the combination\nof the Blockchain Governance Game and the Strategic Alliance for Blockchain\nGovernance Game. Analytically tractable results for executing a safety mode are\nfully obtained and simulated results are demonstrated to obtain the optimal\nvalues of hyper parameters of a Blockchain based security network. This\nresearch helps those whom are constructing a multiple layer network by\nenhancing security features through multi-layer framework in a decentralized\nnetwork.",
    "descriptor": "\nComments: This working paper is targeted to submit at an international journal in the Applied Mathematics area\n",
    "authors": [
      "Song-Kyoo Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.09518"
  },
  {
    "id": "arXiv:2106.09524",
    "title": "Implicit Bias of SGD for Diagonal Linear Networks: a Provable Benefit of  Stochasticity",
    "abstract": "Understanding the implicit bias of training algorithms is of crucial\nimportance in order to explain the success of overparametrised neural networks.\nIn this paper, we study the dynamics of stochastic gradient descent over\ndiagonal linear networks through its continuous time version, namely stochastic\ngradient flow. We explicitly characterise the solution chosen by the stochastic\nflow and prove that it always enjoys better generalisation properties than that\nof gradient flow. Quite surprisingly, we show that the convergence speed of the\ntraining loss controls the magnitude of the biasing effect: the slower the\nconvergence, the better the bias. To fully complete our analysis, we provide\nconvergence guarantees for the dynamics. We also give experimental results\nwhich support our theoretical claims. Our findings highlight the fact that\nstructured noise can induce better generalisation and they help explain the\ngreater performances observed in practice of stochastic gradient descent over\ngradient descent.",
    "descriptor": "",
    "authors": [
      "Scott Pesme",
      "Loucas Pillaud-Vivien",
      "Nicolas Flammarion"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09524"
  },
  {
    "id": "arXiv:2106.09526",
    "title": "Exploring the Properties and Evolution of Neural Network Eigenspaces  during Training",
    "abstract": "In this work we explore the information processing inside neural networks\nusing logistic regression probes \\cite{probes} and the saturation metric\n\\cite{featurespace_saturation}. We show that problem difficulty and neural\nnetwork capacity affect the predictive performance in an antagonistic manner,\nopening the possibility of detecting over- and under-parameterization of neural\nnetworks for a given task. We further show that the observed effects are\nindependent from previously reported pathological patterns like the ``tail\npattern'' described in \\cite{featurespace_saturation}. Finally we are able to\nshow that saturation patterns converge early during training, allowing for a\nquicker cycle time during analysis",
    "descriptor": "",
    "authors": [
      "Mats L. Richter Leila Malihi Anne-Kathrin Patricia Windler Ulf Krumnack"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09526"
  },
  {
    "id": "arXiv:2106.09527",
    "title": "Federated Learning for Intrusion Detection System: Concepts, Challenges  and Future Directions",
    "abstract": "The rapid development of the Internet and smart devices trigger surge in\nnetwork traffic making its infrastructure more complex and heterogeneous. The\npredominated usage of mobile phones, wearable devices and autonomous vehicles\nare examples of distributed networks which generate huge amount of data each\nand every day. The computational power of these devices have also seen steady\nprogression which has created the need to transmit information, store data\nlocally and drive network computations towards edge devices. Intrusion\ndetection systems play a significant role in ensuring security and privacy of\nsuch devices. Machine Learning and Deep Learning with Intrusion Detection\nSystems have gained great momentum due to their achievement of high\nclassification accuracy. However the privacy and security aspects potentially\ngets jeopardised due to the need of storing and communicating data to\ncentralized server. On the contrary, federated learning (FL) fits in\nappropriately as a privacy-preserving decentralized learning technique that\ndoes not transfer data but trains models locally and transfers the parameters\nto the centralized server. The present paper aims to present an extensive and\nexhaustive review on the use of FL in intrusion detection system. In order to\nestablish the need for FL, various types of IDS, relevant ML approaches and its\nassociated issues are discussed. The paper presents detailed overview of the\nimplementation of FL in various aspects of anomaly detection. The allied\nchallenges of FL implementations are also identified which provides idea on the\nscope of future direction of research. The paper finally presents the plausible\nsolutions associated with the identified challenges in FL based intrusion\ndetection system implementation acting as a baseline for prospective research.",
    "descriptor": "\nComments: Submitted to JNCA, Elsevier\n",
    "authors": [
      "Shaashwat Agrawal",
      "Sagnik Sarkar",
      "Ons Aouedi",
      "Gokul Yenduri",
      "Kandaraj Piamrat",
      "Sweta Bhattacharya",
      "Praveen Kumar Reddy Maddikunta",
      "Thippa Reddy Gadekallu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09527"
  },
  {
    "id": "arXiv:2106.09533",
    "title": "Author Clustering and Topic Estimation for Short Texts",
    "abstract": "Analysis of short text, such as social media posts, is extremely difficult\nbecause it relies on observing many document-level word co-occurrence pairs.\nBeyond topic distributions, a common downstream task of the modeling is\ngrouping the authors of these documents for subsequent analyses. Traditional\nmodels estimate the document groupings and identify user clusters with an\nindependent procedure. We propose a novel model that expands on the Latent\nDirichlet Allocation by modeling strong dependence among the words in the same\ndocument, with user-level topic distributions. We also simultaneously cluster\nusers, removing the need for post-hoc cluster estimation and improving topic\nestimation by shrinking noisy user-level topic distributions towards typical\nvalues. Our method performs as well as -- or better -- than traditional\napproaches to problems arising in short text, and we demonstrate its usefulness\non a dataset of tweets from United States Senators, recovering both meaningful\ntopics and clusters that reflect partisan ideology.",
    "descriptor": "",
    "authors": [
      "Graham Tierney",
      "Christopher Bail",
      "Alexander Volfovsky"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09533"
  },
  {
    "id": "arXiv:2106.09534",
    "title": "Adversarial Visual Robustness by Causal Intervention",
    "abstract": "Adversarial training is the de facto most promising defense against\nadversarial examples. Yet, its passive nature inevitably prevents it from being\nimmune to unknown attackers. To achieve a proactive defense, we need a more\nfundamental understanding of adversarial examples, beyond the popular bounded\nthreat model. In this paper, we provide a causal viewpoint of adversarial\nvulnerability: the cause is the confounder ubiquitously existing in learning,\nwhere attackers are precisely exploiting the confounding effect. Therefore, a\nfundamental solution for adversarial robustness is causal intervention. As the\nconfounder is unobserved in general, we propose to use the instrumental\nvariable that achieves intervention without the need for confounder\nobservation. We term our robust training method as Causal intervention by\ninstrumental Variable (CiiV). It has a differentiable retinotopic sampling\nlayer and a consistency loss, which is stable and guaranteed not to suffer from\ngradient obfuscation. Extensive experiments on a wide spectrum of attackers and\nsettings applied in MNIST, CIFAR-10, and mini-ImageNet datasets empirically\ndemonstrate that CiiV is robust to adaptive attacks.",
    "descriptor": "\nComments: Codes are available at this https URL\n",
    "authors": [
      "Kaihua Tang",
      "Mingyuan Tao",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09534"
  },
  {
    "id": "arXiv:2106.09536",
    "title": "Single Event Transient Fault Analysis of ELEPHANT cipher",
    "abstract": "In this paper, we propose a novel fault attack termed as Single Event\nTransient Fault Analysis (SETFA) attack, which is well suited for hardware\nimplementations. The proposed approach pinpoints hotspots in the cypher's Sbox\ncombinational logic circuit that significantly reduce the key entropy when\nsubjected to faults. ELEPHANT is a parallel authenticated encryption and\nassociated data (AEAD) scheme targeted to hardware implementations, a finalist\nin the Lightweight cryptography (LWC) competition launched by NIST. In this\nwork, we investigate vulnerabilities of ELEPHANT against fault analysis. We\nobserve that the use of 128-bit random nonce makes it resistant against many\ncryptanalysis techniques like differential, linear, etc., and their variants.\nHowever, the relaxed nature of Statistical Fault Analysis (SFA) methods makes\nthem widely applicable in restrictive environments. We propose a SETFA-based\nkey recovery attack on Elephant. We performed Single experiments with random\nplaintexts and keys, on Dumbo, a Sponge-based instance of the Elephant-AEAD\nscheme. Our proposed approach could recover the secret key in 85-250\nciphertexts. In essence, this work investigates new vulnerabilities towards\nfault analysis that may require to be addressed to ensure secure computations\nand communications in IoT scenarios.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Priyanka Joshi",
      "Bodhistwa Mazumdar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.09536"
  },
  {
    "id": "arXiv:2106.09538",
    "title": "Exploring deterministic frequency deviations with explainable AI",
    "abstract": "Deterministic frequency deviations (DFDs) critically affect power grid\nfrequency quality and power system stability. A better understanding of these\nevents is urgently needed as frequency deviations have been growing in the\nEuropean grid in recent years. DFDs are partially explained by the rapid\nadjustment of power generation following the intervals of electricity trading,\nbut this intuitive picture fails especially before and around noonday. In this\narticle, we provide a detailed analysis of DFDs and their relation to external\nfeatures using methods from explainable Artificial Intelligence. We establish a\nmachine learning model that well describes the daily cycle of DFDs and\nelucidate key interdependencies using SHapley Additive exPlanations (SHAP).\nThereby, we identify solar ramps as critical to explain patterns in the Rate of\nChange of Frequency (RoCoF).",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Johannes Kruse",
      "Benjamin Sch\u00e4fer",
      "Dirk Witthaut"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.09538"
  },
  {
    "id": "arXiv:2106.09543",
    "title": "Future mobility as a bio-inspired collaborative system",
    "abstract": "The current trends towards vehicle-sharing, electrification, and autonomy are\npredicted to transform mobility. Combined appropriately, they have the\npotential of significantly improving urban mobility. However, what will come\nafter most vehicles are shared, electric, and autonomous remains an open\nquestion, especially regarding the interactions between vehicles and how these\ninteractions will impact system-level behaviour. Inspired by nature and\nsupported by swarm robotics and vehicle platooning models, this paper proposes\na future mobility in which shared, electric, and autonomous vehicles behave as\na bio-inspired collaborative system. The collaboration between vehicles will\nlead to a system-level behaviour analogous to natural swarms. Natural swarms\ncan divide tasks, cluster, build together, or transport cooperatively. In this\nfuture mobility, vehicles will cluster by connecting either physically or\nvirtually, which will enable the possibility of sharing energy, data or\ncomputational power, provide services or transfer cargo, among others. Vehicles\nwill collaborate either with vehicles that are part of the same fleet, or with\nany other vehicle on the road, by finding mutualistic relationships that\nbenefit both parties. The field of swarm robotics has already translated some\nof the behaviours from natural swarms to artificial systems and, if we further\ntranslate these concepts into urban mobility, exciting ideas emerge. Within\nmobility-related research, the coordinated movement proposed in vehicle\nplatooning models can be seen as a first step towards collaborative mobility.\nThis paper contributes with the proposal of a framework for future mobility\nthat integrates current research and mobility trends in a novel and unique way.",
    "descriptor": "",
    "authors": [
      "Naroa Coretti S\u00e1nchez",
      "Juan M\u00fagica Gonz\u00e1lez",
      "Luis Alonso Pastor",
      "Kent Larson"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09543"
  },
  {
    "id": "arXiv:2106.09547",
    "title": "Machine Learning for Postprocessing Ensemble Streamflow Forecasts",
    "abstract": "Skillful streamflow forecasting informs decisions in various areas of water\npolicy and management. We integrate dynamical modeling with machine learning to\ndemonstrate the enhanced quality of streamflow forecasts at short-to\nmedium-range timescales (1 - 7 days). Dynamical modeling generates ensemble\nstreamflow forecasts by forcing a hydrological model with numerical weather\nprediction model outputs. We employ a Long Short-Term Memory (LSTM) neural\nnetwork to correct forecast biases in raw ensemble streamflow forecasts\nobtained from dynamical modeling. For forecast verification, we use different\nmetrics such as skill score and reliability diagram conditioned upon the lead\ntime, flow threshold, and season. The verification results show that the LSTM\ncan improve streamflow forecasts relative to climatological, temporal\npersistence, deterministic, and raw ensemble forecasts. The LSTM demonstrates\nimprovement across all lead times, flow thresholds, and seasons. As compared to\nthe raw ensembles, relative gain in forecast skill from LSTM is generally\nhigher at medium-range timescales compared to initial lead time; high flows\ncompared to low-moderate flows; and warm-season compared to the cool ones.\nOverall, our results highlight the benefits of LSTM for improving both the\nskill and reliability of streamflow forecasts.",
    "descriptor": "",
    "authors": [
      "Sanjib Sharma",
      "Ganesh Raj Ghimire",
      "Ridwan Siddique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09547"
  },
  {
    "id": "arXiv:2106.09548",
    "title": "Scale-Consistent Fusion: from Heterogeneous Local Sampling to Global  Immersive Rendering",
    "abstract": "Image-based geometric modeling and novel view synthesis based on sparse,\nlarge-baseline samplings are challenging but important tasks for emerging\nmultimedia applications such as virtual reality and immersive telepresence.\nExisting methods fail to produce satisfactory results due to the limitation on\ninferring reliable depth information over such challenging reference\nconditions. With the popularization of commercial light field (LF) cameras,\ncapturing LF images (LFIs) is as convenient as taking regular photos, and\ngeometry information can be reliably inferred. This inspires us to use a sparse\nset of LF captures to render high-quality novel views globally. However, fusion\nof LF captures from multiple angles is challenging due to the scale\ninconsistency caused by various capture settings. To overcome this challenge,\nwe propose a novel scale-consistent volume rescaling algorithm that robustly\naligns the disparity probability volumes (DPV) among different captures for\nscale-consistent global geometry fusion. Based on the fused DPV projected to\nthe target camera frustum, novel learning-based modules have been proposed\n(i.e., the attention-guided multi-scale residual fusion module, and the\ndisparity field guided deep re-regularization module) which comprehensively\nregularize noisy observations from heterogeneous captures for high-quality\nrendering of novel LFIs. Both quantitative and qualitative experiments over the\nStanford Lytro Multi-view LF dataset show that the proposed method outperforms\nstate-of-the-art methods significantly under different experiment settings for\ndisparity inference and LF synthesis.",
    "descriptor": "",
    "authors": [
      "Wenpeng Xing",
      "Jie Chen",
      "Zaifeng Yang",
      "Qiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09548"
  },
  {
    "id": "arXiv:2106.09553",
    "title": "Do Large Scale Molecular Language Representations Capture Important  Structural Information?",
    "abstract": "Predicting chemical properties from the structure of a molecule is of great\nimportance in many applications including drug discovery and material design.\nMachine learning based molecular property prediction holds the promise of\nenabling accurate predictions at much less complexity, when compared to, for\nexample Density Functional Theory (DFT) calculations. Features extracted from\nmolecular graphs, using graph neural nets in a supervised manner, have emerged\nas strong baselines for such tasks. However, the vast chemical space together\nwith the limited availability of labels makes supervised learning challenging,\ncalling for learning a general-purpose molecular representation. Recently,\npre-trained transformer-based language models (PTLMs) on large unlabeled corpus\nhave produced state-of-the-art results in many downstream natural language\nprocessing tasks. Inspired by this development, here we present molecular\nembeddings obtained by training an efficient transformer encoder model,\nreferred to as MoLFormer. This model was employed with a linear attention\nmechanism and highly paralleized training on 1D SMILES sequences of 1.1 billion\nunlabeled molecules from the PubChem and ZINC datasets. Experiments show that\nthe learned molecular representation performs competitively, when compared to\nexisting graph-based and fingerprint-based supervised learning baselines, on\nthe challenging tasks of predicting properties of QM8 and QM9 molecules.\nFurther task-specific fine-tuning of the MoLFormerr representation improves\nperformance on several of those property prediction benchmarks. These results\nprovide encouraging evidence that large-scale molecular language models can\ncapture sufficient structural information to be able to accurately predict\nquantum chemical properties and beyond.",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Jerret Ross",
      "Brian Belgodere",
      "Vijil Chenthamarakshan",
      "Inkit Padhi",
      "Youssef Mroueh",
      "Payel Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2106.09553"
  },
  {
    "id": "arXiv:2106.09558",
    "title": "Element Intervention for Open Relation Extraction",
    "abstract": "Open relation extraction aims to cluster relation instances referring to the\nsame underlying relation, which is a critical step for general relation\nextraction. Current OpenRE models are commonly trained on the datasets\ngenerated from distant supervision, which often results in instability and\nmakes the model easily collapsed. In this paper, we revisit the procedure of\nOpenRE from a causal view. By formulating OpenRE using a structural causal\nmodel, we identify that the above-mentioned problems stem from the spurious\ncorrelations from entities and context to the relation type. To address this\nissue, we conduct \\emph{Element Intervention}, which intervenes on the context\nand entities respectively to obtain the underlying causal effects of them. We\nalso provide two specific implementations of the interventions based on entity\nranking and context contrasting. Experimental results on unsupervised relation\nextraction datasets show that our methods outperform previous state-of-the-art\nmethods and are robust across different datasets.",
    "descriptor": "\nComments: Accepted to ACL2021(main conference)\n",
    "authors": [
      "Fangchao Liu",
      "Lingyong Yan",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09558"
  },
  {
    "id": "arXiv:2106.09563",
    "title": "On Anytime Learning at Macroscale",
    "abstract": "Classical machine learning frameworks assume access to a possibly large\ndataset in order to train a predictive model. In many practical applications\nhowever, data does not arrive all at once, but in batches over time. This\ncreates a natural trade-off between accuracy of a model and time to obtain such\na model. A greedy predictor could produce non-trivial predictions by\nimmediately training on batches as soon as these become available but, it may\nalso make sub-optimal use of future data. On the other hand, a tardy predictor\ncould wait for a long time to aggregate several batches into a larger dataset,\nbut ultimately deliver a much better performance. In this work, we consider\nsuch a streaming learning setting, which we dub {\\em anytime learning at\nmacroscale} (ALMA). It is an instance of anytime learning applied not at the\nlevel of a single chunk of data, but at the level of the entire sequence of\nlarge batches. We first formalize this learning setting, we then introduce\nmetrics to assess how well learners perform on the given task for a given\nmemory and compute budget, and finally we test several baseline approaches on\nstandard benchmarks repurposed for anytime learning at macroscale. The general\nfinding is that bigger models always generalize better. In particular, it is\nimportant to grow model capacity over time if the initial model is relatively\nsmall. Moreover, updating the model at an intermediate rate strikes the best\ntrade off between accuracy and time to obtain a useful predictor.",
    "descriptor": "",
    "authors": [
      "Lucas Caccia",
      "Jing Xu",
      "Myle Ott",
      "Marc'Aurelio Ranzato",
      "Ludovic Denoyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09563"
  },
  {
    "id": "arXiv:2106.09564",
    "title": "Knowledge distillation from multi-modal to mono-modal segmentation  networks",
    "abstract": "The joint use of multiple imaging modalities for medical image segmentation\nhas been widely studied in recent years. The fusion of information from\ndifferent modalities has demonstrated to improve the segmentation accuracy,\nwith respect to mono-modal segmentations, in several applications. However,\nacquiring multiple modalities is usually not possible in a clinical setting due\nto a limited number of physicians and scanners, and to limit costs and scan\ntime. Most of the time, only one modality is acquired. In this paper, we\npropose KD-Net, a framework to transfer knowledge from a trained multi-modal\nnetwork (teacher) to a mono-modal one (student). The proposed method is an\nadaptation of the generalized distillation framework where the student network\nis trained on a subset (1 modality) of the teacher's inputs (n modalities). We\nillustrate the effectiveness of the proposed framework in brain tumor\nsegmentation with the BraTS 2018 dataset. Using different architectures, we\nshow that the student network effectively learns from the teacher and always\noutperforms the baseline mono-modal network in terms of segmentation accuracy.",
    "descriptor": "\nComments: MICCAI 2020\n",
    "authors": [
      "Minhao Hu",
      "Matthis Maillard",
      "Ya Zhang",
      "Tommaso Ciceri",
      "Giammarco La Barbera",
      "Isabelle Bloch",
      "Pietro Gori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09564"
  },
  {
    "id": "arXiv:2106.09565",
    "title": "Interval Privacy: A Framework for Data Collection",
    "abstract": "The emerging public awareness and government regulations of data privacy\nmotivate new paradigms of collecting and analyzing data transparent and\nacceptable to data owners. We present a new concept of privacy and\ncorresponding data formats, mechanisms, and tradeoffs for privatizing data\nduring data collection. The privacy, named Interval Privacy, enforces the raw\ndata conditional distribution on the privatized data to be the same as its\nunconditional distribution over a nontrivial support set. Correspondingly, the\nproposed privacy mechanism will record each data value as a random interval\ncontaining it. The proposed interval privacy mechanisms can be easily deployed\nthrough most existing survey-based data collection paradigms, e.g., by asking a\nrespondent whether its data value is within a randomly generated range. Another\nunique feature of interval mechanisms is that they obfuscate the truth but not\ndistort it. The way of using narrowed range to convey information is\ncomplementary to the popular paradigm of perturbing data. Also, the interval\nmechanisms can generate progressively refined information at the discretion of\nindividual respondents. We study different theoretical aspects of the proposed\nprivacy. In the context of supervised learning, we also offer a method such\nthat existing supervised learning algorithms designed for point-valued data\ncould be directly applied to learning from interval-valued data.",
    "descriptor": "",
    "authors": [
      "Jie Ding",
      "Bangjun Ding"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09565"
  },
  {
    "id": "arXiv:2106.09572",
    "title": "Topic Modeling and Progression of American Digital News Media During the  Onset of the COVID-19 Pandemic",
    "abstract": "Currently, the world is in the midst of a severe global pandemic, which has\naffected all aspects of people's lives. As a result, there is a deluge of\nCOVID-related digital media articles published in the United States, due to the\ndisparate effects of the pandemic. This large volume of information is\ndifficult to consume by the audience in a reasonable amount of time. In this\npaper, we develop a Natural Language Processing (NLP) pipeline that is capable\nof automatically distilling various digital articles into manageable pieces of\ninformation, while also modelling the progression topics discussed over time in\norder to aid readers in rapidly gaining holistic perspectives on pressing\nissues (i.e., the COVID-19 pandemic) from a diverse array of sources. We\nachieve these goals by first collecting a large corpus of COVID-related\narticles during the onset of the pandemic. After, we apply unsupervised and\nsemi-supervised learning procedures to summarize articles, then cluster them\nbased on their similarities using the community detection methods. Next, we\nidentify the topic of each cluster of articles using the BART algorithm.\nFinally, we provide a detailed digital media analysis based on the NLP-pipeline\noutputs and show how the conversation surrounding COVID-19 evolved over time.",
    "descriptor": "",
    "authors": [
      "Xiangpeng Wan",
      "Michael C. Lucic",
      "Hakim Ghazzai",
      "Yehia Massoud"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09572"
  },
  {
    "id": "arXiv:2106.09575",
    "title": "Rotation Invariant Graph Neural Networks using Spin Convolutions",
    "abstract": "Progress towards the energy breakthroughs needed to combat climate change can\nbe significantly accelerated through the efficient simulation of atomic\nsystems. Simulation techniques based on first principles, such as Density\nFunctional Theory (DFT), are limited in their practical use due to their high\ncomputational expense. Machine learning approaches have the potential to\napproximate DFT in a computationally efficient manner, which could dramatically\nincrease the impact of computational simulations on real-world problems.\nApproximating DFT poses several challenges. These include accurately modeling\nthe subtle changes in the relative positions and angles between atoms, and\nenforcing constraints such as rotation invariance or energy conservation. We\nintroduce a novel approach to modeling angular information between sets of\nneighboring atoms in a graph neural network. Rotation invariance is achieved\nfor the network's edge messages through the use of a per-edge local coordinate\nframe and a novel spin convolution over the remaining degree of freedom. Two\nmodel variants are proposed for the applications of structure relaxation and\nmolecular dynamics. State-of-the-art results are demonstrated on the\nlarge-scale Open Catalyst 2020 dataset. Comparisons are also performed on the\nMD17 and QM9 datasets.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Muhammed Shuaibi",
      "Adeesh Kolluru",
      "Abhishek Das",
      "Aditya Grover",
      "Anuroop Sriram",
      "Zachary Ulissi",
      "C. Lawrence Zitnick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.09575"
  },
  {
    "id": "arXiv:2106.09578",
    "title": "Modeling Worlds in Text",
    "abstract": "We provide a dataset that enables the creation of learning agents that can\nbuild knowledge graph-based world models of interactive narratives. Interactive\nnarratives -- or text-adventure games -- are partially observable environments\nstructured as long puzzles or quests in which an agent perceives and interacts\nwith the world purely through textual natural language. Each individual game\ntypically contains hundreds of locations, characters, and objects -- each with\ntheir own unique descriptions -- providing an opportunity to study the problem\nof giving language-based agents the structured memory necessary to operate in\nsuch worlds. Our dataset provides 24198 mappings between rich natural language\nobservations and: (1) knowledge graphs that reflect the world state in the form\nof a map; (2) natural language actions that are guaranteed to cause a change in\nthat particular world state. The training data is collected across 27 games in\nmultiple genres and contains a further 7836 heldout instances over 9 additional\ngames in the test set. We further provide baseline models using rules-based,\nquestion-answering, and sequence learning approaches in addition to an analysis\nof the data and corresponding learning tasks.",
    "descriptor": "\nComments: Preprint. Under review. Benchmark can be found at this https URL\n",
    "authors": [
      "Prithviraj Ammanabrolu",
      "Mark O. Riedl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09578"
  },
  {
    "id": "arXiv:2106.09580",
    "title": "Optimality and Stability in Federated Learning: A Game-theoretic  Approach",
    "abstract": "Federated learning is a distributed learning paradigm where multiple agents,\neach only with access to local data, jointly learn a global model. There has\nrecently been an explosion of research aiming not only to improve the accuracy\nrates of federated learning, but also provide certain guarantees around social\ngood properties such as total error. One branch of this research has taken a\ngame-theoretic approach, and in particular, prior work has viewed federated\nlearning as a hedonic game, where error-minimizing players arrange themselves\ninto federating coalitions. This past work proves the existence of stable\ncoalition partitions, but leaves open a wide range of questions, including how\nfar from optimal these stable solutions are. In this work, we motivate and\ndefine a notion of optimality given by the average error rates among federating\nagents (players). First, we provide and prove the correctness of an efficient\nalgorithm to calculate an optimal (error minimizing) arrangement of players.\nNext, we analyze the relationship between the stability and optimality of an\narrangement. First, we show that for some regions of parameter space, all\nstable arrangements are optimal (Price of Anarchy equal to 1). However, we show\nthis is not true for all settings: there exist examples of stable arrangements\nwith higher cost than optimal (Price of Anarchy greater than 1). Finally, we\ngive the first constant-factor bound on the performance gap between stability\nand optimality, proving that the total error of the worst stable solution can\nbe no higher than 9 times the total error of an optimal solution (Price of\nAnarchy bound of 9).",
    "descriptor": "",
    "authors": [
      "Kate Donahue",
      "Jon Kleinberg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09580"
  },
  {
    "id": "arXiv:2106.09584",
    "title": "SIFT Matching by Context Exposed",
    "abstract": "This paper investigates how to step up local image descriptor matching by\nexploiting matching context information. Two main contexts are identified,\noriginated respectively from the descriptor space and from the keypoint space.\nThe former is generally used to design the actual matching strategy while the\nlatter to filter matches according to the local spatial consistency. On this\nbasis, a new matching strategy and a novel local spatial filter, named\nrespectively blob matching and Delaunay Triangulation Matching (DTM) are\ndevised. Blob matching provides a general matching framework by merging\ntogether several strategies, including pre-filtering as well as many-to-many\nand symmetric matching, enabling to achieve a global improvement upon each\nindividual strategy. DTM alternates between Delaunay triangulation contractions\nand expansions to figure out and adjust keypoint neighborhood consistency.\nExperimental evaluation shows that DTM is comparable or better than the\nstate-of-the-art in terms of matching accuracy and robustness, especially for\nnon-planar scenes. Evaluation is carried out according to a new benchmark\ndevised for analyzing the matching pipeline in terms of correct correspondences\non both planar and non-planar scenes, including state-of-the-art methods as\nwell as the common SIFT matching approach for reference. This evaluation can be\nof assistance for future research in this field.",
    "descriptor": "\nComments: Early paper version\n",
    "authors": [
      "Fabio Bellavia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09584"
  },
  {
    "id": "arXiv:2106.09586",
    "title": "Prevalence and Propagation of Fake News",
    "abstract": "In recent years, scholars have raised concerns on the effects that unreliable\nnews, or \"fake news,\" has on our political sphere, and our democracy as a\nwhole. For example, the propagation of fake news on social media is widely\nbelieved to have influenced the outcome of national elections, including the\n2016 U.S. Presidential Election, and the 2020 COVID-19 pandemic. What drives\nthe propagation of fake news on an individual level, and which interventions\ncould effectively reduce the propagation rate? Our model disentangles bias from\ntruthfulness of an article and examines the relationship between these two\nparameters and a reader's own beliefs. Using the model, we create policy\nrecommendations for both social media platforms and individual social media\nusers to reduce the spread of untruthful or highly biased news. We recommend\nthat platforms sponsor unbiased truthful news, focus fact-checking efforts on\nmild to moderately biased news, recommend friend suggestions across the\npolitical spectrum, and provide users with reports about the political\nalignment of their feed. We recommend that individual social media users fact\ncheck news that strongly aligns with their political bias and read articles of\nopposing political bias.",
    "descriptor": "\nComments: 45 pages, 22 figures. Submitted for peer review on 7 May 2021\n",
    "authors": [
      "Banafsheh Behzad",
      "Bhavana Bheem",
      "Daniela Elizondo",
      "Deyana Marsh",
      "Susan Martonosi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Optimization and Control (math.OC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.09586"
  },
  {
    "id": "arXiv:2106.09588",
    "title": "End-to-End Cross-Domain Text-to-SQL Semantic Parsing with Auxiliary Task",
    "abstract": "In this work, we focus on two crucial components in the cross-domain\ntext-to-SQL semantic parsing task: schema linking and value filling. To\nencourage the model to learn better encoding ability, we propose a column\nselection auxiliary task to empower the encoder with the relevance matching\ncapability by using explicit learning targets. Furthermore, we propose two\nvalue filling methods to build the bridge from the existing zero-shot semantic\nparsers to real-world applications, considering most of the existing parsers\nignore the values filling in the synthesized SQL. With experiments on Spider,\nour proposed framework improves over the baselines on the execution accuracy\nand exact set match accuracy when database contents are unavailable, and\ndetailed analysis sheds light on future work.",
    "descriptor": "",
    "authors": [
      "Peng Shi",
      "Tao Yu",
      "Patrick Ng",
      "Zhiguo Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09588"
  },
  {
    "id": "arXiv:2106.09589",
    "title": "Classifying vaccine sentiment tweets by modelling domain-specific  representation and commonsense knowledge into context-aware attentive GRU",
    "abstract": "Vaccines are an important public health measure, but vaccine hesitancy and\nrefusal can create clusters of low vaccine coverage and reduce the\neffectiveness of vaccination programs. Social media provides an opportunity to\nestimate emerging risks to vaccine acceptance by including geographical\nlocation and detailing vaccine-related concerns. Methods for classifying social\nmedia posts, such as vaccine-related tweets, use language models (LMs) trained\non general domain text. However, challenges to measuring vaccine sentiment at\nscale arise from the absence of tonal stress and gestural cues and may not\nalways have additional information about the user, e.g., past tweets or social\nconnections. Another challenge in LMs is the lack of commonsense knowledge that\nare apparent in users metadata, i.e., emoticons, positive and negative words\netc. In this study, to classify vaccine sentiment tweets with limited\ninformation, we present a novel end-to-end framework consisting of\ninterconnected components that use domain-specific LM trained on\nvaccine-related tweets and models commonsense knowledge into a bidirectional\ngated recurrent network (CK-BiGRU) with context-aware attention. We further\nleverage syntactical, user metadata and sentiment information to capture the\nsentiment of a tweet. We experimented using two popular vaccine-related Twitter\ndatasets and demonstrate that our proposed approach outperforms\nstate-of-the-art models in identifying pro-vaccine, anti-vaccine and neutral\ntweets.",
    "descriptor": "\nComments: Accepted in International Joint Conference on Neural Networks (IJCNN) 2021\n",
    "authors": [
      "Usman Naseem",
      "Matloob Khushi",
      "Jinman Kim",
      "Adam G. Dunn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09589"
  },
  {
    "id": "arXiv:2106.09590",
    "title": "Open Data and the Status Quo -- A Fine-Grained Evaluation Framework for  Open Data Quality and an Analysis of Open Data portals in Germany",
    "abstract": "This paper presents a framework for assessing data and metadata quality\nwithin Open Data portals. Although a few benchmark frameworks already exist for\nthis purpose, they are not yet detailed enough in both breadth and depth to\nmake valid statements about the actual discoverability and accessibility of\npublicly available data collections. To address this research gap, we have\ndesigned a quality framework that is able to evaluate data quality in Open Data\nportals on dedicated and fine-grained dimensions, such as interoperability,\nfindability, uniqueness or completeness. Additionally, we propose quality\nmeasures that allow for valid assessments regarding cross-portal findability\nand uniqueness of dataset descriptions. We have validated our novel quality\nframework for the German Open Data landscape and found out that metadata often\nstill lacks meaningful descriptions and is not yet extensively connected to the\nSemantic Web.",
    "descriptor": "",
    "authors": [
      "Lisa Wenige",
      "Claus Stadler",
      "Michael Martin",
      "Richard Figura",
      "Robert Sauter",
      "Christopher W. Frank"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.09590"
  },
  {
    "id": "arXiv:2106.09592",
    "title": "Data lake concept and systems: a survey",
    "abstract": "Although big data has been discussed for some years, it still has many\nresearch challenges, especially the variety of data. It poses a huge difficulty\nto efficiently integrate, access, and query the large volume of diverse data in\ninformation silos with the traditional 'schema-on-write' approaches such as\ndata warehouses. Data lakes have been proposed as a solution to this problem.\nThey are repositories storing raw data in its original formats and providing a\ncommon access interface. This survey reviews the development, definition, and\narchitectures of data lakes. We provide a comprehensive overview of research\nquestions for designing and building data lakes. We classify the existing data\nlake systems based on their provided functions, which makes this survey a\nuseful technical reference for designing, implementing and applying data lakes.\nWe hope that the thorough comparison of existing solutions and the discussion\nof open research challenges in this survey would motivate the future\ndevelopment of data lake research and practice.",
    "descriptor": "",
    "authors": [
      "Rihan Hai",
      "Christoph Quix",
      "Matthias Jarke"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.09592"
  },
  {
    "id": "arXiv:2106.09599",
    "title": "On PQC Migration and Crypto-Agility",
    "abstract": "Besides the development of PQC algorithms, the actual migration of IT systems\nto such new schemes has to be considered, best by utilizing or establishing\ncrypto-agility. Much work in this respect is currently conducted all over the\nworld, making it hard to keep track of the many individual challenges and\nrespective solutions that have been identified. In consequence, it is difficult\nto judge for both individual application scenarios and on a global scale,\nwhether all (known) challenges have been addressed respectively or what their\ncurrent state is. We provide a literature survey and a snapshot of the\ndiscovered challenges and solutions categorized in different areas. We use this\nas starting point for a community project to keep track of the ongoing efforts\nand the state of the art in this field. Thereby we offer a single entry-point\ninto the subject reflecting the current state in a timely manner.",
    "descriptor": "\nComments: 12 pages, 2 tables\n",
    "authors": [
      "Alexander Wiesmaier",
      "Nouri Alnahawi",
      "Tobias Grasmeyer",
      "Julian Gei\u00dfler",
      "Alexander Zeier",
      "Pia Bauspie\u00df",
      "Andreas Heinemann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09599"
  },
  {
    "id": "arXiv:2106.09608",
    "title": "Learning Knowledge Graph-based World Models of Textual Environments",
    "abstract": "World models improve a learning agent's ability to efficiently operate in\ninteractive and situated environments. This work focuses on the task of\nbuilding world models of text-based game environments. Text-based games, or\ninteractive narratives, are reinforcement learning environments in which agents\nperceive and interact with the world using textual natural language. These\nenvironments contain long, multi-step puzzles or quests woven through a world\nthat is filled with hundreds of characters, locations, and objects. Our world\nmodel learns to simultaneously: (1) predict changes in the world caused by an\nagent's actions when representing the world as a knowledge graph; and (2)\ngenerate the set of contextually relevant natural language actions required to\noperate in the world. We frame this task as a Set of Sequences generation\nproblem by exploiting the inherent structure of knowledge graphs and actions\nand introduce both a transformer-based multi-task architecture and a loss\nfunction to train it. A zero-shot ablation study on never-before-seen textual\nworlds shows that our methodology significantly outperforms existing textual\nworld modeling techniques as well as the importance of each of our\ncontributions.",
    "descriptor": "\nComments: Preprint. Under review\n",
    "authors": [
      "Prithviraj Ammanabrolu",
      "Mark O. Riedl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09608"
  },
  {
    "id": "arXiv:2106.09613",
    "title": "Meta-Calibration: Meta-Learning of Model Calibration Using  Differentiable Expected Calibration Error",
    "abstract": "Calibration of neural networks is a topical problem that is becoming\nincreasingly important for real-world use of neural networks. The problem is\nespecially noticeable when using modern neural networks, for which there is\nsignificant difference between the model confidence and the confidence it\nshould have. Various strategies have been successfully proposed, yet there is\nmore space for improvements. We propose a novel approach that introduces a\ndifferentiable metric for expected calibration error and successfully uses it\nas an objective for meta-learning, achieving competitive results with\nstate-of-the-art approaches. Our approach presents a new direction of using\nmeta-learning to directly optimize model calibration, which we believe will\ninspire further work in this promising and new direction.",
    "descriptor": "",
    "authors": [
      "Ondrej Bohdal",
      "Yongxin Yang",
      "Timothy Hospedales"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09613"
  },
  {
    "id": "arXiv:2106.09614",
    "title": "To fit or not to fit: Model-based Face Reconstruction and Occlusion  Segmentation from Weak Supervision",
    "abstract": "3D face reconstruction from a single image is challenging due to its\nill-posed nature. Model-based face autoencoders address this issue effectively\nby fitting a face model to the target image in a weakly supervised manner.\nHowever, in unconstrained environments occlusions distort the face\nreconstruction because the model often erroneously tries to adapt to occluded\nface regions. Supervised occlusion segmentation is a viable solution to avoid\nthe fitting of occluded face regions, but it requires a large amount of\nannotated training data. In this work, we enable model-based face autoencoders\nto segment occluders accurately without requiring any additional supervision\nduring training, and this separates regions where the model will be fitted from\nthose where it will not be fitted. To achieve this, we extend face autoencoders\nwith a segmentation network. The segmentation network decides which regions the\nmodel should adapt to by reaching balances in a trade-off between including\npixels and adapting the model to them, and excluding pixels so that the model\nfitting is not negatively affected and reaches higher overall reconstruction\naccuracy on pixels showing the face. This leads to a synergistic effect, in\nwhich the occlusion segmentation guides the training of the face autoencoder to\nconstrain the fitting in the non-occluded regions, while the improved fitting\nenables the segmentation model to better predict the occluded face regions.\nQualitative and quantitative experiments on the CelebA-HQ database and the AR\ndatabase verify the effectiveness of our model in improving 3D face\nreconstruction under occlusions and in enabling accurate occlusion segmentation\nfrom weak supervision only. Code available at\nhttps://github.com/unibas-gravis/Occlusion-Robust-MoFA.",
    "descriptor": "",
    "authors": [
      "Chunlu Li",
      "Andreas Morel-Forster",
      "Thomas Vetter",
      "Bernhard Egger",
      "Adam Kortylewski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09614"
  },
  {
    "id": "arXiv:2106.09621",
    "title": "Privacy-Preserving Eye-tracking Using Deep Learning",
    "abstract": "The expanding usage of complex machine learning methods like deep learning\nhas led to an explosion in human activity recognition, particularly applied to\nhealth. In particular, as part of a larger body sensor network system, face and\nfull-body analysis is becoming increasingly common for evaluating health\nstatus. However, complex models which handle private and sometimes protected\ndata, raise concerns about the potential leak of identifiable data. In this\nwork, we focus on the case of a deep network model trained on images of\nindividual faces. Full-face video recordings taken from 493 individuals\nundergoing an eye-tracking based evaluation of neurological function were used.\nOutputs, gradients, intermediate layer outputs, loss, and labels were used as\ninputs for a deep network with an added support vector machine emission layer\nto recognize membership in the training data. The inference attack method and\nassociated mathematical analysis indicate that there is a low likelihood of\nunintended memorization of facial features in the deep learning model. In this\nstudy, it is showed that the named model preserves the integrity of training\ndata with reasonable confidence. The same process can be implemented in similar\nconditions for different models.",
    "descriptor": "",
    "authors": [
      "Salman Seyedi",
      "Zifan Jiang",
      "Allan Levey",
      "Gari D. Clifford"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09621"
  },
  {
    "id": "arXiv:2106.09623",
    "title": "Towards Explainable Student Group Collaboration Assessment Models Using  Temporal Representations of Individual Student Roles",
    "abstract": "Collaboration is identified as a required and necessary skill for students to\nbe successful in the fields of Science, Technology, Engineering and Mathematics\n(STEM). However, due to growing student population and limited teaching staff\nit is difficult for teachers to provide constructive feedback and instill\ncollaborative skills using instructional methods. Development of simple and\neasily explainable machine-learning-based automated systems can help address\nthis problem. Improving upon our previous work, in this paper we propose using\nsimple temporal-CNN deep-learning models to assess student group collaboration\nthat take in temporal representations of individual student roles as input. We\ncheck the applicability of dynamically changing feature representations for\nstudent group collaboration assessment and how they impact the overall\nperformance. We also use Grad-CAM visualizations to better understand and\ninterpret the important temporal indices that led to the deep-learning model's\ndecision.",
    "descriptor": "\nComments: Accepted in the poster session at the 14th International Conference on Educational Data Mining\n",
    "authors": [
      "Anirudh Som",
      "Sujeong Kim",
      "Bladimir Lopez-Prado",
      "Svati Dhamija",
      "Nonye Alozie",
      "Amir Tamrakar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09623"
  },
  {
    "id": "arXiv:2106.09624",
    "title": "Probabilistic Stability Assessment for Active Distribution Grids",
    "abstract": "This paper demonstrates the concept of probabilistic stability assessment on\nlarge-signal stability in the use case of short circuits in an active\ndistribution grid. Here, the concept of survivability is applied, which extends\nclassical stability assessments by evaluating the stability and operational\nlimits during transients for a wide range of operating points and failures. For\nthis purpose, a free, open-source, and computationally efficient environment\n(Julia) for dynamic simulation of power grids is used to demonstrate its\ncapabilities. The model implementation is validated against established\ncommercial software and deviations are minimal with respect to power flow and\ndynamic simulations.The results of a large-scale survivability analysis reveal\ni) a broad field of application for probabilistic stability analysis and ii)\nthat new non-intuitive stability correlations can be obtained. Hence,the\nproposed method shows strong potential to efficiently conduct power system\nstability analysis in active distribution grids.",
    "descriptor": "\nComments: submiited to IEEE PowerTech 2021 Madrid conference\n",
    "authors": [
      "Sebastian Liemann",
      "Lia Strenge",
      "Paul Schultz",
      "Holm Hinners",
      "Johannis Porst",
      "Marcel Sarstedt",
      "Frank Hellmann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2106.09624"
  },
  {
    "id": "arXiv:2106.09627",
    "title": "Towards Prevention of Sportsmen Burnout: Formal Analysis of Sub-Optimal  Tournament Scheduling",
    "abstract": "Scheduling a sports tournament is a complex optimization problem, which\nrequires a large number of hard constraints to satisfy. Despite the\navailability of several such constraints in the literature, there remains a gap\nsince most of the new sports events pose their own unique set of requirements,\nand demand novel constraints. Specifically talking of the strictly time bound\nevents, ensuring fairness between the different teams in terms of their rest\ndays, traveling, and the number of successive games they play, becomes a\ndifficult task to resolve, and demands attention. In this work, we present a\nsimilar situation with a recently played sports event, where a suboptimal\nschedule favored some of the sides more than the others. We introduce various\ncompetitive parameters to draw a fairness comparison between the sides and\npropose a weighting criterion to point out the sides that enjoyed this schedule\nmore than the others. Furthermore, we use root mean squared error between an\nideal schedule and the actual ones for each side to determine unfairness in the\ndistribution of rest days across their entire schedules. The latter is crucial,\nsince successively playing a large number of games may lead to sportsmen\nburnout, which must be prevented.",
    "descriptor": "\nComments: 15 pages, 6 figures, CMC-Computers, Materials & Continua\n",
    "authors": [
      "Syed Rameez Naqvi",
      "Adnan Ahmad",
      "S. M. Riazul Islam",
      "Tallha Akram",
      "M. Abdullah-Al-Wadud",
      "Atif Alamri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09627"
  },
  {
    "id": "arXiv:2106.09636",
    "title": "Multi-Modal Prototype Learning for Interpretable Multivariable Time  Series Classification",
    "abstract": "Multivariable time series classification problems are increasing in\nprevalence and complexity in a variety of domains, such as biology and finance.\nWhile deep learning methods are an effective tool for these problems, they\noften lack interpretability. In this work, we propose a novel modular prototype\nlearning framework for multivariable time series classification. In the first\nstage of our framework, encoders extract features from each variable\nindependently. Prototype layers identify single-variable prototypes in the\nresulting feature spaces. The next stage of our framework represents the\nmultivariable time series sample points in terms of their similarity to these\nsingle-variable prototypes. This results in an inherently interpretable\nrepresentation of multivariable patterns, on which prototype learning is\napplied to extract representative examples i.e. multivariable prototypes. Our\nframework is thus able to explicitly identify both informative patterns in the\nindividual variables, as well as the relationships between the variables. We\nvalidate our framework on a simulated dataset with embedded patterns, as well\nas a real human activity recognition problem. Our framework attains comparable\nor superior classification performance to existing time series classification\nmethods on these tasks. On the simulated dataset, we find that our model\nreturns interpretations consistent with the embedded patterns. Moreover, the\ninterpretations learned on the activity recognition dataset align with domain\nknowledge.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Gaurav R. Ghosal",
      "Reza Abbasi-Asl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09636"
  },
  {
    "id": "arXiv:2106.09637",
    "title": "AttDLNet: Attention-based DL Network for 3D LiDAR Place Recognition",
    "abstract": "Deep networks have been progressively adapted to new sensor modalities,\nnamely to 3D LiDAR, which led to unprecedented achievements in autonomous\nvehicle-related applications such as place recognition. One of the main\nchallenges of deep models in place recognition is to extract efficient and\ndescriptive feature representations that relate places based on their\nsimilarity. To address the problem of place recognition using LiDAR data, this\npaper proposes a novel 3D LiDAR-based deep learning network (named AttDLNet)\nthat comprises an encoder network and exploits an attention mechanism to\nselectively focus on long-range context and interfeature relationships. The\nproposed network is trained and validated on the KITTI dataset, using the\ncosine loss for training and a retrieval-based place recognition pipeline for\nvalidation. Additionally, an ablation study is presented to assess the best\nnetwork configuration. Results show that the encoder network features are\nalready very descriptive, but adding attention to the network further improves\nperformance. From the ablation study, results indicate that the middle encoder\nlayers have the highest mean performance, while deeper layers are more robust\nto orientation change. The code is publicly available on the project website:\nhttps://github.com/Cybonic/ AttDLNet",
    "descriptor": "",
    "authors": [
      "Tiago Barros",
      "Lu\u00eds Garrote",
      "Ricardo Pereira",
      "Cristiano Premebida",
      "Urbano J. Nunes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09637"
  },
  {
    "id": "arXiv:2106.09640",
    "title": "Microgrid Resilience: A Holistic and Context-Aware Resilience Metric",
    "abstract": "Microgrids present an effective solution for the coordinated deployment of\nvarious distributed energy resources and furthermore provide myriad additional\nbenefits such as resilience, decreased carbon footprint, and reliability to\nenergy consumers and the energy system as a whole. Boosting the resilience of\ndistribution systems is another major benefit of microgrids. This is because\nthey can also serve as a backup power source when the utility grid operations\nare interrupted due to either high-probability low-impact events like a\ncomponent failure or low-probability high-impact events - be it a natural\ndisaster or a planned cyberattack. However, the degree to which any particular\nsystem can defend, adapt, and restore normal operation depends on various\nfactors including the type and severity of events to which a microgrid is\nsubjected. These factors, in turn, are dependent on the geographical location\nof the deployed microgrid as well as the cyber risk profile of the site where\nthe microgrid is operating. Therefore, in this work, we attempt to capture this\nmulti-dimensional interplay of various factors in quantifying the ability of\nthe microgrid to be resilient in these varying aspects. This paper, thus,\nproposes a customized site-specific quantification of the resilience strength\nfor the individual microgrid capability to absorb, restore, and adapt to the\nchanging circumstances for sustaining the critical load when a low-probability\nhigh-impact event occurs - termed as - context-aware resilience metric. We also\npresent a case study to illustrate the key elements of our integrated\nanalytical approach.",
    "descriptor": "\nComments: 15 pages, 5 figures, in journal review\n",
    "authors": [
      "Sakshi Mishra",
      "Ted Kwasnik",
      "Kate Anderson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09640"
  },
  {
    "id": "arXiv:2106.09643",
    "title": "MetaBalance: High-Performance Neural Networks for Class-Imbalanced Data",
    "abstract": "Class-imbalanced data, in which some classes contain far more samples than\nothers, is ubiquitous in real-world applications. Standard techniques for\nhandling class-imbalance usually work by training on a re-weighted loss or on\nre-balanced data. Unfortunately, training overparameterized neural networks on\nsuch objectives causes rapid memorization of minority class data. To avoid this\ntrap, we harness meta-learning, which uses both an ''outer-loop'' and an\n''inner-loop'' loss, each of which may be balanced using different strategies.\nWe evaluate our method, MetaBalance, on image classification, credit-card fraud\ndetection, loan default prediction, and facial recognition tasks with severely\nimbalanced data, and we find that MetaBalance outperforms a wide array of\npopular re-sampling strategies.",
    "descriptor": "",
    "authors": [
      "Arpit Bansal",
      "Micah Goldblum",
      "Valeriia Cherepanova",
      "Avi Schwarzschild",
      "C. Bayan Bruss",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09643"
  },
  {
    "id": "arXiv:2106.09645",
    "title": "Prototypical Graph Contrastive Learning",
    "abstract": "Graph-level representations are critical in various real-world applications,\nsuch as predicting the properties of molecules. But in practice, precise graph\nannotations are generally very expensive and time-consuming. To address this\nissue, graph contrastive learning constructs instance discrimination task which\npulls together positive pairs (augmentation pairs of the same graph) and pushes\naway negative pairs (augmentation pairs of different graphs) for unsupervised\nrepresentation learning. However, since for a query, its negatives are\nuniformly sampled from all graphs, existing methods suffer from the critical\nsampling bias issue, i.e., the negatives likely having the same semantic\nstructure with the query, leading to performance degradation. To mitigate this\nsampling bias issue, in this paper, we propose a Prototypical Graph Contrastive\nLearning (PGCL) approach. Specifically, PGCL models the underlying semantic\nstructure of the graph data via clustering semantically similar graphs into the\nsame group, and simultaneously encourages the clustering consistency for\ndifferent augmentations of the same graph. Then given a query, it performs\nnegative sampling via drawing the graphs from those clusters that differ from\nthe cluster of query, which ensures the semantic difference between query and\nits negative samples. Moreover, for a query, PGCL further reweights its\nnegative samples based on the distance between their prototypes (cluster\ncentroids) and the query prototype such that those negatives having moderate\nprototype distance enjoy relatively large weights. This reweighting strategy is\nproved to be more effective than uniform sampling. Experimental results on\nvarious graph benchmarks testify the advantages of our PGCL over\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Shuai Lin",
      "Pan Zhou",
      "Zi-Yuan Hu",
      "Shuojia Wang",
      "Ruihui Zhao",
      "Yefeng Zheng",
      "Liang Lin",
      "Eric Xing",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09645"
  },
  {
    "id": "arXiv:2106.09647",
    "title": "Deep Learning Through the Lens of Example Difficulty",
    "abstract": "Existing work on understanding deep learning often employs measures that\ncompress all data-dependent information into a few numbers. In this work, we\nadopt a perspective based on the role of individual examples. We introduce a\nmeasure of the computational difficulty of making a prediction for a given\ninput: the (effective) prediction depth. Our extensive investigation reveals\nsurprising yet simple relationships between the prediction depth of a given\ninput and the model's uncertainty, confidence, accuracy and speed of learning\nfor that data point. We further categorize difficult examples into three\ninterpretable groups, demonstrate how these groups are processed differently\ninside deep models and showcase how this understanding allows us to improve\nprediction accuracy. Insights from our study lead to a coherent view of a\nnumber of separately reported phenomena in the literature: early layers\ngeneralize while later layers memorize; early layers converge faster and\nnetworks learn easy data and simple functions first.",
    "descriptor": "\nComments: Main paper: 15 pages, 8 figures. Appendix: 31 pages, 40 figures\n",
    "authors": [
      "Robert J. N. Baldock",
      "Hartmut Maennel",
      "Behnam Neyshabur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09647"
  },
  {
    "id": "arXiv:2106.09650",
    "title": "Multi-head or Single-head? An Empirical Comparison for Transformer  Training",
    "abstract": "Multi-head attention plays a crucial role in the recent success of\nTransformer models, which leads to consistent performance improvements over\nconventional attention in various applications. The popular belief is that this\neffectiveness stems from the ability of jointly attending multiple positions.\nIn this paper, we first demonstrate that jointly attending multiple positions\nis not a unique feature of multi-head attention, as multi-layer single-head\nattention also attends multiple positions and is more effective. Then, we\nsuggest the main advantage of the multi-head attention is the training\nstability, since it has less number of layers than the single-head attention,\nwhen attending the same number of positions. For example, 24-layer 16-head\nTransformer (BERT-large) and 384-layer single-head Transformer has the same\ntotal attention head number and roughly the same model size, while the\nmulti-head one is significantly shallower. Meanwhile, we show that, with recent\nadvances in deep learning, we can successfully stabilize the training of the\n384-layer Transformer. As the training difficulty is no longer a bottleneck,\nsubstantially deeper single-head Transformer achieves consistent performance\nimprovements without tuning hyper-parameters.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Liyuan Liu",
      "Jialu Liu",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09650"
  },
  {
    "id": "arXiv:2106.09658",
    "title": "Non-intrusive Nonlinear Model Reduction via Machine Learning  Approximations to Low-dimensional Operators",
    "abstract": "Although projection-based reduced-order models (ROMs) for parameterized\nnonlinear dynamical systems have demonstrated exciting results across a range\nof applications, their broad adoption has been limited by their intrusivity:\nimplementing such a reduced-order model typically requires significant\nmodifications to the underlying simulation code. To address this, we propose a\nmethod that enables traditionally intrusive reduced-order models to be\naccurately approximated in a non-intrusive manner. Specifically, the approach\napproximates the low-dimensional operators associated with projection-based\nreduced-order models (ROMs) using modern machine-learning regression\ntechniques. The only requirement of the simulation code is the ability to\nexport the velocity given the state and parameters as this functionality is\nused to train the approximated low-dimensional operators. In addition to\nenabling nonintrusivity, we demonstrate that the approach also leads to very\nlow computational complexity, achieving up to $1000\\times$ reduction in run\ntime. We demonstrate the effectiveness of the proposed technique on two types\nof PDEs.",
    "descriptor": "",
    "authors": [
      "Zhe Bai",
      "Liqian Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Dynamical Systems (math.DS)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2106.09658"
  },
  {
    "id": "arXiv:2106.09659",
    "title": "Robustness and Consistency in Linear Quadratic Control with Predictions",
    "abstract": "We study the problem of learning-augmented predictive linear quadratic\ncontrol. Our goal is to design a controller that balances consistency, which\nmeasures the competitive ratio when predictions are accurate, and robustness,\nwhich bounds the competitive ratio when predictions are inaccurate. We propose\na novel $\\lambda$-confident controller and prove that it maintains a\ncompetitive ratio upper bound of $1+\\min\\{O(\\lambda^2\\varepsilon)+\nO(1-\\lambda)^2,O(1)+O(\\lambda^2)\\}$ where $\\lambda\\in [0,1]$ is a trust\nparameter set based on the confidence in the predictions, and $\\varepsilon$ is\nthe prediction error. Further, we design a self-tuning policy that adaptively\nlearns the trust parameter $\\lambda$ with a regret that depends on\n$\\varepsilon$ and the variation of perturbations and predictions.",
    "descriptor": "\nComments: 31 pages, 4 figures\n",
    "authors": [
      "Tongxin Li",
      "Ruixiao Yang",
      "Guannan Qu",
      "Guanya Shi",
      "Chenkai Yu",
      "Adam Wierman",
      "Steven Low"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.09659"
  },
  {
    "id": "arXiv:2106.09665",
    "title": "Understanding the Effectiveness of Reviews in E-commerce Top-N  Recommendation",
    "abstract": "Modern E-commerce websites contain heterogeneous sources of information, such\nas numerical ratings, textual reviews and images. These information can be\nutilized to assist recommendation. Through textual reviews, a user explicitly\nexpress her affinity towards the item. Previous researchers found that by using\nthe information extracted from these reviews, we can better profile the users'\nexplicit preferences as well as the item features, leading to the improvement\nof recommendation performance. However, most of the previous algorithms were\nonly utilizing the review information for explicit-feedback problem i.e. rating\nprediction, and when it comes to implicit-feedback ranking problem such as\ntop-N recommendation, the usage of review information has not been fully\nexplored. Seeing this gap, in this work, we investigate the effectiveness of\ntextual review information for top-N recommendation under E-commerce settings.\nWe adapt several SOTA review-based rating prediction models for top-N\nrecommendation tasks and compare them to existing top-N recommendation models\nfrom both performance and efficiency. We find that models utilizing only review\ninformation can not achieve better performances than vanilla implicit-feedback\nmatrix factorization method. When utilizing review information as a regularizer\nor auxiliary information, the performance of implicit-feedback matrix\nfactorization method can be further improved. However, the optimal model\nstructure to utilize textual reviews for E-commerce top-N recommendation is yet\nto be determined.",
    "descriptor": "\nComments: in proceedings of ICTIR 2021\n",
    "authors": [
      "Zhichao Xu",
      "Hansi Zeng",
      "Qingyao Ai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.09665"
  },
  {
    "id": "arXiv:2106.09667",
    "title": "Poisoning and Backdooring Contrastive Learning",
    "abstract": "Contrastive learning methods like CLIP train on noisy and uncurated training\ndatasets. This is cheaper than labeling datasets manually, and even improves\nout-of-distribution robustness. We show that this practice makes backdoor and\npoisoning attacks a significant threat. By poisoning just 0.005% of a dataset\n(e.g., just 150 images of the 3 million-example Conceptual Captions dataset),\nwe can cause the model to misclassify test images by overlaying a small patch.\nTargeted poisoning attacks, whereby the model misclassifies a particular test\ninput with an adversarially-desired label, are even easier requiring control of\nless than 0.0001% of the dataset (e.g., just two out of the 3 million images).\nOur attacks call into question whether training on noisy and uncurated Internet\nscrapes is desirable.",
    "descriptor": "",
    "authors": [
      "Nicholas Carlini",
      "Andreas Terzis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09667"
  },
  {
    "id": "arXiv:2106.09668",
    "title": "Multi-modal fusion with gating using audio, lexical and disfluency  features for Alzheimer's Dementia recognition from spontaneous speech",
    "abstract": "This paper is a submission to the Alzheimer's Dementia Recognition through\nSpontaneous Speech (ADReSS) challenge, which aims to develop methods that can\nassist in the automated prediction of severity of Alzheimer's Disease from\nspeech data. We focus on acoustic and natural language features for cognitive\nimpairment detection in spontaneous speech in the context of Alzheimer's\nDisease Diagnosis and the mini-mental state examination (MMSE) score\nprediction. We proposed a model that obtains unimodal decisions from different\nLSTMs, one for each modality of text and audio, and then combines them using a\ngating mechanism for the final prediction. We focused on sequential modelling\nof text and audio and investigated whether the disfluencies present in\nindividuals' speech relate to the extent of their cognitive impairment. Our\nresults show that the proposed classification and regression schemes obtain\nvery promising results on both development and test sets. This suggests\nAlzheimer's Disease can be detected successfully with sequence modeling of the\nspeech data of medical sessions.",
    "descriptor": "",
    "authors": [
      "Morteza Rohanian",
      "Julian Hough",
      "Matthew Purver"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09668"
  },
  {
    "id": "arXiv:2106.09669",
    "title": "Improving On-Screen Sound Separation for Open Domain Videos with  Audio-Visual Self-attention",
    "abstract": "We introduce a state-of-the-art audio-visual on-screen sound separation\nsystem which is capable of learning to separate sounds and associate them with\non-screen objects by looking at in-the-wild videos. We identify limitations of\nprevious work on audiovisual on-screen sound separation, including the\nsimplicity and coarse resolution of spatio-temporal attention, and poor\nconvergence of the audio separation model. Our proposed model addresses these\nissues using cross-modal and self-attention modules that capture audio-visual\ndependencies at a finer resolution over time, and by unsupervised pre-training\nof audio separation model. These improvements allow the model to generalize to\na much wider set of unseen videos. For evaluation and semi-supervised training,\nwe collected human annotations of on-screen audio from a large database of\nin-the-wild videos (YFCC100M). Our results show marked improvements in\non-screen separation performance, in more general conditions than previous\nmethods.",
    "descriptor": "",
    "authors": [
      "Efthymios Tzinis",
      "Scott Wisdom",
      "Tal Remez",
      "John R. Hershey"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09669"
  },
  {
    "id": "arXiv:2106.09670",
    "title": "Indian Masked Faces in the Wild Dataset",
    "abstract": "Due to the COVID-19 pandemic, wearing face masks has become a mandate in\npublic places worldwide. Face masks occlude a significant portion of the facial\nregion. Additionally, people wear different types of masks, from simple ones to\nones with graphics and prints. These pose new challenges to face recognition\nalgorithms. Researchers have recently proposed a few masked face datasets for\ndesigning algorithms to overcome the challenges of masked face recognition.\nHowever, existing datasets lack the cultural diversity and collection in the\nunrestricted settings. Country like India with attire diversity, people are not\nlimited to wearing traditional masks but also clothing like a thin cotton\nprinted towel (locally called as ``gamcha''), ``stoles'', and ``handkerchiefs''\nto cover their faces. In this paper, we present a novel \\textbf{Indian Masked\nFaces in the Wild (IMFW)} dataset which contains images with variations in\npose, illumination, resolution, and the variety of masks worn by the subjects.\nWe have also benchmarked the performance of existing face recognition models on\nthe proposed IMFW dataset. Experimental results demonstrate the limitations of\nexisting algorithms in presence of diverse conditions.",
    "descriptor": "",
    "authors": [
      "Shiksha Mishra",
      "Puspita Majumdar",
      "Richa Singh",
      "Mayank Vatsa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09670"
  },
  {
    "id": "arXiv:2106.09671",
    "title": "An Attract-Repel Decomposition of Undirected Networks",
    "abstract": "Dot product latent space embedding is a common form of representation\nlearning in undirected graphs (e.g. social networks, co-occurrence networks).\nWe show that such models have problems dealing with 'intransitive' situations\nwhere A is linked to B, B is linked to C but A is not linked to C. Such\nsituations occur in social networks when opposites attract (heterophily) and in\nco-occurrence networks when there are substitute nodes (e.g. the presence of\nPepsi or Coke, but rarely both, in otherwise similar purchase baskets). We\npresent a simple expansion which we call the attract-repel (AR) decomposition:\na set of latent attributes on which similar nodes attract and another set of\nlatent attributes on which similar nodes repel. We demonstrate the AR\ndecomposition in real social networks and show that it can be used to measure\nthe amount of latent homophily and heterophily. In addition, it can be applied\nto co-occurrence networks to discover roles in teams and find substitutable\ningredients in recipes.",
    "descriptor": "",
    "authors": [
      "Alexander Peysakhovich",
      "Leon Bottou"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09671"
  },
  {
    "id": "arXiv:2106.09672",
    "title": "The 2021 Image Similarity Dataset and Challenge",
    "abstract": "This paper introduces a new benchmark for large-scale image similarity\ndetection. This benchmark is used for the Image Similarity Challenge at\nNeurIPS'21 (ISC2021). The goal is to determine whether a query image is a\nmodified copy of any image in a reference corpus of size 1~million. The\nbenchmark features a variety of image transformations such as automated\ntransformations, hand-crafted image edits and machine-learning based\nmanipulations. This mimics real-life cases appearing in social media, for\nexample for integrity-related problems dealing with misinformation and\nobjectionable content. The strength of the image manipulations, and therefore\nthe difficulty of the benchmark, is calibrated according to the performance of\na set of baseline approaches. Both the query and reference set contain a\nmajority of ``distractor'' images that do not match, which corresponds to a\nreal-life needle-in-haystack setting, and the evaluation metric reflects that.\nWe expect the DISC21 benchmark to promote image copy detection as an important\nand challenging computer vision task and refresh the state of the art.",
    "descriptor": "",
    "authors": [
      "Matthijs Douze",
      "Giorgos Tolias",
      "Ed Pizzi",
      "Zo\u00eb Papakipos",
      "Lowik Chanussot",
      "Filip Radenovic",
      "Tomas Jenicek",
      "Maxim Maximov",
      "Laura Leal-Taix\u00e9",
      "Ismail Elezi",
      "Ond\u0159ej Chum",
      "Cristian Canton Ferrer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09672"
  },
  {
    "id": "arXiv:2106.09675",
    "title": "Gone Fishing: Neural Active Learning with Fisher Embeddings",
    "abstract": "There is an increasing need for effective active learning algorithms that are\ncompatible with deep neural networks. While there are many classic,\nwell-studied sample selection methods, the non-convexity and varying internal\nrepresentation of neural models make it unclear how to extend these approaches.\nThis article introduces BAIT, a practical, tractable, and high-performing\nactive learning algorithm for neural networks that addresses these concerns.\nBAIT draws inspiration from the theoretical analysis of maximum likelihood\nestimators (MLE) for parametric models. It selects batches of samples by\noptimizing a bound on the MLE error in terms of the Fisher information, which\nwe show can be implemented efficiently at scale by exploiting linear-algebraic\nstructure especially amenable to execution on modern hardware. Our experiments\nshow that BAIT outperforms the previous state of the art on both classification\nand regression problems, and is flexible enough to be used with a variety of\nmodel architectures.",
    "descriptor": "",
    "authors": [
      "Jordan T. Ash",
      "Surbhi Goel",
      "Akshay Krishnamurthy",
      "Sham Kakade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09675"
  },
  {
    "id": "arXiv:2106.09677",
    "title": "Adaptive Low-Rank Regularization with Damping Sequences to Restrict Lazy  Weights in Deep Networks",
    "abstract": "Overfitting is one of the critical problems in deep neural networks. Many\nregularization schemes try to prevent overfitting blindly. However, they\ndecrease the convergence speed of training algorithms. Adaptive regularization\nschemes can solve overfitting more intelligently. They usually do not affect\nthe entire network weights. This paper detects a subset of the weighting layers\nthat cause overfitting. The overfitting recognizes by matrix and tensor\ncondition numbers. An adaptive regularization scheme entitled Adaptive Low-Rank\n(ALR) is proposed that converges a subset of the weighting layers to their\nLow-Rank Factorization (LRF). It happens by minimizing a new Tikhonov-based\nloss function. ALR also encourages lazy weights to contribute to the\nregularization when epochs grow up. It uses a damping sequence to increment\nlayer selection likelihood in the last generations. Thus before falling the\ntraining accuracy, ALR reduces the lazy weights and regularizes the network\nsubstantially. The experimental results show that ALR regularizes the deep\nnetworks well with high training speed and low resource usage.",
    "descriptor": "\nComments: Preprint of a paper submitted in Neural Networks, 27 Pages, 4 Tables and 6 Figures. arXiv admin note: text overlap with arXiv:2005.01995\n",
    "authors": [
      "Mohammad Mahdi Bejani",
      "Mehdi Ghatee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09677"
  },
  {
    "id": "arXiv:2106.09678",
    "title": "SECANT: Self-Expert Cloning for Zero-Shot Generalization of Visual  Policies",
    "abstract": "Generalization has been a long-standing challenge for reinforcement learning\n(RL). Visual RL, in particular, can be easily distracted by irrelevant factors\nin high-dimensional observation space. In this work, we consider robust policy\nlearning which targets zero-shot generalization to unseen visual environments\nwith large distributional shift. We propose SECANT, a novel self-expert cloning\ntechnique that leverages image augmentation in two stages to decouple robust\nrepresentation learning from policy optimization. Specifically, an expert\npolicy is first trained by RL from scratch with weak augmentations. A student\nnetwork then learns to mimic the expert policy by supervised learning with\nstrong augmentations, making its representation more robust against visual\nvariations compared to the expert. Extensive experiments demonstrate that\nSECANT significantly advances the state of the art in zero-shot generalization\nacross 4 challenging domains. Our average reward improvements over prior SOTAs\nare: DeepMind Control (+26.5%), robotic manipulation (+337.8%), vision-based\nautonomous driving (+47.7%), and indoor object navigation (+15.8%). Code\nrelease and video are available at https://linxifan.github.io/secant-site/.",
    "descriptor": "\nComments: ICML 2021. Website: this https URL\n",
    "authors": [
      "Linxi Fan",
      "Guanzhi Wang",
      "De-An Huang",
      "Zhiding Yu",
      "Li Fei-Fei",
      "Yuke Zhu",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09678"
  },
  {
    "id": "arXiv:2106.09679",
    "title": "JOKR: Joint Keypoint Representation for Unsupervised Cross-Domain Motion  Retargeting",
    "abstract": "The task of unsupervised motion retargeting in videos has seen substantial\nadvancements through the use of deep neural networks. While early works\nconcentrated on specific object priors such as a human face or body, recent\nwork considered the unsupervised case. When the source and target videos,\nhowever, are of different shapes, current methods fail. To alleviate this\nproblem, we introduce JOKR - a JOint Keypoint Representation that captures the\nmotion common to both the source and target videos, without requiring any\nobject prior or data collection. By employing a domain confusion term, we\nenforce the unsupervised keypoint representations of both videos to be\nindistinguishable. This encourages disentanglement between the parts of the\nmotion that are common to the two domains, and their distinctive appearance and\nmotion, enabling the generation of videos that capture the motion of the one\nwhile depicting the style of the other. To enable cases where the objects are\nof different proportions or orientations, we apply a learned affine\ntransformation between the JOKRs. This augments the representation to be affine\ninvariant, and in practice broadens the variety of possible retargeting pairs.\nThis geometry-driven representation enables further intuitive control, such as\ntemporal coherence and manual editing. Through comprehensive experimentation,\nwe demonstrate the applicability of our method to different challenging\ncross-domain video pairs. We evaluate our method both qualitatively and\nquantitatively, and demonstrate that our method handles various cross-domain\nscenarios, such as different animals, different flowers, and humans. We also\ndemonstrate superior temporal coherency and visual quality compared to\nstate-of-the-art alternatives, through statistical metrics and a user study.\nSource code and videos can be found at https://rmokady.github.io/JOKR/ .",
    "descriptor": "",
    "authors": [
      "Ron Mokady",
      "Rotem Tzaban",
      "Sagie Benaim",
      "Amit H. Bermano",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09679"
  },
  {
    "id": "arXiv:2106.09680",
    "title": "Accuracy, Interpretability, and Differential Privacy via Explainable  Boosting",
    "abstract": "We show that adding differential privacy to Explainable Boosting Machines\n(EBMs), a recent method for training interpretable ML models, yields\nstate-of-the-art accuracy while protecting privacy. Our experiments on multiple\nclassification and regression datasets show that DP-EBM models suffer\nsurprisingly little accuracy loss even with strong differential privacy\nguarantees. In addition to high accuracy, two other benefits of applying DP to\nEBMs are: a) trained models provide exact global and local interpretability,\nwhich is often important in settings where differential privacy is needed; and\nb) the models can be edited after training without loss of privacy to correct\nerrors which DP noise may have introduced.",
    "descriptor": "\nComments: To be published in ICML 2021. 12 pages, 6 figures\n",
    "authors": [
      "Harsha Nori",
      "Rich Caruana",
      "Zhiqi Bu",
      "Judy Hanwen Shen",
      "Janardhan Kulkarni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09680"
  },
  {
    "id": "arXiv:2106.09681",
    "title": "XCiT: Cross-Covariance Image Transformers",
    "abstract": "Following their success in natural language processing, transformers have\nrecently shown much promise for computer vision. The self-attention operation\nunderlying transformers yields global interactions between all tokens ,i.e.\nwords or image patches, and enables flexible modelling of image data beyond the\nlocal interactions of convolutions. This flexibility, however, comes with a\nquadratic complexity in time and memory, hindering application to long\nsequences and high-resolution images. We propose a \"transposed\" version of\nself-attention that operates across feature channels rather than tokens, where\nthe interactions are based on the cross-covariance matrix between keys and\nqueries. The resulting cross-covariance attention (XCA) has linear complexity\nin the number of tokens, and allows efficient processing of high-resolution\nimages. Our cross-covariance image transformer (XCiT) is built upon XCA. It\ncombines the accuracy of conventional transformers with the scalability of\nconvolutional architectures. We validate the effectiveness and generality of\nXCiT by reporting excellent results on multiple vision benchmarks, including\nimage classification and self-supervised feature learning on ImageNet-1k,\nobject detection and instance segmentation on COCO, and semantic segmentation\non ADE20k.",
    "descriptor": "",
    "authors": [
      "Alaaeldin El-Nouby",
      "Hugo Touvron",
      "Mathilde Caron",
      "Piotr Bojanowski",
      "Matthijs Douze",
      "Armand Joulin",
      "Ivan Laptev",
      "Natalia Neverova",
      "Gabriel Synnaeve",
      "Jakob Verbeek",
      "Herv\u00e9 Jegou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09681"
  },
  {
    "id": "arXiv:2106.09683",
    "title": "PAC-Bayes, MAC-Bayes and Conditional Mutual Information: Fast rate  bounds that handle general VC classes",
    "abstract": "We give a novel, unified derivation of conditional PAC-Bayesian and mutual\ninformation (MI) generalization bounds. We derive conditional MI bounds as an\ninstance, with special choice of prior, of conditional MAC-Bayesian (Mean\nApproximately Correct) bounds, itself derived from conditional PAC-Bayesian\nbounds, where `conditional' means that one can use priors conditioned on a\njoint training and ghost sample. This allows us to get nontrivial PAC-Bayes and\nMI-style bounds for general VC classes, something recently shown to be\nimpossible with standard PAC-Bayesian/MI bounds. Second, it allows us to get\nfaster rates of order $O \\left(({\\text{KL}}/n)^{\\gamma}\\right)$ for $\\gamma >\n1/2$ if a Bernstein condition holds and for exp-concave losses (with\n$\\gamma=1$), which is impossible with both standard PAC-Bayes generalization\nand MI bounds. Our work extends the recent work by Steinke and Zakynthinou\n[2020] who handle MI with VC but neither PAC-Bayes nor fast rates, the recent\nwork of Hellstr\\\"om and Durisi [2020] who extend the latter to the PAC-Bayes\nsetting via a unifying exponential inequality, and Mhammedi et al. [2019] who\ninitiated fast rate PAC-Bayes generalization error bounds but handle neither MI\nnor general VC classes.",
    "descriptor": "\nComments: 24 pages, accepted for publication at COLT 2021\n",
    "authors": [
      "Peter Gr\u00fcnwald",
      "Thomas Steinke",
      "Lydia Zakynthinou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09683"
  },
  {
    "id": "arXiv:2106.09685",
    "title": "LoRA: Low-Rank Adaptation of Large Language Models",
    "abstract": "The dominant paradigm of natural language processing consists of large-scale\npre-training on general domain data and adaptation to particular tasks or\ndomains. As we pre-train larger models, conventional fine-tuning, which\nretrains all model parameters, becomes less feasible. Using GPT-3 175B as an\nexample, deploying many independent instances of fine-tuned models, each with\n175B parameters, is extremely expensive. We propose Low-Rank Adaptation, or\nLoRA, which freezes the pre-trained model weights and injects trainable rank\ndecomposition matrices into each layer of the Transformer architecture, greatly\nreducing the number of trainable parameters for downstream tasks. For GPT-3,\nLoRA can reduce the number of trainable parameters by 10,000 times and the\ncomputation hardware requirement by 3 times compared to full fine-tuning. LoRA\nperforms on-par or better than fine-tuning in model quality on both GPT-3 and\nGPT-2, despite having fewer trainable parameters, a higher training throughput,\nand no additional inference latency. We also provide an empirical investigation\ninto rank-deficiency in language model adaptations, which sheds light on the\nefficacy of LoRA. We release our implementation in GPT-2 at\nhttps://github.com/microsoft/LoRA .",
    "descriptor": "",
    "authors": [
      "Edward J. Hu",
      "Yelong Shen",
      "Phillip Wallis",
      "Zeyuan Allen-Zhu",
      "Yuanzhi Li",
      "Shean Wang",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09685"
  },
  {
    "id": "arXiv:2106.09686",
    "title": "How Low Can We Go: Trading Memory for Error in Low-Precision Training",
    "abstract": "Low-precision arithmetic trains deep learning models using less energy, less\nmemory and less time. However, we pay a price for the savings: lower precision\nmay yield larger round-off error and hence larger prediction error. As\napplications proliferate, users must choose which precision to use to train a\nnew model, and chip manufacturers must decide which precisions to manufacture.\nWe view these precision choices as a hyperparameter tuning problem, and borrow\nideas from meta-learning to learn the tradeoff between memory and error. In\nthis paper, we introduce Pareto Estimation to Pick the Perfect Precision\n(PEPPP). We use matrix factorization to find non-dominated configurations (the\nPareto frontier) with a limited number of network evaluations. For any given\nmemory budget, the precision that minimizes error is a point on this frontier.\nPractitioners can use the frontier to trade memory for error and choose the\nbest precision for their goals.",
    "descriptor": "",
    "authors": [
      "Chengrun Yang",
      "Ziyang Wu",
      "Jerry Chee",
      "Christopher De Sa",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09686"
  },
  {
    "id": "arXiv:2106.09689",
    "title": "Statistical Query Lower Bounds for List-Decodable Linear Regression",
    "abstract": "We study the problem of list-decodable linear regression, where an adversary\ncan corrupt a majority of the examples. Specifically, we are given a set $T$ of\nlabeled examples $(x, y) \\in \\mathbb{R}^d \\times \\mathbb{R}$ and a parameter\n$0< \\alpha <1/2$ such that an $\\alpha$-fraction of the points in $T$ are i.i.d.\nsamples from a linear regression model with Gaussian covariates, and the\nremaining $(1-\\alpha)$-fraction of the points are drawn from an arbitrary noise\ndistribution. The goal is to output a small list of hypothesis vectors such\nthat at least one of them is close to the target regression vector. Our main\nresult is a Statistical Query (SQ) lower bound of $d^{\\mathrm{poly}(1/\\alpha)}$\nfor this problem. Our SQ lower bound qualitatively matches the performance of\npreviously developed algorithms, providing evidence that current upper bounds\nfor this task are nearly best possible.",
    "descriptor": "",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane",
      "Ankit Pensia",
      "Thanasis Pittas",
      "Alistair Stewart"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09689"
  },
  {
    "id": "arXiv:2106.09691",
    "title": "Interactive Change Point Detection using optimisation approach and  Bayesian statistics applied to real world applications",
    "abstract": "Change point detection becomes more and more important as datasets increase\nin size, where unsupervised detection algorithms can help users process data.\nTo detect change points, a number of unsupervised algorithms have been\ndeveloped which are based on different principles. One approach is to define an\noptimisation problem and minimise a cost function along with a penalty\nfunction. In the optimisation approach, the choice of the cost function affects\nthe predictions made by the algorithm. In extension to the existing studies, a\nnew type of cost function using Tikhonov regularisation is introduced. Another\napproach uses Bayesian statistics to calculate the posterior probability\ndistribution of a specific point being a change point. It uses a priori\nknowledge on the distance between consecutive change points and a likelihood\nfunction with information about the segments. The optimisation and Bayesian\napproaches for offline change point detection are studied and applied to\nsimulated datasets as well as a real world multi-phase dataset. The approaches\nhave previously been studied separately and a novelty lies in comparing the\npredictions made by the two approaches in a specific setting, consisting of\nsimulated datasets and a real world example. The study has found that the\nperformance of the change point detection algorithms are affected by the\nfeatures in the data.",
    "descriptor": "",
    "authors": [
      "Rebecca Gedda",
      "Larisa Beilina",
      "Ruomu Tan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09691"
  },
  {
    "id": "arXiv:2106.09692",
    "title": "Hi-Phy: A Benchmark for Hierarchical Physical Reasoning",
    "abstract": "Reasoning about the behaviour of physical objects is a key capability of\nagents operating in physical worlds. Humans are very experienced in physical\nreasoning while it remains a major challenge for AI. To facilitate research\naddressing this problem, several benchmarks have been proposed recently.\nHowever, these benchmarks do not enable us to measure an agent's granular\nphysical reasoning capabilities when solving a complex reasoning task. In this\npaper, we propose a new benchmark for physical reasoning that allows us to test\nindividual physical reasoning capabilities. Inspired by how humans acquire\nthese capabilities, we propose a general hierarchy of physical reasoning\ncapabilities with increasing complexity. Our benchmark tests capabilities\naccording to this hierarchy through generated physical reasoning tasks in the\nvideo game Angry Birds. This benchmark enables us to conduct a comprehensive\nagent evaluation by measuring the agent's granular physical reasoning\ncapabilities. We conduct an evaluation with human players, learning agents, and\nheuristic agents and determine their capabilities. Our evaluation shows that\nlearning agents, with good local generalization ability, still struggle to\nlearn the underlying physical reasoning capabilities and perform worse than\ncurrent state-of-the-art heuristic agents and humans. We believe that this\nbenchmark will encourage researchers to develop intelligent agents with\nadvanced, human-like physical reasoning capabilities. URL:\nhttps://github.com/Cheng-Xue/Hi-Phy",
    "descriptor": "",
    "authors": [
      "Cheng Xue",
      "Vimukthini Pinto",
      "Chathura Gamage",
      "Peng Zhang",
      "Jochen Renz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09692"
  },
  {
    "id": "arXiv:2106.09693",
    "title": "Orthogonal-Pad\u00e9 Activation Functions: Trainable Activation functions  for smooth and faster convergence in deep networks",
    "abstract": "We have proposed orthogonal-Pad\\'e activation functions, which are trainable\nactivation functions and show that they have faster learning capability and\nimproves the accuracy in standard deep learning datasets and models. Based on\nour experiments, we have found two best candidates out of six orthogonal-Pad\\'e\nactivations, which we call safe Hermite-Pade (HP) activation functions, namely\nHP-1 and HP-2. When compared to ReLU, HP-1 and HP-2 has an increment in top-1\naccuracy by 5.06% and 4.63% respectively in PreActResNet-34, by 3.02% and 2.75%\nrespectively in MobileNet V2 model on CIFAR100 dataset while on CIFAR10 dataset\ntop-1 accuracy increases by 2.02% and 1.78% respectively in PreActResNet-34, by\n2.24% and 2.06% respectively in LeNet, by 2.15% and 2.03% respectively in\nEfficientnet B0.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Koushik Biswas",
      "Shilpak Banerjee",
      "Ashish Kumar Pandey"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09693"
  },
  {
    "id": "arXiv:2106.09694",
    "title": "Simulation study on the fleet performance of shared autonomous bicycles",
    "abstract": "Rethinking cities is now more imperative than ever, as society is facing\nchallenges such as population growth and climate change. The design of cities\ncan not be abstracted from the design of its mobility system, and, therefore,\nefficient solutions must be found to transport people and goods throughout the\ncity in an ecological way. An autonomous bicycle-sharing system that combines\nthe benefits of vehicle sharing, electrification, autonomy, and micro-mobility\ncould increase the efficiency and convenience of bicycle-sharing systems\nincentivizing more people to bike and enjoy their cities in an environmentally\nfriendly way. Due to the uniqueness and radical novelty of introducing\nautonomous driving technology into bicycle-sharing systems and the inherent\ncomplexity of these systems, there is a need to quantify the potential impact\nof autonomy on fleet performance and user experience. This paper presents an\nad-hoc agent-based, discrete event simulator that provides an in-depth\nunderstanding of the fleet behavior of autonomous bicycle-sharing systems in\nthe most realistic possible scenarios, including a rebalancing system based on\ndemand prediction. In addition, this work quantifies the extent to which an\nautonomous system would outperform current bicycle-sharing schemes and\ndescribes the impact of different parameters on system efficiency and service\nquality. This research shows that with a fleet size three and a half times\nsmaller than a station-based system and eight times smaller than a dockless\nsystem, an autonomous system can provide overall improved performance and user\nexperience even with no rebalancing. These findings indicate that the\nremarkable efficiency of an autonomous bicycle-sharing system could compensate\nfor the additional cost of autonomous bicycles.",
    "descriptor": "",
    "authors": [
      "Naroa Coretti S\u00e1nchez",
      "I\u00f1igo Martinez",
      "Luis Alonso Pastor",
      "Kent Larson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.09694"
  },
  {
    "id": "arXiv:2106.09696",
    "title": "BABEL: Bodies, Action and Behavior with English Labels",
    "abstract": "Understanding the semantics of human movement -- the what, how and why of the\nmovement -- is an important problem that requires datasets of human actions\nwith semantic labels. Existing datasets take one of two approaches. Large-scale\nvideo datasets contain many action labels but do not contain ground-truth 3D\nhuman motion. Alternatively, motion-capture (mocap) datasets have precise body\nmotions but are limited to a small number of actions. To address this, we\npresent BABEL, a large dataset with language labels describing the actions\nbeing performed in mocap sequences. BABEL consists of action labels for about\n43 hours of mocap sequences from AMASS. Action labels are at two levels of\nabstraction -- sequence labels describe the overall action in the sequence, and\nframe labels describe all actions in every frame of the sequence. Each frame\nlabel is precisely aligned with the duration of the corresponding action in the\nmocap sequence, and multiple actions can overlap. There are over 28k sequence\nlabels, and 63k frame labels in BABEL, which belong to over 250 unique action\ncategories. Labels from BABEL can be leveraged for tasks like action\nrecognition, temporal action localization, motion synthesis, etc. To\ndemonstrate the value of BABEL as a benchmark, we evaluate the performance of\nmodels on 3D action recognition. We demonstrate that BABEL poses interesting\nlearning challenges that are applicable to real-world scenarios, and can serve\nas a useful benchmark of progress in 3D action recognition. The dataset,\nbaseline method, and evaluation code is made available, and supported for\nacademic research purposes at https://babel.is.tue.mpg.de/.",
    "descriptor": "\nComments: 11 pages, 4 figures, Accepted in CVPR'21\n",
    "authors": [
      "Abhinanda R. Punnakkal",
      "Arjun Chandrasekaran",
      "Nikos Athanasiou",
      "Alejandra Quiros-Ramirez",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09696"
  },
  {
    "id": "arXiv:2106.09700",
    "title": "Scientific Language Models for Biomedical Knowledge Base Completion: An  Empirical Study",
    "abstract": "Biomedical knowledge graphs (KGs) hold rich information on entities such as\ndiseases, drugs, and genes. Predicting missing links in these graphs can boost\nmany important applications, such as drug design and repurposing. Recent work\nhas shown that general-domain language models (LMs) can serve as \"soft\" KGs,\nand that they can be fine-tuned for the task of KG completion. In this work, we\nstudy scientific LMs for KG completion, exploring whether we can tap into their\nlatent knowledge to enhance biomedical link prediction. We evaluate several\ndomain-specific LMs, fine-tuning them on datasets centered on drugs and\ndiseases that we represent as KGs and enrich with textual entity descriptions.\nWe integrate the LM-based models with KG embedding models, using a router\nmethod that learns to assign each input example to either type of model and\nprovides a substantial boost in performance. Finally, we demonstrate the\nadvantage of LM models in the inductive setting with novel scientific entities.\nOur datasets and code are made publicly available.",
    "descriptor": "",
    "authors": [
      "Rahul Nadkarni",
      "David Wadden",
      "Iz Beltagy",
      "Noah A. Smith",
      "Hannaneh Hajishirzi",
      "Tom Hope"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09700"
  },
  {
    "id": "arXiv:2106.09701",
    "title": "Always Be Dreaming: A New Approach for Data-Free Class-Incremental  Learning",
    "abstract": "Modern computer vision applications suffer from catastrophic forgetting when\nincrementally learning new concepts over time. The most successful approaches\nto alleviate this forgetting require extensive replay of previously seen data,\nwhich is problematic when memory constraints or data legality concerns exist.\nIn this work, we consider the high-impact problem of Data-Free\nClass-Incremental Learning (DFCIL), where an incremental learning agent must\nlearn new concepts over time without storing generators or training data from\npast tasks. One approach for DFCIL is to replay synthetic images produced by\ninverting a frozen copy of the learner's classification model, but we show this\napproach fails for common class-incremental benchmarks when using standard\ndistillation strategies. We diagnose the cause of this failure and propose a\nnovel incremental distillation strategy for DFCIL, contributing a modified\ncross-entropy training and importance-weighted feature distillation, and show\nthat our method results in up to a 25.1% increase in final task accuracy\n(absolute difference) compared to SOTA DFCIL methods for common\nclass-incremental benchmarks. Our method even outperforms several standard\nreplay based methods which store a coreset of images.",
    "descriptor": "",
    "authors": [
      "James Smith",
      "Yen-Chang Hsu",
      "Jonathan Balloch",
      "Yilin Shen",
      "Hongxia Jin",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09701"
  },
  {
    "id": "arXiv:2106.09703",
    "title": "MoDist: Motion Distillation for Self-supervised Video Representation  Learning",
    "abstract": "We present MoDist as a novel method to explicitly distill motion information\ninto self-supervised video representations. Compared to previous video\nrepresentation learning methods that mostly focus on learning motion cues\nimplicitly from RGB inputs, we show that the representation learned with our\nMoDist method focus more on foreground motion regions and thus generalizes\nbetter to downstream tasks. To achieve this, MoDist enriches standard\ncontrastive learning objectives for RGB video clips with a cross-modal learning\nobjective between a Motion pathway and a Visual pathway. We evaluate MoDist on\nseveral datasets for both action recognition (UCF101/HMDB51/SSv2) as well as\naction detection (AVA), and demonstrate state-of-the-art self-supervised\nperformance on all datasets. Furthermore, we show that MoDist representation\ncan be as effective as (in some cases even better than) representations learned\nwith full supervision. Given its simplicity, we hope MoDist could serve as a\nstrong baseline for future research in self-supervised video representation\nlearning.",
    "descriptor": "",
    "authors": [
      "Fanyi Xiao",
      "Joseph Tighe",
      "Davide Modolo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09703"
  },
  {
    "id": "arXiv:2106.09707",
    "title": "Learning to Predict Visual Attributes in the Wild",
    "abstract": "Visual attributes constitute a large portion of information contained in a\nscene. Objects can be described using a wide variety of attributes which\nportray their visual appearance (color, texture), geometry (shape, size,\nposture), and other intrinsic properties (state, action). Existing work is\nmostly limited to study of attribute prediction in specific domains. In this\npaper, we introduce a large-scale in-the-wild visual attribute prediction\ndataset consisting of over 927K attribute annotations for over 260K object\ninstances. Formally, object attribute prediction is a multi-label\nclassification problem where all attributes that apply to an object must be\npredicted. Our dataset poses significant challenges to existing methods due to\nlarge number of attributes, label sparsity, data imbalance, and object\nocclusion. To this end, we propose several techniques that systematically\ntackle these challenges, including a base model that utilizes both low- and\nhigh-level CNN features with multi-hop attention, reweighting and resampling\ntechniques, a novel negative label expansion scheme, and a novel supervised\nattribute-aware contrastive learning algorithm. Using these techniques, we\nachieve near 3.7 mAP and 5.7 overall F1 points improvement over the current\nstate of the art. Further details about the VAW dataset can be found at\nthis http URL",
    "descriptor": "\nComments: Accepted to CVPR 2021\n",
    "authors": [
      "Khoi Pham",
      "Kushal Kafle",
      "Zhe Lin",
      "Zhihong Ding",
      "Scott Cohen",
      "Quan Tran",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09707"
  },
  {
    "id": "arXiv:2106.09708",
    "title": "Multi-Label Learning from Single Positive Labels",
    "abstract": "Predicting all applicable labels for a given image is known as multi-label\nclassification. Compared to the standard multi-class case (where each image has\nonly one label), it is considerably more challenging to annotate training data\nfor multi-label classification. When the number of potential labels is large,\nhuman annotators find it difficult to mention all applicable labels for each\ntraining image. Furthermore, in some settings detection is intrinsically\ndifficult e.g. finding small object instances in high resolution images. As a\nresult, multi-label training data is often plagued by false negatives. We\nconsider the hardest version of this problem, where annotators provide only one\nrelevant label for each image. As a result, training sets will have only one\npositive label per image and no confirmed negatives. We explore this special\ncase of learning from missing labels across four different multi-label image\nclassification datasets for both linear classifiers and end-to-end fine-tuned\ndeep networks. We extend existing multi-label losses to this setting and\npropose novel variants that constrain the number of expected positive labels\nduring training. Surprisingly, we show that in some cases it is possible to\napproach the performance of fully labeled classifiers despite training with\nsignificantly fewer confirmed labels.",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Elijah Cole",
      "Oisin Mac Aodha",
      "Titouan Lorieul",
      "Pietro Perona",
      "Dan Morris",
      "Nebojsa Jojic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09708"
  },
  {
    "id": "arXiv:2106.09711",
    "title": "Visual Correspondence Hallucination: Towards Geometric Reasoning",
    "abstract": "Given a pair of partially overlapping source and target images and a keypoint\nin the source image, the keypoint's correspondent in the target image can be\neither visible, occluded or outside the field of view. Local feature matching\nmethods are only able to identify the correspondent's location when it is\nvisible, while humans can also hallucinate its location when it is occluded or\noutside the field of view through geometric reasoning. In this paper, we bridge\nthis gap by training a network to output a peaked probability distribution over\nthe correspondent's location, regardless of this correspondent being visible,\noccluded, or outside the field of view. We experimentally demonstrate that this\nnetwork is indeed able to hallucinate correspondences on unseen pairs of\nimages. We also apply this network to a camera pose estimation problem and find\nit is significantly more robust than state-of-the-art local feature\nmatching-based competitors.",
    "descriptor": "",
    "authors": [
      "Hugo Germain",
      "Vincent Lepetit",
      "Guillaume Bourmaud"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09711"
  },
  {
    "id": "arXiv:2106.09712",
    "title": "IFCNet: A Benchmark Dataset for IFC Entity Classification",
    "abstract": "Enhancing interoperability and information exchange between domain-specific\nsoftware products for BIM is an important aspect in the Architecture,\nEngineering, Construction and Operations industry. Recent research started\ninvestigating methods from the areas of machine and deep learning for semantic\nenrichment of BIM models. However, training and evaluation of these machine\nlearning algorithms requires sufficiently large and comprehensive datasets.\nThis work presents IFCNet, a dataset of single-entity IFC files spanning a\nbroad range of IFC classes containing both geometric and semantic information.\nUsing only the geometric information of objects, the experiments show that\nthree different deep learning models are able to achieve good classification\nperformance.",
    "descriptor": "\nComments: To be presented at EG-ICE 2021\n",
    "authors": [
      "Christoph Emunds",
      "Nicolas Pauen",
      "Veronika Richter",
      "J\u00e9r\u00f4me Frisch",
      "Christoph van Treeck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09712"
  },
  {
    "id": "arXiv:2106.09714",
    "title": "No-frills Dynamic Planning using Static Planners",
    "abstract": "In this paper, we address the task of interacting with dynamic environments\nwhere the changes in the environment are independent of the agent. We study\nthis through the context of trapping a moving ball with a UR5 robotic arm. Our\nkey contribution is an approach to utilize a static planner for dynamic tasks\nusing a Dynamic Planning add-on; that is, if we can successfully solve a task\nwith a static target, then our approach can solve the same task when the target\nis moving. Our approach has three key components: an off-the-shelf static\nplanner, a trajectory forecasting network, and a network to predict robot's\nestimated time of arrival at any location. We demonstrate the generalization of\nour approach across environments. More information and videos at\nhttps://mlevy2525.github.io/DynamicAddOn.",
    "descriptor": "\nComments: ICRA 2021\n",
    "authors": [
      "Mara Levy",
      "Vasista Ayyagari",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09714"
  },
  {
    "id": "arXiv:2106.09028",
    "title": "Exponential Error Convergence in Data Classification with Optimized  Random Features: Acceleration by Quantum Machine Learning",
    "abstract": "Random features are a central technique for scalable learning algorithms\nbased on kernel methods. A recent work has shown that an algorithm for machine\nlearning by quantum computer, quantum machine learning (QML), can exponentially\nspeed up sampling of optimized random features, even without imposing\nrestrictive assumptions on sparsity and low-rankness of matrices that had\nlimited applicability of conventional QML algorithms; this QML algorithm makes\nit possible to significantly reduce and provably minimize the required number\nof features for regression tasks. However, a major interest in the field of QML\nis how widely the advantages of quantum computation can be exploited, not only\nin the regression tasks. We here construct a QML algorithm for a classification\ntask accelerated by the optimized random features. We prove that the QML\nalgorithm for sampling optimized random features, combined with stochastic\ngradient descent (SGD), can achieve state-of-the-art exponential convergence\nspeed of reducing classification error in a classification task under a\nlow-noise condition; at the same time, our algorithm with optimized random\nfeatures can take advantage of the significant reduction of the required number\nof features so as to accelerate each iteration in the SGD and evaluation of the\nclassifier obtained from our algorithm. These results discover a promising\napplication of QML to significant acceleration of the leading classification\nalgorithm based on kernel methods, without ruining its applicability to a\npractical class of data sets and the exponential error-convergence speed.",
    "descriptor": "\nComments: 28 pages, no figure\n",
    "authors": [
      "Hayata Yamasaki",
      "Sho Sonoda"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09028"
  },
  {
    "id": "arXiv:2106.09068",
    "title": "Extracting real social interactions from social media: a debate of  COVID-19 policies in Mexico",
    "abstract": "A study of the dynamical formation of networks of friends and enemies in\nsocial media, in this case Twitter, is presented. We characterise the single\nnode properties of such networks, as the clustering coefficient and the degree,\nto investigate the structure of links. The results indicate that the network is\nmade from three kinds of nodes: one with high clustering coefficient but very\nsmall degree, a second group has zero clustering coefficient with variable\ndegree, and finally, a third group in which the clustering coefficient as a\nfunction of the degree decays as a power law. This third group represents\n$\\sim2\\%$ of the nodes and is characteristic of dynamical networks with\nfeedback. This part of the lattice seemingly represents strongly interacting\nfriends in a real social network.",
    "descriptor": "",
    "authors": [
      "Alberto Garc\u00eda-Rodr\u00edguez",
      "Tzipe Govezensky",
      "Carlos Gershenson",
      "Gerardo G. Naumis",
      "Rafael A. Barrio"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.09068"
  },
  {
    "id": "arXiv:2106.09082",
    "title": "Zeroth-Order Methods for Convex-Concave Minmax Problems: Applications to  Decision-Dependent Risk Minimization",
    "abstract": "Min-max optimization is emerging as a key framework for analyzing problems of\nrobustness to strategically and adversarially generated data. We propose a\nrandom reshuffling-based gradient free Optimistic Gradient Descent-Ascent\nalgorithm for solving convex-concave min-max problems with finite sum\nstructure. We prove that the algorithm enjoys the same convergence rate as that\nof zeroth-order algorithms for convex minimization problems. We further\nspecialize the algorithm to solve distributionally robust, decision-dependent\nlearning problems, where gradient information is not readily available. Through\nillustrative simulations, we observe that our proposed approach learns models\nthat are simultaneously robust against adversarial distribution shifts and\nstrategic decisions from the data sources, and outperforms existing methods\nfrom the strategic classification literature.",
    "descriptor": "\nComments: 32 pages, 5 figures\n",
    "authors": [
      "Chinmay Maheshwari",
      "Chih-Yuan Chiu",
      "Eric Mazumdar",
      "S. Shankar Sastry",
      "Lillian J. Ratliff"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09082"
  },
  {
    "id": "arXiv:2106.09093",
    "title": "A Hands-on Comparison of DNNs for Dialog SeparationUsing Transfer  Learning from Music Source Separation",
    "abstract": "This paper describes a hands-on comparison on using state-of-the-art music\nsource separation deep neural networks (DNNs) before and after task-specific\nfine-tuning for separating speech content from non-speech content in broadcast\naudio (i.e., dialog separation). The music separation models are selected as\nthey share the number of channels (2) and sampling rate (44.1 kHz or higher)\nwith the considered broadcast content, and vocals separation in music is\nconsidered as a parallel for dialog separation in the target application\ndomain. These similarities are assumed to enable transfer learning between the\ntasks. Three models pre-trained on music (Open-Unmix, Spleeter, and\nConv-TasNet) are considered in the experiments, and fine-tuned with real\nbroadcast data. The performance of the models is evaluated before and after\nfine-tuning with computational evaluation metrics (SI-SIRi, SI-SDRi, 2f-model),\nas well as with a listening test simulating an application where the non-speech\nsignal is partially attenuated, e.g., for better speech intelligibility. The\nevaluations include two reference systems specifically developed for dialog\nseparation. The results indicate that pre-trained music source separation\nmodels can be used for dialog separation to some degree, and that they benefit\nfrom the fine-tuning, reaching a performance close to task-specific solutions.",
    "descriptor": "\nComments: accepted in INTERSPEECH 2021\n",
    "authors": [
      "Martin Strauss",
      "Jouni Paulus",
      "Matteo Torcoli",
      "Bernd Edler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09093"
  },
  {
    "id": "arXiv:2106.09125",
    "title": "Convex Optimization for Trajectory Generation",
    "abstract": "Reliable and efficient trajectory generation methods are a fundamental need\nfor autonomous dynamical systems of tomorrow. The goal of this article is to\nprovide a comprehensive tutorial of three major convex optimization-based\ntrajectory generation methods: lossless convexification (LCvx), and two\nsequential convex programming algorithms known as SCvx and GuSTO. In this\narticle, trajectory generation is the computation of a dynamically feasible\nstate and control signal that satisfies a set of constraints while optimizing\nkey mission objectives. The trajectory generation problem is almost always\nnonconvex, which typically means that it is not readily amenable to efficient\nand reliable solution onboard an autonomous vehicle. The three algorithms that\nwe discuss use problem reformulation and a systematic algorithmic strategy to\nnonetheless solve nonconvex trajectory generation tasks through the use of a\nconvex optimizer. The theoretical guarantees and computational speed offered by\nconvex optimization have made the algorithms popular in both research and\nindustry circles. To date, the list of applications includes rocket landing,\nspacecraft hypersonic reentry, spacecraft rendezvous and docking, aerial motion\nplanning for fixed-wing and quadrotor vehicles, robot motion planning, and\nmore. Among these applications are high-profile rocket flights conducted by\norganizations like NASA, Masten Space Systems, SpaceX, and Blue Origin. This\narticle aims to give the reader the tools and understanding necessary to work\nwith each algorithm, and to know what each method can and cannot do. A publicly\navailable source code repository supports the provided numerical examples. By\nthe end of the article, the reader should be ready to use the methods, to\nextend them, and to contribute to their many exciting modern applications.",
    "descriptor": "\nComments: 68 pages, 42 figures, 5 tables. This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Danylo Malyuta",
      "Taylor P. Reynolds",
      "Michael Szmuk",
      "Thomas Lew",
      "Riccardo Bonalli",
      "Marco Pavone",
      "Behcet Acikmese"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09125"
  },
  {
    "id": "arXiv:2106.09132",
    "title": "Multivariate Pair Trading by Volatility & Model Adaption Trade-off",
    "abstract": "Pair trading is one of the most discussed topics among financial researches.\nDespite a growing base of work, portfolio management for multivariate time\nseries is rarely discussed. On the other hand, most researches focus on\nrefining strategy rules instead of finding the optimal portfolio weight. In\nthis paper, we brought up a simple yet profitable strategy called Volatility &\nModel Adaption Trade-off (VMAT) to leverage the issues. Experiment studies show\nits superior profit performance over baselines.",
    "descriptor": "\nComments: Submitting to Journal of Financial Economics\n",
    "authors": [
      "Chenyanzi Yu",
      "Tianyang Xie"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.09132"
  },
  {
    "id": "arXiv:2106.09149",
    "title": "Fr\u00e9chet derivatives of expected functionals of solutions to  stochastic differential equations",
    "abstract": "In the analysis of stochastic dynamical systems described by stochastic\ndifferential equations (SDEs), it is often of interest to analyse the\nsensitivity of the expected value of a functional of the solution of the SDE\nwith respect to perturbations in the SDE parameters. In this paper, we consider\npath functionals that depend on the solution of the SDE up to a stopping time.\nWe derive formulas for Fr\\'{e}chet derivatives of the expected values of these\nfunctionals with respect to bounded perturbations of the drift, using the\nCameron-Martin-Girsanov theorem for the change of measure. Using these\nderivatives, we construct an example to show that the map that sends the change\nof drift to the corresponding relative entropy is not in general convex. We\nthen analyse the existence and uniqueness of solutions to stochastic optimal\ncontrol problems defined on possibly random time intervals, as well as\ngradient-based numerical methods for solving such problems.",
    "descriptor": "",
    "authors": [
      "Han Cheng Lie"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.09149"
  },
  {
    "id": "arXiv:2106.09188",
    "title": "Physics-informed CoKriging model of a redox flow battery",
    "abstract": "Redox flow batteries (RFBs) offer the capability to store large amounts of\nenergy cheaply and efficiently, however, there is a need for fast and accurate\nmodels of the charge-discharge curve of a RFB to potentially improve the\nbattery capacity and performance. We develop a multifidelity model for\npredicting the charge-discharge curve of a RFB. In the multifidelity model, we\nuse the Physics-informed CoKriging (CoPhIK) machine learning method that is\ntrained on experimental data and constrained by the so-called\n\"zero-dimensional\" physics-based model. Here we demonstrate that the model\nshows good agreement with experimental results and significant improvements\nover existing zero-dimensional models. We show that the proposed model is\nrobust as it is not sensitive to the input parameters in the zero-dimensional\nmodel. We also show that only a small amount of high-fidelity experimental\ndatasets are needed for accurate predictions for the range of considered input\nparameters, which include current density, flow rate, and initial\nconcentrations.",
    "descriptor": "",
    "authors": [
      "Amanda A. Howard",
      "Alexandre M. Tartakovsky"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09188"
  },
  {
    "id": "arXiv:2106.09215",
    "title": "Optimum-statistical collaboration towards efficient black-box  optimization",
    "abstract": "With increasingly more hyperparameters involved in their training, machine\nlearning systems demand a better understanding of hyperparameter tuning\nautomation. This has raised interest in studies of provably black-box\noptimization, which is made more practical by better exploration mechanism\nimplemented in algorithm design, managing the flux of both optimization and\nstatistical errors. Prior efforts focus on delineating optimization errors, but\nthis is deficient: black-box optimization algorithms can be inefficient without\nconsidering heterogeneity among reward samples. In this paper, we make the key\ndelineation on the role of statistical uncertainty in black-box optimization,\nguiding a more efficient algorithm design. We introduce\n\\textit{optimum-statistical collaboration}, a framework of managing the\ninteraction between optimization error flux and statistical error flux evolving\nin the optimization process. Inspired by this framework, we propose the\n\\texttt{VHCT} algorithms for objective functions with only local-smoothness\nassumptions. In theory, we prove our algorithm enjoys rate-optimal regret\nbounds; in experiments, we show the algorithm outperforms prior efforts in\nextensive settings.",
    "descriptor": "",
    "authors": [
      "Wenjie Li",
      "Chihua Wang",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09215"
  },
  {
    "id": "arXiv:2106.09216",
    "title": "Layer Pruning on Demand with Intermediate CTC",
    "abstract": "Deploying an end-to-end automatic speech recognition (ASR) model on\nmobile/embedded devices is a challenging task, since the device computational\npower and energy consumption requirements are dynamically changed in practice.\nTo overcome the issue, we present a training and pruning method for ASR based\non the connectionist temporal classification (CTC) which allows reduction of\nmodel depth at run-time without any extra fine-tuning. To achieve the goal, we\nadopt two regularization methods, intermediate CTC and stochastic depth, to\ntrain a model whose performance does not degrade much after pruning. We present\nan in-depth analysis of layer behaviors using singular vector canonical\ncorrelation analysis (SVCCA), and efficient strategies for finding layers which\nare safe to prune. Using the proposed method, we show that a Transformer-CTC\nmodel can be pruned in various depth on demand, improving real-time factor from\n0.005 to 0.002 on GPU, while each pruned sub-model maintains the accuracy of\nindividually trained model of the same depth.",
    "descriptor": "\nComments: Interspeech 2021\n",
    "authors": [
      "Jaesong Lee",
      "Jingu Kang",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09216"
  },
  {
    "id": "arXiv:2106.09222",
    "title": "Localized Uncertainty Attacks",
    "abstract": "The susceptibility of deep learning models to adversarial perturbations has\nstirred renewed attention in adversarial examples resulting in a number of\nattacks. However, most of these attacks fail to encompass a large spectrum of\nadversarial perturbations that are imperceptible to humans. In this paper, we\npresent localized uncertainty attacks, a novel class of threat models against\ndeterministic and stochastic classifiers. Under this threat model, we create\nadversarial examples by perturbing only regions in the inputs where a\nclassifier is uncertain. To find such regions, we utilize the predictive\nuncertainty of the classifier when the classifier is stochastic or, we learn a\nsurrogate model to amortize the uncertainty when it is deterministic. Unlike\n$\\ell_p$ ball or functional attacks which perturb inputs indiscriminately, our\ntargeted changes can be less perceptible. When considered under our threat\nmodel, these attacks still produce strong adversarial examples; with the\nexamples retaining a greater degree of similarity with the inputs.",
    "descriptor": "\nComments: CVPR 2021 Workshop on Adversarial Machine Learning in Computer Vision\n",
    "authors": [
      "Ousmane Amadou Dia",
      "Theofanis Karaletsos",
      "Caner Hazirbas",
      "Cristian Canton Ferrer",
      "Ilknur Kaynar Kabul",
      "Erik Meijer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09222"
  },
  {
    "id": "arXiv:2106.09276",
    "title": "Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and  Benign Overfitting",
    "abstract": "We consider interpolation learning in high-dimensional linear regression with\nGaussian data, and prove a generic uniform convergence guarantee on the\ngeneralization error of interpolators in an arbitrary hypothesis class in terms\nof the class's Gaussian width. Applying the generic bound to Euclidean norm\nballs recovers the consistency result of Bartlett et al. (2020) for\nminimum-norm interpolators, and confirms a prediction of Zhou et al. (2020) for\nnear-minimal-norm interpolators in the special case of Gaussian data. We\ndemonstrate the generality of the bound by applying it to the simplex,\nobtaining a novel consistency result for minimum l1-norm interpolators (basis\npursuit). Our results show how norm-based generalization bounds can explain and\nbe used to analyze benign overfitting, at least in some settings.",
    "descriptor": "",
    "authors": [
      "Frederic Koehler",
      "Lijia Zhou",
      "Danica J. Sutherland",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.09276"
  },
  {
    "id": "arXiv:2106.09286",
    "title": "Sub-linear convergence of a tamed stochastic gradient descent method in  Hilbert space",
    "abstract": "In this paper, we introduce the tamed stochastic gradient descent method\n(TSGD) for optimization problems. Inspired by the tamed Euler scheme, which is\na commonly used method within the context of stochastic differential equations,\nTSGD is an explicit scheme that exhibits stability properties similar to those\nof implicit schemes. As its computational cost is essentially equivalent to\nthat of the well-known stochastic gradient descent method (SGD), it constitutes\na very competitive alternative to such methods.\nWe rigorously prove (optimal) sub-linear convergence of the scheme for\nstrongly convex objective functions on an abstract Hilbert space. The analysis\nonly requires very mild step size restrictions, which illustrates the good\nstability properties. The analysis is based on a priori estimates more\nfrequently encountered in a time integration context than in optimization, and\nthis alternative approach provides a different perspective also on the\nconvergence of SGD. Finally, we demonstrate the usability of the scheme on a\nproblem arising in a context of supervised learning.",
    "descriptor": "",
    "authors": [
      "Monika Eisenmann",
      "Tony Stillfjord"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09286"
  },
  {
    "id": "arXiv:2106.09303",
    "title": "A Multi-task convolutional neural network for blind stereoscopic image  quality assessment using naturalness analysis",
    "abstract": "This paper addresses the problem of blind stereoscopic image quality\nassessment (NR-SIQA) using a new multi-task deep learning based-method. In the\nfield of stereoscopic vision, the information is fairly distributed between the\nleft and right views as well as the binocular phenomenon. In this work, we\npropose to integrate these characteristics to estimate the quality of\nstereoscopic images without reference through a convolutional neural network.\nOur method is based on two main tasks: the first task predicts naturalness\nanalysis based features adapted to stereo images, while the second task\npredicts the quality of such images. The former, so-called auxiliary task, aims\nto find more robust and relevant features to improve the quality prediction. To\ndo this, we compute naturalness-based features using a Natural Scene Statistics\n(NSS) model in the complex wavelet domain. It allows to capture the statistical\ndependency between pairs of the stereoscopic images. Experiments are conducted\non the well known LIVE PHASE I and LIVE PHASE II databases. The results\nobtained show the relevance of our method when comparing with those of the\nstate-of-the-art. Our code is available online on\n\\url{https://github.com/Bourbia-Salima/multitask-cnn-nrsiqa_2021}.",
    "descriptor": "",
    "authors": [
      "Salima Bourbia",
      "Ayoub Karine",
      "Aladine Chetouani",
      "Mohammed El Hassouni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09303"
  },
  {
    "id": "arXiv:2106.09311",
    "title": "Controllable Confidence-Based Image Denoising",
    "abstract": "Image denoising is a classic restoration problem. Yet, current deep learning\nmethods are subject to the problems of generalization and interpretability. To\nmitigate these problems, in this project, we present a framework that is\ncapable of controllable, confidence-based noise removal. The framework is based\non the fusion between two different denoised images, both derived from the same\nnoisy input. One of the two is denoised using generic algorithms (e.g.\nGaussian), which make few assumptions on the input images, therefore,\ngeneralize in all scenarios. The other is denoised using deep learning,\nperforming well on seen datasets. We introduce a set of techniques to fuse the\ntwo components smoothly in the frequency domain. Beyond that, we estimate the\nconfidence of a deep learning denoiser to allow users to interpret the output,\nand provide a fusion strategy that safeguards them against out-of-distribution\ninputs. Through experiments, we demonstrate the effectiveness of the proposed\nframework in different use cases.",
    "descriptor": "",
    "authors": [
      "Haley Owsianko",
      "Florian Cassayre",
      "Qiyuan Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09311"
  },
  {
    "id": "arXiv:2106.09363",
    "title": "Similarity of particle systems using an invariant root mean square  deviation measure",
    "abstract": "Determining whether two particle systems are similar is a common problem in\nparticle simulations. When the comparison should be invariant under\npermutations, orthogonal transformations, and translations of the systems,\nspecial techniques are needed. We present an algorithm that can test particle\nsystems of finite size for similarity and, if they are similar, can find the\noptimal alignment between them. Our approach is based on an invariant version\nof the root mean square deviation (RMSD) measure and is capable of finding the\nglobally optimal solution in $O(n^3)$ operations where $n$ is the number of\nthree-dimensional particles.",
    "descriptor": "",
    "authors": [
      "Johannes Bulin",
      "Jan Hamaekers"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.09363"
  },
  {
    "id": "arXiv:2106.09374",
    "title": "Quantum algorithm for Dyck Language with Multiple Types of Brackets",
    "abstract": "We consider the recognition problem of the Dyck Language generalized for\nmultiple types of brackets. We provide an algorithm with quantum query\ncomplexity $O(\\sqrt{n}(\\log n)^{0.5k})$, where $n$ is the length of input and\n$k$ is the maximal nesting depth of brackets. Additionally, we show the lower\nbound for this problem which is $O(\\sqrt{n}c^{k})$ for some constant $c$.\nInterestingly, classical algorithms solving the Dyck Language for multiple\ntypes of brackets substantially differ form the algorithm solving the original\nDyck language. At the same time, quantum algorithms for solving both kinds of\nthe Dyck language are of similar nature and requirements.",
    "descriptor": "",
    "authors": [
      "Kamil Khadiev",
      "Dmitry Kravchenko"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.09374"
  },
  {
    "id": "arXiv:2106.09376",
    "title": "Differentially Private Hamiltonian Monte Carlo",
    "abstract": "Markov chain Monte Carlo (MCMC) algorithms have long been the main workhorses\nof Bayesian inference. Among them, Hamiltonian Monte Carlo (HMC) has recently\nbecome very popular due to its efficiency resulting from effective use of the\ngradients of the target distribution. In privacy-preserving machine learning,\ndifferential privacy (DP) has become the gold standard in ensuring that the\nprivacy of data subjects is not violated. Existing DP MCMC algorithms either\nuse random-walk proposals, or do not use the Metropolis--Hastings (MH)\nacceptance test to ensure convergence without decreasing their step size to\nzero. We present a DP variant of HMC using the MH acceptance test that builds\non a recently proposed DP MCMC algorithm called the penalty algorithm, and adds\nnoise to the gradient evaluations of HMC. We prove that the resulting algorithm\nconverges to the correct distribution, and is ergodic. We compare DP-HMC with\nthe existing penalty, DP-SGLD and DP-SGNHT algorithms, and find that DP-HMC has\nbetter or equal performance than the penalty algorithm, and performs more\nconsistently than DP-SGLD or DP-SGNHT.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Ossi R\u00e4is\u00e4",
      "Antti Koskela",
      "Antti Honkela"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09376"
  },
  {
    "id": "arXiv:2106.09391",
    "title": "Convergence of Dynamic Programming on the Semidefinite Cone",
    "abstract": "The goal of this paper is to investigate new and simple convergence analysis\nof dynamic programming for linear quadratic regulator problem of discrete-time\nlinear time-invariant systems. In particular, bounds on errors are given in\nterms of both matrix inequalities and matrix norm. Under a mild assumption on\nthe initial parameter, we prove that the Q-value iteration exponentially\nconverges to the optimal solution. Moreover, a global asymptotic convergence is\nalso presented. These results are then extended to the policy iteration. We\nprove that in contrast to the Q-value iteration, the policy iteration always\nconverges exponentially fast. An example is given to illustrate the results.",
    "descriptor": "",
    "authors": [
      "Donghwan Lee"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09391"
  },
  {
    "id": "arXiv:2106.09415",
    "title": "Trainable Discrete Feature Embeddings for Variational Quantum Classifier",
    "abstract": "Quantum classifiers provide sophisticated embeddings of input data in Hilbert\nspace promising quantum advantage. The advantage stems from quantum feature\nmaps encoding the inputs into quantum states with variational quantum circuits.\nA recent work shows how to map discrete features with fewer quantum bits using\nQuantum Random Access Coding (QRAC), an important primitive to encode binary\nstrings into quantum states. We propose a new method to embed discrete features\nwith trainable quantum circuits by combining QRAC and a recently proposed\nstrategy for training quantum feature map called quantum metric learning. We\nshow that the proposed trainable embedding requires not only as few qubits as\nQRAC but also overcomes the limitations of QRAC to classify inputs whose\nclasses are based on hard Boolean functions. We numerically demonstrate its use\nin variational quantum classifiers to achieve better performances in\nclassifying real-world datasets, and thus its possibility to leverage near-term\nquantum computers for quantum machine learning.",
    "descriptor": "",
    "authors": [
      "Napat Thumwanit",
      "Chayaphol Lortararprasert",
      "Hiroshi Yano",
      "Rudy Raymond"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09415"
  },
  {
    "id": "arXiv:2106.09473",
    "title": "Importance measures derived from random forests: characterisation and  extension",
    "abstract": "Nowadays new technologies, and especially artificial intelligence, are more\nand more established in our society. Big data analysis and machine learning,\ntwo sub-fields of artificial intelligence, are at the core of many recent\nbreakthroughs in many application fields (e.g., medicine, communication,\nfinance, ...), including some that are strongly related to our day-to-day life\n(e.g., social networks, computers, smartphones, ...). In machine learning,\nsignificant improvements are usually achieved at the price of an increasing\ncomputational complexity and thanks to bigger datasets. Currently, cutting-edge\nmodels built by the most advanced machine learning algorithms typically became\nsimultaneously very efficient and profitable but also extremely complex. Their\ncomplexity is to such an extent that these models are commonly seen as\nblack-boxes providing a prediction or a decision which can not be interpreted\nor justified. Nevertheless, whether these models are used autonomously or as a\nsimple decision-making support tool, they are already being used in machine\nlearning applications where health and human life are at stake. Therefore, it\nappears to be an obvious necessity not to blindly believe everything coming out\nof those models without a detailed understanding of their predictions or\ndecisions. Accordingly, this thesis aims at improving the interpretability of\nmodels built by a specific family of machine learning algorithms, the so-called\ntree-based methods. Several mechanisms have been proposed to interpret these\nmodels and we aim along this thesis to improve their understanding, study their\nproperties, and define their limitations.",
    "descriptor": "\nComments: PhD thesis, Li\\`ege, Belgium, June 2019. Permalink : this http URL\n",
    "authors": [
      "Antonio Sutera"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09473"
  },
  {
    "id": "arXiv:2106.09481",
    "title": "Stochastic Bias-Reduced Gradient Methods",
    "abstract": "We develop a new primitive for stochastic optimization: a low-bias, low-cost\nestimator of the minimizer $x_\\star$ of any Lipschitz strongly-convex function.\nIn particular, we use a multilevel Monte-Carlo approach due to Blanchet and\nGlynn to turn any optimal stochastic gradient method into an estimator of\n$x_\\star$ with bias $\\delta$, variance $O(\\log(1/\\delta))$, and an expected\nsampling cost of $O(\\log(1/\\delta))$ stochastic gradient evaluations. As an\nimmediate consequence, we obtain cheap and nearly unbiased gradient estimators\nfor the Moreau-Yoshida envelope of any Lipschitz convex function, allowing us\nto perform dimension-free randomized smoothing.\nWe demonstrate the potential of our estimator through four applications.\nFirst, we develop a method for minimizing the maximum of $N$ functions,\nimproving on recent results and matching a lower bound up logarithmic factors.\nSecond and third, we recover state-of-the-art rates for projection-efficient\nand gradient-efficient optimization using simple algorithms with a transparent\nanalysis. Finally, we show that an improved version of our estimator would\nyield a nearly linear-time, optimal-utility, differentially-private non-smooth\nstochastic optimization method.",
    "descriptor": "",
    "authors": [
      "Hilal Asi",
      "Yair Carmon",
      "Arun Jambulapati",
      "Yujia Jin",
      "Aaron Sidford"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09481"
  },
  {
    "id": "arXiv:2106.09488",
    "title": "Scaling Laws for Acoustic Models",
    "abstract": "There is a recent trend in machine learning to increase model quality by\ngrowing models to sizes previously thought to be unreasonable. Recent work has\nshown that autoregressive generative models with cross-entropy objective\nfunctions exhibit smooth power-law relationships, or scaling laws, that predict\nmodel quality from model size, training set size, and the available compute\nbudget. These scaling laws allow one to choose nearly optimal hyper-parameters\ngiven constraints on available training data, model parameter count, or\ntraining computation budget. In this paper, we demonstrate that acoustic models\ntrained with an auto-predictive coding loss behave as if they are subject to\nsimilar scaling laws. We extend previous work to jointly predict loss due to\nmodel size, to training set size, and to the inherent \"irreducible loss\" of the\ntask. We find that the scaling laws accurately match model performance over two\norders of magnitude in both model size and training set size, and make\npredictions about the limits of model performance.",
    "descriptor": "\nComments: Submitted to Interspeech 2021\n",
    "authors": [
      "Jasha Droppo",
      "Oguz Elibol"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09488"
  },
  {
    "id": "arXiv:2106.09512",
    "title": "Machine learning methods for postprocessing ensemble forecasts of wind  gusts: A systematic comparison",
    "abstract": "Postprocessing ensemble weather predictions to correct systematic errors has\nbecome a standard practice in research and operations. However, only few recent\nstudies have focused on ensemble postprocessing of wind gust forecasts, despite\nits importance for severe weather warnings. Here, we provide a comprehensive\nreview and systematic comparison of eight statistical and machine learning\nmethods for probabilistic wind gust forecasting via ensemble postprocessing,\nthat can be divided in three groups: State of the art postprocessing techniques\nfrom statistics (ensemble model output statistics (EMOS), member-by-member\npostprocessing, isotonic distributional regression), established machine\nlearning methods (gradient-boosting extended EMOS, quantile regression forests)\nand neural network-based approaches (distributional regression network,\nBernstein quantile network, histogram estimation network). The methods are\nsystematically compared using six years of data from a high-resolution,\nconvection-permitting ensemble prediction system that was run operationally at\nthe German weather service, and hourly observations at 175 surface weather\nstations in Germany. While all postprocessing methods yield calibrated\nforecasts and are able to correct the systematic errors of the raw ensemble\npredictions, incorporating information from additional meteorological predictor\nvariables beyond wind gusts leads to significant improvements in forecast\nskill. In particular, we propose a flexible framework of locally adaptive\nneural networks with different probabilistic forecast types as output, which\nnot only significantly outperform all benchmark postprocessing methods but also\nlearn physically consistent relations associated with the diurnal cycle,\nespecially the evening transition of the planetary boundary layer.",
    "descriptor": "",
    "authors": [
      "Benedikt Schulz",
      "Sebastian Lerch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.09512"
  },
  {
    "id": "arXiv:2106.09532",
    "title": "ASR Adaptation for E-commerce Chatbots using Cross-Utterance Context and  Multi-Task Language Modeling",
    "abstract": "Automatic Speech Recognition (ASR) robustness toward slot entities are\ncritical in e-commerce voice assistants that involve monetary transactions and\npurchases. Along with effective domain adaptation, it is intuitive that cross\nutterance contextual cues play an important role in disambiguating domain\nspecific content words from speech. In this paper, we investigate various\ntechniques to improve contextualization, content word robustness and domain\nadaptation of a Transformer-XL neural language model (NLM) to rescore ASR\nN-best hypotheses. To improve contextualization, we utilize turn level dialogue\nacts along with cross utterance context carry over. Additionally, to adapt our\ndomain-general NLM towards e-commerce on-the-fly, we use embeddings derived\nfrom a finetuned masked LM on in-domain data. Finally, to improve robustness\ntowards in-domain content words, we propose a multi-task model that can jointly\nperform content word detection and language modeling tasks. Compared to a\nnon-contextual LSTM LM baseline, our best performing NLM rescorer results in a\ncontent WER reduction of 19.2% on e-commerce audio test set and a slot labeling\nF1 improvement of 6.4%.",
    "descriptor": "\nComments: Accepted at ACL-IJCNLP 2021 Workshop on e-Commerce and NLP (ECNLP)\n",
    "authors": [
      "Ashish Shenoy",
      "Sravan Bodapati",
      "Katrin Kirchhoff"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09532"
  },
  {
    "id": "arXiv:2106.09539",
    "title": "Automatic Analysis of the Emotional Content of Speech in Daylong  Child-Centered Recordings from a Neonatal Intensive Care Unit",
    "abstract": "Researchers have recently started to study how the emotional speech heard by\nyoung infants can affect their developmental outcomes. As a part of this\nresearch, hundreds of hours of daylong recordings from preterm infants' audio\nenvironments were collected from two hospitals in Finland and Estonia in the\ncontext of so-called APPLE study. In order to analyze the emotional content of\nspeech in such a massive dataset, an automatic speech emotion recognition (SER)\nsystem is required. However, there are no emotion labels or existing indomain\nSER systems to be used for this purpose. In this paper, we introduce this\ninitially unannotated large-scale real-world audio dataset and describe the\ndevelopment of a functional SER system for the Finnish subset of the data. We\nexplore the effectiveness of alternative state-of-the-art techniques to deploy\na SER system to a new domain, comparing cross-corpus generalization, WGAN-based\ndomain adaptation, and active learning in the task. As a result, we show that\nthe best-performing models are able to achieve a classification performance of\n73.4% unweighted average recall (UAR) and 73.2% UAR for a binary classification\nfor valence and arousal, respectively. The results also show that active\nlearning achieves the most consistent performance compared to the two\nalternatives.",
    "descriptor": "",
    "authors": [
      "Einari Vaaras",
      "Sari Ahlqvist-Bj\u00f6rkroth",
      "Konstantinos Drossos",
      "Okko R\u00e4s\u00e4nen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09539"
  },
  {
    "id": "arXiv:2106.09545",
    "title": "STAN: A stuttering therapy analysis helper",
    "abstract": "Stuttering is a complex speech disorder identified by repeti-tions,\nprolongations of sounds, syllables or words and blockswhile speaking. Specific\nstuttering behaviour differs strongly,thus needing personalized therapy.\nTherapy sessions requirea high level of concentration by the therapist. We\nintroduceSTAN, a system to aid speech therapists in stuttering therapysessions.\nSuch an automated feedback system can lower thecognitive load on the therapist\nand thereby enable a more con-sistent therapy as well as allowing analysis of\nstuttering overthe span of multiple therapy sessions.",
    "descriptor": "",
    "authors": [
      "Sebastian P. Bayerl",
      "Marc Wenninger",
      "Jochen Schmidt",
      "Alexander Wolff von Gudenberg",
      "Korbinian Riedhammer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09545"
  },
  {
    "id": "arXiv:2106.09556",
    "title": "A Deep Reinforcement Learning Approach towards Pendulum Swing-up Problem  based on TF-Agents",
    "abstract": "Adapting the idea of training CartPole with Deep Q-learning agent, we are\nable to find a promising result that prevent the pole from falling down. The\ncapacity of reinforcement learning (RL) to learn from the interaction between\nthe environment and agent provides an optimal control strategy. In this paper,\nwe aim to solve the classic pendulum swing-up problem that making the learned\npendulum to be in upright position and balanced. Deep Deterministic Policy\nGradient algorithm is introduced to operate over continuous action domain in\nthis problem. Salient results of optimal pendulum are proved with increasing\naverage return, decreasing loss, and live video in the code part.",
    "descriptor": "",
    "authors": [
      "Yifei Bi",
      "Xinyi Chen",
      "Caihui Xiao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09556"
  },
  {
    "id": "arXiv:2106.09574",
    "title": "Localization based on enhanced low frequency interaural level difference",
    "abstract": "The processing of low-frequency interaural time differences is found to be\nproblematic among hearing-impaired people. The current generation of\nbeamformers does not consider this deficiency. In an attempt to tackle this\nissue, we propose to replace the inaudible interaural time differences in the\nlow-frequency region with the interaural level differences. In addition, a\nbeamformer is introduced and analyzed, which enhances the low-frequency\ninteraural level differences of the sound sources using a near-field\ntransformation. The proposed beamforming problem is relaxed to a convex problem\nusing semi-definite relaxation. The instrumental analysis suggests that the\nlow-frequency interaural level differences are enhanced without hindering the\nprovided intelligibility. A psychoacoustic localization test is done using a\nlistening experiment, which suggests that the replacement of time differences\ninto level differences improves the localization performance of normal-hearing\nlisteners for an anechoic scene but not for a reverberant scene.",
    "descriptor": "\nComments: 15 pages, 8 figures, preprint for a journal submission, paper in review, not yet accepted\n",
    "authors": [
      "Metin Calis",
      "Steven van de Par",
      "Richard Heusdens",
      "Richard C. Hendriks"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09574"
  },
  {
    "id": "arXiv:2106.09606",
    "title": "Cardinality Minimization, Constraints, and Regularization: A Survey",
    "abstract": "We survey optimization problems that involve the cardinality of variable\nvectors in constraints or the objective function. We provide a unified\nviewpoint on the general problem classes and models, and give concrete examples\nfrom diverse application fields such as signal and image processing, portfolio\nselection, or machine learning. The paper discusses general-purpose modeling\ntechniques and broadly applicable as well as problem-specific exact and\nheuristic solution approaches. While our perspective is that of mathematical\noptimization, a main goal of this work is to reach out to and build bridges\nbetween the different communities in which cardinality optimization problems\nare frequently encountered. In particular, we highlight that modern\nmixed-integer programming, which is often regarded as impractical due to\ncommonly unsatisfactory behavior of black-box solvers applied to generic\nproblem formulations, can in fact produce provably high-quality or even optimal\nsolutions for cardinality optimization problems, even in large-scale real-world\nsettings. Achieving such performance typically draws on the merits of\nproblem-specific knowledge that may stem from different fields of application\nand, e.g., shed light on structural properties of a model or its solutions, or\nlead to the development of efficient heuristics; we also provide some\nillustrative examples.",
    "descriptor": "",
    "authors": [
      "Andreas M. Tillmann",
      "Daniel Bienstock",
      "Andrea Lodi",
      "Alexandra Schwartz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.09606"
  },
  {
    "id": "arXiv:2106.09620",
    "title": "Disentangling Identifiable Features from Noisy Data with Structured  Nonlinear ICA",
    "abstract": "We introduce a new general identifiable framework for principled\ndisentanglement referred to as Structured Nonlinear Independent Component\nAnalysis (SNICA). Our contribution is to extend the identifiability theory of\ndeep generative models for a very broad class of structured models. While\nprevious works have shown identifiability for specific classes of time-series\nmodels, our theorems extend this to more general temporal structures as well as\nto models with more complex structures such as spatial dependencies. In\nparticular, we establish the major result that identifiability for this\nframework holds even in the presence of noise of unknown distribution. The\nSNICA setting therefore subsumes all the existing nonlinear ICA models for\ntime-series and also allows for new much richer identifiable models. Finally,\nas an example of our framework's flexibility, we introduce the first nonlinear\nICA model for time-series that combines the following very useful properties:\nit accounts for both nonstationarity and autocorrelation in a fully\nunsupervised setting; performs dimensionality reduction; models hidden states;\nand enables principled estimation and inference by variational\nmaximum-likelihood.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Hermanni H\u00e4lv\u00e4",
      "Sylvain Le Corff",
      "Luc Leh\u00e9ricy",
      "Jonathan So",
      "Yongjie Zhu",
      "Elisabeth Gassiat",
      "Aapo Hyvarinen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09620"
  },
  {
    "id": "arXiv:2106.09622",
    "title": "Extracting Different Levels of Speech Information from EEG Using an  LSTM-Based Model",
    "abstract": "Decoding the speech signal that a person is listening to from the human brain\nvia electroencephalography (EEG) can help us understand how our auditory system\nworks. Linear models have been used to reconstruct the EEG from speech or vice\nversa. Recently, Artificial Neural Networks (ANNs) such as Convolutional Neural\nNetwork (CNN) and Long Short-Term Memory (LSTM) based architectures have\noutperformed linear models in modeling the relation between EEG and speech.\nBefore attempting to use these models in real-world applications such as\nhearing tests or (second) language comprehension assessment we need to know\nwhat level of speech information is being utilized by these models. In this\nstudy, we aim to analyze the performance of an LSTM-based model using different\nlevels of speech features. The task of the model is to determine which of two\ngiven speech segments is matched with the recorded EEG. We used low- and\nhigh-level speech features including: envelope, mel spectrogram, voice\nactivity, phoneme identity, and word embedding. Our results suggest that the\nmodel exploits information about silences, intensity, and broad phonetic\nclasses from the EEG. Furthermore, the mel spectrogram, which contains all this\ninformation, yields the highest accuracy (84%) among all the features.",
    "descriptor": "",
    "authors": [
      "Mohammad Jalilpour Monesi",
      "Bernd Accou",
      "Tom Francart",
      "Hugo Van Hamme"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09622"
  },
  {
    "id": "arXiv:2106.09646",
    "title": "Impurity-induced increase in the thermal quantum correlations and  teleportation in an Ising-XXZ diamond chain",
    "abstract": "In this work we analyze the quantum correlations in a spin-1/2 Ising-XXZ\ndiamond chain with one plaquette distorted impurity. We have shown that the\nintroduction of impurity into the chain can significantly increase entanglement\nas well as quantum correlations compared to the original model, without\nimpurity. Due to the great flexibility in the choice of impurity parameters,\nthe model presented is very general and this fact can be very useful for future\nexperimental measurements. In addition to entanglement and quantum coherence,\nwe studied quantum teleportation through a quantum channel composed by a\ncoupled of Heisenberg dimers with distorted impurity in an Ising-XXZ diamond\nchain, as well as fidelity in teleportation. Our analysis shows that the\nappropriate choice of parameters can greatly increase all the measures\nanalyzed. For comparison purposes, we present all our results together with the\nresults of the measurements made for the original model, without impurity,\nstudied in previous works.",
    "descriptor": "",
    "authors": [
      "Saulo L. L. Silva",
      "Moises Rojas"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.09646"
  },
  {
    "id": "arXiv:2106.09660",
    "title": "WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis",
    "abstract": "This paper introduces WaveGrad 2, a non-autoregressive generative model for\ntext-to-speech synthesis. WaveGrad 2 is trained to estimate the gradient of the\nlog conditional density of the waveform given a phoneme sequence. The model\ntakes an input phoneme sequence, and through an iterative refinement process,\ngenerates an audio waveform. This contrasts to the original WaveGrad vocoder\nwhich conditions on mel-spectrogram features, generated by a separate model.\nThe iterative refinement process starts from Gaussian noise, and through a\nseries of refinement steps (e.g., 50 steps), progressively recovers the audio\nsequence. WaveGrad 2 offers a natural way to trade-off between inference speed\nand sample quality, through adjusting the number of refinement steps.\nExperiments show that the model can generate high fidelity audio, approaching\nthe performance of a state-of-the-art neural TTS system. We also report various\nablation studies over different model configurations. Audio samples are\navailable at https://wavegrad.github.io/v2.",
    "descriptor": "\nComments: Copyright 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Nanxin Chen",
      "Yu Zhang",
      "Heiga Zen",
      "Ron J. Weiss",
      "Mohammad Norouzi",
      "Najim Dehak",
      "William Chan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09660"
  },
  {
    "id": "arXiv:2106.09662",
    "title": "Automatic Segmentation of the Prostate on 3D Trans-rectal Ultrasound  Images using Statistical Shape Models and Convolutional Neural Networks",
    "abstract": "In this work we propose to segment the prostate on a challenging dataset of\ntrans-rectal ultrasound (TRUS) images using convolutional neural networks\n(CNNs) and statistical shape models (SSMs). TRUS is commonly used for a number\nof image-guided interventions on the prostate. Fast and accurate segmentation\non the organ in these images is crucial to planning and fusion with other\nmodalities such as magnetic resonance images (MRIs) . However, TRUS has limited\nsoft tissue contrast and signal to noise ratio which makes the task of\nsegmenting the prostate challenging and subject to inter-observer and\nintra-observer variability. This is especially problematic at the base and apex\nwhere the gland boundary is hard to define. In this paper, we aim to tackle\nthis problem by taking advantage of shape priors learnt on an MR dataset which\nhas higher soft tissue contrast allowing the prostate to be contoured more\naccurately. We use this shape prior in combination with a prostate tissue\nprobability map computed by a CNN for segmentation.",
    "descriptor": "",
    "authors": [
      "Golnoosh Samei",
      "Davood Karimi",
      "Claudia Kesch",
      "Septimiu Salcudean"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09662"
  },
  {
    "id": "arXiv:2106.09663",
    "title": "A Short Note of PAGE: Optimal Convergence Rates for Nonconvex  Optimization",
    "abstract": "In this note, we first recall the nonconvex problem setting and introduce the\noptimal PAGE algorithm (Li et al., ICML'21). Then we provide a simple and clean\nconvergence analysis of PAGE for achieving optimal convergence rates. Moreover,\nPAGE and its analysis can be easily adopted and generalized to other works. We\nhope that this note provides the insights and is helpful for future works.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Zhize Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09663"
  },
  {
    "id": "arXiv:2106.09664",
    "title": "Design and Analysis of Robust Deep Learning Models for Stock Price  Prediction",
    "abstract": "Building predictive models for robust and accurate prediction of stock prices\nand stock price movement is a challenging research problem to solve. The\nwell-known efficient market hypothesis believes in the impossibility of\naccurate prediction of future stock prices in an efficient stock market as the\nstock prices are assumed to be purely stochastic. However, numerous works\nproposed by researchers have demonstrated that it is possible to predict future\nstock prices with a high level of precision using sophisticated algorithms,\nmodel architectures, and the selection of appropriate variables in the models.\nThis chapter proposes a collection of predictive regression models built on\ndeep learning architecture for robust and precise prediction of the future\nprices of a stock listed in the diversified sectors in the National Stock\nExchange (NSE) of India. The Metastock tool is used to download the historical\nstock prices over a period of two years (2013- 2014) at 5 minutes intervals.\nWhile the records for the first year are used to train the models, the testing\nis carried out using the remaining records. The design approaches of all the\nmodels and their performance results are presented in detail. The models are\nalso compared based on their execution time and accuracy of prediction.",
    "descriptor": "\nComments: This is the pre-print of our chapter that has been accepted for publication in the forthcoming book entitled \"Machine Learning: Algorithms, Models, and Applications\". The book will be published by IntechOpen, London, UK, in an open access in the later part of the year 2021. The chapter is 29 pages long, and it has 20 figures and 21 tables. arXiv admin note: substantial text overlap with arXiv:2103.15096\n",
    "authors": [
      "Jaydip Sen",
      "Sidra Mehtab"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09664"
  },
  {
    "id": "arXiv:2106.09702",
    "title": "Spectral goodness-of-fit tests for complete and partial network data",
    "abstract": "Networks describe the, often complex, relationships between individual\nactors. In this work, we address the question of how to determine whether a\nparametric model, such as a stochastic block model or latent space model, fits\na dataset well and will extrapolate to similar data. We use recent results in\nrandom matrix theory to derive a general goodness-of-fit test for dyadic data.\nWe show that our method, when applied to a specific model of interest, provides\nan straightforward, computationally fast way of selecting parameters in a\nnumber of commonly used network models. For example, we show how to select the\ndimension of the latent space in latent space models. Unlike other network\ngoodness-of-fit methods, our general approach does not require simulating from\na candidate parametric model, which can be cumbersome with large graphs, and\neliminates the need to choose a particular set of statistics on the graph for\ncomparison. It also allows us to perform goodness-of-fit tests on partial\nnetwork data, such as Aggregated Relational Data. We show with simulations that\nour method performs well in many situations of interest. We analyze several\nempirically relevant networks and show that our method leads to improved\ncommunity detection algorithms. R code to implement our method is available on\nGithub.",
    "descriptor": "",
    "authors": [
      "Shane Lubold",
      "Bolun Liu",
      "Tyler H. McCormick"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09702"
  },
  {
    "id": "arXiv:1210.8234",
    "title": "The hyperbolic Voronoi diagram in arbitrary dimension",
    "abstract": "Comments: 18 pages, 3 figures",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Frank Nielsen",
      "Richard Nock"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1210.8234"
  },
  {
    "id": "arXiv:1607.06565",
    "title": "Estimating Causal Peer Influence in Homophilous Social Networks by  Inferring Latent Locations",
    "abstract": "Comments: 35 pages, 4 figures",
    "descriptor": "\nComments: 35 pages, 4 figures\n",
    "authors": [
      "Edward McFowland III",
      "Cosma Rohilla Shalizi"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/1607.06565"
  },
  {
    "id": "arXiv:1807.11702",
    "title": "Efficient Computation of Sequence Mappability",
    "abstract": "Comments: Accepted to SPIRE 2018",
    "descriptor": "\nComments: Accepted to SPIRE 2018\n",
    "authors": [
      "Panagiotis Charalampopoulos",
      "Costas S. Iliopoulos",
      "Tomasz Kociumaka",
      "Solon P. Pissis",
      "Jakub Radoszewski",
      "Juliusz Straszy\u0144ski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1807.11702"
  },
  {
    "id": "arXiv:1811.09003",
    "title": "On a Sparse Shortcut Topology of Artificial Neural Networks",
    "abstract": "On a Sparse Shortcut Topology of Artificial Neural Networks",
    "descriptor": "",
    "authors": [
      "Fenglei Fan",
      "Dayang Wang",
      "Hengtao Guo",
      "Qikui Zhu",
      "Pingkun Yan",
      "Ge Wang",
      "Hengyong Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1811.09003"
  },
  {
    "id": "arXiv:1901.01981",
    "title": "A Scale-invariant Generalization of the R\u00e9nyi Entropy, Associated  Divergences and their Optimizations under Tsallis' Nonextensive Framework",
    "abstract": "A Scale-invariant Generalization of the R\u00e9nyi Entropy, Associated  Divergences and their Optimizations under Tsallis' Nonextensive Framework",
    "descriptor": "",
    "authors": [
      "Abhik Ghosh",
      "Ayanendranath Basu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1901.01981"
  },
  {
    "id": "arXiv:1904.12342",
    "title": "Video Analytics with Zero-streaming Cameras",
    "abstract": "Comments: Mengwei Xu and Tiantu Xu contributed equally to the paper",
    "descriptor": "\nComments: Mengwei Xu and Tiantu Xu contributed equally to the paper\n",
    "authors": [
      "Mengwei Xu",
      "Tiantu Xu",
      "Yunxin Liu",
      "Felix Xiaozhu Lin"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1904.12342"
  },
  {
    "id": "arXiv:1905.07382",
    "title": "Merging versus Ensembling in Multi-Study Prediction: Theoretical Insight  from Random Effects",
    "abstract": "Merging versus Ensembling in Multi-Study Prediction: Theoretical Insight  from Random Effects",
    "descriptor": "",
    "authors": [
      "Zoe Guan",
      "Giovanni Parmigiani",
      "Prasad Patil"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1905.07382"
  },
  {
    "id": "arXiv:1908.06757",
    "title": "Boosting the Bounds of Symbolic QED for Effective Pre-Silicon  Verification of Processor Cores",
    "abstract": "Comments: arXiv admin note: withdrawn by arXiv administrators due to incomplete author list",
    "descriptor": "\nComments: arXiv admin note: withdrawn by arXiv administrators due to incomplete author list\n",
    "authors": [
      "Karthik Ganesan",
      "Srinivasa Shashank Nuthakki"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1908.06757"
  },
  {
    "id": "arXiv:1908.08407",
    "title": "Coordination Through Shared Randomness",
    "abstract": "Comments: 27 pages, 7 figures. Some results of this paper were presented at ISIT 2018 and ITW 2019. This paper subsumes arXiv:1805.03193",
    "descriptor": "\nComments: 27 pages, 7 figures. Some results of this paper were presented at ISIT 2018 and ITW 2019. This paper subsumes arXiv:1805.03193\n",
    "authors": [
      "Gowtham R. Kurri",
      "Vinod M. Prabhakaran",
      "Anand D. Sarwate"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1908.08407"
  },
  {
    "id": "arXiv:1908.08430",
    "title": "Residues of skew rational functions",
    "abstract": "Residues of skew rational functions",
    "descriptor": "",
    "authors": [
      "Xavier Caruso"
    ],
    "subjectives": [
      "Rings and Algebras (math.RA)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/1908.08430"
  },
  {
    "id": "arXiv:1909.03405",
    "title": "Symmetric Regularization based BERT for Pair-wise Semantic Reasoning",
    "abstract": "Comments: 8 pages, 3 figures, 6 tables",
    "descriptor": "\nComments: 8 pages, 3 figures, 6 tables\n",
    "authors": [
      "Weidi Xu",
      "Xingyi Cheng",
      "Kunlong Chen",
      "Wei Wang",
      "Bin Bi",
      "Ming Yan",
      "Chen Wu",
      "Luo Si",
      "Wei Chu",
      "Taifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1909.03405"
  },
  {
    "id": "arXiv:1909.12748",
    "title": "Device-to-Device Private Caching with Trusted Server",
    "abstract": "Comments: accepted in 2020 IEEE International Conference on Communications",
    "descriptor": "\nComments: accepted in 2020 IEEE International Conference on Communications\n",
    "authors": [
      "Kai Wan",
      "Hua Sun",
      "Mingyue Ji",
      "Daniela Tuninetti",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1909.12748"
  },
  {
    "id": "arXiv:1911.01212",
    "title": "Scrambled Translation Problem: A Problem of Denoising UNMT",
    "abstract": "Comments: Accepted by MT Summit 2021",
    "descriptor": "\nComments: Accepted by MT Summit 2021\n",
    "authors": [
      "Tamali Banerjee",
      "Rudra Murthy V",
      "Pushpak Bhattacharyya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.01212"
  },
  {
    "id": "arXiv:1911.07899",
    "title": "Cooperative Multiple-Access Channels with Distributed State Information",
    "abstract": "Cooperative Multiple-Access Channels with Distributed State Information",
    "descriptor": "",
    "authors": [
      "Lorenzo Miretti",
      "Mari Kobayashi",
      "David Gesbert",
      "Paul de Kerret"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1911.07899"
  },
  {
    "id": "arXiv:1911.08782",
    "title": "Joint Emotion Label Space Modelling for Affect Lexica",
    "abstract": "Comments: Computer Speech and Language journal, to appear",
    "descriptor": "\nComments: Computer Speech and Language journal, to appear\n",
    "authors": [
      "Luna De Bruyne",
      "Pepa Atanasova",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1911.08782"
  },
  {
    "id": "arXiv:1911.10088",
    "title": "Optimizing Data Usage via Differentiable Rewards",
    "abstract": "Comments: Accepted at ICML 2020",
    "descriptor": "\nComments: Accepted at ICML 2020\n",
    "authors": [
      "Xinyi Wang",
      "Hieu Pham",
      "Paul Michel",
      "Antonios Anastasopoulos",
      "Jaime Carbonell",
      "Graham Neubig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.10088"
  },
  {
    "id": "arXiv:1912.02000",
    "title": "On games with coordinating and anti-coordinating agents",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Martina Vanelli",
      "Laura Arditti",
      "Giacomo Como",
      "Fabio Fagnani"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1912.02000"
  },
  {
    "id": "arXiv:1912.08061",
    "title": "Normalization of breast MRIs using Cycle-Consistent Generative  Adversarial Networks",
    "abstract": "Comments: Final accepted draft in Computer Methods and Programs in Biomedicine",
    "descriptor": "\nComments: Final accepted draft in Computer Methods and Programs in Biomedicine\n",
    "authors": [
      "Gourav Modanwal",
      "Adithya Vellal",
      "Maciej A. Mazurowski"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1912.08061"
  },
  {
    "id": "arXiv:2002.00727",
    "title": "Distance Metric Learning for Graph Structured Data",
    "abstract": "Comments: 38 pages, 11 figures. This is a pre-print of an article published in Machine Learning Journal. The final authenticated version is available online at: this https URL",
    "descriptor": "\nComments: 38 pages, 11 figures. This is a pre-print of an article published in Machine Learning Journal. The final authenticated version is available online at: this https URL\n",
    "authors": [
      "Tomoki Yoshida",
      "Ichiro Takeuchi",
      "Masayuki Karasuyama"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.00727"
  },
  {
    "id": "arXiv:2002.00874",
    "title": "Finite-Sample Analysis of Stochastic Approximation Using Smooth Convex  Envelopes",
    "abstract": "Finite-Sample Analysis of Stochastic Approximation Using Smooth Convex  Envelopes",
    "descriptor": "",
    "authors": [
      "Zaiwei Chen",
      "Siva Theja Maguluri",
      "Sanjay Shakkottai",
      "Karthikeyan Shanmugam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.00874"
  },
  {
    "id": "arXiv:2002.07285",
    "title": "Double/Debiased Machine Learning for Dynamic Treatment Effects via  g-Estimation",
    "abstract": "Double/Debiased Machine Learning for Dynamic Treatment Effects via  g-Estimation",
    "descriptor": "",
    "authors": [
      "Greg Lewis",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.07285"
  },
  {
    "id": "arXiv:2003.09658",
    "title": "A proof of the Total Coloring Conjecture",
    "abstract": "Comments: No major changes in this third-version apart from addition of Remark 3.5, corrections of typos, and some minor refinements in explanation as and where it was necessary",
    "descriptor": "\nComments: No major changes in this third-version apart from addition of Remark 3.5, corrections of typos, and some minor refinements in explanation as and where it was necessary\n",
    "authors": [
      "T Srinivasa Murthy"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2003.09658"
  },
  {
    "id": "arXiv:2003.13742",
    "title": "DC-DistADMM: ADMM Algorithm for Contsrained Distributed Optimization  over Directed Graphs",
    "abstract": "Comments: 18 pages, 9 Figures, includes an appendix",
    "descriptor": "\nComments: 18 pages, 9 Figures, includes an appendix\n",
    "authors": [
      "Vivek Khatana",
      "Murti V. Salapaka"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2003.13742"
  },
  {
    "id": "arXiv:2004.03974",
    "title": "Pre-training is a Hot Topic: Contextualized Document Embeddings Improve  Topic Coherence",
    "abstract": "Comments: Updated version. Published as a conference paper at ACL-IJCNLP 2021",
    "descriptor": "\nComments: Updated version. Published as a conference paper at ACL-IJCNLP 2021\n",
    "authors": [
      "Federico Bianchi",
      "Silvia Terragni",
      "Dirk Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2004.03974"
  },
  {
    "id": "arXiv:2004.08085",
    "title": "Statistical Learning Guarantees for Compressive Clustering and  Compressive Mixture Modeling",
    "abstract": "Comments: This preprint results from a split and profound restructuring and improvements of of this https URL is a companion paper to this https URL",
    "descriptor": "\nComments: This preprint results from a split and profound restructuring and improvements of of this https URL is a companion paper to this https URL\n",
    "authors": [
      "R\u00e9mi Gribonval",
      "Gilles Blanchard",
      "Nicolas Keriven",
      "Yann Traonmilin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2004.08085"
  },
  {
    "id": "arXiv:2005.07662",
    "title": "Guided interactive image segmentation using machine learning and color  based data set clustering",
    "abstract": "Guided interactive image segmentation using machine learning and color  based data set clustering",
    "descriptor": "",
    "authors": [
      "Adrian Friebel",
      "Tim Johann",
      "Dirk Drasdo",
      "Stefan Hoehme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2005.07662"
  },
  {
    "id": "arXiv:2006.01325",
    "title": "Optimal Non-Adaptive Probabilistic Group Testing in General Sparsity  Regimes",
    "abstract": "Comments: Approximate recovery results are in v1 only; v5 sharpens to give precise constants and a matching upper bound",
    "descriptor": "\nComments: Approximate recovery results are in v1 only; v5 sharpens to give precise constants and a matching upper bound\n",
    "authors": [
      "Wei Heng Bay",
      "Eric Price",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2006.01325"
  },
  {
    "id": "arXiv:2006.05630",
    "title": "Distributional Robust Batch Contextual Bandits",
    "abstract": "Comments: The short version has been accepted in ICML 2020",
    "descriptor": "\nComments: The short version has been accepted in ICML 2020\n",
    "authors": [
      "Nian Si",
      "Fan Zhang",
      "Zhengyuan Zhou",
      "Jose Blanchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05630"
  },
  {
    "id": "arXiv:2006.05865",
    "title": "Deep Dimension Reduction for Supervised Representation Learning",
    "abstract": "Deep Dimension Reduction for Supervised Representation Learning",
    "descriptor": "",
    "authors": [
      "Jian Huang",
      "Yuling Jiao",
      "Xu Liao",
      "Jin Liu",
      "Zhou Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05865"
  },
  {
    "id": "arXiv:2006.06356",
    "title": "Adversarial Attack Vulnerability of Medical Image Analysis Systems:  Unexplored Factors",
    "abstract": "Comments: First three authors contributed equally",
    "descriptor": "\nComments: First three authors contributed equally\n",
    "authors": [
      "Gerda Bortsova",
      "Cristina Gonz\u00e1lez-Gonzalo",
      "Suzanne C. Wetstein",
      "Florian Dubost",
      "Ioannis Katramados",
      "Laurens Hogeweg",
      "Bart Liefers",
      "Bram van Ginneken",
      "Josien P.W. Pluim",
      "Mitko Veta",
      "Clara I. S\u00e1nchez",
      "Marleen de Bruijne"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2006.06356"
  },
  {
    "id": "arXiv:2006.07831",
    "title": "Class2Simi: A Noise Reduction Perspective on Learning with Noisy Labels",
    "abstract": "Class2Simi: A Noise Reduction Perspective on Learning with Noisy Labels",
    "descriptor": "",
    "authors": [
      "Songhua Wu",
      "Xiaobo Xia",
      "Tongliang Liu",
      "Bo Han",
      "Mingming Gong",
      "Nannan Wang",
      "Haifeng Liu",
      "Gang Niu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07831"
  },
  {
    "id": "arXiv:2006.09268",
    "title": "Metrizing Weak Convergence with Maximum Mean Discrepancies",
    "abstract": "Comments: 14 pages. Corrects in particular Thm.12 of Simon-Gabriel and Sch\\\"olkopf, JMLR, 19(44):1-29, 2018. See this http URL",
    "descriptor": "\nComments: 14 pages. Corrects in particular Thm.12 of Simon-Gabriel and Sch\\\"olkopf, JMLR, 19(44):1-29, 2018. See this http URL\n",
    "authors": [
      "Carl-Johann Simon-Gabriel",
      "Alessandro Barp",
      "Bernhard Sch\u00f6lkopf",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.09268"
  },
  {
    "id": "arXiv:2006.10411",
    "title": "Sparse bottleneck neural networks for exploratory non-linear  visualization of Patch-seq data",
    "abstract": "Comments: 15 pages, 10 figures",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Yves Bernaerts",
      "Philipp Berens",
      "Dmitry Kobak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10411"
  },
  {
    "id": "arXiv:2006.12557",
    "title": "Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and  Data Poisoning Attacks",
    "abstract": "Comments: 19 pages, 4 figures",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Avi Schwarzschild",
      "Micah Goldblum",
      "Arjun Gupta",
      "John P Dickerson",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.12557"
  },
  {
    "id": "arXiv:2006.13051",
    "title": "Interpretable security analysis of cancellable biometrics using  constrained-optimized similarity-based attack",
    "abstract": "Interpretable security analysis of cancellable biometrics using  constrained-optimized similarity-based attack",
    "descriptor": "",
    "authors": [
      "Hanrui Wang",
      "Xingbo Dong",
      "Zhe Jin",
      "Andrew Beng Jin Teoh",
      "Massimo Tistarelli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2006.13051"
  },
  {
    "id": "arXiv:2006.15417",
    "title": "Invertible Concept-based Explanations for CNN Models with Non-negative  Concept Activation Vectors",
    "abstract": "Invertible Concept-based Explanations for CNN Models with Non-negative  Concept Activation Vectors",
    "descriptor": "",
    "authors": [
      "Ruihan Zhang",
      "Prashan Madumal",
      "Tim Miller",
      "Krista A. Ehinger",
      "Benjamin I. P. Rubinstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.15417"
  },
  {
    "id": "arXiv:2007.03328",
    "title": "Guided Exploration with Proximal Policy Optimization using a Single  Demonstration",
    "abstract": "Guided Exploration with Proximal Policy Optimization using a Single  Demonstration",
    "descriptor": "",
    "authors": [
      "Gabriele Libardi",
      "Gianni De Fabritiis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2007.03328"
  },
  {
    "id": "arXiv:2007.07557",
    "title": "Incremental Without Replacement Sampling in Nonconvex Optimization",
    "abstract": "Incremental Without Replacement Sampling in Nonconvex Optimization",
    "descriptor": "",
    "authors": [
      "Edouard Pauwels"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2007.07557"
  },
  {
    "id": "arXiv:2007.08876",
    "title": "Tractability Beyond $\u03b2$-Acyclicity for Conjunctive Queries with  Negation",
    "abstract": "Tractability Beyond $\u03b2$-Acyclicity for Conjunctive Queries with  Negation",
    "descriptor": "",
    "authors": [
      "Matthias Lanzinger"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2007.08876"
  },
  {
    "id": "arXiv:2007.15147",
    "title": "A General Framework For Detecting Anomalous Inputs to DNN Classifiers",
    "abstract": "A General Framework For Detecting Anomalous Inputs to DNN Classifiers",
    "descriptor": "",
    "authors": [
      "Jayaram Raghuram",
      "Varun Chandrasekaran",
      "Somesh Jha",
      "Suman Banerjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.15147"
  },
  {
    "id": "arXiv:2007.15706",
    "title": "Machine learning for complete intersection Calabi-Yau manifolds: a  methodological study",
    "abstract": "Comments: 59 pages; additional details, references updated",
    "descriptor": "\nComments: 59 pages; additional details, references updated\n",
    "authors": [
      "Harold Erbin",
      "Riccardo Finotello"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (cs.LG)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2007.15706"
  },
  {
    "id": "arXiv:2007.16039",
    "title": "Data-driven Inverter-based Volt/VAr Control for Partially Observable  Distribution Networks",
    "abstract": "Comments: accepted by CSEE Journal of Power and Energy Systems and published in June 2021",
    "descriptor": "\nComments: accepted by CSEE Journal of Power and Energy Systems and published in June 2021\n",
    "authors": [
      "Tong Xu",
      "Wenchuan Wu",
      "Yiwen Hong",
      "Junjie Yu",
      "Fazhong Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2007.16039"
  },
  {
    "id": "arXiv:2008.04990",
    "title": "Batch Value-function Approximation with Only Realizability",
    "abstract": "Comments: Published in ICML 2021",
    "descriptor": "\nComments: Published in ICML 2021\n",
    "authors": [
      "Tengyang Xie",
      "Nan Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.04990"
  },
  {
    "id": "arXiv:2008.07838",
    "title": "Improving adversarial robustness of deep neural networks by using  semantic information",
    "abstract": "Comments: 13 pages, 9 figures",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Lina Wang",
      "Rui Tang",
      "Yawei Yue",
      "Xingshu Chen",
      "Wei Wang",
      "Yi Zhu",
      "Xuemei Zeng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.07838"
  },
  {
    "id": "arXiv:2008.10032",
    "title": "Seesaw Loss for Long-Tailed Instance Segmentation",
    "abstract": "Comments: CVPR 2021 Camera Ready",
    "descriptor": "\nComments: CVPR 2021 Camera Ready\n",
    "authors": [
      "Jiaqi Wang",
      "Wenwei Zhang",
      "Yuhang Zang",
      "Yuhang Cao",
      "Jiangmiao Pang",
      "Tao Gong",
      "Kai Chen",
      "Ziwei Liu",
      "Chen Change Loy",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.10032"
  },
  {
    "id": "arXiv:2008.10255",
    "title": "Optimal internal boundary control of lane-free automated vehicle traffic",
    "abstract": "Optimal internal boundary control of lane-free automated vehicle traffic",
    "descriptor": "",
    "authors": [
      "Milad Malekzadeh",
      "Ioannis Papamichail",
      "Markos Papageorgiou",
      "Klaus Bogenberger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.10255"
  },
  {
    "id": "arXiv:2009.01439",
    "title": "Learning Dexterous Grasping with Object-Centric Visual Affordances",
    "abstract": "Comments: Accepted at ICRA 2021",
    "descriptor": "\nComments: Accepted at ICRA 2021\n",
    "authors": [
      "Priyanka Mandikal",
      "Kristen Grauman"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.01439"
  },
  {
    "id": "arXiv:2009.02007",
    "title": "Real-Time Selfie Video Stabilization",
    "abstract": "Real-Time Selfie Video Stabilization",
    "descriptor": "",
    "authors": [
      "Jiyang Yu",
      "Ravi Ramamoorthi",
      "Keli Cheng",
      "Michel Sarkis",
      "Ning Bi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.02007"
  },
  {
    "id": "arXiv:2009.03017",
    "title": "Non-exponentially weighted aggregation: regret bounds for unbounded loss  functions",
    "abstract": "Non-exponentially weighted aggregation: regret bounds for unbounded loss  functions",
    "descriptor": "",
    "authors": [
      "Pierre Alquier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.03017"
  },
  {
    "id": "arXiv:2009.03586",
    "title": "Hyperparameter Optimization via Sequential Uniform Designs",
    "abstract": "Hyperparameter Optimization via Sequential Uniform Designs",
    "descriptor": "",
    "authors": [
      "Zebin Yang",
      "Aijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.03586"
  },
  {
    "id": "arXiv:2009.05908",
    "title": "Understanding Boolean Function Learnability on Deep Neural Networks",
    "abstract": "Understanding Boolean Function Learnability on Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Anderson R. Tavares",
      "Pedro Avelar",
      "Jo\u00e3o M. Flach",
      "Marcio Nicolau",
      "Luis C. Lamb",
      "Moshe Vardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.05908"
  },
  {
    "id": "arXiv:2009.08039",
    "title": "Discond-VAE: Disentangling Continuous Factors from the Discrete",
    "abstract": "Discond-VAE: Disentangling Continuous Factors from the Discrete",
    "descriptor": "",
    "authors": [
      "Jaewoong Choi",
      "Geonho Hwang",
      "Myungjoo Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.08039"
  },
  {
    "id": "arXiv:2009.12873",
    "title": "RAR-U-Net: a Residual Encoder to Attention Decoder by Residual  Connections Framework for Spine Segmentation under Noisy Labels",
    "abstract": "RAR-U-Net: a Residual Encoder to Attention Decoder by Residual  Connections Framework for Spine Segmentation under Noisy Labels",
    "descriptor": "",
    "authors": [
      "Ziyang Wang",
      "Zhengdong Zhang",
      "Irina Voiculescu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.12873"
  },
  {
    "id": "arXiv:2010.02383",
    "title": "Randomized Value Functions via Posterior State-Abstraction Sampling",
    "abstract": "Comments: Accepted to the Workshop on Biological and Artificial Reinforcement Learning (NeurIPS 2020)",
    "descriptor": "\nComments: Accepted to the Workshop on Biological and Artificial Reinforcement Learning (NeurIPS 2020)\n",
    "authors": [
      "Dilip Arumugam",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.02383"
  },
  {
    "id": "arXiv:2010.04782",
    "title": "Learning Languages in the Limit from Positive Information with Finitely  Many Memory Changes",
    "abstract": "Learning Languages in the Limit from Positive Information with Finitely  Many Memory Changes",
    "descriptor": "",
    "authors": [
      "Timo K\u00f6tzing",
      "Karen Seidel"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.04782"
  },
  {
    "id": "arXiv:2010.05084",
    "title": "Reflexive Design for Fairness and Other Human Values in Formal Models",
    "abstract": "Comments: Published in the proceedings of AIES 2021",
    "descriptor": "\nComments: Published in the proceedings of AIES 2021\n",
    "authors": [
      "Benjamin Fish",
      "Luke Stark"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2010.05084"
  },
  {
    "id": "arXiv:2010.07986",
    "title": "An Empowerment-based Solution to Robotic Manipulation Tasks with Sparse  Rewards",
    "abstract": "Comments: Accepted at RSS 2021",
    "descriptor": "\nComments: Accepted at RSS 2021\n",
    "authors": [
      "Siyu Dai",
      "Wei Xu",
      "Andreas Hofmann",
      "Brian Williams"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.07986"
  },
  {
    "id": "arXiv:2010.09543",
    "title": "Quaternionic Step Derivative: Machine Precision Differentiation of  Holomorphic Functions using Complex Quaternions",
    "abstract": "Comments: 22 pages, 6 figures",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Martin Roelfs",
      "David Dudal",
      "Daan Huybrechs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.09543"
  },
  {
    "id": "arXiv:2010.10811",
    "title": "STN4DST: A Scalable Dialogue State Tracking based on Slot Tagging  Navigation",
    "abstract": "STN4DST: A Scalable Dialogue State Tracking based on Slot Tagging  Navigation",
    "descriptor": "",
    "authors": [
      "Puhai Yang",
      "Heyan Huang",
      "Xianling Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.10811"
  },
  {
    "id": "arXiv:2010.12837",
    "title": "XDM: Improving Sequential Deep Matching with Unclicked User Behaviors  for Recommender System",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Fuyu Lv",
      "Mengxue Li",
      "Tonglei Guo",
      "Changlong Yu",
      "Fei Sun",
      "Taiwei Jin",
      "Hong Wen",
      "Guli Lin",
      "Keping Yang",
      "Wilfred Ng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2010.12837"
  },
  {
    "id": "arXiv:2010.12852",
    "title": "Beyond VQA: Generating Multi-word Answer and Rationale to Visual  Questions",
    "abstract": "Comments: MULA Workshop, CVPR 2021",
    "descriptor": "\nComments: MULA Workshop, CVPR 2021\n",
    "authors": [
      "Radhika Dua",
      "Sai Srinivas Kancheti",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.12852"
  },
  {
    "id": "arXiv:2011.01192",
    "title": "Budget Sharing for Multi-Analyst Differential Privacy",
    "abstract": "Comments: 13 pages, 5 figures. Proceedings of the VLDB Endowment (PVLDB) Vol. 14 No. 10. To be presented at the International Conference on Very Large Data Bases (VLDB) 2021",
    "descriptor": "\nComments: 13 pages, 5 figures. Proceedings of the VLDB Endowment (PVLDB) Vol. 14 No. 10. To be presented at the International Conference on Very Large Data Bases (VLDB) 2021\n",
    "authors": [
      "David Pujol",
      "Yikai Wu",
      "Brandon Fain",
      "Ashwin Machanavajjhala"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.01192"
  },
  {
    "id": "arXiv:2011.02094",
    "title": "A Survey on Contact Tracing: the Latest Advancements and Challenges",
    "abstract": "A Survey on Contact Tracing: the Latest Advancements and Challenges",
    "descriptor": "",
    "authors": [
      "Ting Jiang",
      "Yang Zhang",
      "Minhao Zhang",
      "Ting Yu",
      "Yizheng Chen",
      "Chenhao Lu",
      "Ji Zhang",
      "Zhao Li",
      "Jun Gao",
      "Shuigeng Zhou"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.02094"
  },
  {
    "id": "arXiv:2011.02591",
    "title": "Modified Vector Quantization for Small-Cell Access Point Placement with  Inter-Cell Interference",
    "abstract": "Modified Vector Quantization for Small-Cell Access Point Placement with  Inter-Cell Interference",
    "descriptor": "",
    "authors": [
      "Govind R. Gopal",
      "Elina Nayebi",
      "Gabriel Porto Villardi",
      "Bhaskar D. Rao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2011.02591"
  },
  {
    "id": "arXiv:2011.03279",
    "title": "\"What's This?\" -- Learning to Segment Unknown Objects from Manipulation  Sequences",
    "abstract": "Comments: 8 pages, 6 figures,in Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2021",
    "descriptor": "\nComments: 8 pages, 6 figures,in Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2021\n",
    "authors": [
      "Wout Boerdijk",
      "Martin Sundermeyer",
      "Maximilian Durner",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.03279"
  },
  {
    "id": "arXiv:2011.06818",
    "title": "A new iterative method for solving a class of two-by-two block complex  linear systems",
    "abstract": "Comments: 17 Pages, Revised, Submitted",
    "descriptor": "\nComments: 17 Pages, Revised, Submitted\n",
    "authors": [
      "Davod Khojasteh Salkuyeh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.06818"
  },
  {
    "id": "arXiv:2011.09233",
    "title": "Quantum Broadcast Channels with Cooperating Decoders: An  Information-Theoretic Perspective on Quantum Repeaters",
    "abstract": "Quantum Broadcast Channels with Cooperating Decoders: An  Information-Theoretic Perspective on Quantum Repeaters",
    "descriptor": "",
    "authors": [
      "Uzi Pereg",
      "Christian Deppe",
      "Holger Boche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2011.09233"
  },
  {
    "id": "arXiv:2011.09704",
    "title": "Causal Contextual Prediction for Learned Image Compression",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Zongyu Guo",
      "Zhizheng Zhang",
      "Runsen Feng",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2011.09704"
  },
  {
    "id": "arXiv:2011.13681",
    "title": "Point and Ask: Incorporating Pointing into Visual Question Answering",
    "abstract": "Point and Ask: Incorporating Pointing into Visual Question Answering",
    "descriptor": "",
    "authors": [
      "Arjun Mani",
      "Nobline Yoo",
      "Will Hinthorn",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.13681"
  },
  {
    "id": "arXiv:2011.13752",
    "title": "Adaptive Non-linear Pattern Matching Automata",
    "abstract": "Comments: 31 pages, submitted to FSCD 2020 special issue of LMCS",
    "descriptor": "\nComments: 31 pages, submitted to FSCD 2020 special issue of LMCS\n",
    "authors": [
      "Rick Erkens",
      "Maurice Laveaux"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2011.13752"
  },
  {
    "id": "arXiv:2011.14936",
    "title": "Rethinking and Designing a High-performing Automatic License Plate  Recognition Approach",
    "abstract": "Comments: 13 pages. Accepted for Publication at IEEE Transactions on Intelligent Transportation Systems",
    "descriptor": "\nComments: 13 pages. Accepted for Publication at IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Yi Wang",
      "Zhen-Peng Bian",
      "Yunhao Zhou",
      "Lap-Pui Chau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.14936"
  },
  {
    "id": "arXiv:2012.00096",
    "title": "Multi-Modal Detection of Alzheimer's Disease from Speech and Text",
    "abstract": "Comments: 9 pages, 3 figures, Accepted in BIOKDD 2021",
    "descriptor": "\nComments: 9 pages, 3 figures, Accepted in BIOKDD 2021\n",
    "authors": [
      "Amish Mittal",
      "Sourav Sahoo",
      "Arnhav Datar",
      "Juned Kadiwala",
      "Hrithwik Shalu",
      "Jimson Mathew"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.00096"
  },
  {
    "id": "arXiv:2012.00596",
    "title": "NPAS: A Compiler-aware Framework of Unified Network Pruning and  Architecture Search for Beyond Real-Time Mobile Acceleration",
    "abstract": "Comments: Accepted as an oral paper in the Conference on Computer Vision and Pattern Recognition (CVPR), 2021",
    "descriptor": "\nComments: Accepted as an oral paper in the Conference on Computer Vision and Pattern Recognition (CVPR), 2021\n",
    "authors": [
      "Zhengang Li",
      "Geng Yuan",
      "Wei Niu",
      "Pu Zhao",
      "Yanyu Li",
      "Yuxuan Cai",
      "Xuan Shen",
      "Zheng Zhan",
      "Zhenglun Kong",
      "Qing Jin",
      "Zhiyu Chen",
      "Sijia Liu",
      "Kaiyuan Yang",
      "Bin Ren",
      "Yanzhi Wang",
      "Xue Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2012.00596"
  },
  {
    "id": "arXiv:2012.01767",
    "title": "Robust label attribution for real-time bidding",
    "abstract": "Robust label attribution for real-time bidding",
    "descriptor": "",
    "authors": [
      "Martin Bompaire",
      "Antoine D\u00e9sir",
      "Benjamin Heymann"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2012.01767"
  },
  {
    "id": "arXiv:2012.06276",
    "title": "Dual Control for Exploitation and Exploration (DCEE) in Autonomous  Search",
    "abstract": "Comments: The shortened version of this paper has been accepted by Automatica",
    "descriptor": "\nComments: The shortened version of this paper has been accepted by Automatica\n",
    "authors": [
      "Wen-Hua Chen",
      "Callum Rhodes",
      "Cunjia Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.06276"
  },
  {
    "id": "arXiv:2012.08954",
    "title": "Shortest-support Multi-Spline Bases for Generalized Sampling",
    "abstract": "Shortest-support Multi-Spline Bases for Generalized Sampling",
    "descriptor": "",
    "authors": [
      "Alexis Goujon",
      "Shayan Aziznejad",
      "Alireza Naderi",
      "Michael Unser"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.08954"
  },
  {
    "id": "arXiv:2012.09439",
    "title": "FG-Net: Fast Large-Scale LiDAR Point Clouds Understanding Network  Leveraging Correlated Feature Mining and Geometric-Aware Modelling",
    "abstract": "FG-Net: Fast Large-Scale LiDAR Point Clouds Understanding Network  Leveraging Correlated Feature Mining and Geometric-Aware Modelling",
    "descriptor": "",
    "authors": [
      "Kangcheng Liu",
      "Zhi Gao",
      "Feng Lin",
      "Ben M. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.09439"
  },
  {
    "id": "arXiv:2012.11797",
    "title": "Time Series Domain Adaptation via Sparse Associative Structure Alignment",
    "abstract": "Time Series Domain Adaptation via Sparse Associative Structure Alignment",
    "descriptor": "",
    "authors": [
      "Ruichu Cai",
      "Jiawei Chen",
      "Zijian Li",
      "Wei Chen",
      "Keli Zhang",
      "Junjian Ye",
      "Zhuozhang Li",
      "Xiaoyan Yang",
      "Zhenjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.11797"
  },
  {
    "id": "arXiv:2012.12352",
    "title": "Seeing past words: Testing the cross-modal capabilities of pretrained  V&L models on counting tasks",
    "abstract": "Comments: Paper accepted for publication at MMSR 2021; 13 pages, 3 figures, 7 Tables",
    "descriptor": "\nComments: Paper accepted for publication at MMSR 2021; 13 pages, 3 figures, 7 Tables\n",
    "authors": [
      "Letitia Parcalabescu",
      "Albert Gatt",
      "Anette Frank",
      "Iacer Calixto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.12352"
  },
  {
    "id": "arXiv:2012.13229",
    "title": "A Space-Time DPG Method for the Heat Equation",
    "abstract": "A Space-Time DPG Method for the Heat Equation",
    "descriptor": "",
    "authors": [
      "Lars Diening",
      "Johannes Storn"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.13229"
  },
  {
    "id": "arXiv:2012.13623",
    "title": "Self-Supervised Multimodal Domino: in Search of Biomarkers for  Alzheimer's Disease",
    "abstract": "Self-Supervised Multimodal Domino: in Search of Biomarkers for  Alzheimer's Disease",
    "descriptor": "",
    "authors": [
      "Alex Fedorov",
      "Tristan Sylvain",
      "Eloy Geenjaar",
      "Margaux Luck",
      "Lei Wu",
      "Thomas P. DeRamus",
      "Alex Kirilin",
      "Dmitry Bleklov",
      "Vince D. Calhoun",
      "Sergey M. Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.13623"
  },
  {
    "id": "arXiv:2101.01385",
    "title": "Recurrent Neural Networks for Stochastic Control Problems with Delay",
    "abstract": "Recurrent Neural Networks for Stochastic Control Problems with Delay",
    "descriptor": "",
    "authors": [
      "Jiequn Han",
      "Ruimeng Hu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2101.01385"
  },
  {
    "id": "arXiv:2101.05404",
    "title": "Machine-learning enhanced dark soliton detection in Bose-Einstein  condensates",
    "abstract": "Comments: 17 pages, 5 figures",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Shangjie Guo",
      "Amilson R. Fritsch",
      "Craig Greenberg",
      "I. B. Spielman",
      "Justyna P. Zwolak"
    ],
    "subjectives": [
      "Quantum Gases (cond-mat.quant-gas)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2101.05404"
  },
  {
    "id": "arXiv:2101.05744",
    "title": "A comparative study of scoring systems by simulations",
    "abstract": "Comments: 14 pages, 4 figures, 5 tables",
    "descriptor": "\nComments: 14 pages, 4 figures, 5 tables\n",
    "authors": [
      "L\u00e1szl\u00f3 Csat\u00f3"
    ],
    "subjectives": [
      "Other Statistics (stat.OT)",
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2101.05744"
  },
  {
    "id": "arXiv:2101.07608",
    "title": "Game values of arithmetic functions",
    "abstract": "Comments: 20 pages, 4 figures",
    "descriptor": "\nComments: 20 pages, 4 figures\n",
    "authors": [
      "Douglas E. Iannucci",
      "Urban Larsson"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2101.07608"
  },
  {
    "id": "arXiv:2101.09571",
    "title": "BF++: a language for general-purpose program synthesis",
    "abstract": "Comments: 8+2 pages (paper+references)",
    "descriptor": "\nComments: 8+2 pages (paper+references)\n",
    "authors": [
      "Vadim Liventsev",
      "Aki H\u00e4rm\u00e4",
      "Milan Petkovi\u0107"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2101.09571"
  },
  {
    "id": "arXiv:2101.10533",
    "title": "Numerical aspects of shot noise representation of infinitely divisible  laws and related processes",
    "abstract": "Comments: 37 pages, 8 figures",
    "descriptor": "\nComments: 37 pages, 8 figures\n",
    "authors": [
      "Sida Yuan",
      "Reiichiro Kawai"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.10533"
  },
  {
    "id": "arXiv:2102.01567",
    "title": "A Lyapunov Theory for Finite-Sample Guarantees of Asynchronous  Q-Learning and TD-Learning Variants",
    "abstract": "A Lyapunov Theory for Finite-Sample Guarantees of Asynchronous  Q-Learning and TD-Learning Variants",
    "descriptor": "",
    "authors": [
      "Zaiwei Chen",
      "Siva Theja Maguluri",
      "Sanjay Shakkottai",
      "Karthikeyan Shanmugam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.01567"
  },
  {
    "id": "arXiv:2102.03456",
    "title": "BinaryCoP: Binary Neural Network-based COVID-19 Face-Mask Wear and  Positioning Predictor on Edge Devices",
    "abstract": "Comments: Accepted at IEEE IPDPS-RAW 2021",
    "descriptor": "\nComments: Accepted at IEEE IPDPS-RAW 2021\n",
    "authors": [
      "Nael Fasfous",
      "Manoj-Rohit Vemparala",
      "Alexander Frickenstein",
      "Lukas Frickenstein",
      "Walter Stechele"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.03456"
  },
  {
    "id": "arXiv:2102.07181",
    "title": "Distribution Free Uncertainty for the Minimum Norm Solution of  Over-parameterized Linear Regression",
    "abstract": "Distribution Free Uncertainty for the Minimum Norm Solution of  Over-parameterized Linear Regression",
    "descriptor": "",
    "authors": [
      "Koby Bibas",
      "Meir Feder"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.07181"
  },
  {
    "id": "arXiv:2102.09559",
    "title": "CReST: A Class-Rebalancing Self-Training Framework for Imbalanced  Semi-Supervised Learning",
    "abstract": "Comments: To appear in CVPR 2021. Code release: this https URL",
    "descriptor": "\nComments: To appear in CVPR 2021. Code release: this https URL\n",
    "authors": [
      "Chen Wei",
      "Kihyuk Sohn",
      "Clayton Mellina",
      "Alan Yuille",
      "Fan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.09559"
  },
  {
    "id": "arXiv:2102.09756",
    "title": "TacticZero: Learning to Prove Theorems from Scratch with Deep  Reinforcement Learning",
    "abstract": "TacticZero: Learning to Prove Theorems from Scratch with Deep  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Minchao Wu",
      "Michael Norrish",
      "Christian Walder",
      "Amir Dezfouli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.09756"
  },
  {
    "id": "arXiv:2102.12470",
    "title": "On the Validity of Modeling SGD with Stochastic Differential Equations  (SDEs)",
    "abstract": "Comments: 36 pages, 20 figures",
    "descriptor": "\nComments: 36 pages, 20 figures\n",
    "authors": [
      "Zhiyuan Li",
      "Sadhika Malladi",
      "Sanjeev Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.12470"
  },
  {
    "id": "arXiv:2102.12718",
    "title": "A Simulation-based End-to-End Learning Framework for Evidential  Occupancy Grid Mapping",
    "abstract": "Comments: Accepted to be published as part of the 2021 IEEE Intelligent Vehicles Symposium (IV), Nagoya, Japan, July 11-15, 2021",
    "descriptor": "\nComments: Accepted to be published as part of the 2021 IEEE Intelligent Vehicles Symposium (IV), Nagoya, Japan, July 11-15, 2021\n",
    "authors": [
      "Raphael van Kempen",
      "Bastian Lampe",
      "Timo Woopen",
      "Lutz Eckstein"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2102.12718"
  },
  {
    "id": "arXiv:2102.13186",
    "title": "Towards a Unified Framework for Fair and Stable Graph Representation  Learning",
    "abstract": "Comments: Accepted to UAI'21",
    "descriptor": "\nComments: Accepted to UAI'21\n",
    "authors": [
      "Chirag Agarwal",
      "Himabindu Lakkaraju",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.13186"
  },
  {
    "id": "arXiv:2103.00668",
    "title": "Learning Proposals for Probabilistic Programs with Inference Combinators",
    "abstract": "Comments: Accepted to UAI 2021",
    "descriptor": "\nComments: Accepted to UAI 2021\n",
    "authors": [
      "Sam Stites",
      "Heiko Zimmermann",
      "Hao Wu",
      "Eli Sennesh",
      "Jan-Willem van de Meent"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2103.00668"
  },
  {
    "id": "arXiv:2103.01886",
    "title": "Data-driven control of room temperature and bidirectional EV charging  using deep reinforcement learning: simulations and experiments",
    "abstract": "Comments: 20 pages, 17 figures, 3 tables",
    "descriptor": "\nComments: 20 pages, 17 figures, 3 tables\n",
    "authors": [
      "B. Svetozarevic",
      "C.Baumann",
      "S. Muntwiler",
      "L. Di Natale",
      "M. Zeilinger",
      "P. Heer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.01886"
  },
  {
    "id": "arXiv:2103.03918",
    "title": "FedV: Privacy-Preserving Federated Learning over Vertically Partitioned  Data",
    "abstract": "FedV: Privacy-Preserving Federated Learning over Vertically Partitioned  Data",
    "descriptor": "",
    "authors": [
      "Runhua Xu",
      "Nathalie Baracaldo",
      "Yi Zhou",
      "Ali Anwar",
      "James Joshi",
      "Heiko Ludwig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2103.03918"
  },
  {
    "id": "arXiv:2103.06253",
    "title": "FiLiPo: A Sample Driven Approach for Finding Linkage Points between RDF  Data and APIs (Extended Version)",
    "abstract": "FiLiPo: A Sample Driven Approach for Finding Linkage Points between RDF  Data and APIs (Extended Version)",
    "descriptor": "",
    "authors": [
      "Tobias Zeimetz",
      "Ralf Schenkel"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2103.06253"
  },
  {
    "id": "arXiv:2103.07176",
    "title": "Visualising Deep Network's Time-Series Representations",
    "abstract": "Comments: Accepted to Neural Computing and Applications",
    "descriptor": "\nComments: Accepted to Neural Computing and Applications\n",
    "authors": [
      "B\u0142a\u017cej Leporowski",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.07176"
  },
  {
    "id": "arXiv:2103.07445",
    "title": "Efficient reconstruction of depth three circuits with top fan-in two",
    "abstract": "Comments: 45 pages",
    "descriptor": "\nComments: 45 pages\n",
    "authors": [
      "Gaurav Sinha"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.07445"
  },
  {
    "id": "arXiv:2103.08160",
    "title": "DMN4: Few-shot Learning via Discriminative Mutual Nearest Neighbor  Neural Network",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Yang Liu",
      "Tu Zheng",
      "Jie Song",
      "Deng Cai",
      "Xiaofei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.08160"
  },
  {
    "id": "arXiv:2103.09148",
    "title": "DiCOVA Challenge: Dataset, task, and baseline system for COVID-19  diagnosis using acoustics",
    "abstract": "Comments: To appear in Proceedings of Interspeech, 2021",
    "descriptor": "\nComments: To appear in Proceedings of Interspeech, 2021\n",
    "authors": [
      "Ananya Muguli",
      "Lancelot Pinto",
      "Nirmala R.",
      "Neeraj Sharma",
      "Prashant Krishnan",
      "Prasanta Kumar Ghosh",
      "Rohit Kumar",
      "Shrirama Bhat",
      "Srikanth Raj Chetupalli",
      "Sriram Ganapathy",
      "Shreyas Ramoji",
      "Viral Nanda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2103.09148"
  },
  {
    "id": "arXiv:2103.09159",
    "title": "Learning to Shape Rewards using a Game of Switching Controls",
    "abstract": "Learning to Shape Rewards using a Game of Switching Controls",
    "descriptor": "",
    "authors": [
      "David Mguni",
      "Jianhong Wang",
      "Taher Jafferjee",
      "Nicolas Perez-Nieves",
      "Wenbin Song",
      "Yaodong Yang",
      "Feifei Tong",
      "Hui Chen",
      "Jiangcheng Zhu",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2103.09159"
  },
  {
    "id": "arXiv:2103.10391",
    "title": "Learning to Recommend Frame for Interactive Video Object Segmentation in  the Wild",
    "abstract": "Comments: To appear in CVPR 2021. Minor revision",
    "descriptor": "\nComments: To appear in CVPR 2021. Minor revision\n",
    "authors": [
      "Zhaoyuan Yin",
      "Jia Zheng",
      "Weixin Luo",
      "Shenhan Qian",
      "Hanling Zhang",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.10391"
  },
  {
    "id": "arXiv:2103.15850",
    "title": "An upper bound on the size of Sidon sets",
    "abstract": "Comments: Minor edits from previous version",
    "descriptor": "\nComments: Minor edits from previous version\n",
    "authors": [
      "J\u00f3zsef Balogh",
      "Zolt\u00e1n F\u00fcredi",
      "Souktik Roy"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2103.15850"
  },
  {
    "id": "arXiv:2103.17020",
    "title": "Semantic-guided Automatic Natural Image Matting with Light-weight  Non-local Attention",
    "abstract": "Semantic-guided Automatic Natural Image Matting with Light-weight  Non-local Attention",
    "descriptor": "",
    "authors": [
      "Yuhongze Zhou",
      "Liguang Zhou",
      "Tin Lun Lam",
      "Yangsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.17020"
  },
  {
    "id": "arXiv:2104.00296",
    "title": "Securing Smart Homes via Software-Defined Networking and Low-Cost  Traffic Classification",
    "abstract": "Securing Smart Homes via Software-Defined Networking and Low-Cost  Traffic Classification",
    "descriptor": "",
    "authors": [
      "Holden Gordon",
      "Christopher Batula",
      "Bhagyashri Tushir",
      "Behnam Dezfouli",
      "Yuhong Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.00296"
  },
  {
    "id": "arXiv:2104.00563",
    "title": "Autobots: Latent Variable Sequential Set Transformers",
    "abstract": "Comments: 21 pages, 15 figures, 5 tables",
    "descriptor": "\nComments: 21 pages, 15 figures, 5 tables\n",
    "authors": [
      "Roger Girgis",
      "Florian Golemo",
      "Felipe Codevilla",
      "Jim Aldon D'Souza",
      "Martin Weiss",
      "Samira Ebrahimi Kahou",
      "Felix Heide",
      "Christopher Pal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2104.00563"
  },
  {
    "id": "arXiv:2104.01989",
    "title": "Dr-Vectors: Decision Residual Networks and an Improved Loss for Speaker  Recognition",
    "abstract": "Comments: To appear in Interspeech 2021",
    "descriptor": "\nComments: To appear in Interspeech 2021\n",
    "authors": [
      "Jason Pelecanos",
      "Quan Wang",
      "Ignacio Lopez Moreno"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.01989"
  },
  {
    "id": "arXiv:2104.02321",
    "title": "NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling",
    "abstract": "Comments: Accepted to Interspeech 2021",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Junhyeok Lee",
      "Seungu Han"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.02321"
  },
  {
    "id": "arXiv:2104.02897",
    "title": "Intelligent Reflecting Surface Assisted Terahertz Communications toward  6G",
    "abstract": "Intelligent Reflecting Surface Assisted Terahertz Communications toward  6G",
    "descriptor": "",
    "authors": [
      "Zhi Chen",
      "Chong Han",
      "Boyu Ning",
      "Zhongbao Tian",
      "Shaoqiana Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.02897"
  },
  {
    "id": "arXiv:2104.03416",
    "title": "Pushing the Limits of Non-Autoregressive Speech Recognition",
    "abstract": "Comments: Accepted to Interspeech 2021",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Edwin G. Ng",
      "Chung-Cheng Chiu",
      "Yu Zhang",
      "William Chan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2104.03416"
  },
  {
    "id": "arXiv:2104.05544",
    "title": "Investigating Methods to Improve Language Model Integration for  Attention-based Encoder-Decoder ASR Models",
    "abstract": "Comments: accepted to Interspeech 2021",
    "descriptor": "\nComments: accepted to Interspeech 2021\n",
    "authors": [
      "Mohammad Zeineldeen",
      "Aleksandr Glushko",
      "Wilfried Michel",
      "Albert Zeyer",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.05544"
  },
  {
    "id": "arXiv:2104.05654",
    "title": "Dynamic Matching Markets in Power Grid: Concepts and Solution using Deep  Reinforcement Learning",
    "abstract": "Dynamic Matching Markets in Power Grid: Concepts and Solution using Deep  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Majid Majidi",
      "Deepan Muthirayan",
      "Masood Parvania",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.05654"
  },
  {
    "id": "arXiv:2104.10414",
    "title": "Orderly Dual-Teacher Knowledge Distillation for Lightweight Human Pose  Estimation",
    "abstract": "Orderly Dual-Teacher Knowledge Distillation for Lightweight Human Pose  Estimation",
    "descriptor": "",
    "authors": [
      "Zhong-Qiu Zhao",
      "Yao Gao",
      "Yuchen Ge",
      "Weidong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.10414"
  },
  {
    "id": "arXiv:2104.10507",
    "title": "On Sampling-Based Training Criteria for Neural Language Modeling",
    "abstract": "Comments: Accepted at INTERSPEECH 2021",
    "descriptor": "\nComments: Accepted at INTERSPEECH 2021\n",
    "authors": [
      "Yingbo Gao",
      "David Thulke",
      "Alexander Gerstenberger",
      "Khoa Viet Tran",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.10507"
  },
  {
    "id": "arXiv:2104.11051",
    "title": "Protecting gender and identity with disentangled speech representations",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Dimitrios Stoidis",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.11051"
  },
  {
    "id": "arXiv:2105.00949",
    "title": "CMA-Net: A Cascaded Mutual Attention Network for Light Field Salient  Object Detection",
    "abstract": "Comments: 6 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 6 pages, 4 figures, 2 tables\n",
    "authors": [
      "Yi Zhang",
      "Lu Zhang",
      "Wassim Hamidouche",
      "Olivier Deforges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.00949"
  },
  {
    "id": "arXiv:2105.03818",
    "title": "Heterogeneous Risk Minimization",
    "abstract": "Comments: Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021. (ICML2021)",
    "descriptor": "\nComments: Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021. (ICML2021)\n",
    "authors": [
      "Jiashuo Liu",
      "Zheyuan Hu",
      "Peng Cui",
      "Bo Li",
      "Zheyan Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03818"
  },
  {
    "id": "arXiv:2105.04459",
    "title": "ICON: Learning Regular Maps Through Inverse Consistency",
    "abstract": "ICON: Learning Regular Maps Through Inverse Consistency",
    "descriptor": "",
    "authors": [
      "Hastings Greer",
      "Roland Kwitt",
      "Francois-Xavier Vialard",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04459"
  },
  {
    "id": "arXiv:2105.04551",
    "title": "Stochastic Image-to-Video Synthesis using cINNs",
    "abstract": "Comments: Accepted to CVPR 2021",
    "descriptor": "\nComments: Accepted to CVPR 2021\n",
    "authors": [
      "Michael Dorkenwald",
      "Timo Milbich",
      "Andreas Blattmann",
      "Robin Rombach",
      "Konstantinos G. Derpanis",
      "Bj\u00f6rn Ommer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04551"
  },
  {
    "id": "arXiv:2105.04834",
    "title": "Improving Adversarial Transferability with Gradient Refining",
    "abstract": "Improving Adversarial Transferability with Gradient Refining",
    "descriptor": "",
    "authors": [
      "Guoqiu Wang",
      "Huanqian Yan",
      "Ying Guo",
      "Xingxing Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04834"
  },
  {
    "id": "arXiv:2105.07071",
    "title": "Listen with Intent: Improving Speech Recognition with Audio-to-Intent  Front-End",
    "abstract": "Comments: To appear in Interspeech 2021",
    "descriptor": "\nComments: To appear in Interspeech 2021\n",
    "authors": [
      "Swayambhu Nath Ray",
      "Minhua Wu",
      "Anirudh Raju",
      "Pegah Ghahremani",
      "Raghavendra Bilgi",
      "Milind Rao",
      "Harish Arsikere",
      "Ariya Rastrow",
      "Andreas Stolcke",
      "Jasha Droppo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.07071"
  },
  {
    "id": "arXiv:2105.07921",
    "title": "BigEarthNet-MM: A Large Scale Multi-Modal Multi-Label Benchmark Archive  for Remote Sensing Image Classification and Retrieval",
    "abstract": "Comments: Accepted at the IEEE Geoscience and Remote Sensing Magazine. Our code is available online at this https URL arXiv admin note: substantial text overlap with arXiv:2001.06372",
    "descriptor": "\nComments: Accepted at the IEEE Geoscience and Remote Sensing Magazine. Our code is available online at this https URL arXiv admin note: substantial text overlap with arXiv:2001.06372\n",
    "authors": [
      "Gencer Sumbul",
      "Arne de Wall",
      "Tristan Kreuziger",
      "Filipe Marcelino",
      "Hugo Costa",
      "Pedro Benevides",
      "M\u00e1rio Caetano",
      "Beg\u00fcm Demir",
      "Volker Markl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07921"
  },
  {
    "id": "arXiv:2105.08291",
    "title": "Independent Asymmetric Embedding for Cascade Prediction on Social  Networks",
    "abstract": "Independent Asymmetric Embedding for Cascade Prediction on Social  Networks",
    "descriptor": "",
    "authors": [
      "Wenjin Xie",
      "Xiaomeng Wang",
      "Tao Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.08291"
  },
  {
    "id": "arXiv:2105.10360",
    "title": "BELT: Block-wise Missing Embedding Learning Transformer",
    "abstract": "BELT: Block-wise Missing Embedding Learning Transformer",
    "descriptor": "",
    "authors": [
      "Doudou Zhou",
      "Tianxi Cai",
      "Junwei Lu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.10360"
  },
  {
    "id": "arXiv:2105.11726",
    "title": "There is no data like more data -- current status of machine learning  datasets in remote sensing",
    "abstract": "Comments: accepted for the Proceedings of IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2021",
    "descriptor": "\nComments: accepted for the Proceedings of IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2021\n",
    "authors": [
      "Michael Schmitt",
      "Seyed Ali Ahmadi",
      "Ronny H\u00e4nsch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.11726"
  },
  {
    "id": "arXiv:2105.11763",
    "title": "Efficiently Explaining CSPs with Unsatisfiable Subset Optimization",
    "abstract": "Efficiently Explaining CSPs with Unsatisfiable Subset Optimization",
    "descriptor": "",
    "authors": [
      "Emilio Gamba",
      "Bart Bogaerts",
      "Tias Guns"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.11763"
  },
  {
    "id": "arXiv:2105.11827",
    "title": "Narwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus",
    "abstract": "Narwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus",
    "descriptor": "",
    "authors": [
      "George Danezis",
      "Eleftherios Kokoris Kogias",
      "Alberto Sonnino",
      "Alexander Spiegelman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.11827"
  },
  {
    "id": "arXiv:2105.12972",
    "title": "Tight Lower Bounds for $\u03b1$-Divergences Under Moment Constraints and  Relations Between Different $\u03b1$",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Tomohiro Nishiyama"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.12972"
  },
  {
    "id": "arXiv:2105.13863",
    "title": "On plane algebraic curves passing through $n$-independent nodes",
    "abstract": "Comments: 22 pages. arXiv admin note: substantial text overlap with arXiv:1903.10874",
    "descriptor": "\nComments: 22 pages. arXiv admin note: substantial text overlap with arXiv:1903.10874\n",
    "authors": [
      "Hakop Hakopian",
      "Harutyun Kloyan",
      "Davit Voskanyan"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13863"
  },
  {
    "id": "arXiv:2105.14092",
    "title": "Deep Memory Update",
    "abstract": "Deep Memory Update",
    "descriptor": "",
    "authors": [
      "\u0141ukasz Neumann",
      "Pawe\u0142 Wawrzy\u0144ski"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.14092"
  },
  {
    "id": "arXiv:2105.14457",
    "title": "Learning Personal Style from Few Examples",
    "abstract": "Learning Personal Style from Few Examples",
    "descriptor": "",
    "authors": [
      "David Chuan-En Lin",
      "Nikolas Martelaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14457"
  },
  {
    "id": "arXiv:2106.00243",
    "title": "Comprehensive Energy Footprint Benchmarking of Strong Parallel  Electrified Powertrain",
    "abstract": "Comments: Fixed typos, added discussion",
    "descriptor": "\nComments: Fixed typos, added discussion\n",
    "authors": [
      "Aashrith Vishwanath",
      "Hamza Anwar",
      "Apurva Chunodkar",
      "Qadeer Ahmed"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00243"
  },
  {
    "id": "arXiv:2106.00248",
    "title": "Volta at SemEval-2021 Task 9: Statement Verification and Evidence  Finding with Tables using TAPAS and Transfer Learning",
    "abstract": "Comments: 9 pages, accepted at SemEval-2021 co-located with ACL-IJCNLP 2021",
    "descriptor": "\nComments: 9 pages, accepted at SemEval-2021 co-located with ACL-IJCNLP 2021\n",
    "authors": [
      "Devansh Gautam",
      "Kshitij Gupta",
      "Manish Shrivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00248"
  },
  {
    "id": "arXiv:2106.01072",
    "title": "Evidence-based Factual Error Correction",
    "abstract": "Comments: Uploaded as a new paper in error. Please see the replacement of arxiv paper 2012.15788v2 for this version: arXiv:2012.15788",
    "descriptor": "\nComments: Uploaded as a new paper in error. Please see the replacement of arxiv paper 2012.15788v2 for this version: arXiv:2012.15788\n",
    "authors": [
      "James Thorne",
      "Andreas Vlachos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01072"
  },
  {
    "id": "arXiv:2106.02081",
    "title": "Solving Schr\u00f6dinger Bridges via Maximum Likelihood",
    "abstract": "Comments: 9 pages + appendix (total 28 pages)",
    "descriptor": "\nComments: 9 pages + appendix (total 28 pages)\n",
    "authors": [
      "Francisco Vargas",
      "Pierre Thodoroff",
      "Neil D. Lawrence",
      "Austen Lamacraft"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02081"
  },
  {
    "id": "arXiv:2106.02116",
    "title": "Rotor Thermal Monitoring Scheme for Direct-Torque-Controlled Interior  Permanent Magnet Synchronous Machines via High-Frequency Rotating Flux or  Torque Injection",
    "abstract": "Rotor Thermal Monitoring Scheme for Direct-Torque-Controlled Interior  Permanent Magnet Synchronous Machines via High-Frequency Rotating Flux or  Torque Injection",
    "descriptor": "",
    "authors": [
      "Shen Zhang",
      "Sufei Li",
      "Lijun He",
      "Jose A. Restrepo",
      "Thomas G. Habetler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02116"
  },
  {
    "id": "arXiv:2106.02129",
    "title": "The Algorithmic Phase Transition of Random $k$-SAT for Low Degree  Polynomials",
    "abstract": "Comments: 44 pages, added references",
    "descriptor": "\nComments: 44 pages, added references\n",
    "authors": [
      "Guy Bresler",
      "Brice Huang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02129"
  },
  {
    "id": "arXiv:2106.02283",
    "title": "Privacy Preference Signals: Past, Present and Future",
    "abstract": "Comments: To appear in Proceedings on Privacy Enhancing Technologies (PETS) 2021 Issue 4",
    "descriptor": "\nComments: To appear in Proceedings on Privacy Enhancing Technologies (PETS) 2021 Issue 4\n",
    "authors": [
      "Maximilian Hils",
      "Daniel W. Woods",
      "Rainer B\u00f6hme"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.02283"
  },
  {
    "id": "arXiv:2106.02469",
    "title": "Can convolutional ResNets approximately preserve input distances? A  frequency analysis perspective",
    "abstract": "Comments: Main paper 10 pages including references, appendix 10 pages. 7 figures and 6 tables including appendix",
    "descriptor": "\nComments: Main paper 10 pages including references, appendix 10 pages. 7 figures and 6 tables including appendix\n",
    "authors": [
      "Lewis Smith",
      "Joost van Amersfoort",
      "Haiwen Huang",
      "Stephen Roberts",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02469"
  },
  {
    "id": "arXiv:2106.02569",
    "title": "Neural semi-Markov CRF for Monolingual Word Alignment",
    "abstract": "Comments: Accepted to ACL 2021",
    "descriptor": "\nComments: Accepted to ACL 2021\n",
    "authors": [
      "Wuwei Lan",
      "Chao Jiang",
      "Wei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02569"
  },
  {
    "id": "arXiv:2106.02835",
    "title": "On the Role of Entropy-based Loss for Learning Causal Structures with  Continuous Optimization",
    "abstract": "On the Role of Entropy-based Loss for Learning Causal Structures with  Continuous Optimization",
    "descriptor": "",
    "authors": [
      "Ruichu Cai",
      "Weilin Chen",
      "Jie Qiao",
      "Zhifeng Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02835"
  },
  {
    "id": "arXiv:2106.02875",
    "title": "Integrating Expert ODEs into Neural ODEs: Pharmacology and Disease  Progression",
    "abstract": "Integrating Expert ODEs into Neural ODEs: Pharmacology and Disease  Progression",
    "descriptor": "",
    "authors": [
      "Zhaozhi Qian",
      "William R. Zame",
      "Lucas M. Fleuren",
      "Paul Elbers",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02875"
  },
  {
    "id": "arXiv:2106.03611",
    "title": "Inferring Objectives in Continuous Dynamic Games from Noise-Corrupted  Partial State Observations",
    "abstract": "Comments: Submitted to RSS2021",
    "descriptor": "\nComments: Submitted to RSS2021\n",
    "authors": [
      "Lasse Peters",
      "David Fridovich-Keil",
      "Vicen\u00e7 Rubies-Royo",
      "Claire J. Tomlin",
      "Cyrill Stachniss"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.03611"
  },
  {
    "id": "arXiv:2106.03658",
    "title": "Reduction Using Induced Subnets To Systematically Prove Properties For  Free-Choice Nets",
    "abstract": "Comments: Keywords: Petri Nets, Free-Choice Nets, Net Reduction, Lucency",
    "descriptor": "\nComments: Keywords: Petri Nets, Free-Choice Nets, Net Reduction, Lucency\n",
    "authors": [
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.03658"
  },
  {
    "id": "arXiv:2106.04156",
    "title": "Provable Guarantees for Self-Supervised Deep Learning with Spectral  Contrastive Loss",
    "abstract": "Provable Guarantees for Self-Supervised Deep Learning with Spectral  Contrastive Loss",
    "descriptor": "",
    "authors": [
      "Jeff Z. HaoChen",
      "Colin Wei",
      "Adrien Gaidon",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04156"
  },
  {
    "id": "arXiv:2106.04800",
    "title": "Diffusion Source Identification on Networks with Statistical Confidence",
    "abstract": "Diffusion Source Identification on Networks with Statistical Confidence",
    "descriptor": "",
    "authors": [
      "Quinlan Dawkins",
      "Tianxi Li",
      "Haifeng Xu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04800"
  },
  {
    "id": "arXiv:2106.05234",
    "title": "Do Transformers Really Perform Bad for Graph Representation?",
    "abstract": "Do Transformers Really Perform Bad for Graph Representation?",
    "descriptor": "",
    "authors": [
      "Chengxuan Ying",
      "Tianle Cai",
      "Shengjie Luo",
      "Shuxin Zheng",
      "Guolin Ke",
      "Di He",
      "Yanming Shen",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05234"
  },
  {
    "id": "arXiv:2106.05365",
    "title": "DESCGEN: A Distantly Supervised Dataset for Generating Abstractive  Entity Descriptions",
    "abstract": "DESCGEN: A Distantly Supervised Dataset for Generating Abstractive  Entity Descriptions",
    "descriptor": "",
    "authors": [
      "Weijia Shi",
      "Mandar Joshi",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05365"
  },
  {
    "id": "arXiv:2106.05468",
    "title": "Multi-VFL: A Vertical Federated Learning System for Multiple Data and  Label Owners",
    "abstract": "Multi-VFL: A Vertical Federated Learning System for Multiple Data and  Label Owners",
    "descriptor": "",
    "authors": [
      "Vaikkunth Mugunthan",
      "Pawan Goyal",
      "Lalana Kagal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05468"
  },
  {
    "id": "arXiv:2106.05482",
    "title": "Deep Position-wise Interaction Network for CTR Prediction",
    "abstract": "Comments: Accepted by SIGIR 2021",
    "descriptor": "\nComments: Accepted by SIGIR 2021\n",
    "authors": [
      "Jianqiang Huang",
      "Ke Hu",
      "Qingtao Tang",
      "Mingjian Chen",
      "Yi Qi",
      "Jia Cheng",
      "Jun Lei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.05482"
  },
  {
    "id": "arXiv:2106.05580",
    "title": "AGGGEN: Ordering and Aggregating while Generating",
    "abstract": "Comments: Correct the first citation in the Zero-shot Few-shot scenarios paragraph in Section 7",
    "descriptor": "\nComments: Correct the first citation in the Zero-shot Few-shot scenarios paragraph in Section 7\n",
    "authors": [
      "Xinnuo Xu",
      "Ond\u0159ej Du\u0161ek",
      "Verena Rieser",
      "Ioannis Konstas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.05580"
  },
  {
    "id": "arXiv:2106.06098",
    "title": "Meta-Adaptive Nonlinear Control: Theory and Algorithms",
    "abstract": "Meta-Adaptive Nonlinear Control: Theory and Algorithms",
    "descriptor": "",
    "authors": [
      "Guanya Shi",
      "Kamyar Azizzadenesheli",
      "Soon-Jo Chung",
      "Yisong Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06098"
  },
  {
    "id": "arXiv:2106.06525",
    "title": "ExtendedHyperLogLog: Analysis of a new Cardinality Estimator",
    "abstract": "ExtendedHyperLogLog: Analysis of a new Cardinality Estimator",
    "descriptor": "",
    "authors": [
      "Tal Ohayon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.06525"
  },
  {
    "id": "arXiv:2106.06721",
    "title": "A use case of Content Delivery Network raw logfile analysis",
    "abstract": "A use case of Content Delivery Network raw logfile analysis",
    "descriptor": "",
    "authors": [
      "Hoang-Loc La",
      "Anh-Tu Ngoc Tran",
      "Quang-Trai Le",
      "Masato Yoshimi",
      "Takuma Nakajima",
      "Nam Thoai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.06721"
  },
  {
    "id": "arXiv:2106.06804",
    "title": "Entropy-based Logic Explanations of Neural Networks",
    "abstract": "Entropy-based Logic Explanations of Neural Networks",
    "descriptor": "",
    "authors": [
      "Pietro Barbiero",
      "Gabriele Ciravegna",
      "Francesco Giannini",
      "Pietro Li\u00f3",
      "Marco Gori",
      "Stefano Melacci"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.06804"
  },
  {
    "id": "arXiv:2106.06848",
    "title": "Fixed-Confidence Best Arm Identification in Multi-Armed Bandits: Simple  Sequential Elimination Algorithms",
    "abstract": "Fixed-Confidence Best Arm Identification in Multi-Armed Bandits: Simple  Sequential Elimination Algorithms",
    "descriptor": "",
    "authors": [
      "MohammadJavad Azizi",
      "Sheldon M Ross",
      "Zhengyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06848"
  },
  {
    "id": "arXiv:2106.06885",
    "title": "Online Learning with Optimism and Delay",
    "abstract": "Comments: ICML 2021. 9 pages of main paper and 26 pages of appendix text",
    "descriptor": "\nComments: ICML 2021. 9 pages of main paper and 26 pages of appendix text\n",
    "authors": [
      "Genevieve Flaspohler",
      "Francesco Orabona",
      "Judah Cohen",
      "Soukayna Mouatadid",
      "Miruna Oprescu",
      "Paulo Orenstein",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06885"
  },
  {
    "id": "arXiv:2106.07115",
    "title": "Latent Correlation-Based Multiview Learning and Self-Supervision: A  Unifying Perspective",
    "abstract": "Comments: fixed some typos in the proofs",
    "descriptor": "\nComments: fixed some typos in the proofs\n",
    "authors": [
      "Qi Lyu",
      "Xiao Fu",
      "Weiran Wang",
      "Songtao Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07115"
  },
  {
    "id": "arXiv:2106.07263",
    "title": "Machine Learning for Variance Reduction in Online Experiments",
    "abstract": "Machine Learning for Variance Reduction in Online Experiments",
    "descriptor": "",
    "authors": [
      "Yongyi Guo",
      "Dominic Coey",
      "Mikael Konutgan",
      "Wenting Li",
      "Chris Schoener",
      "Matt Goldman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07263"
  },
  {
    "id": "arXiv:2106.07380",
    "title": "Predicting the Popularity of Reddit Posts with AI",
    "abstract": "Comments: 5 pages, 3 figures",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Juno Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.07380"
  },
  {
    "id": "arXiv:2106.07476",
    "title": "Training Graph Neural Networks with 1000 Layers",
    "abstract": "Comments: Accepted at ICML'2021. Code available at this https URL Work done during Guohao Li's internship at Intel Intelligent Systems Lab",
    "descriptor": "\nComments: Accepted at ICML'2021. Code available at this https URL Work done during Guohao Li's internship at Intel Intelligent Systems Lab\n",
    "authors": [
      "Guohao Li",
      "Matthias M\u00fcller",
      "Bernard Ghanem",
      "Vladlen Koltun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.07476"
  },
  {
    "id": "arXiv:2106.07929",
    "title": "Image Feature Information Extraction for Interest Point Detection: A  Comprehensive Review",
    "abstract": "Image Feature Information Extraction for Interest Point Detection: A  Comprehensive Review",
    "descriptor": "",
    "authors": [
      "Junfeng Jing",
      "Tian Gao",
      "Weichuan Zhang",
      "Yongsheng Gao",
      "Changming Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07929"
  },
  {
    "id": "arXiv:2106.07954",
    "title": "CatBoost model with synthetic features in application to loan risk  assessment of small businesses",
    "abstract": "CatBoost model with synthetic features in application to loan risk  assessment of small businesses",
    "descriptor": "",
    "authors": [
      "Liexin Cheng",
      "Haoxue Wang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07954"
  },
  {
    "id": "arXiv:2106.08008",
    "title": "Towards Long-term Non-invasive Monitoring for Epilepsy via Wearable EEG  Devices",
    "abstract": "Comments: 4 pages, 3 figures, 2 tables, preprint",
    "descriptor": "\nComments: 4 pages, 3 figures, 2 tables, preprint\n",
    "authors": [
      "Thorir Mar Ingolfsson",
      "Andrea Cossettini",
      "Xiaying Wang",
      "Enrico Tabanelli",
      "Giuseppe Tagliavini",
      "Philippe Ryvlin",
      "Luca Benini",
      "Simone Benatti"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08008"
  },
  {
    "id": "arXiv:2106.08153",
    "title": "Now You See It, Now You Dont: Adversarial Vulnerabilities in  Computational Pathology",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Alex Foote",
      "Amina Asif",
      "Ayesha Azam",
      "Tim Marshall-Cox",
      "Nasir Rajpoot",
      "Fayyaz Minhas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08153"
  },
  {
    "id": "arXiv:2106.08166",
    "title": "Query Embedding on Hyper-relational Knowledge Graphs",
    "abstract": "Query Embedding on Hyper-relational Knowledge Graphs",
    "descriptor": "",
    "authors": [
      "Dimitrios Alivanistos",
      "Max Berrendorf",
      "Michael Cochez",
      "Mikhail Galkin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08166"
  },
  {
    "id": "arXiv:2106.08261",
    "title": "Physion: Evaluating Physical Prediction from Vision in Humans and  Machines",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Daniel M. Bear",
      "Elias Wang",
      "Damian Mrowca",
      "Felix J. Binder",
      "Hsiau-Yu Fish Tung",
      "R.T. Pramod",
      "Cameron Holdaway",
      "Sirui Tao",
      "Kevin Smith",
      "Fan-Yun Sun",
      "Li Fei-Fei",
      "Nancy Kanwisher",
      "Joshua B. Tenenbaum",
      "Daniel L.K. Yamins",
      "Judith E. Fan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08261"
  },
  {
    "id": "arXiv:2106.08269",
    "title": "Generating Data Augmentation samples for Semantic Segmentation of Salt  Bodies in a Synthetic Seismic Image Dataset",
    "abstract": "Generating Data Augmentation samples for Semantic Segmentation of Salt  Bodies in a Synthetic Seismic Image Dataset",
    "descriptor": "",
    "authors": [
      "Luis Felipe Henriques",
      "S\u00e9rgio Colcher",
      "Ruy Luiz Milidi\u00fa",
      "Andr\u00e9 Bulc\u00e3o",
      "Pablo Barros"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08269"
  },
  {
    "id": "arXiv:2106.08279",
    "title": "First Place Solution of KDD Cup 2021 OGB Large-Scale Challenge  Graph-Level Track",
    "abstract": "First Place Solution of KDD Cup 2021 OGB Large-Scale Challenge  Graph-Level Track",
    "descriptor": "",
    "authors": [
      "Chengxuan Ying",
      "Mingqi Yang",
      "Shuxin Zheng",
      "Guolin Ke",
      "Shengjie Luo",
      "Tianle Cai",
      "Chenglin Wu",
      "Yuxin Wang",
      "Yanming Shen",
      "Di He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08279"
  },
  {
    "id": "arXiv:2106.08429",
    "title": "Optimal control of a 2D diffusion-advection process with a team of  mobile actuators under jointly optimal guidance",
    "abstract": "Comments: Proofs for Lemmas~2.3, 2.5, and D.1 are attached in the supplement at the end",
    "descriptor": "\nComments: Proofs for Lemmas~2.3, 2.5, and D.1 are attached in the supplement at the end\n",
    "authors": [
      "Sheng Cheng",
      "Derek A. Paley"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08429"
  },
  {
    "id": "arXiv:2106.08462",
    "title": "Multi-Resolution Continuous Normalizing Flows",
    "abstract": "Comments: 9 pages, 5 figures, 3 tables, 17 equations",
    "descriptor": "\nComments: 9 pages, 5 figures, 3 tables, 17 equations\n",
    "authors": [
      "Vikram Voleti",
      "Chris Finlay",
      "Adam Oberman",
      "Christopher Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.08462"
  },
  {
    "id": "arXiv:2106.08616",
    "title": "Out-of-Scope Intent Detection with Self-Supervision and Discriminative  Training",
    "abstract": "Comments: Published as long oral paper in ACL 2021",
    "descriptor": "\nComments: Published as long oral paper in ACL 2021\n",
    "authors": [
      "Li-Ming Zhan",
      "Haowen Liang",
      "Bo Liu",
      "Lu Fan",
      "Xiao-Ming Wu",
      "Albert Y.S. Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08616"
  },
  {
    "id": "arXiv:2106.08652",
    "title": "Maxmin-Fair Ranking: Individual Fairness under Group-Fairness  Constraints",
    "abstract": "Comments: In proceedings of KDD 2021",
    "descriptor": "\nComments: In proceedings of KDD 2021\n",
    "authors": [
      "David Garcia-Soriano",
      "Francesco Bonchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.08652"
  },
  {
    "id": "arXiv:2106.08720",
    "title": "Predicting crop yields with little ground truth: A simple statistical  model for in-season forecasting",
    "abstract": "Predicting crop yields with little ground truth: A simple statistical  model for in-season forecasting",
    "descriptor": "",
    "authors": [
      "Nemo Semret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08720"
  },
  {
    "id": "arXiv:2106.08774",
    "title": "Analysis and Optimisation of Bellman Residual Errors with Neural  Function Approximation",
    "abstract": "Comments: 29 pages, 8 figures",
    "descriptor": "\nComments: 29 pages, 8 figures\n",
    "authors": [
      "Martin Gottwald",
      "Sven Gronauer",
      "Hao Shen",
      "Klaus Diepold"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08774"
  },
  {
    "id": "arXiv:2106.08846",
    "title": "Algorithm to Compilation Co-design: An Integrated View of Neural Network  Sparsity",
    "abstract": "Algorithm to Compilation Co-design: An Integrated View of Neural Network  Sparsity",
    "descriptor": "",
    "authors": [
      "Fu-Ming Guo",
      "Austin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08846"
  },
  {
    "id": "arXiv:2106.08992",
    "title": "A unifying point of view on expressive power of GNNs",
    "abstract": "Comments: 16 pages, 3 figures",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Giuseppe Alessio D'Inverno",
      "Monica Bianchini",
      "Maria Lucia Sampoli",
      "Franco Scarselli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08992"
  },
  {
    "id": "arXiv:2106.09018",
    "title": "End-to-End Semi-Supervised Object Detection with Soft Teacher",
    "abstract": "End-to-End Semi-Supervised Object Detection with Soft Teacher",
    "descriptor": "",
    "authors": [
      "Mengde Xu",
      "Zheng Zhang",
      "Han Hu",
      "Jianfeng Wang",
      "Lijuan Wang",
      "Fangyun Wei",
      "Xiang Bai",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09018"
  }
]
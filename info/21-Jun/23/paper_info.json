[
  {
    "id": "arXiv:2106.11312",
    "title": "Feedback Shaping: A Modeling Approach to Nurture Content Creation",
    "abstract": "Social media platforms bring together content creators and content consumers\nthrough recommender systems like newsfeed. The focus of such recommender\nsystems has thus far been primarily on modeling the content consumer\npreferences and optimizing for their experience. However, it is equally\ncritical to nurture content creation by prioritizing the creators' interests,\nas quality content forms the seed for sustainable engagement and conversations,\nbringing in new consumers while retaining existing ones. In this work, we\npropose a modeling approach to predict how feedback from content consumers\nincentivizes creators. We then leverage this model to optimize the newsfeed\nexperience for content creators by reshaping the feedback distribution, leading\nto a more active content ecosystem. Practically, we discuss how we balance the\nuser experience for both consumers and creators, and how we carry out online\nA/B tests with strong network effects. We present a deployed use case on the\nLinkedIn newsfeed, where we used this approach to improve content creation\nsignificantly without compromising the consumers' experience.",
    "descriptor": "",
    "authors": [
      "Ye Tu",
      "Chun Lo",
      "Yiping Yuan",
      "Shaunak Chatterjee"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11312"
  },
  {
    "id": "arXiv:2106.11335",
    "title": "Do sound event representations generalize to other audio tasks? A case  study in audio transfer learning",
    "abstract": "Transfer learning is critical for efficient information transfer across\nmultiple related learning problems. A simple, yet effective transfer learning\napproach utilizes deep neural networks trained on a large-scale task for\nfeature extraction. Such representations are then used to learn related\ndownstream tasks. In this paper, we investigate transfer learning capacity of\naudio representations obtained from neural networks trained on a large-scale\nsound event detection dataset. We build and evaluate these representations\nacross a wide range of other audio tasks, via a simple linear classifier\ntransfer mechanism. We show that such simple linear transfer is already\npowerful enough to achieve high performance on the downstream tasks. We also\nprovide insights into the attributes of sound event representations that enable\nsuch efficient information transfer.",
    "descriptor": "\nComments: Accepted Interspeech 2021\n",
    "authors": [
      "Anurag Kumar",
      "Yun Wang",
      "Vamsi Krishna Ithapu",
      "Christian Fuegen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.11335"
  },
  {
    "id": "arXiv:2106.11336",
    "title": "Storage Codes with Flexible Number of Nodes",
    "abstract": "This paper presents flexible storage codes, a class of error-correcting codes\nthat can recover information from a flexible number of storage nodes. As a\nresult, one can make a better use of the available storage nodes in the\npresence of unpredictable node failures and reduce the data access latency. Let\nus assume a storage system encodes $k\\ell$ information symbols over a finite\nfield $\\mathbb{F}$ into $n$ nodes, each of size $\\ell$ symbols. The code is\nparameterized by a set of tuples $\\{(R_j,k_j,\\ell_j): 1 \\le j \\le a\\}$,\nsatisfying $k_1\\ell_1=k_2\\ell_2=...=k_a\\ell_a$ and $k_1>k_2>...>k_a = k,\n\\ell_a=\\ell$, such that the information symbols can be reconstructed from any\n$R_j$ nodes, each node accessing $\\ell_j$ symbols. In other words, the code\nallows a flexible number of nodes for decoding to accommodate the variance in\nthe data access time of the nodes. Code constructions are presented for\ndifferent storage scenarios, including LRC (locally recoverable) codes, PMDS\n(partial MDS) codes, and MSR (minimum storage regenerating) codes. We analyze\nthe latency of accessing information and perform simulations on Amazon clusters\nto show the efficiency of presented codes.",
    "descriptor": "",
    "authors": [
      "Weiqi Li",
      "Zhiying Wang",
      "Taiting Lu",
      "Hamid Jafarkhani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11336"
  },
  {
    "id": "arXiv:2106.11339",
    "title": "Understanding top-down attention using task-oriented ablation design",
    "abstract": "Top-down attention allows neural networks, both artificial and biological, to\nfocus on the information most relevant for a given task. This is known to\nenhance performance in visual perception. But it remains unclear how attention\nbrings about its perceptual boost, especially when it comes to naturalistic\nsettings like recognising an object in an everyday scene. What aspects of a\nvisual task does attention help to deal with? We aim to answer this with a\ncomputational experiment based on a general framework called task-oriented\nablation design. First we define a broad range of visual tasks and identify six\nfactors that underlie task variability. Then on each task we compare the\nperformance of two neural networks, one with top-down attention and one\nwithout. These comparisons reveal the task-dependence of attention's perceptual\nboost, giving a clearer idea of the role attention plays. Whereas many existing\ncognitive accounts link attention to stimulus-level variables, such as visual\nclutter and object scale, we find greater explanatory power in system-level\nvariables that capture the interaction between the model, the distribution of\ntraining data and the task format. This finding suggests a shift in how\nattention is studied could be fruitful. We make publicly available our code and\nresults, along with statistics relevant to ImageNet-based experiments beyond\nthis one. Our contribution serves to support the development of more human-like\nvision models and the design of more informative machine-learning experiments.",
    "descriptor": "",
    "authors": [
      "Freddie Bickford Smith",
      "Brett D Roads",
      "Xiaoliang Luo",
      "Bradley C Love"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11339"
  },
  {
    "id": "arXiv:2106.11341",
    "title": "Consideration of the Need for Quantum Grid Computing",
    "abstract": "Quantum computing is poised to dramatically change the computational\nlandscape, worldwide. Quantum computers can solve complex problems that are, at\nleast in some cases, beyond the ability of even advanced future classical-style\ncomputers. In addition to being able to solve these classical\ncomputer-unsolvable problems, quantum computers have demonstrated a capability\nto solve some problems (such as prime factoring) much more efficiently than\nclassical computing. This will create problems for encryption techniques, which\ndepend on the difficulty of factoring for their security. Security, scientific,\nand other applications will require access to quantum computing resources to\naccess their unique capabilities, speed and economic (aggregate computing time\ncost) benefits. Many scientific applications, as well as numerous other ones,\nuse grid computing to provide benefits such as scalability and resource access.\nAs these applications may benefit from quantum capabilities - and some future\napplications may require quantum capabilities - identifying how to integrate\nquantum computing systems into grid computing environments is critical. This\npaper discusses the benefits of grid-connected quantum computers and what is\nrequired to achieve this.",
    "descriptor": "",
    "authors": [
      "Dominic Rosch-Grace",
      "Jeremy Straub"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.11341"
  },
  {
    "id": "arXiv:2106.11342",
    "title": "Dive into Deep Learning",
    "abstract": "This open-source book represents our attempt to make deep learning\napproachable, teaching readers the concepts, the context, and the code. The\nentire book is drafted in Jupyter notebooks, seamlessly integrating exposition\nfigures, math, and interactive examples with self-contained code. Our goal is\nto offer a resource that could (i) be freely available for everyone; (ii) offer\nsufficient technical depth to provide a starting point on the path to actually\nbecoming an applied machine learning scientist; (iii) include runnable code,\nshowing readers how to solve problems in practice; (iv) allow for rapid\nupdates, both by us and also by the community at large; (v) be complemented by\na forum for interactive discussion of technical details and to answer\nquestions.",
    "descriptor": "\nComments: (HTML) this https URL (GitHub) this https URL\n",
    "authors": [
      "Aston Zhang",
      "Zachary C. Lipton",
      "Mu Li",
      "Alexander J. Smola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11342"
  },
  {
    "id": "arXiv:2106.11344",
    "title": "f-Domain-Adversarial Learning: Theory and Algorithms",
    "abstract": "Unsupervised domain adaptation is used in many machine learning applications\nwhere, during training, a model has access to unlabeled data in the target\ndomain, and a related labeled dataset. In this paper, we introduce a novel and\ngeneral domain-adversarial framework. Specifically, we derive a novel\ngeneralization bound for domain adaptation that exploits a new measure of\ndiscrepancy between distributions based on a variational characterization of\nf-divergences. It recovers the theoretical results from Ben-David et al.\n(2010a) as a special case and supports divergences used in practice. Based on\nthis bound, we derive a new algorithmic framework that introduces a key\ncorrection in the original adversarial training method of Ganin et al. (2016).\nWe show that many regularizers and ad-hoc objectives introduced over the last\nyears in this framework are then not required to achieve performance comparable\nto (if not better than) state-of-the-art domain-adversarial methods.\nExperimental analysis conducted on real-world natural language and computer\nvision datasets show that our framework outperforms existing baselines, and\nobtains the best results for f-divergences that were not considered previously\nin domain-adversarial learning.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "David Acuna",
      "Guojun Zhang",
      "Marc T. Law",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11344"
  },
  {
    "id": "arXiv:2106.11345",
    "title": "Cogment: Open Source Framework For Distributed Multi-actor Training,  Deployment & Operations",
    "abstract": "Involving humans directly for the benefit of AI agents' training is getting\ntraction thanks to several advances in reinforcement learning and\nhuman-in-the-loop learning. Humans can provide rewards to the agent,\ndemonstrate tasks, design a curriculum, or act in the environment, but these\nbenefits also come with architectural, functional design and engineering\ncomplexities. We present Cogment, a unifying open-source framework that\nintroduces an actor formalism to support a variety of humans-agents\ncollaboration typologies and training approaches. It is also scalable out of\nthe box thanks to a distributed micro service architecture, and offers\nsolutions to the aforementioned complexities.",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "AI Redefined",
      "Sai Krishna Gottipati",
      "Sagar Kurandwad",
      "Clod\u00e9ric Mars",
      "Gregory Szriftgiser",
      "Fran\u00e7ois Chabot"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.11345"
  },
  {
    "id": "arXiv:2106.11346",
    "title": "GAIA: A Transfer Learning System of Object Detection that Fits Your  Needs",
    "abstract": "Transfer learning with pre-training on large-scale datasets has played an\nincreasingly significant role in computer vision and natural language\nprocessing recently. However, as there exist numerous application scenarios\nthat have distinctive demands such as certain latency constraints and\nspecialized data distributions, it is prohibitively expensive to take advantage\nof large-scale pre-training for per-task requirements. In this paper, we focus\non the area of object detection and present a transfer learning system named\nGAIA, which could automatically and efficiently give birth to customized\nsolutions according to heterogeneous downstream needs. GAIA is capable of\nproviding powerful pre-trained weights, selecting models that conform to\ndownstream demands such as latency constraints and specified data domains, and\ncollecting relevant data for practitioners who have very few datapoints for\ntheir tasks. With GAIA, we achieve promising results on COCO, Objects365, Open\nImages, Caltech, CityPersons, and UODB which is a collection of datasets\nincluding KITTI, VOC, WiderFace, DOTA, Clipart, Comic, and more. Taking COCO as\nan example, GAIA is able to efficiently produce models covering a wide range of\nlatency from 16ms to 53ms, and yields AP from 38.2 to 46.5 without whistles and\nbells. To benefit every practitioner in the community of object detection, GAIA\nis released at https://github.com/GAIA-vision.",
    "descriptor": "\nComments: CVPR2021. The first two authors contribute equally. Code is released at this https URL\n",
    "authors": [
      "Xingyuan Bu",
      "Junran Peng",
      "Junjie Yan",
      "Tieniu Tan",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11346"
  },
  {
    "id": "arXiv:2106.11351",
    "title": "Be your own Benchmark: No-Reference Trajectory Metric on Registered  Point Clouds",
    "abstract": "This paper addresses the problem of assessing trajectory quality in\nconditions when no ground truth poses are available or when their accuracy is\nnot enough for the specific task - for example, small-scale mapping in outdoor\nscenes. In our work, we propose a no-reference metric, Mutually Orthogonal\nMetric (MOM), that estimates the quality of the map from registered point\nclouds via the trajectory poses. MOM strongly correlates with full-reference\ntrajectory metric Relative Pose Error, making it a trajectory benchmarking tool\non setups where 3D sensing technologies are employed. We provide a mathematical\nfoundation for such correlation and confirm it statistically in synthetic\nenvironments. Furthermore, since our metric uses a subset of points from\nmutually orthogonal surfaces, we provide an algorithm for the extraction of\nsuch subset and evaluate its performance in synthetic CARLA environment and on\nKITTI dataset.",
    "descriptor": "",
    "authors": [
      "Anastasiia Kornilova",
      "Gonzalo Ferrer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11351"
  },
  {
    "id": "arXiv:2106.11354",
    "title": "FDeblur-GAN: Fingerprint Deblurring using Generative Adversarial Network",
    "abstract": "While working with fingerprint images acquired from crime scenes, mobile\ncameras, or low-quality sensors, it becomes difficult for automated\nidentification systems to verify the identity due to image blur and distortion.\nWe propose a fingerprint deblurring model FDeblur-GAN, based on the conditional\nGenerative Adversarial Networks (cGANs) and multi-stage framework of the stack\nGAN. Additionally, we integrate two auxiliary sub-networks into the model for\nthe deblurring task. The first sub-network is a ridge extractor model. It is\nadded to generate ridge maps to ensure that fingerprint information and\nminutiae are preserved in the deblurring process and prevent the model from\ngenerating erroneous minutiae. The second sub-network is a verifier that helps\nthe generator to preserve the ID information during the generation process.\nUsing a database of blurred fingerprints and corresponding ridge maps, the deep\nnetwork learns to deblur from the input blurry samples. We evaluate the\nproposed method in combination with two different fingerprint matching\nalgorithms. We achieved an accuracy of 95.18% on our fingerprint database for\nthe task of matching deblurred and ground truth fingerprints.",
    "descriptor": "\nComments: 8 Pages, Accepted in IJCB Conference\n",
    "authors": [
      "Amol S. Joshi",
      "Ali Dabouei",
      "Jeremy Dawson",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11354"
  },
  {
    "id": "arXiv:2106.11355",
    "title": "Port-Hamiltonian System Identification from Noisy Frequency Response  Data",
    "abstract": "We present a new method for the identification of linear time-invariant\npassive systems from noisy frequency response data. In particular, we propose\nto fit a parametrized port-Hamiltonian (pH) system, which is automatically\npassive, to supplied data with respect to a least-squares objective function.\nIn a numerical study, we assess the accuracy of the resulting identified models\nby comparing our method to two other frequency domain system identification\nmethods. One of the methods being compared is a recently published\nidentification procedure that also computes pH systems and the other one is the\nwell-known vector-fitting algorithm, which provides unstructured models. The\nnumerical evaluation demonstrates a substantial increase in accuracy of our\nmethod compared to the other pH identification procedure and a slightly\nimproved accuracy compared to vector-fitting. This underlines the suitability\nof our method for the estimation of passive or pH systems - in particular from\nnoisy frequency response data.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Paul Schwerdtner"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.11355"
  },
  {
    "id": "arXiv:2106.11359",
    "title": "Photozilla: A Large-Scale Photography Dataset and Visual Embedding for  20 Photography Styles",
    "abstract": "The advent of social media platforms has been a catalyst for the development\nof digital photography that engendered a boom in vision applications. With this\nmotivation, we introduce a large-scale dataset termed 'Photozilla', which\nincludes over 990k images belonging to 10 different photographic styles. The\ndataset is then used to train 3 classification models to automatically classify\nthe images into the relevant style which resulted in an accuracy of ~96%. With\nthe rapid evolution of digital photography, we have seen new types of\nphotography styles emerging at an exponential rate. On that account, we present\na novel Siamese-based network that uses the trained classification models as\nthe base architecture to adapt and classify unseen styles with only 25 training\nsamples. We report an accuracy of over 68% for identifying 10 other distinct\ntypes of photography styles. This dataset can be found at\nhttps://trisha025.github.io/Photozilla/",
    "descriptor": "\nComments: In the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, 2021. (Poster)\n",
    "authors": [
      "Trisha Singhal",
      "Junhua Liu",
      "Lucienne T. M. Blessing",
      "Kwan Hui Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11359"
  },
  {
    "id": "arXiv:2106.11360",
    "title": "Hi-BEHRT: Hierarchical Transformer-based model for accurate prediction  of clinical events using multimodal longitudinal electronic health records",
    "abstract": "Electronic health records represent a holistic overview of patients'\ntrajectories. Their increasing availability has fueled new hopes to leverage\nthem and develop accurate risk prediction models for a wide range of diseases.\nGiven the complex interrelationships of medical records and patient outcomes,\ndeep learning models have shown clear merits in achieving this goal. However, a\nkey limitation of these models remains their capacity in processing long\nsequences. Capturing the whole history of medical encounters is expected to\nlead to more accurate predictions, but the inclusion of records collected for\ndecades and from multiple resources can inevitably exceed the receptive field\nof the existing deep learning architectures. This can result in missing\ncrucial, long-term dependencies. To address this gap, we present Hi-BEHRT, a\nhierarchical Transformer-based model that can significantly expand the\nreceptive field of Transformers and extract associations from much longer\nsequences. Using a multimodal large-scale linked longitudinal electronic health\nrecords, the Hi-BEHRT exceeds the state-of-the-art BEHRT 1% to 5% for area\nunder the receiver operating characteristic (AUROC) curve and 3% to 6% for area\nunder the precision recall (AUPRC) curve on average, and 3% to 6% (AUROC) and\n3% to 11% (AUPRC) for patients with long medical history for 5-year heart\nfailure, diabetes, chronic kidney disease, and stroke risk prediction.\nAdditionally, because pretraining for hierarchical Transformer is not\nwell-established, we provide an effective end-to-end contrastive pre-training\nstrategy for Hi-BEHRT using EHR, improving its transferability on predicting\nclinical events with relatively small training dataset.",
    "descriptor": "",
    "authors": [
      "Yikuan Li",
      "Mohammad Mamouei",
      "Gholamreza Salimi-Khorshidi",
      "Shishir Rao",
      "Abdelaali Hassaine",
      "Dexter Canoy",
      "Thomas Lukasiewicz",
      "Kazem Rahimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11360"
  },
  {
    "id": "arXiv:2106.11365",
    "title": "Distributed Heuristic Multi-Agent Path Finding with Communication",
    "abstract": "Multi-Agent Path Finding (MAPF) is essential to large-scale robotic systems.\nRecent methods have applied reinforcement learning (RL) to learn decentralized\npolices in partially observable environments. A fundamental challenge of\nobtaining collision-free policy is that agents need to learn cooperation to\nhandle congested situations. This paper combines communication with deep\nQ-learning to provide a novel learning based method for MAPF, where agents\nachieve cooperation via graph convolution. To guide RL algorithm on\nlong-horizon goal-oriented tasks, we embed the potential choices of shortest\npaths from single source as heuristic guidance instead of using a specific path\nas in most existing works. Our method treats each agent independently and\ntrains the model from a single agent's perspective. The final trained policy is\napplied to each agent for decentralized execution. The whole system is\ndistributed during training and is trained under a curriculum learning\nstrategy. Empirical evaluation in obstacle-rich environment indicates the high\nsuccess rate with low average step of our method.",
    "descriptor": "\nComments: Published at ICRA 2021\n",
    "authors": [
      "Ziyuan Ma",
      "Yudong Luo",
      "Hang Ma"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.11365"
  },
  {
    "id": "arXiv:2106.11366",
    "title": "Adaptive Sampling for Structure Preserving Model Order Reduction of  Port-Hamiltonian Systems",
    "abstract": "We present an adaptive sampling strategy for the optimization-based structure\npreserving model order reduction (MOR) algorithm developed in [Schwerdtner, P.\nand Voigt, M. (2020). Structure preserving model order reduction by parameter\noptimization, Preprint arXiv:2011.07567]. This strategy reduces the\ncomputational demand and the required a priori knowledge about the given full\norder model, while at the same time retaining a high accuracy compared to other\nstructure preserving but also unstructured MOR algorithms. A numerical study\nwith a port-Hamiltonian benchmark system demonstrates the effectiveness of our\nmethod combined with its new adaptive sampling strategy. We also investigate\nthe distribution of the sample points.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Paul Schwerdtner",
      "Matthias Voigt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.11366"
  },
  {
    "id": "arXiv:2106.11372",
    "title": "First Approximation for Uniform Lower and Upper Bounded Facility  Location Problem avoiding violation in Lower Bounds",
    "abstract": "With growing emphasis on e-commerce marketplace platforms where we have a\ncentral platform mediating between the seller and the buyer, it becomes\nimportant to keep a check on the availability and profitability of the central\nstore. A store serving too less clients can be non-profitable and a store\ngetting too many orders can lead to bad service to the customers which can be\ndetrimental for the business. In this paper, we study the facility location\nproblem(FL) with upper and lower bounds on the number of clients an open\nfacility serves. Constant factor approximations are known for the restricted\nvariants of the problem with only the upper bounds or only the lower bounds.\nThe only work that deals with bounds on both the sides violates both the bounds\n\\cite{friggstad_et_al_LBUFL}. In this paper, we present the first (constant\nfactor) approximation for the problem violating the upper bound by a factor of\n%\\textcolor{magenta}{$(2 + \\epsilon)$} $(5/2)$ without violating the lower\nbounds when both the lower and the upper bounds are uniform. We first give a\ntri-criteria (constant factor) approximation violating both the upper and the\nlower bounds and then get rid of violation in lower bounds by transforming the\nproblem instance to an instance of capacitated facility location problem.",
    "descriptor": "",
    "authors": [
      "Sapna Grover",
      "Neelima Gupta",
      "Rajni Dabas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.11372"
  },
  {
    "id": "arXiv:2106.11375",
    "title": "Phrase-level Active Learning for Neural Machine Translation",
    "abstract": "Neural machine translation (NMT) is sensitive to domain shift. In this paper,\nwe address this problem in an active learning setting where we can spend a\ngiven budget on translating in-domain data, and gradually fine-tune a\npre-trained out-of-domain NMT model on the newly translated data. Existing\nactive learning methods for NMT usually select sentences based on uncertainty\nscores, but these methods require costly translation of full sentences even\nwhen only one or two key phrases within the sentence are informative. To\naddress this limitation, we re-examine previous work from the phrase-based\nmachine translation (PBMT) era that selected not full sentences, but rather\nindividual phrases. However, while incorporating these phrases into PBMT\nsystems was relatively simple, it is less trivial for NMT systems, which need\nto be trained on full sequences to capture larger structural properties of\nsentences unique to the new domain. To overcome these hurdles, we propose to\nselect both full sentences and individual phrases from unlabelled data in the\nnew domain for routing to human translators. In a German-English translation\ntask, our active learning approach achieves consistent improvements over\nuncertainty-based sentence selection methods, improving up to 1.2 BLEU score\nover strong active learning baselines.",
    "descriptor": "",
    "authors": [
      "Junjie Hu",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11375"
  },
  {
    "id": "arXiv:2106.11376",
    "title": "Content Addressable Parallel Processors on a FPGA",
    "abstract": "In this short article, we report on the implementation of a Content\nAddressable Parallel Processor using a FPGA. While Content addressable memories\nhave been implemented in FPGAs, to our knowledge this is the first\nimplementation in FPGA of Caxton C. Foster's vision of parallel processing,\nparticularly the notions of parallel write as well as the combining of output\nvalues, which are usually missing in more typical CAM implementations, such as\nthe ones designed for network routing. The resulting CAPP is made accessible to\na host computer over a USB/UART interface, using a straightforward serial\nprotocol that is demonstrated using a Python-based driver.",
    "descriptor": "\nComments: 4 pages, 5 figures\n",
    "authors": [
      "Ayush Salik",
      "Manor Askenazi",
      "Edward Rietman"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.11376"
  },
  {
    "id": "arXiv:2106.11378",
    "title": "Dual-port grid-forming control of MMCs and its applications to grids of  grids",
    "abstract": "Motivated by the emergence of power systems that consist of HVAC and HVDC\nsubgrids this work focuses on grid-forming (GFM) control of Interconnecting\nPower Converters (IPCs) that are the key elements for connecting HVAC and HVDC\nsystems. We introduce the concept of dual-port GFM control that leverages the\nability of Modular Multilevel Converters (MMCs) to simultaneously form its AC\nand DC terminal voltage and present two dual-port GFM MMC controls. We provide\nanalytical results and high-fidelity simulations that demonstrate that (i)\ndual-port GFM control is more resilient to contingencies (i.e., line and\ngenerator outages) than state-of-the-art single-port GFM control, and (ii)\nunlike single-port GFM control, dual-port GFM control does not require\nassigning grid-forming and grid-following (GFL) roles to the IPC terminals in\ngrids of grids. Finally, we provide an in-depth discussion and comparison of\nsingle-port GFM control and the proposed dual-port GFM controls.",
    "descriptor": "",
    "authors": [
      "Dominic Gro\u00df",
      "S\u00e1nchez-S\u00e1nchez",
      "Eduardo Prieto-Araujo",
      "Oriol Gomis-Bellmunt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.11378"
  },
  {
    "id": "arXiv:2106.11379",
    "title": "BEyond observation: an approach for ObjectNav",
    "abstract": "With the rise of automation, unmanned vehicles became a hot topic both as\ncommercial products and as a scientific research topic. It composes a\nmulti-disciplinary field of robotics that encompasses embedded systems, control\ntheory, path planning, Simultaneous Localization and Mapping (SLAM), scene\nreconstruction, and pattern recognition. In this work, we present our\nexploratory research of how sensor data fusion and state-of-the-art machine\nlearning algorithms can perform the Embodied Artificial Intelligence (E-AI)\ntask called Visual Semantic Navigation. This task, a.k.a Object-Goal Navigation\n(ObjectNav) consists of autonomous navigation using egocentric visual\nobservations to reach an object belonging to the target semantic class without\nprior knowledge of the environment. Our method reached fourth place on the\nHabitat Challenge 2021 ObjectNav on the Minival phase and the Test-Standard\nPhase.",
    "descriptor": "\nComments: Presented at the 2th Embodied AI Workshop at CVPR 2021\n",
    "authors": [
      "Daniel V. Ruiz",
      "Eduardo Todt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11379"
  },
  {
    "id": "arXiv:2106.11380",
    "title": "A Drift Homotopy Implicit Particle Filter Method for Nonlinear Filtering  problems",
    "abstract": "In this paper, we develop a drift homotopy implicit particle filter method.\nThe methodology of our approach is to adopt the concept of drift homotopy in\nthe resampling procedure of the particle filter method for solving the\nnonlinear filtering problem, and we introduce an implicit particle filter\nmethod to improve the efficiency of the drift homotopy resampling procedure.\nNumerical experiments are carried out to demonstrate the effectiveness and\nefficiency of our drift homotopy implicit particle filter.",
    "descriptor": "",
    "authors": [
      "Xin Li",
      "Feng Bao",
      "Kyle Gallivan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.11380"
  },
  {
    "id": "arXiv:2106.11381",
    "title": "Efficient Wildland Fire Simulation via Nonlinear Model Order Reduction",
    "abstract": "We propose a new hyper-reduction method for a recently introduced nonlinear\nmodel reduction framework based on dynamically transformed basis functions and\nespecially well-suited for advection-dominated systems. Furthermore, we discuss\napplying this new method to a wildland fire model whose dynamics feature\ntraveling combustion waves and local ignition and is thus challenging for\nclassical model reduction schemes based on linear subspaces. The new\nhyper-reduction framework allows us to construct parameter-dependent\nreduced-order models (ROMs) with efficient offline/online decomposition. The\nnumerical experiments demonstrate that the ROMs obtained by the novel method\noutperform those obtained by a classical approach using the proper orthogonal\ndecomposition and the discrete empirical interpolation method in terms of run\ntime and accuracy.",
    "descriptor": "",
    "authors": [
      "Felix Black",
      "Philipp Schulze",
      "Benjamin Unger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.11381"
  },
  {
    "id": "arXiv:2106.11384",
    "title": "Membership Inference on Word Embedding and Beyond",
    "abstract": "In the text processing context, most ML models are built on word embeddings.\nThese embeddings are themselves trained on some datasets, potentially\ncontaining sensitive data. In some cases this training is done independently,\nin other cases, it occurs as part of training a larger, task-specific model. In\neither case, it is of interest to consider membership inference attacks based\non the embedding layer as a way of understanding sensitive information leakage.\nBut, somewhat surprisingly, membership inference attacks on word embeddings and\ntheir effect in other natural language processing (NLP) tasks that use these\nembeddings, have remained relatively unexplored.\nIn this work, we show that word embeddings are vulnerable to black-box\nmembership inference attacks under realistic assumptions. Furthermore, we show\nthat this leakage persists through two other major NLP applications:\nclassification and text-generation, even when the embedding layer is not\nexposed to the attacker. We show that our MI attack achieves high attack\naccuracy against a classifier model and an LSTM-based language model. Indeed,\nour attack is a cheaper membership inference attack on text-generative models,\nwhich does not require the knowledge of the target model or any expensive\ntraining of text-generative models as shadow models.",
    "descriptor": "",
    "authors": [
      "Saeed Mahloujifar",
      "Huseyin A. Inan",
      "Melissa Chase",
      "Esha Ghosh",
      "Marcello Hasegawa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11384"
  },
  {
    "id": "arXiv:2106.11387",
    "title": "Incentive-Compatible Kidney Exchange in a Slightly Semi-Random Model",
    "abstract": "Motivated by kidney exchange, we study the following mechanism-design\nproblem: On a directed graph (of transplant compatibilities among patient-donor\npairs), the mechanism must select a simple path (a chain of transplantations)\nstarting at a distinguished vertex (an altruistic donor) such that the total\nlength of this path is as large as possible (a maximum number of patients\nreceive a kidney). However, the mechanism does not have direct access to the\ngraph. Instead, the vertices are partitioned over multiple players (hospitals),\nand each player reports a subset of her vertices to the mechanism. In\nparticular, a player may strategically omit vertices to increase how many of\nher vertices lie on the path returned by the mechanism.\nOur objective is to find mechanisms that limit incentives for such\nmanipulation while producing long paths. Unfortunately, in worst-case\ninstances, competing with the overall longest path is impossible while\nincentivizing (approximate) truthfulness, i.e., requiring that hiding nodes\ncannot increase a player's utility by more than a factor of $1 + o(1)$. We\ntherefore adopt a semi-random model where a small ($o(n)$) number of random\nedges are added to worst-case instances. While it remains impossible for\ntruthful mechanisms to compete with the overall longest path, we give a\ntruthful mechanism that competes with a weaker but non-trivial benchmark: the\nlength of any path whose subpaths within each player have a minimum average\nlength. In fact, our mechanism satisfies even a stronger notion of\ntruthfulness, which we call matching-time incentive compatibility. This notion\nof truthfulness requires that each player not only reports her nodes truthfully\nbut also does not stop the returned path at any of her nodes in order to divert\nit to a continuation inside her own subgraph.",
    "descriptor": "\nComments: Full version of EC'21 paper\n",
    "authors": [
      "Avrim Blum",
      "Paul G\u00f6lz"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2106.11387"
  },
  {
    "id": "arXiv:2106.11388",
    "title": "How well do you know your summarization datasets?",
    "abstract": "State-of-the-art summarization systems are trained and evaluated on massive\ndatasets scraped from the web. Despite their prevalence, we know very little\nabout the underlying characteristics (data noise, summarization complexity,\netc.) of these datasets, and how these affect system performance and the\nreliability of automatic metrics like ROUGE. In this study, we manually analyze\n600 samples from three popular summarization datasets. Our study is driven by a\nsix-class typology which captures different noise types (missing facts,\nentities) and degrees of summarization difficulty (extractive, abstractive). We\nfollow with a thorough analysis of 27 state-of-the-art summarization models and\n5 popular metrics, and report our key insights: (1) Datasets have distinct data\nquality and complexity distributions, which can be traced back to their\ncollection process. (2) The performance of models and reliability of metrics is\ndependent on sample complexity. (3) Faithful summaries often receive low scores\nbecause of the poor diversity of references. We release the code, annotated\ndata and model outputs.",
    "descriptor": "\nComments: Accepted into Findings of ACL-IJCNLP 2021\n",
    "authors": [
      "Priyam Tejaswin",
      "Dhruv Naik",
      "Pengfei Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11388"
  },
  {
    "id": "arXiv:2106.11390",
    "title": "An Efficient SDN Architecture for Smart Home Security Accelerated by  FPGA",
    "abstract": "With the rise in Internet of Things (IoT) devices, home network management\nand security are becoming complex. There is an urgent requirement to make smart\nhome network management efficient. This work proposes an SDN-based architecture\nto secure smart home networks through K-Nearest Neighbor (KNN) based device\nclassifications and malicious traffic detection. The efficiency is further\nenhanced by offloading the computation-intensive KNN model to Field\nProgrammable Gate Arrays (FPGA), which offers parallel processing power of GPU\nplatforms at lower costs and higher efficiencies, and can be used to accelerate\ntime-sensitive tasks. The proposed parallelization and implementation of KNN on\nFPGA are achieved by using the Vivado Design Suite from Xilinx and High-Level\nSynthesis (HLS). When optimized with 10-fold cross-validation, the proposed\nsolution for KNN consistently exhibits the best performances on FPGA when\ncompared with four alternative KNN instances (i.e., 78\\% faster than the\nparallel bubble sort-based implementation and 99\\% faster than the other three\nsorting algorithms). Moreover, with 36,225 training samples, the proposed KNN\nsolution classifies a test query with 95\\% accuracy in approximately 4\nmilliseconds on FPGA compared to 57 seconds on a CPU platform.",
    "descriptor": "\nComments: published in LANMAN 2021\n",
    "authors": [
      "Holden Gordon",
      "Conrad Park",
      "Bhagyashri Tushir",
      "Yuhong Liu",
      "Behnam Dezfouli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.11390"
  },
  {
    "id": "arXiv:2106.11394",
    "title": "A Turing Test for Transparency",
    "abstract": "A central goal of explainable artificial intelligence (XAI) is to improve the\ntrust relationship in human-AI interaction. One assumption underlying research\nin transparent AI systems is that explanations help to better assess\npredictions of machine learning (ML) models, for instance by enabling humans to\nidentify wrong predictions more efficiently. Recent empirical evidence however\nshows that explanations can have the opposite effect: When presenting\nexplanations of ML predictions humans often tend to trust ML predictions even\nwhen these are wrong. Experimental evidence suggests that this effect can be\nattributed to how intuitive, or human, an AI or explanation appears. This\neffect challenges the very goal of XAI and implies that responsible usage of\ntransparent AI methods has to consider the ability of humans to distinguish\nmachine generated from human explanations. Here we propose a quantitative\nmetric for XAI methods based on Turing's imitation game, a Turing Test for\nTransparency. A human interrogator is asked to judge whether an explanation was\ngenerated by a human or by an XAI method. Explanations of XAI methods that can\nnot be detected by humans above chance performance in this binary\nclassification task are passing the test. Detecting such explanations is a\nrequirement for assessing and calibrating the trust relationship in human-AI\ninteraction. We present experimental results on a crowd-sourced text\nclassification task demonstrating that even for basic ML models and XAI\napproaches most participants were not able to differentiate human from machine\ngenerated explanations. We discuss ethical and practical implications of our\nresults for applications of transparent ML.",
    "descriptor": "\nComments: Published in Proceedings of the ICML Workshop on Theoretical Foundations, Criticism, and Application Trends of Explainable AI held in conjunction with the 38th International Conference on Machine Learning (ICML)\n",
    "authors": [
      "Felix Biessmann",
      "Viktor Treu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.11394"
  },
  {
    "id": "arXiv:2106.11395",
    "title": "Mapping Slums with Medium Resolution Satellite Imagery: a Comparative  Analysis of Multi-Spectral Data and Grey-level Co-occurrence Matrix  Techniques",
    "abstract": "The UN-Habitat estimates that over one billion people live in slums around\nthe world. However, state-of-the-art techniques to detect the location of slum\nareas employ high-resolution satellite imagery, which is costly to obtain and\nprocess. As a result, researchers have started to look at utilising free and\nopen-access medium resolution satellite imagery. Yet, there is no clear\nconsensus on which data preparation and machine learning approaches are the\nmost appropriate to use with such imagery data. In this paper, we evaluate two\ntechniques (multi-spectral data and grey-level co-occurrence matrix feature\nextraction) on an open-access dataset consisting of labelled Sentinel-2 images\nwith a spatial resolution of 10 meters. Both techniques were paired with a\ncanonical correlation forests classifier. The results show that the grey-level\nco-occurrence matrix performed better than multi-spectral data for all four\ncities. It had an average accuracy for the slum class of 97% and a mean\nintersection over union of 94%, while multi-spectral data had 75% and 64% for\nthe respective metrics. These results indicate that open-access satellite\nimagery with a resolution of at least 10 meters may be suitable for keeping\ntrack of development goals such as the detection of slums in cities.",
    "descriptor": "\nComments: Accepted at the 3rd Workshop on Artificial Intelligence for Social Good (IJCAI 2021)\n",
    "authors": [
      "Agatha C. H. de Mattos",
      "Gavin McArdle",
      "Michela Bertolotto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11395"
  },
  {
    "id": "arXiv:2106.11397",
    "title": "Evaluating Team Skill Aggregation in Online Competitive Games",
    "abstract": "One of the main goals of online competitive games is increasing player\nengagement by ensuring fair matches. These games use rating systems for\ncreating balanced match-ups. Rating systems leverage statistical estimation to\nrate players' skills and use skill ratings to predict rank before matching\nplayers. Skill ratings of individual players can be aggregated to compute the\nskill level of a team. While research often aims to improve the accuracy of\nskill estimation and fairness of match-ups, less attention has been given to\nhow the skill level of a team is calculated from the skill level of its\nmembers. In this paper, we propose two new aggregation methods and compare them\nwith a standard approach extensively used in the research literature. We\npresent an exhaustive analysis of the impact of these methods on the predictive\nperformance of rating systems. We perform our experiments using three popular\nrating systems, Elo, Glicko, and TrueSkill, on three real-world datasets\nincluding over 100,000 battle royale and head-to-head matches. Our evaluations\nshow the superiority of the MAX method over the other two methods in the\nmajority of the tested cases, implying that the overall performance of a team\nis best determined by the performance of its most skilled member. The results\nof this study highlight the necessity of devising more elaborated methods for\ncalculating a team's performance -- methods covering different aspects of\nplayers' behavior such as skills, strategy, or goals.",
    "descriptor": "\nComments: Accepted in IEEE Conference on Games 2021\n",
    "authors": [
      "Arman Dehpanah",
      "Muheeb Faizan Ghori",
      "Jonathan Gemmell",
      "Bamshad Mobasher"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11397"
  },
  {
    "id": "arXiv:2106.11401",
    "title": "Spatio-Temporal Multi-Task Learning Transformer for Joint Moving Object  Detection and Segmentation",
    "abstract": "Moving objects have special importance for Autonomous Driving tasks.\nDetecting moving objects can be posed as Moving Object Segmentation, by\nsegmenting the object pixels, or Moving Object Detection, by generating a\nbounding box for the moving targets. In this paper, we present a Multi-Task\nLearning architecture, based on Transformers, to jointly perform both tasks\nthrough one network. Due to the importance of the motion features to the task,\nthe whole setup is based on a Spatio-Temporal aggregation. We evaluate the\nperformance of the individual tasks architecture versus the MTL setup, both\nwith early shared encoders, and late shared encoder-decoder transformers. For\nthe latter, we present a novel joint tasks query decoder transformer, that\nenables us to have tasks dedicated heads out of the shared model. To evaluate\nour approach, we use the KITTI MOD [29] data set. Results show1.5% mAP\nimprovement for Moving Object Detection, and 2%IoU improvement for Moving\nObject Segmentation, over the individual tasks networks.",
    "descriptor": "",
    "authors": [
      "Eslam Mohamed",
      "Ahmed El-Sallab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11401"
  },
  {
    "id": "arXiv:2106.11403",
    "title": "Deep Learning Models in Detection of Dietary Supplement Adverse Event  Signals from Twitter",
    "abstract": "Objective: The objective of this study is to develop a deep learning pipeline\nto detect signals on dietary supplement-related adverse events (DS AEs) from\nTwitter. Material and Methods: We obtained 247,807 tweets ranging from 2012 to\n2018 that mentioned both DS and AE. We annotated biomedical entities and\nrelations on 2,000 randomly selected tweets. For the concept extraction task,\nwe compared the performance of traditional word embeddings with SVM, CRF and\nLSTM-CRF classifiers to BERT models. For the relation extraction task, we\ncompared GloVe vectors with CNN classifiers to BERT models. We chose the best\nperforming models in each task to assemble an end-to-end deep learning pipeline\nto detect DS AE signals and compared the results to the known DS AEs from a DS\nknowledge base (i.e., iDISK). Results: In both tasks, the BERT-based models\noutperformed traditional word embeddings. The best performing concept\nextraction model is the BioBERT model that can identify supplement, symptom,\nand body organ entities with F1-scores of 0.8646, 0.8497, and 0.7104,\nrespectively. The best performing relation extraction model is the BERT model\nthat can identify purpose and AE relations with F1-scores of 0.8335 and 0.7538,\nrespectively. The end-to-end pipeline was able to extract DS indication and DS\nAEs with an F1-score of 0.7459 and 0,7414, respectively. Comparing to the\niDISK, we could find both known and novel DS-AEs. Conclusion: We have\ndemonstrated the feasibility of detecting DS AE signals from Twitter with a\nBioBERT-based deep learning pipeline.",
    "descriptor": "\nComments: 1 Figure, 6 Tables\n",
    "authors": [
      "Yefeng Wang",
      "Yunpeng Zhao",
      "Jiang Bian",
      "Rui Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.11403"
  },
  {
    "id": "arXiv:2106.11409",
    "title": "Learn Like The Pro: Norms from Theory to Size Neural Computation",
    "abstract": "The optimal design of neural networks is a critical problem in many\napplications. Here, we investigate how dynamical systems with polynomial\nnonlinearities can inform the design of neural systems that seek to emulate\nthem. We propose a Learnability metric and its associated features to quantify\nthe near-equilibrium behavior of learning dynamics. Equating the Learnability\nof neural systems with equivalent parameter estimation metric of the reference\nsystem establishes bounds on network structure. In this way, norms from theory\nprovide a good first guess for neural structure, which may then further adapt\nwith data. The proposed approach neither requires training nor training data.\nIt reveals exact sizing for a class of neural networks with multiplicative\nnodes that mimic continuous- or discrete-time polynomial dynamics. It also\nprovides relatively tight lower size bounds for classical feed-forward networks\nthat is consistent with simulated assessments.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Margaret Trautner",
      "Ziwei Li",
      "Sai Ravela"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2106.11409"
  },
  {
    "id": "arXiv:2106.11410",
    "title": "A Survey of Race, Racism, and Anti-Racism in NLP",
    "abstract": "Despite inextricable ties between race and language, little work has\nconsidered race in NLP research and development. In this work, we survey 79\npapers from the ACL anthology that mention race. These papers reveal various\ntypes of race-related bias in all stages of NLP model development, highlighting\nthe need for proactive consideration of how NLP systems can uphold racial\nhierarchies. However, persistent gaps in research on race and NLP remain: race\nhas been siloed as a niche topic and remains ignored in many NLP tasks; most\nwork operationalizes race as a fixed single-dimensional variable with a\nground-truth label, which risks reinforcing differences produced by historical\nracism; and the voices of historically marginalized people are nearly absent in\nNLP literature. By identifying where and how NLP literature has and has not\nconsidered race, especially in comparison to related fields, our work calls for\ninclusion and racial justice in NLP research practices.",
    "descriptor": "\nComments: Accepted to ACL 2021\n",
    "authors": [
      "Anjalie Field",
      "Su Lin Blodgett",
      "Zeerak Waseem",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11410"
  },
  {
    "id": "arXiv:2106.11411",
    "title": "Attention-based cross-modal fusion for audio-visual voice activity  detection in musical video streams",
    "abstract": "Many previous audio-visual voice-related works focus on speech, ignoring the\nsinging voice in the growing number of musical video streams on the Internet.\nFor processing diverse musical video data, voice activity detection is a\nnecessary step. This paper attempts to detect the speech and singing voices of\ntarget performers in musical video streams using audiovisual information. To\nintegrate information of audio and visual modalities, a multi-branch network is\nproposed to learn audio and image representations, and the representations are\nfused by attention based on semantic similarity to shape the acoustic\nrepresentations through the probability of anchor vocalization. Experiments\nshow the proposed audio-visual multi-branch network far outperforms the\naudio-only model in challenging acoustic environments, indicating the\ncross-modal information fusion based on semantic correlation is sensible and\nsuccessful.",
    "descriptor": "\nComments: Accepted by INTERSPEECH 2021\n",
    "authors": [
      "Yuanbo Hou",
      "Zhesong Yu",
      "Xia Liang",
      "Xingjian Du",
      "Bilei Zhu",
      "Zejun Ma",
      "Dick Botteldooren"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.11411"
  },
  {
    "id": "arXiv:2106.11417",
    "title": "Interpretable Model-based Hierarchical Reinforcement Learning using  Inductive Logic Programming",
    "abstract": "Recently deep reinforcement learning has achieved tremendous success in wide\nranges of applications. However, it notoriously lacks data-efficiency and\ninterpretability. Data-efficiency is important as interacting with the\nenvironment is expensive. Further, interpretability can increase the\ntransparency of the black-box-style deep RL models and hence gain trust from\nthe users. In this work, we propose a new hierarchical framework via symbolic\nRL, leveraging a symbolic transition model to improve the data-efficiency and\nintroduce the interpretability for learned policy. This framework consists of a\nhigh-level agent, a subtask solver and a symbolic transition model. Without\nassuming any prior knowledge on the state transition, we adopt inductive logic\nprogramming (ILP) to learn the rules of symbolic state transitions, introducing\ninterpretability and making the learned behavior understandable to users. In\nempirical experiments, we confirmed that the proposed framework offers\napproximately between 30\\% to 40\\% more data efficiency over previous methods.",
    "descriptor": "",
    "authors": [
      "Duo Xu",
      "Faramarz Fekri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11417"
  },
  {
    "id": "arXiv:2106.11419",
    "title": "Computa\u00e7\u00e3o: O vetor de transforma\u00e7\u00e3o da sociedade",
    "abstract": "Society is changing, has always changed, and will keep changing. However,\nchanges are becoming faster and what used to happen between generations, now\nhappens in the same generation. Computing Science is one of the reasons for\nthis speed and permeates, basically, every other knowledge area. This paper\n(written in Portugu\\^es) describes, briefly, the worldwide initiatives to\nintroduce Computing Science teaching in schools. As the paper's main\nconclusion, it is essential to introduce Computing Science and Computational\nThinking for kids before they enter into a university.",
    "descriptor": "\nComments: 9 pages, in Portuguese. Published as a chapter in the book \"Desafios da Educa\\c{c}\\~ao T\\'ecnico-Cient\\'ifica no Ensino M\\'edio\". 1ed.Rio de Janeiro: Academia Brasileira de Ci\\^encias, 2018\n",
    "authors": [
      "Avelino Francisco Zorzo",
      "Andree Luis Alice Raabe",
      "Christian Brackmann"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11419"
  },
  {
    "id": "arXiv:2106.11420",
    "title": "Policy Smoothing for Provably Robust Reinforcement Learning",
    "abstract": "The study of provable adversarial robustness for deep neural network (DNN)\nmodels has mainly focused on static supervised learning tasks such as image\nclassification. However, DNNs have been used extensively in real-world adaptive\ntasks such as reinforcement learning (RL), making RL systems vulnerable to\nadversarial attacks. The key challenge in adversarial RL is that the attacker\ncan adapt itself to the defense strategy used by the agent in previous\ntime-steps to strengthen its attack in future steps. In this work, we study the\nprovable robustness of RL against norm-bounded adversarial perturbations of the\ninputs. We focus on smoothing-based provable defenses and propose policy\nsmoothing where the agent adds a Gaussian noise to its observation at each\ntime-step before applying the policy network to make itself less sensitive to\nadversarial perturbations of its inputs. Our main theoretical contribution is\nto prove an adaptive version of the Neyman-Pearson Lemma where the adversarial\nperturbation at a particular time can be a stochastic function of current and\nprevious observations and states as well as previously observed actions. Using\nthis lemma, we adapt the robustness certificates produced by randomized\nsmoothing in the static setting of image classification to the dynamic setting\nof RL. We generate certificates that guarantee that the total reward obtained\nby the smoothed policy will not fall below a certain threshold under a\nnorm-bounded adversarial perturbation of the input. We show that our\ncertificates are tight by constructing a worst-case setting that achieves the\nbounds derived in our analysis. In our experiments, we show that this method\ncan yield meaningful certificates in complex environments demonstrating its\neffectiveness against adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Aounon Kumar",
      "Alexander Levine",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11420"
  },
  {
    "id": "arXiv:2106.11422",
    "title": "MODETR: Moving Object Detection with Transformers",
    "abstract": "Moving Object Detection (MOD) is a crucial task for the Autonomous Driving\npipeline. MOD is usually handled via 2-stream convolutional architectures that\nincorporates both appearance and motion cues, without considering the\ninter-relations between the spatial or motion features. In this paper, we\ntackle this problem through multi-head attention mechanisms, both across the\nspatial and motion streams. We propose MODETR; a Moving Object DEtection\nTRansformer network, comprised of multi-stream transformer encoders for both\nspatial and motion modalities, and an object transformer decoder that produces\nthe moving objects bounding boxes using set predictions. The whole architecture\nis trained end-to-end using bi-partite loss. Several methods of incorporating\nmotion cues with the Transformer model are explored, including two-stream RGB\nand Optical Flow (OF) methods, and multi-stream architectures that take\nadvantage of sequence information. To incorporate the temporal information, we\npropose a new Temporal Positional Encoding (TPE) approach to extend the Spatial\nPositional Encoding(SPE) in DETR. We explore two architectural choices for\nthat, balancing between speed and time. To evaluate the our network, we perform\nthe MOD task on the KITTI MOD [6] data set. Results show significant 5% mAP of\nthe Transformer network for MOD over the state-of-the art methods. Moreover,\nthe proposed TPE encoding provides 10% mAP improvement over the SPE baseline.",
    "descriptor": "",
    "authors": [
      "Eslam Mohamed",
      "Ahmad El-Sallab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11422"
  },
  {
    "id": "arXiv:2106.11423",
    "title": "Normalized Avatar Synthesis Using StyleGAN and Perceptual Refinement",
    "abstract": "We introduce a highly robust GAN-based framework for digitizing a normalized\n3D avatar of a person from a single unconstrained photo. While the input image\ncan be of a smiling person or taken in extreme lighting conditions, our method\ncan reliably produce a high-quality textured model of a person's face in\nneutral expression and skin textures under diffuse lighting condition.\nCutting-edge 3D face reconstruction methods use non-linear morphable face\nmodels combined with GAN-based decoders to capture the likeness and details of\na person but fail to produce neutral head models with unshaded albedo textures\nwhich is critical for creating relightable and animation-friendly avatars for\nintegration in virtual environments. The key challenges for existing methods to\nwork is the lack of training and ground truth data containing normalized 3D\nfaces. We propose a two-stage approach to address this problem. First, we adopt\na highly robust normalized 3D face generator by embedding a non-linear\nmorphable face model into a StyleGAN2 network. This allows us to generate\ndetailed but normalized facial assets. This inference is then followed by a\nperceptual refinement step that uses the generated assets as regularization to\ncope with the limited available training samples of normalized faces. We\nfurther introduce a Normalized Face Dataset, which consists of a combination\nphotogrammetry scans, carefully selected photographs, and generated fake people\nwith neutral expressions in diffuse lighting conditions. While our prepared\ndataset contains two orders of magnitude less subjects than cutting edge\nGAN-based 3D facial reconstruction methods, we show that it is possible to\nproduce high-quality normalized face models for very challenging unconstrained\ninput images, and demonstrate superior performance to the current\nstate-of-the-art.",
    "descriptor": "\nComments: Accepted to CVPR 2021\n",
    "authors": [
      "Huiwen Luo",
      "Koki Nagano",
      "Han-Wei Kung",
      "Mclean Goldwhite",
      "Qingguo Xu",
      "Zejian Wang",
      "Lingyu Wei",
      "Liwen Hu",
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.11423"
  },
  {
    "id": "arXiv:2106.11424",
    "title": "Hardness of Samples Is All You Need: Protecting Deep Learning Models  Using Hardness of Samples",
    "abstract": "Several recent studies have shown that Deep Neural Network (DNN)-based\nclassifiers are vulnerable against model extraction attacks. In model\nextraction attacks, an adversary exploits the target classifier to create a\nsurrogate classifier imitating the target classifier with respect to some\ncriteria. In this paper, we investigate the hardness degree of samples and\ndemonstrate that the hardness degree histogram of model extraction attacks\nsamples is distinguishable from the hardness degree histogram of normal\nsamples. Normal samples come from the target classifier's training data\ndistribution. As the training process of DNN-based classifiers is done in\nseveral epochs, we can consider this process as a sequence of subclassifiers so\nthat each subclassifier is created at the end of an epoch. We use the sequence\nof subclassifiers to calculate the hardness degree of samples. We investigate\nthe relation between hardness degree of samples and the trust in the classifier\noutputs. We propose Hardness-Oriented Detection Approach (HODA) to detect the\nsample sequences of model extraction attacks. The results demonstrate that HODA\ncan detect the sample sequences of model extraction attacks with a high success\nrate by only watching 100 attack samples. We also investigate the hardness\ndegree of adversarial examples and indicate that the hardness degree histogram\nof adversarial examples is distinct from the hardness degree histogram of\nnormal samples.",
    "descriptor": "\nComments: 19 pages, 9 figures, 9 tables\n",
    "authors": [
      "Amir Mahdi Sadeghzadeh",
      "Faezeh Dehghan",
      "Amir Mohammad Sobhanian",
      "Rasool Jalili"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.11424"
  },
  {
    "id": "arXiv:2106.11425",
    "title": "Strong Convergence of a GBM Based Tamed Integrator for SDEs and an  Adaptive Implementation",
    "abstract": "We introduce a tamed exponential time integrator which exploits linear terms\nin both the drift and diffusion for Stochastic Differential Equations (SDEs)\nwith a one sided globally Lipschitz drift term. Strong convergence of the\nproposed scheme is proved, exploiting the boundedness of the geometric Brownian\nmotion (GBM) and we establish order 1 convergence for linear diffusion terms.\nIn our implementation we illustrate the efficiency of the proposed scheme\ncompared to existing fixed step methods and utilize it in an adaptive time\nstepping scheme. Furthermore we extend the method to nonlinear diffusion terms\nand show it remains competitive. The efficiency of these GBM based approaches\nare illustrated by considering some well-known SDE models.",
    "descriptor": "",
    "authors": [
      "Utku Erdogan",
      "Gabriel J. Lord"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11425"
  },
  {
    "id": "arXiv:2106.11426",
    "title": "Efficient Inference via Universal LSH Kernel",
    "abstract": "Large machine learning models achieve unprecedented performance on various\ntasks and have evolved as the go-to technique. However, deploying these compute\nand memory hungry models on resource constraint environments poses new\nchallenges. In this work, we propose mathematically provable Representer\nSketch, a concise set of count arrays that can approximate the inference\nprocedure with simple hashing computations and aggregations. Representer Sketch\nbuilds upon the popular Representer Theorem from kernel literature, hence the\nname, providing a generic fundamental alternative to the problem of efficient\ninference that goes beyond the popular approach such as quantization, iterative\npruning and knowledge distillation. A neural network function is transformed to\nits weighted kernel density representation, which can be very efficiently\nestimated with our sketching algorithm. Empirically, we show that Representer\nSketch achieves up to 114x reduction in storage requirement and 59x reduction\nin computation complexity without any drop in accuracy.",
    "descriptor": "",
    "authors": [
      "Zichang Liu",
      "Benjamin Coleman",
      "Anshumali Shrivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.11426"
  },
  {
    "id": "arXiv:2106.11430",
    "title": "ConvDySAT: Deep Neural Representation Learning on Dynamic Graphs via  Self-Attention and Convolutional Neural Networks",
    "abstract": "Learning node representations on temporal graphs is a fundamental step to\nlearn real-word dynamic graphs efficiently. Real-world graphs have the nature\nof continuously evolving over time, such as changing edges weights, removing\nand adding nodes and appearing and disappearing of edges, while previous graph\nrepresentation learning methods focused generally on static graphs. We present\nConvDySAT as an enhancement of DySAT, one of the state-of-the-art dynamic\nmethods, by augmenting convolution neural networks with the self-attention\nmechanism, the employed method in DySAT to express the structural and temporal\nevolution. We conducted single-step link prediction on a communication network\nand rating network, Experimental results show significant performance gains for\nConvDySAT over various state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Ahmad Hafez",
      "Atulya Praphul",
      "Yousef Jaradt",
      "Ezani Godwin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11430"
  },
  {
    "id": "arXiv:2106.11437",
    "title": "Incremental Deep Neural Network Learning using Classification Confidence  Thresholding",
    "abstract": "Most modern neural networks for classification fail to take into account the\nconcept of the unknown. Trained neural networks are usually tested in an\nunrealistic scenario with only examples from a closed set of known classes. In\nan attempt to develop a more realistic model, the concept of working in an open\nset environment has been introduced. This in turn leads to the concept of\nincremental learning where a model with its own architecture and initial\ntrained set of data can identify unknown classes during the testing phase and\nautonomously update itself if evidence of a new class is detected. Some\nproblems that arise in incremental learning are inefficient use of resources to\nretrain the classifier repeatedly and the decrease of classification accuracy\nas multiple classes are added over time. This process of instantiating new\nclasses is repeated as many times as necessary, accruing errors. To address\nthese problems, this paper proposes the Classification Confidence Threshold\napproach to prime neural networks for incremental learning to keep accuracies\nhigh by limiting forgetting. A lean method is also used to reduce resources\nused in the retraining of the neural network. The proposed method is based on\nthe idea that a network is able to incrementally learn a new class even when\nexposed to a limited number samples associated with the new class. This method\ncan be applied to most existing neural networks with minimal changes to network\narchitecture.",
    "descriptor": "\nComments: Accepted to IEEE TNNLS\n",
    "authors": [
      "Justin Leo",
      "Jugal Kalita"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11437"
  },
  {
    "id": "arXiv:2106.11438",
    "title": "Instance-Optimal Compressed Sensing via Posterior Sampling",
    "abstract": "We characterize the measurement complexity of compressed sensing of signals\ndrawn from a known prior distribution, even when the support of the prior is\nthe entire space (rather than, say, sparse vectors). We show for Gaussian\nmeasurements and \\emph{any} prior distribution on the signal, that the\nposterior sampling estimator achieves near-optimal recovery guarantees.\nMoreover, this result is robust to model mismatch, as long as the distribution\nestimate (e.g., from an invertible generative model) is close to the true\ndistribution in Wasserstein distance. We implement the posterior sampling\nestimator for deep generative priors using Langevin dynamics, and empirically\nfind that it produces accurate estimates with more diversity than MAP.",
    "descriptor": "",
    "authors": [
      "Ajil Jalal",
      "Sushrut Karmalkar",
      "Alexandros G. Dimakis",
      "Eric Price"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11438"
  },
  {
    "id": "arXiv:2106.11445",
    "title": "KEA: Tuning an Exabyte-Scale Data Infrastructure",
    "abstract": "Microsoft's internal big-data infrastructure is one of the largest in the\nworld -- with over 300k machines running billions of tasks from over 0.6M daily\njobs. Operating this infrastructure is a costly and complex endeavor, and\nefficiency is paramount. In fact, for over 15 years, a dedicated engineering\nteam has tuned almost every aspect of this infrastructure, achieving\nstate-of-the-art efficiency (>60% average CPU utilization across all clusters).\nDespite rich telemetry and strong expertise, faced with evolving\nhardware/software/workloads this manual tuning approach had reached its limit\n-- we had plateaued.\nIn this paper, we present KEA, a multi-year effort to automate our tuning\nprocesses to be fully data/model-driven. KEA leverages a mix of domain\nknowledge and principled data science to capture the essence of our cluster\ndynamic behavior in a set of machine learning (ML) models based on collected\nsystem data. These models power automated optimization procedures for parameter\ntuning, and inform our leadership in critical decisions around engineering and\ncapacity management (such as hardware and data center design, software\ninvestments, etc.). We combine \"observational\" tuning (i.e., using models to\npredict system behavior without direct experimentation) with judicious use of\n\"flighting\" (i.e., conservative testing in production). This allows us to\nsupport a broad range of applications that we discuss in this paper.\nKEA continuously tunes our cluster configurations and is on track to save\nMicrosoft tens of millions of dollars per year. At the best of our knowledge,\nthis paper is the first to discuss research challenges and practical learnings\nthat emerge when tuning an exabyte-scale data infrastructure.",
    "descriptor": "",
    "authors": [
      "Yiwen Zhu",
      "Subru Krishnan",
      "Konstantinos Karanasos",
      "Isha Tarte",
      "Conor Power",
      "Abhishek Modi",
      "Manoj Kumar",
      "Deli Zhang",
      "Kartheek Muthyala",
      "Nick Jurgens",
      "Sarvesh Sakalanaga",
      "Sudhir Darbha",
      "Minu Iyer",
      "Ankita Agarwal",
      "Carlo Curino"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.11445"
  },
  {
    "id": "arXiv:2106.11454",
    "title": "A Competitive Analysis of Online Multi-Agent Path Finding",
    "abstract": "We study online Multi-Agent Path Finding (MAPF), where new agents are\nconstantly revealed over time and all agents must find collision-free paths to\ntheir given goal locations. We generalize existing complexity results of\n(offline) MAPF to online MAPF. We classify online MAPF algorithms into\ndifferent categories based on (1) controllability (the set of agents that they\ncan plan paths for at each time) and (2) rationality (the quality of paths they\nplan) and study the relationships between them. We perform a competitive\nanalysis for each category of online MAPF algorithms with respect to\ncommonly-used objective functions. We show that a naive algorithm that routes\nnewly-revealed agents one at a time in sequence achieves a competitive ratio\nthat is asymptotically bounded from both below and above by the number of\nagents with respect to flowtime and makespan. We then show a counter-intuitive\nresult that, if rerouting of previously-revealed agents is not allowed, any\nrational online MAPF algorithms, including ones that plan optimal paths for all\nnewly-revealed agents, have the same asymptotic competitive ratio as the naive\nalgorithm, even on 2D 4-neighbor grids. We also derive constant lower bounds on\nthe competitive ratio of any rational online MAPF algorithms that allow\nrerouting. The results thus provide theoretical insights into the effectiveness\nof using MAPF algorithms in an online setting for the first time.",
    "descriptor": "\nComments: Published at ICAPS 2021\n",
    "authors": [
      "Hang Ma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11454"
  },
  {
    "id": "arXiv:2106.11455",
    "title": "KaggleDBQA: Realistic Evaluation of Text-to-SQL Parsers",
    "abstract": "The goal of database question answering is to enable natural language\nquerying of real-life relational databases in diverse application domains.\nRecently, large-scale datasets such as Spider and WikiSQL facilitated novel\nmodeling techniques for text-to-SQL parsing, improving zero-shot generalization\nto unseen databases. In this work, we examine the challenges that still prevent\nthese techniques from practical deployment. First, we present KaggleDBQA, a new\ncross-domain evaluation dataset of real Web databases, with domain-specific\ndata types, original formatting, and unrestricted questions. Second, we\nre-examine the choice of evaluation tasks for text-to-SQL parsers as applied in\nreal-life settings. Finally, we augment our in-domain evaluation task with\ndatabase documentation, a naturally occurring source of implicit domain\nknowledge. We show that KaggleDBQA presents a challenge to state-of-the-art\nzero-shot parsers but a more realistic evaluation setting and creative use of\nassociated database documentation boosts their accuracy by over 13.2%, doubling\ntheir performance.",
    "descriptor": "\nComments: Published as a conference paper at ACL-IJCNLP 2021\n",
    "authors": [
      "Chia-Hsuan Lee",
      "Oleksandr Polozov",
      "Matthew Richardson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.11455"
  },
  {
    "id": "arXiv:2106.11456",
    "title": "Querying in the Age of Graph Databases and Knowledge Graphs",
    "abstract": "Graphs have become the best way we know of representing knowledge. The\ncomputing community has investigated and developed the support for managing\ngraphs by means of digital technology. Graph databases and knowledge graphs\nsurface as the most successful solutions to this program. This tutorial will\nprovide a conceptual map of the data management tasks underlying these\ndevelopments, paying particular attention to data models and query languages\nfor graphs.",
    "descriptor": "",
    "authors": [
      "Marcelo Arenas",
      "Claudio Gutierrez",
      "Juan F. Sequeda"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11456"
  },
  {
    "id": "arXiv:2106.11461",
    "title": "Assertion Based Functional Verification of March Algorithm Based MBIST  Controller",
    "abstract": "The thesis work presents assertion based functional verification of RTL\nrepresentation of a digital design. The MBIST controller is designed based on a\nmemory testing March algorithm. This March algorithm is a little modified March\nC algorithm which is modified by adding a paused element to test memory data\nretention faults. In assertion based functional verification, creation of\nverification plan, for MBIST controller RTL model and the implementation &\nsimulation of the verification plan using System-Verilog and Synopsys-VCS are\ndone. In ABV, verification plan includes the MBIST controller design and\nfunctional specification, functional coverage goals, code coverage goals, and\nassertions. Assertions are used to check the errors in RTL model of MBIST\ncontroller and to provide the functionality coverage. Functional coverage\nmetrics are used to track the level or quality of verification. Most of the\nfunctional metrics score approximately reached the planned goal of 100 % which\nis planned in the verification plan. The designed MBIST controller is verified\nagainst the intended features. ABV approach helped to make the verification and\ndesign process efficient and less time-consuming by finding the bugs,\nexercising the corner cases in the design, and using the directed test cases in\na small design. ABV helped to write directed and efficient test cases (25)\nwhich are approx 32 % less than the use of maximum possible random test cases\n(88) for designed MBIST controller with 100% assertion coverage and\napproximately equal total functional coverage, i.e., 97 % approx. In this way,\nABV helped to fasten the design and verification process with better quality\nand assurance of correct functionality of MBIST controller after the\nintegration in MBIST architecture.",
    "descriptor": "\nComments: 108 pages\n",
    "authors": [
      "Ashwani Kumar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.11461"
  },
  {
    "id": "arXiv:2106.11463",
    "title": "A Logical Neural Network Structure With More Direct Mapping From Logical  Relations",
    "abstract": "Logical relations widely exist in human activities. Human use them for making\njudgement and decision according to various conditions, which are embodied in\nthe form of \\emph{if-then} rules. As an important kind of cognitive\nintelligence, it is prerequisite of representing and storing logical relations\nrightly into computer systems so as to make automatic judgement and decision,\nespecially for high-risk domains like medical diagnosis. However, current\nnumeric ANN (Artificial Neural Network) models are good at perceptual\nintelligence such as image recognition while they are not good at cognitive\nintelligence such as logical representation, blocking the further application\nof ANN. To solve it, researchers have tried to design logical ANN models to\nrepresent and store logical relations. Although there are some advances in this\nresearch area, recent works still have disadvantages because the structures of\nthese logical ANN models still don't map more directly with logical relations\nwhich will cause the corresponding logical relations cannot be read out from\ntheir network structures. Therefore, in order to represent logical relations\nmore clearly by the neural network structure and to read out logical relations\nfrom it, this paper proposes a novel logical ANN model by designing the new\nlogical neurons and links in demand of logical representation. Compared with\nthe recent works on logical ANN models, this logical ANN model has more clear\ncorresponding with logical relations using the more direct mapping method\nherein, thus logical relations can be read out following the connection\npatterns of the network structure. Additionally, less neurons are used.",
    "descriptor": "",
    "authors": [
      "Gang Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11463"
  },
  {
    "id": "arXiv:2106.11466",
    "title": "Gait analysis with curvature maps: A simulation study",
    "abstract": "Gait analysis is an important aspect of clinical investigation for detecting\nneurological and musculoskeletal disorders and assessing the global health of a\npatient. In this paper we propose to focus our attention on extracting relevant\ncurvature information from the body surface provided by a depth camera. We\nassumed that the 3D mesh was made available in a previous step and demonstrated\nhow curvature maps could be useful to assess asymmetric anomalies with two\nsimple simulated abnormal gaits compared with a normal one. This research set\nthe grounds for the future development of a curvature-based gait analysis\nsystem for healthcare professionals.",
    "descriptor": "\nComments: 4 pages, 5 figures\n",
    "authors": [
      "Khac Chinh Tran",
      "Marc Daniel",
      "Jean Meunier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11466"
  },
  {
    "id": "arXiv:2106.11467",
    "title": "Multimodal trajectory forecasting based on discrete heat map",
    "abstract": "In Argoverse motion forecasting competition, the task is to predict the\nprobabilistic future trajectory distribution for the interested targets in the\ntraffic scene. We use vectorized lane map and 2 s targets' history trajectories\nas input. Then the model outputs 6 forecasted trajectories with probability for\neach target.",
    "descriptor": "",
    "authors": [
      "Jingni Yuan",
      "Jianyun Xu",
      "Yushi Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11467"
  },
  {
    "id": "arXiv:2106.11469",
    "title": "Real-Time XFEL Data Analysis at SLAC and NERSC: a Trial Run of Nascent  Exascale Experimental Data Analysis",
    "abstract": "X-ray scattering experiments using Free Electron Lasers (XFELs) are a\npowerful tool to determine the molecular structure and function of unknown\nsamples (such as COVID-19 viral proteins). XFEL experiments are a challenge to\ncomputing in two ways: i) due to the high cost of running XFELs, a fast\nturnaround time from data acquisition to data analysis is essential to make\ninformed decisions on experimental protocols; ii) data collection rates are\ngrowing exponentially, requiring new scalable algorithms. Here we report our\nexperiences analyzing data from two experiments at the Linac Coherent Light\nSource (LCLS) during September 2020. Raw data were analyzed on NERSC's Cori\nXC40 system, using the Superfacility paradigm: our workflow automatically moves\nraw data between LCLS and NERSC, where it is analyzed using the software\npackage CCTBX. We achieved real time data analysis with a turnaround time from\ndata acquisition to full molecular reconstruction in as little as 10 min --\nsufficient time for the experiment's operators to make informed decisions. By\nhosting the data analysis on Cori, and by automating LCLS-NERSC\ninteroperability, we achieved a data analysis rate which matches the data\nacquisition rate. Completing data analysis with 10 mins is a first for XFEL\nexperiments and an important milestone if we are to keep up with data\ncollection trends.",
    "descriptor": "",
    "authors": [
      "Johannes P. Blaschke",
      "Aaron S. Brewster",
      "Daniel W. Paley",
      "Derek Mendez",
      "Nicholas K. Sauter",
      "Wilko Kr\u00f6ger",
      "Murali Shankar",
      "Bjoern Enders",
      "Deborah Bard"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.11469"
  },
  {
    "id": "arXiv:2106.11473",
    "title": "Sequential Late Fusion Technique for Multi-modal Sentiment Analysis",
    "abstract": "Multi-modal sentiment analysis plays an important role for providing better\ninteractive experiences to users. Each modality in multi-modal data can provide\ndifferent viewpoints or reveal unique aspects of a user's emotional state. In\nthis work, we use text, audio and visual modalities from MOSI dataset and we\npropose a novel fusion technique using a multi-head attention LSTM network.\nFinally, we perform a classification task and evaluate its performance.",
    "descriptor": "\nComments: 2 pages, 1 figure, 1 table\n",
    "authors": [
      "Debapriya Banerjee",
      "Fotios Lygerakis",
      "Fillia Makedon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11473"
  },
  {
    "id": "arXiv:2106.11478",
    "title": "An Alternative Auxiliary Task for Enhancing Image Classification",
    "abstract": "Image reconstruction is likely the most predominant auxiliary task for image\nclassification. In this paper, we investigate ``estimating the Fourier\nTransform of the input image\" as a potential alternative auxiliary task, in the\nhope that it may further boost the performances on the primary task or\nintroduce novel constraints not well covered by image reconstruction. We\nexperimented with five popular classification architectures on the CIFAR-10\ndataset, and the empirical results indicated that our proposed auxiliary task\ngenerally improves the classification accuracy. More notably, the results\nshowed that in certain cases our proposed auxiliary task may enhance the\nclassifiers' resistance to adversarial attacks generated using the fast\ngradient sign method.",
    "descriptor": "\nComments: Work in progress. It will be very much appreciated if you can give suggestions on additional experiments and analyses that may improve this manuscript\n",
    "authors": [
      "Chen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11478"
  },
  {
    "id": "arXiv:2106.11480",
    "title": "VoxelEmbed: 3D Instance Segmentation and Tracking with Voxel Embedding  based Deep Learning",
    "abstract": "Recent advances in bioimaging have provided scientists a superior high\nspatial-temporal resolution to observe dynamics of living cells as 3D\nvolumetric videos. Unfortunately, the 3D biomedical video analysis is lagging,\nimpeded by resource insensitive human curation using off-the-shelf 3D analytic\ntools. Herein, biologists often need to discard a considerable amount of rich\n3D spatial information by compromising on 2D analysis via maximum intensity\nprojection. Recently, pixel embedding-based cell instance segmentation and\ntracking provided a neat and generalizable computing paradigm for understanding\ncellular dynamics. In this work, we propose a novel spatial-temporal\nvoxel-embedding (VoxelEmbed) based learning method to perform simultaneous cell\ninstance segmenting and tracking on 3D volumetric video sequences. Our\ncontribution is in four-fold: (1) The proposed voxel embedding generalizes the\npixel embedding with 3D context information; (2) Present a simple multi-stream\nlearning approach that allows effective spatial-temporal embedding; (3)\nAccomplished an end-to-end framework for one-stage 3D cell instance\nsegmentation and tracking without heavy parameter tuning; (4) The proposed 3D\nquantification is memory efficient via a single GPU with 12 GB memory. We\nevaluate our VoxelEmbed method on four 3D datasets (with different cell types)\nfrom the ISBI Cell Tracking Challenge. The proposed VoxelEmbed method achieved\nconsistent superior overall performance (OP) on two densely annotated datasets.\nThe performance is also competitive on two sparsely annotated cohorts with\n20.6% and 2% of data-set having segmentation annotations. The results\ndemonstrate that the VoxelEmbed method is a generalizable and memory-efficient\nsolution.",
    "descriptor": "",
    "authors": [
      "Mengyang Zhao",
      "Quan Liu",
      "Aadarsh Jha",
      "Ruining Deng",
      "Tianyuan Yao",
      "Anita Mahadevan-Jansen",
      "Matthew J.Tyska",
      "Bryan A. Millis",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.11480"
  },
  {
    "id": "arXiv:2106.11481",
    "title": "SeqNetVLAD vs PointNetVLAD: Image Sequence vs 3D Point Clouds for  Day-Night Place Recognition",
    "abstract": "Place Recognition is a crucial capability for mobile robot localization and\nnavigation. Image-based or Visual Place Recognition (VPR) is a challenging\nproblem as scene appearance and camera viewpoint can change significantly when\nplaces are revisited. Recent VPR methods based on ``sequential\nrepresentations'' have shown promising results as compared to traditional\nsequence score aggregation or single image based techniques. In parallel to\nthese endeavors, 3D point clouds based place recognition is also being explored\nfollowing the advances in deep learning based point cloud processing. However,\na key question remains: is an explicit 3D structure based place representation\nalways superior to an implicit ``spatial'' representation based on sequence of\nRGB images which can inherently learn scene structure. In this extended\nabstract, we attempt to compare these two types of methods by considering a\nsimilar ``metric span'' to represent places. We compare a 3D point cloud based\nmethod (PointNetVLAD) with image sequence based methods (SeqNet and others) and\nshowcase that image sequence based techniques approach, and can even surpass,\nthe performance achieved by point cloud based methods for a given metric span.\nThese performance variations can be attributed to differences in data richness\nof input sensors as well as data accumulation strategies for a mobile robot.\nWhile a perfect apple-to-apple comparison may not be feasible for these two\ndifferent modalities, the presented comparison takes a step in the direction of\nanswering deeper questions regarding spatial representations, relevant to\nseveral applications like Autonomous Driving and Augmented/Virtual Reality.\nSource code available publicly https://github.com/oravus/seqNet.",
    "descriptor": "\nComments: Accepted to CVPR 2021 Workshop on 3D Vision and Robotics (3DVR). this https URL\n",
    "authors": [
      "Sourav Garg",
      "Michael Milford"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11481"
  },
  {
    "id": "arXiv:2106.11482",
    "title": "Wallpaper Texture Generation and Style Transfer Based on Multi-label  Semantics",
    "abstract": "Textures contain a wealth of image information and are widely used in various\nfields such as computer graphics and computer vision. With the development of\nmachine learning, the texture synthesis and generation have been greatly\nimproved. As a very common element in everyday life, wallpapers contain a\nwealth of texture information, making it difficult to annotate with a simple\nsingle label. Moreover, wallpaper designers spend significant time to create\ndifferent styles of wallpaper. For this purpose, this paper proposes to\ndescribe wallpaper texture images by using multi-label semantics. Based on\nthese labels and generative adversarial networks, we present a framework for\nperception driven wallpaper texture generation and style transfer. In this\nframework, a perceptual model is trained to recognize whether the wallpapers\nproduced by the generator network are sufficiently realistic and have the\nattribute designated by given perceptual description; these multi-label\nsemantic attributes are treated as condition variables to generate wallpaper\nimages. The generated wallpaper images can be converted to those with\nwell-known artist styles using CycleGAN. Finally, using the aesthetic\nevaluation method, the generated wallpaper images are quantitatively measured.\nThe experimental results demonstrate that the proposed method can generate\nwallpaper textures conforming to human aesthetics and have artistic\ncharacteristics.",
    "descriptor": "\nComments: IEEE Transactions on Circuits and Systems for Video Technology\n",
    "authors": [
      "Ying Gao",
      "Xiaohan Feng",
      "Tiange Zhang",
      "Eric Rigall",
      "Huiyu Zhou",
      "Lin Qi",
      "Junyu Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11482"
  },
  {
    "id": "arXiv:2106.11483",
    "title": "A Comprehensive Exploration of Pre-training Language Models",
    "abstract": "Recently, the development of pre-trained language models has brought natural\nlanguage processing (NLP) tasks to the new state-of-the-art. In this paper we\nexplore the efficiency of various pre-trained language models. We pre-train a\nlist of transformer-based models with the same amount of text and the same\ntraining steps. The experimental results shows that the most improvement upon\nthe origin BERT is adding the RNN-layer to capture more contextual information\nfor the transformer-encoder layers.",
    "descriptor": "\nComments: working in progress\n",
    "authors": [
      "Tong Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11483"
  },
  {
    "id": "arXiv:2106.11485",
    "title": "Spatial-Temporal Super-Resolution of Satellite Imagery via Conditional  Pixel Synthesis",
    "abstract": "High-resolution satellite imagery has proven useful for a broad range of\ntasks, including measurement of global human population, local economic\nlivelihoods, and biodiversity, among many others. Unfortunately,\nhigh-resolution imagery is both infrequently collected and expensive to\npurchase, making it hard to efficiently and effectively scale these downstream\ntasks over both time and space. We propose a new conditional pixel synthesis\nmodel that uses abundant, low-cost, low-resolution imagery to generate accurate\nhigh-resolution imagery at locations and times in which it is unavailable. We\nshow that our model attains photo-realistic sample quality and outperforms\ncompeting baselines on a key downstream task -- object counting -- particularly\nin geographic locations where conditions on the ground are changing rapidly.",
    "descriptor": "",
    "authors": [
      "Yutong He",
      "Dingjie Wang",
      "Nicholas Lai",
      "William Zhang",
      "Chenlin Meng",
      "Marshall Burke",
      "David B. Lobell",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11485"
  },
  {
    "id": "arXiv:2106.11486",
    "title": "Unsupervised Embedding Adaptation via Early-Stage Feature Reconstruction  for Few-Shot Classification",
    "abstract": "We propose unsupervised embedding adaptation for the downstream few-shot\nclassification task. Based on findings that deep neural networks learn to\ngeneralize before memorizing, we develop Early-Stage Feature Reconstruction\n(ESFR) -- a novel adaptation scheme with feature reconstruction and\ndimensionality-driven early stopping that finds generalizable features.\nIncorporating ESFR consistently improves the performance of baseline methods on\nall standard settings, including the recently proposed transductive method.\nESFR used in conjunction with the transductive method further achieves\nstate-of-the-art performance on mini-ImageNet, tiered-ImageNet, and CUB;\nespecially with 1.2%~2.0% improvements in accuracy over the previous best\nperforming method on 1-shot setting.",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Dong Hoon Lee",
      "Sae-Young Chung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11486"
  },
  {
    "id": "arXiv:2106.11487",
    "title": "Routine Clustering of Mobile Sensor Data Facilitates Psychotic Relapse  Prediction in Schizophrenia Patients",
    "abstract": "We aim to develop clustering models to obtain behavioral representations from\ncontinuous multimodal mobile sensing data towards relapse prediction tasks. The\nidentified clusters could represent different routine behavioral trends related\nto daily living of patients as well as atypical behavioral trends associated\nwith impending relapse.\nWe used the mobile sensing data obtained in the CrossCheck project for our\nanalysis. Continuous data from six different mobile sensing-based modalities\n(e.g. ambient light, sound/conversation, acceleration etc.) obtained from a\ntotal of 63 schizophrenia patients, each monitored for up to a year, were used\nfor the clustering models and relapse prediction evaluation. Two clustering\nmodels, Gaussian Mixture Model (GMM) and Partition Around Medoids (PAM), were\nused to obtain behavioral representations from the mobile sensing data. The\nfeatures obtained from the clustering models were used to train and evaluate a\npersonalized relapse prediction model using Balanced Random Forest. The\npersonalization was done by identifying optimal features for a given patient\nbased on a personalization subset consisting of other patients who are of\nsimilar age.\nThe clusters identified using the GMM and PAM models were found to represent\ndifferent behavioral patterns (such as clusters representing sedentary days,\nactive but with low communications days, etc.). Significant changes near the\nrelapse periods were seen in the obtained behavioral representation features\nfrom the clustering models. The clustering model based features, together with\nother features characterizing the mobile sensing data, resulted in an F2 score\nof 0.24 for the relapse prediction task in a leave-one-patient-out evaluation\nsetting. This obtained F2 score is significantly higher than a random\nclassification baseline with an average F2 score of 0.042.",
    "descriptor": "",
    "authors": [
      "Joanne Zhou",
      "Bishal Lamichhane",
      "Dror Ben-Zeev",
      "Andrew Campbell",
      "Akane Sano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11487"
  },
  {
    "id": "arXiv:2106.11490",
    "title": "High Resolution Radar Sensing with Compressive Illumination",
    "abstract": "We present a compressive radar design that combines multitone linear\nfrequency modulated (LFM) waveforms in the transmitter with a classical stretch\nprocessor and sub-Nyquist sampling in the receiver. The proposed compressive\nillumination scheme has fewer random elements resulting in reduced storage and\ncomplexity for implementation than previously proposed compressive radar\ndesigns based on stochastic waveforms. We analyze this illumination scheme for\nthe task of a joint range-angle of arrival estimation in the multi-input and\nmulti-output (MIMO) radar system. We present recovery guarantees for the\nproposed illumination technique. We show that for a sufficiently large number\nof modulating tones, the system achieves high-resolution in range and\nsuccessfully recovers the range and angle-of-arrival of targets in a sparse\nscene. Furthermore, we present an algorithm that estimates the target range,\nangle of arrival, and scattering coefficient in the continuum. Finally, we\npresent simulation results to illustrate the recovery performance as a function\nof system parameters.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1508.07969\n",
    "authors": [
      "Nithin Sugavanam",
      "Siddharth Baskar",
      "Emre Ertin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.11490"
  },
  {
    "id": "arXiv:2106.11491",
    "title": "Well-Founded Extensive Games with Perfect Information",
    "abstract": "We consider extensive games with perfect information with well-founded game\ntrees and study the problems of existence and of characterization of the sets\nof subgame perfect equilibria in these games. We also provide such\ncharacterizations for two classes of these games in which subgame perfect\nequilibria exist: two-player zero-sum games with, respectively, two and three\noutcomes.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Krzysztof R. Apt",
      "Sunil Simon"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.11491"
  },
  {
    "id": "arXiv:2106.11492",
    "title": "Uncertainty-Based Semantics for Multi-Agent Knowing How Logics",
    "abstract": "We introduce a new semantics for a multi-agent epistemic operator of knowing\nhow, based on an indistinguishability relation between plans. Our proposal is,\narguably, closer to the standard presentation of knowing that modalities in\nclassical epistemic logic. We study the relationship between this semantics and\nprevious approaches, showing that our setting is general enough to capture\nthem. We also define a sound and complete axiomatization, and investigate the\ncomputational complexity of its model checking and satisfiability problems.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Carlos Areces",
      "Raul Fervari",
      "Andr\u00e9s R. Saravia",
      "Fernando R. Vel\u00e1zquez-Quesada"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.11492"
  },
  {
    "id": "arXiv:2106.11493",
    "title": "Revisiting Epistemic Logic with Names",
    "abstract": "This paper revisits the multi-agent epistemic logic presented in [10], where\nagents and sets of agents are replaced by abstract, intensional \"names\". We\nmake three contributions. First, we study its model theory, providing adequate\nnotions of bisimulation and frame morphisms, and use them to study the logic's\nexpressive power and definability. Second, we show that the logic has a natural\nneighborhood semantics, which in turn allows to show that the axiomatization in\n[10] does not rely on possibly controversial introspective properties of\nknowledge. Finally, we extend the logic with common and distributed knowledge\noperators, and provide a sound and complete axiomatization for each of these\nextensions. These results together put the original epistemic logic with names\nin a more modern context and opens the door for a logical analysis of epistemic\nphenomena where group membership is uncertain or variable.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Marta B\u00edlkov\u00e1",
      "Zo\u00e9 Christoff",
      "Olivier Roy"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.11493"
  },
  {
    "id": "arXiv:2106.11494",
    "title": "Language-based Decisions",
    "abstract": "In Savage's classic decision-theoretic framework, actions are formally\ndefined as functions from states to outcomes. But where do the state space and\noutcome space come from? Expanding on recent work by Blume, Easley, and Halpern\n(BEH), we consider a language-based framework in which actions are identified\nwith (conditional) descriptions in a simple underlying language, while states\nand outcomes (along with probabilities and utilities) are constructed as part\nof a representation theorem. Our work expands the role of language from that of\nBEH by using it not only for the conditions that determine which actions are\ntaken, but also the effects. More precisely, we take the set of actions to be\nbuilt from those of the form \"do(phi)\", for formulas phi in the underlying\nlanguage. This presents a problem: how do we interpret the result of do(phi)\nwhen phi is underspecified (i.e., compatible with multiple states)? We answer\nthis using tools familiar from the semantics of counterfactuals: roughly\nspeaking, do(phi) maps each state to the \"closest\" phi-state. This notion of\n\"closest\" is also something we construct as part of the representation theorem;\nin effect, then, we prove that (under appropriate assumptions) the agent is\nacting as if each underspecified action is first made definite and then\nevaluated (i.e., by maximizing expected utility). Of course, actions in the\nreal world are often not presented in a fully precise manner, yet agents reason\nabout and form preferences among them all the same. Our work brings the\nabstract tools of decision theory into closer contact with such real-world\nscenarios.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Adam Bjorndahl",
      "Joseph Y. Halpern"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.11494"
  },
  {
    "id": "arXiv:2106.11495",
    "title": "An Awareness Epistemic Framework for Belief, Argumentation and Their  Dynamics",
    "abstract": "The notion of argumentation and the one of belief stand in a problematic\nrelation to one another. On the one hand, argumentation is crucial for belief\nformation: as the outcome of a process of arguing, an agent might come to\n(justifiably) believe that something is the case. On the other hand, beliefs\nare an input for argument evaluation: arguments with believed premisses are to\nbe considered as strictly stronger by the agent to arguments whose premisses\nare not believed. An awareness epistemic logic that captures qualified versions\nof both principles was recently proposed in the literature. This paper extends\nthat logic in three different directions. First, we try to improve its\nconceptual grounds, by depicting its philosophical foundations, critically\ndiscussing some of its design choices and exploring further possibilities.\nSecond, we provide a (heretofore missing) completeness theorem for the basic\nfragment of the logic. Third, we study, using techniques from dynamic epistemic\nlogic, how different forms of information change can be captured in the\nframework.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886. The research activity of Antonio Yuste-Ginel has been partially funded by the predoctoral grant no. MECD-FPU 2016/04113 of Ministerio de Universidades (Spain)\n",
    "authors": [
      "Alfredo Burrieza",
      "Antonio Yuste-Ginel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.11495"
  },
  {
    "id": "arXiv:2106.11496",
    "title": "Collective Argumentation: The Case of Aggregating Support-Relations of  Bipolar Argumentation Frameworks",
    "abstract": "In many real-life situations that involve exchanges of arguments, individuals\nmay differ on their assessment of which supports between the arguments are in\nfact justified, i.e., they put forward different support-relations. When\nconfronted with such situations, we may wish to aggregate individuals'\nargumentation views on support-relations into a collective view, which is\nacceptable to the group. In this paper, we assume that under bipolar\nargumentation frameworks, individuals are equipped with a set of arguments and\na set of attacks between arguments, but with possibly different\nsupport-relations. Using the methodology in social choice theory, we analyze\nwhat semantic properties of bipolar argumentation frameworks can be preserved\nby aggregation rules during the aggregation of support-relations.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886. Accepted by the 18th conference on theoretical aspects of rationality and knowledge (TARK-2021)\n",
    "authors": [
      "Weiwei Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.11496"
  },
  {
    "id": "arXiv:2106.11497",
    "title": "De Re Updates",
    "abstract": "In this paper, we propose a lightweight yet powerful dynamic epistemic logic\nthat captures not only the distinction between de dicto and de re knowledge but\nalso the distinction between de dicto and de re updates. The logic is based on\nthe dynamified version of an epistemic language extended with the assignment\noperator borrowed from dynamic logic, following the work of Wang and Seligman\n(Proc. AiML 2018). We obtain complete axiomatizations for the counterparts of\npublic announcement logic and event-model-based DEL based on new reduction\naxioms taking care of the interactions between dynamics and assignments.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Michael Cohen",
      "Wen Tang",
      "Yanjing Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.11497"
  },
  {
    "id": "arXiv:2106.11498",
    "title": "No Finite Model Property for Logics of Quantified Announcements",
    "abstract": "Quantification over public announcements shifts the perspective from\nreasoning strictly about the results of a particular announcement to reasoning\nabout the existence of an announcement that achieves some certain epistemic\ngoal. Depending on the type of the quantification, we get different formalisms,\nthe most known of which are arbitrary public announcement logic (APAL), group\nannouncement logic (GAL), and coalition announcement logic (CAL). It has been\nan open question whether the logics have the finite model property, and in the\npaper we answer the question negatively. We also discuss how this result is\nconnected to other open questions in the field.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Hans van Ditmarsch",
      "Tim French",
      "Rustam Galimullin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.11498"
  },
  {
    "id": "arXiv:2106.11499",
    "title": "Fire!",
    "abstract": "In this paper, we provide an epistemic analysis of a simple variant of the\nfundamental consistent broadcasting primitive for byzantine fault-tolerant\nasynchronous distributed systems. Our Firing Rebels with Relay (FRR) primitive\nenables agents with a local preference for acting/not acting to trigger an\naction (FIRE) at all correct agents, in an all-or-nothing fashion. By using the\nepistemic reasoning framework for byzantine multi-agent systems introduced in\nour TARK'19 paper, we develop the necessary and sufficient state of knowledge\nthat needs to be acquired by the agents in order to FIRE. It involves eventual\ncommon hope (a modality related to belief), which we show to be attained\nalready by achieving eventual mutual hope in the case of FRR. We also identify\nsubtle variations of the necessary and sufficient state of knowledge for FRR\nfor different assumptions on the local preferences.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Krisztina Fruzsa",
      "Roman Kuznets",
      "Ulrich Schmid"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.11499"
  },
  {
    "id": "arXiv:2106.11500",
    "title": "Are the Players in an Interactive Belief Model Meta-certain of the Model  Itself?",
    "abstract": "In an interactive belief model, are the players \"commonly meta-certain\" of\nthe model itself? This paper formalizes such implicit \"common meta-certainty\"\nassumption. To that end, the paper expands the objects of players' beliefs from\nevents to functions defined on the underlying states. Then, the paper defines a\nplayer's belief-generating map: it associates, with each state, whether a\nplayer believes each event at that state. The paper formalizes what it means\nby: \"a player is (meta-)certain of her own belief-generating map\" or \"the\nplayers are (meta-)certain of the profile of belief-generating maps (i.e., the\nmodel).\" The paper shows: a player is (meta-)certain of her own\nbelief-generating map if and only if her beliefs are introspective. The players\nare commonly (meta-)certain of the model if and only if, for any event which\nsome player i believes at some state, it is common belief at the state that\nplayer i believes the event. This paper then asks whether the \"common\nmeta-certainty\" assumption is needed for an epistemic characterization of\ngame-theoretic solution concepts. The paper shows: if each player is logical\nand (meta-)certain of her own strategy and belief-generating map, then each\nplayer correctly believes her own rationality. Consequently, common belief in\nrationality alone leads to actions that survive iterated elimination of\nstrictly dominated actions.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Satoshi Fukuda"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.11500"
  },
  {
    "id": "arXiv:2106.11501",
    "title": "Knowledge from Probability",
    "abstract": "We give a probabilistic analysis of inductive knowledge and belief and\nexplore its predictions concerning knowledge about the future, about laws of\nnature, and about the values of inexactly measured quantities. The analysis\ncombines a theory of knowledge and belief formulated in terms of relations of\ncomparative normality with a probabilistic reduction of those relations. It\npredicts that only highly probable propositions are believed, and that many\nwidely held principles of belief-revision fail.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Jeremy Goodman",
      "Bernhard Salow"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11501"
  },
  {
    "id": "arXiv:2106.11502",
    "title": "Measuring Violations of Positive Involvement in Voting",
    "abstract": "In the context of computational social choice, we study voting methods that\nassign a set of winners to each profile of voter preferences. A voting method\nsatisfies the property of positive involvement (PI) if for any election in\nwhich a candidate x would be among the winners, adding another voter to the\nelection who ranks x first does not cause x to lose. Surprisingly, a number of\nstandard voting methods violate this natural property. In this paper, we\ninvestigate different ways of measuring the extent to which a voting method\nviolates PI, using computer simulations. We consider the probability (under\ndifferent probability models for preferences) of PI violations in randomly\ndrawn profiles vs. profile-coalition pairs (involving coalitions of different\nsizes). We argue that in order to choose between a voting method that satisfies\nPI and one that does not, we should consider the probability of PI violation\nconditional on the voting methods choosing different winners. We should also\nrelativize the probability of PI violation to what we call voter potency, the\nprobability that a voter causes a candidate to lose. Although absolute\nfrequencies of PI violations may be low, after this conditioning and\nrelativization, we see that under certain voting methods that violate PI, much\nof a voter's potency is turned against them - in particular, against their\ndesire to see their favorite candidate elected.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Wesley H. Holliday",
      "Eric Pacuit"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2106.11502"
  },
  {
    "id": "arXiv:2106.11503",
    "title": "Game-Theoretic Models of Moral and Other-Regarding Agents (extended  abstract)",
    "abstract": "We investigate Kantian equilibria in finite normal form games, a class of\nnon-Nashian, morally motivated courses of action that was recently proposed in\nthe economics literature. We highlight a number of problems with such\nequilibria, including computational intractability, a high price of\nmiscoordination, and problematic extension to general normal form games. We\ngive such a generalization based on concept of program equilibria, and point\nout that that a practically relevant generalization may not exist. To remedy\nthis we propose some general, intuitive, computationally tractable,\nother-regarding equilibria that are special cases Kantian equilibria, as well\nas a class of courses of action that interpolates between purely self-regarding\nand Kantian behavior.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886. This is the extended abstract that appears in the Proceedings of TARK 2021. A longer, more complete, version of the paper is available as preprint arXiv:2012.09759\n",
    "authors": [
      "Gabriel Istrate"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.11503"
  },
  {
    "id": "arXiv:2106.11504",
    "title": "Knowing How to Plan",
    "abstract": "Various planning-based know-how logics have been studied in the recent\nliterature. In this paper, we use such a logic to do know-how-based planning\nvia model checking. In particular, we can handle the higher-order epistemic\nplanning involving know-how formulas as the goal, e.g., find a plan to make\nsure p such that the adversary does not know how to make p false in the future.\nWe give a PTIME algorithm for the model checking problem over finite epistemic\ntransition systems and axiomatize the logic under the assumption of perfect\nrecall.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Yanjun Li",
      "Yanjing Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.11504"
  },
  {
    "id": "arXiv:2106.11505",
    "title": "Reasoning about Emergence of Collective Memory",
    "abstract": "We offer a very simple model of how collective memory may form. Agents keep\nsignalling within neighbourhoods, and depending on how many support each\nsignal, some signals \"win\" in that neighbourhood. By agents interacting between\ndifferent neighbourhoods, 'influence' spreads and sometimes, a collective\nsignal emerges. We propose a logic in which we can reason about such emergence\nof memory and present preliminary technical results on the logic.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "R. Ramanujam"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.11505"
  },
  {
    "id": "arXiv:2106.11506",
    "title": "A Deontic Stit Logic Based on Beliefs and Expected Utility",
    "abstract": "The formalization of action and obligation using logic languages is a topic\nof increasing relevance in the field of ethics for AI. Having an expressive\nsyntactic and semantic framework to reason about agents' decisions in moral\nsituations allows for unequivocal representations of components of behavior\nthat are relevant when assigning blame (or praise) of outcomes to said agents.\nTwo very important components of behavior in this respect are belief and\nbelief-based action. In this work we present a logic of doxastic oughts by\nextending epistemic deontic stit theory with beliefs. On one hand, the\nsemantics for formulas involving belief operators is based on probability\nmeasures. On the other, the semantics for doxastic oughts relies on a notion of\noptimality, and the underlying choice rule is maximization of expected utility.\nWe introduce an axiom system for the resulting logic, and we address its\nsoundness, completeness, and decidability results. These results are\nsignificant in the line of research that intends to use proof systems of\nepistemic, doxastic, and deontic logics to help in the testing of ethical\nbehavior of AI through theorem-proving and model-checking.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Aldo Iv\u00e1n Ram\u00edrez Abarca",
      "Jan Broersen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.11506"
  },
  {
    "id": "arXiv:2106.11507",
    "title": "Epistemic Modality and Coordination under Uncertainty",
    "abstract": "Communication facilitates coordination, but coordination might fail if\nthere's too much uncertainty. I discuss a scenario in which vagueness-driven\nuncertainty undermines the possibility of publicly sharing a belief. I then\nshow that asserting an epistemic modal sentence, 'Might p', can reveal the\nspeaker's uncertainty, and that this may improve the chances of coordination\ndespite the lack of a common epistemic ground. This provides a game-theoretic\nrationale for epistemic modality. The account draws on a standard relational\nsemantics for epistemic modality, Stalnaker's theory of assertion as\ninformative update, and a Bayesian framework for reasoning under uncertainty.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Giorgio Sbardolini"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.11507"
  },
  {
    "id": "arXiv:2106.11508",
    "title": "Communication Pattern Models: An Extension of Action Models for  Dynamic-Network Distributed Systems",
    "abstract": "Halpern and Moses were the first to recognize, in 1984, the importance of a\nformal treatment of knowledge in distributed computing. Many works in\ndistributed computing, however, still employ informal notions of knowledge.\nHence, it is critical to further study such formalizations. Action models, a\nsignificant approach to modeling dynamic epistemic logic, have only recently\nbeen applied to distributed computing, for instance, by Goubault, Ledent, and\nRajsbaum. Using action models for analyzing distributed-computing environments,\nas proposed by these authors, has drawbacks, however. In particular, a direct\nuse of action models may cause such models to grow exponentially as the\ncomputation of the distributed system evolves. Hence, our motivation is finding\ncompact action models for distributed systems. We introduce communication\npattern models as an extension of both ordinary action models and their update\noperator. We give a systematic construction of communication pattern models for\na large variety of distributed-computing models called dynamic-network models.\nFor a proper subclass of dynamic-network models called oblivious, the\ncommunication pattern model remains the same throughout the computation.",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Diego A. Vel\u00e1zquez",
      "Armando Casta\u00f1eda",
      "David A. Rosenblueth"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.11508"
  },
  {
    "id": "arXiv:2106.11512",
    "title": "An Accurate Non-accelerometer-based PPG Motion Artifact Removal  Technique using CycleGAN",
    "abstract": "A photoplethysmography (PPG) is an uncomplicated and inexpensive optical\ntechnique widely used in the healthcare domain to extract valuable\nhealth-related information, e.g., heart rate variability, blood pressure, and\nrespiration rate. PPG signals can easily be collected continuously and remotely\nusing portable wearable devices. However, these measuring devices are\nvulnerable to motion artifacts caused by daily life activities. The most common\nways to eliminate motion artifacts use extra accelerometer sensors, which\nsuffer from two limitations: i) high power consumption and ii) the need to\nintegrate an accelerometer sensor in a wearable device (which is not required\nin certain wearables). This paper proposes a low-power non-accelerometer-based\nPPG motion artifacts removal method outperforming the accuracy of the existing\nmethods. We use Cycle Generative Adversarial Network to reconstruct clean PPG\nsignals from noisy PPG signals. Our novel machine-learning-based technique\nachieves 9.5 times improvement in motion artifact removal compared to the\nstate-of-the-art without using extra sensors such as an accelerometer.",
    "descriptor": "\nComments: Submitted to ACM Health\n",
    "authors": [
      "Amir Hosein Afandizadeh Zargari",
      "Seyed Amir Hossein Aqajari",
      "Hadi Khodabandeh",
      "Amir M. Rahmani",
      "Fadi Kurdahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11512"
  },
  {
    "id": "arXiv:2106.11514",
    "title": "Adapting Stepsizes by Momentumized Gradients Improves Optimization and  Generalization",
    "abstract": "Adaptive gradient methods, such as \\textsc{Adam}, have achieved tremendous\nsuccess in machine learning. Scaling gradients by square roots of the running\naverages of squared past gradients, such methods are able to attain rapid\ntraining of modern deep neural networks. Nevertheless, they are observed to\ngeneralize worse than stochastic gradient descent (\\textsc{SGD}) and tend to be\ntrapped in local minima at an early stage during training. Intriguingly, we\ndiscover that substituting the gradient in the preconditioner term with the\nmomentumized version in \\textsc{Adam} can well solve the issues. The intuition\nis that gradient with momentum contains more accurate directional information\nand therefore its second moment estimation is a better choice for scaling than\nraw gradient's. Thereby we propose \\textsc{AdaMomentum} as a new optimizer\nreaching the goal of training faster while generalizing better. We further\ndevelop a theory to back up the improvement in optimization and generalization\nand provide convergence guarantee under both convex and nonconvex settings.\nExtensive experiments on various models and tasks demonstrate that\n\\textsc{AdaMomentum} exhibits comparable performance to \\textsc{SGD} on vision\ntasks, and achieves state-of-the-art results consistently on other tasks\nincluding language processing.",
    "descriptor": "\nComments: 40 pages, 27 figures\n",
    "authors": [
      "Yizhou Wang",
      "Yue Kang",
      "Can Qin",
      "Yi Xu",
      "Huan Wang",
      "Yulun Zhang",
      "Yun Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11514"
  },
  {
    "id": "arXiv:2106.11516",
    "title": "SA-LOAM: Semantic-aided LiDAR SLAM with Loop Closure",
    "abstract": "LiDAR-based SLAM system is admittedly more accurate and stable than others,\nwhile its loop closure detection is still an open issue. With the development\nof 3D semantic segmentation for point cloud, semantic information can be\nobtained conveniently and steadily, essential for high-level intelligence and\nconductive to SLAM. In this paper, we present a novel semantic-aided LiDAR SLAM\nwith loop closure based on LOAM, named SA-LOAM, which leverages semantics in\nodometry as well as loop closure detection. Specifically, we propose a\nsemantic-assisted ICP, including semantically matching, downsampling and plane\nconstraint, and integrates a semantic graph-based place recognition method in\nour loop closure detection module. Benefitting from semantics, we can improve\nthe localization accuracy, detect loop closures effectively, and construct a\nglobal consistent semantic map even in large-scale scenes. Extensive\nexperiments on KITTI and Ford Campus dataset show that our system significantly\nimproves baseline performance, has generalization ability to unseen data and\nachieves competitive results compared with state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Lin Li",
      "Xin Kong",
      "Xiangrui Zhao",
      "Wanlong Li",
      "Feng Wen",
      "Hongbo Zhang",
      "Yong Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11516"
  },
  {
    "id": "arXiv:2106.11517",
    "title": "Fine-tune the Entire RAG Architecture (including DPR retriever) for  Question-Answering",
    "abstract": "In this paper, we illustrate how to fine-tune the entire Retrieval Augment\nGeneration (RAG) architecture in an end-to-end manner. We highlighted the main\nengineering challenges that needed to be addressed to achieve this objective.\nWe also compare how end-to-end RAG architecture outperforms the original RAG\narchitecture for the task of question answering. We have open-sourced our\nimplementation in the HuggingFace Transformers library.",
    "descriptor": "\nComments: for associated code, see this https URL\n",
    "authors": [
      "Shamane Siriwardhana",
      "Rivindu Weerasekera",
      "Elliott Wen",
      "Suranga Nanayakkara"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11517"
  },
  {
    "id": "arXiv:2106.11519",
    "title": "Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations",
    "abstract": "There have been many recent advances on provably efficient Reinforcement\nLearning (RL) in problems with rich observation spaces. However, all these\nworks share a strong realizability assumption about the optimal value function\nof the true MDP. Such realizability assumptions are often too strong to hold in\npractice. In this work, we consider the more realistic setting of agnostic RL\nwith rich observation spaces and a fixed class of policies $\\Pi$ that may not\ncontain any near-optimal policy. We provide an algorithm for this setting whose\nerror is bounded in terms of the rank $d$ of the underlying MDP. Specifically,\nour algorithm enjoys a sample complexity bound of $\\widetilde{O}\\left((H^{4d}\nK^{3d} \\log |\\Pi|)/\\epsilon^2\\right)$ where $H$ is the length of episodes, $K$\nis the number of actions and $\\epsilon>0$ is the desired sub-optimality. We\nalso provide a nearly matching lower bound for this agnostic setting that shows\nthat the exponential dependence on rank is unavoidable, without further\nassumptions.",
    "descriptor": "",
    "authors": [
      "Christoph Dann",
      "Yishay Mansour",
      "Mehryar Mohri",
      "Ayush Sekhari",
      "Karthik Sridharan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.11519"
  },
  {
    "id": "arXiv:2106.11520",
    "title": "BARTScore: Evaluating Generated Text as Text Generation",
    "abstract": "A wide variety of NLP applications, such as machine translation,\nsummarization, and dialog, involve text generation. One major challenge for\nthese applications is how to evaluate whether such generated texts are actually\nfluent, accurate, or effective. In this work, we conceptualize the evaluation\nof generated text as a text generation problem, modeled using pre-trained\nsequence-to-sequence models. The general idea is that models trained to convert\nthe generated text to/from a reference output or the source text will achieve\nhigher scores when the generated text is better. We operationalize this idea\nusing BART, an encoder-decoder based pre-trained model, and propose a metric\nBARTScore with a number of variants that can be flexibly applied in an\nunsupervised fashion to evaluation of text from different perspectives (e.g.\ninformativeness, fluency, or factuality). BARTScore is conceptually simple and\nempirically effective. It can outperform existing top-scoring metrics in 16 of\n22 test settings, covering evaluation of 16 datasets (e.g., machine\ntranslation, text summarization) and 7 different perspectives (e.g.,\ninformativeness, factuality). Code to calculate BARTScore is available at\nhttps://github.com/neulab/BARTScore, and we have released an interactive\nleaderboard for meta-evaluation at\nthis http URL on the ExplainaBoard\nplatform, which allows us to interactively understand the strengths,\nweaknesses, and complementarity of each metric.",
    "descriptor": "\nComments: Demo at this http URL\n",
    "authors": [
      "Weizhe Yuan",
      "Graham Neubig",
      "Pengfei Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11520"
  },
  {
    "id": "arXiv:2106.11521",
    "title": "ESR: Ethics and Society Review of Artificial Intelligence Research",
    "abstract": "Artificial intelligence (AI) research is routinely criticized for its real\nand potential impacts on society, and we lack adequate institutional responses\nto this criticism and to the responsibility that it reflects. AI research often\nfalls outside the purview of existing feedback mechanisms such as the\nInstitutional Review Board (IRB), which are designed to evaluate harms to human\nsubjects rather than harms to human society. In response, we have developed the\nEthics and Society Review board (ESR), a feedback panel that works with\nresearchers to mitigate negative ethical and societal aspects of AI research.\nThe ESR's main insight is to serve as a requirement for funding: researchers\ncannot receive grant funding from a major AI funding program at our university\nuntil the researchers complete the ESR process for the proposal. In this\narticle, we describe the ESR as we have designed and run it over its first year\nacross 41 proposals. We analyze aggregate ESR feedback on these proposals,\nfinding that the panel most commonly identifies issues of harms to minority\ngroups, inclusion of diverse stakeholders in the research plan, dual use, and\nrepresentation in data. Surveys and interviews of researchers who interacted\nwith the ESR found that 58% felt that it had influenced the design of their\nresearch project, 100% are willing to continue submitting future projects to\nthe ESR, and that they sought additional scaffolding for reasoning through\nethics and society issues.",
    "descriptor": "",
    "authors": [
      "Michael S. Bernstein",
      "Margaret Levi",
      "David Magnus",
      "Betsy Rajala",
      "Debra Satz",
      "Charla Waeiss"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11521"
  },
  {
    "id": "arXiv:2106.11522",
    "title": "Total Least Squares for Optimal Pose Estimation",
    "abstract": "This work provides a theoretical framework for the pose estimation problem\nusing total least squares for vector observations from landmark features.\nFirst, the optimization framework is formulated for the pose estimation problem\nwith observation vectors extracted from point cloud features. Then,\nerror-covariance expressions are derived. The attitude and position solutions\nobtained via the derived optimization framework are proven to reach the bounds\ndefined by the Cram\\'er-Rao lower bound under the small angle approximation of\nattitude errors. The measurement data for the simulation of this problem is\nprovided through a series of vector observation scans, and a fully populated\nobservation noise-covariance matrix is assumed as the weight in the cost\nfunction to cover for the most general case of the sensor uncertainty. Here,\nprevious derivations are expanded for the pose estimation problem to include\nmore generic cases of correlations in the errors than previously cases\ninvolving an isotropic noise assumption. The proposed solution is simulated in\na Monte-Carlo framework with 10,000 samples to validate the error-covariance\nanalysis.",
    "descriptor": "",
    "authors": [
      "Saeed Maleki",
      "John Crassidis",
      "Yang Cheng",
      "Matthias Schmid"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11522"
  },
  {
    "id": "arXiv:2106.11528",
    "title": "Recent Deep Semi-supervised Learning Approaches and Related Works",
    "abstract": "The author of this work proposes an overview of the recent semi-supervised\nlearning approaches and related works. Despite the remarkable success of neural\nnetworks in various applications, there exist few formidable constraints\nincluding the need for a large amount of labeled data. Therefore,\nsemi-supervised learning, which is a learning scheme in which the scarce labels\nand a larger amount of unlabeled data are utilized to train models (e.g., deep\nneural networks) is getting more important. Based on the key assumptions of\nsemi-supervised learning, which are the manifold assumption, cluster\nassumption, and continuity assumption, the work reviews the recent\nsemi-supervised learning approaches. In particular, the methods in regard to\nusing deep neural networks in a semi-supervised learning setting are primarily\ndiscussed. In addition, the existing works are first classified based on the\nunderlying idea and explained, and then the holistic approaches that unify the\naforementioned ideas are detailed.",
    "descriptor": "",
    "authors": [
      "Gyeongho Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11528"
  },
  {
    "id": "arXiv:2106.11531",
    "title": "Graph Routing between Capsules",
    "abstract": "Routing methods in capsule networks often learn a hierarchical relationship\nfor capsules in successive layers, but the intra-relation between capsules in\nthe same layer is less studied, while this intra-relation is a key factor for\nthe semantic understanding in text data. Therefore, in this paper, we introduce\na new capsule network with graph routing to learn both relationships, where\ncapsules in each layer are treated as the nodes of a graph. We investigate\nstrategies to yield adjacency and degree matrix with three different distances\nfrom a layer of capsules, and propose the graph routing mechanism between those\ncapsules. We validate our approach on five text classification datasets, and\nour findings suggest that the approach combining bottom-up routing and top-down\nattention performs the best. Such an approach demonstrates generalization\ncapability across datasets. Compared to the state-of-the-art routing methods,\nthe improvements in accuracy in the five datasets we used were 0.82, 0.39,\n0.07, 1.01, and 0.02, respectively.",
    "descriptor": "",
    "authors": [
      "Yang Li",
      "Wei Zhao",
      "Erik Cambria",
      "Suhang Wang",
      "Steffen Eger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11531"
  },
  {
    "id": "arXiv:2106.11532",
    "title": "Key-Sparse Transformer with Cascaded Cross-Attention Block for  Multimodal Speech Emotion Recognition",
    "abstract": "Speech emotion recognition is a challenging and important research topic that\nplays a critical role in human-computer interaction. Multimodal inputs can\nimprove the performance as more emotional information is used for recognition.\nHowever, existing studies learnt all the information in the sample while only a\nsmall portion of it is about emotion. Moreover, under the multimodal framework,\nthe interaction between different modalities is shallow and insufficient. In\nthis paper, a keysparse Transformer is proposed for efficient SER by only\nfocusing on emotion related information. Furthermore, a cascaded\ncross-attention block, which is specially designed for multimodal framework, is\nintroduced to achieve deep interaction between different modalities. The\nproposed method is evaluated by IEMOCAP corpus and the experimental results\nshow that the proposed method gives better performance than the state-of-theart\napproaches.",
    "descriptor": "",
    "authors": [
      "Weidong Chen",
      "Xiaofeng Xing",
      "Xiangmin Xu",
      "Jichen Yang",
      "Jianxin Pang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.11532"
  },
  {
    "id": "arXiv:2106.11533",
    "title": "Do Language Models Perform Generalizable Commonsense Inference?",
    "abstract": "Inspired by evidence that pretrained language models (LMs) encode commonsense\nknowledge, recent work has applied LMs to automatically populate commonsense\nknowledge graphs (CKGs). However, there is a lack of understanding on their\ngeneralization to multiple CKGs, unseen relations, and novel entities. This\npaper analyzes the ability of LMs to perform generalizable commonsense\ninference, in terms of knowledge capacity, transferability, and induction. Our\nexperiments with these three aspects show that: (1) LMs can adapt to different\nschemas defined by multiple CKGs but fail to reuse the knowledge to generalize\nto new relations. (2) Adapted LMs generalize well to unseen subjects, but less\nso on novel objects. Future work should investigate how to improve the\ntransferability and induction of commonsense mining from LMs.",
    "descriptor": "\nComments: 8 pages, 4 figures. Accepted to ACL'21 Findings\n",
    "authors": [
      "Peifeng Wang",
      "Filip Ilievski",
      "Muhao Chen",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11533"
  },
  {
    "id": "arXiv:2106.11534",
    "title": "Turing Award elites revisited: patterns of productivity, collaboration,  authorship and impact",
    "abstract": "The Turing Award is recognized as the most influential and prestigious award\nin the field of computer science(CS). With the rise of the science of science\n(SciSci), a large amount of bibliographic data has been analyzed in an attempt\nto understand the hidden mechanism of scientific evolution. These include the\nanalysis of the Nobel Prize, including physics, chemistry, medicine, etc. In\nthis article, we extract and analyze the data of 72 Turing Award laureates from\nthe complete bibliographic data, fill the gap in the lack of Turing Award\nanalysis, and discover the development characteristics of computer science as\nan independent discipline. First, we show most Turing Award laureates have\nlong-term and high-quality educational backgrounds, and more than 61% of them\nhave a degree in mathematics, which indicates that mathematics has played a\nsignificant role in the development of computer science. Secondly, the data\nshows that not all scholars have high productivity and high h-index; that is,\nthe number of publications and h-index is not the leading indicator for\nevaluating the Turing Award. Third, the average age of awardees has increased\nfrom 40 to around 70 in recent years. This may be because new breakthroughs\ntake longer, and some new technologies need time to prove their influence.\nBesides, we have also found that in the past ten years, international\ncollaboration has experienced explosive growth, showing a new paradigm in the\nform of collaboration. It is also worth noting that in recent years, the\nemergence of female winners has also been eye-catching. Finally, by analyzing\nthe personal publication records, we find that many people are more likely to\npublish high-impact articles during their high-yield periods.",
    "descriptor": "",
    "authors": [
      "Yinyu Jin",
      "Sha Yuan",
      "Zhou Shao",
      "Wendy Hall",
      "Jie Tang"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.11534"
  },
  {
    "id": "arXiv:2106.11535",
    "title": "Particle Cloud Generation with Message Passing Generative Adversarial  Networks",
    "abstract": "In high energy physics (HEP), jets are collections of correlated particles\nproduced ubiquitously in particle collisions such as those at the CERN Large\nHadron Collider (LHC). Machine-learning-based generative models, such as\ngenerative adversarial networks (GANs), have the potential to significantly\naccelerate LHC jet simulations. However, despite jets having a natural\nrepresentation as a set of particles in momentum-space, a.k.a. a particle\ncloud, to our knowledge there exist no generative models applied to such a\ndataset. We introduce a new particle cloud dataset (JetNet), and, due to\nsimilarities between particle and point clouds, apply to it existing point\ncloud GANs. Results are evaluated using (1) the 1-Wasserstein distance between\nhigh- and low-level feature distributions, (2) a newly developed Fr\\'{e}chet\nParticleNet Distance, and (3) the coverage and (4) minimum matching distance\nmetrics. Existing GANs are found to be inadequate for physics applications,\nhence we develop a new message passing GAN (MPGAN), which outperforms existing\npoint cloud GANs on virtually every metric and shows promise for use in HEP. We\npropose JetNet as a novel point-cloud-style dataset for the machine learning\ncommunity to experiment with, and set MPGAN as a benchmark to improve upon for\nfuture generative models.",
    "descriptor": "\nComments: 13 pages, 4 figures, 2 tables, and a 3 page appendix\n",
    "authors": [
      "Raghav Kansal",
      "Javier Duarte",
      "Hao Su",
      "Breno Orzari",
      "Thiago Tomei",
      "Maurizio Pierini",
      "Mary Touranakou",
      "Jean-Roch Vlimant",
      "Dimitrios Gunopulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2106.11535"
  },
  {
    "id": "arXiv:2106.11536",
    "title": "Deep3DPose: Realtime Reconstruction of Arbitrarily Posed Human Bodies  from Single RGB Images",
    "abstract": "We introduce an approach that accurately reconstructs 3D human poses and\ndetailed 3D full-body geometric models from single images in realtime. The key\nidea of our approach is a novel end-to-end multi-task deep learning framework\nthat uses single images to predict five outputs simultaneously: foreground\nsegmentation mask, 2D joints positions, semantic body partitions, 3D part\norientations and uv coordinates (uv map). The multi-task network architecture\nnot only generates more visual cues for reconstruction, but also makes each\nindividual prediction more accurate. The CNN regressor is further combined with\nan optimization based algorithm for accurate kinematic pose reconstruction and\nfull-body shape modeling. We show that the realtime reconstruction reaches\naccurate fitting that has not been seen before, especially for wild images. We\ndemonstrate the results of our realtime 3D pose and human body reconstruction\nsystem on various challenging in-the-wild videos. We show the system advances\nthe frontier of 3D human body and pose reconstruction from single images by\nquantitative evaluations and comparisons with state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Liguo Jiang",
      "Miaopeng Li",
      "Jianjie Zhang",
      "Congyi Wang",
      "Juntao Ye",
      "Xinguo Liu",
      "Jinxiang Chai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11536"
  },
  {
    "id": "arXiv:2106.11539",
    "title": "DocFormer: End-to-End Transformer for Document Understanding",
    "abstract": "We present DocFormer -- a multi-modal transformer based architecture for the\ntask of Visual Document Understanding (VDU). VDU is a challenging problem which\naims to understand documents in their varied formats (forms, receipts etc.) and\nlayouts. In addition, DocFormer is pre-trained in an unsupervised fashion using\ncarefully designed tasks which encourage multi-modal interaction. DocFormer\nuses text, vision and spatial features and combines them using a novel\nmulti-modal self-attention layer. DocFormer also shares learned spatial\nembeddings across modalities which makes it easy for the model to correlate\ntext to visual tokens and vice versa. DocFormer is evaluated on 4 different\ndatasets each with strong baselines. DocFormer achieves state-of-the-art\nresults on all of them, sometimes beating models 4x its size (in no. of\nparameters).",
    "descriptor": "",
    "authors": [
      "Srikar Appalaraju",
      "Bhavan Jasani",
      "Bhargava Urala Kota",
      "Yusheng Xie",
      "R. Manmatha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11539"
  },
  {
    "id": "arXiv:2106.11541",
    "title": "Kernel Clustering with Sigmoid-based Regularization for Efficient  Segmentation of Sequential Data",
    "abstract": "Kernel segmentation aims at partitioning a data sequence into several\nnon-overlapping segments that may have nonlinear and complex structures. In\ngeneral, it is formulated as a discrete optimization problem with combinatorial\nconstraints. A popular algorithm for optimally solving this problem is dynamic\nprogramming (DP), which has quadratic computation and memory requirements.\nGiven that sequences in practice are too long, this algorithm is not a\npractical approach. Although many heuristic algorithms have been proposed to\napproximate the optimal segmentation, they have no guarantee on the quality of\ntheir solutions. In this paper, we take a differentiable approach to alleviate\nthe aforementioned issues. First, we introduce a novel sigmoid-based\nregularization to smoothly approximate the combinatorial constraints. Combining\nit with objective of the balanced kernel clustering, we formulate a\ndifferentiable model termed Kernel clustering with sigmoid-based regularization\n(KCSR), where the gradient-based algorithm can be exploited to obtain the\noptimal segmentation. Second, we develop a stochastic variant of the proposed\nmodel. By using the stochastic gradient descent algorithm, which has much lower\ntime and space complexities, for optimization, the second model can perform\nsegmentation on overlong data sequences. Finally, for simultaneously segmenting\nmultiple data sequences, we slightly modify the sigmoid-based regularization to\nfurther introduce an extended variant of the proposed model. Through extensive\nexperiments on various types of data sequences performances of our models are\nevaluated and compared with those of the existing methods. The experimental\nresults validate advantages of the proposed models. Our Matlab source code is\navailable on github.",
    "descriptor": "",
    "authors": [
      "Tung Doan",
      "Atsuhiro Takasu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11541"
  },
  {
    "id": "arXiv:2106.11542",
    "title": "Differentiable Architecture Search Without Training Nor Labels: A  Pruning Perspective",
    "abstract": "With leveraging the weight-sharing and continuous relaxation to enable\ngradient-descent to alternately optimize the supernet weights and the\narchitecture parameters through a bi-level optimization paradigm,\n\\textit{Differentiable ARchiTecture Search} (DARTS) has become the mainstream\nmethod in Neural Architecture Search (NAS) due to its simplicity and\nefficiency. However, more recent works found that the performance of the\nsearched architecture barely increases with the optimization proceeding in\nDARTS. In addition, several concurrent works show that the NAS could find more\ncompetitive architectures without labels. The above observations reveal that\nthe supervision signal in DARTS may be a poor indicator for architecture\noptimization, inspiring a foundational question: instead of using the\nsupervision signal to perform bi-level optimization, \\textit{can we find\nhigh-quality architectures \\textbf{without any training nor labels}}? We\nprovide an affirmative answer by customizing the NAS as a network pruning at\ninitialization problem. By leveraging recent techniques on the network pruning\nat initialization, we designed a FreeFlow proxy to score the importance of\ncandidate operations in NAS without any training nor labels, and proposed a\nnovel framework called \\textit{training and label free neural architecture\nsearch} (\\textbf{FreeNAS}) accordingly. We show that, without any training nor\nlabels, FreeNAS with the proposed FreeFlow proxy can outperform most NAS\nbaselines. More importantly, our framework is extremely efficient, which\ncompletes the architecture search within only \\textbf{3.6s} and \\textbf{79s} on\na single GPU for the NAS-Bench-201 and DARTS search space, respectively. We\nhope our work inspires more attempts in solving NAS from the perspective of\npruning at initialization.",
    "descriptor": "",
    "authors": [
      "Miao Zhang",
      "Steven Su",
      "Shirui Pan",
      "Xiaojun Chang",
      "Wei Huang",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11542"
  },
  {
    "id": "arXiv:2106.11548",
    "title": "Adaptive Learning Rate and Momentum for Training Deep Neural Networks",
    "abstract": "Recent progress on deep learning relies heavily on the quality and efficiency\nof training algorithms. In this paper, we develop a fast training method\nmotivated by the nonlinear Conjugate Gradient (CG) framework. We propose the\nConjugate Gradient with Quadratic line-search (CGQ) method. On the one hand, a\nquadratic line-search determines the step size according to current loss\nlandscape. On the other hand, the momentum factor is dynamically updated in\ncomputing the conjugate gradient parameter (like Polak-Ribiere). Theoretical\nresults to ensure the convergence of our method in strong convex settings is\ndeveloped. And experiments in image classification datasets show that our\nmethod yields faster convergence than other local solvers and has better\ngeneralization capability (test set accuracy). One major advantage of the paper\nmethod is that tedious hand tuning of hyperparameters like the learning rate\nand momentum is avoided.",
    "descriptor": "",
    "authors": [
      "Zhiyong Hao",
      "Yixuan Jiang",
      "Huihua Yu",
      "Hsiao-Dong Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11548"
  },
  {
    "id": "arXiv:2106.11549",
    "title": "Winning the CVPR'2021 Kinetics-GEBD Challenge: Contrastive Learning  Approach",
    "abstract": "Generic Event Boundary Detection (GEBD) is a newly introduced task that aims\nto detect \"general\" event boundaries that correspond to natural human\nperception. In this paper, we introduce a novel contrastive learning based\napproach to deal with the GEBD. Our intuition is that the feature similarity of\nthe video snippet would significantly vary near the event boundaries, while\nremaining relatively the same in the remaining part of the video. In our model,\nTemporal Self-similarity Matrix (TSM) is utilized as an intermediate\nrepresentation which takes on a role as an information bottleneck. With our\nmodel, we achieved significant performance boost compared to the given\nbaselines. Our code is available at\nhttps://github.com/hello-jinwoo/LOVEU-CVPR2021.",
    "descriptor": "",
    "authors": [
      "Hyolim Kang",
      "Jinwoo Kim",
      "Kyungmin Kim",
      "Taehyun Kim",
      "Seon Joo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11549"
  },
  {
    "id": "arXiv:2106.11559",
    "title": "Hand-Drawn Electrical Circuit Recognition using Object Detection and  Node Recognition",
    "abstract": "With the recent developments in neural networks, there has been a resurgence\nin algorithms for the automatic generation of simulation ready electronic\ncircuits from hand-drawn circuits. However, most of the approaches in\nliterature were confined to classify different types of electrical components\nand only a few of those methods have shown a way to rebuild the circuit\nschematic from the scanned image, which is extremely important for further\nautomation of netlist generation. This paper proposes a real-time algorithm for\nthe automatic recognition of hand-drawn electrical circuits based on object\ndetection and circuit node recognition. The proposed approach employs You Only\nLook Once version 5 (YOLOv5) for detection of circuit components and a novel\nHough transform based approach for node recognition. Using YOLOv5 object\ndetection algorithm, a mean average precision (mAP0.5) of 98.2% is achieved in\ndetecting the components. The proposed method is also able to rebuild the\ncircuit schematic with 80% accuracy.",
    "descriptor": "\nComments: 11 pages, 15 figures, under review in springer\n",
    "authors": [
      "Rachala Rohith Reddy",
      "Mahesh Raveendranatha Panicker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.11559"
  },
  {
    "id": "arXiv:2106.11560",
    "title": "Finding Valid Adjustments under Non-ignorability with Minimal DAG  Knowledge",
    "abstract": "Treatment effect estimation from observational data is a fundamental problem\nin causal inference. There are two very different schools of thought that have\ntackled this problem. On the one hand, the Pearlian framework commonly assumes\nstructural knowledge (provided by an expert) in the form of Directed Acyclic\nGraphs (DAGs) and provides graphical criteria such as the back-door criterion\nto identify the valid adjustment sets. On the other hand, the potential\noutcomes (PO) framework commonly assumes that all the observed features satisfy\nignorability (i.e., no hidden confounding), which in general is untestable. In\nthis work, we take steps to bridge these two frameworks. We show that even if\nwe know only one parent of the treatment variable (provided by an expert), then\nquite remarkably it suffices to test a broad class of (but not all) back-door\ncriteria. Importantly, we also cover the non-trivial case where the entire set\nof observed features is not ignorable (generalizing the PO framework) without\nrequiring all the parents of the treatment variable to be observed. Our key\ntechnical idea involves a more general result -- Given a synthetic sub-sampling\n(or environment) variable that is a function of the parent variable, we show\nthat an invariance test involving this sub-sampling variable is equivalent to\ntesting a broad class of back-door criteria. We demonstrate our approach on\nsynthetic data as well as real causal effect estimation benchmarks.",
    "descriptor": "",
    "authors": [
      "Abhin Shah",
      "Karthikeyan Shanmugam",
      "Kartik Ahuja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11560"
  },
  {
    "id": "arXiv:2106.11562",
    "title": "SSUL: Semantic Segmentation with Unknown Label for Exemplar-based  Class-Incremental Learning",
    "abstract": "We consider a class-incremental semantic segmentation (CISS) problem. While\nsome recently proposed algorithms utilized variants of knowledge distillation\n(KD) technique to tackle the problem, they only partially addressed the key\nadditional challenges in CISS that causes the catastrophic forgetting; i.e.,\nthe semantic drift of the background class and multi-label prediction issue. To\nbetter address these challenges, we propose a new method, dubbed as SSUL-M\n(Semantic Segmentation with Unknown Label with Memory), by carefully combining\nseveral techniques tailored for semantic segmentation. More specifically, we\nmake three main contributions; (1) modeling unknown class within the background\nclass to help learning future classes (help plasticity), (2) freezing backbone\nnetwork and past classifiers with binary cross-entropy loss and pseudo-labeling\nto overcome catastrophic forgetting (help stability), and (3) utilizing tiny\nexemplar memory for the first time in CISS to improve both plasticity and\nstability. As a result, we show our method achieves significantly better\nperformance than the recent state-of-the-art baselines on the standard\nbenchmark datasets. Furthermore, we justify our contributions with thorough and\nextensive ablation analyses and discuss different natures of the CISS problem\ncompared to the standard class-incremental learning for classification.",
    "descriptor": "",
    "authors": [
      "Sungmin Cha. Beomyoung Kim",
      "Youngjoon Yoo",
      "Taesup Moon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11562"
  },
  {
    "id": "arXiv:2106.11563",
    "title": "Creating A New Color Space utilizing PSO and FCM to Perform Skin  Detection by using Neural Network and ANFIS",
    "abstract": "Skin color detection is an essential required step in various applications\nrelated to computer vision. These applications will include face detection,\nfinding pornographic images in movies and photos, finding ethnicity, age,\ndiagnosis, and so on. Therefore, proposing a proper skin detection method can\nprovide solution to several problems. In this study, first a new color space is\ncreated using FCM and PSO algorithms. Then, skin classification has been\nperformed in the new color space utilizing linear and nonlinear modes.\nAdditionally, it has been done in RGB and LAB color spaces by using ANFIS and\nneural network. Skin detection in RBG color space has been performed using\nMahalanobis distance and Euclidean distance algorithms. In comparison, this\nmethod has 18.38% higher accuracy than the most accurate method on the same\ndatabase. Additionally, this method has achieved 90.05% in equal error rate\n(1-EER) in testing COMPAQ dataset and 92.93% accuracy in testing Pratheepan\ndataset, which compared to the previous method on COMPAQ database, 1-EER has\nincreased by %0.87.",
    "descriptor": "",
    "authors": [
      "Kobra Nazaria",
      "Samaneh Mazaheri",
      "Bahram Sadeghi Bigham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11563"
  },
  {
    "id": "arXiv:2106.11565",
    "title": "Practical Near Neighbor Search via Group Testing",
    "abstract": "We present a new algorithm for the approximate near neighbor problem that\ncombines classical ideas from group testing with locality-sensitive hashing\n(LSH). We reduce the near neighbor search problem to a group testing problem by\ndesignating neighbors as \"positives,\" non-neighbors as \"negatives,\" and\napproximate membership queries as group tests. We instantiate this framework\nusing distance-sensitive Bloom Filters to Identify Near-Neighbor Groups\n(FLINNG). We prove that FLINNG has sub-linear query time and show that our\nalgorithm comes with a variety of practical advantages. For example, FLINNG can\nbe constructed in a single pass through the data, consists entirely of\nefficient integer operations, and does not require any distance computations.\nWe conduct large-scale experiments on high-dimensional search tasks such as\ngenome search, URL similarity search, and embedding search over the massive\nYFCC100M dataset. In our comparison with leading algorithms such as HNSW and\nFAISS, we find that FLINNG can provide up to a 10x query speedup with\nsubstantially smaller indexing time and memory.",
    "descriptor": "\nComments: For source code see this https URL\n",
    "authors": [
      "Joshua Engels",
      "Benjamin Coleman",
      "Anshumali Shrivastava"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.11565"
  },
  {
    "id": "arXiv:2106.11566",
    "title": "SENT: Sentence-level Distant Relation Extraction via Negative Training",
    "abstract": "Distant supervision for relation extraction provides uniform bag labels for\neach sentence inside the bag, while accurate sentence labels are important for\ndownstream applications that need the exact relation type. Directly using bag\nlabels for sentence-level training will introduce much noise, thus severely\ndegrading performance. In this work, we propose the use of negative training\n(NT), in which a model is trained using complementary labels regarding that\n``the instance does not belong to these complementary labels\". Since the\nprobability of selecting a true label as a complementary label is low, NT\nprovides less noisy information. Furthermore, the model trained with NT is able\nto separate the noisy data from the training data. Based on NT, we propose a\nsentence-level framework, SENT, for distant relation extraction. SENT not only\nfilters the noisy data to construct a cleaner dataset, but also performs a\nre-labeling process to transform the noisy data into useful training data, thus\nfurther benefiting the model's performance. Experimental results show the\nsignificant improvement of the proposed method over previous methods on\nsentence-level evaluation and de-noise effect.",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Ruotian Ma",
      "Tao Gui",
      "Linyang Li",
      "Qi Zhang",
      "Yaqian Zhou",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11566"
  },
  {
    "id": "arXiv:2106.11569",
    "title": "Solving the Rank Decoding Problem Over Finite Principal Ideal Rings",
    "abstract": "The rank decoding problem has been the subject of much attention in this last\ndecade. This problem, which is at the base of the security of public-key\ncryptosystems based on rank metric codes, is traditionally studied over finite\nfields. But the recent generalizations of certain classes of rank-metric codes\nfrom finite fields to finite rings have naturally created the interest to\ntackle the rank decoding problem in the case of finite rings. In this paper, we\nshow that some combinatorial type algorithms for solving the rank decoding\nproblem over finite fields can be generalized to solve the same problem over\nfinite principal ideal rings. We study and provide the average complexity of\nthese algorithms. We also observe that some recent algebraic attacks are not\ndirectly applicable when the finite ring is not a field due to zero divisors.\nThese results could be used to justify the use of codes defined over finite\nrings in rank metric code-based cryptography.",
    "descriptor": "\nComments: 11 pages, submitted to IEEE Information Theory\n",
    "authors": [
      "Herv\u00e9 Tale Kalachi",
      "Hermann Tchatchiem Kamche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11569"
  },
  {
    "id": "arXiv:2106.11570",
    "title": "FLRA: A Reference Architecture for Federated Learning Systems",
    "abstract": "Federated learning is an emerging machine learning paradigm that enables\nmultiple devices to train models locally and formulate a global model, without\nsharing the clients' local data. A federated learning system can be viewed as a\nlarge-scale distributed system, involving different components and stakeholders\nwith diverse requirements and constraints. Hence, developing a federated\nlearning system requires both software system design thinking and machine\nlearning knowledge. Although much effort has been put into federated learning\nfrom the machine learning perspectives, our previous systematic literature\nreview on the area shows that there is a distinct lack of considerations for\nsoftware architecture design for federated learning. In this paper, we propose\nFLRA, a reference architecture for federated learning systems, which provides a\ntemplate design for federated learning-based solutions. The proposed FLRA\nreference architecture is based on an extensive review of existing patterns of\nfederated learning systems found in the literature and existing industrial\nimplementation. The FLRA reference architecture consists of a pool of\narchitectural patterns that could address the frequently recurring design\nproblems in federated learning architectures. The FLRA reference architecture\ncan serve as a design guideline to assist architects and developers with\npractical solutions for their problems, which can be further customised.",
    "descriptor": "\nComments: Accepted by ECSA 2021\n",
    "authors": [
      "Sin Kit Lo",
      "Qinghua Lu",
      "Hye-Young Paik",
      "Liming Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.11570"
  },
  {
    "id": "arXiv:2106.11574",
    "title": "Toward a new fully algebraic preconditioner for symmetric positive  definite problems",
    "abstract": "A new domain decomposition preconditioner is introduced for efficiently\nsolving linear systems Ax = b with a symmetric positive definite matrix A. The\nparticularity of the new preconditioner is that it is not necessary to have\naccess to the so-called Neumann matrices (i.e.: the matrices that result from\nassembling the variational problem underlying A restricted to each subdomain).\nAll the components in the preconditioner can be computed with the knowledge\nonly of A (and this is the meaning given here to the word algebraic). The new\npreconditioner relies on the GenEO coarse space for a matrix that is a low-rank\nmodification of A and on the Woodbury matrix identity. The idea underlying the\nnew preconditioner is introduced here for the first time with a first version\nof the preconditioner. Some numerical illustrations are presented. A more\nextensive presentation including some improved variants of the new\npreconditioner can be found in [7]\n(https://hal.archives-ouvertes.fr/hal-03258644).",
    "descriptor": "",
    "authors": [
      "Nicole Spillane"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11574"
  },
  {
    "id": "arXiv:2106.11575",
    "title": "Learn to Resolve Conversational Dependency: A Consistency Training  Framework for Conversational Question Answering",
    "abstract": "One of the main challenges in conversational question answering (CQA) is to\nresolve the conversational dependency, such as anaphora and ellipsis. However,\nexisting approaches do not explicitly train QA models on how to resolve the\ndependency, and thus these models are limited in understanding human dialogues.\nIn this paper, we propose a novel framework, ExCorD (Explicit guidance on how\nto resolve Conversational Dependency) to enhance the abilities of QA models in\ncomprehending conversational context. ExCorD first generates self-contained\nquestions that can be understood without the conversation history, then trains\na QA model with the pairs of original and self-contained questions using a\nconsistency-based regularizer. In our experiments, we demonstrate that ExCorD\nsignificantly improves the QA models' performance by up to 1.2 F1 on QuAC, and\n5.2 F1 on CANARD, while addressing the limitations of the existing approaches.",
    "descriptor": "\nComments: 12 pages, ACL 2021\n",
    "authors": [
      "Gangwoo Kim",
      "Hyunjae Kim",
      "Jungsoo Park",
      "Jaewoo Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11575"
  },
  {
    "id": "arXiv:2106.11576",
    "title": "Universal Domain Adaptation in Ordinal Regression",
    "abstract": "We address the problem of universal domain adaptation (UDA) in ordinal\nregression (OR), which attempts to solve classification problems in which\nlabels are not independent, but follow a natural order. We show that the UDA\ntechniques developed for classification and based on the clustering assumption,\nunder-perform in OR settings. We propose a method that complements the OR\nclassifier with an auxiliary task of order learning, which plays the double\nrole of discriminating between common and private instances, and expanding\nclass labels to the private target images via ranking. Combined with\nadversarial domain discrimination, our model is able to address the closed set,\npartial and open set configurations. We evaluate our method on three face age\nestimation datasets, and show that it outperforms the baseline methods.",
    "descriptor": "",
    "authors": [
      "Chidlovskii Boris",
      "Assem Sadek",
      "Christian Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11576"
  },
  {
    "id": "arXiv:2106.11581",
    "title": "Continuous-Depth Neural Models for Dynamic Graph Prediction",
    "abstract": "We introduce the framework of continuous-depth graph neural networks (GNNs).\nNeural graph differential equations (Neural GDEs) are formalized as the\ncounterpart to GNNs where the input-output relationship is determined by a\ncontinuum of GNN layers, blending discrete topological structures and\ndifferential equations. The proposed framework is shown to be compatible with\nstatic GNN models and is extended to dynamic and stochastic settings through\nhybrid dynamical system theory. Here, Neural GDEs improve performance by\nexploiting the underlying dynamics geometry, further introducing the ability to\naccommodate irregularly sampled data. Results prove the effectiveness of the\nproposed models across applications, such as traffic forecasting or prediction\nin genetic regulatory networks.",
    "descriptor": "\nComments: Extended version of the workshop paper \"Graph Neural Ordinary Differential Equations\". arXiv admin note: substantial text overlap with arXiv:1911.07532\n",
    "authors": [
      "Michael Poli",
      "Stefano Massaroli",
      "Clayton M. Rabideau",
      "Junyoung Park",
      "Atsushi Yamashita",
      "Hajime Asama",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11581"
  },
  {
    "id": "arXiv:2106.11582",
    "title": "A Comparison for Patch-level Classification of Deep Learning Methods on  Transparent Images: from Convolutional Neural Networks to Visual Transformers",
    "abstract": "Nowadays, analysis of transparent images in the field of computer vision has\ngradually become a hot spot. In this paper, we compare the classification\nperformance of different deep learning for the problem that transparent images\nare difficult to analyze. We crop the transparent images into 8 * 8 and 224 *\n224 pixels patches in the same proportion, and then divide the two different\npixels patches into foreground and background according to groundtruch. We also\nuse 4 types of convolutional neural networks and a novel ViT network model to\ncompare the foreground and background classification experiments. We conclude\nthat ViT performs the worst in classifying 8 * 8 pixels patches, but it\noutperforms most convolutional neural networks in classifying 224 * 224.",
    "descriptor": "",
    "authors": [
      "Hechen Yang",
      "Chen Li",
      "Peng Zhao",
      "Ao Chen",
      "Xin Zhao",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11582"
  },
  {
    "id": "arXiv:2106.11586",
    "title": "Optimal input signal distribution for nonlinear optical fiber channel  with small Kerr nonlinearity",
    "abstract": "We consider the information channel described by Schr\\\"{o}dinger equation\nwith additive Gaussian noise. We introduce the model of the input signal and\nthe model of the output signal receiver. For this channel, using perturbation\ntheory for the small nonlinearity parameter, we calculate the first three terms\nof the expansion of the conditional probability density function in the\nnonlinearity parameter. At large signal-to-noise power ratio we calculate the\nconditional entropy, the output signal entropy, and the mutual information in\nthe leading and next-to-leading order in the nonlinearity parameter and in the\nleading order in the parameter $1/\\mathrm{SNR}$. Using the mutual information\nwe find the optimal input signal distribution and channel capacity in the\nleading and next-to-leading order in the nonlinearity parameter. Finally, we\npresent the method of the construction of the input signal with the optimal\nstatistics for the given shape of the signal.",
    "descriptor": "\nComments: 32 pages, 7 figures\n",
    "authors": [
      "A. V. Reznichenko",
      "A. I. Chernykh",
      "E. V. Sedov",
      "I. S. Terekhov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11586"
  },
  {
    "id": "arXiv:2106.11589",
    "title": "Part-Aware Measurement for Robust Multi-View Multi-Human 3D Pose  Estimation and Tracking",
    "abstract": "This paper introduces an approach for multi-human 3D pose estimation and\ntracking based on calibrated multi-view. The main challenge lies in finding the\ncross-view and temporal correspondences correctly even when several human pose\nestimations are noisy. Compare to previous solutions that construct 3D poses\nfrom multiple views, our approach takes advantage of temporal consistency to\nmatch the 2D poses estimated with previously constructed 3D skeletons in every\nview. Therefore cross-view and temporal associations are accomplished\nsimultaneously. Since the performance suffers from mistaken association and\nnoisy predictions, we design two strategies for aiming better correspondences\nand 3D reconstruction. Specifically, we propose a part-aware measurement for\n2D-3D association and a filter that can cope with 2D outliers during\nreconstruction. Our approach is efficient and effective comparing to\nstate-of-the-art methods; it achieves competitive results on two benchmarks:\n96.8% on Campus and 97.4% on Shelf. Moreover, we extends the length of Campus\nevaluation frames to be more challenging and our proposal also reach\nwell-performed result.",
    "descriptor": "\nComments: 12 pages with supplementary material; accepted to CVPR 2021 B-AMFG Workshop\n",
    "authors": [
      "Hau Chu",
      "Jia-Hong Lee",
      "Yao-Chih Lee",
      "Ching-Hsien Hsu",
      "Jia-Da Li",
      "Chu-Song Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11589"
  },
  {
    "id": "arXiv:2106.11593",
    "title": "A Vertical Federated Learning Framework for Graph Convolutional Network",
    "abstract": "Recently, Graph Neural Network (GNN) has achieved remarkable success in\nvarious real-world problems on graph data. However in most industries, data\nexists in the form of isolated islands and the data privacy and security is\nalso an important issue. In this paper, we propose FedVGCN, a federated GCN\nlearning paradigm for privacy-preserving node classification task under data\nvertically partitioned setting, which can be generalized to existing GCN\nmodels. Specifically, we split the computation graph data into two parts. For\neach iteration of the training process, the two parties transfer intermediate\nresults to each other under homomorphic encryption. We conduct experiments on\nbenchmark data and the results demonstrate the effectiveness of FedVGCN in the\ncase of GraphSage.",
    "descriptor": "",
    "authors": [
      "Xiang Ni",
      "Xiaolong Xu",
      "Lingjuan Lyu",
      "Changhua Meng",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11593"
  },
  {
    "id": "arXiv:2106.11594",
    "title": "Efficient recursive least squares solver for rank-deficient matrices",
    "abstract": "Updating a linear least squares solution can be critical for near real-time\nsignalprocessing applications. The Greville algorithm proposes a simple formula\nfor updating the pseudoinverse of a matrix A $\\in$ R nxm with rank r. In this\npaper, we explicitly derive a similar formula by maintaining a general rank\nfactorization, which we call rank-Greville. Based on this formula, we\nimplemented a recursive least squares algorithm exploiting the rank-deficiency\nof A, achieving the update of the minimum-norm least-squares solution in O(mr)\noperations and, therefore, solving the linear least-squares problem from\nscratch in O(nmr) operations. We empirically confirmed that this algorithm\ndisplays a better asymptotic time complexity than LAPACK solvers for\nrank-deficient matrices. The numerical stability of rank-Greville was found to\nbe comparable to Cholesky-based solvers. Nonetheless, our implementation\nsupports exact numerical representations of rationals, due to its remarkable\nalgebraic simplicity.",
    "descriptor": "",
    "authors": [
      "Ruben Staub",
      "Stephan N. Steinmann"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2106.11594"
  },
  {
    "id": "arXiv:2106.11595",
    "title": "Reinforcement learning for PHY layer communications",
    "abstract": "In this chapter, we will give comprehensive examples of applying RL in\noptimizing the physical layer of wireless communications by defining different\nclass of problems and the possible solutions to handle them. In Section 9.2, we\npresent all the basic theory needed to address a RL problem, i.e. Markov\ndecision process (MDP), Partially observable Markov decision process (POMDP),\nbut also two very important and widely used algorithms for RL, i.e. the\nQ-learning and SARSA algorithms. We also introduce the deep reinforcement\nlearning (DRL) paradigm and the section ends with an introduction to the\nmulti-armed bandits (MAB) framework. Section 9.3 focuses on some toy examples\nto illustrate how the basic concepts of RL are employed in communication\nsystems. We present applications extracted from literature with simplified\nsystem models using similar notation as in Section 9.2 of this Chapter. In\nSection 9.3, we also focus on modeling RL problems, i.e. how action and state\nspaces and rewards are chosen. The Chapter is concluded in Section 9.4 with a\nprospective thought on RL trends and it ends with a review of a broader state\nof the art in Section 9.5.",
    "descriptor": "\nComments: Machine Learning and Wireless Communications, In press\n",
    "authors": [
      "Philippe Mary",
      "Visa Koivunen",
      "Christophe Moy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.11595"
  },
  {
    "id": "arXiv:2106.11596",
    "title": "Multi-layered Semantic Representation Network for Multi-label Image  Classification",
    "abstract": "Multi-label image classification (MLIC) is a fundamental and practical task,\nwhich aims to assign multiple possible labels to an image. In recent years,\nmany deep convolutional neural network (CNN) based approaches have been\nproposed which model label correlations to discover semantics of labels and\nlearn semantic representations of images. This paper advances this research\ndirection by improving both the modeling of label correlations and the learning\nof semantic representations. On the one hand, besides the local semantics of\neach label, we propose to further explore global semantics shared by multiple\nlabels. On the other hand, existing approaches mainly learn the semantic\nrepresentations at the last convolutional layer of a CNN. But it has been noted\nthat the image representations of different layers of CNN capture different\nlevels or scales of features and have different discriminative abilities. We\nthus propose to learn semantic representations at multiple convolutional\nlayers. To this end, this paper designs a Multi-layered Semantic Representation\nNetwork (MSRN) which discovers both local and global semantics of labels\nthrough modeling label correlations and utilizes the label semantics to guide\nthe semantic representations learning at multiple layers through an attention\nmechanism. Extensive experiments on four benchmark datasets including VOC 2007,\nCOCO, NUS-WIDE, and Apparel show a competitive performance of the proposed MSRN\nagainst state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Xiwen Qu",
      "Hao Che",
      "Jun Huang",
      "Linchuan Xu",
      "Xiao Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11596"
  },
  {
    "id": "arXiv:2106.11603",
    "title": "Information Retrieval for ZeroSpeech 2021: The Submission by University  of Wroclaw",
    "abstract": "We present a number of low-resource approaches to the tasks of the Zero\nResource Speech Challenge 2021. We build on the unsupervised representations of\nspeech proposed by the organizers as a baseline, derived from CPC and clustered\nwith the k-means algorithm. We demonstrate that simple methods of refining\nthose representations can narrow the gap, or even improve upon the solutions\nwhich use a high computational budget. The results lead to the conclusion that\nthe CPC-derived representations are still too noisy for training language\nmodels, but stable enough for simpler forms of pattern matching and retrieval.",
    "descriptor": "\nComments: Published in Interspeech 2021\n",
    "authors": [
      "Jan Chorowski",
      "Grzegorz Ciesielski",
      "Jaros\u0142aw Dzikowski",
      "Adrian \u0141a\u0144cucki",
      "Ricard Marxer",
      "Mateusz Opala",
      "Piotr Pusz",
      "Pawe\u0142 Rychlikowski",
      "Micha\u0142 Stypu\u0142kowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.11603"
  },
  {
    "id": "arXiv:2106.11607",
    "title": "BCH codes over $\\gf(q)$ with length $q^m+1$",
    "abstract": "BCH codes are an interesting class of cyclic codes due to their efficient\nencoding and decoding algorithms. In many cases, BCH codes are the best linear\ncodes. However, the dimension and minimum distance of BCH codes have been\nseldom solved. Until now, there have been few results on BCH codes over\n$\\gf(q)$ with length $q^m+1$, especially when $q$ is a prime power and $m$ is\neven. The objective of this paper is to study BCH codes of this type over\nfinite fields and analyse their parameters. The BCH codes presented in this\npaper have good parameters in general, and contain many optimal linear codes.",
    "descriptor": "\nComments: BCH code, cyclic code, linear code, optimal code\n",
    "authors": [
      "Xiaoqiang Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11607"
  },
  {
    "id": "arXiv:2106.11609",
    "title": "Distributional Gradient Matching for Learning Uncertain Neural Dynamics  Models",
    "abstract": "Differential equations in general and neural ODEs in particular are an\nessential technique in continuous-time system identification. While many\ndeterministic learning algorithms have been designed based on numerical\nintegration via the adjoint method, many downstream tasks such as active\nlearning, exploration in reinforcement learning, robust control, or filtering\nrequire accurate estimates of predictive uncertainties. In this work, we\npropose a novel approach towards estimating epistemically uncertain neural\nODEs, avoiding the numerical integration bottleneck. Instead of modeling\nuncertainty in the ODE parameters, we directly model uncertainties in the state\nspace. Our algorithm - distributional gradient matching (DGM) - jointly trains\na smoother and a dynamics model and matches their gradients via minimizing a\nWasserstein loss. Our experiments show that, compared to traditional\napproximate inference methods based on numerical integration, our approach is\nfaster to train, faster at predicting previously unseen trajectories, and in\nthe context of neural ODEs, significantly more accurate.",
    "descriptor": "",
    "authors": [
      "Lenart Treven",
      "Philippe Wenk",
      "Florian D\u00f6rfler",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11609"
  },
  {
    "id": "arXiv:2106.11610",
    "title": "SynGuar: Guaranteeing Generalization in Programming by Example",
    "abstract": "Programming by Example (PBE) is a program synthesis paradigm in which the\nsynthesizer creates a program that matches a set of given examples. In many\napplications of such synthesis (e.g., program repair or reverse engineering),\nwe are to reconstruct a program that is close to a specific target program, not\nmerely to produce some program that satisfies the seen examples. In such\nsettings, we wish that the synthesized program generalizes well, i.e., has as\nfew errors as possible on the unobserved examples capturing the target function\nbehavior. In this paper, we propose the first framework (called SynGuar) for\nPBE synthesizers that guarantees to achieve low generalization error with high\nprobability. Our main contribution is a procedure to dynamically calculate how\nmany additional examples suffice to theoretically guarantee generalization. We\nshow how our techniques can be used in 2 well-known synthesis approaches: PROSE\nand STUN (synthesis through unification), for common string-manipulation\nprogram benchmarks. We find that often a few hundred examples suffice to\nprovably bound generalization error below $5\\%$ with high ($\\geq 98\\%$)\nprobability on these benchmarks. Further, we confirm this empirically: SynGuar\nsignificantly improves the accuracy of existing synthesizers in generating the\nright target programs. But with fewer examples chosen arbitrarily, the same\nbaseline synthesizers (without SynGuar) overfit and lose accuracy.",
    "descriptor": "",
    "authors": [
      "Bo Wang",
      "Teodora Baluta",
      "Aashish Kolluri",
      "Prateek Saxena"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.11610"
  },
  {
    "id": "arXiv:2106.11612",
    "title": "Uniform-PAC Bounds for Reinforcement Learning with Linear Function  Approximation",
    "abstract": "We study reinforcement learning (RL) with linear function approximation.\nExisting algorithms for this problem only have high-probability regret and/or\nProbably Approximately Correct (PAC) sample complexity guarantees, which cannot\nguarantee the convergence to the optimal policy. In this paper, in order to\novercome the limitation of existing algorithms, we propose a new algorithm\ncalled FLUTE, which enjoys uniform-PAC convergence to the optimal policy with\nhigh probability. The uniform-PAC guarantee is the strongest possible guarantee\nfor reinforcement learning in the literature, which can directly imply both PAC\nand high probability regret bounds, making our algorithm superior to all\nexisting algorithms with linear function approximation. At the core of our\nalgorithm is a novel minimax value function estimator and a multi-level\npartition scheme to select the training samples from historical observations.\nBoth of these techniques are new and of independent interest.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Jiafan He",
      "Dongruo Zhou",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11612"
  },
  {
    "id": "arXiv:2106.11613",
    "title": "Zero-Shot Chinese Character Recognition with Stroke-Level Decomposition",
    "abstract": "Chinese character recognition has attracted much research interest due to its\nwide applications. Although it has been studied for many years, some issues in\nthis field have not been completely resolved yet, e.g. the zero-shot problem.\nPrevious character-based and radical-based methods have not fundamentally\naddressed the zero-shot problem since some characters or radicals in test sets\nmay not appear in training sets under a data-hungry condition. Inspired by the\nfact that humans can generalize to know how to write characters unseen before\nif they have learned stroke orders of some characters, we propose a\nstroke-based method by decomposing each character into a sequence of strokes,\nwhich are the most basic units of Chinese characters. However, we observe that\nthere is a one-to-many relationship between stroke sequences and Chinese\ncharacters. To tackle this challenge, we employ a matching-based strategy to\ntransform the predicted stroke sequence to a specific character. We evaluate\nthe proposed method on handwritten characters, printed artistic characters, and\nscene characters. The experimental results validate that the proposed method\noutperforms existing methods on both character zero-shot and radical zero-shot\ntasks. Moreover, the proposed method can be easily generalized to other\nlanguages whose characters can be decomposed into strokes.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Jingye Chen",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11613"
  },
  {
    "id": "arXiv:2106.11621",
    "title": "Near-Delaunay Metrics",
    "abstract": "We study metrics that assess how close a triangulation is to being a Delaunay\ntriangulation, for use in contexts where a good triangulation is desired but\nconstraints (e.g., maximum degree) prevent the use of the Delaunay\ntriangulation itself. Our near-Delaunay metrics derive from common Delaunay\nproperties and satisfy a basic set of design criteria, such as being invariant\nunder similarity transformations. We compare the metrics, showing that each can\nmake different judgments as to which triangulation is closer to Delaunay. We\nalso present a preliminary experiment, showing how optimizing for these metrics\nunder different constraints gives similar, but not necessarily identical\nresults, on random and constructed small point sets.",
    "descriptor": "",
    "authors": [
      "Nathan van Beusekom",
      "Kevin Buchin",
      "Hidde Koerts",
      "Wouter Meulemans",
      "Benjamin Rodatz",
      "Bettina Speckmann"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.11621"
  },
  {
    "id": "arXiv:2106.11626",
    "title": "Morse-Smale complexes on convex polyhedra",
    "abstract": "Motivated by applications in geomorphology, the aim of this paper is to\nextend Morse-Smale theory from smooth functions to the radial distance function\n(measured from an internal point), defining a convex polyhedron in\n3-dimensional Euclidean space. The resulting polyhedral Morse-Smale complex may\nbe regarded, on one hand, as a generalization of the Morse-Smale complex of the\nsmooth radial distance function defining a smooth, convex body, on the other\nhand, it could be also regarded as a generalization of the Morse-Smale complex\nof the piecewise linear parallel distance function (measured from a plane),\ndefining a polyhedral surface. Beyond similarities, our paper also highlights\nthe marked differences between these three problems and it also includes the\ndesign, implementation and testing of an explicit algorithm computing the\nMorse-Smale complex on a convex polyhedron.",
    "descriptor": "\nComments: 19 pages, 8 figures\n",
    "authors": [
      "Bal\u00e1zs Ludm\u00e1ny",
      "Zsolt L\u00e1ngi",
      "G\u00e1bor Domokos"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2106.11626"
  },
  {
    "id": "arXiv:2106.11629",
    "title": "On Adversarial Robustness of Synthetic Code Generation",
    "abstract": "Automatic code synthesis from natural language descriptions is a challenging\ntask. We witness massive progress in developing code generation systems for\ndomain-specific languages (DSLs) employing sequence-to-sequence deep learning\ntechniques in the recent past. In this paper, we specifically experiment with\n\\textsc{AlgoLisp} DSL-based generative models and showcase the existence of\nsignificant dataset bias through different classes of adversarial examples. We\nalso experiment with two variants of Transformer-based models that outperform\nall existing \\textsc{AlgoLisp} DSL-based code generation baselines. Consistent\nwith the current state-of-the-art systems, our proposed models, too, achieve\npoor performance under adversarial settings. Therefore, we propose several\ndataset augmentation techniques to reduce bias and showcase their efficacy\nusing robust experimentation.",
    "descriptor": "",
    "authors": [
      "Mrinal Anand",
      "Pratik Kayal",
      "Mayank Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.11629"
  },
  {
    "id": "arXiv:2106.11641",
    "title": "Confidence-Aware Learning for Camouflaged Object Detection",
    "abstract": "Confidence-aware learning is proven as an effective solution to prevent\nnetworks becoming overconfident. We present a confidence-aware camouflaged\nobject detection framework using dynamic supervision to produce both accurate\ncamouflage map and meaningful \"confidence\" representing model awareness about\nthe current prediction. A camouflaged object detection network is designed to\nproduce our camouflage prediction. Then, we concatenate it with the input image\nand feed it to the confidence estimation network to produce an one channel\nconfidence map.We generate dynamic supervision for the confidence estimation\nnetwork, representing the agreement of camouflage prediction with the ground\ntruth camouflage map. With the produced confidence map, we introduce\nconfidence-aware learning with the confidence map as guidance to pay more\nattention to the hard/low-confidence pixels in the loss function. We claim\nthat, once trained, our confidence estimation network can evaluate pixel-wise\naccuracy of the prediction without relying on the ground truth camouflage map.\nExtensive results on four camouflaged object detection testing datasets\nillustrate the superior performance of the proposed model in explaining the\ncamouflage prediction.",
    "descriptor": "",
    "authors": [
      "Jiawei Liu",
      "Jing Zhang",
      "Nick Barnes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11641"
  },
  {
    "id": "arXiv:2106.11642",
    "title": "Repulsive Deep Ensembles are Bayesian",
    "abstract": "Deep ensembles have recently gained popularity in the deep learning community\nfor their conceptual simplicity and efficiency. However, maintaining functional\ndiversity between ensemble members that are independently trained with gradient\ndescent is challenging. This can lead to pathologies when adding more ensemble\nmembers, such as a saturation of the ensemble performance, which converges to\nthe performance of a single model. Moreover, this does not only affect the\nquality of its predictions, but even more so the uncertainty estimates of the\nensemble, and thus its performance on out-of-distribution data. We hypothesize\nthat this limitation can be overcome by discouraging different ensemble members\nfrom collapsing to the same function. To this end, we introduce a kernelized\nrepulsive term in the update rule of the deep ensembles. We show that this\nsimple modification not only enforces and maintains diversity among the members\nbut, even more importantly, transforms the maximum a posteriori inference into\nproper Bayesian inference. Namely, we show that the training dynamics of our\nproposed repulsive ensembles follow a Wasserstein gradient flow of the KL\ndivergence with the true posterior. We study repulsive terms in weight and\nfunction space and empirically compare their performance to standard ensembles\nand Bayesian baselines on synthetic and real-world prediction tasks.",
    "descriptor": "",
    "authors": [
      "Francesco D'Angelo",
      "Vincent Fortuin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11642"
  },
  {
    "id": "arXiv:2106.11644",
    "title": "Self-Supervised Iterative Contextual Smoothing for Efficient Adversarial  Defense against Gray- and Black-Box Attack",
    "abstract": "We propose a novel and effective input transformation based adversarial\ndefense method against gray- and black-box attack, which is computationally\nefficient and does not require any adversarial training or retraining of a\nclassification model. We first show that a very simple iterative Gaussian\nsmoothing can effectively wash out adversarial noise and achieve substantially\nhigh robust accuracy. Based on the observation, we propose Self-Supervised\nIterative Contextual Smoothing (SSICS), which aims to reconstruct the original\ndiscriminative features from the Gaussian-smoothed image in context-adaptive\nmanner, while still smoothing out the adversarial noise. From the experiments\non ImageNet, we show that our SSICS achieves both high standard accuracy and\nvery competitive robust accuracy for the gray- and black-box attacks; e.g.,\ntransfer-based PGD-attack and score-based attack. A note-worthy point to stress\nis that our defense is free of computationally expensive adversarial training,\nyet, can approach its robust accuracy via input transformation.",
    "descriptor": "\nComments: Preprint version\n",
    "authors": [
      "Sungmin Cha",
      "Naeun Ko",
      "Youngjoon Yoo",
      "Taesup Moon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11644"
  },
  {
    "id": "arXiv:2106.11650",
    "title": "A Survey on Human-aware Robot Navigation",
    "abstract": "Intelligent systems are increasingly part of our everyday lives and have been\nintegrated seamlessly to the point where it is difficult to imagine a world\nwithout them. Physical manifestations of those systems on the other hand, in\nthe form of embodied agents or robots, have so far been used only for specific\napplications and are often limited to functional roles (e.g. in the industry,\nentertainment and military fields). Given the current growth and innovation in\nthe research communities concerned with the topics of robot navigation,\nhuman-robot-interaction and human activity recognition, it seems like this\nmight soon change. Robots are increasingly easy to obtain and use and the\nacceptance of them in general is growing. However, the design of a socially\ncompliant robot that can function as a companion needs to take various areas of\nresearch into account. This paper is concerned with the navigation aspect of a\nsocially-compliant robot and provides a survey of existing solutions for the\nrelevant areas of research as well as an outlook on possible future directions.",
    "descriptor": "\nComments: Robotics and Autonomous Systems, 2021\n",
    "authors": [
      "Ronja M\u00f6ller",
      "Antonino Furnari",
      "Sebastiano Battiato",
      "Aki H\u00e4rm\u00e4",
      "Giovanni Maria Farinella"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11650"
  },
  {
    "id": "arXiv:2106.11652",
    "title": "MMD-MIX: Value Function Factorisation with Maximum Mean Discrepancy for  Cooperative Multi-Agent Reinforcement Learning",
    "abstract": "In the real world, many tasks require multiple agents to cooperate with each\nother under the condition of local observations. To solve such problems, many\nmulti-agent reinforcement learning methods based on Centralized Training with\nDecentralized Execution have been proposed. One representative class of work is\nvalue decomposition, which decomposes the global joint Q-value $Q_\\text{jt}$\ninto individual Q-values $Q_a$ to guide individuals' behaviors, e.g. VDN\n(Value-Decomposition Networks) and QMIX. However, these baselines often ignore\nthe randomness in the situation. We propose MMD-MIX, a method that combines\ndistributional reinforcement learning and value decomposition to alleviate the\nabove weaknesses. Besides, to improve data sampling efficiency, we were\ninspired by REM (Random Ensemble Mixture) which is a robust RL algorithm to\nexplicitly introduce randomness into the MMD-MIX. The experiments demonstrate\nthat MMD-MIX outperforms prior baselines in the StarCraft Multi-Agent Challenge\n(SMAC) environment.",
    "descriptor": "\nComments: 7 pages, 2 figures, 2 tables. Accepted by IJCNN 2021\n",
    "authors": [
      "Zhiwei Xu",
      "Dapeng Li",
      "Yunpeng Bai",
      "Guoliang Fan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11652"
  },
  {
    "id": "arXiv:2106.11653",
    "title": "Give Me Your Trained Model: Domain Adaptive Semantic Segmentation  without Source Data",
    "abstract": "Benefited from considerable pixel-level annotations collected from a specific\nsituation (source), the trained semantic segmentation model performs quite\nwell, but fails in a new situation (target) due to the large domain shift. To\nmitigate the domain gap, previous cross-domain semantic segmentation methods\nalways assume the co-existence of source data and target data during\ndistribution alignment. However, the access to source data in the real scenario\nmay raise privacy concerns and violate intellectual property. To tackle this\nproblem, we focus on an interesting and challenging cross-domain semantic\nsegmentation task where only the trained source model is provided to the target\ndomain, and further propose a unified framework called Domain Adaptive Semantic\nSegmentation without Source data (DAS$^3$ for short). Specifically, DAS$^3$\nconsists of three schemes, i.e., feature alignment, self-training, and\ninformation propagation. First, we mainly develop a focal entropic loss on the\nnetwork outputs to implicitly align the target features with unseen source\nfeatures via the provided source model. Second, besides positive pseudo labels\nin vanilla self-training, we first introduce negative pseudo labels to the\nfield and develop a bi-directional self-training strategy to enhance the\nrepresentation learning in the target domain. Finally, the information\npropagation scheme further reduces the intra-domain discrepancy within the\ntarget domain via pseudo semi-supervised learning. Extensive results on\nsynthesis-to-real and cross-city driving datasets validate DAS$^3$ yields\nstate-of-the-art performance, even on par with methods that need access to\nsource data.",
    "descriptor": "",
    "authors": [
      "Yuxi Wang",
      "Jian Liang",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11653"
  },
  {
    "id": "arXiv:2106.11654",
    "title": "Energy Efficient In-memory Hyperdimensional Encoding for Spatio-temporal  Signal Processing",
    "abstract": "The emerging brain-inspired computing paradigm known as hyperdimensional\ncomputing (HDC) has been proven to provide a lightweight learning framework for\nvarious cognitive tasks compared to the widely used deep learning-based\napproaches. Spatio-temporal (ST) signal processing, which encompasses\nbiosignals such as electromyography (EMG) and electroencephalography (EEG), is\none family of applications that could benefit from an HDC-based learning\nframework. At the core of HDC lie manipulations and comparisons of large bit\npatterns, which are inherently ill-suited to conventional computing platforms\nbased on the von-Neumann architecture. In this work, we propose an architecture\nfor ST signal processing within the HDC framework using predominantly in-memory\ncompute arrays. In particular, we introduce a methodology for the in-memory\nhyperdimensional encoding of ST data to be used together with an in-memory\nassociative search module. We show that the in-memory HDC encoder for ST\nsignals offers at least 1.80x energy efficiency gains, 3.36x area gains, as\nwell as 9.74x throughput gains compared with a dedicated digital hardware\nimplementation. At the same time it achieves a peak classification accuracy\nwithin 0.04% of that of the baseline HDC framework.",
    "descriptor": "",
    "authors": [
      "Geethan Karunaratne",
      "Manuel Le Gallo",
      "Michael Hersche",
      "Giovanni Cherubini",
      "Luca Benini",
      "Abu Sebastian",
      "Abbas Rahimi"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2106.11654"
  },
  {
    "id": "arXiv:2106.11655",
    "title": "On Constrained Optimization in Differentiable Neural Architecture Search",
    "abstract": "Differentiable Architecture Search (DARTS) is a recently proposed neural\narchitecture search (NAS) method based on a differentiable relaxation. Due to\nits success, numerous variants analyzing and improving parts of the DARTS\nframework have recently been proposed. By considering the problem as a\nconstrained bilevel optimization, we propose and analyze three improvements to\narchitectural weight competition, update scheduling, and regularization towards\ndiscretization. First, we introduce a new approach to the activation of\narchitecture weights, which prevents confounding competition within an edge and\nallows for fair comparison across edges to aid in discretization. Next, we\npropose a dynamic schedule based on per-minibatch network information to make\narchitecture updates more informed. Finally, we consider two regularizations,\nbased on proximity to discretization and the Alternating Directions Method of\nMultipliers (ADMM) algorithm, to promote early discretization. Our results show\nthat this new activation scheme reduces final architecture size and the\nregularizations improve reliability in search results while maintaining\ncomparable performance to state-of-the-art in NAS, especially when used with\nour new dynamic informed schedule.",
    "descriptor": "",
    "authors": [
      "Kaitlin Maile",
      "Erwan Lecarpentier",
      "Herv\u00e9 Luga",
      "Dennis G. Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11655"
  },
  {
    "id": "arXiv:2106.11656",
    "title": "HAP-Reserved Communications in Space-Air-Ground Integrated Networks",
    "abstract": "Terrestrial communication networks have experienced significant development\nin recent years by providing emerging services for ground users. However, one\ncritical challenge raised is to provide full coverage (especially in dense\nhigh-rise urban environments) for ground users due to scarce network resources\nand limited coverage. To meet this challenge, we propose a high altitude\nplatform (HAP)-reserved ground-air-space (GAS) transmission scheme, which\ncombines with the ground-to-space (G2S) transmission scheme to strengthen the\nterrestrial communication and save the transmission power. To integrate the two\ntransmission schemes, we propose a transmission control strategy. Wherein, the\nground user decides its transmission scheme, i.e., switches between the GAS\nlink transmission and the G2S link transmission with a probability. We then\nmaximize the overall throughput and derive the optimal probability that a\nground user adopts the GAS transmission scheme. Numerical results demonstrate\nthe superiority of the proposed transmission control strategy.",
    "descriptor": "",
    "authors": [
      "Xuelin Cao",
      "Bo Yang",
      "Chau Yuen",
      "Zhu Han"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.11656"
  },
  {
    "id": "arXiv:2106.11675",
    "title": "Preprocessing to Reduce the Search Space: Antler Structures for Feedback  Vertex Set",
    "abstract": "The goal of this paper is to open up a new research direction aimed at\nunderstanding the power of preprocessing in speeding up algorithms that solve\nNP-hard problems exactly. We explore this direction for the classic Feedback\nVertex Set problem on undirected graphs, leading to a new type of graph\nstructure called antler decomposition, which identifies vertices that belong to\nan optimal solution. It is an analogue of the celebrated crown decomposition\nwhich has been used for Vertex Cover. We develop the graph structure theory\naround such decompositions and develop fixed-parameter tractable algorithms to\nfind them, parameterized by the number of vertices for which they witness\npresence in an optimal solution. This reduces the search space of\nfixed-parameter tractable algorithms parameterized by the solution size that\nsolve Feedback Vertex Set.",
    "descriptor": "",
    "authors": [
      "Huib Donkers",
      "Bart M.P. Jansen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.11675"
  },
  {
    "id": "arXiv:2106.11676",
    "title": "Proof-of-Vax: Studying User Preferences and Perception of Covid  Vaccination Certificates",
    "abstract": "Digital tools play an important role in fighting the current global COVID-19\npandemic. We conducted a representative online study in Germany on a sample of\n599 participants to evaluate the user perception of vaccination certificates.\nWe investigated five different variants of vaccination certificates, based on\ndeployed and planned designs in a between-group design, including paper-based\nand app-based variants. Our main results show that the willingness to use and\nadopt vaccination certificates is generally high. Overall, paper-based\nvaccination certificates were favored over app-based solutions. The willingness\nto use digital apps decreased significantly by a higher disposition to privacy,\nand increased by higher worries about the pandemic and acceptance of the\ncoronavirus vaccination. Vaccination certificates resemble an interesting use\ncase for studying privacy perceptions for health related data. We hope that our\nwork will be able to educate the currently ongoing design of vaccination\ncertificates, will give us deeper insights into privacy of health-related data\nand apps, and prepare us for future potential applications of vaccination\ncertificates and health apps in general.",
    "descriptor": "\nComments: 22 pages, 4 figures, 5 tables\n",
    "authors": [
      "Marvin Kowalewski",
      "Franziska Herbert",
      "Theodor Schnitzler",
      "Markus D\u00fcrmuth"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11676"
  },
  {
    "id": "arXiv:2106.11689",
    "title": "On the Parameterized Complexity of the Connected Flow and Many Visits  TSP Problem",
    "abstract": "We study a variant of Min Cost Flow in which the flow needs to be connected.\nSpecifically, in the Connected Flow problem one is given a directed graph $G$,\nalong with a set of demand vertices $D \\subseteq V(G)$ with demands\n$\\mathsf{dem}: D \\rightarrow \\mathbb{N}$, and costs and capacities for each\nedge. The goal is to find a minimum cost flow that satisfies the demands,\nrespects the capacities and induces a (strongly) connected subgraph. This\ngeneralizes previously studied problems like the (Many Visits) TSP. We study\nthe parameterized complexity of Connected Flow parameterized by $|D|$, the\ntreewidth $tw$ and by vertex cover size $k$ of $G$ and provide:\n(i) $\\mathsf{NP}$-completeness already for the case $|D|=2$ with only unit\ndemands and capacities and no edge costs, and fixed-parameter tractability if\nthere are no capacities,\n(ii) a fixed-parameter tractable $\\mathcal{O}^{\\star}(k^{\\mathcal{O}(k)})$\ntime algorithm for the general case, and a kernel of size polynomial in $k$ for\nthe special case of Many Visits TSP,\n(iii) an $|V(G)|^{\\mathcal{O}(tw)}$ time algorithm and a matching\n$|V(G)|^{o(tw)}$ time conditional lower bound conditioned on the Exponential\nTime Hypothesis.\nTo achieve some of our results, we significantly extend an approach by\nKowalik et al.~[ESA'20].",
    "descriptor": "\nComments: To be included in the proceedings of the 'International Workshop on Graph-Theoretic Concepts in Computer Science' (WG2021)\n",
    "authors": [
      "Isja Mannens",
      "Jesper Nederlof",
      "C\u00e9line Swennenhuis",
      "Krisztina Szil\u00e1gyi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.11689"
  },
  {
    "id": "arXiv:2106.11690",
    "title": "Gradient-based Label Binning in Multi-label Classification",
    "abstract": "In multi-label classification, where a single example may be associated with\nseveral class labels at the same time, the ability to model dependencies\nbetween labels is considered crucial to effectively optimize non-decomposable\nevaluation measures, such as the Subset 0/1 loss. The gradient boosting\nframework provides a well-studied foundation for learning models that are\nspecifically tailored to such a loss function and recent research attests the\nability to achieve high predictive accuracy in the multi-label setting. The\nutilization of second-order derivatives, as used by many recent boosting\napproaches, helps to guide the minimization of non-decomposable losses, due to\nthe information about pairs of labels it incorporates into the optimization\nprocess. On the downside, this comes with high computational costs, even if the\nnumber of labels is small. In this work, we address the computational\nbottleneck of such approach -- the need to solve a system of linear equations\n-- by integrating a novel approximation technique into the boosting procedure.\nBased on the derivatives computed during training, we dynamically group the\nlabels into a predefined number of bins to impose an upper bound on the\ndimensionality of the linear system. Our experiments, using an existing\nrule-based algorithm, suggest that this may boost the speed of training,\nwithout any significant loss in predictive performance.",
    "descriptor": "",
    "authors": [
      "Michael Rapp",
      "Eneldo Loza Menc\u00eda",
      "Johannes F\u00fcrnkranz",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11690"
  },
  {
    "id": "arXiv:2106.11692",
    "title": "A Unified Framework for Conservative Exploration",
    "abstract": "We study bandits and reinforcement learning (RL) subject to a conservative\nconstraint where the agent is asked to perform at least as well as a given\nbaseline policy. This setting is particular relevant in real-world domains\nincluding digital marketing, healthcare, production, finance, etc. For\nmulti-armed bandits, linear bandits and tabular RL, specialized algorithms and\ntheoretical analyses were proposed in previous work. In this paper, we present\na unified framework for conservative bandits and RL, in which our core\ntechnique is to calculate the necessary and sufficient budget obtained from\nrunning the baseline policy. For lower bounds, our framework gives a black-box\nreduction that turns a certain lower bound in the nonconservative setting into\na new lower bound in the conservative setting. We strengthen the existing lower\nbound for conservative multi-armed bandits and obtain new lower bounds for\nconservative linear bandits, tabular RL and low-rank MDP. For upper bounds, our\nframework turns a certain nonconservative upper-confidence-bound (UCB)\nalgorithm into a conservative algorithm with a simple analysis. For multi-armed\nbandits, linear bandits and tabular RL, our new upper bounds tighten or match\nexisting ones with significantly simpler analyses. We also obtain a new upper\nbound for conservative low-rank MDP.",
    "descriptor": "",
    "authors": [
      "Yunchang Yang",
      "Tianhao Wu",
      "Han Zhong",
      "Evrard Garcelon",
      "Matteo Pirotta",
      "Alessandro Lazaric",
      "Liwei Wang",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11692"
  },
  {
    "id": "arXiv:2106.11695",
    "title": "The Hitchhiker's Guide to Prior-Shift Adaptation",
    "abstract": "In many computer vision classification tasks, class priors at test time often\ndiffer from priors on the training set. In the case of such prior shift,\nclassifiers must be adapted correspondingly to maintain close to optimal\nperformance. This paper analyzes methods for adaptation of probabilistic\nclassifiers to new priors and for estimating new priors on an unlabeled test\nset. We propose a novel method to address a known issue of prior estimation\nmethods based on confusion matrices, where inconsistent estimates of decision\nprobabilities and confusion matrices lead to negative values in the estimated\npriors. Experiments on fine-grained image classification datasets provide\ninsight into the best practice of prior shift estimation and classifier\nadaptation and show that the proposed method achieves state-of-the-art results\nin prior adaptation. Applying the best practice to two tasks with naturally\nimbalanced priors, learning from web-crawled images and plant species\nclassification, increased the recognition accuracy by 1.1% and 3.4%\nrespectively.",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Tomas Sipka",
      "Milan Sulc",
      "Jiri Matas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11695"
  },
  {
    "id": "arXiv:2106.11696",
    "title": "Diversity-aware $k$-median : Clustering with fair center representation",
    "abstract": "We introduce a novel problem for diversity-aware clustering. We assume that\nthe potential cluster centers belong to a set of groups defined by protected\nattributes, such as ethnicity, gender, etc. We then ask to find a minimum-cost\nclustering of the data into $k$ clusters so that a specified minimum number of\ncluster centers are chosen from each group. We thus require that all groups are\nrepresented in the clustering solution as cluster centers, according to\nspecified requirements. More precisely, we are given a set of clients $C$, a\nset of facilities $\\pazocal{F}$, a collection $\\mathcal{F}=\\{F_1,\\dots,F_t\\}$\nof facility groups $F_i \\subseteq \\pazocal{F}$, budget $k$, and a set of\nlower-bound thresholds $R=\\{r_1,\\dots,r_t\\}$, one for each group in\n$\\mathcal{F}$. The \\emph{diversity-aware $k$-median problem} asks to find a set\n$S$ of $k$ facilities in $\\pazocal{F}$ such that $|S \\cap F_i| \\geq r_i$, that\nis, at least $r_i$ centers in $S$ are from group $F_i$, and the $k$-median cost\n$\\sum_{c \\in C} \\min_{s \\in S} d(c,s)$ is minimized. We show that in the\ngeneral case where the facility groups may overlap, the diversity-aware\n$k$-median problem is \\np-hard, fixed-parameter intractable, and inapproximable\nto any multiplicative factor. On the other hand, when the facility groups are\ndisjoint, approximation algorithms can be obtained by reduction to the\n\\emph{matroid median} and \\emph{red-blue median} problems. Experimentally, we\nevaluate our approximation methods for the tractable cases, and present a\nrelaxation-based heuristic for the theoretically intractable case, which can\nprovide high-quality and efficient solutions for real-world datasets.",
    "descriptor": "\nComments: To appear in ECML-PKDD 2021\n",
    "authors": [
      "Suhas Thejaswi",
      "Bruno Ordozgoiti",
      "Aristides Gionis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.11696"
  },
  {
    "id": "arXiv:2106.11702",
    "title": "Categorising Fine-to-Coarse Grained Misinformation: An Empirical Study  of COVID-19 Infodemic",
    "abstract": "The spreading COVID-19 misinformation over social media already draws the\nattention of many researchers. According to Google Scholar, about 26000\nCOVID-19 related misinformation studies have been published to date. Most of\nthese studies focusing on 1) detect and/or 2) analysing the characteristics of\nCOVID-19 related misinformation. However, the study of the social behaviours\nrelated to misinformation is often neglected. In this paper, we introduce a\nfine-grained annotated misinformation tweets dataset including social\nbehaviours annotation (e.g. comment or question to the misinformation). The\ndataset not only allows social behaviours analysis but also suitable for both\nevidence-based or non-evidence-based misinformation classification task. In\naddition, we introduce leave claim out validation in our experiments and\ndemonstrate the misinformation classification performance could be\nsignificantly different when applying to real-world unseen misinformation.",
    "descriptor": "",
    "authors": [
      "Ye Jiang",
      "Xingyi Song",
      "Carolina Scarton",
      "Ahmet Aker",
      "Kalina Bontcheva"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11702"
  },
  {
    "id": "arXiv:2106.11703",
    "title": "Connectivity of spaces of directed paths in geometric models for  concurrent computation",
    "abstract": "Higher Dimensional Automata (HDA) are higher dimensional relatives to\ntransition systems in concurrency theory taking into account to which degree\nvarious actions commute. Mathematically, they take the form of labelled cubical\ncomplexes. It is important to know, and challenging from a\ngeometric/topological perspective, whether the space of directed paths\n(executions in the model) between two vertices (states) is connected; more\ngenerally, to estimate higher connectedness of these path spaces.\nThis paper presents an approach for such an estimation for particularly\nsimple HDA modelling the access of a number of processors to a number of\nresources with given limited capacity each. It defines a spare capacity for a\nconcurrent program with prescribed periods of access of the processors to the\nresources. It shows that the connectedness of spaces of directed paths can be\nestimated (from above) by spare capacities. Moreover, spare capacities can also\nbe used to detect deadlocks and critical states in such a HDA.\nThe key theoretical ingredient is a transition from the calculation of local\nconnectedness bounds (of the upper links of vertices of an HDA) to global ones\nby applying a version of the nerve lemma due to Anders Bj\\\"orner.",
    "descriptor": "",
    "authors": [
      "Martin Raussen"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2106.11703"
  },
  {
    "id": "arXiv:2106.11710",
    "title": "Quantum-resistant digital signatures schemes for low-power IoT",
    "abstract": "Quantum computers are on the horizon to get to a sufficient size. These will\nthen be able to break most of the encryption and signature schemes currently in\nuse. This is the case for human interface devices as well as for IoT nodes. In\nthis paper i am comparing some signature schemes currently in the process of\nstandardization by the NIST. After explaining the underlying basis on why some\nschemes are different in some aspects compared to others i will evaluate which\ncurrently available implementations are better suited for usage in IoT\nuse-cases. We will come to further focus on the most promising schemes FALCON\nand Dilithium, which differ in one signifiant aspect that makes FALCON worse\nfor signing but very good for verification purposes.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Hannes Hattenbach"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2106.11710"
  },
  {
    "id": "arXiv:2106.11712",
    "title": "Learning Dynamical Systems from Noisy Sensor Measurements using Multiple  Shooting",
    "abstract": "Modeling dynamical systems plays a crucial role in capturing and\nunderstanding complex physical phenomena. When physical models are not\nsufficiently accurate or hardly describable by analytical formulas, one can use\ngeneric function approximators such as neural networks to capture the system\ndynamics directly from sensor measurements. As for now, current methods to\nlearn the parameters of these neural networks are highly sensitive to the\ninherent instability of most dynamical systems of interest, which in turn\nprevents the study of very long sequences. In this work, we introduce a generic\nand scalable method based on multiple shooting to learn latent representations\nof indirectly observed dynamical systems. We achieve state-of-the-art\nperformances on systems observed directly from raw images. Further, we\ndemonstrate that our method is robust to noisy measurements and can handle\ncomplex dynamical systems, such as chaotic ones.",
    "descriptor": "",
    "authors": [
      "Armand Jordana",
      "Justin Carpentier",
      "Ludovic Righetti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11712"
  },
  {
    "id": "arXiv:2106.11713",
    "title": "Multi-accent Speech Separation with One Shot Learning",
    "abstract": "Speech separation is a problem in the field of speech processing that has\nbeen studied in full swing recently. However, there has not been much work\nstudying a multi-accent speech separation scenario. Unseen speakers with new\naccents and noise aroused the domain mismatch problem which cannot be easily\nsolved by conventional joint training methods. Thus, we applied MAML and FOMAML\nto tackle this problem and obtained higher average Si-SNRi values than joint\ntraining on almost all the unseen accents. This proved that these two methods\ndo have the ability to generate well-trained parameters for adapting to speech\nmixtures of new speakers and accents. Furthermore, we found out that FOMAML\nobtains similar performance compared to MAML while saving a lot of time.",
    "descriptor": "\nComments: Accepted at ACL 2021 Meta Learning for NLP\n",
    "authors": [
      "Kuan-Po Huang",
      "Yuan-Kuei Wu",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.11713"
  },
  {
    "id": "arXiv:2106.11714",
    "title": "Self-sovereign identity as a tool for digital democracy",
    "abstract": "The importance of digital identity as a foundation for digital public\nservices is considered. As the classical, centralised model digital identity\nhas proven to be subject to several limitations, self-sovereign identities are\nproposed as replacement, especially in the context of e-government platforms\nand direct participation to policymaking (e.g. through e-voting tools).",
    "descriptor": "\nComments: Accepted at the 6th Italian Conference on ICT for Smart Cities and Communities, University of Salerno, Italy\n",
    "authors": [
      "Roberta Centonze",
      "Roberto Reale"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11714"
  },
  {
    "id": "arXiv:2106.11716",
    "title": "Robust EMRAN based Neural Aided Learning Controller for Autonomous  Vehicles",
    "abstract": "This paper presents an online evolving neural network-based inverse dynamics\nlearning controller for an autonomous vehicles' longitudinal and lateral\ncontrol under model uncertainties and disturbances. The inverse dynamics of the\nvehicle is approximated using a feedback error learning mechanism that utilizes\na dynamic Radial Basis Function neural network, referred to as the Extended\nMinimal Resource Allocating Network (EMRAN). EMRAN uses an extended Kalman\nfilter approach for learning and a growing/pruning condition helps in keeping\nthe number of hidden neurons minimum. The online learning algorithm helps in\nhandling the uncertainties and dynamic variations and also the unknown\ndisturbances on the road. The proposed control architecture employs two coupled\nconventional controllers aided by the EMRAN inverse dynamics controller. The\ncontrol architecture has a conventional PID controller for cruise control and a\nStanley controller for path-tracking. Performances of both the longitudinal and\nlateral controllers are compared with existing control methods and the results\nclearly indicate that the proposed control scheme handles the disturbances and\nparametric uncertainties better, and also provides better tracking performance\nin autonomous vehicles.",
    "descriptor": "",
    "authors": [
      "Sauranil Debarshi",
      "Suresh Sundaram",
      "Narasimhan Sundararajan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11716"
  },
  {
    "id": "arXiv:2106.11719",
    "title": "Active Learning under Pool Set Distribution Shift and Noisy Data",
    "abstract": "Active Learning is essential for more label-efficient deep learning. Bayesian\nActive Learning has focused on BALD, which reduces model parameter uncertainty.\nHowever, we show that BALD gets stuck on out-of-distribution or junk data that\nis not relevant for the task. We examine a novel *Expected Predictive\nInformation Gain (EPIG)* to deal with distribution shifts of the pool set. EPIG\nreduces the uncertainty of *predictions* on an unlabelled *evaluation set*\nsampled from the test data distribution whose distribution might be different\nto the pool set distribution. Based on this, our new EPIG-BALD acquisition\nfunction for Bayesian Neural Networks selects samples to improve the\nperformance on the test data distribution instead of selecting samples that\nreduce model uncertainty everywhere, including for out-of-distribution regions\nwith low density in the test data distribution. Our method outperforms\nstate-of-the-art Bayesian active learning methods on high-dimensional datasets\nand avoids out-of-distribution junk data in cases where current\nstate-of-the-art methods fail.",
    "descriptor": "",
    "authors": [
      "Andreas Kirsch",
      "Tom Rainforth",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11719"
  },
  {
    "id": "arXiv:2106.11721",
    "title": "A Deep Latent Space Model for Graph Representation Learning",
    "abstract": "Graph representation learning is a fundamental problem for modeling\nrelational data and benefits a number of downstream applications. Traditional\nBayesian-based graph models and recent deep learning based GNN either suffer\nfrom impracticability or lack interpretability, thus combined models for\nundirected graphs have been proposed to overcome the weaknesses. As a large\nportion of real-world graphs are directed graphs (of which undirected graphs\nare special cases), in this paper, we propose a Deep Latent Space Model (DLSM)\nfor directed graphs to incorporate the traditional latent variable based\ngenerative model into deep learning frameworks. Our proposed model consists of\na graph convolutional network (GCN) encoder and a stochastic decoder, which are\nlayer-wise connected by a hierarchical variational auto-encoder architecture.\nBy specifically modeling the degree heterogeneity using node random factors,\nour model possesses better interpretability in both community structure and\ndegree heterogeneity. For fast inference, the stochastic gradient variational\nBayes (SGVB) is adopted using a non-iterative recognition model, which is much\nmore scalable than traditional MCMC-based methods. The experiments on\nreal-world datasets show that the proposed model achieves the state-of-the-art\nperformances on both link prediction and community detection tasks while\nlearning interpretable node embeddings. The source code is available at\nhttps://github.com/upperr/DLSM.",
    "descriptor": "",
    "authors": [
      "Hanxuan Yang",
      "Qingchao Kong",
      "Wenji Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11721"
  },
  {
    "id": "arXiv:2106.11725",
    "title": "RGB2Hands: Real-Time Tracking of 3D Hand Interactions from Monocular RGB  Video",
    "abstract": "Tracking and reconstructing the 3D pose and geometry of two hands in\ninteraction is a challenging problem that has a high relevance for several\nhuman-computer interaction applications, including AR/VR, robotics, or sign\nlanguage recognition. Existing works are either limited to simpler tracking\nsettings (e.g., considering only a single hand or two spatially separated\nhands), or rely on less ubiquitous sensors, such as depth cameras. In contrast,\nin this work we present the first real-time method for motion capture of\nskeletal pose and 3D surface geometry of hands from a single RGB camera that\nexplicitly considers close interactions. In order to address the inherent depth\nambiguities in RGB data, we propose a novel multi-task CNN that regresses\nmultiple complementary pieces of information, including segmentation, dense\nmatchings to a 3D hand model, and 2D keypoint positions, together with newly\nproposed intra-hand relative depth and inter-hand distance maps. These\npredictions are subsequently used in a generative model fitting framework in\norder to estimate pose and shape parameters of a 3D hand model for both hands.\nWe experimentally verify the individual components of our RGB two-hand tracking\nand 3D reconstruction pipeline through an extensive ablation study. Moreover,\nwe demonstrate that our approach offers previously unseen two-hand tracking\nperformance from RGB, and quantitatively and qualitatively outperforms existing\nRGB-based methods that were not explicitly designed for two-hand interactions.\nMoreover, our method even performs on-par with depth-based real-time methods.",
    "descriptor": "\nComments: SIGGRAPH Asia 2020\n",
    "authors": [
      "Jiayi Wang",
      "Franziska Mueller",
      "Florian Bernard",
      "Suzanne Sorli",
      "Oleksandr Sotnychenko",
      "Neng Qian",
      "Miguel A. Otaduy",
      "Dan Casas",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11725"
  },
  {
    "id": "arXiv:2106.11726",
    "title": "Fog computing state of the art: concept and classification of platforms  to support distributed computing systems",
    "abstract": "As the Internet of Things (IoT) becomes a part of our daily life, there is a\nrapid growth in connected devices. A well-established approach based on cloud\ncomputing technologies cannot provide the necessary quality of service in such\nan environment, particularly in terms of reducing data latency. Today, fog\ncomputing technology is seen as a novel approach for processing large amounts\nof critical and time-sensitive data. This article reviews cloud computing\ntechnology and analyzes the prerequisites for the evolution of this approach\nand the emergence of the concept of fog computing. As part of an overview of\nthe critical features of fog computing, we analyze the frequent confusion of\nthe concepts of fog and edge computing. We provide an overview of fog computing\ntechnologies: virtualization, containerization, orchestration, scalability,\nparallel computing environments, as well as a systematic analysis of the most\npopular platforms that support fog computing. As a result of the analysis, we\noffer two approaches to classification of the fog computing platforms: by the\nprinciple of openness/closure of components and a three-level classification\nbased on the provided platform functionality (Deploy-, Platform- and Ecosystem\nas a Service).",
    "descriptor": "\nComments: 33 pages, 8 figures\n",
    "authors": [
      "Alexandra A. Kirsanova",
      "Gleb I. Radchenko",
      "Andrei N. Tchernykh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.11726"
  },
  {
    "id": "arXiv:2106.11728",
    "title": "Digital Twins, Internet of Things and Mobile Medicine: a Review of  Current Platforms to Support Smart Healthcare",
    "abstract": "As the population grows, the need for a quality level of medical services\ngrows correspondingly, so does the demand for information technology in\nmedicine. The concept of \"Smart Healthcare\" offers many approaches aimed at\nsolving the acute problems faced by modern healthcare. In this paper, we review\nthe main problems of modern healthcare, analyze existing approaches and\ntechnologies in the areas of digital twins, the Internet of Things and mobile\nmedicine, determine their effectiveness in solving the set problems, consider\nthe technologies that are used to monitor and treat patients and propose the\nconcept of the Smart Healthcare platform.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Ivan Volkov",
      "Gleb Radchenko",
      "Andrey Tchernykh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.11728"
  },
  {
    "id": "arXiv:2106.11729",
    "title": "A Bibliography of Combinators",
    "abstract": "A categorized bibliography of combinators is given, providing what is\nbelieved to be a largely complete coverage of publications from the origination\nof combinators in 1920 to the present day.",
    "descriptor": "",
    "authors": [
      "Stephen Wolfram"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.11729"
  },
  {
    "id": "arXiv:2106.11730",
    "title": "Learning to Inference with Early Exit in the Progressive Speech  Enhancement",
    "abstract": "In real scenarios, it is often necessary and significant to control the\ninference speed of speech enhancement systems under different conditions. To\nthis end, we propose a stage-wise adaptive inference approach with early exit\nmechanism for progressive speech enhancement. Specifically, in each stage, once\nthe spectral distance between adjacent stages lowers the empirically preset\nthreshold, the inference will terminate and output the estimation, which can\neffectively accelerate the inference speed. To further improve the performance\nof existing speech enhancement systems, PL-CRN++ is proposed, which is an\nimproved version over our preliminary work PL-CRN and combines stage recurrent\nmechanism and complex spectral mapping. Extensive experiments are conducted on\nthe TIMIT corpus, the results demonstrate the superiority of our system over\nstate-of-the-art baselines in terms of PESQ, ESTOI and DNSMOS. Moreover, by\nadjusting the threshold, we can easily control the inference efficiency while\nsustaining the system performance.",
    "descriptor": "\nComments: Accepted by EUSIPCO2021\n",
    "authors": [
      "Andong Li",
      "Chengshi Zheng",
      "Lu Zhang",
      "Xiaodong Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.11730"
  },
  {
    "id": "arXiv:2106.11732",
    "title": "FLEA: Provably Fair Multisource Learning from Unreliable Training Data",
    "abstract": "Fairness-aware learning aims at constructing classifiers that not only make\naccurate predictions, but do not discriminate against specific groups. It is a\nfast-growing area of machine learning with far-reaching societal impact.\nHowever, existing fair learning methods are vulnerable to accidental or\nmalicious artifacts in the training data, which can cause them to unknowingly\nproduce unfair classifiers. In this work we address the problem of fair\nlearning from unreliable training data in the robust multisource setting, where\nthe available training data comes from multiple sources, a fraction of which\nmight be not representative of the true data distribution. We introduce FLEA, a\nfiltering-based algorithm that allows the learning system to identify and\nsuppress those data sources that would have a negative impact on fairness or\naccuracy if they were used for training. We show the effectiveness of our\napproach by a diverse range of experiments on multiple datasets. Additionally\nwe prove formally that, given enough data, FLEA protects the learner against\nunreliable data as long as the fraction of affected data sources is less than\nhalf.",
    "descriptor": "",
    "authors": [
      "Eugenia Iofinova",
      "Nikola Konstantinov",
      "Christoph H. Lampert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11732"
  },
  {
    "id": "arXiv:2106.11735",
    "title": "Lifted Model Checking for Relational MDPs",
    "abstract": "Model checking has been developed for verifying the behaviour of systems with\nstochastic and non-deterministic behavior. It is used to provide guarantees\nabout such systems. While most model checking methods focus on propositional\nmodels, various probabilistic planning and reinforcement frameworks deal with\nrelational domains, for instance, STRIPS planning and relational Markov\nDecision Processes. Using propositional model checking in relational settings\nrequires one to ground the model, which leads to the well known state explosion\nproblem and intractability. We present pCTL-REBEL, a lifted model checking\napproach for verifying pCTL properties on relational MDPs. It extends REBEL,\nthe relational Bellman update operator, which is a lifted value iteration\napproach for model-based relational reinforcement learning, toward relational\nmodel-checking. PCTL-REBEL is lifted, which means that rather than grounding,\nthe model exploits symmetries and reasons at an abstract relational level.\nTheoretically, we show that the pCTL model checking approach is decidable for\nrelational MDPs even for possibly infinite domains provided that the states\nhave a bounded size. Practically, we contribute algorithms and an\nimplementation of lifted relational model checking, and we show that the lifted\napproach improves the scalability of the model checking approach.",
    "descriptor": "",
    "authors": [
      "Wen-Chi Yang",
      "Jean-Fran\u00e7ois Raskin",
      "Luc De Raedt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.11735"
  },
  {
    "id": "arXiv:2106.11739",
    "title": "Error-Aware Interactive Semantic Parsing of OpenStreetMap",
    "abstract": "In semantic parsing of geographical queries against real-world databases such\nas OpenStreetMap (OSM), unique correct answers do not necessarily exist.\nInstead, the truth might be lying in the eye of the user, who needs to enter an\ninteractive setup where ambiguities can be resolved and parsing mistakes can be\ncorrected. Our work presents an approach to interactive semantic parsing where\nan explicit error detection is performed, and a clarification question is\ngenerated that pinpoints the suspected source of ambiguity or error and\ncommunicates it to the human user. Our experimental results show that a\ncombination of entropy-based uncertainty detection and beam search, together\nwith multi-source training on clarification question, initial parse, and user\nanswer, results in improvements of 1.2% F1 score on a parser that already\nperforms at 90.26% on the NLMaps dataset for OSM semantic parsing.",
    "descriptor": "\nComments: Accepted at SpLU-RoboNLP 2021\n",
    "authors": [
      "Michael Staniek",
      "Stefan Riezler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11739"
  },
  {
    "id": "arXiv:2106.11740",
    "title": "LV-BERT: Exploiting Layer Variety for BERT",
    "abstract": "Modern pre-trained language models are mostly built upon backbones stacking\nself-attention and feed-forward layers in an interleaved order. In this paper,\nbeyond this stereotyped layer pattern, we aim to improve pre-trained models by\nexploiting layer variety from two aspects: the layer type set and the layer\norder. Specifically, besides the original self-attention and feed-forward\nlayers, we introduce convolution into the layer type set, which is\nexperimentally found beneficial to pre-trained models. Furthermore, beyond the\noriginal interleaved order, we explore more layer orders to discover more\npowerful architectures. However, the introduced layer variety leads to a large\narchitecture space of more than billions of candidates, while training a single\ncandidate model from scratch already requires huge computation cost, making it\nnot affordable to search such a space by directly training large amounts of\ncandidate models. To solve this problem, we first pre-train a supernet from\nwhich the weights of all candidate models can be inherited, and then adopt an\nevolutionary algorithm guided by pre-training accuracy to find the optimal\narchitecture. Extensive experiments show that LV-BERT model obtained by our\nmethod outperforms BERT and its variants on various downstream tasks. For\nexample, LV-BERT-small achieves 78.8 on the GLUE testing set, 1.8 higher than\nthe strong baseline ELECTRA-small.",
    "descriptor": "\nComments: Accepted to Findings of ACL 2021. The code and pre-trained models are available at this https URL\n",
    "authors": [
      "Weihao Yu",
      "Zihang Jiang",
      "Fei Chen",
      "Qibin Hou",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11740"
  },
  {
    "id": "arXiv:2106.11744",
    "title": "Fully Dynamic Algorithms for Minimum Weight Cycle and Related Problems",
    "abstract": "We consider the directed minimum weight cycle problem in the fully dynamic\nsetting. To the best of our knowledge, so far no fully dynamic algorithms have\nbeen designed specifically for the minimum weight cycle problem in general\ndigraphs. One can achieve $\\tilde{O}(n^2)$ amortized update time by simply\ninvoking the fully dynamic APSP algorithm of Demetrescu and Italiano [J.\nACM'04]. This bound, however, yields no improvement over the trivial\nrecompute-from-scratch algorithm for sparse graphs.\nOur first contribution is a very simple deterministic\n$(1+\\epsilon)$-approximate algorithm supporting vertex updates (i.e., changing\nall edges incident to a specified vertex) in conditionally near-optimal\n$\\tilde{O}(m\\log{(W)}/\\epsilon)$ amortized time for digraphs with real edge\nweights in $[1,W]$. Using known techniques, the algorithm can be implemented on\nplanar graphs and also gives some new sublinear fully dynamic algorithms\nmaintaining approximate cuts and flows in planar digraphs.\nAdditionally, we show a Monte Carlo randomized exact fully dynamic minimum\nweight cycle algorithm with $\\tilde{O}(mn^{2/3})$ worst-case update that works\nfor real edge weights. To this end, we generalize the exact fully dynamic APSP\ndata structure of Abraham et al. [SODA'17] to solve the ``multiple-pairs\nshortest paths problem'', where one is interested in computing distances for\nsome $k$ (instead of all $n^2$) fixed source-target pairs after each update. We\nshow that in such a scenario, $\\tilde{O}((m+k)n^{2/3})$ worst-case update time\nis possible.",
    "descriptor": "\nComments: Full version of an ICALP 2021 paper\n",
    "authors": [
      "Adam Karczmarz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.11744"
  },
  {
    "id": "arXiv:2106.11747",
    "title": "Single-chip photonic deep neural network for instantaneous image  classification",
    "abstract": "Deep neural networks with applications from computer vision and image\nprocessing to medical diagnosis are commonly implemented using clock-based\nprocessors, where computation speed is limited by the clock frequency and the\nmemory access time. Advances in photonic integrated circuits have enabled\nresearch in photonic computation, where, despite excellent features such as\nfast linear computation, no integrated photonic deep network has been\ndemonstrated to date due to the lack of scalable nonlinear functionality and\nthe loss of photonic devices, making scalability to a large number of layers\nchallenging. Here we report the first integrated end-to-end photonic deep\nneural network (PDNN) that performs instantaneous image classification through\ndirect processing of optical waves. Images are formed on the input pixels and\noptical waves are coupled into nanophotonic waveguides and processed as the\nlight propagates through layers of neurons on-chip. Each neuron generates an\noptical output from input optical signals, where linear computation is\nperformed optically and the nonlinear activation function is realised\nopto-electronically. The output of a laser coupled into the chip is uniformly\ndistributed among all neurons within the network providing the same per-neuron\nsupply light. Thus, all neurons have the same optical output range enabling\nscalability to deep networks with large number of layers. The PDNN chip is used\nfor 2- and 4-class classification of handwritten letters achieving accuracies\nof higher than 93.7% and 90.3%, respectively, with a computation time less than\none clock cycle of state-of-the-art digital computation platforms. Direct\nclock-less processing of optical data eliminates photo-detection, A/D\nconversion, and the requirement for a large memory module, enabling\nsignificantly faster and more energy-efficient neural networks for the next\ngenerations of deep learning systems.",
    "descriptor": "",
    "authors": [
      "Farshid Ashtiani",
      "Alexander J. Geers",
      "Firooz Aflatouni"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2106.11747"
  },
  {
    "id": "arXiv:2106.11749",
    "title": "Optimizing Partial Power Processing for Second-Use Battery Energy  Storage Systems",
    "abstract": "Repurposing automotive batteries to second-use battery energy storage systems\n(2-BESS) may have environmental and economic benefits. The challenge with\nsecond-use batteries is the uncertainty and diversity of the expected packs in\nterms of their chemistry, capacity and remaining useful life. This paper\nintroduces a new strategy to optimize 2-BESS performance despite the diversity\nor heterogeneity of individual batteries while reducing the cost of power\nconversion. In this paper, the statistical distribution of the power\nheterogeneity in the supply of batteries is considered when optimizing the\nchoice of power converters and designing the power flow within the battery\nenergy storage system (BESS) to maximize battery utilization. By leveraging a\nnew lite-sparse hierarchical partial power processing (LS-HiPPP) approach, we\nshow a hierarchy in partial power processing (PPP) partitions power converters\nto a) significantly reduce converter ratings, b) process less power to achieve\nhigh system efficiency with lower cost (lower efficiency) converters, and c)\ntake advantage of economies of scale by requiring only a minimal number of sets\nof identical converters. The results demonstrate that LS-HiPPP architectures\noffer the best tradeoff between battery utilization and converter cost and had\nhigher system efficiency than conventional partial power processing (C-PPP) in\nall cases.",
    "descriptor": "",
    "authors": [
      "Xiaofan Cui",
      "Alireza Ramyar",
      "Peyman Mohtat",
      "Veronica Contreras",
      "Jason Siegel",
      "Anna Stefanopoulou",
      "Al-Thaddeus Avestruz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.11749"
  },
  {
    "id": "arXiv:2106.11750",
    "title": "Carbon-Aware Computing for Datacenters",
    "abstract": "The amount of CO$_2$ emitted per kilowatt-hour on an electricity grid varies\nby time of day and substantially varies by location due to the types of\ngeneration. Networked collections of warehouse scale computers, sometimes\ncalled Hyperscale Computing, emit more carbon than needed if operated without\nregard to these variations in carbon intensity. This paper introduces Google's\nsystem for Carbon-Intelligent Compute Management, which actively minimizes\nelectricity-based carbon footprint and power infrastructure costs by delaying\ntemporally flexible workloads. The core component of the system is a suite of\nanalytical pipelines used to gather the next day's carbon intensity forecasts,\ntrain day-ahead demand prediction models, and use risk-aware optimization to\ngenerate the next day's carbon-aware Virtual Capacity Curves (VCCs) for all\ndatacenter clusters across Google's fleet. VCCs impose hourly limits on\nresources available to temporally flexible workloads while preserving overall\ndaily capacity, enabling all such workloads to complete within a day. Data from\noperation shows that VCCs effectively limit hourly capacity when the grid's\nenergy supply mix is carbon intensive and delay the execution of temporally\nflexible workloads to \"greener\" times.",
    "descriptor": "",
    "authors": [
      "Ana Radovanovic",
      "Ross Koningstein",
      "Ian Schneider",
      "Bokan Chen",
      "Alexandre Duarte",
      "Binz Roy",
      "Diyue Xiao",
      "Maya Haridasan",
      "Patrick Hung",
      "Nick Care",
      "Saurav Talukdar",
      "Eric Mullen",
      "Kendal Smith",
      "MariEllen Cottman",
      "Walfredo Cirne"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.11750"
  },
  {
    "id": "arXiv:2106.11753",
    "title": "Symplectic Learning for Hamiltonian Neural Networks",
    "abstract": "Machine learning methods are widely used in the natural sciences to model and\npredict physical systems from observation data. Yet, they are often used as\npoorly understood \"black boxes,\" disregarding existing mathematical structure\nand invariants of the problem. Recently, the proposal of Hamiltonian Neural\nNetworks (HNNs) took a first step towards a unified \"gray box\" approach, using\nphysical insight to improve performance for Hamiltonian systems. In this paper,\nwe explore a significantly improved training method for HNNs, exploiting the\nsymplectic structure of Hamiltonian systems with a different loss function.\nThis frees the loss from an artificial lower bound. We mathematically guarantee\nthe existence of an exact Hamiltonian function which the HNN can learn. This\nallows us to prove and numerically analyze the errors made by HNNs which, in\nturn, renders them fully explainable. Finally, we present a novel post-training\ncorrection to obtain the true Hamiltonian only from discretized observation\ndata, up to an arbitrary order.",
    "descriptor": "\nComments: 10 pages, 4 figures; Source code, datasets and pre-trained models available at this https URL\n",
    "authors": [
      "Marco David",
      "Florian M\u00e9hats"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11753"
  },
  {
    "id": "arXiv:2106.11754",
    "title": "Experiments in Artificial Culture: from noisy imitation to storytelling  robots",
    "abstract": "This paper presents a series of experiments in collective social robotics,\nspanning more than 10 years, with the long-term aim of building embodied models\nof (aspects) of cultural evolution. Initial experiments demonstrated the\nemergence of behavioural traditions in a group of social robots programmed to\nimitate each other's behaviours (we call these Copybots). These experiments\nshow that the noisy (i.e. less than perfect fidelity) imitation that comes for\nfree with real physical robots gives rise naturally to variation in social\nlearning. More recent experimental work extends the robots' cognitive\ncapabilities with simulation-based internal models, equipping them with a\nsimple artificial theory of mind. With this extended capability we explore, in\nour current work, social learning not via imitation but robot-robot\nstorytelling, in an effort to model this very human mode of cultural\ntransmission. In this paper we give an account of the methods and inspiration\nfor these experiments, the experiments and their results, and an outline of\npossible directions for this programme of research. It is our hope that this\npaper stimulates not only discussion but suggestions for hypotheses to test\nwith the Storybots.",
    "descriptor": "",
    "authors": [
      "Alan F. T. Winfield",
      "Susan Blackmore"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11754"
  },
  {
    "id": "arXiv:2106.11755",
    "title": "Sphynx: ReLU-Efficient Network Design for Private Inference",
    "abstract": "The emergence of deep learning has been accompanied by privacy concerns\nsurrounding users' data and service providers' models. We focus on private\ninference (PI), where the goal is to perform inference on a user's data sample\nusing a service provider's model. Existing PI methods for deep networks enable\ncryptographically secure inference with little drop in functionality; however,\nthey incur severe latency costs, primarily caused by non-linear network\noperations (such as ReLUs). This paper presents Sphynx, a ReLU-efficient\nnetwork design method based on micro-search strategies for convolutional cell\ndesign. Sphynx achieves Pareto dominance over all existing private inference\nmethods on CIFAR-100. We also design large-scale networks that support\ncryptographically private inference on Tiny-ImageNet and ImageNet.",
    "descriptor": "",
    "authors": [
      "Minsu Cho",
      "Zahra Ghodsi",
      "Brandon Reagen",
      "Siddharth Garg",
      "Chinmay Hegde"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11755"
  },
  {
    "id": "arXiv:2106.11756",
    "title": "Trinity: A No-Code AI platform for complex spatial datasets",
    "abstract": "We present a no-code Artificial Intelligence (AI) platform called Trinity\nwith the main design goal of enabling both machine learning researchers and\nnon-technical geospatial domain experts to experiment with domain-specific\nsignals and datasets for solving a variety of complex problems on their own.\nThis versatility to solve diverse problems is achieved by transforming complex\nSpatio-temporal datasets to make them consumable by standard deep learning\nmodels, in this case, Convolutional Neural Networks (CNNs), and giving the\nability to formulate disparate problems in a standard way, eg. semantic\nsegmentation. With an intuitive user interface, a feature store that hosts\nderivatives of complex feature engineering, a deep learning kernel, and a\nscalable data processing mechanism, Trinity provides a powerful platform for\ndomain experts to share the stage with scientists and engineers in solving\nbusiness-critical problems. It enables quick prototyping, rapid experimentation\nand reduces the time to production by standardizing model building and\ndeployment. In this paper, we present our motivation behind Trinity and its\ndesign along with showcasing sample applications to motivate the idea of\nlowering the bar to using AI.",
    "descriptor": "\nComments: 12 pages, Submitted to SIGSPATIAL '21\n",
    "authors": [
      "C.V.Krishnakumar Iyer",
      "Feili Hou",
      "Henry Wang",
      "Yonghong Wang",
      "Kay Oh",
      "Swetava Ganguli",
      "Vipul Pandey"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11756"
  },
  {
    "id": "arXiv:2106.11757",
    "title": "Application-driven Design Exploration for Dense Ferroelectric Embedded  Non-volatile Memories",
    "abstract": "The memory wall bottleneck is a key challenge across many data-intensive\napplications. Multi-level FeFET-based embedded non-volatile memories are a\npromising solution for denser and more energy-efficient on-chip memory.\nHowever, reliable multi-level cell storage requires careful optimizations to\nminimize the design overhead costs. In this work, we investigate the interplay\nbetween FeFET device characteristics, programming schemes, and memory array\narchitecture, and explore different design choices to optimize performance,\nenergy, area, and accuracy metrics for critical data-intensive workloads. From\nour cross-stack design exploration, we find that we can store DNN weights and\nsocial network graphs at a density of over 8MB/mm^2 and sub-2ns read access\nlatency without loss in application accuracy.",
    "descriptor": "\nComments: Accepted at ISLPED 2021\n",
    "authors": [
      "Mohammad Mehdi Sharifi",
      "Lillian Pentecost",
      "Ramin Rajaei",
      "Arman Kazemi",
      "Qiuwen Lou",
      "Gu-Yeon Wei",
      "David Brooks",
      "Kai Ni",
      "X. Sharon Hu",
      "Michael Niemier",
      "Marco Donato"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.11757"
  },
  {
    "id": "arXiv:2106.11760",
    "title": "A Stealthy and Robust Fingerprinting Scheme for Generative Models",
    "abstract": "This paper presents a novel fingerprinting methodology for the Intellectual\nProperty protection of generative models. Prior solutions for discriminative\nmodels usually adopt adversarial examples as the fingerprints, which give\nanomalous inference behaviors and prediction results. Hence, these methods are\nnot stealthy and can be easily recognized by the adversary. Our approach\nleverages the invisible backdoor technique to overcome the above limitation.\nSpecifically, we design verification samples, whose model outputs look normal\nbut can trigger a backdoor classifier to make abnormal predictions. We propose\na new backdoor embedding approach with Unique-Triplet Loss and fine-grained\ncategorization to enhance the effectiveness of our fingerprints. Extensive\nevaluations show that this solution can outperform other strategies with higher\nrobustness, uniqueness and stealthiness for various GAN models.",
    "descriptor": "",
    "authors": [
      "Li Guanlin",
      "Guo Shangwei",
      "Wang Run",
      "Xu Guowen",
      "Zhang Tianwei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11760"
  },
  {
    "id": "arXiv:2106.11762",
    "title": "Modeling of Personalized Privacy Disclosure Behavior: A Formal Method  Approach",
    "abstract": "In order to create user-centric and personalized privacy management tools,\nthe underlying models must account for individual users' privacy expectations,\npreferences, and their ability to control their information sharing activities.\nExisting studies of users' privacy behavior modeling attempt to frame the\nproblem from a request's perspective, which lack the crucial involvement of the\ninformation owner, resulting in limited or no control of policy management.\nMoreover, very few of them take into the consideration the aspect of\ncorrectness, explainability, usability, and acceptance of the methodologies for\neach user of the system. In this paper, we present a methodology to formally\nmodel, validate, and verify personalized privacy disclosure behavior based on\nthe analysis of the user's situational decision-making process. We use a model\nchecking tool named UPPAAL to represent users' self-reported privacy disclosure\nbehavior by an extended form of finite state automata (FSA), and perform\nreachability analysis for the verification of privacy properties through\ncomputation tree logic (CTL) formulas. We also describe the practical use cases\nof the methodology depicting the potential of formal technique towards the\ndesign and development of user-centric behavioral modeling. This paper, through\nextensive amounts of experimental outcomes, contributes several insights to the\narea of formal methods and user-tailored privacy behavior modeling.",
    "descriptor": "",
    "authors": [
      "A K M Nuhil Mehdy",
      "Hoda Mehrpouyan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.11762"
  },
  {
    "id": "arXiv:2106.11763",
    "title": "Formation Control with Lane Preference for Connected and Automated  Vehicles in Multi-lane Scenarios",
    "abstract": "Multi-lane roads are typical scenarios in the real-world traffic system.\nVehicles usually have preference on lanes according to their routes and\ndestinations. Few of the existing studies looks into the problem of controlling\nvehicles to drive on their desired lanes. This paper proposes a formation\ncontrol method that considers vehicles' preference on different lanes. The\nbi-level formation control framework is utilized to plan collision-free motion\nfor vehicles, where relative target assignment and path planning are performed\nin the upper level, and trajectory planning and tracking are performed in the\nlower level. The collision-free multi-vehicle path planning problem considering\nlane preference is decoupled into two sub problems: calculating assignment list\nwith non-decreasing cost and planning collision-free paths according to given\nassignment result. The Conflict-based Searching (CBS) method is utilized to\nplan collision-free paths for vehicles based on given assignment results. Case\nstudy is conducted and simulations are carried out in a three-lane road\nscenario. The results indicate that the proposed formation control method\nsignificantly reduces congestion and improves traffic efficiency at high\ntraffic volumes, compared to the rule-based method.",
    "descriptor": "",
    "authors": [
      "Mengchi Cai",
      "Chaoyi Chen",
      "Jiawei Wang",
      "Qing Xu",
      "Keqiang Li",
      "Jianqiang Wang",
      "Xiangbin Wu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.11763"
  },
  {
    "id": "arXiv:2106.11767",
    "title": "Privacy Amplification via Iteration for Shuffled and Online PNSGD",
    "abstract": "In this paper, we consider the framework of privacy amplification via\niteration, which is originally proposed by Feldman et al. and subsequently\nsimplified by Asoodeh et al. in their analysis via the contraction coefficient.\nThis line of work focuses on the study of the privacy guarantees obtained by\nthe projected noisy stochastic gradient descent (PNSGD) algorithm with hidden\nintermediate updates. A limitation in the existing literature is that only the\nearly stopped PNSGD has been studied, while no result has been proved on the\nmore widely-used PNSGD applied on a shuffled dataset. Moreover, no scheme has\nbeen yet proposed regarding how to decrease the injected noise when new data\nare received in an online fashion. In this work, we first prove a privacy\nguarantee for shuffled PNSGD, which is investigated asymptotically when the\nnoise is fixed for each sample size $n$ but reduced at a predetermined rate\nwhen $n$ increases, in order to achieve the convergence of privacy loss. We\nthen analyze the online setting and provide a faster decaying scheme for the\nmagnitude of the injected noise that also guarantees the convergence of privacy\nloss.",
    "descriptor": "",
    "authors": [
      "Matteo Sordello",
      "Zhiqi Bu",
      "Jinshuo Dong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11767"
  },
  {
    "id": "arXiv:2106.11770",
    "title": "SISA: Securing Images by Selective Alteration",
    "abstract": "With an increase in mobile and camera devices' popularity, digital content in\nthe form of images has increased drastically. As personal life is being\ncontinuously documented in pictures, the risk of losing it to eavesdroppers is\na matter of grave concern. Secondary storage is the most preferred medium for\nthe storage of personal and other images. Our work is concerned with the\nsecurity of such images. While encryption is the best way to ensure image\nsecurity, full encryption and decryption is a computationally-intensive\nprocess. Moreover, as cameras are getting better every day, image quality, and\nthus, the pixel density has increased considerably. The increased pixel density\nmakes encryption and decryption more expensive. We, therefore, delve into\nselective encryption and selective blurring based on the region of interest.\nInstead of encrypting or blurring the entire photograph, we only encode\nselected regions of the image. We present a comparative analysis of the partial\nand full encryption of the photos. This kind of encoding will help us lower the\nencryption overhead without compromising security. The applications utilizing\nthis technique will become more usable due to the reduction in the decryption\ntime. Additionally, blurred images being more readable than encrypted ones,\nallowed us to define the level of security. We leverage the machine learning\nalgorithms like Mask-RCNN (Region-based convolutional neural network) and YOLO\n(You Only Look Once) to select the region of interest. These algorithms have\nset new benchmarks for object recognition. We develop an end to end system to\ndemonstrate our idea of selective encryption.",
    "descriptor": "\nComments: Accepted at ICTCS 2020\n",
    "authors": [
      "Prutha Gaherwar",
      "Shraddha Joshi",
      "Raviraj Joshi",
      "Rahul Khengare"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11770"
  },
  {
    "id": "arXiv:2106.11773",
    "title": "A Survey on Serverless Computing",
    "abstract": "This paper provides a formal account of the research contributions in the\nfield of Serverless computing.",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Jacob John",
      "Shashank Gupta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.11773"
  },
  {
    "id": "arXiv:2106.11776",
    "title": "A Review of the Vision-based Approaches for Dietary Assessment",
    "abstract": "Dietary-related problems such as obesity are a growing concern in todays\nmodern world. If the current trend continues, it is most likely that the\nquality of life, in general, is significantly affected since obesity is\nassociated with other chronic diseases such as hypertension, irregular blood\nsugar levels, and increased risk of heart attacks. The primary cause of these\nproblems is poor lifestyle choices and unhealthy dietary habits, with emphasis\non a select few food groups such as sugars, fats, and carbohydrates. In this\nregard, computer-based food recognition offers automatic visual-based methods\nto assess dietary intake and help people make healthier choices. Thus, the\nfollowing paper presents a brief review of visual-based methods for food\nrecognition, including their accuracy, performance, and the use of popular food\ndatabases to evaluate existing models. The work further aims to highlight\nfuture challenges in this area. New high-quality studies for developing\nstandard benchmarks and using continual learning methods for food recognition\nare recommended.",
    "descriptor": "",
    "authors": [
      "Ghalib Tahir",
      "Chu Kiong Loo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.11776"
  },
  {
    "id": "arXiv:2106.11779",
    "title": "Emphatic Algorithms for Deep Reinforcement Learning",
    "abstract": "Off-policy learning allows us to learn about possible policies of behavior\nfrom experience generated by a different behavior policy. Temporal difference\n(TD) learning algorithms can become unstable when combined with function\napproximation and off-policy sampling - this is known as the ''deadly triad''.\nEmphatic temporal difference (ETD($\\lambda$)) algorithm ensures convergence in\nthe linear case by appropriately weighting the TD($\\lambda$) updates. In this\npaper, we extend the use of emphatic methods to deep reinforcement learning\nagents. We show that naively adapting ETD($\\lambda$) to popular deep\nreinforcement learning algorithms, which use forward view multi-step returns,\nresults in poor performance. We then derive new emphatic algorithms for use in\nthe context of such algorithms, and we demonstrate that they provide noticeable\nbenefits in small problems designed to highlight the instability of TD methods.\nFinally, we observed improved performance when applying these algorithms at\nscale on classic Atari games from the Arcade Learning Environment.",
    "descriptor": "",
    "authors": [
      "Ray Jiang",
      "Tom Zahavy",
      "Zhongwen Xu",
      "Adam White",
      "Matteo Hessel",
      "Charles Blundell",
      "Hado van Hasselt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11779"
  },
  {
    "id": "arXiv:2106.11783",
    "title": "Towards Knowledge-Grounded Counter Narrative Generation for Hate Speech",
    "abstract": "Tackling online hatred using informed textual responses - called counter\nnarratives - has been brought under the spotlight recently. Accordingly, a\nresearch line has emerged to automatically generate counter narratives in order\nto facilitate the direct intervention in the hate discussion and to prevent\nhate content from further spreading. Still, current neural approaches tend to\nproduce generic/repetitive responses and lack grounded and up-to-date evidence\nsuch as facts, statistics, or examples. Moreover, these models can create\nplausible but not necessarily true arguments. In this paper we present the\nfirst complete knowledge-bound counter narrative generation pipeline, grounded\nin an external knowledge repository that can provide more informative content\nto fight online hatred. Together with our approach, we present a series of\nexperiments that show its feasibility to produce suitable and informative\ncounter narratives in in-domain and cross-domain settings.",
    "descriptor": "\nComments: To appear in \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics (ACL): Findings\"\n",
    "authors": [
      "Yi-Ling Chung",
      "Serra Sinem Tekiroglu",
      "Marco Guerini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11783"
  },
  {
    "id": "arXiv:2106.11784",
    "title": "The Interplay of Reconfigurable Intelligent Surfaces and Mobile Edge  Computing in Future Wireless Networks: A Win-Win Strategy to 6G",
    "abstract": "Reconfigurable intelligent surface (RIS)-empowered communication is being\nconsidered as an enabling technology for sixth generation (6G) wireless\nnetworks. The key idea of RIS-assisted communication is to enhance the\ncapacity, coverage, energy efficiency, physical layer security, and many other\naspects of modern wireless networks. At the same time, mobile edge computing\n(MEC) has already shown its huge potential by extending the computation,\ncommunication, and caching capabilities of a standalone cloud server to the\nnetwork edge. In this article, we first provide an overview of how MEC and RIS\ncan benefit each other. We envision that the integration of MEC and RIS will\nbring an unprecedented transformation to the future evolution of wireless\nnetworks. We provide a system-level perspective on the MEC-aided RIS (and\nRIS-assisted MEC) that will evolve wireless network towards 6G. We also outline\nsome of the fundamental challenges that pertain to the implementation of\nMEC-aided RIS (and RIS-assisted MEC) networks. Finally, the key research trends\nin the RIS-assisted MEC are discussed.",
    "descriptor": "",
    "authors": [
      "Mithun Mukherjee",
      "Vikas Kumar",
      "Mian Guo",
      "Daniel Benevides da Costa",
      "Ertugrul Basar",
      "Zhiguo Ding"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Emerging Technologies (cs.ET)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11784"
  },
  {
    "id": "arXiv:2106.11789",
    "title": "Glance and Gaze: A Collaborative Learning Framework for Single-channel  Speech Enhancement",
    "abstract": "The capability of the human to pay attention to both coarse and fine-grained\nregions has been applied to computer vision tasks. Motivated by that, we\npropose a collaborative learning framework in the complex domain for monaural\nnoise suppression. The proposed system consists of two principal modules,\nnamely spectral feature extraction module (FEM) and stacked glance-gaze modules\n(GGMs). In FEM, the UNet-block is introduced after each convolution layer,\nenabling the feature recalibration from multiple scales. In each GGM, we\ndecompose the multi-target optimization in the complex spectrum into two\nsub-tasks. Specifically, the glance path aims to suppress the noise in the\nmagnitude domain to obtain a coarse estimation, and meanwhile, the gaze path\nattempts to compensate for the lost spectral detail in the complex domain. The\ntwo paths work collaboratively and facilitate spectral estimation from\ncomplementary perspectives. Besides, by repeatedly unfolding the GGMs, the\nintermediate result can be iteratively refined across stages and lead to the\nultimate estimation of the spectrum. The experiments are conducted on the\nWSJ0-SI84, DNS-Challenge dataset, and Voicebank+Demand dataset. Results show\nthat the proposed approach achieves state-of-the-art performance over previous\nadvanced systems on the WSJ0-SI84 and DNS-Challenge dataset, and meanwhile,\ncompetitive performance is achieved on the Voicebank+Demand corpus.",
    "descriptor": "",
    "authors": [
      "Andong Li",
      "Chengshi Zheng",
      "Lu Zhang",
      "Xiaodong Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.11789"
  },
  {
    "id": "arXiv:2106.11791",
    "title": "Exemplars-guided Empathetic Response Generation Controlled by the  Elements of Human Communication",
    "abstract": "The majority of existing methods for empathetic response generation rely on\nthe emotion of the context to generate empathetic responses. However, empathy\nis much more than generating responses with an appropriate emotion. It also\noften entails subtle expressions of understanding and personal resonance with\nthe situation of the other interlocutor. Unfortunately, such qualities are\ndifficult to quantify and the datasets lack the relevant annotations. To\naddress this issue, in this paper we propose an approach that relies on\nexemplars to cue the generative model on fine stylistic properties that signal\nempathy to the interlocutor. To this end, we employ dense passage retrieval to\nextract relevant exemplary responses from the training set. Three elements of\nhuman communication -- emotional presence, interpretation, and exploration, and\nsentiment are additionally introduced using synthetic labels to guide the\ngeneration towards empathy. The human evaluation is also extended by these\nelements of human communication. We empirically show that these approaches\nyield significant improvements in empathetic response quality in terms of both\nautomated and human-evaluated metrics. The implementation is available at\nhttps://github.com/declare-lab/exemplary-empathy.",
    "descriptor": "",
    "authors": [
      "Navonil Majumder",
      "Deepanway Ghosal",
      "Devamanyu Hazarika",
      "Alexander Gelbukh",
      "Rada Mihalcea",
      "Soujanya Poria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11791"
  },
  {
    "id": "arXiv:2106.11795",
    "title": "DeepMesh: Differentiable Iso-Surface Extraction",
    "abstract": "Geometric Deep Learning has recently made striking progress with the advent\nof continuous Deep Implicit Fields. They allow for detailed modeling of\nwatertight surfaces of arbitrary topology while not relying on a 3D Euclidean\ngrid, resulting in a learnable parameterization that is unlimited in\nresolution. Unfortunately, these methods are often unsuitable for applications\nthat require an explicit mesh-based surface representation because converting\nan implicit field to such a representation relies on the Marching Cubes\nalgorithm, which cannot be differentiated with respect to the underlying\nimplicit field. In this work, we remove this limitation and introduce a\ndifferentiable way to produce explicit surface mesh representations from Deep\nImplicit Fields. Our key insight is that by reasoning on how implicit field\nperturbations impact local surface geometry, one can ultimately differentiate\nthe 3D location of surface samples with respect to the underlying deep implicit\nfield. We exploit this to define DeepMesh -- end-to-end differentiable mesh\nrepresentation that can vary its topology. We use two different applications to\nvalidate our theoretical insight: Single view 3D Reconstruction via\nDifferentiable Rendering and Physically-Driven Shape Optimization. In both\ncases our end-to-end differentiable parameterization gives us an edge over\nstate-of-the-art algorithms.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2006.03997\n",
    "authors": [
      "Benoit Guillard",
      "Edoardo Remelli",
      "Artem Lukoianov",
      "Stephan Richter",
      "Timur Bagautdinov",
      "Pierre Baque",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11795"
  },
  {
    "id": "arXiv:2106.11796",
    "title": "End-to-End Task-Oriented Dialog Modeling with Semi-Structured Knowledge  Management",
    "abstract": "Current task-oriented dialog (TOD) systems mostly manage structured knowledge\n(e.g. databases and tables) to guide the goal-oriented conversations. However,\nthey fall short of handling dialogs which also involve unstructured knowledge\n(e.g. reviews and documents). In this paper, we formulate a task of modeling\nTOD grounded on a fusion of structured and unstructured knowledge. To address\nthis task, we propose a TOD system with semi-structured knowledge management,\nSeKnow, which extends the belief state to manage knowledge with both structured\nand unstructured contents. Furthermore, we introduce two implementations of\nSeKnow based on a non-pretrained sequence-to-sequence model and a pretrained\nlanguage model, respectively. Both implementations use the end-to-end manner to\njointly optimize dialog modeling grounded on structured and unstructured\nknowledge. We conduct experiments on the modified version of MultiWOZ 2.1\ndataset, where dialogs are processed to involve semi-structured knowledge.\nExperimental results show that SeKnow has strong performances in both\nend-to-end dialog and intermediate knowledge management, compared to existing\nTOD systems and their extensions with pipeline knowledge management schemes.",
    "descriptor": "\nComments: Submitted to IEEE/ACM TASLP, regular paper. arXiv admin note: substantial text overlap with arXiv:2105.06041\n",
    "authors": [
      "Silin Gao",
      "Ryuichi Takanobu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11796"
  },
  {
    "id": "arXiv:2106.11797",
    "title": "Evaluation of a Region Proposal Architecture for Multi-task Document  Layout Analysis",
    "abstract": "Automatically recognizing the layout of handwritten documents is an important\nstep towards useful extraction of information from those documents. The most\ncommon application is to feed downstream applications such as automatic text\nrecognition and keyword spotting; however, the recognition of the layout also\nhelps to establish relationships between elements in the document which allows\nto enrich the information that can be extracted. Most of the modern document\nlayout analysis systems are designed to address only one part of the document\nlayout problem, namely: baseline detection or region segmentation. In contrast,\nwe evaluate the effectiveness of the Mask-RCNN architecture to address the\nproblem of baseline detection and region segmentation in an integrated manner.\nWe present experimental results on two handwritten text datasets and one\nhandwritten music dataset. The analyzed architecture yields promising results,\noutperforming state-of-the-art techniques in all three datasets.",
    "descriptor": "",
    "authors": [
      "Lorenzo Quir\u00f3s",
      "Enrique Vidal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11797"
  },
  {
    "id": "arXiv:2106.11798",
    "title": "Counterexample to cut-elimination in cyclic proof system for first-order  logic with inductive definitions",
    "abstract": "A cyclic proof system is a proof system whose proof figure is a tree with\ncycles. The cut-elimination in a proof system is fundamental. It is conjectured\nthat the cut-elimination in the cyclic proof system for first-order logic with\ninductive definitions does not hold. This paper shows that the conjecture is\ncorrect by giving a sequent not provable without the cut rule but provable in\nthe cyclic proof system.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Yukihiro Masuoka",
      "Makoto Tatsuta"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.11798"
  },
  {
    "id": "arXiv:2106.11804",
    "title": "Evo* 2021 -- Late-Breaking Abstracts Volume",
    "abstract": "Volume with the Late-Breaking Abstracts submitted to the Evo* 2021\nConference, held online from 7 to 9 of April 2021. These papers present ongoing\nresearch and preliminary results investigating on the application of different\napproaches of Bioinspired Methods (mainly Evolutionary Computation) to\ndifferent problems, most of them real world ones.",
    "descriptor": "\nComments: LBAs accepted in Evo* 2021. Part of the Conference Proceedings\n",
    "authors": [
      "A.M. Mora",
      "A.I. Esparcia-Alc\u00e1zar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11804"
  },
  {
    "id": "arXiv:2106.11807",
    "title": "Maximum-principle-satisfying discontinuous Galerkin methods for  incompressible two-phase immiscible flow",
    "abstract": "This paper proposes a fully implicit numerical scheme for immiscible\nincompressible two-phase flow in porous media taking into account gravity,\ncapillary effects, and heterogeneity. The objective is to develop a fully\nimplicit stable discontinuous Galerkin (DG) solver for this system that is\naccurate, bound-preserving, and locally mass conservative. To achieve this, we\naugment our DG formulation with post-processing flux and slope limiters. The\nproposed framework is applied to several benchmark problems and the discrete\nsolutions are shown to be accurate, to satisfy the maximum principle and local\nmass conservation.",
    "descriptor": "\nComments: 33 pages, 27 figures\n",
    "authors": [
      "M. S. Joshaghani",
      "B. Riviere",
      "M. Sekachev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11807"
  },
  {
    "id": "arXiv:2106.11808",
    "title": "Fully CMOS-compatible passive TiO2-based memristor crossbars for  in-memory computing",
    "abstract": "Brain-inspired computing and neuromorphic hardware are promising approaches\nthat offer great potential to overcome limitations faced by current computing\nparadigms based on traditional von-Neumann architecture. In this regard,\ninterest in developing memristor crossbar arrays has increased due to their\nability to natively perform in-memory computing and fundamental synaptic\noperations required for neural network implementation. For optimal efficiency,\ncrossbar-based circuits need to be compatible with fabrication processes and\nmaterials of industrial CMOS technologies. Herein, we report a complete\nCMOS-compatible fabrication process of TiO2-based passive memristor crossbars\nwith 700 nm wide electrodes. We show successful bottom electrode fabrication by\na damascene process, resulting in an optimised topography and a surface\nroughness as low as 1.1 nm. DC sweeps and voltage pulse programming yield\nstatistical results related to synaptic-like multilevel switching. Both\ncycle-to-cycle and device-to-device variability are investigated. Analogue\nprogramming of the conductance using sequences of 200 ns voltage pulses suggest\nthat the fabricated memories have a multilevel capacity of at least 3 bits due\nto the cycle-to-cycle reproducibility.",
    "descriptor": "\nComments: 14 pages, 4 figures in main text, 2 figures in SI\n",
    "authors": [
      "Abdelouadoud El Mesoudy",
      "Gw\u00e9na\u00eblle Lamri",
      "Rapha\u00ebl Dawant",
      "Javier Arias-Zapata",
      "Pierre Gliech",
      "Yann Beilliard",
      "Serge Ecoffey",
      "Andreas Ruediger",
      "Fabien Alibart",
      "Dominique Drouin"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.11808"
  },
  {
    "id": "arXiv:2106.11810",
    "title": "nuPlan: A closed-loop ML-based planning benchmark for autonomous  vehicles",
    "abstract": "In this work, we propose the world's first closed-loop ML-based planning\nbenchmark for autonomous driving. While there is a growing body of ML-based\nmotion planners, the lack of established datasets and metrics has limited the\nprogress in this area. Existing benchmarks for autonomous vehicle motion\nprediction have focused on short-term motion forecasting, rather than long-term\nplanning. This has led previous works to use open-loop evaluation with L2-based\nmetrics, which are not suitable for fairly evaluating long-term planning. Our\nbenchmark overcomes these limitations by introducing a large-scale driving\ndataset, lightweight closed-loop simulator, and motion-planning-specific\nmetrics. We provide a high-quality dataset with 1500h of human driving data\nfrom 4 cities across the US and Asia with widely varying traffic patterns\n(Boston, Pittsburgh, Las Vegas and Singapore). We will provide a closed-loop\nsimulation framework with reactive agents and provide a large set of both\ngeneral and scenario-specific planning metrics. We plan to release the dataset\nat NeurIPS 2021 and organize benchmark challenges starting in early 2022.",
    "descriptor": "\nComments: Camera-ready for CVPR ADP3 workshop\n",
    "authors": [
      "Holger Caesar",
      "Juraj Kabzan",
      "Kok Seang Tan",
      "Whye Kit Fong",
      "Eric Wolff",
      "Alex Lang",
      "Luke Fletcher",
      "Oscar Beijbom",
      "Sammy Omari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11810"
  },
  {
    "id": "arXiv:2106.11811",
    "title": "Weakly-Supervised Temporal Action Localization Through Local-Global  Background Modeling",
    "abstract": "Weakly-Supervised Temporal Action Localization (WS-TAL) task aims to\nrecognize and localize temporal starts and ends of action instances in an\nuntrimmed video with only video-level label supervision. Due to lack of\nnegative samples of background category, it is difficult for the network to\nseparate foreground and background, resulting in poor detection performance. In\nthis report, we present our 2021 HACS Challenge - Weakly-supervised Learning\nTrack solution that based on BaSNet to address above problem. Specifically, we\nfirst adopt pre-trained CSN, Slowfast, TDN, and ViViT as feature extractors to\nget feature sequences. Then our proposed Local-Global Background Modeling\nNetwork (LGBM-Net) is trained to localize instances by using only video-level\nlabels based on Multi-Instance Learning (MIL). Finally, we ensemble multiple\nmodels to get the final detection results and reach 22.45% mAP on the test set",
    "descriptor": "\nComments: CVPR-2021 HACS Challenge - Weakly-supervised Learning Track champion solution (1st Place)\n",
    "authors": [
      "Xiang Wang",
      "Zhiwu Qing",
      "Ziyuan Huang",
      "Yutong Feng",
      "Shiwei Zhang",
      "Jianwen Jiang",
      "Mingqian Tang",
      "Yuanjie Shao",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11811"
  },
  {
    "id": "arXiv:2106.11812",
    "title": "Proposal Relation Network for Temporal Action Detection",
    "abstract": "This technical report presents our solution for temporal action detection\ntask in AcitivityNet Challenge 2021. The purpose of this task is to locate and\nidentify actions of interest in long untrimmed videos. The crucial challenge of\nthe task comes from that the temporal duration of action varies dramatically,\nand the target actions are typically embedded in a background of irrelevant\nactivities. Our solution builds on BMN, and mainly contains three steps: 1)\naction classification and feature encoding by Slowfast, CSN and ViViT; 2)\nproposal generation. We improve BMN by embedding the proposed Proposal Relation\nNetwork (PRN), by which we can generate proposals of high quality; 3) action\ndetection. We calculate the detection results by assigning the proposals with\ncorresponding classification results. Finally, we ensemble the results under\ndifferent settings and achieve 44.7% on the test set, which improves the\nchampion result in ActivityNet 2020 by 1.9% in terms of average mAP.",
    "descriptor": "\nComments: CVPR-2021 ActivityNet Temporal Action Localization Challenge champion solution (1st Place)\n",
    "authors": [
      "Xiang Wang",
      "Zhiwu Qing",
      "Ziyuan Huang",
      "Yutong Feng",
      "Shiwei Zhang",
      "Jianwen Jiang",
      "Mingqian Tang",
      "Changxin Gao",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11812"
  },
  {
    "id": "arXiv:2106.11813",
    "title": "Enabling and interpreting hyper-differential sensitivity analysis for  Bayesian inverse problems",
    "abstract": "Inverse problems constrained by partial differential equations (PDEs) play a\ncritical role in model development and calibration. In many applications, there\nare multiple uncertain parameters in a model which must be estimated. Although\nthe Bayesian formulation is attractive for such problems, computational cost\nand high dimensionality frequently prohibit a thorough exploration of the\nparametric uncertainty. A common approach is to reduce the dimension by fixing\nsome parameters (which we will call auxiliary parameters) to a best estimate\nand using techniques from PDE-constrained optimization to approximate\nproperties of the Bayesian posterior distribution. For instance, the maximum a\nposteriori probability (MAP) and the Laplace approximation of the posterior\ncovariance can be computed. In this article, we propose using\nhyper-differential sensitivity analysis (HDSA) to assess the sensitivity of the\nMAP point to changes in the auxiliary parameters. We establish an\ninterpretation of HDSA as correlations in the posterior distribution.\nFoundational assumptions for HDSA require satisfaction of the optimality\nconditions which are not always feasible or appropriate as a result of\nill-posedness in the inverse problem. We introduce novel theoretical and\ncomputational approaches to justify and enable HDSA for ill-posed inverse\nproblems by projecting the sensitivities on likelihood informed subspaces and\ndefining a posteriori updates. Our proposed framework is demonstrated on a\nnonlinear multi-physics inverse problem motivated by estimation of spatially\nheterogenous material properties in the presence of spatially distributed\nparametric modeling uncertainties.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Joseph Hart",
      "Bart van Bloemen Waanders"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11813"
  },
  {
    "id": "arXiv:2106.11814",
    "title": "Enabling Long-Term Cooperation in Cross-Silo Federated Learning: A  Repeated Game Perspective",
    "abstract": "Cross-silo federated learning (FL) is a distributed learning approach where\nclients train a global model cooperatively while keeping their local data\nprivate. Different from cross-device FL, clients in cross-silo FL are usually\norganizations or companies which may execute multiple cross-silo FL processes\nrepeatedly due to their time-varying local data sets, and aim to optimize their\nlong-term benefits by selfishly choosing their participation levels. While\nthere has been some work on incentivizing clients to join FL, the analysis of\nthe long-term selfish participation behaviors of clients in cross-silo FL\nremains largely unexplored. In this paper, we analyze the selfish participation\nbehaviors of heterogeneous clients in cross-silo FL. Specifically, we model the\nlong-term selfish participation behaviors of clients as an infinitely repeated\ngame, with the stage game being a selfish participation game in one cross-silo\nFL process (SPFL). For the stage game SPFL, we derive the unique Nash\nequilibrium (NE), and propose a distributed algorithm for each client to\ncalculate its equilibrium participation strategy. For the long-term\ninteractions among clients, we derive a cooperative strategy for clients which\nminimizes the number of free riders while increasing the amount of local data\nfor model training. We show that enforced by a punishment strategy, such a\ncooperative strategy is a SPNE of the infinitely repeated game, under which\nsome clients who are free riders at the NE of the stage game choose to be\n(partial) contributors. We further propose an algorithm to calculate the\noptimal SPNE which minimizes the number of free riders while maximizing the\namount of local data for model training. Simulation results show that our\nproposed cooperative strategy at the optimal SPNE can effectively reduce the\nnumber of free riders and increase the amount of local data for model training.",
    "descriptor": "",
    "authors": [
      "Ning Zhang",
      "Qian Ma",
      "Xu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.11814"
  },
  {
    "id": "arXiv:2106.11815",
    "title": "User Identification across Social Networking Sites using User Profiles  and Posting Patterns",
    "abstract": "With the prevalence of online social networking sites (OSNs) and mobile\ndevices, people are increasingly reliant on a variety of OSNs for keeping in\ntouch with family and friends, and using it as a source of information. For\nexample, a user might utilise multiple OSNs for different purposes, such as\nusing Flickr to share holiday pictures with family and friends, and Twitter to\npost short messages about their thoughts. Identifying the same user across\nmultiple OSNs is an important task as this allows us to understand the usage\npatterns of users among different OSNs, make recommendations when a user\nregisters for a new OSN, and various other useful applications. To address this\nproblem, we proposed an algorithm based on the multilayer perceptron using\nvarious types of features, namely: (i) user profile, such as name, location,\ndescription; (ii) temporal distribution of user generated content; and (iii)\nembedding based on user name, real name and description. Using a Twitter and\nFlickr dataset of users and their posting activities, we perform an empirical\nstudy on how these features affect the performance of user identification\nacross the two OSNs and discuss our main findings based on the different\nfeatures.",
    "descriptor": "\nComments: Accepted at the 2021 International Joint Conference on Neural Networks (IJCNN'21)\n",
    "authors": [
      "Prashant Solanki",
      "Kwan Hui Lim",
      "Aaron Harwood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.11815"
  },
  {
    "id": "arXiv:2106.11818",
    "title": "Linear Logic, the $\u03c0$-calculus, and their Metatheory: A Recipe for  Proofs as Processes",
    "abstract": "Initiated by Abramsky [1994], the Proofs as Processes agenda is to establish\na solid foundation for the study of concurrent languages, by researching the\nconnection between linear logic and the $\\pi$-calculus.\nTo date, Proofs as Processes is still a partial success. Caires and Pfenning\n[2010] showed that linear propositions correspond to session types, which\nprescribe the observable behaviour of processes. Further, Carbone et al. [2018]\ndemonstrated that adopting devices from hypersequents [Avron 1991] shapes\nproofs such that they correspond to the expected syntactic structure of\nprocesses in the $\\pi$-calculus. What remains is reconstructing the expected\nmetatheory of session types and the $\\pi$-calculus. In particular, the hallmark\nof session types, session fidelity, still has to be reconstructed: a\ncorrespondence between the observable behaviours of processes and their session\ntypes, in terms of labelled transitions.\nIn this article, we present $\\pi$LL, a new process calculus rooted in linear\nlogic. The key novelty of $\\pi$LL is that it comes with a carefully formulated\ndesign recipe, based on a dialgebraic view of labelled transition systems.\nThanks to our recipe, $\\pi$LL offers the expected transition systems of session\ntypes, which we use to establish session fidelity. We use $\\pi$LL to carry out\nthe first thorough investigation of the metatheoretical properties enforced by\nlinear logic on the observable behaviour of processes, uncovering connections\nwith similarity and bisimilarity. We also prove that $\\pi$LL and our recipe\nform a robust basis for the further exploration of Proofs as Processes, by\nconsidering different features: polymorphism, process mobility, and recursion.",
    "descriptor": "",
    "authors": [
      "Fabrizio Montesi",
      "Marco Peressotti"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.11818"
  },
  {
    "id": "arXiv:2106.11819",
    "title": "High Performance Optimization at the Door of the Exascale",
    "abstract": "quest for processing speed potential. In fact, we always get a fraction of\nthe technically available computing power (so-called {\\em theoretical peak}),\nand the gap is likely to go hand-to-hand with the hardware complexity of the\ntarget system. Among the key aspects of this complexity, we have: the {\\em\nheterogeneity} of the computing units, the {\\em memory hierarchy and\npartitioning} including the non-uniform memory access (NUMA) configuration, and\nthe {\\em interconnect} for data exchanges among the computing nodes. Scientific\ninvestigations and cutting-edge technical activities should ideally scale-up\nwith respect to sustained performance. The special case of quantitative\napproaches for solving (large-scale) problems deserves a special focus. Indeed,\nmost of common real-life problems, even when considering the artificial\nintelligence paradigm, rely on optimization techniques for the main kernels of\nalgorithmic solutions. Mathematical programming and pure combinatorial methods\nare not easy to implement efficiently on large-scale supercomputers because of\n{\\em irregular control flow}, {\\em complex memory access patterns}, {\\em\nheterogeneous kernels}, {\\em numerical issues}, to name a few. We describe and\nexamine our thoughts from the standpoint of large-scale supercomputers.",
    "descriptor": "",
    "authors": [
      "Claude Tadonki"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.11819"
  },
  {
    "id": "arXiv:2106.11821",
    "title": "Data Augmentation for Opcode Sequence Based Malware Detection",
    "abstract": "Data augmentation has been successfully used in many areas of deep-learning\nto significantly improve model performance. Typically data augmentation\nsimulates realistic variations in data in order to increase the apparent\ndiversity of the training-set. However, for opcode-based malware analysis,\nwhere deep learning methods are already achieving state of the art performance,\nit is not immediately clear how to apply data augmentation. In this paper we\nstudy different methods of data augmentation starting with basic methods using\nfixed transformations and moving to methods that adapt to the data. We propose\na novel data augmentation method based on using an opcode embedding layer\nwithin the network and its corresponding opcode embedding matrix to perform\nadaptive data augmentation during training. To the best of our knowledge this\nis the first paper to carry out a systematic study of different augmentation\nmethods applied to opcode sequence based malware classification.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Niall McLaughlin",
      "Jesus Martinez del Rincon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11821"
  },
  {
    "id": "arXiv:2106.11823",
    "title": "A Clustering-based Framework for Classifying Data Streams",
    "abstract": "The non-stationary nature of data streams strongly challenges traditional\nmachine learning techniques. Although some solutions have been proposed to\nextend traditional machine learning techniques for handling data streams, these\napproaches either require an initial label set or rely on specialized design\nparameters. The overlap among classes and the labeling of data streams\nconstitute other major challenges for classifying data streams. In this paper,\nwe proposed a clustering-based data stream classification framework to handle\nnon-stationary data streams without utilizing an initial label set. A\ndensity-based stream clustering procedure is used to capture novel concepts\nwith a dynamic threshold and an effective active label querying strategy is\nintroduced to continuously learn the new concepts from the data streams. The\nsub-cluster structure of each cluster is explored to handle the overlap among\nclasses. Experimental results and quantitative comparison studies reveal that\nthe proposed method provides statistically better or comparable performance\nthan the existing methods.",
    "descriptor": "\nComments: This paper has been accepted by IJCAI 2021\n",
    "authors": [
      "Xuyang Yan",
      "Abdollah Homaifar",
      "Mrinmoy Sarkar",
      "Abenezer Girma",
      "Edward Tunstel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11823"
  },
  {
    "id": "arXiv:2106.11825",
    "title": "Beyond 5G URLLC Evolution: New Service Modes and Practical  Considerations",
    "abstract": "Ultra-reliable low latency communications (URLLC) arose to serve industrial\nIoT (IIoT) use cases within the 5G. Currently, it has inherent limitations to\nsupport future services. Based on state-of-the-art research and practical\ndeployment experience, in this article, we introduce and advocate for three\nvariants: broadband, scalable and extreme URLLC. We discuss use cases and key\nperformance indicators and identify technology enablers for the new service\nmodes. We bring practical considerations from the IIoT testbed and provide an\noutlook toward some new research directions.",
    "descriptor": "\nComments: Submitted to IEEE Wireless Commun. Mag\n",
    "authors": [
      "Hirley Alves",
      "Gweon Do Jo",
      "JaeSheung Shin",
      "Choongil Yeh",
      "Nurul Huda Mahmood",
      "Carlos Lima",
      "Chanho Yoon",
      "Nandana Rahatheva",
      "Ok-Sun Park",
      "Seokki Kim",
      "Eunah Kim",
      "Ville Niemel\u00e4",
      "Hyeon Woo Lee",
      "Ari Pouttu",
      "Hyun Kyu Chung",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.11825"
  },
  {
    "id": "arXiv:2106.11827",
    "title": "Lower and Upper Bounds on the VC-Dimension of Tensor Network Models",
    "abstract": "Tensor network methods have been a key ingredient of advances in condensed\nmatter physics and have recently sparked interest in the machine learning\ncommunity for their ability to compactly represent very high-dimensional\nobjects. Tensor network methods can for example be used to efficiently learn\nlinear models in exponentially large feature spaces [Stoudenmire and Schwab,\n2016]. In this work, we derive upper and lower bounds on the VC dimension and\npseudo-dimension of a large class of tensor network models for classification,\nregression and completion. Our upper bounds hold for linear models\nparameterized by arbitrary tensor network structures, and we derive lower\nbounds for common tensor decomposition models~(CP, Tensor Train, Tensor Ring\nand Tucker) showing the tightness of our general upper bound. These results are\nused to derive a generalization bound which can be applied to classification\nwith low rank matrices as well as linear classifiers based on any of the\ncommonly used tensor decomposition models. As a corollary of our results, we\nobtain a bound on the VC dimension of the matrix product state classifier\nintroduced in [Stoudenmire and Schwab, 2016] as a function of the so-called\nbond dimension~(i.e. tensor train rank), which answers an open problem listed\nby Cirac, Garre-Rubio and P\\'erez-Garc\\'ia in [Cirac et al., 2019].",
    "descriptor": "",
    "authors": [
      "Behnoush Khavari",
      "Guillaume Rabusseau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11827"
  },
  {
    "id": "arXiv:2106.11828",
    "title": "Speeding Up OPFython with Numba",
    "abstract": "A graph-inspired classifier, known as Optimum-Path Forest (OPF), has proven\nto be a state-of-the-art algorithm comparable to Logistic Regressors, Support\nVector Machines in a wide variety of tasks. Recently, its Python-based version,\ndenoted as OPFython, has been proposed to provide a more friendly framework and\na faster prototyping environment. Nevertheless, Python-based algorithms are\nslower than their counterpart C-based algorithms, impacting their performance\nwhen confronted with large amounts of data. Therefore, this paper proposed a\nsimple yet highly efficient speed up using the Numba package, which accelerates\nNumpy-based calculations and attempts to increase the algorithm's overall\nperformance. Experimental results showed that the proposed approach achieved\nbetter results than the na\\\"ive Python-based OPF and speeded up its distance\nmeasurement calculation.",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Gustavo H. de Rosa",
      "Jo\u00e3o Paulo Papa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11828"
  },
  {
    "id": "arXiv:2106.11841",
    "title": "Domain-Smoothing Network for Zero-Shot Sketch-Based Image Retrieval",
    "abstract": "Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR) is a novel cross-modal\nretrieval task, where abstract sketches are used as queries to retrieve natural\nimages under zero-shot scenario. Most existing methods regard ZS-SBIR as a\ntraditional classification problem and employ a cross-entropy or triplet-based\nloss to achieve retrieval, which neglect the problems of the domain gap between\nsketches and natural images and the large intra-class diversity in sketches.\nToward this end, we propose a novel Domain-Smoothing Network (DSN) for ZS-SBIR.\nSpecifically, a cross-modal contrastive method is proposed to learn generalized\nrepresentations to smooth the domain gap by mining relations with additional\naugmented samples. Furthermore, a category-specific memory bank with sketch\nfeatures is explored to reduce intra-class diversity in the sketch domain.\nExtensive experiments demonstrate that our approach notably outperforms the\nstate-of-the-art methods in both Sketchy and TU-Berlin datasets. Our source\ncode is publicly available at https://github.com/haowang1992/DSN.",
    "descriptor": "\nComments: Accepted to IJCAI 2021\n",
    "authors": [
      "Zhipeng Wang",
      "Hao Wang",
      "Jiexi Yan",
      "Aming Wu",
      "Cheng Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11841"
  },
  {
    "id": "arXiv:2106.11844",
    "title": "Detecting Anomalous User Behavior in Remote Patient Monitoring",
    "abstract": "The growth in Remote Patient Monitoring (RPM) services using wearable and\nnon-wearable Internet of Medical Things (IoMT) promises to improve the quality\nof diagnosis and facilitate timely treatment for a gamut of medical conditions.\nAt the same time, the proliferation of IoMT devices increases the potential for\nmalicious activities that can lead to catastrophic results including theft of\npersonal information, data breach, and compromised medical devices, putting\nhuman lives at risk. IoMT devices generate tremendous amount of data that\nreflect user behavior patterns including both personal and day-to-day social\nactivities along with daily routine health monitoring. In this context, there\nare possibilities of anomalies generated due to various reasons including\nunexpected user behavior, faulty sensor, or abnormal values from\nmalicious/compromised devices. To address this problem, there is an imminent\nneed to develop a framework for securing the smart health care infrastructure\nto identify and mitigate anomalies. In this paper, we present an anomaly\ndetection model for RPM utilizing IoMT and smart home devices. We propose\nHidden Markov Model (HMM) based anomaly detection that analyzes normal user\nbehavior in the context of RPM comprising both smart home and smart health\ndevices, and identifies anomalous user behavior. We design a testbed with\nmultiple IoMT devices and home sensors to collect data and use the HMM model to\ntrain using network and user behavioral data. Proposed HMM based anomaly\ndetection model achieved over 98% accuracy in identifying the anomalies in the\ncontext of RPM.",
    "descriptor": "",
    "authors": [
      "Deepti Gupta",
      "Maanak Gupta",
      "Smriti Bhatt",
      "Ali Saman Tosun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11844"
  },
  {
    "id": "arXiv:2106.11847",
    "title": "Machine learning for risk assessment in gender-based crime",
    "abstract": "Gender-based crime is one of the most concerning scourges of contemporary\nsociety. Governments worldwide have invested lots of economic and human\nresources to radically eliminate this threat. Despite these efforts, providing\naccurate predictions of the risk that a victim of gender violence has of being\nattacked again is still a very hard open problem. The development of new\nmethods for issuing accurate, fair and quick predictions would allow police\nforces to select the most appropriate measures to prevent recidivism. In this\nwork, we propose to apply Machine Learning (ML) techniques to create models\nthat accurately predict the recidivism risk of a gender-violence offender. The\nrelevance of the contribution of this work is threefold: (i) the proposed ML\nmethod outperforms the preexisting risk assessment algorithm based on classical\nstatistical techniques, (ii) the study has been conducted through an official\nspecific-purpose database with more than 40,000 reports of gender violence, and\n(iii) two new quality measures are proposed for assessing the effective police\nprotection that a model supplies and the overload in the invested resources\nthat it generates. Additionally, we propose a hybrid model that combines the\nstatistical prediction methods with the ML method, permitting authorities to\nimplement a smooth transition from the preexisting model to the ML-based model.\nThis hybrid nature enables a decision-making process to optimally balance\nbetween the efficiency of the police system and aggressiveness of the\nprotection measures taken.",
    "descriptor": "\nComments: 17 pages, 5 figures, 4 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "\u00c1ngel Gonz\u00e1lez-Prieto",
      "Antonio Br\u00fa",
      "Juan Carlos Nu\u00f1o",
      "Jos\u00e9 Luis Gonz\u00e1lez-\u00c1lvarez"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11847"
  },
  {
    "id": "arXiv:2106.11851",
    "title": "Stochastic Polyak Stepsize with a Moving Target",
    "abstract": "We propose a new stochastic gradient method that uses recorded past loss\nvalues to reduce the variance. Our method can be interpreted as a new\nstochastic variant of the Polyak Stepsize that converges globally without\nassuming interpolation. Our method introduces auxiliary variables, one for each\ndata point, that track the loss value for each data point. We provide a global\nconvergence theory for our method by showing that it can be interpreted as a\nspecial variant of online SGD. The new method only stores a single scalar per\ndata point, opening up new applications for variance reduction where memory is\nthe bottleneck.",
    "descriptor": "\nComments: 41 pages, 13 figures, 1 table\n",
    "authors": [
      "Robert M. Gower",
      "Aaron Defazio",
      "Michael Rabbat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.11851"
  },
  {
    "id": "arXiv:2106.11854",
    "title": "Off-Policy Reinforcement Learning with Delayed Rewards",
    "abstract": "We study deep reinforcement learning (RL) algorithms with delayed rewards. In\nmany real-world tasks, instant rewards are often not readily accessible or even\ndefined immediately after the agent performs actions. In this work, we first\nformally define the environment with delayed rewards and discuss the challenges\nraised due to the non-Markovian nature of such environments. Then, we introduce\na general off-policy RL framework with a new Q-function formulation that can\nhandle the delayed rewards with theoretical convergence guarantees. For\npractical tasks with high dimensional state spaces, we further introduce the\nHC-decomposition rule of the Q-function in our framework which naturally leads\nto an approximation scheme that helps boost the training efficiency and\nstability. We finally conduct extensive experiments to demonstrate the superior\nperformance of our algorithms over the existing work and their variants.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Beining Han",
      "Zhizhou Ren",
      "Zuofan Wu",
      "Yuan Zhou",
      "Jian Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11854"
  },
  {
    "id": "arXiv:2106.11855",
    "title": "Intuitive and Ubiquitous Fever Monitoring Using Smartphones and  Smartwatches",
    "abstract": "Inside all smart devices, such as smartphones or smartwatches, there are\nthermally sensitive resistors known as thermistors which are used to monitor\nthe temperature of the device. These thermistors are sensitive to temperature\nchanges near their location on-device. While they are designed to measure the\ntemperature of the device components such as the battery, they can also sense\nchanges in the temperature of the ambient environment or thermal entities in\ncontact with the device. We have developed a model to estimate core body\ntemperature from signals sensed by these thermistors during a user interaction\nin which the user places the capacitive touchscreen of a smart device against a\nthermal site on their body such as their forehead. During the interaction, the\ndevice logs the temperature sensed by the thermistors as well as the raw\ncapacitance seen by the touch screen to capture features describing the rate of\nheat transfer from the body to the device and device-to-skin contact\nrespectively. These temperature and contact features are then used to model the\nrate of heat transferred from the user's body to the device and thus core-body\ntemperature of the user for ubiquitous and accessible fever monitoring using\nonly a smart device. We validate this system in a lab environment on a\nsimulated skin-like heat source with a temperature estimate mean absolute error\nof 0.743$^{\\circ}$F (roughly 0.4$^{\\circ}$C) and limit of agreement of\n$\\pm2.374^{\\circ}$F (roughly 1.3$^{\\circ}$C) which is comparable to some\noff-the-shelf peripheral and tympanic thermometers. We found a Pearson's\ncorrelation $R^2$ of 0.837 between ground truth temperature and temperature\nestimated by our system. We also deploy this system in an ongoing clinical\nstudy on a population of 7 participants in a clinical environment to show the\nsimilarity between simulated and clinical trials.",
    "descriptor": "\nComments: 18 pages, 9 figures, Not yet submitted to conference (submitting after clinical trials)\n",
    "authors": [
      "Joseph Breda",
      "Shwetak Patel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11855"
  },
  {
    "id": "arXiv:2106.11857",
    "title": "HybVIO: Pushing the Limits of Real-time Visual-inertial Odometry",
    "abstract": "We present HybVIO, a novel hybrid approach for combining filtering-based\nvisual-inertial odometry (VIO) with optimization-based SLAM. The core of our\nmethod is highly robust, independent VIO with improved IMU bias modeling,\noutlier rejection, stationarity detection, and feature track selection, which\nis adjustable to run on embedded hardware. Long-term consistency is achieved\nwith a loosely-coupled SLAM module. In academic benchmarks, our solution yields\nexcellent performance in all categories, especially in the real-time use case,\nwhere we outperform the current state-of-the-art. We also demonstrate the\nfeasibility of VIO for vehicular tracking on consumer-grade hardware using a\ncustom dataset, and show good performance in comparison to current commercial\nVISLAM alternatives.",
    "descriptor": "",
    "authors": [
      "Otto Seiskari",
      "Pekka Rantalankila",
      "Juho Kannala",
      "Jerry Ylilammi",
      "Esa Rahtu",
      "Arno Solin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11857"
  },
  {
    "id": "arXiv:2106.11858",
    "title": "MEAL: Manifold Embedding-based Active Learning",
    "abstract": "Image segmentation is a common and challenging task in autonomous driving.\nAvailability of sufficient pixel-level annotations for the training data is a\nhurdle. Active learning helps learning from small amounts of data by suggesting\nthe most promising samples for labeling. In this work, we propose a new\npool-based method for active learning, which proposes promising image regions,\nin each acquisition step. The problem is framed in an exploration-exploitation\nframework by combining an embedding based on Uniform Manifold Approximation to\nmodel representativeness with entropy as uncertainty measure to model\ninformativeness. We applied our proposed method to the challenging autonomous\ndriving data sets CamVid and Cityscapes and performed a quantitative comparison\nwith state-of-the-art methods. We find that our active learning method achieves\nbetter performance on CamVid compared to other methods, while on Cityscapes,\nthe performance lift was negligible.",
    "descriptor": "",
    "authors": [
      "Deepthi Sreenivasaiah",
      "Thomas Wollmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11858"
  },
  {
    "id": "arXiv:2106.11863",
    "title": "Graph coarsening: From scientific computing to machine learning",
    "abstract": "The general method of graph coarsening or graph reduction has been a\nremarkably useful and ubiquitous tool in scientific computing and it is now\njust starting to have a similar impact in machine learning. The goal of this\npaper is to take a broad look into coarsening techniques that have been\nsuccessfully deployed in scientific computing and see how similar principles\nare finding their way in more recent applications related to machine learning.\nIn scientific computing, coarsening plays a central role in algebraic multigrid\nmethods as well as the related class of multilevel incomplete LU\nfactorizations. In machine learning, graph coarsening goes under various names,\ne.g., graph downsampling or graph reduction. Its goal in most cases is to\nreplace some original graph by one which has fewer nodes, but whose structure\nand characteristics are similar to those of the original graph. As will be\nseen, a common strategy in these methods is to rely on spectral properties to\ndefine the coarse graph.",
    "descriptor": "",
    "authors": [
      "Jie Chen",
      "Yousef Saad",
      "Zechen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11863"
  },
  {
    "id": "arXiv:2106.11864",
    "title": "Towards Automated Evaluation of Explanations in Graph Neural Networks",
    "abstract": "Explaining Graph Neural Networks predictions to end users of AI applications\nin easily understandable terms remains an unsolved problem. In particular, we\ndo not have well developed methods for automatically evaluating explanations,\nin ways that are closer to how users consume those explanations. Based on\nrecent application trends and our own experiences in real world problems, we\npropose automatic evaluation approaches for GNN Explanations.",
    "descriptor": "\nComments: 5 pages, 4 figures, XAI Workshop at ICML 2021\n",
    "authors": [
      "Vanya BK",
      "Balaji Ganesan",
      "Aniket Saxena",
      "Devbrat Sharma",
      "Arvind Agarwal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11864"
  },
  {
    "id": "arXiv:2106.11865",
    "title": "NetFense: Adversarial Defenses against Privacy Attacks on Neural  Networks for Graph Data",
    "abstract": "Recent advances in protecting node privacy on graph data and attacking graph\nneural networks (GNNs) gain much attention. The eye does not bring these two\nessential tasks together yet. Imagine an adversary can utilize the powerful\nGNNs to infer users' private labels in a social network. How can we\nadversarially defend against such privacy attacks while maintaining the utility\nof perturbed graphs? In this work, we propose a novel research task,\nadversarial defenses against GNN-based privacy attacks, and present a graph\nperturbation-based approach, NetFense, to achieve the goal. NetFense can\nsimultaneously keep graph data unnoticeability (i.e., having limited changes on\nthe graph structure), maintain the prediction confidence of targeted label\nclassification (i.e., preserving data utility), and reduce the prediction\nconfidence of private label classification (i.e., protecting the privacy of\nnodes). Experiments conducted on single- and multiple-target perturbations\nusing three real graph data exhibit that the perturbed graphs by NetFense can\neffectively maintain data utility (i.e., model unnoticeability) on targeted\nlabel classification and significantly decrease the prediction confidence of\nprivate label classification (i.e., privacy protection). Extensive studies also\nbring several insights, such as the flexibility of NetFense, preserving local\nneighborhoods in data unnoticeability, and better privacy protection for\nhigh-degree nodes.",
    "descriptor": "\nComments: Accepted to IEEE TKDE 2021. Code is available at this https URL\n",
    "authors": [
      "I-Chung Hsieh",
      "Cheng-Te Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.11865"
  },
  {
    "id": "arXiv:2106.11872",
    "title": "Randomness In Neural Network Training: Characterizing The Impact of  Tooling",
    "abstract": "The quest for determinism in machine learning has disproportionately focused\non characterizing the impact of noise introduced by algorithmic design choices.\nIn this work, we address a less well understood and studied question: how does\nour choice of tooling introduce randomness to deep neural network training. We\nconduct large scale experiments across different types of hardware,\naccelerators, state of art networks, and open-source datasets, to characterize\nhow tooling choices contribute to the level of non-determinism in a system, the\nimpact of said non-determinism, and the cost of eliminating different sources\nof noise.\nOur findings are surprising, and suggest that the impact of non-determinism\nin nuanced. While top-line metrics such as top-1 accuracy are not noticeably\nimpacted, model performance on certain parts of the data distribution is far\nmore sensitive to the introduction of randomness. Our results suggest that\ndeterministic tooling is critical for AI safety. However, we also find that the\ncost of ensuring determinism varies dramatically between neural network\narchitectures and hardware types, e.g., with overhead up to $746\\%$, $241\\%$,\nand $196\\%$ on a spectrum of widely used GPU accelerator architectures,\nrelative to non-deterministic training. The source code used in this paper is\navailable at https://github.com/usyd-fsalab/NeuralNetworkRandomness.",
    "descriptor": "\nComments: 21 pages, 10 figures\n",
    "authors": [
      "Donglin Zhuang",
      "Xingyao Zhang",
      "Shuaiwen Leon Song",
      "Sara Hooker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.11872"
  },
  {
    "id": "arXiv:2106.11878",
    "title": "Multiple Organ Failure Prediction with Classifier-Guided Generative  Adversarial Imputation Networks",
    "abstract": "Multiple organ failure (MOF) is a severe syndrome with a high mortality rate\namong Intensive Care Unit (ICU) patients. Early and precise detection is\ncritical for clinicians to make timely decisions. An essential challenge in\napplying machine learning models to electronic health records (EHRs) is the\npervasiveness of missing values. Most existing imputation methods are involved\nin the data preprocessing phase, failing to capture the relationship between\ndata and outcome for downstream predictions. In this paper, we propose\nclassifier-guided generative adversarial imputation networks Classifier-GAIN)\nfor MOF prediction to bridge this gap, by incorporating both observed data and\nlabel information. Specifically, the classifier takes imputed values from the\ngenerator(imputer) to predict task outcomes and provides additional supervision\nsignals to the generator by joint training. The classifier-guide generator\nimputes missing values with label-awareness during training, improving the\nclassifier's performance during inference. We conduct extensive experiments\nshowing that our approach consistently outperforms classical and state-of-art\nneural baselines across a range of missing data scenarios and evaluation\nmetrics.",
    "descriptor": "\nComments: BioKDD\n",
    "authors": [
      "Xinlu Zhang",
      "Yun Zhao",
      "Rachael Callcut",
      "Linda Petzold"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11878"
  },
  {
    "id": "arXiv:2106.11880",
    "title": "Dynamic Customer Embeddings for Financial Service Applications",
    "abstract": "As financial services (FS) companies have experienced drastic technology\ndriven changes, the availability of new data streams provides the opportunity\nfor more comprehensive customer understanding. We propose Dynamic Customer\nEmbeddings (DCE), a framework that leverages customers' digital activity and a\nwide range of financial context to learn dense representations of customers in\nthe FS industry. Our method examines customer actions and pageviews within a\nmobile or web digital session, the sequencing of the sessions themselves, and\nsnapshots of common financial features across our organization at the time of\nlogin. We test our customer embeddings using real world data in three\nprediction problems: 1) the intent of a customer in their next digital session,\n2) the probability of a customer calling the call centers after a session, and\n3) the probability of a digital session to be fraudulent. DCE showed\nperformance lift in all three downstream problems.",
    "descriptor": "\nComments: ICML Workshop on Representation Learning for Finance and E-Commerce Applications\n",
    "authors": [
      "Nima Chitsazan",
      "Samuel Sharpe",
      "Dwipam Katariya",
      "Qianyu Cheng",
      "Karthik Rajasethupathy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11880"
  },
  {
    "id": "arXiv:2106.11881",
    "title": "Failing with Grace: Learning Neural Network Controllers that are  Boundedly Unsafe",
    "abstract": "In this work, we consider the problem of learning a feed-forward neural\nnetwork (NN) controller to safely steer an arbitrarily shaped planar robot in a\ncompact and obstacle-occluded workspace. Unlike existing methods that depend\nstrongly on the density of data points close to the boundary of the safe state\nspace to train NN controllers with closed-loop safety guarantees, we propose an\napproach that lifts such assumptions on the data that are hard to satisfy in\npractice and instead allows for graceful safety violations, i.e., of a bounded\nmagnitude that can be spatially controlled. To do so, we employ reachability\nanalysis methods to encapsulate safety constraints in the training process.\nSpecifically, to obtain a computationally efficient over-approximation of the\nforward reachable set of the closed-loop system, we partition the robot's state\nspace into cells and adaptively subdivide the cells that contain states which\nmay escape the safe set under the trained control law. To do so, we first\ndesign appropriate under- and over-approximations of the robot's footprint to\nadaptively subdivide the configuration space into cells. Then, using the\noverlap between each cell's forward reachable set and the set of infeasible\nrobot configurations as a measure for safety violations, we introduce penalty\nterms into the loss function that penalize this overlap in the training\nprocess. As a result, our method can learn a safe vector field for the\nclosed-loop system and, at the same time, provide numerical worst-case bounds\non safety violation over the whole configuration space, defined by the overlap\nbetween the over-approximation of the forward reachable set of the closed-loop\nsystem and the set of unsafe states. Moreover, it can control the tradeoff\nbetween computational complexity and tightness of these bounds. Finally, we\nprovide a simulation study that verifies the efficacy of the proposed scheme.",
    "descriptor": "",
    "authors": [
      "Panagiotis Vlantis",
      "Michael M. Zavlanos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11881"
  },
  {
    "id": "arXiv:2106.11886",
    "title": "A Negative Answer to $P\\overset{?}{=}PSPACE$",
    "abstract": "There is a conjecture on $P\\overset{?}{=}PSPACE$ in computational complexity\nzoo. It is a widespread belief that $P\\neq PSPACE$, otherwise $P=NP$ which is\nextremely impossible. In this short work, we assert that $P\\neq PSPACE$ no\nmatter what outcome is on $P\\overset{?}{=}NP$. We accomplishe this via showing\n$NP\\neq PSPACE$. The method is by the result that Circuit-SAT$\\in DSPACE[n]$\nand the known result $DSPACE[n]\\subset DSPACE[n^2]$ by the space complexity\nhierarchy theorem. Closely related consequences are summarized.",
    "descriptor": "\nComments: Any technical mistakes are welcome to point out; comments are welcome\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.11886"
  },
  {
    "id": "arXiv:2106.11888",
    "title": "Notes on the H-measure of classifier performance",
    "abstract": "The H-measure is a classifier performance measure which takes into account\nthe context of application without requiring a rigid value of relative\nmisclassification costs to be set. Since its introduction in 2009 it has become\nwidely adopted. This paper answers various queries which users have raised\nsince its introduction, including questions about its interpretation, the\nchoice of a weighting function, whether it is strictly proper, and its\ncoherence, and relates the measure to other work.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "D. J. Hand",
      "C. Anagnostopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11888"
  },
  {
    "id": "arXiv:2106.11890",
    "title": "Latency-Aware Neural Architecture Search with Multi-Objective Bayesian  Optimization",
    "abstract": "When tuning the architecture and hyperparameters of large machine learning\nmodels for on-device deployment, it is desirable to understand the optimal\ntrade-offs between on-device latency and model accuracy. In this work, we\nleverage recent methodological advances in Bayesian optimization over\nhigh-dimensional search spaces and multi-objective Bayesian optimization to\nefficiently explore these trade-offs for a production-scale on-device natural\nlanguage understanding model at Facebook.",
    "descriptor": "\nComments: To Appear at the 8th ICML Workshop on Automated Machine Learning, ICML 2021\n",
    "authors": [
      "David Eriksson",
      "Pierce I-Jen Chuang",
      "Sam Daulton",
      "Ahmed Aly",
      "Arun Babu",
      "Akshat Shrivastava",
      "Peng Xia",
      "Shicong Zhao",
      "Ganesh Venkatesh",
      "Maximilian Balandat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11890"
  },
  {
    "id": "arXiv:2106.11891",
    "title": "On the Evaluation of Machine Translation for Terminology Consistency",
    "abstract": "As neural machine translation (NMT) systems become an important part of\nprofessional translator pipelines, a growing body of work focuses on combining\nNMT with terminologies. In many scenarios and particularly in cases of domain\nadaptation, one expects the MT output to adhere to the constraints provided by\na terminology. In this work, we propose metrics to measure the consistency of\nMT output with regards to a domain terminology. We perform studies on the\nCOVID-19 domain over 5 languages, also performing terminology-targeted human\nevaluation. We open-source the code for computing all proposed metrics:\nhttps://github.com/mahfuzibnalam/terminology_evaluation",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Md Mahfuz ibn Alam",
      "Antonios Anastasopoulos",
      "Laurent Besacier",
      "James Cross",
      "Matthias Gall\u00e9",
      "Philipp Koehn",
      "Vassilina Nikoulina"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11891"
  },
  {
    "id": "arXiv:2106.11892",
    "title": "Making Invisible Visible: Data-Driven Seismic Inversion with  Physics-Informed Data Augmentation",
    "abstract": "Deep learning and data-driven approaches have shown great potential in\nscientific domains. The promise of data-driven techniques relies on the\navailability of a large volume of high-quality training datasets. Due to the\nhigh cost of obtaining data through expensive physical experiments,\ninstruments, and simulations, data augmentation techniques for scientific\napplications have emerged as a new direction for obtaining scientific data\nrecently. However, existing data augmentation techniques originating from\ncomputer vision, yield physically unacceptable data samples that are not\nhelpful for the domain problems that we are interested in. In this paper, we\ndevelop new physics-informed data augmentation techniques based on\nconvolutional neural networks. Specifically, our generative models leverage\ndifferent physics knowledge (such as governing equations, observable\nperception, and physics phenomena) to improve the quality of the synthetic\ndata. To validate the effectiveness of our data augmentation techniques, we\napply them to solve a subsurface seismic full-waveform inversion using\nsimulated CO$_2$ leakage data. Our interest is to invert for subsurface\nvelocity models associated with very small CO$_2$ leakage. We validate the\nperformance of our methods using comprehensive numerical tests. Via comparison\nand analysis, we show that data-driven seismic imaging can be significantly\nenhanced by using our physics-informed data augmentation techniques.\nParticularly, the imaging quality has been improved by 15% in test scenarios of\ngeneral-sized leakage and 17% in small-sized leakage when using an augmented\ntraining set obtained with our techniques.",
    "descriptor": "\nComments: 13 pages, 12 figures, submitted to IEEE Transactions on Geoscience and Remote Sensing\n",
    "authors": [
      "Yuxin Yang",
      "Xitong Zhang",
      "Qiang Guan",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11892"
  },
  {
    "id": "arXiv:2106.11895",
    "title": "A Latent Transformer for Disentangled and Identity-Preserving Face  Editing",
    "abstract": "High quality facial image editing is a challenging problem in the movie\npost-production industry, requiring a high degree of control and identity\npreservation. Previous works that attempt to tackle this problem may suffer\nfrom the entanglement of facial attributes and the loss of the person's\nidentity. Furthermore, many algorithms are limited to a certain task. To tackle\nthese limitations, we propose to edit facial attributes via the latent space of\na StyleGAN generator, by training a dedicated latent transformation network and\nincorporating explicit disentanglement and identity preservation terms in the\nloss function. We further introduce a pipeline to generalize our face editing\nto videos. Our model achieves a disentangled, controllable, and\nidentity-preserving facial attribute editing, even in the challenging case of\nreal (i.e., non-synthetic) images and videos. We conduct extensive experiments\non image and video datasets and show that our model outperforms other\nstate-of-the-art methods in visual quality and quantitative evaluation.",
    "descriptor": "",
    "authors": [
      "Xu Yao",
      "Alasdair Newson",
      "Yann Gousseau",
      "Pierre Hellier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11895"
  },
  {
    "id": "arXiv:2106.11896",
    "title": "Distributed Beam Training for Intelligent Reflecting Surface Enabled  Multi-Hop Routing",
    "abstract": "Intelligent reflecting surface (IRS) is an emerging technology to enhance the\nspectral and energy efficiency of wireless communications cost-effectively.\nThis letter considers a new multi-IRS aided wireless network where a cascaded\nline-of-sight (LoS) link is established between the base station (BS) and a\nremote user by leveraging the multi-hop signal reflection of selected IRSs. As\ncompared to the conventional single-/double-hop IRS system, multi-hop IRS\nsystem provides more pronounced path diversity and cooperative passive\nbeamforming gains, especially in the environment with dense obstacles. However,\na more challenging joint active/passive beamforming and multi-hop beam routing\nproblem also arises for maximizing the end-to-end channel gain. Furthermore,\nthe number of IRS-associated channel coefficients increases drastically with\nthe number of IRS hops. To tackle the above issues, in this letter we propose a\nnew and efficient beam training based solution by considering the use of\npractical codebook-based BS/IRS active/passive beamforming without the need of\nexplicit channel estimation. Instead of exhaustively or sequentially searching\nover all combinations of active and passive beam patterns for each beam route,\na distributed beam training scheme is proposed to reduce the complexity, by\nexploiting the (nearly) time-invariant BS-IRS and inter-IRS channels and the\ncooperative training among the BS and IRSs' controllers. Simulation results\nshow that our proposed design achieves the end-to-end channel gain close to\nthat of the sequential beam search, but at a much lower training overhead and\ncomplexity.",
    "descriptor": "\nComments: 6 pages, 5 figures. Our other works on multi-IRS aided wireless network: IRS-user associations (arXiv:2009.02551), single-beam multi-hop routing (arXiv:2010.13589), and multi-beam multi-hop routing (arXiv:2101.00217)\n",
    "authors": [
      "Weidong Mei",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.11896"
  },
  {
    "id": "arXiv:2106.11897",
    "title": "MuseumViz -- Towards Visualizing Online Museum Collections",
    "abstract": "Despite the growth of online museums for India's cultural heritage data,\nthere is limited increase in terms of visitors. Over the years, online museums\nadopted many techniques to improve the overall user experience. However, many\nIndian online museums display artifacts as lists and grids with basic search\nfunctionality, making it less visually appealing and difficult to comprehend.\nOur work aims to enhance the user experience of accessing Indian online museums\nby utilizing advancements in information visualization. Hence, we propose\nMuseumViz, a framework which processes data from online museums and visualizes\nit using four different interactive visualizations: the Network Graph,\nTreepMap, Polygon Chart and SunBurst Chart. We demonstrate MuseumViz on a total\nof 723 cultural heritage artifacts present in the Archaeological Survey of\nIndia, Goa. Based on our evaluation with 25 users, about 83% of them find it\neasier and more comprehensible to browse cultural heritage artifacts through\nMuseumViz.",
    "descriptor": "\nComments: 8 pages, 3 figures, 1 Table\n",
    "authors": [
      "Dheeraj Vagavolu",
      "Akhila Sri Manasa Venigalla",
      "Sridhar Chimalakonda"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.11897"
  },
  {
    "id": "arXiv:2106.11899",
    "title": "Local policy search with Bayesian optimization",
    "abstract": "Reinforcement learning (RL) aims to find an optimal policy by interaction\nwith an environment. Consequently, learning complex behavior requires a vast\nnumber of samples, which can be prohibitive in practice. Nevertheless, instead\nof systematically reasoning and actively choosing informative samples, policy\ngradients for local search are often obtained from random perturbations. These\nrandom samples yield high variance estimates and hence are sub-optimal in terms\nof sample complexity. Actively selecting informative samples is at the core of\nBayesian optimization, which constructs a probabilistic surrogate of the\nobjective from past samples to reason about informative subsequent ones. In\nthis paper, we propose to join both worlds. We develop an algorithm utilizing a\nprobabilistic model of the objective function and its gradient. Based on the\nmodel, the algorithm decides where to query a noisy zeroth-order oracle to\nimprove the gradient estimates. The resulting algorithm is a novel type of\npolicy search method, which we compare to existing black-box algorithms. The\ncomparison reveals improved sample complexity and reduced variance in extensive\nempirical evaluations on synthetic objectives. Further, we highlight the\nbenefits of active sampling on popular RL benchmarks.",
    "descriptor": "",
    "authors": [
      "Sarah M\u00fcller",
      "Alexander von Rohr",
      "Sebastian Trimpe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11899"
  },
  {
    "id": "arXiv:2106.11900",
    "title": "Person Re-identification Attack on Wearable Sensing",
    "abstract": "Person re-identification is a critical privacy attack in publicly shared\nhealthcare data as per Health Insurance Portability and Accountability Act\n(HIPAA) privacy rule. In this paper, we investigate the possibility of a new\ntype of privacy attack, Person Re-identification Attack (PRI-attack) on\npublicly shared privacy insensitive wearable data. We investigate user's\nspecific biometric signature in terms of two contextual biometric traits,\nphysiological (photoplethysmography and electrodermal activity) and physical\n(accelerometer) contexts. In this regard, we develop a Multi-Modal Siamese\nConvolutional Neural Network (mmSNN) model. The framework learns the spatial\nand temporal information individually and combines them together in a modified\nweighted cost with an objective of predicting a person's identity. We evaluated\nour proposed model using real-time collected data from 3 collected datasets and\none publicly available dataset. Our proposed framework shows that PPG-based\nbreathing rate and heart rate in conjunction with hand gesture contexts can be\nutilized by attackers to re-identify user's identity (max. 71%) from HIPAA\ncompliant wearable data. Given publicly placed camera can estimate heart rate\nand breathing rate along with hand gestures remotely, person re-identification\nusing them imposes a significant threat to future HIPAA compliant server which\nrequires a better encryption method to store wearable healthcare data.",
    "descriptor": "",
    "authors": [
      "Mohammad Arif Ul Alam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.11900"
  },
  {
    "id": "arXiv:2106.11902",
    "title": "PALMAR: Towards Adaptive Multi-inhabitant Activity Recognition in  Point-Cloud Technology",
    "abstract": "With the advancement of deep neural networks and computer vision-based Human\nActivity Recognition, employment of Point-Cloud Data technologies (LiDAR,\nmmWave) has seen a lot interests due to its privacy preserving nature. Given\nthe high promise of accurate PCD technologies, we develop, PALMAR, a\nmultiple-inhabitant activity recognition system by employing efficient signal\nprocessing and novel machine learning techniques to track individual person\ntowards developing an adaptive multi-inhabitant tracking and HAR system. More\nspecifically, we propose (i) a voxelized feature representation-based real-time\nPCD fine-tuning method, (ii) efficient clustering (DBSCAN and BIRCH), Adaptive\nOrder Hidden Markov Model based multi-person tracking and crossover ambiguity\nreduction techniques and (iii) novel adaptive deep learning-based domain\nadaptation technique to improve the accuracy of HAR in presence of data\nscarcity and diversity (device, location and population diversity). We\nexperimentally evaluate our framework and systems using (i) a real-time PCD\ncollected by three devices (3D LiDAR and 79 GHz mmWave) from 6 participants,\n(ii) one publicly available 3D LiDAR activity data (28 participants) and (iii)\nan embedded hardware prototype system which provided promising HAR performances\nin multi-inhabitants (96%) scenario with a 63% improvement of multi-person\ntracking than state-of-art framework without losing significant system\nperformances in the edge computing device.",
    "descriptor": "\nComments: Accepted in IEEE International Conference on Computer Communications 2021\n",
    "authors": [
      "Mohammad Arif Ul Alam",
      "Md Mahmudur Rahman",
      "Jared Q Widberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11902"
  },
  {
    "id": "arXiv:2106.11904",
    "title": "Do practitioners intentionally self-fix Technical Debt and why?",
    "abstract": "The impact of Technical Debt (TD) on software maintenance and evolution is of\ngreat concern, but recent evidence shows that a considerable amount of TD is\nfixed by the same developers who introduced it; this is termed self-fixed TD.\nThis characteristic of TD management can potentially impact team dynamics and\npractices in managing TD. However, the initial evidence is based on low-level\nsource code analysis; this casts some doubt whether practitioners repay their\nown debt intentionally and under what circumstances. To address this gap, we\nconducted an online survey on 17 well-known Java and Python open-source\nsoftware communities to investigate practitioners' intent and rationale for\nself-fixing technical debt. We also investigate the relationship between\nhuman-related factors (e.g., experience) and self-fixing. The results, derived\nfrom the responses of 181 participants, show that a majority addresses their\nown debt consciously and often. Moreover, those with a higher level of\ninvolvement (e.g., more experience in the project and number of contributions)\ntend to be more concerned about self-fixing TD. We also learned that the sense\nof responsibility is a common self-fixing driver and that decisions to fix TD\nare not superficial but consider balancing costs and benefits, among other\nfactors. The findings in this paper can lead to improving TD prevention and\nmanagement strategies.",
    "descriptor": "\nComments: Proceedings of the 37th IEEE International Conference on Software Maintenance and Evolution (ICSME '21)\n",
    "authors": [
      "Jie Tan",
      "Daniel Feitosa",
      "Paris Avgeriou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.11904"
  },
  {
    "id": "arXiv:2106.11905",
    "title": "Dangers of Bayesian Model Averaging under Covariate Shift",
    "abstract": "Approximate Bayesian inference for neural networks is considered a robust\nalternative to standard training, often providing good performance on\nout-of-distribution data. However, Bayesian neural networks (BNNs) with\nhigh-fidelity approximate inference via full-batch Hamiltonian Monte Carlo\nachieve poor generalization under covariate shift, even underperforming\nclassical estimation. We explain this surprising result, showing how a Bayesian\nmodel average can in fact be problematic under covariate shift, particularly in\ncases where linear dependencies in the input features cause a lack of posterior\ncontraction. We additionally show why the same issue does not affect many\napproximate inference procedures, or classical maximum a-posteriori (MAP)\ntraining. Finally, we propose novel priors that improve the robustness of BNNs\nto many sources of covariate shift.",
    "descriptor": "",
    "authors": [
      "Pavel Izmailov",
      "Patrick Nicholson",
      "Sanae Lotfi",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11905"
  },
  {
    "id": "arXiv:2106.11907",
    "title": "Iso-geometric Integral Equation Solvers and their Compression via  Manifold Harmonics",
    "abstract": "The state of art of electromagnetic integral equations has seen significant\ngrowth over the past few decades, overcoming some of the fundamental\nbottlenecks: computational complexity, low frequency and dense discretization\nbreakdown, preconditioning, and so on. Likewise, the community has seen\nextensive investment in development of methods for higher order analysis, in\nboth geometry and physics. Unfortunately, these standard geometric descriptors\nare $C^0$ at the boundary between patches with a few exceptions; as a result,\none needs to define additional mathematical infrastructure to define physical\nbasis sets for vector problems. In stark contrast, the geometric representation\nused for design is higher-order differentiable over the entire surface.\nGeometric descriptions that have $C^{2}$-continuity almost everywhere on the\nsurfaces are common in computer graphics. Using these description for analysis\nopens the door to several possibilities, and is the area we explore in this\npaper. Our focus is on Loop subdivision based isogeometric methods. In this\npaper, our goals are two fold: (i) development of computational infrastructure\nnecessary to effect efficient methods for isogeometric analysis of electrically\nlarge simply connected objects, and (ii) to introduce the notion of manifold\nharmonics transforms and its utility in computational electromagnetics. Several\nresults highlighting the efficacy of these two methods are presented.",
    "descriptor": "",
    "authors": [
      "A. M. A. Alsnayyan",
      "B. Shanker"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.11907"
  },
  {
    "id": "arXiv:2106.11908",
    "title": "Deep Phasor Networks: Connecting Conventional and Spiking Neural  Networks",
    "abstract": "In this work, we extend standard neural networks by building upon an\nassumption that neuronal activations correspond to the angle of a complex\nnumber lying on the unit circle, or 'phasor.' Each layer in such a network\nproduces new activations by taking a weighted superposition of the previous\nlayer's phases and calculating the new phase value. This generalized\narchitecture allows models to reach high accuracy and carries the singular\nadvantage that mathematically equivalent versions of the network can be\nexecuted with or without regard to a temporal variable. Importantly, the value\nof a phase angle in the temporal domain can be sparsely represented by a\nperiodically repeating series of delta functions or 'spikes'. We demonstrate\nthe atemporal training of a phasor network on standard deep learning tasks and\nshow that these networks can then be executed in either the traditional\natemporal domain or spiking temporal domain with no conversion step needed.\nThis provides a novel basis for constructing deep networkswhich operate via\ntemporal, spike-based calculations suitable for neuromorphic computing\nhardware.",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Wilkie Olin-Ammentorp",
      "Maxim Bazhenov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11908"
  },
  {
    "id": "arXiv:2106.11911",
    "title": "Residual Networks as Flows of Velocity Fields for Diffeomorphic Time  Series Alignment",
    "abstract": "Non-linear (large) time warping is a challenging source of nuisance in\ntime-series analysis. In this paper, we propose a novel diffeomorphic temporal\ntransformer network for both pairwise and joint time-series alignment. Our\nResNet-TW (Deep Residual Network for Time Warping) tackles the alignment\nproblem by compositing a flow of incremental diffeomorphic mappings. Governed\nby the flow equation, our Residual Network (ResNet) builds smooth, fluid and\nregular flows of velocity fields and consequently generates smooth and\ninvertible transformations (i.e. diffeomorphic warping functions). Inspired by\nthe elegant Large Deformation Diffeomorphic Metric Mapping (LDDMM) framework,\nthe final transformation is built by the flow of time-dependent vector fields\nwhich are none other than the building blocks of our Residual Network. The\nlatter is naturally viewed as an Eulerian discretization schema of the flow\nequation (an ODE). Once trained, our ResNet-TW aligns unseen data by a single\ninexpensive forward pass. As we show in experiments on both univariate (84\ndatasets from UCR archive) and multivariate time-series (MSR Action-3D,\nFlorence-3D and MSR Daily Activity), ResNet-TW achieves competitive performance\nin joint alignment and classification.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Hao Huang",
      "Boulbaba Ben Amor",
      "Xichan Lin",
      "Fan Zhu",
      "Yi Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11911"
  },
  {
    "id": "arXiv:2106.11914",
    "title": "MONCAE: Multi-Objective Neuroevolution of Convolutional Autoencoders",
    "abstract": "In this paper, we present a novel neuroevolutionary method to identify the\narchitecture and hyperparameters of convolutional autoencoders. Remarkably, we\nused a hypervolume indicator in the context of neural architecture search for\nautoencoders, for the first time to our current knowledge. Results show that\nimages were compressed by a factor of more than 10, while still retaining\nenough information to achieve image classification for the majority of the\ntasks. Thus, this new approach can be used to speed up the AutoML pipeline for\nimage compression.",
    "descriptor": "\nComments: Published as a Poster paper in ICLR 2021 Neural Architecture Search workshop\n",
    "authors": [
      "Daniel Dimanov",
      "Emili Balaguer-Ballester",
      "Colin Singleton",
      "Shahin Rostami"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11914"
  },
  {
    "id": "arXiv:2106.11915",
    "title": "Enhanced Separable Disentanglement for Unsupervised Domain Adaptation",
    "abstract": "Domain adaptation aims to mitigate the domain gap when transferring knowledge\nfrom an existing labeled domain to a new domain. However, existing\ndisentanglement-based methods do not fully consider separation between\ndomain-invariant and domain-specific features, which means the domain-invariant\nfeatures are not discriminative. The reconstructed features are also not\nsufficiently used during training. In this paper, we propose a novel enhanced\nseparable disentanglement (ESD) model. We first employ a disentangler to\ndistill domain-invariant and domain-specific features. Then, we apply feature\nseparation enhancement processes to minimize contamination between\ndomain-invariant and domain-specific features. Finally, our model reconstructs\ncomplete feature vectors, which are used for further disentanglement during the\ntraining phase. Extensive experiments from three benchmark datasets outperform\nstate-of-the-art methods, especially on challenging cross-domain tasks.",
    "descriptor": "\nComments: ICIP 2021\n",
    "authors": [
      "Youshan Zhang",
      "Brian D. Davison"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11915"
  },
  {
    "id": "arXiv:2106.11916",
    "title": "Selecting Miners within Blockchain-based Systems Using Evolutionary  Algorithms for Energy Optimisation",
    "abstract": "In this paper, we represent the problem of selecting miners within a\nblockchain-based system as a subset selection problem. We formulate the problem\nof minimising blockchain energy consumption as an optimisation problem with two\nconflicting objectives: energy consumption and trust. The proposed model is\ncompared across different algorithms to demonstrate its performance.",
    "descriptor": "\nComments: To appear in 2021 Genetic and Evolutionary Computation Conference Companion (GECCO '21 Companion), July 10--14, 2021, Lille, France\n",
    "authors": [
      "Akram Alofi",
      "Mahmoud A. Bokhari",
      "Robert Hendley",
      "Rami Bahsoon"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.11916"
  },
  {
    "id": "arXiv:2106.11919",
    "title": "Speed Benchmarking of Genetic Programming Frameworks",
    "abstract": "Genetic Programming (GP) is known to suffer from the burden of being\ncomputationally expensive by design. While, over the years, many techniques\nhave been developed to mitigate this issue, data vectorization, in particular,\nis arguably still the most attractive strategy due to the parallel nature of\nGP. In this work, we employ a series of benchmarks meant to compare both the\nperformance and evolution capabilities of different vectorized and iterative\nimplementation approaches across several existing frameworks. Namely, TensorGP,\na novel open-source engine written in Python, is shown to greatly benefit from\nthe TensorFlow library to accelerate the domain evaluation phase in GP. The\npresented performance benchmarks demonstrate that the TensorGP engine manages\nto pull ahead, with relative speedups above two orders of magnitude for\nproblems with a higher number of fitness cases. Additionally, as a consequence\nof being able to compute larger domains, we argue that TensorGP performance\ngains aid the discovery of more accurate candidate solutions.",
    "descriptor": "",
    "authors": [
      "Francisco Baeta",
      "Jo\u00e3o Correia",
      "Tiago Martins",
      "Penousal Machado"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11919"
  },
  {
    "id": "arXiv:2106.11920",
    "title": "G-VAE, a Geometric Convolutional VAE for ProteinStructure Generation",
    "abstract": "Analyzing the structure of proteins is a key part of understanding their\nfunctions and thus their role in biology at the molecular level. In addition,\ndesign new proteins in a methodical way is a major engineering challenge. In\nthis work, we introduce a joint geometric-neural networks approach for\ncomparing, deforming and generating 3D protein structures. Viewing protein\nstructures as 3D open curves, we adopt the Square Root Velocity Function (SRVF)\nrepresentation and leverage its suitable geometric properties along with Deep\nResidual Networks (ResNets) for a joint registration and comparison. Our\nResNets handle better large protein deformations while being more\ncomputationally efficient. On top of the mathematical framework, we further\ndesign a Geometric Variational Auto-Encoder (G-VAE), that once trained, maps\noriginal, previously unseen structures, into a low-dimensional (latent)\nhyper-sphere. Motivated by the spherical structure of the pre-shape space, we\nnaturally adopt the von Mises-Fisher (vMF) distribution to model our hidden\nvariables. We test the effectiveness of our models by generating novel protein\nstructures and predicting completions of corrupted protein structures.\nExperimental results show that our method is able to generate plausible\nstructures, different from the structures in the training data.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Hao Huang",
      "Boulbaba Ben Amor",
      "Xichan Lin",
      "Fan Zhu",
      "Yi Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11920"
  },
  {
    "id": "arXiv:2106.11921",
    "title": "Towards Reducing Labeling Cost in Deep Object Detection",
    "abstract": "Deep neural networks have reached very high accuracy on object detection but\ntheir success hinges on large amounts of labeled data. To reduce the dependency\non labels, various active-learning strategies have been proposed, typically\nbased on the confidence of the detector. However, these methods are biased\ntowards best-performing classes and can lead to acquired datasets that are not\ngood representatives of the data in the testing set. In this work, we propose a\nunified framework for active learning, that considers both the uncertainty and\nthe robustness of the detector, ensuring that the network performs accurately\nin all classes. Furthermore, our method is able to pseudo-label the very\nconfident predictions, suppressing a potential distribution drift while further\nboosting the performance of the model. Experiments show that our method\ncomprehensively outperforms a wide range of active-learning methods on PASCAL\nVOC07+12 and MS-COCO, having up to a 7.7% relative improvement, or up to 82%\nreduction in labeling cost.",
    "descriptor": "\nComments: Includes supplementary material\n",
    "authors": [
      "Ismail Elezi",
      "Zhiding Yu",
      "Anima Anandkumar",
      "Laura Leal-Taixe",
      "Jose M. Alvarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11921"
  },
  {
    "id": "arXiv:2106.11927",
    "title": "Any equation is a forest: Symbolic genetic algorithm for discovering  open-form partial differential equations (SGA-PDE)",
    "abstract": "Partial differential equations (PDEs) are concise and understandable\nrepresentations of domain knowledge, which are essential for deepening our\nunderstanding of physical processes and predicting future responses. However,\nthe PDEs of many real-world problems are uncertain, which calls for PDE\ndiscovery. We propose the symbolic genetic algorithm (SGA-PDE) to discover\nopen-form PDEs directly from data without prior knowledge about the equation\nstructure. SGA-PDE focuses on the representation and optimization of PDE.\nFirstly, SGA-PDE uses symbolic mathematics to realize the flexible\nrepresentation of any given PDE, transforms a PDE into a forest, and converts\neach function term into a binary tree. Secondly, SGA-PDE adopts a specially\ndesigned genetic algorithm to efficiently optimize the binary trees by\niteratively updating the tree topology and node attributes. The SGA-PDE is\ngradient-free, which is a desirable characteristic in PDE discovery since it is\ndifficult to obtain the gradient between the PDE loss and the PDE structure. In\nthe experiment, SGA-PDE not only successfully discovered nonlinear Burgers'\nequation, Korteweg-de Vries (KdV) equation, and Chafee-Infante equation, but\nalso handled PDEs with fractional structure and compound functions that cannot\nbe solved by conventional PDE discovery methods.",
    "descriptor": "\nComments: 24 pages, 16 figures\n",
    "authors": [
      "Yuntian Chen",
      "Yingtao Luo",
      "Qiang Liu",
      "Hao Xu",
      "Dongxiao Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.11927"
  },
  {
    "id": "arXiv:2106.11929",
    "title": "Physics-Informed Deep Reversible Regression Model for Temperature Field  Reconstruction of Heat-Source Systems",
    "abstract": "Temperature monitoring during the life time of heat-source components in\nengineering systems becomes essential to ensure the normal work and even the\nlong working life of the heat sources. However, prior methods, which mainly use\nthe interpolate estimation, require large amounts of temperature tensors for an\naccurate estimation. To solve this problem, this work develops a novel\nphysics-informed deep surrogate models for temperature field reconstruction.\nFirst, we defines the temperature field reconstruction task of heat-source\nsystems. Then, this work develops the deep surrogate model mapping for the\nproposed task. Finally, considering the physical properties of heat transfer,\nthis work proposes four different losses and joint learns the deep surrogate\nmodel with these losses. Experimental studies have conducted over typical\ntwo-dimensional heat-source systems to demonstrate the effectiveness and\nefficiency of the proposed physics-informed deep surrogate models for\ntemperature field reconstruction.",
    "descriptor": "",
    "authors": [
      "Zhiqiang Gong",
      "Weien Zhou",
      "Jun Zhang",
      "Wei Peng",
      "Wen Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11929"
  },
  {
    "id": "arXiv:2106.11930",
    "title": "On the importance of cross-task features for class-incremental learning",
    "abstract": "In class-incremental learning, an agent with limited resources needs to learn\na sequence of classification tasks, forming an ever growing classification\nproblem, with the constraint of not being able to access data from previous\ntasks. The main difference with task-incremental learning, where a task-ID is\navailable at inference time, is that the learner also needs to perform\ncross-task discrimination, i.e. distinguish between classes that have not been\nseen together. Approaches to tackle this problem are numerous and mostly make\nuse of an external memory (buffer) of non-negligible size. In this paper, we\nablate the learning of cross-task features and study its influence on the\nperformance of basic replay strategies used for class-IL. We also define a new\nforgetting measure for class-incremental learning, and see that forgetting is\nnot the principal cause of low performance. Our experimental results show that\nfuture algorithms for class-incremental learning should not only prevent\nforgetting, but also aim to improve the quality of the cross-task features.\nThis is especially important when the number of classes per task is small.",
    "descriptor": "\nComments: includes supplementary material\n",
    "authors": [
      "Albin Soutif--Cormerais",
      "Marc Masana",
      "Joost Van de Weijer",
      "Bart\u0142omiej Twardowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11930"
  },
  {
    "id": "arXiv:2106.11935",
    "title": "Provably Efficient Representation Learning in Low-rank Markov Decision  Processes",
    "abstract": "The success of deep reinforcement learning (DRL) is due to the power of\nlearning a representation that is suitable for the underlying exploration and\nexploitation task. However, existing provable reinforcement learning algorithms\nwith linear function approximation often assume the feature representation is\nknown and fixed. In order to understand how representation learning can improve\nthe efficiency of RL, we study representation learning for a class of low-rank\nMarkov Decision Processes (MDPs) where the transition kernel can be represented\nin a bilinear form. We propose a provably efficient algorithm called ReLEX that\ncan simultaneously learn the representation and perform exploration. We show\nthat ReLEX always performs no worse than a state-of-the-art algorithm without\nrepresentation learning, and will be strictly better in terms of sample\nefficiency if the function class of representations enjoys a certain mild\n\"coverage'' property over the whole state-action space.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Weitong Zhang",
      "Jiafan He",
      "Dongruo Zhou",
      "Amy Zhang",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11935"
  },
  {
    "id": "arXiv:2106.11938",
    "title": "Robust Regression Revisited: Acceleration and Improved Estimation Rates",
    "abstract": "We study fast algorithms for statistical regression problems under the strong\ncontamination model, where the goal is to approximately optimize a generalized\nlinear model (GLM) given adversarially corrupted samples. Prior works in this\nline of research were based on the robust gradient descent framework of Prasad\net. al., a first-order method using biased gradient queries, or the Sever\nframework of Diakonikolas et. al., an iterative outlier-removal method calling\na stationary point finder.\nWe present nearly-linear time algorithms for robust regression problems with\nimproved runtime or estimation guarantees compared to the state-of-the-art. For\nthe general case of smooth GLMs (e.g. logistic regression), we show that the\nrobust gradient descent framework of Prasad et. al. can be accelerated, and\nshow our algorithm extends to optimizing the Moreau envelopes of Lipschitz GLMs\n(e.g. support vector machines), answering several open questions in the\nliterature.\nFor the well-studied case of robust linear regression, we present an\nalternative approach obtaining improved estimation rates over prior\nnearly-linear time algorithms. Interestingly, our method starts with an\nidentifiability proof introduced in the context of the sum-of-squares algorithm\nof Bakshi and Prasad, which achieved optimal error rates while requiring large\npolynomial runtime and sample complexity. We reinterpret their proof within the\nSever framework and obtain a dramatically faster and more sample-efficient\nalgorithm under fewer distributional assumptions.",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Arun Jambulapati",
      "Jerry Li",
      "Tselil Schramm",
      "Kevin Tian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11938"
  },
  {
    "id": "arXiv:2106.11942",
    "title": "RootPainter3D: Interactive-machine-learning enables rapid and accurate  contouring for radiotherapy",
    "abstract": "Organ-at-risk contouring is still a bottleneck in radiotherapy, with many\ndeep learning methods falling short of promised results when evaluated on\nclinical data. We investigate the accuracy and time-savings resulting from the\nuse of an interactive-machine-learning method for an organ-at-risk contouring\ntask. We compare the method to the Eclipse contouring software and find strong\nagreement with manual delineations, with a dice score of 0.95. The annotations\ncreated using corrective-annotation also take less time to create as more\nimages are annotated, resulting in substantial time savings compared to manual\nmethods, with hearts that take 2 minutes and 2 seconds to delineate on average,\nafter 923 images have been delineated, compared to 7 minutes and 1 seconds when\ndelineating manually. Our experiment demonstrates that\ninteractive-machine-learning with corrective-annotation provides a fast and\naccessible way for non computer-scientists to train deep-learning models to\nsegment their own structures of interest as part of routine clinical workflows.\nSource code is available at\n\\href{https://github.com/Abe404/RootPainter3D}{this HTTPS URL}.",
    "descriptor": "",
    "authors": [
      "Abraham George Smith",
      "Jens Petersen",
      "Cynthia Terrones-Campos",
      "Anne Kiil Berthelsen",
      "Nora Jarrett Forbes",
      "Sune Darkner",
      "Lena Specht",
      "Ivan Richter Vogelius"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11942"
  },
  {
    "id": "arXiv:2106.11943",
    "title": "Reusing Combinatorial Structure: Faster Iterative Projections over  Submodular Base Polytopes",
    "abstract": "Optimization algorithms such as projected Newton's method, FISTA, mirror\ndescent and its variants enjoy near-optimal regret bounds and convergence\nrates, but suffer from a computational bottleneck of computing \"projections''\nin potentially each iteration (e.g., $O(T^{1/2})$ regret of online mirror\ndescent). On the other hand, conditional gradient variants solve a linear\noptimization in each iteration, but result in suboptimal rates (e.g.,\n$O(T^{3/4})$ regret of online Frank-Wolfe). Motivated by this trade-off in\nruntime v/s convergence rates, we consider iterative projections of close-by\npoints over widely-prevalent submodular base polytopes $B(f)$. We develop a\ntoolkit to speed up the computation of projections using both discrete and\ncontinuous perspectives. We subsequently adapt the away-step Frank-Wolfe\nalgorithm to use this information and enable early termination. For the special\ncase of cardinality based submodular polytopes, we improve the runtime of\ncomputing certain Bregman projections by a factor of $\\Omega(n/\\log(n))$. Our\ntheoretical results show orders of magnitude reduction in runtime in\npreliminary computational experiments.",
    "descriptor": "",
    "authors": [
      "Jai Moondra",
      "Hassan Mortagy",
      "Swati Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.11943"
  },
  {
    "id": "arXiv:2106.11944",
    "title": "MetaAvatar: Learning Animatable Clothed Human Models from Few Depth  Images",
    "abstract": "In this paper, we aim to create generalizable and controllable neural signed\ndistance fields (SDFs) that represent clothed humans from monocular depth\nobservations. Recent advances in deep learning, especially neural implicit\nrepresentations, have enabled human shape reconstruction and controllable\navatar generation from different sensor inputs. However, to generate realistic\ncloth deformations from novel input poses, watertight meshes or dense full-body\nscans are usually needed as inputs. Furthermore, due to the difficulty of\neffectively modeling pose-dependent cloth deformations for diverse body shapes\nand cloth types, existing approaches resort to per-subject/cloth-type\noptimization from scratch, which is computationally expensive. In contrast, we\npropose an approach that can quickly generate realistic clothed human avatars,\nrepresented as controllable neural SDFs, given only monocular depth images. We\nachieve this by using meta-learning to learn an initialization of a\nhypernetwork that predicts the parameters of neural SDFs. The hypernetwork is\nconditioned on human poses and represents a clothed neural avatar that deforms\nnon-rigidly according to the input poses. Meanwhile, it is meta-learned to\neffectively incorporate priors of diverse body shapes and cloth types and thus\ncan be much faster to fine-tune, compared to models trained from scratch. We\nqualitatively and quantitatively show that our approach outperforms\nstate-of-the-art approaches that require complete meshes as inputs while our\napproach requires only depth frames as inputs and runs orders of magnitudes\nfaster. Furthermore, we demonstrate that our meta-learned hypernetwork is very\nrobust, being the first to generate avatars with realistic dynamic cloth\ndeformations given as few as 8 monocular depth frames.",
    "descriptor": "\nComments: 17 pages, 9 figures. Project page: this https URL\n",
    "authors": [
      "Shaofei Wang",
      "Marko Mihajlovic",
      "Qianli Ma",
      "Andreas Geiger",
      "Siyu Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11944"
  },
  {
    "id": "arXiv:2106.11952",
    "title": "Unsupervised Object-Level Representation Learning from Scene Images",
    "abstract": "Contrastive self-supervised learning has largely narrowed the gap to\nsupervised pre-training on ImageNet. However, its success highly relies on the\nobject-centric priors of ImageNet, i.e., different augmented views of the same\nimage correspond to the same object. Such a heavily curated constraint becomes\nimmediately infeasible when pre-trained on more complex scene images with many\nobjects. To overcome this limitation, we introduce Object-level Representation\nLearning (ORL), a new self-supervised learning framework towards scene images.\nOur key insight is to leverage image-level self-supervised pre-training as the\nprior to discover object-level semantic correspondence, thus realizing\nobject-level representation learning from scene images. Extensive experiments\non COCO show that ORL significantly improves the performance of self-supervised\nlearning on scene images, even surpassing supervised ImageNet pre-training on\nseveral downstream tasks. Furthermore, ORL improves the downstream performance\nwhen more unlabeled scene images are available, demonstrating its great\npotential of harnessing unlabeled data in the wild. We hope our approach can\nmotivate future research on more general-purpose unsupervised representation\nlearning from scene data. Project page: https://www.mmlab-ntu.com/project/orl/.",
    "descriptor": "",
    "authors": [
      "Jiahao Xie",
      "Xiaohang Zhan",
      "Ziwei Liu",
      "Yew Soon Ong",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11952"
  },
  {
    "id": "arXiv:2106.11958",
    "title": "Prototypical Cross-Attention Networks for Multiple Object Tracking and  Segmentation",
    "abstract": "Multiple object tracking and segmentation requires detecting, tracking, and\nsegmenting objects belonging to a set of given classes. Most approaches only\nexploit the temporal dimension to address the association problem, while\nrelying on single frame predictions for the segmentation mask itself. We\npropose Prototypical Cross-Attention Network (PCAN), capable of leveraging rich\nspatio-temporal information for online multiple object tracking and\nsegmentation. PCAN first distills a space-time memory into a set of prototypes\nand then employs cross-attention to retrieve rich information from the past\nframes. To segment each object, PCAN adopts a prototypical appearance module to\nlearn a set of contrastive foreground and background prototypes, which are then\npropagated over time. Extensive experiments demonstrate that PCAN outperforms\ncurrent video instance tracking and segmentation competition winners on both\nYoutube-VIS and BDD100K datasets, and shows efficacy to both one-stage and\ntwo-stage segmentation frameworks. Code will be available at\nthis http URL",
    "descriptor": "\nComments: Multiple object tracking and segmentation on large-scale datasets\n",
    "authors": [
      "Lei Ke",
      "Xia Li",
      "Martin Danelljan",
      "Yu-Wing Tai",
      "Chi-Keung Tang",
      "Fisher Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11958"
  },
  {
    "id": "arXiv:2106.11959",
    "title": "Revisiting Deep Learning Models for Tabular Data",
    "abstract": "The necessity of deep learning for tabular data is still an unanswered\nquestion addressed by a large number of research efforts. The recent literature\non tabular DL proposes several deep architectures reported to be superior to\ntraditional \"shallow\" models like Gradient Boosted Decision Trees. However,\nsince existing works often use different benchmarks and tuning protocols, it is\nunclear if the proposed models universally outperform GBDT. Moreover, the\nmodels are often not compared to each other, therefore, it is challenging to\nidentify the best deep model for practitioners.\nIn this work, we start from a thorough review of the main families of DL\nmodels recently developed for tabular data. We carefully tune and evaluate them\non a wide range of datasets and reveal two significant findings. First, we show\nthat the choice between GBDT and DL models highly depends on data and there is\nstill no universally superior solution. Second, we demonstrate that a simple\nResNet-like architecture is a surprisingly effective baseline, which\noutperforms most of the sophisticated models from the DL literature. Finally,\nwe design a simple adaptation of the Transformer architecture for tabular data\nthat becomes a new strong DL baseline and reduces the gap between GBDT and DL\nmodels on datasets where GBDT dominates.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Yury Gorishniy",
      "Ivan Rubachev",
      "Valentin Khrulkov",
      "Artem Babenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11959"
  },
  {
    "id": "arXiv:2106.11960",
    "title": "Variance-Aware Off-Policy Evaluation with Linear Function Approximation",
    "abstract": "We study the off-policy evaluation (OPE) problem in reinforcement learning\nwith linear function approximation, which aims to estimate the value function\nof a target policy based on the offline data collected by a behavior policy. We\npropose to incorporate the variance information of the value function to\nimprove the sample efficiency of OPE. More specifically, for time-inhomogeneous\nepisodic linear Markov decision processes (MDPs), we propose an algorithm,\nVA-OPE, which uses the estimated variance of the value function to reweight the\nBellman residual in Fitted Q-Iteration. We show that our algorithm achieves a\ntighter error bound than the best-known result. We also provide a fine-grained\ncharacterization of the distribution shift between the behavior policy and the\ntarget policy. Extensive numerical experiments corroborate our theory.",
    "descriptor": "\nComments: 70 pages, 4 figures\n",
    "authors": [
      "Yifei Min",
      "Tianhao Wang",
      "Dongruo Zhou",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11960"
  },
  {
    "id": "arXiv:2106.11962",
    "title": "Analysis of Executional and Procedural Errors in Dry-lab Robotic Surgery  Experiments",
    "abstract": "Background We aim to develop a method for automated detection of potentially\nerroneous motions that lead to sub-optimal surgeon performance and\nsafety-critical events in robot-assisted surgery.\nMethods We develop a rubric for identifying task and gesture-specific\nExecutional and Procedural errors and evaluate dry-lab demonstrations of\nSuturing and Needle Passing tasks from the JIGSAWS dataset. We characterize\nerroneous parts of demonstrations by labeling video data, and use distribution\nsimilarity analysis and trajectory averaging on kinematic data to identify\nparameters that distinguish erroneous gestures.\nResults Executional error frequency varies by task and gesture and correlates\nwith skill level. Some predominant error modes in each gesture are\ndistinguishable by analyzing error-specific kinematic parameters. Procedural\nerrors could lead to lower performance scores and increased demonstration times\nbut also depend on surgical style.\nConclusions This study provides preliminary evidence that automated error\ndetection can provide context-dependent and quantitative feedback to surgical\ntrainees for performance improvement.",
    "descriptor": "\nComments: 18 pages, 14 figures, 6 tables. Submitted to The International Journal of Medical Robotics and Computer Assisted Surgery (IJMRCAS). Supplementary video files are available at this https URL\n",
    "authors": [
      "Kay Hutchinson",
      "Zongyu Li",
      "Leigh A. Cantrell",
      "Noah S. Schenkman",
      "Homa Alemzadeh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11962"
  },
  {
    "id": "arXiv:2106.11963",
    "title": "Tracking Instances as Queries",
    "abstract": "Recently, query based deep networks catch lots of attention owing to their\nend-to-end pipeline and competitive results on several fundamental computer\nvision tasks, such as object detection, semantic segmentation, and instance\nsegmentation. However, how to establish a query based video instance\nsegmentation (VIS) framework with elegant architecture and strong performance\nremains to be settled. In this paper, we present \\textbf{QueryTrack} (i.e.,\ntracking instances as queries), a unified query based VIS framework fully\nleveraging the intrinsic one-to-one correspondence between instances and\nqueries in QueryInst. The proposed method obtains 52.7 / 52.3 AP on\nYouTube-VIS-2019 / 2021 datasets, which wins the 2-nd place in the YouTube-VIS\nChallenge at CVPR 2021 \\textbf{with a single online end-to-end model, single\nscale testing \\& modest amount of training data}. We also provide\nQueryTrack-ResNet-50 baseline results on YouTube-VIS-2021 dataset as references\nfor the VIS community.",
    "descriptor": "\nComments: Preprint. Work in progress\n",
    "authors": [
      "Shusheng Yang",
      "Yuxin Fang",
      "Xinggang Wang",
      "Yu Li",
      "Ying Shan",
      "Bin Feng",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.11963"
  },
  {
    "id": "arXiv:2106.10697",
    "title": "Distributed strategy-updating rules for aggregative games of  multi-integrator systems with coupled constraints",
    "abstract": "In this paper, we explore aggregative games over networks of multi-integrator\nagents with coupled constraints. To reach the general Nash equilibrium of an\naggregative game, a distributed strategy-updating rule is proposed by a\ncombination of the coordination of Lagrange multipliers and the estimation of\nthe aggregator. Each player has only access to partial-decision information and\ncommunicates with his neighbors in a weight-balanced digraph which\ncharacterizes players' preferences as to the values of information received\nfrom neighbors. We first consider networks of double-integrator agents and then\nfocus on multi-integrator agents. The effectiveness of the proposed\nstrategy-updating rules is demonstrated by analyzing the convergence of\ncorresponding dynamical systems via the Lyapunov stability theory, singular\nperturbation theory and passive theory. Numerical examples are given to\nillustrate our results.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Xin Cai",
      "Feng Xiao",
      "Bo Wei"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10697"
  },
  {
    "id": "arXiv:2106.11170",
    "title": "Transformer-based Spatial-Temporal Feature Learning for EEG Decoding",
    "abstract": "At present, people usually use some methods based on convolutional neural\nnetworks (CNNs) for Electroencephalograph (EEG) decoding. However, CNNs have\nlimitations in perceiving global dependencies, which is not adequate for common\nEEG paradigms with a strong overall relationship. Regarding this issue, we\npropose a novel EEG decoding method that mainly relies on the attention\nmechanism. The EEG data is firstly preprocessed and spatially filtered. And\nthen, we apply attention transforming on the feature-channel dimension so that\nthe model can enhance more relevant spatial features. The most crucial step is\nto slice the data in the time dimension for attention transforming, and finally\nobtain a highly distinguishable representation. At this time, global averaging\npooling and a simple fully-connected layer are used to classify different\ncategories of EEG data. Experiments on two public datasets indicate that the\nstrategy of attention transforming effectively utilizes spatial and temporal\nfeatures. And we have reached the level of the state-of-the-art in\nmulti-classification of EEG, with fewer parameters. As far as we know, it is\nthe first time that a detailed and complete method based on the transformer\nidea has been proposed in this field. It has good potential to promote the\npracticality of brain-computer interface (BCI). The source code can be found\nat: \\textit{https://github.com/anranknight/EEG-Transformer}.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Yonghao Song",
      "Xueyu Jia",
      "Lie Yang",
      "Longhan Xie"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11170"
  },
  {
    "id": "arXiv:2106.11200",
    "title": "Impossibility of composable Oblivious Transfer in relativistic quantum  cryptography",
    "abstract": "We study the cryptographic primitive Oblivious Transfer; a composable\nconstruction of this resource would allow arbitrary multi-party computation to\nbe carried out in a secure way, i.e. to compute functions in a distributed way\nwhile keeping inputs from different parties private. First we review a\nframework that allows us to analyze composability of classical and quantum\ncryptographic protocols in special relativity: Abstract Cryptography\nimplemented with Causal Boxes. We then (1) explore and formalize different\nversions of oblivious transfer found in the literature, (2) prove that their\nequivalence holds also in relativistic quantum settings, (3) show that it is\nimpossible to composably construct any of these versions of oblivious transfer\nfrom only classical or quantum communication among distrusting agents in\nrelativistic settings, (4) prove that the impossibility also extends to\nmulti-party computation, and (5) provide a mutual construction between\noblivious transfer and bit commitment.",
    "descriptor": "\nComments: 13+11 pages, many figures\n",
    "authors": [
      "Lorenzo Laneve",
      "Lidia del Rio"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.11200"
  },
  {
    "id": "arXiv:2106.11322",
    "title": "Image simulation for space applications with the SurRender software",
    "abstract": "Image Processing algorithms for vision-based navigation require reliable\nimage simulation capacities. In this paper we explain why traditional rendering\nengines may present limitations that are potentially critical for space\napplications. We introduce Airbus SurRender software v7 and provide details on\nfeatures that make it a very powerful space image simulator. We show how\nSurRender is at the heart of the development processes of our computer vision\nsolutions and we provide a series of illustrations of rendered images for\nvarious use cases ranging from Moon and Solar System exploration, to in orbit\nrendezvous and planetary robotics.",
    "descriptor": "\nComments: 11th International ESA Conference on Guidance, Navigation & Control Systems, 22 - 25 June 2021 16 pages, 8 figures\n",
    "authors": [
      "J\u00e9r\u00e9my Lebreton",
      "Roland Brochard",
      "Matthieu Baudry",
      "Gr\u00e9gory Jonniaux",
      "Adrien Hadj Salah",
      "Keyvan Kanani",
      "Matthieu Le Goff",
      "Aurore Masson",
      "Nicolas Ollagnier",
      "Paolo Panicucci",
      "Amsha Proag",
      "Cyril Robin"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11322"
  },
  {
    "id": "arXiv:2106.11330",
    "title": "Context-aware PolyUNet for Liver and Lesion Segmentation from Abdominal  CT Images",
    "abstract": "Accurate liver and lesion segmentation from computed tomography (CT) images\nare highly demanded in clinical practice for assisting the diagnosis and\nassessment of hepatic tumor disease. However, automatic liver and lesion\nsegmentation from contrast-enhanced CT volumes is extremely challenging due to\nthe diversity in contrast, resolution, and quality of images. Previous methods\nbased on UNet for 2D slice-by-slice or 3D volume-by-volume segmentation either\nlack sufficient spatial contexts or suffer from high GPU computational cost,\nwhich limits the performance. To tackle these issues, we propose a novel\ncontext-aware PolyUNet for accurate liver and lesion segmentation. It jointly\nexplores structural diversity and consecutive t-adjacent slices to enrich\nfeature expressive power and spatial contextual information while avoiding the\noverload of GPU memory consumption. In addition, we utilize zoom out/in and\ntwo-stage refinement strategy to exclude the irrelevant contexts and focus on\nthe specific region for the fine-grained segmentation. Our method achieved very\ncompetitive performance at the MICCAI 2017 Liver Tumor Segmentation (LiTS)\nChallenge among all tasks with a single model and ranked the $3^{rd}$,\n$12^{th}$, $2^{nd}$, and $5^{th}$ places in the liver segmentation, lesion\nsegmentation, lesion detection, and tumor burden estimation, respectively.",
    "descriptor": "\nComments: 7 pages and 3 figures\n",
    "authors": [
      "Liping Zhang",
      "Simon Chun-Ho Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11330"
  },
  {
    "id": "arXiv:2106.11368",
    "title": "Reinforcement Learning for Resource Allocation in Steerable Laser-based  Optical Wireless Systems",
    "abstract": "Vertical Cavity Surface Emitting Lasers (VCSELs) have demonstrated\nsuitability for data transmission in indoor optical wireless communication\n(OWC) systems due to the high modulation bandwidth and low manufacturing cost\nof these sources. Specifically, resource allocation is one of the major\nchallenges that can affect the performance of multi-user optical wireless\nsystems. In this paper, an optimisation problem is formulated to optimally\nassign each user to an optical access point (AP) composed of multiple VCSELs\nwithin a VCSEL array at a certain time to maximise the signal to interference\nplus noise ratio (SINR). In this context, a mixed-integer linear programming\n(MILP) model is introduced to solve this optimisation problem. Despite the\noptimality of the MILP model, it is considered impractical due to its high\ncomplexity, high memory and full system information requirements. Therefore,\nreinforcement Learning (RL) is considered, which recently has been widely\ninvestigated as a practical solution for various optimization problems in\ncellular networks due to its ability to interact with environments with no\nprevious experience. In particular, a Q-learning (QL) algorithm is investigated\nto perform resource management in a steerable VCSEL-based OWC systems. The\nresults demonstrate the ability of the QL algorithm to achieve optimal\nsolutions close to the MILP model. Moreover, the adoption of beam steering,\nusing holograms implemented by exploiting liquid crystal devices, results in\nfurther enhancement in the performance of the network considered.",
    "descriptor": "",
    "authors": [
      "Abdelrahman S. Elgamal",
      "Osama Z. Alsulami",
      "Ahmad Adnan Qidan",
      "Taisir E.H. El-Gorashi",
      "Jaafar M. H. Elmirghani"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.11368"
  },
  {
    "id": "arXiv:2106.11374",
    "title": "Tensor Learning-based Precoder Codebooks for FD-MIMO Systems",
    "abstract": "This paper develops an efficient procedure for designing low-complexity\ncodebooks for precoding in a full-dimension (FD) multiple-input multiple-output\n(MIMO) system with a uniform planar array (UPA) antenna at the transmitter (Tx)\nusing tensor learning. In particular, instead of using statistical channel\nmodels, we utilize a model-free data-driven approach with foundations in\nmachine learning to generate codebooks that adapt to the surrounding\npropagation conditions. We use a tensor representation of the FD-MIMO channel\nand exploit its properties to design quantized version of the channel\nprecoders. We find the best representation of the optimal precoder as a\nfunction of Kronecker Product (KP) of two low-dimensional precoders,\nrespectively corresponding to the horizontal and vertical dimensions of the\nUPA, obtained from the tensor decomposition of the channel. We then quantize\nthis precoder to design product codebooks such that an average loss in mutual\ninformation due to quantization of channel state information (CSI) is\nminimized. The key technical contribution lies in exploiting the constraints on\nthe precoders to reduce the product codebook design problem to an unsupervised\nclustering problem on a Cartesian Product Grassmann manifold (CPM), where the\ncluster centroids form a finite-sized precoder codebook. This codebook can be\nfound efficiently by running a $K$-means clustering on the CPM. With a suitable\ninduced distance metric on the CPM, we show that the construction of product\ncodebooks is equivalent to finding the optimal set of centroids on the factor\nmanifolds corresponding to the horizontal and vertical dimensions. Simulation\nresults are presented to demonstrate the capability of the proposed design\ncriterion in learning the codebooks and the attractive performance of the\ndesigned codebooks.",
    "descriptor": "\nComments: 30 pages, 8 figures\n",
    "authors": [
      "Keerthana Bhogi",
      "Chiranjib Saha",
      "Harpreet S. Dhillon"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11374"
  },
  {
    "id": "arXiv:2106.11396",
    "title": "BiAdam: Fast Adaptive Bilevel Optimization Methods",
    "abstract": "Bilevel optimization recently has attracted increased interest in machine\nlearning due to its many applications such as hyper-parameter optimization and\npolicy optimization. Although some methods recently have been proposed to solve\nthe bilevel problems, these methods do not consider using adaptive learning\nrates. To fill this gap, in the paper, we propose a class of fast and effective\nadaptive methods for solving bilevel optimization problems that the outer\nproblem is possibly nonconvex and the inner problem is strongly-convex.\nSpecifically, we propose a fast single-loop BiAdam algorithm based on the basic\nmomentum technique, which achieves a sample complexity of\n$\\tilde{O}(\\epsilon^{-4})$ for finding an $\\epsilon$-stationary point. At the\nsame time, we propose an accelerated version of BiAdam algorithm (VR-BiAdam) by\nusing variance reduced technique, which reaches the best known sample\ncomplexity of $\\tilde{O}(\\epsilon^{-3})$. To further reduce computation in\nestimating derivatives, we propose a fast single-loop stochastic approximated\nBiAdam algorithm (saBiAdam) by avoiding the Hessian inverse, which still\nachieves a sample complexity of $\\tilde{O}(\\epsilon^{-4})$ without large\nbatches. We further present an accelerated version of saBiAdam algorithm\n(VR-saBiAdam), which also reaches the best known sample complexity of\n$\\tilde{O}(\\epsilon^{-3})$. We apply the unified adaptive matrices to our\nmethods as the SUPER-ADAM \\citep{huang2021super}, which including many types of\nadaptive learning rates. Moreover, our framework can flexibly use the momentum\nand variance reduced techniques. In particular, we provide a useful convergence\nanalysis framework for both the constrained and unconstrained bilevel\noptimization. To the best of our knowledge, we first study the adaptive bilevel\noptimization methods with adaptive learning rates.",
    "descriptor": "\nComments: 20 pages, 2 tables\n",
    "authors": [
      "Feihu Huang",
      "Heng Huang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11396"
  },
  {
    "id": "arXiv:2106.11408",
    "title": "Decentralized Constrained Optimization: Double Averaging and Gradient  Projection",
    "abstract": "In this paper, we consider the convex, finite-sum minimization problem with\nexplicit convex constraints over strongly connected directed graphs. The\nconstraint is an intersection of several convex sets each being known to only\none node. To solve this problem, we propose a novel decentralized projected\ngradient scheme based on local averaging and prove its convergence using only\nlocal functions' smoothness.",
    "descriptor": "",
    "authors": [
      "Firooz Shahriari-Mehr",
      "David Bosch",
      "Ashkan Panahi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.11408"
  },
  {
    "id": "arXiv:2106.11428",
    "title": "Local convexity of the TAP free energy and AMP convergence for  Z2-synchronization",
    "abstract": "We study mean-field variational Bayesian inference using the TAP approach,\nfor Z2-synchronization as a prototypical example of a high-dimensional Bayesian\nmodel. We show that for any signal strength $\\lambda > 1$ (the weak-recovery\nthreshold), there exists a unique local minimizer of the TAP free energy\nfunctional near the mean of the Bayes posterior law. Furthermore, the TAP free\nenergy in a local neighborhood of this minimizer is strongly convex.\nConsequently, a natural-gradient/mirror-descent algorithm achieves linear\nconvergence to this minimizer from a local initialization, which may be\nobtained by a finite number of iterates of Approximate Message Passing (AMP).\nThis provides a rigorous foundation for variational inference in high\ndimensions via minimization of the TAP free energy.\nWe also analyze the finite-sample convergence of AMP, showing that AMP is\nasymptotically stable at the TAP minimizer for any $\\lambda > 1$, and is\nlinearly convergent to this minimizer from a spectral initialization for\nsufficiently large $\\lambda$. Such a guarantee is stronger than results\nobtainable by state evolution analyses, which only describe a fixed number of\nAMP iterations in the infinite-sample limit.\nOur proofs combine the Kac-Rice formula and Sudakov-Fernique Gaussian\ncomparison inequality to analyze the complexity of critical points that satisfy\nstrong convexity and stability conditions within their local neighborhoods.",
    "descriptor": "\nComments: 56 pages\n",
    "authors": [
      "Michael Celentano",
      "Zhou Fan",
      "Song Mei"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.11428"
  },
  {
    "id": "arXiv:2106.11446",
    "title": "Bitcoin's Crypto Flow Newtork",
    "abstract": "How crypto flows among Bitcoin users is an important question for\nunderstanding the structure and dynamics of the cryptoasset at a global scale.\nWe compiled all the blockchain data of Bitcoin from its genesis to the year\n2020, identified users from anonymous addresses of wallets, and constructed\nmonthly snapshots of networks by focusing on regular users as big players. We\napply the methods of bow-tie structure and Hodge decomposition in order to\nlocate the users in the upstream, downstream, and core of the entire crypto\nflow. Additionally, we reveal principal components hidden in the flow by using\nnon-negative matrix factorization, which we interpret as a probabilistic model.\nWe show that the model is equivalent to a probabilistic latent semantic\nanalysis in natural language processing, enabling us to estimate the number of\nsuch hidden components. Moreover, we find that the bow-tie structure and the\nprincipal components are quite stable among those big players. This study can\nbe a solid basis on which one can further investigate the temporal change of\ncrypto flow, entry and exit of big players, and so forth.",
    "descriptor": "\nComments: 39 pages, 18 Figures; \"Blockchain in Kyoto 2021\" conference; forthcoming in JPS Conference Proceedings\n",
    "authors": [
      "Yoshi Fujiwara",
      "Rubaiyat Islam"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.11446"
  },
  {
    "id": "arXiv:2106.11447",
    "title": "Encoder-Decoder Architectures for Clinically Relevant Coronary Artery  Segmentation",
    "abstract": "Coronary X-ray angiography is a crucial clinical procedure for the diagnosis\nand treatment of coronary artery disease, which accounts for roughly 16% of\nglobal deaths every year. However, the images acquired in these procedures have\nlow resolution and poor contrast, making lesion detection and assessment\nchallenging. Accurate coronary artery segmentation not only helps mitigate\nthese problems, but also allows the extraction of relevant anatomical features\nfor further analysis by quantitative methods. Although automated segmentation\nof coronary arteries has been proposed before, previous approaches have used\nnon-optimal segmentation criteria, leading to less useful results. Most methods\neither segment only the major vessel, discarding important information from the\nremaining ones, or segment the whole coronary tree based mostly on contrast\ninformation, producing a noisy output that includes vessels that are not\nrelevant for diagnosis. We adopt a better-suited clinical criterion and segment\nvessels according to their clinical relevance. Additionally, we simultaneously\nperform catheter segmentation, which may be useful for diagnosis due to the\nscale factor provided by the catheter's known diameter, and is a task that has\nnot yet been performed with good results. To derive the optimal approach, we\nconducted an extensive comparative study of encoder-decoder architectures\ntrained on a combination of focal loss and a variant of generalized dice loss.\nBased on the EfficientNet and the UNet++ architectures, we propose a line of\nefficient and high-performance segmentation models using a new decoder\narchitecture, the EfficientUNet++, whose best-performing version achieved\naverage dice scores of 0.8904 and 0.7526 for the artery and catheter classes,\nrespectively, and an average generalized dice score of 0.9234.",
    "descriptor": "",
    "authors": [
      "Jo\u00e3o Louren\u00e7o Silva",
      "Miguel Nobre Menezes",
      "Tiago Rodrigues",
      "Beatriz Silva",
      "Fausto J. Pinto",
      "Arlindo L. Oliveira"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11447"
  },
  {
    "id": "arXiv:2106.11451",
    "title": "Physics-constrained deep neural network method for estimating parameters  in a redox flow battery",
    "abstract": "In this paper, we present a physics-constrained deep neural network (PCDNN)\nmethod for parameter estimation in the zero-dimensional (0D) model of the\nvanadium redox flow battery (VRFB). In this approach, we use deep neural\nnetworks (DNNs) to approximate the model parameters as functions of the\noperating conditions. This method allows the integration of the VRFB\ncomputational models as the physical constraints in the parameter learning\nprocess, leading to enhanced accuracy of parameter estimation and cell voltage\nprediction. Using an experimental dataset, we demonstrate that the PCDNN method\ncan estimate model parameters for a range of operating conditions and improve\nthe 0D model prediction of voltage compared to the 0D model prediction with\nconstant operation-condition-independent parameters estimated with traditional\ninverse methods. We also demonstrate that the PCDNN approach has an improved\ngeneralization ability for estimating parameter values for operating conditions\nnot used in the DNN training.",
    "descriptor": "",
    "authors": [
      "QiZhi He",
      "Panos Stinis",
      "Alexandre Tartakovsky"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11451"
  },
  {
    "id": "arXiv:2106.11558",
    "title": "Learning-Based Practical Light Field Image Compression Using A  Disparity-Aware Model",
    "abstract": "Light field technology has increasingly attracted the attention of the\nresearch community with its many possible applications. The lenslet array in\ncommercial plenoptic cameras helps capture both the spatial and angular\ninformation of light rays in a single exposure. While the resulting high\ndimensionality of light field data enables its superior capabilities, it also\nimpedes its extensive adoption. Hence, there is a compelling need for efficient\ncompression of light field images. Existing solutions are commonly composed of\nseveral separate modules, some of which may not have been designed for the\nspecific structure and quality of light field data. This increases the\ncomplexity of the codec and results in impractical decoding runtimes. We\npropose a new learning-based, disparity-aided model for compression of 4D light\nfield images capable of parallel decoding. The model is end-to-end trainable,\neliminating the need for hand-tuning separate modules and allowing joint\nlearning of rate and distortion. The disparity-aided approach ensures the\nstructural integrity of the reconstructed light fields. Comparisons with the\nstate of the art show encouraging performance in terms of PSNR and MS-SSIM\nmetrics. Also, there is a notable gain in the encoding and decoding runtimes.\nSource code is available at https://moha23.github.io/LFDAAE.",
    "descriptor": "\nComments: accepted to Picture Coding Symposium 2021\n",
    "authors": [
      "Mohana Singh",
      "Renu M. Rameshan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11558"
  },
  {
    "id": "arXiv:2106.11578",
    "title": "Online Ordering Platform City Distribution Based on Genetic Algorithm",
    "abstract": "Since the rising of the takeaway ordering platform, the M platform has taken\nthe lead in the industry with its high-quality service. The increasing order\nvolume leads the competition between platforms to reduce the distribution cost,\nwhich increases rapidly because of the unreasonable distribution route. By\nanalyzing platform distribution's current situation, we study the vehicle\nrouting problem of urban distribution on the M platform and minimize the\ndistribution cost. Considering the constraints of the customer's expected\ndelivery time and vehicle condition, we combine the different arrival times of\nthe vehicle routing problem model using three soft time windows and solve the\nproblem using a genetic algorithm (GA). The results show that our model and\nalgorithm can design the vehicle path superior to the original model in terms\nof distribution cost and delivery time, thus providing decision support for the\nM platform to save distribution cost in urban distribution in the future.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Yu Du"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.11578"
  },
  {
    "id": "arXiv:2106.11633",
    "title": "Machine Learning for Model Order Selection in MIMO OFDM Systems",
    "abstract": "A variety of wireless channel estimation methods, e.g., MUSIC and ESPRIT,\nrely on prior knowledge of the model order. Therefore, it is important to\ncorrectly estimate the number of multipath components (MPCs) which compose such\nchannels. However, environments with many scatterers may generate MPCs which\nare closely spaced. This clustering of MPCs in addition to noise makes the\nmodel order selection task difficult in practice to currently known algorithms.\nIn this paper, we exploit the multidimensional characteristics of MIMO\northogonal frequency division multiplexing (OFDM) systems and propose a machine\nlearning (ML) method capable of determining the number of MPCs with a higher\naccuracy than state of the art methods in almost coherent scenarios. Moreover,\nour results show that our proposed ML method has an enhanced reliability.",
    "descriptor": "\nComments: to be published\n",
    "authors": [
      "Brenda Vilas Boas",
      "Wolfgang Zirwas",
      "Martin Haardt"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11633"
  },
  {
    "id": "arXiv:2106.11688",
    "title": "Mixing dynamics and group imbalance lead to degree inequality in  face-to-face interaction",
    "abstract": "Uncovering how inequality emerges from human interaction is imperative for\njust societies. Here we show that the way social groups interact in\nface-to-face situations can enable the emergence of degree inequality. We\npresent a mechanism that integrates group mixing dynamics with individual\npreferences, which reproduces group degree inequality found in six empirical\ndata sets of face-to-face interactions. We uncover the impact of group-size\nimbalance on degree inequality, revealing a critical minority group size that\nchanges social gatherings qualitatively. If the minority group is larger than\nthis 'critical mass' size, it can be a well-connected, cohesive group; if it is\nsmaller, minority cohesion widens degree inequality. Finally, we expose the\nunder-representation of social groups in degree rankings due to mixing dynamics\nand propose a way to reduce such biases.",
    "descriptor": "\nComments: 24 pages; 5 figures\n",
    "authors": [
      "Marcos Oliveira",
      "Fariba Karimi",
      "Maria Zens",
      "Johann Schaible",
      "Mathieu G\u00e9nois",
      "Markus Strohmaier"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.11688"
  },
  {
    "id": "arXiv:2106.11700",
    "title": "A New Channel Estimation Strategy in Intelligent Reflecting Surface  Assisted Networks",
    "abstract": "Channel estimation is the main hurdle to reaping the benefits promised by the\nintelligent reflecting surface (IRS), due to its absence of ability to\ntransmit/receive pilot signals as well as the huge number of channel\ncoefficients associated with its reflecting elements. Recently, a breakthrough\nwas made in reducing the channel estimation overhead by revealing that the\nIRS-BS (base station) channels are common in the cascaded user-IRS-BS channels\nof all the users, and if the cascaded channel of one typical user is estimated,\nthe other users' cascaded channels can be estimated very quickly based on their\ncorrelation with the typical user's channel \\cite{b5}. One limitation of this\nstrategy, however, is the waste of user energy, because many users need to keep\nsilent when the typical user's channel is estimated. In this paper, we reveal\nanother correlation hidden in the cascaded user-IRS-BS channels by observing\nthat the user-IRS channel is common in all the cascaded channels from users to\neach BS antenna as well. Building upon this finding, we propose a novel\ntwo-phase channel estimation protocol in the uplink communication.\nSpecifically, in Phase I, the correlation coefficients between the channels of\na typical BS antenna and those of the other antennas are estimated; while in\nPhase II, the cascaded channel of the typical antenna is estimated. In\nparticular, all the users can transmit throughput Phase I and Phase II. Under\nthis strategy, it is theoretically shown that the minimum number of time\ninstants required for perfect channel estimation is the same as that of the\naforementioned strategy in the ideal case without BS noise. Then, in the case\nwith BS noise, we show by simulation that the channel estimation error of our\nproposed scheme is significantly reduced thanks to the full exploitation of the\nuser energy.",
    "descriptor": "\nComments: submitted to Globecom 2021\n",
    "authors": [
      "Rui Wang",
      "Liang Liu",
      "Shuowen Zhang",
      "Changyuan Yu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11700"
  },
  {
    "id": "arXiv:2106.11723",
    "title": "Deep Stereo Image Compression with Decoder Side Information using Wyner  Common Information",
    "abstract": "We present a novel deep neural network (DNN) architecture for compressing an\nimage when a correlated image is available as side information only at the\ndecoder. This problem is known as distributed source coding (DSC) in\ninformation theory. In particular, we consider a pair of stereo images, which\ngenerally have high correlation with each other due to overlapping fields of\nview, and assume that one image of the pair is to be compressed and\ntransmitted, while the other image is available only at the decoder. In the\nproposed architecture, the encoder maps the input image to a latent space,\nquantizes the latent representation, and compresses it using entropy coding.\nThe decoder is trained to extract the Wyner's common information between the\ninput image and the correlated image from the latter. The received latent\nrepresentation and the locally generated common information are passed through\na decoder network to obtain an enhanced reconstruction of the input image. The\ncommon information provides a succinct representation of the relevant\ninformation at the receiver. We train and demonstrate the effectiveness of the\nproposed approach on the KITTI dataset of stereo image pairs. Our results show\nthat the proposed architecture is capable of exploiting the decoder-only side\ninformation, and outperforms previous work on stereo image compression with\ndecoder side information.",
    "descriptor": "\nComments: 19 pages, 18 figures\n",
    "authors": [
      "Nitish Mital",
      "Ezgi Ozyilkan",
      "Ali Garjani",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11723"
  },
  {
    "id": "arXiv:2106.11731",
    "title": "MIMIR: Deep Regression for Automated Analysis of UK Biobank Body MRI",
    "abstract": "UK Biobank (UKB) is conducting a large-scale study of more than half a\nmillion volunteers, collecting health-related information on genetics,\nlifestyle, blood biochemistry, and more. Medical imaging furthermore targets\n100,000 subjects, with 70,000 follow-up sessions, enabling measurements of\norgans, muscle, and body composition. With up to 170,000 mounting MR images,\nvarious methodologies are accordingly engaged in large-scale image analysis.\nThis work presents an experimental inference engine that can automatically\npredict a comprehensive profile of subject metadata from UKB neck-to-knee body\nMRI. In cross-validation, it accurately inferred baseline characteristics such\nas age, height, weight, and sex, but also emulated measurements of body\ncomposition by DXA, organ volumes, and abstract properties like grip strength,\npulse rate, and type 2 diabetic status (AUC: 0.866). The proposed system can\nautomatically analyze thousands of subjects within hours and provide individual\nconfidence intervals. The underlying methodology is based on convolutional\nneural networks for image-based mean-variance regression on two-dimensional\nrepresentations of the MRI data. This work aims to make the proposed system\navailable for free to researchers, who can use it to obtain fast and\nfully-automated estimates of 72 different measurements immediately upon release\nof new UK Biobank image data.",
    "descriptor": "",
    "authors": [
      "Taro Langner",
      "Andr\u00e9s Mart\u00ednez Mora",
      "Robin Strand",
      "H\u00e5kan Ahlstr\u00f6m",
      "Joel Kullberg"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11731"
  },
  {
    "id": "arXiv:2106.11733",
    "title": "Data-Driven Modeling and Control of Complex Dynamical Systems Arising in  Renal Anemia Therapy",
    "abstract": "This project is based on a mathematical model of erythropoiesis for anemia,\nwhich consists of five hyperbolic population equations describing the\nproduction of red blood cells under treatment with epoetin-alfa (EPO). Extended\ndynamic mode decomposition (EDMD) is utilized to approximate the non-linear\ndynamical systems by linear ones. This allows for efficient and reliable\nstrategies based on a combination of EDMD and model predictive control (MPC),\nwhich produces results comparable with the one obtained in past publications\nfor the original model.",
    "descriptor": "",
    "authors": [
      "Sabrina Casper",
      "Doris H. Fuertinger",
      "Peter Kotanko",
      "Luca Mechelli",
      "Jan Rohleff",
      "Stefan Volkwein"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11733"
  },
  {
    "id": "arXiv:2106.11745",
    "title": "A behavioural modelling approach to assess the impact of COVID-19  vaccine hesitancy",
    "abstract": "In this paper we introduce a compartmental epidemic model describing the\ntransmission of the COVID-19 disease in presence of non-mandatory vaccination.\nThe model takes into account the hesitancy and refusal of vaccination. To this\naim, we employ the information index, which mimics the idea that individuals\ntake their decision on vaccination based not only on the present but also on\nthe past information about the spread of the disease. Theoretical analysis and\nsimulations show clearly as a voluntary vaccination can certainly reduce the\nimpact of the disease but it is unable to eliminate it. We also show how the\ninformation-related parameters affect the dynamics of the disease. In\nparticular, the hesitancy and refusal of vaccination is better contained in\ncase of large information coverage and small memory characteristic time.\nFinally, the possible influence of seasonality is also investigated.",
    "descriptor": "",
    "authors": [
      "Bruno Buonomo",
      "Rossella Della Marca",
      "Alberto d'Onofrio",
      "Maria Groppi"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.11745"
  },
  {
    "id": "arXiv:2106.11759",
    "title": "Analysis and Tuning of a Voice Assistant System for Dysfluent Speech",
    "abstract": "Dysfluencies and variations in speech pronunciation can severely degrade\nspeech recognition performance, and for many individuals with\nmoderate-to-severe speech disorders, voice operated systems do not work.\nCurrent speech recognition systems are trained primarily with data from fluent\nspeakers and as a consequence do not generalize well to speech with\ndysfluencies such as sound or word repetitions, sound prolongations, or audible\nblocks. The focus of this work is on quantitative analysis of a consumer speech\nrecognition system on individuals who stutter and production-oriented\napproaches for improving performance for common voice assistant tasks (i.e.,\n\"what is the weather?\"). At baseline, this system introduces a significant\nnumber of insertion and substitution errors resulting in intended speech Word\nError Rates (isWER) that are 13.64\\% worse (absolute) for individuals with\nfluency disorders. We show that by simply tuning the decoding parameters in an\nexisting hybrid speech recognition system one can improve isWER by 24\\%\n(relative) for individuals with fluency disorders. Tuning these parameters\ntranslates to 3.6\\% better domain recognition and 1.7\\% better intent\nrecognition relative to the default setup for the 18 study participants across\nall stuttering severities.",
    "descriptor": "\nComments: 5 pages, 1 page reference, 2 figures\n",
    "authors": [
      "Vikramjit Mitra",
      "Zifang Huang",
      "Colin Lea",
      "Lauren Tooley",
      "Sarah Wu",
      "Darren Botten",
      "Ashwini Palekar",
      "Shrinath Thelapurath",
      "Panayiotis Georgiou",
      "Sachin Kajarekar",
      "Jefferey Bigham"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.11759"
  },
  {
    "id": "arXiv:2106.11765",
    "title": "Three-dimensional bipedal model with zero-energy-cost walking",
    "abstract": "We study a three-dimensional articulated rigid-body biped model that\npossesses zero cost of transport walking gaits. Energy losses are avoided due\nto the complete elimination of the foot-ground collisions by the concerted\noscillatory motion of the model's parts. The model consists of two parts\nconnected via a universal joint. It does not rely on any geometry altering\nmechanisms, massless parts or springs. Despite the model's simplicity, its\ncollisionless gaits feature walking with finite speed, foot clearance and\nground friction. The collisionless spectrum can be studied analytically in the\nsmall movement limit, revealing infinitely many periodic modes. The modes\ndiffer in the number of sagittal and coronal plane oscillations at different\nstages of the walking cycle. We focus on the mode with the minimal number of\nsuch oscillations, presenting its complete analytical solution. We then\nnumerically evolve it toward a general non-small movement solution. A general\ncollisionless mode can be tuned by adjusting a single model parameter. Some of\nthe presented results display a surprising degree of generality and\nuniversality.",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Sergey Pankov"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11765"
  },
  {
    "id": "arXiv:2106.11769",
    "title": "Improving Ultrasound Tongue Image Reconstruction from Lip Images Using  Self-supervised Learning and Attention Mechanism",
    "abstract": "Speech production is a dynamic procedure, which involved multi human organs\nincluding the tongue, jaw and lips. Modeling the dynamics of the vocal tract\ndeformation is a fundamental problem to understand the speech, which is the\nmost common way for human daily communication. Researchers employ several\nsensory streams to describe the process simultaneously, which are\nincontrovertibly statistically related to other streams. In this paper, we\naddress the following question: given an observable image sequences of lips,\ncan we picture the corresponding tongue motion. We formulated this problem as\nthe self-supervised learning problem, and employ the two-stream convolutional\nnetwork and long-short memory network for the learning task, with the attention\nmechanism. We evaluate the performance of the proposed method by leveraging the\nunlabeled lip videos to predict an upcoming ultrasound tongue image sequence.\nThe results show that our model is able to generate images that close to the\nreal ultrasound tongue images, and results in the matching between two imaging\nmodalities.",
    "descriptor": "\nComments: Accepted in KDD Workshop (BIOKDD 2021)\n",
    "authors": [
      "Haiyang Liu",
      "Jihan Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.11769"
  },
  {
    "id": "arXiv:2106.11794",
    "title": "Deep neural network Based Low-latency Speech Separation with Asymmetric  analysis-Synthesis Window Pair",
    "abstract": "Time-frequency masking or spectrum prediction computed via short symmetric\nwindows are commonly used in low-latency deep neural network (DNN) based source\nseparation. In this paper, we propose the usage of an asymmetric\nanalysis-synthesis window pair which allows for training with targets with\nbetter frequency resolution, while retaining the low-latency during inference\nsuitable for real-time speech enhancement or assisted hearing applications. In\norder to assess our approach across various model types and datasets, we\nevaluate it with both speaker-independent deep clustering (DC) model and a\nspeaker-dependent mask inference (MI) model. We report an improvement in\nseparation performance of up to 1.5 dB in terms of source-to-distortion ratio\n(SDR) while maintaining an algorithmic latency of 8 ms.",
    "descriptor": "\nComments: Accepted to EUSIPCO-2021\n",
    "authors": [
      "Shanshan Wang",
      "Gaurav Naithani",
      "Archontis Politis",
      "Tuomas Virtanen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.11794"
  },
  {
    "id": "arXiv:2106.11805",
    "title": "Reconfigurable Intelligent Surface-Aided Wireless Power Transfer  Systems: Analysis and Implementation",
    "abstract": "Reconfigurable intelligent surface (RIS) is a promising technology for RF\nwireless power transfer (WPT) as it is capable of beamforming and beam focusing\nwithout using active and power-hungry components. In this paper, we propose a\nmulti-tile RIS beam scanning (MTBS) algorithm for powering up\ninternet-of-things (IoT) devices. Considering the hardware limitations of the\nIoT devices, the proposed algorithm requires only power information to enable\nthe beam focusing capability of the RIS. Specifically, we first divide the RIS\ninto smaller RIS tiles. Then, all RIS tiles and the phased array transmitter\nare iteratively scanned and optimized to maximize the receive power. We\nelaborately analyze the proposed algorithm and build a simulator to verify it.\nFurthermore, we have built a real-life testbed of RIS-aided WPT systems to\nvalidate the algorithm. The experimental results show that the proposed MTBS\nalgorithm can properly control the transmission phase of the transmitter and\nthe reflection phase of the RIS to focus the power at the receiver.\nConsequently, after executing the algorithm, about 20 dB improvement of the\nreceive power is achieved compared to the case that all unit cells of the RIS\nare in OFF state. By experiments, we confirm that the RIS with the MTBS\nalgorithm can greatly enhance the power transfer efficiency.",
    "descriptor": "",
    "authors": [
      "Nguyen Minh Tran",
      "Muhammad Miftahul Amri",
      "Je Hyeon Park",
      "Dong In Kim",
      "Kae Won Choi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.11805"
  },
  {
    "id": "arXiv:2106.11840",
    "title": "Quantum Computing -- from NISQ to PISQ",
    "abstract": "Given the impeding timeline of developing good quality quantum processing\nunits, it is the moment to rethink the approach to advance quantum computing\nresearch. Rather than waiting for quantum hardware technologies to mature, we\nneed to start assessing in tandem the impact of the occurrence of quantum\ncomputing in various scientific fields. However, to this purpose, we need to\nuse a complementary but quite different approach than proposed by the NISQ\nvision, which is heavily focused on and burdened by the engineering challenges.\nThat is why we propose and advocate the PISQ approach: Perfect Intermediate\nScale Quantum computing based on the already known concept of perfect qubits.\nThis will allow researchers to focus much more on the development of new\napplications by defining the algorithms in terms of perfect qubits and evaluate\nthem on quantum computing simulators that are executed on supercomputers. It is\nnot the long-term solution but will currently allow universities to research on\nquantum logic and algorithms and companies can already start developing their\ninternal know-how on quantum solutions.",
    "descriptor": "\nComments: 8 pages, 3 figures, 1 table\n",
    "authors": [
      "Koen Bertels",
      "Aritra Sarkar",
      "Imran Ashraf"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.11840"
  },
  {
    "id": "arXiv:2106.11846",
    "title": "Quantifying the Impact of Human Capital, Job History, and Language  Factors on Job Seniority with a Large-scale Analysis of Resumes",
    "abstract": "As job markets worldwide have become more competitive and applicant selection\ncriteria have become more opaque, and different (and sometimes contradictory)\ninformation and advice is available for job seekers wishing to progress in\ntheir careers, it has never been more difficult to determine which factors in a\nr\\'esum\\'e most effectively help career progression. In this work we present a\nnovel, large scale dataset of over half a million r\\'esum\\'es with preliminary\nanalysis to begin to answer empirically which factors help or hurt people\nwishing to transition to more senior roles as they progress in their career. We\nfind that previous experience forms the most important factor, outweighing\nother aspects of human capital, and find which language factors in a r\\'esum\\'e\nhave significant effects. This lays the groundwork for future inquiry in career\ntrajectories using large scale data analysis and natural language processing\ntechniques.",
    "descriptor": "\nComments: 9 Pages, 5 Figures, 8 Tables\n",
    "authors": [
      "Austin P Wright",
      "Caleb Ziems",
      "Haekyu Park",
      "Jon Saad-Falcon",
      "Duen Horng Chau",
      "Diyi Yang",
      "Maria Tomprou"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.11846"
  },
  {
    "id": "arXiv:2106.11849",
    "title": "Algorithmic Recourse in Partially and Fully Confounded Settings Through  Bounding Counterfactual Effects",
    "abstract": "Algorithmic recourse aims to provide actionable recommendations to\nindividuals to obtain a more favourable outcome from an automated\ndecision-making system. As it involves reasoning about interventions performed\nin the physical world, recourse is fundamentally a causal problem. Existing\nmethods compute the effect of recourse actions using a causal model learnt from\ndata under the assumption of no hidden confounding and modelling assumptions\nsuch as additive noise. Building on the seminal work of Balke and Pearl (1994),\nwe propose an alternative approach for discrete random variables which relaxes\nthese assumptions and allows for unobserved confounding and arbitrary\nstructural equations. The proposed approach only requires specification of the\ncausal graph and confounding structure and bounds the expected counterfactual\neffect of recourse actions. If the lower bound is above a certain threshold,\ni.e., on the other side of the decision boundary, recourse is guaranteed in\nexpectation.",
    "descriptor": "\nComments: Preliminary workshop version; work in progress\n",
    "authors": [
      "Julius von K\u00fcgelgen",
      "Nikita Agarwal",
      "Jakob Zeitler",
      "Afsaneh Mastouri",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11849"
  },
  {
    "id": "arXiv:2106.11853",
    "title": "Credal Self-Supervised Learning",
    "abstract": "Self-training is an effective approach to semi-supervised learning. The key\nidea is to let the learner itself iteratively generate \"pseudo-supervision\" for\nunlabeled instances based on its current hypothesis. In combination with\nconsistency regularization, pseudo-labeling has shown promising performance in\nvarious domains, for example in computer vision. To account for the\nhypothetical nature of the pseudo-labels, these are commonly provided in the\nform of probability distributions. Still, one may argue that even a probability\ndistribution represents an excessive level of informedness, as it suggests that\nthe learner precisely knows the ground-truth conditional probabilities. In our\napproach, we therefore allow the learner to label instances in the form of\ncredal sets, that is, sets of (candidate) probability distributions. Thanks to\nthis increased expressiveness, the learner is able to represent uncertainty and\na lack of knowledge in a more flexible and more faithful manner. To learn from\nweakly labeled data of that kind, we leverage methods that have recently been\nproposed in the realm of so-called superset learning. In an exhaustive\nempirical evaluation, we compare our methodology to state-of-the-art\nself-supervision approaches, showing competitive to superior performance\nespecially in low-label scenarios incorporating a high degree of uncertainty.",
    "descriptor": "\nComments: 17 pages, 1 figure, 7 tables\n",
    "authors": [
      "Julian Lienen",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11853"
  },
  {
    "id": "arXiv:2106.11877",
    "title": "Eliminating Intermediate Measurements using Pseudorandom Generators",
    "abstract": "We show that quantum algorithms of time $T$ and space $S\\ge \\log T$ with\nintermediate measurements can be simulated by quantum algorithms of time $T\n\\cdot \\mathrm{poly}(S)$ and space $O(S\\cdot \\log T )$ without intermediate\nmeasurements. The best simulations prior to this work required either\n$\\Omega(T)$ space (by the deferred measurement principle) or\n$\\mathrm{poly}(2^S)$ time [FR21, GRZ21]. Our result is thus a time-efficient\nand space-efficient simulation of algorithms with intermediate measurements by\nalgorithms without intermediate measurements.\nTo prove our result, we study pseudorandom generators for quantum\nspace-bounded algorithms. We show that (an instance of) the INW pseudorandom\ngenerator for classical space-bounded algorithms [INW94] also fools quantum\nspace-bounded algorithms. More precisely, we show that for quantum\nspace-bounded algorithms that have access to a read-once tape consisting of\nrandom bits, the final state of the algorithm when the random bits are drawn\nfrom the uniform distribution is nearly identical to the final state when the\nrandom bits are drawn using the INW pseudorandom generator.",
    "descriptor": "",
    "authors": [
      "Uma Girish",
      "Ran Raz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.11877"
  },
  {
    "id": "arXiv:2106.11879",
    "title": "Asynchronous Stochastic Optimization Robust to Arbitrary Delays",
    "abstract": "We consider stochastic optimization with delayed gradients where, at each\ntime step $t$, the algorithm makes an update using a stale stochastic gradient\nfrom step $t - d_t$ for some arbitrary delay $d_t$. This setting abstracts\nasynchronous distributed optimization where a central server receives gradient\nupdates computed by worker machines. These machines can experience computation\nand communication loads that might vary significantly over time. In the general\nnon-convex smooth optimization setting, we give a simple and efficient\nalgorithm that requires $O( \\sigma^2/\\epsilon^4 + \\tau/\\epsilon^2 )$ steps for\nfinding an $\\epsilon$-stationary point $x$, where $\\tau$ is the \\emph{average}\ndelay $\\smash{\\frac{1}{T}\\sum_{t=1}^T d_t}$ and $\\sigma^2$ is the variance of\nthe stochastic gradients. This improves over previous work, which showed that\nstochastic gradient decent achieves the same rate but with respect to the\n\\emph{maximal} delay $\\max_{t} d_t$, that can be significantly larger than the\naverage delay especially in heterogeneous distributed systems. Our experiments\ndemonstrate the efficacy and robustness of our algorithm in cases where the\ndelay distribution is skewed or heavy-tailed.",
    "descriptor": "",
    "authors": [
      "Alon Cohen",
      "Amit Daniely",
      "Yoel Drori",
      "Tomer Koren",
      "Mariano Schain"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11879"
  },
  {
    "id": "arXiv:2106.11884",
    "title": "Parallel decomposition of persistence modules through interval bases",
    "abstract": "We introduce an algorithm to decompose any finite-type persistence module\nwith coefficients in a field into what we call an {\\em interval basis}. This\nconstruction yields both the standard persistence pairs of Topological Data\nAnalysis (TDA), as well as a special set of generators inducing the interval\ndecomposition of the Structure theorem. The computation of this basis can be\ndistributed over the steps in the persistence module. This construction works\nfor general persistence modules on a field $\\mathbb{F}$, not necessarily\nderiving from persistent homology. We subsequently provide a parallel algorithm\nto build a persistent homology module over $\\mathbb{R}$ by leveraging the Hodge\ndecomposition, thus providing new motivation to explore the interplay between\nTDA and the Hodge Laplacian.",
    "descriptor": "\nComments: 37 pages, 6 figures\n",
    "authors": [
      "Alessandro De Gregorio",
      "Marco Guerra",
      "Sara Scaramuccia",
      "Francesco Vaccarino"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.11884"
  },
  {
    "id": "arXiv:2106.11918",
    "title": "From SIR to SEAIRD: a novel data-driven modeling approach based on the  Grey-box System Theory to predict the dynamics of COVID-19",
    "abstract": "Common compartmental modeling for COVID-19 is based on a priori knowledge and\nnumerous assumptions. Additionally, they do not systematically incorporate\nasymptomatic cases. Our study aimed at providing a framework for data-driven\napproaches, by leveraging the strengths of the grey-box system theory or\ngrey-box identification, known for its robustness in problem solving under\npartial, incomplete, or uncertain data. Empirical data on confirmed cases and\ndeaths, extracted from an open source repository were used to develop the\nSEAIRD compartment model. Adjustments were made to fit current knowledge on the\nCOVID-19 behavior. The model was implemented and solved using an Ordinary\nDifferential Equation solver and an optimization tool. A cross-validation\ntechnique was applied, and the coefficient of determination $R^2$ was computed\nin order to evaluate the goodness-of-fit of the model. %to the data. Key\nepidemiological parameters were finally estimated and we provided the rationale\nfor the construction of SEAIRD model. When applied to Brazil's cases, SEAIRD\nproduced an excellent agreement to the data, with an %coefficient of\ndetermination $R^2$ $\\geq 90\\%$. The probability of COVID-19 transmission was\ngenerally high ($\\geq 95\\%$). On the basis of a 20-day modeling data, the\nincidence rate of COVID-19 was as low as 3 infected cases per 100,000 exposed\npersons in Brazil and France. Within the same time frame, the fatality rate of\nCOVID-19 was the highest in France (16.4\\%) followed by Brazil (6.9\\%), and the\nlowest in Russia ($\\leq 1\\%$). SEAIRD represents an asset for modeling\ninfectious diseases in their dynamical stable phase, especially for new viruses\nwhen pathophysiology knowledge is very limited.",
    "descriptor": "",
    "authors": [
      "Komi Midzodzi P\u00e9kp\u00e9",
      "Djamel Zitouni",
      "Gilles Gasso",
      "Wajdi Dhifli",
      "Benjamin C. Guinhouya"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11918"
  },
  {
    "id": "arXiv:2106.11926",
    "title": "Surrogate-based variational data assimilation for tidal modelling",
    "abstract": "Data assimilation (DA) is widely used to combine physical knowledge and\nobservations. It is nowadays commonly used in geosciences to perform parametric\ncalibration. In a context of climate change, old calibrations can not\nnecessarily be used for new scenarios. This raises the question of DA\ncomputational cost, as costly physics-based numerical models need to be\nreanalyzed. Reduction and metamodelling represent therefore interesting\nperspectives, for example proposed in recent contributions as hybridization\nbetween ensemble and variational methods, to combine their advantages\n(efficiency, non-linear framework). They are however often based on Monte Carlo\n(MC) type sampling, which often requires considerable increase of the ensemble\nsize for better efficiency, therefore representing a computational burden in\nensemble-based methods as well. To address these issues, two methods to replace\nthe complex model by a surrogate are proposed and confronted : (i) PODEn3DVAR\ndirectly inspired from PODEn4DVAR, relies on an ensemble-based joint\nparameter-state Proper Orthogonal Decomposition (POD), which provides a linear\nmetamodel ; (ii) POD-PCE-3DVAR, where the model states are POD reduced then\nlearned using Polynomial Chaos Expansion (PCE), resulting in a non-linear\nmetamodel. Both metamodels allow to write an approximate cost function whose\nminimum can be analytically computed, or deduced by a gradient descent at\nnegligible cost. Furthermore, adapted metamodelling error covariance matrix is\ngiven for POD-PCE-3DVAR, allowing to substantially improve the metamodel-based\nDA analysis. Proposed methods are confronted on a twin experiment, and compared\nto classical 3DVAR on a measurement-based problem. Results are promising, in\nparticular superior with POD-PCE-3DVAR, showing good convergence to classical\n3DVAR and robustness to noise.",
    "descriptor": "",
    "authors": [
      "Rem-Sophia Mouradi",
      "C\u00e9dric Goeury",
      "Olivier Thual",
      "Fabrice Zaoui",
      "Pablo Tassi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2106.11926"
  },
  {
    "id": "arXiv:2106.11936",
    "title": "Sparsistent Model Discovery",
    "abstract": "Discovering the partial differential equations underlying a spatio-temporal\ndatasets from very limited observations is of paramount interest in many\nscientific fields. However, it remains an open question to know when model\ndiscovery algorithms based on sparse regression can actually recover the\nunderlying physical processes. We trace back the poor of performance of Lasso\nbased model discovery algorithms to its potential variable selection\ninconsistency: meaning that even if the true model is present in the library,\nit might not be selected. By first revisiting the irrepresentability condition\n(IRC) of the Lasso, we gain some insights of when this might occur. We then\nshow that the adaptive Lasso will have more chances of verifying the IRC than\nthe Lasso and propose to integrate it within a deep learning model discovery\nframework with stability selection and error control. Experimental results show\nwe can recover several nonlinear and chaotic canonical PDEs with a single set\nof hyperparameters from a very limited number of samples at high noise levels.",
    "descriptor": "",
    "authors": [
      "Georges Tod",
      "Gert-Jan Both",
      "Remy Kusters"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.11936"
  },
  {
    "id": "arXiv:2106.11945",
    "title": "Smaller extended formulations for spanning tree polytopes in  minor-closed classes and beyond",
    "abstract": "Let $G$ be a connected $n$-vertex graph in a proper minor-closed class\n$\\mathcal G$. We prove that the extension complexity of the spanning tree\npolytope of $G$ is $O(n^{3/2})$. This improves on the $O(n^2)$ bounds following\nfrom the work of Wong (1980) and Martin (1991). It also extends a result of\nFiorini, Huynh, Joret, and Pashkovich (2017), who obtained a $O(n^{3/2})$ bound\nfor graphs embedded in a fixed surface. Our proof works more generally for all\ngraph classes admitting strongly sublinear balanced separators: We prove that\nfor every constant $\\beta$ with $0<\\beta<1$, if $\\mathcal G$ is a graph class\nclosed under induced subgraphs such that all $n$-vertex graphs in $\\mathcal G$\nhave balanced separators of size $O(n^\\beta)$, then the extension complexity of\nthe spanning tree polytope of every connected $n$-vertex graph in $\\mathcal{G}$\nis $O(n^{1+\\beta})$. We in fact give two proofs of this result, one is a direct\nconstruction of the extended formulation, the other is via communication\nprotocols. Using the latter approach we also give a short proof of the $O(n)$\nbound for planar graphs due to Williams (2002).",
    "descriptor": "",
    "authors": [
      "Manuel Aprile",
      "Samuel Fiorini",
      "Tony Huynh",
      "Gwena\u00ebl Joret",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.11945"
  },
  {
    "id": "arXiv:2106.11950",
    "title": "Rank-one matrix estimation with groupwise heteroskedasticity",
    "abstract": "We study the problem of estimating a rank-one matrix from Gaussian\nobservations where different blocks of the matrix are observed under different\nnoise levels. This problem is motivated by applications in clustering and\ncommunity detection where latent variables can be partitioned into a fixed\nnumber of known groups (e.g., users and items) and the blocks of the matrix\ncorrespond to different types of pairwise interactions (e.g., user-user,\nuser-item, or item-item interactions). In the setting where the number of\nblocks is fixed while the number of variables tends to infinity, we prove\nasymptotically exact formulas for the minimum mean-squared error in estimating\nboth the matrix and the latent variables. These formulas describe the weak\nrecovery thresholds for the problem and reveal invariance properties with\nrespect to certain scalings of the noise variance. We also derive an\napproximate message passing algorithm and a gradient descent algorithm and show\nempirically that these algorithms achieve the information-theoretic limits in\ncertain regimes.",
    "descriptor": "\nComments: 22 pages, 3 figures\n",
    "authors": [
      "Joshua K. Behne",
      "Galen Reeves"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11950"
  },
  {
    "id": "arXiv:1705.10760",
    "title": "Attainable Knowledge and Omniscience",
    "abstract": "Comments: In Proceedings TARK 2021, arXiv:2106.10886",
    "descriptor": "\nComments: In Proceedings TARK 2021, arXiv:2106.10886\n",
    "authors": [
      "Pavel Naumov",
      "Jia Tao"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1705.10760"
  },
  {
    "id": "arXiv:1706.07180",
    "title": "Compressive Statistical Learning with Random Feature Moments",
    "abstract": "Comments: Main novelties between version 1 and version 2: improved concentration bounds, improved sketch sizes for compressive k-means and compressive GMM that now scale linearly with the ambient dimensionMain novelties of version 3: all content on compressive clustering and compressive GMM is now developed in the companion paper hal-02536818; improved statistical guarantees in a generic framework with illustration of the improvements on compressive PCA. Mathematical Statistics and Learning, EMS Publishing House, In press",
    "descriptor": "\nComments: Main novelties between version 1 and version 2: improved concentration bounds, improved sketch sizes for compressive k-means and compressive GMM that now scale linearly with the ambient dimensionMain novelties of version 3: all content on compressive clustering and compressive GMM is now developed in the companion paper hal-02536818; improved statistical guarantees in a generic framework with illustration of the improvements on compressive PCA. Mathematical Statistics and Learning, EMS Publishing House, In press\n",
    "authors": [
      "R\u00e9mi Gribonval",
      "Gilles Blanchard",
      "Nicolas Keriven",
      "Yann Traonmilin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/1706.07180"
  },
  {
    "id": "arXiv:1707.04618",
    "title": "Communication Lower Bounds of Bilinear Algorithms for Symmetric Tensor  Contractions",
    "abstract": "Communication Lower Bounds of Bilinear Algorithms for Symmetric Tensor  Contractions",
    "descriptor": "",
    "authors": [
      "Edgar Solomonik",
      "James Demmel",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1707.04618"
  },
  {
    "id": "arXiv:1901.11259",
    "title": "Semantic Hierarchy Preserving Deep Hashing for Large-scale Image  Retrieval",
    "abstract": "Semantic Hierarchy Preserving Deep Hashing for Large-scale Image  Retrieval",
    "descriptor": "",
    "authors": [
      "Ming Zhang",
      "Xuefei Zhe",
      "Le Ou-Yang",
      "Shifeng Chen",
      "Hong Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1901.11259"
  },
  {
    "id": "arXiv:1902.01635",
    "title": "Preconditioned Riemannian Optimization on the Generalized Stiefel  Manifold",
    "abstract": "Preconditioned Riemannian Optimization on the Generalized Stiefel  Manifold",
    "descriptor": "",
    "authors": [
      "Boris Shustin",
      "Haim Avron"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1902.01635"
  },
  {
    "id": "arXiv:1903.12561",
    "title": "Adversarial Robustness vs Model Compression, or Both?",
    "abstract": "Comments: Accepted by ICCV 2019",
    "descriptor": "\nComments: Accepted by ICCV 2019\n",
    "authors": [
      "Shaokai Ye",
      "Kaidi Xu",
      "Sijia Liu",
      "Jan-Henrik Lambrechts",
      "Huan Zhang",
      "Aojun Zhou",
      "Kaisheng Ma",
      "Yanzhi Wang",
      "Xue Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1903.12561"
  },
  {
    "id": "arXiv:1904.08475",
    "title": "Image Resizing by Reconstruction from Deep Features",
    "abstract": "Comments: 13 pages, 21 figures",
    "descriptor": "\nComments: 13 pages, 21 figures\n",
    "authors": [
      "Moab Arar",
      "Dov Danon",
      "Daniel Cohen-Or",
      "Ariel Shamir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1904.08475"
  },
  {
    "id": "arXiv:1906.04648",
    "title": "Analysis of Optimization Algorithms via Sum-of-Squares",
    "abstract": "Comments: Extended version of a paper presented at the 2019 Signal Processing with Adaptive Sparse Structured Representations (SPARS) workshop; Code for numerically and symbolically verifying the results can be found at this https URL; v3: added acknowledgments; v4 Accepted to the Journal of Optimization Theory and Applications (JOTA)",
    "descriptor": "\nComments: Extended version of a paper presented at the 2019 Signal Processing with Adaptive Sparse Structured Representations (SPARS) workshop; Code for numerically and symbolically verifying the results can be found at this https URL; v3: added acknowledgments; v4 Accepted to the Journal of Optimization Theory and Applications (JOTA)\n",
    "authors": [
      "Sandra S. Y. Tan",
      "Antonios Varvitsiotis",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1906.04648"
  },
  {
    "id": "arXiv:1908.06957",
    "title": "On the Capacity of Secure Distributed Batch Matrix Multiplication",
    "abstract": "Comments: The updated version is the revision for IEEE IT Transactions",
    "descriptor": "\nComments: The updated version is the revision for IEEE IT Transactions\n",
    "authors": [
      "Zhuqing Jia",
      "Syed A. Jafar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1908.06957"
  },
  {
    "id": "arXiv:1910.00482",
    "title": "Estimating Smooth GLM in Non-interactive Local Differential Privacy  Model with Public Unlabeled Data",
    "abstract": "Estimating Smooth GLM in Non-interactive Local Differential Privacy  Model with Public Unlabeled Data",
    "descriptor": "",
    "authors": [
      "Di Wang",
      "Lijie Hu",
      "Huanyu Zhang",
      "Marco Gaboardi",
      "Jinhui Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.00482"
  },
  {
    "id": "arXiv:1910.02684",
    "title": "Effective Semi-Supervised Node Classification on Few-Labeled Graph Data",
    "abstract": "Comments: 12pages",
    "descriptor": "\nComments: 12pages\n",
    "authors": [
      "Ziang Zhou",
      "Jieming Shi",
      "Shengzhong Zhang",
      "Zengfeng Huang",
      "Qing Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.02684"
  },
  {
    "id": "arXiv:1911.07532",
    "title": "Graph Neural Ordinary Differential Equations",
    "abstract": "Comments: Accepted [Spotlight] at the AAAI workshop DLGMA20. For the extended version, see \"Continuous-Depth Neural Models for Dynamic Graph Prediction\"",
    "descriptor": "\nComments: Accepted [Spotlight] at the AAAI workshop DLGMA20. For the extended version, see \"Continuous-Depth Neural Models for Dynamic Graph Prediction\"\n",
    "authors": [
      "Michael Poli",
      "Stefano Massaroli",
      "Junyoung Park",
      "Atsushi Yamashita",
      "Hajime Asama",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.07532"
  },
  {
    "id": "arXiv:2002.02712",
    "title": "Discovering Mathematical Objects of Interest -- A Study of Mathematical  Notations",
    "abstract": "Comments: Proceedings of The Web Conference 2020 (WWW'20), April 20--24, 2020, Taipei, Taiwan",
    "descriptor": "\nComments: Proceedings of The Web Conference 2020 (WWW'20), April 20--24, 2020, Taipei, Taiwan\n",
    "authors": [
      "Andre Greiner-Petter",
      "Moritz Schubotz",
      "Fabian Mueller",
      "Corinna Breitinger",
      "Howard S. Cohl",
      "Akiko Aizawa",
      "Bela Gipp"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2002.02712"
  },
  {
    "id": "arXiv:2002.03979",
    "title": "Online Covariance Matrix Estimation in Stochastic Gradient Descent",
    "abstract": "Online Covariance Matrix Estimation in Stochastic Gradient Descent",
    "descriptor": "",
    "authors": [
      "Wanrong Zhu",
      "Xi Chen",
      "Wei Biao Wu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.03979"
  },
  {
    "id": "arXiv:2002.12873",
    "title": "Federated Over-Air Subspace Tracking from Incomplete and Corrupted Data",
    "abstract": "Comments: New model, algorithm for centralized case; added algorithms to deal with sparse outliers; modified organization significantly",
    "descriptor": "\nComments: New model, algorithm for centralized case; added algorithms to deal with sparse outliers; modified organization significantly\n",
    "authors": [
      "Praneeth Narayanamurthy",
      "Namrata Vaswani",
      "Aditya Ramamoorthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.12873"
  },
  {
    "id": "arXiv:2003.00563",
    "title": "An Equivalence Between Private Classification and Online Prediction",
    "abstract": "Comments: An earlier version of this manuscript claimed an upper bound over the sample complexity that is exponential in the Littlestone dimension. The argument was erranous, and the current version contains a correction, which leads to double-exponential dependence in the Littlestone-dimension",
    "descriptor": "\nComments: An earlier version of this manuscript claimed an upper bound over the sample complexity that is exponential in the Littlestone dimension. The argument was erranous, and the current version contains a correction, which leads to double-exponential dependence in the Littlestone-dimension\n",
    "authors": [
      "Mark Bun",
      "Roi Livni",
      "Shay Moran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.00563"
  },
  {
    "id": "arXiv:2004.05409",
    "title": "How to Secure Distributed Filters Under Sensor Attacks",
    "abstract": "How to Secure Distributed Filters Under Sensor Attacks",
    "descriptor": "",
    "authors": [
      "Xingkang He",
      "Xiaoqiang Ren",
      "Henrik Sandberg",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2004.05409"
  },
  {
    "id": "arXiv:2004.10443",
    "title": "A combinatorial algorithm for computing the rank of a generic  partitioned matrix with $2 \\times 2$ submatrices",
    "abstract": "Comments: This is a post-peer-review, pre-copyedit version of an article published in Mathematical Programming. The final authenticated version is available online at: this https URL",
    "descriptor": "\nComments: This is a post-peer-review, pre-copyedit version of an article published in Mathematical Programming. The final authenticated version is available online at: this https URL\n",
    "authors": [
      "Hiroshi Hirai",
      "Yuni Iwamasa"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2004.10443"
  },
  {
    "id": "arXiv:2005.00356",
    "title": "Understanding the Perceived Quality of Video Predictions",
    "abstract": "Comments: Project website: this https URL",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Nagabhushan Somraj",
      "Manoj Surya Kashi",
      "S. P. Arun",
      "Rajiv Soundararajan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.00356"
  },
  {
    "id": "arXiv:2005.01586",
    "title": "What Do Our Choices Say About Our Preferences?",
    "abstract": "Comments: 22 pages, 6 figures",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Krzysztof Grining",
      "Marek Klonowski",
      "Ma\u0142gorzata Sulkowska"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2005.01586"
  },
  {
    "id": "arXiv:2005.03197",
    "title": "Fair Algorithms for Hierarchical Agglomerative Clustering",
    "abstract": "Fair Algorithms for Hierarchical Agglomerative Clustering",
    "descriptor": "",
    "authors": [
      "Anshuman Chhabra",
      "Vidushi Vashishth",
      "Prasant Mohapatra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.03197"
  },
  {
    "id": "arXiv:2005.08140",
    "title": "Global inducing point variational posteriors for Bayesian neural  networks and deep Gaussian processes",
    "abstract": "Comments: Accepted for publication at the 38th International Conference on Machine Learning (ICML 2021, PMLR 139), 33 pages",
    "descriptor": "\nComments: Accepted for publication at the 38th International Conference on Machine Learning (ICML 2021, PMLR 139), 33 pages\n",
    "authors": [
      "Sebastian W. Ober",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.08140"
  },
  {
    "id": "arXiv:2005.09353",
    "title": "\"Guess Who ?\" Large-Scale Data-Centric Study of the Adequacy of Browser  Fingerprints for Web Authentication",
    "abstract": "\"Guess Who ?\" Large-Scale Data-Centric Study of the Adequacy of Browser  Fingerprints for Web Authentication",
    "descriptor": "",
    "authors": [
      "Nampoina Andriamilanto",
      "Tristan Allard",
      "Ga\u00ebtan Le Guelvouit"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2005.09353"
  },
  {
    "id": "arXiv:2006.03226",
    "title": "Brain-inspired global-local learning incorporated with neuromorphic  computing",
    "abstract": "Comments: 5 figures, 6 tables",
    "descriptor": "\nComments: 5 figures, 6 tables\n",
    "authors": [
      "Yujie Wu",
      "Rong Zhao",
      "Jun Zhu",
      "Feng Chen",
      "Mingkun Xu",
      "Guoqi Li",
      "Sen Song",
      "Lei Deng",
      "Guanrui Wang",
      "Hao Zheng",
      "Jing Pei",
      "Youhui Zhang",
      "Mingguo Zhao",
      "Luping Shi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2006.03226"
  },
  {
    "id": "arXiv:2006.08453",
    "title": "Bayesian Neural Network via Stochastic Gradient Descent",
    "abstract": "Comments: This work was part of an undergraduate project. There was an error in modelling bayesian neural networks, hence the results are false",
    "descriptor": "\nComments: This work was part of an undergraduate project. There was an error in modelling bayesian neural networks, hence the results are false\n",
    "authors": [
      "Abhinav Sagar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.08453"
  },
  {
    "id": "arXiv:2006.16899",
    "title": "The finiteness conjecture holds in SL(2,Z>=0)^2",
    "abstract": "Comments: To appear in Nonlinearity; we sincerely thank the referee for the precious remarks. The ArXiv version is outdated, but we cannot replace it due to copyright reasons. The final author-created, un-copyedited version of this paper is available from the first author's home page",
    "descriptor": "\nComments: To appear in Nonlinearity; we sincerely thank the referee for the precious remarks. The ArXiv version is outdated, but we cannot replace it due to copyright reasons. The final author-created, un-copyedited version of this paper is available from the first author's home page\n",
    "authors": [
      "Giovanni Panti",
      "Davide Sclosa"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Group Theory (math.GR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.16899"
  },
  {
    "id": "arXiv:2007.02227",
    "title": "Solving stochastic optimal control problem via stochastic maximum  principle with deep learning method",
    "abstract": "Solving stochastic optimal control problem via stochastic maximum  principle with deep learning method",
    "descriptor": "",
    "authors": [
      "Shaolin Ji",
      "Shige Peng",
      "Ying Peng",
      "Xichuan Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.02227"
  },
  {
    "id": "arXiv:2007.02730",
    "title": "Refined Analysis of the Asymptotic Complexity of the Number Field Sieve",
    "abstract": "Comments: Accepted for publication in Mathematical Cryptology",
    "descriptor": "\nComments: Accepted for publication in Mathematical Cryptology\n",
    "authors": [
      "Aude Le Gluher",
      "Pierre-Jean Spaenlehauer",
      "Emmanuel Thom\u00e9"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Complexity (cs.CC)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2007.02730"
  },
  {
    "id": "arXiv:2007.04547",
    "title": "An Optimal Uniform Concentration Inequality for Discrete Entropies on  Finite Alphabets in the High-dimensional Setting",
    "abstract": "An Optimal Uniform Concentration Inequality for Discrete Entropies on  Finite Alphabets in the High-dimensional Setting",
    "descriptor": "",
    "authors": [
      "Yunpeng Zhao"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2007.04547"
  },
  {
    "id": "arXiv:2007.10200",
    "title": "Sample, Quantize and Encode: Timely Estimation Over Noisy Channels",
    "abstract": "Comments: Accepted for publication in the IEEE Transactions on Communications. arXiv admin note: substantial text overlap with arXiv:2004.12982",
    "descriptor": "\nComments: Accepted for publication in the IEEE Transactions on Communications. arXiv admin note: substantial text overlap with arXiv:2004.12982\n",
    "authors": [
      "Ahmed Arafa",
      "Karim Banawan",
      "Karim G. Seddik",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2007.10200"
  },
  {
    "id": "arXiv:2008.07404",
    "title": "Skeleton-based Action Recognition via Spatial and Temporal Transformer  Networks",
    "abstract": "Comments: Accepted at Computer Vision and Image Understanding (CVIU) 12 pages, 8 figures",
    "descriptor": "\nComments: Accepted at Computer Vision and Image Understanding (CVIU) 12 pages, 8 figures\n",
    "authors": [
      "Chiara Plizzari",
      "Marco Cannici",
      "Matteo Matteucci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.07404"
  },
  {
    "id": "arXiv:2008.07587",
    "title": "Stochastic Bayesian Neural Networks",
    "abstract": "Comments: There is an error in modelling stochastic process. Hence the results are not correct",
    "descriptor": "\nComments: There is an error in modelling stochastic process. Hence the results are not correct\n",
    "authors": [
      "Abhinav Sagar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.07587"
  },
  {
    "id": "arXiv:2008.07606",
    "title": "Optimal Best-Arm Identification Methods for Tail-Risk Measures",
    "abstract": "Comments: 55 pages, 4 figures",
    "descriptor": "\nComments: 55 pages, 4 figures\n",
    "authors": [
      "Shubhada Agrawal",
      "Wouter M. Koolen",
      "Sandeep Juneja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.07606"
  },
  {
    "id": "arXiv:2008.08652",
    "title": "The Organization of Software Teams in the Quest for Continuous Delivery:  A Grounded Theory Approach",
    "abstract": "Comments: Version accepted for publication in the Information and Software Technology journal (Jun, 2021) / CC-BY-NC-ND license",
    "descriptor": "\nComments: Version accepted for publication in the Information and Software Technology journal (Jun, 2021) / CC-BY-NC-ND license\n",
    "authors": [
      "Leonardo Leite",
      "Gustavo Pinto",
      "Fabio Kon",
      "Paulo Meirelles"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2008.08652"
  },
  {
    "id": "arXiv:2008.10399",
    "title": "Generate High Resolution Images With Generative Variational Autoencoder",
    "abstract": "Comments: The network architecture used in this paper while training the model is not correct",
    "descriptor": "\nComments: The network architecture used in this paper while training the model is not correct\n",
    "authors": [
      "Abhinav Sagar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.10399"
  },
  {
    "id": "arXiv:2008.10875",
    "title": "ETC-NLG: End-to-end Topic-Conditioned Natural Language Generation",
    "abstract": "ETC-NLG: End-to-end Topic-Conditioned Natural Language Generation",
    "descriptor": "",
    "authors": [
      "Ginevra Carbone",
      "Gabriele Sarti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2008.10875"
  },
  {
    "id": "arXiv:2008.12067",
    "title": "Orbit Structure of Grassmannian $G_{2, m}$ and a decoder for Grassmann  code $C(2, m)$",
    "abstract": "Orbit Structure of Grassmannian $G_{2, m}$ and a decoder for Grassmann  code $C(2, m)$",
    "descriptor": "",
    "authors": [
      "Fernando Pi\u00f1ero",
      "Prasant Singh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2008.12067"
  },
  {
    "id": "arXiv:2009.00326",
    "title": "PYCSP3: Modeling Combinatorial Constrained Problems in Python",
    "abstract": "PYCSP3: Modeling Combinatorial Constrained Problems in Python",
    "descriptor": "",
    "authors": [
      "Christophe Lecoutre",
      "Nicolas Szczepanski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.00326"
  },
  {
    "id": "arXiv:2009.09147",
    "title": "Enhancing Dialogue Generation via Multi-Level Contrastive Learning",
    "abstract": "Enhancing Dialogue Generation via Multi-Level Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Xin Li",
      "Piji Li",
      "Yan Wang",
      "Xiaojiang Liu",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.09147"
  },
  {
    "id": "arXiv:2009.10796",
    "title": "Scaling Probe-Based Real-Time Dynamic Global Illumination for Production",
    "abstract": "Comments: Supplemental video: this https URL Journal of Computer Graphics Techniques (published version): this http URL",
    "descriptor": "\nComments: Supplemental video: this https URL Journal of Computer Graphics Techniques (published version): this http URL\n",
    "authors": [
      "Zander Majercik",
      "Adam Marrs",
      "Josef Spjut",
      "Morgan McGuire"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2009.10796"
  },
  {
    "id": "arXiv:2010.00207",
    "title": "Stochastic Optimal Control for Multivariable Dynamical Systems Using  Expectation Maximization",
    "abstract": "Comments: 14 pages, 10 figures",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Prakash Mallick",
      "Zhiyong Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.00207"
  },
  {
    "id": "arXiv:2010.07092",
    "title": "Data Augmentation for Meta-Learning",
    "abstract": "Comments: 15 pages, 3 figures, Accepted to ICML 2021",
    "descriptor": "\nComments: 15 pages, 3 figures, Accepted to ICML 2021\n",
    "authors": [
      "Renkun Ni",
      "Micah Goldblum",
      "Amr Sharaf",
      "Kezhi Kong",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.07092"
  },
  {
    "id": "arXiv:2010.12405",
    "title": "Unsupervised Cross-lingual Adaptation for Sequence Tagging and Beyond",
    "abstract": "Unsupervised Cross-lingual Adaptation for Sequence Tagging and Beyond",
    "descriptor": "",
    "authors": [
      "Xin Li",
      "Lidong Bing",
      "Wenxuan Zhang",
      "Zheng Li",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12405"
  },
  {
    "id": "arXiv:2011.05733",
    "title": "StoqMA meets distribution testing",
    "abstract": "Comments: 24 pages. v2: mostly adds corrections and clarifications. v3: add a connection between eStoqMA and Guided Stoquastic Hamiltonian Problem",
    "descriptor": "\nComments: 24 pages. v2: mostly adds corrections and clarifications. v3: add a connection between eStoqMA and Guided Stoquastic Hamiltonian Problem\n",
    "authors": [
      "Yupan Liu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2011.05733"
  },
  {
    "id": "arXiv:2011.07471",
    "title": "Adversarially Robust and Sliding Window Streaming Algorithms without the  Overhead",
    "abstract": "Adversarially Robust and Sliding Window Streaming Algorithms without the  Overhead",
    "descriptor": "",
    "authors": [
      "David P. Woodruff",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.07471"
  },
  {
    "id": "arXiv:2011.08119",
    "title": "The Longest Run Subsequence Problem: Further Complexity Results",
    "abstract": "Comments: Accepted in CPM 2021",
    "descriptor": "\nComments: Accepted in CPM 2021\n",
    "authors": [
      "Riccardo Dondi",
      "Florian Sikora"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2011.08119"
  },
  {
    "id": "arXiv:2011.12517",
    "title": "Interpretable Signed Link Prediction with Signed Infomax Hyperbolic  Graph",
    "abstract": "Interpretable Signed Link Prediction with Signed Infomax Hyperbolic  Graph",
    "descriptor": "",
    "authors": [
      "Yadan Luo",
      "Zi Huang",
      "Hongxu Chen",
      "Yang Yang",
      "Mahsa Baktashmotlagh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.12517"
  },
  {
    "id": "arXiv:2011.12834",
    "title": "Interpolation and stability properties of low order face and edge  virtual element spaces",
    "abstract": "Interpolation and stability properties of low order face and edge  virtual element spaces",
    "descriptor": "",
    "authors": [
      "Louren\u00e7o Beir\u00e3o da Veiga",
      "Lorenzo Mascotto"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.12834"
  },
  {
    "id": "arXiv:2012.03515",
    "title": "Fine-grained Angular Contrastive Learning with Coarse Labels",
    "abstract": "Fine-grained Angular Contrastive Learning with Coarse Labels",
    "descriptor": "",
    "authors": [
      "Guy Bukchin",
      "Eli Schwartz",
      "Kate Saenko",
      "Ori Shahar",
      "Rogerio Feris",
      "Raja Giryes",
      "Leonid Karlinsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.03515"
  },
  {
    "id": "arXiv:2012.04053",
    "title": "Minimax Regret for Stochastic Shortest Path with Adversarial Costs and  Known Transition",
    "abstract": "Minimax Regret for Stochastic Shortest Path with Adversarial Costs and  Known Transition",
    "descriptor": "",
    "authors": [
      "Liyu Chen",
      "Haipeng Luo",
      "Chen-Yu Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.04053"
  },
  {
    "id": "arXiv:2012.05901",
    "title": "Robust Consistent Video Depth Estimation",
    "abstract": "Comments: Project website: this https URL",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Johannes Kopf",
      "Xuejian Rong",
      "Jia-Bin Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.05901"
  },
  {
    "id": "arXiv:2012.07348",
    "title": "Bandit Learning in Decentralized Matching Markets",
    "abstract": "Comments: 34 pages",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Lydia T. Liu",
      "Feng Ruan",
      "Horia Mania",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.07348"
  },
  {
    "id": "arXiv:2012.08141",
    "title": "AsyncTaichi: On-the-fly Inter-kernel Optimizations for Imperative and  Spatially Sparse Programming",
    "abstract": "Comments: 18 pages, 20 figures, submitted to ACM SIGGRAPH Asia",
    "descriptor": "\nComments: 18 pages, 20 figures, submitted to ACM SIGGRAPH Asia\n",
    "authors": [
      "Yuanming Hu",
      "Mingkuan Xu",
      "Ye Kuang",
      "Fr\u00e9do Durand"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2012.08141"
  },
  {
    "id": "arXiv:2012.09110",
    "title": "Developing Future Human-Centered Smart Cities: Critical Analysis of  Smart City Security, Interpretability, and Ethical Challenges",
    "abstract": "Comments: 33 pages, 13 figures, 8 tables",
    "descriptor": "\nComments: 33 pages, 13 figures, 8 tables\n",
    "authors": [
      "Kashif Ahmad",
      "Majdi Maabreh",
      "Mohamed Ghaly",
      "Khalil Khan",
      "Junaid Qadir",
      "Ala Al-Fuqaha"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.09110"
  },
  {
    "id": "arXiv:2012.09301",
    "title": "Latent-CF: A Simple Baseline for Reverse Counterfactual Explanations",
    "abstract": "Latent-CF: A Simple Baseline for Reverse Counterfactual Explanations",
    "descriptor": "",
    "authors": [
      "Rachana Balasubramanian",
      "Samuel Sharpe",
      "Brian Barr",
      "Jason Wittenbach",
      "C. Bayan Bruss"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.09301"
  },
  {
    "id": "arXiv:2012.09421",
    "title": "Learning Fair Policies in Decentralized Cooperative Multi-Agent  Reinforcement Learning",
    "abstract": "Comments: International Conference on Machine Learning",
    "descriptor": "\nComments: International Conference on Machine Learning\n",
    "authors": [
      "Matthieu Zimmer",
      "Claire Glanois",
      "Umer Siddique",
      "Paul Weng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2012.09421"
  },
  {
    "id": "arXiv:2012.10490",
    "title": "Perception-Based Temporal Logic Planning in Uncertain Semantic Maps",
    "abstract": "Perception-Based Temporal Logic Planning in Uncertain Semantic Maps",
    "descriptor": "",
    "authors": [
      "Yiannis Kantaros",
      "Samarth Kalluraya",
      "Qi Jin",
      "George J. Pappas"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.10490"
  },
  {
    "id": "arXiv:2012.11409",
    "title": "3D Object Detection with Pointformer",
    "abstract": "Comments: Accepted by IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2021. Code is available at this https URL",
    "descriptor": "\nComments: Accepted by IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2021. Code is available at this https URL\n",
    "authors": [
      "Xuran Pan",
      "Zhuofan Xia",
      "Shiji Song",
      "Li Erran Li",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.11409"
  },
  {
    "id": "arXiv:2012.11575",
    "title": "From Points to Multi-Object 3D Reconstruction",
    "abstract": "Comments: CVPR2021 - Project Page: this https URL",
    "descriptor": "\nComments: CVPR2021 - Project Page: this https URL\n",
    "authors": [
      "Francis Engelmann",
      "Konstantinos Rematas",
      "Bastian Leibe",
      "Vittorio Ferrari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.11575"
  },
  {
    "id": "arXiv:2012.13787",
    "title": "Degrees of Freedom of the $K$-User Interference Channel in the Presence  of Intelligent Reflecting Surfaces",
    "abstract": "Degrees of Freedom of the $K$-User Interference Channel in the Presence  of Intelligent Reflecting Surfaces",
    "descriptor": "",
    "authors": [
      "Ali H. Abdollahi Bafghi",
      "Vahid Jamali",
      "Masoumeh Nasiri-Kenari",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.13787"
  },
  {
    "id": "arXiv:2012.15864",
    "title": "EC-GAN: Low-Sample Classification using Semi-Supervised Algorithms and  GANs",
    "abstract": "Comments: AAAI 2021; 7 pages, 7 figures, 2 tables",
    "descriptor": "\nComments: AAAI 2021; 7 pages, 7 figures, 2 tables\n",
    "authors": [
      "Ayaan Haque"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.15864"
  },
  {
    "id": "arXiv:2101.03355",
    "title": "Downlink SCMA Codebook Design with Low Error Rate by Maximizing Minimum  Euclidean Distance of Superimposed Codewords",
    "abstract": "Comments: 15 pages, 12 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 15 pages, 12 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Chinwei Huang",
      "Borching Su",
      "Tingyi Lin",
      "Yenming Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2101.03355"
  },
  {
    "id": "arXiv:2101.06197",
    "title": "Deciding What to Learn: A Rate-Distortion Approach",
    "abstract": "Deciding What to Learn: A Rate-Distortion Approach",
    "descriptor": "",
    "authors": [
      "Dilip Arumugam",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.06197"
  },
  {
    "id": "arXiv:2101.08293",
    "title": "What is all this new MeSH about? Exploring the semantic provenance of  new descriptors in the MeSH thesaurus",
    "abstract": "Comments: 18 pages, 14 figures, 2 tables",
    "descriptor": "\nComments: 18 pages, 14 figures, 2 tables\n",
    "authors": [
      "Anastasios Nentidis",
      "Anastasia Krithara",
      "Grigorios Tsoumakas",
      "Georgios Paliouras"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2101.08293"
  },
  {
    "id": "arXiv:2101.08940",
    "title": "Hessian-Aware Pruning and Optimal Neural Implant",
    "abstract": "Hessian-Aware Pruning and Optimal Neural Implant",
    "descriptor": "",
    "authors": [
      "Shixing Yu",
      "Zhewei Yao",
      "Amir Gholami",
      "Zhen Dong",
      "Sehoon Kim",
      "Michael W Mahoney",
      "Kurt Keutzer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.08940"
  },
  {
    "id": "arXiv:2101.10763",
    "title": "Benchmarking Invertible Architectures on Inverse Problems",
    "abstract": "Benchmarking Invertible Architectures on Inverse Problems",
    "descriptor": "",
    "authors": [
      "Jakob Kruse",
      "Lynton Ardizzone",
      "Carsten Rother",
      "Ullrich K\u00f6the"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.10763"
  },
  {
    "id": "arXiv:2101.11058",
    "title": "Supervised Momentum Contrastive Learning for Few-Shot Classification",
    "abstract": "Comments: V2 version; updated with new experiments and figures",
    "descriptor": "\nComments: V2 version; updated with new experiments and figures\n",
    "authors": [
      "Orchid Majumder",
      "Avinash Ravichandran",
      "Subhransu Maji",
      "Alessandro Achille",
      "Marzia Polito",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.11058"
  },
  {
    "id": "arXiv:2101.11453",
    "title": "Meta Adversarial Training against Universal Patches",
    "abstract": "Comments: Accepted by the ICML 2021 workshop on \"A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning\"",
    "descriptor": "\nComments: Accepted by the ICML 2021 workshop on \"A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning\"\n",
    "authors": [
      "Jan Hendrik Metzen",
      "Nicole Finnie",
      "Robin Hutmacher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.11453"
  },
  {
    "id": "arXiv:2102.00218",
    "title": "Estimating the Unique Information of Continuous Variables in Recurrent  Networks",
    "abstract": "Estimating the Unique Information of Continuous Variables in Recurrent  Networks",
    "descriptor": "",
    "authors": [
      "Ari Pakman",
      "Amin Nejatbakhsh",
      "Dar Gilboa",
      "Abdullah Makkeh",
      "Michael Wibral",
      "Elad Schneidman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2102.00218"
  },
  {
    "id": "arXiv:2102.01046",
    "title": "Impossible Tuning Made Possible: A New Expert Algorithm and Its  Applications",
    "abstract": "Impossible Tuning Made Possible: A New Expert Algorithm and Its  Applications",
    "descriptor": "",
    "authors": [
      "Liyu Chen",
      "Haipeng Luo",
      "Chen-Yu Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2102.01046"
  },
  {
    "id": "arXiv:2102.03796",
    "title": "Brain-computer interface with rapid serial multimodal presentation using  artificial facial images and voice",
    "abstract": "Brain-computer interface with rapid serial multimodal presentation using  artificial facial images and voice",
    "descriptor": "",
    "authors": [
      "Akinari Onishi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2102.03796"
  },
  {
    "id": "arXiv:2102.04062",
    "title": "An Update of a Progressively Expanded Database for Automated Lung Sound  Analysis",
    "abstract": "Comments: Under review, 8 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: Under review, 8 pages, 5 figures, 3 tables\n",
    "authors": [
      "Fu-Shun Hsu",
      "Shang-Ran Huang",
      "Chien-Wen Huang",
      "Yuan-Ren Cheng",
      "Chun-Chieh Chen",
      "Jack Hsiao",
      "Chung-Wei Chen",
      "Feipei Lai"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2102.04062"
  },
  {
    "id": "arXiv:2102.04075",
    "title": "Fast and Reliable Probabilistic Face Embeddings in the Wild",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Kai Chen",
      "Qi Lv",
      "Taihe Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.04075"
  },
  {
    "id": "arXiv:2102.04279",
    "title": "Constrained Ensemble Langevin Monte Carlo",
    "abstract": "Constrained Ensemble Langevin Monte Carlo",
    "descriptor": "",
    "authors": [
      "Zhiyan Ding",
      "Qin Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.04279"
  },
  {
    "id": "arXiv:2102.04909",
    "title": "Best-of-Both-Worlds Fair-Share Allocations",
    "abstract": "Best-of-Both-Worlds Fair-Share Allocations",
    "descriptor": "",
    "authors": [
      "Moshe Babaioff",
      "Tomer Ezra",
      "Uriel Feige"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2102.04909"
  },
  {
    "id": "arXiv:2102.07810",
    "title": "HDMI: High-order Deep Multiplex Infomax",
    "abstract": "Comments: Accepted by WWW'2021 Updated section 3.1.1",
    "descriptor": "\nComments: Accepted by WWW'2021 Updated section 3.1.1\n",
    "authors": [
      "Baoyu Jing",
      "Chanyoung Park",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2102.07810"
  },
  {
    "id": "arXiv:2102.09427",
    "title": "Deep Learning for Suicide and Depression Identification with  Unsupervised Label Correction",
    "abstract": "Comments: ICANN 2021; First two authors contributed equally",
    "descriptor": "\nComments: ICANN 2021; First two authors contributed equally\n",
    "authors": [
      "Ayaan Haque",
      "Viraaj Reddi",
      "Tyler Giallanza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09427"
  },
  {
    "id": "arXiv:2102.10092",
    "title": "$\\mathcal{S}$-adic characterization of minimal ternary dendric shifts",
    "abstract": "Comments: 40 pages",
    "descriptor": "\nComments: 40 pages\n",
    "authors": [
      "France Gheeraert",
      "Marie Lejeune",
      "Julien Leroy"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2102.10092"
  },
  {
    "id": "arXiv:2102.11509",
    "title": "Performance Improvement of LoRa Modulation with Signal Combining and  Semi-Coherent Detection",
    "abstract": "Comments: The paper is accepted for publications in IEEE Communications Letters",
    "descriptor": "\nComments: The paper is accepted for publications in IEEE Communications Letters\n",
    "authors": [
      "Khai Nguyen",
      "Ha H. Nguyen",
      "Ebrahim Bedeer"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.11509"
  },
  {
    "id": "arXiv:2102.12319",
    "title": "GEM: Glare or Gloom, I Can Still See You -- End-to-End Multimodal Object  Detection",
    "abstract": "Comments: IEEE Robotics and Automation Letters (RA-L)",
    "descriptor": "\nComments: IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Osama Mazhar",
      "Robert Babuska",
      "Jens Kober"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.12319"
  },
  {
    "id": "arXiv:2102.12801",
    "title": "The Role of Correlation in the Doubly Dirty Fading MAC with Side  Information at the Transmitters",
    "abstract": "The Role of Correlation in the Doubly Dirty Fading MAC with Side  Information at the Transmitters",
    "descriptor": "",
    "authors": [
      "Farshad Rostami Ghadi",
      "Ghosheh Abed Hodtani",
      "F. Javier Lopez-Martinez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.12801"
  },
  {
    "id": "arXiv:2102.13307",
    "title": "Potential Impacts of Smart Homes on Human Behavior: A Reinforcement  Learning Approach",
    "abstract": "Potential Impacts of Smart Homes on Human Behavior: A Reinforcement  Learning Approach",
    "descriptor": "",
    "authors": [
      "Shashi Suman",
      "Ali Etemad",
      "Francois Rivest"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.13307"
  },
  {
    "id": "arXiv:2103.01396",
    "title": "DeepReDuce: ReLU Reduction for Fast Private Inference",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Nandan Kumar Jha",
      "Zahra Ghodsi",
      "Siddharth Garg",
      "Brandon Reagen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.01396"
  },
  {
    "id": "arXiv:2103.03335",
    "title": "A Systematic Evaluation of Transfer Learning and Pseudo-labeling with  BERT-based Ranking Models",
    "abstract": "A Systematic Evaluation of Transfer Learning and Pseudo-labeling with  BERT-based Ranking Models",
    "descriptor": "",
    "authors": [
      "Iurii Mokrii",
      "Leonid Boytsov",
      "Pavel Braslavski"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.03335"
  },
  {
    "id": "arXiv:2103.03375",
    "title": "Nutrition5k: Towards Automatic Nutritional Understanding of Generic Food",
    "abstract": "Comments: 8 pages, 3 of appendices. CVPR 2021",
    "descriptor": "\nComments: 8 pages, 3 of appendices. CVPR 2021\n",
    "authors": [
      "Quin Thames",
      "Arjun Karpur",
      "Wade Norris",
      "Fangting Xia",
      "Liviu Panait",
      "Tobias Weyand",
      "Jack Sim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.03375"
  },
  {
    "id": "arXiv:2103.04955",
    "title": "Threshold-based Network Structural Dynamics",
    "abstract": "Comments: 29 pages, extension of the Post-print containing all proofs, to appear in SIROCCO 2021",
    "descriptor": "\nComments: 29 pages, extension of the Post-print containing all proofs, to appear in SIROCCO 2021\n",
    "authors": [
      "Evangelos Kipouridis",
      "Paul G. Spirakis",
      "Kostas Tsichlas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2103.04955"
  },
  {
    "id": "arXiv:2103.05788",
    "title": "Selling Data to an Agent with Endogenous Information",
    "abstract": "Selling Data to an Agent with Endogenous Information",
    "descriptor": "",
    "authors": [
      "Yingkai Li"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2103.05788"
  },
  {
    "id": "arXiv:2103.06671",
    "title": "Sample Complexity of Offline Reinforcement Learning with Deep ReLU  Networks",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Thanh Nguyen-Tang",
      "Sunil Gupta",
      "Hung Tran-The",
      "Svetha Venkatesh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06671"
  },
  {
    "id": "arXiv:2103.07609",
    "title": "Untrained networks for compressive lensless photography",
    "abstract": "Comments: 17 pages, 8 figures",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Kristina Monakhova",
      "Vi Tran",
      "Grace Kuo",
      "Laura Waller"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2103.07609"
  },
  {
    "id": "arXiv:2103.08067",
    "title": "Quasi-Equivalence Discovery for Zero-Shot Emergent Communication",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Kalesha Bullard",
      "Douwe Kiela",
      "Franziska Meier",
      "Joelle Pineau",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.08067"
  },
  {
    "id": "arXiv:2103.08533",
    "title": "Lasry-Lions Envelopes and Nonconvex Optimization: A Homotopy Approach",
    "abstract": "Comments: 29th Eur. Signal Process. Conf. (EUSIPCO 2021), accepted. 5 pages, 2 figures, 2 tables",
    "descriptor": "\nComments: 29th Eur. Signal Process. Conf. (EUSIPCO 2021), accepted. 5 pages, 2 figures, 2 tables\n",
    "authors": [
      "Miguel Sim\u00f5es",
      "Andreas Themelis",
      "Panagiotis Patrinos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.08533"
  },
  {
    "id": "arXiv:2103.08666",
    "title": "Spline quadrature and semi-classical orthogonal Jacobi polynomials",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Helmut Ruhland"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.08666"
  },
  {
    "id": "arXiv:2103.08902",
    "title": "Differentiable Learning Under Triage",
    "abstract": "Differentiable Learning Under Triage",
    "descriptor": "",
    "authors": [
      "Nastaran Okati",
      "Abir De",
      "Manuel Gomez-Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.08902"
  },
  {
    "id": "arXiv:2103.09171",
    "title": "Interpretable Deep Learning for the Remote Characterisation of  Ambulation in Multiple Sclerosis using Smartphones",
    "abstract": "Interpretable Deep Learning for the Remote Characterisation of  Ambulation in Multiple Sclerosis using Smartphones",
    "descriptor": "",
    "authors": [
      "Andrew P. Creagh",
      "Florian Lipsmeier",
      "Michael Lindemann",
      "Maarten De Vos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2103.09171"
  },
  {
    "id": "arXiv:2103.09430",
    "title": "OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs",
    "abstract": "Comments: KDD Cup 2021: this https URL",
    "descriptor": "\nComments: KDD Cup 2021: this https URL\n",
    "authors": [
      "Weihua Hu",
      "Matthias Fey",
      "Hongyu Ren",
      "Maho Nakata",
      "Yuxiao Dong",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.09430"
  },
  {
    "id": "arXiv:2103.10201",
    "title": "The impact of using biased performance metrics on software defect  prediction research",
    "abstract": "Comments: Accepted by the journal Information & Software Technology. It is a greatly extended version of \"Assessing Software Defection Prediction Performance: Why Using the Matthews Correlation Coefficient Matters\" presented at EASE 2020",
    "descriptor": "\nComments: Accepted by the journal Information & Software Technology. It is a greatly extended version of \"Assessing Software Defection Prediction Performance: Why Using the Matthews Correlation Coefficient Matters\" presented at EASE 2020\n",
    "authors": [
      "Jingxiu Yao",
      "Martin Shepperd"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10201"
  },
  {
    "id": "arXiv:2103.11351",
    "title": "Cross-Dataset Collaborative Learning for Semantic Segmentation",
    "abstract": "Cross-Dataset Collaborative Learning for Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Li Wang",
      "Dong Li",
      "Yousong Zhu",
      "Lu Tian",
      "Yi Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11351"
  },
  {
    "id": "arXiv:2103.12998",
    "title": "Including Sparse Production Knowledge into Variational Autoencoders to  Increase Anomaly Detection Reliability",
    "abstract": "Including Sparse Production Knowledge into Variational Autoencoders to  Increase Anomaly Detection Reliability",
    "descriptor": "",
    "authors": [
      "Tom Hammerbacher",
      "Markus Lange-Hegermann",
      "Gorden Platz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.12998"
  },
  {
    "id": "arXiv:2103.13028",
    "title": "Lightweight Image Super-Resolution with Multi-scale Feature Interaction  Network",
    "abstract": "Comments: ICME2021, this https URL",
    "descriptor": "\nComments: ICME2021, this https URL\n",
    "authors": [
      "Zhengxue Wang",
      "Guangwei Gao",
      "Juncheng Li",
      "Yi Yu",
      "Huimin Lu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.13028"
  },
  {
    "id": "arXiv:2103.13346",
    "title": "Information Freshness Analysis of Slotted ALOHA in Gilbert-Elliot  Channels",
    "abstract": "Information Freshness Analysis of Slotted ALOHA in Gilbert-Elliot  Channels",
    "descriptor": "",
    "authors": [
      "Andrea Munari",
      "Gianluigi Liva"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2103.13346"
  },
  {
    "id": "arXiv:2103.13630",
    "title": "A Survey of Quantization Methods for Efficient Neural Network Inference",
    "abstract": "Comments: Book Chapter: Low-Power Computer Vision: Improving the Efficiency of Artificial Intelligence",
    "descriptor": "\nComments: Book Chapter: Low-Power Computer Vision: Improving the Efficiency of Artificial Intelligence\n",
    "authors": [
      "Amir Gholami",
      "Sehoon Kim",
      "Zhen Dong",
      "Zhewei Yao",
      "Michael W. Mahoney",
      "Kurt Keutzer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.13630"
  },
  {
    "id": "arXiv:2103.14602",
    "title": "Data Quality as Predictor of Voice Anti-Spoofing Generalization",
    "abstract": "Comments: INTERSPEECH 2021",
    "descriptor": "\nComments: INTERSPEECH 2021\n",
    "authors": [
      "Bhusan Chettri",
      "Rosa Gonz\u00e1lez Hautam\u00e4ki",
      "Md Sahidullah",
      "Tomi Kinnunen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2103.14602"
  },
  {
    "id": "arXiv:2103.15208",
    "title": "Unified Shape and SVBRDF Recovery using Differentiable Monte Carlo  Rendering",
    "abstract": "Unified Shape and SVBRDF Recovery using Differentiable Monte Carlo  Rendering",
    "descriptor": "",
    "authors": [
      "Fujun Luan",
      "Shuang Zhao",
      "Kavita Bala",
      "Zhao Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15208"
  },
  {
    "id": "arXiv:2103.15851",
    "title": "Distilled Replay: Overcoming Forgetting through Synthetic Samples",
    "abstract": "Distilled Replay: Overcoming Forgetting through Synthetic Samples",
    "descriptor": "",
    "authors": [
      "Andrea Rosasco",
      "Antonio Carta",
      "Andrea Cossu",
      "Vincenzo Lomonaco",
      "Davide Bacciu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.15851"
  },
  {
    "id": "arXiv:2103.17132",
    "title": "Empirically explaining SGD from a line search perspective",
    "abstract": "Comments: Empirical Analysis , Optimization, Line Search, SGD",
    "descriptor": "\nComments: Empirical Analysis , Optimization, Line Search, SGD\n",
    "authors": [
      "Maximus Mutschler",
      "Andreas Zell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.17132"
  },
  {
    "id": "arXiv:2103.17228",
    "title": "OLIVAW: Mastering Othello with neither Humans nor a Penny",
    "abstract": "Comments: Presented at AAAI-21 Reinforcement Learning in Games Workshop, 7 pages, 6 figures",
    "descriptor": "\nComments: Presented at AAAI-21 Reinforcement Learning in Games Workshop, 7 pages, 6 figures\n",
    "authors": [
      "Antonio Norelli",
      "Alessandro Panconesi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.17228"
  },
  {
    "id": "arXiv:2104.04757",
    "title": "Adversarially-Trained Nonnegative Matrix Factorization",
    "abstract": "Comments: Accepted to the IEEE Signal Processing Letters; 5 pages, 4 figures",
    "descriptor": "\nComments: Accepted to the IEEE Signal Processing Letters; 5 pages, 4 figures\n",
    "authors": [
      "Ting Cai",
      "Vincent Y. F. Tan",
      "C\u00e9dric F\u00e9votte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.04757"
  },
  {
    "id": "arXiv:2104.04846",
    "title": "Coherence and Plausibility, not Presence?! Pivotal Conditions for XR  Experiences and Effects, a Novel Model",
    "abstract": "Comments: 10 pages,2 figures",
    "descriptor": "\nComments: 10 pages,2 figures\n",
    "authors": [
      "Marc Erich Latoschik",
      "Carolin Wienrich"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2104.04846"
  },
  {
    "id": "arXiv:2104.07406",
    "title": "A systematic review of Python packages for time series analysis",
    "abstract": "Comments: 12 pages, 3 figures, 4 tables, accepted to ITISE2021",
    "descriptor": "\nComments: 12 pages, 3 figures, 4 tables, accepted to ITISE2021\n",
    "authors": [
      "Julien Siebert",
      "Janek Gro\u00df",
      "Christof Schroth"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2104.07406"
  },
  {
    "id": "arXiv:2104.07696",
    "title": "The Immersion and Invariance Wind Speed Estimator Revisited and New  Results",
    "abstract": "Comments: IEEE Control Systems Letters (L-CSS)",
    "descriptor": "\nComments: IEEE Control Systems Letters (L-CSS)\n",
    "authors": [
      "Yichao Liu",
      "Atindriyo Kusumo Pamososuryo",
      "Riccardo M.G. Ferrari",
      "Jan-Willem van Wingerden"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.07696"
  },
  {
    "id": "arXiv:2104.08006",
    "title": "ProphetNet-X: Large-Scale Pre-training Models for English, Chinese,  Multi-lingual, Dialog, and Code Generation",
    "abstract": "Comments: Accepted by ACL 2021 demo papers",
    "descriptor": "\nComments: Accepted by ACL 2021 demo papers\n",
    "authors": [
      "Weizhen Qi",
      "Yeyun Gong",
      "Yu Yan",
      "Can Xu",
      "Bolun Yao",
      "Bartuer Zhou",
      "Biao Cheng",
      "Daxin Jiang",
      "Jiusheng Chen",
      "Ruofei Zhang",
      "Houqiang Li",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08006"
  },
  {
    "id": "arXiv:2104.08653",
    "title": "IITP@COLIEE 2019: Legal Information Retrieval using BM25 and BERT",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Baban Gain",
      "Dibyanayan Bandyopadhyay",
      "Tanik Saikh",
      "Asif Ekbal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2104.08653"
  },
  {
    "id": "arXiv:2104.08760",
    "title": "Towards Solving Inefficiency of Self-supervised Representation Learning",
    "abstract": "Comments: 12 pages, 5 figures, 8 tables",
    "descriptor": "\nComments: 12 pages, 5 figures, 8 tables\n",
    "authors": [
      "Guangrun Wang",
      "Keze Wang",
      "Guangcong Wang",
      "Philip H.S. Torr",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08760"
  },
  {
    "id": "arXiv:2104.10809",
    "title": "Provable Limitations of Acquiring Meaning from Ungrounded Form: What  Will Future Language Models Understand?",
    "abstract": "Comments: Updated 06/22/21 with substantive changes. Accepted at TACL; pre-MIT Press publication version",
    "descriptor": "\nComments: Updated 06/22/21 with substantive changes. Accepted at TACL; pre-MIT Press publication version\n",
    "authors": [
      "William Merrill",
      "Yoav Goldberg",
      "Roy Schwartz",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.10809"
  },
  {
    "id": "arXiv:2104.11946",
    "title": "Aligned Contrastive Predictive Coding",
    "abstract": "Comments: Published in Interspeech 2021",
    "descriptor": "\nComments: Published in Interspeech 2021\n",
    "authors": [
      "Jan Chorowski",
      "Grzegorz Ciesielski",
      "Jaros\u0142aw Dzikowski",
      "Adrian \u0141a\u0144cucki",
      "Ricard Marxer",
      "Mateusz Opala",
      "Piotr Pusz",
      "Pawe\u0142 Rychlikowski",
      "Micha\u0142 Stypu\u0142kowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.11946"
  },
  {
    "id": "arXiv:2104.12492",
    "title": "Simulation Modelling and Analysis of Primary Health Centre Operations",
    "abstract": "Simulation Modelling and Analysis of Primary Health Centre Operations",
    "descriptor": "",
    "authors": [
      "Mohd Shoaib",
      "Varun Ramamohan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2104.12492"
  },
  {
    "id": "arXiv:2105.00401",
    "title": "Generation and frame characteristics of predefined evenly-distributed  class centroids for pattern classification",
    "abstract": "Generation and frame characteristics of predefined evenly-distributed  class centroids for pattern classification",
    "descriptor": "",
    "authors": [
      "Haiping Hu",
      "Yingying Yan",
      "Qiuyu Zhu",
      "Guohui Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.00401"
  },
  {
    "id": "arXiv:2105.02062",
    "title": "Understanding Long Range Memory Effects in Deep Neural Networks",
    "abstract": "Comments: Due to a bug in the code, we've wrongly concluded that stochastic gradient noise (SGN) exhibits long-range memory effects. Instead, it exhibits short-range memory effects",
    "descriptor": "\nComments: Due to a bug in the code, we've wrongly concluded that stochastic gradient noise (SGN) exhibits long-range memory effects. Instead, it exhibits short-range memory effects\n",
    "authors": [
      "Chengli Tan",
      "Jiangshe Zhang",
      "Junmin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.02062"
  },
  {
    "id": "arXiv:2105.03279",
    "title": "Generating abstractive summaries of Lithuanian news articles using a  transformer model",
    "abstract": "Comments: Accepted in ICIST 2021",
    "descriptor": "\nComments: Accepted in ICIST 2021\n",
    "authors": [
      "Lukas Stankevi\u010dius",
      "Mantas Luko\u0161evi\u010dius"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03279"
  },
  {
    "id": "arXiv:2105.04848",
    "title": "Forecast Analysis of the COVID-19 Incidence in Lebanon: Prediction of  Future Epidemiological Trends to Plan More Effective Control Programs",
    "abstract": "Forecast Analysis of the COVID-19 Incidence in Lebanon: Prediction of  Future Epidemiological Trends to Plan More Effective Control Programs",
    "descriptor": "",
    "authors": [
      "Salah El Falou",
      "Fouad Trad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.04848"
  },
  {
    "id": "arXiv:2105.04916",
    "title": "Pruning of Deep Spiking Neural Networks through Gradient Rewiring",
    "abstract": "Comments: 9 pages, 7 figures, 4 tables. To appear in the 30th International Joint Conference on Artificial Intelligence (IJCAI 2021)",
    "descriptor": "\nComments: 9 pages, 7 figures, 4 tables. To appear in the 30th International Joint Conference on Artificial Intelligence (IJCAI 2021)\n",
    "authors": [
      "Yanqi Chen",
      "Zhaofei Yu",
      "Wei Fang",
      "Tiejun Huang",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04916"
  },
  {
    "id": "arXiv:2105.07467",
    "title": "Focus U-Net: A novel dual attention-gated CNN for polyp segmentation  during colonoscopy",
    "abstract": "Focus U-Net: A novel dual attention-gated CNN for polyp segmentation  during colonoscopy",
    "descriptor": "",
    "authors": [
      "Michael Yeung",
      "Evis Sala",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Leonardo Rundo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.07467"
  },
  {
    "id": "arXiv:2105.09266",
    "title": "Copyright in Generative Deep Learning",
    "abstract": "Comments: 11 pages. New version contains updates after entry into force of EU's directive on copyright in the Digital Single Market, and corrections of typos",
    "descriptor": "\nComments: 11 pages. New version contains updates after entry into force of EU's directive on copyright in the Digital Single Market, and corrections of typos\n",
    "authors": [
      "Giorgio Franceschelli",
      "Mirco Musolesi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09266"
  },
  {
    "id": "arXiv:2105.10793",
    "title": "GOO: A Dataset for Gaze Object Prediction in Retail Environments",
    "abstract": "Comments: CVPR 20201 Workshop on Gaze Estimation and Prediction in the Wild (GAZE 2021)",
    "descriptor": "\nComments: CVPR 20201 Workshop on Gaze Estimation and Prediction in the Wild (GAZE 2021)\n",
    "authors": [
      "Henri Tomas",
      "Marcus Reyes",
      "Raimarc Dionido",
      "Mark Ty",
      "Jonric Mirando",
      "Joel Casimiro",
      "Rowel Atienza",
      "Richard Guinto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.10793"
  },
  {
    "id": "arXiv:2105.10880",
    "title": "RtFPS: An Interactive Map that Visualizes and Predicts Wildfires in the  US",
    "abstract": "Comments: Source code: this https URL",
    "descriptor": "\nComments: Source code: this https URL\n",
    "authors": [
      "Yang Li",
      "Hermawan Mulyono",
      "Ying Chen",
      "Zhiyin Lu",
      "Desmond Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.10880"
  },
  {
    "id": "arXiv:2105.13132",
    "title": "Enhance Multimodal Model Performance with Data Augmentation: Facebook  Hateful Meme Challenge Solution",
    "abstract": "Comments: Our code is available at: this https URL",
    "descriptor": "\nComments: Our code is available at: this https URL\n",
    "authors": [
      "Yang Li",
      "Zinc Zhang",
      "Hutchin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.13132"
  },
  {
    "id": "arXiv:2105.13945",
    "title": "Quantum Optimisation of Complex Systems with a Quantum Annealer",
    "abstract": "Comments: 24 pages, 19 figures, V3 (fixed typo on page 5)",
    "descriptor": "\nComments: 24 pages, 19 figures, V3 (fixed typo on page 5)\n",
    "authors": [
      "Steve Abel",
      "Andrew Blance",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.13945"
  },
  {
    "id": "arXiv:2105.13961",
    "title": "A Study about the Knowledge and Use of Requirements Engineering  Standards in Industry",
    "abstract": "Comments: Preprint accepted for publication at IEEE Transactions on Software Engineering. Latest update: Several smaller corrections along the creation of the final CR version of the manuscript",
    "descriptor": "\nComments: Preprint accepted for publication at IEEE Transactions on Software Engineering. Latest update: Several smaller corrections along the creation of the final CR version of the manuscript\n",
    "authors": [
      "Xavier Franch",
      "Martin Glinz",
      "Daniel Mendez",
      "Norbert Seyff"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.13961"
  },
  {
    "id": "arXiv:2105.14240",
    "title": "Analysis and Applications of Class-wise Robustness in Adversarial  Training",
    "abstract": "Analysis and Applications of Class-wise Robustness in Adversarial  Training",
    "descriptor": "",
    "authors": [
      "Qi Tian",
      "Kun Kuang",
      "Kelu Jiang",
      "Fei Wu",
      "Yisen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14240"
  },
  {
    "id": "arXiv:2105.14259",
    "title": "Detecting Backdoor in Deep Neural Networks via Intentional Adversarial  Perturbations",
    "abstract": "Detecting Backdoor in Deep Neural Networks via Intentional Adversarial  Perturbations",
    "descriptor": "",
    "authors": [
      "Mingfu Xue",
      "Yinghao Wu",
      "Zhiyu Wu",
      "Yushu Zhang",
      "Jian Wang",
      "Weiqiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14259"
  },
  {
    "id": "arXiv:2105.14536",
    "title": "On the Lagrangian-Eulerian Coupling in the Immersed Finite  Element/Difference Method",
    "abstract": "On the Lagrangian-Eulerian Coupling in the Immersed Finite  Element/Difference Method",
    "descriptor": "",
    "authors": [
      "Jae H. Lee",
      "Boyce E. Griffith"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14536"
  },
  {
    "id": "arXiv:2105.14707",
    "title": "Emergence and algorithmic information dynamics of systems and observers",
    "abstract": "Emergence and algorithmic information dynamics of systems and observers",
    "descriptor": "",
    "authors": [
      "Felipe S. Abrah\u00e3o",
      "Hector Zenil"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.14707"
  },
  {
    "id": "arXiv:2106.00197",
    "title": "Multilingual Speech Translation with Unified Transformer: Huawei Noah's  Ark Lab at IWSLT 2021",
    "abstract": "Comments: IWSLT 2021",
    "descriptor": "\nComments: IWSLT 2021\n",
    "authors": [
      "Xingshan Zeng",
      "Liangyou Li",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00197"
  },
  {
    "id": "arXiv:2106.00285",
    "title": "Shapley Counterfactual Credits for Multi-Agent Reinforcement Learning",
    "abstract": "Shapley Counterfactual Credits for Multi-Agent Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Jiahui Li",
      "Kun Kuang",
      "Baoxiang Wang",
      "Furui Liu",
      "Long Chen",
      "Fei Wu",
      "Jun Xiao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.00285"
  },
  {
    "id": "arXiv:2106.00583",
    "title": "Triggerflow: Trigger-based Orchestration of Serverless Workflows",
    "abstract": "Comments: 17 pages, 17 figures, preprint submitted to Future Generation Computer Systems. arXiv admin note: substantial text overlap with arXiv:2006.08654",
    "descriptor": "\nComments: 17 pages, 17 figures, preprint submitted to Future Generation Computer Systems. arXiv admin note: substantial text overlap with arXiv:2006.08654\n",
    "authors": [
      "Aitor Arjona",
      "Pedro Garc\u00eda-L\u00f3pez",
      "Josep Samp\u00e9",
      "Aleksander Slominski",
      "Lionel Villard"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.00583"
  },
  {
    "id": "arXiv:2106.01033",
    "title": "Who Blames or Endorses Whom? Entity-to-Entity Directed Sentiment  Extraction in News Text",
    "abstract": "Comments: Published in Findings of ACL 2021 (Long paper). The manuscript is slightly revised after the camera ready version",
    "descriptor": "\nComments: Published in Findings of ACL 2021 (Long paper). The manuscript is slightly revised after the camera ready version\n",
    "authors": [
      "Kunwoo Park",
      "Zhufeng Pan",
      "Jungseock Joo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.01033"
  },
  {
    "id": "arXiv:2106.02601",
    "title": "Learning Hard Optimization Problems: A Data Generation Perspective",
    "abstract": "Learning Hard Optimization Problems: A Data Generation Perspective",
    "descriptor": "",
    "authors": [
      "James Kotary",
      "Ferdinando Fioretto",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02601"
  },
  {
    "id": "arXiv:2106.02638",
    "title": "Associating Objects with Transformers for Video Object Segmentation",
    "abstract": "Comments: 18 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: 18 pages, 9 figures, 5 tables\n",
    "authors": [
      "Zongxin Yang",
      "Yunchao Wei",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02638"
  },
  {
    "id": "arXiv:2106.02812",
    "title": "Optimizing Ansatz Design in QAOA for Max-cut",
    "abstract": "Comments: 14 pages; single column (without reference)",
    "descriptor": "\nComments: 14 pages; single column (without reference)\n",
    "authors": [
      "Ritajit Majumdar",
      "Dhiraj Madan",
      "Debasmita Bhoumik",
      "Dhinakaran Vinayagamurthy",
      "Shesha Raghunathan",
      "Susmita Sur-Kolay"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.02812"
  },
  {
    "id": "arXiv:2106.04512",
    "title": "Formal Verification of a Map Merging Protocol in the Multi-Agent  Programming Contest",
    "abstract": "Comments: EMAS 2021 Proceedings Submitted Version",
    "descriptor": "\nComments: EMAS 2021 Proceedings Submitted Version\n",
    "authors": [
      "Matt Luckcuck",
      "Rafael C. Cardoso"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.04512"
  },
  {
    "id": "arXiv:2106.05009",
    "title": "Network insensitivity to parameter noise via adversarial regularization",
    "abstract": "Network insensitivity to parameter noise via adversarial regularization",
    "descriptor": "",
    "authors": [
      "Julian B\u00fcchel",
      "Fynn Faber",
      "Dylan R. Muir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05009"
  },
  {
    "id": "arXiv:2106.05115",
    "title": "Convergence of the EBT method for a non-local model of cell  proliferation with discontinuous interaction kernel",
    "abstract": "Convergence of the EBT method for a non-local model of cell  proliferation with discontinuous interaction kernel",
    "descriptor": "",
    "authors": [
      "Piotr Gwiazda",
      "B\u0142a\u017cej Miasojedow",
      "Jakub Skrzeczkowski",
      "Zuzanna Szyma\u0144ska"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.05115"
  },
  {
    "id": "arXiv:2106.05522",
    "title": "A Mathematical Foundation for Robust Machine Learning based on  Bias-Variance Trade-off",
    "abstract": "A Mathematical Foundation for Robust Machine Learning based on  Bias-Variance Trade-off",
    "descriptor": "",
    "authors": [
      "Ou Wu",
      "Weiyao Zhu",
      "Yingjun Deng",
      "Haixiang Zhang",
      "Qinghu Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05522"
  },
  {
    "id": "arXiv:2106.05544",
    "title": "CogAlign: Learning to Align Textual Neural Representations to Cognitive  Language Processing Signals",
    "abstract": "CogAlign: Learning to Align Textual Neural Representations to Cognitive  Language Processing Signals",
    "descriptor": "",
    "authors": [
      "Yuqi Ren",
      "Deyi Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.05544"
  },
  {
    "id": "arXiv:2106.06087",
    "title": "Causal Analysis of Syntactic Agreement Mechanisms in Neural Language  Models",
    "abstract": "Comments: Accepted to ACL-IJCNLP 2021",
    "descriptor": "\nComments: Accepted to ACL-IJCNLP 2021\n",
    "authors": [
      "Matthew Finlayson",
      "Aaron Mueller",
      "Sebastian Gehrmann",
      "Stuart Shieber",
      "Tal Linzen",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06087"
  },
  {
    "id": "arXiv:2106.06385",
    "title": "Deep Conditional Gaussian Mixture Model for Constrained Clustering",
    "abstract": "Deep Conditional Gaussian Mixture Model for Constrained Clustering",
    "descriptor": "",
    "authors": [
      "Laura Manduchi",
      "Kieran Chin-Cheong",
      "Holger Michel",
      "Sven Wellmann",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06385"
  },
  {
    "id": "arXiv:2106.06499",
    "title": "Policy Gradient Bayesian Robust Optimization for Imitation Learning",
    "abstract": "Comments: In proceedings of the International Conference on Machine Learning (ICML) 2021",
    "descriptor": "\nComments: In proceedings of the International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Zaynah Javed",
      "Daniel S. Brown",
      "Satvik Sharma",
      "Jerry Zhu",
      "Ashwin Balakrishna",
      "Marek Petrik",
      "Anca D. Dragan",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06499"
  },
  {
    "id": "arXiv:2106.06600",
    "title": "Break-It-Fix-It: Unsupervised Learning for Program Repair",
    "abstract": "Comments: ICML 2021. Code & data available at this https URL",
    "descriptor": "\nComments: ICML 2021. Code & data available at this https URL\n",
    "authors": [
      "Michihiro Yasunaga",
      "Percy Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.06600"
  },
  {
    "id": "arXiv:2106.06804",
    "title": "Entropy-based Logic Explanations of Neural Networks",
    "abstract": "Entropy-based Logic Explanations of Neural Networks",
    "descriptor": "",
    "authors": [
      "Pietro Barbiero",
      "Gabriele Ciravegna",
      "Francesco Giannini",
      "Pietro Li\u00f3",
      "Marco Gori",
      "Stefano Melacci"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.06804"
  },
  {
    "id": "arXiv:2106.06848",
    "title": "Guaranteed Fixed-Confidence Best Arm Identification in Multi-Armed  Bandits: Simple Sequential Elimination Algorithms",
    "abstract": "Guaranteed Fixed-Confidence Best Arm Identification in Multi-Armed  Bandits: Simple Sequential Elimination Algorithms",
    "descriptor": "",
    "authors": [
      "MohammadJavad Azizi",
      "Sheldon M Ross",
      "Zhengyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06848"
  },
  {
    "id": "arXiv:2106.06950",
    "title": "An efficient way to manage blocks of data with Wise Red-Black Trees",
    "abstract": "Comments: Added references to order-statistic trees. Corrected some terms and form. Results unchanged",
    "descriptor": "\nComments: Added references to order-statistic trees. Corrected some terms and form. Results unchanged\n",
    "authors": [
      "Alberto Boffi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.06950"
  },
  {
    "id": "arXiv:2106.07346",
    "title": "A Query-Driven Topic Model",
    "abstract": "Comments: ACL2021 finding paper. For source code, see this https URL",
    "descriptor": "\nComments: ACL2021 finding paper. For source code, see this https URL\n",
    "authors": [
      "Zheng Fang",
      "Yulan He",
      "Rob Procter"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07346"
  },
  {
    "id": "arXiv:2106.08043",
    "title": "CausalNLP: A Practical Toolkit for Causal Inference with Text",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Arun S. Maiya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08043"
  },
  {
    "id": "arXiv:2106.08462",
    "title": "Multi-Resolution Continuous Normalizing Flows",
    "abstract": "Comments: 9 pages, 5 figures, 3 tables, 18 equations",
    "descriptor": "\nComments: 9 pages, 5 figures, 3 tables, 18 equations\n",
    "authors": [
      "Vikram Voleti",
      "Chris Finlay",
      "Adam Oberman",
      "Christopher Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.08462"
  },
  {
    "id": "arXiv:2106.08592",
    "title": "STAR-RIS Enabled Heterogeneous Networks: Ubiquitous NOMA Communication  and Pervasive Federated Learning",
    "abstract": "Comments: 16 pages, 8 figures",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Wanli Ni",
      "Yuanwei Liu",
      "Yonina C. Eldar",
      "Zhaohui Yang",
      "Hui Tian"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.08592"
  },
  {
    "id": "arXiv:2106.08903",
    "title": "GemNet: Universal Directional Graph Neural Networks for Molecules",
    "abstract": "GemNet: Universal Directional Graph Neural Networks for Molecules",
    "descriptor": "",
    "authors": [
      "Johannes Klicpera",
      "Florian Becker",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08903"
  },
  {
    "id": "arXiv:2106.09093",
    "title": "A Hands-on Comparison of DNNs for Dialog Separation Using Transfer  Learning from Music Source Separation",
    "abstract": "Comments: accepted in INTERSPEECH 2021",
    "descriptor": "\nComments: accepted in INTERSPEECH 2021\n",
    "authors": [
      "Martin Strauss",
      "Jouni Paulus",
      "Matteo Torcoli",
      "Bernd Edler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09093"
  },
  {
    "id": "arXiv:2106.09435",
    "title": "Multi-Agent Training beyond Zero-Sum with Correlated Equilibrium  Meta-Solvers",
    "abstract": "Comments: ICML 2021, 9 pages, coded implementation available in this https URL (jpsro.py in examples)",
    "descriptor": "\nComments: ICML 2021, 9 pages, coded implementation available in this https URL (jpsro.py in examples)\n",
    "authors": [
      "Luke Marris",
      "Paul Muller",
      "Marc Lanctot",
      "Karl Tuyls",
      "Thore Graepel"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09435"
  },
  {
    "id": "arXiv:2106.09855",
    "title": "On the Prandtl-Kolmogorov 1-equation model of turbulence",
    "abstract": "On the Prandtl-Kolmogorov 1-equation model of turbulence",
    "descriptor": "",
    "authors": [
      "Kiera Kean",
      "William Layton",
      "Michael Schneier"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09855"
  },
  {
    "id": "arXiv:2106.09919",
    "title": "Approximation Algorithms for Two-Bar Charts Packing Problem",
    "abstract": "Approximation Algorithms for Two-Bar Charts Packing Problem",
    "descriptor": "",
    "authors": [
      "Adil Erzin",
      "Georgii Melidi",
      "Stepan Nazarenko",
      "Roman Plotnikov"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.09919"
  },
  {
    "id": "arXiv:2106.09938",
    "title": "Goal-Directed Planning by Reinforcement Learning and Active Inference",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Dongqi Han",
      "Kenji Doya",
      "Jun Tani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09938"
  },
  {
    "id": "arXiv:2106.10013",
    "title": "Shape Prior Non-Uniform Sampling Guided Real-time Stereo 3D Object  Detection",
    "abstract": "Comments: 9 pages, 7 figures",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Aqi Gao",
      "Jiale Cao",
      "Yanwei Pang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10013"
  },
  {
    "id": "arXiv:2106.10199",
    "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based  Masked Language-models",
    "abstract": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based  Masked Language-models",
    "descriptor": "",
    "authors": [
      "Elad Ben Zaken",
      "Shauli Ravfogel",
      "Yoav Goldberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10199"
  },
  {
    "id": "arXiv:2106.10338",
    "title": "Intersectional synergies: untangling irreducible effects of intersecting  identities via information decomposition",
    "abstract": "Comments: 15 pages, 6 figures",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Thomas F. Varley"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.10338"
  },
  {
    "id": "arXiv:2106.10411",
    "title": "Boosting Offline Reinforcement Learning with Residual Generative  Modeling",
    "abstract": "Comments: Accepted by IJCAI 2021, appendix included, 9 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: Accepted by IJCAI 2021, appendix included, 9 pages, 4 figures, 2 tables\n",
    "authors": [
      "Hua Wei",
      "Deheng Ye",
      "Zhao Liu",
      "Hao Wu",
      "Bo Yuan",
      "Qiang Fu",
      "Wei Yang",
      "Zhenhui Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10411"
  },
  {
    "id": "arXiv:2106.10437",
    "title": "One-to-many Approach for Improving Super-Resolution",
    "abstract": "One-to-many Approach for Improving Super-Resolution",
    "descriptor": "",
    "authors": [
      "Sieun Park",
      "Eunho Lee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10437"
  },
  {
    "id": "arXiv:2106.10458",
    "title": "Place recognition survey: An update on deep learning approaches",
    "abstract": "Comments: Under review in IEEE Transactions on Intelligent Vehicles. This work was submitted on the 13/01/2021 to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Upon acceptance of the article by IEEE, the preprint article will be replaced with the accepted version",
    "descriptor": "\nComments: Under review in IEEE Transactions on Intelligent Vehicles. This work was submitted on the 13/01/2021 to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Upon acceptance of the article by IEEE, the preprint article will be replaced with the accepted version\n",
    "authors": [
      "Tiago Barros",
      "Ricardo Pereira",
      "Lu\u00eds Garrote",
      "Cristiano Premebida",
      "Urbano J. Nunes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10458"
  },
  {
    "id": "arXiv:2106.10476",
    "title": "Neural network interpretability for forecasting of aggregated renewable  generation",
    "abstract": "Neural network interpretability for forecasting of aggregated renewable  generation",
    "descriptor": "",
    "authors": [
      "Yucun Lu",
      "Ilgiz Murzakhanov",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10476"
  },
  {
    "id": "arXiv:2106.10520",
    "title": "SAN: Stochastic Average Newton Algorithm for Minimizing Finite Sums",
    "abstract": "Comments: 37 pages, 6 figures, 6 tables",
    "descriptor": "\nComments: 37 pages, 6 figures, 6 tables\n",
    "authors": [
      "Jiabin Chen",
      "Rui Yuan",
      "Guillaume Garrigos",
      "Robert M. Gower"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10520"
  },
  {
    "id": "arXiv:2106.10592",
    "title": "ExplorerTree: a focus+context exploration approach for 2D embeddings",
    "abstract": "ExplorerTree: a focus+context exploration approach for 2D embeddings",
    "descriptor": "",
    "authors": [
      "Wilson E. Marc\u00edlio-Jr",
      "Danilo M. Eler",
      "Fernando V. Paulovich",
      "Jos\u00e9 F. Rodrigues-Jr",
      "Almir O. Artero"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.10592"
  },
  {
    "id": "arXiv:2106.10662",
    "title": "FedXGBoost: Privacy-Preserving XGBoost for Federated Learning",
    "abstract": "FedXGBoost: Privacy-Preserving XGBoost for Federated Learning",
    "descriptor": "",
    "authors": [
      "Nhan Khanh Le",
      "Yang Liu",
      "Quang Minh Nguyen",
      "Qingchen Liu",
      "Fangzhou Liu",
      "Quanwei Cai",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.10662"
  },
  {
    "id": "arXiv:2106.10663",
    "title": "A PDE approach to centroidal tessellations of domains",
    "abstract": "A PDE approach to centroidal tessellations of domains",
    "descriptor": "",
    "authors": [
      "Fabio Camilli",
      "Adriano Festa"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10663"
  },
  {
    "id": "arXiv:2106.10679",
    "title": "A Comprehensive Review on Non-Neural Networks Collaborative Filtering  Recommendation Systems",
    "abstract": "Comments: 29 pages, 7 tables and 2 figures",
    "descriptor": "\nComments: 29 pages, 7 tables and 2 figures\n",
    "authors": [
      "Carmel Wenga",
      "Majirus Fansi",
      "S\u00e9bastien Chabrier",
      "Jean-Martial Mari",
      "Alban Gabillon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10679"
  },
  {
    "id": "arXiv:2106.10711",
    "title": "Transfer Bayesian Meta-learning via Weighted Free Energy Minimization",
    "abstract": "Comments: 9 pages, 5 figures, submitted",
    "descriptor": "\nComments: 9 pages, 5 figures, submitted\n",
    "authors": [
      "Yunchuan Zhang",
      "Sharu Theresa Jose",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10711"
  },
  {
    "id": "arXiv:2106.10712",
    "title": "Solving for best inhomogeneous linear approximations",
    "abstract": "Solving for best inhomogeneous linear approximations",
    "descriptor": "",
    "authors": [
      "Avraham Bourla"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.10712"
  },
  {
    "id": "arXiv:2106.10759",
    "title": "Robust Regression via Model Based Methods",
    "abstract": "Robust Regression via Model Based Methods",
    "descriptor": "",
    "authors": [
      "Armin Moharrer",
      "Khashayar Kamran",
      "Edmund Yeh",
      "Stratis Ioannidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10759"
  },
  {
    "id": "arXiv:2106.10760",
    "title": "On Stein Variational Neural Network Ensembles",
    "abstract": "On Stein Variational Neural Network Ensembles",
    "descriptor": "",
    "authors": [
      "Francesco D'Angelo",
      "Vincent Fortuin",
      "Florian Wenzel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10760"
  },
  {
    "id": "arXiv:2106.10831",
    "title": "Glow-WaveGAN: Learning Speech Representations from GAN-based Variational  Auto-Encoder For High Fidelity Flow-based Speech Synthesis",
    "abstract": "Comments: Accepted to INTERSPEECH 2021",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2021\n",
    "authors": [
      "Jian Cong",
      "Shan Yang",
      "Lei Xie",
      "Dan Su"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.10831"
  },
  {
    "id": "arXiv:2106.10887",
    "title": "Confidence-Guided Radiology Report Generation",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Yixin Wang",
      "Zihao Lin",
      "Jiang Tian",
      "Zhongchao Shi",
      "Yang Zhang",
      "Jianping Fan",
      "Zhiqiang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10887"
  },
  {
    "id": "arXiv:2106.10906",
    "title": "Energy stability analysis of turbulent incompressible flow based on the  triple decomposition of the velocity gradient tensor",
    "abstract": "Comments: 4 pages. The following article has been submitted to Physics of Fluids",
    "descriptor": "\nComments: 4 pages. The following article has been submitted to Physics of Fluids\n",
    "authors": [
      "Johan Hoffman"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10906"
  },
  {
    "id": "arXiv:2106.10950",
    "title": "Multiple Object Tracking with Mixture Density Networks for Trajectory  Estimation",
    "abstract": "Comments: Best paper runner up on CVPR 2021 RVSU workshop",
    "descriptor": "\nComments: Best paper runner up on CVPR 2021 RVSU workshop\n",
    "authors": [
      "Andreu Girbau",
      "Xavier Gir\u00f3-i-Nieto",
      "Ignasi Rius",
      "Ferran Marqu\u00e9s"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10950"
  },
  {
    "id": "arXiv:2106.11098",
    "title": "Obstacle Detection for BVLOS Drones",
    "abstract": "Comments: 7 pages, 7 figures, Supervisors: Maya Aghaei Gavari and Jaap van de Loosdrecht",
    "descriptor": "\nComments: 7 pages, 7 figures, Supervisors: Maya Aghaei Gavari and Jaap van de Loosdrecht\n",
    "authors": [
      "Jan Moros Esteban",
      "Jaap van de Loosdrecht",
      "Maya Aghaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11098"
  },
  {
    "id": "arXiv:2106.11118",
    "title": "SODA10M: Towards Large-Scale Object Detection Benchmark for Autonomous  Driving",
    "abstract": "SODA10M: Towards Large-Scale Object Detection Benchmark for Autonomous  Driving",
    "descriptor": "",
    "authors": [
      "Jianhua Han",
      "Xiwen Liang",
      "Hang Xu",
      "Kai Chen",
      "Lanqing Hong",
      "Chaoqiang Ye",
      "Wei Zhang",
      "Zhenguo Li",
      "Xiaodan Liang",
      "Chunjing Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11118"
  },
  {
    "id": "arXiv:2106.11294",
    "title": "Smooth Sequential Optimisation with Delayed Feedback",
    "abstract": "Comments: Workshop on Bayesian causal inference for real world interactive systems, 27th SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2021)",
    "descriptor": "\nComments: Workshop on Bayesian causal inference for real world interactive systems, 27th SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2021)\n",
    "authors": [
      "Srivas Chennu",
      "Jamie Martin",
      "Puli Liyanagama",
      "Phil Mohr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11294"
  }
]
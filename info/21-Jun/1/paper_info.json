[
  {
    "id": "arXiv:2105.14024",
    "title": "Near-Optimal Multi-Perturbation Experimental Design for Causal Structure  Learning",
    "abstract": "Causal structure learning is a key problem in many domains. Causal structures\ncan be learnt by performing experiments on the system of interest. We address\nthe largely unexplored problem of designing experiments that simultaneously\nintervene on multiple variables. While potentially more informative than the\ncommonly considered single-variable interventions, selecting such interventions\nis algorithmically much more challenging, due to the doubly-exponential\ncombinatorial search space over sets of composite interventions. In this paper,\nwe develop efficient algorithms for optimizing different objective functions\nquantifying the informativeness of experiments. By establishing novel\nsubmodularity properties of these objectives, we provide approximation\nguarantees for our algorithms. Our algorithms empirically perform superior to\nboth random interventions and algorithms that only select single-variable\ninterventions.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Scott Sussex",
      "Andreas Krause",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14024"
  },
  {
    "id": "arXiv:2105.14038",
    "title": "Learning to Extend Program Graphs to Work-in-Progress Code",
    "abstract": "Source code spends most of its time in a broken or incomplete state during\nsoftware development. This presents a challenge to machine learning for code,\nsince high-performing models typically rely on graph structured representations\nof programs derived from traditional program analyses. Such analyses may be\nundefined for broken or incomplete code. We extend the notion of program graphs\nto work-in-progress code by learning to predict edge relations between tokens,\ntraining on well-formed code before transferring to work-in-progress code. We\nconsider the tasks of code completion and localizing and repairing variable\nmisuse in a work-in-process scenario. We demonstrate that training\nrelation-aware models with fine-tuned edges consistently leads to improved\nperformance on both tasks.",
    "descriptor": "",
    "authors": [
      "Xuechen Li",
      "Chris J. Maddison",
      "Daniel Tarlow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14038"
  },
  {
    "id": "arXiv:2105.14039",
    "title": "Towards mental time travel: a hierarchical memory for reinforcement  learning agents",
    "abstract": "Reinforcement learning agents often forget details of the past, especially\nafter delays or distractor tasks. Agents with common memory architectures\nstruggle to recall and integrate across multiple timesteps of a past event, or\neven to recall the details of a single timestep that is followed by distractor\ntasks. To address these limitations, we propose a Hierarchical Transformer\nMemory (HTM), which helps agents to remember the past in detail. HTM stores\nmemories by dividing the past into chunks, and recalls by first performing\nhigh-level attention over coarse summaries of the chunks, and then performing\ndetailed attention within only the most relevant chunks. An agent with HTM can\ntherefore \"mentally time-travel\" -- remember past events in detail without\nattending to all intervening events. We show that agents with HTM substantially\noutperform agents with other memory architectures at tasks requiring long-term\nrecall, retention, or reasoning over memory. These include recalling where an\nobject is hidden in a 3D environment, rapidly learning to navigate efficiently\nin a new neighborhood, and rapidly learning and retaining new object names.\nAgents with HTM can extrapolate to task sequences an order of magnitude longer\nthan they were trained on, and can even generalize zero-shot from a\nmeta-learning setting to maintaining knowledge across episodes. HTM improves\nagent sample efficiency, generalization, and generality (by solving tasks that\npreviously required specialized architectures). Our work is a step towards\nagents that can learn, interact, and adapt in complex and temporally-extended\nenvironments.",
    "descriptor": "\nComments: 10 pages main text; 22 pages total\n",
    "authors": [
      "Andrew Kyle Lampinen",
      "Stephanie C.Y. Chan",
      "Andrea Banino",
      "Felix Hill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.14039"
  },
  {
    "id": "arXiv:2105.14044",
    "title": "Fair Representations by Compression",
    "abstract": "Organizations that collect and sell data face increasing scrutiny for the\ndiscriminatory use of data. We propose a novel unsupervised approach to\ntransform data into a compressed binary representation independent of sensitive\nattributes. We show that in an information bottleneck framework, a parsimonious\nrepresentation should filter out information related to sensitive attributes if\nthey are provided directly to the decoder. Empirical results show that the\nproposed method, \\textbf{FBC}, achieves state-of-the-art accuracy-fairness\ntrade-off. Explicit control of the entropy of the representation bit stream\nallows the user to move smoothly and simultaneously along both rate-distortion\nand rate-fairness curves. \\end{abstract}",
    "descriptor": "",
    "authors": [
      "Xavier Gitiaux",
      "Huzefa Rangwala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.14044"
  },
  {
    "id": "arXiv:2105.14052",
    "title": "Targeted Deep Learning: Framework, Methods, and Applications",
    "abstract": "Deep learning systems are typically designed to perform for a wide range of\ntest inputs. For example, deep learning systems in autonomous cars are supposed\nto deal with traffic situations for which they were not specifically trained.\nIn general, the ability to cope with a broad spectrum of unseen test inputs is\ncalled generalization. Generalization is definitely important in applications\nwhere the possible test inputs are known but plentiful or simply unknown, but\nthere are also cases where the possible inputs are few and unlabeled but known\nbeforehand. For example, medicine is currently interested in targeting\ntreatments to individual patients; the number of patients at any given time is\nusually small (typically one), their diagnoses/responses/... are still unknown,\nbut their general characteristics (such as genome information, protein levels\nin the blood, and so forth) are known before the treatment. We propose to call\ndeep learning in such applications targeted deep learning. In this paper, we\nintroduce a framework for targeted deep learning, and we devise and test an\napproach for adapting standard pipelines to the requirements of targeted deep\nlearning. The approach is very general yet easy to use: it can be implemented\nas a simple data-preprocessing step. We demonstrate on a variety of real-world\ndata that our approach can indeed render standard deep learning faster and more\naccurate when the test inputs are known beforehand.",
    "descriptor": "",
    "authors": [
      "Shih-Ting Huang",
      "Johannes Lederer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.14052"
  },
  {
    "id": "arXiv:2105.14058",
    "title": "Symmetry-driven graph neural networks",
    "abstract": "Exploiting symmetries and invariance in data is a powerful, yet not fully\nexploited, way to achieve better generalisation with more efficiency. In this\npaper, we introduce two graph network architectures that are equivariant to\nseveral types of transformations affecting the node coordinates. First, we\nbuild equivariance to any transformation in the coordinate embeddings that\npreserves the distance between neighbouring nodes, allowing for equivariance to\nthe Euclidean group. Then, we introduce angle attributes to build equivariance\nto any angle preserving transformation - thus, to the conformal group. Thanks\nto their equivariance properties, the proposed models can be vastly more data\nefficient with respect to classical graph architectures, intrinsically equipped\nwith a better inductive bias and better at generalising. We demonstrate these\ncapabilities on a synthetic dataset composed of $n$-dimensional geometric\nobjects. Additionally, we provide examples of their limitations when (the\nright) symmetries are not present in the data.",
    "descriptor": "",
    "authors": [
      "Francesco Farina",
      "Emma Slade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14058"
  },
  {
    "id": "arXiv:2105.14059",
    "title": "On the Usage of Psychophysiological Data in Software Engineering: An  Extended Systematic Mapping Study",
    "abstract": "In recent years, many studies have applied wearable devices to capture\npsychophysiological data from software developers. However, the current\nliterature lacks investigations that classify the studies and point out gaps to\nbe explored. This article, therefore, seeks to present a comprehensive overview\nof the literature by classifying and creating a systematic map of the works.\nBesides, it seeks to pinpoint research gaps, challenges, and trends. Based on\nwidely known guidelines, a systematic mapping of the literature was designed\nand run to answer eight research questions. After applying a careful filtering\nprocess, we selected 27 representative studies from a sample of 2,084\npotentially relevant works retrieved from seven digital libraries. The main\nresults are: a classification scheme of the published studies was produced;\nthere is no predominance of the devices used to capture psychophysiological\ndata; over 50% of the studies have explored indicators related to mental states\nand neural activity; and 80% have analyzed composite data to understand the\ncognitive load and in the context of understanding debugging programs and\nstrategies. Our findings can benefit researchers and students by creating a\nsystematic map of the literature, being a starting point for future research.",
    "descriptor": "",
    "authors": [
      "Roger Vieira",
      "Kleinner Farias"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14059"
  },
  {
    "id": "arXiv:2105.14060",
    "title": "Rethinking Lifelong Sequential Recommendation with Incremental  Multi-Interest Attention",
    "abstract": "Sequential recommendation plays an increasingly important role in many\ne-commerce services such as display advertisement and online shopping. With the\nrapid development of these services in the last two decades, users have\naccumulated a massive amount of behavior data. Richer sequential behavior data\nhas been proven to be of great value for sequential recommendation. However,\ntraditional sequential models fail to handle users' lifelong sequences, as\ntheir linear computational and storage cost prohibits them from performing\nonline inference. Recently, lifelong sequential modeling methods that borrow\nthe idea of memory networks from NLP are proposed to address this issue.\nHowever, the RNN-based memory networks built upon intrinsically suffer from the\ninability to capture long-term dependencies and may instead be overwhelmed by\nthe noise on extremely long behavior sequences. In addition, as the user's\nbehavior sequence gets longer, more interests would be demonstrated in it. It\nis therefore crucial to model and capture the diverse interests of users. In\norder to tackle these issues, we propose a novel lifelong incremental\nmulti-interest self attention based sequential recommendation model, namely\nLimaRec. Our proposed method benefits from the carefully designed\nself-attention to identify relevant information from users' behavior sequences\nwith different interests. It is still able to incrementally update users'\nrepresentations for online inference, similarly to memory network based\napproaches. We extensively evaluate our method on four real-world datasets and\ndemonstrate its superior performances compared to the state-of-the-art\nbaselines.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Yongji Wu",
      "Lu Yin",
      "Defu Lian",
      "Mingyang Yin",
      "Neil Zhenqiang Gong",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.14060"
  },
  {
    "id": "arXiv:2105.14064",
    "title": "Controllable Abstractive Dialogue Summarization with Sketch Supervision",
    "abstract": "In this paper, we aim to improve abstractive dialogue summarization quality\nand, at the same time, enable granularity control. Our model has two primary\ncomponents and stages: 1) a two-stage generation strategy that generates a\npreliminary summary sketch serving as the basis for the final summary. This\nsummary sketch provides a weakly supervised signal in the form of\npseudo-labeled interrogative pronoun categories and key phrases extracted using\na constituency parser. 2) A simple strategy to control the granularity of the\nfinal summary, in that our model can automatically determine or control the\nnumber of generated summary sentences for a given dialogue by predicting and\nhighlighting different text spans from the source text. Our model achieves\nstate-of-the-art performance on the largest dialogue summarization corpus\nSAMSum, with as high as 50.79 in ROUGE-L score. In addition, we conduct a case\nstudy and show competitive human evaluation results and controllability to\nhuman-annotated summaries.",
    "descriptor": "\nComments: ACL-Findings 2021. Code is released at this https URL\n",
    "authors": [
      "Chien-Sheng Wu",
      "Linqing Liu",
      "Wenhao Liu",
      "Pontus Stenetorp",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14064"
  },
  {
    "id": "arXiv:2105.14065",
    "title": "TransCamP: Graph Transformer for 6-DoF Camera Pose Estimation",
    "abstract": "Camera pose estimation or camera relocalization is the centerpiece in\nnumerous computer vision tasks such as visual odometry, structure from motion\n(SfM) and SLAM. In this paper we propose a neural network approach with a graph\ntransformer backbone, namely TransCamP, to address the camera relocalization\nproblem. In contrast with prior work where the pose regression is mainly guided\nby photometric consistency, TransCamP effectively fuses the image features,\ncamera pose information and inter-frame relative camera motions into encoded\ngraph attributes and is trained towards the graph consistency and accuracy\ninstead, yielding significantly higher computational efficiency. By leveraging\ngraph transformer layers with edge features and enabling tensorized adjacency\nmatrix, TransCamP dynamically captures the global attention and thus endows the\npose graph with evolving structures to achieve improved robustness and\naccuracy. In addition, optional temporal transformer layers actively enhance\nthe spatiotemporal inter-frame relation for sequential inputs. Evaluation of\nthe proposed network on various public benchmarks demonstrates that TransCamP\noutperforms state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Xinyi Li",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14065"
  },
  {
    "id": "arXiv:2105.14066",
    "title": "Are Privacy Dashboards Good for End Users? Evaluating User Perceptions  and Reactions to Google's My Activity (Extended Version)",
    "abstract": "Privacy dashboards and transparency tools help users review and manage the\ndata collected about them online. Since 2016, Google has offered such a tool,\nMy Activity, which allows users to review and delete their activity data from\nGoogle services. We conducted an online survey with $n = 153$ participants to\nunderstand if Google's My Activity, as an example of a privacy transparency\ntool, increases or decreases end-users' concerns and benefits regarding data\ncollection. While most participants were aware of Google's data collection, the\nvolume and detail was surprising, but after exposure to My Activity,\nparticipants were significantly more likely to be both less concerned about\ndata collection and to view data collection more beneficially. Only $25\\,\\%$\nindicated that they would change any settings in the My Activity service or\nchange any behaviors. This suggests that privacy transparency tools are quite\nbeneficial for online services as they garner trust with their users and\nimprove their perceptions without necessarily changing users' behaviors. At the\nsame time, though, it remains unclear if such transparency tools actually\nimprove end user privacy by sufficiently assisting or motivating users to\nchange or review data collection settings.",
    "descriptor": "",
    "authors": [
      "Florian M. Farke",
      "David G. Balash",
      "Maximilian Golla",
      "Markus D\u00fcrmuth",
      "Adam J. Aviv"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14066"
  },
  {
    "id": "arXiv:2105.14068",
    "title": "Linear-Time Self Attention with Codeword Histogram for Efficient  Recommendation",
    "abstract": "Self-attention has become increasingly popular in a variety of sequence\nmodeling tasks from natural language processing to recommendation, due to its\neffectiveness. However, self-attention suffers from quadratic computational and\nmemory complexities, prohibiting its applications on long sequences. Existing\napproaches that address this issue mainly rely on a sparse attention context,\neither using a local window, or a permuted bucket obtained by\nlocality-sensitive hashing (LSH) or sorting, while crucial information may be\nlost. Inspired by the idea of vector quantization that uses cluster centroids\nto approximate items, we propose LISA (LInear-time Self Attention), which\nenjoys both the effectiveness of vanilla self-attention and the efficiency of\nsparse attention. LISA scales linearly with the sequence length, while enabling\nfull contextual attention via computing differentiable histograms of codeword\ndistributions. Meanwhile, unlike some efficient attention methods, our method\nposes no restriction on casual masking or sequence length. We evaluate our\nmethod on four real-world datasets for sequential recommendation. The results\nshow that LISA outperforms the state-of-the-art efficient attention methods in\nboth performance and speed; and it is up to 57x faster and 78x more memory\nefficient than vanilla self-attention.",
    "descriptor": "\nComments: 11 pages. Accepted by the Web Conference 2021 (WWW '21)\n",
    "authors": [
      "Yongji Wu",
      "Defu Lian",
      "Neil Zhenqiang Gong",
      "Lu Yin",
      "Mingyang Yin",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.14068"
  },
  {
    "id": "arXiv:2105.14069",
    "title": "The Evaluation of Rating Systems in Team-based Battle Royale Games",
    "abstract": "Online competitive games have become a mainstream entertainment platform. To\ncreate a fair and exciting experience, these games use rating systems to match\nplayers with similar skills. While there has been an increasing amount of\nresearch on improving the performance of these systems, less attention has been\npaid to how their performance is evaluated. In this paper, we explore the\nutility of several metrics for evaluating three popular rating systems on a\nreal-world dataset of over 25,000 team battle royale matches. Our results\nsuggest considerable differences in their evaluation patterns. Some metrics\nwere highly impacted by the inclusion of new players. Many could not capture\nthe real differences between certain groups of players. Among all metrics\nstudied, normalized discounted cumulative gain (NDCG) demonstrated more\nreliable performance and more flexibility. It alleviated most of the challenges\nfaced by the other metrics while adding the freedom to adjust the focus of the\nevaluations on different groups of players.",
    "descriptor": "\nComments: 11 pages, 1 figure, Accepted in the 23rd International Conference on Artificial Intelligence (ICAI'21)\n",
    "authors": [
      "Arman Dehpanah",
      "Muheeb Faizan Ghori",
      "Jonathan Gemmell",
      "Bamshad Mobasher"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.14069"
  },
  {
    "id": "arXiv:2105.14070",
    "title": "Accelerating Neural ODEs Using Model Order Reduction",
    "abstract": "Embedding nonlinear dynamical systems into artificial neural networks is a\npowerful new formalism for machine learning. By parameterizing ordinary\ndifferential equations (ODEs) as neural network layers, these Neural ODEs are\nmemory-efficient to train, process time-series naturally and incorporate\nknowledge of physical systems into deep learning models. However, the practical\napplications of Neural ODEs are limited due to long inference times, because\nthe outputs of the embedded ODE layers are computed numerically with\ndifferential equation solvers that can be computationally demanding. Here we\nshow that mathematical model order reduction methods can be used for\ncompressing and accelerating Neural ODEs by accurately simulating the\ncontinuous nonlinear dynamics in low-dimensional subspaces. We implement our\nnovel compression method by developing Neural ODEs that integrate the necessary\nsubspace-projection and interpolation operations as layers of the neural\nnetwork. We validate our model reduction approach by comparing it to two\nestablished acceleration methods from the literature in two classification\nasks. In compressing convolutional and recurrent Neural ODE architectures, we\nachieve the best balance between speed and accuracy when compared to the other\ntwo acceleration methods. Based on our results, our integration of model order\nreduction with Neural ODEs can facilitate efficient, dynamical system-driven\ndeep learning in resource-constrained applications.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Mikko Lehtim\u00e4ki",
      "Lassi Paunonen",
      "Marja-Leena Linne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.14070"
  },
  {
    "id": "arXiv:2105.14073",
    "title": "Task-Guided Inverse Reinforcement Learning Under Partial Information",
    "abstract": "We study the problem of inverse reinforcement learning (IRL), where the\nlearning agent recovers a reward function using expert demonstrations. Most of\nthe existing IRL techniques make the often unrealistic assumption that the\nagent has access to full information about the environment. We remove this\nassumption by developing an algorithm for IRL in partially observable Markov\ndecision processes (POMDPs), where an agent cannot directly observe the current\nstate of the POMDP. The algorithm addresses several limitations of existing\ntechniques that do not take the \\emph{information asymmetry} between the expert\nand the agent into account. First, it adopts causal entropy as the measure of\nthe likelihood of the expert demonstrations as opposed to entropy in most\nexisting IRL techniques and avoids a common source of algorithmic complexity.\nSecond, it incorporates task specifications expressed in temporal logic into\nIRL. Such specifications may be interpreted as side information available to\nthe learner a priori in addition to the demonstrations, and may reduce the\ninformation asymmetry between the expert and the agent. Nevertheless, the\nresulting formulation is still nonconvex due to the intrinsic nonconvexity of\nthe so-called \\emph{forward problem}, i.e., computing an optimal policy given a\nreward function, in POMDPs. We address this nonconvexity through sequential\nconvex programming and introduce several extensions to solve the forward\nproblem in a scalable manner. This scalability allows computing policies that\nincorporate memory at the expense of added computational cost yet also achieves\nhigher performance compared to memoryless policies. We demonstrate that, even\nwith severely limited data, the algorithm learns reward functions and policies\nthat satisfy the task and induce a similar behavior to the expert by leveraging\nthe side information and incorporating memory into the policy.",
    "descriptor": "\nComments: Submitted to NeurIPS 2021\n",
    "authors": [
      "Franck Djeumou",
      "Murat Cubuktepe",
      "Craig Lennon",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.14073"
  },
  {
    "id": "arXiv:2105.14074",
    "title": "Learning Neuro-Symbolic Relational Transition Models for Bilevel  Planning",
    "abstract": "Despite recent, independent progress in model-based reinforcement learning\nand integrated symbolic-geometric robotic planning, synthesizing these\ntechniques remains challenging because of their disparate assumptions and\nstrengths. In this work, we take a step toward bridging this gap with\nNeuro-Symbolic Relational Transition Models (NSRTs), a novel class of\ntransition models that are data-efficient to learn, compatible with powerful\nrobotic planning methods, and generalizable over objects. NSRTs have both\nsymbolic and neural components, enabling a bilevel planning scheme where\nsymbolic AI planning in an outer loop guides continuous planning with neural\nmodels in an inner loop. Experiments in four robotic planning domains show that\nNSRTs can be learned after only tens or hundreds of training episodes, and then\nused for fast planning in new tasks that require up to 60 actions to reach the\ngoal and involve many more objects than were seen during training. Video:\nhttps://tinyurl.com/chitnis-nsrts",
    "descriptor": "",
    "authors": [
      "Rohan Chitnis",
      "Tom Silver",
      "Joshua B. Tenenbaum",
      "Tomas Lozano-Perez",
      "Leslie Pack Kaelbling"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14074"
  },
  {
    "id": "arXiv:2105.14077",
    "title": "On the Bias Against Inductive Biases",
    "abstract": "Borrowing from the transformer models that revolutionized the field of\nnatural language processing, self-supervised feature learning for visual tasks\nhas also seen state-of-the-art success using these extremely deep, isotropic\nnetworks. However, the typical AI researcher does not have the resources to\nevaluate, let alone train, a model with several billion parameters and\nquadratic self-attention activations. To facilitate further research, it is\nnecessary to understand the features of these huge transformer models that can\nbe adequately studied by the typical researcher. One interesting characteristic\nof these transformer models is that they remove most of the inductive biases\npresent in classical convolutional networks. In this work, we analyze the\neffect of these and more inductive biases on small to moderately-sized\nisotropic networks used for unsupervised visual feature learning and show that\ntheir removal is not always ideal.",
    "descriptor": "\nComments: Under Review at NeurIPS 2021\n",
    "authors": [
      "George Cazenavette",
      "Simon Lucey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14077"
  },
  {
    "id": "arXiv:2105.14078",
    "title": "UCPhrase: Unsupervised Context-aware Quality Phrase Tagging",
    "abstract": "Identifying and understanding quality phrases from context is a fundamental\ntask in text mining. The most challenging part of this task arguably lies in\nuncommon, emerging, and domain-specific phrases. The infrequent nature of these\nphrases significantly hurts the performance of phrase mining methods that rely\non sufficient phrase occurrences in the input corpus. Context-aware tagging\nmodels, though not restricted by frequency, heavily rely on domain experts for\neither massive sentence-level gold labels or handcrafted gazetteers. In this\nwork, we propose UCPhrase, a novel unsupervised context-aware quality phrase\ntagger. Specifically, we induce high-quality phrase spans as silver labels from\nconsistently co-occurring word sequences within each document. Compared with\ntypical context-agnostic distant supervision based on existing knowledge bases\n(KBs), our silver labels root deeply in the input domain and context, thus\nhaving unique advantages in preserving contextual completeness and capturing\nemerging, out-of-KB phrases. Training a conventional neural tagger based on\nsilver labels usually faces the risk of overfitting phrase surface names.\nAlternatively, we observe that the contextualized attention maps generated from\na transformer-based neural language model effectively reveal the connections\nbetween words in a surface-agnostic way. Therefore, we pair such attention maps\nwith the silver labels to train a lightweight span prediction model, which can\nbe applied to new input to recognize (unseen) quality phrases regardless of\ntheir surface names or frequency. Thorough experiments on various tasks and\ndatasets, including corpus-level phrase ranking, document-level keyphrase\nextraction, and sentence-level phrase tagging, demonstrate the superiority of\nour design over state-of-the-art pre-trained, unsupervised, and distantly\nsupervised methods.",
    "descriptor": "\nComments: KDD 2021\n",
    "authors": [
      "Xiaotao Gu",
      "Zihan Wang",
      "Zhenyu Bi",
      "Yu Meng",
      "Liyuan Liu",
      "Jiawei Han",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14078"
  },
  {
    "id": "arXiv:2105.14080",
    "title": "Gotta Go Fast When Generating Data with Score-Based Models",
    "abstract": "Score-based (denoising diffusion) generative models have recently gained a\nlot of success in generating realistic and diverse data. These approaches\ndefine a forward diffusion process for transforming data to noise and generate\ndata by reversing it (thereby going from noise to data). Unfortunately, current\nscore-based models generate data very slowly due to the sheer number of score\nnetwork evaluations required by numerical SDE solvers.\nIn this work, we aim to accelerate this process by devising a more efficient\nSDE solver. Existing approaches rely on the Euler-Maruyama (EM) solver, which\nuses a fixed step size. We found that naively replacing it with other SDE\nsolvers fares poorly - they either result in low-quality samples or become\nslower than EM. To get around this issue, we carefully devise an SDE solver\nwith adaptive step sizes tailored to score-based generative models piece by\npiece. Our solver requires only two score function evaluations, rarely rejects\nsamples, and leads to high-quality samples. Our approach generates data 2 to 10\ntimes faster than EM while achieving better or equal sample quality. For\nhigh-resolution images, our method leads to significantly higher quality\nsamples than all other methods tested. Our SDE solver has the benefit of\nrequiring no step size tuning.",
    "descriptor": "\nComments: Code is available on this https URL\n",
    "authors": [
      "Alexia Jolicoeur-Martineau",
      "Ke Li",
      "R\u00e9mi Pich\u00e9-Taillefer",
      "Tal Kachman",
      "Ioannis Mitliagkas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14080"
  },
  {
    "id": "arXiv:2105.14082",
    "title": "Bh\u0101$\\unicode{x1E63}$\u0101citra: Visualising the dialect geography of  South Asia",
    "abstract": "We present Bh\\=a$\\unicode{x1E63}$\\=acitra, a dialect mapping system for South\nAsia built on a database of linguistic studies of languages of the region\nannotated for topic and location data. We analyse language coverage and look\ntowards applications to typology by visualising example datasets. The\napplication is not only meant to be useful for feature mapping, but also serves\nas a new kind of interactive bibliography for linguists of South Asian\nlanguages.",
    "descriptor": "\nComments: 4 + 2 pages, 3 figures. To appear at LChange'21 workshop located at ACL 2021\n",
    "authors": [
      "Aryaman Arora",
      "Adam Farris",
      "Gopalakrishnan R",
      "Samopriya Basu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14082"
  },
  {
    "id": "arXiv:2105.14083",
    "title": "Rethinking Noisy Label Models: Labeler-Dependent Noise with Adversarial  Awareness",
    "abstract": "Most studies on learning from noisy labels rely on unrealistic models of\ni.i.d. label noise, such as class-conditional transition matrices. More recent\nwork on instance-dependent noise models are more realistic, but assume a single\ngenerative process for label noise across the entire dataset. We propose a more\nprincipled model of label noise that generalizes instance-dependent noise to\nmultiple labelers, based on the observation that modern datasets are typically\nannotated using distributed crowdsourcing methods. Under our labeler-dependent\nmodel, label noise manifests itself under two modalities: natural error of\ngood-faith labelers, and adversarial labels provided by malicious actors. We\npresent two adversarial attack vectors that more accurately reflect the label\nnoise that may be encountered in real-world settings, and demonstrate that\nunder our multimodal noisy labels model, state-of-the-art approaches for\nlearning from noisy labels are defeated by adversarial label attacks. Finally,\nwe propose a multi-stage, labeler-aware, model-agnostic framework that reliably\nfilters noisy labels by leveraging knowledge about which data partitions were\nlabeled by which labeler, and show that our proposed framework remains robust\neven in the presence of extreme adversarial label noise.",
    "descriptor": "\nComments: 9 pages, 3 figures, 3 algorithms. Currently under blind review at NeurIPS 2021\n",
    "authors": [
      "Glenn Dawson",
      "Robi Polikar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14083"
  },
  {
    "id": "arXiv:2105.14084",
    "title": "Support vector machines and linear regression coincide with very  high-dimensional features",
    "abstract": "The support vector machine (SVM) and minimum Euclidean norm least squares\nregression are two fundamentally different approaches to fitting linear models,\nbut they have recently been connected in models for very high-dimensional data\nthrough a phenomenon of support vector proliferation, where every training\nexample used to fit an SVM becomes a support vector. In this paper, we explore\nthe generality of this phenomenon and make the following contributions. First,\nwe prove a super-linear lower bound on the dimension (in terms of sample size)\nrequired for support vector proliferation in independent feature models,\nmatching the upper bounds from previous works. We further identify a sharp\nphase transition in Gaussian feature models, bound the width of this\ntransition, and give experimental support for its universality. Finally, we\nhypothesize that this phase transition occurs only in much higher-dimensional\nsettings in the $\\ell_1$ variant of the SVM, and we present a new geometric\ncharacterization of the problem that may elucidate this phenomenon for the\ngeneral $\\ell_p$ case.",
    "descriptor": "\nComments: 32 pages, 9 figures\n",
    "authors": [
      "Navid Ardeshir",
      "Clayton Sanford",
      "Daniel Hsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14084"
  },
  {
    "id": "arXiv:2105.14086",
    "title": "Augmenting Anchors by the Detector Itself",
    "abstract": "It is difficult to determine the scale and aspect ratio of anchors for\nanchor-based object detection methods. Current state-of-the-art object\ndetectors either determine anchor parameters according to objects' shape and\nscale in a dataset, or avoid this problem by utilizing anchor-free method. In\nthis paper, we propose a gradient-free anchor augmentation method named AADI,\nwhich means Augmenting Anchors by the Detector Itself. AADI is not an\nanchor-free method, but it converts the scale and aspect ratio of anchors from\na continuous space to a discrete space, which greatly alleviates the problem of\nanchors' designation. Furthermore, AADI does not add any parameters or\nhyper-parameters, which is beneficial for future research and downstream tasks.\nExtensive experiments on COCO dataset show that AADI has obvious advantages for\nboth two-stage and single-stage methods, specifically, AADI achieves at least\n2.1 AP improvements on Faster R-CNN and 1.6 AP improvements on RetinaNet, using\nResNet-50 model. We hope that this simple and cost-efficient method can be\nwidely used in object detection.",
    "descriptor": "",
    "authors": [
      "Xiaopei Wan",
      "Shengjie Chen",
      "Yujiu Yang",
      "Zhenhua Guo",
      "Fangbo Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14086"
  },
  {
    "id": "arXiv:2105.14088",
    "title": "Cloud Collectives: Towards Cloud-aware Collectives forML Workloads with  Rank Reordering",
    "abstract": "ML workloads are becoming increasingly popular in the cloud. Good cloud\ntraining performance is contingent on efficient parameter exchange among VMs.\nWe find that Collectives, the widely used distributed communication algorithms,\ncannot perform optimally out of the box due to the hierarchical topology of\ndatacenter networks and multi-tenancy nature of the cloudenvironment.In this\npaper, we present Cloud Collectives , a prototype that accelerates collectives\nby reordering theranks of participating VMs such that the communication pattern\ndictated by the selected collectives operation best exploits the locality in\nthe network.Collectives is non-intrusive, requires no code changes nor rebuild\nof an existing application, and runs without support from cloud providers. Our\npreliminary application of Cloud Collectives on allreduce operations in public\nclouds results in a speedup of up to 3.7x in multiple microbenchmarks and 1.3x\nin real-world workloads of distributed training of deep neural networks and\ngradient boosted decision trees using state-of-the-art frameworks.",
    "descriptor": "",
    "authors": [
      "Liang Luo",
      "Jacob Nelson",
      "Arvind Krishnamurthy",
      "Luis Ceze"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.14088"
  },
  {
    "id": "arXiv:2105.14089",
    "title": "Improved Convergence Rate for a Distributed Two-Time-Scale Gradient  Method under Random Quantization",
    "abstract": "We study the so-called distributed two-time-scale gradient method for solving\nconvex optimization problems over a network of agents when the communication\nbandwidth between the nodes is limited, and so information that is exchanged\nbetween the nodes must be quantized. Our main contribution is to provide a\nnovel analysis, resulting to an improved convergence rate of this method as\ncompared to the existing works. In particular, we show that the method\nconverges at a rate $O(log_2 k/\\sqrt k)$ to the optimal solution, when the\nunderlying objective function is strongly convex and smooth. The key technique\nin our analysis is to consider a Lyapunov function that simultaneously captures\nthe coupling of the consensus and optimality errors generated by the method.",
    "descriptor": "\nComments: Submitted to IEEE Conference on Decision and Control (CDC) 2021\n",
    "authors": [
      "Marcos M. Vasconcelos",
      "Thinh T. Doan",
      "Urbashi Mitra"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14089"
  },
  {
    "id": "arXiv:2105.14091",
    "title": "Influence of sampling on the convergence rates of greedy algorithms for  parameter-dependent random variables",
    "abstract": "The main focus of this article is to provide a mathematical study of the\nalgorithm proposed in~\\cite{boyaval2010variance} where the authors proposed a\nvariance reduction technique for the computation of parameter-dependent\nexpectations using a reduced basis paradigm. We study the effect of Monte-Carlo\nsampling on the theoretical properties of greedy algorithms. In particular,\nusing concentration inequalities for the empirical measure in Wasserstein\ndistance proved in~\\cite{fournier2015rate}, we provide sufficient conditions on\nthe number of samples used for the computation of empirical variances at each\niteration of the greedy procedure to guarantee that the resulting method\nalgorithm is a weak greedy algorithm with high probability. These theoretical\nresults are not fully practical and we therefore propose a heuristic procedure\nto choose the number of Monte-Carlo samples at each iteration, inspired from\nthis theoretical study, which provides satisfactory results on several\nnumerical test cases.",
    "descriptor": "",
    "authors": [
      "Mohamed-Raed Blel",
      "Virginie Ehrlacher",
      "Tony Leli\u00e8vre"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14091"
  },
  {
    "id": "arXiv:2105.14092",
    "title": "Deep Memory Update",
    "abstract": "Recurrent neural networks are key tools for sequential data processing.\nExisting architectures support only a limited class of operations that these\nnetworks can apply to their memory state. In this paper, we address this issue\nand introduce a recurrent neural module called Deep Memory Update (DMU). This\nmodule is an alternative to well-established LSTM and GRU. However, it uses a\nuniversal function approximator to process its lagged memory state. In\naddition, the module normalizes the lagged memory to avoid gradient exploding\nor vanishing in backpropagation through time. The subnetwork that transforms\nthe memory state of DMU can be arbitrary. Experimental results presented here\nconfirm that the previously mentioned properties of the network allow it to\ncompete with and often outperform state-of-the-art architectures such as LSTM\nand GRU.",
    "descriptor": "",
    "authors": [
      "\u0141ukasz Neumann",
      "Pawe\u0142 Wawrzy\u0144ski"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.14092"
  },
  {
    "id": "arXiv:2105.14094",
    "title": "Galerkin Neural Networks: A Framework for Approximating Variational  Equations with Error Control",
    "abstract": "We present a new approach to using neural networks to approximate the\nsolutions of variational equations, based on the adaptive construction of a\nsequence of finite-dimensional subspaces whose basis functions are realizations\nof a sequence of neural networks. The finite-dimensional subspaces are then\nused to define a standard Galerkin approximation of the variational equation.\nThis approach enjoys a number of advantages, including: the sequential nature\nof the algorithm offers a systematic approach to enhancing the accuracy of a\ngiven approximation; the sequential enhancements provide a useful indicator for\nthe error that can be used as a criterion for terminating the sequential\nupdates; the basic approach is largely oblivious to the nature of the partial\ndifferential equation under consideration; and, some basic theoretical results\nare presented regarding the convergence (or otherwise) of the method which are\nused to formulate basic guidelines for applying the method.",
    "descriptor": "",
    "authors": [
      "Mark Ainsworth",
      "Justin Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14094"
  },
  {
    "id": "arXiv:2105.14095",
    "title": "Weighted Training for Cross-Task Learning",
    "abstract": "In this paper, we introduce Target-Aware Weighted Training (TAWT), a weighted\ntraining algorithm for cross-task learning based on minimizing a\nrepresentation-based task distance between the source and target tasks. We show\nthat TAWT is easy to implement, is computationally efficient, requires little\nhyperparameter tuning, and enjoys non-asymptotic learning-theoretic guarantees.\nThe effectiveness of TAWT is corroborated through extensive experiments with\nBERT on four sequence tagging tasks in natural language processing (NLP),\nincluding part-of-speech (PoS) tagging, chunking, predicate detection, and\nnamed entity recognition (NER). As a byproduct, the proposed\nrepresentation-based task distance allows one to reason in a theoretically\nprincipled way about several critical aspects of cross-task learning, such as\nthe choice of the source data and the impact of fine-tuning",
    "descriptor": "\nComments: 21 pages, 3 figures, 6 tables\n",
    "authors": [
      "Shuxiao Chen",
      "Koby Crammer",
      "Hangfeng He",
      "Dan Roth",
      "Weijie J. Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14095"
  },
  {
    "id": "arXiv:2105.14097",
    "title": "Reinforcement Learning for on-line Sequence Transformation",
    "abstract": "A number of problems in the processing of sound and natural language, as well\nas in other areas, can be reduced to simultaneously reading an input sequence\nand writing an output sequence of generally different length. There are well\ndeveloped methods that produce the output sequence based on the entirely known\ninput. However, efficient methods that enable such transformations on-line do\nnot exist. In this paper we introduce an architecture that learns with\nreinforcement to make decisions about whether to read a token or write another\ntoken. This architecture is able to transform potentially infinite sequences\non-line. In an experimental study we compare it with state-of-the-art methods\nfor neural machine translation. While it produces slightly worse translations\nthan Transformer, it outperforms the autoencoder with attention, even though\nour architecture translates texts on-line thereby solving a more difficult\nproblem than both reference methods.",
    "descriptor": "",
    "authors": [
      "Grzegorz Rype\u015b\u0107",
      "\u0141ukasz Lepak",
      "Pawe\u0142 Wawrzy\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14097"
  },
  {
    "id": "arXiv:2105.14098",
    "title": "Ray-based inversion accounting for scattering for biomedical ultrasound  computed tomography",
    "abstract": "An efficient and accurate image reconstruction algorithm for ultrasound\ntomography (UST) is described and demonstrated, which can recover accurate\nsound speed distribution from acoustic time series measurements made in soft\ntissue. The approach is based on a second-order iterative minimisation of the\ndifference between the measurements and a model based on a ray-approximation to\nthe heterogeneous Green's function. It overcomes the computational burden of\nfull-wave solvers while avoiding the drawbacks of time-of-flight methods.\nThrough the use of a second-order iterative minimisation scheme, applied\nstepwise from low to high frequencies, the effects of scattering are\nincorporated into the inversion.",
    "descriptor": "",
    "authors": [
      "Ashkan Javaherian",
      "Ben Cox"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14098"
  },
  {
    "id": "arXiv:2105.14099",
    "title": "Bridging the Gap Between Practice and PAC-Bayes Theory in Few-Shot  Meta-Learning",
    "abstract": "Despite recent advances in its theoretical understanding, there still remains\na significant gap in the ability of existing PAC-Bayesian theories on\nmeta-learning to explain performance improvements in the few-shot learning\nsetting, where the number of training examples in the target tasks is severely\nlimited. This gap originates from an assumption in the existing theories which\nsupposes that the number of training examples in the observed tasks and the\nnumber of training examples in the target tasks follow the same distribution,\nan assumption that rarely holds in practice. By relaxing this assumption, we\ndevelop two PAC-Bayesian bounds tailored for the few-shot learning setting and\nshow that two existing meta-learning algorithms (MAML and Reptile) can be\nderived from our bounds, thereby bridging the gap between practice and\nPAC-Bayesian theories. Furthermore, we derive a new computationally-efficient\nPACMAML algorithm, and show it outperforms existing meta-learning algorithms on\nseveral few-shot benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Nan Ding",
      "Xi Chen",
      "Tomer Levinboim",
      "Sebastian Goodman",
      "Radu Soricut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14099"
  },
  {
    "id": "arXiv:2105.14100",
    "title": "Latticed $k$-Induction with an Application to Probabilistic Programs",
    "abstract": "We revisit two well-established verification techniques, $k$-induction and\nbounded model checking (BMC), in the more general setting of fixed point theory\nover complete lattices. Our main theoretical contribution is latticed\n$k$-induction, which (i) generalizes classical $k$-induction for verifying\ntransition systems, (ii) generalizes Park induction for bounding fixed points\nof monotonic maps on complete lattices, and (iii) extends from naturals $k$ to\ntransfinite ordinals $\\kappa$, thus yielding $\\kappa$-induction. The\nlattice-theoretic understanding of $k$-induction and BMC enables us to apply\nboth techniques to the fully automatic verification of infinite-state\nprobabilistic programs. Our prototypical implementation manages to\nautomatically verify non-trivial specifications for probabilistic programs\ntaken from the literature that - using existing techniques - cannot be verified\nwithout synthesizing a stronger inductive invariant first.",
    "descriptor": "\nComments: to be published in: CAV (2021)\n",
    "authors": [
      "Kevin Batz",
      "Mingshuai Chen",
      "Benjamin Lucien Kaminski",
      "Joost-Pieter Katoen",
      "Christoph Matheja",
      "Philipp Schr\u00f6er"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14100"
  },
  {
    "id": "arXiv:2105.14103",
    "title": "An Attention Free Transformer",
    "abstract": "We introduce Attention Free Transformer (AFT), an efficient variant of\nTransformers that eliminates the need for dot product self attention. In an AFT\nlayer, the key and value are first combined with a set of learned position\nbiases, the result of which is multiplied with the query in an element-wise\nfashion. This new operation has a memory complexity linear w.r.t. both the\ncontext size and the dimension of features, making it compatible to both large\ninput and model sizes. We also introduce AFT-local and AFT-conv, two model\nvariants that take advantage of the idea of locality and spatial weight sharing\nwhile maintaining global connectivity. We conduct extensive experiments on two\nautoregressive modeling tasks (CIFAR10 and Enwik8) as well as an image\nrecognition task (ImageNet-1K classification). We show that AFT demonstrates\ncompetitive performance on all the benchmarks, while providing excellent\nefficiency at the same time.",
    "descriptor": "",
    "authors": [
      "Shuangfei Zhai",
      "Walter Talbott",
      "Nitish Srivastava",
      "Chen Huang",
      "Hanlin Goh",
      "Ruixiang Zhang",
      "Josh Susskind"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14103"
  },
  {
    "id": "arXiv:2105.14105",
    "title": "Reinforcement Learning reveals fundamental limits on the mixing of  active particles",
    "abstract": "The control of far-from-equilibrium physical systems, including active\nmaterials, has emerged as an important area for the application of\nreinforcement learning (RL) strategies to derive control policies for physical\nsystems. In active materials, non-linear dynamics and long-range interactions\nbetween particles prohibit closed-form descriptions of the system's dynamics\nand prevent explicit solutions to optimal control problems. Due to fundamental\nchallenges in solving for explicit control strategies, RL has emerged as an\napproach to derive control strategies for far-from-equilibrium active matter\nsystems. However, an important open question is how the mathematical structure\nand the physical properties of the active matter systems determine the\ntractability of RL for learning control policies. In this work, we show that RL\ncan only find good strategies to the canonical active matter task of mixing for\nsystems that combine attractive and repulsive particle interactions. Using\nmathematical results from dynamical systems theory, we relate the availability\nof both interaction types with the existence of hyperbolic dynamics and the\nability of RL to find homogeneous mixing strategies. In particular, we show\nthat for drag-dominated translational-invariant particle systems, hyperbolic\ndynamics and, therefore, mixing requires combining attractive and repulsive\ninteractions. Broadly, our work demonstrates how fundamental physical and\nmathematical properties of dynamical systems can enable or constrain\nreinforcement learning-based control.",
    "descriptor": "",
    "authors": [
      "Dominik Schildknecht",
      "Anastasia N. Popova",
      "Jack Stellwagen",
      "Matt Thomson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2105.14105"
  },
  {
    "id": "arXiv:2105.14106",
    "title": "More Is Better: An Analysis of Instance Quantity/Quality Trade-off in  Rehearsal-based Continual Learning",
    "abstract": "The design of machines and algorithms capable of learning in a dynamically\nchanging environment has become an increasingly topical problem with the\nincrease of the size and heterogeneity of data available to learning systems.\nAs a consequence, the key issue of Continual Learning has become that of\naddressing the stability-plasticity dilemma of connectionist systems, as they\nneed to adapt their model without forgetting previously acquired knowledge.\nWithin this context, rehearsal-based methods i.e., solutions in where the\nlearner exploits memory to revisit past data, has proven to be very effective,\nleading to performance at the state-of-the-art. In our study, we propose an\nanalysis of the memory quantity/quality trade-off adopting various data\nreduction approaches to increase the number of instances storable in memory. In\nparticular, we investigate complex instance compression techniques such as deep\nencoders, but also trivial approaches such as image resizing and linear\ndimensionality reduction. Our findings suggest that the optimal trade-off is\nseverely skewed toward instance quantity, where rehearsal approaches with\nseveral heavily compressed instances easily outperform state-of-the-art\napproaches with the same amount of memory at their disposal. Further, in high\nmemory configurations, deep approaches extracting spatial structure combined\nwith extreme resizing (of the order of $8\\times8$ images) yield the best\nresults, while in memory-constrained configurations where deep approaches\ncannot be used due to their memory requirement in training, Extreme Learning\nMachines (ELM) offer a clear advantage.",
    "descriptor": "",
    "authors": [
      "Francesco Pelosin",
      "Andrea Torsello"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14106"
  },
  {
    "id": "arXiv:2105.14107",
    "title": "Data Acquisition for Improving Machine Learning Models",
    "abstract": "The vast advances in Machine Learning over the last ten years have been\npowered by the availability of suitably prepared data for training purposes.\nThe future of ML-enabled enterprise hinges on data. As such, there is already a\nvibrant market offering data annotation services to tailor sophisticated ML\nmodels. In this paper, we present research on the practical problem of\nobtaining data in order to improve the accuracy of ML models. We consider an\nenvironment in which consumers query for data to enhance the accuracy of their\nmodels and data providers who possess data make them available for training\npurposes. We first formalize this interaction process laying out the suitable\nframework and associated parameters for data exchange. We then propose two data\nacquisition strategies that consider a trade-off between exploration during\nwhich we obtain data to learn about the distribution of a provider's data and\nexploitation during which we optimize our data inquiries utilizing the gained\nknowledge. In the first strategy, Estimation and Allocation, we utilize queries\nto estimate the utilities of various predicates while learning about the\ndistribution of the provider's data; then we proceed to the allocation stage in\nwhich we utilize those learned utility estimates to inform our data acquisition\ndecisions. The second algorithmic proposal, named Sequential Predicate\nSelection, utilizes a sampling strategy to explore the distribution of the\nprovider's data, adaptively investing more resources to parts of the data space\nthat are statistically more promising to improve overall model accuracy. We\npresent a detailed experimental evaluation of our proposals utilizing a variety\nof ML models and associated real data sets exploring all applicable parameters\nof interest. We identify trade-offs and highlight the relative benefits of each\nalgorithm to further optimize model accuracy.",
    "descriptor": "\nComments: Accepted by VLDB2020\n",
    "authors": [
      "Yifan Li",
      "Xiaohui Yu",
      "Nick Koudas"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2105.14107"
  },
  {
    "id": "arXiv:2105.14108",
    "title": "Efficient and robust multi-task learning in the brain with modular task  primitives",
    "abstract": "In a real-world setting biological agents do not have infinite resources to\nlearn new things. It is thus useful to recycle previously acquired knowledge in\na way that allows for faster, less resource-intensive acquisition of multiple\nnew skills. Neural networks in the brain are likely not entirely re-trained\nwith new tasks, but how they leverage existing computations to learn new tasks\nis not well understood. In this work, we study this question in artificial\nneural networks trained on commonly used neuroscience paradigms. Building on\nrecent work from the multi-task learning literature, we propose two\ningredients: (1) network modularity, and (2) learning task primitives.\nTogether, these ingredients form inductive biases we call structural and\nfunctional, respectively. Using a corpus of nine different tasks, we show that\na modular network endowed with task primitives allows for learning multiple\ntasks well while keeping parameter counts, and updates, low. We also show that\nthe skills acquired with our approach are more robust to a broad range of\nperturbations compared to those acquired with other multi-task learning\nstrategies. This work offers a new perspective on achieving efficient\nmulti-task learning in the brain, and makes predictions for novel neuroscience\nexperiments in which targeted perturbations are employed to explore solution\nspaces.",
    "descriptor": "",
    "authors": [
      "Christian David Marton",
      "Guillaume Lajoie",
      "Kanaka Rajan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2105.14108"
  },
  {
    "id": "arXiv:2105.14110",
    "title": "MixerGAN: An MLP-Based Architecture for Unpaired Image-to-Image  Translation",
    "abstract": "While attention-based transformer networks achieve unparalleled success in\nnearly all language tasks, the large number of tokens coupled with the\nquadratic activation memory usage makes them prohibitive for visual tasks. As\nsuch, while language-to-language translation has been revolutionized by the\ntransformer model, convolutional networks remain the de facto solution for\nimage-to-image translation. The recently proposed MLP-Mixer architecture\nalleviates some of the speed and memory issues associated with attention-based\nnetworks while still retaining the long-range connections that make transformer\nmodels desirable. Leveraging this efficient alternative to self-attention, we\npropose a new unpaired image-to-image translation model called MixerGAN: a\nsimpler MLP-based architecture that considers long-distance relationships\nbetween pixels without the need for expensive attention mechanisms.\nQuantitative and qualitative analysis shows that MixerGAN achieves competitive\nresults when compared to prior convolutional-based methods.",
    "descriptor": "\nComments: Under Review for NeurIPS 2021\n",
    "authors": [
      "George Cazenavette",
      "Manuel Ladron De Guevara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14110"
  },
  {
    "id": "arXiv:2105.14111",
    "title": "Objective Robustness in Deep Reinforcement Learning",
    "abstract": "We study objective robustness failures, a type of out-of-distribution\nrobustness failure in reinforcement learning (RL). Objective robustness\nfailures occur when an RL agent retains its capabilities off-distribution yet\npursues the wrong objective. We provide the first explicit empirical\ndemonstrations of objective robustness failures and argue that this type of\nfailure is critical to address.",
    "descriptor": "",
    "authors": [
      "Jack Koch",
      "Lauro Langosco",
      "Jacob Pfau",
      "James Le",
      "Lee Sharkey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14111"
  },
  {
    "id": "arXiv:2105.14114",
    "title": "Asymptotically Optimal Bandits under Weighted Information",
    "abstract": "We study the problem of regret minimization in a multi-armed bandit setup\nwhere the agent is allowed to play multiple arms at each round by spreading the\nresources usually allocated to only one arm. At each iteration the agent\nselects a normalized power profile and receives a Gaussian vector as outcome,\nwhere the unknown variance of each sample is inversely proportional to the\npower allocated to that arm. The reward corresponds to a linear combination of\nthe power profile and the outcomes, resembling a linear bandit. By spreading\nthe power, the agent can choose to collect information much faster than in a\ntraditional multi-armed bandit at the price of reducing the accuracy of the\nsamples. This setup is fundamentally different from that of a linear bandit --\nthe regret is known to scale as $\\Theta(\\sqrt{T})$ for linear bandits, while in\nthis setup the agent receives a much more detailed feedback, for which we\nderive a tight $\\log(T)$ problem-dependent lower-bound. We propose a\nThompson-Sampling-based strategy, called Weighted Thompson Sampling (\\WTS),\nthat designs the power profile as its posterior belief of each arm being the\nbest arm, and show that its upper bound matches the derived logarithmic lower\nbound. Finally, we apply this strategy to a problem of control and system\nidentification, where the goal is to estimate the maximum gain (also called\n$\\mathcal{H}_\\infty$-norm) of a linear dynamical system based on batches of\ninput-output samples.",
    "descriptor": "\nComments: 9 content pages, 3 references pages, 22 appendix pages, 4 figures, 34 total pages\n",
    "authors": [
      "Matias I. M\u00fcller",
      "Cristian R. Rojas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14114"
  },
  {
    "id": "arXiv:2105.14115",
    "title": "Towards More Equitable Question Answering Systems: How Much More Data Do  You Need?",
    "abstract": "Question answering (QA) in English has been widely explored, but multilingual\ndatasets are relatively new, with several methods attempting to bridge the gap\nbetween high- and low-resourced languages using data augmentation through\ntranslation and cross-lingual transfer. In this project, we take a step back\nand study which approaches allow us to take the most advantage of existing\nresources in order to produce QA systems in many languages. Specifically, we\nperform extensive analysis to measure the efficacy of few-shot approaches\naugmented with automatic translations and permutations of\ncontext-question-answer pairs. In addition, we make suggestions for future\ndataset development efforts that make better use of a fixed annotation budget,\nwith a goal of increasing the language coverage of QA datasets and systems.\nCode and data for reproducing our experiments are available here:\nhttps://github.com/NavidRajabi/EMQA.",
    "descriptor": "\nComments: Accepted at ACL 2021\n",
    "authors": [
      "Arnab Debnath",
      "Navid Rajabi",
      "Fardina Fathmiul Alam",
      "Antonios Anastasopoulos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14115"
  },
  {
    "id": "arXiv:2105.14116",
    "title": "Visualizing Representations of Adversarially Perturbed Inputs",
    "abstract": "It has been shown that deep learning models are vulnerable to adversarial\nattacks. We seek to further understand the consequence of such attacks on the\nintermediate activations of neural networks. We present an evaluation metric,\nPOP-N, which scores the effectiveness of projecting data to N dimensions under\nthe context of visualizing representations of adversarially perturbed inputs.\nWe conduct experiments on CIFAR-10 to compare the POP-2 score of several\ndimensionality reduction algorithms across various adversarial attacks.\nFinally, we utilize the 2D data corresponding to high POP-2 scores to generate\nexample visualizations.",
    "descriptor": "",
    "authors": [
      "Daniel Steinberg",
      "Paul Munro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14116"
  },
  {
    "id": "arXiv:2105.14117",
    "title": "About Explicit Variance Minimization: Training Neural Networks for  Medical Imaging With Limited Data Annotations",
    "abstract": "Self-supervised learning methods for computer vision have demonstrated the\neffectiveness of pre-training feature representations, resulting in\nwell-generalizing Deep Neural Networks, even if the annotated data are limited.\nHowever, representation learning techniques require a significant amount of\ntime for model training, with most of it time spent on precise hyper-parameter\noptimization and selection of augmentation techniques. We hypothesized that if\nthe annotated dataset has enough morphological diversity to capture the general\npopulation's as is common in medical imaging, for example, due to conserved\nsimilarities of tissue mythologies, the variance error of the trained model is\nthe prevalent component of the Bias-Variance Trade-off. We propose the Variance\nAware Training (VAT) method that exploits this property by introducing the\nvariance error into the model loss function, i.e., enabling minimizing the\nvariance explicitly. Additionally, we provide the theoretical formulation and\nproof of the proposed method to aid in interpreting the approach. Our method\nrequires selecting only one hyper-parameter and was able to match or improve\nthe state-of-the-art performance of self-supervised methods while achieving an\norder of magnitude reduction in the GPU training time. We validated VAT on\nthree medical imaging datasets from diverse domains and various learning\nobjectives. These included a Magnetic Resonance Imaging (MRI) dataset for the\nheart semantic segmentation (MICCAI 2017 ACDC challenge), fundus photography\ndataset for ordinary regression of diabetic retinopathy progression (Kaggle\n2019 APTOS Blindness Detection challenge), and classification of\nhistopathologic scans of lymph node sections (PatchCamelyon dataset).",
    "descriptor": "",
    "authors": [
      "Dmitrii Shubin",
      "Danny Eytan",
      "Sebastian D. Goodfellow"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14117"
  },
  {
    "id": "arXiv:2105.14118",
    "title": "Robust Sample-Based Output-Feedback Path Planning",
    "abstract": "We propose a novel approach for sampling-based and control-based motion\nplanning that combines a representation of the environment obtained via a\nmodified version of optimal Rapidly-exploring Random Trees (RRT*), with\nlandmark-based output-feedback controllers obtained via Control Lyapunov\nFunctions, Control Barrier Functions, and robust Linear Programming. Our\nsolution inherits many benefits of RRT*-like algorithms, such as the ability to\nimplicitly handle arbitrarily complex obstacles, and asymptotic optimality.\nAdditionally, it extends planning beyond the discrete nominal paths, as\nfeedback controllers can correct deviations from such paths, and are robust to\ndiscrepancies between the map used for planning and the real environment.\nWe test our algorithms first in simulations and then in experiments, testing\nthe robustness of the approach to practical conditions, such as deformations of\nthe environment, mismatches in the dynamical model of the robot, and\nmeasurements acquired with a camera with a limited field of view.",
    "descriptor": "\nComments: submitted to IROS2021\n",
    "authors": [
      "Mahroo Bahreinian",
      "Marc Mitjans",
      "Roberto Tron"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14118"
  },
  {
    "id": "arXiv:2105.14119",
    "title": "Towards optimally abstaining from prediction",
    "abstract": "A common challenge across all areas of machine learning is that training data\nis not distributed like test data, due to natural shifts, \"blind spots,\" or\nadversarial examples. We consider a model where one may abstain from\npredicting, at a fixed cost. In particular, our transductive abstention\nalgorithm takes labeled training examples and unlabeled test examples as input,\nand provides predictions with optimal prediction loss guarantees. The loss\nbounds match standard generalization bounds when test examples are i.i.d. from\nthe training distribution, but add an additional term that is the cost of\nabstaining times the statistical distance between the train and test\ndistribution (or the fraction of adversarial examples). For linear regression,\nwe give a polynomial-time algorithm based on Celis-Dennis-Tapia optimization\nalgorithms. For binary classification, we show how to efficiently implement it\nusing a proper agnostic learner (i.e., an Empirical Risk Minimizer) for the\nclass of interest. Our work builds on a recent abstention algorithm of\nGoldwasser, Kalais, and Montasser (2020) for transductive binary\nclassification.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Adam Tauman Kalai",
      "Varun Kanade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14119"
  },
  {
    "id": "arXiv:2105.14125",
    "title": "Joint Optimization of Multi-Objective Reinforcement Learning with Policy  Gradient Based Algorithm",
    "abstract": "Many engineering problems have multiple objectives, and the overall aim is to\noptimize a non-linear function of these objectives. In this paper, we formulate\nthe problem of maximizing a non-linear concave function of multiple long-term\nobjectives. A policy-gradient based model-free algorithm is proposed for the\nproblem. To compute an estimate of the gradient, a biased estimator is\nproposed. The proposed algorithm is shown to achieve convergence to within an\n$\\epsilon$ of the global optima after sampling\n$\\mathcal{O}(\\frac{M^4\\sigma^2}{(1-\\gamma)^8\\epsilon^4})$ trajectories where\n$\\gamma$ is the discount factor and $M$ is the number of the agents, thus\nachieving the same dependence on $\\epsilon$ as the policy gradient algorithm\nfor the standard reinforcement learning.",
    "descriptor": "",
    "authors": [
      "Qinbo Bai",
      "Mridul Agarwal",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14125"
  },
  {
    "id": "arXiv:2105.14127",
    "title": "Risk-Aware Transfer in Reinforcement Learning using Successor Features",
    "abstract": "Sample efficiency and risk-awareness are central to the development of\npractical reinforcement learning (RL) for complex decision-making. The former\ncan be addressed by transfer learning and the latter by optimizing some utility\nfunction of the return. However, the problem of transferring skills in a\nrisk-aware manner is not well-understood. In this paper, we address the problem\nof risk-aware policy transfer between tasks in a common domain that differ only\nin their reward functions, in which risk is measured by the variance of reward\nstreams. Our approach begins by extending the idea of generalized policy\nimprovement to maximize entropic utilities, thus extending policy improvement\nvia dynamic programming to sets of policies and levels of risk-aversion. Next,\nwe extend the idea of successor features (SF), a value function representation\nthat decouples the environment dynamics from the rewards, to capture the\nvariance of returns. Our resulting risk-aware successor features (RaSF)\nintegrate seamlessly within the RL framework, inherit the superior task\ngeneralization ability of SFs, and incorporate risk-awareness into the\ndecision-making. Experiments on a discrete navigation domain and control of a\nsimulated robotic arm demonstrate the ability of RaSFs to outperform\nalternative methods including SFs, when taking the risk of the learned policies\ninto account.",
    "descriptor": "",
    "authors": [
      "Michael Gimelfarb",
      "Andr\u00e9 Barreto",
      "Scott Sanner",
      "Chi-Guhn Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14127"
  },
  {
    "id": "arXiv:2105.14130",
    "title": "3D U-NetR: Low Dose Computed Tomography Reconstruction via Deep Learning  and 3 Dimensional Convolutions",
    "abstract": "In this paper, we introduced a novel deep learning based reconstruction\ntechnique using the correlations of all 3 dimensions with each other by taking\ninto account the correlation between 2-dimensional low-dose CT images. Sparse\nor noisy sinograms are back projected to the image domain with FBP operation,\nthen denoising process is applied with a U-Net like 3 dimensional network\ncalled 3D U-NetR. Proposed network is trained with synthetic and real chest CT\nimages, and 2D U-Net is also trained with the same dataset to prove the\nimportance of the 3rd dimension. Proposed network shows better quantitative\nperformance on SSIM and PSNR. More importantly, 3D U-NetR captures medically\ncritical visual details that cannot be visualized by 2D network.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Doga Gunduzalp",
      "Batuhan Cengiz",
      "Mehmet Ozan Unal",
      "Isa Yildirim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.14130"
  },
  {
    "id": "arXiv:2105.14134",
    "title": "Recommendations and Results Organization in Netflix Search",
    "abstract": "Personalized recommendations on the Netflix Homepage are based on a user's\nviewing habits and the behavior of similar users. These recommendations,\norganized for efficient browsing, enable users to discover the next great video\nto watch and enjoy without additional input or an explicit expression of their\nintents or goals. The Netflix Search experience, on the other hand, allows\nusers to take active control of discovering new videos by explicitly expressing\ntheir entertainment needs via search queries.\nIn this talk, we discuss the importance of producing search results that go\nbeyond traditional keyword-matches to effectively satisfy users' search needs\nin the Netflix entertainment setting. Motivated by users' various search\nintents, we highlight the necessity to improve Search by applying approaches\nthat have historically powered the Homepage. Specifically, we discuss our\napproach to leverage recommendations in the context of Search and to\neffectively organize search results to provide a product experience that\nmeaningfully adds value for our users.",
    "descriptor": "\nComments: Extended abstract submitted to RecSys 2021 Industry Track. 5 pages\n",
    "authors": [
      "Sudarshan Lamkhede",
      "Christoph Kofler"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14134"
  },
  {
    "id": "arXiv:2105.14136",
    "title": "Towards a modeling and analysis environment for industrial IoT systems",
    "abstract": "The development of Industrial Internet of Things systems (IIoT) requires\ntools robust enough to cope with the complexity and heterogeneity of such\nsystems, which are supposed to work in safety-critical conditions. The\navailability of methodologies to support early analysis, verification, and\nvalidation is still an open issue in the research community. The early\nreal-time schedulability analysis can help quantify to what extent the desired\nsystem's timing performance can eventually be achieved. In this paper, we\npresent CHESSIoT, a model-driven environment to support the design and analysis\nof industrial IoT systems. CHESSIoT follows a multi-view, component-based\nmodelling approach with a comprehensive way to perform event-based modelling on\nsystem components for code generation purposes employing an intermediate\nThingML model. To showcase the capability of the extension, we have designed\nand analysed an Industrial real-time safety use case.",
    "descriptor": "\nComments: 7 figures, 10 pages\n",
    "authors": [
      "Felicien Ihirwe",
      "Davide Di Ruscio",
      "Silvia Mazzini",
      "Alfonso Pierantonio"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.14136"
  },
  {
    "id": "arXiv:2105.14137",
    "title": "Aspects of High-Rated Games",
    "abstract": "As the video game market grows larger, it becomes harder to stand out from\nthe crowd. Launching a successful game involves different aspects. But what are\nthey? In this paper, we investigate some aspects of the high-rated games from a\ndataset of 200 projects. The results show that the none of the aspects of this\nstudy have a strong relationship with the game's success. A further analysis on\nthe high-rated games shows that team, technical, and game-design aspects should\nbe the main focus of the game developers.",
    "descriptor": "",
    "authors": [
      "Gabriel Ullmann",
      "Cristiano Politowski",
      "Fabio Petrillo",
      "Yann-G\u00e4el Gu\u00e9h\u00e9neuc"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14137"
  },
  {
    "id": "arXiv:2105.14138",
    "title": "Transformer-Based Source-Free Domain Adaptation",
    "abstract": "In this paper, we study the task of source-free domain adaptation (SFDA),\nwhere the source data are not available during target adaptation. Previous\nworks on SFDA mainly focus on aligning the cross-domain distributions. However,\nthey ignore the generalization ability of the pretrained source model, which\nlargely influences the initial target outputs that are vital to the target\nadaptation stage. To address this, we make the interesting observation that the\nmodel accuracy is highly correlated with whether or not attention is focused on\nthe objects in an image. To this end, we propose a generic and effective\nframework based on Transformer, named TransDA, for learning a generalized model\nfor SFDA. Specifically, we apply the Transformer as the attention module and\ninject it into a convolutional network. By doing so, the model is encouraged to\nturn attention towards the object regions, which can effectively improve the\nmodel's generalization ability on the target domains. Moreover, a novel\nself-supervised knowledge distillation approach is proposed to adapt the\nTransformer with target pseudo-labels, thus further encouraging the network to\nfocus on the object regions. Experiments on three domain adaptation tasks,\nincluding closed-set, partial-set, and open-set adaption, demonstrate that\nTransDA can greatly improve the adaptation accuracy and produce\nstate-of-the-art results. The source code and trained models are available at\nhttps://github.com/ygjwd12345/TransDA.",
    "descriptor": "",
    "authors": [
      "Guanglei Yang",
      "Hao Tang",
      "Zhun Zhong",
      "Mingli Ding",
      "Ling Shao",
      "Nicu Sebe",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14138"
  },
  {
    "id": "arXiv:2105.14141",
    "title": "ARMS: Antithetic-REINFORCE-Multi-Sample Gradient for Binary Variables",
    "abstract": "Estimating the gradients for binary variables is a task that arises\nfrequently in various domains, such as training discrete latent variable\nmodels. What has been commonly used is a REINFORCE based Monte Carlo estimation\nmethod that uses either independent samples or pairs of negatively correlated\nsamples. To better utilize more than two samples, we propose ARMS, an\nAntithetic REINFORCE-based Multi-Sample gradient estimator. ARMS uses a copula\nto generate any number of mutually antithetic samples. It is unbiased, has low\nvariance, and generalizes both DisARM, which we show to be ARMS with two\nsamples, and the leave-one-out REINFORCE (LOORF) estimator, which is ARMS with\nuncorrelated samples. We evaluate ARMS on several datasets for training\ngenerative models, and our experimental results show that it outperforms\ncompeting methods. We also develop a version of ARMS for optimizing the\nmulti-sample variational bound, and show that it outperforms both VIMCO and\nDisARM. The code is publicly available.",
    "descriptor": "",
    "authors": [
      "Alek Dimitriev",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14141"
  },
  {
    "id": "arXiv:2105.14146",
    "title": "Deep Fair Discriminative Clustering",
    "abstract": "Deep clustering has the potential to learn a strong representation and hence\nbetter clustering performance compared to traditional clustering methods such\nas $k$-means and spectral clustering. However, this strong representation\nlearning ability may make the clustering unfair by discovering surrogates for\nprotected information which we empirically show in our experiments. In this\nwork, we study a general notion of group-level fairness for both binary and\nmulti-state protected status variables (PSVs). We begin by formulating the\ngroup-level fairness problem as an integer linear programming formulation whose\ntotally unimodular constraint matrix means it can be efficiently solved via\nlinear programming. We then show how to inject this solver into a\ndiscriminative deep clustering backbone and hence propose a refinement learning\nalgorithm to combine the clustering goal with the fairness objective to learn\nfair clusters adaptively. Experimental results on real-world datasets\ndemonstrate that our model consistently outperforms state-of-the-art fair\nclustering algorithms. Our framework shows promising results for novel\nclustering tasks including flexible fairness constraints, multi-state PSVs and\npredictive clustering.",
    "descriptor": "",
    "authors": [
      "Hongjing Zhang",
      "Ian Davidson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14146"
  },
  {
    "id": "arXiv:2105.14148",
    "title": "OpenMatch: Open-set Consistency Regularization for Semi-supervised  Learning with Outliers",
    "abstract": "Semi-supervised learning (SSL) is an effective means to leverage unlabeled\ndata to improve a model's performance. Typical SSL methods like FixMatch assume\nthat labeled and unlabeled data share the same label space. However, in\npractice, unlabeled data can contain categories unseen in the labeled set,\ni.e., outliers, which can significantly harm the performance of SSL algorithms.\nTo address this problem, we propose a novel Open-set Semi-Supervised Learning\n(OSSL) approach called OpenMatch. Learning representations of inliers while\nrejecting outliers is essential for the success of OSSL. To this end, OpenMatch\nunifies FixMatch with novelty detection based on one-vs-all (OVA) classifiers.\nThe OVA-classifier outputs the confidence score of a sample being an inlier,\nproviding a threshold to detect outliers. Another key contribution is an\nopen-set soft-consistency regularization loss, which enhances the smoothness of\nthe OVA-classifier with respect to input transformations and greatly improves\noutlier detection. OpenMatch achieves state-of-the-art performance on three\ndatasets, and even outperforms a fully supervised model in detecting outliers\nunseen in unlabeled data on CIFAR10.",
    "descriptor": "",
    "authors": [
      "Kuniaki Saito",
      "Donghyun Kim",
      "Kate Saenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14148"
  },
  {
    "id": "arXiv:2105.14149",
    "title": "Log2NS: Enhancing Deep Learning Based Analysis of Logs With Formal to  Prevent Survivorship Bias",
    "abstract": "Analysis of large observational data sets generated by a reactive system is a\ncommon challenge in debugging system failures and determining their root cause.\nOne of the major problems is that these observational data suffer from\nsurvivorship bias. Examples include analyzing traffic logs from networks, and\nsimulation logs from circuit design. In such applications, users want to detect\nnon-spurious correlations from observational data and obtain actionable\ninsights about them. In this paper, we introduce log to Neuro-symbolic\n(Log2NS), a framework that combines probabilistic analysis from machine\nlearning (ML) techniques on observational data with certainties derived from\nsymbolic reasoning on an underlying formal model. We apply the proposed\nframework to network traffic debugging by employing the following steps. To\ndetect patterns in network logs, we first generate global embedding vector\nrepresentations of entities such as IP addresses, ports, and applications.\nNext, we represent large log flow entries as clusters that make it easier for\nthe user to visualize and detect interesting scenarios that will be further\nanalyzed. To generalize these patterns, Log2NS provides an ability to query\nfrom static logs and correlation engines for positive instances, as well as\nformal reasoning for negative and unseen instances. By combining the strengths\nof deep learning and symbolic methods, Log2NS provides a very powerful\nreasoning and debugging tool for log-based data. Empirical evaluations on a\nreal internal data set demonstrate the capabilities of Log2NS.",
    "descriptor": "\nComments: 10 pages, 5 tables, 4 figures\n",
    "authors": [
      "Charanraj Thimmisetty",
      "Praveen Tiwari",
      "Didac Gil de la Iglesia",
      "Nandini Ramanan",
      "Marjorie Sayer",
      "Viswesh Ananthakrishnan",
      "Claudionor Nunes Coelho Jr"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14149"
  },
  {
    "id": "arXiv:2105.14150",
    "title": "Annotation Inconsistency and Entity Bias in MultiWOZ",
    "abstract": "MultiWOZ is one of the most popular multi-domain task-oriented dialog\ndatasets, containing 10K+ annotated dialogs covering eight domains. It has been\nwidely accepted as a benchmark for various dialog tasks, e.g., dialog state\ntracking (DST), natural language generation (NLG), and end-to-end (E2E) dialog\nmodeling. In this work, we identify an overlooked issue with dialog state\nannotation inconsistencies in the dataset, where a slot type is tagged\ninconsistently across similar dialogs leading to confusion for DST modeling. We\npropose an automated correction for this issue, which is present in a whopping\n70% of the dialogs. Additionally, we notice that there is significant entity\nbias in the dataset (e.g., \"cambridge\" appears in 50% of the destination cities\nin the train domain). The entity bias can potentially lead to named entity\nmemorization in generative models, which may go unnoticed as the test set\nsuffers from a similar entity bias as well. We release a new test set with all\nentities replaced with unseen entities. Finally, we benchmark joint goal\naccuracy (JGA) of the state-of-the-art DST baselines on these modified versions\nof the data. Our experiments show that the annotation inconsistency corrections\nlead to 7-10% improvement in JGA. On the other hand, we observe a 29% drop in\nJGA when models are evaluated on the new test set with unseen entities.",
    "descriptor": "\nComments: Accepted by SIGDIAL 2021\n",
    "authors": [
      "Kun Qian",
      "Ahmad Beirami",
      "Zhouhan Lin",
      "Ankita De",
      "Alborz Geramifard",
      "Zhou Yu",
      "Chinnadhurai Sankar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14150"
  },
  {
    "id": "arXiv:2105.14151",
    "title": "Approximate MRAM: High-performance and Power-efficient Computing with  MRAM Chips for Error-tolerant Applications",
    "abstract": "Approximate computing (AC) leverages the inherent error resilience and is\nused in many big-data applications from various domains such as multimedia,\ncomputer vision, signal processing, and machine learning to improve systems\nperformance and power consumption. Like many other approximate circuits and\nalgorithms, the memory subsystem can also be used to enhance performance and\nsave power significantly. This paper proposes an efficient and effective\nsystematic methodology to construct an approximate non-volatile\nmagneto-resistive RAM (MRAM) framework using consumer-off-the-shelf (COTS) MRAM\nchips. In the proposed scheme, an extensive experimental characterization of\nmemory errors is performed by manipulating the write latency of MRAM chips\nwhich exploits the inherent (intrinsic/extrinsic process variation) stochastic\nswitching behavior of magnetic tunnel junctions (MTJs). The experimental\nresults and error-resilient image application reveal that the proposed AC\nframework provides a significant performance improvement and demonstrates a\nmaximum reduction in MRAM write current of ~66% on average with negligible or\nno loss in output quality.",
    "descriptor": "",
    "authors": [
      "Farah Ferdaus",
      "B. M. S. Bahar Talukder",
      "Md Tauhidur Rahman"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2105.14151"
  },
  {
    "id": "arXiv:2105.14152",
    "title": "Radar Odometry Combining Probabilistic Estimation and Unsupervised  Feature Learning",
    "abstract": "This paper presents a radar odometry method that combines probabilistic\ntrajectory estimation and deep learned features without needing groundtruth\npose information. The feature network is trained unsupervised, using only the\non-board radar data. With its theoretical foundation based on a data likelihood\nobjective, our method leverages a deep network for processing rich radar data,\nand a non-differentiable classic estimator for probabilistic inference. We\nprovide extensive experimental results on both the publicly available Oxford\nRadar RobotCar Dataset and an additional 100 km of driving collected in an\nurban setting. Our sliding-window implementation of radar odometry outperforms\nexisting hand-crafted methods and approaches the current state of the art\nwithout requiring a groundtruth trajectory for training. We also demonstrate\nthe effectiveness of radar odometry under adverse weather conditions. Code for\nthis project can be found at: https://github.com/utiasASRL/hero_radar_odometry",
    "descriptor": "\nComments: Accepted to Robotics Science and Systems 2021\n",
    "authors": [
      "Keenan Burnett",
      "David J. Yoon",
      "Angela P. Schoellig",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14152"
  },
  {
    "id": "arXiv:2105.14154",
    "title": "How the University Portal Inspired Changes in the Academic Assessment  Culture",
    "abstract": "Information retrieval (IR) is known facilitator of changes ongoing in human\nsociety and vice versa. This is due to the fact that IR is a key component of\nthe digital ecosystems, where both information providers and information\nconsumers collaboratively address their problems with the use of technologies.\nOrganization and design of such ecosystems drives particular social impact for\nall the players involved. In this paper, we study the impact made by a\nparticular IR ecosystem (semantic portal) used for management of academic\ninformation resources and processes within the Ukrainian higher education. We\nshow how this portal is changing a collective mindset of the academic community\nof its users. We argue that such impact becomes possible due to specific\norganization of the ecosystem, where all the information resources, IR services\nand related analytics (search, assessment, ranking, etc.) and IR users inhabit\nthe same semantic space under umbrella of the corresponding ontologies.\nPersonal values and preferences of the users configure on-the-fly the\ncorresponding IR analytics and enable personalized value-driven IR services,\nmaking everyone feel involved into the organizational decision-making\nprocesses. Four years of active use of this portal in university environment\nhas been reported and related impact is evaluated in this study.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Valerii Semenets",
      "Svitlana Gryshko",
      "Mariia Golovianko",
      "Oleksandr Shevchenko",
      "Liudmyla Titova",
      "Olena Kaikova",
      "Vagan Terziyan",
      "Timo Tiihonen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.14154"
  },
  {
    "id": "arXiv:2105.14155",
    "title": "An $\\ell_p$ Variable Projection Method for Large-Scale Separable  Nonlinear Inverse Problems",
    "abstract": "The variable projection (VarPro) method is an efficient method to solve\nseparable nonlinear least squares problems. In this paper, we propose a\nmodified VarPro for large-scale separable nonlinear inverse problems that\npromotes edge-preserving and sparsity properties on the desired solution and\nenhances the convergence of the parameters that define the forward problem. We\nadopt a majorization minimization method that relies on constructing a\nquadratic tangent majorant to approximate a general $\\ell_p$ regularized\nproblem by an $\\ell_2$ regularized problem that can be solved by the aid of\ngeneralized Krylov subspace methods at a relatively low cost compared to the\noriginal unprojected problem. In addition, we can use more potential general\nregularizers including total variation (TV), framelet, and wavelets operators.\nThe regularization parameter can be defined automatically at each iteration by\nmeans of generalized cross validation. Numerical examples on large-scale\ntwo-dimensional imaging problems arising from blind deconvolution are used to\nhighlight the performance of the proposed approach in both quality of the\nreconstructed image as well as the reconstructed forward operator.",
    "descriptor": "\nComments: 23 pages, 9 figures\n",
    "authors": [
      "Malena Espanol",
      "Mirjeta Pasha"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14155"
  },
  {
    "id": "arXiv:2105.14156",
    "title": "SMASH: Sparse Matrix Atomic Scratchpad Hashing",
    "abstract": "Sparse matrices, more specifically SpGEMM kernels, are commonly found in a\nwide range of applications, spanning graph-based path-finding to machine\nlearning algorithms (e.g., neural networks). A particular challenge in\nimplementing SpGEMM kernels has been the pressure placed on DRAM memory. One\napproach to tackle this problem is to use an inner product method for the\nSpGEMM kernel implementation. While the inner product produces fewer\nintermediate results, it can end up saturating the memory bandwidth, given the\nhigh number of redundant fetches of the input matrix elements. Using an outer\nproduct-based SpGEMM kernel can reduce redundant fetches, but at the cost of\nincreased overhead due to extra computation and memory accesses for\nproducing/managing partial products.\nIn this thesis, we introduce a novel SpGEMM kernel implementation based on\nthe row-wise product approach. We leverage atomic instructions to merge\nintermediate partial products as they are generated. The use of atomic\ninstructions eliminates the need to create partial product matrices.\nTo evaluate our row-wise product approach, we map an optimized SpGEMM kernel\nto a custom accelerator designed to accelerate graph-based applications. The\ntargeted accelerator is an experimental system named PIUMA, being developed by\nIntel. PIUMA provides several attractive features, including fast context\nswitching, user-configurable caches, globally addressable memory, non-coherent\ncaches, and asynchronous pipelines. We tailor our SpGEMM kernel to exploit many\nof the features of the PIUMA fabric.\nThis thesis compares our SpGEMM implementation against prior solutions, all\nmapped to the PIUMA framework. We briefly describe some of the PIUMA\narchitecture features and then delve into the details of our optimized SpGEMM\nkernel. Our SpGEMM kernel can achieve 9.4x speedup as compared to competing\napproaches.",
    "descriptor": "",
    "authors": [
      "Kaustubh Shivdikar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14156"
  },
  {
    "id": "arXiv:2105.14157",
    "title": "SMURF: Efficient and Scalable Metadata Access for Distributed  Applications",
    "abstract": "In parallel with big data processing and analysis dominating the usage of\ndistributed and cloud infrastructures, the demand for distributed metadata\naccess and transfer has increased. In many application domains, the volume of\ndata generated exceeds petabytes, while the corresponding metadata amounts to\nterabytes or even more. This paper proposes a novel solution for efficient and\nscalable metadata access for distributed applications across wide-area\nnetworks, dubbed SMURF. Our solution combines novel pipelining and concurrent\ntransfer mechanisms with reliability, provides distributed continuum caching\nand prefetching strategies to sidestep fetching latency, and achieves scalable\nand high-performance metadata fetch/prefetch services in the cloud. We also\nstudy the phenomenon of semantic locality in real trace logs, which is not well\nutilized in metadata access prediction. We implement a novel prefetch predictor\nbased on this observation and compare it with three existing state-of-the-art\nprefetch schemes on Yahoo! Hadoop audit traces. By effectively caching and\nprefetching metadata based on the access patterns, our continuum caching and\nprefetching mechanism significantly improves local cache hit rate and reduces\nthe average fetching latency. We replayed approximately 20 Million metadata\naccess operations from real audit traces, in which our system achieved 90%\naccuracy during prefetch prediction and reduced the average fetch latency by\n50% compared to the state-of-the-art mechanisms.",
    "descriptor": "",
    "authors": [
      "Bing Zhang",
      "Tevfik Kosar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.14157"
  },
  {
    "id": "arXiv:2105.14158",
    "title": "Unsupervised Action Segmentation with Self-supervised Feature Learning  and Co-occurrence Parsing",
    "abstract": "Temporal action segmentation is a task to classify each frame in the video\nwith an action label. However, it is quite expensive to annotate every frame in\na large corpus of videos to construct a comprehensive supervised training\ndataset. Thus in this work we explore a self-supervised method that operates on\na corpus of unlabeled videos and predicts a likely set of temporal segments\nacross the videos. To do this we leverage self-supervised video classification\napproaches to perform unsupervised feature extraction. On top of these features\nwe develop CAP, a novel co-occurrence action parsing algorithm that can not\nonly capture the correlation among sub-actions underlying the structure of\nactivities, but also estimate the temporal trajectory of the sub-actions in an\naccurate and general way. We evaluate on both classic datasets (Breakfast,\n50Salads) and emerging fine-grained action datasets (FineGym) with more complex\nactivity structures and similar sub-actions. Results show that our method\nachieves state-of-the-art performance on all three datasets with up to 22\\%\nimprovement, and can even outperform some weakly-supervised approaches,\ndemonstrating its effectiveness and generalizability.",
    "descriptor": "",
    "authors": [
      "Zhe Wang",
      "Hao Chen",
      "Xinyu Li",
      "Chunhui Liu",
      "Yuanjun Xiong",
      "Joseph Tighe",
      "Charless Fowlkes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14158"
  },
  {
    "id": "arXiv:2105.14159",
    "title": "Enhancing Environmental Enforcement with Near Real-Time Monitoring:  Likelihood-Based Detection of Structural Expansion of Intensive Livestock  Farms",
    "abstract": "Environmental enforcement has historically relied on physical,\nresource-intensive, and infrequent inspections. Advances in remote sensing and\ncomputer vision have the potential to augment compliance monitoring, by\nproviding early warning signals of permit violations. We demonstrate a process\nfor rapid identification of significant structural expansion using satellite\nimagery and focusing on Concentrated Animal Feeding Operations (CAFOs) as a\ntest case. Unpermitted expansion has been a particular challenge with CAFOs,\nwhich pose significant health and environmental risks. Using a new hand-labeled\ndataset of 175,736 images of 1,513 CAFOs, we combine state-of-the-art building\nsegmentation with a likelihood-based change-point detection model to provide a\nrobust signal of building expansion (AUC = 0.80). A major advantage of this\napproach is that it is able to work with high-cadence (daily to weekly), but\nlower resolution (3m/pixel), satellite imagery. It is also highly generalizable\nand thus provides a near real-time monitoring tool to prioritize enforcement\nresources to other settings where unpermitted construction poses environmental\nrisk, e.g. zoning, habitat modification, or wetland protection.",
    "descriptor": "",
    "authors": [
      "Ben Chugg",
      "Brandon Anderson",
      "Seiji Eicher",
      "Sandy Lee",
      "Daniel E. Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14159"
  },
  {
    "id": "arXiv:2105.14161",
    "title": "Detailed Primary and Secondary Distribution System Model Enhancement  Using AMI Data",
    "abstract": "Reliable and accurate distribution system modeling, including the secondary\nnetwork, is essential in examining distribution system performance with high\npenetration of distributed energy resources (DERs). This paper presents a\nhighly automated, novel method to enhance the accuracy of utility distribution\nfeeder models to capture their performance by matching simulation results with\ncorresponding field measurements. The method is demonstrated using an actual\nfeeder from an electrical utility with high penetration of DERs. The method\nproposed uses advanced metering infrastructure (AMI) voltage and derived active\npower measurements at the customer level, and data acquisition systems (DAS)\nmeasurements at the feeder-head, in conjunction with an AC optimal power flow\n(ACOPF) to estimate customer active and reactive power consumption over a time\nhorizon, while accounting for unmetered loads. Additionally, the method\nproposed estimates both voltage magnitude and angle for each phase at the\nunbalanced distribution substation. Furthermore, the accuracy of the method\ndeveloped is verified by comparing the time-series power flow results obtained\nfrom the enhancement algorithm with OpenDSS results. The proposed approach\nseamlessly manages the data available from the optimization procedure through\nthe final model verification automatically.",
    "descriptor": "",
    "authors": [
      "Karen Montano-Martinez",
      "Student Member",
      "IEEE",
      "Sushrut Thakar",
      "Student Member",
      "IEEE",
      "Shanshan Ma",
      "Member",
      "IEEE",
      "Zahra Soltani",
      "Student Member",
      "IEEE",
      "Vijay Vittal",
      "Life Fellow",
      "IEEE",
      "Mojdeh Khorsand",
      "Member",
      "IEEE",
      "Raja Ayyanar",
      "Senior Member",
      "IEEE",
      "Cynthia Rojas",
      "Member",
      "IEEE"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.14161"
  },
  {
    "id": "arXiv:2105.14162",
    "title": "EDDA: Explanation-driven Data Augmentation to Improve Model and  Explanation Alignment",
    "abstract": "Recent years have seen the introduction of a range of methods for post-hoc\nexplainability of image classifier predictions. However, these post-hoc\nexplanations may not always align perfectly with classifier predictions, which\nposes a significant challenge when attempting to debug models based on such\nexplanations. To this end, we seek a methodology that can improve alignment\nbetween model predictions and explanation method that is both agnostic to the\nmodel and explanation classes and which does not require ground truth\nexplanations. We achieve this through a novel explanation-driven data\naugmentation (EDDA) method that augments the training data with occlusions of\nexisting data stemming from model-explanations; this is based on the simple\nmotivating principle that occluding salient regions for the model prediction\nshould decrease the model confidence in the prediction, while occluding\nnon-salient regions should not change the prediction -- if the model and\nexplainer are aligned. To verify that this augmentation method improves model\nand explainer alignment, we evaluate the methodology on a variety of datasets,\nimage classification models, and explanation methods. We verify in all cases\nthat our explanation-driven data augmentation method improves alignment of the\nmodel and explanation in comparison to no data augmentation and non-explanation\ndriven data augmentation methods. In conclusion, this approach provides a novel\nmodel- and explainer-agnostic methodology for improving alignment between model\npredictions and explanations, which we see as a critical step forward for\npractical deployment and debugging of image classification models.",
    "descriptor": "",
    "authors": [
      "Ruiwen Li",
      "Zhibo Zhang",
      "Jiani Li",
      "Scott Sanner",
      "Jongseong Jang",
      "Yeonjeong Jeong",
      "Dongsub Shim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14162"
  },
  {
    "id": "arXiv:2105.14166",
    "title": "Rejection sampling from shape-constrained distributions in sublinear  time",
    "abstract": "We consider the task of generating exact samples from a target distribution,\nknown up to normalization, over a finite alphabet. The classical algorithm for\nthis task is rejection sampling, and although it has been used in practice for\ndecades, there is surprisingly little study of its fundamental limitations. In\nthis work, we study the query complexity of rejection sampling in a minimax\nframework for various classes of discrete distributions. Our results provide\nnew algorithms for sampling whose complexity scales sublinearly with the\nalphabet size. When applied to adversarial bandits, we show that a slight\nmodification of the Exp3 algorithm reduces the per-iteration complexity from\n$\\mathcal O(K)$ to $\\mathcal O(\\log^2 K)$, where $K$ is the number of arms.",
    "descriptor": "\nComments: 23 pages, 5 figures\n",
    "authors": [
      "Sinho Chewi",
      "Patrik Gerber",
      "Chen Lu",
      "Thibaut Le Gouic",
      "Philippe Rigollet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14166"
  },
  {
    "id": "arXiv:2105.14167",
    "title": "NeuralLog: Natural Language Inference with Joint Neural and Logical  Reasoning",
    "abstract": "Deep learning (DL) based language models achieve high performance on various\nbenchmarks for Natural Language Inference (NLI). And at this time, symbolic\napproaches to NLI are receiving less attention. Both approaches (symbolic and\nDL) have their advantages and weaknesses. However, currently, no method\ncombines them in a system to solve the task of NLI. To merge symbolic and deep\nlearning methods, we propose an inference framework called NeuralLog, which\nutilizes both a monotonicity-based logical inference engine and a neural\nnetwork language model for phrase alignment. Our framework models the NLI task\nas a classic search problem and uses the beam search algorithm to search for\noptimal inference paths. Experiments show that our joint logic and neural\ninference system improves accuracy on the NLI task and can achieve state-of-art\naccuracy on the SICK and MED datasets.",
    "descriptor": "\nComments: 8 pages, 4 figures, The 10th Joint Conference on Lexical and Computational Semantics (*SEM2021) @ ACL2021\n",
    "authors": [
      "Zeming Chen",
      "Qiyue Gao",
      "Lawrence S. Moss"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14167"
  },
  {
    "id": "arXiv:2105.14170",
    "title": "Towards a Rigorous Statistical Analysis of Empirical Password Datasets",
    "abstract": "In this paper we consider the following problem: given $N$ independent\nsamples from an unknown distribution $\\mathcal{P}$ over passwords $pwd_1,pwd_2,\n\\ldots$ can we generate high confidence upper/lower bounds on the guessing\ncurve $\\lambda_G \\doteq \\sum_{i=1}^G p_i$ where $p_i=\\Pr[pwd_i]$ and the\npasswords are ordered such that $p_i \\geq p_{i+1}$. Intuitively, $\\lambda_G$\nrepresents the probability that an attacker who knows the distribution\n$\\mathcal{P}$ can guess a random password $pwd \\leftarrow \\mathcal{P}$ within\n$G$ guesses. Understanding how $\\lambda_G$ increases with the number of guesses\n$G$ can help quantify the damage of a password cracking attack and inform\npassword policies. Despite an abundance of large (breached) password datasets\nupper/lower bounding $\\lambda_G$ remains a challenging problem. We introduce\nseveral statistical techniques to derive tighter upper/lower bounds on the\nguessing curve $\\lambda_G$ which hold with high confidence. We apply our\ntechniques to analyze $9$ large password datasets finding that our new lower\nbounds dramatically improve upon prior work. Our empirical analysis shows that\neven state-of-the-art password cracking models are significantly less guess\nefficient than an attacker who knows the distribution. When $G$ is not too\nlarge we find that our upper/lower bounds on $\\lambda_G$ are both very close to\nthe empirical distribution which justifies the use of the empirical\ndistribution in settings where $G$ is not too large i.e., $G \\ll N$ closely\napproximates $\\lambda_G$. The analysis also highlights regions of the curve\nwhere we can, with high confidence, conclude that the empirical distribution\nsignificantly overestimates $\\lambda_G$. Our new statistical techniques yield\nsubstantially tighter upper/lower bounds on $\\lambda_G$ though there are still\nregions of the curve where the best upper/lower bounds diverge significantly.",
    "descriptor": "",
    "authors": [
      "Jeremiah Blocki",
      "Peiyuan Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14170"
  },
  {
    "id": "arXiv:2105.14171",
    "title": "The Definitions of Interpretability and Learning of Interpretable Models",
    "abstract": "As machine learning algorithms getting adopted in an ever-increasing number\nof applications, interpretation has emerged as a crucial desideratum. In this\npaper, we propose a mathematical definition for the human-interpretable model.\nIn particular, we define interpretability between two information process\nsystems. If a prediction model is interpretable by a human recognition system\nbased on the above interpretability definition, the prediction model is defined\nas a completely human-interpretable model. We further design a practical\nframework to train a completely human-interpretable model by user interactions.\nExperiments on image datasets show the advantages of our proposed model in two\naspects: 1) The completely human-interpretable model can provide an entire\ndecision-making process that is human-understandable; 2) The completely\nhuman-interpretable model is more robust against adversarial attacks.",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Weishen Pan",
      "Changshui Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14171"
  },
  {
    "id": "arXiv:2105.14172",
    "title": "A Stochastic Alternating Balance $k$-Means Algorithm for Fair Clustering",
    "abstract": "In the application of data clustering to human-centric decision-making\nsystems, such as loan applications and advertisement recommendations, the\nclustering outcome might discriminate against people across different\ndemographic groups, leading to unfairness. A natural conflict occurs between\nthe cost of clustering (in terms of distance to cluster centers) and the\nbalance representation of all demographic groups across the clusters, leading\nto a bi-objective optimization problem that is nonconvex and nonsmooth. To\ndetermine the complete trade-off between these two competing goals, we design a\nnovel stochastic alternating balance fair $k$-means (SAfairKM) algorithm, which\nconsists of alternating classical mini-batch $k$-means updates and group swap\nupdates. The number of $k$-means updates and the number of swap updates\nessentially parameterize the weight put on optimizing each objective function.\nOur numerical experiments show that the proposed SAfairKM algorithm is robust\nand computationally efficient in constructing well-spread and high-quality\nPareto fronts both on synthetic and real datasets. Moreover, we propose a novel\ncompanion algorithm, the stochastic alternating bi-objective gradient descent\n(SA2GD) algorithm, which can handle a smooth version of the considered\nbi-objective fair $k$-means problem, more amenable for analysis. A sublinear\nconvergence rate of $\\mathcal{O}(1/T)$ is established under strong convexity\nfor the determination of a stationary point of a weighted sum of the two\nfunctions parameterized by the number of steps or updates on each function.",
    "descriptor": "",
    "authors": [
      "Suyun Liu",
      "Luis Nunes Vicente"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14172"
  },
  {
    "id": "arXiv:2105.14173",
    "title": "FoveaTer: Foveated Transformer for Image Classification",
    "abstract": "Many animals and humans process the visual field with a varying spatial\nresolution (foveated vision) and use peripheral processing to make eye\nmovements and point the fovea to acquire high-resolution information about\nobjects of interest. This architecture results in computationally efficient\nrapid scene exploration. Recent progress in vision Transformers has brought\nabout new alternatives to the traditionally convolution-reliant computer vision\nsystems. However, these models do not explicitly model the foveated properties\nof the visual system nor the interaction between eye movements and the\nclassification task. We propose foveated Transformer (FoveaTer) model, which\nuses pooling regions and saccadic movements to perform object classification\ntasks using a vision Transformer architecture. Our proposed model pools the\nimage features using squared pooling regions, an approximation to the\nbiologically-inspired foveated architecture, and uses the pooled features as an\ninput to a Transformer Network. It decides on the following fixation location\nbased on the attention assigned by the Transformer to various locations from\nprevious and present fixations. The model uses a confidence threshold to stop\nscene exploration, allowing to dynamically allocate more fixation/computational\nresources to more challenging images. We construct an ensemble model using our\nproposed model and unfoveated model, achieving an accuracy 1.36% below the\nunfoveated model with 22% computational savings. Finally, we demonstrate our\nmodel's robustness against adversarial attacks, where it outperforms the\nunfoveated model.",
    "descriptor": "\nComments: 7 figures\n",
    "authors": [
      "Aditya Jonnalagadda",
      "William Wang",
      "Miguel P. Eckstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14173"
  },
  {
    "id": "arXiv:2105.14174",
    "title": "Multi-Label Few-Shot Learning for Aspect Category Detection",
    "abstract": "Aspect category detection (ACD) in sentiment analysis aims to identify the\naspect categories mentioned in a sentence. In this paper, we formulate ACD in\nthe few-shot learning scenario. However, existing few-shot learning approaches\nmainly focus on single-label predictions. These methods can not work well for\nthe ACD task since a sentence may contain multiple aspect categories.\nTherefore, we propose a multi-label few-shot learning method based on the\nprototypical network. To alleviate the noise, we design two effective attention\nmechanisms. The support-set attention aims to extract better prototypes by\nremoving irrelevant aspects. The query-set attention computes multiple\nprototype-specific representations for each query instance, which are then used\nto compute accurate distances with the corresponding prototypes. To achieve\nmulti-label inference, we further learn a dynamic threshold per instance by a\npolicy network. Extensive experimental results on three datasets demonstrate\nthat the proposed method significantly outperforms strong baselines.",
    "descriptor": "\nComments: Accepted by ACL 2021 main conference\n",
    "authors": [
      "Mengting Hu",
      "Shiwan Zhao",
      "Honglei Guo",
      "Chao Xue",
      "Hang Gao",
      "Tiegang Gao",
      "Renhong Cheng",
      "Zhong Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14174"
  },
  {
    "id": "arXiv:2105.14177",
    "title": "The Jacobi sums over Galois rings of arbitrary characters and their  applications in constructing asymptotically optimal codebooks",
    "abstract": "Codebooks with small maximum cross-correlation amplitudes are used to\ndistinguish the signals from different users in CDMA communication systems. In\nthis paper, we first study the Jacobi sums over Galois rings of arbitrary\ncharacteristics and completely determine their absolute values, which extends\nthe work in [34], where the Jacobi sums over Galois rings with characteristics\nof a square of a prime number were discussed. Then, the deterministic\nconstruction of codebooks based on the Jacobi sums over Galois rings of\narbitrary characteristics is presented, which produces asymptotically optimal\ncodebooks with respect to the Welch bound. In addition, the parameters of the\ncodebooks provided in this paper are new.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2001.04028\n",
    "authors": [
      "Deng-Ming Xu",
      "Chen Meng",
      "Gang Wang",
      "Fang-Wei Fu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.14177"
  },
  {
    "id": "arXiv:2105.14179",
    "title": "Investigating the Significance of Bellwether Effect to Improve Software  Effort Estimation",
    "abstract": "Bellwether effect refers to the existence of exemplary projects (called the\nBellwether) within a historical dataset to be used for improved prediction\nperformance. Recent studies have shown an implicit assumption of using recently\ncompleted projects (referred to as moving window) for improved prediction\naccuracy. In this paper, we investigate the Bellwether effect on software\neffort estimation accuracy using moving windows. The existence of the\nBellwether was empirically proven based on six postulations. We apply\nstatistical stratification and Markov chain methodology to select the\nBellwether moving window. The resulting Bellwether moving window is used to\npredict the software effort of a new project. Empirical results show that\nBellwether effect exist in chronological datasets with a set of exemplary and\nrecently completed projects representing the Bellwether moving window. Result\nfrom this study has shown that the use of Bellwether moving window with the\nGaussian weighting function significantly improve the prediction accuracy.",
    "descriptor": "\nComments: Conference paper, 13 papers, 3 figures, 9 tables. arXiv admin note: text overlap with arXiv:2105.07366\n",
    "authors": [
      "Solomon Mensah",
      "Jacky Keung",
      "Stephen G. MacDonell",
      "Michael F. Bosu",
      "Kwabena E. Bennin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14179"
  },
  {
    "id": "arXiv:2105.14183",
    "title": "Verified Quadratic Virtual Substitution for Real Arithmetic",
    "abstract": "This paper presents a formally verified quantifier elimination (QE) algorithm\nfor first-order real arithmetic by linear and quadratic virtual substitution\n(VS) in Isabelle/HOL. The Tarski-Seidenberg theorem established that the\nfirst-order logic of real arithmetic is decidable by QE. However, in practice,\nQE algorithms are highly complicated and often combine multiple methods for\nperformance. VS is a practically successful method for QE that targets formulas\nwith low-degree polynomials. To our knowledge, this is the first work to\nformalize VS for quadratic real arithmetic including inequalities. The proofs\nnecessitate various contributions to the existing multivariate polynomial\nlibraries in Isabelle/HOL, including a method for re-indexing variables in a\npolynomial. Our framework is modularized and easily expandable (to facilitate\nintegrating future optimizations), and could serve as a basis for developing a\ngeneral-purpose QE algorithm. Further, as our formalization is designed with\npracticality in mind, we export our development to SML and test the resulting\ncode on 378 benchmarks from the literature, comparing to Redlog, Z3,\nMathematica, and SMT-RAT.",
    "descriptor": "",
    "authors": [
      "Matias Scharager",
      "Katherine Cordwell",
      "Stefan Mitsch",
      "Andr\u00e9 Platzer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14183"
  },
  {
    "id": "arXiv:2105.14184",
    "title": "E2ETag: An End-to-End Trainable Method for Generating and Detecting  Fiducial Markers",
    "abstract": "Existing fiducial markers solutions are designed for efficient detection and\ndecoding, however, their ability to stand out in natural environments is\ndifficult to infer from relatively limited analysis. Furthermore, worsening\nperformance in challenging image capture scenarios - such as poor exposure,\nmotion blur, and off-axis viewing - sheds light on their limitations. E2ETag\nintroduces an end-to-end trainable method for designing fiducial markers and a\ncomplimentary detector. By introducing back-propagatable marker augmentation\nand superimposition into training, the method learns to generate markers that\ncan be detected and classified in challenging real-world environments using a\nfully convolutional detector network. Results demonstrate that E2ETag\noutperforms existing methods in ideal conditions and performs much better in\nthe presence of motion blur, contrast fluctuations, noise, and off-axis viewing\nangles. Source code and trained models are available at\nhttps://github.com/jbpeace/E2ETag.",
    "descriptor": "\nComments: Accepted for publication at BMVC2020\n",
    "authors": [
      "J. Brennan Peace",
      "Eric Psota",
      "Yanfeng Liu",
      "Lance C. P\u00e9rez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14184"
  },
  {
    "id": "arXiv:2105.14185",
    "title": "FCPose: Fully Convolutional Multi-Person Pose Estimation with Dynamic  Instance-Aware Convolutions",
    "abstract": "We propose a fully convolutional multi-person pose estimation framework using\ndynamic instance-aware convolutions, termed FCPose. Different from existing\nmethods, which often require ROI (Region of Interest) operations and/or\ngrouping post-processing, FCPose eliminates the ROIs and grouping\npost-processing with dynamic instance-aware keypoint estimation heads. The\ndynamic keypoint heads are conditioned on each instance (person), and can\nencode the instance concept in the dynamically-generated weights of their\nfilters. Moreover, with the strong representation capacity of dynamic\nconvolutions, the keypoint heads in FCPose are designed to be very compact,\nresulting in fast inference and making FCPose have almost constant inference\ntime regardless of the number of persons in the image. For example, on the COCO\ndataset, a real-time version of FCPose using the DLA-34 backbone infers about\n4.5x faster than Mask R-CNN (ResNet-101) (41.67 FPS vs. 9.26FPS) while\nachieving improved performance. FCPose also offers better speed/accuracy\ntrade-off than other state-of-the-art methods. Our experiment results show that\nFCPose is a simple yet effective multi-person pose estimation framework. Code\nis available at: https://git.io/AdelaiDet",
    "descriptor": "\nComments: Accepted to Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR) 2021. Code is at this https URL\n",
    "authors": [
      "Weian Mao",
      "Zhi Tian",
      "Xinlong Wang",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14185"
  },
  {
    "id": "arXiv:2105.14186",
    "title": "Improved, Extended, and Total Impact Factor of a Journal",
    "abstract": "In this short paper we recall the (Garfield) Impact Factor of a Journal, we\nimprove and extend it, and eventually we present the Total Impact Factor that\nreflects the most accurate impact factor.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Florentin Smarandache"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2105.14186"
  },
  {
    "id": "arXiv:2105.14188",
    "title": "We Know What You Want: An Advertising Strategy Recommender System for  Online Advertising",
    "abstract": "Advertisers play an important role in e-commerce platforms, whose advertising\nexpenditures are the main source of revenue for e-commerce platforms.\nTherefore, providing advertisers with a better advertising experience by\nreducing their cost of trial and error during ad real-time bidding is crucial\nto the long-term revenue of e-commerce platforms. To achieve this goal, the\nadvertising platform needs to understand the advertisers' unique marketing\ndemands and actively recommend personalized and optimal advertising strategies\nfor them. In this work, we first deploy a prototype recommender system on\nTaobao display advertising platform for constant bid and crowd optimization.\nThen, we propose a novel recommender system for dynamic bidding strategy\nrecommendation, which models the advertiser's strategy recommendation problem\nas a contextual bandit problem. We use a neural network as the agent to predict\nthe advertisers' demands based on their profile and historical adoption\nbehaviors. Based on the estimated demand, we apply simulated bidding to derive\nthe optimal bidding strategy for recommendation and interact with the\nadvertiser by displaying the possible advertising performance. To solve the\nexploration/exploitation dilemma, we use Dropout to represent the uncertainty\nof the network, which approximately equals to conduct Thompson sampling for\nefficient strategy exploration. Online evaluations show that the system can\noptimize the advertisers' advertising performance, and advertisers are willing\nto open the system, select and adopt the suggestions, which further increases\nthe platform's revenue income. Simulation experiments based on Alibaba online\nbidding data prove that the agent can effectively optimize the adoption rate of\nadvertisers, and Thompson sampling can better balance exploration and\nexploitation to further optimize the performance of the model.",
    "descriptor": "\nComments: Accepted by KDD 2021\n",
    "authors": [
      "Liyi Guo",
      "Junqi Jin",
      "Haoqi Zhang",
      "Zhenzhe Zheng",
      "Zhiye Yang",
      "Zhizhuang Xing",
      "Fei Pan",
      "Fan Wu",
      "Lvyin Niu",
      "Haiyang Xu",
      "Chuan Yu",
      "Yuning Jiang",
      "Xiaoqiang Zhu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14188"
  },
  {
    "id": "arXiv:2105.14189",
    "title": "Quotation Recommendation and Interpretation Based on Transformation from  Queries to Quotations",
    "abstract": "To help individuals express themselves better, quotation recommendation is\nreceiving growing attention. Nevertheless, most prior efforts focus on modeling\nquotations and queries separately and ignore the relationship between the\nquotations and the queries. In this work, we introduce a transformation matrix\nthat directly maps the query representations to quotation representations. To\nbetter learn the mapping relationship, we employ a mapping loss that minimizes\nthe distance of two semantic spaces (one for quotation and another for\nmapped-query). Furthermore, we explore using the words in history queries to\ninterpret the figurative language of quotations, where quotation-aware\nattention is applied on top of history queries to highlight the indicator\nwords. Experiments on two datasets in English and Chinese show that our model\noutperforms previous state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Lingzhi Wang",
      "Xingshan Zeng",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.14189"
  },
  {
    "id": "arXiv:2105.14190",
    "title": "RaspberryPI for mosquito neutralization by power laser",
    "abstract": "In this article for the first time, comprehensive studies of mosquito\nneutralization using machine vision and a 1 W power laser are considered.\nDeveloped laser installation with Raspberry Pi that changing the direction of\nthe laser with a galvanometer. We developed a program for mosquito tracking in\nreal. The possibility of using deep neural networks, Haar cascades, machine\nlearning for mosquito recognition was considered. We considered in detail the\nclassification problems of mosquitoes in images. A recommendation is given for\nthe implementation of this device based on a microcontroller for subsequent use\nas part of an unmanned aerial vehicle. Any harmful insects in the fields can be\nused as objects for control.",
    "descriptor": "",
    "authors": [
      "R. Ildar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14190"
  },
  {
    "id": "arXiv:2105.14191",
    "title": "Instance Segmentation of Microscopic Foraminifera",
    "abstract": "Foraminifera are single-celled marine organisms that construct shells that\nremain as fossils in the marine sediments. Classifying and counting these\nfossils are important in e.g. paleo-oceanographic and -climatological research.\nHowever, the identification and counting process has been performed manually\nsince the 1800s and is laborious and time-consuming. In this work, we present a\ndeep learning-based instance segmentation model for classifying, detecting, and\nsegmenting microscopic foraminifera. Our model is based on the Mask R-CNN\narchitecture, using model weight parameters that have learned on the COCO\ndetection dataset. We use a fine-tuning approach to adapt the parameters on a\nnovel object detection dataset of more than 7000 microscopic foraminifera and\nsediment grains. The model achieves a (COCO-style) average precision of $0.78\n\\pm 0.00$ on the classification and detection task, and $0.80 \\pm 0.00$ on the\nsegmentation task. When the model is evaluated without challenging sediment\ngrain images, the average precision for both tasks increases to $0.84 \\pm 0.00$\nand $0.86 \\pm 0.00$, respectively. Prediction results are analyzed both\nquantitatively and qualitatively and discussed. Based on our findings we\npropose several directions for future work, and conclude that our proposed\nmodel is an important step towards automating the identification and counting\nof microscopic foraminifera.",
    "descriptor": "\nComments: 18 pages, 14 figures. Submitted to Applied Sciences\n",
    "authors": [
      "Thomas Haugland Johansen",
      "Steffen Aagaard S\u00f8rensen",
      "Kajsa M\u00f8llersen",
      "Fred Godtliebsen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14191"
  },
  {
    "id": "arXiv:2105.14195",
    "title": "A Survey of Performance Optimization in Neural Network-Based Video  Analytics Systems",
    "abstract": "Video analytics systems perform automatic events, movements, and actions\nrecognition in a video and make it possible to execute queries on the video. As\na result of a large number of video data that need to be processed, optimizing\nthe performance of video analytics systems has become an important research\ntopic. Neural networks are the state-of-the-art for performing video analytics\ntasks such as video annotation and object detection. Prior survey papers\nconsider application-specific video analytics techniques that improve accuracy\nof the results; however, in this survey paper, we provide a review of the\ntechniques that focus on optimizing the performance of Neural Network-Based\nVideo Analytics Systems.",
    "descriptor": "",
    "authors": [
      "Nada Ibrahim",
      "Preeti Maurya",
      "Omid Jafari",
      "Parth Nagarkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14195"
  },
  {
    "id": "arXiv:2105.14196",
    "title": "Classifying States of Cooking Objects Using Convolutional Neural Network",
    "abstract": "Automated cooking machine is a goal for the future. The main aim is to make\nthe cooking process easier, safer, and create human welfare. To allow robots to\naccurately perform the cooking activities, it is important for them to\nunderstand the cooking environment and recognize the objects, especially\ncorrectly identifying the state of the cooking objects. This will significantly\nimprove the correctness of the following cooking recipes. In this project,\nseveral parts of the experiment were conducted to design a robust deep\nconvolutional neural network for classifying the state of the cooking objects\nfrom scratch. The model is evaluated by using various techniques, such as\nadjusting architecture layers, tuning key hyperparameters, and using different\noptimization techniques to maximize the accuracy of state classification.",
    "descriptor": "\nComments: 6 pages,9 figures, 5 tables\n",
    "authors": [
      "Qi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14196"
  },
  {
    "id": "arXiv:2105.14201",
    "title": "Automated Timeline Length Selection for Flexible Timeline Summarization",
    "abstract": "By producing summaries for long-running events, timeline summarization (TLS)\nunderpins many information retrieval tasks. Successful TLS requires identifying\nan appropriate set of key dates (the timeline length) to cover. However, doing\nso is challenging as the right length can change from one topic to another.\nExisting TLS solutions either rely on an event-agnostic fixed length or an\nexpert-supplied setting. Neither of the strategies is desired for real-life TLS\nscenarios. A fixed, event-agnostic setting ignores the diversity of events and\ntheir development and hence can lead to low-quality TLS. Relying on\nexpert-crafted settings is neither scalable nor sustainable for processing many\ndynamically changing events. This paper presents a better TLS approach for\nautomatically and dynamically determining the TLS timeline length. We achieve\nthis by employing the established elbow method from the machine learning\ncommunity to automatically find the minimum number of dates within the time\nseries to generate concise and informative summaries. We applied our approach\nto four TLS datasets of English and Chinese and compared them against three\nprior methods. Experimental results show that our approach delivers comparable\nor even better summaries over state-of-art TLS methods, but it achieves this\nwithout expert involvement.",
    "descriptor": "",
    "authors": [
      "Xi Li",
      "Qianren Mao",
      "Hao Peng",
      "Hongdong Zhu",
      "Jianxin Li",
      "Zheng Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14201"
  },
  {
    "id": "arXiv:2105.14202",
    "title": "Learning Convolutions with Only Additions",
    "abstract": "Compared with cheap addition operation, multiplication operation is of much\nhigher computation complexity. The widely-used convolutions in deep neural\nnetworks are exactly cross-correlation to measure the similarity between input\nfeature and convolution filters, which involves massive multiplications between\nfloat values. In this paper, we present adder networks (AdderNets) to trade\nthese massive multiplications in deep neural networks, especially convolutional\nneural networks (CNNs), for much cheaper additions to reduce computation costs.\nIn AdderNets, we take the $\\ell_1$-norm distance between filters and input\nfeature as the output response. The influence of this new similarity measure on\nthe optimization of neural network have been thoroughly analyzed. To achieve a\nbetter performance, we develop a special training approach for AdderNets by\ninvestigating the $\\ell_p$-norm. We then propose an adaptive learning rate\nstrategy to enhance the training procedure of AdderNets according to the\nmagnitude of each neuron's gradient. As a result, the proposed AdderNets can\nachieve 75.7% Top-1 accuracy 92.3% Top-5 accuracy using ResNet-50 on the\nImageNet dataset without any multiplication in convolutional layer. Moreover,\nwe develop a theoretical foundation for AdderNets, by showing that both the\nsingle hidden layer AdderNet and the width-bounded deep AdderNet with ReLU\nactivation functions are universal function approximators. These results match\nthose of the traditional neural networks using the more complex multiplication\nunits. An approximation bound for AdderNets with a single hidden layer is also\npresented.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1912.13200\n",
    "authors": [
      "Hanting Chen",
      "Yunhe Wang",
      "Chang Xu",
      "Chao Xu",
      "Chunjing Xu",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14202"
  },
  {
    "id": "arXiv:2105.14203",
    "title": "Understanding Instance-based Interpretability of Variational  Auto-Encoders",
    "abstract": "Instance-based interpretation methods have been widely studied for supervised\nlearning methods as they help explain how black box neural networks predict.\nHowever, instance-based interpretations remain ill-understood in the context of\nunsupervised learning. In this paper, we investigate influence functions [20],\na popular instance-based interpretation method, for a class of deep generative\nmodels called variational auto-encoders (VAE). We formally frame the\ncounter-factual question answered by influence functions in this setting, and\nthrough theoretical analysis, examine what they reveal about the impact of\ntraining samples on classical unsupervised learning methods. We then introduce\nVAE-TracIn, a computationally efficient and theoretically sound solution based\non Pruthi et al. [28], for VAEs. Finally, we evaluate VAE-TracIn on several\nreal world datasets with extensive quantitative and qualitative analysis.",
    "descriptor": "",
    "authors": [
      "Zhifeng Kong",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14203"
  },
  {
    "id": "arXiv:2105.14207",
    "title": "Maintaining Common Ground in Dynamic Environments",
    "abstract": "Common grounding is the process of creating and maintaining mutual\nunderstandings, which is a critical aspect of sophisticated human\ncommunication. While various task settings have been proposed in existing\nliterature, they mostly focus on creating common ground under static context\nand ignore the aspect of maintaining them overtime under dynamic context. In\nthis work, we propose a novel task setting to study the ability of both\ncreating and maintaining common ground in dynamic environments. Based on our\nminimal task formulation, we collected a large-scale dataset of 5,617 dialogues\nto enable fine-grained evaluation and analysis of various dialogue systems.\nThrough our dataset analyses, we highlight novel challenges introduced in our\nsetting, such as the usage of complex spatio-temporal expressions to create and\nmaintain common ground. Finally, we conduct extensive experiments to assess the\ncapabilities of our baseline dialogue system and discuss future prospects of\nour research.",
    "descriptor": "\nComments: Accepted at TACL; pre-MIT Press publication version\n",
    "authors": [
      "Takuma Udagawa",
      "Akiko Aizawa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14207"
  },
  {
    "id": "arXiv:2105.14209",
    "title": "Grammatical Error Correction as GAN-like Sequence Labeling",
    "abstract": "In Grammatical Error Correction (GEC), sequence labeling models enjoy fast\ninference compared to sequence-to-sequence models; however, inference in\nsequence labeling GEC models is an iterative process, as sentences are passed\nto the model for multiple rounds of correction, which exposes the model to\nsentences with progressively fewer errors at each round. Traditional GEC models\nlearn from sentences with fixed error rates. Coupling this with the iterative\ncorrection process causes a mismatch between training and inference that\naffects final performance. In order to address this mismatch, we propose a\nGAN-like sequence labeling model, which consists of a grammatical error\ndetector as a discriminator and a grammatical error labeler with Gumbel-Softmax\nsampling as a generator. By sampling from real error distributions, our errors\nare more genuine compared to traditional synthesized GEC errors, thus\nalleviating the aforementioned mismatch and allowing for better training. Our\nresults on several evaluation benchmarks demonstrate that our proposed approach\nis effective and improves the previous state-of-the-art baseline.",
    "descriptor": "\nComments: Accepted by ACL21, Findings\n",
    "authors": [
      "Kevin Parnow",
      "Zuchao Li",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14209"
  },
  {
    "id": "arXiv:2105.14210",
    "title": "Exploiting Position Bias for Robust Aspect Sentiment Classification",
    "abstract": "Aspect sentiment classification (ASC) aims at determining sentiments\nexpressed towards different aspects in a sentence. While state-of-the-art ASC\nmodels have achieved remarkable performance, they are recently shown to suffer\nfrom the issue of robustness. Particularly in two common scenarios: when\ndomains of test and training data are different (out-of-domain scenario) or\ntest data is adversarially perturbed (adversarial scenario), ASC models may\nattend to irrelevant words and neglect opinion expressions that truly describe\ndiverse aspects. To tackle the challenge, in this paper, we hypothesize that\nposition bias (i.e., the words closer to a concerning aspect would carry a\nhigher degree of importance) is crucial for building more robust ASC models by\nreducing the probability of mis-attending. Accordingly, we propose two\nmechanisms for capturing position bias, namely position-biased weight and\nposition-biased dropout, which can be flexibly injected into existing models to\nenhance representations for classification. Experiments conducted on\nout-of-domain and adversarial datasets demonstrate that our proposed approaches\nlargely improve the robustness and effectiveness of current models.",
    "descriptor": "\nComments: 7 pages, 2 figures, 4 tables, accepted to Findings of ACL 2021. Repo: this https URL\n",
    "authors": [
      "Fang Ma",
      "Chen Zhang",
      "Dawei Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14210"
  },
  {
    "id": "arXiv:2105.14211",
    "title": "UFC-BERT: Unifying Multi-Modal Controls for Conditional Image Synthesis",
    "abstract": "Conditional image synthesis aims to create an image according to some\nmulti-modal guidance in the forms of textual descriptions, reference images,\nand image blocks to preserve, as well as their combinations. In this paper,\ninstead of investigating these control signals separately, we propose a new\ntwo-stage architecture, UFC-BERT, to unify any number of multi-modal controls.\nIn UFC-BERT, both the diverse control signals and the synthesized image are\nuniformly represented as a sequence of discrete tokens to be processed by\nTransformer. Different from existing two-stage autoregressive approaches such\nas DALL-E and VQGAN, UFC-BERT adopts non-autoregressive generation (NAR) at the\nsecond stage to enhance the holistic consistency of the synthesized image, to\nsupport preserving specified image blocks, and to improve the synthesis speed.\nFurther, we design a progressive algorithm that iteratively improves the\nnon-autoregressively generated image, with the help of two estimators developed\nfor evaluating the compliance with the controls and evaluating the fidelity of\nthe synthesized image, respectively. Extensive experiments on a newly collected\nlarge-scale clothing dataset M2C-Fashion and a facial dataset Multi-Modal\nCelebA-HQ verify that UFC-BERT can synthesize high-fidelity images that comply\nwith flexible multi-modal controls.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Zhu Zhang",
      "Jianxin Ma",
      "Chang Zhou",
      "Rui Men",
      "Zhikang Li",
      "Ming Ding",
      "Jie Tang",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14211"
  },
  {
    "id": "arXiv:2105.14212",
    "title": "Towards a General Many-Sorted Framework for Describing Certain Kinds of  Legal Statutes with a Potential Computational Realization",
    "abstract": "Examining a 20th-century Scandinavian legal theoretical tradition, we can\nextract an ontological naturalistic, a logical empiristic, and a modern\nidealistic rationale. We introduce the mathematical syntactic figure present in\nthe `logical empiricism' in a contemporary mathematical logic. A new formal\nframework for describing explicit purchase statutes (Sweden) is gradually\ndeveloped and subsequently proposed. This new framework is based on a\nmany-sorted first-order logic (MFOL) approach, where the semantics are grounded\nin concrete `physical' objects and situations with a legal relevance.\nSpecifically, we present a concrete formal syntactic translation of one of the\ncentral statutes of Swedish legislation for the purchase of immovable property.\nAdditionally, we discuss the potential implications that a subsequent\ndevelopment of such formalisations would have for constructing artificial\nagents (e.g., software) that can be used as `co-creative' legal assistance for\nsolving highly complex legal issues concerning the transfer of property, among\nothers.",
    "descriptor": "",
    "authors": [
      "Danny A. J. Gomez-Ramirez",
      "Egil Nordqvist"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14212"
  },
  {
    "id": "arXiv:2105.14214",
    "title": "Predictive Representation Learning for Language Modeling",
    "abstract": "To effectively perform the task of next-word prediction, long short-term\nmemory networks (LSTMs) must keep track of many types of information. Some\ninformation is directly related to the next word's identity, but some is more\nsecondary (e.g. discourse-level features or features of downstream words).\nCorrelates of secondary information appear in LSTM representations even though\nthey are not part of an \\emph{explicitly} supervised prediction task. In\ncontrast, in reinforcement learning (RL), techniques that explicitly supervise\nrepresentations to predict secondary information have been shown to be\nbeneficial. Inspired by that success, we propose Predictive Representation\nLearning (PRL), which explicitly constrains LSTMs to encode specific\npredictions, like those that might need to be learned implicitly. We show that\nPRL 1) significantly improves two strong language modeling methods, 2)\nconverges more quickly, and 3) performs better when data is limited. Our work\nshows that explicitly encoding a simple predictive task facilitates the search\nfor a more effective language model.",
    "descriptor": "",
    "authors": [
      "Qingfeng Lan",
      "Luke Kumar",
      "Martha White",
      "Alona Fyshe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14214"
  },
  {
    "id": "arXiv:2105.14215",
    "title": "Biomimetic Control of Myoelectric Prosthetic Hand Based on a Lambda-type  Muscle Model",
    "abstract": "Myoelectric prosthetic hands are intended to replace the function of the\namputee's lost arm. Therefore, developing robotic prosthetics that can mimic\nnot only the appearance and functionality of humans but also characteristics\nunique to human movements is paramount. Although the impedance model was\nproposed to realize biomimetic control, this model cannot replicate the\ncharacteristics of human movements effectively because the joint angle always\nconverges to the equilibrium position during muscle relaxation. This paper\nproposes a novel biomimetic control method for myoelectric prosthetic hands\nintegrating the impedance model with the concept of the $\\lambda$-type muscle\nmodel. The proposed method can dynamically control the joint equilibrium\nposition, according to the state of the muscle, and can maintain the joint\nangle naturally during muscle relaxation. The effectiveness of the proposed\nmethod is evaluated through simulations and a series of experiments on\nnon-amputee participants. The experimental results, based on comparison with\nthe actual human joint angles, suggest that the proposed method has a better\ncorrelation with the actual human motion than the conventional methods.\nAdditionally, the control experiments showed that the proposed method could\nachieve a natural prosthetic hand movement similar to that of a human, thereby\nallowing voluntary hand opening and closing movements.",
    "descriptor": "\nComments: This paper is accepted for publication at the International Conference on Robotics and Automation 2021 (ICRA 2021)\n",
    "authors": [
      "Akira Furui",
      "Kosuke Nakagaki",
      "Toshio Tsuji"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14215"
  },
  {
    "id": "arXiv:2105.14216",
    "title": "A Federated Learning Framework for Nonconvex-PL Minimax Problems",
    "abstract": "We consider a general class of nonconvex-PL minimax problems in the\ncross-device federated learning setting. Although nonconvex-PL minimax problems\nhave received a lot of interest in recent years, existing algorithms do not\napply to the cross-device federated learning setting which is substantially\ndifferent from conventional distributed settings and poses new challenges. To\nbridge this gap, we propose an algorithmic framework named FedSGDA. FedSGDA\nperforms multiple local update steps on a subset of active clients in each\nround and leverages global gradient estimates to correct the bias in local\nupdate directions. By incorporating FedSGDA with two representative global\ngradient estimators, we obtain two specific algorithms. We establish\nconvergence rates of the proposed algorithms by using novel potential\nfunctions. Experimental results on synthetic and real data corroborate our\ntheory and demonstrate the effectiveness of our algorithms.",
    "descriptor": "",
    "authors": [
      "Jiahao Xie",
      "Chao Zhang",
      "Yunsong Zhang",
      "Zebang Shen",
      "Hui Qian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.14216"
  },
  {
    "id": "arXiv:2105.14217",
    "title": "Less is More: Pay Less Attention in Vision Transformers",
    "abstract": "Transformers have become one of the dominant architectures in deep learning,\nparticularly as a powerful alternative to convolutional neural networks (CNNs)\nin computer vision. However, Transformer training and inference in previous\nworks can be prohibitively expensive due to the quadratic complexity of\nself-attention over a long sequence of representations, especially for\nhigh-resolution dense prediction tasks. To this end, we present a novel Less\nattention vIsion Transformer (LIT), building upon the fact that convolutions,\nfully-connected (FC) layers, and self-attentions have almost equivalent\nmathematical expressions for processing image patch sequences. Specifically, we\npropose a hierarchical Transformer where we use pure multi-layer perceptrons\n(MLPs) to encode rich local patterns in the early stages while applying\nself-attention modules to capture longer dependencies in deeper layers.\nMoreover, we further propose a learned deformable token merging module to\nadaptively fuse informative patches in a non-uniform manner. The proposed LIT\nachieves promising performance on image recognition tasks, including image\nclassification, object detection and instance segmentation, serving as a strong\nbackbone for many vision tasks.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Zizheng Pan",
      "Bohan Zhuang",
      "Haoyu He",
      "Jing Liu",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14217"
  },
  {
    "id": "arXiv:2105.14218",
    "title": "A Survey of Deep Reinforcement Learning Algorithms for Motion Planning  and Control of Autonomous Vehicles",
    "abstract": "In this survey, we systematically summarize the current literature on studies\nthat apply reinforcement learning (RL) to the motion planning and control of\nautonomous vehicles. Many existing contributions can be attributed to the\npipeline approach, which consists of many hand-crafted modules, each with a\nfunctionality selected for the ease of human interpretation. However, this\napproach does not automatically guarantee maximal performance due to the lack\nof a system-level optimization. Therefore, this paper also presents a growing\ntrend of work that falls into the end-to-end approach, which typically offers\nbetter performance and smaller system scales. However, their performance also\nsuffers from the lack of expert data and generalization issues. Finally, the\nremaining challenges applying deep RL algorithms on autonomous driving are\nsummarized, and future research directions are also presented to tackle these\nchallenges.",
    "descriptor": "",
    "authors": [
      "Fei Ye",
      "Shen Zhang",
      "Pin Wang",
      "Ching-Yao Chan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14218"
  },
  {
    "id": "arXiv:2105.14219",
    "title": "Machine Learning for Performance Prediction of Channel Bonding in  Next-Generation IEEE 802.11 WLANs",
    "abstract": "With the advent of Artificial Intelligence (AI)-empowered communications,\nindustry, academia, and standardization organizations are progressing on the\ndefinition of mechanisms and procedures to address the increasing complexity of\nfuture 5G and beyond communications. In this context, the International\nTelecommunication Union (ITU) organized the first AI for 5G Challenge to bring\nindustry and academia together to introduce and solve representative problems\nrelated to the application of Machine Learning (ML) to networks. In this paper,\nwe present the results gathered from Problem Statement~13 (PS-013), organized\nby Universitat Pompeu Fabra (UPF), which primary goal was predicting the\nperformance of next-generation Wireless Local Area Networks (WLANs) applying\nChannel Bonding (CB) techniques. In particular, we overview the ML models\nproposed by participants (including Artificial Neural Networks, Graph Neural\nNetworks, Random Forest regression, and gradient boosting) and analyze their\nperformance on an open dataset generated using the IEEE 802.11ax-oriented\nKomondor network simulator. The accuracy achieved by the proposed methods\ndemonstrates the suitability of ML for predicting the performance of WLANs.\nMoreover, we discuss the importance of abstracting WLAN interactions to achieve\nbetter results, and we argue that there is certainly room for improvement in\nthroughput prediction through ML.",
    "descriptor": "",
    "authors": [
      "Francesc Wilhelmi",
      "David G\u00f3ez",
      "Paola Soto",
      "Ramon Vall\u00e9s",
      "Mohammad Alfaifi",
      "Abdulrahman Algunayah",
      "Jorge Martin-P\u00e9rez",
      "Luigi Girletti",
      "Rajasekar Mohan",
      "K Venkat Ramnan",
      "Boris Bellalta"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14219"
  },
  {
    "id": "arXiv:2105.14220",
    "title": "CoDesc: A Large Code-Description Parallel Dataset",
    "abstract": "Translation between natural language and source code can help software\ndevelopment by enabling developers to comprehend, ideate, search, and write\ncomputer programs in natural language. Despite growing interest from the\nindustry and the research community, this task is often difficult due to the\nlack of large standard datasets suitable for training deep neural models,\nstandard noise removal methods, and evaluation benchmarks. This leaves\nresearchers to collect new small-scale datasets, resulting in inconsistencies\nacross published works. In this study, we present CoDesc -- a large parallel\ndataset composed of 4.2 million Java methods and natural language descriptions.\nWith extensive analysis, we identify and remove prevailing noise patterns from\nthe dataset. We demonstrate the proficiency of CoDesc in two complementary\ntasks for code-description pairs: code summarization and code search. We show\nthat the dataset helps improve code search by up to 22\\% and achieves the new\nstate-of-the-art in code summarization. Furthermore, we show CoDesc's\neffectiveness in pre-training--fine-tuning setup, opening possibilities in\nbuilding pretrained language models for Java. To facilitate future research, we\nrelease the dataset, a data processing tool, and a benchmark at\n\\url{https://github.com/csebuetnlp/CoDesc}.",
    "descriptor": "\nComments: Findings of the Association for Computational Linguistics, ACL 2021 (camera-ready)\n",
    "authors": [
      "Masum Hasan",
      "Tanveer Muttaqueen",
      "Abdullah Al Ishtiaq",
      "Kazi Sajeed Mehrab",
      "Md. Mahim Anjum Haque",
      "Tahmid Hasan",
      "Wasi Uddin Ahmad",
      "Anindya Iqbal",
      "Rifat Shahriyar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14220"
  },
  {
    "id": "arXiv:2105.14221",
    "title": "On the Performance of Blockchain-enabled RAN-as-a-service in Beyond 5G  Networks",
    "abstract": "Blockchain (BC) technology can revolutionize the future of communications by\nenabling decentralized and open sharing networks. In this paper, we propose the\napplication of BC to facilitate Mobile Network Operators (MNOs) and other\nplayers such as Verticals or Over-The-Top (OTT) service providers to exchange\nRadio Access Network (RAN) resources (e.g., infrastructure, spectrum) in a\nsecure, flexible and autonomous manner. In particular, we propose a BC-enabled\nreverse auction mechanism for RAN sharing and dynamic users' service provision\nin Beyond 5G networks, and we analyze its potential advantages with respect to\ncurrent service provisioning and RAN sharing schemes. Moreover, we study the\ndelay and overheads incurred by the BC in the whole process, when running over\nboth wireless and wired interfaces.",
    "descriptor": "",
    "authors": [
      "Francesc Wilhelmi",
      "Lorenza Giupponi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.14221"
  },
  {
    "id": "arXiv:2105.14226",
    "title": "A Longitudinal Analysis of Bloated Java Dependencies",
    "abstract": "We study the evolution and impact of bloated dependencies in a single\nsoftware ecosystem: Java/Maven. Bloated dependencies are third-party libraries\nthat are packaged in the application binary but are not needed to run the\napplication. We analyze the history of 435 Java projects. This historical data\nincludes 48,469 distinct dependencies, which we study across a total of 31,515\nversions of Maven dependency trees. Bloated dependencies steadily increase over\ntime, and 89.02% of the direct dependencies that are bloated remain bloated in\nall subsequent versions of the studied projects. This empirical evidence\nsuggests that developers can safely remove a bloated dependency. We further\nreport novel insights regarding the unnecessary maintenance efforts induced by\nbloat. We find that 22% of dependency updates performed by developers are made\non bloated dependencies and that Dependabot suggests a similar ratio of updates\non bloated dependencies.",
    "descriptor": "\nComments: In Proceeding of the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE'2021)\n",
    "authors": [
      "C\u00e9sar Soto-Valero",
      "Thomas Durieux",
      "Benoit Baudry"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14226"
  },
  {
    "id": "arXiv:2105.14229",
    "title": "The Dantzig selector: Recovery of Signal via $\\ell_1-\u03b1\\ell_2$  Minimization",
    "abstract": "In the paper, we proposed the Dantzig selector based on the $\\ell_{1}-\\alpha\n\\ell_{2}$~$(0< \\alpha \\leq1)$ minimization for the signal recovery. In the\nDantzig selector, the constraint $\\|{\\bf A}^{\\top}({\\bf b}-{\\bf A}{\\bf\nx})\\|_\\infty \\leq \\eta$ for some small constant $\\eta>0$ means the columns of\n${\\bf A}$ has very weakly correlated with the error vector ${\\bf e}={\\bf A}{\\bf\nx}-{\\bf b}$. First, recovery guarantees based on the restricted isometry\nproperty (RIP) are established for signals. Next, we propose the effective\nalgorithm to solve the proposed Dantzig selector. Last, we illustrate the\nproposed model and algorithm by extensive numerical experiments for the\nrecovery of signals in the cases of Gaussian, impulsive and uniform noise. And\nthe performance of the proposed Dantzig selector is better than that of the\nexisting methods.",
    "descriptor": "",
    "authors": [
      "Huanmin Ge",
      "Peng Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.14229"
  },
  {
    "id": "arXiv:2105.14230",
    "title": "Transforming the Latent Space of StyleGAN for Real Face Editing",
    "abstract": "Despite recent advances in semantic manipulation using StyleGAN, semantic\nediting of real faces remains challenging. The gap between the $W$ space and\nthe $W$+ space demands an undesirable trade-off between reconstruction quality\nand editing quality. To solve this problem, we propose to expand the latent\nspace by replacing fully-connected layers in the StyleGAN's mapping network\nwith attention-based transformers. This simple and effective technique\nintegrates the aforementioned two spaces and transforms them into one new\nlatent space called $W$++. Our modified StyleGAN maintains the state-of-the-art\ngeneration quality of the original StyleGAN with moderately better diversity.\nBut more importantly, the proposed $W$++ space achieves superior performance in\nboth reconstruction quality and editing quality. Despite these significant\nadvantages, our $W$++ space supports existing inversion algorithms and editing\nmethods with only negligible modifications thanks to its structural similarity\nwith the $W/W$+ space. Extensive experiments on the FFHQ dataset prove that our\nproposed $W$++ space is evidently more preferable than the previous $W/W$+\nspace for real face editing. The code is publicly available for research\npurposes at https://github.com/AnonSubm2021/TransStyleGAN.",
    "descriptor": "\nComments: 16 pages, 14 figures\n",
    "authors": [
      "Heyi Li",
      "Jinlong Liu",
      "Yunzhi Bai",
      "Huayan Wang",
      "Klaus Mueller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14230"
  },
  {
    "id": "arXiv:2105.14231",
    "title": "Development, Implementation, and Experimental Outdoor Evaluation of  Quadcopter Controllers for Computationally Limited Embedded Systems",
    "abstract": "Quadcopters are increasingly used for applications ranging from hobby to\nindustrial products and services. This paper serves as a tutorial on the\ndesign, simulation, implementation, and experimental outdoor testing of digital\nquadcopter flight controllers, including Explicit Model Predictive Control,\nLinear Quadratic Regulator, and Proportional Integral Derivative. A quadcopter\nwas flown in an outdoor testing facility and made to track an inclined,\ncircular path at different tangential velocities under ambient wind conditions.\nController performance was evaluated via multiple metrics, such as position\ntracking error, velocity tracking error, and onboard computation time.\nChallenges related to the use of computationally limited embedded hardware and\nflight in an outdoor environment are addressed with proposed solutions.",
    "descriptor": "",
    "authors": [
      "Juan Paredes",
      "Prashin Sharma",
      "Brian Ha",
      "Manuel Lanchares",
      "Ella Atkins",
      "Peter Gaskell",
      "Ilya Kolmanovsky"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14231"
  },
  {
    "id": "arXiv:2105.14232",
    "title": "Identification and Measurement of Technical Debt Requirements in  Software Development: a Systematic Literature Review",
    "abstract": "Context: Technical Debt requirements are related to the distance between the\nideal value of the specification and the system's actual implementation, which\nare consequences of strategic decisions for immediate gains, or unintended\nchanges in context. To ensure the evolution of the software, it is necessary to\nkeep it managed. Identification and measurement are the first two stages of the\nmanagement process; however, they are little explored in academic research in\nrequirements engineering. Objective: We aimed at investigating which evidence\nhelps to strengthen the process of TD requirements management, including\nidentification and measurement. Method: We conducted a Systematic Literature\nReview through manual and automatic searches considering 7499 studies from 2010\nto 2020, and including 61 primary studies. Results: We identified some causes\nrelated to Technical Debt requirements, existing strategies to help in the\nidentification and measurement, and metrics to support the measurement stage.\nConclusion: Studies on TD requirements are still preliminary, especially on\nmanagement tools. Yet, not enough attention is given to interpersonal issues,\nwhich are difficulties encountered when performing such activities, and\ntherefore also require research. Finally, the provision of metrics to help\nmeasure TD is part of this work's contribution, providing insights into the\napplication in the requirements context.",
    "descriptor": "",
    "authors": [
      "Ana Melo",
      "Roberta Fagundes",
      "Valentina Lenarduzzi",
      "Williams Santos"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14232"
  },
  {
    "id": "arXiv:2105.14233",
    "title": "Realization of all logic gates and memory latch in the SC-CNN cell of  the simple nonlinear MLC circuit",
    "abstract": "We investigate the State-Controlled Cellular Neural Network (SC-CNN)\nframework of Murali-Lakshmanan-Chua (MLC) circuit system subjected to two\nlogical signals. By exploiting the attractors generated by this circuit in\ndifferent regions of phase-space, we show that the nonlinear circuit is capable\nof producing all the logic gates, namely OR, AND, NOR, NAND, Ex-OR and Ex-NOR\ngates available in digital systems. Further the circuit system emulates\nthree-input gates and Set-Reset flip-flop logic as well. Moreover, all these\nlogical elements and flip-flop are found to be tolerant to noise. These\nphenomena are also experimentally demonstrated. Thus our investigation to\nrealize all logic gates and memory latch in a nonlinear circuit system paves\nthe way to replace or complement the existing technology with a limited number\nof hardware.",
    "descriptor": "\nComments: Accepted for publication in Chaos (15 pages, 20 Figures)\n",
    "authors": [
      "P. Ashokkumar",
      "M. Sathish Aravindh",
      "A. Venkatesan",
      "M. Lakshmanan"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2105.14233"
  },
  {
    "id": "arXiv:2105.14239",
    "title": "Simplified Belief-Dependent Reward MCTS Planning with Guaranteed Tree  Consistency",
    "abstract": "Partially Observable Markov Decision Processes (POMDPs) are notoriously hard\nto solve. Most advanced state-of-the-art online solvers leverage ideas of Monte\nCarlo Tree Search (MCTS). These solvers rapidly converge to the most promising\nbranches of the belief tree, avoiding the suboptimal sections. Most of these\nalgorithms are designed to utilize straightforward access to the state reward\nand assume the belief-dependent reward is nothing but expectation over the\nstate reward. Thus, they are inapplicable to a more general and essential\nsetting of belief-dependent rewards. One example of such reward is differential\nentropy approximated using a set of weighted particles of the belief. Such an\ninformation-theoretic reward introduces a significant computational burden. In\nthis paper, we embed the paradigm of simplification into the MCTS algorithm. In\nparticular, we present Simplified Information-Theoretic Particle Filter Tree\n(SITH-PFT), a novel variant to the MCTS algorithm that considers\ninformation-theoretic rewards but avoids the need to calculate them completely.\nWe replace the costly calculation of information-theoretic rewards with\nadaptive upper and lower bounds. These bounds are easy to calculate and\ntightened only by the demand of our algorithm. Crucially, we guarantee\nprecisely the same belief tree and solution that would be obtained by MCTS,\nwhich explicitly calculates the original information-theoretic rewards. Our\napproach is general; namely, any converging to the reward bounds can be easily\nplugged-in to achieve substantial speedup without any loss in performance.",
    "descriptor": "\nComments: The first two authors contributed equally to this work\n",
    "authors": [
      "Ori Sztyglic",
      "Andrey Zhitnikov",
      "Vadim Indelman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14239"
  },
  {
    "id": "arXiv:2105.14240",
    "title": "Analysis and Applications of Class-wise Robustness in Adversarial  Training",
    "abstract": "Adversarial training is one of the most effective approaches to improve model\nrobustness against adversarial examples. However, previous works mainly focus\non the overall robustness of the model, and the in-depth analysis on the role\nof each class involved in adversarial training is still missing. In this paper,\nwe propose to analyze the class-wise robustness in adversarial training. First,\nwe provide a detailed diagnosis of adversarial training on six benchmark\ndatasets, i.e., MNIST, CIFAR-10, CIFAR-100, SVHN, STL-10 and ImageNet.\nSurprisingly, we find that there are remarkable robustness discrepancies among\nclasses, leading to unbalance/unfair class-wise robustness in the robust\nmodels. Furthermore, we keep investigating the relations between classes and\nfind that the unbalanced class-wise robustness is pretty consistent among\ndifferent attack and defense methods. Moreover, we observe that the stronger\nattack methods in adversarial learning achieve performance improvement mainly\nfrom a more successful attack on the vulnerable classes (i.e., classes with\nless robustness). Inspired by these interesting findings, we design a simple\nbut effective attack method based on the traditional PGD attack, named\nTemperature-PGD attack, which proposes to enlarge the robustness disparity\namong classes with a temperature factor on the confidence distribution of each\nimage. Experiments demonstrate our method can achieve a higher attack rate than\nthe PGD attack. Furthermore, from the defense perspective, we also make some\nmodifications in the training and inference phases to improve the robustness of\nthe most vulnerable class, so as to mitigate the large difference in class-wise\nrobustness. We believe our work can contribute to a more comprehensive\nunderstanding of adversarial training as well as rethinking the class-wise\nproperties in robust models.",
    "descriptor": "",
    "authors": [
      "Qi Tian",
      "Kun Kuang",
      "Kelu Jiang",
      "Fei Wu",
      "Yisen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14240"
  },
  {
    "id": "arXiv:2105.14241",
    "title": "Demoting the Lead Bias in News Summarization via Alternating Adversarial  Learning",
    "abstract": "In news articles the lead bias is a common phenomenon that usually dominates\nthe learning signals for neural extractive summarizers, severely limiting their\nperformance on data with different or even no bias. In this paper, we introduce\na novel technique to demote lead bias and make the summarizer focus more on the\ncontent semantics. Experiments on two news corpora with different degrees of\nlead bias show that our method can effectively demote the model's learned lead\nbias and improve its generality on out-of-distribution data, with little to no\nperformance loss on in-distribution data.",
    "descriptor": "\nComments: Accepted at ACL-IJCNLP 2021 main conference (short paper)\n",
    "authors": [
      "Linzi Xing",
      "Wen Xiao",
      "Giuseppe Carenini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14241"
  },
  {
    "id": "arXiv:2105.14242",
    "title": "CommitBERT: Commit Message Generation Using Pre-Trained Programming  Language Model",
    "abstract": "Commit message is a document that summarizes source code changes in natural\nlanguage. A good commit message clearly shows the source code changes, so this\nenhances collaboration between developers. Therefore, our work is to develop a\nmodel that automatically writes the commit message.\nTo this end, we release 345K datasets consisting of code modification and\ncommit messages in six programming languages (Python, PHP, Go, Java,\nJavaScript, and Ruby). Similar to the neural machine translation (NMT) model,\nusing our dataset, we feed the code modification to the encoder input and the\ncommit message to the decoder input and measure the result of the generated\ncommit message with BLEU-4.\nAlso, we propose the following two training methods to improve the result of\ngenerating the commit message: (1) A method of preprocessing the input to feed\nthe code modification to the encoder input. (2) A method that uses an initial\nweight suitable for the code domain to reduce the gap in contextual\nrepresentation between programming language (PL) and natural language (NL).\nTraining code, dataset, and pre-trained weights are available at\nhttps://github.com/graykode/commit-autosuggestions",
    "descriptor": "\nComments: 8 pages, 3 figures, 4 Tables\n",
    "authors": [
      "Tae-Hwan Jung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14242"
  },
  {
    "id": "arXiv:2105.14244",
    "title": "Learning Graphon Autoencoders for Generative Graph Modeling",
    "abstract": "Graphon is a nonparametric model that generates graphs with arbitrary sizes\nand can be induced from graphs easily. Based on this model, we propose a novel\nalgorithmic framework called \\textit{graphon autoencoder} to build an\ninterpretable and scalable graph generative model. This framework treats\nobserved graphs as induced graphons in functional space and derives their\nlatent representations by an encoder that aggregates Chebshev graphon filters.\nA linear graphon factorization model works as a decoder, leveraging the latent\nrepresentations to reconstruct the induced graphons (and the corresponding\nobserved graphs). We develop an efficient learning algorithm to learn the\nencoder and the decoder, minimizing the Wasserstein distance between the model\nand data distributions. This algorithm takes the KL divergence of the graph\ndistributions conditioned on different graphons as the underlying distance and\nleads to a reward-augmented maximum likelihood estimation. The graphon\nautoencoder provides a new paradigm to represent and generate graphs, which has\ngood generalizability and transferability.",
    "descriptor": "",
    "authors": [
      "Hongteng Xu",
      "Peilin Zhao",
      "Junzhou Huang",
      "Dixin Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14244"
  },
  {
    "id": "arXiv:2105.14246",
    "title": "Orienting Novel 3D Objects Using Self-Supervised Learning of Rotation  Transforms",
    "abstract": "Orienting objects is a critical component in the automation of many packing\nand assembly tasks. We present an algorithm to orient novel objects given a\ndepth image of the object in its current and desired orientation. We formulate\na self-supervised objective for this problem and train a deep neural network to\nestimate the 3D rotation as parameterized by a quaternion, between these\ncurrent and desired depth images. We then use the trained network in a\nproportional controller to re-orient objects based on the estimated rotation\nbetween the two depth images. Results suggest that in simulation we can rotate\nunseen objects with unknown geometries by up to 30{\\deg} with a median angle\nerror of 1.47{\\deg} over 100 random initial/desired orientations each for 22\nnovel objects. Experiments on physical objects suggest that the controller can\nachieve a median angle error of 4.2{\\deg} over 10 random initial/desired\norientations each for 5 objects.",
    "descriptor": "",
    "authors": [
      "Shivin Devgon",
      "Jeffrey Ichnowski",
      "Ashwin Balakrishna",
      "Harry Zhang",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14246"
  },
  {
    "id": "arXiv:2105.14247",
    "title": "Causality-Based Game Solving",
    "abstract": "We present a causality-based algorithm for solving two-player reachability\ngames represented by logical constraints. These games are a useful formalism to\nmodel a wide array of problems arising, e.g., in program synthesis. Our\ntechnique for solving these games is based on the notion of subgoals, which are\nslices of the game that the reachability player necessarily needs to pass\nthrough in order to reach the goal. We use Craig interpolation to identify\nthese necessary sets of moves and recursively slice the game along these\nsubgoals. Our approach allows us to infer winning strategies that are\nstructured along the subgoals. If the game is won by the reachability player,\nthis is a strategy that progresses through the subgoals towards the final goal;\nif the game is won by the safety player, it is a permissive strategy that\ncompletely avoids a single subgoal. We evaluate our prototype implementation on\na range of different games. On multiple benchmark families, our prototype\nscales dramatically better than previously available tools.",
    "descriptor": "\nComments: 33rd International Conference on Computer-Aided Verification (CAV 2021)\n",
    "authors": [
      "Christel Baier",
      "Norine Coenen",
      "Bernd Finkbeiner",
      "Florian Funke",
      "Simon Jantsch",
      "Julian Siber"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14247"
  },
  {
    "id": "arXiv:2105.14250",
    "title": "Cherry-Picking Gradients: Learning Low-Rank Embeddings of Visual Data  via Differentiable Cross-Approximation",
    "abstract": "We propose an end-to-end trainable framework that processes large-scale\nvisual data tensors by looking \\emph{at a fraction of their entries only}. Our\nmethod combines a neural network encoder with a \\emph{tensor train\ndecomposition} to learn a low-rank latent encoding, coupled with\ncross-approximation (CA) to learn the representation through a subset of the\noriginal samples. CA is an adaptive sampling algorithm that is native to tensor\ndecompositions and avoids working with the full high-resolution data\nexplicitly. Instead, it actively selects local representative samples that we\nfetch out-of-core and on-demand. The required number of samples grows only\nlogarithmically with the size of the input. Our implicit representation of the\ntensor in the network enables processing large grids that could not be\notherwise tractable in their uncompressed form. The proposed approach is\nparticularly useful for large-scale multidimensional grid data (e.g., 3D\ntomography), and for tasks that require context over a large receptive field\n(e.g., predicting the medical condition of entire organs). The code will be\navailable at https://github.com/aelphy/c-pic",
    "descriptor": "",
    "authors": [
      "Mikhail Usvyatsov",
      "Anastasia Makarova",
      "Rafael Ballester-Ripoll",
      "Maxim Rakhuba",
      "Andreas Krause",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14250"
  },
  {
    "id": "arXiv:2105.14251",
    "title": "Revisiting Challenges for Selective Data Protection of Real Applications",
    "abstract": "Selective data protection is a promising technique to defend against the data\nleakage attack. In this paper, we revisit technical challenges that were\nneglected when applying this protection to real applications. These challenges\ninclude the secure input channel, granularity conflict, and sensitivity\nconflict. We summarize the causes of them and propose corresponding solutions.\nThen we design and implement a prototype system for selective data protection\nand evaluate the overhead using the RISC-V Spike simulator. The evaluation\ndemonstrates the efficiency (less than 3% runtime overhead with optimizations)\nand the security guarantees provided by our system.",
    "descriptor": "",
    "authors": [
      "Lin Ma",
      "Jinyan Xu",
      "Jiadong Sun",
      "Yajin Zhou",
      "Xun Xie",
      "Wenbo Shen",
      "Rui Chang",
      "Kui Ren"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14251"
  },
  {
    "id": "arXiv:2105.14252",
    "title": "Sustainability Forecasting for Apache Incubator Projects",
    "abstract": "Although OSS development is very popular, ultimately more than 80 percent of\nOSS projects fail. Identifying the factors associated with OSS success can help\nin devising interventions when a project takes a downturn. OSS success has been\nstudied from a variety of angles, more recently in empirical studies of large\nnumbers of diverse projects, using proxies for sustainability, e.g., internal\nmetrics related to productivity and external ones, related to community\npopularity. The internal socio-technical structure of projects has also been\nshown important, especially their dynamics. This points to another angle on\nevaluating software success, from the perspective of self-sustaining and\nself-governing communities.\nTo uncover the dynamics of how a project at a nascent development stage\ngradually evolves into a sustainable one, here we apply a socio-technical\nnetwork modeling perspective to a dataset of Apache Software Foundation\nIncubator (ASFI), sustainability-labeled projects. To identify and validate the\ndeterminants of sustainability, we undertake a mix of quantitative and\nqualitative studies of ASFI projects' socio-technical network trajectories. We\ndevelop interpretable models which can forecast a project becoming sustainable\nwith more than 93 percent accuracy, within 8 months of incubation start. Based\non the interpretable models we describe a strategy for real-time monitoring and\nsuggesting actions, which can be used by projects to correct their\nsustainability trajectories.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Likang Yin",
      "Zhunagzhi Chen",
      "Qi Xuan",
      "Vladimir Filkov"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14252"
  },
  {
    "id": "arXiv:2105.14255",
    "title": "Compressed Sensing for Photoacoustic Computed Tomography Using an  Untrained Neural Network",
    "abstract": "Photoacoustic (PA) computed tomography (PACT) shows great potentials in\nvarious preclinical and clinical applications. A great number of measurements\nare the premise that obtains a high-quality image, which implies a low imaging\nrate or a high system cost. The artifacts or sidelobes could pollute the image\nif we decrease the number of measured channels or limit the detected view. In\nthis paper, a novel compressed sensing method for PACT using an untrained\nneural network is proposed, which decreases half number of the measured\nchannels and recoveries enough details. This method uses a neural network to\nreconstruct without the requirement for any additional learning based on the\ndeep image prior. The model can reconstruct the image only using a few\ndetections with gradient descent. Our method can cooperate with other existing\nregularization, and further improve the quality. In addition, we introduce a\nshape prior to easily converge the model to the image. We verify the\nfeasibility of untrained network based compressed sensing in PA image\nreconstruction, and compare this method with a conventional method using total\nvariation minimization. The experimental results show that our proposed method\noutperforms 32.72% (SSIM) with the traditional compressed sensing method in the\nsame regularization. It could dramatically reduce the requirement for the\nnumber of transducers, by sparsely sampling the raw PA data, and improve the\nquality of PA image significantly.",
    "descriptor": "",
    "authors": [
      "Hengrong Lan",
      "Juze Zhang",
      "Changchun Yang",
      "Fei Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14255"
  },
  {
    "id": "arXiv:2105.14256",
    "title": "Performance of Dual-Hop Relaying for OWC System Over Foggy Channel with  Pointing Errors and Atmospheric Turbulence",
    "abstract": "Optical wireless communication (OWC) over atmospheric turbulence and pointing\nerrors is a well-studied topic. Still, there is limited research on signal\nfading due to random fog and pointing errors in outdoor environments. In this\npaper, we analyze the performance of a decode-and-forward (DF) relaying under\nthe combined effect of random fog, pointing errors, and atmospheric turbulence\nwith a negligible line-of-sight (LOS) direct link. We consider a generalized\nmodel for the end-to-end channel with independent and not identically\ndistributed (i.ni.d.) pointing errors, random fog with Gamma distributed\nattenuation coefficient, asymptotic exponentiated Weibull turbulence, and\nasymmetrical distance between the source and destination. We derive\ndistribution functions of the signal-to-noise ratio (SNR), and then we develop\nanalytical expressions of the outage probability, average SNR, ergodic rate,\nand average bit error rate (BER) in terms of OWC system parameters. We also\ndevelop simplified performance to provide insight on the system behavior\nanalytically under various practically relevant scenarios. We demonstrate the\nmutual effects of channel impairments and pointing errors on the OWC\nperformance, and show that the relaying system provides significant performance\nimprovement compared with the direct transmissions, especially when pointing\nerrors and fog becomes more pronounced.",
    "descriptor": "\nComments: 14 pages, 7 figures, 2 Tables. This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Ziyaur Rahman",
      "Tejas Nimish Shah",
      "S. M. Zafaruddin",
      "V. K. Chaubey"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14256"
  },
  {
    "id": "arXiv:2105.14257",
    "title": "Representation Learning in Continuous-Time Score-Based Generative Models",
    "abstract": "Score-based methods represented as stochastic differential equations on a\ncontinuous time domain have recently proven successful as a non-adversarial\ngenerative model. Training such models relies on denoising score matching,\nwhich can be seen as multi-scale denoising autoencoders. Here, we augment the\ndenoising score-matching framework to enable representation learning without\nany supervised signal. GANs and VAEs learn representations by directly\ntransforming latent codes to data samples. In contrast, score-based\nrepresentation learning relies on a new formulation of the denoising\nscore-matching objective and thus encodes information needed for denoising. We\nshow how this difference allows for manual control of the level of detail\nencoded in the representation.",
    "descriptor": "",
    "authors": [
      "Korbinian Abstreiter",
      "Stefan Bauer",
      "Arash Mehrjou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14257"
  },
  {
    "id": "arXiv:2105.14259",
    "title": "Detecting Backdoor in Deep Neural Networks via Intentional Adversarial  Perturbations",
    "abstract": "Recent researches show that deep learning model is susceptible to backdoor\nattacks where the backdoor embedded in the model will be triggered when a\nbackdoor instance arrives. In this paper, a novel backdoor detection method\nbased on adversarial examples is proposed. The proposed method leverages\nintentional adversarial perturbations to detect whether the image contains a\ntrigger, which can be applied in two scenarios (sanitize the training set in\ntraining stage and detect the backdoor instances in inference stage).\nSpecifically, given an untrusted image, the adversarial perturbation is added\nto the input image intentionally, if the prediction of model on the perturbed\nimage is consistent with that on the unperturbed image, the input image will be\nconsidered as a backdoor instance. The proposed adversarial perturbation based\nmethod requires low computational resources and maintains the visual quality of\nthe images. Experimental results show that, the proposed defense method reduces\nthe backdoor attack success rates from 99.47%, 99.77% and 97.89% to 0.37%,\n0.24% and 0.09% on Fashion-MNIST, CIFAR-10 and GTSRB datasets, respectively.\nBesides, the proposed method maintains the visual quality of the image as the\nadded perturbation is very small. In addition, for attacks under different\nsettings (trigger transparency, trigger size and trigger pattern), the false\nacceptance rates of the proposed method are as low as 1.2%, 0.3% and 0.04% on\nFashion-MNIST, CIFAR-10 and GTSRB datasets, respectively, which demonstrates\nthat the proposed method can achieve high defense performance against backdoor\nattacks under different attack settings.",
    "descriptor": "",
    "authors": [
      "Mingfu Xue",
      "Yinghao Wu",
      "Zhiyu Wu",
      "Jian Wang",
      "Yushu Zhang",
      "Weiqiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14259"
  },
  {
    "id": "arXiv:2105.14260",
    "title": "Understanding Bandits with Graph Feedback",
    "abstract": "The bandit problem with graph feedback, proposed in [Mannor and Shamir,\nNeurIPS 2011], is modeled by a directed graph $G=(V,E)$ where $V$ is the\ncollection of bandit arms, and once an arm is triggered, all its incident arms\nare observed. A fundamental question is how the structure of the graph affects\nthe min-max regret. We propose the notions of the fractional weak domination\nnumber $\\delta^*$ and the $k$-packing independence number capturing upper bound\nand lower bound for the regret respectively. We show that the two notions are\ninherently connected via aligning them with the linear program of the weakly\ndominating set and its dual -- the fractional vertex packing set respectively.\nBased on this connection, we utilize the strong duality theorem to prove a\ngeneral regret upper bound $O\\left(\\left( \\delta^*\\log\n|V|\\right)^{\\frac{1}{3}}T^{\\frac{2}{3}}\\right)$ and a lower bound\n$\\Omega\\left(\\left(\\delta^*/\\alpha\\right)^{\\frac{1}{3}}T^{\\frac{2}{3}}\\right)$\nwhere $\\alpha$ is the integrality gap of the dual linear program. Therefore,\nour bounds are tight up to a $\\left(\\log |V|\\right)^{\\frac{1}{3}}$ factor on\ngraphs with bounded integrality gap for the vertex packing problem including\ntrees and graphs with bounded degree. Moreover, we show that for several\nspecial families of graphs, we can get rid of the $\\left(\\log\n|V|\\right)^{\\frac{1}{3}}$ factor and establish optimal regret.",
    "descriptor": "",
    "authors": [
      "Houshuang Chen",
      "Zengfeng Huang",
      "Shuai Li",
      "Chihao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14260"
  },
  {
    "id": "arXiv:2105.14261",
    "title": "Computing with Infinite Objects: the Gray Code Case",
    "abstract": "Infinite Gray code has been introduced by Tsuiki~\\cite{ts} as a\nredundancy-free representation of the reals. In applications the signed digit\nrepresentation is mostly used which has maximal redundancy. Tsuiki presented a\nfunctional program converting signed digit code into infinite Gray code.\nMoreover, he showed that infinite Gray code can effectively be converted into\nsigned digit code, but the program needs to have some non-deterministic\nfeatures (see also \\cite{tsug}). Berger and Tsuiki~\\cite{btifp,bt} reproved the\nresult in a system of formal first-order intuitionistic logic extended by\ninductive and co-inductive definitions, as well as some new logical connectives\ncapturing concurrent behaviour. The programs extracted from the proofs are\nexactly the ones given by Tsuiki. In order to do so, co-inductive predicates\n$\\bS$ and $\\bG$ are defined and the inclusion $\\bS \\subseteq \\bG$ is derived.\nFor the converse inclusion the new logical connectives are used to introduce a\nconcurrent version $\\S_{2}$ of $S$ and $\\bG \\subseteq \\bS_{2}$ is shown. What\none is looking for, however, is an equivalence proof of the involved concepts.\nOne of the main aims of the present paper is to close the gap. A concurrent\nversion $\\bG^{*}$ of $\\bG$ and a modification $\\bS^{*}$ of $\\bS_{2}$ are\npresented such that $\\bS^{*} = \\bG^{*}$. A crucial tool in \\cite{btifp} is a\nformulation of the Archimedean property of the real numbers as an induction\nprinciple. We introduce a concurrent version of this principle which allows us\nto prove that $\\bS^{*}$ and $\\bG^{*}$ coincide. A further central contribution\nis the extension of the above results to the hyperspace of non-empty compact\nsubsets of the reals.",
    "descriptor": "",
    "authors": [
      "Dieter Spreen",
      "Ulrich Berger"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14261"
  },
  {
    "id": "arXiv:2105.14262",
    "title": "The Privacy Paradox and Optimal Bias-Variance Trade-offs in Data  Acquisition",
    "abstract": "While users claim to be concerned about privacy, often they do little to\nprotect their privacy in their online actions. One prominent explanation for\nthis \"privacy paradox\" is that when an individual shares her data, it is not\njust her privacy that is compromised; the privacy of other individuals with\ncorrelated data is also compromised. This information leakage encourages\noversharing of data and significantly impacts the incentives of individuals in\nonline platforms. In this paper, we study the design of mechanisms for data\nacquisition in settings with information leakage and verifiable data. We design\nan incentive compatible mechanism that optimizes the worst-case trade-off\nbetween bias and variance of the estimation subject to a budget constraint,\nwhere the worst-case is over the unknown correlation between costs and data.\nAdditionally, we characterize the structure of the optimal mechanism in closed\nform and study monotonicity and non-monotonicity properties of the marketplace.",
    "descriptor": "",
    "authors": [
      "Guocheng Liao",
      "Yu Su",
      "Juba Ziani",
      "Adam Wierman",
      "Jianwei Huang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2105.14262"
  },
  {
    "id": "arXiv:2105.14271",
    "title": "Learning to Harness Bandwidth with Multipath Congestion Control and  Scheduling",
    "abstract": "Multipath TCP (MPTCP) has emerged as a facilitator for harnessing and pooling\navailable bandwidth in wireless/wireline communication networks and in data\ncenters. Existing implementations of MPTCP such as, Linked Increase Algorithm\n(LIA), Opportunistic LIA (OLIA) and BAlanced LInked Adaptation (BALIA) include\nseparate algorithms for congestion control and packet scheduling, with\npre-selected control parameters. We propose a Deep Q-Learning (DQL) based\nframework for joint congestion control and packet scheduling for MPTCP. At the\nheart of the solution is an intelligent agent for interface, learning and\nactuation, which learns from experience optimal congestion control and\nscheduling mechanism using DQL techniques with policy gradients. We provide a\nrigorous stability analysis of system dynamics which provides important\npractical design insights. In addition, the proposed DQL-MPTCP algorithm\nutilizes the `recurrent neural network' and integrates it with `long short-term\nmemory' for continuously i) learning dynamic behavior of subflows (paths) and\nii) responding promptly to their behavior using prioritized experience replay.\nWith extensive emulations, we show that the proposed DQL-based MPTCP algorithm\noutperforms MPTCP LIA, OLIA and BALIA algorithms. Moreover, the DQL-MPTCP\nalgorithm is robust to time-varying network characteristics, and provides\ndynamic exploration and exploitation of paths.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Shiva Raj Pokhrel",
      "Anwar Walid"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.14271"
  },
  {
    "id": "arXiv:2105.14273",
    "title": "Examiner: Automatically Locating Inconsistent Instructions Between Real  Devices and CPU Emulators for ARM",
    "abstract": "Emulator is widely used to build dynamic analysis frameworks due to its\nfine-grained tracing capability, full system monitoring functionality, and\nscalability of running on different operating systemsand architectures.\nHowever, whether the emulator is consistent with real devices is unknown. To\nunderstand this problem, we aim to automatically locate inconsistent\ninstructions, which behave differently between emulators and real devices.\nWe target ARM architecture, which provides machine readable specification.\nBased on the specification, we propose a test case generator by designing and\nimplementing the first symbolic execution engine for ARM architecture\nspecification language (ASL). We generate 2,774,649 representative instruction\nstreams and conduct differential testing with these instruction streams between\nfour ARM real devices in different architecture versions (i.e., ARMv5, ARMv6,\nARMv7-a, and ARMv8-a) and the state-of-the-art emulators (i.e., QEMU). We\nlocate 155,642 inconsistent instruction streams, which cover 30% of all\ninstruction encodings and 47.8% of the instructions. We find undefined\nimplementation in ARM manual and implementation bugs of QEMU are the major\ncauses of inconsistencies. Furthermore, we discover four QEMU bugs, which are\nconfirmed and patched by thedevelopers, covering 13 instruction encodings\nincluding the most commonly used ones (e.g.,STR,BLX). With the inconsistent\ninstructions, we build three security applications and demonstrate\nthecapability of these instructions on detecting emulators, anti-emulation, and\nanti-fuzzing.",
    "descriptor": "",
    "authors": [
      "Muhui Jiang",
      "Tianyi Xu",
      "Yajin Zhou",
      "Yufeng Hu",
      "Ming Zhong",
      "Lei Wu",
      "Xiapu Luo",
      "Kui Ren"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14273"
  },
  {
    "id": "arXiv:2105.14274",
    "title": "Korean-English Machine Translation with Multiple Tokenization Strategy",
    "abstract": "This study was conducted to find out how tokenization methods affect the\ntraining results of machine translation models. In this work, character\ntokenization, morpheme tokenization, and BPE tokenization were applied to\nKorean as the source language and English as the target language respectively,\nand the comparison experiment was conducted by repeating 50,000 epochs of each\n9 models using the Transformer neural network. As a result of measuring the\nBLEU scores of the experimental models, the model that applied BPE tokenization\nto Korean and morpheme tokenization to English recorded 35.73, showing the best\nperformance.",
    "descriptor": "\nComments: KCC2021 Undergraduate/Junior Thesis Competition\n",
    "authors": [
      "Dojun Park",
      "Youngjin Jang",
      "Harksoo Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14274"
  },
  {
    "id": "arXiv:2105.14275",
    "title": "Greedy Bayesian Posterior Approximation with Deep Ensembles",
    "abstract": "Ensembles of independently trained neural networks are a state-of-the-art\napproach to estimate predictive uncertainty in Deep Learning, and can be\ninterpreted as an approximation of the posterior distribution via a mixture of\ndelta functions. The training of ensembles relies on non-convexity of the loss\nlandscape and random initialization of their individual members, making the\nresulting posterior approximation uncontrolled. This paper proposes a novel and\nprincipled method to tackle this limitation, minimizing an $f$-divergence\nbetween the true posterior and a kernel density estimator in a function space.\nWe analyze this objective from a combinatorial point of view, and show that it\nis submodular with respect to mixture components for any $f$. Subsequently, we\nconsider the problem of greedy ensemble construction, and from the marginal\ngain of the total objective, we derive a novel diversity term for ensemble\nmethods. The performance of our approach is demonstrated on computer vision\nout-of-distribution benchmarks in a range of architectures trained on multiple\ndatasets. The source code of our method is publicly available at\nhttps://github.com/MIPT-Oulu/greedy_ensembles_training.",
    "descriptor": "",
    "authors": [
      "Aleksei Tiulpin",
      "Matthew B. Blaschko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14275"
  },
  {
    "id": "arXiv:2105.14276",
    "title": "Correcting public opinion trends through Bayesian data assimilation",
    "abstract": "Measuring public opinion is a key focus during democratic elections, enabling\ncandidates to gauge their popularity and alter their campaign strategies\naccordingly. Traditional survey polling remains the most popular estimation\ntechnique, despite its cost and time intensity, measurement errors, lack of\nreal-time capabilities and lagged representation of public opinion. In recent\nyears, Twitter opinion mining has attempted to combat these issues. Despite\nachieving promising results, it experiences its own set of shortcomings such as\nan unrepresentative sample population and a lack of long term stability. This\npaper aims to merge data from both these techniques using Bayesian data\nassimilation to arrive at a more accurate estimate of true public opinion for\nthe Brexit referendum. This paper demonstrates the effectiveness of the\nproposed approach using Twitter opinion data and survey data from trusted\npollsters. Firstly, the possible existence of a time gap of 16 days between the\ntwo data sets is identified. This gap is subsequently incorporated into a\nproposed assimilation architecture. This method was found to adequately\nincorporate information from both sources and measure a strong upward trend in\nLeave support leading up to the Brexit referendum. The proposed technique\nprovides useful estimates of true opinion, which is essential to future opinion\nmeasurement and forecasting research.",
    "descriptor": "",
    "authors": [
      "Robin Hendrickx",
      "Rossella Arcucci",
      "Julio Amador D\u0131az Lopez",
      "Yi-Ke Guo",
      "Mark Kennedy"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14276"
  },
  {
    "id": "arXiv:2105.14277",
    "title": "Grammar Accuracy Evaluation (GAE): Quantifiable Intrinsic Evaluation of  Machine Translation Models",
    "abstract": "Intrinsic evaluation by humans for the performance of natural language\ngeneration models is conducted to overcome the fact that the quality of\ngenerated sentences cannot be fully represented by only extrinsic evaluation.\nNevertheless, existing intrinsic evaluations have a large score deviation\naccording to the evaluator's criteria. In this paper, we propose Grammar\nAccuracy Evaluation (GAE) that can provide specific evaluating criteria. As a\nresult of analyzing the quality of machine translation by BLEU and GAE, it was\nconfirmed that the BLEU score does not represent the absolute performance of\nmachine translation models and that GAE compensates for the shortcomings of\nBLEU with a flexible evaluation on alternative synonyms and changes in sentence\nstructure.",
    "descriptor": "\nComments: Journal of KIISE\n",
    "authors": [
      "Dojun Park",
      "Youngjin Jang",
      "Harksoo Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14277"
  },
  {
    "id": "arXiv:2105.14278",
    "title": "Applications of Epileptic Seizures Detection in Neuroimaging Modalities  Using Deep Learning Techniques: Methods, Challenges, and Future Works",
    "abstract": "Epileptic seizures are a type of neurological disorder that affect many\npeople worldwide. Specialist physicians and neurologists take advantage of\nstructural and functional neuroimaging modalities to diagnose various types of\nepileptic seizures. Neuroimaging modalities assist specialist physicians\nconsiderably in analyzing brain tissue and the changes made in it. One method\nto accelerate the accurate and fast diagnosis of epileptic seizures is to\nemploy computer aided diagnosis systems (CADS) based on artificial intelligence\n(AI) and functional and structural neuroimaging modalities. AI encompasses a\nvariety of areas, and one of its branches is deep learning (DL). Not long ago,\nand before the rise of DL algorithms, feature extraction was an essential part\nof every conventional machine learning method, yet handcrafting features limit\nthese models' performances to the knowledge of system designers. DL methods\nresolved this issue entirely by automating the feature extraction and\nclassification process; applications of these methods in many fields of\nmedicine, such as the diagnosis of epileptic seizures, have made notable\nimprovements. In this paper, a comprehensive overview of the types of DL\nmethods exploited to diagnose epileptic seizures from various neuroimaging\nmodalities has been studied. Additionally, rehabilitation systems and cloud\ncomputing in epileptic seizures diagnosis applications have been exactly\ninvestigated using various modalities.",
    "descriptor": "",
    "authors": [
      "Afshin Shoeibi",
      "Navid Ghassemi",
      "Marjane Khodatars",
      "Mahboobeh Jafari",
      "Parisa Moridian",
      "Roohallah Alizadehsani",
      "Ali Khadem",
      "Yinan Kong",
      "Assef Zare",
      "Juan Manuel Gorriz",
      "Javier Ram\u00edrez",
      "Maryam Panahiazar",
      "Abbas Khosravi",
      "Saeid Nahavandi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14278"
  },
  {
    "id": "arXiv:2105.14280",
    "title": "Hashing-Accelerated Graph Neural Networks for Link Prediction",
    "abstract": "Networks are ubiquitous in the real world. Link prediction, as one of the key\nproblems for network-structured data, aims to predict whether there exists a\nlink between two nodes. The traditional approaches are based on the explicit\nsimilarity computation between the compact node representation by embedding\neach node into a low-dimensional space. In order to efficiently handle the\nintensive similarity computation in link prediction, the hashing technique has\nbeen successfully used to produce the node representation in the Hamming space.\nHowever, the hashing-based link prediction algorithms face accuracy loss from\nthe randomized hashing techniques or inefficiency from the learning to hash\ntechniques in the embedding process. Currently, the Graph Neural Network (GNN)\nframework has been widely applied to the graph-related tasks in an end-to-end\nmanner, but it commonly requires substantial computational resources and memory\ncosts due to massive parameter learning, which makes the GNN-based algorithms\nimpractical without the help of a powerful workhorse. In this paper, we propose\na simple and effective model called #GNN, which balances the trade-off between\naccuracy and efficiency. #GNN is able to efficiently acquire node\nrepresentation in the Hamming space for link prediction by exploiting the\nrandomized hashing technique to implement message passing and capture\nhigh-order proximity in the GNN framework. Furthermore, we characterize the\ndiscriminative power of #GNN in probability. The extensive experimental results\ndemonstrate that the proposed #GNN algorithm achieves accuracy comparable to\nthe learning-based algorithms and outperforms the randomized algorithm, while\nrunning significantly faster than the learning-based algorithms. Also, the\nproposed algorithm shows excellent scalability on a large-scale network with\nthe limited resources.",
    "descriptor": "",
    "authors": [
      "Wei Wu",
      "Bin Li",
      "Chuan Luo",
      "Wolfgang Nejdl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.14280"
  },
  {
    "id": "arXiv:2105.14281",
    "title": "Circuit Design for $k$-coloring Problem and Its Implementation in Any  Dimensional Quantum System",
    "abstract": "With the evolution of quantum computing, researchers now-a-days tend to\nincline to find solutions to NP-complete problems by using quantum algorithms\nin order to gain asymptotic advantage. In this paper, we solve $k$-coloring\nproblem (NP-complete problem) using Grover's algorithm in any dimensional\nquantum system or any $d$-ary quantum system for the first time to the best of\nour knowledge, where $d \\ge 2$. A newly proposed comparator-based approach\nhelps to generalize the implementation of the $k$-coloring problem in any\ndimensional quantum system. Till date, $k$-coloring problem has been\nimplemented only in binary and ternary quantum system, hence, we abide to $d=2$\nor $d=3$, that is for binary and ternary quantum system for comparing our\nproposed work with the state-of-the-art techniques. This proposed approach\nmakes the reduction of the qubit cost possible, compared to the\nstate-of-the-art binary quantum systems. Further, with the help of newly\nproposed ternary comparator, a substantial reduction in quantum gate count for\nthe ternary oracle circuit of the $k$-coloring problem than the previous\napproaches has been obtained. An end-to-end automated framework has been put\nforward for implementing the $k$-coloring problem for any undirected and\nunweighted graph on any available Near-term quantum devices or Noisy\nIntermediate-Scale Quantum (NISQ) devices or multi-valued quantum simulator,\nwhich helps in generalizing our approach.",
    "descriptor": "\nComments: 24 pages, 18 figures. arXiv admin note: text overlap with arXiv:2009.06073\n",
    "authors": [
      "Amit Saha",
      "Debasri Saha",
      "Amlan Chakrabarti"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2105.14281"
  },
  {
    "id": "arXiv:2105.14286",
    "title": "Social Cost Optimization for Prosumer Community with Two Price-Package  Incentives in Two-Settlement Based Electricity Market",
    "abstract": "In this paper, we consider a future electricity market consisting of\naggregated energy prosumers, who are equipped with local wind power plants\n(WPPs) to support (part of) their energy demands and can also trade energy with\nday-ahead market (DAM) and energy balancing market (EBM). In addition, an\nenergy aggregator (EA) is established, who can provide the trading gateways\nbetween prosumers and the markets. The EA is responsible for making pricing\nstrategies on the prosumers to influence their trading behaviours such that the\nsocial benefit of the prosumer community is improved. Specifically, two price\npackages are provided by the EA: wholesale price (WP) package and lump-sum (LS)\npackage, which can be flexibly selected by prosumers based on their own\npreferences. Analytical energy-trading strategies will be derived for WP\nprosumers and LS prosumers based on non-cooperative games and Nash resource\nallocation strategies, respectively. In this work, a social cost optimization\nproblem will be formulated for the EA, where the detailed WP/LS selection plans\nare unknown in advance. Consequently, a stochastic Stackelberg game between\nprosumers and the EA is formulated, and a two-level stochastic convex\nprogramming algorithm is proposed to minimize the expectation of the social\ncost. The performance of the proposed algorithm is demonstrated with a\ntwo-settlement based market model in the simulation.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Jianzheng Wang",
      "Guoqiang Hu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14286"
  },
  {
    "id": "arXiv:2105.14289",
    "title": "Modeling Discriminative Representations for Out-of-Domain Detection with  Supervised Contrastive Learning",
    "abstract": "Detecting Out-of-Domain (OOD) or unknown intents from user queries is\nessential in a task-oriented dialog system. A key challenge of OOD detection is\nto learn discriminative semantic features. Traditional cross-entropy loss only\nfocuses on whether a sample is correctly classified, and does not explicitly\ndistinguish the margins between categories. In this paper, we propose a\nsupervised contrastive learning objective to minimize intra-class variance by\npulling together in-domain intents belonging to the same class and maximize\ninter-class variance by pushing apart samples from different classes. Besides,\nwe employ an adversarial augmentation mechanism to obtain pseudo diverse views\nof a sample in the latent space. Experiments on two public datasets prove the\neffectiveness of our method capturing discriminative representations for OOD\ndetection.",
    "descriptor": "\nComments: Accepted by ACL2021\n",
    "authors": [
      "Zhiyuan Zeng",
      "Keqing He",
      "Yuanmeng Yan",
      "Zijun Liu",
      "Yanan Wu",
      "Hong Xu",
      "Huixing Jiang",
      "Weiran Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14289"
  },
  {
    "id": "arXiv:2105.14291",
    "title": "Deep Learning on Monocular Object Pose Detection and Tracking: A  Comprehensive Overview",
    "abstract": "Object pose detection and tracking has recently attracted increasing\nattention due to its wide applications in many areas, such as autonomous\ndriving, robotics, and augmented reality. Among methods for object pose\ndetection and tracking, deep learning is the most promising one that has shown\nbetter performance than others. However, there is lack of survey study about\nlatest development of deep learning based methods. Therefore, this paper\npresents a comprehensive review of recent progress in object pose detection and\ntracking that belongs to the deep learning technical route. To achieve a more\nthorough introduction, the scope of this paper is limited to methods taking\nmonocular RGB/RGBD data as input, covering three kinds of major tasks:\ninstance-level monocular object pose detection, category-level monocular object\npose detection, and monocular object pose tracking. In our work, metrics,\ndatasets, and methods about both detection and tracking are presented in\ndetail. Comparative results of current state-of-the-art methods on several\npublicly available datasets are also presented, together with insightful\nobservations and inspiring future research directions.",
    "descriptor": "\nComments: 24 pages,8 figures\n",
    "authors": [
      "Zhaoxin Fan",
      "Yazhi Zhu",
      "Yulin He",
      "Qi Sun",
      "Hongyan Liu",
      "Jun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14291"
  },
  {
    "id": "arXiv:2105.14295",
    "title": "ECMO: Peripheral Transplantation to Rehost Embedded Linux Kernels",
    "abstract": "Dynamic analysis based on the full-system emulator QEMU is widely used for\nvarious purposes. However, it is challenging to run firmware images of embedded\ndevices in QEMU, especially theprocess to boot the Linux kernel (we call this\nprocess rehosting the Linux kernel in this paper.) That's because embedded\ndevices usually use different system-on-chips (SoCs) from multiple vendors\nandonly a limited number of SoCs are currently supported in QEMU.\nIn this work, we propose a technique calledperipheral transplantation. The\nmain idea is to transplant the device drivers of designated peripherals into\nthe Linux kernel binary. By doing so, it can replace the peripherals in the\nkernel that are currently unsupported in QEMU with supported ones, thus making\nthe Linux kernel rehostable. After that, various applications can be built\nupon.\nWe implemented this technique inside a prototype system called ECMO and\napplied it to 824 firmware images, which consist of 17 kernel versions, 37\ndevice models, and 24 vendors. The resultshows that ECMO can successfully\ntransplant peripherals for all the 824 Linux kernels. Among them, 719 kernels\ncan be successfully rehosted, i.e., launching a user-space shell (87.3% success\nrate). The failed cases are mainly because the root file system format (ramfs)\nis not supported by the kernel. We further build three applications, i.e.,\nkernel crash analysis, rootkit forensic analysis, and kernel fuzzing, based on\nthe rehosted kernels to demonstrate the usage scenarios of ECMO.",
    "descriptor": "",
    "authors": [
      "Muhui Jiang",
      "Lin Ma",
      "Yajin Zhou",
      "Qiang Liu",
      "Cen Zhang",
      "Zhi Wang",
      "Xiapu Luo",
      "Lei Wu",
      "Kui Ren"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.14295"
  },
  {
    "id": "arXiv:2105.14298",
    "title": "A Measurement Study on the (In)security of End-of-Life (EoL) Embedded  Devices",
    "abstract": "Embedded devices are becoming popular. Meanwhile, researchers are actively\nworking on improving the security of embedded devices. However, previous work\nignores the insecurity caused by a special category of devices, i.e., the\nEnd-of-Life (EoL in short) devices. Once a product becomes End-of-Life, vendors\ntend to no longer maintain its firmware or software, including providing bug\nfixes and security patches. This makes EoL devices susceptible to attacks. For\ninstance, a report showed that an EoL model with thousands of active devices\nwas exploited to redirect web traffic for malicious purposes. In this paper, we\nconduct the first measurement study to shed light on the (in)security of EoL\ndevices. To this end, our study performs two types of analysis, including the\naliveness analysis and the vulnerability analysis. The first one aims to detect\nthe scale of EoL devices that are still alive. The second one is to evaluate\nthe vulnerabilities existing in (active) EoL devices. We have applied our\napproach to a large number of EoL models from three vendors (i.e., D-Link,\nTp-Link, and Netgear) and detect the alive devices in a time period of ten\nmonths. Our study reveals some worrisome facts that were unknown by the\ncommunity. For instance, there exist more than 2 million active EoL devices.\nNearly 300,000 of them are still alive even after five years since they became\nEoL. Although vendors may release security patches after the EoL date, however,\nthe process is ad hoc and incomplete. As a result, more than 1 million active\nEoL devices are vulnerable, and nearly half of them are threatened by high-risk\nvulnerabilities. Attackers can achieve a minimum of 2.79 Tbps DDoS attack by\ncompromising a large number of active EoL devices. We believe these facts pose\na clear call for more attention to deal with the security issues of EoL\ndevices.",
    "descriptor": "",
    "authors": [
      "Dingding Wang",
      "Muhui Jiang",
      "Rui Chang",
      "Yajin Zhou",
      "Baolei Hou",
      "Xiapu Luo",
      "Lei Wu",
      "Kui Ren"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14298"
  },
  {
    "id": "arXiv:2105.14299",
    "title": "An algorithm for identifying eigenvectors exhibiting strong spatial  localization",
    "abstract": "We introduce an approach for exploring eigenvector localization phenomena for\na class of (unbounded) selfadjoint operators. More specifically, given a target\nregion and a tolerance, the algorithm identifies candidate eigenpairs for which\nthe eigenvector is expected to be localized in the target region to within that\ntolerance. Theoretical results, together with detailed numerical illustrations\nof them, are provided that support our algorithm. A partial realization of the\nalgorithm is described and tested, providing a proof of concept for the\napproach.",
    "descriptor": "",
    "authors": [
      "Jeffrey Ovall",
      "Robyn Reid"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14299"
  },
  {
    "id": "arXiv:2105.14300",
    "title": "LPF: A Language-Prior Feedback Objective Function for De-biased Visual  Question Answering",
    "abstract": "Most existing Visual Question Answering (VQA) systems tend to overly rely on\nlanguage bias and hence fail to reason from the visual clue. To address this\nissue, we propose a novel Language-Prior Feedback (LPF) objective function, to\nre-balance the proportion of each answer's loss value in the total VQA loss.\nThe LPF firstly calculates a modulating factor to determine the language bias\nusing a question-only branch. Then, the LPF assigns a self-adaptive weight to\neach training sample in the training process. With this reweighting mechanism,\nthe LPF ensures that the total VQA loss can be reshaped to a more balanced\nform. By this means, the samples that require certain visual information to\npredict will be efficiently used during training. Our method is simple to\nimplement, model-agnostic, and end-to-end trainable. We conduct extensive\nexperiments and the results show that the LPF (1) brings a significant\nimprovement over various VQA models, (2) achieves competitive performance on\nthe bias-sensitive VQA-CP v2 benchmark.",
    "descriptor": "\nComments: Accepted by ACM SIGIR 2021\n",
    "authors": [
      "Zujie Liang",
      "Haifeng Hu",
      "Jiaying Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14300"
  },
  {
    "id": "arXiv:2105.14304",
    "title": "Stability and Super-resolution of MUSIC and ESPRIT for Multi-snapshot  Spectral Estimation",
    "abstract": "This paper studies the spectral estimation problem of estimating the\nlocations of a fixed number of point sources given multiple snapshots of\nFourier measurements collected by a uniform array of sensors. We prove novel\nnon-asymptotic stability bounds for MUSIC and ESPRIT as a function of the noise\nstandard deviation, number of snapshots, source amplitudes, and support. Our\nmost general result is a perturbation bound of the signal space in terms of the\nminimum singular value of Fourier matrices. When the point sources are located\nin several separated clumps, we provide an explicit upper bound of the\nnoise-space correlation perturbation error in MUSIC and the support error in\nESPRIT in terms of a Super-Resolution Factor (SRF). The upper bound for ESPRIT\nis then compared with a new Cram\\'er-Rao lower bound for the clumps model. As a\nresult, we show that ESPRIT is comparable to that of the optimal unbiased\nestimator(s) in terms of the dependence on noise, number of snapshots and SRF.\nAs a byproduct of our analysis, we discover several fundamental differences\nbetween the single-snapshot and multi-snapshot problems. Our theory is\nvalidated by numerical experiments.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Weilin Li",
      "Zengying Zhu",
      "Weiguo Gao",
      "Wenjing Liao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14304"
  },
  {
    "id": "arXiv:2105.14305",
    "title": "Efficient Folding Algorithms for Regular Polyhedra",
    "abstract": "We investigate the folding problem that asks if a polygon P can be folded to\na polyhedron Q for given P and Q. Recently, an efficient algorithm for this\nproblem has been developed when Q is a box. We extend this idea to regular\npolyhedra, also known as Platonic solids. The basic idea of our algorithms is\ncommon, which is called stamping. However, the computational complexities of\nthem are different depending on their geometric properties. We developed four\nalgorithms for the problem as follows. (1) An algorithm for a regular\ntetrahedron, which can be extended to a tetramonohedron. (2) An algorithm for a\nregular hexahedron (or a cube), which is much efficient than the previously\nknown one. (3) An algorithm for a general deltahedron, which contains the cases\nthat Q is a regular octahedron or a regular icosahedron. (4) An algorithm for a\nregular dodecahedron. Combining these algorithms, we can conclude that the\nfolding problem can be solved pseudo-polynomial time when Q is a regular\npolyhedron and other related solid.",
    "descriptor": "",
    "authors": [
      "Tonan Kamata",
      "Akira Kadoguchi",
      "Takashi Horiyama",
      "Ryuhei Uehara"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2105.14305"
  },
  {
    "id": "arXiv:2105.14307",
    "title": "Towards a Dichotomy for Minimally Factorizing the Provenance of  Self-Join Free Conjunctive Queries",
    "abstract": "We consider the problem of finding the minimal-size factorization of the\nprovenance of self-join-free conjunctive queries, i.e., we want to find an\nequivalent propositional formula that minimizes the number of variable\noccurrences. Our work is partly motivated from probabilistic inference where\nread-once formulas are known to allow exact PTIME solutions and non-read-once\nformulas allow approximate solutions with an error that depends on the number\nof repetitions of variables. We embark on the challenge of characterizing the\ndata complexity of this problem and show its connection to the query resilience\nproblem. While the problem is NP-complete in general, we develop an encoding as\nmax-flow problem that is guaranteed to give the exact solution for several\nqueries (and otherwise approximate minimizations). We show that our encoding is\nguaranteed to return a read-once factorization if it exists. Our problem and\napproach is a complete solution that naturally recovers exact solutions for all\nknown PTIME cases, as well as identifying additional queries for which the\nproblem can be solved in PTIME.",
    "descriptor": "",
    "authors": [
      "Neha Makhija",
      "Wolfgang Gatterbauer"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2105.14307"
  },
  {
    "id": "arXiv:2105.14309",
    "title": "A Simple Voting Mechanism for Online Sexist Content Identification",
    "abstract": "This paper presents the participation of the MiniTrue team in the EXIST 2021\nChallenge on the sexism detection in social media task for English and Spanish.\nOur approach combines the language models with a simple voting mechanism for\nthe sexist label prediction. For this, three BERT based models and a voting\nfunction are used. Experimental results show that our final model with the\nvoting function has achieved the best results among our four models, which\nmeans that our voting mechanism brings an extra benefit to our system.\nNevertheless, we also observe that our system is robust to data sources and\nlanguages.",
    "descriptor": "",
    "authors": [
      "Chao Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14309"
  },
  {
    "id": "arXiv:2105.14311",
    "title": "Synthesizing Invariant Barrier Certificates via Difference-of-Convex  Programming",
    "abstract": "A barrier certificate often serves as an inductive invariant that isolates an\nunsafe region from the reachable set of states, and hence is widely used in\nproving safety of hybrid systems possibly over the infinite time horizon. We\npresent a novel condition on barrier certificates, termed the invariant\nbarrier-certificate condition, that witnesses unbounded-time safety of\ndifferential dynamical systems. The proposed condition is by far the least\nconservative one on barrier certificates, and can be shown as the weakest\npossible one to attain inductive invariance. We show that discharging the\ninvariant barrier-certificate condition -- thereby synthesizing invariant\nbarrier certificates -- can be encoded as solving an optimization problem\nsubject to bilinear matrix inequalities (BMIs). We further propose a synthesis\nalgorithm based on difference-of-convex programming, which approaches a local\noptimum of the BMI problem via solving a series of convex optimization\nproblems. This algorithm is incorporated in a branch-and-bound framework that\nsearches for the global optimum in a divide-and-conquer fashion. We present a\nweak completeness result of our method, in the sense that a barrier certificate\nis guaranteed to be found (under some mild assumptions) whenever there exists\nan inductive invariant (in the form of a given template) that suffices to\ncertify safety of the system. Experimental results on benchmark examples\ndemonstrate the effectiveness and efficiency of our approach.",
    "descriptor": "\nComments: To be published in Proc. of CAV 2021\n",
    "authors": [
      "Qiuye Wang",
      "Mingshuai Chen",
      "Bai Xue",
      "Naijun Zhan",
      "Joost-Pieter Katoen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14311"
  },
  {
    "id": "arXiv:2105.14313",
    "title": "Novel Slot Detection: A Benchmark for Discovering Unknown Slot Types in  the Task-Oriented Dialogue System",
    "abstract": "Existing slot filling models can only recognize pre-defined in-domain slot\ntypes from a limited slot set. In the practical application, a reliable\ndialogue system should know what it does not know. In this paper, we introduce\na new task, Novel Slot Detection (NSD), in the task-oriented dialogue system.\nNSD aims to discover unknown or out-of-domain slot types to strengthen the\ncapability of a dialogue system based on in-domain training data. Besides, we\nconstruct two public NSD datasets, propose several strong NSD baselines, and\nestablish a benchmark for future work. Finally, we conduct exhaustive\nexperiments and qualitative analysis to comprehend key challenges and provide\nnew guidance for future directions.",
    "descriptor": "\nComments: Accepted by ACL2021\n",
    "authors": [
      "Yanan Wu",
      "Zhiyuan Zeng",
      "Keqing He",
      "Hong Xu",
      "Yuanmeng Yan",
      "Huixing Jiang",
      "Weiran Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14313"
  },
  {
    "id": "arXiv:2105.14314",
    "title": "Automatic CT Segmentation from Bounding Box Annotations using  Convolutional Neural Networks",
    "abstract": "Accurate segmentation for medical images is important for clinical diagnosis.\nExisting automatic segmentation methods are mainly based on fully supervised\nlearning and have an extremely high demand for precise annotations, which are\nvery costly and time-consuming to obtain. To address this problem, we proposed\nan automatic CT segmentation method based on weakly supervised learning, by\nwhich one could train an accurate segmentation model only with weak annotations\nin the form of bounding boxes. The proposed method is composed of two steps: 1)\ngenerating pseudo masks with bounding box annotations by k-means clustering,\nand 2) iteratively training a 3D U-Net convolutional neural network as a\nsegmentation model. Some data pre-processing methods are used to improve\nperformance. The method was validated on four datasets containing three types\nof organs with a total of 627 CT volumes. For liver, spleen and kidney\nsegmentation, it achieved an accuracy of 95.19%, 92.11%, and 91.45%,\nrespectively. Experimental results demonstrate that our method is accurate,\nefficient, and suitable for clinical use.",
    "descriptor": "",
    "authors": [
      "Yuanpeng Liu",
      "Qinglei Hui",
      "Zhiyi Peng",
      "Shaolin Gong",
      "Dexing Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14314"
  },
  {
    "id": "arXiv:2105.14322",
    "title": "RPG: Learning Recursive Point Cloud Generation",
    "abstract": "In this paper we propose a novel point cloud generator that is able to\nreconstruct and generate 3D point clouds composed of semantic parts. Given a\nlatent representation of the target 3D model, the generation starts from a\nsingle point and gets expanded recursively to produce the high-resolution point\ncloud via a sequence of point expansion stages. During the recursive procedure\nof generation, we not only obtain the coarse-to-fine point clouds for the\ntarget 3D model from every expansion stage, but also unsupervisedly discover\nthe semantic segmentation of the target model according to the\nhierarchical/parent-child relation between the points across expansion stages.\nMoreover, the expansion modules and other elements used in our recursive\ngenerator are mostly sharing weights thus making the overall framework light\nand efficient. Extensive experiments are conducted to demonstrate that our\nproposed point cloud generator has comparable or even superior performance on\nboth generation and reconstruction tasks in comparison to various baselines, as\nwell as provides the consistent co-segmentation among 3D instances of the same\nobject class.",
    "descriptor": "",
    "authors": [
      "Wei-Jan Ko",
      "Hui-Yu Huang",
      "Yu-Liang Kuo",
      "Chen-Yi Chiu",
      "Li-Heng Wang",
      "Wei-Chen Chiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14322"
  },
  {
    "id": "arXiv:2105.14326",
    "title": "Implementing a foveal-pit inspired filter in a Spiking Convolutional  Neural Network: a preliminary study",
    "abstract": "We have presented a Spiking Convolutional Neural Network (SCNN) that\nincorporates retinal foveal-pit inspired Difference of Gaussian filters and\nrank-order encoding. The model is trained using a variant of the\nbackpropagation algorithm adapted to work with spiking neurons, as implemented\nin the Nengo library. We have evaluated the performance of our model on two\npublicly available datasets - one for digit recognition task, and the other for\nvehicle recognition task. The network has achieved up to 90% accuracy, where\nloss is calculated using the cross-entropy function. This is an improvement\nover around 57% accuracy obtained with the alternate approach of performing the\nclassification without any kind of neural filtering. Overall, our\nproof-of-concept study indicates that introducing biologically plausible\nfiltering in existing SCNN architecture will work well with noisy input images\nsuch as those in our vehicle recognition task. Based on our results, we plan to\nenhance our SCNN by integrating lateral inhibition-based redundancy reduction\nprior to rank-ordering, which will further improve the classification accuracy\nby the network.",
    "descriptor": "\nComments: 8 pages, 8 figures, 4 tables. 2020 International Joint Conference on Neural Networks (IJCNN)\n",
    "authors": [
      "Shriya T.P. Gupta",
      "Basabdatta Sen Bhattacharya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14326"
  },
  {
    "id": "arXiv:2105.14327",
    "title": "A Spectral-Spatial-Dependent Global Learning Framework for Insufficient  and Imbalanced Hyperspectral Image Classification",
    "abstract": "Deep learning techniques have been widely applied to hyperspectral image\n(HSI) classification and have achieved great success. However, the deep neural\nnetwork model has a large parameter space and requires a large number of\nlabeled data. Deep learning methods for HSI classification usually follow a\npatchwise learning framework. Recently, a fast patch-free global learning\n(FPGA) architecture was proposed for HSI classification according to global\nspatial context information. However, FPGA has difficulty extracting the most\ndiscriminative features when the sample data is imbalanced. In this paper, a\nspectral-spatial dependent global learning (SSDGL) framework based on global\nconvolutional long short-term memory (GCL) and global joint attention mechanism\n(GJAM) is proposed for insufficient and imbalanced HSI classification. In\nSSDGL, the hierarchically balanced (H-B) sampling strategy and the weighted\nsoftmax loss are proposed to address the imbalanced sample problem. To\neffectively distinguish similar spectral characteristics of land cover types,\nthe GCL module is introduced to extract the long short-term dependency of\nspectral features. To learn the most discriminative feature representations,\nthe GJAM module is proposed to extract attention areas. The experimental\nresults obtained with three public HSI datasets show that the SSDGL has\npowerful performance in insufficient and imbalanced sample problems and is\nsuperior to other state-of-the-art methods. Code can be obtained at:\nhttps://github.com/dengweihuan/SSDGL.",
    "descriptor": "\nComments: 14 pages,14 figures\n",
    "authors": [
      "Qiqi Zhu",
      "Weihuan Deng",
      "Zhuo Zheng",
      "Yanfei Zhong",
      "Qingfeng Guan",
      "Weihua Lin",
      "Liangpei Zhang",
      "Deren Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14327"
  },
  {
    "id": "arXiv:2105.14329",
    "title": "GINA: Neural Relational Inference From Independent Snapshots",
    "abstract": "Dynamical systems in which local interactions among agents give rise to\ncomplex emerging phenomena are ubiquitous in nature and society. This work\nexplores the problem of inferring the unknown interaction structure\n(represented as a graph) of such a system from measurements of its constituent\nagents or individual components (represented as nodes). We consider a setting\nwhere the underlying dynamical model is unknown and where different\nmeasurements (i.e., snapshots) may be independent (e.g., may stem from\ndifferent experiments). We propose GINA (Graph Inference Network Architecture),\na graph neural network (GNN) to simultaneously learn the latent interaction\ngraph and, conditioned on the interaction graph, the prediction of a node's\nobservable state based on adjacent vertices. GINA is based on the hypothesis\nthat the ground truth interaction graph -- among all other potential graphs --\nallows to predict the state of a node, given the states of its neighbors, with\nthe highest accuracy. We test this hypothesis and demonstrate GINA's\neffectiveness on a wide range of interaction graphs and dynamical processes.",
    "descriptor": "",
    "authors": [
      "Gerrit Gro\u00dfmann",
      "Julian Zimmerlin",
      "Michael Backenk\u00f6hler",
      "Verena Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Multiagent Systems (cs.MA)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.14329"
  },
  {
    "id": "arXiv:2105.14331",
    "title": "Foveal-pit inspired filtering of DVS spike response",
    "abstract": "In this paper, we present results of processing Dynamic Vision Sensor (DVS)\nrecordings of visual patterns with a retinal model based on foveal-pit inspired\nDifference of Gaussian (DoG) filters. A DVS sensor was stimulated with varying\nnumber of vertical white and black bars of different spatial frequencies moving\nhorizontally at a constant velocity. The output spikes generated by the DVS\nsensor were applied as input to a set of DoG filters inspired by the receptive\nfield structure of the primate visual pathway. In particular, these filters\nmimic the receptive fields of the midget and parasol ganglion cells (spiking\nneurons of the retina) that sub-serve the photo-receptors of the foveal-pit.\nThe features extracted with the foveal-pit model are used for further\nclassification using a spiking convolutional neural network trained with a\nbackpropagation variant adapted for spiking neural networks.",
    "descriptor": "\nComments: 6 pages, 4 figures, 2 tables. 2021 55th Annual Conference on Information Sciences and Systems (CISS), 2021\n",
    "authors": [
      "Shriya T.P. Gupta",
      "Pablo Linares-Serrano",
      "Basabdatta Sen Bhattacharya",
      "Teresa Serrano-Gotarredona"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2105.14331"
  },
  {
    "id": "arXiv:2105.14344",
    "title": "BPFroid: Robust Real Time Android Malware Detection Framework",
    "abstract": "We present BPFroid -- a novel dynamic analysis framework for Android that\nuses the eBPF technology of the Linux kernel to continuously monitor events of\nuser applications running on a real device. The monitored events are collected\nfrom different components of the Android software stack: internal kernel\nfunctions, system calls, native library functions, and the Java API framework.\nAs BPFroid hooks these events in the kernel, a malware is unable to trivially\nbypass monitoring. Moreover, using eBPF doesn't require any change to the\nAndroid system or the monitored applications. We also present an analytical\ncomparison of BPFroid to other malware detection methods and demonstrate its\nusage by developing novel signatures to detect suspicious behavior that are\nbased on it. These signatures are then evaluated using real apps. We also\ndemonstrate how BPFroid can be used to capture forensic artifacts for further\ninvestigation. Our results show that BPFroid successfully alerts in real time\nwhen a suspicious behavioral signature is detected, without incurring a\nsignificant runtime performance overhead.",
    "descriptor": "\nComments: 22 pages, 7 figures, submitted to ieee access\n",
    "authors": [
      "Yaniv Agman",
      "Danny Hendler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14344"
  },
  {
    "id": "arXiv:2105.14347",
    "title": "Is Sluice Resolution really just Question Answering?",
    "abstract": "Sluice resolution is a problem where a system needs to output the\ncorresponding antecedents of wh-ellipses. The antecedents are elided contents\nbehind the wh-words but are implicitly referred to using contexts. Previous\nwork frames sluice resolution as question answering where this setting\noutperforms all its preceding works by large margins. Ellipsis and questions\nare referentially dependent expressions (anaphoras) and retrieving the\ncorresponding antecedents are like answering questions to output pieces of\nclarifying information. However, the task is not fully solved. Therefore, we\nwant to further investigate what makes sluice resolution differ to question\nanswering and fill in the error gaps. We also present some results using recent\nstate-of-the-art question answering systems which improve the previous work\n(86.01 to 90.39 F1).",
    "descriptor": "\nComments: Extended Abstract at the The First Workshop on Understanding Implicit and Underspecified Language @ ACL-2021\n",
    "authors": [
      "Peratham Wiriyathammabhum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14347"
  },
  {
    "id": "arXiv:2105.14352",
    "title": "WfCommons: A Framework for Enabling Scientific Workflow Research and  Development",
    "abstract": "Scientific workflows are a cornerstone of modern scientific computing. They\nare used to describe complex computational applications that require efficient\nand robust management of large volumes of data, which are typically\nstored/processed on heterogeneous, distributed resources. The workflow research\nand development community has employed a number of methods for the quantitative\nevaluation of existing and novel workflow algorithms and systems. In\nparticular, a common approach is to simulate workflow executions. In previous\nworks, we have presented a collection of tools that have been adopted by the\ncommunity for conducting workflow research. Despite their popularity, they\nsuffer from several shortcomings that prevent easy adoption, maintenance, and\nconsistency with the evolving structures and computational requirements of\nproduction workflows. In this work, we present WfCommons, a framework that\nprovides a collection of tools for analyzing workflow executions, for producing\ngenerators of synthetic workflows, and for simulating workflow executions. We\ndemonstrate the realism of the generated synthetic workflows by comparing their\nsimulated executions to real workflow executions. We also contrast these\nresults with results obtained when using the previously available collection of\ntools. We find that the workflow generators that are automatically constructed\nby our framework not only generate representative same-scale workflows (i.e.,\nwith structures and task characteristics distributions that resemble those\nobserved in real-world workflows), but also do so at scales larger than that of\navailable real-world workflows. Finally, we conduct a case study to demonstrate\nthe usefulness of our framework for estimating the energy consumption of\nlarge-scale workflow executions.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2009.00250\n",
    "authors": [
      "Tain\u00e3 Coleman",
      "Henri Casanova",
      "Lo\u00efc Pottier",
      "Manav Kaushik",
      "Ewa Deelman",
      "Rafael Ferreira da Silva"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.14352"
  },
  {
    "id": "arXiv:2105.14353",
    "title": "A coupled discontinuous Galerkin-Finite Volume framework for solving gas  dynamics over embedded geometries",
    "abstract": "We present a computational framework for solving the equations of inviscid\ngas dynamics using structured grids with embedded geometries. The novelty of\nthe proposed approach is the use of high-order discontinuous Galerkin (dG)\nschemes and a shock-capturing Finite Volume (FV) scheme coupled via an $hp$\nadaptive mesh refinement ($hp$-AMR) strategy that offers high-order accurate\nresolution of the embedded geometries. The $hp$-AMR strategy is based on a\nmulti-level block-structured domain partition in which each level is\nrepresented by block-structured Cartesian grids and the embedded geometry is\nrepresented implicitly by a level set function. The intersection of the\nembedded geometry with the grids produces the implicitly-defined mesh that\nconsists of a collection of regular rectangular cells plus a relatively small\nnumber of irregular curved elements in the vicinity of the embedded boundaries.\nHigh-order quadrature rules for implicitly-defined domains enable high-order\naccuracy resolution of the curved elements with a cell-merging strategy to\naddress the small-cell problem. The $hp$-AMR algorithm treats the system with a\nsecond-order finite volume scheme at the finest level to dynamically track the\nevolution of solution discontinuities while using dG schemes at coarser levels\nto provide high-order accuracy in smooth regions of the flow. On the dG levels,\nthe methodology supports different orders of basis functions on different\nlevels. The space-discretized governing equations are then advanced explicitly\nin time using high-order Runge-Kutta algorithms. Numerical tests are presented\nfor two-dimensional and three-dimensional problems involving an ideal gas. The\nresults are compared with both analytical solutions and experimental\nobservations and demonstrate that the framework provides high-order accuracy\nfor smooth flows and accurately captures solution discontinuities.",
    "descriptor": "",
    "authors": [
      "Vincenzo Gulizzi",
      "Ann S. Almgren",
      "John B. Bell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14353"
  },
  {
    "id": "arXiv:2105.14355",
    "title": "Three-dimensional multimodal medical imaging system based on free-hand  ultrasound and structured light",
    "abstract": "We propose a three-dimensional (3D) multimodal medical imaging system that\ncombines freehand ultrasound and structured light 3D reconstruction in a single\ncoordinate system without requiring registration. To the best of our knowledge,\nthese techniques have not been combined before as a multimodal imaging\ntechnique. The system complements the internal 3D information acquired with\nultrasound, with the external surface measured with the structure light\ntechnique. Moreover, the ultrasound probe's optical tracking for pose\nestimation was implemented based on a convolutional neural network.\nExperimental results show the system's high accuracy and reproducibility, as\nwell as its potential for preoperative and intraoperative applications. The\nexperimental multimodal error, or the distance from two surfaces obtained with\ndifferent modalities, was 0.12 mm. The code is available as a Github\nrepository.",
    "descriptor": "",
    "authors": [
      "Jhacson Meza",
      "Sonia H. Contreras-Ortiz",
      "Lenny A. Romero",
      "Andres G. Marrugo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.14355"
  },
  {
    "id": "arXiv:2105.14357",
    "title": "Constructing Flow Graphs from Procedural Cybersecurity Texts",
    "abstract": "Following procedural texts written in natural languages is challenging. We\nmust read the whole text to identify the relevant information or identify the\ninstruction flows to complete a task, which is prone to failures. If such texts\nare structured, we can readily visualize instruction-flows, reason or infer a\nparticular step, or even build automated systems to help novice agents achieve\na goal. However, this structure recovery task is a challenge because of such\ntexts' diverse nature. This paper proposes to identify relevant information\nfrom such texts and generate information flows between sentences. We built a\nlarge annotated procedural text dataset (CTFW) in the cybersecurity domain\n(3154 documents). This dataset contains valuable instructions regarding\nsoftware vulnerability analysis experiences. We performed extensive experiments\non CTFW with our LM-GNN model variants in multiple settings. To show the\ngeneralizability of both this task and our method, we also experimented with\nprocedural texts from two other domains (Maintenance Manual and Cooking), which\nare substantially different from cybersecurity. Our experiments show that Graph\nConvolution Network with BERT sentence embeddings outperforms BERT in all three\ndomains",
    "descriptor": "\nComments: 13 pages, 5 pages, accepted in the Findings of ACL 2021\n",
    "authors": [
      "Kuntal Kumar Pal",
      "Kazuaki Kashihara",
      "Pratyay Banerjee",
      "Swaroop Mishra",
      "Ruoyu Wang",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14357"
  },
  {
    "id": "arXiv:2105.14362",
    "title": "Dash Sylvereye: A WebGL-powered Library for Dashboard-driven  Visualization of Large Street Networks",
    "abstract": "State-of-the-art open network visualization tools like Gephi, KeyLines, and\nCytoscape are not suitable for studying street networks with thousands of roads\nsince they do not support simultaneously polylines for edges, navigable maps,\nGPU-accelerated rendering, interactivity, and the means for visualizing\nmultivariate data. The present paper presents Dash Sylvereye: a new Python\nlibrary to produce interactive visualizations of primal street networks on top\nof tiled web maps to fill this gap. Dash Sylvereye can render large street\ngraphs in commodity computers by exploiting WebGL for GPU acceleration. Dash\nSylvereye also provides convenient functions to easily import OpenStreetMap\nstreet topologies obtained with the OSMnx library. Thanks to its integration\nwith the Dash framework, Dash Sylvereye can be used to develop web dashboards\naround temporal and multivariate street data by coordinating the various\nelements of a Dash Sylvereye visualization with other plotting and UI\ncomponents provided by Dash. We conduct experiments to assess the performance\nof Dash Sylvereye on a commodity computer in terms of animation CPU time and\nframes per second. To further illustrate the features of Dash Sylvereye, we\nalso describe a web dashboard application that exploits Dash Sylvereye for the\nanalysis of a SUMO vehicle traffic simulation.",
    "descriptor": "\nComments: Submitted to IEEE Access on May 8, 2021\n",
    "authors": [
      "Alberto Garcia-Robledo",
      "Mahboobeh Zangiabady"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14362"
  },
  {
    "id": "arXiv:2105.14363",
    "title": "On the Theory of Reinforcement Learning with Once-per-Episode Feedback",
    "abstract": "We introduce a theory of reinforcement learning (RL) in which the learner\nreceives feedback only once at the end of an episode. While this is an extreme\ntest case for theory, it is also arguably more representative of real-world\napplications than the traditional requirement in RL practice that the learner\nreceive feedback at every time step. Indeed, in many real-world applications of\nreinforcement learning, such as self-driving cars and robotics, it is easier to\nevaluate whether a learner's complete trajectory was either \"good\" or \"bad,\"\nbut harder to provide a reward signal at each step. To show that learning is\npossible in this more challenging setting, we study the case where trajectory\nlabels are generated by an unknown parametric model, and provide a\nstatistically and computationally efficient algorithm that achieves sub-linear\nregret.",
    "descriptor": "",
    "authors": [
      "Niladri S. Chatterji",
      "Aldo Pacchiano",
      "Peter L. Bartlett",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14363"
  },
  {
    "id": "arXiv:2105.14364",
    "title": "Graph Similarity Description: How Are These Graphs Similar?",
    "abstract": "How do social networks differ across platforms? How do information networks\nchange over time? Answering questions like these requires us to compare two or\nmore graphs. This task is commonly treated as a measurement problem, but\nnumerical answers give limited insight. Here, we argue that if the goal is to\ngain understanding, we should treat graph similarity assessment as a\ndescription problem instead. We formalize this problem as a model selection\ntask using the Minimum Description Length principle, capturing the similarity\nof the input graphs in a common model and the differences between them in\ntransformations to individual models. To discover good models, we propose Momo,\nwhich breaks the problem into two parts and introduces efficient algorithms for\neach. Through an extensive set of experiments on a wide range of synthetic and\nreal-world graphs, we confirm that Momo works well in practice.",
    "descriptor": "\nComments: 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2021); 9+2 pages, 9+4 figures\n",
    "authors": [
      "Corinna Coupette",
      "Jilles Vreeken"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14364"
  },
  {
    "id": "arXiv:2105.14367",
    "title": "Deconvolutional Density Network: Free-Form Conditional Density  Estimation",
    "abstract": "Conditional density estimation is the task of estimating the probability of\nan event, conditioned on some inputs. A neural network can be used to compute\nthe output distribution explicitly. For such a task, there are many ways to\nrepresent a continuous-domain distribution using the output of a neural\nnetwork, but each comes with its own limitations for what distributions it can\naccurately render. If the family of functions is too restrictive, it will not\nbe appropriate for many datasets. In this paper, we demonstrate the benefits of\nmodeling free-form distributions using deconvolution. It has the advantage of\nbeing flexible, but also takes advantage of the topological smoothness offered\nby the deconvolution layers. We compare our method to a number of other\ndensity-estimation approaches, and show that our Deconvolutional Density\nNetwork (DDN) outperforms the competing methods on many artificial and real\ntasks, without committing to a restrictive parametric model.",
    "descriptor": "\nComments: 11 pages, 5 figures, 3 tables\n",
    "authors": [
      "Bing Chen",
      "Mazharul Islam",
      "Lin Wang",
      "Jisuo Gao",
      "Jeff Orchard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14367"
  },
  {
    "id": "arXiv:2105.14369",
    "title": "Temporal Minimal-World Semantics for Sparse ABoxes",
    "abstract": "Ontology-mediated query answering is a popular paradigm for enriching answers\nto user queries with background knowledge. For querying the absence of\ninformation, however, there exist only few ontology-based approaches. Moreover,\nthese proposals conflate the closed-domain and closed-world assumption, and\ntherefore are not suited to deal with the anonymous objects that are common in\nontological reasoning. Many real-world applications, like processing electronic\nhealth records (EHRs), also contain a temporal dimension, and require efficient\nreasoning algorithms. Moreover, since medical data is not recorded on a regular\nbasis, reasoners must deal with sparse data with potentially large temporal\ngaps. Our contribution consists of two main parts: In the first part we\nintroduce a new closed-world semantics for answering conjunctive queries with\nnegation over ontologies formulated in the description logic ELHb, which is\nbased on the minimal canonical model. We propose a rewriting strategy for\ndealing with negated query atoms, which shows that query answering is possible\nin polynomial time in data complexity. In the second part, we extend this\nminimal-world semantics for answering metric temporal conjunctive queries with\nnegation over the lightweight temporal logic TELHb and obtain similar\nrewritability and complexity results. This paper is under consideration in\nTheory and Practice of Logic Programming (TPLP).",
    "descriptor": "",
    "authors": [
      "Stefan Borgwardt",
      "Walter Forkel",
      "Alisa Kovtunova"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2105.14369"
  },
  {
    "id": "arXiv:2105.14370",
    "title": "BAAI-VANJEE Roadside Dataset: Towards the Connected Automated Vehicle  Highway technologies in Challenging Environments of China",
    "abstract": "As the roadside perception plays an increasingly significant role in the\nConnected Automated Vehicle Highway(CAVH) technologies, there are immediate\nneeds of challenging real-world roadside datasets for bench marking and\ntraining various computer vision tasks such as 2D/3D object detection and\nmulti-sensor fusion. In this paper, we firstly introduce a challenging\nBAAI-VANJEE roadside dataset which consist of LiDAR data and RGB images\ncollected by VANJEE smart base station placed on the roadside about 4.5m high.\nThis dataset contains 2500 frames of LiDAR data, 5000 frames of RGB images,\nincluding 20% collected at the same time. It also contains 12 classes of\nobjects, 74K 3D object annotations and 105K 2D object annotations. By providing\na real complex urban intersections and highway scenes, we expect the\nBAAI-VANJEE roadside dataset will actively assist the academic and industrial\ncircles to accelerate the innovation research and achievement transformation in\nthe field of intelligent transportation in big data era.",
    "descriptor": "",
    "authors": [
      "Deng Yongqiang",
      "Wang Dengjiang",
      "Cao Gang",
      "Ma Bing",
      "Guan Xijia",
      "Wang Yajun",
      "Liu Jianchao",
      "Fang Yanming",
      "Li Juanjuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14370"
  },
  {
    "id": "arXiv:2105.14371",
    "title": "Fine-Tuning the Odds in Bayesian Networks",
    "abstract": "This paper proposes various new analysis techniques for Bayes networks in\nwhich conditional probability tables (CPTs) may contain symbolic variables. The\nkey idea is to exploit scalable and powerful techniques for synthesis problems\nin parametric Markov chains. Our techniques are applicable to arbitrarily many,\npossibly dependent parameters that may occur in various CPTs. This lifts the\nsevere restrictions on parameters, e.g., by restricting the number of\nparametrized CPTs to one or two, or by avoiding parameter dependencies between\nseveral CPTs, in existing works for parametric Bayes networks (pBNs). We\ndescribe how our techniques can be used for various pBN synthesis problems\nstudied in the literature such as computing sensitivity functions (and values),\nsimple and difference parameter tuning, ratio parameter tuning, and minimal\nchange tuning. Experiments on several benchmarks show that our prototypical\ntool built on top of the probabilistic model checker Storm can handle several\nhundreds of parameters.",
    "descriptor": "",
    "authors": [
      "Bahare Salmani",
      "Joost-Pieter Katoen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14371"
  },
  {
    "id": "arXiv:2105.14373",
    "title": "Sentiment analysis in tweets: an assessment study from classical to  modern text representation models",
    "abstract": "With the growth of social medias, such as Twitter, plenty of user-generated\ndata emerge daily. The short texts published on Twitter -- the tweets -- have\nearned significant attention as a rich source of information to guide many\ndecision-making processes. However, their inherent characteristics, such as the\ninformal, and noisy linguistic style, remain challenging to many natural\nlanguage processing (NLP) tasks, including sentiment analysis. Sentiment\nclassification is tackled mainly by machine learning-based classifiers. The\nliterature has adopted word representations from distinct natures to transform\ntweets to vector-based inputs to feed sentiment classifiers. The\nrepresentations come from simple count-based methods, such as bag-of-words, to\nmore sophisticated ones, such as BERTweet, built upon the trendy BERT\narchitecture. Nevertheless, most studies mainly focus on evaluating those\nmodels using only a small number of datasets. Despite the progress made in\nrecent years in language modelling, there is still a gap regarding a robust\nevaluation of induced embeddings applied to sentiment analysis on tweets.\nFurthermore, while fine-tuning the model from downstream tasks is prominent\nnowadays, less attention has been given to adjustments based on the specific\nlinguistic style of the data. In this context, this study fulfils an assessment\nof existing language models in distinguishing the sentiment expressed in tweets\nby using a rich collection of 22 datasets from distinct domains and five\nclassification algorithms. The evaluation includes static and contextualized\nrepresentations. Contexts are assembled from Transformer-based autoencoder\nmodels that are also fine-tuned based on the masked language model task, using\na plethora of strategies.",
    "descriptor": "",
    "authors": [
      "S\u00e9rgio Barreto",
      "Ricardo Moura",
      "Jonnathan Carvalho",
      "Aline Paes",
      "Alexandre Plastino"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14373"
  },
  {
    "id": "arXiv:2105.14376",
    "title": "Beyond the Spectrum: Detecting Deepfakes via Re-Synthesis",
    "abstract": "The rapid advances in deep generative models over the past years have led to\nhighly {realistic media, known as deepfakes,} that are commonly\nindistinguishable from real to human eyes. These advances make assessing the\nauthenticity of visual data increasingly difficult and pose a misinformation\nthreat to the trustworthiness of visual content in general. Although recent\nwork has shown strong detection accuracy of such deepfakes, the success largely\nrelies on identifying frequency artifacts in the generated images, which will\nnot yield a sustainable detection approach as generative models continue\nevolving and closing the gap to real images. In order to overcome this issue,\nwe propose a novel fake detection that is designed to re-synthesize testing\nimages and extract visual cues for detection. The re-synthesis procedure is\nflexible, allowing us to incorporate a series of visual tasks - we adopt\nsuper-resolution, denoising and colorization as the re-synthesis. We\ndemonstrate the improved effectiveness, cross-GAN generalization, and\nrobustness against perturbations of our approach in a variety of detection\nscenarios involving multiple generators over CelebA-HQ, FFHQ, and LSUN\ndatasets. Source code is available at\nhttps://github.com/SSAW14/BeyondtheSpectrum.",
    "descriptor": "\nComments: To appear in IJCAI2021. Source code at this https URL\n",
    "authors": [
      "Yang He",
      "Ning Yu",
      "Margret Keuper",
      "Mario Fritz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14376"
  },
  {
    "id": "arXiv:2105.14380",
    "title": "Transmission Delay Minimization via Joint Power Control and Caching in  Wireless HetNets",
    "abstract": "A fundamental challenge in wireless heterogeneous networks (HetNets) is to\neffectively utilize the limited transmission and storage resources in the\npresence of increasing deployment density and backhaul capacity constraints. To\nalleviate bottlenecks and reduce resource consumption, we design optimal\ncaching and power control algorithms for multi-hop wireless HetNets. We\nformulate a joint optimization framework to minimize the average transmission\ndelay as a function of the caching variables and the\nsignal-to-interference-plus-noise ratios (SINR) which are determined by the\ntransmission powers, while explicitly accounting for backhaul connection costs\nand the power constraints.\nUsing convex relaxation and rounding, we obtain a reduced-complexity\nformulation (RCF) of the joint optimization problem, which can provide a\nconstant factor approximation to the globally optimal solution. We then solve\nRCF in two ways: 1) alternating optimization of the power and caching variables\nby leveraging biconvexity, and 2) joint optimization of power control and\ncaching. We characterize the necessary (KKT) conditions for an optimal solution\nto RCF, and use strict quasi-convexity to show that the KKT points are Pareto\noptimal for RCF. We then devise a subgradient projection algorithm to jointly\nupdate the caching and power variables, and show that under appropriate\nconditions, the algorithm converges at a linear rate to the local minima of\nRCF, under general SINR conditions. We support our analytical findings with\nresults from extensive numerical experiments.",
    "descriptor": "\nComments: Supplementary material for conference submission\n",
    "authors": [
      "Derya Malak",
      "Faruk V. Mutlu",
      "Jinkun Zhang",
      "Edmund M. Yeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.14380"
  },
  {
    "id": "arXiv:2105.14381",
    "title": "Formally Validating a Practical Verification Condition Generator  (extended version)",
    "abstract": "A program verifier produces reliable results only if both the logic used to\njustify the program's correctness is sound, and the implementation of the\nprogram verifier is itself correct. Whereas it is common to formally prove\nsoundness of the logic, the implementation of a verifier typically remains\nunverified. Bugs in verifier implementations may compromise the trustworthiness\nof successful verification results. Since program verifiers used in practice\nare complex, evolving software systems, it is generally not feasible to\nformally verify their implementation.\nIn this paper, we present an alternative approach: we validate successful\nruns of the widely-used Boogie verifier by producing a certificate which proves\ncorrectness of the obtained verification result. Boogie performs a complex\nseries of program translations before ultimately generating a verification\ncondition whose validity should imply the correctness of the input program. We\nshow how to certify three of Boogie's core transformation phases: the\nelimination of cyclic control flow paths, the (SSA-like) replacement of\nassignments by assumptions using fresh variables (passification), and the final\ngeneration of verification conditions. Similar translations are employed by\nother verifiers. Our implementation produces certificates in Isabelle, based on\na novel formalisation of the Boogie language.",
    "descriptor": "\nComments: Extended version of CAV 2021 publication\n",
    "authors": [
      "Gaurav Parthasarathy",
      "Peter M\u00fcller",
      "Alexander J. Summers"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.14381"
  },
  {
    "id": "arXiv:2105.14383",
    "title": "Gradient-Free Neural Network Training via Synaptic-Level Reinforcement  Learning",
    "abstract": "An ongoing challenge in neural information processing is: how do neurons\nadjust their connectivity to improve task performance over time (i.e.,\nactualize learning)? It is widely believed that there is a consistent,\nsynaptic-level learning mechanism in specific brain regions that actualizes\nlearning. However, the exact nature of this mechanism remains unclear. Here we\npropose an algorithm based on reinforcement learning (RL) to generate and apply\na simple synaptic-level learning policy for multi-layer perceptron (MLP)\nmodels. In this algorithm, the action space for each MLP synapse consists of a\nsmall increase, decrease, or null action on the synapse weight, and the state\nfor each synapse consists of the last two actions and reward signals. A binary\nreward signal indicates improvement or deterioration in task performance. The\nstatic policy produces superior training relative to the adaptive policy and is\nagnostic to activation function, network shape, and task. Trained MLPs yield\ncharacter recognition performance comparable to identically shaped networks\ntrained with gradient descent. 0 hidden unit character recognition tests\nyielded an average validation accuracy of 88.28%, 1.86$\\pm$0.47% higher than\nthe same MLP trained with gradient descent. 32 hidden unit character\nrecognition tests yielded an average validation accuracy of 88.45%,\n1.11$\\pm$0.79% lower than the same MLP trained with gradient descent. The\nrobustness and lack of reliance on gradient computations opens the door for new\ntechniques for training difficult-to-differentiate artificial neural networks\nsuch as spiking neural networks (SNNs) and recurrent neural networks (RNNs).\nFurther, the method's simplicity provides a unique opportunity for further\ndevelopment of local rule-driven multi-agent connectionist models for machine\nintelligence analogous to cellular automata.",
    "descriptor": "\nComments: 10 pages, 3 figures, submitted to NeurIPS 2021\n",
    "authors": [
      "Aman Bhargava",
      "Mohammad R. Rezaei",
      "Milad Lankarany"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.14383"
  },
  {
    "id": "arXiv:2105.14388",
    "title": "Dynamic Placement in Refugee Resettlement",
    "abstract": "Employment outcomes of resettled refugees depend strongly on where they are\nplaced inside the host country. While the United States sets refugee capacities\nfor communities on an annual basis, refugees arrive and must be placed over the\ncourse of the year. We introduce a dynamic allocation system based on two-stage\nstochastic programming to improve employment outcomes. Our algorithm is able to\nachieve over 98 percent of the hindsight-optimal employment compared to under\n90 percent of current greedy-like approaches. This dramatic improvement\npersists even when we incorporate a vast array of practical features of the\nrefugee resettlement process including indivisible families, batching, and\nuncertainty with respect to the number of future arrivals. Our algorithm is now\npart of the Annie MOORE optimization software used by a leading American\nrefugee resettlement agency.",
    "descriptor": "",
    "authors": [
      "Narges Ahani",
      "Paul G\u00f6lz",
      "Ariel D. Procaccia",
      "Alexander Teytelboym",
      "Andrew C. Trapp"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.14388"
  },
  {
    "id": "arXiv:2105.14391",
    "title": "Data-driven 6D Pose Tracking by Calibrating Image Residuals in Synthetic  Domains",
    "abstract": "Tracking the 6D pose of objects in video sequences is important for robot\nmanipulation. This work presents se(3)-TrackNet, a data-driven optimization\napproach for long term, 6D pose tracking. It aims to identify the optimal\nrelative pose given the current RGB-D observation and a synthetic image\nconditioned on the previous best estimate and the object's model. The key\ncontribution in this context is a novel neural network architecture, which\nappropriately disentangles the feature encoding to help reduce domain shift,\nand an effective 3D orientation representation via Lie Algebra. Consequently,\neven when the network is trained solely with synthetic data can work\neffectively over real images. Comprehensive experiments over multiple\nbenchmarks show se(3)-TrackNet achieves consistently robust estimates and\noutperforms alternatives, even though they have been trained with real images.\nThe approach runs in real time at 90.9Hz. Code, data and supplementary video\nfor this project are available at\nhttps://github.com/wenbowen123/iros20-6d-pose-tracking",
    "descriptor": "\nComments: CVPR 2021 Workshop on 3D Vision and Robotics. arXiv admin note: substantial text overlap with arXiv:2007.13866\n",
    "authors": [
      "Bowen Wen",
      "Chaitanya Mitash",
      "Kostas Bekris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14391"
  },
  {
    "id": "arXiv:2105.14396",
    "title": "SyReNets: Symbolic Residual Neural Networks",
    "abstract": "Despite successful seminal works on passive systems in the literature,\nlearning free-form physical laws for controlled dynamical systems given\nexperimental data is still an open problem. For decades, symbolic mathematical\nequations and system identification were the golden standards. Unfortunately, a\nset of assumptions about the properties of the underlying system is required,\nwhich makes the model very rigid and unable to adapt to unforeseen changes in\nthe physical system. Neural networks, on the other hand, are known universal\nfunction approximators but are prone to over-fit, limited accuracy, and bias\nproblems, which makes them alone unreliable candidates for such tasks. In this\npaper, we propose SyReNets, an approach that leverages neural networks for\nlearning symbolic relations to accurately describe dynamic physical systems\nfrom data. It explores a sequence of symbolic layers that build, in a residual\nmanner, mathematical relations that describes a given desired output from input\nvariables. We apply it to learn the symbolic equation that describes the\nLagrangian of a given physical system. We do this by only observing random\nsamples of position, velocity, and acceleration as input and torque as output.\nTherefore, using the Lagrangian as a latent representation from which we derive\ntorque using the Euler-Lagrange equations. The approach is evaluated using a\nsimulated controlled double pendulum and compared with neural networks, genetic\nprogramming, and traditional system identification. The results demonstrate\nthat, compared to neural networks and genetic programming, SyReNets converges\nto representations that are more accurate and precise throughout the state\nspace. Despite having slower convergence than traditional system\nidentification, similar to neural networks, the approach remains flexible\nenough to adapt to an unforeseen change in the physical system structure.",
    "descriptor": "\nComments: 11 pages, 3 figures, 2 table\n",
    "authors": [
      "Carlos Magno C. O. Valle",
      "Sami Haddadin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14396"
  },
  {
    "id": "arXiv:2105.14398",
    "title": "Learning Domain-Specialised Representations for Cross-Lingual Biomedical  Entity Linking",
    "abstract": "Injecting external domain-specific knowledge (e.g., UMLS) into pretrained\nlanguage models (LMs) advances their capability to handle specialised in-domain\ntasks such as biomedical entity linking (BEL). However, such abundant expert\nknowledge is available only for a handful of languages (e.g., English). In this\nwork, by proposing a novel cross-lingual biomedical entity linking task\n(XL-BEL) and establishing a new XL-BEL benchmark spanning 10 typologically\ndiverse languages, we first investigate the ability of standard\nknowledge-agnostic as well as knowledge-enhanced monolingual and multilingual\nLMs beyond the standard monolingual English BEL task. The scores indicate large\ngaps to English performance. We then address the challenge of transferring\ndomain-specific knowledge in resource-rich languages to resource-poor ones. To\nthis end, we propose and evaluate a series of cross-lingual transfer methods\nfor the XL-BEL task, and demonstrate that general-domain bitext helps propagate\nthe available English knowledge to languages with little to no in-domain data.\nRemarkably, we show that our proposed domain-specific transfer methods yield\nconsistent gains across all target languages, sometimes up to 20 Precision@1\npoints, without any in-domain knowledge in the target language, and without any\nin-domain parallel data.",
    "descriptor": "\nComments: ACL-IJCNLP 2021\n",
    "authors": [
      "Fangyu Liu",
      "Ivan Vuli\u0107",
      "Anna Korhonen",
      "Nigel Collier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14398"
  },
  {
    "id": "arXiv:2105.14399",
    "title": "Improving Entropic Out-of-Distribution Detection using Isometric  Distances and the Minimum Distance Score",
    "abstract": "Current out-of-distribution detection approaches usually present special\nrequirements (e.g., collecting outlier data and hyperparameter validation) and\nproduce side effects (classification accuracy drop and slow/inefficient\ninferences). Recently, entropic out-of-distribution detection has been proposed\nas a seamless approach (i.e., a solution that avoids all the previously\nmentioned drawbacks). The entropic out-of-distribution detection solution\ncomprises the IsoMax loss for training and the entropic score for\nout-of-distribution detection. The IsoMax loss works as a SoftMax loss drop-in\nreplacement because swapping the SoftMax loss with the IsoMax loss requires no\nchanges in the model's architecture or training procedures/hyperparameters. In\nthis paper, we propose to perform what we call an isometrization of the\ndistances used in the IsoMax loss. Additionally, we propose to replace the\nentropic score with the minimum distance score. Our experiments showed that\nthese simple modifications increase out-of-distribution detection performance\nwhile keeping the solution seamless.",
    "descriptor": "",
    "authors": [
      "David Mac\u00eado",
      "Teresa Ludermir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.14399"
  },
  {
    "id": "arXiv:2105.14401",
    "title": "A Tapered Floating Point Extension for the Redundant Signed Radix 2  System Using the Canonical Recoding",
    "abstract": "A tapered floating point encoding is proposed which uses the redundant signed\nradix 2 system and is based on the canonical recoding. By making use of ternary\ntechnology, the encoding has a dynamic range exceeding that of the\nrecently-proposed Posit number system and the IEEE 754-1985 Standard for\nFloating Point Arithmetic (IEEE-754-1985), and precision equal to or better\nthan that of the IEEE-754-1985 system and the recently proposed Posit system\nwhen equal input sizes are compared. In addition, the encoding is capable of\nsupporting several proposed extensions, including extensions to integers,\nboolean values, complex numbers, higher number systems, low-dimensional\nvectors, and system artifacts such as machine instructions. A detailed analytic\ncomparison is provided between the proposed encoding, the IEEE-754-1985 system,\nand the recently proposed Posit number system.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Lucius T. Schoenbaum"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2105.14401"
  },
  {
    "id": "arXiv:2105.14403",
    "title": "Re-evaluating Word Mover's Distance",
    "abstract": "The word mover's distance (WMD) is a fundamental technique for measuring the\nsimilarity of two documents. As the crux of WMD, it can take advantage of the\nunderlying geometry of the word space by employing an optimal transport\nformulation. The original study on WMD reported that WMD outperforms classical\nbaselines such as bag-of-words (BOW) and TF-IDF by significant margins in\nvarious datasets. In this paper, we point out that the evaluation in the\noriginal study could be misleading. We re-evaluate the performances of WMD and\nthe classical baselines and find that the classical baselines are competitive\nwith WMD if we employ an appropriate preprocessing, i.e., L1 normalization.\nHowever, this result is not intuitive. WMD should be superior to BOW because\nWMD can take the underlying geometry into account, whereas BOW cannot. Our\nanalysis shows that this is due to the high-dimensional nature of the\nunderlying metric. We find that WMD in high-dimensional spaces behaves more\nsimilarly to BOW than in low-dimensional spaces due to the curse of\ndimensionality.",
    "descriptor": "",
    "authors": [
      "Ryoma Sato",
      "Makoto Yamada",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.14403"
  },
  {
    "id": "arXiv:2105.14405",
    "title": "IoTAthena: Unveiling IoT Device Activities from Network Traffic",
    "abstract": "The recent spate of cyber attacks towards Internet of Things (IoT) devices in\nsmart homes calls for effective techniques to understand, characterize, and\nunveil IoT device activities. In this paper, we present a new system, named\nIoTAthena, to unveil IoT device activities from raw network traffic consisting\nof timestamped IP packets. IoTAthena characterizes each IoT device activity\nusing an activity signature consisting of an ordered sequence of IP packets\nwith inter-packet time intervals. IoTAthena has two novel polynomial time\nalgorithms, sigMatch and actExtract. For any given signature, sigMatch can\ncapture all matches of the signature in the raw network traffic. Using sigMatch\nas a subfunction, actExtract can accurately unveil the sequence of various IoT\ndevice activities from the raw network traffic. Using the network traffic of\nheterogeneous IoT devices collected at the router of a real-world smart home\ntestbed and a public IoT dataset, we demonstrate that IoTAthena is able to\ncharacterize and generate activity signatures of IoT device activities and\naccurately unveil the sequence of IoT device activities from raw network\ntraffic.",
    "descriptor": "",
    "authors": [
      "Yinxin Wan",
      "Kuai Xu",
      "Feng Wang",
      "Guoliang Xue"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.14405"
  },
  {
    "id": "arXiv:2105.14406",
    "title": "A splitting Hamiltonian Monte Carlo method for efficient sampling",
    "abstract": "We propose a splitting Hamiltonian Monte Carlo (SHMC) algorithm, which can be\nnumerically and computationally efficient when combined with the random\nmini-batch strategy. By splitting the \"effective potential energy\" $U\\propto\n-\\beta^{-1}\\log \\rho$ into two parts $U = U_1 + U_2$, one makes a proposal\nusing the \"easy-to-sample\" part $U_1$, followed by probabilistically accepting\nthat proposal by a Metropolis rejection step using $U_2$. The splitting allows\nefficient sampling from systems with singular potentials (or distributions with\ndegenerate points) and/or with multiple potential barriers. In our SHMC\nalgorithm, the proposal using $U_1$ is generated by the Hamiltonian dynamics,\nwhich can be potentially more efficient than the overdamped Langevin dynamics.\nWe also use random batch strategies to reduce the computational cost to\n$\\mathcal{O}(1)$ per time step in generating the proposals for problems arising\nfrom many-body systems and Bayesian inference, and prove that the errors of the\nHamiltonian induced by the random batch approximation is\n$\\mathcal{O}(\\sqrt{\\Delta t})$ in the strong and $\\mathcal{O}(\\Delta t)$ in the\nweak sense, where $\\Delta t$ is the time step. Numerical experiments are\nconducted to verify the theoretical results and the computational efficiency of\nthe proposed algorithms in practice.",
    "descriptor": "",
    "authors": [
      "Lei Li",
      "Lin Liu",
      "Yuzhou Peng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14406"
  },
  {
    "id": "arXiv:2105.14408",
    "title": "PPT: A Privacy-Preserving Global Model Training Protocol for Federated  Learning in P2P Networks",
    "abstract": "The concept of Federated Learning has emerged as a convergence of distributed\nmachine learning, information, and communication technology. It is vital to the\ndevelopment of distributed machine learning, which is expected to be fully\ndecentralized, robust, communication efficient, and secure. However, the\nfederated learning settings with a central server can't meet requirements in\nfully decentralized networks. In this paper, we propose a fully decentralized,\nefficient, and privacy-preserving global model training protocol, named PPT,\nfor federated learning in Peer-to-peer (P2P) Networks. PPT uses a one-hop\ncommunication form to aggregate local model update parameters and adopts the\nsymmetric cryptosystem to ensure security. It is worth mentioning that PPT\nmodifies the Eschenauer-Gligor (E-G) scheme to distribute keys for encryption.\nPPT also adopts Neighborhood Broadcast, Supervision and Report, and Termination\nas complementary mechanisms to enhance security and robustness. Through\nextensive analysis, we demonstrate that PPT resists various security threats\nand preserve user privacy. Ingenious experiments demonstrate the utility and\nefficiency as well.",
    "descriptor": "",
    "authors": [
      "Qian Chen",
      "Zilong Wang",
      "Xiaodong Lin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14408"
  },
  {
    "id": "arXiv:2105.14410",
    "title": "Machine learning moment closure models for the radiative transfer  equation II: enforcing global hyperbolicity in gradient based closures",
    "abstract": "This is the second paper in a series in which we develop machine learning\n(ML) moment closure models for the radiative transfer equation (RTE). In our\nprevious work \\cite{huang2021gradient}, we proposed an approach to directly\nlearn the gradient of the unclosed high order moment, which performs much\nbetter than learning the moment itself and the conventional $P_N$ closure.\nHowever, the ML moment closure model in \\cite{huang2021gradient} is not able to\nguarantee hyperbolicity and long time stability. We propose in this paper a\nmethod to enforce the global hyperbolicity of the ML closure model. The main\nidea is to seek a symmetrizer (a symmetric positive definite matrix) for the\nclosure system, and derive constraints such that the system is globally\nsymmetrizable hyperbolic. It is shown that the new ML closure system inherits\nthe dissipativeness of the RTE and preserves the correct diffusion limit as the\nKnunsden number goes to zero. Several benchmark tests including the Gaussian\nsource problem and the two-material problem show the good accuracy, long time\nstability and generalizability of our globally hyperbolic ML closure model.",
    "descriptor": "",
    "authors": [
      "Juntao Huang",
      "Yingda Cheng",
      "Andrew J. Christlieb",
      "Luke F. Roberts",
      "Wen-An Yong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.14410"
  },
  {
    "id": "arXiv:2105.14412",
    "title": "An improved LogNNet classifier for IoT application",
    "abstract": "The internet of things devices suffer of low memory while good accuracy is\nneeded. Designing suitable algorithms is vital in this subject. This paper\nproposes a feed forward LogNNet neural network which uses a semi-linear Henon\ntype discrete chaotic map to classify MNIST-10 dataset. The model is composed\nof reservoir part and trainable classifier. The aim of reservoir part is\ntransforming the inputs to maximize the classification accuracy using a special\nmatrix filing method and a time series generated by the chaotic map. The\nparameters of the chaotic map are optimized using particle swarm optimization\nwith random immigrants. The results show that the proposed LogNNet/Henon\nclassifier has higher accuracy and same RAM saving comparable to the original\nversion of LogNNet and has broad prospects for implementation in IoT devices.\nIn addition, the relation between the entropy and accuracy of the\nclassification is investigated. It is shown that there exists a direct relation\nbetween the value of entropy and accuracy of the classification.",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Hanif Heidari",
      "Andrei Velichko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2105.14412"
  },
  {
    "id": "arXiv:2105.14416",
    "title": "Communication efficient privacy-preserving distributed optimization  using adaptive differential quantization",
    "abstract": "Privacy issues and communication cost are both major concerns in distributed\noptimization. There is often a trade-off between them because the encryption\nmethods required for privacy-preservation often incur expensive communication\nbandwidth. To address this issue, we, in this paper, propose a\nquantization-based approach to achieve both communication efficient and\nprivacy-preserving solutions in the context of distributed optimization. By\ndeploying an adaptive differential quantization scheme, we allow each node in\nthe network to achieve its optimum solution with a low communication cost while\nkeeping its private data unrevealed. Additionally, the proposed approach is\ngeneral and can be applied in various distributed optimization methods, such as\nthe primal-dual method of multipliers (PDMM) and the alternating direction\nmethod of multipliers (ADMM). Moveover, we consider two widely used adversary\nmodels: passive and eavesdropping. Finally, we investigate the properties of\nthe proposed approach using different applications and demonstrate its superior\nperformance in terms of several parameters including accuracy, privacy, and\ncommunication cost.",
    "descriptor": "",
    "authors": [
      "Qiongxiu Li",
      "Richard Heusdens",
      "Mads Gr\u00e6sb\u00f8ll Christensen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14416"
  },
  {
    "id": "arXiv:2105.14417",
    "title": "Overparameterization of deep ResNet: zero loss and mean-field analysis",
    "abstract": "Finding parameters in a deep neural network (NN) that fit training data is a\nnonconvex optimization problem, but a basic first-order optimization method\n(gradient descent) finds a global solution with perfect fit in many practical\nsituations. We examine this phenomenon for the case of Residual Neural Networks\n(ResNet) with smooth activation functions in a limiting regime in which both\nthe number of layers (depth) and the number of neurons in each layer (width) go\nto infinity. First, we use a mean-field-limit argument to prove that the\ngradient descent for parameter training becomes a partial differential equation\n(PDE) that characterizes gradient flow for a probability distribution in the\nlarge-NN limit. Next, we show that the solution to the PDE converges in the\ntraining time to a zero-loss solution. Together, these results imply that\ntraining of the ResNet also gives a near-zero loss if the Resnet is large\nenough. We give estimates of the depth and width needed to reduce the loss\nbelow a given threshold, with high probability.",
    "descriptor": "",
    "authors": [
      "Zhiyan Ding",
      "Shi Chen",
      "Qin Li",
      "Stephen Wright"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14417"
  },
  {
    "id": "arXiv:2105.14418",
    "title": "Virtual element approximation of two-dimensional parabolic variational  inequalities",
    "abstract": "We design a virtual element method for the numerical treatment of the\ntwo-dimensional parabolic variational inequality problem on unstructured\npolygonal meshes. Due to the expected low regularity of the exact solution, the\nvirtual element method is based on the lowest-order virtual element space that\ncontains the subspace of the linear polynomials defined on each element. The\nconnection between the nonnegativity of the virtual element functions and the\nnonnegativity of the degrees of freedom, i.e., the values at the mesh vertices,\nis established by applying the Maximum and Minimum Principle Theorem. The mass\nmatrix is computed through an approximate L 2 polynomial projection, whose\nproperties are carefully investigated in the paper. We prove the well-posedness\nof the resulting scheme in two different ways that reveal the contractive\nnature of the VEM and its connection with the minimization of quadratic\nfunctionals. The convergence analysis requires the existence of a nonnegative\nquasi-interpolation operator, whose construction is also discussed in the\npaper. The variational crime introduced by the virtual element setting produces\nfive error terms that we control by estimating a suitable upper bound.\nNumerical experiments confirm the theoretical convergence rate for the\nrefinement in space and time on three different mesh families including\ndistorted squares, nonconvex elements, and Voronoi tesselations.",
    "descriptor": "\nComments: 33 pages, 3 figures\n",
    "authors": [
      "Dibyendu Adak",
      "Gianmarco Manzini",
      "Sundararajan Natarajan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14418"
  },
  {
    "id": "arXiv:2105.14421",
    "title": "VersatileGait: A Large-Scale Synthetic Gait Dataset Towards in-the-Wild  Simulation",
    "abstract": "Gait recognition has a rapid development in recent years. However, gait\nrecognition in the wild is not well explored yet. An obvious reason could be\nascribed to the lack of diverse training data from the perspective of intrinsic\nand extrinsic factors. To remedy this problem, we propose to construct a\nlarge-scale gait dataset with the help of controllable computer simulation. In\ndetail, to diversify the intrinsic factors of gait, we generate numerous\ncharacters with diverse attributes and empower them with various types of\nwalking styles. To diversify the extrinsic factors of gait, we build a\ncomplicated scene with a dense camera layout. Finally, we design an automated\ngeneration toolkit under Unity3D for simulating the walking scenario and\ncapturing the gait data automatically. As a result, we obtain an in-the-wild\ngait dataset, called VersatileGait, which has more than one million silhouette\nsequences of 10,000 subjects with diverse scenarios. VersatileGait possesses\nseveral nice properties, including huge dataset size, diverse pedestrian\nattributes, complicated camera layout, high-quality annotations, small domain\ngap with the real one, good scalability for new demands, and no privacy issues.\nBased on VersatileGait, we propose series of experiments and applications for\nboth research exploration of gait in the wild and practical applications. Our\ndataset and its corresponding generation toolkit will be publicly available for\nfurther studies.",
    "descriptor": "",
    "authors": [
      "Pengyi Zhang",
      "Huanzhang Dou",
      "Wenhu Zhang",
      "Yuhan Zhao",
      "Songyuan Li",
      "Zequn Qin",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14421"
  },
  {
    "id": "arXiv:2105.14422",
    "title": "Periodic-GP: Learning Periodic World with Gaussian Process Bandits",
    "abstract": "We consider the sequential decision optimization on the periodic environment,\nthat occurs in a wide variety of real-world applications when the data involves\nseasonality, such as the daily demand of drivers in ride-sharing and dynamic\ntraffic patterns in transportation. In this work, we focus on learning the\nstochastic periodic world by leveraging this seasonal law. To deal with the\ngeneral action space, we use the bandit based on Gaussian process (GP) as the\nbase model due to its flexibility and generality, and propose the Periodic-GP\nmethod with a temporal periodic kernel based on the upper confidence bound.\nTheoretically, we provide a new regret bound of the proposed method, by\nexplicitly characterizing the periodic kernel in the periodic stationary model.\nEmpirically, the proposed algorithm significantly outperforms the existing\nmethods in both synthetic data experiments and a real data application on\nMadrid traffic pollution.",
    "descriptor": "",
    "authors": [
      "Hengrui Cai",
      "Zhihao Cen",
      "Ling Leng",
      "Rui Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.14422"
  },
  {
    "id": "arXiv:2105.14423",
    "title": "Enumerating Fair Packages for Group Recommendations",
    "abstract": "In package recommendations, a set of items is regarded as a unified package\ntowards a single common goal, whereas conventional recommender systems treat\nitems independently. For example, for music playlist recommendations, each\npackage (i.e., playlist) should be consistent with respect to the genres. In\ngroup recommendations, items are recommended to a group of users, whereas\nconventional recommender systems recommend items to an individual user.\nDifferent from the conventional settings, it is difficult to measure the\nutility of group recommendations because it involves more than one user. In\nparticular, fairness is crucial in group recommendations. Even if some members\nin a group are substantially satisfied with a recommendation, it is undesirable\nif other members are ignored to increase the total utility. Various methods for\nevaluating and applying the fairness of group recommendations have been\nproposed in the literature. However, all these methods maximize the score and\noutput only a single package. This is in contrast to conventional recommender\nsystems, which output several (e.g., top-$K$) candidates. This can be\nproblematic because a group can be dissatisfied with the recommended package\nowing to some unobserved reasons, even if the score is high. In particular,\neach fairness measure is not absolute, and users may call for different\nfairness criteria than the one adopted in the recommender system in operation.\nTo address this issue, we propose a method to enumerate fair packages so that a\ngroup can select their favorite packages from the list. Our proposed method can\nenumerate fair packages efficiently, and users can search their favorite\npackages by various filtering queries. We confirm that our algorithm scales to\nlarge datasets and can balance several aspects of the utility of the packages.",
    "descriptor": "",
    "authors": [
      "Ryoma Sato"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.14423"
  },
  {
    "id": "arXiv:2105.14424",
    "title": "Gaze Estimation using Transformer",
    "abstract": "Recent work has proven the effectiveness of transformers in many computer\nvision tasks. However, the performance of transformers in gaze estimation is\nstill unexplored. In this paper, we employ transformers and assess their\neffectiveness for gaze estimation. We consider two forms of vision transformer\nwhich are pure transformers and hybrid transformers. We first follow the\npopular ViT and employ a pure transformer to estimate gaze from images. On the\nother hand, we preserve the convolutional layers and integrate CNNs as well as\ntransformers. The transformer serves as a component to complement CNNs. We\ncompare the performance of the two transformers in gaze estimation. The Hybrid\ntransformer significantly outperforms the pure transformer in all evaluation\ndatasets with less parameters. We further conduct experiments to assess the\neffectiveness of the hybrid transformer and explore the advantage of\nself-attention mechanism. Experiments show the hybrid transformer can achieve\nstate-of-the-art performance in all benchmarks with pre-training.To facilitate\nfurther research, we release codes and models in\nhttps://github.com/yihuacheng/GazeTR.",
    "descriptor": "",
    "authors": [
      "Yihua Cheng",
      "Feng Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14424"
  },
  {
    "id": "arXiv:2105.14426",
    "title": "ICDAR 2021 Competition on Scientific Table Image Recognition to LaTeX",
    "abstract": "Tables present important information concisely in many scientific documents.\nVisual features like mathematical symbols, equations, and spanning cells make\nstructure and content extraction from tables embedded in research documents\ndifficult. This paper discusses the dataset, tasks, participants' methods, and\nresults of the ICDAR 2021 Competition on Scientific Table Image Recognition to\nLaTeX. Specifically, the task of the competition is to convert a tabular image\nto its corresponding LaTeX source code. We proposed two subtasks. In Subtask 1,\nwe ask the participants to reconstruct the LaTeX structure code from an image.\nIn Subtask 2, we ask the participants to reconstruct the LaTeX content code\nfrom an image. This report describes the datasets and ground truth\nspecification, details the performance evaluation metrics used, presents the\nfinal results, and summarizes the participating methods. Submission by team\nVCGroup got the highest Exact Match accuracy score of 74% for Subtask 1 and 55%\nfor Subtask 2, beating previous baselines by 5% and 12%, respectively. Although\nimprovements can still be made to the recognition capabilities of models, this\ncompetition contributes to the development of fully automated table recognition\nsystems by challenging practitioners to solve problems under specific\nconstraints and sharing their approaches; the platform will remain available\nfor post-challenge submissions at\nhttps://competitions.codalab.org/competitions/26979 .",
    "descriptor": "\nComments: Competition on Scientific Table Image Recognition to LaTeX\n",
    "authors": [
      "Pratik Kayal",
      "Mrinal Anand",
      "Harsh Desai",
      "Mayank Singh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14426"
  },
  {
    "id": "arXiv:2105.14427",
    "title": "Concurrent Composition of Differential Privacy",
    "abstract": "We initiate a study of the composition properties of interactive\ndifferentially private mechanisms. An interactive differentially private\nmechanism is an algorithm that allows an analyst to adaptively ask queries\nabout a sensitive dataset, with the property that an adversarial analyst's view\nof the interaction is approximately the same regardless of whether or not any\nindividual's data is in the dataset. Previous studies of composition of\ndifferential privacy have focused on non-interactive algorithms, but\ninteractive mechanisms are needed to capture many of the intended applications\nof differential privacy and a number of the important differentially private\nprimitives.\nWe focus on concurrent composition, where an adversary can arbitrarily\ninterleave its queries to several differentially private mechanisms, which may\nbe feasible when differentially private query systems are deployed in practice.\nWe prove that when the interactive mechanisms being composed are pure\ndifferentially private, their concurrent composition achieves privacy\nparameters (with respect to pure or approximate differential privacy) that\nmatch the (optimal) composition theorem for noninteractive differential\nprivacy. We also prove a composition theorem for interactive mechanisms that\nsatisfy approximate differential privacy. That bound is weaker than even the\nbasic (suboptimal) composition theorem for noninteractive differential privacy,\nand we leave closing the gap as a direction for future research, along with\nunderstanding concurrent composition for other variants of differential\nprivacy.",
    "descriptor": "",
    "authors": [
      "Salil Vadhan",
      "Tianhao Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14427"
  },
  {
    "id": "arXiv:2105.14428",
    "title": "DAGNN: Demand-aware Graph Neural Networks for Session-based  Recommendation",
    "abstract": "Session-based recommendations have been widely adopted for various online\nvideo and E-commerce Websites. Most existing approaches are intuitively\nproposed to discover underlying interests or preferences out of the anonymous\nsession data. This apparently ignores the fact these sequential behaviors\nusually reflect session user's potential demand, i.e., a semantic level factor,\nand therefore how to estimate underlying demands from a session is challenging.\nTo address aforementioned issue, this paper proposes a demand-aware graph\nneural networks (DAGNN). Particularly, a demand modeling component is designed\nto first extract session demand and the underlying multiple demands of each\nsession is estimated using the global demand matrix. Then, the demand-aware\ngraph neural network is designed to extract session demand graph to learn the\ndemand-aware item embedddings for the later recommendations. The mutual\ninformation loss is further designed to enhance the quality of the learnt\nembeddings. Extensive experiments are evaluated on several real-world datasets\nand the proposed model achieves the SOTA model performance.",
    "descriptor": "",
    "authors": [
      "Liqi Yang",
      "Linhan Luo",
      "Lifeng Xin",
      "Xiaofeng Zhang",
      "Xinni Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.14428"
  },
  {
    "id": "arXiv:2105.14429",
    "title": "Deformation Control of a Deformable Object Based on Visual and Tactile  Feedback",
    "abstract": "In this paper, we presented a new method for deformation control of\ndeformable objects, which utilizes both visual and tactile feedback. At\npresent, manipulation of deformable objects is basically formulated by assuming\npositional constraints. But in fact, in many situations manipulation has to be\nperformed under actively applied force constraints. This scenario is considered\nin this research. In the proposed scheme a tactile feedback is integrated to\nensure a stable contact between the robot end-effector and the soft object to\nbe manipulated. The controlled contact force is also utilized to regulate the\ndeformation of the soft object with its shape measured by a vision sensor. The\neffectiveness of the proposed method is demonstrated by a book page turning and\nshaping experiment.",
    "descriptor": "\nComments: \"7 pages\" \"9 figures\" \"submitted to IROS2021\"\n",
    "authors": [
      "Yuhao Guo",
      "Xin Jiang",
      "Yunhui Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14429"
  },
  {
    "id": "arXiv:2105.14430",
    "title": "Rethinking the constraints of multimodal fusion: case study in  Weakly-Supervised Audio-Visual Video Parsing",
    "abstract": "For multimodal tasks, a good feature extraction network should extract\ninformation as much as possible and ensure that the extracted feature embedding\nand other modal feature embedding have an excellent mutual understanding. The\nlatter is often more critical in feature fusion than the former. Therefore,\nselecting the optimal feature extraction network collocation is a very\nimportant subproblem in multimodal tasks. Most of the existing studies ignore\nthis problem or adopt an ergodic approach. This problem is modeled as an\noptimization problem in this paper. A novel method is proposed to convert the\noptimization problem into an issue of comparative upper bounds by referring to\nthe general practice of extreme value conversion in mathematics. Compared with\nthe traditional method, it reduces the time cost.\nMeanwhile, aiming at the common problem that the feature similarity and the\nfeature semantic similarity are not aligned in the multimodal time-series\nproblem, we refer to the idea of contrast learning and propose a multimodal\ntime-series contrastive loss(MTSC).\nBased on the above issues, We demonstrated the feasibility of our approach in\nthe audio-visual video parsing task. Substantial analyses verify that our\nmethods promote the fusion of different modal features.",
    "descriptor": "",
    "authors": [
      "Jianning Wu",
      "Zhuqing Jiang",
      "Shiping Wen",
      "Aidong Men",
      "Haiying Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14430"
  },
  {
    "id": "arXiv:2105.14431",
    "title": "Contact Mode Guided Motion Planning for Dexterous Manipulation",
    "abstract": "Within the field of robotic manipulation, a central goal is to replicate the\nhuman ability to manipulate any object in any situation using a sequence of\nmanipulation primitives such as grasping, pushing, inserting, sliding, etc.\nConceptually, each manipulation primitive restricts the object and robot to\nmove on a lower-dimensional manifold defined by the primitive's dynamic\nequations of motion. Likewise, a manipulation sequence represents a dynamically\nfeasible trajectory that traverses multiple manifolds. To manipulate any object\nin any situation, robotic systems must include the ability to automatically\nsynthesize manipulation primitives (manifolds) and sequence those primitives\ninto a coherent plan (find a path across the manifolds). This paper\ninvestigates a principled approach for solving dexterous manipulation planning.\nThis approach is based on rapidly-exploring random trees which use contact\nmodes to guide tree expansion along primitive manifolds. This paper extends\nthis algorithm from 2D domains to 3D domains. We validated our algorithm on a\nlarge collection of simulated 3D manipulation tasks. These tasks required our\nalgorithm to sequence between 6-42 manipulation primitives (i.e.\\! distinct\ncontact modes). We believe this work represents an important step towards\nrobotic manipulation capabilities which generalize across objects and\nenvironments.",
    "descriptor": "",
    "authors": [
      "Xianyi Cheng",
      "Eric Huang",
      "Yifan Hou",
      "Matthew T. Mason"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14431"
  },
  {
    "id": "arXiv:2105.14432",
    "title": "Transformer-Based Deep Image Matching for Generalizable Person  Re-identification",
    "abstract": "Transformers have recently gained increasing attention in computer vision.\nHowever, existing studies mostly use Transformers for feature representation\nlearning, e.g. for image classification and dense predictions. In this work, we\nfurther investigate the possibility of applying Transformers for image matching\nand metric learning given pairs of images. We find that the Vision Transformer\n(ViT) and the vanilla Transformer with decoders are not adequate for image\nmatching due to their lack of image-to-image attention. Thus, we further design\ntwo naive solutions, i.e. query-gallery concatenation in ViT, and query-gallery\ncross-attention in the vanilla Transformer. The latter improves the\nperformance, but it is still limited. This implies that the attention mechanism\nin Transformers is primarily designed for global feature aggregation, which is\nnot naturally suitable for image matching. Accordingly, we propose a new\nsimplified decoder, which drops the full attention implementation with the\nsoftmax weighting, keeping only the query-key similarity computation.\nAdditionally, global max pooling and a multilayer perceptron (MLP) head are\napplied to decode the matching result. This way, the simplified decoder is\ncomputationally more efficient, while at the same time more effective for image\nmatching. The proposed method, called TransMatcher, achieves state-of-the-art\nperformance in generalizable person re-identification, with up to 6.1% and 5.7%\nperformance gains in Rank-1 and mAP, respectively, on several popular datasets.\nThe source code of this study will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Shengcai Liao",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14432"
  },
  {
    "id": "arXiv:2105.14435",
    "title": "Convergence of Datalog over (Pre-) Semirings",
    "abstract": "Recursive queries have been traditionally studied in the framework of\ndatalog, a language that restricts recursion to monotone queries over sets,\nwhich is guaranteed to converge in polynomial time in the size of the input.\nBut modern big data systems require recursive computations beyond the Boolean\nspace. In this paper we study the convergence of datalog when it is interpreted\nover an arbitrary semiring. We consider an ordered semiring, define the\nsemantics of a datalog program as a least fixpoint in this semiring, and study\nthe number of steps required to reach that fixpoint, if ever. We identify\nalgebraic properties of the semiring that correspond to certain convergence\nproperties of datalog programs. Finally, we describe a class of ordered\nsemirings on which one can use the semi-naive evaluation algorithm on any\ndatalog program.",
    "descriptor": "",
    "authors": [
      "Mahmoud Abo Khamis",
      "Hung Q. Ngo",
      "Reinhard Pichler",
      "Dan Suciu",
      "Yisu Remy Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2105.14435"
  },
  {
    "id": "arXiv:2105.14441",
    "title": "Logspace Sequential Quadratic Programming for Design Optimization",
    "abstract": "A novel approach to exploiting the log-convex structure present in many\ndesign problems is developed by modifying the classical Sequential Quadratic\nProgramming (SQP) algorithm. The modified algorithm, Logspace Sequential\nQuadratic Programming (LSQP), inherits some of the computational efficiency\nexhibited by log-convex methods such as Geometric Programing and Signomial\nPrograming, but retains the the natural integration of black box analysis\nmethods from SQP. As a result, significant computational savings is achieved\nwithout the need to invasively modify existing black box analysis methods\nprevalent in practical design problems. In the cases considered here, the LSQP\nalgorithm shows a 40-70% reduction in number of iterations compared to SQP.",
    "descriptor": "\nComments: 24 pages, 7 figures, 5 tables, submitted to the AIAA Journal\n",
    "authors": [
      "Cody Karcher"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.14441"
  },
  {
    "id": "arXiv:2105.14442",
    "title": "Reuse Distance-based Copy-backs of Clean Cache Lines to Lower-level  Caches",
    "abstract": "Cache plays a critical role in reducing the performance gap between CPU and\nmain memory. A modern multi-core CPU generally employs a multi-level hierarchy\nof caches, through which the most recently and frequently used data are\nmaintained in each core's local private caches while all cores share the\nlast-level cache (LLC). For inclusive caches, clean cache lines replaced in\nhigher-level caches are not necessarily copied back to lower levels, as the\ninclusiveness implies their existences in lower levels. For exclusive and\nnon-inclusive caches that are widely utilized by Intel, AMD, and ARM today,\neither indiscriminately copying back all or none of replaced clean cache lines\nto lower levels raises no violation to exclusiveness and non-inclusiveness\ndefinitions.\nWe have conducted a quantitative study and found that, copying back all or\nnone of clean cache lines to lower-level cache of exclusive caches entails\nsuboptimal performance. The reason is that only a part of cache lines would be\nreused and others turn to be dead in a long run. This observation motivates us\nto selectively copy back some clean cache lines to LLC in an architecture of\nexclusive or non-inclusive caches. We revisit the concept of reuse distance of\ncache lines. In a nutshell, a clean cache line with a shorter reuse distance is\ncopied back to lower-level cache as it is likely to be re-referenced in the\nnear future, while cache lines with much longer reuse distances would be\ndiscarded or sent to memory if they are dirty. We have implemented and\nevaluated our proposal with non-volatile (STT-MRAM) LLC. Experimental results\nwith gem5 and SPEC CPU 2017 benchmarks show that on average our proposal yields\nup to 12.8% higher throughput of IPC (instructions per cycle) than the\nleast-recently-used (LRU) replacement policy with copying back all clean cache\nlines for STT-MRAM LLC.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Rui Wang",
      "Chundong Wang",
      "Chongnan Ye"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2105.14442"
  },
  {
    "id": "arXiv:2105.14444",
    "title": "NAS-BERT: Task-Agnostic and Adaptive-Size BERT Compression with Neural  Architecture Search",
    "abstract": "While pre-trained language models (e.g., BERT) have achieved impressive\nresults on different natural language processing tasks, they have large numbers\nof parameters and suffer from big computational and memory costs, which make\nthem difficult for real-world deployment. Therefore, model compression is\nnecessary to reduce the computation and memory cost of pre-trained models. In\nthis work, we aim to compress BERT and address the following two challenging\npractical issues: (1) The compression algorithm should be able to output\nmultiple compressed models with different sizes and latencies, in order to\nsupport devices with different memory and latency limitations; (2) The\nalgorithm should be downstream task agnostic, so that the compressed models are\ngenerally applicable for different downstream tasks. We leverage techniques in\nneural architecture search (NAS) and propose NAS-BERT, an efficient method for\nBERT compression. NAS-BERT trains a big supernet on a search space containing a\nvariety of architectures and outputs multiple compressed models with adaptive\nsizes and latency. Furthermore, the training of NAS-BERT is conducted on\nstandard self-supervised pre-training tasks (e.g., masked language model) and\ndoes not depend on specific downstream tasks. Thus, the compressed models can\nbe used across various downstream tasks. The technical challenge of NAS-BERT is\nthat training a big supernet on the pre-training task is extremely costly. We\nemploy several techniques including block-wise search, search space pruning,\nand performance approximation to improve search efficiency and accuracy.\nExtensive experiments on GLUE and SQuAD benchmark datasets demonstrate that\nNAS-BERT can find lightweight models with better accuracy than previous\napproaches, and can be directly applied to different downstream tasks with\nadaptive model sizes for different requirements of memory or latency.",
    "descriptor": "\nComments: Accepted by KDD 2021\n",
    "authors": [
      "Jin Xu",
      "Xu Tan",
      "Renqian Luo",
      "Kaitao Song",
      "Jian Li",
      "Tao Qin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14444"
  },
  {
    "id": "arXiv:2105.14445",
    "title": "Modeling Text-visual Mutual Dependency for Multi-modal Dialog Generation",
    "abstract": "Multi-modal dialog modeling is of growing interest. In this work, we propose\nframeworks to resolve a specific case of multi-modal dialog generation that\nbetter mimics multi-modal dialog generation in the real world, where each\ndialog turn is associated with the visual context in which it takes place.\nSpecifically, we propose to model the mutual dependency between text-visual\nfeatures, where the model not only needs to learn the probability of generating\nthe next dialog utterance given preceding dialog utterances and visual\ncontexts, but also the probability of predicting the visual features in which a\ndialog utterance takes place, leading the generated dialog utterance specific\nto the visual context. We observe significant performance boosts over vanilla\nmodels when the mutual dependency between text and visual features is modeled.\nCode is available at https://github.com/ShannonAI/OpenViDial.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2012.15015\n",
    "authors": [
      "Shuhe Wang",
      "Yuxian Meng",
      "Xiaofei Sun",
      "Fei Wu",
      "Rongbin Ouyang",
      "Rui Yan",
      "Tianwei Zhang",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14445"
  },
  {
    "id": "arXiv:2105.14447",
    "title": "EPSANet: An Efficient Pyramid Split Attention Block on Convolutional  Neural Network",
    "abstract": "Recently, it has been demonstrated that the performance of a deep\nconvolutional neural network can be effectively improved by embedding an\nattention module into it. In this work, a novel lightweight and effective\nattention method named Pyramid Split Attention (PSA) module is proposed. By\nreplacing the 3x3 convolution with the PSA module in the bottleneck blocks of\nthe ResNet, a novel representational block named Efficient Pyramid Split\nAttention (EPSA) is obtained. The EPSA block can be easily added as a\nplug-and-play component into a well-established backbone network, and\nsignificant improvements on model performance can be achieved. Hence, a simple\nand efficient backbone architecture named EPSANet is developed in this work by\nstacking these ResNet-style EPSA blocks. Correspondingly, a stronger\nmulti-scale representation ability can be offered by the proposed EPSANet for\nvarious computer vision tasks including but not limited to, image\nclassification, object detection, instance segmentation, etc. Without bells and\nwhistles, the performance of the proposed EPSANet outperforms most of the\nstate-of-the-art channel attention methods. As compared to the SENet-50, the\nTop-1 accuracy is improved by 1.93 % on ImageNet dataset, a larger margin of\n+2.7 box AP for object detection and an improvement of +1.7 mask AP for\ninstance segmentation by using the Mask-RCNN on MS-COCO dataset are obtained.\nOur source code is available at:https://github.com/murufeng/EPSANet.",
    "descriptor": "",
    "authors": [
      "Hu Zhang",
      "Keke Zu",
      "Jian Lu",
      "Yuru Zou",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14447"
  },
  {
    "id": "arXiv:2105.14450",
    "title": "Maximizing Parallelism in Distributed Training for Huge Neural Networks",
    "abstract": "The recent Natural Language Processing techniques have been refreshing the\nstate-of-the-art performance at an incredible speed. Training huge language\nmodels is therefore an imperative demand in both industry and academy. However,\nhuge language models impose challenges to both hardware and software. Graphical\nprocessing units (GPUs) are iterated frequently to meet the exploding demand,\nand a variety of ASICs like TPUs are spawned. However, there is still a tension\nbetween the fast growth of the extremely huge models and the fact that Moore's\nlaw is approaching the end. To this end, many model parallelism techniques are\nproposed to distribute the model parameters to multiple devices, so as to\nalleviate the tension on both memory and computation. Our work is the first to\nintroduce a 3-dimensional model parallelism for expediting huge language\nmodels. By reaching a perfect load balance, our approach presents smaller\nmemory and communication cost than existing state-of-the-art 1-D and 2-D model\nparallelism. Our experiments on 64 TACC's V100 GPUs show that our 3-D\nparallelism outperforms the 1-D and 2-D parallelism with 2.32x and 1.57x\nspeedup, respectively.",
    "descriptor": "\nComments: Technical Report of NUS HPC-AI Lab (this https URL). The leading two authors have equal contributions\n",
    "authors": [
      "Zhengda Bian",
      "Qifan Xu",
      "Boxiang Wang",
      "Yang You"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.14450"
  },
  {
    "id": "arXiv:2105.14452",
    "title": "A logic for binary classifiers and their explanation",
    "abstract": "Recent years have witnessed a renewed interest in Boolean function in\nexplaining binary classifiers in the field of explainable AI (XAI). The\nstandard approach of Boolean function is propositional logic. We present a\nmodal language of a ceteris paribus nature which supports reasoning about\nbinary classifiers and their properties. We study families of decision models\nfor binary classifiers, axiomatize them and show completeness of our\naxiomatics. Moreover, we prove that the variant of our modal language with\nfinite propositional atoms interpreted over these models is NP-complete. We\nleverage the language to formalize counterfactual conditional as well as a\nbunch of notions of explanation such as abductive, contrastive and\ncounterfactual explanations, and biases. Finally, we present two extensions of\nour language: a dynamic extension by the notion of assignment enabling\nclassifier change and an epistemic extension in which the classifier's\nuncertainty about the actual input can be represented.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Xinghan Liu",
      "Emiliano Lorini"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14452"
  },
  {
    "id": "arXiv:2105.14454",
    "title": "NeuralWOZ: Learning to Collect Task-Oriented Dialogue via Model-Based  Simulation",
    "abstract": "We propose NeuralWOZ, a novel dialogue collection framework that uses\nmodel-based dialogue simulation. NeuralWOZ has two pipelined models, Collector\nand Labeler. Collector generates dialogues from (1) user's goal instructions,\nwhich are the user context and task constraints in natural language, and (2)\nsystem's API call results, which is a list of possible query responses for user\nrequests from the given knowledge base. Labeler annotates the generated\ndialogue by formulating the annotation as a multiple-choice problem, in which\nthe candidate labels are extracted from goal instructions and API call results.\nWe demonstrate the effectiveness of the proposed method in the zero-shot domain\ntransfer learning for dialogue state tracking. In the evaluation, the synthetic\ndialogue corpus generated from NeuralWOZ achieves a new state-of-the-art with\nimprovements of 4.4% point joint goal accuracy on average across domains, and\nimprovements of 5.7% point of zero-shot coverage against the MultiWOZ 2.1\ndataset.",
    "descriptor": "\nComments: Accepted to ACL 2021 as a long paper\n",
    "authors": [
      "Sungdong Kim",
      "Minsuk Chang",
      "Sang-Woo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14454"
  },
  {
    "id": "arXiv:2105.14455",
    "title": "Soft Biomimetic Optical Tactile Sensing with the TacTip: A Review",
    "abstract": "Reproducing the capabilities of the human sense of touch in machines is an\nimportant step in enabling robot manipulation to have the ease of human\ndexterity. A combination of robotic technologies will be needed, including soft\nrobotics, biomimetics and the high-resolution sensing offered by optical\ntactile sensors. This combination is considered here as a SoftBOT (Soft\nBiomimetic Optical Tactile) sensor. This article reviews the BRL TacTip as a\nprototypical example of such a sensor. Topics include the relation between\nartificial skin morphology and the transduction principles of human touch, the\nnature and benefits of tactile shear sensing, 3D printing for fabrication and\nintegration into robot hands, the application of AI to tactile perception and\ncontrol, and the recent step-change in capabilities due to deep learning. This\nreview consolidates those advances from the past decade to indicate a path for\nrobots to reach human-like dexterity.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Nathan F. Lepora"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14455"
  },
  {
    "id": "arXiv:2105.14457",
    "title": "Learning Personal Style from Few Examples",
    "abstract": "A key task in design work is grasping the client's implicit tastes. Designers\noften do this based on a set of examples from the client. However, recognizing\na common pattern among many intertwining variables such as color, texture, and\nlayout and synthesizing them into a composite preference can be challenging. In\nthis paper, we leverage the pattern recognition capability of computational\nmodels to aid in this task. We offer a set of principles for computationally\nlearning personal style. The principles are manifested in PseudoClient, a deep\nlearning framework that learns a computational model for personal graphic\ndesign style from only a handful of examples. In several experiments, we found\nthat PseudoClient achieves a 79.40% accuracy with only five positive and\nnegative examples, outperforming several alternative methods. Finally, we\ndiscuss how PseudoClient can be utilized as a building block to support the\ndevelopment of future design applications.",
    "descriptor": "",
    "authors": [
      "David Chuan-En Lin",
      "Nikolas Martelaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14457"
  },
  {
    "id": "arXiv:2105.14461",
    "title": "A Hybrid SIE-PDE Formulation Without Boundary Condition Requirement for  Electromagnetic Analysis",
    "abstract": "A hybrid surface integral equation partial differential equation (SIE-PDE)\nformulation without the boundary condition requirement is proposed to solve the\nelectromagnetic problems. In the proposed formulation, the computational domain\nis decomposed into two \\emph{overlapping} domains: the SIE and PDE domains. In\nthe SIE domain, complex structures with piecewise homogeneous media, e.g.,\nhighly conductive media, are included. An equivalent model for those structures\nis constructed through replacing them by the background medium and introducing\na surface equivalent electric current density on an enclosed boundary to\nrepresent their electromagnetic effects. The remaining computational domain and\nhomogeneous background medium replaced domain consist of the PDE domain, in\nwhich inhomogeneous or non-isotropic media are included. Through combining the\nsurface equivalent electric current density and the inhomogeneous Helmholtz\nequation, a hybrid SIE-PDE formulation is derived. Unlike other hybrid\nformulations, where the transmission condition is usually used, no boundary\nconditions are required in the proposed SIE-PDE formulation, and it is\nmathematically equivalent to the original physical model. Through careful\nconstruction of basis functions to expand electric fields and the equivalent\ncurrent density, the discretized formulation is compatible on the interface of\nthe SIE and PDE domain. Finally, its accuracy and efficiency are validated\nthrough two numerical examples. Results show that the proposed SIE-PDE\nformulation can obtain accurate results including both near and far fields, and\nsignificant performance improvements in terms of CPU time and memory\nconsumption compared with the FEM are achieved.",
    "descriptor": "",
    "authors": [
      "Aipeng Sun",
      "Zekun Zhu",
      "Shunchuan Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2105.14461"
  },
  {
    "id": "arXiv:2105.14462",
    "title": "Good for Misconceived Reasons: An Empirical Revisiting on the Need for  Visual Context in Multimodal Machine Translation",
    "abstract": "A neural multimodal machine translation (MMT) system is one that aims to\nperform better translation by extending conventional text-only translation\nmodels with multimodal information. Many recent studies report improvements\nwhen equipping their models with the multimodal module, despite the controversy\nof whether such improvements indeed come from the multimodal part. We revisit\nthe contribution of multimodal information in MMT by devising two interpretable\nMMT models. To our surprise, although our models replicate similar gains as\nrecently developed multimodal-integrated systems achieved, our models learn to\nignore the multimodal information. Upon further investigation, we discover that\nthe improvements achieved by the multimodal models over text-only counterparts\nare in fact results of the regularization effect. We report empirical findings\nthat highlight the importance of MMT models' interpretability, and discuss how\nour findings will benefit future research.",
    "descriptor": "\nComments: To appear at ACL 2021 main conference\n",
    "authors": [
      "Zhiyong Wu",
      "Lingpeng Kong",
      "Wei Bi",
      "Xiang Li",
      "Ben Kao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14462"
  },
  {
    "id": "arXiv:2105.14463",
    "title": "Approximate Implication with d-Separation",
    "abstract": "The graphical structure of Probabilistic Graphical Models (PGMs) encodes the\nconditional independence (CI) relations that hold in the modeled distribution.\nGraph algorithms, such as d-separation, use this structure to infer additional\nconditional independencies, and to query whether a specific CI holds in the\ndistribution. The premise of all current systems-of-inference for deriving CIs\nin PGMs, is that the set of CIs used for the construction of the PGM hold\nexactly. In practice, algorithms for extracting the structure of PGMs from\ndata, discover approximate CIs that do not hold exactly in the distribution. In\nthis paper, we ask how the error in this set propagates to the inferred CIs\nread off the graphical structure. More precisely, what guarantee can we provide\non the inferred CI when the set of CIs that entailed it hold only\napproximately? It has recently been shown that in the general case, no such\nguarantee can be provided. We prove that such a guarantee exists for the set of\nCIs inferred in directed graphical models, making the d-separation algorithm a\nsound and complete system for inferring approximate CIs. We also prove an\napproximation guarantee for independence relations derived from marginal CIs.",
    "descriptor": "\nComments: Accepted for the 37th conference on Uncertainty in Artificial Intelligence (UAI 2021)\n",
    "authors": [
      "Batya Kenig"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.14463"
  },
  {
    "id": "arXiv:2105.14464",
    "title": "Comparison-limited Vector Quantization",
    "abstract": "In this paper a variation of the classic vector quantization problem is\nconsidered. In the standard formulation, a quantizer is designed to minimize\nthe distortion between input and output when the number of reconstruction\npoints is fixed. We consider, instead, the scenario in which the number of\ncomparators used in quantization is fixed. More precisely, we study the case in\nwhich a vector quantizer of dimension d is comprised of k comparators, each\nreceiving a linear combination of the inputs and producing the output value\none/zero if this linear combination is above/below a certain threshold. In\nreconstruction, the comparators' output is mapped to a reconstruction point,\nchosen so as to minimize a chosen distortion measure between the quantizer\ninput and its reconstruction. The Comparison-Limited Vector Quantization (CLVQ)\nproblem is then defined as the problem of optimally designing the configuration\nof the compactors and the choice of reconstruction points so as to minimize the\ngiven distortion. In this paper, we design a numerical optimization algorithm\nfor the CLVQ problem. This algorithm leverages combinatorial geometrical\nnotions to describe the hyperplane arrangement induced by the configuration of\nthe comparators. It also relies on a genetic genetic meta heuristic to improve\nthe selection of the quantizer initialization and avoid local minima\nencountered during optimization. We numerically evaluate the performance of our\nalgorithm in the case of input distributions following uniform and Gaussian\ni.i.d. sources to be compressed under quadratic distortion and compare it to\nthe classic Linde-Buzo-Gray (LBG) algorithm.",
    "descriptor": "\nComments: 27 pages, 10 figures\n",
    "authors": [
      "Joseph Chataignon",
      "Stefano Rini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.14464"
  },
  {
    "id": "arXiv:2105.14465",
    "title": "A Brief Survey on Interactive Automotive UI",
    "abstract": "Automotive User Interface (AutoUI) is relatively a new discipline in the\ncontext of both Transportation Engineering and Human Machine Interaction (HMI).\nIt covers various HMI aspects both inside and outside vehicle ranging from\noperating the vehicle itself, undertaking various secondary tasks, driver\nbehaviour analysis, cognitive load estimation and so on. This review paper\ndiscusses various interactive HMI inside a vehicle used for undertaking\nsecondary tasks. We divided recent HMIs through four sections on virtual touch\ninterfaces, wearable devices, speech recognition and non-visual interfaces and\neye gaze controlled systems. Finally, we summarized advantages and\ndisadvantages of various technologies.",
    "descriptor": "",
    "authors": [
      "Gowdham Prabhakar",
      "Pradipta Biswas"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14465"
  },
  {
    "id": "arXiv:2105.14467",
    "title": "Occam Learning Meets Synthesis Through Unification",
    "abstract": "The generalizability of PBE solvers is the key to the empirical synthesis\nperformance. Despite the importance of generalizability, related studies on PBE\nsolvers are still limited. In theory, few existing solvers provide theoretical\nguarantees on generalizability, and in practice, there is a lack of PBE solvers\nwith satisfactory generalizability on important domains such as conditional\nlinear integer arithmetic (CLIA). In this paper, we adopt a concept from the\ncomputational learning theory, Occam learning, and perform a comprehensive\nstudy on the framework of synthesis through unification (STUN), a\nstate-of-the-art framework for synthesizing programs with nested if-then-else\noperators. We prove that Eusolver, a state-of-the-art STUN solver, does not\nsatisfy the condition of Occam learning, and then we design a novel STUN\nsolver, PolyGen, of which the generalizability is theoretically guaranteed by\nOccam learning. We evaluate PolyGen on the domains of CLIA and demonstrate that\nPolyGen significantly outperforms two state-of-the-art PBE solvers on CLIA,\nEusolver and Euphony, on both generalizability and efficiency.",
    "descriptor": "",
    "authors": [
      "Ruyi Ji",
      "Jingtao Xia",
      "Yingfei Xiong",
      "Zhenjiang Hu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.14467"
  },
  {
    "id": "arXiv:2105.14470",
    "title": "Internet of Everything Driven Neuromarketing: Key Technologies and  Challenges",
    "abstract": "Preserving customers' expectations and understanding factors affecting their\npurchasing decisions would significantly affect designing effective marketing\nand advertising strategies. However, constantly and swiftly changing the\ncustomers' interests and consumption behaviors, make it inevitable to utilize\nthe sophisticated tools and approaches based on advanced technologies. Among\nthem, neuromarketing by measuring the customers' physiological and neural\nsignals, studying the consumers' cognitive, and affective responses to\nmarketing stimulus, provides deep insight into the customers' motivations,\npreferences, and decisions. Recently, the Internet of Everything (IoE) has\nbrought many new opportunities to the industry and has attracted the attention\nof many researchers in recent years. The main objective of this paper is to\naddress how the Internet of Everything (IoE) would empower neuromarketing\ntechniques. In particular, applications of IoE gadgets and devices in eleven\ngroups of neuromarketing techniques are discussed to present numerous solutions\nthat would help meet this goal. Moreover, we present an in-depth understanding\nof current research issues as well as emerging trends.",
    "descriptor": "",
    "authors": [
      "Seyed Mojtaba Hosseini Bamakan",
      "Aref Toghroljerdib",
      "Peyman Tirandazib"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14470"
  },
  {
    "id": "arXiv:2105.14471",
    "title": "Reducing the Deployment-Time Inference Control Costs of Deep  Reinforcement Learning Agents via an Asymmetric Architecture",
    "abstract": "Deep reinforcement learning (DRL) has been demonstrated to provide promising\nresults in several challenging decision making and control tasks. However, the\nrequired inference costs of deep neural networks (DNNs) could prevent DRL from\nbeing applied to mobile robots which cannot afford high energy-consuming\ncomputations. To enable DRL methods to be affordable in such energy-limited\nplatforms, we propose an asymmetric architecture that reduces the overall\ninference costs via switching between a computationally expensive policy and an\neconomic one. The experimental results evaluated on a number of representative\nbenchmark suites for robotic control tasks demonstrate that our method is able\nto reduce the inference costs while retaining the agent's overall performance.",
    "descriptor": "",
    "authors": [
      "Chin-Jui Chang",
      "Yu-Wei Chu",
      "Chao-Hsien Ting",
      "Hao-Kang Liu",
      "Zhang-Wei Hong",
      "Chun-Yi Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14471"
  },
  {
    "id": "arXiv:2105.14473",
    "title": "Determining the Credibility of Science Communication",
    "abstract": "Most work on scholarly document processing assumes that the information\nprocessed is trustworthy and factually correct. However, this is not always the\ncase. There are two core challenges, which should be addressed: 1) ensuring\nthat scientific publications are credible -- e.g. that claims are not made\nwithout supporting evidence, and that all relevant supporting evidence is\nprovided; and 2) that scientific findings are not misrepresented, distorted or\noutright misreported when communicated by journalists or the general public. I\nwill present some first steps towards addressing these problems and outline\nremaining challenges.",
    "descriptor": "",
    "authors": [
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14473"
  },
  {
    "id": "arXiv:2105.14476",
    "title": "CSCAD: Correlation Structure-based Collective Anomaly Detection in  Complex System",
    "abstract": "Detecting anomalies in large complex systems is a critical and challenging\ntask. The difficulties arise from several aspects. First, collecting ground\ntruth labels or prior knowledge for anomalies is hard in real-world systems,\nwhich often lead to limited or no anomaly labels in the dataset. Second,\nanomalies in large systems usually occur in a collective manner due to the\nunderlying dependency structure among devices or sensors. Lastly, real-time\nanomaly detection for high-dimensional data requires efficient algorithms that\nare capable of handling different types of data (i.e. continuous and discrete).\nWe propose a correlation structure-based collective anomaly detection (CSCAD)\nmodel for high-dimensional anomaly detection problem in large systems, which is\nalso generalizable to semi-supervised or supervised settings. Our framework\nutilize graph convolutional network combining a variational autoencoder to\njointly exploit the feature space correlation and reconstruction deficiency of\nsamples to perform anomaly detection. We propose an extended mutual information\n(EMI) metric to mine the internal correlation structure among different data\nfeatures, which enhances the data reconstruction capability of CSCAD. The\nreconstruction loss and latent standard deviation vector of a sample obtained\nfrom reconstruction network can be perceived as two natural anomalous degree\nmeasures. An anomaly discriminating network can then be trained using low\nanomalous degree samples as positive samples, and high anomalous degree samples\nas negative samples. Experimental results on five public datasets demonstrate\nthat our approach consistently outperforms all the competing baselines.",
    "descriptor": "",
    "authors": [
      "Huiling Qin",
      "Xianyuan Zhan",
      "Yu Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14476"
  },
  {
    "id": "arXiv:2105.14477",
    "title": "Towards Diverse Paragraph Captioning for Untrimmed Videos",
    "abstract": "Video paragraph captioning aims to describe multiple events in untrimmed\nvideos with descriptive paragraphs. Existing approaches mainly solve the\nproblem in two steps: event detection and then event captioning. Such two-step\nmanner makes the quality of generated paragraphs highly dependent on the\naccuracy of event proposal detection which is already a challenging task. In\nthis paper, we propose a paragraph captioning model which eschews the\nproblematic event detection stage and directly generates paragraphs for\nuntrimmed videos. To describe coherent and diverse events, we propose to\nenhance the conventional temporal attention with dynamic video memories, which\nprogressively exposes new video features and suppresses over-accessed video\ncontents to control visual focuses of the model. In addition, a\ndiversity-driven training strategy is proposed to improve diversity of\nparagraph on the language perspective. Considering that untrimmed videos\ngenerally contain massive but redundant frames, we further augment the video\nencoder with keyframe awareness to improve efficiency. Experimental results on\nthe ActivityNet and Charades datasets show that our proposed model\nsignificantly outperforms the state-of-the-art performance on both accuracy and\ndiversity metrics without using any event boundary annotations. Code will be\nreleased at https://github.com/syuqings/video-paragraph.",
    "descriptor": "\nComments: Accepted by CVPR 2021\n",
    "authors": [
      "Yuqing Song",
      "Shizhe Chen",
      "Qin Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14477"
  },
  {
    "id": "arXiv:2105.14478",
    "title": "Pre-training Universal Language Representation",
    "abstract": "Despite the well-developed cut-edge representation learning for language,\nmost language representation models usually focus on specific levels of\nlinguistic units. This work introduces universal language representation\nlearning, i.e., embeddings of different levels of linguistic units or text with\nquite diverse lengths in a uniform vector space. We propose the training\nobjective MiSAD that utilizes meaningful n-grams extracted from large unlabeled\ncorpus by a simple but effective algorithm for pre-trained language models.\nThen we empirically verify that well designed pre-training scheme may\neffectively yield universal language representation, which will bring great\nconvenience when handling multiple layers of linguistic objects in a unified\nway. Especially, our model achieves the highest accuracy on analogy tasks in\ndifferent language levels and significantly improves the performance on\ndownstream tasks in the GLUE benchmark and a question answering dataset.",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021 main conference\n",
    "authors": [
      "Yian Li",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14478"
  },
  {
    "id": "arXiv:2105.14483",
    "title": "Computation of Eigenvalues for Nonlocal Models by Spectral Methods",
    "abstract": "The purpose of this work is to study spectral methods to approximate the\neigenvalues of nonlocal integral operators. Indeed, even if the spatial domain\nis an interval, it is very challenging to obtain closed analytical expressions\nfor the eigenpairs of peridynamic operators. Our approach is based on the weak\nformulation of eigenvalue problem and we consider as orthogonal basis to\ncompute the eigenvalues a set of Fourier trigonometric or Chebyshev\npolynomials. We show the order of convergence for eigenvalues and\neigenfunctions in $L^2$-norm, and finally, we perform some numerical\nsimulations to compare the two proposed methods.",
    "descriptor": "",
    "authors": [
      "Luciano Lopez",
      "Sabrina Francesca Pellegrino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14483"
  },
  {
    "id": "arXiv:2105.14484",
    "title": "Joint Training of the Superimposed Direct and Reflected Links in  Reconfigurable Intelligent Surface Assisted Multiuser Communications",
    "abstract": "In Reconfigurable intelligent surface (RIS)-assisted systems the acquisition\nof CSI and the optimization of the reflecting coefficients constitute a pair of\nsalient design issues. In this paper, a novel channel training protocol is\nproposed, which is capable of achieving a flexible performance vs. signalling\nand pilot overhead as well as implementation complexity trade-off. More\nspecifically, first of all, we conceive a holistic channel estimation protocol,\nwhich integrates the existing channel estimation techniques and passive\nbeamforming design. Secondly, we propose a new channel training framework. In\ncontrast to the conventional channel estimation arrangements, our new framework\ndivides the training phase into several periods, where the superimposed\nend-to-end channel is estimated instead of separately estimating the direct\nBS-user channel and cascaded reflected BS-RIS-user channels. As a result, the\nreflecting coefficients of the RIS are optimized by comparing the objective\nfunction values over multiple training periods. Moreover, the theoretical\nperformance of our channel training protocol is analyzed and compared to that\nunder the optimal reflecting coefficients. In addition, the potential benefits\nof our channel training protocol in reducing the complexity, pilot overhead as\nwell as signalling overhead are also detailed. Thirdly, we derive the\ntheoretical performance of channel estimation protocols and our channel\ntraining protocol in the presence of noise for a SISO scenario, which provides\nuseful insights into the impact of the noise on the overall RIS performance.\nFinally, our numerical simulations characterize the performance of the proposed\nprotocols and verify our theoretical analysis. In particular, the simulation\nresults demonstrate that our channel training protocol is more competitive than\nthe channel estimation protocol at low signal-to-noise ratios.",
    "descriptor": "",
    "authors": [
      "Jiancheng An",
      "Chao Xu",
      "Li Wang",
      "Yusha Liu",
      "Lu Gan",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14484"
  },
  {
    "id": "arXiv:2105.14485",
    "title": "CLEVE: Contrastive Pre-training for Event Extraction",
    "abstract": "Event extraction (EE) has considerably benefited from pre-trained language\nmodels (PLMs) by fine-tuning. However, existing pre-training methods have not\ninvolved modeling event characteristics, resulting in the developed EE models\ncannot take full advantage of large-scale unsupervised data. To this end, we\npropose CLEVE, a contrastive pre-training framework for EE to better learn\nevent knowledge from large unsupervised data and their semantic structures\n(e.g. AMR) obtained with automatic parsers. CLEVE contains a text encoder to\nlearn event semantics and a graph encoder to learn event structures\nrespectively. Specifically, the text encoder learns event semantic\nrepresentations by self-supervised contrastive learning to represent the words\nof the same events closer than those unrelated words; the graph encoder learns\nevent structure representations by graph contrastive pre-training on parsed\nevent-related semantic structures. The two complementary representations then\nwork together to improve both the conventional supervised EE and the\nunsupervised \"liberal\" EE, which requires jointly extracting events and\ndiscovering event schemata without any annotated data. Experiments on ACE 2005\nand MAVEN datasets show that CLEVE achieves significant improvements,\nespecially in the challenging unsupervised setting. The source code and\npre-trained checkpoints can be obtained from https://github.com/THU-KEG/CLEVE.",
    "descriptor": "\nComments: Accepted at ACL 2021\n",
    "authors": [
      "Ziqi Wang",
      "Xiaozhi Wang",
      "Xu Han",
      "Yankai Lin",
      "Lei Hou",
      "Zhiyuan Liu",
      "Peng Li",
      "Juanzi Li",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14485"
  },
  {
    "id": "arXiv:2105.14488",
    "title": "REAM$\\sharp$: An Enhancement Approach to Reference-based Evaluation  Metrics for Open-domain Dialog Generation",
    "abstract": "The lack of reliable automatic evaluation metrics is a major impediment to\nthe development of open-domain dialogue systems. Various reference-based\nmetrics have been proposed to calculate a score between a predicted response\nand a small set of references. However, these metrics show unsatisfactory\ncorrelations with human judgments. For a reference-based metric, its\nreliability mainly depends on two factors: its ability to measure the\nsimilarity between the predicted response and the reference response, as well\nas the reliability of the given reference set. Yet, there are few discussions\non the latter. Our work attempts to fill this vacancy. We first clarify an\nassumption on reference-based metrics that, if more high-quality references are\nadded into the reference set, the reliability of the metric will increase.\nNext, we present REAM$\\sharp$: an enhancement approach to Reference-based\nEvAluation Metrics for open-domain dialogue systems. A prediction model is\ndesigned to estimate the reliability of the given reference set. We show how\nits predicted results can be helpful to augment the reference set, and thus\nimprove the reliability of the metric. Experiments validate both the\neffectiveness of our prediction model and that the reliability of\nreference-based metrics improves with the augmented reference sets.",
    "descriptor": "\nComments: ACL Findings 2021\n",
    "authors": [
      "Jun Gao",
      "Wei Bi",
      "Ruifeng Xu",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14488"
  },
  {
    "id": "arXiv:2105.14490",
    "title": "Hop-Aware Dimension Optimization for Graph Neural Networks",
    "abstract": "In Graph Neural Networks (GNNs), the embedding of each node is obtained by\naggregating information with its direct and indirect neighbors. As the messages\npassed among nodes contain both information and noise, the critical issue in\nGNN representation learning is how to retrieve information effectively while\nsuppressing noise. Generally speaking, interactions with distant nodes usually\nintroduce more noise for a particular node than those with close nodes.\nHowever, in most existing works, the messages being passed among nodes are\nmingled together, which is inefficient from a communication perspective. Mixing\nthe information from clean sources (low-order neighbors) and noisy sources\n(high-order neighbors) makes discriminative feature extraction challenging.\nMotivated by the above, we propose a simple yet effective ladder-style GNN\narchitecture, namely LADDER-GNN. Specifically, we separate messages from\ndifferent hops and assign different dimensions for them before concatenating\nthem to obtain the node representation. Such disentangled representations\nfacilitate extracting information from messages passed from different hops, and\ntheir corresponding dimensions are determined with a reinforcement\nlearning-based neural architecture search strategy. The resulted hop-aware\nrepresentations generally contain more dimensions for low-order neighbors and\nfewer dimensions for high-order neighbors, leading to a ladder-style\naggregation scheme. We verify the proposed LADDER-GNN on several\nsemi-supervised node classification datasets. Experimental results show that\nthe proposed simple hop-aware representation learning solution can achieve\nstate-of-the-art performance on most datasets.",
    "descriptor": "",
    "authors": [
      "Ailing Zeng",
      "Minhao Liu",
      "Zhiwei Liu",
      "Ruiyuan Gao",
      "Qiang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14490"
  },
  {
    "id": "arXiv:2105.14491",
    "title": "How Attentive are Graph Attention Networks?",
    "abstract": "Graph Attention Networks (GATs) are one of the most popular GNN architectures\nand are considered as the state-of-the-art architecture for representation\nlearning with graphs. In GAT, every node attends to its neighbors given its own\nrepresentation as the query. However, in this paper we show that GATs can only\ncompute a restricted kind of attention where the ranking of attended nodes is\nunconditioned on the query node. We formally define this restricted kind of\nattention as static attention and distinguish it from a strictly more\nexpressive dynamic attention. Because GATs use a static attention mechanism,\nthere are simple graph problems that GAT cannot express: in a controlled\nproblem, we show that static attention hinders GAT from even fitting the\ntraining data. To remove this limitation, we introduce a simple fix by\nmodifying the order of operations and propose GATv2: a dynamic graph attention\nvariant that is strictly more expressive than GAT. We perform an extensive\nevaluation and show that GATv2 outperforms GAT across 11 OGB and other\nbenchmarks while we match their parametric costs. Our code is available at\nhttps://github.com/tech-srl/how_attentive_are_gats .",
    "descriptor": "",
    "authors": [
      "Shaked Brody",
      "Uri Alon",
      "Eran Yahav"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14491"
  },
  {
    "id": "arXiv:2105.14493",
    "title": "Generating Ten BCI Commands Using Four Simple Motor Imageries",
    "abstract": "The brain computer interface (BCI) systems are utilized for transferring\ninformation among humans and computers by analyzing electroencephalogram (EEG)\nrecordings.The process of mentally previewing a motor movement without\ngenerating the corporal output can be described as motor imagery (MI).In this\nemerging research field, the number of commands is also limited in relation to\nthe number of MI tasks; in the current literature, mostly two or four commands\n(classes) are studied. As a solution to this problem, it is recommended to use\nmental tasks as well as MI tasks. Unfortunately, the use of this approach\nreduces the classification performance of MI EEG signals. The fMRI analyses\nshow that the resources in the brain associated with the motor imagery can be\nactivated independently. It is assumed that the brain activity induced by the\nMI of the combination of body parts corresponds to the superposition of the\nactivities generated during each body parts's simple MI. In this study, in\norder to create more than four BCI commands, we suggest to generate combined MI\nEEG signals artificially by using left hand, right hand, tongue, and feet motor\nimageries in pairs. A maximum of ten different BCI commands can be generated by\nusing four motor imageries in pairs.This study aims to achieve high\nclassification performances for BCI commands produced from four motor imageries\nby implementing a small-sized deep neural network (DNN).The presented method is\nevaluated on the four-class datasets of BCI Competitions III and IV, and an\naverage classification performance of 81.8% is achieved for ten classes. The\nabove assumption is also validated on a different dataset which consists of\nsimple and combined MI EEG signals acquired in real time. Trained with the\nartificially generated combined MI EEG signals, DivFE resulted in an average of\n76.5% success rate for the combined MI EEG signals acquired in real-time.",
    "descriptor": "",
    "authors": [
      "Nuri Korkan",
      "Tamer Olmez",
      "Zumray Dokur"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2105.14493"
  },
  {
    "id": "arXiv:2105.14499",
    "title": "Perceived Safety in Physical Human Robot Interaction -- A Survey",
    "abstract": "This review paper focuses on different aspects of perceived safety for a\nnumber of autonomous physical systems. This is a major aspect of robotics\nresearch, as more and more applications allow human and autonomous systems to\nshare their space, with crucial implications both on safety and on its\nperception. The alternative terms used to express related concepts (e.g.,\npsychological safety, trust, comfort, stress, fear, and anxiety) are listed and\nexplained. Then, the available methods to assess perceived safety (i.e.,\nquestionnaires, physiological measurements, behavioral assessment, and direct\ninput devices) are described. Six categories of autonomous systems are\nconsidered (industrial manipulators, mobile robots, mobile manipulators,\nhumanoid robots, drones, and autonomous vehicles), providing an overview of the\nmain themes related to perceived safety in the specific domain, a description\nof selected works, and an analysis of how motion and characteristics of the\nsystem influence the perception of safety. The survey also discusses\nexperimental duration and location of the reviewed papers as well as identified\ntrends over time.",
    "descriptor": "\nComments: 23 pages, 3 figures, 4 tables, submitted for journal publication\n",
    "authors": [
      "Matteo Rubagotti",
      "Inara Tusseyeva",
      "Sara Baltabayeva",
      "Danna Summers",
      "Anara Sandygulova"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14499"
  },
  {
    "id": "arXiv:2105.14500",
    "title": "2.5-dimensional distributed model training",
    "abstract": "Data parallelism does a good job in speeding up the training. However, when\nit comes to the case when the memory of a single device can not host a whole\nmodel, data parallelism would not have the chance to do anything. Another\noption is to split the model by operator, or horizontally. Megatron-LM\nintroduced a 1-Dimensional distributed method to use GPUs to speed up the\ntraining process. Optimus is a 2D solution for distributed tensor parallelism.\nHowever, these methods have a high communication overhead and a low scaling\nefficiency on large-scale computing clusters. To solve this problem, we\ninvestigate the 2.5-Dimensional distributed tensor parallelism.Introduced by\nSolomonik et al., 2.5-Dimensional Matrix Multiplication developed an effective\nmethod to perform multiple Cannon's algorithm at the same time to increase the\nefficiency. With many restrictions of Cannon's Algorithm and a huge amount of\nshift operation, we need to invent a new method of 2.5-dimensional matrix\nmultiplication to enhance the performance. Absorbing the essence from both\nSUMMA and 2.5-Dimensional Matrix Multiplication, we introduced SUMMA2.5-LM for\nlanguage models to overcome the abundance of unnecessary transmission loss\nresult from the increasing size of language model parallelism. Compared to\nprevious 1D and 2D model parallelization of language models, our SUMMA2.5-LM\nmanaged to reduce the transmission cost on each layer, which could get a 1.45X\nefficiency according to our weak scaling result between 2.5-D [4,4,4]\narrangement and 2-D [8,8,1] arrangement.",
    "descriptor": "",
    "authors": [
      "Boxiang Wang",
      "Qifan Xu",
      "Zhengda Bian",
      "Yang You"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14500"
  },
  {
    "id": "arXiv:2105.14504",
    "title": "Structured Sentiment Analysis as Dependency Graph Parsing",
    "abstract": "Structured sentiment analysis attempts to extract full opinion tuples from a\ntext, but over time this task has been subdivided into smaller and smaller\nsub-tasks, e,g,, target extraction or targeted polarity classification. We\nargue that this division has become counterproductive and propose a new unified\nframework to remedy the situation. We cast the structured sentiment problem as\ndependency graph parsing, where the nodes are spans of sentiment holders,\ntargets and expressions, and the arcs are the relations between them. We\nperform experiments on five datasets in four languages (English, Norwegian,\nBasque, and Catalan) and show that this approach leads to strong improvements\nover state-of-the-art baselines. Our analysis shows that refining the sentiment\ngraphs with syntactic dependency information further improves results.",
    "descriptor": "\nComments: Accepted at ACL-IJCNLP 2021\n",
    "authors": [
      "Jeremy Barnes",
      "Robin Kurtz",
      "Stephan Oepen",
      "Lilja \u00d8vrelid",
      "Erik Velldal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14504"
  },
  {
    "id": "arXiv:2105.14506",
    "title": "Human Interpretable AI: Enhancing Tsetlin Machine Stochasticity with  Drop Clause",
    "abstract": "In this article, we introduce a novel variant of the Tsetlin machine (TM)\nthat randomly drops clauses, the key learning elements of a TM. In effect, TM\nwith drop clause ignores a random selection of the clauses in each epoch,\nselected according to a predefined probability. In this way, additional\nstochasticity is introduced in the learning phase of TM. Along with producing\nmore distinct and well-structured patterns that improve the performance, we\nalso show that dropping clauses increases learning robustness. To explore the\neffects clause dropping has on accuracy, training time, and interpretability,\nwe conduct extensive experiments on various benchmark datasets in natural\nlanguage processing (NLP) (IMDb and SST2) as well as computer vision (MNIST and\nCIFAR10). In brief, we observe from +2% to +4% increase in accuracy and 2x to\n4x faster learning. We further employ the Convolutional TM to document\ninterpretable results on the CIFAR10 dataset. To the best of our knowledge,\nthis is the first time an interpretable machine learning algorithm has been\nused to produce pixel-level human-interpretable results on CIFAR10. Also,\nunlike previous interpretable methods that focus on attention visualisation or\ngradient interpretability, we show that the TM is a more general interpretable\nmethod. That is, by producing rule-based propositional logic expressions that\nare \\emph{human}-interpretable, the TM can explain how it classifies a\nparticular instance at the pixel level for computer vision and at the word\nlevel for NLP.",
    "descriptor": "",
    "authors": [
      "Jivitesh Sharma",
      "Rohan Yadav",
      "Ole-Christoffer Granmo",
      "Lei Jiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.14506"
  },
  {
    "id": "arXiv:2105.14507",
    "title": "Entanglement Rate Optimization in Heterogeneous Quantum Communication  Networks",
    "abstract": "Quantum communication networks are emerging as a promising technology that\ncould constitute a key building block in future communication networks in the\n6G era and beyond. These networks have an inherent feature of parallelism that\nallows them to boost the capacity and enhance the security of communication\nsystems. Recent advances led to the deployment of small- and large-scale\nquantum communication networks with real quantum hardware. In quantum networks,\nentanglement is a key resource that allows for data transmission between\ndifferent nodes. However, to reap the benefits of entanglement and enable\nefficient quantum communication, the number of generated entangled pairs must\nbe optimized. Indeed, if the entanglement generation rates are not optimized,\nthen some of these valuable resources will be discarded and lost. In this\npaper, the problem of optimizing the entanglement generation rates and their\ndistribution over a quantum memory is studied. In particular, a quantum network\nin which users have heterogeneous distances and applications is considered.\nThis problem is posed as a mixed integer nonlinear programming optimization\nproblem whose goal is to efficiently utilize the available quantum memory by\ndistributing the quantum entangled pairs in a way that maximizes the user\nsatisfaction. An interior point optimization method is used to solve the\noptimization problem and extensive simulations are conducted to evaluate the\neffectiveness of the proposed system. Simulation results show the key design\nconsiderations for efficient quantum networks, and the effect of different\nnetwork parameters on the network performance.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Mahdi Chehimi",
      "Walid Saad"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.14507"
  },
  {
    "id": "arXiv:2105.14508",
    "title": "Secret sharing schemes from hypersurfaces over finite fields",
    "abstract": "Linear error-correcting codes can be used for constructing secret sharing\nschemes, however finding in general the access structures of these secret\nsharing schemes and, in particular, determining efficient access structures is\ndifficult. Here we investigate the properties of certain algebraic\nhypersurfaces over finite fields, whose intersection numbers with any\nhyperplane only takes a few values. These varieties give rise to $q$-divisible\nlinear codes with at most $5$ weights. Furthermore, for $q$ odd these codes\nturn out to be minimal and we characterize the access structures of the secret\nsharing schemes based on their dual codes. Indeed, we prove that the secret\nsharing schemes thus obtained are democratic that is, each participant belongs\nto the same number of minimal access sets.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Angela Aguglia",
      "Michela Ceria",
      "Luca Giuzzi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.14508"
  },
  {
    "id": "arXiv:2105.14512",
    "title": "SHELBRS: Location Based Recommendation Services using Switchable  Homomorphic Encryption",
    "abstract": "Location-Based Recommendation Services (LBRS) has seen an unprecedented rise\nin its usage in recent years. LBRS facilitates a user by recommending services\nbased on his location and past preferences. However, leveraging such services\ncomes at a cost of compromising one's sensitive information like their shopping\npreferences, lodging places, food habits, recently visited places, etc. to the\nthird-party servers. Losing such information could be crucial and threatens\none's privacy. Nowadays, the privacy-aware society seeks solutions that can\nprovide such services, with minimized risks. Recently, a few privacy-preserving\nrecommendation services have been proposed that exploit the fully homomorphic\nencryption (FHE) properties to address the issue. Though, it reduced privacy\nrisks but suffered from heavy computational overheads that ruled out their\ncommercial applications. Here, we propose SHELBRS, a lightweight LBRS that is\nbased on switchable homomorphic encryption (SHE), which will benefit the users\nas well as the service providers. A SHE exploits both the additive as well as\nthe multiplicative homomorphic properties but with comparatively much lesser\nprocessing time as it's FHE counterpart. We evaluate the performance of our\nproposed scheme with the other state-of-the-art approaches without compromising\nsecurity.",
    "descriptor": "\nComments: 9 pages, 6 figures, 3 tables\n",
    "authors": [
      "Mishel Jain",
      "Priyanka Singh",
      "Balasubramanian Raman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14512"
  },
  {
    "id": "arXiv:2105.14513",
    "title": "Knowledge Transfer for Few-shot Segmentation of Novel White Matter  Tracts",
    "abstract": "Convolutional neural networks (CNNs) have achieved stateof-the-art\nperformance for white matter (WM) tract segmentation based on diffusion\nmagnetic resonance imaging (dMRI). These CNNs require a large number of manual\ndelineations of the WM tracts of interest for training, which are generally\nlabor-intensive and costly. The expensive manual delineation can be a\nparticular disadvantage when novel WM tracts, i.e., tracts that have not been\nincluded in existing manual delineations, are to be analyzed. To accurately\nsegment novel WM tracts, it is desirable to transfer the knowledge learned\nabout existing WM tracts, so that even with only a few delineations of the\nnovel WM tracts, CNNs can learn adequately for the segmentation. In this paper,\nwe explore the transfer of such knowledge to the segmentation of novel WM\ntracts in the few-shot setting. Although a classic fine-tuning strategy can be\nused for the purpose, the information in the last task-specific layer for\nsegmenting existing WM tracts is completely discarded. We hypothesize that the\nweights of this last layer can bear valuable information for segmenting the\nnovel WM tracts and thus completely discarding the information is not optimal.\nIn particular, we assume that the novel WM tracts can correlate with existing\nWM tracts and the segmentation of novel WM tracts can be predicted with the\nlogits of existing WM tracts. In this way, better initialization of the last\nlayer than random initialization can be achieved for fine-tuning. Further, we\nshow that a more adaptive use of the knowledge in the last layer for segmenting\nexisting WM tracts can be conveniently achieved by simply inserting a warmup\nstage before classic fine-tuning. The proposed method was evaluated on a\npublicly available dMRI dataset, where we demonstrate the benefit of our method\nfor few-shot segmentation of novel WM tracts.",
    "descriptor": "",
    "authors": [
      "Qi Lu",
      "Chuyang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.14513"
  },
  {
    "id": "arXiv:2105.14515",
    "title": "How Low is Too Low? A Computational Perspective on Extremely  Low-Resource Languages",
    "abstract": "Despite the recent advancements of attention-based deep learning\narchitectures across a majority of Natural Language Processing tasks, their\napplication remains limited in a low-resource setting because of a lack of\npre-trained models for such languages. In this study, we make the first attempt\nto investigate the challenges of adapting these techniques for an extremely\nlow-resource language -- Sumerian cuneiform -- one of the world's oldest\nwritten languages attested from at least the beginning of the 3rd millennium\nBC. Specifically, we introduce the first cross-lingual information extraction\npipeline for Sumerian, which includes part-of-speech tagging, named entity\nrecognition, and machine translation. We further curate InterpretLR, an\ninterpretability toolkit for low-resource NLP, and use it alongside human\nattributions to make sense of the models. We emphasize on human evaluations to\ngauge all our techniques. Notably, most components of our pipeline can be\ngeneralised to any other language to obtain an interpretable execution of the\ntechniques, especially in a low-resource setting. We publicly release all\nsoftware, model checkpoints, and a novel dataset with domain-specific\npre-processing to promote further research.",
    "descriptor": "\nComments: ACL SRW 2021\n",
    "authors": [
      "Rachit Bansal",
      "Himanshu Choudhary",
      "Ravneet Punia",
      "Niko Schenk",
      "Jacob L Dahl",
      "\u00c9milie Pag\u00e9-Perron"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14515"
  },
  {
    "id": "arXiv:2105.14517",
    "title": "GeoQA: A Geometric Question Answering Benchmark Towards Multimodal  Numerical Reasoning",
    "abstract": "Automatic math problem solving has recently attracted increasing attention as\na long-standing AI benchmark. In this paper, we focus on solving geometric\nproblems, which requires a comprehensive understanding of textual descriptions,\nvisual diagrams, and theorem knowledge. However, the existing methods were\nhighly dependent on handcraft rules and were merely evaluated on small-scale\ndatasets. Therefore, we propose a Geometric Question Answering dataset GeoQA,\ncontaining 5,010 geometric problems with corresponding annotated programs,\nwhich illustrate the solving process of the given problems. Compared with\nanother publicly available dataset GeoS, GeoQA is 25 times larger, in which the\nprogram annotations can provide a practical testbed for future research on\nexplicit and explainable numerical reasoning. Moreover, we introduce a Neural\nGeometric Solver (NGS) to address geometric problems by comprehensively parsing\nmultimodal information and generating interpretable programs. We further add\nmultiple self-supervised auxiliary tasks on NGS to enhance cross-modal semantic\nrepresentation. Extensive experiments on GeoQA validate the effectiveness of\nour proposed NGS and auxiliary tasks. However, the results are still\nsignificantly lower than human performance, which leaves large room for future\nresearch. Our benchmark and code are released at\nhttps://github.com/chen-judge/GeoQA .",
    "descriptor": "",
    "authors": [
      "Jiaqi Chen",
      "Jianheng Tang",
      "Jinghui Qin",
      "Xiaodan Liang",
      "Lingbo Liu",
      "Eric P. Xing",
      "Liang Lin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14517"
  },
  {
    "id": "arXiv:2105.14519",
    "title": "RFCBF: enhance the performance and stability of Fast Correlation-Based  Filter",
    "abstract": "Feature selection is a preprocessing step which plays a crucial role in the\ndomain of machine learning and data mining. Feature selection methods have been\nshown to be effctive in removing redundant and irrelevant features, improving\nthe learning algorithm's prediction performance. Among the various methods of\nfeature selection based on redundancy, the fast correlation-based filter (FCBF)\nis one of the most effective. In this paper, we proposed a novel extension of\nFCBF, called RFCBF, which combines resampling technique to improve\nclassification accuracy. We performed comprehensive experiments to compare the\nRFCBF with other state-of-the-art feature selection methods using the KNN\nclassifier on 12 publicly available data sets. The experimental results show\nthat the RFCBF algorithm yields significantly better results than previous\nstate-of-the-art methods in terms of classification accuracy and runtime.",
    "descriptor": "",
    "authors": [
      "Xiongshi Deng",
      "Min Li",
      "Lei Wang",
      "Qikang Wan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14519"
  },
  {
    "id": "arXiv:2105.14520",
    "title": "Unsupervised Joint Learning of Depth, Optical Flow, Ego-motion from  Video",
    "abstract": "Estimating geometric elements such as depth, camera motion, and optical flow\nfrom images is an important part of the robot's visual perception. We use a\njoint self-supervised method to estimate the three geometric elements. Depth\nnetwork, optical flow network and camera motion network are independent of each\nother but are jointly optimized during training phase. Compared with\nindependent training, joint training can make full use of the geometric\nrelationship between geometric elements and provide dynamic and static\ninformation of the scene. In this paper, we improve the joint self-supervision\nmethod from three aspects: network structure, dynamic object segmentation, and\ngeometric constraints. In terms of network structure, we apply the attention\nmechanism to the camera motion network, which helps to take advantage of the\nsimilarity of camera movement between frames. And according to attention\nmechanism in Transformer, we propose a plug-and-play convolutional attention\nmodule. In terms of dynamic object, according to the different influences of\ndynamic objects in the optical flow self-supervised framework and the\ndepth-pose self-supervised framework, we propose a threshold algorithm to\ndetect dynamic regions, and mask that in the loss function respectively. In\nterms of geometric constraints, we use traditional methods to estimate the\nfundamental matrix from the corresponding points to constrain the camera motion\nnetwork. We demonstrate the effectiveness of our method on the KITTI dataset.\nCompared with other joint self-supervised methods, our method achieves\nstate-of-the-art performance in the estimation of pose and optical flow, and\nthe depth estimation has also achieved competitive results. Code will be\navailable https://github.com/jianfenglihg/Unsupervised_geometry.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Jianfeng Li",
      "Junqiao Zhao",
      "Shuangfu Song",
      "Tiantian Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14520"
  },
  {
    "id": "arXiv:2105.14522",
    "title": "Vector Detection Network: An Application Study on Robots Reading Analog  Meters in the Wild",
    "abstract": "Analog meters equipped with one or multiple pointers are wildly utilized to\nmonitor vital devices' status in industrial sites for safety concerns. Reading\nthese legacy meters {\\bi autonomously} remains an open problem since estimating\npointer origin and direction under imaging damping factors imposed in the wild\ncould be challenging. Nevertheless, high accuracy, flexibility, and real-time\nperformance are demanded. In this work, we propose the Vector Detection Network\n(VDN) to detect analog meters' pointers given their images, eliminating the\nbarriers for autonomously reading such meters using intelligent agents like\nrobots. We tackled the pointer as a two-dimensional vector, whose initial point\ncoincides with the tip, and the direction is along tail-to-tip. The network\nestimates a confidence map, wherein the peak pixels are treated as vectors'\ninitial points, along with a two-layer scalar map, whose pixel values at each\npeak form the scalar components in the directions of the coordinate axes. We\nestablished the Pointer-10K dataset composing of real-world analog meter images\nto evaluate our approach due to no similar dataset is available for now.\nExperiments on the dataset demonstrated that our methods generalize well to\nvarious meters, robust to harsh imaging factors, and run in real-time.",
    "descriptor": "",
    "authors": [
      "Zhipeng Dong",
      "Yi Gao",
      "Yunhui Yan",
      "Fei Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14522"
  },
  {
    "id": "arXiv:2105.14526",
    "title": "LRTuner: A Learning Rate Tuner for Deep Neural Networks",
    "abstract": "One very important hyperparameter for training deep neural networks is the\nlearning rate schedule of the optimizer. The choice of learning rate schedule\ndetermines the computational cost of getting close to a minima, how close you\nactually get to the minima, and most importantly the kind of local minima\n(wide/narrow) attained. The kind of minima attained has a significant impact on\nthe generalization accuracy of the network. Current systems employ hand tuned\nlearning rate schedules, which are painstakingly tuned for each network and\ndataset. Given that the state space of schedules is huge, finding a\nsatisfactory learning rate schedule can be very time consuming. In this paper,\nwe present LRTuner, a method for tuning the learning rate as training proceeds.\nOur method works with any optimizer, and we demonstrate results on SGD with\nMomentum, and Adam optimizers.\nWe extensively evaluate LRTuner on multiple datasets, models, and across\noptimizers. We compare favorably against standard learning rate schedules for\nthe given dataset and models, including ImageNet on Resnet-50, Cifar-10 on\nResnet-18, and SQuAD fine-tuning on BERT. For example on ImageNet with\nResnet-50, LRTuner shows up to 0.2% absolute gains in test accuracy compared to\nthe hand-tuned baseline schedule. Moreover, LRTuner can achieve the same\naccuracy as the baseline schedule in 29% less optimization steps.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Nikhil Iyer",
      "V Thejas",
      "Nipun Kwatra",
      "Ramachandran Ramjee",
      "Muthian Sivathanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14526"
  },
  {
    "id": "arXiv:2105.14527",
    "title": "Reflow: Zero Knowledge Multi Party Signatures with Application to  Distributed Authentication",
    "abstract": "Reflow is a novel signature scheme supporting unlinkable signatures by\nmultiple parties authenticated by means of zero-knowledge credentials. Reflow\nintegrates with blockchains and graph databases to ensure confidentiality and\nauthenticity of signatures made by disposable identities that can be verified\neven when credential issuing authorities are offline. We implement and evaluate\nReflow smart contracts for Zenroom and present an application to produce\nauthenticated material passports for resource-event-agent accounting systems\nbased on graph data structures. Reflow uses short and computationally efficient\nauthentication credentials and can easily scale signatures to include thousands\nof participants.",
    "descriptor": "",
    "authors": [
      "Denis Roio",
      "Alberto Ibrisevic",
      "Andrea D'Intino"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.14527"
  },
  {
    "id": "arXiv:2105.14528",
    "title": "Fast Nearest Neighbor Machine Translation",
    "abstract": "Though nearest neighbor Machine Translation ($k$NN-MT)\n\\cite{khandelwal2020nearest} has proved to introduce significant performance\nboosts over standard neural MT systems, it is prohibitively slow since it uses\nthe entire reference corpus as the datastore for the nearest neighbor search.\nThis means each step for each beam in the beam search has to search over the\nentire reference corpus. $k$NN-MT is thus two-order slower than vanilla MT\nmodels, making it hard to be applied to real-world applications, especially\nonline services. In this work, we propose Fast $k$NN-MT to address this issue.\nFast $k$NN-MT constructs a significantly smaller datastore for the nearest\nneighbor search: for each word in a source sentence, Fast $k$NN-MT first\nselects its nearest token-level neighbors, which is limited to tokens that are\nthe same as the query token. Then at each decoding step, in contrast to using\nthe entire corpus as the datastore, the search space is limited to target\ntokens corresponding to the previously selected reference source tokens. This\nstrategy avoids search through the whole datastore for nearest neighbors and\ndrastically improves decoding efficiency. Without loss of performance, Fast\n$k$NN-MT is two-order faster than $k$NN-MT, and is only two times slower than\nthe standard NMT model. Fast $k$NN-MT enables the practical use of $k$NN-MT\nsystems in real-world MT applications.\\footnote{Code is available at\n\\url{https://github.com/ShannonAI/fast-knn-nmt.}}",
    "descriptor": "",
    "authors": [
      "Yuxian Meng",
      "Xiaoya Li",
      "Xiayu Zheng",
      "Fei Wu",
      "Xiaofei Sun",
      "Tianwei Zhang",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14528"
  },
  {
    "id": "arXiv:2105.14529",
    "title": "On the benefits of representation regularization in invariance based  domain generalization",
    "abstract": "A crucial aspect in reliable machine learning is to design a deployable\nsystem in generalizing new related but unobserved environments. Domain\ngeneralization aims to alleviate such a prediction gap between the observed and\nunseen environments. Previous approaches commonly incorporated learning\ninvariant representation for achieving good empirical performance. In this\npaper, we reveal that merely learning invariant representation is vulnerable to\nthe unseen environment. To this end, we derive novel theoretical analysis to\ncontrol the unseen test environment error in the representation learning, which\nhighlights the importance of controlling the smoothness of representation. In\npractice, our analysis further inspires an efficient regularization method to\nimprove the robustness in domain generalization. Our regularization is\northogonal to and can be straightforwardly adopted in existing domain\ngeneralization algorithms for invariant representation learning. Empirical\nresults show that our algorithm outperforms the base versions in various\ndataset and invariance criteria.",
    "descriptor": "",
    "authors": [
      "Changjian Shui",
      "Boyu Wang",
      "Christian Gagn\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14529"
  },
  {
    "id": "arXiv:2105.14536",
    "title": "On the Lagrangian-Eulerian Coupling in the Immersed Finite  Element/Difference Method",
    "abstract": "The immersed boundary (IB) method is a non-body conforming approach to\nfluid-structure interaction (FSI) that uses an Eulerian description of the\nmomentum, viscosity, and incompressibility of a coupled fluid-structure system\nand a Lagrangian description of the deformations, stresses, and resultant\nforces of the immersed structure. Integral transforms with Dirac delta function\nkernels couple Eulerian and Lagrangian variables. In practice, discretizations\nof these integral transforms use regularized delta function kernels, and\nalthough a number of different types of regularized delta functions have been\nproposed, there has been limited prior work to investigate the impact of the\nchoice of kernel function on the accuracy of the methodology. This work\nsystematically studies the effect of the choice of regularized delta function\nin several fluid-structure interaction benchmark tests using the immersed\nfinite element/difference (IFED) method, which is an extension of the IB method\nthat uses finite element structural discretizations combined with a Cartesian\ngrid finite difference method for the incompressible Navier-Stokes equations.\nFurther, many IB-type methods evaluate the delta functions at the nodes of the\nstructural mesh, and this requires the Lagrangian mesh to be relatively fine\ncompared to the background Eulerian grid to avoid leaks. The IFED formulation\noffers the possibility to avoid leaks with relatively coarse structural meshes\nby evaluating the delta function on a denser collection of interaction points.\nThis study investigates the effect of varying the relative mesh widths of the\nLagrangian and Eulerian discretizations. Although this study is done within the\ncontext of the IFED method, the effect of different kernels could be important\nnot just for this method, but also for other IB-type methods more generally.",
    "descriptor": "",
    "authors": [
      "Jae H. Lee",
      "Boyce E. Griffith"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14536"
  },
  {
    "id": "arXiv:2105.14538",
    "title": "Longer Version for \"Deep Context-Encoding Network for Retinal Image  Captioning\"",
    "abstract": "Automatically generating medical reports for retinal images is one of the\npromising ways to help ophthalmologists reduce their workload and improve work\nefficiency. In this work, we propose a new context-driven encoding network to\nautomatically generate medical reports for retinal images. The proposed model\nis mainly composed of a multi-modal input encoder and a fused-feature decoder.\nOur experimental results show that our proposed method is capable of\neffectively leveraging the interactive information between the input image and\ncontext, i.e., keywords in our case. The proposed method creates more accurate\nand meaningful reports for retinal images than baseline models and achieves\nstate-of-the-art performance. This performance is shown in several commonly\nused metrics for the medical report generation task: BLEU-avg (+16%), CIDEr\n(+10.2%), and ROUGE (+8.6%).",
    "descriptor": "\nComments: This paper is a longer version of \"Deep Context-Encoding Network for Retinal Image Captioning\" which is accepted by IEEE International Conference on Image Processing (ICIP), 2021\n",
    "authors": [
      "Jia-Hong Huang",
      "Ting-Wei Wu",
      "Chao-Han Huck Yang",
      "Marcel Worring"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2105.14538"
  },
  {
    "id": "arXiv:2105.14540",
    "title": "Attention Based Semantic Segmentation on UAV Dataset for Natural  Disaster Damage Assessment",
    "abstract": "The detrimental impacts of climate change include stronger and more\ndestructive hurricanes happening all over the world. Identifying different\ndamaged structures of an area including buildings and roads are vital since it\nhelps the rescue team to plan their efforts to minimize the damage by a natural\ndisaster. Semantic segmentation helps to identify different parts of an image.\nWe implement a novel self-attention based semantic segmentation model on a high\nresolution UAV dataset and attain Mean IoU score of around88%on the test set.\nThe result inspires to use self-attention schemes in natural disaster damage\nassessment which will save human lives and reduce economic losses.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2009.01193\n",
    "authors": [
      "Tashnim Chowdhury",
      "Maryam Rahnemoonfar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14540"
  },
  {
    "id": "arXiv:2105.14545",
    "title": "A Joint Power Splitting, Active and Passive Beamforming Optimization  Framework for IRS Assisted MIMO SWIPT System",
    "abstract": "This paper considers an intelligent reflecting surface (IRS) assisted\nmulti-input multi-output (MIMO) power splitting (PS) based simultaneous\nwireless information and power transfer (SWIPT) system with multiple PS\nreceivers (PSRs). The objective is to maximize the achievable data rate of the\nsystem by jointly optimizing the PS ratios at the PSRs, the active transmit\nbeamforming (ATB) at the access point (AP), and the passive reflective\nbeamforming (PRB) at the IRS, while the constraints on maximum transmission\npower at the AP, the reflective phase shift of each element at the IRS, the\nindividual minimum harvested energy requirement of each PSR, and the domain of\nPS ratio of each PSR are all satisfied. For this unsolved problem, however,\nsince the optimization variables are intricately coupled and the constraints\nare conflicting, the formulated problem is non-convex, and cannot be addressed\nby employing exist approaches directly. To this end, we propose a joint\noptimization framework to solve this problem. Particularly, we reformulate it\nas an equivalent form by employing the Lagrangian dual transform and the\nfractional programming transform, and decompose the transformed problem into\nseveral sub-problems. Then, we propose an alternate optimization algorithm by\ncapitalizing on the dual sub-gradient method, the successive convex\napproximation method, and the penalty-based majorization-minimization approach,\nto solve the sub-problems iteratively, and obtain the optimal solutions in\nnearly closed-forms. Numerical simulation results verify the effectiveness of\nthe IRS in SWIPT system and indicate that the proposed algorithm offers a\nsubstantial performance gain.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Chen He",
      "Xie Xie",
      "Kun Yang",
      "Z. Jane Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14545"
  },
  {
    "id": "arXiv:2105.14547",
    "title": "Incorporating forecasting and peer-to-peer negotiation frameworks into a  distributed model predictive control approach for meshed electric networks",
    "abstract": "Continuous integration of renewable energy sources into power networks is\ncausing a paradigm shift in energy generation and distribution with regards to\ntrading and control; the intermittent nature of renewable sources affects\npricing of energy sold or purchased; the networks are subject to operational\nconstraints, voltage limits at each node, rated capacities for the power\nelectronic devices, current bounds for distribution lines. These economic and\ntechnical constraints coupled with intermittent renewable injection may pose a\nthreat to system stability and performance. We propose a novel holistic\napproach to energy trading composed of a distributed predictive control\nframework to handle physical interactions, i,e., voltage constraints and power\ndispatch, together with a negotiation framework to determine pricing policies\nfor energy transactions. We study the effect of forecasting generation and\nconsumption on the overall network's performance and market behaviours. We\nprovide a rigorous convergence analysis for both the negotiation framework and\nthe distributed control. Lastly, we assess the impact of forecasting in the\nproposed system with the aid of testing scenarios.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Pablo R. Baldivieso Monasterios",
      "Nandor Verba",
      "Euan A Morris",
      "Thomas Morstyn",
      "George. C",
      ". Konstantopoulos",
      "Elena Gaura",
      "Stephen McArthur"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14547"
  },
  {
    "id": "arXiv:2105.14548",
    "title": "Z2P: Instant Rendering of Point Clouds",
    "abstract": "We present a technique for rendering point clouds using a neural network.\nExisting point rendering techniques either use splatting, or first reconstruct\na surface mesh that can then be rendered. Both of these techniques require\nsolving for global point normal orientation, which is a challenging problem on\nits own. Furthermore, splatting techniques result in holes and overlaps,\nwhereas mesh reconstruction is particularly challenging, especially in the\ncases of thin surfaces and sheets.\nWe cast the rendering problem as a conditional image-to-image translation\nproblem. In our formulation, Z2P, i.e., depth-augmented point features as\nviewed from target camera view, are directly translated by a neural network to\nrendered images, conditioned on control variables (e.g., color, light). We\navoid inevitable issues with splatting (i.e., holes and overlaps), and bypass\nsolving the notoriously challenging surface reconstruction problem or\nestimating oriented normals. Yet, our approach results in a rendered image as\nif a surface mesh was reconstructed. We demonstrate that our framework produces\na plausible image, and can effectively handle noise, non-uniform sampling, thin\nsurfaces / sheets, and is fast.",
    "descriptor": "",
    "authors": [
      "Gal Metzer",
      "Rana Hanocka",
      "Raja Giryes",
      "Niloy J. Mitra",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14548"
  },
  {
    "id": "arXiv:2105.14550",
    "title": "Blind Quality Assessment for in-the-Wild Images via Hierarchical Feature  Fusion and Iterative Mixed Database Training",
    "abstract": "Image quality assessment (IQA) is very important for both end-users and\nservice-providers since a high-quality image can significantly improve the\nuser's quality of experience (QoE). Most existing blind image quality\nassessment (BIQA) models were developed for synthetically distorted images,\nhowever, they perform poorly on in-the-wild images, which are widely existed in\nvarious practical applications. In this paper, we propose a novel BIQA model\nfor in-the-wild images by addressing two critical problems in this field: how\nto learn better quality-aware features, and how to solve the problem of\ninsufficient training samples. Considering that perceptual visual quality is\naffected by both low-level visual features and high-level semantic information,\nwe first propose a staircase structure to hierarchically integrate the features\nfrom intermediate layers into the final feature representation, which enables\nthe model to make full use of visual information from low-level to high-level.\nThen an iterative mixed database training (IMDT) strategy is proposed to train\nthe BIQA model on multiple databases simultaneously, so the model can benefit\nfrom the increase in both training samples and image content and distortion\ndiversity and can learn a more general feature representation. Experimental\nresults show that the proposed model outperforms other state-of-the-art BIQA\nmodels on six in-the-wild IQA databases by a large margin. Moreover, the\nproposed model shows an excellent performance in the cross-database evaluation\nexperiments, which further demonstrates that the learned feature representation\nis robust to images sampled from various distributions.",
    "descriptor": "",
    "authors": [
      "Wei Sun",
      "Xiongkuo Min",
      "Guangtao Zhai",
      "Siwei Ma"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2105.14550"
  },
  {
    "id": "arXiv:2105.14553",
    "title": "Defending Pre-trained Language Models from Adversarial Word  Substitutions Without Performance Sacrifice",
    "abstract": "Pre-trained contextualized language models (PrLMs) have led to strong\nperformance gains in downstream natural language understanding tasks. However,\nPrLMs can still be easily fooled by adversarial word substitution, which is one\nof the most challenging textual adversarial attack methods. Existing defence\napproaches suffer from notable performance loss and complexities. Thus, this\npaper presents a compact and performance-preserved framework, Anomaly Detection\nwith Frequency-Aware Randomization (ADFAR). In detail, we design an auxiliary\nanomaly detection classifier and adopt a multi-task learning procedure, by\nwhich PrLMs are able to distinguish adversarial input samples. Then, in order\nto defend adversarial word substitution, a frequency-aware randomization\nprocess is applied to those recognized adversarial input samples. Empirical\nresults show that ADFAR significantly outperforms those newly proposed defense\nmethods over various tasks with much higher inference speed. Remarkably, ADFAR\ndoes not impair the overall performance of PrLMs. The code is available at\nhttps://github.com/LilyNLP/ADFAR",
    "descriptor": "\nComments: Findings of ACL: ACL 2021\n",
    "authors": [
      "Rongzhou Bao",
      "Jiayi Wang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14553"
  },
  {
    "id": "arXiv:2105.14556",
    "title": "Diversifying Dialog Generation via Adaptive Label Smoothing",
    "abstract": "Neural dialogue generation models trained with the one-hot target\ndistribution suffer from the over-confidence issue, which leads to poor\ngeneration diversity as widely reported in the literature. Although existing\napproaches such as label smoothing can alleviate this issue, they fail to adapt\nto diverse dialog contexts. In this paper, we propose an Adaptive Label\nSmoothing (AdaLabel) approach that can adaptively estimate a target label\ndistribution at each time step for different contexts. The maximum probability\nin the predicted distribution is used to modify the soft target distribution\nproduced by a novel light-weight bi-directional decoder module. The resulting\ntarget distribution is aware of both previous and future contexts and is\nadjusted to avoid over-training the dialogue model. Our model can be trained in\nan end-to-end manner. Extensive experiments on two benchmark datasets show that\nour approach outperforms various competitive baselines in producing diverse\nresponses.",
    "descriptor": "\nComments: ACL2021 Main Track (Long Paper), Code Available in this https URL\n",
    "authors": [
      "Yida Wang",
      "Yinhe Zheng",
      "Yong Jiang",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14556"
  },
  {
    "id": "arXiv:2105.14557",
    "title": "Robust Dynamic Network Embedding via Ensembles",
    "abstract": "Dynamic Network Embedding (DNE) has recently attracted considerable attention\ndue to the advantage of network embedding in various applications and the\ndynamic nature of many real-world networks. For dynamic networks, the degree of\nchanges, i.e., defined as the averaged number of changed edges between\nconsecutive snapshots spanning a dynamic network, could be very different in\nreal-world scenarios. Although quite a few DNE methods have been proposed, it\nstill remains unclear that whether and to what extent the existing DNE methods\nare robust to the degree of changes, which is however an important factor in\nboth academic research and industrial applications. In this work, we\ninvestigate the robustness issue of DNE methods w.r.t. the degree of changes\nfor the first time and accordingly, propose a robust DNE method. Specifically,\nthe proposed method follows the notion of ensembles where the base learner\nadopts an incremental Skip-Gram neural embedding approach. To further boost the\nperformance, a novel strategy is proposed to enhance the diversity among base\nlearners at each timestep by capturing different levels of local-global\ntopology. Extensive experiments demonstrate the benefits of special designs in\nthe proposed method, and the superior performance of the proposed method\ncompared to state-of-the-art methods. The comparative study also reveals the\nrobustness issue of some DNE methods. The source code is available at\nhttps://github.com/houchengbin/SG-EDNE",
    "descriptor": "",
    "authors": [
      "Chengbin Hou",
      "Guoji Fu",
      "Peng Yang",
      "Shan He",
      "Ke Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14557"
  },
  {
    "id": "arXiv:2105.14559",
    "title": "BABA: Beta Approximation for Bayesian Active Learning",
    "abstract": "This paper introduces a new acquisition function under the Bayesian active\nlearning framework, namely BABA. It is motivated by previously well-established\nworks BALD, and BatchBALD which capture the mutual information between the\nmodel parameters and the predictive outputs of the data. Our proposed measure,\nBABA, endeavors to quantify the normalized mutual information by approximating\nthe stochasticity of predictive probabilities using Beta distributions. BABA\noutperforms the well-known family of acquisition functions, including BALD and\nBatchBALD. We demonstrate this by showing extensive experimental results\nobtained from MNIST and EMNIST datasets.",
    "descriptor": "",
    "authors": [
      "Jae Oh Woo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14559"
  },
  {
    "id": "arXiv:2105.14564",
    "title": "Evaluating Resilience of Encrypted Traffic Classification Against  Adversarial Evasion Attacks",
    "abstract": "Machine learning and deep learning algorithms can be used to classify\nencrypted Internet traffic. Classification of encrypted traffic can become more\nchallenging in the presence of adversarial attacks that target the learning\nalgorithms. In this paper, we focus on investigating the effectiveness of\ndifferent evasion attacks and see how resilient machine and deep learning\nalgorithms are. Namely, we test C4.5 Decision Tree, K-Nearest Neighbor (KNN),\nArtificial Neural Network (ANN), Convolutional Neural Networks (CNN) and\nRecurrent Neural Networks (RNN). In most of our experimental results, deep\nlearning shows better resilience against the adversarial samples in comparison\nto machine learning. Whereas, the impact of the attack varies depending on the\ntype of attack.",
    "descriptor": "",
    "authors": [
      "Ramy Maarouf",
      "Danish Sattar",
      "Ashraf Matrawy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14564"
  },
  {
    "id": "arXiv:2105.14565",
    "title": "SPI: Automated Identification of Security Patches via Commits",
    "abstract": "Security patches in open-source software, providing security fixes to\nidentified vulnerabilities, are crucial in protecting against cyberattacks.\nDespite the National Vulnerability Database (NVD) publishes identified\nvulnerabilities, a vast majority of vulnerabilities and their corresponding\nsecurity patches remain beyond public exposure, e.g., in the open-source\nlibraries that are heavily relied on by developers. An extensive security\npatches dataset could help end-users such as security companies, e.g., building\na security knowledge base, or researchers, e.g., aiding in vulnerability\nresearch. To curate security patches including undisclosed patches at a large\nscale and low cost, we propose a deep neural-network-based approach built upon\ncommits of open-source repositories. We build security patch datasets that\ninclude 38,291 security-related commits and 1,045 CVE patches from four C\nlibraries. We manually verify each commit, among the 38,291 security-related\ncommits, to determine if they are security-related. We devise a deep\nlearning-based security patch identification system that consists of two neural\nnetworks: one commit-message neural network that utilizes pretrained word\nrepresentations learned from our commits dataset; and one code-revision neural\nnetwork that takes code before and after revision and learns the distinction on\nthe statement level. Our evaluation results show that our system outperforms\nSVM and K-fold stacking algorithm, achieving as high as 87.93% F1-score and\nprecision of 86.24%. We deployed our pipeline and learned model in an\nindustrial production environment to evaluate the generalization ability of our\napproach. The industrial dataset consists of 298,917 commits from 410 new\nlibraries that range from a wide functionality. Our experiment results and\nobservation proved that our approach identifies security patches effectively\namong open-sourced projects.",
    "descriptor": "\nComments: Accepted By ACM Transactions on Software Engineering and Methodology (TOSEM), Continuous Special Section: AI and SE\n",
    "authors": [
      "Yaqin Zhou",
      "Jing Kai Siow",
      "Chenyu Wang",
      "ShangQing Liu",
      "Yang Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14565"
  },
  {
    "id": "arXiv:2105.14566",
    "title": "CNN Retrieval based Unsupervised Metric Learning for Near-Duplicated  Video Retrieval",
    "abstract": "As important data carriers, the drastically increasing number of multimedia\nvideos often brings many duplicate and near-duplicate videos in the top results\nof search. Near-duplicate video retrieval (NDVR) can cluster and filter out the\nredundant contents. In this paper, the proposed NDVR approach extracts the\nframe-level video representation based on convolutional neural network (CNN)\nfeatures from fully-connected layer and aggregated intermediate convolutional\nlayers. Unsupervised metric learning is used for similarity measurement and\nfeature matching. An efficient re-ranking algorithm combined with k-nearest\nneighborhood fuses the retrieval results from two levels of features and\nfurther improves the retrieval performance. Extensive experiments on the widely\nused CC\\_WEB\\_VIDEO dataset shows that the proposed approach exhibits superior\nperformance over the state-of-the-art.",
    "descriptor": "\nComments: This paper is submitted to ICIP 2019\n",
    "authors": [
      "Hao Cheng",
      "Ping Wang",
      "Chun Qi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.14566"
  },
  {
    "id": "arXiv:2105.14568",
    "title": "How effective are Graph Neural Networks in Fraud Detection for Network  Data?",
    "abstract": "Graph-based Neural Networks (GNNs) are recent models created for learning\nrepresentations of nodes (and graphs), which have achieved promising results\nwhen detecting patterns that occur in large-scale data relating different\nentities. Among these patterns, financial fraud stands out for its\nsocioeconomic relevance and for presenting particular challenges, such as the\nextreme imbalance between the positive (fraud) and negative (legitimate\ntransactions) classes, and the concept drift (i.e., statistical properties of\nthe data change over time). Since GNNs are based on message propagation, the\nrepresentation of a node is strongly impacted by its neighbors and by the\nnetwork's hubs, amplifying the imbalance effects. Recent works attempt to adapt\nundersampling and oversampling strategies for GNNs in order to mitigate this\neffect without, however, accounting for concept drift. In this work, we conduct\nexperiments to evaluate existing techniques for detecting network fraud,\nconsidering the two previous challenges. For this, we use real data sets,\ncomplemented by synthetic data created from a new methodology introduced here.\nBased on this analysis, we propose a series of improvement points that should\nbe investigated in future research.",
    "descriptor": "\nComments: 12 pages, in Portuguese\n",
    "authors": [
      "Ronald D. R. Pereira",
      "Fabr\u00edcio Murai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14568"
  },
  {
    "id": "arXiv:2105.14572",
    "title": "Multiscale IoU: A Metric for Evaluation of Salient Object Detection with  Fine Structures",
    "abstract": "General-purpose object-detection algorithms often dismiss the fine structure\nof detected objects. This can be traced back to how their proposed regions are\nevaluated. Our goal is to renegotiate the trade-off between the generality of\nthese algorithms and their coarse detections. In this work, we present a new\nmetric that is a marriage of a popular evaluation metric, namely Intersection\nover Union (IoU), and a geometrical concept, called fractal dimension. We\npropose Multiscale IoU (MIoU) which allows comparison between the detected and\nground-truth regions at multiple resolution levels. Through several\nreproducible examples, we show that MIoU is indeed sensitive to the fine\nboundary structures which are completely overlooked by IoU and f1-score. We\nfurther examine the overall reliability of MIoU by comparing its distribution\nwith that of IoU on synthetic and real-world datasets of objects. We intend\nthis work to re-initiate exploration of new evaluation methods for\nobject-detection algorithms.",
    "descriptor": "\nComments: 5 pages, 3 figures, ICIP 2021\n",
    "authors": [
      "Azim Ahmadzadeh",
      "Dustin J. Kempton",
      "Yang Chen",
      "Rafal A. Angryk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14572"
  },
  {
    "id": "arXiv:2105.14573",
    "title": "Embedding Principle of Loss Landscape of Deep Neural Networks",
    "abstract": "Understanding the structure of loss landscape of deep neural networks\n(DNNs)is obviously important. In this work, we prove an embedding principle\nthat the loss landscape of a DNN \"contains\" all the critical points of all the\nnarrower DNNs. More precisely, we propose a critical embedding such that any\ncritical point, e.g., local or global minima, of a narrower DNN can be embedded\nto a critical point/hyperplane of the target DNN with higher degeneracy and\npreserving the DNN output function. The embedding structure of critical points\nis independent of loss function and training data, showing a stark difference\nfrom other nonconvex problems such as protein-folding. Empirically, we find\nthat a wide DNN is often attracted by highly-degenerate critical points that\nare embedded from narrow DNNs. The embedding principle provides an explanation\nfor the general easy optimization of wide DNNs and unravels a potential\nimplicit low-complexity regularization during the training. Overall, our work\nprovides a skeleton for the study of loss landscape of DNNs and its\nimplication, by which a more exact and comprehensive understanding can be\nanticipated in the near",
    "descriptor": "",
    "authors": [
      "Yaoyu Zhang",
      "Zhongwang Zhang",
      "Tao Luo",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14573"
  },
  {
    "id": "arXiv:2105.14576",
    "title": "StyTr^2: Unbiased Image Style Transfer with Transformers",
    "abstract": "The goal of image style transfer is to render an image with artistic features\nguided by a style reference while maintaining the original content. Due to the\nlocality and spatial invariance in CNNs, it is difficult to extract and\nmaintain the global information of input images. Therefore, traditional neural\nstyle transfer methods are usually biased and content leak can be observed by\nrunning several times of the style transfer process with the same reference\nstyle image. To address this critical issue, we take long-range dependencies of\ninput images into account for unbiased style transfer by proposing a\ntransformer-based approach, namely StyTr^2. In contrast with visual\ntransformers for other vision tasks, our StyTr^2 contains two different\ntransformer encoders to generate domain-specific sequences for content and\nstyle, respectively. Following the encoders, a multi-layer transformer decoder\nis adopted to stylize the content sequence according to the style sequence. In\naddition, we analyze the deficiency of existing positional encoding methods and\npropose the content-aware positional encoding (CAPE) which is scale-invariant\nand more suitable for image style transfer task. Qualitative and quantitative\nexperiments demonstrate the effectiveness of the proposed StyTr^2 compared to\nstate-of-the-art CNN-based and flow-based approaches.",
    "descriptor": "",
    "authors": [
      "Yingying Deng",
      "Fan Tang",
      "Xingjia Pan",
      "Weiming Dong",
      "ChongyangMa",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.14576"
  },
  {
    "id": "arXiv:2105.14579",
    "title": "A Rice's Theorem for Abstract Semantics",
    "abstract": "Classical results in computability theory, notably Rice's theorem, focus on\nthe extensional content of programs, namely, on the partial recursive functions\nthat programs compute. Later and more recent work investigated intensional\ngeneralisations of such results that take into account the way in which\nfunctions are computed, thus affected by the specific programs computing them.\nIn this paper, we single out a novel class of program semantics based on\nabstract domains of program properties that are able to capture nonextensional\naspects of program computations, such as their asymptotic complexity or logical\ninvariants, and allow us to generalise some foundational computability results\nsuch as Rice's Theorem and Kleene's Second Recursion Theorem to these\nsemantics. In particular, it turns out that for this class of abstract program\nsemantics, any nontrivial abstract property is undecidable and every decidable\noverapproximation necessarily includes an infinite set of false positives which\ncovers all values of the semantic abstract domain.",
    "descriptor": "\nComments: Full version of a conference paper presented at the 48th International Colloquium on Automata, Languages, and Programming (ICALP 2021)\n",
    "authors": [
      "Paolo Baldan",
      "Francesco Ranzato",
      "Linpeng Zhang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.14579"
  },
  {
    "id": "arXiv:2105.14582",
    "title": "Robustness of electricity systems with nearly 100% share of renewables:  a worst-case study",
    "abstract": "Several research studies have shown that future sustainable electricity\nsystems, mostly based on renewable generation and storage, are feasible with\ncurrent technologies and costs. However, recent episodes of extreme weather\nconditions, probably associated with climate change, cast shades of doubt on\nwhether the resulting generation portfolios are sufficiently robust to assure,\nat all times, a suitable balance between generation and demand, when adverse\nconditions are faced. To address this issue, this work elaborates a methodology\nintended to determine a sustainable electricity system that can endure extreme\nweather conditions, which are likely to occur. First, using hourly production\nand demand data from the last decade, along with estimates of new uses of\nelectricity, a worst-case scenario is constructed, including the storage\ncapacity and additional photovoltaic power which are needed to serve the demand\non an hourly basis. Next, several key parameters which may have a significant\ninfluence on the LCOE are considered, and a sensitivity analysis is carried out\nto determine their real impact, significance and potential trends. The proposed\nmethodology is then applied to the Spanish system. The results show that, under\nthe hypotheses and conditions considered in this paper, it is possible to\ndesign a decarbonized electricity system that, taking advantage of existing\nsustainable assets, satisfies the long-term needs by providing a reliable\nsupply at an average cost significantly lower than current market prices.",
    "descriptor": "\nComments: 33 pages, 13 figures, 10 tables\n",
    "authors": [
      "Francisco Gutierrez-Garcia",
      "Angel Arcos-Vargas",
      "Antonio Gomez-Exposito"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14582"
  },
  {
    "id": "arXiv:2105.14583",
    "title": "A Note On The Randomized Kaczmarz Method With A Partially Weighted  Selection Step",
    "abstract": "In this note we reconsider two known algorithms which both usually converge\nfaster than the randomized Kaczmarz method introduced by Strohmer and\nVershynin(2009), but require the additional computation of all residuals of an\niteration at each step. As already indicated in the literature, e.g.\narXiv:2007.02910 and arXiv:2011.14693, it is shown that the non-randomized\nversion of the two algorithms converges at least as fast as the randomized\nversion, while still requiring computation of all residuals. Based on that\nobservation, a new simple random sample selection scheme has been introduced by\narXiv:2011.14693 to reduce the required total of residuals. In the same light\nwe propose an alternative random selection scheme which can easily be included\nas a `partially weighted selection step' into the classical randomized Kaczmarz\nalgorithm without much ado. Numerical examples show that the randomly\ndetermined number of required residuals can be quite moderate.",
    "descriptor": "",
    "authors": [
      "J\u00fcrgen Gro\u00df"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14583"
  },
  {
    "id": "arXiv:2105.14584",
    "title": "Polygonal Point Set Tracking",
    "abstract": "In this paper, we propose a novel learning-based polygonal point set tracking\nmethod. Compared to existing video object segmentation~(VOS) methods that\npropagate pixel-wise object mask information, we propagate a polygonal point\nset over frames.\nSpecifically, the set is defined as a subset of points in the target contour,\nand our goal is to track corresponding points on the target contour. Those\noutputs enable us to apply various visual effects such as motion tracking, part\ndeformation, and texture mapping. To this end, we propose a new method to track\nthe corresponding points between frames by the global-local alignment with\ndelicately designed losses and regularization terms. We also introduce a novel\nlearning strategy using synthetic and VOS datasets that makes it possible to\ntackle the problem without developing the point correspondence dataset. Since\nthe existing datasets are not suitable to validate our method, we build a new\npolygonal point set tracking dataset and demonstrate the superior performance\nof our method over the baselines and existing contour-based VOS methods. In\naddition, we present visual-effects applications of our method on part\ndistortion and text mapping.",
    "descriptor": "\nComments: 14 pages, 10 figures, 6 tables\n",
    "authors": [
      "Gunhee Nam",
      "Miran Heo",
      "Seoung Wug Oh",
      "Joon-Young Lee",
      "Seon Joo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14584"
  },
  {
    "id": "arXiv:2105.14599",
    "title": "Personalization in E-Grocery: Top-N versus Top-k Rankings",
    "abstract": "Business success in e-commerce depends on customer perceived value. A\ncustomer with high perceived value buys, returns, and recommends items. The\nperceived value is at risk whenever the information load harms users' shopping\nexperience. In e-grocery, shoppers face an overwhelming number of items, the\nmajority of which is irrelevant for the shopper. Recommender systems (RS)\nenable businesses to master information overload (IO) by providing users with\nan item ranking by relevance. Prior work proposes RS with short personalized\nrankings (top-k). Given large order sizes and high user heterogeneity in\ne-grocery, top-k RS are insufficient to diminish IO in this domain. To fill\nthis gap and raise business performance, this paper introduces an RS with a\npersonalized long ranking (top-N). Undertaking a randomized field experiment,\nthe paper establishes the merit of shifting from top-k to top-N rankings.\nSpecifically, the proposed RS reduces IO by 29.4% and lowers users' search time\nby 3.3 seconds per item. The field experiment also reveals a 7% uplift in\nrevenue due to the top-N ranking. Substantial benefits for the customer and the\ncompany highlight the business value of top-N rankings as a new design\nrequirement for recommender systems in e-grocery.",
    "descriptor": "",
    "authors": [
      "Franziska Scherpinski",
      "Stefan Lessmann"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.14599"
  },
  {
    "id": "arXiv:2105.14600",
    "title": "HIT: A Hierarchically Fused Deep Attention Network for Robust Code-mixed  Language Representation",
    "abstract": "Understanding linguistics and morphology of resource-scarce code-mixed texts\nremains a key challenge in text processing. Although word embedding comes in\nhandy to support downstream tasks for low-resource languages, there are plenty\nof scopes in improving the quality of language representation particularly for\ncode-mixed languages. In this paper, we propose HIT, a robust representation\nlearning method for code-mixed texts. HIT is a hierarchical transformer-based\nframework that captures the semantic relationship among words and\nhierarchically learns the sentence-level semantics using a fused attention\nmechanism. HIT incorporates two attention modules, a multi-headed\nself-attention and an outer product attention module, and computes their\nweighted sum to obtain the attention weights. Our evaluation of HIT on one\nEuropean (Spanish) and five Indic (Hindi, Bengali, Tamil, Telugu, and\nMalayalam) languages across four NLP tasks on eleven datasets suggests\nsignificant performance improvement against various state-of-the-art systems.\nWe further show the adaptability of learned representation across tasks in a\ntransfer learning setup (with and without fine-tuning).",
    "descriptor": "\nComments: 15 pages, 13 tables, 6 Figures. Accepted at ACL-IJCNLP-2021 (Findings)\n",
    "authors": [
      "Ayan Sengupta",
      "Sourabh Kumar Bhattacharjee",
      "Tanmoy Chakraborty",
      "Md Shad Akhtar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14600"
  },
  {
    "id": "arXiv:2105.14602",
    "title": "On the geometry of generalization and memorization in deep neural  networks",
    "abstract": "Understanding how large neural networks avoid memorizing training data is key\nto explaining their high generalization performance. To examine the structure\nof when and where memorization occurs in a deep network, we use a recently\ndeveloped replica-based mean field theoretic geometric analysis method. We find\nthat all layers preferentially learn from examples which share features, and\nlink this behavior to generalization performance. Memorization predominately\noccurs in the deeper layers, due to decreasing object manifolds' radius and\ndimension, whereas early layers are minimally affected. This predicts that\ngeneralization can be restored by reverting the final few layer weights to\nearlier epochs before significant memorization occurred, which is confirmed by\nthe experiments. Additionally, by studying generalization under different model\nsizes, we reveal the connection between the double descent phenomenon and the\nunderlying model geometry. Finally, analytical analysis shows that networks\navoid memorization early in training because close to initialization, the\ngradient contribution from permuted examples are small. These findings provide\nquantitative evidence for the structure of memorization across layers of a deep\nneural network, the drivers for such structure, and its connection to manifold\ngeometric properties.",
    "descriptor": "\nComments: ICLR 2021\n",
    "authors": [
      "Cory Stephenson",
      "Suchismita Padhy",
      "Abhinav Ganesh",
      "Yue Hui",
      "Hanlin Tang",
      "SueYeon Chung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14602"
  },
  {
    "id": "arXiv:2105.14607",
    "title": "Power and Performance Efficient SDN-Enabled Fog Architecture",
    "abstract": "Software Defined Networks (SDNs) have dramatically simplified network\nmanagement. However, enabling pure SDNs to respond in real-time while handling\nmassive amounts of data still remains a challenging task. In contrast, fog\ncomputing has strong potential to serve large surges of data in real-time. SDN\ncontrol plane enables innovation, and greatly simplifies network operations and\nmanagement thereby providing a promising solution to implement energy and\nperformance aware SDN-enabled fog computing. Besides, power efficiency and\nperformance evaluation in SDN-enabled fog computing is an area that has not yet\nbeen fully explored by the research community. We present a novel SDN-enabled\nfog architecture to improve power efficacy and performance by leveraging\ncooperative and non-cooperative policy-based computing. Preliminary results\nfrom extensive simulation demonstrate an improvement in the power utilization\nas well as the overall performance (i.e., processing time, response time).\nFinally, we discuss several open research issues that need further\ninvestigation in the future.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Adnan Akhunzada",
      "Sherali Zeadally",
      "Saif ul Islam"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.14607"
  },
  {
    "id": "arXiv:2105.14608",
    "title": "Safety Embedded Differential Dynamic Programming using Discrete Barrier  States",
    "abstract": "Certified safe control is a growing challenge in robotics, especially when\nperformance and safety objectives are desired to be concurrently achieved. In\nthis work, we extend the barrier state (BaS) concept, recently proposed for\nstabilization of continuous time systems, to enforce safety for discrete time\nsystems by creating a discrete barrier state (DBaS). The constructed DBaS is\nembedded into the discrete model of the safety-critical system in order to\nintegrate safety objectives into performance objectives. We subsequently use\nthe proposed technique to implement a safety embedded stabilizing control for\nnonlinear discrete systems. Furthermore, we employ the DBaS method to develop a\nsafety embedded differential dynamic programming (DDP) technique to plan and\nexecute safe optimal trajectories. The proposed algorithm is leveraged on a\ndifferential wheeled robot and on a quadrotor to safely perform several tasks\nincluding reaching, tracking and safe multi-quadrotor movement. The DBaS-based\nDDP (DBaS-DDP) is compared to the penalty method used in constrained DDP\nproblems where it is shown that the DBaS-DDP consistently outperforms the\npenalty method.",
    "descriptor": "",
    "authors": [
      "Hassan Almubarak",
      "Kyle Stachowicz",
      "Nader Sadegh",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14608"
  },
  {
    "id": "arXiv:2105.14609",
    "title": "Identity and Attribute Preserving Thumbnail Upscaling",
    "abstract": "We consider the task of upscaling a low resolution thumbnail image of a\nperson, to a higher resolution image, which preserves the person's identity and\nother attributes. Since the thumbnail image is of low resolution, many higher\nresolution versions exist. Previous approaches produce solutions where the\nperson's identity is not preserved, or biased solutions, such as predominantly\nCaucasian faces. We address the existing ambiguity by first augmenting the\nfeature extractor to better capture facial identity, facial attributes (such as\nsmiling or not) and race, and second, use this feature extractor to generate\nhigh-resolution images which are identity preserving as well as conditioned on\nrace and facial attributes. Our results indicate an improvement in face\nsimilarity recognition and lookalike generation as well as in the ability to\ngenerate higher resolution images which preserve an input thumbnail identity\nand whose race and attributes are maintained.",
    "descriptor": "\nComments: ICIP 2021\n",
    "authors": [
      "Noam Gat",
      "Sagie Benaim",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14609"
  },
  {
    "id": "arXiv:2105.14614",
    "title": "Evolution of Activation Functions: An Empirical Investigation",
    "abstract": "The hyper-parameters of a neural network are traditionally designed through a\ntime consuming process of trial and error that requires substantial expert\nknowledge. Neural Architecture Search (NAS) algorithms aim to take the human\nout of the loop by automatically finding a good set of hyper-parameters for the\nproblem at hand. These algorithms have mostly focused on hyper-parameters such\nas the architectural configurations of the hidden layers and the connectivity\nof the hidden neurons, but there has been relatively little work on automating\nthe search for completely new activation functions, which are one of the most\ncrucial hyper-parameters to choose. There are some widely used activation\nfunctions nowadays which are simple and work well, but nonetheless, there has\nbeen some interest in finding better activation functions. The work in the\nliterature has mostly focused on designing new activation functions by hand, or\nchoosing from a set of predefined functions while this work presents an\nevolutionary algorithm to automate the search for completely new activation\nfunctions. We compare these new evolved activation functions to other existing\nand commonly used activation functions. The results are favorable and are\nobtained from averaging the performance of the activation functions found over\n30 runs, with experiments being conducted on 10 different datasets and\narchitectures to ensure the statistical robustness of the study.",
    "descriptor": "",
    "authors": [
      "Andrew Nader",
      "Danielle Azar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.14614"
  },
  {
    "id": "arXiv:2105.14615",
    "title": "On the Controllers Based on Time Delay Estimation for Robotic  Manipulators",
    "abstract": "Assurance of asymptotic trajectory tracking in robotic manipulators with a\ncontinuous control law in the presence of unmodeled dynamics or external\ndisturbance is a challenging problem. Recently, it is asserted that this aim is\nachieved by designing a traditional model-free controller together with time\ndelay estimation (TDE) such that neither dynamical parameters nor conservative\nassumptions on the external disturbance are required. In this note, the purpose\nis to show that this claim is wrong. Additionally, modification of this method\nfor some special cases is presented.",
    "descriptor": "",
    "authors": [
      "M. Reza J. Harandi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14615"
  },
  {
    "id": "arXiv:2105.14618",
    "title": "FED-$\u03c7^2$: Privacy Preserving Federated Correlation Test",
    "abstract": "In this paper, we propose the first secure federated $\\chi^2$-test protocol\nFed-$\\chi^2$. To minimize both the privacy leakage and the communication cost,\nwe recast $\\chi^2$-test to the second moment estimation problem and thus can\ntake advantage of stable projection to encode the local information in a short\nvector. As such encodings can be aggregated with only summation, secure\naggregation can be naturally applied to hide the individual updates. We\nformally prove the security guarantee of Fed-$\\chi^2$ that the joint\ndistribution is hidden in a subspace with exponential possible distributions.\nOur evaluation results show that Fed-$\\chi^2$ achieves negligible accuracy\ndrops with small client-side computation overhead. In several real-world case\nstudies, the performance of Fed-$\\chi^2$ is comparable to the centralized\n$\\chi^2$-test.",
    "descriptor": "",
    "authors": [
      "Lun Wang",
      "Qi Pang",
      "Shuai Wang",
      "Dawn Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.14618"
  },
  {
    "id": "arXiv:2105.14619",
    "title": "Strategies and Perceived Risks of Sending Sensitive Documents",
    "abstract": "People are frequently required to send documents, forms, or other materials\ncontaining sensitive data (e.g., personal information, medical records,\nfinancial data) to remote parties, sometimes without a formal procedure to do\nso securely. The specific transmission mechanisms end up relying on the\nknowledge and preferences of the parties involved. Through two online surveys\n($n=60$ and $n=250$), we explore the various methods used to transmit sensitive\ndocuments, as well as the perceived risk and satisfaction with those methods.\nWe find that users are more likely to recognize risk to data-at-rest after\nreceipt (but not at the sender, namely, themselves). When not using an online\nportal provided by the recipient, participants primarily envision transmitting\nsensitive documents in person or via email, and have little experience using\nsecure, privacy-preserving alternatives. Despite recognizing general risks,\nparticipants express high privacy satisfaction and convenience with actually\nexperienced situations. These results suggest opportunities to design new\nsolutions to promote securely sending sensitive materials, perhaps as new\nutilities within standard email workflows.",
    "descriptor": "\nComments: 25 pages, to appear in USENIX Security Symposium 2021\n",
    "authors": [
      "Noel Warford",
      "Collins W. Munyendo",
      "Ashna Mediratta",
      "Adam J. Aviv",
      "Michelle L. Mazurek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14619"
  },
  {
    "id": "arXiv:2105.14620",
    "title": "Non-local Patch-based Low-rank Tensor Ring Completion for Visual Data",
    "abstract": "Tensor completion is the problem of estimating the missing entries of a\npartially observed tensor with a certain low-rank structure. It improves on\nmatrix completion for image and video data by capturing additional structural\ninformation intrinsic to such data. % With more inherent information involving\nin tensor structure than matrix, tensor completion has shown better performance\ncompared with matrix completion especially in image and video data. Traditional\ncompletion algorithms treat the entire visual data as a tensor, which may not\nalways work well especially when camera or object motion exists. In this paper,\nwe develop a novel non-local patch-based tensor ring completion algorithm. In\nthe proposed approach, similar patches are extracted for each reference patch\nalong both the spatial and temporal domains of the visual data. The collected\npatches are then formed into a high-order tensor and a tensor ring completion\nalgorithm is proposed to recover the completed tensor. A novel interval\nsampling-based block matching (ISBM) strategy and a hybrid completion strategy\nare also proposed to improve efficiency and accuracy. Further, we develop an\nonline patch-based completion algorithm to deal with streaming video data. An\nefficient online tensor ring completion algorithm is proposed to reduce the\ntime cost. Extensive experimental results demonstrate the superior performance\nof the proposed algorithms compared with state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yicong He",
      "George K. Atia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14620"
  },
  {
    "id": "arXiv:2105.14622",
    "title": "Modeling of Visco-Elastic Environments for Humanoid Robot Motion Control",
    "abstract": "This manuscript presents a model of compliant contacts for time-critical\nhumanoid robot motion control. The proposed model considers the environment as\na continuum of spring-damper systems, which allows us to compute the equivalent\ncontact force and torque that the environment exerts on the contact surface. We\nshow that the proposed model extends the linear and rotational springs and\ndampers - classically used to characterize soft terrains - to the case of large\ncontact surface orientations. The contact model is then used for the real-time\nwhole-body control of humanoid robots walking on visco-elastic environments.\nThe overall approach is validated by simulating walking motions of the iCub\nhumanoid robot. Furthermore, the paper compares the proposed whole-body control\nstrategy and state of the art approaches. In this respect, we investigate the\nterrain compliance that makes the classical approaches assuming rigid contacts\nfail. We finally analyze the robustness of the presented control design with\nrespect to non-parametric uncertainty in the contact-model.",
    "descriptor": "",
    "authors": [
      "Giulio Romualdi",
      "Stefano Dafarra",
      "Daniele Pucci"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14622"
  },
  {
    "id": "arXiv:2105.14625",
    "title": "Surrogate Model Based Hyperparameter Tuning for Deep Learning with SPOT",
    "abstract": "A surrogate model based hyperparameter tuning approach for deep learning is\npresented. This article demonstrates how the architecture-level parameters\n(hyperparameters) of deep learning models that were implemented in\nKeras/tensorflow can be optimized. The implementation of the tuning procedure\nis 100 % based on R, the software environment for statistical computing. With a\nfew lines of code, existing R packages (tfruns and SPOT) can be combined to\nperform hyperparameter tuning. An elementary hyperparameter tuning task (neural\nnetwork and the MNIST data) is used to exemplify this approach.",
    "descriptor": "",
    "authors": [
      "Thomas Bartz-Beielstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14625"
  },
  {
    "id": "arXiv:2105.14629",
    "title": "$\\ell_2$-norm Flow Diffusion in Near-Linear Time",
    "abstract": "Diffusion is a fundamental graph process and has been a basic building block\nin the study of graph clustering and graph learning tasks such as node\nclassification. In this paper, we initiate the study of computationally\nefficient diffusion primitives beyond random walk.\nWe provide an $\\widetilde{O}(m)$-time randomized algorithm for the\n$\\ell_2$-norm flow diffusion problem, obtaining the approximation factor of\n$1+1/\\mathrm{poly}(n)$. Using the connection between its dual solution and\nlocal cut structure, we give an alternative approach for finding locally-biased\nlow conductance cuts. It is done simply by sweeping over the dual solution\nvector.\nThis algorithm demonstrates a novel way of dealing with inequality\nconstraints in graph optimization problems. It adapts the high-level\nalgorithmic framework of Laplacian system solvers, but requires several new\ntools: vertex elimination under constraints, a new family of graph\nultra-sparsifiers, and accelerated proximal gradient methods with inexact\nproximal mapping computation.",
    "descriptor": "",
    "authors": [
      "Li Chen",
      "Richard Peng",
      "Di Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14629"
  },
  {
    "id": "arXiv:2105.14633",
    "title": "A learning-based projection method for model order reduction of  transport problems",
    "abstract": "The Kolmogorov $n$-width of the solution manifolds of transport-dominated\nproblems can decay slowly. As a result, it can be challenging to design\nefficient and accurate reduced order models (ROMs) for such problems. To\naddress this issue, we propose a new learning-based projection method to\nconstruct nonlinear adaptive ROMs for transport problems. The construction\nfollows the offline-online decomposition. In the offline stage, we train a\nneural network to construct adaptive reduced basis dependent on time and model\nparameters. In the online stage, we project the solution to the learned reduced\nmanifold. Inheriting the merits from both deep learning and the projection\nmethod, the proposed method is more efficient than the conventional linear\nprojection-based methods, and may reduce the generalization error of a solely\nlearning-based ROM. Unlike some learning-based projection methods, the proposed\nmethod does not need to take derivatives of the neural network in the online\nstage.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Zhichao Peng",
      "Min Wang",
      "Fengyan Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14633"
  },
  {
    "id": "arXiv:2105.14636",
    "title": "MLPruning: A Multilevel Structured Pruning Framework for  Transformer-based Models",
    "abstract": "Pruning is an effective method to reduce the memory footprint and\ncomputational cost associated with large natural language processing models.\nHowever, current approaches either only explore head pruning, which has a\nlimited pruning ratio, or only focus on unstructured pruning, which has\nnegligible effects on the real inference time and/or power consumption. To\naddress these challenges, we develop a novel MultiLevel structured Pruning\n(MLPruning) framework, which uses three different levels of structured pruning:\nhead pruning, row pruning, and block-wise sparse pruning. We propose using a\nlearnable Top-k threshold, which employs an adaptive regularization to adjust\nthe regularization magnitude adaptively, to select appropriate pruning ratios\nfor different weight matrices. We also propose a two-step pipeline to combine\nblock-wise pruning with head/row pruning to achieve high structured pruning\nratios with minimum accuracy degradation. Our empirical results show that for\n\\bertbase, with \\textapprox20\\% of remaining weights, \\OURS can achieve an\naccuracy that is comparable to the full model on QQP/MNLI/\\squad, with up to\n\\textapprox3.69x speedup. Our framework has been open sourced~\\cite{codebase}.",
    "descriptor": "\nComments: 20 pages, 4 figures, 9 tables\n",
    "authors": [
      "Zhewei Yao",
      "Linjian Ma",
      "Sheng Shen",
      "Kurt Keutzer",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14636"
  },
  {
    "id": "arXiv:2105.14637",
    "title": "Organizational Artifacts of Code Development",
    "abstract": "Software is the outcome of active and effective communication between members\nof an organization. This has been noted with Conway's law, which states that\n``organizations design systems that mirror their own communication structure.''\nHowever, software developers are often members of multiple organizational\ngroups (e.g., corporate, regional,) and it is unclear how association with\ngroups beyond one's company influence the development process. In this paper,\nwe study social effects of country by measuring differences in software\nrepositories associated with different countries. Using a novel dataset we\nobtain from GitHub, we identify key properties that differentiate software\nrepositories based upon the country of the developers. We propose a novel\napproach of modeling repositories based on their sequence of development\nactivities as a sequence embedding task and coupled with repo profile features\nwe achieve 79.2% accuracy in identifying the country of a repository. Finally,\nwe conduct a case study on repos from well-known corporations and find that\ncountry can describe the differences in development better than the company\naffiliation itself. These results have larger implications for software\ndevelopment and indicate the importance of considering the multiple groups\ndevelopers are associated with when considering the formation and structure of\nteams.",
    "descriptor": "",
    "authors": [
      "Parisa Kaghazgaran",
      "Nichola Lubold",
      "Fred Morstatter"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.14637"
  },
  {
    "id": "arXiv:2105.14638",
    "title": "DAAIN: Detection of Anomalous and Adversarial Input using Normalizing  Flows",
    "abstract": "Despite much recent work, detecting out-of-distribution (OOD) inputs and\nadversarial attacks (AA) for computer vision models remains a challenge. In\nthis work, we introduce a novel technique, DAAIN, to detect OOD inputs and AA\nfor image segmentation in a unified setting. Our approach monitors the inner\nworkings of a neural network and learns a density estimator of the activation\ndistribution. We equip the density estimator with a classification head to\ndiscriminate between regular and anomalous inputs. To deal with the\nhigh-dimensional activation-space of typical segmentation networks, we\nsubsample them to obtain a homogeneous spatial and layer-wise coverage. The\nsubsampling pattern is chosen once per monitored model and kept fixed for all\ninputs. Since the attacker has access to neither the detection model nor the\nsampling key, it becomes harder for them to attack the segmentation network, as\nthe attack cannot be backpropagated through the detector. We demonstrate the\neffectiveness of our approach using an ESPNet trained on the Cityscapes dataset\nas segmentation model, an affine Normalizing Flow as density estimator and use\nblue noise to ensure homogeneous sampling. Our model can be trained on a single\nGPU making it compute efficient and deployable without requiring specialized\naccelerators.",
    "descriptor": "\nComments: 14 pages, 4 figures, 4 tables\n",
    "authors": [
      "Samuel von Bau\u00dfnern",
      "Johannes Otterbach",
      "Adrian Loy",
      "Mathieu Salzmann",
      "Thomas Wollmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14638"
  },
  {
    "id": "arXiv:2105.14639",
    "title": "Shaped Policy Search for Evolutionary Strategies using Waypoints",
    "abstract": "In this paper, we try to improve exploration in Blackbox methods,\nparticularly Evolution strategies (ES), when applied to Reinforcement Learning\n(RL) problems where intermediate waypoints/subgoals are available. Since\nEvolutionary strategies are highly parallelizable, instead of extracting just a\nscalar cumulative reward, we use the state-action pairs from the trajectories\nobtained during rollouts/evaluations, to learn the dynamics of the agent. The\nlearnt dynamics are then used in the optimization procedure to speed-up\ntraining. Lastly, we show how our proposed approach is universally applicable\nby presenting results from experiments conducted on Carla driving and UR5\nrobotic arm simulators.",
    "descriptor": "\nComments: Presented at the International Conference on Robotics and Automation (ICRA) 2021\n",
    "authors": [
      "Kiran Lekkala",
      "Laurent Itti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.14639"
  },
  {
    "id": "arXiv:2105.14641",
    "title": "On the Secrecy Rate under Statistical QoS Provisioning for RIS-Assisted  MISO Wiretap Channel",
    "abstract": "Reconfigurable intelligent surface (RIS) assisted radio is considered as an\nenabling technology with great potential for the sixth-generation (6G) wireless\ncommunications standard. The achievable secrecy rate (ASR) is one of the most\nfundamental metrics to evaluate the capability of facilitating secure\ncommunication for RIS-assisted systems. However, the definition of ASR is based\non Shannon's information theory, which generally requires long codewords and\nthus fails to quantify the secrecy of emerging delay-critical services.\nMotivated by this, in this paper we investigate the problem of maximizing the\nsecrecy rate under a delay-limited quality-of-service (QoS) constraint, termed\nas the effective secrecy rate (ESR), for an RIS-assisted multiple-input\nsingle-output (MISO) wiretap channel subject to a transmit power constraint. We\npropose an iterative method to find a stationary solution to the formulated\nnon-convex optimization problem using a block coordinate ascent method (BCAM),\nwhere both the beamforming vector at the transmitter as well as the phase\nshifts at the RIS are obtained in closed forms in each iteration. We also\npresent a convergence proof, an efficient implementation, and the associated\ncomplexity analysis for the proposed method. Our numerical results demonstrate\nthat the proposed optimization algorithm converges significantly faster that an\nexisting solution. The simulation results also confirm that the secrecy rate\nperformance of the system with stringent delay requirements reduce\nsignificantly compared to the system without any delay constraints, and that\nthis reduction can be significantly mitigated by an appropriately placed\nlarge-size RIS.",
    "descriptor": "\nComments: 6 pages, 5 figures, 1 table\n",
    "authors": [
      "Vaibhav Kumar",
      "Mark F. Flanagan",
      "Derrick Wing Kwan Ng",
      "Le-Nam Tran"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.14641"
  },
  {
    "id": "arXiv:2105.14642",
    "title": "An iterative Jacobi-like algorithm to compute a few sparse  eigenvalue-eigenvector pairs",
    "abstract": "In this paper, we describe a new algorithm to compute the extreme\neigenvalue/eigenvector pairs of a symmetric matrix. The proposed algorithm can\nbe viewed as an extension of the Jacobi transformation method for symmetric\nmatrix diagonalization to the case where we want to compute just a few\neigenvalues/eigenvectors. The method is also particularly well suited for the\ncomputation of sparse eigenspaces. We show the effectiveness of the method for\nsparse low-rank approximations and show applications to random symmetric\nmatrices, graph Fourier transforms, and with the sparse principal component\nanalysis in image classification experiments.",
    "descriptor": "",
    "authors": [
      "Cristian Rusu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14642"
  },
  {
    "id": "arXiv:2105.14644",
    "title": "Generating Adversarial Examples with Graph Neural Networks",
    "abstract": "Recent years have witnessed the deployment of adversarial attacks to evaluate\nthe robustness of Neural Networks. Past work in this field has relied on\ntraditional optimization algorithms that ignore the inherent structure of the\nproblem and data, or generative methods that rely purely on learning and often\nfail to generate adversarial examples where they are hard to find. To alleviate\nthese deficiencies, we propose a novel attack based on a graph neural network\n(GNN) that takes advantage of the strengths of both approaches; we call it\nAdvGNN. Our GNN architecture closely resembles the network we wish to attack.\nDuring inference, we perform forward-backward passes through the GNN layers to\nguide an iterative procedure towards adversarial examples. During training, its\nparameters are estimated via a loss function that encourages the efficient\ncomputation of adversarial examples over a time horizon. We show that our\nmethod beats state-of-the-art adversarial attacks, including PGD-attack,\nMI-FGSM, and Carlini and Wagner attack, reducing the time required to generate\nadversarial examples with small perturbation norms by over 65\\%. Moreover,\nAdvGNN achieves good generalization performance on unseen networks. Finally, we\nprovide a new challenging dataset specifically designed to allow for a more\nillustrative comparison of adversarial attacks.",
    "descriptor": "\nComments: To be published in UAI 2021\n",
    "authors": [
      "Florian Jaeckle",
      "M. Pawan Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14644"
  },
  {
    "id": "arXiv:2105.14648",
    "title": "Sharper bounds for online learning of smooth functions of a single  variable",
    "abstract": "We investigate the generalization of the mistake-bound model to continuous\nreal-valued single variable functions. Let $\\mathcal{F}_q$ be the class of\nabsolutely continuous functions $f: [0, 1] \\rightarrow \\mathbb{R}$ with\n$||f'||_q \\le 1$, and define $opt_p(\\mathcal{F}_q)$ as the best possible bound\non the worst-case sum of the $p^{th}$ powers of the absolute prediction errors\nover any number of trials. Kimber and Long (Theoretical Computer Science, 1995)\nproved for $q \\ge 2$ that $opt_p(\\mathcal{F}_q) = 1$ when $p \\ge 2$ and\n$opt_p(\\mathcal{F}_q) = \\infty$ when $p = 1$. For $1 < p < 2$ with $p =\n1+\\epsilon$, the only known bound was $opt_p(\\mathcal{F}_{q}) =\nO(\\epsilon^{-1})$ from the same paper. We show for all $\\epsilon \\in (0, 1)$\nand $q \\ge 2$ that $opt_{1+\\epsilon}(\\mathcal{F}_q) =\n\\Theta(\\epsilon^{-\\frac{1}{2}})$, where the constants in the bound do not\ndepend on $q$. We also show that $opt_{1+\\epsilon}(\\mathcal{F}_{\\infty}) =\n\\Theta(\\epsilon^{-\\frac{1}{2}})$.",
    "descriptor": "",
    "authors": [
      "Jesse Geneson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14648"
  },
  {
    "id": "arXiv:2105.14652",
    "title": "Attention Flows are Shapley Value Explanations",
    "abstract": "Shapley Values, a solution to the credit assignment problem in cooperative\ngame theory, are a popular type of explanation in machine learning, having been\nused to explain the importance of features, embeddings, and even neurons. In\nNLP, however, leave-one-out and attention-based explanations still predominate.\nCan we draw a connection between these different methods? We formally prove\nthat -- save for the degenerate case -- attention weights and leave-one-out\nvalues cannot be Shapley Values. $\\textit{Attention flow}$ is a post-processed\nvariant of attention weights obtained by running the max-flow algorithm on the\nattention graph. Perhaps surprisingly, we prove that attention flows are indeed\nShapley Values, at least at the layerwise level. Given the many desirable\ntheoretical qualities of Shapley Values -- which has driven their adoption\namong the ML community -- we argue that NLP practitioners should, when\npossible, adopt attention flow explanations alongside more traditional ones.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Kawin Ethayarajh",
      "Dan Jurafsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14652"
  },
  {
    "id": "arXiv:2105.14655",
    "title": "UNiTE: Unitary N-body Tensor Equivariant Network with Applications to  Quantum Chemistry",
    "abstract": "Equivariant neural networks have been successful in incorporating various\ntypes of symmetries, but are mostly limited to vector representations of\ngeometric objects. Despite the prevalence of higher-order tensors in various\napplication domains, e.g. in quantum chemistry, equivariant neural networks for\ngeneral tensors remain unexplored. Previous strategies for learning equivariant\nfunctions on tensors mostly rely on expensive tensor factorization which is not\nscalable when the dimensionality of the problem becomes large. In this work, we\npropose unitary $N$-body tensor equivariant neural network (UNiTE), an\narchitecture for a general class of symmetric tensors called $N$-body tensors.\nThe proposed neural network is equivariant with respect to the actions of a\nunitary group, such as the group of 3D rotations. Furthermore, it has a linear\ntime complexity with respect to the number of non-zero elements in the tensor.\nWe also introduce a normalization method, viz., Equivariant Normalization, to\nimprove generalization of the neural network while preserving symmetry. When\napplied to quantum chemistry, UNiTE outperforms all state-of-the-art machine\nlearning methods of that domain with over 110% average improvements on multiple\nbenchmarks. Finally, we show that UNiTE achieves a robust zero-shot\ngeneralization performance on diverse down stream chemistry tasks, while being\nthree orders of magnitude faster than conventional numerical methods with\ncompetitive accuracy.",
    "descriptor": "",
    "authors": [
      "Zhuoran Qiao",
      "Anders S. Christensen",
      "Frederick R. Manby",
      "Matthew Welborn",
      "Anima Anandkumar",
      "Thomas F. Miller III"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.14655"
  },
  {
    "id": "arXiv:2105.14658",
    "title": "Eco-Driving of Connected and Autonomous Vehicles with  Sequence-to-Sequence Prediction of Target Vehicle Velocity",
    "abstract": "The Eco-Driving control problem seeks to perform fuel efficient speed\nplanning for a Connected and Autonomous Vehicle (CAV) that can exploit\ninformation available from advanced mapping, and from Vehicle-to-Everything\n(V2X) communication. The ability of an Eco-Driving strategy to adapt in real\ntime to variable traffic scenarios where surrounding vehicles can be either\nconnected or unconnected is critical for further development and deployment of\nthis technology in the transportation sector. In this work, the Eco-Driving\nstrategy, formulated as a receding-horizon optimal control problem, is\nintegrated with a target vehicle speed prediction model and solved via Dynamic\nProgramming (DP) to determine the optimal speed trajectory in the presence of a\nhuman-driven target vehicle. An encoder-decoder architecture analyzes the\npatterns in the target vehicle velocity recorded over a historic window using a\nGated-Recurrent-Unit (GRU) based encoder and generates an estimate of the\nfuture velocity trajectory using the GRU based decoder. A sensitivity study is\ndone to analyze the effect of the historical and prediction windows on the\naccuracy of the velocity predictor. The proposed Eco-Driving controller is\nevaluated through microscopic simulations using a traffic simulator.",
    "descriptor": "\nComments: 8 pages, 11 figures, conference paper\n",
    "authors": [
      "Shobhit Gupta",
      "Marcello Canova"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14658"
  },
  {
    "id": "arXiv:2105.14659",
    "title": "Federated Learning for Industrial Internet of Things in Future  Industries",
    "abstract": "The Industrial Internet of Things (IIoT) offers promising opportunities to\ntransform the operation of industrial systems and becomes a key enabler for\nfuture industries. Recently, artificial intelligence (AI) has been widely\nutilized for realizing intelligent IIoT applications where AI techniques\nrequire centralized data collection and processing. However, this is not always\nfeasible in realistic scenarios due to the high scalability of modern IIoT\nnetworks and growing industrial data confidentiality. Federated Learning (FL),\nas an emerging collaborative AI approach, is particularly attractive for\nintelligent IIoT networks by coordinating multiple IIoT devices and machines to\nperform AI training at the network edge while helping protect user privacy. In\nthis article, we provide a detailed overview and discussions of the emerging\napplications of FL in key IIoT services and applications. A case study is also\nprovided to demonstrate the feasibility of FL in IIoT. Finally, we highlight a\nrange of interesting open research topics that need to be addressed for the\nfull realization of FL-IIoT in industries.",
    "descriptor": "\nComments: Accepted at IEEE Wireless Communications Magazine\n",
    "authors": [
      "Dinh C. Nguyen",
      "Ming Ding",
      "Pubudu N. Pathirana",
      "Aruna Seneviratne",
      "Jun Li",
      "Dusit Niyato",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14659"
  },
  {
    "id": "arXiv:2105.14666",
    "title": "EchoFilter: End-to-End Neural Network for Acoustic Echo Cancellation",
    "abstract": "Acoustic Echo Cancellation (AEC) whose aim is to suppress the echo originated\nfrom acoustic coupling between loudspeakers and microphones, plays a key role\nin voice interaction. Linear adaptive filter (AF) is always used for handling\nthis problem. However, since there would be some severe effects in real\nscenarios, such nonlinear distortions, background noises, and microphone\nclipping, it would lead to considerable residual echo, giving poor performance\nin practice. In this paper, we propose an end-to-end network structure for echo\ncancellation, which is directly done on time-domain audio waveform. It is\ntransformed to deep representation by temporal convolution, and modelled by\nLong Short-Term Memory (LSTM) for considering temporal property. Since time\ndelay and severe reverberation may exist at the near-end with respect to the\nfar-end, a local attention is employed for alignment. The network is trained\nusing multitask learning by employing an auxiliary classification network for\ndouble-talk detection. Experiments show the superiority of our proposed method\nin terms of the echo return loss enhancement (ERLE) for single-talk periods and\nthe perceptual evaluation of speech quality (PESQ) score for double-talk\nperiods in background noise and nonlinear distortion scenarios.",
    "descriptor": "\nComments: 5 pages, 3 figures, 6 tabels\n",
    "authors": [
      "Lu Ma",
      "Song Yang",
      "Yaguang Gong",
      "Xintian Wang",
      "Zhongqin Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.14666"
  },
  {
    "id": "arXiv:2105.14668",
    "title": "On the Interplay Between Fine-tuning and Composition in Transformers",
    "abstract": "Pre-trained transformer language models have shown remarkable performance on\na variety of NLP tasks. However, recent research has suggested that\nphrase-level representations in these models reflect heavy influences of\nlexical content, but lack evidence of sophisticated, compositional phrase\ninformation. Here we investigate the impact of fine-tuning on the capacity of\ncontextualized embeddings to capture phrase meaning information beyond lexical\ncontent. Specifically, we fine-tune models on an adversarial paraphrase\nclassification task with high lexical overlap, and on a sentiment\nclassification task. After fine-tuning, we analyze phrasal representations in\ncontrolled settings following prior work. We find that fine-tuning largely\nfails to benefit compositionality in these representations, though training on\nsentiment yields a small, localized benefit for certain models. In follow-up\nanalyses, we identify confounding cues in the paraphrase dataset that may\nexplain the lack of composition benefits from that task, and we discuss\npotential factors underlying the localized benefits from sentiment training.",
    "descriptor": "\nComments: To appear in Findings of ACL 2021\n",
    "authors": [
      "Lang Yu",
      "Allyson Ettinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14668"
  },
  {
    "id": "arXiv:2105.14669",
    "title": "Memory-Efficient Differentiable Transformer Architecture Search",
    "abstract": "Differentiable architecture search (DARTS) is successfully applied in many\nvision tasks. However, directly using DARTS for Transformers is\nmemory-intensive, which renders the search process infeasible. To this end, we\npropose a multi-split reversible network and combine it with DARTS.\nSpecifically, we devise a backpropagation-with-reconstruction algorithm so that\nwe only need to store the last layer's outputs. By relieving the memory burden\nfor DARTS, it allows us to search with larger hidden size and more candidate\noperations. We evaluate the searched architecture on three sequence-to-sequence\ndatasets, i.e., WMT'14 English-German, WMT'14 English-French, and WMT'14\nEnglish-Czech. Experimental results show that our network consistently\noutperforms standard Transformers across the tasks. Moreover, our method\ncompares favorably with big-size Evolved Transformers, reducing search\ncomputation by an order of magnitude.",
    "descriptor": "\nComments: Accepted by Findings of ACL 2021\n",
    "authors": [
      "Yuekai Zhao",
      "Li Dong",
      "Yelong Shen",
      "Zhihua Zhang",
      "Furu Wei",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14669"
  },
  {
    "id": "arXiv:2105.14673",
    "title": "A Minimax Lower Bound for Low-Rank Matrix-Variate Logistic Regression",
    "abstract": "This paper considers the problem of matrix-variate logistic regression. The\nfundamental error threshold on estimating coefficient matrices in the logistic\nregression problem is found by deriving a lower bound on the minimax risk. The\nfocus of this paper is on derivation of a minimax risk lower bound for low-rank\ncoefficient matrices. The bound depends explicitly on the dimensions and\ndistribution of the covariates, the rank and energy of the coefficient matrix,\nand the number of samples. The resulting bound is proportional to the intrinsic\ndegrees of freedom in the problem, which suggests the sample complexity of the\nlow-rank matrix logistic regression problem can be lower than that for\nvectorized logistic regression. \\color{red}\\color{black} The proof techniques\nutilized in this work also set the stage for development of minimax lower\nbounds for tensor-variate logistic regression problems.",
    "descriptor": "\nComments: 8 pages; preprint of a conference paper\n",
    "authors": [
      "Batoul Taki",
      "Mohsen Ghassemi",
      "Anand D. Sarwate",
      "Waheed U. Bajwa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14673"
  },
  {
    "id": "arXiv:2105.14675",
    "title": "Towards a Federated Learning Framework for Heterogeneous Devices of  Internet of Things",
    "abstract": "Federated Learning (FL) has received a significant amount of attention in the\nindustry and research community due to its capability of keeping data on local\ndevices. To aggregate the gradients of local models to train the global model,\nexisting works require that the global model and the local models are the same.\nHowever, Internet of Things (IoT) devices are inherently diverse regarding\ncomputation speed and onboard memory. In this paper, we propose an FL framework\ntargeting the heterogeneity of IoT devices. Specifically, local models are\ncompressed from the global model, and the gradients of the compressed local\nmodels are used to update the global model. We conduct preliminary experiments\nto illustrate that our framework can facilitate the design of IoT-aware FL.",
    "descriptor": "",
    "authors": [
      "Huanle Zhang",
      "Jeonghoon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.14675"
  },
  {
    "id": "arXiv:2105.14676",
    "title": "NoiLIn: Do Noisy Labels Always Hurt Adversarial Training?",
    "abstract": "Adversarial training (AT) based on minimax optimization is a popular learning\nstyle that enhances the model's adversarial robustness. Noisy labels (NL)\ncommonly undermine the learning and hurt the model's performance.\nInterestingly, both research directions hardly crossover and hit sparks. In\nthis paper, we raise an intriguing question -- Does NL always hurt AT? Firstly,\nwe find that NL injection in inner maximization for generating adversarial data\naugments natural data implicitly, which benefits AT's generalization. Secondly,\nwe find NL injection in outer minimization for the learning serves as\nregularization that alleviates robust overfitting, which benefits AT's\nrobustness. To enhance AT's adversarial robustness, we propose \"NoiLIn\" that\ngradually increases \\underline{Noi}sy \\underline{L}abels \\underline{In}jection\nover the AT's training process. Empirically, NoiLIn answers the previous\nquestion negatively -- the adversarial robustness can be indeed enhanced by NL\ninjection. Philosophically, we provide a new perspective of the learning with\nNL: NL should not always be deemed detrimental, and even in the absence of NL\nin the training set, we may consider injecting it deliberately.",
    "descriptor": "",
    "authors": [
      "Jingfeng Zhang",
      "Xilie Xu",
      "Bo Han",
      "Tongliang Liu",
      "Gang Niu",
      "Lizhen Cui",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14676"
  },
  {
    "id": "arXiv:2105.14677",
    "title": "Characterization of Generalizability of Spike Time Dependent Plasticity  trained Spiking Neural Networks",
    "abstract": "A Spiking Neural Network (SNN) trained with Spike Time Dependent Plasticity\n(STDP) is a neuro-inspired unsupervised learning method for various machine\nlearning applications. This paper studies the generalizability properties of\nthe STDP learning processes using the Hausdorff dimension of the trajectories\nof the learning algorithm. The paper analyzes the effects of STDP learning\nmodels and associated hyper-parameters on the generalizability properties of an\nSNN and characterizes the generalizability vs learnability trade-off in an SNN.\nThe analysis is used to develop a Bayesian optimization approach to optimize\nthe hyper-parameters for an STDP model to improve the generalizability\nproperties of an SNN.",
    "descriptor": "\nComments: 15 pages, submitted to Frontiers in Neuroscience. arXiv admin note: text overlap with arXiv:2010.08195, arXiv:2006.09313 by other authors\n",
    "authors": [
      "Biswadeep Chakraborty",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14677"
  },
  {
    "id": "arXiv:2105.14678",
    "title": "Image-to-Video Generation via 3D Facial Dynamics",
    "abstract": "We present a versatile model, FaceAnime, for various video generation tasks\nfrom still images. Video generation from a single face image is an interesting\nproblem and usually tackled by utilizing Generative Adversarial Networks (GANs)\nto integrate information from the input face image and a sequence of sparse\nfacial landmarks. However, the generated face images usually suffer from\nquality loss, image distortion, identity change, and expression mismatching due\nto the weak representation capacity of the facial landmarks. In this paper, we\npropose to \"imagine\" a face video from a single face image according to the\nreconstructed 3D face dynamics, aiming to generate a realistic and\nidentity-preserving face video, with precisely predicted pose and facial\nexpression. The 3D dynamics reveal changes of the facial expression and motion,\nand can serve as a strong prior knowledge for guiding highly realistic face\nvideo generation. In particular, we explore face video prediction and exploit a\nwell-designed 3D dynamic prediction network to predict a 3D dynamic sequence\nfor a single face image. The 3D dynamics are then further rendered by the\nsparse texture mapping algorithm to recover structural details and sparse\ntextures for generating face frames. Our model is versatile for various AR/VR\nand entertainment applications, such as face video retargeting and face video\nprediction. Superior experimental results have well demonstrated its\neffectiveness in generating high-fidelity, identity-preserving, and visually\npleasant face video clips from a single source face image.",
    "descriptor": "",
    "authors": [
      "Xiaoguang Tu",
      "Yingtian Zou",
      "Jian Zhao",
      "Wenjie Ai",
      "Jian Dong",
      "Yuan Yao",
      "Zhikang Wang",
      "Guodong Guo",
      "Zhifeng Li",
      "Wei Liu",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.14678"
  },
  {
    "id": "arXiv:2105.14680",
    "title": "ThumbTrak: Recognizing Micro-finger Poses Using a Ring with Proximity  Sensing",
    "abstract": "ThumbTrak is a novel wearable input device that recognizes 12 micro-finger\nposes in real-time. Poses are characterized by the thumb touching each of the\n12 phalanges on the hand. It uses a thumb-ring, built with a flexible printed\ncircuit board, which hosts nine proximity sensors. Each sensor measures the\ndistance from the thumb to various parts of the palm or other fingers.\nThumbTrak uses a support-vector-machine (SVM) model to classify finger poses\nbased on distance measurements in real-time. A user study with ten participants\nshowed that ThumbTrak could recognize 12 micro finger poses with an average\naccuracy of 93.6%. We also discuss potential opportunities and challenges in\napplying ThumbTrak in real-world applications.",
    "descriptor": "\nComments: MobileHCI '21: The ACM International Conference on Mobile Human-Computer Interaction, September 27 - October 1, 2021, Toulouse, France\n",
    "authors": [
      "Wei Sun",
      "Franklin Mingzhe Li",
      "Congshu Huang",
      "Zhenyu Lei",
      "Benjamin Steeper",
      "Songyun Tao",
      "Feng Tian",
      "Cheng Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14680"
  },
  {
    "id": "arXiv:2105.14682",
    "title": "Zero-shot Fact Verification by Claim Generation",
    "abstract": "Neural models for automated fact verification have achieved promising results\nthanks to the availability of large, human-annotated datasets. However, for\neach new domain that requires fact verification, creating a dataset by manually\nwriting claims and linking them to their supporting evidence is expensive. We\ndevelop QACG, a framework for training a robust fact verification model by\nusing automatically generated claims that can be supported, refuted, or\nunverifiable from evidence from Wikipedia. QACG generates question-answer pairs\nfrom the evidence and then converts them into different types of claims.\nExperiments on the FEVER dataset show that our QACG framework significantly\nreduces the demand for human-annotated training data. In a zero-shot scenario,\nQACG improves a RoBERTa model's F1 from 50% to 77%, equivalent in performance\nto 2K+ manually-curated examples. Our QACG code is publicly available.",
    "descriptor": "\nComments: ACL-IJCNLP 2021 (main conference, short paper)\n",
    "authors": [
      "Liangming Pan",
      "Wenhu Chen",
      "Wenhan Xiong",
      "Min-Yen Kan",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14682"
  },
  {
    "id": "arXiv:2105.14683",
    "title": "Know Your Surroundings: Panoramic Multi-Object Tracking by Multimodality  Collaboration",
    "abstract": "In this paper, we focus on the multi-object tracking (MOT) problem of\nautomatic driving and robot navigation. Most existing MOT methods track\nmultiple objects using a singular RGB camera, which are prone to camera\nfield-of-view and suffer tracking failures in complex scenarios due to\nbackground clutters and poor light conditions. To meet these challenges, we\npropose a MultiModality PAnoramic multi-object Tracking framework (MMPAT),\nwhich takes both 2D panorama images and 3D point clouds as input and then\ninfers target trajectories using the multimodality data. The proposed method\ncontains four major modules, a panorama image detection module, a multimodality\ndata fusion module, a data association module and a trajectory inference model.\nWe evaluate the proposed method on the JRDB dataset, where the MMPAT achieves\nthe top performance in both the detection and tracking tasks and significantly\noutperforms state-of-the-art methods by a large margin (15.7 and 8.5\nimprovement in terms of AP and MOTA, respectively).",
    "descriptor": "",
    "authors": [
      "Yuhang He",
      "Wentao Yu",
      "Jie Han",
      "Xing Wei",
      "Xiaopeng Hong",
      "Yihong Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14683"
  },
  {
    "id": "arXiv:2105.14685",
    "title": "Long-term Person Re-identification: A Benchmark",
    "abstract": "Existing person re-identification (Re-ID) works mostly consider a short-term\nsearch problem assuming unchanged clothes and personal appearance. However, in\nrealworld we often dress ourselves differently across locations, time, dates,\nseasons, weather, and events. As a result, the existing methods are unsuitable\nfor long-term person Re-ID with clothes change involved. Whilst there are\nseveral recent longterm Re-ID attempts, a large realistic dataset with clothes\nchange is lacking and indispensable for enabling extensive study as already\nexperienced in short-term Re-ID setting. In this work, we contribute timely a\nlarge, realistic long-term person re-identification benchmark. It consists of\n171K bounding boxes from 1.1K person identities, collected and constructed over\na course of 12 months. Unique characteristics of this dataset include: (1)\nNatural/native personal appearance (e.g., clothes and hair style) variations:\nThe degrees of clothes-change and dressing styles all are highly diverse, with\nthe reappearing gap in time ranging from minutes, hours, and days to weeks,\nmonths, seasons, and years. (2) Diverse walks of life: Persons across a wide\nrange of ages and professions appear in different weather conditions (e.g.,\nsunny, cloudy, windy, rainy, snowy, extremely cold) and events (e.g., working,\nleisure, daily activities). (3) Rich camera setups: The raw videos were\nrecorded by 17 outdoor security cameras with various resolutions operating in a\nreal-world surveillance system for a wide and dense block. (4) Largest scale:\nIt covers the largest number of (17) cameras, (1082) identities, and (171K)\nbounding boxes, as compared to alternative datasets.",
    "descriptor": "",
    "authors": [
      "Peng Xu",
      "Xiatian Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14685"
  },
  {
    "id": "arXiv:2105.14686",
    "title": "Fully Hyperbolic Neural Networks",
    "abstract": "Hyperbolic neural networks have shown great potential for modeling complex\ndata. However, existing hyperbolic networks are not completely hyperbolic, as\nthey encode features in a hyperbolic space yet formalize most of their\noperations in the tangent space (a Euclidean subspace) at the origin of the\nhyperbolic space. This hybrid method greatly limits the modeling ability of\nnetworks. In this paper, we propose a fully hyperbolic framework to build\nhyperbolic networks based on the Lorentz model by adapting the Lorentz\ntransformations (including boost and rotation) to formalize essential\noperations of neural networks. Moreover, we also prove that linear\ntransformation in tangent spaces used by existing hyperbolic networks is a\nrelaxation of the Lorentz rotation and does not include the boost, implicitly\nlimiting the capabilities of existing hyperbolic networks. The experimental\nresults on four NLP tasks show that our method has better performance for\nbuilding both shallow and deep networks. Our code will be released to\nfacilitate follow-up research.",
    "descriptor": "",
    "authors": [
      "Weize Chen",
      "Xu Han",
      "Yankai Lin",
      "Hexu Zhao",
      "Zhiyuan Liu",
      "Peng Li",
      "Maosong Sun",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14686"
  },
  {
    "id": "arXiv:2105.14688",
    "title": "Learning to Expand Audience via Meta Hybrid Experts and Critics for  Recommendation and Advertising",
    "abstract": "In recommender systems and advertising platforms, marketers always want to\ndeliver products, contents, or advertisements to potential audiences over media\nchannels such as display, video, or social. Given a set of audiences or\ncustomers (seed users), the audience expansion technique (look-alike modeling)\nis a promising solution to identify more potential audiences, who are similar\nto the seed users and likely to finish the business goal of the target\ncampaign. However, look-alike modeling faces two challenges: (1) In practice, a\ncompany could run hundreds of marketing campaigns to promote various contents\nwithin completely different categories every day, e.g., sports, politics,\nsociety. Thus, it is difficult to utilize a common method to expand audiences\nfor all campaigns. (2) The seed set of a certain campaign could only cover\nlimited users. Therefore, a customized approach based on such a seed set is\nlikely to be overfitting.\nIn this paper, to address these challenges, we propose a novel two-stage\nframework named Meta Hybrid Experts and Critics (MetaHeac) which has been\ndeployed in WeChat Look-alike System. In the offline stage, a general model\nwhich can capture the relationships among various tasks is trained from a\nmeta-learning perspective on all existing campaign tasks. In the online stage,\nfor a new campaign, a customized model is learned with the given seed set based\non the general model. According to both offline and online experiments, the\nproposed MetaHeac shows superior effectiveness for both content marketing\ncampaigns in recommender systems and advertising campaigns in advertising\nplatforms. Besides, MetaHeac has been successfully deployed in WeChat for the\npromotion of both contents and advertisements, leading to great improvement in\nthe quality of marketing. The code has been available at\n\\url{https://github.com/easezyc/MetaHeac}.",
    "descriptor": "\nComments: accepted by KDD2021\n",
    "authors": [
      "Yongchun Zhu",
      "Yudan Liu",
      "Ruobing Xie",
      "Fuzhen Zhuang",
      "Xiaobo Hao",
      "Kaikai Ge",
      "Xu Zhang",
      "Leyu Lin",
      "Juan Cao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.14688"
  },
  {
    "id": "arXiv:2105.14693",
    "title": "Training Domain-invariant Object Detector Faster with Feature Replay and  Slow Learner",
    "abstract": "In deep learning-based object detection on remote sensing domain, nuisance\nfactors, which affect observed variables while not affecting predictor\nvariables, often matters because they cause domain changes. Previously,\nnuisance disentangled feature transformation (NDFT) was proposed to build\ndomain-invariant feature extractor with with knowledge of nuisance factors.\nHowever, NDFT requires enormous time in a training phase, so it has been\nimpractical. In this paper, we introduce our proposed method, A-NDFT, which is\nan improvement to NDFT. A-NDFT utilizes two acceleration techniques, feature\nreplay and slow learner. Consequently, on a large-scale UAVDT benchmark, it is\nshown that our framework can reduce the training time of NDFT from 31 hours to\n3 hours while still maintaining the performance. The code will be made publicly\navailable online.",
    "descriptor": "\nComments: 2021 CVPR Workshop\n",
    "authors": [
      "Chaehyeon Lee",
      "Junghoon Seo",
      "Heechul Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14693"
  },
  {
    "id": "arXiv:2105.14694",
    "title": "Combining resampling and reweighting for faithful stochastic  optimization",
    "abstract": "Many machine learning and data science tasks require solving non-convex\noptimization problems. When the loss function is a sum of multiple terms, a\npopular method is stochastic gradient descent. Viewed as a process for sampling\nthe loss function landscape, the stochastic gradient descent is known to prefer\nflat local minimums. Though this is desired for certain optimization problems\nsuch as in deep learning, it causes issues when the goal is to find the global\nminimum, especially if the global minimum resides in a sharp valley.\nIllustrated with a simple motivating example, we show that the fundamental\nreason is that the difference in the Lipschitz constants of multiple terms in\nthe loss function causes stochastic gradient descent to experience different\nvariances at different minimums. In order to mitigate this effect and perform\nfaithful optimization, we propose a combined resampling-reweighting scheme to\nbalance the variance at local minimums and extend to general loss functions. We\nalso explain from the stochastic asymptotics perspective how the proposed\nscheme is more likely to select the true global minimum when compared with the\nvanilla stochastic gradient descent. Experiments from robust statistics,\ncomputational chemistry, and neural network training are provided to\ndemonstrate the theoretical findings.",
    "descriptor": "",
    "authors": [
      "Jing An",
      "Lexing Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.14694"
  },
  {
    "id": "arXiv:2105.14695",
    "title": "Halt Properties and Complexity Evaluations for Optimal DeepLLL Algorithm  Families",
    "abstract": "DeepLLL algorithm (Schnorr, 1994) is a famous variant of LLL lattice basis\nreduction algorithm, and PotLLL algorithm (Fontein et al., 2014) and $S^2$LLL\nalgorithm (Yasuda and Yamaguchi, 2019) are recent polynomial-time variants of\nDeepLLL algorithm developed from cryptographic applications. However, the known\npolynomial bounds for computational complexity are shown only for parameter\n$\\delta < 1$; for \\lq\\lq optimal\\rq\\rq{} parameter $\\delta = 1$ which ensures\nthe best output quality, no polynomial bounds are known, and except for LLL\nalgorithm, it is even not formally proved that the algorithm always halts\nwithin finitely many steps. In this paper, we prove that these four algorithms\nalways halt also with optimal parameter $\\delta = 1$, and furthermore give\nexplicit upper bounds for the numbers of loops executed during the algorithms.\nUnlike the known bound (Akhavi, 2003) applicable to LLL algorithm only, our\nupper bounds are deduced in a unified way for all of the four algorithms.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Takuto Odagawa",
      "Koji Nuida"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14695"
  },
  {
    "id": "arXiv:2105.14697",
    "title": "An Automated Approach to the Collatz Conjecture",
    "abstract": "We explore the Collatz conjecture and its variants through the lens of\ntermination of string rewriting. We construct a rewriting system that simulates\nthe iterated application of the Collatz function on strings corresponding to\nmixed binary-ternary representations of positive integers. We prove that the\ntermination of this rewriting system is equivalent to the Collatz conjecture.\nWe also prove that a previously studied rewriting system that simulates the\nCollatz function using unary representations does not admit termination proofs\nvia matrix interpretations. To show the feasibility of our approach in proving\nmathematically interesting statements, we implement a minimal termination\nprover that uses matrix/arctic interpretations and we find automated proofs of\nnontrivial weakenings of the Collatz conjecture. Finally, we adapt our\nrewriting system to show that other open problems in mathematics can also be\napproached as termination problems for relatively small rewriting systems.\nAlthough we do not succeed in proving the Collatz conjecture, we believe that\nthe ideas here represent an interesting new approach.",
    "descriptor": "",
    "authors": [
      "Emre Yolcu",
      "Scott Aaronson",
      "Marijn J.H. Heule"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14697"
  },
  {
    "id": "arXiv:2105.14703",
    "title": "Myocardial ischemic effects on cardiac electro-mechanical activity",
    "abstract": "In this work, we investigated the effect of varying strength of Hyperkalemia\nand Hypoxia, in human cardiac tissue with a local ischemic subregion, on the\nelectrical and mechanical activity of healthy and ischemic zones of the cardiac\nmuscle. The Monodomain model in a deforming domain is taken with the addition\nof mechanical feedback and stretch-activated channel current coupled with the\nten Tusscher human ventricular membrane model. The equations of finite\nelasticity are used to describe the deformation of the cardiac tissue. The\nresulting coupled electro-mechanical PDEs-ODEs non-linear system is solved\nnumerically using finite elements in space and finite difference method in\ntime. We examined the effect of local ischemia on cardiac electrical and\nmechanical activity in different cases. We concluded that the spread of\nHyperkalemic or Hypoxic region alters the electro-mechanical coupling in terms\nof the action potential ($v$), intracellular calcium ion concentration\n$[Ca^{+2}]_i$, active tension, ($T_A$), stretch ($\\lambda$), stretch rate ($\n\\frac{d \\lambda}{dt}$). With the increase in the size of the ischemic region by\na factor of five, approximately $45\\%$ variation in the stretch rate $\\frac{d\n\\lambda}{dt}$ is noticed. It is also shown that ischemia affects the\ndeformation (expansion and contraction) of the heart.",
    "descriptor": "",
    "authors": [
      "B.V. Rathish Kumar",
      "Meena Pargaei",
      "Luca F. Pavarino",
      "Simone Scacchi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14703"
  },
  {
    "id": "arXiv:2105.14706",
    "title": "The Role of Entropy in Guiding a Connection Prover",
    "abstract": "In this work we study how to learn good algorithms for selecting reasoning\nsteps in theorem proving. We explore this in the connection tableau calculus\nimplemented by leanCoP where the partial tableau provides a clean and compact\nnotion of a state to which a limited number of inferences can be applied. We\nstart by incorporating a state-of-the-art learning algorithm -- a graph neural\nnetwork (GNN) -- into the plCoP theorem prover. Then we use it to observe the\nsystem's behaviour in a reinforcement learning setting, i.e., when learning\ninference guidance from successful Monte-Carlo tree searches on many problems.\nDespite its better pattern matching capability, the GNN initially performs\nworse than a simpler previously used learning algorithm. We observe that the\nsimpler algorithm is less confident, i.e., its recommendations have higher\nentropy. This leads us to explore how the entropy of the inference selection\nimplemented via the neural network influences the proof search. This is related\nto research in human decision-making under uncertainty, and in particular the\nprobability matching theory. Our main result shows that a proper entropy\nregularisation, i.e., training the GNN not to be overconfident, greatly\nimproves plCoP's performance on a large mathematical corpus.",
    "descriptor": "",
    "authors": [
      "Zsolt Zombori",
      "Josef Urban",
      "Miroslav Ol\u0161\u00e1k"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14706"
  },
  {
    "id": "arXiv:2105.14707",
    "title": "Emergence and algorithmic information dynamics of systems and observers",
    "abstract": "Previous work has shown that perturbation analysis in algorithmic information\ndynamics can uncover generative causal processes of finite objects and quantify\neach of its element's information contribution to computably constructing the\nobjects. One of the challenges for defining emergence is that the dependency on\nthe observer's previous knowledge may cause a phenomenon to present itself as\nemergent for one observer at the same time that reducible for another observer.\nThus, in order to quantify emergence of algorithmic information in computable\ngenerative processes, perturbation analyses may inherit such a problem of the\ndependency on the observer's previous formal knowledge. In this sense, by\nformalizing the act of observing as mutual perturbations, the emergence of\nalgorithmic information becomes invariant, minimal, and robust to information\ncosts and distortions, while it indeed depends on the observer. Then, we\ndemonstrate that the unbounded increase of emergent algorithmic information\nimplies asymptotically observer-independent emergence, which eventually\novercomes any formal theory that any observer might devise. In addition, we\ndiscuss weak and strong emergence and analyze the concepts of\nobserver-dependent emergence and asymptotically observer-independent emergence\nfound in previous definitions and models in the literature of deterministic\ndynamical and computable systems.",
    "descriptor": "",
    "authors": [
      "Felipe S. Abrah\u00e3o",
      "Hector Zenil"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.14707"
  },
  {
    "id": "arXiv:2105.14708",
    "title": "On Dynamic Resource Allocation for Blockchain Assisted Federated  Learning over Wireless Channels",
    "abstract": "Blockchain assisted federated learning (BFL) has been widely studied as a\npromising technology to process data at the network edge in a distributed\nmanner. However, the study of BFL involves key challenges, including resource\nallocation and client scheduling. In this paper, we propose a BFL framework\nconsisting of multiple clients, where the roles of clients include local model\ntraining, wireless uploading, and block mining in each round. First, we develop\na renewal BFL framework to study the long-term system performance under\ntime-varying fading channels. Second, in order to speed up the BFL process with\nlimited communication, computation and energy resources, we propose a dynamic\nresource allocation and client scheduling (DRACS) algorithm based on Lyapunov\noptimization to maximize the training data size under energy consumption\nconstraints, by jointly optimizing the allocation of communication,\ncomputation, and energy resources. For the DRACS algorithm, we characterize a\ntrade-off of [$\\mathcal{O}(1/V)$, $\\mathcal{O}(\\sqrt{V})$] between the training\ndata size and energy consumption to balance the maximization of training data\nsize and the minimization of energy consumption. Our experimental results show\nthat the DRACS algorithm can provide both higher learning accuracy and faster\nconvergence with limited time and energy based on the MNIST and Fashion-MNIST\ndatasets.",
    "descriptor": "",
    "authors": [
      "Xiumei Deng",
      "Jun Li",
      "Chuan Ma",
      "Kang Wei",
      "Long Shi",
      "Ming Ding",
      "Wen Chen",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.14708"
  },
  {
    "id": "arXiv:2105.14709",
    "title": "Joint Stabilization and Regret Minimization through Switching in Systems  with Actuator Redundancy",
    "abstract": "Adaptively controlling and minimizing regret in unknown dynamical systems\nwhile controlling the growth of the system state is crucial in real-world\napplications. In this work, we study the problem of stabilizing and regret\nminimization of linear dynamical systems with system-level actuator redundancy.\nWe propose an optimism-based algorithm that utilizes the actuator redundancy\nand the possibility of switching between actuating modes to guarantee the\nboundedness of the state. This is in contrast to the prior works that may\nresult in an exponential (in system dimension) explosion of the state of the\nsystem. We theoretically study the rate at which our algorithm learns a\nstabilizing controller and prove that it achieves a regret upper bound of\n$\\mathcal{O}(\\sqrt{T})$.",
    "descriptor": "",
    "authors": [
      "Jafar Abbaszadeh Chekan",
      "Kamyar Azizzadenesheli",
      "Cedric Langbort"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14709"
  },
  {
    "id": "arXiv:2105.14710",
    "title": "Robustifying $\\ell_\\infty$ Adversarial Training to the Union of  Perturbation Models",
    "abstract": "Classical adversarial training (AT) frameworks are designed to achieve high\nadversarial accuracy against a single attack type, typically $\\ell_\\infty$\nnorm-bounded perturbations. Recent extensions in AT have focused on defending\nagainst the union of multiple perturbations but this benefit is obtained at the\nexpense of a significant (up to $10\\times$) increase in training complexity\nover single-attack $\\ell_\\infty$ AT. In this work, we expand the capabilities\nof widely popular single-attack $\\ell_\\infty$ AT frameworks to provide\nrobustness to the union of ($\\ell_\\infty, \\ell_2, \\ell_1$) perturbations while\npreserving their training efficiency. Our technique, referred to as Shaped\nNoise Augmented Processing (SNAP), exploits a well-established byproduct of\nsingle-attack AT frameworks -- the reduction in the curvature of the decision\nboundary of networks. SNAP prepends a given deep net with a shaped noise\naugmentation layer whose distribution is learned along with network parameters\nusing any standard single-attack AT. As a result, SNAP enhances adversarial\naccuracy of ResNet-18 on CIFAR-10 against the union of ($\\ell_\\infty, \\ell_2,\n\\ell_1$) perturbations by 14%-to-20% for four state-of-the-art (SOTA)\nsingle-attack $\\ell_\\infty$ AT frameworks, and, for the first time, establishes\na benchmark for ResNet-50 and ResNet-101 on ImageNet.",
    "descriptor": "",
    "authors": [
      "Ameya D. Patil",
      "Michael Tuttle",
      "Alexander G. Schwing",
      "Naresh R. Shanbhag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14710"
  },
  {
    "id": "arXiv:2105.14713",
    "title": "1$\\times$N Block Pattern for Network Sparsity",
    "abstract": "Though network sparsity emerges as a promising direction to overcome the\ndrastically increasing size of neural networks, it remains an open problem to\nconcurrently maintain model accuracy as well as achieve significant speedups on\ngeneral CPUs. In this paper, we propose one novel concept of $1\\times N$ block\nsparsity pattern (block pruning) to break this limitation. In particular,\nconsecutive $N$ output kernels with the same input channel index are grouped\ninto one block, which serves as a basic pruning granularity of our pruning\npattern. Our $1 \\times N$ sparsity pattern prunes these blocks considered\nunimportant. We also provide a workflow of filter rearrangement that first\nrearranges the weight matrix in the output channel dimension to derive more\ninfluential blocks for accuracy improvements, and then applies similar\nrearrangement to the next-layer weights in the input channel dimension to\nensure correct convolutional operations. Moreover, the output computation after\nour $1 \\times N$ block sparsity can be realized via a parallelized block-wise\nvectorized operation, leading to significant speedups on general CPUs-based\nplatforms. The efficacy of our pruning pattern is proved with experiments on\nILSVRC-2012. For example, in the case of 50% sparsity and $N=4$, our pattern\nobtains about 3.0% improvements over filter pruning in the top-1 accuracy of\nMobileNet-V2. Meanwhile, it obtains 56.04ms inference savings on Cortex-A7 CPU\nover weight pruning. Code is available at https://github.com/lmbxmu/1xN.",
    "descriptor": "",
    "authors": [
      "Mingbao Lin",
      "Yuchao Li",
      "Yuxin Zhang",
      "Bohong Chen",
      "Fei Chao",
      "Mengdi Wang",
      "Shen Li",
      "Jun Yang",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14713"
  },
  {
    "id": "arXiv:2105.14716",
    "title": "Improving the Accuracy and Efficiency of Online Calibration for  Simulation-based Dynamic Traffic Assignment",
    "abstract": "Simulation-based Dynamic Traffic Assignment models have important\napplications in real-time traffic management and control. The efficacy of these\nsystems rests on the ability to generate accurate estimates and predictions of\ntraffic states, which necessitates online calibration. A widely used solution\napproach for online calibration is the Extended Kalman Filter (EKF), which --\nalthough appealing in its flexibility to incorporate any class of parameters\nand measurements -- poses several challenges with regard to calibration\naccuracy and scalability, especially in congested situations for large-scale\nnetworks. This paper addresses these issues in turn so as to improve the\naccuracy and efficiency of EKF-based online calibration approaches for large\nand congested networks. First, the concept of state augmentation is revisited\nto handle violations of the Markovian assumption typically implicit in online\napplications of the EKF. Second, a method based on graph-coloring is proposed\nto operationalize the partitioned finite-difference approach that enhances\nscalability of the gradient computations.\nSeveral synthetic experiments and a real world case study demonstrate that\napplication of the proposed approaches yields improvements in terms of both\nprediction accuracy and computational performance. The work has applications in\nreal-world deployments of simulation-based dynamic traffic assignment systems.",
    "descriptor": "\nComments: 26 pages, 15 figures\n",
    "authors": [
      "Haizheng Zhang",
      "Ravi Seshadri",
      "A. Arun Prakash",
      "Constantinos Antoniou",
      "Francisco C. Pereira",
      "Moshe Ben-Akiva"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.14716"
  },
  {
    "id": "arXiv:2105.14717",
    "title": "Multi-Scale Temporal Convolution Network for Classroom Voice Detection",
    "abstract": "Teaching with the cooperation of expert teacher and assistant teacher, which\nis the so-called \"double-teachers classroom\", i.e., the course is giving by the\nexpert online and presented through projection screen at the classroom, and the\nteacher at the classroom performs as an assistant for guiding the students in\nlearning, is becoming more prevalent in today's teaching method for K-12\neducation. For monitoring the teaching quality, a microphone clipped on the\nassistant's neckline is always used for voice recording, then fed to the\ndownstream tasks of automatic speech recognition (ASR) and neural language\nprocessing (NLP). However, besides its voice, there would be some other\ninterfering voices, including the expert's one and the student's one. Here, we\npropose to extract the assistant' voices from the perspective of sound event\ndetection, i.e., the voices are classified into four categories, namely the\nexpert, the teacher, the mixture of them, and the background. To make\nframe-level identification, which is important for grabbing sensitive words for\nthe downstream tasks, a multi-scale temporal convolution neural network is\nconstructed with stacked dilated convolutions for considering both local and\nglobal properties. These features are concatenated and fed to a classification\nnetwork constructed by three linear layers. The framework is evaluated on\nsimulated data and real-world recordings, giving considerable performance in\nterms of precision and recall, compared with some classical classification\nmethods.",
    "descriptor": "\nComments: 5 pages, 2 figures, 1 table\n",
    "authors": [
      "Lu Ma",
      "Xintian Wang",
      "Song Yang",
      "Yaguang Gong",
      "Zhongqin Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.14717"
  },
  {
    "id": "arXiv:2105.14719",
    "title": "Noise Classification Aided Attention-Based Neural Network for Monaural  Speech Enhancement",
    "abstract": "This paper proposes an noise type classification aided attention-based neural\nnetwork approach for monaural speech enhancement. The network is constructed\nbased on a previous work by introducing a noise classification subnetwork into\nthe structure and taking the classification embedding into the attention\nmechanism for guiding the network to make better feature extraction.\nSpecifically, to make the network an end-to-end way, an audio encoder and\ndecoder constructed by temporal convolution is used to make transformation\nbetween waveform and spectrogram. Additionally, our model is composed of two\nlong short term memory (LSTM) based encoders, two attention mechanism, a noise\nclassifier and a speech mask generator. Experiments show that, compared with\nOM-LSA and the previous work, the proposed noise classification aided\nattention-based approach can achieve better performance in terms of speech\nquality (PESQ). More promisingly, our approach has better generalization\nability to unseen noise conditions.",
    "descriptor": "\nComments: 2 figures, 3 tables\n",
    "authors": [
      "Lu Ma",
      "Song Yang",
      "Yaguang Gong",
      "Zhongqin Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.14719"
  },
  {
    "id": "arXiv:2105.14720",
    "title": "Energy-preserving fully-discrete schemes for nonlinear stochastic wave  equations with multiplicative noise",
    "abstract": "In this paper, we focus on constructing numerical schemes preserving the\naveraged energy evolution law for nonlinear stochastic wave equations driven by\nmultiplicative noise. We first apply the compact finite difference method and\nthe interior penalty discontinuous Galerkin finite element method to discretize\nspace variable and present two semi-discrete schemes, respectively. Then we\nmake use of the discrete gradient method and Pad\\'e approximation and propose\nefficient fully-discrete schemes. These semi-discrete and fully-discrete\nschemes are proved to preserve the discrete averaged energy evolution law, In\nparticular, we also prove that the proposed fully-discrete schemes exactly\ninherit the averaged energy evolution law almost surely if the considered model\nis driven by additive noise. Numerical experiments are given to confirm\ntheoretical findings.",
    "descriptor": "",
    "authors": [
      "Jialin Hong",
      "Baohui Hou",
      "Liying Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14720"
  },
  {
    "id": "arXiv:2105.14727",
    "title": "Transferable Sparse Adversarial Attack",
    "abstract": "Deep neural networks have shown their vulnerability to adversarial attacks.\nIn this paper, we focus on sparse adversarial attack based on the $\\ell_0$ norm\nconstraint, which can succeed by only modifying a few pixels of an image.\nDespite a high attack success rate, prior sparse attack methods achieve a low\ntransferability under the black-box protocol due to overfitting the target\nmodel. Therefore, we introduce a generator architecture to alleviate the\noverfitting issue and thus efficiently craft transferable sparse adversarial\nexamples. Specifically, the generator decouples the sparse perturbation into\namplitude and position components. We carefully design a random quantization\noperator to optimize these two components jointly in an end-to-end way. The\nexperiment shows that our method has improved the transferability by a large\nmargin under a similar sparsity setting compared with state-of-the-art methods.\nMoreover, our method achieves superior inference speed, 700$\\times$ faster than\nother optimization-based methods. The code is available at\nhttps://github.com/shaguopohuaizhe/TSAA.",
    "descriptor": "",
    "authors": [
      "Ziwen He",
      "Wei Wang",
      "Jing Dong",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14727"
  },
  {
    "id": "arXiv:2105.14730",
    "title": "Transfer Learning as an Enhancement for Reconfiguration Management of  Cyber-Physical Production Systems",
    "abstract": "Reconfiguration demand is increasing due to frequent requirement changes for\nmanufacturing systems. Recent approaches aim at investigating feasible\nconfiguration alternatives from which they select the optimal one. This relies\non processes whose behavior is not reliant on e.g. the production sequence.\nHowever, when machine learning is used, components' behavior depends on the\nprocess' specifics, requiring additional concepts to successfully conduct\nreconfiguration management. Therefore, we propose the enhancement of the\ncomprehensive reconfiguration management with transfer learning. This provides\nthe ability to assess the machine learning dependent behavior of the different\nCPPS configurations with reduced effort and further assists the recommissioning\nof the chosen one. A real cyber-physical production system from the discrete\nmanufacturing domain is utilized to demonstrate the aforementioned proposal.",
    "descriptor": "\nComments: 6 pages, 4 figures, 1 table. Submitted for publication at CIRP ICME 2021\n",
    "authors": [
      "Benjamin Maschler",
      "Timo M\u00fcller",
      "Andreas L\u00f6cklin",
      "Michael Weyrich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14730"
  },
  {
    "id": "arXiv:2105.14731",
    "title": "Deep Reinforcement Based Optimization of Function Splitting in  Virtualized Radio Access Networks",
    "abstract": "Virtualized Radio Access Network (vRAN) is one of the key enablers of future\nwireless networks as it brings the agility to the radio access network (RAN)\narchitecture and offers degrees of design freedom. Yet, it also creates a\nchallenging problem on how to design the functional split configuration. In\nthis paper, a deep reinforcement learning approach is proposed to optimize\nfunction splitting in vRAN. A learning paradigm is developed that optimizes the\nlocation of functions in the RAN. These functions can be placed either at a\ncentral/cloud unit (CU) or a distributed unit (DU). This problem is formulated\nas constrained neural combinatorial reinforcement learning to minimize the\ntotal network cost. In this solution, a policy gradient method with Lagrangian\nrelaxation is applied that uses a stacked long short-term memory (LSTM) neural\nnetwork architecture to approximate the policy. Then, a sampling technique with\na temperature hyperparameter is applied for the inference process. The results\nshow that our proposed solution can learn the optimal function split decision\nand solve the problem with a $0.4\\%$ optimality gap. Moreover, our method can\nreduce the cost by up to $320\\%$ compared to a distributed-RAN (D-RAN). We also\nconclude that altering the traffic load and routing cost does not significantly\ndegrade the optimality performance.",
    "descriptor": "\nComments: This paper has been accepted in IEEE International Conference on Communications Workshops (ICC Workshops) 2021\n",
    "authors": [
      "Fahri Wisnu Murti",
      "Samad Ali",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.14731"
  },
  {
    "id": "arXiv:2105.14734",
    "title": "Dual-stream Network for Visual Recognition",
    "abstract": "Transformers with remarkable global representation capacities achieve\ncompetitive results for visual tasks, but fail to consider high-level local\npattern information in input images. In this paper, we present a generic\nDual-stream Network (DS-Net) to fully explore the representation capacity of\nlocal and global pattern features for image classification. Our DS-Net can\nsimultaneously calculate fine-grained and integrated features and efficiently\nfuse them. Specifically, we propose an Intra-scale Propagation module to\nprocess two different resolutions in each block and an Inter-Scale Alignment\nmodule to perform information interaction across features at dual scales.\nBesides, we also design a Dual-stream FPN (DS-FPN) to further enhance\ncontextual information for downstream dense predictions. Without bells and\nwhistles, the propsed DS-Net outperforms Deit-Small by 2.4% in terms of top-1\naccuracy on ImageNet-1k and achieves state-of-the-art performance over other\nVision Transformers and ResNets. For object detection and instance\nsegmentation, DS-Net-Small respectively outperforms ResNet-50 by 6.4% and 5.5 %\nin terms of mAP on MSCOCO 2017, and surpasses the previous state-of-the-art\nscheme, which significantly demonstrates its potential to be a general backbone\nin vision tasks. The code will be released soon.",
    "descriptor": "",
    "authors": [
      "Mingyuan Mao",
      "Renrui Zhang",
      "Honghui Zheng",
      "Peng Gao",
      "Teli Ma",
      "Yan Peng",
      "Errui Ding",
      "Shumin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14734"
  },
  {
    "id": "arXiv:2105.14737",
    "title": "Semi-orthogonal Embedding for Efficient Unsupervised Anomaly  Segmentation",
    "abstract": "We present the efficiency of semi-orthogonal embedding for unsupervised\nanomaly segmentation. The multi-scale features from pre-trained CNNs are\nrecently used for the localized Mahalanobis distances with significant\nperformance. However, the increased feature size is problematic to scale up to\nthe bigger CNNs, since it requires the batch-inverse of multi-dimensional\ncovariance tensor. Here, we generalize an ad-hoc method, random feature\nselection, into semi-orthogonal embedding for robust approximation, cubically\nreducing the computational cost for the inverse of multi-dimensional covariance\ntensor. With the scrutiny of ablation studies, the proposed method achieves a\nnew state-of-the-art with significant margins for the MVTec AD, KolektorSDD,\nKolektorSDD2, and mSTC datasets. The theoretical and empirical analyses offer\ninsights and verification of our straightforward yet cost-effective approach.",
    "descriptor": "",
    "authors": [
      "Jin-Hwa Kim",
      "Do-Hyeong Kim",
      "Saehoon Yi",
      "Taehoon Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14737"
  },
  {
    "id": "arXiv:2105.14739",
    "title": "Controllable Person Image Synthesis with Spatially-Adaptive Warped  Normalization",
    "abstract": "Controllable person image generation aims to produce realistic human images\nwith desirable attributes (e.g., the given pose, cloth textures or hair style).\nHowever, the large spatial misalignment between the source and target images\nmakes the standard architectures for image-to-image translation not suitable\nfor this task. Most of the state-of-the-art architectures avoid the alignment\nstep during the generation, which causes many artifacts, especially for person\nimages with complex textures. To solve this problem, we introduce a novel\nSpatially-Adaptive Warped Normalization (SAWN), which integrates a learned\nflow-field to warp modulation parameters. This allows us to align person\nspatial-adaptive styles with pose features efficiently. Moreover, we propose a\nnovel self-training part replacement strategy to refine the pretrained model\nfor the texture-transfer task, significantly improving the quality of the\ngenerated cloth and the preservation ability of irrelevant regions. Our\nexperimental results on the widely used DeepFashion dataset demonstrate a\nsignificant improvement of the proposed method over the state-of-the-art\nmethods on both pose-transfer and texture-transfer tasks.",
    "descriptor": "",
    "authors": [
      "Jichao Zhang",
      "Aliaksandr Siarohin",
      "Hao Tang",
      "Jingjing Chen",
      "Enver Sangineto",
      "Wei Wang",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2105.14739"
  },
  {
    "id": "arXiv:2105.14740",
    "title": "A Study On the Effects of Pre-processing On Spatio-temporal Action  Recognition Using Spiking Neural Networks Trained with STDP",
    "abstract": "There has been an increasing interest in spiking neural networks in recent\nyears. SNNs are seen as hypothetical solutions for the bottlenecks of ANNs in\npattern recognition, such as energy efficiency. But current methods such as\nANN-to-SNN conversion and back-propagation do not take full advantage of these\nnetworks, and unsupervised methods have not yet reached a success comparable to\nadvanced artificial neural networks. It is important to study the behavior of\nSNNs trained with unsupervised learning methods such as spike-timing dependent\nplasticity (STDP) on video classification tasks, including mechanisms to model\nmotion information using spikes, as this information is critical for video\nunderstanding. This paper presents multiple methods of transposing temporal\ninformation into a static format, and then transforming the visual information\ninto spikes using latency coding. These methods are paired with two types of\ntemporal fusion known as early and late fusion, and are used to help the\nspiking neural network in capturing the spatio-temporal features from videos.\nIn this paper, we rely on the network architecture of a convolutional spiking\nneural network trained with STDP, and we test the performance of this network\nwhen challenged with action recognition tasks. Understanding how a spiking\nneural network responds to different methods of movement extraction and\nrepresentation can help reduce the performance gap between SNNs and ANNs. In\nthis paper we show the effect of the similarity in the shape and speed of\ncertain actions on action recognition with spiking neural networks, we also\nhighlight the effectiveness of some methods compared to others.",
    "descriptor": "",
    "authors": [
      "El-Assal Mireille",
      "Tirilly Pierre",
      "Bilasco Ioan Marius"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14740"
  },
  {
    "id": "arXiv:2105.14741",
    "title": "An Adaptive Demand Response Framework using Price Elasticity Model in  Distribution Networks: A Case Study",
    "abstract": "Price elasticity model (PEM) is an appealing and modest model for assessing\nthe potential of flexible demand in DR. It measures the customers demand\nsensitivity through elasticity in relation to price variation. However,\napplication of PEM in DR is partially apprehensible on attributing the\nadaptability and adjustability with intertemporal constraints in DR. Thus, this\narticle presents an adaptive economic DR framework with attributes of DR via a\ndynamic elasticity approach to model customers sensitivity. This dynamic\nelasticity is modeled through the deterministic and stochastic approaches. Both\napproaches envision the notion of load recovery for shiftable/flexible loads to\nmake the proposed DR framework adaptive and adjustable relative to price\nvariation. In stochastic approach, a geometric Brownian motion is employed to\nemulate load recovery with inclusion of intertemporal constraint of load\nflexibility. The proposed mathematical model shows what should be the customers\nelasticity value to achieve the factual DR. The case study is carried out on\nstandard IEEE 33 distribution system bus load data to assess technical and\nsocio-economic impact of DR on customers and is also compared with the exiting\nmodel.",
    "descriptor": "",
    "authors": [
      "Vipin Chandra Pandey",
      "Nikhil Gupta",
      "K. R. Niazi",
      "Anil Swarnkar",
      "Rayees Ahmad Thokar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14741"
  },
  {
    "id": "arXiv:2105.14748",
    "title": "Diffy: Inductive Reasoning of Array Programs using Difference Invariants",
    "abstract": "We present a novel verification technique to prove interesting properties of\na class of array programs with a symbolic parameter N denoting the size of the\narray. The technique relies on constructing two slightly different versions of\nthe program. It infers difference relations between the corresponding variables\nat key control points of the joint control-flow graph of the two program\nversions. The inferred difference invaraints are agnostic of the post-condition\nto be proved and are typically much simpler than the inductive invariants\nneeded for proving the post-condition directly. We formulate a new technique to\nprove the desired post-condition by inducting on the program parameter N, in\nwhich the difference invariants are crucially used in the key inductive step.\nThis contrasts with classical techniques that rely on finding potentially\ncomplex loop invaraints for each loop in the program. Our synergistic\ncombination of inductive reasoning and finding simple difference invariants\nhelps prove properties of programs that cannot be proved even by the winner of\nArrays sub-category from SV-COMP 2021. We have implemented a prototype tool\ncalled diffy to demonstrate these ideas. We show the results on a set of\nbenchmarks and compare its performance vis-a-vis state-of-the-art tools for\nverifying array programs.",
    "descriptor": "\nComments: arXiv version of the paper accepted at CAV 2021\n",
    "authors": [
      "Supratik Chakraborty",
      "Ashutosh Gupta",
      "Divyesh Unadkat"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14748"
  },
  {
    "id": "arXiv:2105.14750",
    "title": "Efficient Hierarchical Exploration with Stable Subgoal Representation  Learning",
    "abstract": "Goal-conditioned hierarchical reinforcement learning (HRL) serves as a\nsuccessful approach to solving complex and temporally extended tasks. Recently,\nits success has been extended to more general settings by concurrently learning\nhierarchical policies and subgoal representations. However, online subgoal\nrepresentation learning exacerbates the non-stationary issue of HRL and\nintroduces challenges for exploration in high-level policy learning. In this\npaper, we propose a state-specific regularization that stabilizes subgoal\nembeddings in well-explored areas while allowing representation updates in less\nexplored state regions. Benefiting from this stable representation, we design\nmeasures of novelty and potential for subgoals, and develop an efficient\nhierarchical exploration strategy that actively seeks out new promising\nsubgoals and states. Experimental results show that our method significantly\noutperforms state-of-the-art baselines in continuous control tasks with sparse\nrewards and further demonstrate the stability and efficiency of the subgoal\nrepresentation learning of this work, which promotes superior policy learning.",
    "descriptor": "",
    "authors": [
      "Siyuan Li",
      "Jin Zhang",
      "Jianhao Wang",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14750"
  },
  {
    "id": "arXiv:2105.14753",
    "title": "Bio-inspired visual attention for silicon retinas based on spiking  neural networks applied to pattern classification",
    "abstract": "Visual attention can be defined as the behavioral and cognitive process of\nselectively focusing on a discrete aspect of sensory cues while disregarding\nother perceivable information. This biological mechanism, more specifically\nsaliency detection, has long been used in multimedia indexing to drive the\nanalysis only on relevant parts of images or videos for further processing.\nThe recent advent of silicon retinas (or event cameras -- sensors that\nmeasure pixel-wise changes in brightness and output asynchronous events\naccordingly) raises the question of how to adapt attention and saliency to the\nunconventional type of such sensors' output. Silicon retina aims to reproduce\nthe biological retina behaviour. In that respect, they produce punctual events\nin time that can be construed as neural spikes and interpreted as such by a\nneural network.\nIn particular, Spiking Neural Networks (SNNs) represent an asynchronous type\nof artificial neural network closer to biology than traditional artificial\nnetworks, mainly because they seek to mimic the dynamics of neural membrane and\naction potentials over time. SNNs receive and process information in the form\nof spike trains. Therefore, they make for a suitable candidate for the\nefficient processing and classification of incoming event patterns measured by\nsilicon retinas. In this paper, we review the biological background behind the\nattentional mechanism, and introduce a case study of event videos\nclassification with SNNs, using a biology-grounded low-level computational\nattention mechanism, with interesting preliminary results.",
    "descriptor": "\nComments: 6 pages, 3 figures. To be published in Content-Based Multimedia Indexing (CBMI) 2021, Lille, France. This work was supported by the European Union's ERA-NET CHIST-ERA 2018 research and innovation programme under grant agreement ANR-19-CHR3-0008\n",
    "authors": [
      "Am\u00e9lie Gruel",
      "Jean Martinet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.14753"
  },
  {
    "id": "arXiv:2105.14754",
    "title": "List-decoding and list-recovery of Reed-Solomon codes beyond the Johnson  radius for any rate",
    "abstract": "Understanding the limits of list-decoding and list-recovery of Reed-Solomon\n(RS) codes is of prime interest in coding theory and has attracted a lot of\nattention in recent decades. However, the best possible parameters for these\nproblems are still unknown, and in this paper, we take a step in this\ndirection. We show the existence of RS codes that are list-decodable or\nlist-recoverable beyond the Johnson radius for \\emph{any} rate, with a\npolynomial field size in the block length. In particular, we show that for any\n$\\epsilon\\in (0,1)$ there exist RS codes that are list-decodable from radius\n$1-\\epsilon$ and rate less than $\\frac{\\epsilon}{2-\\epsilon}$, with constant\nlist size. We deduce our results by extending and strengthening a recent result\nof Ferber, Kwan, and Sauermann on puncturing codes with large minimum distance\nand by utilizing the underlying code's linearity.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Eitan Goldberg",
      "Chong Shangguan",
      "Itzhak Tamo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.14754"
  },
  {
    "id": "arXiv:2105.14755",
    "title": "Parallel transport dynamics for mixed quantum states with applications  to time-dependent density functional theory",
    "abstract": "Direct simulation of the von Neumann dynamics for a general (pure or mixed)\nquantum state can often be expensive. One prominent example is the real-time\ntime-dependent density functional theory (rt-TDDFT), a widely used framework\nfor the first principle description of many-electron dynamics in chemical and\nmaterials systems. Practical rt-TDDFT calculations often avoid the direct\nsimulation of the von Neumann equation, and solve instead a set of\nSchr\\\"odinger equations, of which the dynamics is equivalent to that of the von\nNeumann equation. However, the time step size employed by the Schr\\\"odinger\ndynamics is often much smaller. In order to improve the time step size and the\noverall efficiency of the simulation, we generalize a recent work of the\nparallel transport (PT) dynamics for simulating pure states [An, Lin,\nMultiscale Model. Simul. 18, 612, 2020] to general quantum states. The PT\ndynamics provides the optimal gauge choice, and can employ a time step size\ncomparable to that of the von Neumann dynamics. Going beyond the linear and\nnear adiabatic regime in previous studies, we find that the error of the PT\ndynamics can be bounded by certain commutators between Hamiltonians, density\nmatrices, and their derived quantities. Such a commutator structure is not\npresent in the Schr\\\"odinger dynamics. We demonstrate that the parallel\ntransport-implicit midpoint (PT-IM) method is a suitable method for simulating\nthe PT dynamics, especially when the spectral radius of the Hamiltonian is\nlarge. The commutator structure of the error bound, and numerical results for\nmodel rt-TDDFT calculations in both linear and nonlinear regimes, confirm the\nadvantage of the PT dynamics.",
    "descriptor": "",
    "authors": [
      "Dong An",
      "Di Fang",
      "Lin Lin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.14755"
  },
  {
    "id": "arXiv:2105.14756",
    "title": "A Protection Method of Trained CNN Model with Secret Key from  Unauthorized Access",
    "abstract": "In this paper, we propose a novel method for protecting convolutional neural\nnetwork (CNN) models with a secret key set so that unauthorized users without\nthe correct key set cannot access trained models. The method enables us to\nprotect not only from copyright infringement but also the functionality of a\nmodel from unauthorized access without any noticeable overhead. We introduce\nthree block-wise transformations with a secret key set to generate learnable\ntransformed images: pixel shuffling, negative/positive transformation, and FFX\nencryption. Protected models are trained by using transformed images. The\nresults of experiments with the CIFAR and ImageNet datasets show that the\nperformance of a protected model was close to that of non-protected models when\nthe key set was correct, while the accuracy severely dropped when an incorrect\nkey set was given. The protected model was also demonstrated to be robust\nagainst various attacks. Compared with the state-of-the-art model protection\nwith passports, the proposed method does not have any additional layers in the\nnetwork, and therefore, there is no overhead during training and inference\nprocesses.",
    "descriptor": "",
    "authors": [
      "AprilPyone MaungMaung",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14756"
  },
  {
    "id": "arXiv:2105.14759",
    "title": "The x-index: A new citation-distance-based index to measure academic  influence",
    "abstract": "An important issue in the field of academic measurement is how to evaluate\nacademic influence scientifically and comprehensively, which can help\ngovernment and research organizations better allocate academic resources and\nrecruit researchers. It is generally accepted that using weighted citations to\nmeasure academic influence is more reasonable than treating all citations\nequally. Given the limitations of the existing c-index, the first index in\nbibliometric literature that measures output based on the quantity and quality\nof received citations, we propose the x-index, which assigns weight to each\ncitation according to its distance. By defining collaboration distance and\ncitation distance, we first analyze the properties of the collaboration network\nand citation distance, then perform theoretical and empirical analyses on\nc-index to reveal its shortcomings, finally, we suggest the x-index and conduct\nexperiments and analysis on the x-index. Experimental results demonstrate that\ncompared with the c-index, h-index, and g-index, the x-index shows a stronger\ndiscriminatory power.",
    "descriptor": "",
    "authors": [
      "Yun Wan",
      "Feng Xiao",
      "Bintong Chen",
      "Zhenghao Zhong"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.14759"
  },
  {
    "id": "arXiv:2105.14761",
    "title": "G-Transformer for Document-level Machine Translation",
    "abstract": "Document-level MT models are still far from satisfactory. Existing work\nextend translation unit from single sentence to multiple sentences. However,\nstudy shows that when we further enlarge the translation unit to a whole\ndocument, supervised training of Transformer can fail. In this paper, we find\nsuch failure is not caused by overfitting, but by sticking around local minima\nduring training. Our analysis shows that the increased complexity of\ntarget-to-source attention is a reason for the failure. As a solution, we\npropose G-Transformer, introducing locality assumption as an inductive bias\ninto Transformer, reducing the hypothesis space of the attention from target to\nsource. Experiments show that G-Transformer converges faster and more stably\nthan Transformer, achieving new state-of-the-art BLEU scores for both\nnon-pretraining and pre-training settings on three benchmark datasets.",
    "descriptor": "\nComments: Accepted by ACL2021 main track\n",
    "authors": [
      "Guangsheng Bao",
      "Yue Zhang",
      "Zhiyang Teng",
      "Boxing Chen",
      "Weihua Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14761"
  },
  {
    "id": "arXiv:2105.14762",
    "title": "Emotional Voice Conversion: Theory, Databases and ESD",
    "abstract": "In this paper, we first provide a review of the state-of-the-art emotional\nvoice conversion research, and the existing emotional speech databases. We then\nmotivate the development of a novel emotional speech database (ESD) that\naddresses the increasing research need. With this paper, the ESD database is\nnow made available to the research community. The ESD database consists of 350\nparallel utterances spoken by 10 native English and 10 native Chinese speakers\nand covers 5 emotion categories (neutral, happy, angry, sad and surprise). More\nthan 29 hours of speech data were recorded in a controlled acoustic\nenvironment. The database is suitable for multi-speaker and cross-lingual\nemotional voice conversion studies. As case studies, we implement several\nstate-of-the-art emotional voice conversion systems on the ESD database. This\npaper provides a reference study on ESD in conjunction with its release.",
    "descriptor": "\nComments: Submitted to Speech Communication\n",
    "authors": [
      "Kun Zhou",
      "Berrak Sisman",
      "Rui Liu",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14762"
  },
  {
    "id": "arXiv:2105.14764",
    "title": "Bimanual Shelf Picking Planner Based on Collapse Prediction",
    "abstract": "In logistics warehouse, since many objects are randomly stacked on shelves,\nit becomes difficult for a robot to safely extract one of the objects without\nother objects falling from the shelf. In previous works, a robot needed to\nextract the target object after rearranging the neighboring objects. In\ncontrast, humans extract an object from a shelf while supporting other\nneighboring objects. In this paper, we propose a bimanual manipulation planner\nbased on collapse prediction trained with data generated from a physics\nsimulator, which can safely extract a single object while supporting the other\nobject. We confirmed that the proposed method achieves more than 80% success\nrate for safe extraction by real-world experiments using a dual-arm\nmanipulator.",
    "descriptor": "\nComments: 6 pages with 9 figures and 2 tables\n",
    "authors": [
      "T. Motoda",
      "D. Petit",
      "W. Wan",
      "K. Harada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14764"
  },
  {
    "id": "arXiv:2105.14768",
    "title": "Securing IoT Devices by Exploiting Backscatter Propagation Signatures",
    "abstract": "The low-power radio technologies open up many opportunities to facilitate\nInternet-of-Things (IoT) into our daily life, while their minimalist design\nalso makes IoT devices vulnerable to many active attacks. Recent advances use\nan antenna array to extract fine-grained physical-layer signatures to identify\nthe attackers, which adds burdens in terms of energy and hardware cost to IoT\ndevices. In this paper, we present ShieldScatter, a lightweight system that\nattaches low-cost tags to single-antenna devices to shield the system from\nactive attacks. The key insight of ShieldScatter is to intentionally create\nmulti-path propagation signatures with the careful deployment of tags. These\nsignatures can be used to construct a sensitive profile to identify the\nlocation of the signals' arrival, and thus detect the threat. In addition, we\nalso design a tag-random scheme and a multiple receivers combination approach\nto detect a powerful attacker who has the strong priori knowledge of the\nlegitimate user. We prototype ShieldScatter with USRPs and tags to evaluate our\nsystem in various environments. The results show that even when the powerful\nattacker is close to the legitimate device, ShieldScatter can mitigate 95% of\nattack attempts while triggering false alarms on just 7% of legitimate traffic.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1810.07058\n",
    "authors": [
      "Zhiqing Luo",
      "Wei Wang",
      "Qianyi Huang",
      "Tao Jiang",
      "Qian Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14768"
  },
  {
    "id": "arXiv:2105.14769",
    "title": "Gillian: A Multi-Language Platform for Unified Symbolic Analysis",
    "abstract": "This is an evolving document describing the meta-theory, the implementation,\nand the instantiations of Gillian, a multi-language symbolic analysis platform.",
    "descriptor": "",
    "authors": [
      "Petar Maksimovi\u0107",
      "Jos\u00e9 Fragoso Santos",
      "Sacha-\u00c9lie Ayoun",
      "Philippa Gardner"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14769"
  },
  {
    "id": "arXiv:2105.14772",
    "title": "Energy-Efficient and Federated Meta-Learning via Projected Stochastic  Gradient Ascent",
    "abstract": "In this paper, we propose an energy-efficient federated meta-learning\nframework. The objective is to enable learning a meta-model that can be\nfine-tuned to a new task with a few number of samples in a distributed setting\nand at low computation and communication energy consumption. We assume that\neach task is owned by a separate agent, so a limited number of tasks is used to\ntrain a meta-model. Assuming each task was trained offline on the agent's local\ndata, we propose a lightweight algorithm that starts from the local models of\nall agents, and in a backward manner using projected stochastic gradient ascent\n(P-SGA) finds a meta-model. The proposed method avoids complex computations\nsuch as computing hessian, double looping, and matrix inversion, while\nachieving high performance at significantly less energy consumption compared to\nthe state-of-the-art methods such as MAML and iMAML on conducted experiments\nfor sinusoid regression and image classification tasks.",
    "descriptor": "",
    "authors": [
      "Anis Elgabli",
      "Chaouki Ben Issaid",
      "Amrit S. Bedi",
      "Mehdi Bennis",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.14772"
  },
  {
    "id": "arXiv:2105.14773",
    "title": "Learning Inductive Attention Guidance for Partially Supervised  Pancreatic Ductal Adenocarcinoma Prediction",
    "abstract": "Pancreatic ductal adenocarcinoma (PDAC) is the third most common cause of\ncancer death in the United States. Predicting tumors like PDACs (including both\nclassification and segmentation) from medical images by deep learning is\nbecoming a growing trend, but usually a large number of annotated data are\nrequired for training, which is very labor-intensive and time-consuming. In\nthis paper, we consider a partially supervised setting, where cheap image-level\nannotations are provided for all the training data, and the costly per-voxel\nannotations are only available for a subset of them. We propose an Inductive\nAttention Guidance Network (IAG-Net) to jointly learn a global image-level\nclassifier for normal/PDAC classification and a local voxel-level classifier\nfor semi-supervised PDAC segmentation. We instantiate both the global and the\nlocal classifiers by multiple instance learning (MIL), where the attention\nguidance, indicating roughly where the PDAC regions are, is the key to bridging\nthem: For global MIL based normal/PDAC classification, attention serves as a\nweight for each instance (voxel) during MIL pooling, which eliminates the\ndistraction from the background; For local MIL based semi-supervised PDAC\nsegmentation, the attention guidance is inductive, which not only provides\nbag-level pseudo-labels to training data without per-voxel annotations for MIL\ntraining, but also acts as a proxy of an instance-level classifier.\nExperimental results show that our IAG-Net boosts PDAC segmentation accuracy by\nmore than 5% compared with the state-of-the-arts.",
    "descriptor": "",
    "authors": [
      "Yan Wang",
      "Peng Tang",
      "Yuyin Zhou",
      "Wei Shen",
      "Elliot K. Fishman",
      "Alan L. Yuille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14773"
  },
  {
    "id": "arXiv:2105.14774",
    "title": "LIIR at SemEval-2021 task 6: Detection of Persuasion Techniques In Texts  and Images using CLIP features",
    "abstract": "We describe our approach for SemEval-2021 task 6 on detection of persuasion\ntechniques in multimodal content (memes). Our system combines pretrained\nmultimodal models (CLIP) and chained classifiers. Also, we propose to enrich\nthe data by a data augmentation technique. Our submission achieves a rank of\n8/16 in terms of F1-micro and 9/16 with F1-macro on the test set.",
    "descriptor": "",
    "authors": [
      "Erfan Ghadery",
      "Damien Sileo",
      "Marie-Francine Moens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14774"
  },
  {
    "id": "arXiv:2105.14778",
    "title": "Sketch and Refine: Towards Faithful and Informative Table-to-Text  Generation",
    "abstract": "Table-to-text generation refers to generating a descriptive text from a\nkey-value table. Traditional autoregressive methods, though can generate text\nwith high fluency, suffer from low coverage and poor faithfulness problems. To\nmitigate these problems, we propose a novel Skeleton-based two-stage method\nthat combines both Autoregressive and Non-Autoregressive generations (SANA).\nOur approach includes: (1) skeleton generation with an autoregressive pointer\nnetwork to select key tokens from the source table; (2) edit-based\nnon-autoregressive generation model to produce texts via iterative insertion\nand deletion operations. By integrating hard constraints from the skeleton, the\nnon-autoregressive model improves the generation's coverage over the source\ntable and thus enhances its faithfulness. We conduct automatic and human\nevaluations on both WikiPerson and WikiBio datasets. Experimental results\ndemonstrate that our method outperforms the previous state-of-the-art methods\nin both automatic and human evaluation, especially on coverage and\nfaithfulness. In particular, we achieve PARENT-T recall of 99.47 in WikiPerson,\nimproving over the existing best results by more than 10 points.",
    "descriptor": "\nComments: 13 pages, 2 figures. Accepted in ACL2021 Findings\n",
    "authors": [
      "Peng Wang",
      "Junyang Lin",
      "An Yang",
      "Chang Zhou",
      "Yichang Zhang",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14778"
  },
  {
    "id": "arXiv:2105.14779",
    "title": "Towards One Model to Rule All: Multilingual Strategy for Dialectal  Code-Switching Arabic ASR",
    "abstract": "With the advent of globalization, there is an increasing demand for\nmultilingual automatic speech recognition (ASR), handling language and\ndialectal variation of spoken content. Recent studies show its efficacy over\nmonolingual systems. In this study, we design a large multilingual end-to-end\nASR using self-attention based conformer architecture. We trained the system\nusing Arabic (Ar), English (En) and French (Fr) languages. We evaluate the\nsystem performance handling: (i) monolingual (Ar, En and Fr); (ii)\nmulti-dialectal (Modern Standard Arabic, along with dialectal variation such as\nEgyptian and Moroccan); (iii) code-switching -- cross-lingual (Ar-En/Fr) and\ndialectal (MSA-Egyptian dialect) test cases, and compare with current\nstate-of-the-art systems. Furthermore, we investigate the influence of\ndifferent embedding/character representations including character vs\nword-piece; shared vs distinct input symbol per language. Our findings\ndemonstrate the strength of such a model by outperforming state-of-the-art\nmonolingual dialectal Arabic and code-switching Arabic ASR.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2021, Multilingual ASR, Multi-dialectal ASR, Code-Switching ASR, Arabic ASR, Conformer, Transformer, E2E ASR, Speech Recognition, ASR, Arabic, English, French\n",
    "authors": [
      "Shammur Absar Chowdhury",
      "Amir Hussein",
      "Ahmed Abdelali",
      "Ahmed Ali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.14779"
  },
  {
    "id": "arXiv:2105.14780",
    "title": "Procedural Content Generation: Better Benchmarks for Transfer  Reinforcement Learning",
    "abstract": "The idea of transfer in reinforcement learning (TRL) is intriguing: being\nable to transfer knowledge from one problem to another problem without learning\neverything from scratch. This promises quicker learning and learning more\ncomplex methods. To gain an insight into the field and to detect emerging\ntrends, we performed a database search. We note a surprisingly late adoption of\ndeep learning that starts in 2018. The introduction of deep learning has not\nyet solved the greatest challenge of TRL: generalization. Transfer between\ndifferent domains works well when domains have strong similarities (e.g.\nMountainCar to Cartpole), and most TRL publications focus on different tasks\nwithin the same domain that have few differences. Most TRL applications we\nencountered compare their improvements against self-defined baselines, and the\nfield is still missing unified benchmarks. We consider this to be a\ndisappointing situation. For the future, we note that: (1) A clear measure of\ntask similarity is needed. (2) Generalization needs to improve. Promising\napproaches merge deep learning with planning via MCTS or introduce memory\nthrough LSTMs. (3) The lack of benchmarking tools will be remedied to enable\nmeaningful comparison and measure progress. Already Alchemy and Meta-World are\nemerging as interesting benchmark suites. We note that another development, the\nincrease in procedural content generation (PCG), can improve both benchmarking\nand generalization in TRL.",
    "descriptor": "",
    "authors": [
      "Matthias M\u00fcller-Brockhausen",
      "Mike Preuss",
      "Aske Plaat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14780"
  },
  {
    "id": "arXiv:2105.14781",
    "title": "A Semantic-based Method for Unsupervised Commonsense Question Answering",
    "abstract": "Unsupervised commonsense question answering is appealing since it does not\nrely on any labeled task data. Among existing work, a popular solution is to\nuse pre-trained language models to score candidate choices directly conditioned\non the question or context. However, such scores from language models can be\neasily affected by irrelevant factors, such as word frequencies, sentence\nstructures, etc. These distracting factors may not only mislead the model to\nchoose a wrong answer but also make it oversensitive to lexical perturbations\nin candidate answers.\nIn this paper, we present a novel SEmantic-based Question Answering method\n(SEQA) for unsupervised commonsense question answering. Instead of directly\nscoring each answer choice, our method first generates a set of plausible\nanswers with generative models (e.g., GPT-2), and then uses these plausible\nanswers to select the correct choice by considering the semantic similarity\nbetween each plausible answer and each choice. We devise a simple, yet sound\nformalism for this idea and verify its effectiveness and robustness with\nextensive experiments. We evaluate the proposed method on four benchmark\ndatasets, and our method achieves the best results in unsupervised settings.\nMoreover, when attacked by TextFooler with synonym replacement, SEQA\ndemonstrates much less performance drops than baselines, thereby indicating\nstronger robustness.",
    "descriptor": "\nComments: Accepted by ACL 2021 (long paper)\n",
    "authors": [
      "Yilin Niu",
      "Fei Huang",
      "Jiaming Liang",
      "Wenkai Chen",
      "Xiaoyan Zhu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14781"
  },
  {
    "id": "arXiv:2105.14783",
    "title": "Electryo, In-person Voting with Transparent Voter Verifiability and  Eligibility Verifiability",
    "abstract": "Selene is an e-voting protocol that allows voters to directly check their\nindividual vote, in cleartext, in the final tally via a tracker system, while\nproviding good coercion mitigation. This is in contrast to conventional,\nend-to-end verifiable schemes in which the voter verifies the presence of an\nencryption of her vote on the bulletin board. The Selene mechanism can be\napplied to many e-voting schemes, but here we present an application to the\npolling station context, resulting in a voter-verifiable electronic tally with\na paper audit trail. The system uses a smartcard-based public key system to\nprovide the individual verification and universal eligibility verifiability.\nThe paper record contains an encrypted link to the voter's identity, requiring\nstronger assumptions on ballot privacy than normal paper voting, but with the\nbenefit of providing good auditability and dispute resolution as well as\nsupporting (comparison) risk limiting audits.",
    "descriptor": "\nComments: E-Vote-ID 2018 TUT Proceedings\n",
    "authors": [
      "Peter B. Roenne",
      "Peter Y.A Ryan",
      "Marie-Laure Zollinger"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14783"
  },
  {
    "id": "arXiv:2105.14784",
    "title": "SN-Graph: a Minimalist 3D Object Representation for Classification",
    "abstract": "Using deep learning techniques to process 3D objects has achieved many\nsuccesses. However, few methods focus on the representation of 3D objects,\nwhich could be more effective for specific tasks than traditional\nrepresentations, such as point clouds, voxels, and multi-view images. In this\npaper, we propose a Sphere Node Graph (SN-Graph) to represent 3D objects.\nSpecifically, we extract a certain number of internal spheres (as nodes) from\nthe signed distance field (SDF), and then establish connections (as edges)\namong the sphere nodes to construct a graph, which is seamlessly suitable for\n3D analysis using graph neural network (GNN). Experiments conducted on the\nModelNet40 dataset show that when there are fewer nodes in the graph or the\ntested objects are rotated arbitrarily, the classification accuracy of SN-Graph\nis significantly higher than the state-of-the-art methods.",
    "descriptor": "\nComments: ICME 2021\n",
    "authors": [
      "Siyu Zhang",
      "Hui Cao",
      "Yuqi Liu",
      "Shen Cai",
      "Yanting Zhang",
      "Yuanzhan Li",
      "Xiaoyu Chi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14784"
  },
  {
    "id": "arXiv:2105.14785",
    "title": "Adversarial Training with Rectified Rejection",
    "abstract": "Adversarial training (AT) is one of the most effective strategies for\npromoting model robustness, whereas even the state-of-the-art adversarially\ntrained models struggle to exceed 60% robust test accuracy on CIFAR-10 without\nadditional data, which is far from practical. A natural way to break this\naccuracy bottleneck is to introduce a rejection option, where confidence is a\ncommonly used certainty proxy. However, the vanilla confidence can overestimate\nthe model certainty if the input is wrongly classified. To this end, we propose\nto use true confidence (T-Con) (i.e., predicted probability of the true class)\nas a certainty oracle, and learn to predict T-Con by rectifying confidence. We\nprove that under mild conditions, a rectified confidence (R-Con) rejector and a\nconfidence rejector can be coupled to distinguish any wrongly classified input\nfrom correctly classified ones, even under adaptive attacks. We also quantify\nthat training R-Con to be aligned with T-Con could be an easier task than\nlearning robust classifiers. In our experiments, we evaluate our rectified\nrejection (RR) module on CIFAR-10, CIFAR-10-C, and CIFAR-100 under several\nattacks, and demonstrate that the RR module is well compatible with different\nAT frameworks on improving robustness, with little extra computation.",
    "descriptor": "",
    "authors": [
      "Tianyu Pang",
      "Huishuai Zhang",
      "Di He",
      "Yinpeng Dong",
      "Hang Su",
      "Wei Chen",
      "Jun Zhu",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14785"
  },
  {
    "id": "arXiv:2105.14787",
    "title": "Voice of Your Brain: Cognitive Representations of Imagined Speech,Overt  Speech, and Speech Perception Based on EEG",
    "abstract": "Every people has their own voice, likewise, brain signals dis-play distinct\nneural representations for each individual. Al-though recent studies have\nrevealed the robustness of speech-related paradigms for efficient\nbrain-computer interface, the dis-tinction on their cognitive representations\nwith practical usabil-ity still remains to be discovered. Herein, we\ninvestigate the dis-tinct brain patterns from electroencephalography (EEG)\nduringimagined speech, overt speech, and speech perception in termsof subject\nvariations with its practical use of speaker identifica-tion from single\nchannel EEG. We performed classification ofnine subjects using deep neural\nnetwork that captures temporal-spectral-spatial features from EEG of imagined\nspeech, overtspeech, and speech perception. Furthermore, we demonstratedthe\nunderlying neural features of individual subjects while per-forming imagined\nspeech by comparing the functional connec-tivity and the EEG envelope features.\nOur results demonstratethe possibility of subject identification from single\nchannel EEGof imagined speech and overt speech. Also, the comparison ofthe\nthree speech-related paradigms will provide valuable infor-mation for the\npractical use of speech-related brain signals inthe further studies.",
    "descriptor": "\nComments: 5 pages, 6 figures, 1 table\n",
    "authors": [
      "Seo-Hyun Lee",
      "Young-Eun Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14787"
  },
  {
    "id": "arXiv:2105.14790",
    "title": "Driver Intention Anticipation Based on In-Cabin and Driving Scene  Monitoring Using Deep Learning",
    "abstract": "To improve driving safety and avoid car accidents, Advanced Driver Assistance\nSystems (ADAS) are given significant attention. Recent studies have focused on\npredicting driver intention as a key part of these systems. In this study, we\nproposed new framework in which 4 inputs are employed to anticipate diver\nmaneuver using Brain4Cars dataset and the maneuver prediction is achieved from\n5, 4, 3, 2, 1 seconds before the actual action occurs. We evaluated our\nframework in three scenarios: using only 1) inside view 2) outside view and 3)\nboth inside and outside view. We divided the dataset into training, validation\nand test sets, also K-fold cross validation is utilized. Compared with\nstate-of-the-art studies, our architecture is faster and achieved higher\nperformance in second and third scenario. Accuracy, precision, recall and\nf1-score as evaluation metrics were utilized and the result of 82.41%, 82.28%,\n82,42% and 82.24% for outside view and 98.90%, 98.96%, 98.90% and 98.88% for\nboth inside and outside view were gained, respectively.",
    "descriptor": "",
    "authors": [
      "Mahdi Bonyani",
      "Mina Rahmanian",
      "Simindokht Jahangard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14790"
  },
  {
    "id": "arXiv:2105.14796",
    "title": "Improving Tree-Structured Decoder Training for Code Generation via  Mutual Learning",
    "abstract": "Code generation aims to automatically generate a piece of code given an input\nnatural language utterance. Currently, among dominant models, it is treated as\na sequence-to-tree task, where a decoder outputs a sequence of actions\ncorresponding to the pre-order traversal of an Abstract Syntax Tree. However,\nsuch a decoder only exploits the preorder traversal based preceding actions,\nwhich are insufficient to ensure correct action predictions. In this paper, we\nfirst throughly analyze the context modeling difference between neural code\ngeneration models with different traversals based decodings (preorder traversal\nvs breadth-first traversal), and then propose to introduce a mutual learning\nframework to jointly train these models. Under this framework, we continuously\nenhance both two models via mutual distillation, which involves synchronous\nexecutions of two one-to-one knowledge transfers at each training step. More\nspecifically, we alternately choose one model as the student and the other as\nits teacher, and require the student to fit the training data and the action\nprediction distributions of its teacher. By doing so, both models can fully\nabsorb the knowledge from each other and thus could be improved simultaneously.\nExperimental results and in-depth analysis on several benchmark datasets\ndemonstrate the effectiveness of our approach. We release our code at\nhttps://github.com/DeepLearnXMU/CGML.",
    "descriptor": "",
    "authors": [
      "Binbin Xie",
      "Jinsong Su",
      "Yubin Ge",
      "Xiang Li",
      "Jianwei Cui",
      "Junfeng Yao",
      "Bin Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14796"
  },
  {
    "id": "arXiv:2105.14797",
    "title": "RED : Looking for Redundancies for Data-Free Structured Compression of  Deep Neural Networks",
    "abstract": "Deep Neural Networks (DNNs) are ubiquitous in today's computer vision\nland-scape, despite involving considerable computational costs. The mainstream\napproaches for runtime acceleration consist in pruning connections\n(unstructured pruning) or, better, filters (structured pruning), both often\nrequiring data to re-train the model. In this paper, we present RED, a\ndata-free structured, unified approach to tackle structured pruning. First, we\npropose a novel adaptive hashing of the scalar DNN weight distribution\ndensities to increase the number of identical neurons represented by their\nweight vectors. Second, we prune the network by merging redundant neurons based\non their relative similarities, as defined by their distance. Third, we propose\na novel uneven depthwise separation technique to further prune convolutional\nlayers. We demonstrate through a large variety of benchmarks that RED largely\noutperforms other data-free pruning methods, often reaching performance similar\nto unconstrained, data-driven methods.",
    "descriptor": "",
    "authors": [
      "Edouard Yvinec",
      "Arnaud Dapogny",
      "Matthieu Cord",
      "Kevin Bailly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.14797"
  },
  {
    "id": "arXiv:2105.14799",
    "title": "Resultant-based Elimination in Ore Algebra",
    "abstract": "We consider resultant-based methods for elimination of indeterminates of Ore\npolynomial systems in Ore algebra. We start with defining the concept of\nresultant for bivariate Ore polynomials then compute it by the Dieudonne\ndeterminant of the polynomial coefficients. Additionally, we apply\nnoncommutative versions of evaluation and interpolation techniques to the\ncomputation process to improve the efficiency of the method. The implementation\nof the algorithms will be performed in Maple to evaluate the performance of the\napproaches.",
    "descriptor": "",
    "authors": [
      "Raqeeb Rasheed"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2105.14799"
  },
  {
    "id": "arXiv:2105.14802",
    "title": "On Compositional Generalization of Neural Machine Translation",
    "abstract": "Modern neural machine translation (NMT) models have achieved competitive\nperformance in standard benchmarks such as WMT. However, there still exist\nsignificant issues such as robustness, domain generalization, etc. In this\npaper, we study NMT models from the perspective of compositional generalization\nby building a benchmark dataset, CoGnition, consisting of 216k clean and\nconsistent sentence pairs. We quantitatively analyze effects of various factors\nusing compound translation error rate, then demonstrate that the NMT model\nfails badly on compositional generalization, although it performs remarkably\nwell under traditional metrics.",
    "descriptor": "\nComments: To appear at the ACL 2021 main conference\n",
    "authors": [
      "Yafu Li",
      "Yongjing Yin",
      "Yulong Chen",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14802"
  },
  {
    "id": "arXiv:2105.14803",
    "title": "Gradient-based Data Subversion Attack Against Binary Classifiers",
    "abstract": "Machine learning based data-driven technologies have shown impressive\nperformances in a variety of application domains. Most enterprises use data\nfrom multiple sources to provide quality applications. The reliability of the\nexternal data sources raises concerns for the security of the machine learning\ntechniques adopted. An attacker can tamper the training or test datasets to\nsubvert the predictions of models generated by these techniques. Data poisoning\nis one such attack wherein the attacker tries to degrade the performance of a\nclassifier by manipulating the training data.\nIn this work, we focus on label contamination attack in which an attacker\npoisons the labels of data to compromise the functionality of the system. We\ndevelop Gradient-based Data Subversion strategies to achieve model degradation\nunder the assumption that the attacker has limited-knowledge of the victim\nmodel. We exploit the gradients of a differentiable convex loss function\n(residual errors) with respect to the predicted label as a warm-start and\nformulate different strategies to find a set of data instances to contaminate.\nFurther, we analyze the transferability of attacks and the susceptibility of\nbinary classifiers. Our experiments show that the proposed approach outperforms\nthe baselines and is computationally efficient.",
    "descriptor": "\nComments: 26 pages, 3 Figures, 8 tables, adversarial attacks, data poisoning attacks, label contamination, transferability of attack, susceptibility\n",
    "authors": [
      "Rosni K Vasu",
      "Sanjay Seetharaman",
      "Shubham Malaviya",
      "Manish Shukla",
      "Sachin Lodha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14803"
  },
  {
    "id": "arXiv:2105.14804",
    "title": "Scene-aware Generative Network for Human Motion Synthesis",
    "abstract": "We revisit human motion synthesis, a task useful in various real world\napplications, in this paper. Whereas a number of methods have been developed\npreviously for this task, they are often limited in two aspects: focusing on\nthe poses while leaving the location movement behind, and ignoring the impact\nof the environment on the human motion. In this paper, we propose a new\nframework, with the interaction between the scene and the human motion taken\ninto account. Considering the uncertainty of human motion, we formulate this\ntask as a generative task, whose objective is to generate plausible human\nmotion conditioned on both the scene and the human initial position. This\nframework factorizes the distribution of human motions into a distribution of\nmovement trajectories conditioned on scenes and that of body pose dynamics\nconditioned on both scenes and trajectories. We further derive a GAN based\nlearning approach, with discriminators to enforce the compatibility between the\nhuman motion and the contextual scene as well as the 3D to 2D projection\nconstraints. We assess the effectiveness of the proposed method on two\nchallenging datasets, which cover both synthetic and real world environments.",
    "descriptor": "\nComments: Accepted by CVPR2021\n",
    "authors": [
      "Jingbo Wang",
      "Sijie Yan",
      "Bo Dai",
      "Dahua LIn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14804"
  },
  {
    "id": "arXiv:2105.14805",
    "title": "Circulant decomposition of a matrix and the eigenvalues of Toeplitz type  matrices",
    "abstract": "We begin by showing that a n*n matrix can be decomposed into a sum of 'n'\ncirculant matrices with appropriate relaxations. We use Fast-Fourier-Transform\n(FFT) operations to perform a sparse similarity transformation representing\nonly the dominant circulant components, to evaluate all eigenvalues of dense\nToeplitz, block-Toeplitz and other periodic or quasi-periodic matrices, to a\nreasonable approximation in O(n^2) arithmetic operations. This sparse\nsimilarity transformation can be exploited for other evaluations as well.",
    "descriptor": "",
    "authors": [
      "Hariprasad M.",
      "Murugesan Venkatapathi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14805"
  },
  {
    "id": "arXiv:2105.14809",
    "title": "Transfer Learning for Sequence Generation: from Single-source to  Multi-source",
    "abstract": "Multi-source sequence generation (MSG) is an important kind of sequence\ngeneration tasks that takes multiple sources, including automatic post-editing,\nmulti-source translation, multi-document summarization, etc. As MSG tasks\nsuffer from the data scarcity problem and recent pretrained models have been\nproven to be effective for low-resource downstream tasks, transferring\npretrained sequence-to-sequence models to MSG tasks is essential. Although\ndirectly finetuning pretrained models on MSG tasks and concatenating multiple\nsources into a single long sequence is regarded as a simple method to transfer\npretrained models to MSG tasks, we conjecture that the direct finetuning method\nleads to catastrophic forgetting and solely relying on pretrained\nself-attention layers to capture cross-source information is not sufficient.\nTherefore, we propose a two-stage finetuning method to alleviate the\npretrain-finetune discrepancy and introduce a novel MSG model with a fine\nencoder to learn better representations in MSG tasks. Experiments show that our\napproach achieves new state-of-the-art results on the WMT17 APE task and\nmulti-source translation task using the WMT14 test set. When adapted to\ndocument-level translation, our framework outperforms strong baselines\nsignificantly.",
    "descriptor": "\nComments: ACL2021 main track long paper\n",
    "authors": [
      "Xuancheng Huang",
      "Jingfang Xu",
      "Maosong Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14809"
  },
  {
    "id": "arXiv:2105.14811",
    "title": "A simple numerical method for Hele-Shaw type problems by the method of  fundamental solutions",
    "abstract": "Hele-Shaw flows with time-dependent gaps create fingering patterns, and\nmagnetic fluids in Hele-Shaw cells create intriguing patterns.We propose a\nsimple numerical method for Hele-Shaw type problems by the method of\nfundamental solutions.The method of fundamental solutions is one of the\nmesh-free numerical solvers for potential problems, which provides a highly\naccurate approximate solution despite its simplicity.Moreover, combining with\nthe asymptotic uniform distribution method, the numerical method satisfies the\nvolume-preserving property.We use Amano's method to arrange the singular points\nin the method of fundamental solutions.We show several numerical results to\nexemplify the effectiveness of our numerical scheme.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Koya Sakakibara",
      "Yusaku Shimoji",
      "Shigetoshi Yazaki"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14811"
  },
  {
    "id": "arXiv:2105.14813",
    "title": "Exploration and Exploitation: Two Ways to Improve Chinese Spelling  Correction Models",
    "abstract": "A sequence-to-sequence learning with neural networks has empirically proven\nto be an effective framework for Chinese Spelling Correction (CSC), which takes\na sentence with some spelling errors as input and outputs the corrected one.\nHowever, CSC models may fail to correct spelling errors covered by the\nconfusion sets, and also will encounter unseen ones. We propose a method, which\ncontinually identifies the weak spots of a model to generate more valuable\ntraining instances, and apply a task-specific pre-training strategy to enhance\nthe model. The generated adversarial examples are gradually added to the\ntraining set. Experimental results show that such an adversarial training\nmethod combined with the pretraining strategy can improve both the\ngeneralization and robustness of multiple CSC models across three different\ndatasets, achieving stateof-the-art performance for CSC task.",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Chong Li",
      "Cenyuan Zhang",
      "Xiaoqing Zheng",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14813"
  },
  {
    "id": "arXiv:2105.14815",
    "title": "Supporting Cognitive and Emotional Empathic Writing of Students",
    "abstract": "We present an annotation approach to capturing emotional and cognitive\nempathy in student-written peer reviews on business models in German. We\npropose an annotation scheme that allows us to model emotional and cognitive\nempathy scores based on three types of review components. Also, we conducted an\nannotation study with three annotators based on 92 student essays to evaluate\nour annotation scheme. The obtained inter-rater agreement of {\\alpha}=0.79 for\nthe components and the multi-{\\pi}=0.41 for the empathy scores indicate that\nthe proposed annotation scheme successfully guides annotators to a substantial\nto moderate agreement. Moreover, we trained predictive models to detect the\nannotated empathy structures and embedded them in an adaptive writing support\nsystem for students to receive individual empathy feedback independent of an\ninstructor, time, and location. We evaluated our tool in a peer learning\nexercise with 58 students and found promising results for perceived empathy\nskill learning, perceived feedback accuracy, and intention to use. Finally, we\npresent our freely available corpus of 500 empathy-annotated, student-written\npeer reviews on business models and our annotation guidelines to encourage\nfuture research on the design and development of empathy support systems.",
    "descriptor": "\nComments: to be published in The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)\n",
    "authors": [
      "Thiemo Wambsganss",
      "Christina Niklaus",
      "Matthias S\u00f6llner",
      "Siegfried Handschuh",
      "Jan Marco Leimeister"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14815"
  },
  {
    "id": "arXiv:2105.14816",
    "title": "Ultrasonic Array Characterization in Multiscattering and Attenuating  Media Using Pin Targets",
    "abstract": "This paper presents an approach to characterize ultrasonic imaging arrays\nusing pin targets in commercial test phantoms. We used a 128-element phased\narray transducer operating at 7.5 MHz with a fractional bandwidth of %70. We\nalso used a tissue-mimicking phantom in the measurements. This phantom consists\nof pin targets with a 50-micrometer diameter. We excited the transducer with\npulsed and coded signals. We used Complementary Golay Sequences to code the\ntransmitted signal and Binary Phase Shift Keying for modulation. We\ncharacterized the transducer array using the transfer function, line spread\nfunction, range resolution, and beam width in an attenuating and scattering\nmedium. We showed that the pin targets, which are very thin compared to the\ndiffraction-limited focus of the transducer array, are suitable for the\ntransducer characterization under weak reflected signal conditions.",
    "descriptor": "\nComments: 11 pages, 16 figures, 1 table\n",
    "authors": [
      "Yasin Kumru",
      "Hayrettin K\u00f6ymen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14816"
  },
  {
    "id": "arXiv:2105.14817",
    "title": "SQUADfps: Integrated Model-Based Machine Safety and Product Quality for  Flexible Production Systems",
    "abstract": "Growing individualization of products up to lot-size-1 and high volatility of\nproduct mixes lead to new challenges in the manufacturing domain, including the\nneed for frequent reconfiguration of the system and reacting to changing\norders. Thus, apart from functional aspects, safety aspects of the production\nsystem as well as product quality assurance aspects must be addressed for\nflexible and reconfigurable manufacturing systems at runtime. To cope with the\nmentioned challenges, we present an integrated model-based approach SQUADfps\n(machine Safety and product QUAlity for flexible proDuction systems) to support\nthe automatic conduct of the risk assessment of flexible production scenarios\nin terms of safety as well as the process-FMEA to ensure that the requirements\nw.r.t. the quality of the production process and the resulting product are met.\nOur approach is based on a meta-model which captures all information needed to\nconduct both risk assessment and process-FMEA dynamically during the runtime,\nand thus enables flexible manufacturing scenarios with frequent changes of the\nproduction system and orders up to a lot-size of one while guaranteeing safety\nand product quality requirements. The automatically generated results will\nassist human in making further decisions. To demonstrate the feasibility of our\napproach, we apply it to a case study.",
    "descriptor": "",
    "authors": [
      "Chee Hung Koo",
      "Stefan Rothbauer",
      "Marian Vorderer",
      "Kai Hoefig",
      "Marc Zeller"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14817"
  },
  {
    "id": "arXiv:2105.14818",
    "title": "Redacting Transactions fromExecute-Order-Validate Blockchains",
    "abstract": "As user privacy gains popularity and attention, and starts to shape relations\nbetween users and service providers, blockchain based solutions thrive for ways\nto relax immutability without sacrificing consistency. This work answers that\nneed and presents the first design for a redactable execute-order-validate\nblockchain, that grants users with the \\emph{right to be forgotten}. The design\nis easy to adopt, as we exemplify by implementing it on top of Hyperledger\nFabric. It modifies the block structure and extracts user data from the\nhash-chain without loosening any correctness or liveness criteria. We evaluate\nour design and show that it provides compliance with only a minimal performance\noverhead, making it a feasible add-on to any execute-order-validate blockchain\nsystem.",
    "descriptor": "",
    "authors": [
      "Yacov Manevich",
      "Artem Barger",
      "Gal Assa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14818"
  },
  {
    "id": "arXiv:2105.14820",
    "title": "An exact counterfactual-example-based approach to tree-ensemble models  interpretability",
    "abstract": "Explaining the decisions of machine learning models is becoming a necessity\nin many areas where trust in ML models decision is key to their\naccreditation/adoption. The ability to explain models decisions also allows to\nprovide diagnosis in addition to the model decision, which is highly valuable\nin scenarios such as fault detection. Unfortunately, high-performance models do\nnot exhibit the necessary transparency to make their decisions fully\nunderstandable. And the black-boxes approaches, which are used to explain such\nmodel decisions, suffer from a lack of accuracy in tracing back the exact cause\nof a model decision regarding a given input. Indeed, they do not have the\nability to explicitly describe the decision regions of the model around that\ninput, which is necessary to determine what influences the model towards one\ndecision or the other. We thus asked ourselves the question: is there a\ncategory of high-performance models among the ones currently used for which we\ncould explicitly and exactly characterise the decision regions in the input\nfeature space using a geometrical characterisation? Surprisingly we came out\nwith a positive answer for any model that enters the category of tree ensemble\nmodels, which encompasses a wide range of high-performance models such as\nXGBoost, LightGBM, random forests ... We could derive an exact geometrical\ncharacterisation of their decision regions under the form of a collection of\nmultidimensional intervals. This characterisation makes it straightforward to\ncompute the optimal counterfactual (CF) example associated with a query point.\nWe demonstrate several possibilities of the approach, such as computing the CF\nexample based only on a subset of features. This allows to obtain more\nplausible explanations by adding prior knowledge about which variables the user\ncan control. An adaptation to CF reasoning on regression problems is also\nenvisaged.",
    "descriptor": "",
    "authors": [
      "Pierre Blanchart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14820"
  },
  {
    "id": "arXiv:2105.14822",
    "title": "Effective Batching for Recurrent Neural Network Grammars",
    "abstract": "As a language model that integrates traditional symbolic operations and\nflexible neural representations, recurrent neural network grammars (RNNGs) have\nattracted great attention from both scientific and engineering perspectives.\nHowever, RNNGs are known to be harder to scale due to the difficulty of batched\ntraining. In this paper, we propose effective batching for RNNGs, where every\noperation is computed in parallel with tensors across multiple sentences. Our\nPyTorch implementation effectively employs a GPU and achieves x6 speedup\ncompared to the existing C++ DyNet implementation with model-independent\nauto-batching. Moreover, our batched RNNG also accelerates inference and\nachieves x20-150 speedup for beam search depending on beam sizes. Finally, we\nevaluate syntactic generalization performance of the scaled RNNG against the\nLSTM baseline, based on the large training data of 100M tokens from English\nWikipedia and the broad-coverage targeted syntactic evaluation benchmark. Our\nRNNG implementation is available at https://github.com/aistairc/rnng-pytorch/.",
    "descriptor": "\nComments: Findings of ACL: ACL-IJCNLP 2021\n",
    "authors": [
      "Hiroshi Noji",
      "Yohei Oseki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14822"
  },
  {
    "id": "arXiv:2105.14824",
    "title": "Bounded logit attention: Learning to explain image classifiers",
    "abstract": "Explainable artificial intelligence is the attempt to elucidate the workings\nof systems too complex to be directly accessible to human cognition through\nsuitable side-information referred to as \"explanations\". We present a trainable\nexplanation module for convolutional image classifiers we call bounded logit\nattention (BLA). The BLA module learns to select a subset of the convolutional\nfeature map for each input instance, which then serves as an explanation for\nthe classifier's prediction. BLA overcomes several limitations of the\ninstancewise feature selection method \"learning to explain\" (L2X) introduced by\nChen et al. (2018): 1) BLA scales to real-world sized image classification\nproblems, and 2) BLA offers a canonical way to learn explanations of variable\nsize. Due to its modularity BLA lends itself to transfer learning setups and\ncan also be employed as a post-hoc add-on to trained classifiers. Beyond\nexplainability, BLA may serve as a general purpose method for differentiable\napproximation of subset selection. In a user study we find that BLA\nexplanations are preferred over explanations generated by the popular\n(Grad-)CAM method.",
    "descriptor": "",
    "authors": [
      "Thomas Baumhauer",
      "Djordje Slijepcevic",
      "Matthias Zeppelzauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14824"
  },
  {
    "id": "arXiv:2105.14829",
    "title": "Q-attention: Enabling Efficient Learning for Vision-based Robotic  Manipulation",
    "abstract": "Despite the success of reinforcement learning methods, they have yet to have\ntheir breakthrough moment when applied to a broad range of robotic manipulation\ntasks. This is partly due to the fact that reinforcement learning algorithms\nare notoriously difficult and time consuming to train, which is exacerbated\nwhen training from images rather than full-state inputs. As humans perform\nmanipulation tasks, our eyes closely monitor every step of the process with our\ngaze focusing sequentially on the objects being manipulated. With this in mind,\nwe present our Attention-driven Robotic Manipulation (ARM) algorithm, which is\na general manipulation algorithm that can be applied to a range of\nsparse-rewarded tasks, given only a small number of demonstrations. ARM splits\nthe complex task of manipulation into a 3 stage pipeline: (1) a Q-attention\nagent extracts interesting pixel locations from RGB and point cloud inputs, (2)\na next-best pose agent that accepts crops from the Q-attention agent and\noutputs poses, and (3) a control agent that takes the goal pose and outputs\njoint actions. We show that current learning algorithms fail on a range of\nRLBench tasks, whilst ARM is successful.",
    "descriptor": "\nComments: Videos and code found at: this https URL\n",
    "authors": [
      "Stephen James",
      "Andrew J. Davison"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14829"
  },
  {
    "id": "arXiv:2105.14830",
    "title": "Advantages of NOMA for Multi-User BackCom Networks",
    "abstract": "Ambient backscatter communication (BackCom) is faced with the challenge that\na single BackCom device can occupy multiple orthogonal resource blocks\nunintentionally. As a result, in order to avoid co-channel interference, a\nconventional approach is to serve multiple BackCom devices in different time\nslots, which reduces both spectral efficiency and connectivity. This letter\ndemonstrates that the use of non-orthogonal multiple access (NOMA) can\nefficiently improve the system throughput and support massive connectivity in\nambient BackCom networks. In particular, two transceiver design approaches are\ndeveloped in the letter to realize different tradeoffs between system\nperformance and complexity.",
    "descriptor": "",
    "authors": [
      "Zhiguo Ding",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.14830"
  },
  {
    "id": "arXiv:2105.14831",
    "title": "Insights into the performance of loosely-coupled FSI schemes based on  Robin boundary conditions",
    "abstract": "Robin boundary conditions are a natural consequence of employing Nitsche's\nmethod for imposing the kinematic velocity constraint at the fluid-solid\ninterface. Loosely-coupled FSI schemes based on Dirichlet-Robin or Robin-Robin\ncoupling have been demonstrated to improve the stability of such schemes with\nrespect to added-mass. This paper aims to offer some numerical insights into\nthe performance characteristics of such loosely-coupled FSI schemes based on\nRobin boundary conditions. Using numerical examples, we demonstrate that the\nimproved stability due to the added damping term is actually at the expense of\nimportant dynamic characteristics of the structural sub-problem.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Chennakesava Kadapa"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14831"
  },
  {
    "id": "arXiv:2105.14835",
    "title": "Towards Lower Bounds on the Depth of ReLU Neural Networks",
    "abstract": "We contribute to a better understanding of the class of functions that is\nrepresented by a neural network with ReLU activations and a given architecture.\nUsing techniques from mixed-integer optimization, polyhedral theory, and\ntropical geometry, we provide a mathematical counterbalance to the universal\napproximation theorems which suggest that a single hidden layer is sufficient\nfor learning tasks. In particular, we investigate whether the class of exactly\nrepresentable functions strictly increases by adding more layers (with no\nrestrictions on size). This problem has potential impact on algorithmic and\nstatistical aspects because of the insight it provides into the class of\nfunctions represented by neural hypothesis classes. However, to the best of our\nknowledge, this question has not been investigated in the neural network\nliterature. We also present upper bounds on the sizes of neural networks\nrequired to represent functions in these neural hypothesis classes.",
    "descriptor": "",
    "authors": [
      "Christoph Hertrich",
      "Amitabh Basu",
      "Marco Di Summa",
      "Martin Skutella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Combinatorics (math.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14835"
  },
  {
    "id": "arXiv:2105.14838",
    "title": "Does the Venue of Scientific Conferences Leverage their Impact? A Large  Scale study on Computer Science Conferences",
    "abstract": "Background: Conferences bring scientists together and provide one of the most\ntimely means for disseminating new ideas and cutting-edge works.The importance\nof conferences in scientific areas is testified by quantitative indicators. In\nComputer Science, for instance, almost two out of three papers published on\nScopus are conference papers. Objective/Purpose: The main goal of this paper is\nto investigate a novel research question: is there any correlation between the\nimpact of a scientific conference and the venue where it took place? Approach:\nIn order to measure the impact of conferences we conducted a large scale\nanalysis on the bibliographic data extracted from 3,838 Computer Science\nconference series and over 2.5 million papers spanning more than 30 years of\nresearch. To quantify the \"touristicity\" of a venue we exploited some\nindicators such as the size of the Wikipedia page for the city hosting the\nvenue and other indexes from reports of the World Economic Forum.\nResults/Findings: We found out that the two aspects are related, and the\ncorrelation with conference impact is stronger when considering country-wide\ntouristic indicators, such as the Travel&Tourism Competitiveness Index.\nMore-over the almost linear correlation with the Tourist Service Infrastructure\nindex attests the specific importance of tourist/accommodation facilities in a\ngiven country. Conclusions: This is the first attempt to focus on the\nrelationship of venue characteristics to conference papers. The results open up\nnew possibilities, such as allowing conference organizers and authors to\nestimate in advance the impact of conferences, thus supporting them in their\ndecisions.",
    "descriptor": "",
    "authors": [
      "Luca Bedogni",
      "Giacomo Cabri",
      "Riccardo Martoglia",
      "Francesco Poggi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.14838"
  },
  {
    "id": "arXiv:2105.14839",
    "title": "Greedy Layer Pruning: Decreasing Inference Time of Transformer Models",
    "abstract": "Fine-tuning transformer models after unsupervised pre-training reaches a very\nhigh performance on many different NLP tasks. Unfortunately, transformers\nsuffer from long inference times which greatly increases costs in production\nand is a limiting factor for the deployment into embedded devices. One possible\nsolution is to use knowledge distillation, which solves this problem by\ntransferring information from large teacher models to smaller student models,\nbut as it needs an additional expensive pre-training phase, this solution is\ncomputationally expensive and can be financially prohibitive for smaller\nacademic research groups. Another solution is to use layer-wise pruning\nmethods, which reach high compression rates for transformer models and avoids\nthe computational load of the pre-training distillation stage. The price to pay\nis that the performance of layer-wise pruning algorithms is not on par with\nstate-of-the-art knowledge distillation methods. In this paper, greedy layer\npruning (GLP) is introduced to (1) outperform current state-of-the-art for\nlayer-wise pruning (2) close the performance gap when compared to knowledge\ndistillation, while (3) using only a modest budget. More precisely, with the\nmethodology presented it is possible to prune and evaluate competitive models\non the whole GLUE benchmark with a budget of just $\\$300$. Our source code is\navailable on https://github.com/deepopinion/greedy-layer-pruning.",
    "descriptor": "",
    "authors": [
      "David Peer",
      "Sebastian Stabinger",
      "Stefan Engl",
      "Antonio Rodriguez-Sanchez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14839"
  },
  {
    "id": "arXiv:2105.14840",
    "title": "Elegant elaboration with function invocation",
    "abstract": "We present an elegant design of the core language in a dependently-typed\nlambda calculus with $\\delta$-reduction and an elaboration algorithm.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Tesla Zhang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.14840"
  },
  {
    "id": "arXiv:2105.14844",
    "title": "Demographic Fairness in Biometric Systems: What do the Experts say?",
    "abstract": "Algorithmic decision systems have frequently been labelled as \"biased\",\n\"racist\", \"sexist\", or \"unfair\" by numerous media outlets, organisations, and\nresearchers. There is an ongoing debate about whether such assessments are\njustified and whether citizens and policymakers should be concerned. These and\nother related matters have recently become a hot topic in the context of\nbiometric technologies, which are ubiquitous in personal, commercial, and\ngovernmental applications. Biometrics represent an essential component of many\nsurveillance, access control, and operational identity management systems, thus\ndirectly or indirectly affecting billions of people all around the world.\nRecently, the European Association for Biometrics organised an event series\nwith \"demographic fairness in biometric systems\" as an overarching theme. The\nevents featured presentations by international experts from academic, industry,\nand governmental organisations and facilitated interactions and discussions\nbetween the experts and the audience. Further consultation of experts was\nundertaken by means of a questionnaire. This work summarises opinions of\nexperts and findings of said events on the topic of demographic fairness in\nbiometric systems including several important aspects such as the developments\nof evaluation metrics and standards as well as related issues, e.g. the need\nfor transparency and explainability in biometric systems or legal and ethical\nissues.",
    "descriptor": "",
    "authors": [
      "Christian Rathgeb",
      "Pawel Drozdowski",
      "Naser Damer",
      "Dinusha C. Frings",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14844"
  },
  {
    "id": "arXiv:2105.14845",
    "title": "With Great Freedom Comes Great Opportunity: Rethinking Resource  Allocation for Serverless Functions",
    "abstract": "Current serverless offerings give users a limited degree of flexibility for\nconfiguring the resources allocated to their function invocations by either\ncoupling memory and CPU resources together or providing no knobs at all. These\nconfiguration choices simplify resource allocation decisions on behalf of\nusers, but at the same time, create deployments that are resource inefficient.\nIn this paper, we take a principled approach to the problem of resource\nallocation for serverless functions, allowing this choice to be made in an\nautomatic way that leads to the best combination of performance and cost. In\nparticular, we systematically explore the opportunities that come with\ndecoupling memory and CPU resource allocations and also enabling the use of\ndifferent VM types. We find a rich trade-off space between performance and\ncost. The provider can use this in a number of ways: from exposing all these\nparameters to the user, to eliciting preferences for performance and cost from\nusers, or by simply offering the same performance with lower cost. This\nflexibility can also enable the provider to optimize its resource utilization\nand enable a cost-effective service with predictable performance.\nOur results show that, by decoupling memory and CPU allocation, there is\npotential to have up to 40% lower execution cost than the preset coupled\nconfigurations that are the norm in current serverless offerings. Similarly,\nmaking the correct choice of VM instance type can provide up to 50% better\nexecution time. Furthermore, we demonstrate that providers can utilize\ndifferent instance types for the same functions to maximize resource\nutilization while providing performance within 10-20% of the best resource\nconfiguration for each respective function.",
    "descriptor": "",
    "authors": [
      "Muhammad Bilal",
      "Marco Canini",
      "Rodrigo Fonseca",
      "Rodrigo Rodrigues"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.14845"
  },
  {
    "id": "arXiv:2105.14849",
    "title": "Why does CTC result in peaky behavior?",
    "abstract": "The peaky behavior of CTC models is well known experimentally. However, an\nunderstanding about why peaky behavior occurs is missing, and whether this is a\ngood property. We provide a formal analysis of the peaky behavior and gradient\ndescent convergence properties of the CTC loss and related training criteria.\nOur analysis provides a deep understanding why peaky behavior occurs and when\nit is suboptimal. On a simple example which should be trivial to learn for any\nmodel, we prove that a feed-forward neural network trained with CTC from\nuniform initialization converges towards peaky behavior with a 100% error rate.\nOur analysis further explains why CTC only works well together with the blank\nlabel. We further demonstrate that peaky behavior does not occur on other\nrelated losses including a label prior model, and that this improves\nconvergence.",
    "descriptor": "",
    "authors": [
      "Albert Zeyer",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.14849"
  },
  {
    "id": "arXiv:2105.14850",
    "title": "Cascaded Head-colliding Attention",
    "abstract": "Transformers have advanced the field of natural language processing (NLP) on\na variety of important tasks. At the cornerstone of the Transformer\narchitecture is the multi-head attention (MHA) mechanism which models pairwise\ninteractions between the elements of the sequence. Despite its massive success,\nthe current framework ignores interactions among different heads, leading to\nthe problem that many of the heads are redundant in practice, which greatly\nwastes the capacity of the model. To improve parameter efficiency, we\nre-formulate the MHA as a latent variable model from a probabilistic\nperspective. We present cascaded head-colliding attention (CODA) which\nexplicitly models the interactions between attention heads through a\nhierarchical variational distribution. We conduct extensive experiments and\ndemonstrate that CODA outperforms the transformer baseline, by $0.6$ perplexity\non \\texttt{Wikitext-103} in language modeling, and by $0.6$ BLEU on\n\\texttt{WMT14 EN-DE} in machine translation, due to its improvements on the\nparameter efficiency.\\footnote{Our implementation is publicly available at\n\\url{https://github.com/LZhengisme/CODA}.}",
    "descriptor": "\nComments: ACL 2021 Camera-ready version\n",
    "authors": [
      "Lin Zheng",
      "Zhiyong Wu",
      "Lingpeng Kong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14850"
  },
  {
    "id": "arXiv:2105.14857",
    "title": "Learning Free-Form Deformation for 3D Face Reconstruction from  In-The-Wild Images",
    "abstract": "The 3D Morphable Model (3DMM), which is a Principal Component Analysis (PCA)\nbased statistical model that represents a 3D face using linear basis functions,\nhas shown promising results for reconstructing 3D faces from single-view\nin-the-wild images. However, 3DMM has restricted representation power due to\nthe limited number of 3D scans and the global linear basis. To address the\nlimitations of 3DMM, we propose a straightforward learning-based method that\nreconstructs a 3D face mesh through Free-Form Deformation (FFD) for the first\ntime. FFD is a geometric modeling method that embeds a reference mesh within a\nparallelepiped grid and deforms the mesh by moving the sparse control points of\nthe grid. As FFD is based on mathematically defined basis functions, it has no\nlimitation in representation power. Thus, we can recover accurate 3D face\nmeshes by estimating appropriate deviation of control points as deformation\nparameters. Although both 3DMM and FFD are parametric models, it is difficult\nto predict the effect of the 3DMM parameters on the face shape, while the\ndeformation parameters of FFD are interpretable in terms of their effect on the\nfinal shape of the mesh. This practical advantage of FFD allows the resulting\nmesh and control points to serve as a good starting point for 3D face modeling,\nin that ordinary users can fine-tune the mesh by using widely available 3D\nsoftware tools. Experiments on multiple datasets demonstrate how our method\nsuccessfully estimates the 3D face geometry and facial expressions from 2D face\nimages, achieving comparable performance to the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Harim Jung",
      "Myeong-Seok Oh",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14857"
  },
  {
    "id": "arXiv:2105.14859",
    "title": "Consistency Regularization for Variational Auto-Encoders",
    "abstract": "Variational auto-encoders (VAEs) are a powerful approach to unsupervised\nlearning. They enable scalable approximate posterior inference in\nlatent-variable models using variational inference (VI). A VAE posits a\nvariational family parameterized by a deep neural network called an encoder\nthat takes data as input. This encoder is shared across all the observations,\nwhich amortizes the cost of inference. However the encoder of a VAE has the\nundesirable property that it maps a given observation and a\nsemantics-preserving transformation of it to different latent representations.\nThis \"inconsistency\" of the encoder lowers the quality of the learned\nrepresentations, especially for downstream tasks, and also negatively affects\ngeneralization. In this paper, we propose a regularization method to enforce\nconsistency in VAEs. The idea is to minimize the Kullback-Leibler (KL)\ndivergence between the variational distribution when conditioning on the\nobservation and the variational distribution when conditioning on a random\nsemantic-preserving transformation of this observation. This regularization is\napplicable to any VAE. In our experiments we apply it to four different VAE\nvariants on several benchmark datasets and found it always improves the quality\nof the learned representations but also leads to better generalization. In\nparticular, when applied to the Nouveau Variational Auto-Encoder (NVAE), our\nregularization method yields state-of-the-art performance on MNIST and\nCIFAR-10. We also applied our method to 3D data and found it learns\nrepresentations of superior quality as measured by accuracy on a downstream\nclassification task.",
    "descriptor": "",
    "authors": [
      "Samarth Sinha",
      "Adji B. Dieng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14859"
  },
  {
    "id": "arXiv:2105.14860",
    "title": "Definability Results for Top-Down Tree Transducers",
    "abstract": "We prove that for a given deterministic top-down transducer with look-ahead\nit is decidable whether or not its translation is definable (1)~by a linear\ntop-down tree transducer or (2)~by a tree homomorphism. We present algorithms\nthat construct equivalent such transducers if they exist.",
    "descriptor": "",
    "authors": [
      "Sebastian Maneth",
      "Helmut Seidl",
      "Martin Vu"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.14860"
  },
  {
    "id": "arXiv:2105.14867",
    "title": "Accurate and Efficient Time Series Matching by Season- and Trend-aware  Symbolic Approximation -- Extended Version Including Additional Evaluation  and Proofs",
    "abstract": "Processing and analyzing time series data\\-sets have become a central issue\nin many domains requiring data management systems to support time series as a\nnative data type. A crucial prerequisite of these systems is time series\nmatching, which still is a challenging problem. A time series is a\nhigh-dimensional data type, its representation is storage-, and its comparison\nis time-consuming. Among the representation techniques that tackle these\nchallenges, the symbolic aggregate approximation (SAX) is the current state of\nthe art. This technique reduces a time series to a low-dimensional space by\nsegmenting it and discretizing each segment into a small symbolic alphabet.\nHowever, SAX ignores the deterministic behavior of time series such as cyclical\nrepeating patterns or trend component affecting all segments and leading to a\ndistortion of the symbolic distribution. In this paper, we present a season-\nand a trend-aware symbolic approximation. We show that this improves the\nsymbolic distribution and increase the representation accuracy without\nincreasing its memory footprint. Most importantly, this enables a more\nefficient time series matching by providing a match up to three orders of\nmagnitude faster than SAX.",
    "descriptor": "",
    "authors": [
      "Lars Kegel",
      "Claudio Hartmann",
      "Maik Thiele",
      "Wolfgang Lehner"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2105.14867"
  },
  {
    "id": "arXiv:2105.14869",
    "title": "Collective Information Security in Large-Scale Urban Protests: the Case  of Hong Kong",
    "abstract": "The Anti-Extradition Law Amendment Bill protests in Hong Kong present a rich\ncontext for exploring information security practices among protesters due to\ntheir large-scale urban setting and highly digitalised nature. We conducted\nin-depth, semi-structured interviews with 11 participants of these protests.\nResearch findings reveal how protesters favoured Telegram and relied on its\nsecurity for internal communication and organisation of on-the-ground\ncollective action; were organised in small private groups and large public\ngroups to enable collective action; adopted tactics and technologies that\nenable pseudonymity; and developed a variety of strategies to detect\ncompromises and to achieve forms of forward secrecy and post-compromise\nsecurity when group members were (presumed) arrested. We further show how group\nadministrators had assumed the roles of leaders in these 'leaderless' protests\nand were critical to collective protest efforts.",
    "descriptor": "",
    "authors": [
      "Martin R. Albrecht",
      "Jorge Blasco",
      "Rikke Bjerg Jensen",
      "Lenka Marekov\u00e1"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14869"
  },
  {
    "id": "arXiv:2105.14874",
    "title": "BiasRV: Uncovering Biased Sentiment Predictions at Runtime",
    "abstract": "Sentiment analysis (SA) systems, though widely applied in many domains, have\nbeen demonstrated to produce biased results. Some research works have been done\nin automatically generating test cases to reveal unfairness in SA systems, but\nthe community still lacks tools that can monitor and uncover biased predictions\nat runtime. This paper fills this gap by proposing BiasRV, the first tool to\nraise an alarm when a deployed SA system makes a biased prediction on a given\ninput text. To implement this feature, BiasRV dynamically extracts a template\nfrom an input text and from the template generates gender-discriminatory\nmutants (semantically-equivalent texts that only differ in gender information).\nBased on popular metrics used to evaluate the overall fairness of an SA system,\nwe define distributional fairness property for an individual prediction of an\nSA system. This property specifies a requirement that for one piece of text,\nmutants from different gender classes should be treated similarly as a whole.\nVerifying the distributional fairness property causes much overhead to the\nrunning system. To run more efficiently, BiasRV adopts a two-step heuristic:\n(1) sampling several mutants from each gender and checking if the system\npredicts them as of the same sentiment, (2) checking distributional fairness\nonly when sampled mutants have conflicting results. Experiments show that\ncompared to directly checking the distributional fairness property for each\ninput text, our two-step heuristic can decrease overhead used for analyzing\nmutants by 73.81% while only resulting in 6.7% of biased predictions being\nmissed. Besides, BiasRV can be used conveniently without knowing the\nimplementation of SA systems. Future researchers can easily extend BiasRV to\ndetect more types of bias, e.g. race and occupation.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Zhou Yang",
      "Muhammad Hilmi Asyrofi",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14874"
  },
  {
    "id": "arXiv:2105.14875",
    "title": "Bangla Natural Language Processing: A Comprehensive Review of Classical,  Machine Learning, and Deep Learning Based Methods",
    "abstract": "The Bangla language is the seventh most spoken language, with 265 million\nnative and non-native speakers worldwide. However, English is the predominant\nlanguage for online resources and technical knowledge, journals, and\ndocumentation. Consequently, many Bangla-speaking people, who have limited\ncommand of English, face hurdles to utilize English resources. To bridge the\ngap between limited support and increasing demand, researchers conducted many\nexperiments and developed valuable tools and techniques to create and process\nBangla language materials. Many efforts are also ongoing to make it easy to use\nthe Bangla language in the online and technical domains. There are some review\npapers to understand the past, previous, and future Bangla Natural Language\nProcessing (BNLP) trends. The studies are mainly concentrated on the specific\ndomains of BNLP, such as sentiment analysis, speech recognition, optical\ncharacter recognition, and text summarization. There is an apparent scarcity of\nresources that contain a comprehensive study of the recent BNLP tools and\nmethods. Therefore, in this paper, we present a thorough review of 71 BNLP\nresearch papers and categorize them into 11 categories, namely Information\nExtraction, Machine Translation, Named Entity Recognition, Parsing, Parts of\nSpeech Tagging, Question Answering System, Sentiment Analysis, Spam and Fake\nDetection, Text Summarization, Word Sense Disambiguation, and Speech Processing\nand Recognition. We study articles published between 1999 to 2021, and 50\\% of\nthe papers were published after 2015. We discuss Classical, Machine Learning\nand Deep Learning approaches with different datasets while addressing the\nlimitations and current and future trends of the BNLP.",
    "descriptor": "\nComments: This preprint will be submitted to IEEE Access Journal and it contains total of 41 pages\n",
    "authors": [
      "Ovishake Sen",
      "Mohtasim Fuad",
      "MD. Nazrul Islam",
      "Jakaria Rabbi",
      "MD. Kamrul Hasan",
      "Awal Ahmed Fime",
      "Md. Tahmid Hasan Fuad",
      "Delowar Sikder",
      "MD. Akil Raihan Iftee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14875"
  },
  {
    "id": "arXiv:2105.14876",
    "title": "Fast, Accurate and Interpretable Time Series Classification Through  Randomization",
    "abstract": "Time series classification (TSC) aims to predict the class label of a given\ntime series, which is critical to a rich set of application areas such as\neconomics and medicine. State-of-the-art TSC methods have mostly focused on\nclassification accuracy and efficiency, without considering the\ninterpretability of their classifications, which is an important property\nrequired by modern applications such as appliance modeling and legislation such\nas the European General Data Protection Regulation. To address this gap, we\npropose a novel TSC method - the Randomized-Supervised Time Series Forest\n(r-STSF). r-STSF is highly efficient, achieves state-of-the-art classification\naccuracy and enables interpretability. r-STSF takes an efficient interval-based\napproach to classify time series according to aggregate values of\ndiscriminatory sub-series (intervals). To achieve state-of-the-art accuracy,\nr-STSF builds an ensemble of randomized trees using the discriminatory\nsub-series. It uses four time series representations, nine aggregation\nfunctions and a supervised binary-inspired search combined with a feature\nranking metric to identify highly discriminatory sub-series. The discriminatory\nsub-series enable interpretable classifications. Experiments on extensive\ndatasets show that r-STSF achieves state-of-the-art accuracy while being orders\nof magnitude faster than most existing TSC methods. It is the only classifier\nfrom the state-of-the-art group that enables interpretability. Our findings\nalso highlight that r-STSF is the best TSC method when classifying complex time\nseries datasets.",
    "descriptor": "",
    "authors": [
      "Nestor Cabello",
      "Elham Naghizade",
      "Jianzhong Qi",
      "Lars Kulik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14876"
  },
  {
    "id": "arXiv:2105.14877",
    "title": "Adaptive Multi-Source Causal Inference",
    "abstract": "Data scarcity is a tremendous challenge in causal effect estimation. In this\npaper, we propose to exploit additional data sources to facilitate estimating\ncausal effects in the target population. Specifically, we leverage additional\nsource datasets which share similar causal mechanisms with the target\nobservations to help infer causal effects of the target population. We propose\nthree levels of knowledge transfer, through modelling the outcomes, treatments,\nand confounders. To achieve consistent positive transfer, we introduce\nlearnable parametric transfer factors to adaptively control the transfer\nstrength, and thus achieving a fair and balanced knowledge transfer between the\nsources and the target. The proposed method can infer causal effects in the\ntarget population without prior knowledge of data discrepancy between the\nadditional data sources and the target. Experiments on both synthetic and\nreal-world datasets show the effectiveness of the proposed method as compared\nwith recent baselines.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Thanh Vinh Vo",
      "Pengfei Wei",
      "Trong Nghia Hoang",
      "Tze-Yun Leong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.14877"
  },
  {
    "id": "arXiv:2105.14878",
    "title": "Verdi: Quality Estimation and Error Detection for Bilingual",
    "abstract": "Translation Quality Estimation is critical to reducing post-editing efforts\nin machine translation and to cross-lingual corpus cleaning. As a research\nproblem, quality estimation (QE) aims to directly estimate the quality of\ntranslation in a given pair of source and target sentences, and highlight the\nwords that need corrections, without referencing to golden translations. In\nthis paper, we propose Verdi, a novel framework for word-level and\nsentence-level post-editing effort estimation for bilingual corpora. Verdi\nadopts two word predictors to enable diverse features to be extracted from a\npair of sentences for subsequent quality estimation, including a\ntransformer-based neural machine translation (NMT) model and a pre-trained\ncross-lingual language model (XLM). We exploit the symmetric nature of\nbilingual corpora and apply model-level dual learning in the NMT predictor,\nwhich handles a primal task and a dual task simultaneously with weight sharing,\nleading to stronger context prediction ability than single-direction NMT\nmodels. By taking advantage of the dual learning scheme, we further design a\nnovel feature to directly encode the translated target information without\nrelying on the source context. Extensive experiments conducted on WMT20 QE\ntasks demonstrate that our method beats the winner of the competition and\noutperforms other baseline methods by a great margin. We further use the\nsentence-level scores provided by Verdi to clean a parallel corpus and observe\nbenefits on both model performance and training efficiency.",
    "descriptor": "\nComments: Accepted by The Web Conference 2021\n",
    "authors": [
      "Mingjun Zhao",
      "Haijiang Wu",
      "Di Niu",
      "Zixuan Wang",
      "Xiaoli Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14878"
  },
  {
    "id": "arXiv:2105.14879",
    "title": "SemEval-2021 Task 4: Reading Comprehension of Abstract Meaning",
    "abstract": "This paper introduces the SemEval-2021 shared task 4: Reading Comprehension\nof Abstract Meaning (ReCAM). This shared task is designed to help evaluate the\nability of machines in representing and understanding abstract concepts. Given\na passage and the corresponding question, a participating system is expected to\nchoose the correct answer from five candidates of abstract concepts in a\ncloze-style machine reading comprehension setup. Based on two typical\ndefinitions of abstractness, i.e., the imperceptibility and nonspecificity, our\ntask provides three subtasks to evaluate the participating models.\nSpecifically, Subtask 1 aims to evaluate how well a system can model concepts\nthat cannot be directly perceived in the physical world. Subtask 2 focuses on\nmodels' ability in comprehending nonspecific concepts located high in a\nhypernym hierarchy given the context of a passage. Subtask 3 aims to provide\nsome insights into models' generalizability over the two types of abstractness.\nDuring the SemEval-2021 official evaluation period, we received 23 submissions\nto Subtask 1 and 28 to Subtask 2. The participating teams additionally made 29\nsubmissions to Subtask 3. The leaderboard and competition website can be found\nat https://competitions.codalab.org/competitions/26153. The data and baseline\ncode are available at\nhttps://github.com/boyuanzheng010/SemEval2021-Reading-Comprehension-of-Abstract-Meaning.",
    "descriptor": "",
    "authors": [
      "Boyuan Zheng",
      "Xiaoyu Yang",
      "Yu-Ping Ruan",
      "Zhenhua Ling",
      "Quan Liu",
      "Si Wei",
      "Xiaodan Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14879"
  },
  {
    "id": "arXiv:2105.14880",
    "title": "A Multilingual Modeling Method for Span-Extraction Reading Comprehension",
    "abstract": "Span-extraction reading comprehension models have made tremendous advances\nenabled by the availability of large-scale, high-quality training datasets.\nDespite such rapid progress and widespread application, extractive reading\ncomprehension datasets in languages other than English remain scarce, and\ncreating such a sufficient amount of training data for each language is costly\nand even impossible. An alternative to creating large-scale high-quality\nmonolingual span-extraction training datasets is to develop multilingual\nmodeling approaches and systems which can transfer to the target language\nwithout requiring training data in that language. In this paper, in order to\nsolve the scarce availability of extractive reading comprehension training data\nin the target language, we propose a multilingual extractive reading\ncomprehension approach called XLRC by simultaneously modeling the existing\nextractive reading comprehension training data in a multilingual environment\nusing self-adaptive attention and multilingual attention. Specifically, we\nfirstly construct multilingual parallel corpora by translating the existing\nextractive reading comprehension datasets (i.e., CMRC 2018) from the target\nlanguage (i.e., Chinese) into different language families (i.e., English).\nSecondly, to enhance the final target representation, we adopt self-adaptive\nattention (SAA) to combine self-attention and inter-attention to extract the\nsemantic relations from each pair of the target and source languages.\nFurthermore, we propose multilingual attention (MLA) to learn the rich\nknowledge from various language families. Experimental results show that our\nmodel outperforms the state-of-the-art baseline (i.e., RoBERTa_Large) on the\nCMRC 2018 task, which demonstrate the effectiveness of our proposed\nmulti-lingual modeling approach and show the potentials in multilingual NLP\ntasks.",
    "descriptor": "",
    "authors": [
      "Gaochen Wu",
      "Bin Xu",
      "Dejie Chang",
      "Bangchang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14880"
  },
  {
    "id": "arXiv:2105.14881",
    "title": "CrossASR++: A Modular Differential Testing Framework for Automatic  Speech Recognition",
    "abstract": "Developers need to perform adequate testing to ensure the quality of\nAutomatic Speech Recognition (ASR) systems. However, manually collecting\nrequired test cases is tedious and time-consuming. Our recent work proposes\nCrossASR, a differential testing method for ASR systems. This method first\nutilizes Text-to-Speech (TTS) to generate audios from texts automatically and\nthen feed these audios into different ASR systems for cross-referencing to\nuncover failed test cases. It also leverages a failure estimator to find\nfailing test cases more efficiently. Such a method is inherently\nself-improvable: the performance can increase by leveraging more advanced TTS\nand ASR systems. So in this accompanying tool demo paper, we devote more\nengineering and propose CrossASR++, an easy-to-use ASR testing tool that can be\nconveniently extended to incorporate different TTS and ASR systems, and failure\nestimators. We also make CrossASR++ chunk texts from a given corpus dynamically\nand enable the estimator to work in a more effective and flexible way. We\ndemonstrate that the new features can help CrossASR++ discover more failed test\ncases. Using the same TTS and ASR systems, CrossASR++ can uncover 26.2% more\nfailed test cases for 4 ASRs than the original tool. Moreover, by simply adding\none more ASR for cross-referencing, we can increase the number of failed test\ncases uncovered for each of the 4 ASR systems by 25.07%, 39.63%, 20.9\\% and\n8.17% respectively. We also extend CrossASR++ with 5 additional failure\nestimators. Compared to worst estimator, the best one can discover 10.41% more\nfailed test cases within the same amount of time.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Muhammad Hilmi Asyrofi",
      "Zhou Yang",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14881"
  },
  {
    "id": "arXiv:2105.14882",
    "title": "Parameterized Problems Complete for Nondeterministic FPT time and  Logarithmic Space",
    "abstract": "Let XNLP be the class of parameterized problems such that an instance of size\n$n$ with parameter $k$ can be solved nondeterministically in time\n$f(k)n^{O(1)}$ and space $f(k)\\log(n)$ (for some computable function $f$). We\ngive a wide variety of XNLP-complete problems, such as {\\sc List Coloring} and\n{\\sc Precoloring Extension} with pathwidth as parameter, {\\sc Scheduling of\nJobs with Precedence Constraints}, with both number of machines and partial\norder width as parameter, {\\sc Bandwidth} and variants of {\\sc Weighted\nCNF-Satisfiability} and reconfiguration problems. In particular, this implies\nthat all these problems are $W[t]$-hard for all $t$. This also answers a long\nstanding question on the parameterized complexity of the {\\sc Bandwidth}\nproblem.",
    "descriptor": "",
    "authors": [
      "Hans L. Bodlaender",
      "Carla Groenland",
      "Jesper Nederlof",
      "C\u00e9line M. F. Swennenhuis"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2105.14882"
  },
  {
    "id": "arXiv:2105.14884",
    "title": "Control of bifurcation structures using shape optimization",
    "abstract": "Many problems in engineering can be understood as controlling the bifurcation\nstructure of a given device. For example, one may wish to delay the onset of\ninstability, or bring forward a bifurcation to enable rapid switching between\nstates. We propose a numerical technique for controlling the bifurcation\ndiagram of a nonlinear partial differential equation by varying the shape of\nthe domain. Specifically, we are able to delay or advance a given bifurcation\npoint to a given parameter value, often to within machine precision. The\nalgorithm consists of solving a shape optimization problem constrained by an\naugmented system of equations, the Moore--Spence system, that characterize the\nlocation of the bifurcation points. Numerical experiments on the Allen--Cahn,\nNavier--Stokes, and hyperelasticity equations demonstrate the effectiveness of\nthis technique in a wide range of settings.",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Nicolas Boull\u00e9",
      "Patrick E. Farrell",
      "Alberto Paganini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.14884"
  },
  {
    "id": "arXiv:2105.14887",
    "title": "Parameterised Complexity of Propositional Logic in Team Semantics",
    "abstract": "In this work we analyse the parameterised complexity of propositional\ninclusion (PINC) and independence logic (PIND). The problems of interest are\nmodel checking (MC) and satisfiability (SAT). The complexity of these problems\nis well understood in the classical (non-parameterised) setting. Mahmood and\nMeier (FoIKS 2020) recently studied the parameterised complexity of\npropositional dependence logic (PDL). As a continuation of their work, we\nclassify inclusion and independence logic and thereby come closer to completing\nthe picture with respect to the parametrised complexity for the three most\nstudied logics in the propositional team semantics setting. We present results\nfor each problem with respect to 8 different parameterisations. It turns out\nthat for a team-based logic L such that L-atoms can be evaluated in polynomial\ntime, then MC parameterised by teamsize is FPT. As a corollary, we get an FPT\nmembership under the following parameterisations: formula-size, formula-depth,\ntreewidth, and number of variables. The parameter teamsize shows interesting\nbehavior for SAT. For PINC, the parameter teamsize is not meaningful, whereas\nfor PDL and PIND the satisfiability is paraNP-complete. Finally, we prove that\nwhen parameterised by arity, both MC and SAT are paraNP-complete for each of\nthe considered logics.",
    "descriptor": "",
    "authors": [
      "Yasir Mahmood",
      "Jonni Virtema"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14887"
  },
  {
    "id": "arXiv:2105.14888",
    "title": "An Exploratory Analysis of the Relation Between Offensive Language and  Mental Health",
    "abstract": "In this paper, we analyze the interplay between the use of offensive language\nand mental health. We acquired publicly available datasets created for\noffensive language identification and depression detection and we train\ncomputational models to compare the use of offensive language in social media\nposts written by groups of individuals with and without self-reported\ndepression diagnosis. We also look at samples written by groups of individuals\nwhose posts show signs of depression according to recent related studies. Our\nanalysis indicates that offensive language is more frequently used in the\nsamples written by individuals with self-reported depression as well as\nindividuals showing signs of depression. The results discussed here open new\navenues in research in politeness/offensiveness and mental health.",
    "descriptor": "\nComments: Accepted to Findings of the Association for Computational Linguistics: ACL 2021\n",
    "authors": [
      "Ana-Maria Bucur",
      "Marcos Zampieri",
      "Liviu P. Dinu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14888"
  },
  {
    "id": "arXiv:2105.14890",
    "title": "Rawlsian Fair Adaptation of Deep Learning Classifiers",
    "abstract": "Group-fairness in classification aims for equality of a predictive utility\nacross different sensitive sub-populations, e.g., race or gender. Equality or\nnear-equality constraints in group-fairness often worsen not only the aggregate\nutility but also the utility for the least advantaged sub-population. In this\npaper, we apply the principles of Pareto-efficiency and least-difference to the\nutility being accuracy, as an illustrative example, and arrive at the Rawls\nclassifier that minimizes the error rate on the worst-off sensitive\nsub-population. Our mathematical characterization shows that the Rawls\nclassifier uniformly applies a threshold to an ideal score of features, in the\nspirit of fair equality of opportunity. In practice, such a score or a feature\nrepresentation is often computed by a black-box model that has been useful but\nunfair. Our second contribution is practical Rawlsian fair adaptation of any\ngiven black-box deep learning model, without changing the score or feature\nrepresentation it computes. Given any score function or feature representation\nand only its second-order statistics on the sensitive sub-populations, we seek\na threshold classifier on the given score or a linear threshold classifier on\nthe given feature representation that achieves the Rawls error rate restricted\nto this hypothesis class. Our technical contribution is to formulate the above\nproblems using ambiguous chance constraints, and to provide efficient\nalgorithms for Rawlsian fair adaptation, along with provable upper bounds on\nthe Rawls error rate. Our empirical results show significant improvement over\nstate-of-the-art group-fair algorithms, even without retraining for fairness.",
    "descriptor": "\nComments: 24 figures, 19 figures\n",
    "authors": [
      "Kulin Shah",
      "Pooja Gupta",
      "Amit Deshpande",
      "Chiranjib Bhattacharyya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14890"
  },
  {
    "id": "arXiv:2105.14891",
    "title": "ACNet: Mask-Aware Attention with Dynamic Context Enhancement for Robust  Acne Detection",
    "abstract": "Computer-aided diagnosis has recently received attention for its advantage of\nlow cost and time efficiency. Although deep learning played a major role in the\nrecent success of acne detection, there are still several challenges such as\ncolor shift by inconsistent illumination, variation in scales, and high density\ndistribution. To address these problems, we propose an acne detection network\nwhich consists of three components, specifically: Composite Feature Refinement,\nDynamic Context Enhancement, and Mask-Aware Multi-Attention. First, Composite\nFeature Refinement integrates semantic information and fine details to enrich\nfeature representation, which mitigates the adverse impact of imbalanced\nillumination. Then, Dynamic Context Enhancement controls different receptive\nfields of multi-scale features for context enhancement to handle scale\nvariation. Finally, Mask-Aware Multi-Attention detects densely arranged and\nsmall acne by suppressing uninformative regions and highlighting probable acne\nregions. Experiments are performed on acne image dataset ACNE04 and natural\nimage dataset PASCAL VOC 2007. We demonstrate how our method achieves the\nstate-of-the-art result on ACNE04 and competitive performance with previous\nstate-of-the-art methods on the PASCAL VOC 2007.",
    "descriptor": "",
    "authors": [
      "Kyungseo Min",
      "Gun-Hee Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14891"
  },
  {
    "id": "arXiv:2105.14894",
    "title": "LTL-Constrained Steady-State Policy Synthesis",
    "abstract": "Decision-making policies for agents are often synthesized with the constraint\nthat a formal specification of behaviour is satisfied. Here we focus on\ninfinite-horizon properties. On the one hand, Linear Temporal Logic (LTL) is a\npopular example of a formalism for qualitative specifications. On the other\nhand, Steady-State Policy Synthesis (SSPS) has recently received considerable\nattention as it provides a more quantitative and more behavioural perspective\non specifications, in terms of the frequency with which states are visited.\nFinally, rewards provide a classic framework for quantitative properties. In\nthis paper, we study Markov decision processes (MDP) with the specification\ncombining all these three types. The derived policy maximizes the reward among\nall policies ensuring the LTL specification with the given probability and\nadhering to the steady-state constraints. To this end, we provide a unified\nsolution reducing the multi-type specification to a multi-dimensional long-run\naverage reward. This is enabled by Limit-Deterministic B\\\"uchi Automata (LDBA),\nrecently studied in the context of LTL model checking on MDP, and allows for an\nelegant solution through a simple linear programme. The algorithm also extends\nto the general $\\omega$-regular properties and runs in time polynomial in the\nsizes of the MDP as well as the LDBA.",
    "descriptor": "",
    "authors": [
      "Jan K\u0159et\u00ednsk\u00fd"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14894"
  },
  {
    "id": "arXiv:2105.14895",
    "title": "APEX: Unsupervised, Object-Centric Scene Segmentation and Tracking for  Robot Manipulation",
    "abstract": "Recent advances in unsupervised learning for object detection, segmentation,\nand tracking hold significant promise for applications in robotics. A common\napproach is to frame these tasks as inference in probabilistic latent-variable\nmodels. In this paper, however, we show that the current state-of-the-art\nstruggles with visually complex scenes such as typically encountered in robot\nmanipulation tasks. We propose APEX, a new latent-variable model which is able\nto segment and track objects in more realistic scenes featuring objects that\nvary widely in size and texture, including the robot arm itself. This is\nachieved by a principled mask normalisation algorithm and a high-resolution\nscene encoder. To evaluate our approach, we present results on the real-world\nSketchy dataset. This dataset, however, does not contain ground truth masks and\nobject IDs for a quantitative evaluation. We thus introduce the Panda Pushing\nDataset (P2D) which shows a Panda arm interacting with objects on a table in\nsimulation and which includes ground-truth segmentation masks and object IDs\nfor tracking. In both cases, APEX comprehensively outperforms the current\nstate-of-the-art in unsupervised object segmentation and tracking. We\ndemonstrate the efficacy of our segmentations for robot skill execution on an\nobject arrangement task, where we also achieve the best or comparable\nperformance among all the baselines.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Yizhe Wu",
      "Oiwi Parker Jones",
      "Martin Engelcke",
      "Ingmar Posner"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14895"
  },
  {
    "id": "arXiv:2105.14897",
    "title": "Connecting Language and Vision for Natural Language-Based Vehicle  Retrieval",
    "abstract": "Vehicle search is one basic task for the efficient traffic management in\nterms of the AI City. Most existing practices focus on the image-based vehicle\nmatching, including vehicle re-identification and vehicle tracking. In this\npaper, we apply one new modality, i.e., the language description, to search the\nvehicle of interest and explore the potential of this task in the real-world\nscenario. The natural language-based vehicle search poses one new challenge of\nfine-grained understanding of both vision and language modalities. To connect\nlanguage and vision, we propose to jointly train the state-of-the-art vision\nmodels with the transformer-based language model in an end-to-end manner.\nExcept for the network structure design and the training strategy, several\noptimization objectives are also re-visited in this work. The qualitative and\nquantitative experiments verify the effectiveness of the proposed method. Our\nproposed method has achieved the 1st place on the 5th AI City Challenge,\nyielding competitive performance 18.69% MRR accuracy on the private test set.\nWe hope this work can pave the way for the future study on using language\ndescription effectively and efficiently for real-world vehicle retrieval\nsystems. The code will be available at\nhttps://github.com/ShuaiBai623/AIC2021-T5-CLV.",
    "descriptor": "\nComments: CVPR 2021 AI CITY CHALLENGE Natural Language-Based Vehicle Retrieval Top 1\n",
    "authors": [
      "Shuai Bai",
      "Zhedong Zheng",
      "Xiaohan Wang",
      "Junyang Lin",
      "Zhu Zhang",
      "Chang Zhou",
      "Yi Yang",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14897"
  },
  {
    "id": "arXiv:2105.14898",
    "title": "Retweet communities reveal the main sources of hate speech",
    "abstract": "We address a challenging problem of identifying main sources of hate speech\non Twitter. On one hand, we carefully annotate a large set of tweets for hate\nspeech, and deploy advanced deep learning to produce high quality hate speech\nclassification models. On the other hand, we create retweet networks, detect\ncommunities and monitor their evolution through time. This combined approach is\napplied to three years of Slovenian Twitter data. We report a number of\ninteresting results. Hate speech is dominated by offensive tweets, related to\npolitical and ideological issues. The share of unacceptable tweets is\nmoderately increasing with time, from the initial 20% to 30% by the end of\n2020. Unacceptable tweets are retweeted significantly more often than\nacceptable tweets. About 60% of unacceptable tweets are produced by a single\nright-wing community of only moderate size. Institutional Twitter accounts and\nmedia accounts post significantly less unacceptable tweets than individual\naccounts. However, the main sources of unacceptable tweets are anonymous\naccounts, and accounts that were suspended or closed during the last three\nyears.",
    "descriptor": "",
    "authors": [
      "Bojan Evkoski",
      "Andraz Pelicon",
      "Igor Mozetic",
      "Nikola Ljubesic",
      "Petra Kralj Novak"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14898"
  },
  {
    "id": "arXiv:2105.14900",
    "title": "A unified view of likelihood ratio and reparameterization gradients",
    "abstract": "Reparameterization (RP) and likelihood ratio (LR) gradient estimators are\nused to estimate gradients of expectations throughout machine learning and\nreinforcement learning; however, they are usually explained as simple\nmathematical tricks, with no insight into their nature. We use a first\nprinciples approach to explain that LR and RP are alternative methods of\nkeeping track of the movement of probability mass, and the two are connected\nvia the divergence theorem. Moreover, we show that the space of all possible\nestimators combining LR and RP can be completely parameterized by a flow field\n$u(x)$ and an importance sampling distribution $q(x)$. We prove that there\ncannot exist a single-sample estimator of this type outside our characterized\nspace, thus, clarifying where we should be searching for better Monte Carlo\ngradient estimators.",
    "descriptor": "\nComments: AISTATS2021; Earlier paper was split in two (arXiv:1910.06419). Refer to the current paper for the unified view, but see the earlier paper for discussion on an importance sampling technique\n",
    "authors": [
      "Paavo Parmas",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14900"
  },
  {
    "id": "arXiv:2105.14901",
    "title": "User Experience Design for E-Voting: How mental models align with  security mechanisms",
    "abstract": "This paper presents a mobile application for vote-casting and\nvote-verification based on the Selene e-voting protocol and explains how it was\ndeveloped and implemented using the User Experience Design process. The\nresulting interface was tested with 38 participants, and user experience data\nwas collected via questionnaires and semi-structured interviews on user\nexperience and perceived security. Results concerning the impact of displaying\nsecurity mechanisms on UX were presented in a complementary paper. Here we\nexpand on this analysis by studying the mental models revealed during the\ninterviews and compare them with theoretical security notions. Finally, we\npropose a list of improvements for designs of future voting protocols.",
    "descriptor": "\nComments: E-Vote-ID 2019 TalTech Proceedings\n",
    "authors": [
      "Marie-Laure Zollinger",
      "Verena Distler",
      "Peter B. Roenne",
      "Peter Y. A. Ryan",
      "Carine Lallemand",
      "Vincent Koenig"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14901"
  },
  {
    "id": "arXiv:2105.14903",
    "title": "Lower Bounds for the Number of Repetitions in 2D Strings",
    "abstract": "A two-dimensional string is simply a two-dimensional array. We continue the\nstudy of the combinatorial properties of repetitions in such strings over the\nbinary alphabet, namely the number of distinct tandems, distinct quartics, and\nruns. First, we construct an infinite family of $n\\times n$ 2D strings with\n$\\Omega(n^{3})$ distinct tandems. Second, we construct an infinite family of\n$n\\times n$ 2D strings with $\\Omega(n^{2}\\log n)$ distinct quartics. Third, we\nconstruct an infinite family of $n\\times n$ 2D strings with $\\Omega(n^{2}\\log\nn)$ runs. This resolves an open question of Charalampopoulos, Radoszewski,\nRytter, Wale\\'n, and Zuba [ESA 2020], who asked if the number of distinct\nquartics and runs in an $n\\times n$ 2D string is $\\mathcal{O}(n^{2})$.",
    "descriptor": "",
    "authors": [
      "Pawe\u0142 Gawrychowski",
      "Samah Ghazawi",
      "Gad M. Landau"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.14903"
  },
  {
    "id": "arXiv:2105.14909",
    "title": "Generating Interesting Song-to-Song Segues With Dave",
    "abstract": "We introduce a novel domain-independent algorithm for generating interesting\nitem-to-item textual connections, or segues. Pivotal to our contribution is the\nintroduction of a scoring function for segues, based on their\n\"interestingness\". We provide an implementation of our algorithm in the music\ndomain. We refer to our implementation as Dave. Dave is able to generate 1553\ndifferent types of segues, that can be broadly categorized as either\ninformative or funny. We evaluate Dave by comparing it against a curated source\nof song-to-song segues, called The Chain. In the case of informative segues, we\nfind that Dave can produce segues of the same quality, if not better, than\nthose to be found in The Chain. And, we report positive correlation between the\nvalues produced by our scoring function and human perceptions of segue quality.\nThe results highlight the validity of our method, and open future directions in\nthe application of segues to recommender systems research.",
    "descriptor": "",
    "authors": [
      "Giovanni Gabbolini",
      "Derek Bridge"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.14909"
  },
  {
    "id": "arXiv:2105.14913",
    "title": "GWLAN: General Word-Level AutocompletioN for Computer-Aided Translation",
    "abstract": "Computer-aided translation (CAT), the use of software to assist a human\ntranslator in the translation process, has been proven to be useful in\nenhancing the productivity of human translators. Autocompletion, which suggests\ntranslation results according to the text pieces provided by human translators,\nis a core function of CAT. There are two limitations in previous research in\nthis line. First, most research works on this topic focus on sentence-level\nautocompletion (i.e., generating the whole translation as a sentence based on\nhuman input), but word-level autocompletion is under-explored so far. Second,\nalmost no public benchmarks are available for the autocompletion task of CAT.\nThis might be among the reasons why research progress in CAT is much slower\ncompared to automatic MT. In this paper, we propose the task of general\nword-level autocompletion (GWLAN) from a real-world CAT scenario, and construct\nthe first public benchmark to facilitate research in this topic. In addition,\nwe propose an effective method for GWLAN and compare it with several strong\nbaselines. Experiments demonstrate that our proposed method can give\nsignificantly more accurate predictions than the baseline methods on our\nbenchmark datasets.",
    "descriptor": "\nComments: Accepted into the main conference of ACL 2021. arXiv admin note: text overlap with arXiv:2105.13072\n",
    "authors": [
      "Huayang Li",
      "Lemao Liu",
      "Guoping Huang",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14913"
  },
  {
    "id": "arXiv:2105.14914",
    "title": "DILIGENT-KIO: A Proprioceptive Base Estimator for Humanoid Robots using  Extended Kalman Filtering on Matrix Lie Groups",
    "abstract": "This paper presents a contact-aided inertial-kinematic floating base\nestimation for humanoid robots considering an evolution of the state and\nobservations over matrix Lie groups. This is achieved through the application\nof a geometrically meaningful estimator which is characterized by concentrated\nGaussian distributions. The configuration of a floating base system like a\nhumanoid robot usually requires the knowledge of an additional six degrees of\nfreedom which describes its base position-and-orientation. This quantity\nusually cannot be measured and needs to be estimated. A matrix Lie group,\nencapsulating the position-and-orientation and linear velocity of the base\nlink, feet positions-and-orientations and Inertial Measurement Units' biases,\nis used to represent the state while relative positions-and-orientations of\ncontact feet from forward kinematics are used as observations. The proposed\nestimator exhibits fast convergence for large initialization errors owing to\nchoice of uncertainty parametrization. An experimental validation is done on\nthe iCub humanoid platform.",
    "descriptor": "\nComments: Accepted to the IEEE International Conference on Robotics and Automation (ICRA) 2021\n",
    "authors": [
      "Prashanth Ramadoss",
      "Giulio Romualdi",
      "Stefano Dafarra",
      "Francisco Javier Andrade Chavez",
      "Silvio Traversaro",
      "Daniele Pucci"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14914"
  },
  {
    "id": "arXiv:2105.14915",
    "title": "SMASH: a Semantic-enabled Multi-agent Approach for Self-adaptation of  Human-centered IoT",
    "abstract": "Nowadays, IoT devices have an enlarging scope of activities spanning from\nsensing, computing to acting and even more, learning, reasoning and planning.\nAs the number of IoT applications increases, these objects are becoming more\nand more ubiquitous. Therefore, they need to adapt their functionality in\nresponse to the uncertainties of their environment to achieve their goals. In\nHuman-centered IoT, objects and devices have direct interactions with human\nbeings and have access to online contextual information. Self-adaptation of\nsuch applications is a crucial subject that needs to be addressed in a way that\nrespects human goals and human values. Hence, IoT applications must be equipped\nwith self-adaptation techniques to manage their run-time uncertainties locally\nor in cooperation with each other. This paper presents SMASH: a multi-agent\napproach for self-adaptation of IoT applications in human-centered\nenvironments. In this paper, we have considered the Smart Home as the case\nstudy of smart environments. SMASH agents are provided with a 4-layer\narchitecture based on the BDI agent model that integrates human values with\ngoal-reasoning, planning, and acting. It also takes advantage of a\nsemantic-enabled platform called Home'In to address interoperability issues\namong non-identical agents and devices with heterogeneous protocols and data\nformats. This approach is compared with the literature and is validated by\ndeveloping a scenario as the proof of concept. The timely responses of SMASH\nagents show the feasibility of the proposed approach in human-centered\nenvironments.",
    "descriptor": "\nComments: Submitted to PAAMS 2021\n",
    "authors": [
      "Hamed Rahimi",
      "Iago Felipe Trentin",
      "Fano Ramparany",
      "Olivier Boissier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14915"
  },
  {
    "id": "arXiv:2105.14917",
    "title": "Measurement placement in electric power transmission and distribution  grids: Review of methods and opportunities",
    "abstract": "Sensing and measurement systems are a quintessential piece to the safe and\nreliable operation of electric power grids. Their strategic placement is of\nultimate importance because it is not economically viable to install\nmeasurement systems on every node and branch of a power grid, though they need\nto be monitored. An overwhelming number of strategies have been developed to\nmeet oftentimes multiple conflicting objectives. The prime challenge in\nformulating the problem lies in developing a heuristic or an optimization model\nthat, though mathematically tractable and constrained in cost, leads to\ntrustworthy technical solutions. Besides, large-scale, long-term deployments\npose additional challenges because the boundary conditions change as\ntechnologies evolve. For instance, the advent of new technologies in sensing\nand measurement, as well as in communications and networking, might impact the\ncost and performance of available solutions and shift initially set conditions.\nAlso, the placement strategies developed for transmission grids might not be\nsuitable for distribution grids, and vice versa, due to unique characteristics.\nTherefore, the strategies need to be flexible, to a certain extent, because no\ntwo power grids are alike. Despite the extensive literature on the present\ntopic, the focus of published works tends to be on a specific subject, such as\noptimal placement of measurements to assure observability in transmission\ngrids. There is a dearth of work providing a comprehensive picture for\ndeveloping optimal placement strategies. Because of the ongoing efforts on the\nmodernization of electric power grids, there is a need to consolidate the\nstatus quo while exposing its limitations to inform policymakers, industry\nstakeholders, and researchers on the research-and-development needs to push the\nboundaries for innovation.",
    "descriptor": "",
    "authors": [
      "Marcos Netto",
      "Venkat Krishnan",
      "Yingchen Zhang",
      "Lamine Mili"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14917"
  },
  {
    "id": "arXiv:2105.14918",
    "title": "Long-term Scientific Impact Revisited",
    "abstract": "Citation based measures are widely used as quantitative proxies for\nsubjective factors such as the importance of a paper or even the worth of\nindividual researchers. Here we analyze the citation histories of $4669$ papers\npublished in journals of the American Physical Society between $1960$ and\n$1968$ and argue that state-of-the-art models of citation dynamics and\nalgorithms for forecasting nonstationary time series are very likely to fail to\npredict the long-term ($50$ years after publication) citation counts of\nhighly-cited papers using citation data collected in a short period (say, $10$\nyears) after publication. This is so because those papers do not exhibit\ndistinctive short-term citation patterns, although their long-term citation\npatterns clearly set them apart from the other papers. We conclude that even if\none accepts that citation counts are proxies for the quality of papers, they\nare not useful evaluative tools since the short-term counts are not informative\nabout the long-term counts in the case of highly-cited papers.",
    "descriptor": "",
    "authors": [
      "Sandro M. Reia",
      "Jos\u00e9 F. Fontanari"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.14918"
  },
  {
    "id": "arXiv:2105.14921",
    "title": "How Lexical Gold Standards Have Effects On The Usefulness Of Text  Analysis Tools For Digital Scholarship",
    "abstract": "This paper describes how the current lexical similarity and analogy gold\nstandards are built to conform to certain ideas about what the models they are\ndesigned to evaluate are used for. Topical relevance has always been the most\nimportant target notion for information access tools and related language\ntechnology technologies, and while this has proven a useful starting point for\nmuch of what information technology is used for, it does not always align well\nwith other uses to which technologies are being put, most notably use cases\nfrom digital scholarship in the humanities or social sciences. This paper\nargues for more systematic formulation of requirements from the digital\nhumanities and social sciences and more explicit description of the assumptions\nunderlying model design.",
    "descriptor": "",
    "authors": [
      "Jussi Karlgren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14921"
  },
  {
    "id": "arXiv:2105.14923",
    "title": "Hybrid Henry Gas Solubility Optimization Algorithm with Dynamic  Cluster-to-Algorithm Mapping for Search-based Software Engineering Problems",
    "abstract": "This paper discusses a new variant of the Henry Gas Solubility Optimization\n(HGSO) Algorithm, called Hybrid HGSO (HHGSO). Unlike its predecessor, HHGSO\nallows multiple clusters serving different individual meta-heuristic algorithms\n(i.e., with its own defined parameters and local best) to coexist within the\nsame population. Exploiting the dynamic cluster-to-algorithm mapping via\npenalized and reward model with adaptive switching factor, HHGSO offers a novel\napproach for meta-heuristic hybridization consisting of Jaya Algorithm, Sooty\nTern Optimization Algorithm, Butterfly Optimization Algorithm, and Owl Search\nAlgorithm, respectively. The acquired results from the selected two case\nstudies (i.e., involving team formation problem and combinatorial test suite\ngeneration) indicate that the hybridization has notably improved the\nperformance of HGSO and gives superior performance against other competing\nmeta-heuristic and hyper-heuristic algorithms.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Kamal Z. Zamli",
      "Md. Abdul Kader",
      "Saiful Azad",
      "Bestoun S. Ahmed"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14923"
  },
  {
    "id": "arXiv:2105.14924",
    "title": "Document-level Event Extraction via Heterogeneous Graph-based  Interaction Model with a Tracker",
    "abstract": "Document-level event extraction aims to recognize event information from a\nwhole piece of article. Existing methods are not effective due to two\nchallenges of this task: a) the target event arguments are scattered across\nsentences; b) the correlation among events in a document is non-trivial to\nmodel. In this paper, we propose Heterogeneous Graph-based Interaction Model\nwith a Tracker (GIT) to solve the aforementioned two challenges. For the first\nchallenge, GIT constructs a heterogeneous graph interaction network to capture\nglobal interactions among different sentences and entity mentions. For the\nsecond, GIT introduces a Tracker module to track the extracted events and hence\ncapture the interdependency among the events. Experiments on a large-scale\ndataset (Zheng et al., 2019) show GIT outperforms the previous methods by 2.8\nF1. Further analysis reveals GIT is effective in extracting multiple correlated\nevents and event arguments that scatter across the document. Our code is\navailable at https://github.com/RunxinXu/GIT.",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021 main conference (Long Paper)\n",
    "authors": [
      "Runxin Xu",
      "Tianyu Liu",
      "Lei Li",
      "Baobao Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14924"
  },
  {
    "id": "arXiv:2105.14931",
    "title": "Document Domain Randomization for Deep Learning Document Layout  Extraction",
    "abstract": "We present document domain randomization (DDR), the first successful transfer\nof convolutional neural networks (CNNs) trained only on graphically rendered\npseudo-paper pages to real-world document segmentation. DDR renders\npseudo-document pages by modeling randomized textual and non-textual contents\nof interest, with user-defined layout and font styles to support joint learning\nof fine-grained classes. We demonstrate competitive results using our DDR\napproach to extract nine document classes from the benchmark CS-150 and papers\npublished in two domains, namely annual meetings of Association for\nComputational Linguistics (ACL) and IEEE Visualization (VIS). We compare DDR to\nconditions of style mismatch, fewer or more noisy samples that are more easily\nobtained in the real world. We show that high-fidelity semantic information is\nnot necessary to label semantic classes but style mismatch between train and\ntest can lower model accuracy. Using smaller training samples had a slightly\ndetrimental effect. Finally, network models still achieved high test accuracy\nwhen correct labels are diluted towards confusing labels; this behavior hold\nacross several classes.",
    "descriptor": "\nComments: Main paper to appear in ICDAR 2021 (16th International Conference on Document Analysis and Recognition). This version contains additional materials. The associated test data is hosted on IEEE Data Port: this http URL\n",
    "authors": [
      "Meng Ling",
      "Jian Chen",
      "Torsten M\u00f6ller",
      "Petra Isenberg",
      "Tobias Isenberg",
      "Michael Sedlmair",
      "Robert S. Laramee",
      "Han-Wei Shen",
      "Jian Wu",
      "C. Lee Giles"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14931"
  },
  {
    "id": "arXiv:2105.14932",
    "title": "STEP: Spatial-Temporal Network Security Event Prediction",
    "abstract": "Network security events prediction helps network operators to take response\nstrategies from a proactive perspective, and reduce the cost caused by network\nattacks, which is of great significance for maintaining the security of the\nentire network. Most of the existing event prediction methods rely on temporal\ncharacteristics and are dedicated to exploring time series predictions, but\nignoring the spatial relationship between hosts. This paper combines the\ntemporal and spatial characteristics of security events and proposes a\nspatial-temporal event prediction model, named STEP. In particular, STEP\nformulates the security events prediction into a spatial-temporal sequence\nprediction. STEP utilizes graph convolution operation to capture the spatial\ncharacteristics of hosts in the network, and adopts the long short term memory\n(LSTM) to capture the dynamic temporal dependency of events. This paper\nverifies the proposed STEP scheme on two public data sets. The experimental\nresults show that the prediction accuracy of security events under STEP is\nhigher than that of benchmark models such as LSTM, ConvLSTM. Besides, STEP\nachieves high prediction accuracy when we predict events from different lengths\nof sequence.",
    "descriptor": "",
    "authors": [
      "Qiumei Cheng",
      "Yi Shen",
      "Dezhang Kong",
      "Chunming Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14932"
  },
  {
    "id": "arXiv:2105.14934",
    "title": "Review Of Integrated Photonic Elastic WDM Switches For Data Centers",
    "abstract": "In this review paper, we present an elaborate discussion on wavelength\nselective switches and their demonstrations. We also review packaging and\nelectronic photonic integration of switches; a topic neglected in other review\npapers. We also cover wavelength locking which is paramount in switching\nnetworks with many tunable filters.",
    "descriptor": "",
    "authors": [
      "Akhilesh S P Khope",
      "Anirban Samanta",
      "Xian Xiao",
      "Ben Yoo",
      "John E Bowers"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2105.14934"
  },
  {
    "id": "arXiv:2105.14935",
    "title": "Microservice Maturity of Organizations: towards an assessment framework",
    "abstract": "This early work aims to allow organizations to diagnose their capacity to\nproperly adopt microservices through initial milestones of a Microservice\nMaturity Model (MiMMo). The objective is to prepare the way towards a general\nframework to help companies and industries to determine their microservices\nmaturity. Organizations lean more and more on distributed web applications and\nLine of Business software. This is particularly relevant during the current\nCovid-19 crisis, where companies are even more challenged to offer their\nservices online, targeting a very high level of responsiveness in the face of\nrapidly increasing and diverse demands. For this, microservices remain the most\nsuitable delivery application architectural style. They allow agility not only\non the technical application, as often considered, but on the enterprise\narchitecture as a whole, influencing the actual financial business of the\ncompany. However, microservices adoption is highly risk-prone and complex.\nBefore they establish an appropriate migration plan, first and foremost,\ncompanies must assess their degree of readiness to adopt microservices. For\nthis, MiMMo, a Microservices Maturity Model framework assessment, is proposed\nto help companies assess their readiness for the microservice architectural\nstyle, based on their actual situation. MiMMo results from observations of and\nexperience with about thirty organizations writing software. It conceptualizes\nand generalizes the progression paths they have followed to adopt microservices\nappropriately. Using the model, an organization can evaluate itself in two\ndimensions and five maturity levels and thus: (i) benchmark itself on its\ncurrent use of microservices; (ii) project the next steps it needs to achieve a\nhigher maturity level and (iii) analyze how it has evolved and maintain a\nglobal coherence between technical and business stakes.",
    "descriptor": "",
    "authors": [
      "Jean-Philippe Gouigoux",
      "Dalila Tamzalit",
      "Joost Noppen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14935"
  },
  {
    "id": "arXiv:2105.14937",
    "title": "Safe Pontryagin Differentiable Programming",
    "abstract": "We propose a Safe Pontryagin Differentiable Programming (Safe PDP)\nmethodology, which establishes a theoretical and algorithmic safe\ndifferentiable framework to solve a broad class of safety-critical learning and\ncontrol tasks -- problems that require the guarantee of both immediate and\nlong-term constraint satisfaction at any stage of the learning and control\nprogress. In the spirit of interior-point methods, Safe PDP handles different\ntypes of state and input constraints by incorporating them into the cost and\nloss through barrier functions. We prove the following fundamental features of\nSafe PDP: first, both the constrained solution and its gradient in backward\npass can be approximated by solving a more efficient unconstrained counterpart;\nsecond, the approximation for both the solution and its gradient can be\ncontrolled for arbitrary accuracy using a barrier parameter; and third,\nimportantly, any intermediate results throughout the approximation and\noptimization are strictly respecting all constraints, thus guaranteeing safety\nthroughout the entire learning and control process. We demonstrate the\ncapabilities of Safe PDP in solving various safe learning and control tasks,\nincluding safe policy optimization, safe motion planning, and learning MPCs\nfrom demonstrations, on different challenging control systems such as 6-DoF\nmaneuvering quadrotor and 6-DoF rocket powered landing.",
    "descriptor": "\nComments: We have developed the implementation codes of Safe PDP as a stand-alone package, available at this https URL\n",
    "authors": [
      "Wanxin Jin",
      "Shaoshuai Mou",
      "George J. Pappas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14937"
  },
  {
    "id": "arXiv:2105.14940",
    "title": "Do Multilingual Neural Machine Translation Models Contain Language Pair  Specific Attention Heads?",
    "abstract": "Recent studies on the analysis of the multilingual representations focus on\nidentifying whether there is an emergence of language-independent\nrepresentations, or whether a multilingual model partitions its weights among\ndifferent languages. While most of such work has been conducted in a\n\"black-box\" manner, this paper aims to analyze individual components of a\nmultilingual neural translation (NMT) model. In particular, we look at the\nencoder self-attention and encoder-decoder attention heads (in a many-to-one\nNMT model) that are more specific to the translation of a certain language pair\nthan others by (1) employing metrics that quantify some aspects of the\nattention weights such as \"variance\" or \"confidence\", and (2) systematically\nranking the importance of attention heads with respect to translation quality.\nExperimental results show that surprisingly, the set of most important\nattention heads are very similar across the language pairs and that it is\npossible to remove nearly one-third of the less important heads without hurting\nthe translation quality greatly.",
    "descriptor": "\nComments: 10 pages, accepted at Findings of ACL 2021 (short)\n",
    "authors": [
      "Zae Myung Kim",
      "Laurent Besacier",
      "Vassilina Nikoulina",
      "Didier Schwab"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14940"
  },
  {
    "id": "arXiv:2105.14943",
    "title": "An Exploratory Study of Hardware Reverse Engineering Technical and  Cognitive Processes",
    "abstract": "Understanding the internals of Integrated Circuits (ICs), referred to as\nHardware Reverse Engineering (HRE), is of interest to both legitimate and\nmalicious parties. HRE is a complex process in which semi-automated steps are\ninterwoven with human sense-making processes. Currently, little is known about\nthe technical and cognitive processes which determine the success of HRE.\nThis paper performs an initial investigation on how reverse engineers solve\nproblems, how manual and automated analysis methods interact, and which\ncognitive factors play a role. We present the results of an exploratory\nbehavioral study with eight participants that was conducted after they had\ncompleted a 14-week training. We explored the validity of our findings by\ncomparing them with the behavior (strategies applied and solution time) of an\nHRE expert. The participants were observed while solving a realistic HRE task.\nWe tested cognitive abilities of our participants and collected large sets of\nbehavioral data from log files. By comparing the least and most efficient\nreverse engineers, we were able to observe successful strategies. Moreover, our\nanalyses suggest a phase model for reverse engineering, consisting of three\nphases. Our descriptive results further indicate that the cognitive factor\nWorking Memory (WM) might play a role in efficiently solving HRE problems. Our\nexploratory study builds the foundation for future research in this topic and\noutlines ideas for designing cognitively difficult countermeasures (\"cognitive\nobfuscation\") against HRE.",
    "descriptor": "",
    "authors": [
      "Steffen Becker",
      "Carina Wiesen",
      "Nils Albartus",
      "Nikol Rummel",
      "Christof Paar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14943"
  },
  {
    "id": "arXiv:2105.14944",
    "title": "The effectiveness of feature attribution methods and its correlation  with automatic evaluation scores",
    "abstract": "Explaining the decisions of an Artificial Intelligence (AI) model is\nincreasingly critical in many real-world, high-stake applications. Hundreds of\npapers have either proposed new feature attribution methods, discussed or\nharnessed these tools in their work. However, despite humans being the target\nend-users, most attribution methods were only evaluated on proxy\nautomatic-evaluation metrics. In this paper, we conduct the first, large-scale\nuser study on 320 lay and 11 expert users to shed light on the effectiveness of\nstate-of-the-art attribution methods in assisting humans in ImageNet\nclassification, Stanford Dogs fine-grained classification, and these two tasks\nbut when the input image contains adversarial perturbations. We found that, in\noverall, feature attribution is surprisingly not more effective than showing\nhumans nearest training-set examples. On a hard task of fine-grained dog\ncategorization, presenting attribution maps to humans does not help, but\ninstead hurts the performance of human-AI teams compared to AI alone.\nImportantly, we found automatic attribution-map evaluation measures to\ncorrelate poorly with the actual human-AI team performance. Our findings\nencourage the community to rigorously test their methods on the downstream\nhuman-in-the-loop applications and to rethink the existing evaluation metrics.",
    "descriptor": "",
    "authors": [
      "Giang Nguyen",
      "Daeyoung Kim",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14944"
  },
  {
    "id": "arXiv:2105.14950",
    "title": "A New Transmit Antenna Selection Technique for Physical Layer Security  with Strong Eavesdropping",
    "abstract": "We propose a new transmit antenna selection (TAS) technique that can be\nbeneficial for physical layer security purposes. Specifically, we show that the\nconventional TAS criterion based on the legitimate channel state information\n(CSI) is not recommended when the average signal-to-noise ratio for the\nillegitimate user becomes comparable or superior to that of the legitimate\nuser. We illustrate that an eavesdropper's based antenna selection technique\noutperforms conventional TAS, without explicit knowledge of the eavesdropper's\ninstantaneous CSI. Analytical expressions and simulation results to support\nthis comparison are given, showing how this new TAS scheme is a better choice\nin scenarios with a strong eavesdropper.",
    "descriptor": "\nComments: 4 pages, 4 figures, journal article.This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Gonzalo J. Anaya-L\u00f3pez",
      "J. Carlos Ruiz-Sicilia",
      "F. Javier L\u00f3pez-Mart\u00ednez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.14950"
  },
  {
    "id": "arXiv:2105.14953",
    "title": "ACE-NODE: Attentive Co-Evolving Neural Ordinary Differential Equations",
    "abstract": "Neural ordinary differential equations (NODEs) presented a new paradigm to\nconstruct (continuous-time) neural networks. While showing several good\ncharacteristics in terms of the number of parameters and the flexibility in\nconstructing neural networks, they also have a couple of well-known\nlimitations: i) theoretically NODEs learn homeomorphic mapping functions only,\nand ii) sometimes NODEs show numerical instability in solving integral\nproblems. To handle this, many enhancements have been proposed. To our\nknowledge, however, integrating attention into NODEs has been overlooked for a\nwhile. To this end, we present a novel method of attentive dual co-evolving\nNODE (ACE-NODE): one main NODE for a downstream machine learning task and the\nother for providing attention to the main NODE. Our ACE-NODE supports both\npairwise and elementwise attention. In our experiments, our method outperforms\nexisting NODE-based and non-NODE-based baselines in almost all cases by\nnon-trivial margins.",
    "descriptor": "\nComments: Accepted by KDD 2021\n",
    "authors": [
      "Sheo Yon Jhin",
      "Minju Jo",
      "Taeyong Kong",
      "Jinsung Jeon",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14953"
  },
  {
    "id": "arXiv:2105.14954",
    "title": "VidFace: A Full-Transformer Solver for Video FaceHallucination with  Unaligned Tiny Snapshots",
    "abstract": "In this paper, we investigate the task of hallucinating an authentic\nhigh-resolution (HR) human face from multiple low-resolution (LR) video\nsnapshots. We propose a pure transformer-based model, dubbed VidFace, to fully\nexploit the full-range spatio-temporal information and facial structure cues\namong multiple thumbnails. Specifically, VidFace handles multiple snapshots all\nat once and harnesses the spatial and temporal information integrally to\nexplore face alignments across all the frames, thus avoiding accumulating\nalignment errors. Moreover, we design a recurrent position embedding module to\nequip our transformer with facial priors, which not only effectively\nregularises the alignment mechanism but also supplants notorious pre-training.\nFinally, we curate a new large-scale video face hallucination dataset from the\npublic Voxceleb2 benchmark, which challenges prior arts on tackling unaligned\nand tiny face snapshots. To the best of our knowledge, we are the first attempt\nto develop a unified transformer-based solver tailored for video-based face\nhallucination. Extensive experiments on public video face benchmarks show that\nthe proposed method significantly outperforms the state of the arts.",
    "descriptor": "",
    "authors": [
      "Yuan Gan",
      "Yawei Luo",
      "Xin Yu",
      "Bang Zhang",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14954"
  },
  {
    "id": "arXiv:2105.14956",
    "title": "Leveraging Mobile Phone Data for Migration Flows",
    "abstract": "Statistics on migration flows are often derived from census data, which\nsuffer from intrinsic limitations, including costs and infrequent sampling.\nWhen censuses are used, there is typically a time gap - up to a few years -\nbetween the data collection process and the computation and publication of\nrelevant statistics. This gap is a significant drawback for the analysis of a\nphenomenon that is continuously and rapidly changing. Alternative data sources,\nsuch as surveys and field observations, also suffer from reliability, costs,\nand scale limitations. The ubiquity of mobile phones enables an accurate and\nefficient collection of up-to-date data related to migration. Indeed, passively\ncollected data by the mobile network infrastructure via aggregated,\npseudonymized Call Detail Records (CDRs) is of great value to understand human\nmigrations. Through the analysis of mobile phone data, we can shed light on the\nmobility patterns of migrants, detect spontaneous settlements and understand\nthe daily habits, levels of integration, and human connections of such\nvulnerable social groups. This Chapter discusses the importance of leveraging\nmobile phone data as an alternative data source to gather precious and\npreviously unavailable insights on various aspects of migration. Also, we\nhighlight pending challenges that would need to be addressed before we can\neffectively benefit from the availability of mobile phone data to help make\nbetter decisions that would ultimately improve millions of people's lives.",
    "descriptor": "\nComments: To appear as a book chapter in \"Data Science for Migration and Mobility Studies\" edited by Dr. Emre Eren Korkmaz, Dr. Albert Ali Salah\n",
    "authors": [
      "Massimiliano Luca",
      "Gianni Barlacchi",
      "Nuria Oliver",
      "Bruno Lepri"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.14956"
  },
  {
    "id": "arXiv:2105.14964",
    "title": "A Capacity Region Outer Bound for the Two-User Dispersive Nonlinear  Fiber Optical Channel",
    "abstract": "We study a nonlinear fiber optical channel impaired by cross-phase modulation\nand dispersion from the viewpoint of an interference channel. We characterize\nan outer bound on the capacity region of simultaneously achievable rate pairs,\nassuming a two-user perturbative channel model.",
    "descriptor": "",
    "authors": [
      "Viswanathan Ramachandran",
      "Astrid Barreiro",
      "Gabriele Liga",
      "Alex Alvarado"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.14964"
  },
  {
    "id": "arXiv:2105.14969",
    "title": "OCT-GAN: Neural ODE-based Conditional Tabular GANs",
    "abstract": "Synthesizing tabular data is attracting much attention these days for various\npurposes. With sophisticate synthetic data, for instance, one can augment its\ntraining data. For the past couple of years, tabular data synthesis techniques\nhave been greatly improved. Recent work made progress to address many problems\nin synthesizing tabular data, such as the imbalanced distribution and\nmultimodality problems. However, the data utility of state-of-the-art methods\nis not satisfactory yet. In this work, we significantly improve the utility by\ndesigning our generator and discriminator based on neural ordinary differential\nequations (NODEs). After showing that NODEs have theoretically preferred\ncharacteristics for generating tabular data, we introduce our designs. The\nNODE-based discriminator performs a hidden vector evolution trajectory-based\nclassification rather than classifying with a hidden vector at the last layer\nonly. Our generator also adopts an ODE layer at the very beginning of its\narchitecture to transform its initial input vector (i.e., the concatenation of\na noisy vector and a condition vector in our case) onto another latent vector\nspace suitable for the generation process. We conduct experiments with 13\ndatasets, including but not limited to insurance fraud detection, online news\narticle prediction, and so on, and our presented method outperforms other\nstate-of-the-art tabular data synthesis methods in many cases of our\nclassification, regression, and clustering experiments.",
    "descriptor": "\nComments: Accepted by WWW 2021\n",
    "authors": [
      "Jayoung Kim",
      "Jinsung Jeon",
      "Jaehoon Lee",
      "Jihyeon Hyeong",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14969"
  },
  {
    "id": "arXiv:2105.14974",
    "title": "Non-Convex Tensor Low-Rank Approximation for Infrared Small Target  Detection",
    "abstract": "Infrared small target detection plays an important role in many infrared\nsystems. Recently, many infrared small target detection methods have been\nproposed, in which the lowrank model has been used as a powerful tool. However,\nmost low-rank-based methods assign the same weights for different singular\nvalues, which will lead to inaccurate background estimation. Considering that\ndifferent singular values have different importance and should be treated\ndiscriminatively, in this paper, we propose a non-convex tensor low-rank\napproximation (NTLA) method for infrared small target detection. In our method,\nNTLA adaptively assigns different weights to different singular values for\naccurate background estimation. Based on the proposed NTLA, we use the\nasymmetric spatial-temporal total variation (ASTTV) to thoroughly describe\nbackground feature, which can achieve good background estimation and detection\nin complex scenes. Compared with the traditional total variation approach,\nASTTV exploits different smoothness strength for spatial and temporal\nregularization. We develop an efficient algorithm to find the optimal solution\nof the proposed model. Compared with some state-of-the-art methods, the\nproposed method achieve an improvement in different evaluation metrics.\nExtensive experiments on both synthetic and real data demonstrate the proposed\nmethod provide a more robust detection in complex situations with low false\nrates.",
    "descriptor": "",
    "authors": [
      "Ting Liu",
      "Jungang Yang",
      "Boyang Li",
      "Chao Xiao",
      "Yang Sun",
      "Yingqian Wang",
      "Wei An"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14974"
  },
  {
    "id": "arXiv:2105.14975",
    "title": "Privileged Graph Distillation for Cold Start Recommendation",
    "abstract": "The cold start problem in recommender systems is a long-standing challenge,\nwhich requires recommending to new users (items) based on attributes without\nany historical interaction records. In these recommendation systems, warm users\n(items) have privileged collaborative signals of interaction records compared\nto cold start users (items), and these Collaborative Filtering (CF) signals are\nshown to have competing performance for recommendation. Many researchers\nproposed to learn the correlation between collaborative signal embedding space\nand the attribute embedding space to improve the cold start recommendation, in\nwhich user and item categorical attributes are available in many online\nplatforms. However, the cold start recommendation is still limited by two\nembedding spaces modeling and simple assumptions of space transformation. As\nuser-item interaction behaviors and user (item) attributes naturally form a\nheterogeneous graph structure, in this paper, we propose a privileged graph\ndistillation model~(PGD). The teacher model is composed of a heterogeneous\ngraph structure for warm users and items with privileged CF links. The student\nmodel is composed of an entity-attribute graph without CF links. Specifically,\nthe teacher model can learn better embeddings of each entity by injecting\ncomplex higher-order relationships from the constructed heterogeneous graph.\nThe student model can learn the distilled output with privileged CF embeddings\nfrom the teacher embeddings. Our proposed model is generally applicable to\ndifferent cold start scenarios with new user, new item, or new user-new item.\nFinally, extensive experimental results on the real-world datasets clearly show\nthe effectiveness of our proposed model on different types of cold start\nproblems, with average $6.6\\%, 5.6\\%, $ and $17.1\\%$ improvement over\nstate-of-the-art baselines on three datasets, respectively.",
    "descriptor": "\nComments: 10 pages,5 figures\n",
    "authors": [
      "Shuai Wang",
      "Kun Zhang",
      "Le Wu",
      "Haiping Ma",
      "Richang Hong",
      "Meng Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14975"
  },
  {
    "id": "arXiv:2105.14980",
    "title": "Crowdsourcing Learning as Domain Adaptation: A Case Study on Named  Entity Recognition",
    "abstract": "Crowdsourcing is regarded as one prospective solution for effective\nsupervised learning, aiming to build large-scale annotated training data by\ncrowd workers. Previous studies focus on reducing the influences from the\nnoises of the crowdsourced annotations for supervised models. We take a\ndifferent point in this work, regarding all crowdsourced annotations as\ngold-standard with respect to the individual annotators. In this way, we find\nthat crowdsourcing could be highly similar to domain adaptation, and then the\nrecent advances of cross-domain methods can be almost directly applied to\ncrowdsourcing. Here we take named entity recognition (NER) as a study case,\nsuggesting an annotator-aware representation learning model that inspired by\nthe domain adaptation methods which attempt to capture effective domain-aware\nfeatures. We investigate both unsupervised and supervised crowdsourcing\nlearning, assuming that no or only small-scale expert annotations are\navailable. Experimental results on a benchmark crowdsourced NER dataset show\nthat our method is highly effective, leading to a new state-of-the-art\nperformance. In addition, under the supervised setting, we can achieve\nimpressive performance gains with only a very small scale of expert\nannotations.",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021 (long paper), accepted version\n",
    "authors": [
      "Xin Zhang",
      "Guangwei Xu",
      "Yueheng Sun",
      "Meishan Zhang",
      "Pengjun Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14980"
  },
  {
    "id": "arXiv:2105.14981",
    "title": "Critical Functions and Inf-Sup Stability of Crouzeix-Raviart Elements",
    "abstract": "In this paper, we prove that Crouzeix-Raviart finite elements of polynomial\norder $p\\geq5$, $p$ odd, are inf-sup stable for the Stokes problem on\ntriangulations. For $p\\geq4$, $p$ even, the stability was proved by \\'{A}.\nBaran and G. Stoyan in 2007 by using the \\textit{macroelement technique,} a\n\\textit{dimension formula}, the concept of \\textit{critical points} in a\ntriangulation and a representation of the corresponding \\textit{critical\nfunctions}. Baran and Stoyan proved that these critical functions belong to the\nrange of the divergence operator applied to Crouzeix-Raviart velocity functions\nand the macroelement technique implies the inf-sup stability.\nThe generalization of this theory to cover odd polynomial orders $p\\geq5$ is\ninvolved; one reason is that the macroelement classes, which have been used for\neven $p$, are unsuitable for odd $p$. In this paper, we introduce a new and\nsimple representation of non-conforming Crouzeix-Raviart basis functions of odd\ndegree. We employ only one type of macroelement and derive representations of\nall possible critical functions. Finally, we show that they are in the range of\nthe divergence operator applied to Crouzeix-Raviart velocities from which the\nstability of the discretization follows.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "C. Carstensen",
      "S. Sauter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14981"
  },
  {
    "id": "arXiv:2105.14984",
    "title": "WAP: Digital Dependability Identities",
    "abstract": "Cyber-Physical Systems (CPS) provide enormous potential for innovation but a\nprecondition for this is that the issue of dependability has been addressed.\nThis paper presents the concept of a Digital Dependability Identity (DDI) of a\ncomponent or system as foundation for assuring the dependability of CPS. A DDI\nis an analyzable and potentially executable model of information about the\ndependability of a component or system. We argue that DDIs must fulfill a\nnumber of properties including being universally useful across supply chains,\nenabling off-line certification of systems where possible, and providing\ncapabilities for in-field certification of safety of CPS. In this paper, we\nfocus on system safety as one integral part of dependability and as a practical\ndemonstration of the concept, we present an initial implementation of DDIs in\nthe form of Conditional Safety Certificates (also known as ConSerts). We\nexplain ConSerts and their practical operationalization based on an\nillustrative example.",
    "descriptor": "",
    "authors": [
      "Daniel Schneider",
      "Mario Trapp",
      "Yiannis Papadopoulos",
      "Eric Armengaud",
      "Marc Zeller",
      "Kai Hoefig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14984"
  },
  {
    "id": "arXiv:2105.14987",
    "title": "Crouzeix-Raviart triangular elements are inf-sup stable",
    "abstract": "The Crouzeix-Raviart triangular finite elements are $\\inf$-$\\sup$ stable for\nthe Stokes equations for any mesh with at least one interior vertex. This\nresult affirms a {\\em conjecture of Crouzeix-Falk} from 1989 for $p=3$. Our\nproof applies to {\\em any odd degree} $p\\ge 3$ and hence Crouzeix-Raviart\ntriangular finite elements of degree $p$ in two dimensions and the piecewise\npolynomials of degree $p-1$ with vanishing integral form a stable Stokes pair\n{\\em for all positive integers} $p$.",
    "descriptor": "\nComments: 17\n",
    "authors": [
      "C. Carstensen",
      "S. Sauter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14987"
  },
  {
    "id": "arXiv:2105.14990",
    "title": "A new distance based on minimal absent words and applications to  biological sequences",
    "abstract": "A minimal absent word of a sequence x, is a sequence yt hat is not a factorof\nx, but all of its proper factors are factors of x as well. The set of minimal\nabsent words uniquely defines the sequence itself. In recent times minimal\nabsent words have been used in order to compare sequences. In fact, to do this,\none can compare the sets of their minimal absent words. Chairungasee and\nCrochemorein [2] define a distance between pairs of sequences x and y, where\nthe symmetric difference of the sets of minimal absent words of x and y is\ninvolved. Here, weconsider a different distance, introduced in [1], based on a\nspecific subset of such symmetric difference that, in our opinion, better\ncapture the different features ofthe considered sequences. We show the result\nof some experiments where the distance is tested on a dataset of genetic\nsequences by 11 living species, in order to compare the new distance with the\nones existing in literature.",
    "descriptor": "",
    "authors": [
      "Giuseppa Castiglione",
      "Jia Gao",
      "Sabrina Mantaci",
      "Antonio Restivo"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.14990"
  },
  {
    "id": "arXiv:2105.14992",
    "title": "INSiDER: Incorporation of system and safety analysis models using a  dedicated reference model",
    "abstract": "In order to enable model-based, iterative design of safety-relevant systems,\nan efficient incorporation of safety and system engineering is a pressing need.\nOur approach interconnects system design and safety analysis models efficiently\nusing a dedicated reference model. Since all information are available in a\nstructured way, traceability between the model elements and consistency checks\nenable automated synchronization to guarantee that information within both kind\nof models are consistent during the development life-cycle.",
    "descriptor": "",
    "authors": [
      "Marc Zeller",
      "Kai Hoefig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14992"
  },
  {
    "id": "arXiv:2105.14993",
    "title": "Urban Traffic Surveillance (UTS): A fully probabilistic 3D tracking  approach based on 2D detections",
    "abstract": "Urban Traffic Surveillance (UTS) is a surveillance system based on a\nmonocular and calibrated video camera that detects vehicles in an urban traffic\nscenario with dense traffic on multiple lanes and vehicles performing sharp\nturning maneuvers. UTS then tracks the vehicles using a 3D bounding box\nrepresentation and a physically reasonable 3D motion model relying on an\nUnscented Kalman filter based approach. Since UTS recovers positions, shape and\nmotion information in a three-dimensional world coordinate system, it can be\nemployed to recognize diverse traffic violations or to supply intelligent\nvehicles with valuable traffic information. We rely on YOLOv3 as a detector\nyielding 2D bounding boxes and class labels for each vehicle. A 2D detector\nrenders our system much more independent to different camera perspectives as a\nvariety of labeled training data is available. This allows for a good\ngeneralization while also being more hardware efficient. The task of 3D\ntracking based on 2D detections is supported by integrating class specific\nprior knowledge about the vehicle shape. We quantitatively evaluate UTS using\nself generated synthetic data and ground truth from the CARLA simulator, due to\nthe non-existence of datasets with an urban vehicle surveillance setting and\nlabeled 3D bounding boxes. Additionally, we give a qualitative impression of\nhow UTS performs on real-world data. Our implementation is capable of operating\nin real time on a reasonably modern workstation. To the best of our knowledge,\nUTS is the only 3D vehicle tracking system in a surveillance scenario (static\ncamera observing moving targets).",
    "descriptor": "\nComments: Accepted at the 2021 IEEE Intelligent Vehicles Symposium (IV), Nagoya, Japan, July 11-17, 2021\n",
    "authors": [
      "Henry Bradler",
      "Adrian Kretz",
      "Rudolf Mester"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14993"
  },
  {
    "id": "arXiv:2105.14994",
    "title": "MAOMaps: A Photo-Realistic Benchmark For vSLAM and Map Merging Quality  Assessment",
    "abstract": "Running numerous experiments in simulation is a necessary step before\ndeploying a control system on a real robot. In this paper we introduce a novel\nbenchmark that is aimed at quantitatively evaluating the quality of\nvision-based simultaneous localization and mapping (vSLAM) and map merging\nalgorithms. The benchmark consists of both a dataset and a set of tools for\nautomatic evaluation. The dataset is photo-realistic and provides both the\nlocalization and the map ground truth data. This makes it possible to evaluate\nnot only the localization part of the SLAM pipeline but the mapping part as\nwell. To compare the vSLAM-built maps and the ground-truth ones we introduce a\nnovel way to find correspondences between them that takes the SLAM context into\naccount (as opposed to other approaches like nearest neighbors). The benchmark\nis ROS-compatable and is open-sourced to the community.\nThe data and the code are available at: \\texttt{github.com/CnnDepth/MAOMaps}.",
    "descriptor": "\nComments: submitted to ECMR-2021\n",
    "authors": [
      "Andrey Bokovoy",
      "Kirill Muravyev",
      "Konstantin Yakovlev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14994"
  },
  {
    "id": "arXiv:2105.14995",
    "title": "Choose a Transformer: Fourier or Galerkin",
    "abstract": "In this paper, we apply the self-attention from the state-of-art Transformer\nin Attention Is All You Need the first time to a data-driven operator learning\nproblem related to partial differential equations. We put together an effort to\nexplain the heuristics of, and improve the efficacy of the self-attention by\ndemonstrating that the softmax normalization in the scaled dot-product\nattention is sufficient but not necessary, and have proved the approximation\ncapacity of a linear variant as a Petrov-Galerkin projection. A new layer\nnormalization scheme is proposed to allow a scaling to propagate through\nattention layers, which helps the model achieve remarkable accuracy in operator\nlearning tasks with unnormalized data. Finally, we present three operator\nlearning experiments, including the viscid Burgers' equation, an interface\nDarcy flow, and an inverse interface coefficient identification problem. All\nexperiments validate the improvements of the newly proposed simple\nattention-based operator learner over their softmax-normalized counterparts.",
    "descriptor": "",
    "authors": [
      "Shuhao Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14995"
  },
  {
    "id": "arXiv:2105.14998",
    "title": "Incomplete Information VCG Contracts for Common Agency",
    "abstract": "We study contract design for welfare maximization in the well known \"common\nagency\" model of [Bernheim and Whinston, 1986]. This model combines the\nchallenges of coordinating multiple principals with the fundamental challenge\nof contract design: that principals have incomplete information of the agent's\nchoice of action. Motivated by the significant social inefficiency of standard\ncontracts for such settings (which we formally quantify using a price of\nanarchy/stability analysis), we investigate whether and how a recent toolbox\ndeveloped for the first set of challenges under a complete-information\nassumption, VCG contracts [Lavi and Shamash, 2019], can be extended to\nincomplete information.\nWe define and characterize the class of \"incomplete information VCG contracts\n(IIVCG)\", and show it is the unique class guaranteeing truthfulness of the\nprincipals and welfare maximization by the agent. Our results reveal an\ninherent tradeoff between two important properties required to ensure\nparticipation in the contract: individual rationality (for the principals) and\nlimited liability (for the agent). We design a polynomial-time algorithm for\ndetermining whether a setting has an IIVCG contract with both properties. As\nour main result we design a polynomial-time \"algorithmic IIVCG\" contract: given\nvaluation reports from the principals it returns, if possible for the setting,\na payment scheme for the agent that constitutes an IIVCG contract with all\ndesired properties. We also give a sufficient graph-theoretic condition on the\npopulation of principals that ensures the existence of such an IIVCG contract.",
    "descriptor": "",
    "authors": [
      "Tal Alon",
      "Ron Lavi",
      "Elisheva S. Shamash",
      "Inbal Talgam-Cohen"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2105.14998"
  },
  {
    "id": "arXiv:2105.15002",
    "title": "ArChes -- Automatic generation of component fault trees from continuous  function charts",
    "abstract": "The growing size and complexity of software in embedded systems poses new\nchallenges to the safety assessment of embedded control systems. In industrial\npractice, the control software is mostly treated as a black box during the\nsystem's safety analysis. The appropriate representation of the failure\npropagation of the software is a pressing need in order to increase the\naccuracy of safety analyses. However, it also increase the effort for creating\nand maintaining the safety analysis models (such as fault trees) significantly.\nIn this work, we present a method to automatically generate Component Fault\nTrees from Continuous Function Charts. This method aims at generating the\nfailure propagation model of the detailed software specification. Hence,\ncontrol software can be included into safety analyses without additional manual\neffort required to construct the safety analysis models of the software.\nMoreover, safety analyses created during early system specification phases can\nbe verified by comparing it with the automatically generated one in the\ndetailed specification phased.",
    "descriptor": "\nComments: 2017 IEEE 15th International Conference on Industrial Informatics (INDIN)\n",
    "authors": [
      "Marc Zeller",
      "Kai Hoefig",
      "Jean-Pascal Schwinn"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.15002"
  },
  {
    "id": "arXiv:2105.15007",
    "title": "Locally Private $k$-Means Clustering with Constant Multiplicative  Approximation and Near-Optimal Additive Error",
    "abstract": "Given a data set of size $n$ in $d'$-dimensional Euclidean space, the\n$k$-means problem asks for a set of $k$ points (called centers) so that the sum\nof the $\\ell_2^2$-distances between points of a given data set of size $n$ and\nthe set of $k$ centers is minimized. Recent work on this problem in the locally\nprivate setting achieves constant multiplicative approximation with additive\nerror $\\tilde{O} (n^{1/2 + a} \\cdot k \\cdot \\max \\{\\sqrt{d}, \\sqrt{k} \\})$ and\nproves a lower bound of $\\Omega(\\sqrt{n})$ on the additive error for any\nsolution with a constant number of rounds. In this work we bridge the gap\nbetween the exponents of $n$ in the upper and lower bounds on the additive\nerror with two new algorithms. Given any $\\alpha>0$, our first algorithm\nachieves a multiplicative approximation guarantee which is at most a\n$(1+\\alpha)$ factor greater than that of any non-private $k$-means clustering\nalgorithm with $k^{\\tilde{O}(1/\\alpha^2)} \\sqrt{d' n} \\mbox{poly}\\log n$\nadditive error. Given any $c>\\sqrt{2}$, our second algorithm achieves $O(k^{1 +\n\\tilde{O}(1/(2c^2-1))} \\sqrt{d' n} \\mbox{poly} \\log n)$ additive error with\nconstant multiplicative approximation. Both algorithms go beyond the\n$\\Omega(n^{1/2 + a})$ factor that occurs in the additive error for arbitrarily\nsmall parameters $a$ in previous work, and the second algorithm in particular\nshows for the first time that it is possible to solve the locally private\n$k$-means problem in a constant number of rounds with constant factor\nmultiplicative approximation and polynomial dependence on $k$ in the additive\nerror arbitrarily close to linear.",
    "descriptor": "\nComments: 61 pages\n",
    "authors": [
      "Anamay Chaturvedi",
      "Matthew Jones",
      "Huy L. Nguyen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15007"
  },
  {
    "id": "arXiv:2105.15010",
    "title": "QueryNet: An Efficient Attack Framework with Surrogates Carrying  Multiple Identities",
    "abstract": "Deep Neural Networks (DNNs) are acknowledged as vulnerable to adversarial\nattacks, while the existing black-box attacks require extensive queries on the\nvictim DNN to achieve high success rates. For query-efficiency, surrogate\nmodels of the victim are adopted as transferable attackers in consideration of\ntheir Gradient Similarity (GS), i.e., surrogates' attack gradients are similar\nto the victim's ones to some extent. However, it is generally neglected to\nexploit their similarity on outputs, namely the Prediction Similarity (PS), to\nfilter out inefficient queries. To jointly utilize and also optimize\nsurrogates' GS and PS, we develop QueryNet, an efficient attack network that\ncan significantly reduce queries. QueryNet crafts several transferable\nAdversarial Examples (AEs) by surrogates, and then decides also by surrogates\non the most promising AE, which is then sent to query the victim. That is to\nsay, in QueryNet, surrogates are not only exploited as transferable attackers,\nbut also as transferability evaluators for AEs. The AEs are generated using\nsurrogates' GS and evaluated based on their FS, and therefore, the query\nresults could be back-propagated to optimize surrogates' parameters and also\ntheir architectures, enhancing both the GS and the FS. QueryNet has significant\nquery-efficiency, i.e., reduces queries by averagely about an order of\nmagnitude compared to recent SOTA methods according to our comprehensive and\nreal-world experiments: 11 victims (including 2 commercial models) on\nMNIST/CIFAR10/ImageNet, allowing only 8-bit image queries, and no access to the\nvictim's training data.",
    "descriptor": "\nComments: QueryNet reduces queries by about an order of magnitude against SOTA black-box attacks. 21 pages, 6 figures\n",
    "authors": [
      "Sizhe Chen",
      "Zhehao Huang",
      "Qinghua Tao",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.15010"
  },
  {
    "id": "arXiv:2105.15012",
    "title": "Large-Scale Data-Driven Airline Market Influence Maximization",
    "abstract": "We present a prediction-driven optimization framework to maximize the market\ninfluence in the US domestic air passenger transportation market by adjusting\nflight frequencies. At the lower level, our neural networks consider a wide\nvariety of features, such as classical air carrier performance features and\ntransportation network features, to predict the market influence. On top of the\nprediction models, we define a budget-constrained flight frequency optimization\nproblem to maximize the market influence over 2,262 routes. This problem falls\ninto the category of the non-linear optimization problem, which cannot be\nsolved exactly by conventional methods. To this end, we present a novel\nadaptive gradient ascent (AGA) method. Our prediction models show two to eleven\ntimes better accuracy in terms of the median root-mean-square error (RMSE) over\nbaselines. In addition, our AGA optimization method runs 690 times faster with\na better optimization result (in one of our largest scale experiments) than a\ngreedy algorithm.",
    "descriptor": "\nComments: Accepted by KDD 2021\n",
    "authors": [
      "Duanshun Li",
      "Jing Liu",
      "Jinsung Jeon",
      "Seoyoung Hong",
      "Thai Le",
      "Dongwon Lee",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15012"
  },
  {
    "id": "arXiv:2105.15013",
    "title": "SHAQ: Incorporating Shapley Value Theory into Q-Learning for Multi-Agent  Reinforcement Learning",
    "abstract": "Value factorisation proves to be a very useful technique in multi-agent\nreinforcement learning (MARL), but the underlying mechanism is not yet fully\nunderstood. This paper explores a theoretic basis for value factorisation. We\ngeneralise the Shapley value in the coalitional game theory to a Markov convex\ngame (MCG) and use it to guide value factorisation in MARL. We show that the\ngeneralised Shapley value possesses several features such as (1) accurate\nestimation of the maximum global value, (2) fairness in the factorisation of\nthe global value, and (3) being sensitive to dummy agents. The proposed theory\nyields a new learning algorithm called Sharpley Q-learning (SHAQ), which\ninherits the important merits of ordinary Q-learning but extends it to MARL. In\ncomparison with prior-arts, SHAQ has a much weaker assumption (MCG) that is\nmore compatible with real-world problems, but has superior explainability and\nperformance in many cases. We demonstrated SHAQ and verified the theoretic\nclaims on Predator-Prey and StarCraft Multi-Agent Challenge (SMAC).",
    "descriptor": "",
    "authors": [
      "Jianhong Wang",
      "Jinxin Wang",
      "Yuan Zhang",
      "Yunjie Gu",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.15013"
  },
  {
    "id": "arXiv:2105.15014",
    "title": "Singing Language Identification using a Deep Phonotactic Approach",
    "abstract": "Extensive works have tackled Language Identification (LID) in the speech\ndomain, however their application to the singing voice trails and performances\non Singing Language Identification (SLID) can be improved leveraging recent\nprogresses made in other singing related tasks. This work presents a modernized\nphonotactic system for SLID on polyphonic music: phoneme recognition is\nperformed with a Connectionist Temporal Classification (CTC)-based acoustic\nmodel trained with multilingual data, before language classification with a\nrecurrent model based on the phonemes estimation. The full pipeline is trained\nand evaluated with a large and publicly available dataset, with unprecedented\nperformances. First results of SLID with out-of-set languages are also\npresented.",
    "descriptor": "\nComments: 5 pages, 1 figure, ICASSP 2021\n",
    "authors": [
      "Lenny Renault",
      "Andrea Vaglio",
      "Romain Hennequin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.15014"
  },
  {
    "id": "arXiv:2105.15015",
    "title": "Model-Based Reliability and Safety: Reducing the Complexity of Safety  Analyses Using Component Fault Trees",
    "abstract": "The importance of mission or safety critical software systems in many\napplication domains of embedded systems is continuously growing, and so is the\neffort and complexity for reliability and safety analysis. Model driven\ndevelopment is currently one of the key approaches to cope with increasing\ndevelopment complexity, in general. Applying similar concepts to reliability,\navailability, maintainability and safety (RAMS) analysis activities is a\npromising approach to extend the advantages of model driven development to\nsafety engineering activities aiming at a reduction of development costs, a\nhigher product quality and a shorter time-to-market. Nevertheless, many\nmodel-based safety or reliability engineering approaches aim at reducing the\nanalysis complexity but applications or case studies are rare. Therefore we\npresent here a large scale industrial case study which shows the benefits of\nthe application of component fault trees when it comes to complex safety\nmechanisms. We compare the methodology of component fault trees against classic\nfault trees and summarize benefits and drawbacks of both modeling\nmethodologies.",
    "descriptor": "",
    "authors": [
      "Kai Hoefig",
      "Andreas Joanni",
      "Marc Zeller",
      "Francesco Montrone",
      "Martin Rothfelder",
      "Rakshith Amarnath",
      "Peter Munk",
      "Arne Nordmann"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.15015"
  },
  {
    "id": "arXiv:2105.15018",
    "title": "Product Progression: a machine learning approach to forecasting  industrial upgrading",
    "abstract": "Economic complexity methods, and in particular relatedness measures, lack a\nsystematic evaluation and comparison framework. We argue that out-of-sample\nforecast exercises should play this role, and we compare various machine\nlearning models to set the prediction benchmark. We find that the key object to\nforecast is the activation of new products, and that tree-based algorithms\nclearly overperform both the quite strong auto-correlation benchmark and the\nother supervised algorithms. Interestingly, we find that the best results are\nobtained in a cross-validation setting, when data about the predicted country\nwas excluded from the training set. Our approach has direct policy\nimplications, providing a quantitative and scientifically tested measure of the\nfeasibility of introducing a new product in a given country.",
    "descriptor": "\nComments: 17 pages, 9 figures\n",
    "authors": [
      "Giambattista Albora",
      "Luciano Pietronero",
      "Andrea Tacchella",
      "Andrea Zaccaria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15018"
  },
  {
    "id": "arXiv:2105.15021",
    "title": "Neural Bi-Lexicalized PCFG Induction",
    "abstract": "Neural lexicalized PCFGs (L-PCFGs) have been shown effective in grammar\ninduction. However, to reduce computational complexity, they make a strong\nindependence assumption on the generation of the child word and thus bilexical\ndependencies are ignored. In this paper, we propose an approach to parameterize\nL-PCFGs without making implausible independence assumptions. Our approach\ndirectly models bilexical dependencies and meanwhile reduces both learning and\nrepresentation complexities of L-PCFGs. Experimental results on the English WSJ\ndataset confirm the effectiveness of our approach in improving both running\nspeed and unsupervised parsing performance.",
    "descriptor": "\nComments: To appear in ACL 2021 main conference\n",
    "authors": [
      "Songlin Yang",
      "Yanpeng Zhao",
      "Kewei Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15021"
  },
  {
    "id": "arXiv:2105.15022",
    "title": "Reinforcement Learning-based Dynamic Service Placement in Vehicular  Networks",
    "abstract": "The emergence of technologies such as 5G and mobile edge computing has\nenabled provisioning of different types of services with different resource and\nservice requirements to the vehicles in a vehicular network.The growing\ncomplexity of traffic mobility patterns and dynamics in the requests for\ndifferent types of services has made service placement a challenging task. A\ntypical static placement solution is not effective as it does not consider the\ntraffic mobility and service dynamics. In this paper, we propose a\nreinforcement learning-based dynamic (RL-Dynamic) service placement framework\nto find the optimal placement of services at the edge servers while considering\nthe vehicle's mobility and dynamics in the requests for different types of\nservices. We use SUMO and MATLAB to carry out simulation experiments. In our\nlearning framework, for the decision module, we consider two alternative\nobjective functions-minimizing delay and minimizing edge server utilization. We\ndeveloped an ILP based problem formulation for the two objective functions. The\nexperimental results show that 1) compared to static service placement,\nRL-based dynamic service placement achieves fair utilization of edge server\nresources and low service delay, and 2) compared to delay-optimized placement,\nserver utilization optimized placement utilizes resources more effectively,\nachieving higher fairness with lower edge-server utilization.",
    "descriptor": "\nComments: Accepted and presented in IEEE 93rd Vehicular Technology Conference VTC2021-Spring\n",
    "authors": [
      "Anum Talpur",
      "Mohan Gurusamy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15022"
  },
  {
    "id": "arXiv:2105.15023",
    "title": "System-aware dynamic partitioning for batch and streaming workloads",
    "abstract": "When processing data streams with highly skewed and nonstationary key\ndistributions, we often observe overloaded partitions when the hash\npartitioning fails to balance data correctly. To avoid slow tasks that delay\nthe completion of the whole stage of computation, it is necessary to apply\nadaptive, on-the-fly partitioning that continuously recomputes an optimal\npartitioner, given the observed key distribution. While such solutions exist\nfor batch processing of static data sets and stateless stream processing, the\ntask is difficult for long-running stateful streaming jobs where key\ndistribution changes over time. Careful checkpointing and operator state\nmigration is necessary to change the partitioning while the operation is\nrunning.\nOur key result is a lightweight on-the-fly Dynamic Repartitioning (DR) module\nfor distributed data processing systems (DDPS), including Apache Spark and\nFlink, which improves the performance with negligible overhead. DR can\nadaptively repartition data during execution using our Key Isolator Partitioner\n(KIP). In our experiments with real workloads and power-law distributions, we\nreach a speedup of 1.5-6 for a variety of Spark and Flink jobs.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Zolt\u00e1n Zvara",
      "P\u00e9ter G.N. Szab\u00f3",
      "Bal\u00e1zs Barnab\u00e1s L\u00f3r\u00e1nt",
      "Andr\u00e1s A. Bencz\u00far"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.15023"
  },
  {
    "id": "arXiv:2105.15024",
    "title": "OASIS: An Active Framework for Set Inversion",
    "abstract": "In this work, we introduce a novel method for solving the set inversion\nproblem by formulating it as a binary classification problem. Aiming to develop\na fast algorithm that can work effectively with high-dimensional and\ncomputationally expensive nonlinear models, we focus on active learning, a\nfamily of new and powerful techniques which can achieve the same level of\naccuracy with fewer data points compared to traditional learning methods.\nSpecifically, we propose OASIS, an active learning framework using Support\nVector Machine algorithms for solving the problem of set inversion. Our method\nworks well in high dimensions and its computational cost is relatively robust\nto the increase of dimension. We illustrate the performance of OASIS by several\nsimulation studies and show that our algorithm outperforms VISIA, the\nstate-of-the-art method.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Binh T. Nguyen",
      "Duy M. Nguyen",
      "Lam Si Tung Ho",
      "Vu Dinh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15024"
  },
  {
    "id": "arXiv:2105.15028",
    "title": "ArtGraph: Towards an Artistic Knowledge Graph",
    "abstract": "This paper presents our ongoing work towards ArtGraph: an artistic knowledge\ngraph based on WikiArt and DBpedia. Automatic art analysis has seen an\never-increasing interest from the pattern recognition and computer vision\ncommunity. However, most of the current work is mainly based solely on\ndigitized artwork images, sometimes supplemented with some metadata and textual\ncomments. A knowledge graph that integrates a rich body of information about\nartworks, artists, painting schools, etc., in a unified structured framework\ncan provide a valuable resource for more powerful information retrieval and\nknowledge discovery tools in the artistic domain.",
    "descriptor": "\nComments: Submitted to DS2021\n",
    "authors": [
      "Giovanna Castellano",
      "Giovanni Sansaro",
      "Gennaro Vessio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.15028"
  },
  {
    "id": "arXiv:2105.15029",
    "title": "Aristotle Said \"Happiness is a State of Activity\" -- Predicting Mood  through Body Sensing with Smartwatches",
    "abstract": "We measure and predict states of Activation and Happiness using a body\nsensing application connected to smartwatches. Through the sensors of\ncommercially available smartwatches we collect individual mood states and\ncorrelate them with body sensing data such as acceleration, heart rate, light\nlevel data, and location, through the GPS sensor built into the smartphone\nconnected to the smartwatch. We polled users on the smartwatch for seven weeks\nfour times per day asking for their mood state. We found that both Happiness\nand Activation are negatively correlated with heart beats and with the levels\nof light. People tend to be happier when they are moving more intensely and are\nfeeling less activated during weekends. We also found that people with a lower\nConscientiousness and Neuroticism and higher Agreeableness tend to be happy\nmore frequently. In addition, more Activation can be predicted by lower\nOpenness to experience and higher Agreeableness and Conscientiousness. Lastly,\nwe find that tracking people's geographical coordinates might play an important\nrole in predicting Happiness and Activation. The methodology we propose is a\nfirst step towards building an automated mood tracking system, to be used for\nbetter teamwork and in combination with social network analysis studies.",
    "descriptor": "",
    "authors": [
      "P. A. Gloor",
      "A. Fronzetti Colladon",
      "F. Grippa",
      "P. Budner",
      "J. Eirich"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15029"
  },
  {
    "id": "arXiv:2105.15030",
    "title": "Digital Contact Tracing for Covid 19",
    "abstract": "The COVID19 pandemic created a worldwide emergency as it is estimated that\nsuch a large number of infections are due to human-to-human transmission of the\nCOVID19. As a necessity, there is a need to track users who came in contact\nwith users having travel history, asymptomatic and not yet symptomatic, but\nthey can be in the future. To solve this problem, the present work proposes a\nsolution for contact tracing based on assisted GPS and cloud computing\ntechnologies. An application is developed to collect each user's assisted GPS\ncoordinates once all the users install this application. This application\nperiodically sends assisted GPS data to the cloud. To determine which devices\nare within the permissible limit of 5m, we perform clustering over assisted GPS\ncoordinates and track the clusters for about t mins to allow the measure of\nspread. We assume that it takes around 3 or 5 mins to get the virus from an\ninfected object. For clustering, the proposed M way like tree data structure\nstores the assisted GPS coordinates in degree, minute, and second format. Thus,\nevery user is mapped to a leaf node of the tree. We split the \"seconds\" part of\nthe assisted GPS location into m equal parts, which amount to d meter in\nlatitude(longitude). Hence, two users who are within d meter range will map to\nthe same leaf node. Thus, by mapping assisted GPS locations every t mins, we\ncan find out how many users came in contact with a particular user for at least\nt mins. Our work's salient feature is that it runs in linear time O(n) for n\nusers in the static case, i.e., when users are not moving. We also propose a\nvariant of our solution to handle the dynamic case, that is, when users are\nmoving. Besides, the proposed solution offers potential hotspot detection and\nsafe-route recommendation as an additional feature, and proof of concept is\npresented through experiments on simulated data of 10M users.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Chandresh Kumar Maurya",
      "Seemandhar Jain",
      "Vishal Thakre"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.15030"
  },
  {
    "id": "arXiv:2105.15032",
    "title": "Truthful Mechanisms for Two-Sided Markets via Prophet Inequalities",
    "abstract": "We design novel mechanisms for welfare-maximization in two-sided markets.\nThat is, there are buyers willing to purchase items and sellers holding items\ninitially, both acting rationally and strategically in order to maximize\nutility. Our mechanisms are designed based on a powerful correspondence between\ntwo-sided markets and prophet inequalities. They satisfy individual\nrationality, dominant-strategy incentive compatibility, budget-balance\nconstraints and give constant-factor approximations to the optimal social\nwelfare.\nWe improve previous results in several settings: Our main focus is on matroid\ndouble auctions, where the set of buyers who obtain an item needs to be\nindependent in a matroid. We construct two mechanisms, the first being a\n$1/3$-approximation of the optimal social welfare satisfying strong\nbudget-balance and requiring the agents to trade in a customized order, the\nsecond being a $1/2$-approximation, weakly budget-balanced and able to deal\nwith online arrival determined by an adversary. In addition, we construct\nconstant-factor approximations in two-sided markets when buyers need to fulfill\na knapsack constraint. Also, in combinatorial double auctions, where buyers\nhave valuation functions over item bundles instead of being interested in only\none item, using similar techniques, we design a mechanism which is a\n$1/2$-approximation of the optimal social welfare, strongly budget-balanced and\ncan deal with online arrival of agents in an adversarial order.",
    "descriptor": "\nComments: An extended abstract will appear at EC 2021\n",
    "authors": [
      "Alexander Braun",
      "Thomas Kesselheim"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.15032"
  },
  {
    "id": "arXiv:2105.15033",
    "title": "DiaKG: an Annotated Diabetes Dataset for Medical Knowledge Graph  Construction",
    "abstract": "Knowledge Graph has been proven effective in modeling structured information\nand conceptual knowledge, especially in the medical domain. However, the lack\nof high-quality annotated corpora remains a crucial problem for advancing the\nresearch and applications on this task. In order to accelerate the research for\ndomain-specific knowledge graphs in the medical domain, we introduce DiaKG, a\nhigh-quality Chinese dataset for Diabetes knowledge graph, which contains\n22,050 entities and 6,890 relations in total. We implement recent typical\nmethods for Named Entity Recognition and Relation Extraction as a benchmark to\nevaluate the proposed dataset thoroughly. Empirical results show that the DiaKG\nis challenging for most existing methods and further analysis is conducted to\ndiscuss future research direction for improvements. We hope the release of this\ndataset can assist the construction of diabetes knowledge graphs and facilitate\nAI-based applications.",
    "descriptor": "",
    "authors": [
      "Dejie Chang",
      "Mosha Chen",
      "Chaozhen Liu",
      "Liping Liu",
      "Dongdong Li",
      "Wei Li",
      "Fei Kong",
      "Bangchang Liu",
      "Xiaobin Luo",
      "Ji Qi",
      "Qiao Jin",
      "Bin Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.15033"
  },
  {
    "id": "arXiv:2105.15035",
    "title": "Machine Learning for Security in Vehicular Networks: A Comprehensive  Survey",
    "abstract": "Machine Learning (ML) has emerged as an attractive and viable technique to\nprovide effective solutions for a wide range of application domains. An\nimportant application domain is vehicular networks wherein ML-based approaches\nare found to be very useful to address various problems. The use of wireless\ncommunication between vehicular nodes and/or infrastructure makes it vulnerable\nto different types of attacks. In this regard, ML and its variants are gaining\npopularity to detect attacks and deal with different kinds of security issues\nin vehicular communication. In this paper, we present a comprehensive survey of\nML-based techniques for different security issues in vehicular networks. We\nfirst briefly introduce the basics of vehicular networks and different types of\ncommunications. Apart from the traditional vehicular networks, we also consider\nmodern vehicular network architectures. We propose a taxonomy of security\nattacks in vehicular networks and discuss various security challenges and\nrequirements. We classify the ML techniques developed in the literature\naccording to their use in vehicular network applications. We explain the\nsolution approaches and working principles of these ML techniques in addressing\nvarious security challenges and provide insightful discussion. The limitations\nand challenges in using ML-based methods in vehicular networks are discussed.\nFinally, we present observations and lessons learned before we conclude our\nwork.",
    "descriptor": "\nComments: Submitted in IEEE Communications Surveys & Tutorials\n",
    "authors": [
      "Anum Talpur",
      "Mohan Gurusamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.15035"
  },
  {
    "id": "arXiv:2105.15039",
    "title": "Sequenceable Event Recorders",
    "abstract": "With recent high-throughput technology we can synthesize large heterogeneous\ncollections of DNA structures, and also read them all out precisely in a single\nprocedure. Can we use these tools, not only to do things faster, but also to\ndevise new techniques and algorithms? In this paper we examine some DNA\nalgorithms that assume high-throughput synthesis and sequencing. We aim to\nmonitor, record, and read out the order in which a number $N$ of events occur,\nusing $N^2$ redundant detectors, and (after sequencing) reconstructing the\norder by transitive reduction.",
    "descriptor": "",
    "authors": [
      "Luca Cardelli"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2105.15039"
  },
  {
    "id": "arXiv:2105.15041",
    "title": "Scorpion detection and classification systems based on computer vision  and deep learning for health security purposes",
    "abstract": "In this paper, two novel automatic and real-time systems for the detection\nand classification of two genera of scorpions found in La Plata city\n(Argentina) were developed using computer vision and deep learning techniques.\nThe object detection technique was implemented with two different methods, YOLO\n(You Only Look Once) and MobileNet, based on the shape features of the\nscorpions. High accuracy values of 88% and 91%, and high recall values of 90%\nand 97%, have been achieved for both models, respectively, which guarantees\nthat they can successfully detect scorpions. In addition, the MobileNet method\nhas been shown to have excellent performance to detect scorpions within an\nuncontrolled environment and to perform multiple detections. The MobileNet\nmodel was also used for image classification in order to successfully\ndistinguish between dangerous scorpion (Tityus) and non-dangerous scorpion\n(Bothriurus) with the purpose of providing a health security tool. Applications\nfor smartphones were developed, with the advantage of the portability of the\nsystems, which can be used as a help tool for emergency services, or for\nbiological research purposes. The developed systems can be easily scalable to\nother genera and species of scorpions to extend the region where these\napplications can be used.",
    "descriptor": "",
    "authors": [
      "Francisco Luis Giambelluca",
      "Marcelo A. Cappelletti",
      "Jorge Osio",
      "Luis A. Giambelluca"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.15041"
  },
  {
    "id": "arXiv:2105.15053",
    "title": "Factorising Meaning and Form for Intent-Preserving Paraphrasing",
    "abstract": "We propose a method for generating paraphrases of English questions that\nretain the original intent but use a different surface form. Our model combines\na careful choice of training objective with a principled information\nbottleneck, to induce a latent encoding space that disentangles meaning and\nform. We train an encoder-decoder model to reconstruct a question from a\nparaphrase with the same meaning and an exemplar with the same surface form,\nleading to separated encoding spaces. We use a Vector-Quantized Variational\nAutoencoder to represent the surface form as a set of discrete latent\nvariables, allowing us to use a classifier to select a different surface form\nat test time. Crucially, our method does not require access to an external\nsource of target exemplars. Extensive experiments and a human evaluation show\nthat we are able to generate paraphrases with a better tradeoff between\nsemantic preservation and syntactic novelty compared to previous methods.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Tom Hosking",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15053"
  },
  {
    "id": "arXiv:2105.15054",
    "title": "Telling Stories through Multi-User Dialogue by Modeling Character  Relations",
    "abstract": "This paper explores character-driven story continuation, in which the story\nemerges through characters' first- and second-person narration as well as\ndialogue -- requiring models to select language that is consistent with a\ncharacter's persona and their relationships with other characters while\nfollowing and advancing the story. We hypothesize that a multi-task model that\ntrains on character dialogue plus character relationship information improves\ntransformer-based story continuation. To this end, we extend the Critical Role\nDungeons and Dragons Dataset (Rameshkumar and Bailey, 2020) -- consisting of\ndialogue transcripts of people collaboratively telling a story while playing\nthe role-playing game Dungeons and Dragons -- with automatically extracted\nrelationships between each pair of interacting characters as well as their\npersonas. A series of ablations lend evidence to our hypothesis, showing that\nour multi-task model using character relationships improves story continuation\naccuracy over strong baselines.",
    "descriptor": "\nComments: In Proceedings of SIGDIAL 2021\n",
    "authors": [
      "Wai Man Si",
      "Prithviraj Ammanabrolu",
      "Mark O. Riedl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.15054"
  },
  {
    "id": "arXiv:2105.15057",
    "title": "Dominant Patterns: Critical Features Hidden in Deep Neural Networks",
    "abstract": "In this paper, we find the existence of critical features hidden in Deep\nNeuralNetworks (DNNs), which are imperceptible but can actually dominate the\noutputof DNNs. We call these features dominant patterns. As the name suggests,\nfor a natural image, if we add the dominant pattern of a DNN to it, the output\nof this DNN is determined by the dominant pattern instead of the original\nimage, i.e., DNN's prediction is the same with the dominant pattern's. We\ndesign an algorithm to find such patterns by pursuing the insensitivity in the\nfeature space. A direct application of the dominant patterns is the Universal\nAdversarial Perturbations(UAPs). Numerical experiments show that the found\ndominant patterns defeat state-of-the-art UAP methods, especially in label-free\nsettings. In addition, dominant patterns are proved to have the potential to\nattack downstream tasks in which DNNs share the same backbone. We claim that\nDNN-specific dominant patterns reveal some essential properties of a DNN and\nare of great importance for its feature analysis and robustness enhancement.",
    "descriptor": "",
    "authors": [
      "Zhixing Ye",
      "Shaofei Qin",
      "Sizhe Chen",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.15057"
  },
  {
    "id": "arXiv:2105.15061",
    "title": "All-in-one: Certifiable Optimal Distributed Kalman Filter under Unknown  Correlations",
    "abstract": "The optimal fusion of estimates in a Distributed Kalman Filter (DKF) requires\ntracking of the complete network error covariance, which is a problem in terms\nof memory and communication bandwidth. A scalable alternative is to fuse\nestimates under unknown correlations, updating the local estimates and error\ncovariance matrix as the solution of an optimisation problem. Unfortunately,\nthis problem is NP-hard, forcing relaxations that lose optimality guarantees\nover the original problem. Motivated by this, we present the first Certifiable\nOptimal DKF (CO-DKF). Using only information from one-hop neighbours, CO-DKF\nsolves the optimal fusion of estimates under unknown correlations by a tight\nSemidefinite Programming (SDP) relaxation. This particular relaxation allows to\ncertify locally and in real time if the solution from the relaxed problem is\nthe optimum of the original. In that case, we prove that CO-DKF is optimal in\nthe Mean Square Error (MSE) sense. Additionally, we demonstrate that CO-DKF is\na globally asymptotically stable estimator. Simulations show that CO-DKF\noutperforms other state-of-the-art DKF algorithms, specially in sparse, highly\nnoisy setups.",
    "descriptor": "",
    "authors": [
      "Eduardo Sebasti\u00e1n",
      "Eduardo Montijano",
      "Carlos Sag\u00fc\u00e9s"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.15061"
  },
  {
    "id": "arXiv:2105.15064",
    "title": "Using Pareto Simulated Annealing to Address Algorithmic Bias in Machine  Learning",
    "abstract": "Algorithmic Bias can be due to bias in the training data or issues with the\nalgorithm itself. These algorithmic issues typically relate to problems with\nmodel capacity and regularisation. This underestimation bias may arise because\nthe model has been optimised for good generalisation accuracy without any\nexplicit consideration of bias or fairness. In a sense, we should not be\nsurprised that a model might be biased when it hasn't been \"asked\" not to be.\nIn this paper, we consider including bias (underestimation) as an additional\ncriterion in model training. We present a multi-objective optimisation strategy\nusing Pareto Simulated Annealing that optimise for both balanced accuracy and\nunderestimation. We demonstrate the effectiveness of this strategy on one\nsynthetic and two real-world datasets.",
    "descriptor": "",
    "authors": [
      "William Blanzeisky",
      "P\u00e1draig Cunningham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15064"
  },
  {
    "id": "arXiv:2105.15065",
    "title": "Picking Pearl From Seabed: Extracting Artefacts from Noisy Issue  Triaging Collaborative Conversations for Hybrid Cloud Services",
    "abstract": "Site Reliability Engineers (SREs) play a key role in issue identification and\nresolution. After an issue is reported, SREs come together in a virtual room\n(collaboration platform) to triage the issue. While doing so, they leave behind\na wealth of information which can be used later for triaging similar issues.\nHowever, usability of the conversations offer challenges due to them being i)\nnoisy and ii) unlabelled. This paper presents a novel approach for issue\nartefact extraction from the noisy conversations with minimal labelled data. We\npropose a combination of unsupervised and supervised model with minimum human\nintervention that leverages domain knowledge to predict artefacts for a small\namount of conversation data and use that for fine-tuning an already pretrained\nlanguage model for artefact prediction on a large amount of conversation data.\nExperimental results on our dataset show that the proposed ensemble of\nunsupervised and supervised model is better than using either one of them\nindividually.",
    "descriptor": "",
    "authors": [
      "Amar Prakash Azad",
      "Supriyo Ghosh",
      "Ajay Gupta",
      "Harshit Kumar",
      "Prateeti Mohapatra"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15065"
  },
  {
    "id": "arXiv:2105.15069",
    "title": "Max-Margin is Dead, Long Live Max-Margin!",
    "abstract": "The foundational concept of Max-Margin in machine learning is ill-posed for\noutput spaces with more than two labels such as in structured prediction. In\nthis paper, we show that the Max-Margin loss can only be consistent to the\nclassification task under highly restrictive assumptions on the discrete loss\nmeasuring the error between outputs. These conditions are satisfied by\ndistances defined in tree graphs, for which we prove consistency, thus being\nthe first losses shown to be consistent for Max-Margin beyond the binary\nsetting. We finally address these limitations by correcting the concept of\nMax-Margin and introducing the Restricted-Max-Margin, where the maximization of\nthe loss-augmented scores is maintained, but performed over a subset of the\noriginal domain. The resulting loss is also a generalization of the binary\nsupport vector machine and it is consistent under milder conditions on the\ndiscrete loss.",
    "descriptor": "",
    "authors": [
      "Alex Nowak-Vila",
      "Alessandro Rudi",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.15069"
  },
  {
    "id": "arXiv:2105.15071",
    "title": "Adapting High-resource NMT Models to Translate Low-resource Related  Languages without Parallel Data",
    "abstract": "The scarcity of parallel data is a major obstacle for training high-quality\nmachine translation systems for low-resource languages. Fortunately, some\nlow-resource languages are linguistically related or similar to high-resource\nlanguages; these related languages may share many lexical or syntactic\nstructures. In this work, we exploit this linguistic overlap to facilitate\ntranslating to and from a low-resource language with only monolingual data, in\naddition to any parallel data in the related high-resource language. Our\nmethod, NMT-Adapt, combines denoising autoencoding, back-translation and\nadversarial objectives to utilize monolingual data for low-resource adaptation.\nWe experiment on 7 languages from three different language families and show\nthat our technique significantly improves translation into low-resource\nlanguage compared to other translation baselines.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Wei-Jen Ko",
      "Ahmed El-Kishky",
      "Adithya Renduchintala",
      "Vishrav Chaudhary",
      "Naman Goyal",
      "Francisco Guzm\u00e1n",
      "Pascale Fung",
      "Philipp Koehn",
      "Mona Diab"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15071"
  },
  {
    "id": "arXiv:2105.15074",
    "title": "Detecting Fetal Alcohol Spectrum Disorder in children using Artificial  Neural Network",
    "abstract": "Fetal alcohol spectrum disorder (FASD) is a syndrome whose only difference\ncompared to other children's conditions is the mother's alcohol consumption\nduring pregnancy. An earlier diagnosis of FASD improving the quality of life of\nchildren and adolescents. For this reason, this study focus on evaluating the\nuse of the artificial neural network (ANN) to classify children with FASD and\nexplore how accurate it is. ANN has been used to diagnose cancer, diabetes, and\nother diseases in the medical area, being a tool that presents good results.\nThe data used is from a battery of tests from children for 5-18 years old\n(include tests of psychometric, saccade eye movement, and diffusion tensor\nimaging (DTI)). We study the different configurations of ANN with dense layers.\nThe first one predicts 75\\% of the outcome correctly for psychometric data. The\nothers models include a feature layer, and we used it to predict FASD using\nevery test individually. The models accurately predict over 70\\% of the cases,\nand psychometric and memory guides predict over 88\\% accuracy. The results\nsuggest that the ANN approach is a competitive and efficient methodology to\ndetect FASD. However, we could be careful in used as a diagnostic technique.",
    "descriptor": "",
    "authors": [
      "Vannessa de J. Duarte",
      "Paul Leger",
      "Sergio Contreras",
      "Hiroaki Fukuda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.15074"
  },
  {
    "id": "arXiv:2105.15075",
    "title": "Not All Images are Worth 16x16 Words: Dynamic Vision Transformers with  Adaptive Sequence Length",
    "abstract": "Vision Transformers (ViT) have achieved remarkable success in large-scale\nimage recognition. They split every 2D image into a fixed number of patches,\neach of which is treated as a token. Generally, representing an image with more\ntokens would lead to higher prediction accuracy, while it also results in\ndrastically increased computational cost. To achieve a decent trade-off between\naccuracy and speed, the number of tokens is empirically set to 16x16. In this\npaper, we argue that every image has its own characteristics, and ideally the\ntoken number should be conditioned on each individual input. In fact, we have\nobserved that there exist a considerable number of \"easy\" images which can be\naccurately predicted with a mere number of 4x4 tokens, while only a small\nfraction of \"hard\" ones need a finer representation. Inspired by this\nphenomenon, we propose a Dynamic Transformer to automatically configure a\nproper number of tokens for each input image. This is achieved by cascading\nmultiple Transformers with increasing numbers of tokens, which are sequentially\nactivated in an adaptive fashion at test time, i.e., the inference is\nterminated once a sufficiently confident prediction is produced. We further\ndesign efficient feature reuse and relationship reuse mechanisms across\ndifferent components of the Dynamic Transformer to reduce redundant\ncomputations. Extensive empirical results on ImageNet, CIFAR-10, and CIFAR-100\ndemonstrate that our method significantly outperforms the competitive baselines\nin terms of both theoretical computational efficiency and practical inference\nspeed.",
    "descriptor": "",
    "authors": [
      "Yulin Wang",
      "Rui Huang",
      "Shiji Song",
      "Zeyi Huang",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15075"
  },
  {
    "id": "arXiv:2105.15076",
    "title": "Large-Scale Spatio-Temporal Person Re-identification: Algorithm and  Benchmark",
    "abstract": "Person re-identification (re-ID) in the scenario with large spatial and\ntemporal spans has not been fully explored. This is partially because that,\nexisting benchmark datasets were mainly collected with limited spatial and\ntemporal ranges, e.g., using videos recorded in a few days by cameras in a\nspecific region of the campus. Such limited spatial and temporal ranges make it\nhard to simulate the difficulties of person re-ID in real scenarios. In this\nwork, we contribute a novel Large-scale Spatio-Temporal (LaST) person re-ID\ndataset, including 10,860 identities with more than 224k images. Compared with\nexisting datasets, LaST presents more challenging and high-diversity reID\nsettings, and significantly larger spatial and temporal ranges. For instance,\neach person can appear in different cities or countries, and in various time\nslots from daytime to night, and in different seasons from spring to winter. To\nour best knowledge, LaST is a novel person re-ID dataset with the largest\nspatiotemporal ranges. Based on LaST, we verified its challenge by conducting a\ncomprehensive performance evaluation of 14 re-ID algorithms. We further propose\nan easy-to-implement baseline that works well on such challenging re-ID\nsetting. We also verified that models pre-trained on LaST can generalize well\non existing datasets with short-term and cloth-changing scenarios. We expect\nLaST to inspire future works toward more realistic and challenging re-ID tasks.\nMore information about the dataset is available at\nhttps://github.com/shuxjweb/last.git.",
    "descriptor": "",
    "authors": [
      "Xiujun Shu",
      "Xiao Wang",
      "Shiliang Zhang",
      "Xianghao Zhang",
      "Yuanqi Chen",
      "Ge Li",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.15076"
  },
  {
    "id": "arXiv:2105.15077",
    "title": "SDNet: mutil-branch for single image deraining using swin",
    "abstract": "Rain streaks degrade the image quality and seriously affect the performance\nof subsequent computer vision tasks, such as autonomous driving, social\nsecurity, etc. Therefore, removing rain streaks from a given rainy images is of\ngreat significance. Convolutional neural networks(CNN) have been widely used in\nimage deraining tasks, however, the local computational characteristics of\nconvolutional operations limit the development of image deraining tasks.\nRecently, the popular transformer has global computational features that can\nfurther facilitate the development of image deraining tasks. In this paper, we\nintroduce Swin-transformer into the field of image deraining for the first time\nto study the performance and potential of Swin-transformer in the field of\nimage deraining. Specifically, we improve the basic module of Swin-transformer\nand design a three-branch model to implement single-image rain removal. The\nformer implements the basic rain pattern feature extraction, while the latter\nfuses different features to further extract and process the image features. In\naddition, we employ a jump connection to fuse deep features and shallow\nfeatures. In terms of experiments, the existing public dataset suffers from\nimage duplication and relatively homogeneous background. So we propose a new\ndataset Rain3000 to validate our model. Therefore, we propose a new dataset\nRain3000 for validating our model. Experimental results on the publicly\navailable datasets Rain100L, Rain100H and our dataset Rain3000 show that our\nproposed method has performance and inference speed advantages over the current\nmainstream single-image rain streaks removal models.The source code will be\navailable at https://github.com/H-tfx/SDNet.",
    "descriptor": "",
    "authors": [
      "Fuxiang Tan",
      "YuTing Kong",
      "Yingying Fan",
      "Feng Liu",
      "Daxin Zhou",
      "Hao zhang",
      "Long Chen",
      "Liang Gao",
      "Yurong Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.15077"
  },
  {
    "id": "arXiv:2105.15078",
    "title": "Can Attention Enable MLPs To Catch Up With CNNs?",
    "abstract": "In the first week of May, 2021, researchers from four different institutions:\nGoogle, Tsinghua University, Oxford University and Facebook, shared their\nlatest work [16, 7, 12, 17] on arXiv.org almost at the same time, each\nproposing new learning architectures, consisting mainly of linear layers,\nclaiming them to be comparable, or even superior to convolutional-based models.\nThis sparked immediate discussion and debate in both academic and industrial\ncommunities as to whether MLPs are sufficient, many thinking that learning\narchitectures are returning to MLPs. Is this true? In this perspective, we give\na brief history of learning architectures, including multilayer perceptrons\n(MLPs), convolutional neural networks (CNNs) and transformers. We then examine\nwhat the four newly proposed architectures have in common. Finally, we give our\nviews on challenges and directions for new learning architectures, hoping to\ninspire future research.",
    "descriptor": "\nComments: Computational Visual Media, 2021, accepted. 4 pages, 1 figure\n",
    "authors": [
      "Meng-Hao Guo",
      "Zheng-Ning Liu",
      "Tai-Jiang Mu",
      "Dun Liang",
      "Ralph R. Martin",
      "Shi-Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15078"
  },
  {
    "id": "arXiv:2105.15079",
    "title": "SA2SL: From Aspect-Based Sentiment Analysis to Social Listening System  for Business Intelligence",
    "abstract": "In this paper, we present a process of building a social listening system\nbased on aspect-based sentiment analysis in Vietnamese from creating a dataset\nto building a real application. Firstly, we create UIT-ViSFD, a Vietnamese\nSmartphone Feedback Dataset as a new benchmark corpus built based on a strict\nannotation schemes for evaluating aspect-based sentiment analysis, consisting\nof 11,122 human-annotated comments for mobile e-commerce, which is freely\navailable for research purposes. We also present a proposed approach based on\nthe Bi-LSTM architecture with the fastText word embeddings for the Vietnamese\naspect based sentiment task. Our experiments show that our approach achieves\nthe best performances with the F1-score of 84.48% for the aspect task and\n63.06% for the sentiment task, which performs several conventional machine\nlearning and deep learning systems. Last but not least, we build SA2SL, a\nsocial listening system based on the best performance model on our dataset,\nwhich will inspire more social listening systems in future.",
    "descriptor": "",
    "authors": [
      "Luong Luc Phan",
      "Phuc Huynh Pham",
      "Kim Thi-Thanh Nguyen",
      "Tham Thi Nguyen",
      "Sieu Khai Huynh",
      "Luan Thanh Nguyen",
      "Tin Van Huynh",
      "Kiet Van Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15079"
  },
  {
    "id": "arXiv:2105.15080",
    "title": "Predicting Chronic Homelessness: The Importance of Comparing Algorithms  using Client Histories",
    "abstract": "This paper investigates how to best compare algorithms for predicting chronic\nhomelessness for the purpose of identifying good candidates for housing\nprograms. Predictive methods can rapidly refer potentially chronic shelter\nusers to housing but also sometimes incorrectly identify individuals who will\nnot become chronic (false positives). We use shelter access histories to\ndemonstrate that these false positives are often still good candidates for\nhousing. Using this approach, we compare a simple threshold method for\npredicting chronic homelessness to the more complex logistic regression and\nneural network algorithms. While traditional binary classification performance\nmetrics show that the machine learning algorithms perform better than the\nthreshold technique, an examination of the shelter access histories of the\ncohorts identified by the three algorithms show that they select groups with\nvery similar characteristics. This has important implications for resource\nconstrained not-for-profit organizations since the threshold technique can be\nimplemented using much simpler information technology infrastructure than the\nmachine learning algorithms.",
    "descriptor": "",
    "authors": [
      "Geoffrey G. Messier",
      "Caleb John",
      "Ayush Malik"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15080"
  },
  {
    "id": "arXiv:2105.15082",
    "title": "Exploring Sparse Expert Models and Beyond",
    "abstract": "Mixture-of-Experts (MoE) models can achieve promising results with outrageous\nlarge amount of parameters but constant computation cost, and thus it has\nbecome a trend in model scaling. Still it is a mystery how MoE layers bring\nquality gains by leveraging the parameters with sparse activation. In this\nwork, we investigate several key factors in sparse expert models. We observe\nthat load imbalance may not be a significant problem affecting model quality,\ncontrary to the perspectives of recent studies, while the number of sparsely\nactivated experts $k$ and expert capacity $C$ in top-$k$ routing can\nsignificantly make a difference in this context. Furthermore, we take a step\nforward to propose a simple method called expert prototyping that splits\nexperts into different prototypes and applies $k$ top-$1$ routing. This\nstrategy improves the model quality but maintains constant computational costs,\nand our further exploration on extremely large-scale models reflects that it is\nmore effective in training larger models. We push the model scale to over $1$\ntrillion parameters and implement it on solely $480$ NVIDIA V100-32GB GPUs, in\ncomparison with the recent SOTA Switch Transformer on $2048$ TPUs. The proposed\ngiant model achieves substantial speedup in convergence over the same-size\nbaseline.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "An Yang",
      "Junyang Lin",
      "Rui Men",
      "Chang Zhou",
      "Le Jiang",
      "Xianyan Jia",
      "Ang Wang",
      "Jie Zhang",
      "Jiamang Wang",
      "Yong Li",
      "Di Zhang",
      "Wei Lin",
      "Lin Qu",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15082"
  },
  {
    "id": "arXiv:2105.15086",
    "title": "Sum-rank product codes and bounds on the minimum distance",
    "abstract": "The tensor product of one code endowed with the Hamming metric and one\nendowed with the rank metric is analyzed. This gives a code which naturally\ninherits the sum-rank metric. Specializing to the product of a cyclic code and\na skew-cyclic code, the resulting code turns out to belong to the recently\nintroduced family of cyclic-skew-cyclic. A group theoretical description of\nthese codes is given, after investigating the semilinear isometries in the\nsum-rank metric. Finally, a generalization of the Roos and the Hartmann-Tzeng\nbounds for the sum rank-metric is established, as well as a new lower bound on\nthe minimum distance of one of the two codes constituting the product code.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Gianira N. Alfarano",
      "F.J. Lobillo",
      "Alessandro Neri",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.15086"
  },
  {
    "id": "arXiv:2105.15087",
    "title": "Beyond Noise: Mitigating the Impact of Fine-grained Semantic Divergences  on Neural Machine Translation",
    "abstract": "While it has been shown that Neural Machine Translation (NMT) is highly\nsensitive to noisy parallel training samples, prior work treats all types of\nmismatches between source and target as noise. As a result, it remains unclear\nhow samples that are mostly equivalent but contain a small number of\nsemantically divergent tokens impact NMT training. To close this gap, we\nanalyze the impact of different types of fine-grained semantic divergences on\nTransformer models. We show that models trained on synthetic divergences output\ndegenerated text more frequently and are less confident in their predictions.\nBased on these findings, we introduce a divergent-aware NMT framework that uses\nfactors to help NMT recover from the degradation caused by naturally occurring\ndivergences, improving both translation quality and model calibration on EN-FR\ntasks.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Eleftheria Briakou",
      "Marine Carpuat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15087"
  },
  {
    "id": "arXiv:2105.15089",
    "title": "Analogous to Evolutionary Algorithm: Designing a Unified Sequence Model",
    "abstract": "Inspired by biological evolution, we explain the rationality of Vision\nTransformer by analogy with the proven practical Evolutionary Algorithm (EA)\nand derive that both of them have consistent mathematical representation.\nAnalogous to the dynamic local population in EA, we improve the existing\ntransformer structure and propose a more efficient EAT model, and design\ntask-related heads to deal with different tasks more flexibly. Moreover, we\nintroduce the spatial-filling curve into the current vision transformer to\nsequence image data into a uniform sequential format. Thus we can design a\nunified EAT framework to address multi-modal tasks, separating the network\narchitecture from the data format adaptation. Our approach achieves\nstate-of-the-art results on the ImageNet classification task compared with\nrecent vision transformer works while having smaller parameters and greater\nthroughput. We further conduct multi-model tasks to demonstrate the superiority\nof the unified EAT, e.g., Text-Based Image Retrieval, and our approach improves\nthe rank-1 by +3.7 points over the baseline on the CSS dataset.",
    "descriptor": "",
    "authors": [
      "Jiangning Zhang",
      "Chao Xu",
      "Jian Li",
      "Wenzhou Chen",
      "Yabiao Wang",
      "Ying Tai",
      "Shuo Chen",
      "Chengjie Wang",
      "Feiyue Huang",
      "Yong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.15089"
  },
  {
    "id": "arXiv:2105.15093",
    "title": "Pho(SC)Net: An Approach Towards Zero-shot Word Image Recognition in  Historical Documents",
    "abstract": "Annotating words in a historical document image archive for word image\nrecognition purpose demands time and skilled human resource (like historians,\npaleographers). In a real-life scenario, obtaining sample images for all\npossible words is also not feasible. However, Zero-shot learning methods could\naptly be used to recognize unseen/out-of-lexicon words in such historical\ndocument images. Based on previous state-of-the-art methods for word spotting\nand recognition, we propose a hybrid representation that considers the\ncharacter's shape appearance to differentiate between two different words and\nhas shown to be more effective in recognizing unseen words. This representation\nhas been termed as Pyramidal Histogram of Shapes (PHOS), derived from PHOC,\nwhich embeds information about the occurrence and position of characters in the\nword. Later, the two representations are combined and experiments were\nconducted to examine the effectiveness of an embedding that has properties of\nboth PHOS and PHOC. Encouraging results were obtained on two publicly available\nhistorical document datasets and one synthetic handwritten dataset, which\njustifies the efficacy of \"Phos\" and the combined \"Pho(SC)\" representation.",
    "descriptor": "\nComments: Published at 16th International Conference on Document Analysis and Recognition (ICDAR 2021)\n",
    "authors": [
      "Anuj Rai",
      "Narayanan C. Krishnan",
      "Sukalpa Chanda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.15093"
  },
  {
    "id": "arXiv:2105.15094",
    "title": "Systematic investigation into generalization of COVID-19 CT deep  learning models with Gabor ensemble for lung involvement scoring",
    "abstract": "The COVID-19 pandemic has inspired unprecedented data collection and computer\nvision modelling efforts worldwide, focusing on diagnosis and stratification of\nCOVID-19 from medical images. Despite this large-scale research effort, these\nmodels have found limited practical application due in part to unproven\ngeneralization of these models beyond their source study. This study\ninvestigates the generalizability of key published models using the publicly\navailable COVID-19 Computed Tomography data through cross dataset validation.\nWe then assess the predictive ability of these models for COVID-19 severity\nusing an independent new dataset that is stratified for COVID-19 lung\ninvolvement. Each inter-dataset study is performed using histogram\nequalization, and contrast limited adaptive histogram equalization with and\nwithout a learning Gabor filter. The study shows high variability in the\ngeneralization of models trained on these datasets due to varied sample image\nprovenances and acquisition processes amongst other factors. We show that under\ncertain conditions, an internally consistent dataset can generalize well to an\nexternal dataset despite structural differences between these datasets with f1\nscores up to 86%. Our best performing model shows high predictive accuracy for\nlung involvement score for an independent dataset for which expertly labelled\nlung involvement stratification is available. Creating an ensemble of our best\nmodel for disease positive prediction with our best model for disease negative\nprediction using a min-max function resulted in a superior model for lung\ninvolvement prediction with average predictive accuracy of 75% for zero lung\ninvolvement and 96% for 75-100% lung involvement with almost linear\nrelationship between these stratifications.",
    "descriptor": "\nComments: 39 Pages, 8 figures, 14 tables comparing the generalization of COVID-19 CT Deep Learning Models\n",
    "authors": [
      "Michael J. Horry",
      "Subrata Chakraborty",
      "Biswajeet Pradhan",
      "Maryam Fallahpoor",
      "Chegeni Hossein",
      "Manoranjan Paul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.15094"
  },
  {
    "id": "arXiv:2105.15096",
    "title": "Small-Scale Spatial-Temporal Correlation Modeling for Reconfigurable  Intelligent Surfaces",
    "abstract": "The reconfigurable intelligent surface (RIS) is an emerging promising\ncandidate technology for the sixth-generation wireless networks, where the\nelement spacing is usually of sub-wavelength. Only limited knowledge, however,\nhas been gained about the spatial-temporal correlation behavior among the\nelements in an RIS. In this paper, we investigate the joint spatial-temporal\ncorrelation models for an RIS in a wireless communication system. Joint\nsmall-scale spatial-temporal correlation functions are provided and analyzed\nfor both ideal isotropic scattering and more practical non-isotropic scattering\nenvironments, where the latter is studied by employing an angular distribution\nderived from real-world millimeter-wave measurements. Analytical and simulation\nresults demonstrate that the joint spatial-temporal correlation can be\nrepresented by a four-dimensional sinc function under isotropic scattering,\nwhile the correlation is generally stronger with more fluctuation for\nnon-isotropic scattering with various motion directions.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Shu Sun",
      "Hangsong Yan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.15096"
  },
  {
    "id": "arXiv:2105.15097",
    "title": "Multiple Sources Localization with Sparse Recovery under Log-normal  Shadow Fading",
    "abstract": "Localization based on received signal strength (RSS) has drawn great interest\nin the wireless sensor network (WSN). In this paper, we investigate the\nRSS-based multi-sources localization problem with unknown transmitted power\nunder shadow fading. The log-normal shadowing effect is approximated through\nFenton-Wilkinson (F-W) method and maximum likelihood estimation is adopted to\noptimize the RSS-based multiple sources localization problem. Moreover, we\nexploit a sparse recovery and weighted average of candidates (SR-WAC) based\nmethod to set up an initiation, which can efficiently approach a superior local\noptimal solution. It is shown from the simulation results that the proposed\nmethod has a much higher localization accuracy and outperforms the other",
    "descriptor": "",
    "authors": [
      "Yueyan Chu",
      "Kangyong You",
      "Wenbin Guo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.15097"
  },
  {
    "id": "arXiv:2105.15098",
    "title": "Zero-bias Deep Learning Enabled Quick and Reliable Abnormality Detection  in IoT",
    "abstract": "Abnormality detection is essential to the performance of safety-critical and\nlatency-constrained systems. However, as systems are becoming increasingly\ncomplicated with a large quantity of heterogeneous data, conventional\nstatistical change point detection methods are becoming less effective and\nefficient. Although Deep Learning (DL) and Deep Neural Networks (DNNs) are\nincreasingly employed to handle heterogeneous data, they still lack theoretic\nassurable performance and explainability. This paper integrates zero-bias DNN\nand Quickest Event Detection algorithms to provide a holistic framework for\nquick and reliable detection of both abnormalities and time-dependent abnormal\nevents in the Internet of Things (IoT). We first use the zero-bias dense layer\nto increase the explainability of DNN. We provide a solution to convert\nzero-bias DNN classifiers into performance assured binary abnormality\ndetectors. Using the converted abnormality detector, we then present a\nsequential quickest detection scheme that provides the theoretically assured\nlowest abnormal event detection delay under false alarm constraints. Finally,\nwe demonstrate the effectiveness of the framework using both massive signal\nrecords from real-world aviation communication systems and simulated data. Code\nand data of our work is available at\n\\url{https://github.com/pcwhy/AbnormalityDetectionInZbDNN}",
    "descriptor": "",
    "authors": [
      "Yongxin Liu",
      "Jian Wang",
      "Jianqiang Li",
      "Shuteng Niu",
      "Houbing Song"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.15098"
  },
  {
    "id": "arXiv:2105.15100",
    "title": "Skin-Health Monitoring system using a Wireless Body Area Network",
    "abstract": "A new class of sensing paradigm known as lab-onskin where stretchable and\nflexible smart sensor devices are integrated into the skin, provides direct\nmonitoring and diagnostic interfaces to the body. Distributed lab-on-skin\nwireless sensors have the ability to provide continuous long term assessment of\nthe skin health. This paper proposes a distributed skin health monitoring\nsystem using a wireless body area network. The system is responsive to the\ndynamic changes in the skin health, and remotely reports on the same. The\nproposed algorithm detects the abnormal skin and creates an energy efficient\ndata aggregation tree covering the affected area while putting the unnecessary\nsensors to sleep mode. The algorithm responds to the changing conditions of the\nskin by dynamically adapting the size and shape of the monitoring trees to that\nof the abnormal skin areas thus providing a comprehensive monitoring.\nSimulation results demonstrate the application and utility of the proposed\nalgorithm for changing wound shapes and sizes.",
    "descriptor": "",
    "authors": [
      "Suman Kumar",
      "Kazi Amanul Islam Siddiqui",
      "Mukesh Kumary"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.15100"
  },
  {
    "id": "arXiv:2105.15101",
    "title": "Anchor Nodes Positioning for Self-localization in Wireless Sensor  Networks using Belief Propagation and Evolutionary Algorithms",
    "abstract": "Locating each node in a wireless sensor network is essential for starting the\nmonitoring job and sending information about the area. One method that has been\nused in hard and inaccessible environments is randomly scattering each node in\nthe area. In order to reduce the cost of using GPS at each node, some nodes\nshould be equipped with GPS (anchors), Then using the belief propagation\nalgorithm, locate other nodes. The number of anchor nodes must be reduced since\nthey are expensive. Furthermore, the location of these nodes affects the\nalgorithm's performance. Using multi-objective optimization, an algorithm is\nintroduced in this paper that minimizes the estimated location error and the\nnumber of anchor nodes. According to simulation results, This algorithm\nproposes a set of solutions with less energy consumption and less error than\nsimilar algorithms.",
    "descriptor": "\nComments: 5 pages, 12 figures\n",
    "authors": [
      "Saeed Ghadiri"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.15101"
  },
  {
    "id": "arXiv:2105.15102",
    "title": "Age of Information in an URLLC-enabled Decode-and-Forward Wireless  Communication System",
    "abstract": "Age of Information (AoI) measures the freshness of data in mission critical\nInternet-of-Things (IoT) applications i.e., industrial internet, intelligent\ntransportation systems etc. In this paper, a new system model is proposed to\nestimate the average AoI (AAoI) in an ultra-reliable low latency communication\n(URLLC) enabled wireless communication system with decodeand-forward relay\nscheme over the quasi-static Rayleigh block fading channels. Short packet\ncommunication scheme is used to meet both reliability and latency requirements\nof the proposed wireless network. By resorting finite block length information\ntheory, queuing theory and stochastic processes, a closed-form expression for\nAAoI is obtained. Finally, the impact of the system parameters, such as update\ngeneration rate, block length and block length allocation factor on the AAoI\nare investigated. All results are validated by the numerical results.",
    "descriptor": "",
    "authors": [
      "Chathuranga M. Wijerathna Basnayaka",
      "Dushantha Nalin K. Jayakody",
      "Tharindu D. Ponnimbaduge Perera",
      "Moises Vidal Ribeiro"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.15102"
  },
  {
    "id": "arXiv:2105.15103",
    "title": "Applications of Artificial Intelligence, Machine Learning and related  techniques for Computer Networking Systems",
    "abstract": "This article presents a primer/overview of applications of Artificial\nIntelligence and Machine Learning (AI/ML) techniques to address problems in the\ndomain of computer networking. In particular, the techniques have been used to\nsupport efficient and accurate traffic prediction, traffic classification,\nanomaly detection, network management, network security, network resource\nallocation and optimization, network scheduling algorithms, fault diagnosis and\nmany more such applications. The article first summarizes some of the key\nnetworking concepts and a few representative machine learning techniques and\nalgorithms. The article then presents details regarding the availability of\ndata sets for networking applications and machine learning software and\ntoolkits for processing these data sets. Highlights of some of the standards\nactivities, pursued by ITU-T and ETSI, which are related to AI/ML for\nnetworking, are also presented. Finally, the article discusses a small set of\nrepresentative networking problems where AI/ML techniques have been\nsuccessfully applied.",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Krishna M. Sivalingam"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15103"
  },
  {
    "id": "arXiv:2105.15105",
    "title": "SeReMAS: Self-Resilient Mobile AutonomousSystems Through Predictive Edge  Computing",
    "abstract": "Edge computing enables Mobile Autonomous Systems (MASs) to execute continuous\nstreams of heavy-duty mission-critical processing tasks, such as real-time\nobstacle detection and navigation. However, in practical applications, erratic\npatterns in channel quality, network load, and edge server load can interrupt\nthe task flow execution, which necessarily leads to severe disruption of the\nsystem's key operations. Existing work has mostly tackled the problem with\nreactive approaches, which cannot guarantee task-level reliability. Conversely,\nin this paper we focus on learning-based predictive edge computing to achieve\nself-resilient task offloading. By conducting a preliminary experimental\nevaluation, we show that there is no dominant feature that can predict the\nedge-MAS system reliability, which calls for an ensemble and selection of\nweaker features. To tackle the complexity of the problem, we propose SeReMAS, a\ndata-driven optimization framework. We first mathematically formulate a\nRedundant Task Offloading Problem (RTOP), where a MAS may connect to multiple\nedge servers for redundancy, and needs to select which server(s) to transmit\nits computing tasks in order to maximize the probability of task execution\nwhile minimizing channel and edge resource utilization. We then create a\npredictor based on Deep Reinforcement Learning (DRL), which produces the\noptimum task assignment based on application-, network- and telemetry-based\nfeatures. We prototype SeReMAS on a testbed composed by a drone, mounting a\nPixHawk flight controller, a Jetson Nano board, and three 802.11n WiFi\ninterfaces. We extensively evaluate SeReMAS by considering an application where\none drone offloads high-resolution images for real-time analysis to three edge\nservers on the ground. Experimental results show that SeReMAS improves task\nexecution probability by $17\\%$ with respect to existing reactive-based\napproaches.",
    "descriptor": "",
    "authors": [
      "Davide Callegaro",
      "Marco Levorato",
      "Francesco Restuccia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.15105"
  },
  {
    "id": "arXiv:2105.15106",
    "title": "A Survey of Knowledge Tracing",
    "abstract": "High-quality education is one of the keys to achieving a more sustainable\nworld. The recent COVID-19 epidemic has triggered the outbreak of online\neducation, which has enabled both students and teachers to learn and teach at\nhome. Meanwhile, it is now possible to record and research a large amount of\nlearning data using online learning platforms in order to offer better\nintelligent educational services. Knowledge Tracing (KT), which aims to monitor\nstudents' evolving knowledge state, is a fundamental and crucial task to\nsupport these intelligent services. Therefore, an increasing amount of research\nattention has been paid to this emerging area and considerable progress has\nbeen made. In this survey, we propose a new taxonomy of existing basic KT\nmodels from a technical perspective and provide a comprehensive overview of\nthese models in a systematic manner. In addition, many variants of KT models\nhave been proposed to capture more complete learning process. We then review\nthese variants involved in three phases of the learning process: before,\nduring, and after the student learning, respectively. Moreover, we present\nseveral typical applications of KT in different educational scenarios. Finally,\nwe provide some potential directions for future research in this fast-growing\nfield.",
    "descriptor": "\nComments: 20 pages, submitting to the TKDE journal\n",
    "authors": [
      "Qi Liu",
      "Shuanghong Shen",
      "Zhenya Huang",
      "Enhong Chen",
      "Yonghe Zheng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15106"
  },
  {
    "id": "arXiv:2105.15110",
    "title": "A Multilingual Entity Linking System for Wikipedia with a  Machine-in-the-Loop Approach",
    "abstract": "Hyperlinks constitute the backbone of the Web; they enable user navigation,\ninformation discovery, content ranking, and many other crucial services on the\nInternet. In particular, hyperlinks found within Wikipedia allow the readers to\nnavigate from one page to another to expand their knowledge on a given subject\nof interest or to discover a new one. However, despite Wikipedia editors'\nefforts to add and maintain its content, the distribution of links remains\nsparse in many language editions. This paper introduces a machine-in-the-loop\nentity linking system that can comply with community guidelines for adding a\nlink and aims at increasing link coverage in new pages and wiki-projects with\nlow-resources. To tackle these challenges, we build a context and language\nagnostic entity linking model that combines data collected from millions of\nanchors found across wiki-projects, as well as billions of users' reading\nsessions. We develop an interactive recommendation interface that proposes\ncandidate links to editors who can confirm, reject, or adapt the recommendation\nwith the overall aim of providing a more accessible editing experience for\nnewcomers through structured tasks. Our system's design choices were made in\ncollaboration with members of several language communities. When the system is\nimplemented as part of Wikipedia, its usage by volunteer editors will help us\nbuild a continuous evaluation dataset with active feedback. Our experimental\nresults show that our link recommender can achieve a precision above 80% while\nensuring a recall of at least 50% across 6 languages covering different sizes,\ncontinents, and families.",
    "descriptor": "",
    "authors": [
      "Martin Gerlach",
      "Marshall Miller",
      "Rita Ho",
      "Kosta Harlan",
      "Djellel Difallah"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.15110"
  },
  {
    "id": "arXiv:2105.15111",
    "title": "An Epidemiological Model for contact tracing with the Dutch CoronaMelder  App",
    "abstract": "We present an epidemiological model for the effectiveness of CoronaMelder,\nthe Dutch digital contact tracing app developed on top of the Google/Apple\nExposure Notification framework. We compare the effectiveness of CoronaMelder\nwith manual contract tracing on a number of metrics. CoronaMelder turns out to\nhave a small but noticeable positive influence in slowing down the COVID-19\npandemic, an effect that will become more pronounced in an opened-up society\nwhere adoption of CoronaMelder is increased.",
    "descriptor": "\nComments: This is a first and preliminary draft. Future updates are expected\n",
    "authors": [
      "Peter Boncz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.15111"
  },
  {
    "id": "arXiv:2105.15114",
    "title": "The use of e-portfolios in teaching and assessment",
    "abstract": "In this paper, we will initially go through the results of assessment in\nmathematics according to the international assessment programs PISA, TIMSS\n(2003), with respect to students' portfolios. Furthermore, we will present the\nforms and the ways of assessment and will focus on that assessment which refers\nto the use of eportfolios.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Maria Chionidou-Moskofoglou",
      "Spyridon Doukakis",
      "Amalia Lappa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15114"
  },
  {
    "id": "arXiv:2105.15115",
    "title": "Adoption of Precision Medicine; Limitations and Considerations",
    "abstract": "Research is ongoing all over the world for identifying the barriers and\nfinding effective solutions to accelerate the projection of Precision Medicine\n(PM) in the healthcare industry. Yet there has not been a valid and practical\nmodel to tackle the several challenges that have slowed down the widespread of\nthis clinical practice. This study aimed to highlight the major limitations and\nconsiderations for implementing Precision Medicine. The two theories Diffusion\nof Innovation and Socio-Technical are employed to discuss the success\nindicators of PM adoption. Throughout the theoretical assessment, two key\ntheoretical gaps are identified and related findings are discussed.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Nasim Sadat Mosavi",
      "Manuel Filipe Santos"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15115"
  },
  {
    "id": "arXiv:2105.15121",
    "title": "Pregnancy loss and unethical algorithms: Ethical issues in targeted  advertising",
    "abstract": "In this paper, the ethical issues and the importance of ethical algorithm\ndesign for target ads were briefly discussed.",
    "descriptor": "\nComments: 18th International Conference on the Ethical and Social Impacts of ICT Proceedings of the ETHICOMP 2020. Paradigm Shifts in ICT Ethics\n",
    "authors": [
      "Fatemeh Golpayegani"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15121"
  },
  {
    "id": "arXiv:2105.15122",
    "title": "The Social Responsibility of Game AI",
    "abstract": "Over the last decade we have watched as artificial intelligence has been\ntransformed into one of the most important issues of our time, and games have\ngrown into the biggest entertainment industry. As a result, game AI research as\na field has enjoyed increased access to funding, exposure in the press, and\ninfluence with governments and some of the largest technology firms in the\nworld. At this pivotal moment in the history of our field, this paper argues\nthat this privileged position brings with it an important set of\nresponsibilities which we have largely failed to meet. We show to whom we are\nresponsible, identify some of these responsibilities, and suggest actions we\ncan take as a community to leverage this power for good.",
    "descriptor": "",
    "authors": [
      "Michael Cook"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15122"
  },
  {
    "id": "arXiv:2105.15124",
    "title": "Screening of the Characteristics of Hate Crimes against Asian American  and Comparison to African Americans in Bay Area",
    "abstract": "COVID-19 has aided the spread of racism, as well as national insecurity,\ndistrust of immigrants, and general xenophobia, both of which may be linked to\nthe rise in anti-Asian hate crimes during the pandemic. Coronavirus Disease\n2019(COVID19) is thought to have originated in late December 2019 in Wuhan,\nChina, and quickly spread across the world during the spring months of 2020.\nAsian Americans recorded in increase in racially based hate crimes including\nphysical abuse and intimidation as COVID-19 spread throughout the United\nStates. This research study was conducted by high school students in the Bay\nArea to compare the intention and characteristics of hate crimes against Asian\nAmericans to hate crimes against African Americans. According to studies of\nboth victim-related and most offender-related variables, hate crimes against\nAsian Americans have been rapidly growing in the United States and vary from\nthose against African Americans. This leads to an investigation into the racial\ndisparity between Asian American offenders and those of other races. The nature\nand characteristics of hate crimes against Asian Americans are compared to\nthose of hate crimes against African Americans in our research. According to\nstudies of all victim-related factors, hate crimes against Asian Americans are\nsimilar to those against African Americans. Hate crimes against Asian\nAmericans, on the other hand, vary greatly from hate crimes against African\nAmericans in terms of the offender's ethnicity and all incident-related\nvariables.",
    "descriptor": "\nComments: 10 pages, 3 tables\n",
    "authors": [
      "Myung Suh Choi",
      "Yuli Choi",
      "Kevin Kang",
      "Katherine Lee",
      "Jacquelyn Ryu",
      "Nayeon Yu",
      "Sihyeon Yoon"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15124"
  },
  {
    "id": "arXiv:2105.15125",
    "title": "Strengthening e-Education in India using Machine Learning",
    "abstract": "e-Education has developed as one of the most encouraging territories. The\nIndian Government is investing all amounts of energy to improve education among\nthe residents of the nation. School and graduate understudies are focused on,\nhowever the stage is being created for all the residents seeking to learn.\nWithout a doubt, the objective is to build the quantity of literates with\nadvanced education. To accomplish the equivalent, propels in Data and\nCorrespondence innovation are being utilized in the education division, which\nhas cleared route for e-Training in India as well. To help educators in\nconcentrating more on more current viewpoints, their excess work can be\ndisposed of utilizing Machine Learning (ML). Difference to programming, ML\ndeals with information and answers to create rules. In the event that Machine\nLearning is tackled effectively, it can setup the training division and\ncontribute essentially to the development of the country. Hence, the work\npresented in this paper fortifies e-Education in India utilizing Machine\nLearning. For the most part, three concerns are focused to be tended to:\nPersonalized recommendation of course and Customized teaching methodology. The\nwork proposes utilizing developmental methodology of hereditary calculations\nfor improving conventional procedures. Implementation and experiments presented\nin the paper verify the viability of proposed calculations.",
    "descriptor": "",
    "authors": [
      "Naheed Khan",
      "Darshan Bhanushali",
      "Shreya Patel",
      "Radhika Kotecha"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15125"
  },
  {
    "id": "arXiv:2105.15131",
    "title": "Towards a trustful digital world: exploring self-sovereign identity  ecosystems",
    "abstract": "In the current global situation-burdened by, among others, a vast number of\npeople without formal identification, digital leap, the need for health\npassports and contact tracking applications-providing private and secure\ndigital identity for individuals, organizations and other entities is crucial.\nThe emerging self-sovereign identity (SSI) solutions rely on distributed ledger\ntechnologies and verifiable credentials and have the potential to enable\ntrustful digital interactions. In this human-centric paradigm, trust among\nactors can be established in a decentralized manner while the identity holders\nare able to own and control their confidential data. In this paper, we build on\nobservations gathered in a field study to identify the building blocks,\nantecedents and possible outcomes of SSI ecosystems. We also showcase\nopportunities for researchers and practitioners to investigate this phenomenon\nfrom a wide range of domains and theories, such as the digital innovation\necosystems, value co-creation, surveillance theory, or entrepreneurship\ntheories.",
    "descriptor": "\nComments: This is a preprint (the authors' version) of an article accepted for publication in Twenty-fifth Pacific Asia Conference on Information Systems, Dubai, UAE, 2021 (PACIS 2021) conference\n",
    "authors": [
      "Gabriella Laatikainen",
      "Taija Kolehmainen",
      "Mengcheng Li",
      "Markus Hautala",
      "Antti Kettunen",
      "Pekka Abrahamsson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15131"
  },
  {
    "id": "arXiv:2105.15133",
    "title": "An Assessment of the AI Regulation Proposed by the European Commission",
    "abstract": "In April 2021, the European Commission published a proposed regulation on AI.\nIt intends to create a uniform legal framework for AI within the European Union\n(EU). In this chapter, we analyze and assess the proposal. We show that the\nproposed regulation is actually not needed due to existing regulations. We also\nargue that the proposal clearly poses the risk of overregulation. As a\nconsequence, this would make the use or development of AI applications in\nsafety-critical application areas, such as in healthcare, almost impossible in\nthe EU. This would also likely further strengthen Chinese and US corporations\nin their technology leadership. Our assessment is based on the oral evidence we\ngave in May 2021 to the joint session of the European Union affairs committees\nof the German federal parliament and the French National Assembly.",
    "descriptor": "\nComments: To appear in the 2022 Springer book \"The Future Circle of Healthcare: AI, 3D Printing, Longevity, Ethics, and Uncertainty Mitigation\" edited by Sepehr Ehsani, Patrick Glauner, Philipp Plugmann and Florian M. Thieringer\n",
    "authors": [
      "Patrick Glauner"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15133"
  },
  {
    "id": "arXiv:2105.15134",
    "title": "Toward Understanding the Feature Learning Process of Self-supervised  Contrastive Learning",
    "abstract": "How can neural networks trained by contrastive learning extract features from\nthe unlabeled data? Why does contrastive learning usually need much stronger\ndata augmentations than supervised learning to ensure good representations?\nThese questions involve both the optimization and statistical aspects of deep\nlearning, but can hardly be answered by analyzing supervised learning, where\nthe target functions are the highest pursuit. Indeed, in self-supervised\nlearning, it is inevitable to relate to the optimization/generalization of\nneural networks to how they can encode the latent structures in the data, which\nwe refer to as the \\textit{feature learning process}.\nIn this work, we formally study how contrastive learning learns the feature\nrepresentations for neural networks by analyzing its feature learning process.\nWe consider the case where our data are comprised of two types of features: the\nmore semantically aligned sparse features which we want to learn from, and the\nother dense features we want to avoid. Theoretically, we prove that contrastive\nlearning using \\textbf{ReLU} networks provably learns the desired sparse\nfeatures if proper augmentations are adopted. We present an underlying\nprinciple called \\textbf{feature decoupling} to explain the effects of\naugmentations, where we theoretically characterize how augmentations can reduce\nthe correlations of dense features between positive samples while keeping the\ncorrelations of sparse features intact, thereby forcing the neural networks to\nlearn from the self-supervision of sparse features. Empirically, we verified\nthat the feature decoupling principle matches the underlying mechanism of\ncontrastive learning in practice.",
    "descriptor": "\nComments: Accepted to ICML2021\n",
    "authors": [
      "Zixin Wen",
      "Yuanzhi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.15134"
  },
  {
    "id": "arXiv:2105.15135",
    "title": "Reputation Bootstrapping for Composite Services using CP-nets",
    "abstract": "We propose a novel framework to bootstrap the reputation of on-demand service\ncompositions. On-demand compositions are usually context-aware and have little\nor no direct consumer feedback. The reputation bootstrapping of single or\natomic services does not consider the topology of the composition and\nrelationships among reputation-related factors. We apply Conditional Preference\nNetworks (CP-nets) of reputation-related factors for component services in a\ncomposition. The reputation of a composite service is bootstrapped by the\ncomposition of CP-nets. We consider the history of invocation among component\nservices to determine reputation-interdependence in a composition. The\ncomposition rules are constructed using the composition topology and four types\nof reputation-influence among component services. A heuristic-based Q-learning\napproach is proposed to select the optimal set of reputation-related CP-nets.\nExperimental results prove the efficiency of the proposed approach.",
    "descriptor": "\nComments: 14 Pages, accepted and to appear in IEEE Transactions on Services Computing\n",
    "authors": [
      "Sajib Mistry",
      "Athman Bouguettaya"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.15135"
  },
  {
    "id": "arXiv:2105.15136",
    "title": "Students Programming Competitions as an Educational Tool and a  Motivational Incentive to Students",
    "abstract": "In this short paper we report on student programming competition results by\nstudents from the Computer Science Department (COSC) of Okanagan College (OC)\nand discuss the achieved results from an educational point of view. We found\nthat some freshmen and sophomore students in diploma and degree programs are\nvery capable and eager to be involved in applied research projects as early as\nthe second semester, and into local and international programming competitions\nas well. Our observation is based on the last 2 educational years, beginning\n2015 when we introduced programming competitions to COSC students. Students\nreported that participation in competitions give them motivation to effectively\nlearn in their programming courses, inspire them to learn deeper and more\nthoroughly, and help them achieve better results in their classes.",
    "descriptor": "",
    "authors": [
      "Youry Khmelevsky",
      "Ken Chidlow"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15136"
  },
  {
    "id": "arXiv:2105.15139",
    "title": "Towards an Integrated Conceptual Modelling Kernel for Business  Transaction Workflows",
    "abstract": "The workflow concept, proliferated through the recently emergent computer\nsupported cooperative work (CSCW) systems and workflow systems, advances\ninformation systems (IS) implementation models by incorporating aspects of\ncollaboration and coordination in business processes. Under traditional\nimplementation models, applications are partitioned into discrete units of\nfunctionality, with (typically) operational procedures used to describe how\nhuman and computerised actions of business processes combine to deliver\nbusiness services. In this paper, a number of essential modelling concepts and\nfeatures for business transaction workflows are developed.",
    "descriptor": "",
    "authors": [
      "Alistair P. Barros",
      "Arthur H.M. ter Hofstede",
      "Henderik A. Proper"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.15139"
  },
  {
    "id": "arXiv:2105.15147",
    "title": "Comparing Two Different Approaches in Big Data and Business Analysis for  Churn Prediction with the Focus on How Apache Spark Employed",
    "abstract": "Due to the significant importance of Big Data analysis, especially in\nbusiness-related topics such as improving services, finding potential\ncustomers, and selecting practical approaches to manage income and expenses,\nmany companies attempt to collaborate with scientists to find how, why, and\nwhat they should analysis. In this work, we would like to compare and discuss\ntwo different approaches that employed in business analysis topic in Big Data\nwith more consideration on how they utilized Spark. Both studies have\ninvestigated Churn Prediction as their case study for their proposed approaches\nsince it is an essential topic in business analysis for companies to recognize\na customer intends to leave or stop using their services. Here, we focus on\nApache Spark since it has provided several solutions to handle a massive amount\nof data in recent years efficiently. This feature in Spark makes it one of the\nmost robust candidate tools to upfront with a Big Data problem, particularly\ntime and resource are concerns.",
    "descriptor": "",
    "authors": [
      "Mohammad Sina Kiarostami"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.15147"
  },
  {
    "id": "arXiv:2105.15152",
    "title": "UML Sequence Diagram: An Alternative Model",
    "abstract": "The general acceptance of sequence diagrams can be attributed to their\nrelatively intuitive nature and ability to describe partial behaviors (as\nopposed to such diagrams as state charts). However, studies have shown that\nover 80 percent of graduating students were unable to create a software design\nor even a partial design, and many students had no idea how sequence diagrams\nwere constrained by other models. Many students exhibited difficulties in\nidentifying valid interacting objects and constructing messages with\nappropriate arguments. Additionally, according to authorities, even though many\ndifferent semantics have been proposed for sequence diagrams (e.g.,\ntranslations to state machines), there exists no suitable semantic basis\nrefinement of required sequence diagram behavior because direct style semantics\ndo not precisely capture required sequence diagram behaviors; translations to\nother formalisms disregard essential features of sequence diagrams such as\nguard conditions and critical regions. This paper proposes an alternative to\nsequence diagrams, a generalized model that provides further understanding of\nsequence diagrams to assimilate them into a new modeling language called\nthinging machine (TM). The sequence diagram is extended horizontally by\nremoving the superficial vertical-only dimensional limitation of expansion to\npreserve the logical chronology of events. TM diagramming is spread nonlinearly\nin terms of actions. Events and their chronology are constructed on a second\nplane of description that is superimposed on the initial static description.\nThe result is a more refined representation that would simplify the modeling\nprocess. This is demonstrated through remodeling sequence diagram cases from\nthe literature.",
    "descriptor": "\nComments: 11 pages, 11 figures\n",
    "authors": [
      "Sabah Al-Fedaghi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.15152"
  },
  {
    "id": "arXiv:2105.15157",
    "title": "Adaptive Feature Alignment for Adversarial Training",
    "abstract": "Recent studies reveal that Convolutional Neural Networks (CNNs) are typically\nvulnerable to adversarial attacks, which pose a threat to security-sensitive\napplications. Many adversarial defense methods improve robustness at the cost\nof accuracy, raising the contradiction between standard and adversarial\naccuracies. In this paper, we observe an interesting phenomenon that feature\nstatistics change monotonically and smoothly w.r.t the rising of attacking\nstrength. Based on this observation, we propose the adaptive feature alignment\n(AFA) to generate features of arbitrary attacking strengths. Our method is\ntrained to automatically align features of arbitrary attacking strength. This\nis done by predicting a fusing weight in a dual-BN architecture. Unlike\nprevious works that need to either retrain the model or manually tune a\nhyper-parameters for different attacking strengths, our method can deal with\narbitrary attacking strengths with a single model without introducing any\nhyper-parameter. Importantly, our method improves the model robustness against\nadversarial samples without incurring much loss in standard accuracy.\nExperiments on CIFAR-10, SVHN, and tiny-ImageNet datasets demonstrate that our\nmethod outperforms the state-of-the-art under a wide range of attacking\nstrengths.",
    "descriptor": "",
    "authors": [
      "Tao Wang",
      "Ruixin Zhang",
      "Xingyu Chen",
      "Kai Zhao",
      "Xiaolin Huang",
      "Yuge Huang",
      "Shaoxin Li",
      "Jilin Li",
      "Feiyue Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.15157"
  },
  {
    "id": "arXiv:2105.15158",
    "title": "Isogeometric shape optimization for scaffold structures",
    "abstract": "The development of materials with specific structural properties is of huge\npractical interest, for example, for medical applications or for the\ndevelopment of light weight structures in aeronautics. In this article, we\ncombine shape optimization and homogenization for the optimal design of the\nmicrostructure in scaffolds. Given the current microstructure, we apply the\nisogeometric boundary element method to compute the effective tensor and to\nupdate the microstructure by using the shape gradient in order to match the\ndesired effective tensor. Extensive numerical studies are presented to\ndemonstrate the applicability and feasibility of the approach.",
    "descriptor": "",
    "authors": [
      "Helmut Harbrecht",
      "Michael Multerer",
      "Remo von Rickenbach"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.15158"
  },
  {
    "id": "arXiv:2105.15159",
    "title": "On maximizing a monotone $k$-submodular function under a knapsack  constraint",
    "abstract": "We study the problem of maximizing a monotone $k$-submodular function $f$\nunder a knapsack constraint, where a $k$-submodular function is a natural\ngeneralization of a submodular function to $k$ dimensions. We present a\ndeterministic $(\\frac12-\\frac{1}{2e})$-approximation algorithm that evaluates\n$f$ $O(n^5k^4)$ times.",
    "descriptor": "",
    "authors": [
      "Zhongzheng Tang",
      "Chenhao Wang",
      "Hau Chan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.15159"
  },
  {
    "id": "arXiv:2105.15161",
    "title": "Energy Efficiency Optimization for Multi-cell Massive MIMO: Centralized  and Distributed Power Allocation Algorithms",
    "abstract": "This paper investigates the energy efficiency (EE) optimization in downlink\nmulti-cell massive multiple-input multiple-output (MIMO). In our research, the\nstatistical channel state information (CSI) is exploited to reduce the\nsignaling overhead. To maximize the minimum EE among the neighbouring cells, we\ndesign the transmit covariance matrices for each base station (BS).\nSpecifically, optimization schemes for this max-min EE problem are developed,\nin the centralized and distributed ways, respectively. To obtain the transmit\ncovariance matrices, we first find out the closed-form optimal transmit\neigenmatrices for the BS in each cell, and convert the original transmit\ncovariance matrices designing problem into a power allocation one. Then, to\nlower the computational complexity, we utilize an asymptotic approximation\nexpression for the problem objective. Moreover, for the power allocation\ndesign, we adopt the minorization maximization method to address the\nnon-convexity of the ergodic rate, and use Dinkelbach's transform to convert\nthe max-min fractional problem into a series of convex optimization\nsubproblems. To tackle the transformed subproblems, we propose a centralized\niterative water-filling scheme. For reducing the backhaul burden, we further\ndevelop a distributed algorithm for the power allocation problem, which\nrequires limited inter-cell information sharing. Finally, the performance of\nthe proposed algorithms are demonstrated by extensive numerical results.",
    "descriptor": "\nComments: to appear in IEEE Transactions on Communications\n",
    "authors": [
      "Li You",
      "Yufei Huang",
      "Di Zhang",
      "Zheng Chang",
      "Wenjin Wang",
      "Xiqi Gao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.15161"
  },
  {
    "id": "arXiv:2105.15164",
    "title": "DISSECT: Disentangled Simultaneous Explanations via Concept Traversals",
    "abstract": "Explaining deep learning model inferences is a promising venue for scientific\nunderstanding, improving safety, uncovering hidden biases, evaluating fairness,\nand beyond, as argued by many scholars. One of the principal benefits of\ncounterfactual explanations is allowing users to explore \"what-if\" scenarios\nthrough what does not and cannot exist in the data, a quality that many other\nforms of explanation such as heatmaps and influence functions are inherently\nincapable of doing. However, most previous work on generative explainability\ncannot disentangle important concepts effectively, produces unrealistic\nexamples, or fails to retain relevant information. We propose a novel approach,\nDISSECT, that jointly trains a generator, a discriminator, and a concept\ndisentangler to overcome such challenges using little supervision. DISSECT\ngenerates Concept Traversals (CTs), defined as a sequence of generated examples\nwith increasing degrees of concepts that influence a classifier's decision. By\ntraining a generative model from a classifier's signal, DISSECT offers a way to\ndiscover a classifier's inherent \"notion\" of distinct concepts automatically\nrather than rely on user-predefined concepts. We show that DISSECT produces CTs\nthat (1) disentangle several concepts, (2) are influential to a classifier's\ndecision and are coupled to its reasoning due to joint training (3), are\nrealistic, (4) preserve relevant information, and (5) are stable across similar\ninputs. We validate DISSECT on several challenging synthetic and realistic\ndatasets where previous methods fall short of satisfying desirable criteria for\ninterpretability and show that it performs consistently well and better than\nexisting methods. Finally, we present experiments showing applications of\nDISSECT for detecting potential biases of a classifier and identifying spurious\nartifacts that impact predictions.",
    "descriptor": "",
    "authors": [
      "Asma Ghandeharioun",
      "Been Kim",
      "Chun-Liang Li",
      "Brendan Jou",
      "Brian Eoff",
      "Rosalind W. Picard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.15164"
  },
  {
    "id": "arXiv:2105.15165",
    "title": "Multimodal Detection of Information Disorder from Social Media",
    "abstract": "Social media is accompanied by an increasing proportion of content that\nprovides fake information or misleading content, known as information disorder.\nIn this paper, we study the problem of multimodal fake news detection on a\nlargescale multimodal dataset. We propose a multimodal network architecture\nthat enables different levels and types of information fusion. In addition to\nthe textual and visual content of a posting, we further leverage secondary\ninformation, i.e. user comments and metadata. We fuse information at multiple\nlevels to account for the specific intrinsic structure of the modalities. Our\nresults show that multimodal analysis is highly effective for the task and all\nmodalities contribute positively when fused properly.",
    "descriptor": "\nComments: 4 pages, 2 figures, 2 tables, PrePrint CBMI 2021\n",
    "authors": [
      "Armin Kirchknopf",
      "Djordje Slijepcevic",
      "Matthias Zeppelzauer"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.15165"
  },
  {
    "id": "arXiv:2105.15168",
    "title": "MSG-Transformer: Exchanging Local Spatial Information by Manipulating  Messenger Tokens",
    "abstract": "Transformers have offered a new methodology of designing neural networks for\nvisual recognition. Compared to convolutional networks, Transformers enjoy the\nability of referring to global features at each stage, yet the attention module\nbrings higher computational overhead that obstructs the application of\nTransformers to process high-resolution visual data. This paper aims to\nalleviate the conflict between efficiency and flexibility, for which we propose\na specialized token for each region that serves as a messenger (MSG). Hence, by\nmanipulating these MSG tokens, one can flexibly exchange visual information\nacross regions and the computational complexity is reduced. We then integrate\nthe MSG token into a multi-scale architecture named MSG-Transformer. In\nstandard image classification and object detection, MSG-Transformer achieves\ncompetitive performance and the inference on both GPU and CPU is accelerated.\nThe code will be available at https://github.com/hustvl/MSG-Transformer.",
    "descriptor": "",
    "authors": [
      "Jiemin Fang",
      "Lingxi Xie",
      "Xinggang Wang",
      "Xiaopeng Zhang",
      "Wenyu Liu",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15168"
  },
  {
    "id": "arXiv:2105.15171",
    "title": "Learning from Perturbations: Diverse and Informative Dialogue Generation  with Inverse Adversarial Training",
    "abstract": "In this paper, we propose Inverse Adversarial Training (IAT) algorithm for\ntraining neural dialogue systems to avoid generic responses and model dialogue\nhistory better. In contrast to standard adversarial training algorithms, IAT\nencourages the model to be sensitive to the perturbation in the dialogue\nhistory and therefore learning from perturbations. By giving higher rewards for\nresponses whose output probability reduces more significantly when dialogue\nhistory is perturbed, the model is encouraged to generate more diverse and\nconsistent responses. By penalizing the model when generating the same response\ngiven perturbed dialogue history, the model is forced to better capture\ndialogue history and generate more informative responses. Experimental results\non two benchmark datasets show that our approach can better model dialogue\nhistory and generate more diverse and consistent responses. In addition, we\npoint out a problem of the widely used maximum mutual information (MMI) based\nmethods for improving the diversity of dialogue response generation models and\ndemonstrate it empirically.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Wangchunshu Zhou",
      "Qifei Li",
      "Chenle Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15171"
  },
  {
    "id": "arXiv:2105.15173",
    "title": "Calculating a function of a matrix with a real spectrum",
    "abstract": "Let $T$ be a square matrix with a real spectrum, and let $f$ be an analytic\nfunction. The problem of the approximate calculation of $f(T)$ is discussed.\nApplying the Schur triangular decomposition and the reordering, one can assume\nthat $T$ is triangular and its diagonal entries $t_{ii}$ are arranged in\nincreasing order. To avoid calculations using the differences $t_{ii}-t_{jj}$\nwith close (including equal) $t_{ii}$ and $t_{jj}$, it is proposed to represent\n$T$ in a block form and calculate the two main block diagonals using\ninterpolating polynomials. The rest of the $f(T)$ entries can be calculated\nusing the Parlett recurrence algorithm. It is also proposed to perform scalar\noperations (such as the building of interpolating polynomials) with an enlarged\nnumber of decimal digits.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "P. Kubel\u00edk",
      "V. G. Kurbatov",
      "I. V. Kurbatova"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.15173"
  },
  {
    "id": "arXiv:2105.15174",
    "title": "Energy-Efficient Precoding in Electromagnetic Exposure-Constrained  Uplink Multiuser MIMO",
    "abstract": "User electromagnetic (EM) exposure is continuously being exacerbated by the\nevolution of multi-antenna portable devices. To mitigate the effects of EM\nradiation, portable devices must satisfy tight regulations on user exposure\nlevel, generally measured by specific absorption rate (SAR). To this end, we\ninvestigate the SAR-aware uplink precoder design for the energy efficiency (EE)\nmaximization in multiuser multiple-input multiple-output transmission\nexploiting statistical channel state information (CSI). As the objective\nfunction of the design problem is computationally demanding in the absence of\nclosed form, we present an asymptotic approximation of the objective to\nfacilitate the precoder design. An iterative algorithm based on Dinkelbach's\nmethod and sequential optimization is proposed to obtain an optimal solution of\nthe asymptotic EE optimization problem. Based on the transformed problem, an\niterative SAR-aware water-filing scheme is further conceived for the EE\noptimization precoding design with statistical CSI. Numerical results\nillustrate substantial performance improvements provided by our proposed\nSAR-aware energy-efficient transmission scheme over the traditional baseline\nschemes.",
    "descriptor": "\nComments: We investigate the SAR-aware uplink precoder design for the EE maximization in multiuser MIMO transmission exploiting statistical CSI\n",
    "authors": [
      "Jiayuan Xiong",
      "Li You",
      "Derrick Wing Kwan Ng",
      "Wenjin Wang",
      "Xiqi Gao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.15174"
  },
  {
    "id": "arXiv:2105.15176",
    "title": "Reinforced Generative Adversarial Network for Abstractive Text  Summarization",
    "abstract": "Sequence-to-sequence models provide a viable new approach to generative\nsummarization, allowing models that are no longer limited to simply selecting\nand recombining sentences from the original text. However, these models have\nthree drawbacks: their grasp of the details of the original text is often\ninaccurate, and the text generated by such models often has repetitions, while\nit is difficult to handle words that are beyond the word list. In this paper,\nwe propose a new architecture that combines reinforcement learning and\nadversarial generative networks to enhance the sequence-to-sequence attention\nmodel. First, we use a hybrid pointer-generator network that copies words\ndirectly from the source text, contributing to accurate reproduction of\ninformation without sacrificing the ability of generators to generate new\nwords. Second, we use both intra-temporal and intra-decoder attention to\npenalize summarized content and thus discourage repetition. We apply our model\nto our own proposed COVID-19 paper title summarization task and achieve close\napproximations to the current model on ROUEG, while bringing better\nreadability.",
    "descriptor": "",
    "authors": [
      "Tianyang Xu",
      "Chunyun Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15176"
  },
  {
    "id": "arXiv:2105.15179",
    "title": "How transfer learning impacts linguistic knowledge in deep NLP models?",
    "abstract": "Transfer learning from pre-trained neural language models towards downstream\ntasks has been a predominant theme in NLP recently. Several researchers have\nshown that deep NLP models learn non-trivial amount of linguistic knowledge,\ncaptured at different layers of the model. We investigate how fine-tuning\ntowards downstream NLP tasks impacts the learned linguistic knowledge. We carry\nout a study across popular pre-trained models BERT, RoBERTa and XLNet using\nlayer and neuron-level diagnostic classifiers. We found that for some GLUE\ntasks, the network relies on the core linguistic information and preserve it\ndeeper in the network, while for others it forgets. Linguistic information is\ndistributed in the pre-trained language models but becomes localized to the\nlower layers post fine-tuning, reserving higher layers for the task specific\nknowledge. The pattern varies across architectures, with BERT retaining\nlinguistic information relatively deeper in the network compared to RoBERTa and\nXLNet, where it is predominantly delegated to the lower layers.",
    "descriptor": "\nComments: Findings of the ACL 2021\n",
    "authors": [
      "Nadir Durrani",
      "Hassan Sajjad",
      "Fahim Dalvi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15179"
  },
  {
    "id": "arXiv:2105.15182",
    "title": "Model Mis-specification and Algorithmic Bias",
    "abstract": "Machine learning algorithms are increasingly used to inform critical\ndecisions. There is a growing concern about bias, that algorithms may produce\nuneven outcomes for individuals in different demographic groups. In this work,\nwe measure bias as the difference between mean prediction errors across groups.\nWe show that even with unbiased input data, when a model is mis-specified: (1)\npopulation-level mean prediction error can still be negligible, but group-level\nmean prediction errors can be large; (2) such errors are not equal across\ngroups; and (3) the difference between errors, i.e., bias, can take the\nworst-case realization. That is, when there are two groups of the same size,\nmean prediction errors for these two groups have the same magnitude but\nopposite signs. In closed form, we show such errors and bias are functions of\nthe first and second moments of the joint distribution of features (for linear\nand probit regressions). We also conduct numerical experiments to show similar\nresults in more general settings. Our work provides a first step for decoupling\nthe impact of different causes of bias.",
    "descriptor": "",
    "authors": [
      "Runshan Fu",
      "Yangfan Liang",
      "Peter Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.15182"
  },
  {
    "id": "arXiv:2105.15183",
    "title": "Efficient and Modular Implicit Differentiation",
    "abstract": "Automatic differentiation (autodiff) has revolutionized machine learning. It\nallows expressing complex computations by composing elementary ones in creative\nways and removes the burden of computing their derivatives by hand. More\nrecently, differentiation of optimization problem solutions has attracted\nwidespread attention with applications such as optimization as a layer, and in\nbi-level problems such as hyper-parameter optimization and meta-learning.\nHowever, the formulas for these derivatives often involve case-by-case tedious\nmathematical derivations. In this paper, we propose a unified, efficient and\nmodular approach for implicit differentiation of optimization problems. In our\napproach, the user defines (in Python in the case of our implementation) a\nfunction $F$ capturing the optimality conditions of the problem to be\ndifferentiated. Once this is done, we leverage autodiff of $F$ and implicit\ndifferentiation to automatically differentiate the optimization problem. Our\napproach thus combines the benefits of implicit differentiation and autodiff.\nIt is efficient as it can be added on top of any state-of-the-art solver and\nmodular as the optimality condition specification is decoupled from the\nimplicit differentiation mechanism. We show that seemingly simple principles\nallow to recover many recently proposed implicit differentiation methods and\ncreate new ones easily. We demonstrate the ease of formulating and solving\nbi-level optimization problems using our framework. We also showcase an\napplication to the sensitivity analysis of molecular dynamics.",
    "descriptor": "",
    "authors": [
      "Mathieu Blondel",
      "Quentin Berthet",
      "Marco Cuturi",
      "Roy Frostig",
      "Stephan Hoyer",
      "Felipe Llinares-L\u00f3pez",
      "Fabian Pedregosa",
      "Jean-Philippe Vert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.15183"
  },
  {
    "id": "arXiv:2105.15187",
    "title": "A Quasipolynomial $(2+\\varepsilon)$-Approximation for Planar Sparsest  Cut",
    "abstract": "The (non-uniform) sparsest cut problem is the following graph-partitioning\nproblem: given a \"supply\" graph, and demands on pairs of vertices, delete some\nsubset of supply edges to minimize the ratio of the supply edges cut to the\ntotal demand of the pairs separated by this deletion. Despite much effort,\nthere are only a handful of nontrivial classes of supply graphs for which\nconstant-factor approximations are known.\nWe consider the problem for planar graphs, and give a\n$(2+\\varepsilon)$-approximation algorithm that runs in quasipolynomial time.\nOur approach defines a new structural decomposition of an optimal solution\nusing a \"patching\" primitive. We combine this decomposition with a\nSherali-Adams-style linear programming relaxation of the problem, which we then\nround. This should be compared with the polynomial-time approximation algorithm\nof Rao (1999), which uses the metric linear programming relaxation and\n$\\ell_1$-embeddings, and achieves an $O(\\sqrt{\\log n})$-approximation in\npolynomial time.",
    "descriptor": "\nComments: To appear at STOC 2021\n",
    "authors": [
      "Vincent Cohen-Addad",
      "Anupam Gupta",
      "Philip N. Klein",
      "Jason Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.15187"
  },
  {
    "id": "arXiv:2105.15189",
    "title": "CVaR-based Flight Energy Risk Assessment for Multirotor UAVs using a  Deep Energy Model",
    "abstract": "Energy management is a critical aspect of risk assessment for Uncrewed Aerial\nVehicle (UAV) flights, as a depleted battery during a flight brings almost\nguaranteed vehicle damage and a high risk of human injuries or property damage.\nPredicting the amount of energy a flight will consume is challenging as\nrouting, weather, obstacles, and other factors affect the overall consumption.\nWe develop a deep energy model for a UAV that uses Temporal Convolutional\nNetworks to capture the time varying features while incorporating static\ncontextual information. Our energy model is trained on a real world dataset and\ndoes not require segregating flights into regimes. We illustrate an improvement\nin power predictions by $29\\%$ on test flights when compared to a\nstate-of-the-art analytical method. Using the energy model, we can predict the\nenergy usage for a given trajectory and evaluate the risk of running out of\nbattery during flight. We propose using Conditional Value-at-Risk (CVaR) as a\nmetric for quantifying this risk. We show that CVaR captures the risk\nassociated with worst-case energy consumption on a nominal path by transforming\nthe output distribution of Monte Carlo forward simulations into a risk space.\nComputing the CVaR on the risk-space distribution provides a metric that can\nevaluate the overall risk of a flight before take-off. Our energy model and\nrisk evaluation method can improve flight safety and evaluate the coverage area\nfrom a proposed takeoff location.\nThe video and codebase are available at https://youtu.be/PHXGigqilOA and\nhttps://git.io/cvar-risk .",
    "descriptor": "\nComments: 7 pages, 8 figures, Submitted ICRA 2021\n",
    "authors": [
      "Arnav Choudhry",
      "Brady Moon",
      "Jay Patrikar",
      "Constantine Samaras",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.15189"
  },
  {
    "id": "arXiv:2105.15191",
    "title": "Unifying Distillation with Personalization in Federated Learning",
    "abstract": "Federated learning (FL) is a decentralized privacy-preserving learning\ntechnique in which clients learn a joint collaborative model through a central\naggregator without sharing their data. In this setting, all clients learn a\nsingle common predictor (FedAvg), which does not generalize well on each\nclient's local data due to the statistical data heterogeneity among clients. In\nthis paper, we address this problem with PersFL, a discrete two-stage\npersonalized learning algorithm. In the first stage, PersFL finds the optimal\nteacher model of each client during the FL training phase. In the second stage,\nPersFL distills the useful knowledge from optimal teachers into each user's\nlocal model. The teacher model provides each client with some rich, high-level\nrepresentation that a client can easily adapt to its local model, which\novercomes the statistical heterogeneity present at different clients. We\nevaluate PersFL on CIFAR-10 and MNIST datasets using three data-splitting\nstrategies to control the diversity between clients' data distributions. We\nempirically show that PersFL outperforms FedAvg and three state-of-the-art\npersonalization methods, pFedMe, Per-FedAvg, and FedPer on majority data-splits\nwith minimal communication cost. Further, we study the performance of PersFL on\ndifferent distillation objectives, how this performance is affected by the\nequitable notion of fairness among clients, and the number of required\ncommunication rounds. PersFL code is available at https://tinyurl.com/hdh5zhxs\nfor public use and validation.",
    "descriptor": "",
    "authors": [
      "Siddharth Divi",
      "Habiba Farrukh",
      "Berkay Celik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.15191"
  },
  {
    "id": "arXiv:2105.15196",
    "title": "A novel second-order nonstandard finite difference method for solving  one-dimensional autonomous dynamical systems",
    "abstract": "A novel second-order nonstandard finite difference method that preserves\nsimultaneously the positivity and local asymptotic stability of one-dimensional\nautonomous dynamical systems is constructed and analyzed. The obtained results\nnot only resolve the contradiction between the dynamic consistency and\nhigh-order accuracy of NSFD schemes but also improve some well-known results\nthat have been published recently in [Applied Mathematics Letters 112(2021)\n106775], [AIP Conference Proceedings 2302(2020) 110003] and [Applied\nMathematics Letters 50(2015) 78-82].",
    "descriptor": "\nComments: 15 pages, 1 figure\n",
    "authors": [
      "Manh Tuan Hoang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.15196"
  },
  {
    "id": "arXiv:2105.15203",
    "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with  Transformers",
    "abstract": "We present SegFormer, a simple, efficient yet powerful semantic segmentation\nframework which unifies Transformers with lightweight multilayer perception\n(MLP) decoders. SegFormer has two appealing features: 1) SegFormer comprises a\nnovel hierarchically structured Transformer encoder which outputs multiscale\nfeatures. It does not need positional encoding, thereby avoiding the\ninterpolation of positional codes which leads to decreased performance when the\ntesting resolution differs from training. 2) SegFormer avoids complex decoders.\nThe proposed MLP decoder aggregates information from different layers, and thus\ncombining both local attention and global attention to render powerful\nrepresentations. We show that this simple and lightweight design is the key to\nefficient segmentation on Transformers. We scale our approach up to obtain a\nseries of models from SegFormer-B0 to SegFormer-B5, reaching significantly\nbetter performance and efficiency than previous counterparts. For example,\nSegFormer-B4 achieves 50.3% mIoU on ADE20K with 64M parameters, being 5x\nsmaller and 2.2% better than the previous best method. Our best model,\nSegFormer-B5, achieves 84.0% mIoU on Cityscapes validation set and shows\nexcellent zero-shot robustness on Cityscapes-C. Code will be released at:\ngithub.com/NVlabs/SegFormer.",
    "descriptor": "\nComments: Tech Report\n",
    "authors": [
      "Enze Xie",
      "Wenhai Wang",
      "Zhiding Yu",
      "Anima Anandkumar",
      "Jose M. Alvarez",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15203"
  },
  {
    "id": "arXiv:1806.01344",
    "title": "Data-Driven Participation Factors for Nonlinear Systems Based on Koopman  Mode Decomposition",
    "abstract": "This paper develops a novel data-driven technique to compute the\nparticipation factors for nonlinear systems based on the Koopman mode\ndecomposition. Provided that certain conditions are satisfied, it is shown that\nthe proposed technique generalizes the original definition of the linear\nmode-in-state participation factors. Two numerical examples are provided to\ndemonstrate the performance of our approach: one relying on a canonical\nnonlinear dynamical system, and the other based on the two-area four-machine\npower system. The Koopman mode decomposition is capable of coping with a large\nclass of nonlinearity, thereby making our technique able to deal with\noscillations arising in practice due to nonlinearities while being fast to\ncompute and compatible with real-time applications.",
    "descriptor": "",
    "authors": [
      "Marcos Netto",
      "Yoshihiko Susuki",
      "Lamine Mili"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1806.01344"
  },
  {
    "id": "arXiv:2105.12626",
    "title": "Automatic design of quantum feature maps",
    "abstract": "We propose a new technique for the automatic generation of optimal ad-hoc\nans\\\"atze for classification by using quantum support vector machine (QSVM).\nThis efficient method is based on NSGA-II multiobjective genetic algorithms\nwhich allow both maximize the accuracy and minimize the ansatz size. It is\ndemonstrated the validity of the technique by a practical example with a\nnon-linear dataset, interpreting the resulting circuit and its outputs. We also\nshow other application fields of the technique that reinforce the validity of\nthe method, and a comparison with classical classifiers in order to understand\nthe advantages of using quantum machine learning.",
    "descriptor": "",
    "authors": [
      "Sergio Altares-L\u00f3pez",
      "Angela Ribeiro",
      "Juan Jos\u00e9 Garc\u00eda-Ripoll"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.12626"
  },
  {
    "id": "arXiv:2105.13647",
    "title": "Hybrid Beamforming for Intelligent Reflecting Surface Aided Millimeter  Wave MIMO Systems",
    "abstract": "While communication systems that employ millimeter wave (mmWave) frequency\nbands can support extremely high data rates, they must use large antenna arrays\nin order to overcome the severe propagation loss of mmWave signals. As the cost\nof traditional fully-digital beamforming at baseband increases rapidly with the\nnumber of antennas, hybrid beamforming that requires only a small number of\nradio frequency (RF) chains has been considered as a key enabling technology\nfor mmWave communications. Intelligent reflecting surface (IRS) is another\ninnovative technology that has been proposed as an integral element of future\ncommunication systems, establishing the favorable propagation environment in a\ntimely manner through the use of low-cost passive reflecting elements. In this\npaper, we study IRS-aided mmWave multiple-input multiple-output (MIMO) systems\nwith hybrid beamforming architectures. We first propose the joint design of IRS\nreflection pattern and hybrid beamformer for narrowband MIMO systems. Then, by\nexploiting the sparsity of frequency-selective mmWave channels in the angular\ndomain, we generalize the proposed joint design to broadband MIMO systems with\northogonal frequency division multiplexing (OFDM) modulation. Simulation\nresults demonstrate that the proposed joint designs can significantly enhance\nthe spectral efficiency of the systems of interest and achieve superior\nperformance over the existing designs.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Sung Hyuck Hong",
      "Jaeyong Park",
      "Sung-Jin Kim",
      "Junil Choi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.13647"
  },
  {
    "id": "arXiv:2105.14033",
    "title": "STRIDE along Spectrahedral Vertices for Solving Large-Scale Rank-One  Semidefinite Relaxations",
    "abstract": "We consider solving high-order semidefinite programming (SDP) relaxations of\nnonconvex polynomial optimization problems (POPs) that admit rank-one optimal\nsolutions. Existing approaches, which solve the SDP independently from the POP,\neither cannot scale to large problems or suffer from slow convergence due to\nthe typical degeneracy of such SDPs. We propose a new algorithmic framework,\ncalled SpecTrahedral pRoximal gradIent Descent along vErtices (STRIDE), that\nblends fast local search on the nonconvex POP with global descent on the convex\nSDP. Specifically, STRIDE follows a globally convergent trajectory driven by a\nproximal gradient method (PGM) for solving the SDP, while simultaneously\nprobing long, but safeguarded, rank-one \"strides\", generated by fast nonlinear\nprogramming algorithms on the POP, to seek rapid descent. We prove STRIDE has\nglobal convergence. To solve the subproblem of projecting a given point onto\nthe feasible set of the SDP, we reformulate the projection step as a\ncontinuously differentiable unconstrained optimization and apply a\nlimited-memory BFGS method to achieve both scalability and accuracy. We conduct\nnumerical experiments on solving second-order SDP relaxations arising from two\nimportant applications in machine learning and computer vision. STRIDE\ndominates a diverse set of five existing SDP solvers and is the only solver\nthat can solve degenerate rank-one SDPs to high accuracy (e.g., KKT residuals\nbelow 1e-9), even in the presence of millions of equality constraints.",
    "descriptor": "\nComments: 9 pages main context, 2 figures\n",
    "authors": [
      "Heng Yang",
      "Ling Liang",
      "Kim-Chuan Toh",
      "Luca Carlone"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14033"
  },
  {
    "id": "arXiv:2105.14035",
    "title": "DeepMoM: Robust Deep Learning With Median-of-Means",
    "abstract": "Data used in deep learning is notoriously problematic. For example, data are\nusually combined from diverse sources, rarely cleaned and vetted thoroughly,\nand sometimes corrupted on purpose. Intentional corruption that targets the\nweak spots of algorithms has been studied extensively under the label of\n\"adversarial attacks.\" In contrast, the arguably much more common case of\ncorruption that reflects the limited quality of data has been studied much\nless. Such \"random\" corruptions are due to measurement errors, unreliable\nsources, convenience sampling, and so forth. These kinds of corruption are\ncommon in deep learning, because data are rarely collected according to strict\nprotocols -- in strong contrast to the formalized data collection in some parts\nof classical statistics. This paper concerns such corruption. We introduce an\napproach motivated by very recent insights into median-of-means and Le Cam's\nprinciple, we show that the approach can be readily implemented, and we\ndemonstrate that it performs very well in practice. In conclusion, we believe\nthat our approach is a very promising alternative to standard parameter\ntraining based on least-squares and cross-entropy loss.",
    "descriptor": "",
    "authors": [
      "Shih-Ting Huang",
      "Johannes Lederer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.14035"
  },
  {
    "id": "arXiv:2105.14047",
    "title": "Generators and relations for $U_n(\\mathbb Z [\\frac{1}{2}, i])$",
    "abstract": "Consider the universal gate set for quantum computing consisting of the gates\nX, CX, CCX, ${\\omega}{\\dagger}H$ and S. All of these gates have matrix entries\nin the ring $\\mathbb Z [\\frac{1}{2}, i]$, the smallest subring of the complex\nnumbers containing $\\frac{1}{2}$ and $i$. Amy, Glaudell, and Ross proved the\nconverse, i.e., any unitary matrix with entries in $\\mathbb Z [\\frac{1}{2}, i]$\ncan be realized by a quantum circuit over the above gate set using at most one\nancilla. In this paper, we give a finite presentation by generators and\nrelations of $U_n(\\mathbb Z [\\frac{1}{2}, i])$, the group of unitary $n\\times\nn$-matrices with entries in $\\mathbb Z [\\frac{1}{2}, i]$.",
    "descriptor": "",
    "authors": [
      "Xiaoning Bian",
      "Peter Selinger"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14047"
  },
  {
    "id": "arXiv:2105.14071",
    "title": "Classification of Brain Tumours in MR Images using Deep Spatiospatial  Models",
    "abstract": "A brain tumour is a mass or cluster of abnormal cells in the brain, which has\nthe possibility of becoming life-threatening because of its ability to invade\nneighbouring tissues and also form metastases. An accurate diagnosis is\nessential for successful treatment planning and magnetic resonance imaging is\nthe principal imaging modality for diagnostic of brain tumours and their\nextent. Deep Learning methods in computer vision applications have shown\nsignificant improvement in recent years, most of which can be credited to the\nfact that a sizeable amount of data is available to train models on, and the\nimprovements in the model architectures yielding better approximations in a\nsupervised setting. Classifying tumours using such deep learning methods has\nmade significant progress with the availability of open datasets with reliable\nannotations. Typically those methods are either 3D models, which use 3D\nvolumetric MRIs or even 2D models considering each slice separately. However,\nby treating the slice spatial dimension separately, spatiotemporal models can\nbe employed as spatiospatial models for this task. These models have the\ncapabilities of learning specific spatial and temporal relationship, while\nreducing computational costs. This paper uses two spatiotemporal models, ResNet\n(2+1)D and ResNet Mixed Convolution, to classify different types of brain\ntumours. It was observed that both these models performed superior to the pure\n3D convolutional model, ResNet18. Furthermore, it was also observed that\npre-training the models on a different, even unrelated dataset before training\nthem for the task of tumour classification improves the performance. Finally,\nPre-trained ResNet Mixed Convolution was observed to be the best model in these\nexperiments, achieving a macro F1-score of 0.93 and a test accuracy of 96.98\\%,\nwhile at the same time being the model with the least computational cost.",
    "descriptor": "",
    "authors": [
      "Soumick Chatterjee",
      "Faraz Ahmed Nizamani",
      "Andreas N\u00fcrnberger",
      "Oliver Speck"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14071"
  },
  {
    "id": "arXiv:2105.14113",
    "title": "Necessary and Sufficient Conditions for Stability of Discrete-Time  Switched Linear Systems with Ranged Dwell Time",
    "abstract": "This paper deals with the stability analysis problem of discrete-time\nswitched linear systems with ranged dwell time. A novel concept called\nL-switching-cycle is proposed, which contains sequences of multiple activation\ncycles satisfying the prescribed ranged dwell time constraint. Based on\nL-switching-cycle, two sufficient conditions are proposed to ensure the global\nuniform asymptotic stability of discrete-time switched linear systems. It is\nnoted that two conditions are equivalent in stability analysis with the same\n$L$-switching-cycle. These two sufficient conditions can be viewed as\ngeneralizations of the clock-dependent Lyapunov and multiple Lyapunov function\nmethods, respectively. Furthermore, it has been proven that the proposed\nL-switching-cycle can eventually achieve the nonconservativeness in stability\nanalysis as long as a sufficiently long L-switching-cycle is adopted. A\nnumerical example is provided to illustrate our theoretical results.",
    "descriptor": "",
    "authors": [
      "Weiming Xiang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14113"
  },
  {
    "id": "arXiv:2105.14120",
    "title": "Assessing the intelligibility of vocoded speech using a remote testing  framework",
    "abstract": "Over the past year, remote speech intelligibility testing has become a\npopular and necessary alternative to traditional in-person experiments due to\nthe need for physical distancing during the COVID-19 pandemic. A remote\nframework was developed for conducting speech intelligibility tests with normal\nhearing listeners. In this study, subjects used their personal computers to\ncomplete sentence recognition tasks in anechoic and reverberant listening\nenvironments. The results obtained using this remote framework were compared\nwith previously collected in-lab results, and showed higher levels of speech\nintelligibility among remote study participants than subjects who completed the\ntest in the laboratory.",
    "descriptor": "",
    "authors": [
      "Kevin M. Chu",
      "Leslie M. Collins",
      "Boyla O. Mainsah"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.14120"
  },
  {
    "id": "arXiv:2105.14135",
    "title": "Phoneme-Based Ratio Mask Estimation for Reverberant Speech Enhancement  in Cochlear Implant Processors",
    "abstract": "Cochlear implant (CI) users have considerable difficulty in understanding\nspeech in reverberant listening environments. Time-frequency (T-F) masking is a\ncommon technique that aims to improve speech intelligibility by multiplying\nreverberant speech by a matrix of gain values to suppress T-F bins dominated by\nreverberation. Recently proposed mask estimation algorithms leverage machine\nlearning approaches to distinguish between target speech and reverberant\nreflections. However, the spectro-temporal structure of speech is highly\nvariable and dependent on the underlying phoneme. One way to potentially\novercome this variability is to leverage explicit knowledge of phonemic\ninformation during mask estimation. This study proposes a phoneme-based mask\nestimation algorithm, where separate mask estimation models are trained for\neach phoneme. Sentence recognition tests were conducted in normal hearing\nlisteners to determine whether a phoneme-based mask estimation algorithm is\nbeneficial in the ideal scenario where perfect knowledge of the phoneme is\navailable. The results showed that the phoneme-based masks improved the\nintelligibility of vocoded speech when compared to conventional\nphoneme-independent masks. The results suggest that a phoneme-based speech\nenhancement strategy may potentially benefit CI users in reverberant listening\nenvironments.",
    "descriptor": "",
    "authors": [
      "Kevin M. Chu",
      "Leslie M. Collins",
      "Boyla O. Mainsah"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.14135"
  },
  {
    "id": "arXiv:2105.14139",
    "title": "Data-Driven Combinatorial Optimization with Incomplete Information: a  Distributionally Robust Optimization Approach",
    "abstract": "In this study we analyze linear combinatorial optimization problems where the\ncost vector is not known a priori, but is only observable through a finite data\nset. In contrast to the related studies, we presume that the number of\nobservations with respect to particular components of the cost vector may vary.\nThe goal is to find a procedure that transforms the data set into an estimate\nof the expected value of the objective function (which is referred to as a\nprediction rule) and a procedure that retrieves a candidate decision (which is\nreferred to as a prescription rule). We aim at finding the least conservative\nprediction and prescription rules, which satisfy some specified asymptotic\nguarantees. We demonstrate that the resulting vector optimization problems\nadmit a weakly optimal solution, which can be obtained by solving a particular\ndistributionally robust optimization problem. Specifically, the decision-maker\nmay optimize the worst-case expected loss across all probability distributions\nwith given component-wise relative entropy distances from the empirical\nmarginal distributions. Finally, we perform numerical experiments to analyze\nthe out-of-sample performance of the proposed solution approach.",
    "descriptor": "",
    "authors": [
      "Sergey S. Ketkov",
      "Andrei S. Shilov",
      "Oleg A. Prokopyev"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.14139"
  },
  {
    "id": "arXiv:2105.14143",
    "title": "Parallel server systems with cancel-on-completion redundancy",
    "abstract": "We consider a parallel server system with so-called cancel-on-completion\nredundancy. There are $n$ servers and multiple job classes $j$. An arriving\nclass $j$ job consists of $d_j$ components, placed on a randomly selected\nsubset of servers; the job service is complete as soon as $k_j$ components out\nof $d_j$ complete their service, at which point the service of all remaining\n$d_j-k_j$ components is canceled. The system is in general non-work-conserving\n-- the average amount of new workload added to the system by an arriving class\n$j$ job depends on the system state. This poses the main challenge for the\nsystem analysis.\nThe results of this paper concern both the system with fixed number of\nservers $n$ and the mean-field asymptotic regime when $n\\to\\infty$ while each\njob class arrival rate per server remains constant. The main question we\naddress for the asymptotic regime is whether the steady-state asymptotic\nindependence of server workloads holds. We prove that this property does hold\nunder certain conditions, including the important special case when job\ncomponents of each class $j$ are i.i.d. with an increasing-hazard-rate\ndistribution.",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Alexander Stolyar"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.14143"
  },
  {
    "id": "arXiv:2105.14144",
    "title": "A mechanism of Individualistic Indirect Reciprocity with internal and  external dynamics",
    "abstract": "The cooperation mechanism of indirect reciprocity has been studied by making\nmultiple variations of its parts. This research proposes a new variant of Nowak\nand Sigmund model, focused on agents' attitude; it is called Individualistic\nIndirect Reciprocity. In our model, an agent reinforces its strategy to the\nextent to which it makes a profit. We also include conditions related to the\nenvironment, visibility of agents, cooperation demand, and the attitude of an\nagent to maintain his cooperation strategy. Using Agent-Based Model and a Data\nScience method, we show on simulation results that the discriminatory stance of\nthe agents prevails in most cases. In general, cooperators only appear in\nconditions with low visibility of reputation and a high degree of cooperation\ndemand. The results also show that when the reputation of others is unknown,\nwith a high obstinacy and high cooperation demand, a heterogeneous society is\nobtained. The simulations show a wide diversity of scenarios, centralized,\npolarized, and mixed societies.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Mario Ignacio Gonz\u00e1lez Silva",
      "Ricardo Armando Gonz\u00e1lez Silva",
      "H\u00e9ctor Alfonso Ju\u00e1rez L\u00f3pez",
      "Antonio Aguilera Ontiveros"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.14144"
  },
  {
    "id": "arXiv:2105.14163",
    "title": "The query complexity of sampling from strongly log-concave distributions  in one dimension",
    "abstract": "We establish the first tight lower bound of $\\Omega(\\log\\log\\kappa)$ on the\nquery complexity of sampling from the class of strongly log-concave and\nlog-smooth distributions with condition number $\\kappa$ in one dimension.\nWhereas existing guarantees for MCMC-based algorithms scale polynomially in\n$\\kappa$, we introduce a novel algorithm based on rejection sampling that\ncloses this doubly exponential gap.",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Sinho Chewi",
      "Patrik Gerber",
      "Chen Lu",
      "Thibaut Le Gouic",
      "Philippe Rigollet"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14163"
  },
  {
    "id": "arXiv:2105.14176",
    "title": "Local Minimizers of the Crouzeix Ratio: A Nonsmooth Optimization Case  Study",
    "abstract": "Given a square matrix $A$ and a polynomial $p$, the Crouzeix ratio is the\nnorm of the polynomial on the field of values of $A$ divided by the 2-norm of\nthe matrix $p(A)$. Crouzeix's conjecture states that the globally minimal value\nof the Crouzeix ratio is 0.5, regardless of the matrix order and polynomial\ndegree, and it is known that 1 is a frequently occurring locally minimal value.\nMaking use of a heavy-tailed distribution to initialize our optimization\ncomputations, we demonstrate for the first time that the Crouzeix ratio has\nmany other locally minimal values between 0.5 and 1. Besides showing that the\nsame function values are repeatedly obtained for many different starting\npoints, we also verify that an approximate nonsmooth stationarity condition\nholds at computed candidate local minimizers. We also find that the same\nlocally minimal values are often obtained both when optimizing over real\nmatrices and polynomials, and over complex matrices and polynomials. We argue\nthat minimization of the Crouzeix ratio makes a very interesting nonsmooth\noptimization case study, illustrating among other things how effective the BFGS\nmethod is for nonsmooth, nonconvex optimization. Our method for verifying\napproximate nonsmooth stationarity is based on what may be a novel approach to\nfinding approximate subgradients of max functions on an interval. Our extensive\ncomputations strongly support Crouzeix's conjecture: in all cases, we find that\nthe smallest locally minimal value is 0.5.",
    "descriptor": "\nComments: 19 pages, 6 figures\n",
    "authors": [
      "Michael L. Overton"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14176"
  },
  {
    "id": "arXiv:2105.14180",
    "title": "DPLM: A Deep Perceptual Spatial-Audio Localization Metric",
    "abstract": "Subjective evaluations are critical for assessing the perceptual realism of\nsounds in audio-synthesis driven technologies like augmented and virtual\nreality. However, they are challenging to set up, fatiguing for users, and\nexpensive. In this work, we tackle the problem of capturing the perceptual\ncharacteristics of localizing sounds. Specifically, we propose a framework for\nbuilding a general purpose quality metric to assess spatial localization\ndifferences between two binaural recordings. We model localization similarity\nby utilizing activation-level distances from deep networks trained for\ndirection of arrival (DOA) estimation. Our proposed metric (DPLM) outperforms\nbaseline metrics on correlation with subjective ratings on a diverse set of\ndatasets, even without the benefit of any human-labeled training data.",
    "descriptor": "",
    "authors": [
      "Pranay Manocha",
      "Anurag Kumar",
      "Buye Xu",
      "Anjali Menon",
      "Israel D. Gebru",
      "Vamsi K. Ithapu",
      "Paul Calamia"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.14180"
  },
  {
    "id": "arXiv:2105.14187",
    "title": "Prediction error quantification through probabilistic scaling",
    "abstract": "In this paper, we address the probabilistic error quantification of a general\nclass of prediction methods. We consider a given prediction model and show how\nto obtain, through a sample-based approach, a probabilistic upper bound on the\nabsolute value of the prediction error. The proposed scheme is based on a\nprobabilistic scaling methodology in which the number of required randomized\nsamples is independent of the complexity of the prediction model. The\nmethodology is extended to address the case in which the probabilistic\nuncertain quantification is required to be valid for every member of a finite\nfamily of predictors. We illustrate the results of the paper by means of a\nnumerical example.",
    "descriptor": "\nComments: 8 pages, 2 figure\n",
    "authors": [
      "Victor Mirasierra",
      "Martina Mammarella",
      "Fabrizio Dabbene",
      "Teodoro Alamo"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14187"
  },
  {
    "id": "arXiv:2105.14192",
    "title": "Evolving Deep Convolutional Neural Network by Hybrid Sine-Cosine and  Extreme Learning Machine for Real-time COVID19 Diagnosis from X-Ray Images",
    "abstract": "The COVID19 pandemic globally and significantly has affected the life and\nhealth of many communities. The early detection of infected patients is\neffective in fighting COVID19. Using radiology (X-Ray) images is perhaps the\nfastest way to diagnose the patients. Thereby, deep Convolutional Neural\nNetworks (CNNs) can be considered as applicable tools to diagnose COVID19\npositive cases. Due to the complicated architecture of a deep CNN, its\nreal-time training and testing become a challenging problem. This paper\nproposes using the Extreme Learning Machine (ELM) instead of the last fully\nconnected layer to address this deficiency. However, the parameters' stochastic\ntuning of ELM's supervised section causes the final model unreliability.\nTherefore, to cope with this problem and maintain network reliability, the\nsine-cosine algorithm was utilized to tune the ELM's parameters. The designed\nnetwork is then benchmarked on the COVID-Xray-5k dataset, and the results are\nverified by a comparative study with canonical deep CNN, ELM optimized by\ncuckoo search, ELM optimized by genetic algorithm, and ELM optimized by whale\noptimization algorithm. The proposed approach outperforms comparative\nbenchmarks with a final accuracy of 98.83% on the COVID-Xray-5k dataset,\nleading to a relative error reduction of 2.33% compared to a canonical deep\nCNN. Even more critical, the designed network's training time is only 0.9421\nmilliseconds and the overall detection test time for 3100 images is 2.721\nseconds.",
    "descriptor": "\nComments: 28 pages, Soft Computing, 2021\n",
    "authors": [
      "Wu Chao",
      "Mohammad Khishe",
      "Mokhtar Mohammadi",
      "Sarkhel H. Taher Karim",
      "Tarik A. Rashid"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.14192"
  },
  {
    "id": "arXiv:2105.14194",
    "title": "Constraint-Based Inference of Heuristics for Foreign Exchange Trade  Model Optimization",
    "abstract": "The Foreign Exchange (Forex) is a large decentralized market, on which\ntrading analysis and algorithmic trading are popular. Research efforts have\nbeen focusing on proof of efficiency of certain technical indicators. We\ndemonstrate, however, that the values of indicator functions are not\nreproducible and often reduce the number of trade opportunities, compared to\nprice-action trading.\nIn this work, we develop two dataset-agnostic Forex trading heuristic\ntemplates with high rate of trading signals. In order to determine most optimal\nparameters for the given heuristic prototypes, we perform a machine learning\nsimulation of 10 years of Forex price data over three low-margin instruments\nand 6 different OHLC granularities. As a result, we develop a specific and\nreproducible list of most optimal trade parameters found for each\ninstrument-granularity pair, with 118 pips of average daily profit for the\noptimized configuration.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Nikolay Ivanov",
      "Qiben Yan"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14194"
  },
  {
    "id": "arXiv:2105.14197",
    "title": "The Impact of the U.S. Census Disclosure Avoidance System on  Redistricting and Voting Rights Analysis",
    "abstract": "The US Census Bureau plans to protect the privacy of 2020 Census respondents\nthrough its Disclosure Avoidance System (DAS), which attempts to achieve\ndifferential privacy guarantees by adding noise to the Census microdata. By\napplying redistricting simulation and analysis methods to DAS-protected 2010\nCensus data, we find that the protected data are not of sufficient quality for\nredistricting purposes. We demonstrate that the injected noise makes it\nimpossible for states to accurately comply with the One Person, One Vote\nprinciple. Our analysis finds that the DAS-protected data are biased against\ncertain areas, depending on voter turnout and partisan and racial composition,\nand that these biases lead to large and unpredictable errors in the analysis of\npartisan and racial gerrymanders. Finally, we show that the DAS algorithm does\nnot universally protect respondent privacy. Based on the names and addresses of\nregistered voters, we are able to predict their race as accurately using the\nDAS-protected data as when using the 2010 Census data. Despite this, the\nDAS-protected data can still inaccurately estimate the number of\nmajority-minority districts. We conclude with recommendations for how the\nCensus Bureau should proceed with privacy protection for the 2020 Census.",
    "descriptor": "\nComments: 18 pages, 11 figures\n",
    "authors": [
      "Christopher T. Kenny",
      "Shiro Kuriwaki",
      "Cory McCartan",
      "Evan Rosenman",
      "Tyler Simko",
      "Kosuke Imai"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.14197"
  },
  {
    "id": "arXiv:2105.14224",
    "title": "A Novel Framework Integrating AI Model and Enzymological Experiments  Promotes Identification of SARS-CoV-2 3CL Protease Inhibitors and  Activity-based Probe",
    "abstract": "The identification of protein-ligand interaction plays a key role in\nbiochemical research and drug discovery. Although deep learning has recently\nshown great promise in discovering new drugs, there remains a gap between deep\nlearning-based and experimental approaches. Here we propose a novel framework,\nnamed AIMEE, integrating AI Model and Enzymology Experiments, to identify\ninhibitors against 3CL protease of SARS-CoV-2, which has taken a significant\ntoll on people across the globe. From a bioactive chemical library, we have\nconducted two rounds of experiments and identified six novel inhibitors with a\nhit rate of 29.41%, and four of them showed an IC50 value less than 3 {\\mu}M.\nMoreover, we explored the interpretability of the central model in AIMEE,\nmapping the deep learning extracted features to domain knowledge of chemical\nproperties. Based on this knowledge, a commercially available compound was\nselected and proven to be an activity-based probe of 3CLpro. This work\nhighlights the great potential of combining deep learning models and\nbiochemical experiments for intelligent iteration and expanding the boundaries\nof drug discovery.",
    "descriptor": "",
    "authors": [
      "Fan Hu",
      "Lei Wang",
      "Yishen Hu",
      "Dongqi Wang",
      "Weijie Wang",
      "Jianbing Jiang",
      "Nan Li",
      "Peng Yin"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14224"
  },
  {
    "id": "arXiv:2105.14258",
    "title": "Hyperbolic compartmental models for epidemic spread on networks with  uncertain data: application to the emergence of Covid-19 in Italy",
    "abstract": "The importance of spatial networks in the spread of an epidemic is an\nessential aspect in modeling the dynamics of an infectious disease.\nAdditionally, any realistic data-driven model must take into account the large\nuncertainty in the values reported by official sources, such as the amount of\ninfectious individuals. In this paper we address the above aspects through a\nhyperbolic compartmental model on networks, in which nodes identify locations\nof interest, such as cities or regions, and arcs represent the ensemble of main\nmobility paths. The model describes the spatial movement and interactions of a\npopulation partitioned, from an epidemiological point of view, on the basis of\nan extended compartmental structure and divided into commuters, moving on a\nsuburban scale, and non-commuters, acting on an urban scale. Through a\ndiffusive rescaling, the model allows us to recover classical diffusion\nequations related to commuting dynamics. The numerical solution of the\nresulting multiscale hyperbolic system with uncertainty is then tackled using a\nstochastic collocation approach in combination with a finite-volume IMEX\nmethod. The ability of the model to correctly describe the spatial\nheterogeneity underlying the spread of an epidemic in a realistic city network\nis confirmed with a study of the outbreak of COVID-19 in Italy and its spread\nin the Lombardy Region.",
    "descriptor": "",
    "authors": [
      "Giulia Bertaglia",
      "Lorenzo Pareschi"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Numerical Analysis (math.NA)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.14258"
  },
  {
    "id": "arXiv:2105.14267",
    "title": "Information Directed Sampling for Sparse Linear Bandits",
    "abstract": "Stochastic sparse linear bandits offer a practical model for high-dimensional\nonline decision-making problems and have a rich information-regret structure.\nIn this work we explore the use of information-directed sampling (IDS), which\nnaturally balances the information-regret trade-off. We develop a class of\ninformation-theoretic Bayesian regret bounds that nearly match existing lower\nbounds on a variety of problem instances, demonstrating the adaptivity of IDS.\nTo efficiently implement sparse IDS, we propose an empirical Bayesian approach\nfor sparse posterior sampling using a spike-and-slab Gaussian-Laplace prior.\nNumerical results demonstrate significant regret reductions by sparse IDS\nrelative to several baselines.",
    "descriptor": "",
    "authors": [
      "Botao Hao",
      "Tor Lattimore",
      "Wei Deng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.14267"
  },
  {
    "id": "arXiv:2105.14301",
    "title": "Rapid Feature Evolution Accelerates Learning in Neural Networks",
    "abstract": "Neural network (NN) training and generalization in the infinite-width limit\nare well-characterized by kernel methods with a neural tangent kernel (NTK)\nthat is stationary in time. However, finite-width NNs consistently outperform\ncorresponding kernel methods, suggesting the importance of feature learning,\nwhich manifests as the time evolution of NTKs. Here, we analyze the phenomenon\nof kernel alignment of the NTK with the target functions during gradient\ndescent. We first provide a mechanistic explanation for why alignment between\ntask and kernel occurs in deep linear networks. We then show that this behavior\noccurs more generally if one optimizes the feature map over time to accelerate\nlearning while constraining how quickly the features evolve. Empirically,\ngradient descent undergoes a feature learning phase, during which top\neigenfunctions of the NTK quickly align with the target function and the loss\ndecreases faster than power law in time; it then enters a kernel gradient\ndescent (KGD) phase where the alignment does not improve significantly and the\ntraining loss decreases in power law. We show that feature evolution is faster\nand more dramatic in deeper networks. We also found that networks with multiple\noutput nodes develop separate, specialized kernels for each output channel, a\nphenomenon we termed kernel specialization. We show that this class-specific\nalignment is does not occur in linear networks.",
    "descriptor": "",
    "authors": [
      "Haozhe Shan",
      "Blake Bordelon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14301"
  },
  {
    "id": "arXiv:2105.14318",
    "title": "Estimating air quality co-benefits of energy transition using machine  learning",
    "abstract": "Estimating health benefits of reducing fossil fuel use from improved air\nquality provides important rationales for carbon emissions abatement.\nSimulating pollution concentration is a crucial step of the estimation, but\ntraditional approaches often rely on complicated chemical transport models that\nrequire extensive expertise and computational resources. In this study, we\ndevelop a novel and succinct machine learning framework that is able to provide\nprecise and robust annual average fine particle (PM2.5) concentration\nestimations directly from a high-resolution fossil energy use data set. The\naccessibility and applicability of this framework show great potentials of\nmachine learning approaches for integrated assessment studies. Applications of\nthe framework with Chinese data reveal highly heterogeneous health benefits of\nreducing fossil fuel use in different sectors and regions in China with a mean\nof \\$34/tCO2 and a standard deviation of \\$84/tCO2. Reducing rural and\nresidential coal use offers the highest co-benefits with a mean of \\$360/tCO2.\nOur findings prompt careful policy designs to maximize cost-effectiveness in\nthe transition towards a carbon-neutral energy system.",
    "descriptor": "",
    "authors": [
      "Da Zhang",
      "Qingyi Wang",
      "Shaojie Song",
      "Simiao Chen",
      "Mingwei Li",
      "Lu Shen",
      "Siqi Zheng",
      "Bofeng Cai",
      "Shenhao Wang"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14318"
  },
  {
    "id": "arXiv:2105.14320",
    "title": "Self-Supervised Nonlinear Transform-Based Tensor Nuclear Norm for  Multi-Dimensional Image Recovery",
    "abstract": "In this paper, we study multi-dimensional image recovery. Recently,\ntransform-based tensor nuclear norm minimization methods are considered to\ncapture low-rank tensor structures to recover third-order tensors in\nmulti-dimensional image processing applications. The main characteristic of\nsuch methods is to perform the linear transform along the third mode of\nthird-order tensors, and then compute tensor nuclear norm minimization on the\ntransformed tensor so that the underlying low-rank tensors can be recovered.\nThe main aim of this paper is to propose a nonlinear multilayer neural network\nto learn a nonlinear transform via the observed tensor data under\nself-supervision. The proposed network makes use of low-rank representation of\ntransformed tensors and data-fitting between the observed tensor and the\nreconstructed tensor to construct the nonlinear transformation. Extensive\nexperimental results on tensor completion, background subtraction, robust\ntensor completion, and snapshot compressive imaging are presented to\ndemonstrate that the performance of the proposed method is better than that of\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yi-Si Luo",
      "Xi-Le Zhao",
      "Tai-Xiang Jiang",
      "Yi Chang",
      "Michael K. Ng",
      "Chao Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14320"
  },
  {
    "id": "arXiv:2105.14328",
    "title": "Transfer Learning under High-dimensional Generalized Linear Models",
    "abstract": "In this work, we study the transfer learning problem under high-dimensional\ngeneralized linear models (GLMs), which aim to improve the fit on target data\nby borrowing information from useful source data. Given which sources to\ntransfer, we propose an oracle algorithm and derive its $\\ell_2$-estimation\nerror bounds. The theoretical analysis shows that under certain conditions,\nwhen the target and source are sufficiently close to each other, the estimation\nerror bound could be improved over that of the classical penalized estimator\nusing only target data. When we don't know which sources to transfer, an\nalgorithm-free transferable source detection approach is introduced to detect\ninformative sources. The detection consistency is proved under the\nhigh-dimensional GLM transfer learning setting. Extensive simulations and a\nreal-data experiment verify the effectiveness of our algorithms.",
    "descriptor": "\nComments: 52 pages, 7 figures\n",
    "authors": [
      "Ye Tian",
      "Yang Feng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.14328"
  },
  {
    "id": "arXiv:2105.14333",
    "title": "Covid-19 diagnosis from x-ray using neural networks",
    "abstract": "Corona virus or COVID-19 is a pandemic illness, which has influenced more\nthan million of causalities worldwide and infected a few large number of\nindividuals .Innovative instrument empowering quick screening of the COVID-19\ncontamination with high precision can be critically useful to the medical care\nexperts. The primary clinical device presently being used for the analysis of\nCOVID-19 is the Reverse record polymerase chain response as known as RT-PCR,\nwhich is costly, less-delicate and requires specific clinical work force. X-Ray\nimaging is an effectively available apparatus that can be a great option in the\nCOVID-19 conclusion. This exploration was taken to examine the utility of\ncomputerized reasoning in the quick and exact recognition of COVID-19 from\nchest X-Ray pictures. The point of this paper is to propose a procedure for\nprogrammed recognition of COVID-19 from advanced chest X-Ray images applying\npre-prepared profound learning calculations while boosting the discovery\nexactness. The point is to give over-focused on clinical experts a second pair\nof eyes through a learning picture characterization models. We distinguish an\nappropriate Convolutional Neural Network-CNN model through beginning similar\ninvestigation of a few mainstream CNN models.",
    "descriptor": "\nComments: 3 Graphs, 1 Figures\n",
    "authors": [
      "Dinesh J",
      "Mohammed Rhithick A"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14333"
  },
  {
    "id": "arXiv:2105.14338",
    "title": "Conditional Deep Convolutional Neural Networks for Improving the  Automated Screening of Histopathological Images",
    "abstract": "Semantic segmentation of breast cancer metastases in histopathological slides\nis a challenging task. In fact, significant variation in data characteristics\nof histopathology images (domain shift) make generalization of deep learning to\nunseen data difficult. Our goal is to address this challenge by using a\nconditional Fully Convolutional Network (co-FCN) whose output can be\nconditioned at run time, and which can improve its performance when a properly\nselected set of reference slides are used to condition the output. We adapted\nto our task a co-FCN originally applied to organs segmentation in volumetric\nmedical images and we trained it on the Whole Slide Images (WSIs) from three\nout of five medical centers present in the CAMELYON17 dataset. We tested the\nperformance of the network on the WSIs of the remaining centers. We also\ndeveloped an automated selection strategy for selecting the conditioning\nsubset, based on an unsupervised clustering process applied to a\ntarget-specific set of reference patches, followed by a selection policy that\nrelies on the cluster similarities with the input patch. We benchmarked our\nproposed method against a U-Net trained on the same dataset with no\nconditioning. The conditioned network shows better performance that the U-Net\non the WSIs with Isolated Tumor Cells and micro-metastases from the medical\ncenters used as test. Our contributions are an architecture which can be\napplied to the histopathology domain and an automated procedure for the\nselection of conditioning data.",
    "descriptor": "",
    "authors": [
      "Gianluca Gerard",
      "Marco Piastra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14338"
  },
  {
    "id": "arXiv:2105.14351",
    "title": "Corn Yield Prediction with Ensemble CNN-DNN",
    "abstract": "We investigate the predictive performance of two novel CNN-DNN machine\nlearning ensemble models in predicting county-level corn yields across the US\nCorn Belt (12 states). The developed data set is a combination of management,\nenvironment, and historical corn yields from 1980-2019. Two scenarios for\nensemble creation are considered: homogenous and heterogeneous ensembles. In\nhomogenous ensembles, the base CNN-DNN models are all the same, but they are\ngenerated with a bagging procedure to ensure they exhibit a certain level of\ndiversity. Heterogenous ensembles are created from different base CNN-DNN\nmodels which share the same architecture but have different levels of depth.\nThree types of ensemble creation methods were used to create several ensembles\nfor either of the scenarios: Basic Ensemble Method (BEM), Generalized Ensemble\nMethod (GEM), and stacked generalized ensembles. Results indicated that both\ndesigned ensemble types (heterogenous and homogenous) outperform the ensembles\ncreated from five individual ML models (linear regression, LASSO, random\nforest, XGBoost, and LightGBM). Furthermore, by introducing improvements over\nthe heterogeneous ensembles, the homogenous ensembles provide the most accurate\nyield predictions across US Corn Belt states. This model could make 2019 yield\npredictions with a root mean square error of 866 kg/ha, equivalent to 8.5%\nrelative root mean square, and could successfully explain about 77% of the\nspatio-temporal variation in the corn grain yields. The significant predictive\npower of this model can be leveraged for designing a reliable tool for corn\nyield prediction which will, in turn, assist agronomic decision-makers.",
    "descriptor": "",
    "authors": [
      "Mohsen Shahhosseini",
      "Guiping Hu",
      "Saeed Khaki",
      "Sotirios V. Archontoulis"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14351"
  },
  {
    "id": "arXiv:2105.14359",
    "title": "Green Tethered UAVs for EMF-Aware Cellular Networks",
    "abstract": "A prevalent theory circulating among the non-scientific community is that the\nintensive deployment of base stations over the territory significantly\nincreases the level of electromagnetic field (EMF) exposure and affects\npopulation health. To alleviate this concern, in this work, we propose a\nnetwork architecture that introduces tethered unmanned aerial vehicles (TUAVs)\ncarrying green antennas to minimize the EMF exposure while guaranteeing a high\ndata rate for users. In particular, each TUAV can attach itself to one of the\npossible ground stations at the top of some buildings. The location of the\nTUAVs, transmit power of user equipment and association policy are optimized to\nminimize the EMF exposure. Unfortunately, the problem turns out to be\nmixed-integer non-linear programming (MINLP), which is non-deterministic\npolynomial-time (NP) hard. We propose an efficient low-complexity algorithm\ncomposed of three submodules. Firstly, we propose an algorithm based on the\ngreedy principle to determine the optimal association matrix between the users\nand base stations. Then, we offer two approaches, a modified K-mean and shrink\nand realign (SR) process, to associate each TUAV with a ground station.\nFinally, we put forward two algorithms based on the golden search and SR\nprocess to adjust the TUAV's position within the hovering area over the\nbuilding. After that, we consider the dual problem that maximizes the sum rate\nwhile keeping the exposure below a predefined value, such as the level enforced\nby the regulation. Next, we perform extensive simulations to show the\neffectiveness of the proposed TUAVs to reduce the exposure compared to various\narchitectures. Eventually, we show that TUAVs with green antennas can\neffectively mitigate the EMF exposure by more than 20% compared to fixed green\nsmall cells while achieving a higher data rate.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Zhengying Lou",
      "Ahmed Elzanaty",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.14359"
  },
  {
    "id": "arXiv:2105.14368",
    "title": "Fit without fear: remarkable mathematical phenomena of deep learning  through the prism of interpolation",
    "abstract": "In the past decade the mathematical theory of machine learning has lagged far\nbehind the triumphs of deep neural networks on practical challenges. However,\nthe gap between theory and practice is gradually starting to close. In this\npaper I will attempt to assemble some pieces of the remarkable and still\nincomplete mathematical mosaic emerging from the efforts to understand the\nfoundations of deep learning. The two key themes will be interpolation, and its\nsibling, over-parameterization. Interpolation corresponds to fitting data, even\nnoisy data, exactly. Over-parameterization enables interpolation and provides\nflexibility to select a right interpolating model.\nAs we will see, just as a physical prism separates colors mixed within a ray\nof light, the figurative prism of interpolation helps to disentangle\ngeneralization and optimization properties within the complex picture of modern\nMachine Learning. This article is written with belief and hope that clearer\nunderstanding of these issues brings us a step closer toward a general theory\nof deep learning and machine learning.",
    "descriptor": "\nComments: A version of this paper will appear in Acta Numerica\n",
    "authors": [
      "Mikhail Belkin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.14368"
  },
  {
    "id": "arXiv:2105.14372",
    "title": "Ten Quick Tips for Deep Learning in Biology",
    "abstract": "Machine learning is a modern approach to problem-solving and task automation.\nIn particular, machine learning is concerned with the development and\napplications of algorithms that can recognize patterns in data and use them for\npredictive modeling. Artificial neural networks are a particular class of\nmachine learning algorithms and models that evolved into what is now described\nas deep learning. Given the computational advances made in the last decade,\ndeep learning can now be applied to massive data sets and in innumerable\ncontexts. Therefore, deep learning has become its own subfield of machine\nlearning. In the context of biological research, it has been increasingly used\nto derive novel insights from high-dimensional biological data. To make the\nbiological applications of deep learning more accessible to scientists who have\nsome experience with machine learning, we solicited input from a community of\nresearchers with varied biological and deep learning interests. These\nindividuals collaboratively contributed to this manuscript's writing using the\nGitHub version control platform and the Manubot manuscript generation toolset.\nThe goal was to articulate a practical, accessible, and concise set of\nguidelines and suggestions to follow when using deep learning. In the course of\nour discussions, several themes became clear: the importance of understanding\nand applying machine learning fundamentals as a baseline for utilizing deep\nlearning, the necessity for extensive model comparisons with careful\nevaluation, and the need for critical thought in interpreting results generated\nby deep learning, among others.",
    "descriptor": "\nComments: 23 pages, 2 figures\n",
    "authors": [
      "Benjamin D. Lee",
      "Anthony Gitter",
      "Casey S. Greene",
      "Sebastian Raschka",
      "Finlay Maguire",
      "Alexander J. Titus",
      "Michael D. Kessler",
      "Alexandra J. Lee",
      "Marc G. Chevrette",
      "Paul Allen Stewart",
      "Thiago Britto-Borges",
      "Evan M. Cofer",
      "Kun-Hsing Yu",
      "Juan Jose Carmona",
      "Elana J. Fertig",
      "Alexandr A. Kalinin",
      "Beth Signal",
      "Benjamin J. Lengerich",
      "Timothy J. Triche Jr",
      "Simina M. Boca"
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14372"
  },
  {
    "id": "arXiv:2105.14385",
    "title": "On Centralized and Distributed Mirror Descent: Exponential Convergence  Analysis Using Quadratic Constraints",
    "abstract": "Mirror descent (MD) is a powerful first-order optimization technique that\nsubsumes several optimization algorithms including gradient descent (GD). In\nthis work, we study the exact convergence rate of MD in both centralized and\ndistributed cases for strongly convex and smooth problems. We view MD with a\ndynamical system lens and leverage quadratic constraints (QCs) to provide\nconvergence guarantees based on the Lyapunov stability. For centralized MD, we\nestablish a semi-definite programming (SDP) that certifies exponentially fast\nconvergence of MD subject to a linear matrix inequality (LMI). We prove that\nthe SDP always has a feasible solution that recovers the optimal GD rate. Next,\nwe analyze the exponential convergence of distributed MD and characterize the\nrate using two LMIs. To the best of our knowledge, the exact (exponential) rate\nof distributed MD has not been previously explored in the literature. We\npresent numerical results as a verification of our theory and observe that the\nrichness of the Lyapunov function entails better (worst-case) convergence rates\ncompared to existing works on distributed GD.",
    "descriptor": "",
    "authors": [
      "Youbang Sun",
      "Mahyar Fazlyab",
      "Shahin Shahrampour"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14385"
  },
  {
    "id": "arXiv:2105.14397",
    "title": "The Sample Fr\u00e9chet Mean of Sparse Graphs is Sparse",
    "abstract": "In this note we prove the following result: the sample Fr\\'echet mean of a\nset of sparse graphs is sparse. We prove the result for the graph Hamming\ndistance, and the spectral adjacency pseudometric, using very different\narguments.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Francois G. Meyer",
      "Daniel Ferguson"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14397"
  },
  {
    "id": "arXiv:2105.14409",
    "title": "A Matrix Autoencoder Framework to Align the Functional and Structural  Connectivity Manifolds as Guided by Behavioral Phenotypes",
    "abstract": "We propose a novel matrix autoencoder to map functional connectomes from\nresting state fMRI (rs-fMRI) to structural connectomes from Diffusion Tensor\nImaging (DTI), as guided by subject-level phenotypic measures. Our specialized\nautoencoder infers a low dimensional manifold embedding for the rs-fMRI\ncorrelation matrices that mimics a canonical outer-product decomposition. The\nembedding is simultaneously used to reconstruct DTI tractography matrices via a\nsecond manifold alignment decoder and to predict inter-subject phenotypic\nvariability via an artificial neural network. We validate our framework on a\ndataset of 275 healthy individuals from the Human Connectome Project database\nand on a second clinical dataset consisting of 57 subjects with Autism Spectrum\nDisorder. We demonstrate that the model reliably recovers structural\nconnectivity patterns across individuals, while robustly extracting predictive\nand interpretable brain biomarkers in a cross-validated setting. Finally, our\nframework outperforms several baselines at predicting behavioral phenotypes in\nboth real-world datasets.",
    "descriptor": "",
    "authors": [
      "Niharika Shimona D'Souza",
      "Mary Beth Nebel",
      "Deana Crocetti",
      "Nicholas Wymbs",
      "Joshua Robinson",
      "Stewart Mostofsky",
      "Archana Venkataraman"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14409"
  },
  {
    "id": "arXiv:2105.14438",
    "title": "Hitting times for non-backtracking random walks",
    "abstract": "A non-backtracking random walk on a graph is a random walk where, at each\nstep, it is not allowed to return back to the node that has just been left.\nNon-backtracking random walks can model physical diffusion phenomena in a more\nrealistic way than traditional random walks. However, the interest in these\nstochastic processes has grown only in recent years and, for this reason, there\nare still various open questions. In this work, we show how to compute the\naverage number of steps a non-backtracking walker takes to reach a specific\nnode starting from a given node. This problem can be reduced to solving a\nlinear system that, under suitable conditions, has a unique solution. Finally,\nwe compute the average number of steps required to perform a round trip from a\ngiven node and we show that mean return times for non-backtracking random walks\ncoincide with their analogue for random walks in all finite, undirected graphs\nin which both stochastic processes are well-defined.",
    "descriptor": "",
    "authors": [
      "Dario Fasino",
      "Arianna Tonetto",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14438"
  },
  {
    "id": "arXiv:2105.14505",
    "title": "Computation-aided classical-quantum multiple access to boost network  communication speeds",
    "abstract": "A multiple access channel (MAC) consists of multiple senders simultaneously\ntransmitting their messages to a single receiver. For the classical-quantum\ncase (cq-MAC), achievable rates are known assuming that all the messages are\ndecoded, a common assumption in quantum network design. However, such a\nconventional design approach ignores the global network structure, i.e., the\nnetwork topology. When a cq-MAC is given as a part of quantum network\ncommunication, this work shows that computation properties can be used to boost\ncommunication speeds with code design dependently on the network topology. We\nquantify achievable quantum communication rates of codes with computation\nproperty for a two-sender cq-MAC. When the two-sender cq-MAC is a boson\ncoherent channel with binary discrete modulation, we show that it achieves the\nmaximum possible communication rate (the single-user capacity), which cannot be\nachieved with conventional design. Further, such a rate can be achieved by\ndifferent detection methods: quantum (with and without quantum memory), on-off\nphoton counting and homodyne (each at different photon power). Finally, we\ndescribe two practical applications, one of which cryptographic.",
    "descriptor": "",
    "authors": [
      "Masahito Hayashi",
      "Angeles Vazquez-Castro"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.14505"
  },
  {
    "id": "arXiv:2105.14524",
    "title": "Parameter Estimation for the SEIR Model Using Recurrent Nets",
    "abstract": "The standard way to estimate the parameters $\\Theta_\\text{SEIR}$ (e.g., the\ntransmission rate $\\beta$) of an SEIR model is to use grid search, where\nsimulations are performed on each set of parameters, and the parameter set\nleading to the least $L_2$ distance between predicted number of infections and\nobserved infections is selected. This brute-force strategy is not only time\nconsuming, as simulations are slow when the population is large, but also\ninaccurate, since it is impossible to enumerate all parameter combinations. To\naddress these issues, in this paper, we propose to transform the\nnon-differentiable problem of finding optimal $\\Theta_\\text{SEIR}$ to a\ndifferentiable one, where we first train a recurrent net to fit a small number\nof simulation data. Next, based on this recurrent net that is able to\ngeneralize SEIR simulations, we are able to transform the objective to a\ndifferentiable one with respect to $\\Theta_\\text{SEIR}$, and straightforwardly\nobtain its optimal value. The proposed strategy is both time efficient as it\nonly relies on a small number of SEIR simulations, and accurate as we are able\nto find the optimal $\\Theta_\\text{SEIR}$ based on the differentiable objective.\nOn two COVID-19 datasets, we observe that the proposed strategy leads to\nsignificantly better parameter estimations with a smaller number of\nsimulations.",
    "descriptor": "",
    "authors": [
      "Chun Fan",
      "Yuxian Meng",
      "Xiaofei Sun",
      "Fei Wu",
      "Tianwei Zhang",
      "Jiwei Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14524"
  },
  {
    "id": "arXiv:2105.14574",
    "title": "Scalable and Interpretable Marked Point Processes",
    "abstract": "We introduce a novel inferential framework for marked point processes that\nenjoys both scalability and interpretability. The framework is based on\nvariational inference and it aims to speed up inference for a flexible family\nof marked point processes where the joint distribution of times and marks can\nbe specified in terms of the conditional distribution of times given the\nprocess filtration, and of the conditional distribution of marks given the\nprocess filtration and the current time. We assess the predictive ability of\nour proposed method over four real-world datasets where results show its\ncompetitive performance against other baselines. The attractiveness of our\nframework for the modelling of marked point processes is illustrated through a\ncase study of association football data where scalability and interpretability\nare exploited for extracting useful informative patterns.",
    "descriptor": "",
    "authors": [
      "Aristeidis Panos",
      "Ioannis Kosmidis",
      "Petros Dellaportas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14574"
  },
  {
    "id": "arXiv:2105.14586",
    "title": "Kolmogorov-Smirnov Test-Based Actively-Adaptive Thompson Sampling for  Non-Stationary Bandits",
    "abstract": "We consider the non-stationary multi-armed bandit (MAB) framework and propose\na Kolmogorov-Smirnov (KS) test based Thompson Sampling (TS) algorithm named\nTS-KS, that actively detects change points and resets the TS parameters once a\nchange is detected. In particular, for the two-armed bandit case, we derive\nbounds on the number of samples of the reward distribution to detect the change\nonce it occurs. Consequently, we show that the proposed algorithm has\nsub-linear regret. Contrary to existing works, our algorithm is able to detect\na change when the underlying reward distribution changes even though the mean\nreward remains the same. Finally, to test the efficacy of the proposed\nalgorithm, we employ it in two case-studies: i) task-offloading scenario in\nwireless edge-computing, and ii) portfolio optimization. Our results show that\nthe proposed TS-KS algorithm outperforms not only the static TS algorithm but\nalso it performs better than other bandit algorithms designed for\nnon-stationary environments. Moreover, the performance of TS-KS is at par with\nthe state-of-the-art forecasting algorithms such as Facebook-PROPHET and ARIMA.",
    "descriptor": "",
    "authors": [
      "Gourab Ghatak",
      "Hardhik Mohanty",
      "Aniq Ur Rahman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.14586"
  },
  {
    "id": "arXiv:2105.14594",
    "title": "Sparse Uncertainty Representation in Deep Learning with Inducing Weights",
    "abstract": "Bayesian neural networks and deep ensembles represent two modern paradigms of\nuncertainty quantification in deep learning. Yet these approaches struggle to\nscale mainly due to memory inefficiency issues, since they require parameter\nstorage several times higher than their deterministic counterparts. To address\nthis, we augment the weight matrix of each layer with a small number of\ninducing weights, thereby projecting the uncertainty quantification into such\nlow dimensional spaces. We further extend Matheron's conditional Gaussian\nsampling rule to enable fast weight sampling, which enables our inference\nmethod to maintain reasonable run-time as compared with ensembles. Importantly,\nour approach achieves competitive performance to the state-of-the-art in\nprediction and uncertainty estimation tasks with fully connected neural\nnetworks and ResNets, while reducing the parameter size to $\\leq 24.3\\%$ of\nthat of a $single$ neural network.",
    "descriptor": "",
    "authors": [
      "Hippolyt Ritter",
      "Martin Kukla",
      "Cheng Zhang",
      "Yingzhen Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14594"
  },
  {
    "id": "arXiv:2105.14613",
    "title": "Square Kilometre Array : Processing Voluminous MeerKAT Data on IRIS",
    "abstract": "Processing astronomical data often comes with huge challenges with regards to\ndata management as well as data processing. MeerKAT telescope is one of the\nprecursor telescopes of the World's largest observatory - Square Kilometre\nArray. So far, MeerKAT data was processed using the South African computing\nfacility i.e. IDIA, and exploited to make ground-breaking discoveries. However,\nto process MeerKAT data on UK's IRIS computing facility requires new\nimplementation of the MeerKAT pipeline. This paper focuses on how to transfer\nMeerKAT data from the South African site to UK's IRIS systems for processing.\nWe discuss about our RapifXfer Data transfer framework for transferring the\nMeerKAT data from South Africa to the UK, and the MeerKAT job processing\nframework pertaining to the UK's IRIS resources.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Priyaa Thavasimani",
      "Anna Scaife"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.14613"
  },
  {
    "id": "arXiv:2105.14634",
    "title": "DimRad: A Radar-Based Perception System for Prosthetic Leg Barrier  Traversing",
    "abstract": "Lower extremity amputees face challenges in natural locomotion, which is\npartially compensated using powered assistive systems, e.g., micro-processor\ncontrolled prosthetic leg. In this paper, a radar-based perception system is\nproposed to assist prosthetic legs for autonomous obstacle traversing, focusing\non multiple-step staircases. The presented perception system is composed of a\nradar module operating with a multiple-input-multiple-output (MIMO)\nconfiguration to localize consecutive stair corners. An inertial measurement\nunit (IMU) is integrated for coordinates correction due to the angular\ndis-positioning that occurs because of the knee angular motion. The captured\ninformation from both sensors is used for staircase dimensioning (depth and\nheight). A shallow neural network (NN) is proposed to model the error due to\nthe hardware limitations and enhance the dimension estimation accuracy (1 cm).\nThe algorithm is implemented on a microcontroller subsystem of the radar kit to\nqualify the perception system for embedded integration in powered prosthetic\nlegs.",
    "descriptor": "\nComments: 5 pages, 6 figures, 2 tables\n",
    "authors": [
      "Fady Aziz",
      "Bassam Elmakhzangy",
      "Christophe Maufroy",
      "Urs Schneider",
      "Marco F. Huber"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14634"
  },
  {
    "id": "arXiv:2105.14645",
    "title": "Empirical Models for Multidimensional Regression of Fission Systems",
    "abstract": "The development of next-generation autonomous control of fission systems,\nsuch as nuclear power plants, will require leveraging advancements in machine\nlearning. For fission systems, accurate prediction of nuclear transport is\nimportant to quantify the safety margin and optimize performance. The\nstate-of-the-art approach to this problem is costly Monte Carlo (MC)\nsimulations to approximate solutions of the neutron transport equation. Such an\napproach is feasible for offline calculations e.g., for design or licensing,\nbut is precluded from use as a model-based controller. In this work, we explore\nthe use of Artificial Neural Networks (ANN), Gradient Boosting Regression\n(GBR), Gaussian Process Regression (GPR) and Support Vector Regression (SVR) to\ngenerate empirical models. The empirical model can then be deployed, e.g., in a\nmodel predictive controller. Two fission systems are explored: the subcritical\nMIT Graphite Exponential Pile (MGEP), and the critical MIT Research Reactor\n(MITR).\nFindings from this work establish guidelines for developing empirical models\nfor multidimensional regression of neutron transport. An assessment of the\naccuracy and precision finds that the SVR, followed closely by ANN, performs\nthe best. For both MGEP and MITR, the optimized SVR model exhibited a\ndomain-averaged, test, mean absolute percentage error of 0.17 %. A spatial\ndistribution of performance metrics indicates that physical regions of poor\nperformance coincide with locations of largest neutron flux perturbation --\nthis outcome is mitigated by ANN and SVR. Even at local maxima, ANN and SVR\nbias is within experimental uncertainty bounds. A comparison of the performance\nvs. training dataset size found that SVR is more data-efficient than ANN. Both\nANN and SVR achieve a greater than 7 order reduction in evaluation time vs. a\nMC simulation.",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Akshay J. Dave",
      "Jiankai Yu",
      "Jarod Wilson",
      "Bren Phillips",
      "Kaichao Sun",
      "Benoit Forget"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14645"
  },
  {
    "id": "arXiv:2105.14656",
    "title": "Human-level COVID-19 Diagnosis from Low-dose CT Scans Using a Two-stage  Time-distributed Capsule Network",
    "abstract": "Reverse transcription-polymerase chain reaction (RT-PCR) is currently the\ngold standard in COVID-19 diagnosis. It can, however, take days to provide the\ndiagnosis, and false negative rate is relatively high. Imaging, in particular\nchest computed tomography (CT), can assist with diagnosis and assessment of\nthis disease. Nevertheless, it is shown that standard dose CT scan gives\nsignificant radiation burden to patients, especially those in need of multiple\nscans. In this study, we consider low-dose and ultra-low-dose (LDCT and ULDCT)\nscan protocols that reduce the radiation exposure close to that of a single\nX-Ray, while maintaining an acceptable resolution for diagnosis purposes. Since\nthoracic radiology expertise may not be widely available during the pandemic,\nwe develop an Artificial Intelligence (AI)-based framework using a collected\ndataset of LDCT/ULDCT scans, to study the hypothesis that the AI model can\nprovide human-level performance. The AI model uses a two stage capsule network\narchitecture and can rapidly classify COVID-19, community acquired pneumonia\n(CAP), and normal cases, using LDCT/ULDCT scans. The AI model achieves COVID-19\nsensitivity of 89.5% +\\- 0.11, CAP sensitivity of 95% +\\- 0.11, normal cases\nsensitivity (specificity) of 85.7% +\\- 0.16, and accuracy of 90% +\\- 0.06. By\nincorporating clinical data (demographic and symptoms), the performance further\nimproves to COVID-19 sensitivity of 94.3% +\\- pm 0.05, CAP sensitivity of 96.7%\n+\\- 0.07, normal cases sensitivity (specificity) of 91% +\\- 0.09 , and accuracy\nof 94.1% +\\- 0.03. The proposed AI model achieves human-level diagnosis based\non the LDCT/ULDCT scans with reduced radiation exposure. We believe that the\nproposed AI model has the potential to assist the radiologists to accurately\nand promptly diagnose COVID-19 infection and help control the transmission\nchain during the pandemic.",
    "descriptor": "",
    "authors": [
      "Parnian Afshar",
      "Moezedin Javad Rafiee",
      "Farnoosh Naderkhani",
      "Shahin Heidarian",
      "Nastaran Enshaei",
      "Anastasia Oikonomou",
      "Faranak Babaki Fard",
      "Reut Anconina",
      "Keyvan Farahani",
      "Konstantinos N. Plataniotis",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14656"
  },
  {
    "id": "arXiv:2105.14704",
    "title": "Parkinsonian Chinese Speech Analysis towards Automatic Classification of  Parkinson's Disease",
    "abstract": "Speech disorders often occur at the early stage of Parkinson's disease (PD).\nThe speech impairments could be indicators of the disorder for early diagnosis,\nwhile motor symptoms are not obvious. In this study, we constructed a new\nspeech corpus of Mandarin Chinese and addressed classification of patients with\nPD. We implemented classical machine learning methods with ranking algorithms\nfor feature selection, convolutional and recurrent deep networks, and an end to\nend system. Our classification accuracy significantly surpassed\nstate-of-the-art studies. The result suggests that free talk has stronger\nclassification power than standard speech tasks, which could help the design of\nfuture speech tasks for efficient early diagnosis of the disease. Based on\nexisting classification methods and our natural speech study, the automatic\ndetection of PD from daily conversation could be accessible to the majority of\nthe clinical population.",
    "descriptor": "\nComments: 12 pages, 5 figures, proceedings of the Machine Learning for Health NeurIPS Workshop, PMLR 136:114-125, 2020\n",
    "authors": [
      "Hao Fang",
      "Chen Gong",
      "Chen Zhang",
      "Yanan Sui",
      "Luming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.14704"
  },
  {
    "id": "arXiv:2105.14711",
    "title": "CTSpine1K: A Large-Scale Dataset for Spinal Vertebrae Segmentation in  Computed Tomography",
    "abstract": "Spine-related diseases have high morbidity and cause a huge burden of social\ncost. Spine imaging is an essential tool for noninvasively visualizing and\nassessing spinal pathology. Segmenting vertebrae in computed tomography (CT)\nimages is the basis of quantitative medical image analysis for clinical\ndiagnosis and surgery planning of spine diseases. Current publicly available\nannotated datasets on spinal vertebrae are small in size. Due to the lack of a\nlarge-scale annotated spine image dataset, the mainstream deep learning-based\nsegmentation methods, which are data-driven, are heavily restricted. In this\npaper, we introduce a large-scale spine CT dataset, called CTSpine1K, curated\nfrom multiple sources for vertebra segmentation, which contains 1,005 CT\nvolumes with over 11,100 labeled vertebrae belonging to different spinal\nconditions. Based on this dataset, we conduct several spinal vertebrae\nsegmentation experiments to set the first benchmark. We believe that this\nlarge-scale dataset will facilitate further research in many spine-related\nimage analysis tasks, including but not limited to vertebrae segmentation,\nlabeling, 3D spine reconstruction from biplanar radiographs, image\nsuper-resolution, and enhancement.",
    "descriptor": "",
    "authors": [
      "Yang Deng",
      "Ce Wang",
      "Yuan Hui",
      "Qian Li",
      "Jun Li",
      "Shiwei Luo",
      "Mengke Sun",
      "Quan Quan",
      "Shuxin Yang",
      "You Hao",
      "Pengbo Liu",
      "Honghu Xiao",
      "Chunpeng Zhao",
      "Xinbao Wu",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14711"
  },
  {
    "id": "arXiv:2105.14732",
    "title": "Hierarchical Deep Network with Uncertainty-aware Semi-supervised  Learning for Vessel Segmentation",
    "abstract": "The analysis of organ vessels is essential for computer-aided diagnosis and\nsurgical planning. But it is not a easy task since the fine-detailed connected\nregions of organ vessel bring a lot of ambiguity in vessel segmentation and\nsub-type recognition, especially for the low-contrast capillary regions.\nFurthermore, recent two-staged approaches would accumulate and even amplify\nthese inaccuracies from the first-stage whole vessel segmentation into the\nsecond-stage sub-type vessel pixel-wise classification. Moreover, the scarcity\nof manual annotation in organ vessels poses another challenge. In this paper,\nto address the above issues, we propose a hierarchical deep network where an\nattention mechanism localizes the low-contrast capillary regions guided by the\nwhole vessels, and enhance the spatial activation in those areas for the\nsub-type vessels. In addition, we propose an uncertainty-aware semi-supervised\ntraining framework to alleviate the annotation-hungry limitation of deep\nmodels. The proposed method achieves the state-of-the-art performance in the\nbenchmarks of both retinal artery/vein segmentation in fundus images and liver\nportal/hepatic vessel segmentation in CT images.",
    "descriptor": "",
    "authors": [
      "Chenxin Li",
      "Wenao Ma",
      "Liyan Sun",
      "Xinghao Ding",
      "Yue Huang",
      "Guisheng Wang",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14732"
  },
  {
    "id": "arXiv:2105.14736",
    "title": "Recovering the Potential in One-Dimensional Time-Fractional Diffusion  with Unknown Initial Condition and Source",
    "abstract": "This paper is concerned with an inverse problem of recovering a potential\nterm in a one-dimensional subdiffusion problem, which involves a\nDjrbashian-Caputo fractional derivative of order $\\alpha\\in(0,1)$ in time, from\nthe lateral Cauchy data. In the model, we do not assume a full knowledge of the\ninitial data and the source term, since they might be unavailable in some\npractical applications. We prove the unique recovery of the spatially-dependent\npotential coefficient and the order $\\alpha$ of the derivation simultaneously\nfrom the measured trace data at one end point, when the model is equipped with\na boundary excitation with compact supports away from $t=0$. One of the initial\ndata and the source can also be uniquely determined, provided that the other is\nknown. The analysis employs a representation of the solution and the time\nanalyticity of the associated function. Further, we discuss a two-stage\nprocedure, directly inspired by the analysis, for the numerical identification\nof the order and potential coefficient, and illustrate the feasibility of the\nrecovery with several numerical experiments.",
    "descriptor": "\nComments: 23 pages, 3 figures, 3 tables\n",
    "authors": [
      "Bangti Jin",
      "Zhi Zhou"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14736"
  },
  {
    "id": "arXiv:2105.14742",
    "title": "Active Learning of Continuous-time Bayesian Networks through  Interventions",
    "abstract": "We consider the problem of learning structures and parameters of\nContinuous-time Bayesian Networks (CTBNs) from time-course data under minimal\nexperimental resources. In practice, the cost of generating experimental data\nposes a bottleneck, especially in the natural and social sciences. A popular\napproach to overcome this is Bayesian optimal experimental design (BOED).\nHowever, BOED becomes infeasible in high-dimensional settings, as it involves\nintegration over all possible experimental outcomes. We propose a novel\ncriterion for experimental design based on a variational approximation of the\nexpected information gain. We show that for CTBNs, a semi-analytical expression\nfor this criterion can be calculated for structure and parameter learning. By\ndoing so, we can replace sampling over experimental outcomes by solving the\nCTBNs master-equation, for which scalable approximations exist. This alleviates\nthe computational burden of sampling possible experimental outcomes in\nhigh-dimensions. We employ this framework in order to recommend interventional\nsequences. In this context, we extend the CTBN model to conditional CTBNs in\norder to incorporate interventions. We demonstrate the performance of our\ncriterion on synthetic and real-world data.",
    "descriptor": "\nComments: Accepted at ICML2021\n",
    "authors": [
      "Dominik Linzner",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14742"
  },
  {
    "id": "arXiv:2105.14758",
    "title": "Low-Dose CT Denoising Using a Structure-Preserving Kernel Prediction  Network",
    "abstract": "Low-dose CT has been a key diagnostic imaging modality to reduce the\npotential risk of radiation overdose to patient health. Despite recent\nadvances, CNN-based approaches typically apply filters in a spatially invariant\nway and adopt similar pixel-level losses, which treat all regions of the CT\nimage equally and can be inefficient when fine-grained structures coexist with\nnon-uniformly distributed noises. To address this issue, we propose a\nStructure-preserving Kernel Prediction Network (StructKPN) that combines the\nkernel prediction network with a structure-aware loss function that utilizes\nthe pixel gradient statistics and guides the model towards spatially-variant\nfilters that enhance noise removal, prevent over-smoothing and preserve\ndetailed structures for different regions in CT imaging. Extensive experiments\ndemonstrated that our approach achieved superior performance on both synthetic\nand non-synthetic datasets, and better preserves structures that are highly\ndesired in clinical screening and low-dose protocol optimization.",
    "descriptor": "\nComments: ICIP2021\n",
    "authors": [
      "Lu Xu",
      "Yuwei Zhang",
      "Ying Liu",
      "Daoye Wang",
      "Mu Zhou",
      "Jimmy Ren",
      "Zhaoxiang Ye"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14758"
  },
  {
    "id": "arXiv:2105.14760",
    "title": "Multi-Objective LQG Design with Primal-Dual Method",
    "abstract": "The goal of this paper is to study a multi-objective linear quadratic\nGaussian (LQG) control problem. In particular, we consider an optimal control\nproblem minimizing a quadratic cost over a finite time horizon for linear\nstochastic systems subject to control energy constraints. To solve the problem,\nwe suggest an efficient bisection line search algorithm which is\ncomputationally efficient compared to other approaches such as the semidefinite\nprogramming. The main idea is to use the Lagrangian function and\nKarush-Kuhn-Tucker (KKT) optimality conditions to solve the constrained\noptimization problem. The Lagrange multiplier is searched using the bisection\nline search. Numerical examples are given to demonstrate the effectiveness of\nthe proposed methods.",
    "descriptor": "",
    "authors": [
      "Donghwan Lee",
      "Do Wan Kim"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14760"
  },
  {
    "id": "arXiv:2105.14766",
    "title": "BaMBNet: A Blur-aware Multi-branch Network for Defocus Deblurring",
    "abstract": "The defocus deblurring raised from the finite aperture size and exposure time\nis an essential problem in the computational photography. It is very\nchallenging because the blur kernel is spatially varying and difficult to\nestimate by traditional methods. Due to its great breakthrough in low-level\ntasks, convolutional neural networks (CNNs) have been introduced to the defocus\ndeblurring problem and achieved significant progress. However, they apply the\nsame kernel for different regions of the defocus blurred images, thus it is\ndifficult to handle these nonuniform blurred images. To this end, this study\ndesigns a novel blur-aware multi-branch network (BaMBNet), in which different\nregions (with different blur amounts) should be treated differentially. In\nparticular, we estimate the blur amounts of different regions by the internal\ngeometric constraint of the DP data, which measures the defocus disparity\nbetween the left and right views. Based on the assumption that different image\nregions with different blur amounts have different deblurring difficulties, we\nleverage different networks with different capacities (\\emph{i.e.} parameters)\nto process different image regions. Moreover, we introduce a meta-learning\ndefocus mask generation algorithm to assign each pixel to a proper branch. In\nthis way, we can expect to well maintain the information of the clear regions\nwhile recovering the missing details of the blurred regions. Both quantitative\nand qualitative experiments demonstrate that our BaMBNet outperforms the\nstate-of-the-art methods. Source code will be available at\nhttps://github.com/junjun-jiang/BaMBNet.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Pengwei Liang",
      "Junjun Jiang",
      "Xianming Liu",
      "Jiayi Ma"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14766"
  },
  {
    "id": "arXiv:2105.14776",
    "title": "Fragmentation model and strewn field estimation for meteoroids entry",
    "abstract": "Everyday thousands of meteoroids enter the Earth's atmosphere. The vast\nmajority burn up harmlessly during the descent, but the larger objects survive,\noccasionally experiencing intense fragmentation events, and reach the ground.\nThese events can pose a threat for a village or a small city; therefore, models\nof asteroid fragmentation, along with accurate post-breakup trajectory and\nstrewn field estimation, are needed to enable a reliable risk assessment. In\nthis work, a methodology to describe meteoroids entry, fragmentation, descent,\nand strewn field is presented by means of a continuum approach. At breakup, a\nmodified version of the NASA Standard Breakup Model is used to generate the\ndistribution of the fragments in terms of their area-to-mass ratio and ejection\nvelocity. This distribution, combined with the meteoroid state, is directly\npropagated using the continuity equation coupled with the non-linear entry\ndynamics. At each time step, the probability density evolution of the fragments\nis reconstructed using GMM interpolation. Using this information is then\npossible to estimate the meteoroid's ground impact probability. This approach\ndeparts from the current state-of-the-art models: it has the flexibility to\ninclude large fragmentation events while maintaining a continuum formulation\nfor a better physical representation of the phenomenon. The methodology is also\ncharacterised by a modular structure, so that updated asteroids fragmentation\nmodels can be readily integrated into the framework, allowing a continuously\nimproving prediction of re-entry and fragmentation events. The propagation of\nthe fragments' density and its reconstruction, currently considering only one\nfragmentation point, is first compared against Monte Carlo simulations, and\nthen against real observations. Both deceleration due to atmospheric drag and\nablation due to aerothermodynamics effects have been considered.",
    "descriptor": "\nComments: 29 pages, 26 figures, published in Icarus\n",
    "authors": [
      "Simone Limonta",
      "Mirko Trisolini",
      "Stefan Frey",
      "Camilla Colombo"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14776"
  },
  {
    "id": "arXiv:2105.14826",
    "title": "Speaker Identification from Raw Waveform with LineNet",
    "abstract": "Speaker Identification using i-vector has gradually been replaced by speaker\nIdentification using deep learning. Speaker Identification based on\nConvolutional Neural Networks (CNNs) has been widely used in recent years,\nwhich learn low-level speech representations from raw waveforms. On this basis,\na CNN architecture called SincNet proposes a kind of unique convolutional\nlayer, which has achieved band-pass filters. Compared with standard CNNs,\nSincNet learns the low and high cutoff frequencies of each filter.This paper\nproposes an improved CNNs architecture called LineNet, which encourages the\nfirst convolutional layer to implement more specific filters than SincNet.\nLineNet parameterizes the frequency domain shape and can realize band-pass\nfilters by learning some deformation points in frequency domain. Compared with\nstandard CNN, LineNet can learn the characteristics of each filter. Compared\nwith SincNet, LineNet can learn more characteristic parameters, instead of only\nlow and high cutoff frequencies. This provides a personalized filter bank for\ndifferent tasks. As a result, our experiments show that the LineNet converges\nfaster than standard CNN and performs better than SincNet.",
    "descriptor": "",
    "authors": [
      "Wencheng Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.14826"
  },
  {
    "id": "arXiv:2105.14848",
    "title": "Refined Deep Neural Network and U-Net for Polyps Segmentation",
    "abstract": "The Medico: Multimedia Task 2020 focuses on developing an efficient and\naccurate computer-aided diagnosis system for automatic segmentation [3]. We\nparticipate in task 1, Polyps segmentation task, which is to develop algorithms\nfor segmenting polyps on a comprehensive dataset. In this task, we propose\nmethods combining Residual module, Inception module, Adaptive Convolutional\nneural network with U-Net model, and PraNet for semantic segmentation of\nvarious types of polyps in endoscopic images. We select 5 runs with different\narchitecture and parameters in our methods. Our methods show potential results\nin accuracy and efficiency through multiple experiments, and our team is in the\nTop 3 best results with a Jaccard index of 0.765.",
    "descriptor": "",
    "authors": [
      "Quoc-Huy Trinh",
      "Minh-Van Nguyen",
      "Thiet-Gia Huynh",
      "Minh-Triet Tran"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14848"
  },
  {
    "id": "arXiv:2105.14866",
    "title": "Variational Autoencoders: A Harmonic Perspective",
    "abstract": "In this work we study Variational Autoencoders (VAEs) from the perspective of\nharmonic analysis. By viewing a VAE's latent space as a Gaussian Space, a\nvariety of measure space, we derive a series of results that show that the\nencoder variance of a VAE controls the frequency content of the functions\nparameterised by the VAE encoder and decoder neural networks. In particular we\ndemonstrate that larger encoder variances reduce the high frequency content of\nthese functions. Our analysis allows us to show that increasing this variance\neffectively induces a soft Lipschitz constraint on the decoder network of a\nVAE, which is a core contributor to the adversarial robustness of VAEs. We\nfurther demonstrate that adding Gaussian noise to the input of a VAE allows us\nto more finely control the frequency content and the Lipschitz constant of the\nVAE encoder networks. To support our theoretical analysis we run experiments\nwith VAEs with small fully-connected neural networks and with larger\nconvolutional networks, demonstrating empirically that our theory holds for a\nvariety of neural network architectures.",
    "descriptor": "\nComments: 18 pages including Appendix, 7 Figures\n",
    "authors": [
      "Alexander Camuto",
      "Matthew Willetts"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14866"
  },
  {
    "id": "arXiv:2105.14927",
    "title": "First Full-Event Reconstruction from Imaging Atmospheric Cherenkov  Telescope Real Data with Deep Learning",
    "abstract": "The Cherenkov Telescope Array is the future of ground-based gamma-ray\nastronomy. Its first prototype telescope built on-site, the Large Size\nTelescope 1, is currently under commissioning and taking its first scientific\ndata. In this paper, we present for the first time the development of a\nfull-event reconstruction based on deep convolutional neural networks and its\napplication to real data. We show that it outperforms the standard analysis,\nboth on simulated and on real data, thus validating the deep approach for the\nCTA data analysis. This work also illustrates the difficulty of moving from\nsimulated data to actual data.",
    "descriptor": "",
    "authors": [
      "Mika\u00ebl Jacquemont",
      "Thomas Vuillaume",
      "Alexandre Benoit",
      "Gilles Maurin",
      "Patrick Lambert",
      "Giovanni Lamanna"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14927"
  },
  {
    "id": "arXiv:2105.14933",
    "title": "The use of Generative Adversarial Networks to characterise new physics  in multi-lepton final states at the LHC",
    "abstract": "Semi-supervision in Machine Learning can be used in searches for new physics\nwhere the signal plus background regions are not labelled. This strongly\nreduces model dependency in the search for signals Beyond the Standard Model.\nThis approach displays the drawback in that over-fitting can give rise to fake\nsignals. Tossing toy Monte Carlo (MC) events can be used to estimate the\ncorresponding trials factor through a frequentist inference. However, MC events\nthat are based on full detector simulations are resource intensive. Generative\nAdversarial Networks (GANs) can be used to mimic MC generators. GANs are\npowerful generative models, but often suffer from training instability. We\nhenceforth show a review of GANs. We advocate the use of Wasserstein GAN (WGAN)\nwith weight clipping and WGAN with gradient penalty (WGAN-GP) where the norm of\ngradient of the critic is penalized with respect to its input. Following the\nemergence of multi-lepton anomalies at the LHC, we apply GANs for the\ngeneration of di-leptons final states in association with b-quarks at the LHC.\nA good agreement between the MC events and the WGAN-GP events is found for the\nobservables selected in the study.",
    "descriptor": "\nComments: 18 pages, 5 figures, 1 table, journal (JHEP)\n",
    "authors": [
      "Thabang Lebese",
      "Bruce Mellado",
      "Xifeng Ruan"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2105.14933"
  },
  {
    "id": "arXiv:2105.14951",
    "title": "SNIPS: Solving Noisy Inverse Problems Stochastically",
    "abstract": "In this work we introduce a novel stochastic algorithm dubbed SNIPS, which\ndraws samples from the posterior distribution of any linear inverse problem,\nwhere the observation is assumed to be contaminated by additive white Gaussian\nnoise. Our solution incorporates ideas from Langevin dynamics and Newton's\nmethod, and exploits a pre-trained minimum mean squared error (MMSE) Gaussian\ndenoiser. The proposed approach relies on an intricate derivation of the\nposterior score function that includes a singular value decomposition (SVD) of\nthe degradation operator, in order to obtain a tractable iterative algorithm\nfor the desired sampling. Due to its stochasticity, the algorithm can produce\nmultiple high perceptual quality samples for the same noisy observation. We\ndemonstrate the abilities of the proposed paradigm for image deblurring,\nsuper-resolution, and compressive sensing. We show that the samples produced\nare sharp, detailed and consistent with the given measurements, and their\ndiversity exposes the inherent uncertainty in the inverse problem being solved.",
    "descriptor": "",
    "authors": [
      "Bahjat Kawar",
      "Gregory Vaksman",
      "Michael Elad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14951"
  },
  {
    "id": "arXiv:2105.14961",
    "title": "Exact solution of network flow models with strong relaxations",
    "abstract": "We address the solution of Mixed Integer Linear Programming (MILP) models\nwith strong relaxations that are derived from Dantzig-Wolfe decompositions and\nallow a pseudo-polynomial pricing algorithm. We exploit their network-flow\ncharacterization and provide a framework based on column generation,\nreduced-cost variable-fixing, and a highly asymmetric branching scheme that\nallows us to take advantage of the potential of the current MILP solvers. We\napply our framework to a variety of cutting and packing problems from the\nliterature. The efficiency of the framework is proved by extensive\ncomputational experiments, in which a significant number of open instances\ncould be solved to proven optimality for the first time.",
    "descriptor": "",
    "authors": [
      "Vin\u00edcius L. de Lima",
      "Manuel Iori",
      "Fl\u00e1vio K. Miyazawa"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.14961"
  },
  {
    "id": "arXiv:2105.14962",
    "title": "Boosting the Performance of Video Compression Artifact Reduction with  Reference Frame Proposals and Frequency Domain Information",
    "abstract": "Many deep learning based video compression artifact removal algorithms have\nbeen proposed to recover high-quality videos from low-quality compressed\nvideos. Recently, methods were proposed to mine spatiotemporal information via\nutilizing multiple neighboring frames as reference frames. However, these\npost-processing methods take advantage of adjacent frames directly, but neglect\nthe information of the video itself, which can be exploited. In this paper, we\npropose an effective reference frame proposal strategy to boost the performance\nof the existing multi-frame approaches. Besides, we introduce a loss based on\nfast Fourier transformation~(FFT) to further improve the effectiveness of\nrestoration. Experimental results show that our method achieves better fidelity\nand perceptual performance on MFQE 2.0 dataset than the state-of-the-art\nmethods. And our method won Track 1 and Track 2, and was ranked the 2nd in\nTrack 3 of NTIRE 2021 Quality enhancement of heavily compressed videos\nChallenge.",
    "descriptor": "\nComments: CPVR Workshop, NTIRE 2021\n",
    "authors": [
      "Yi Xu",
      "Minyi Zhao",
      "Jing Liu",
      "Xinjian Zhang",
      "Longwen Gao",
      "Shuigeng Zhou",
      "Huyang Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14962"
  },
  {
    "id": "arXiv:2105.14986",
    "title": "Feasibility Assessment of Multitasking in MRI Neuroimaging Analysis:  Tissue Segmentation, Cross-Modality Conversion and Bias correction",
    "abstract": "Neuroimaging is essential in brain studies for the diagnosis and\nidentification of disease, structure, and function of the brain in its healthy\nand disease states. Literature shows that there are advantages of multitasking\nwith some deep learning (DL) schemes in challenging neuroimaging applications.\nThis study examines the feasibility of using multitasking in three different\napplications, including tissue segmentation, cross-modality conversion, and\nbias-field correction. These applications reflect five different scenarios in\nwhich multitasking is explored and 280 training and testing sessions conducted\nfor empirical evaluations. Two well-known networks, U-Net as a well-known\nconvolutional neural network architecture, and a closed architecture based on\nthe conditional generative adversarial network are implemented. Different\nmetrics such as the normalized cross-correlation coefficient and Dice scores\nare used for comparison of methods and results of the different experiments.\nStatistical analysis is also provided by paired t-test. The present study\nexplores the pros and cons of these methods and their practical impacts on\nmultitasking in different implementation scenarios. This investigation shows\nthat bias correction and cross-modality conversion applications are\nsignificantly easier than the segmentation application, and having multitasking\nwith segmentation is not reasonable if one of them is identified as the main\ntarget application. However, when the main application is the segmentation of\ntissues, multitasking with cross-modality conversion is beneficial, especially\nfor the U-net architecture.",
    "descriptor": "",
    "authors": [
      "Mohammad Eslami",
      "Solale Tabarestani",
      "Malek Adjouadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.14986"
  },
  {
    "id": "arXiv:2105.14988",
    "title": "Asymmetric All-or-nothing Transforms",
    "abstract": "In this paper, we initiate a study of asymmetric all-or-nothing transforms\n(or asymmetric AONTs). A (symmetric) $t$-all-or-nothing transform is a\nbijective mapping defined on the set of $s$-tuples over a specified finite\nalphabet. It is required that knowledge of all but $t$ outputs leaves any $t$\ninputs completely undetermined. There have been numerous papers developing the\ntheory of AONTs as well as presenting various applications of AONTs in\ncryptography and information security.\nIn this paper, we replace the parameter $t$ by two parameters $t_o$ and\n$t_i$, where $t_i \\leq t_o$. The requirement is that knowledge of all but $t_o$\noutputs leaves any $t_i$ inputs completely undetermined. When $t_i < t_o$, we\nrefer to the AONT as asymmetric.\nWe give several constructions and bounds for various classes of asymmetric\nAONTs, especially those with $t_i = 1$ or $t_i = 2$. We pay particular\nattention to linear transforms, where the alphabet is a finite field\n$\\mathbb{F}_q$ and the mapping is linear.",
    "descriptor": "",
    "authors": [
      "Navid Nasr Esfahani",
      "Douglas R. Stinson"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14988"
  },
  {
    "id": "arXiv:2105.14989",
    "title": "Representation Learning Beyond Linear Prediction Functions",
    "abstract": "Recent papers on the theory of representation learning has shown the\nimportance of a quantity called diversity when generalizing from a set of\nsource tasks to a target task. Most of these papers assume that the function\nmapping shared representations to predictions is linear, for both source and\ntarget tasks. In practice, researchers in deep learning use different numbers\nof extra layers following the pretrained model based on the difficulty of the\nnew task. This motivates us to ask whether diversity can be achieved when\nsource tasks and the target task use different prediction function spaces\nbeyond linear functions. We show that diversity holds even if the target task\nuses a neural network with multiple layers, as long as source tasks use linear\nfunctions. If source tasks use nonlinear prediction functions, we provide a\nnegative result by showing that depth-1 neural networks with ReLu activation\nfunction need exponentially many source tasks to achieve diversity. For a\ngeneral function class, we find that eluder dimension gives a lower bound on\nthe number of tasks required for diversity. Our theoretical results imply that\nsimpler tasks generalize better. Though our theoretical results are shown for\nthe global minimizer of empirical risks, their qualitative predictions still\nhold true for gradient-based optimization algorithms as verified by our\nsimulations on deep neural networks.",
    "descriptor": "\nComments: 1 Figure\n",
    "authors": [
      "Ziping Xu",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14989"
  },
  {
    "id": "arXiv:2105.15004",
    "title": "Generalization Error Rates in Kernel Regression: The Crossover from the  Noiseless to Noisy Regime",
    "abstract": "In this manuscript we consider Kernel Ridge Regression (KRR) under the\nGaussian design. Exponents for the decay of the excess generalization error of\nKRR have been reported in various works under the assumption of power-law decay\nof eigenvalues of the features co-variance. These decays were, however,\nprovided for sizeably different setups, namely in the noiseless case with\nconstant regularization and in the noisy optimally regularized case.\nIntermediary settings have been left substantially uncharted. In this work, we\nunify and extend this line of work, providing characterization of all regimes\nand excess error decay rates that can be observed in terms of the interplay of\nnoise and regularization. In particular, we show the existence of a transition\nin the noisy setting between the noiseless exponents to its noisy values as the\nsample complexity is increased. Finally, we illustrate how this crossover can\nalso be observed on real data sets.",
    "descriptor": "\nComments: 22 pages, 10 figures, 2 tables\n",
    "authors": [
      "Hugo Cui",
      "Bruno Loureiro",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15004"
  },
  {
    "id": "arXiv:2105.15005",
    "title": "Rapid mixing of Glauber dynamics via spectral independence for all  degrees",
    "abstract": "We prove an optimal $\\Omega(n^{-1})$ lower bound on the spectral gap of\nGlauber dynamics for anti-ferromagnetic two-spin systems with $n$ vertices in\nthe tree uniqueness regime. This spectral gap holds for all, including\nunbounded, maximum degree $\\Delta$. Consequently, we have the following mixing\ntime bounds for the models satisfying the uniqueness condition with a slack\n$\\delta\\in(0,1)$:\n$\\bullet$ $C(\\delta) n^2\\log n$ mixing time for the hardcore model with\nfugacity $\\lambda\\le (1-\\delta)\\lambda_c(\\Delta)= (1-\\delta)\\frac{(\\Delta -\n1)^{\\Delta - 1}}{(\\Delta - 2)^\\Delta}$;\n$\\bullet$ $C(\\delta) n^2$ mixing time for the Ising model with edge activity\n$\\beta\\in\\left[\\frac{\\Delta-2+\\delta}{\\Delta-\\delta},\\frac{\\Delta-\\delta}{\\Delta-2+\\delta}\\right]$;\nwhere the maximum degree $\\Delta$ may depend on the number of vertices $n$,\nand $C(\\delta)$ depends only on $\\delta$.\nOur proof is built upon the recently developed connections between the\nGlauber dynamics for spin systems and the high-dimensional expander walks. In\nparticular, we prove a stronger notion of spectral independence, called the\ncomplete spectral independence, and use a novel Markov chain called the field\ndynamics to connect this stronger spectral independence to the rapid mixing of\nGlauber dynamics for all degrees.",
    "descriptor": "",
    "authors": [
      "Xiaoyu Chen",
      "Weiming Feng",
      "Yitong Yin",
      "Xinyuan Zhang"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.15005"
  },
  {
    "id": "arXiv:2105.15034",
    "title": "A remark on a paper of Krotov and Hopfield [arXiv:2008.06996]",
    "abstract": "In their recent paper titled \"Large Associative Memory Problem in\nNeurobiology and Machine Learning\" [arXiv:2008.06996] the authors gave a\nbiologically plausible microscopic theory from which one can recover many dense\nassociative memory models discussed in the literature. We show that the layers\nof the recent \"MLP-mixer\" [arXiv:2105.01601] as well as the essentially\nequivalent model in [arXiv:2105.02723] are amongst them.",
    "descriptor": "\nComments: 1 page, 8 formulae\n",
    "authors": [
      "Fei Tang",
      "Michael Kopp"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15034"
  },
  {
    "id": "arXiv:2105.15037",
    "title": "A Novel Automatic Modulation Classification Scheme Based on Multi-Scale  Networks",
    "abstract": "Automatic modulation classification enables intelligent communications and it\nis of crucial importance in today's and future wireless communication networks.\nAlthough many automatic modulation classification schemes have been proposed,\nthey cannot tackle the intra-class diversity problem caused by the dynamic\nchanges of the wireless communication environment. In order to overcome this\nproblem, inspired by face recognition, a novel automatic modulation\nclassification scheme is proposed by using the multi-scale network in this\npaper. Moreover, a novel loss function that combines the center loss and the\ncross entropy loss is exploited to learn both discriminative and separable\nfeatures in order to further improve the classification performance. Extensive\nsimulation results demonstrate that our proposed automatic modulation\nclassification scheme can achieve better performance than the benchmark schemes\nin terms of the classification accuracy. The influence of the network\nparameters and the loss function with the two-stage training strategy on the\nclassification accuracy of our proposed scheme are investigated.",
    "descriptor": "",
    "authors": [
      "Hao Zhang",
      "Fuhui Zhou",
      "Qihui Wu",
      "Wei Wu",
      "Rose Qingyang Hu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.15037"
  },
  {
    "id": "arXiv:2105.15056",
    "title": "Boundary Output Feedback Stabilization of State Delayed  Reaction-Diffusion PDEs",
    "abstract": "This paper studies the boundary output feedback stabilization of general 1-D\nreaction-diffusion PDEs in the presence of a state delay in the reaction term.\nThe control input applies through a Robin boundary condition while the system\noutput is selected as a either Dirichlet or Neumann boundary trace. The control\nstrategy takes the form of a finite-dimensional observer-based controller with\nfeedback and observer gains that are computed in order to dominate the state\ndelayed term. For any arbitrarily given value of the state delay, we show the\nexponential stability of the resulting closed-loop system provided the order of\nthe observer is selected large enough.",
    "descriptor": "",
    "authors": [
      "Hugo Lhachemi",
      "Robert Shorten"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.15056"
  },
  {
    "id": "arXiv:2105.15081",
    "title": "Optimal Spectral Recovery of a Planted Vector in a Subspace",
    "abstract": "Recovering a planted vector $v$ in an $n$-dimensional random subspace of\n$\\mathbb{R}^N$ is a generic task related to many problems in machine learning\nand statistics, such as dictionary learning, subspace recovery, and principal\ncomponent analysis. In this work, we study computationally efficient estimation\nand detection of a planted vector $v$ whose $\\ell_4$ norm differs from that of\na Gaussian vector with the same $\\ell_2$ norm. For instance, in the special\ncase of an $N \\rho$-sparse vector $v$ with Rademacher nonzero entries, our\nresults include the following:\n(1) We give an improved analysis of (a slight variant of) the spectral method\nproposed by Hopkins, Schramm, Shi, and Steurer, showing that it approximately\nrecovers $v$ with high probability in the regime $n \\rho \\ll \\sqrt{N}$. In\ncontrast, previous work required either $\\rho \\ll 1/\\sqrt{n}$ or $n \\sqrt{\\rho}\n\\lesssim \\sqrt{N}$ for polynomial-time recovery. Our result subsumes both of\nthese conditions (up to logarithmic factors) and also treats the dense case\n$\\rho = 1$ which was not previously considered.\n(2) Akin to $\\ell_\\infty$ bounds for eigenvector perturbation, we establish\nan entrywise error bound for the spectral estimator via a leave-one-out\nanalysis, from which it follows that thresholding recovers $v$ exactly.\n(3) We study the associated detection problem and show that in the regime $n\n\\rho \\gg \\sqrt{N}$, any spectral method from a large class (and more generally,\nany low-degree polynomial of the input) fails to detect the planted vector.\nThis establishes optimality of our upper bounds and offers evidence that no\npolynomial-time algorithm can succeed when $n \\rho \\gg \\sqrt{N}$.",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Cheng Mao",
      "Alexander S. Wein"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.15081"
  },
  {
    "id": "arXiv:2105.15108",
    "title": "Prediction of soft proton intensities in the near-Earth space using  machine learning",
    "abstract": "The spatial distribution of energetic protons contributes towards the\nunderstanding of magnetospheric dynamics. Based upon 17 years of the\nCluster/RAPID observations, we have derived machine learning-based models to\npredict the proton intensities at energies from 28 to 1,885 keV in the 3D\nterrestrial magnetosphere at radial distances between 6 and 22 RE. We used the\nsatellite location and indices for solar, solar wind and geomagnetic activity\nas predictors. The results demonstrate that the neural network (multi-layer\nperceptron regressor) outperforms baseline models based on the k-Nearest\nNeighbors and historical binning on average by ~80% and ~33\\%, respectively.\nThe average correlation between the observed and predicted data is about 56%,\nwhich is reasonable in light of the complex dynamics of fast-moving energetic\nprotons in the magnetosphere. In addition to a quantitative analysis of the\nprediction results, we also investigate parameter importance in our model. The\nmost decisive parameters for predicting proton intensities are related to the\nlocation: ZGSE direction and the radial distance. Among the activity indices,\nthe solar wind dynamic pressure is the most important. The results have a\ndirect practical application, for instance, for assessing the contamination\nparticle background in the X-Ray telescopes for X-ray astronomy orbiting above\nthe radiation belts. To foster reproducible research and to enable the\ncommunity to build upon our work we publish our complete code, the data, as\nwell as weights of trained models. Further description can be found in the\nGitHub project at https://github.com/Tanveer81/deep_horizon.",
    "descriptor": "",
    "authors": [
      "Elena A. Kronberg",
      "Tanveer Hannan",
      "Jens Huthmacher",
      "Marcus M\u00fcnzer",
      "Florian Peste",
      "Ziyang Zhou",
      "Max Berrendorf",
      "Evgeniy Faerman",
      "Fabio Gastaldello",
      "Simona Ghizzardi",
      "Philippe Escoubet",
      "Stein Haaland",
      "Artem Smirnov",
      "Nithin Sivadas",
      "Robert C. Allen",
      "Andrea Tiengo",
      "Raluca Ilie"
    ],
    "subjectives": [
      "Space Physics (physics.space-ph)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15108"
  },
  {
    "id": "arXiv:2105.15119",
    "title": "Policies for the Dynamic Traveling Maintainer Problem with Alerts",
    "abstract": "Companies require modern capital assets such as wind turbines, trains and\nhospital equipment to experience minimal downtime. Ideally, assets are\nmaintained right before failure to ensure maximum availability at minimum\nmaintenance costs. To this end, two challenges arise: failure times of assets\nare unknown a priori and assets can be part of a larger asset network.\nNowadays, it is common for assets to be equipped with real-time monitoring that\nemits alerts, typically triggered by the first signs of degradation. Thus, it\nbecomes crucial to plan maintenance considering information received via\nalerts, asset locations and maintenance costs. This problem is referred to as\nthe Dynamic Traveling Maintainer Problem with Alerts (DTMPA). We propose a\nmodeling framework for the DTMPA, where the alerts are early and imperfect\nindicators of failures. The objective is to minimize discounted maintenance\ncosts accrued over an infinite time horizon. We propose three methods to solve\nthis problem, leveraging different information levels from the alert signals.\nThe proposed methods comprise various greedy heuristics that rank assets based\non proximity, urgency and economic risk; a Traveling Maintainer Heuristic\nemploying combinatorial optimization to optimize near-future costs; a Deep\nReinforcement Learning (DRL) method trained to minimize the long-term costs\nusing exclusively the history of alerts. In a simulated environment, all\nmethods can approximate optimal policies with access to perfect condition\ninformation for small asset networks. For larger networks, where computing the\noptimal policy is intractable, the proposed methods yield competitive\nmaintenance policies, with DRL consistently achieving the lowest costs.",
    "descriptor": "",
    "authors": [
      "Paulo da Costa",
      "Peter Verleijsdonk",
      "Simon Voorberg",
      "Alp Akcay",
      "Stella Kapodistria",
      "Willem van Jaarsveld",
      "Yingqian Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15119"
  },
  {
    "id": "arXiv:2105.15145",
    "title": "A polynomial composites and monoid domains as algebraic structures and  their applications",
    "abstract": "This paper contains the results collected so far on polynomial composites in\nterms of many basic algebraic properties. Since it is a polynomial structure,\nresults for monoid domains come in here and there. The second part of the paper\ncontains the results of the relationship between the theory of polynomial\ncomposites, the Galois theory and the theory of nilpotents. The third part of\nthis paper shows us some cryptosystems. We find generalizations of known\nciphers taking into account the infinite alphabet and using simple algebraic\nmethods. We also find two cryptosystems in which the structure of Dedekind\nrings resides, namely certain elements are equivalent to fractional ideals.\nFinally, we find the use of polynomial composites and monoid domains in\ncryptology.",
    "descriptor": "\nComments: 22 pages. arXiv admin note: substantial text overlap with arXiv:2006.14948\n",
    "authors": [
      "Magdalena Jankowska",
      "Lukasz Matysiak"
    ],
    "subjectives": [
      "Commutative Algebra (math.AC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.15145"
  },
  {
    "id": "arXiv:2105.15162",
    "title": "Automatic audiovisual synchronisation for ultrasound tongue imaging",
    "abstract": "Ultrasound tongue imaging is used to visualise the intra-oral articulators\nduring speech production. It is utilised in a range of applications, including\nspeech and language therapy and phonetics research. Ultrasound and speech audio\nare recorded simultaneously, and in order to correctly use this data, the two\nmodalities should be correctly synchronised. Synchronisation is achieved using\nspecialised hardware at recording time, but this approach can fail in practice\nresulting in data of limited usability. In this paper, we address the problem\nof automatically synchronising ultrasound and audio after data collection. We\nfirst investigate the tolerance of expert ultrasound users to synchronisation\nerrors in order to find the thresholds for error detection. We use these\nthresholds to define accuracy scoring boundaries for evaluating our system. We\nthen describe our approach for automatic synchronisation, which is driven by a\nself-supervised neural network, exploiting the correlation between the two\nsignals to synchronise them. We train our model on data from multiple domains\nwith different speaker characteristics, different equipment, and different\nrecording environments, and achieve an accuracy >92.4% on held-out in-domain\ndata. Finally, we introduce a novel resource, the Cleft dataset, which we\ngathered with a new clinical subgroup and for which hardware synchronisation\nproved unreliable. We apply our model to this out-of-domain data, and evaluate\nits performance subjectively with expert users. Results show that users prefer\nour model's output over the original hardware output 79.3% of the time. Our\nresults demonstrate the strength of our approach and its ability to generalise\nto data from new domains.",
    "descriptor": "\nComments: 18 pages, 10 figures. Manuscript accepted at Speech Communication\n",
    "authors": [
      "Aciel Eshky",
      "Joanne Cleland",
      "Manuel Sam Ribeiro",
      "Eleanor Sugden",
      "Korin Richmond",
      "Steve Renals"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.15162"
  },
  {
    "id": "arXiv:2105.15172",
    "title": "Assessing disinformation through the dynamics of supply and demand in  the news ecosystem",
    "abstract": "Social dialogue, the foundation of our democracies, is currently threatened\nby disinformation and partisanship, with their disrupting role on individual\nand collective awareness and detrimental effects on decision-making processes.\nDespite a great deal of attention to the news sphere itself, little is known\nabout the subtle interplay between the offer and the demand for information.\nStill, a broader perspective on the news ecosystem, including both the\nproducers and the consumers of information, is needed to build new tools to\nassess the health of the infosphere. Here, we combine in the same framework\nnews supply, as mirrored by a fairly complete Italian news database - partially\nannotated for fake news, and news demand, as captured through the Google Trends\ndata for Italy. Our investigation focuses on the temporal and semantic\ninterplay of news, fake news, and searches in several domains, including the\nvirus SARS-CoV-2 pandemic. Two main results emerge. First, disinformation is\nextremely reactive to people's interests and tends to thrive, especially when\nthere is a mismatch between what people are interested in and what news outlets\nprovide. Second, a suitably defined index can assess the level of\ndisinformation only based on the available volumes of news and searches.\nAlthough our results mainly concern the Coronavirus subject, we provide hints\nthat the same findings can have more general applications. We contend these\nresults can be a powerful asset in informing campaigns against disinformation\nand providing news outlets and institutions with potentially relevant\nstrategies.",
    "descriptor": "",
    "authors": [
      "Pietro Gravino",
      "Giulio Prevedello",
      "Martina Galletti",
      "Vittorio Loreto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2105.15172"
  },
  {
    "id": "arXiv:2105.15186",
    "title": "Fast Policy Extragradient Methods for Competitive Games with Entropy  Regularization",
    "abstract": "This paper investigates the problem of computing the equilibrium of\ncompetitive games, which is often modeled as a constrained saddle-point\noptimization problem with probability simplex constraints. Despite recent\nefforts in understanding the last-iterate convergence of extragradient methods\nin the unconstrained setting, the theoretical underpinnings of these methods in\nthe constrained settings, especially those using multiplicative updates, remain\nhighly inadequate, even when the objective function is bilinear. Motivated by\nthe algorithmic role of entropy regularization in single-agent reinforcement\nlearning and game theory, we develop provably efficient extragradient methods\nto find the quantal response equilibrium (QRE) -- which are solutions to\nzero-sum two-player matrix games with entropy regularization -- at a linear\nrate. The proposed algorithms can be implemented in a decentralized manner,\nwhere each player executes symmetric and multiplicative updates iteratively\nusing its own payoff without observing the opponent's actions directly. In\naddition, by controlling the knob of entropy regularization, the proposed\nalgorithms can locate an approximate Nash equilibrium of the unregularized\nmatrix game at a sublinear rate without assuming the Nash equilibrium to be\nunique. Our methods also lead to efficient policy extragradient algorithms for\nsolving entropy-regularized zero-sum Markov games at a linear rate. All of our\nconvergence rates are nearly dimension-free, which are independent of the size\nof the state and action spaces up to logarithm factors, highlighting the\npositive role of entropy regularization for accelerating convergence.",
    "descriptor": "",
    "authors": [
      "Shicong Cen",
      "Yuting Wei",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15186"
  },
  {
    "id": "arXiv:2105.15197",
    "title": "A Simple and General Debiased Machine Learning Theorem with Finite  Sample Guarantees",
    "abstract": "Debiased machine learning is a meta algorithm based on bias correction and\nsample splitting to calculate confidence intervals for functionals (i.e. scalar\nsummaries) of machine learning algorithms. For example, an analyst may desire\nthe confidence interval for a treatment effect estimated with a neural network.\nWe provide a nonasymptotic debiased machine learning theorem that encompasses\nany global or local functional of any machine learning algorithm that satisfies\na few simple, interpretable conditions. Formally, we prove consistency,\nGaussian approximation, and semiparametric efficiency by finite sample\narguments. The rate of convergence is root-n for global functionals, and it\ndegrades gracefully for local functionals. Our results culminate in a simple\nset of conditions that an analyst can use to translate modern learning theory\nrates into traditional statistical inference. The conditions reveal a new\ndouble robustness property for ill posed inverse problems.",
    "descriptor": "\nComments: 25 pages. arXiv admin note: text overlap with arXiv:2102.11076\n",
    "authors": [
      "Victor Chernozhukov",
      "Whitney K. Newey",
      "Rahul Singh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.15197"
  },
  {
    "id": "arXiv:1709.04673",
    "title": "Analyzing Approximate Value Iteration Algorithms",
    "abstract": "Analyzing Approximate Value Iteration Algorithms",
    "descriptor": "",
    "authors": [
      "Arunselvan Ramaswamy",
      "Shalabh Bhatnagar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1709.04673"
  },
  {
    "id": "arXiv:1809.06172",
    "title": "Investigating Crowd Creativity in Online Music Communities",
    "abstract": "Comments: Proceedings of the ACM on Human-Computer Interaction, Vol. 2, No. CSCW, Article 27, Publication date: November 2018",
    "descriptor": "\nComments: Proceedings of the ACM on Human-Computer Interaction, Vol. 2, No. CSCW, Article 27, Publication date: November 2018\n",
    "authors": [
      "Fabio Calefato",
      "Giuseppe Iaffaldano",
      "Filippo Lanubile",
      "Federico Maiorano"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1809.06172"
  },
  {
    "id": "arXiv:1902.10899",
    "title": "Adversarial Attack and Defense on Point Sets",
    "abstract": "Adversarial Attack and Defense on Point Sets",
    "descriptor": "",
    "authors": [
      "Jiancheng Yang",
      "Qiang Zhang",
      "Rongyao Fang",
      "Bingbing Ni",
      "Jinxian Liu",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1902.10899"
  },
  {
    "id": "arXiv:1905.09676",
    "title": "Pruning-Aware Merging for Efficient Multitask Inference",
    "abstract": "Comments: Accepted to KDD'21 as research track paper",
    "descriptor": "\nComments: Accepted to KDD'21 as research track paper\n",
    "authors": [
      "Xiaoxi He",
      "Dawei Gao",
      "Zimu Zhou",
      "Yongxin Tong",
      "Lothar Thiele"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1905.09676"
  },
  {
    "id": "arXiv:1905.12698",
    "title": "Leveraging Latent Features for Local Explanations",
    "abstract": "Comments: Accepted to KDD 2021",
    "descriptor": "\nComments: Accepted to KDD 2021\n",
    "authors": [
      "Ronny Luss",
      "Pin-Yu Chen",
      "Amit Dhurandhar",
      "Prasanna Sattigeri",
      "Yunfeng Zhang",
      "Karthikeyan Shanmugam",
      "Chun-Chen Tu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.12698"
  },
  {
    "id": "arXiv:1905.13120",
    "title": "Analysis of high-dimensional Continuous Time Markov Chains using the  Local Bouncy Particle Sampler",
    "abstract": "Analysis of high-dimensional Continuous Time Markov Chains using the  Local Bouncy Particle Sampler",
    "descriptor": "",
    "authors": [
      "Tingting Zhao",
      "Alexandre Bouchard-C\u00f4t\u00e9"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/1905.13120"
  },
  {
    "id": "arXiv:1906.00722",
    "title": "Topological Autoencoders",
    "abstract": "Comments: Accepted at the International Conference on Machine Learning (ICML) 2020; camera-ready version",
    "descriptor": "\nComments: Accepted at the International Conference on Machine Learning (ICML) 2020; camera-ready version\n",
    "authors": [
      "Michael Moor",
      "Max Horn",
      "Bastian Rieck",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.00722"
  },
  {
    "id": "arXiv:1906.04285",
    "title": "Continuous Time Analysis of Momentum Methods",
    "abstract": "Comments: 40 pages, 7 figures",
    "descriptor": "\nComments: 40 pages, 7 figures\n",
    "authors": [
      "Nikola B. Kovachki",
      "Andrew M. Stuart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.04285"
  },
  {
    "id": "arXiv:1907.00865",
    "title": "Radial Bayesian Neural Networks: Beyond Discrete Support In Large-Scale  Bayesian Deep Learning",
    "abstract": "Radial Bayesian Neural Networks: Beyond Discrete Support In Large-Scale  Bayesian Deep Learning",
    "descriptor": "",
    "authors": [
      "Sebastian Farquhar",
      "Michael Osborne",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1907.00865"
  },
  {
    "id": "arXiv:1907.03103",
    "title": "Towards Enhancing Fault Tolerance in Neural Networks",
    "abstract": "Comments: MobiQuitous 2020",
    "descriptor": "\nComments: MobiQuitous 2020\n",
    "authors": [
      "Vasisht Duddu",
      "D. Vijay Rao",
      "Valentina E. Balas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1907.03103"
  },
  {
    "id": "arXiv:1907.07758",
    "title": "HITS hits art",
    "abstract": "HITS hits art",
    "descriptor": "",
    "authors": [
      "Massimo Franceschet"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1907.07758"
  },
  {
    "id": "arXiv:1907.08556",
    "title": "D-GAN: Deep Generative Adversarial Nets for Spatio-Temporal Prediction",
    "abstract": "D-GAN: Deep Generative Adversarial Nets for Spatio-Temporal Prediction",
    "descriptor": "",
    "authors": [
      "Divya Saxena",
      "Jiannong Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1907.08556"
  },
  {
    "id": "arXiv:1908.05865",
    "title": "A framework of constructing placement delivery arrays for centralized  coded caching",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Minquan Cheng",
      "Jinyu Wang",
      "Xi Zhong",
      "Qiang Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1908.05865"
  },
  {
    "id": "arXiv:1908.06211",
    "title": "PAStime: Progress-aware Scheduling for Time-critical Computing",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Soham Sinha",
      "Richard West",
      "Ahmad Golchin"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/1908.06211"
  },
  {
    "id": "arXiv:1910.05843",
    "title": "Regularized Sparse Gaussian Processes",
    "abstract": "Regularized Sparse Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Rui Meng",
      "Herbert Lee",
      "Soper Braden",
      "Priyadip Ray"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.05843"
  },
  {
    "id": "arXiv:1910.09227",
    "title": "Safe-Bayesian Generalized Linear Regression",
    "abstract": "Comments: Final version. Accepted to AISTATS 2020",
    "descriptor": "\nComments: Final version. Accepted to AISTATS 2020\n",
    "authors": [
      "Rianne de Heide",
      "Alisa Kirichenko",
      "Nishant Mehta",
      "Peter Gr\u00fcnwald"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/1910.09227"
  },
  {
    "id": "arXiv:1910.09857",
    "title": "An Efficient and Effective Second-Order Training Algorithm for  LSTM-based Adaptive Learning",
    "abstract": "An Efficient and Effective Second-Order Training Algorithm for  LSTM-based Adaptive Learning",
    "descriptor": "",
    "authors": [
      "N. Mert Vural",
      "Salih Erg\u00fct",
      "Suleyman S. Kozat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.09857"
  },
  {
    "id": "arXiv:1910.14560",
    "title": "A Relational Program Logic with Data Abstraction and Dynamic Framing",
    "abstract": "Comments: Submitted for publication. Version 3: Revise exposition with more examples; add case study; add author; revise title, add index, minor changes throughout. Version 4: Improved relational second order frame rule; revised and expanded examples and description of prototype; polish exposition",
    "descriptor": "\nComments: Submitted for publication. Version 3: Revise exposition with more examples; add case study; add author; revise title, add index, minor changes throughout. Version 4: Improved relational second order frame rule; revised and expanded examples and description of prototype; polish exposition\n",
    "authors": [
      "Anindya Banerjee",
      "Ramana Nagasamudram",
      "David A. Naumann",
      "Mohammad Nikouei"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1910.14560"
  },
  {
    "id": "arXiv:1911.04788",
    "title": "Fractal Impedance for Passive Controllers",
    "abstract": "Comments: Video Available at this https URL",
    "descriptor": "\nComments: Video Available at this https URL\n",
    "authors": [
      "Keyhan Kouhkiloui Babarahmati",
      "Carlo Tiseo",
      "Joshua Smith",
      "Hsiu Chin Lin",
      "Mustafa Suphi Erden",
      "Michael Mistry"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1911.04788"
  },
  {
    "id": "arXiv:1911.12258",
    "title": "Stability of the Decoupled Extended Kalman Filter Learning Algorithm in  LSTM-Based Online Learning",
    "abstract": "Comments: This paper was an early draft of the presented results. We have written and published another paper (arXiv:1911.12258) where we have improved on the material in this paper. The published paper covers most of the material presented in this paper as well. Therefore, we remove this paper from Arxiv and refer the interested readers to arXiv:1911.12258",
    "descriptor": "\nComments: This paper was an early draft of the presented results. We have written and published another paper (arXiv:1911.12258) where we have improved on the material in this paper. The published paper covers most of the material presented in this paper as well. Therefore, we remove this paper from Arxiv and refer the interested readers to arXiv:1911.12258\n",
    "authors": [
      "Nuri Mert Vural",
      "Fatih Ilhan",
      "Suleyman S. Kozat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.12258"
  },
  {
    "id": "arXiv:1912.11347",
    "title": "Robust Group Synchronization via Cycle-Edge Message Passing",
    "abstract": "Robust Group Synchronization via Cycle-Edge Message Passing",
    "descriptor": "",
    "authors": [
      "Gilad Lerman",
      "Yunpeng Shi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1912.11347"
  },
  {
    "id": "arXiv:2001.01414",
    "title": "A time-optimal feedback control for a particular case of the game of two  cars",
    "abstract": "A time-optimal feedback control for a particular case of the game of two  cars",
    "descriptor": "",
    "authors": [
      "Aditya Chaudhari",
      "Debraj Chakraborty"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2001.01414"
  },
  {
    "id": "arXiv:2001.03108",
    "title": "Feedback Capacity and a Variant of the Kalman Filter with ARMA Gaussian  Noises: Explicit Bounds and Feedback Coding Design",
    "abstract": "Feedback Capacity and a Variant of the Kalman Filter with ARMA Gaussian  Noises: Explicit Bounds and Feedback Coding Design",
    "descriptor": "",
    "authors": [
      "Song Fang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2001.03108"
  },
  {
    "id": "arXiv:2001.03246",
    "title": "The Logic of Strategic Assets: From Oil to Artificial Intelligence",
    "abstract": "Comments: Added references and corrected typos",
    "descriptor": "\nComments: Added references and corrected typos\n",
    "authors": [
      "Jeffrey Ding",
      "Allan Dafoe"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2001.03246"
  },
  {
    "id": "arXiv:2001.08780",
    "title": "Hardware Security for and beyond CMOS Technology",
    "abstract": "Comments: [v1] ISPD'20; [v2] extended arXiv version; [v3] some references updated, some paragraphs further extended; [v4] ISPD'21, extended arXiv version",
    "descriptor": "\nComments: [v1] ISPD'20; [v2] extended arXiv version; [v3] some references updated, some paragraphs further extended; [v4] ISPD'21, extended arXiv version\n",
    "authors": [
      "Johann Knechtel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2001.08780"
  },
  {
    "id": "arXiv:2002.00253",
    "title": "Bandits with Knapsacks beyond the Worst-Case",
    "abstract": "Comments: The initial version, titled \"Advances in Bandits with Knapsacks\", was published on arxiv.org in Jan'20. The present version improves both upper and lower bounds, deriving Theorem 3.2(ii) and Theorem 4.2. Moreover, it simplifies the algorithm and analysis in the main result, and fixes several issues in the lower bounds",
    "descriptor": "\nComments: The initial version, titled \"Advances in Bandits with Knapsacks\", was published on arxiv.org in Jan'20. The present version improves both upper and lower bounds, deriving Theorem 3.2(ii) and Theorem 4.2. Moreover, it simplifies the algorithm and analysis in the main result, and fixes several issues in the lower bounds\n",
    "authors": [
      "Karthik Abinav Sankararaman",
      "Aleksandrs Slivkins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.00253"
  },
  {
    "id": "arXiv:2002.06979",
    "title": "Convergence of End-to-End Training in Deep Unsupervised Contrastive  Learning",
    "abstract": "Convergence of End-to-End Training in Deep Unsupervised Contrastive  Learning",
    "descriptor": "",
    "authors": [
      "Zixin Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.06979"
  },
  {
    "id": "arXiv:2002.10669",
    "title": "Binary Scoring Rules that Incentivize Precision",
    "abstract": "Comments: 42 pages, accepted for publication in EC 2021",
    "descriptor": "\nComments: 42 pages, accepted for publication in EC 2021\n",
    "authors": [
      "Eric Neyman",
      "Georgy Noarov",
      "S. Matthew Weinberg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2002.10669"
  },
  {
    "id": "arXiv:2002.11809",
    "title": "Assortativity and bidegree distributions on Bernoulli random graph  superpositions",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Mindaugas Bloznelis",
      "Joona Karjalainen",
      "Lasse Leskel\u00e4"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2002.11809"
  },
  {
    "id": "arXiv:2003.00400",
    "title": "Learn Task First or Learn Human Partner First: A Hierarchical Task  Decomposition Method for Human-Robot Cooperation",
    "abstract": "Comments: Submitted to SMC2021",
    "descriptor": "\nComments: Submitted to SMC2021\n",
    "authors": [
      "Lingfeng Tao",
      "Michael Bowman",
      "Jiucai Zhang",
      "Xiaoli Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2003.00400"
  },
  {
    "id": "arXiv:2003.03601",
    "title": "RNN-based Online Learning: An Efficient First-Order Optimization  Algorithm with a Convergence Guarantee",
    "abstract": "Comments: This paper was an early draft of the presented results. We have written and published another paper (arXiv:2005.08948) where we have improved the material in this paper. The published paper covers most of the material presented in this paper as well. Therefore, we remove this paper from Arxiv and kindly refer the interested readers to arXiv:2005.08948",
    "descriptor": "\nComments: This paper was an early draft of the presented results. We have written and published another paper (arXiv:2005.08948) where we have improved the material in this paper. The published paper covers most of the material presented in this paper as well. Therefore, we remove this paper from Arxiv and kindly refer the interested readers to arXiv:2005.08948\n",
    "authors": [
      "N. Mert Vural",
      "Selim F. Yilmaz",
      "Fatih Ilhan",
      "Suleyman S. Kozat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.03601"
  },
  {
    "id": "arXiv:2003.11611",
    "title": "Deep Agent: Studying the Dynamics of Information Spread and Evolution in  Social Networks",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Ivan Garibay",
      "Toktam A. Oghaz",
      "Niloofar Yousefi",
      "Ece C. Mutlu",
      "Madeline Schiappa",
      "Steven Scheinert",
      "Georgios C. Anagnostopoulos",
      "Christina Bouwens",
      "Stephen M. Fiore",
      "Alexander Mantzaris",
      "John T. Murphy",
      "William Rand",
      "Anastasia Salter",
      "Mel Stanfill",
      "Gita Sukthankar",
      "Nisha Baral",
      "Gabriel Fair",
      "Chathika Gunaratne",
      "Neda B. Hajiakhoond",
      "Jasser Jasser",
      "Chathura Jayalath",
      "Olivia Newton",
      "Samaneh Saadat",
      "Chathurani Senevirathna",
      "Rachel Winter",
      "Xi Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2003.11611"
  },
  {
    "id": "arXiv:2003.12127",
    "title": "Gryffin: An algorithm for Bayesian optimization of categorical variables  informed by expert knowledge",
    "abstract": "Comments: 19 pages, 6 figures (SI: 16 pages, 14 figures). Expanded background, discussion, minor fixes and changes",
    "descriptor": "\nComments: 19 pages, 6 figures (SI: 16 pages, 14 figures). Expanded background, discussion, minor fixes and changes\n",
    "authors": [
      "Florian H\u00e4se",
      "Matteo Aldeghi",
      "Riley J. Hickman",
      "Lo\u00efc M. Roch",
      "Al\u00e1n Aspuru-Guzik"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2003.12127"
  },
  {
    "id": "arXiv:2003.13726",
    "title": "Continual Learning with Node-Importance based Adaptive Group Sparse  Regularization",
    "abstract": "Continual Learning with Node-Importance based Adaptive Group Sparse  Regularization",
    "descriptor": "",
    "authors": [
      "Sangwon Jung",
      "Hongjoon Ahn",
      "Sungmin Cha",
      "Taesup Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.13726"
  },
  {
    "id": "arXiv:2004.00646",
    "title": "A Survey on Conversational Recommender Systems",
    "abstract": "Comments: 35 pages, 5 figures",
    "descriptor": "\nComments: 35 pages, 5 figures\n",
    "authors": [
      "Dietmar Jannach",
      "Ahtsham Manzoor",
      "Wanling Cai",
      "Li Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2004.00646"
  },
  {
    "id": "arXiv:2004.03853",
    "title": "Shape-Constrained Regression using Sum of Squares Polynomials",
    "abstract": "Shape-Constrained Regression using Sum of Squares Polynomials",
    "descriptor": "",
    "authors": [
      "Mihaela Curmei",
      "Georgina Hall"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2004.03853"
  },
  {
    "id": "arXiv:2004.11697",
    "title": "A Time Series Analysis-Based Stock Price Prediction Using Machine  Learning and Deep Learning Models",
    "abstract": "Comments: This is the preprint of our paper accepted for publication in the Inderscience Journal International Journal of Business Forecasting and Marketing Intelligence. The paper consists of 53 pages, 26 Tables, and 46 Figures",
    "descriptor": "\nComments: This is the preprint of our paper accepted for publication in the Inderscience Journal International Journal of Business Forecasting and Marketing Intelligence. The paper consists of 53 pages, 26 Tables, and 46 Figures\n",
    "authors": [
      "Sidra Mehtab",
      "Jaydip Sen"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.11697"
  },
  {
    "id": "arXiv:2004.13003",
    "title": "Corpus-level and Concept-based Explanations for Interpretable Document  Classification",
    "abstract": "Corpus-level and Concept-based Explanations for Interpretable Document  Classification",
    "descriptor": "",
    "authors": [
      "Tian Shi",
      "Xuchao Zhang",
      "Ping Wang",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.13003"
  },
  {
    "id": "arXiv:2004.14064",
    "title": "Quantum and approximation algorithms for maximum witnesses of Boolean  matrix products",
    "abstract": "Comments: 14 pages, 3 figures",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Miros\u0142aw Kowaluk",
      "Andrzej Lingas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2004.14064"
  },
  {
    "id": "arXiv:2004.14276",
    "title": "A novel two-point gradient method for Regularization of inverse problems  in Banach spaces",
    "abstract": "Comments: Submitted in Applicable Analysis",
    "descriptor": "\nComments: Submitted in Applicable Analysis\n",
    "authors": [
      "Gaurav Mittal",
      "Ankik Kumar Giri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2004.14276"
  },
  {
    "id": "arXiv:2005.00575",
    "title": "Approximating maximum integral multiflows on bounded genus graphs",
    "abstract": "Approximating maximum integral multiflows on bounded genus graphs",
    "descriptor": "",
    "authors": [
      "Chien-chung Huang",
      "Mathieu Mari",
      "Claire Mathieu",
      "Jens Vygen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2005.00575"
  },
  {
    "id": "arXiv:2005.08948",
    "title": "Achieving Online Regression Performance of LSTMs with Simple RNNs",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2003.03601",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2003.03601\n",
    "authors": [
      "N. Mert Vural",
      "Fatih Ilhan",
      "Selim F. Yilmaz",
      "Salih Erg\u00fct",
      "Suleyman S. Kozat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.08948"
  },
  {
    "id": "arXiv:2005.09351",
    "title": "Cores in discrete exchange economies with complex endowments",
    "abstract": "Comments: 38 pages",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Jun Zhang"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2005.09351"
  },
  {
    "id": "arXiv:2005.13746",
    "title": "Tensor decomposition to Compress Convolutional Layers in Deep Learning",
    "abstract": "Comments: 35 pages, IISE Transactions",
    "descriptor": "\nComments: 35 pages, IISE Transactions\n",
    "authors": [
      "Yinan Wang",
      "Weihong \"Grace\" Guo",
      "Xiaowei Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.13746"
  },
  {
    "id": "arXiv:2005.14458",
    "title": "Distributional Random Forests: Heterogeneity Adjustment and Multivariate  Distributional Regression",
    "abstract": "Distributional Random Forests: Heterogeneity Adjustment and Multivariate  Distributional Regression",
    "descriptor": "",
    "authors": [
      "Domagoj \u0106evid",
      "Loris Michel",
      "Jeffrey N\u00e4f",
      "Nicolai Meinshausen",
      "Peter B\u00fchlmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2005.14458"
  },
  {
    "id": "arXiv:2006.01236",
    "title": "Aperiodicity, Star-freeness, and First-order Definability of Structured  Context-Free Languages",
    "abstract": "Aperiodicity, Star-freeness, and First-order Definability of Structured  Context-Free Languages",
    "descriptor": "",
    "authors": [
      "Dino Mandrioli",
      "Matteo Pradella",
      "Stefano Crespi Reghizzi"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2006.01236"
  },
  {
    "id": "arXiv:2006.04099",
    "title": "On Hermitian varieties in $\\mathrm{PG}(6,q^2)$",
    "abstract": "Comments: 13 pages/revised version",
    "descriptor": "\nComments: 13 pages/revised version\n",
    "authors": [
      "Angela Aguglia",
      "Luca Giuzzi",
      "Masaaki Homma"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2006.04099"
  },
  {
    "id": "arXiv:2006.05896",
    "title": "A Probabilistic Model for Discriminative and Neuro-Symbolic  Semi-Supervised Learning",
    "abstract": "A Probabilistic Model for Discriminative and Neuro-Symbolic  Semi-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Carl Allen",
      "Ivana Bala\u017eevi\u0107",
      "Timothy Hospedales"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05896"
  },
  {
    "id": "arXiv:2006.05905",
    "title": "Spatial-Temporal Dynamic Graph Attention Networks for Ride-hailing  Demand Prediction",
    "abstract": "Comments: 11 pages, 6 figures. arXiv admin note: text overlap with arXiv:2006.04089",
    "descriptor": "\nComments: 11 pages, 6 figures. arXiv admin note: text overlap with arXiv:2006.04089\n",
    "authors": [
      "Weiguo Pian",
      "Yingbo Wu",
      "Xiangmou Qu",
      "Junpeng Cai",
      "Ziyi Kou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2006.05905"
  },
  {
    "id": "arXiv:2006.06518",
    "title": "Towards Expedited Impedance Tuning of a Robotic Prosthesis for  Personalized Gait Assistance by Reinforcement Learning Control",
    "abstract": "Towards Expedited Impedance Tuning of a Robotic Prosthesis for  Personalized Gait Assistance by Reinforcement Learning Control",
    "descriptor": "",
    "authors": [
      "Minhan Li",
      "Yue Wen",
      "Xiang Gao",
      "Jennie Si",
      "He Helen Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.06518"
  },
  {
    "id": "arXiv:2006.08855",
    "title": "RaSE: Random Subspace Ensemble Classification",
    "abstract": "Comments: 93 pages, 13 figures",
    "descriptor": "\nComments: 93 pages, 13 figures\n",
    "authors": [
      "Ye Tian",
      "Yang Feng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2006.08855"
  },
  {
    "id": "arXiv:2006.10811",
    "title": "Learning to infer in recurrent biological networks",
    "abstract": "Learning to infer in recurrent biological networks",
    "descriptor": "",
    "authors": [
      "Ari S. Benjamin",
      "Konrad P. Kording"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10811"
  },
  {
    "id": "arXiv:2006.11122",
    "title": "A general framework for defining and optimizing robustness",
    "abstract": "A general framework for defining and optimizing robustness",
    "descriptor": "",
    "authors": [
      "Alessandro Tibo",
      "Manfred Jaeger",
      "Kim G. Larsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.11122"
  },
  {
    "id": "arXiv:2006.11440",
    "title": "Local Convolutions Cause an Implicit Bias towards High Frequency  Adversarial Examples",
    "abstract": "Comments: 19 pages, 12 figures",
    "descriptor": "\nComments: 19 pages, 12 figures\n",
    "authors": [
      "Josue Ortega Caro",
      "Yilong Ju",
      "Ryan Pyle",
      "Sourav Dey",
      "Wieland Brendel",
      "Fabio Anselmi",
      "Ankit Patel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.11440"
  },
  {
    "id": "arXiv:2006.12897",
    "title": "Polynomial Time Approximation Schemes for Clustering in Low Highway  Dimension Graphs",
    "abstract": "Polynomial Time Approximation Schemes for Clustering in Low Highway  Dimension Graphs",
    "descriptor": "",
    "authors": [
      "Andreas Emil Feldmann",
      "David Saulpic"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2006.12897"
  },
  {
    "id": "arXiv:2006.13912",
    "title": "Unified Reinforcement Q-Learning for Mean Field Game and Control  Problems",
    "abstract": "Unified Reinforcement Q-Learning for Mean Field Game and Control  Problems",
    "descriptor": "",
    "authors": [
      "Andrea Angiuli",
      "Jean-Pierre Fouque",
      "Mathieu Lauri\u00e8re"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2006.13912"
  },
  {
    "id": "arXiv:2007.01276",
    "title": "Epileptic Seizures Detection Using Deep Learning Techniques: A Review",
    "abstract": "Epileptic Seizures Detection Using Deep Learning Techniques: A Review",
    "descriptor": "",
    "authors": [
      "Afshin Shoeibi",
      "Marjane Khodatars",
      "Navid Ghassemi",
      "Mahboobeh Jafari",
      "Parisa Moridian",
      "Roohallah Alizadehsani",
      "Maryam Panahiazar",
      "Fahime Khozeimeh",
      "Assef Zare",
      "Hossein Hosseini-Nejad",
      "Abbas Khosravi",
      "Amir F. Atiya",
      "Diba Aminshahidi",
      "Sadiq Hussain",
      "Modjtaba Rouhani",
      "Saeid Nahavandi",
      "Udyavara Rajendra Acharya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.01276"
  },
  {
    "id": "arXiv:2007.03073",
    "title": "Generative Model-Based Loss to the Rescue: A Method to Overcome  Annotation Errors for Depth-Based Hand Pose Estimation",
    "abstract": "Generative Model-Based Loss to the Rescue: A Method to Overcome  Annotation Errors for Depth-Based Hand Pose Estimation",
    "descriptor": "",
    "authors": [
      "Jiayi Wang",
      "Franziska Mueller",
      "Florian Bernard",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.03073"
  },
  {
    "id": "arXiv:2007.09532",
    "title": "Fast Learning for Renewal Optimization in Online Task Scheduling",
    "abstract": "Comments: 32 pages, 9 figures. This version 2 fixes some minor typos from my submission last year",
    "descriptor": "\nComments: 32 pages, 9 figures. This version 2 fixes some minor typos from my submission last year\n",
    "authors": [
      "Michael J. Neely"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.09532"
  },
  {
    "id": "arXiv:2007.14247",
    "title": "Downlink channel access performance of NR-U: Impact of numerology and  mini-slots on coexistence with Wi-Fi in the 5 GHz band",
    "abstract": "Comments: 20 double-column single-spaced pages, 10 figures, 3 tables, 39 references, journal submission",
    "descriptor": "\nComments: 20 double-column single-spaced pages, 10 figures, 3 tables, 39 references, journal submission\n",
    "authors": [
      "Katarzyna Kosek-Szott",
      "Alice Lo Valvo",
      "Szymon Szott",
      "Pierluigi Gallo",
      "Ilenia Tinnirello"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2007.14247"
  },
  {
    "id": "arXiv:2007.15107",
    "title": "OrcVIO: Object residual constrained Visual-Inertial Odometry",
    "abstract": "Comments: Submitted to T-RO",
    "descriptor": "\nComments: Submitted to T-RO\n",
    "authors": [
      "Mo Shan",
      "Vikas Dhiman",
      "Qiaojun Feng",
      "Jinzhao Li",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.15107"
  },
  {
    "id": "arXiv:2007.15154",
    "title": "Approximate Ridesharing of Personal Vehicles Problem",
    "abstract": "Comments: 39 pages, 6 figures",
    "descriptor": "\nComments: 39 pages, 6 figures\n",
    "authors": [
      "Qian-Ping Gu",
      "Jiajian Leo Liang",
      "Guochuan Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2007.15154"
  },
  {
    "id": "arXiv:2007.16079",
    "title": "Creating RESTful APIs over SPARQL endpoints using RAMOSE",
    "abstract": "Creating RESTful APIs over SPARQL endpoints using RAMOSE",
    "descriptor": "",
    "authors": [
      "Marilena Daquino",
      "Ivan Heibi",
      "Silvio Peroni",
      "David Shotton"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2007.16079"
  },
  {
    "id": "arXiv:2008.00335",
    "title": "V2I Connectivity-Based Dynamic Queue-Jump Lane for Emergency Vehicles: A  Deep Reinforcement Learning Approach",
    "abstract": "Comments: 20 pages, 6 figures",
    "descriptor": "\nComments: 20 pages, 6 figures\n",
    "authors": [
      "Haoran Su",
      "Kejian Shi",
      "Li Jin",
      "Joseph Y.J. Chow"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.00335"
  },
  {
    "id": "arXiv:2008.03408",
    "title": "Learning to Detect Bipolar Disorder and Borderline Personality Disorder  with Language and Speech in Non-Clinical Interviews",
    "abstract": "Learning to Detect Bipolar Disorder and Borderline Personality Disorder  with Language and Speech in Non-Clinical Interviews",
    "descriptor": "",
    "authors": [
      "Bo Wang",
      "Yue Wu",
      "Niall Taylor",
      "Terry Lyons",
      "Maria Liakata",
      "Alejo J Nevado-Holgado",
      "Kate E A Saunders"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.03408"
  },
  {
    "id": "arXiv:2008.05758",
    "title": "Conservative Stochastic Optimization with Expectation Constraints",
    "abstract": "Conservative Stochastic Optimization with Expectation Constraints",
    "descriptor": "",
    "authors": [
      "Zeeshan Akhtar",
      "Amrit Singh Bedi",
      "Ketan Rajawat"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2008.05758"
  },
  {
    "id": "arXiv:2008.07230",
    "title": "Robustness Verification of Quantum Classifiers",
    "abstract": "Robustness Verification of Quantum Classifiers",
    "descriptor": "",
    "authors": [
      "Ji Guan",
      "Wang Fang",
      "Mingsheng Ying"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.07230"
  },
  {
    "id": "arXiv:2008.08617",
    "title": "MTHetGNN: A Heterogeneous Graph Embedding Framework for Multivariate  Time Series Forecasting",
    "abstract": "MTHetGNN: A Heterogeneous Graph Embedding Framework for Multivariate  Time Series Forecasting",
    "descriptor": "",
    "authors": [
      "Yueyang Wang",
      "Ziheng Duan",
      "Yida Huang",
      "Haoyan Xu",
      "Jie Feng",
      "Anni Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.08617"
  },
  {
    "id": "arXiv:2008.08753",
    "title": "When Homomorphic Encryption Marries Secret Sharing: Secure Large-Scale  Sparse Logistic Regression and Applications in Risk Control",
    "abstract": "Comments: Accepted by KDD'21",
    "descriptor": "\nComments: Accepted by KDD'21\n",
    "authors": [
      "Chaochao Chen",
      "Jun Zhou",
      "Li Wang",
      "Xibin Wu",
      "Wenjing Fang",
      "Jin Tan",
      "Lei Wang",
      "Alex X. Liu",
      "Hao Wang",
      "Cheng Hong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.08753"
  },
  {
    "id": "arXiv:2008.08930",
    "title": "Why Adopting Regularization and Normalization For Generative Adversarial  Networks: A Survey",
    "abstract": "Why Adopting Regularization and Normalization For Generative Adversarial  Networks: A Survey",
    "descriptor": "",
    "authors": [
      "Ziqiang Li",
      "Xintian Wu",
      "Rentuo Tao",
      "Pengfei Xia",
      "Huanhuan Chen",
      "Bin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2008.08930"
  },
  {
    "id": "arXiv:2009.02070",
    "title": "AutoTrans: Automating Transformer Design via Reinforced Architecture  Search",
    "abstract": "Comments: will add new technical contents",
    "descriptor": "\nComments: will add new technical contents\n",
    "authors": [
      "Wei Zhu",
      "Xiaoling Wang",
      "Xipeng Qiu",
      "Yuan Ni",
      "Guotong Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.02070"
  },
  {
    "id": "arXiv:2009.07360",
    "title": "Constrained Labeling for Weakly Supervised Learning",
    "abstract": "Comments: Accepted at UAI 2021",
    "descriptor": "\nComments: Accepted at UAI 2021\n",
    "authors": [
      "Chidubem Arachie",
      "Bert Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.07360"
  },
  {
    "id": "arXiv:2009.07542",
    "title": "Perturbation expansions and error bounds for the truncated singular  value decomposition",
    "abstract": "Comments: Accepted to Linear Algebra and Its Applications",
    "descriptor": "\nComments: Accepted to Linear Algebra and Its Applications\n",
    "authors": [
      "Trung Vu",
      "Evgenia Chunikhina",
      "Raviv Raich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2009.07542"
  },
  {
    "id": "arXiv:2009.08008",
    "title": "The Boundary Element Method of Peridynamics",
    "abstract": "The Boundary Element Method of Peridynamics",
    "descriptor": "",
    "authors": [
      "Xue Liang",
      "Linjuan Wang",
      "Jifeng Xu",
      "Jianxiang Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2009.08008"
  },
  {
    "id": "arXiv:2009.08553",
    "title": "Generation-Augmented Retrieval for Open-domain Question Answering",
    "abstract": "Comments: ACL 2021 Camera-ready",
    "descriptor": "\nComments: ACL 2021 Camera-ready\n",
    "authors": [
      "Yuning Mao",
      "Pengcheng He",
      "Xiaodong Liu",
      "Yelong Shen",
      "Jianfeng Gao",
      "Jiawei Han",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2009.08553"
  },
  {
    "id": "arXiv:2009.08633",
    "title": "fastHan: A BERT-based Multi-Task Toolkit for Chinese NLP",
    "abstract": "Comments: ACL2021 Demo Track",
    "descriptor": "\nComments: ACL2021 Demo Track\n",
    "authors": [
      "Zhichao Geng",
      "Hang Yan",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.08633"
  },
  {
    "id": "arXiv:2009.09112",
    "title": "An Interpretable and Uncertainty Aware Multi-Task Framework for  Multi-Aspect Sentiment Analysis",
    "abstract": "An Interpretable and Uncertainty Aware Multi-Task Framework for  Multi-Aspect Sentiment Analysis",
    "descriptor": "",
    "authors": [
      "Tian Shi",
      "Ping Wang",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2009.09112"
  },
  {
    "id": "arXiv:2009.09235",
    "title": "Open-Ended Fine-Grained 3D Object Categorization by Combining Shape and  Texture Features in Multiple Colorspaces",
    "abstract": "Open-Ended Fine-Grained 3D Object Categorization by Combining Shape and  Texture Features in Multiple Colorspaces",
    "descriptor": "",
    "authors": [
      "Nils Keunecke",
      "S. Hamidreza Kasaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2009.09235"
  },
  {
    "id": "arXiv:2009.10178",
    "title": "Industry-Relevant Implicit Large-Eddy Simulation of a High-Performance  Road Car via Spectral/hp Element Methods",
    "abstract": "Industry-Relevant Implicit Large-Eddy Simulation of a High-Performance  Road Car via Spectral/hp Element Methods",
    "descriptor": "",
    "authors": [
      "Gianmarco Mengaldo",
      "David Moxey",
      "Michael Turner",
      "Rodrigo C. Moura",
      "Ayad Jassim",
      "Mark Taylor",
      "Joaquim Peiro",
      "Spencer J. Sherwin"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2009.10178"
  },
  {
    "id": "arXiv:2009.10580",
    "title": "Heuristic Rank Selection with Progressively Searching Tensor Ring  Network",
    "abstract": "Heuristic Rank Selection with Progressively Searching Tensor Ring  Network",
    "descriptor": "",
    "authors": [
      "Nannan Li",
      "Yu Pan",
      "Yaran Chen",
      "Zixiang Ding",
      "Dongbin Zhao",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.10580"
  },
  {
    "id": "arXiv:2009.13284",
    "title": "Pchatbot: A Large-Scale Dataset for Personalized Chatbot",
    "abstract": "Comments: Camera-ready version, SIGIR 2021 (Resource Track), the dataset and codes are available at this https URL",
    "descriptor": "\nComments: Camera-ready version, SIGIR 2021 (Resource Track), the dataset and codes are available at this https URL\n",
    "authors": [
      "Hongjin Qian",
      "Xiaohe Li",
      "Hanxun Zhong",
      "Yu Guo",
      "Yueyuan Ma",
      "Yutao Zhu",
      "Zhanliang Liu",
      "Zhicheng Dou",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.13284"
  },
  {
    "id": "arXiv:2009.13845",
    "title": "GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing",
    "abstract": "Comments: 16 pages; Accepted to ICLR 2021",
    "descriptor": "\nComments: 16 pages; Accepted to ICLR 2021\n",
    "authors": [
      "Tao Yu",
      "Chien-Sheng Wu",
      "Xi Victoria Lin",
      "Bailin Wang",
      "Yi Chern Tan",
      "Xinyi Yang",
      "Dragomir Radev",
      "Richard Socher",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.13845"
  },
  {
    "id": "arXiv:2010.00174",
    "title": "Information Propagation Model in Hybrid Networks",
    "abstract": "Information Propagation Model in Hybrid Networks",
    "descriptor": "",
    "authors": [
      "Fuzhong Nian",
      "Hongyuan Diao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2010.00174"
  },
  {
    "id": "arXiv:2010.01175",
    "title": "Towards Bidirectional Protection in Federated Learning",
    "abstract": "Towards Bidirectional Protection in Federated Learning",
    "descriptor": "",
    "authors": [
      "Lun Wang",
      "Qi Pang",
      "Shuai Wang",
      "Dawn Song"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2010.01175"
  },
  {
    "id": "arXiv:2010.01282",
    "title": "TCLNet: Learning to Locate Typhoon Center Using Deep Neural Network",
    "abstract": "TCLNet: Learning to Locate Typhoon Center Using Deep Neural Network",
    "descriptor": "",
    "authors": [
      "Chao Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.01282"
  },
  {
    "id": "arXiv:2010.01283",
    "title": "Generating the Cloud Motion Winds Field from Satellite Cloud Imagery  Using Deep Learning Approach",
    "abstract": "Generating the Cloud Motion Winds Field from Satellite Cloud Imagery  Using Deep Learning Approach",
    "descriptor": "",
    "authors": [
      "Chao Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.01283"
  },
  {
    "id": "arXiv:2010.01291",
    "title": "Unsupervised Shadow Removal Using Target Consistency Generative  Adversarial Network",
    "abstract": "Unsupervised Shadow Removal Using Target Consistency Generative  Adversarial Network",
    "descriptor": "",
    "authors": [
      "Chao Tan",
      "Xin Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2010.01291"
  },
  {
    "id": "arXiv:2010.01590",
    "title": "Deep kernel processes",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Laurence Aitchison",
      "Adam X. Yang",
      "Sebastian W. Ober"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.01590"
  },
  {
    "id": "arXiv:2010.01736",
    "title": "Geometry-aware Instance-reweighted Adversarial Training",
    "abstract": "Comments: ICLR 2021, Oral, Code &lt;this https URL&gt;",
    "descriptor": "\nComments: ICLR 2021, Oral, Code &lt;this https URL&gt;\n",
    "authors": [
      "Jingfeng Zhang",
      "Jianing Zhu",
      "Gang Niu",
      "Bo Han",
      "Masashi Sugiyama",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.01736"
  },
  {
    "id": "arXiv:2010.02709",
    "title": "An Infinite-Feature Extension for Bayesian ReLU Nets That Fixes Their  Asymptotic Overconfidence",
    "abstract": "An Infinite-Feature Extension for Bayesian ReLU Nets That Fixes Their  Asymptotic Overconfidence",
    "descriptor": "",
    "authors": [
      "Agustinus Kristiadi",
      "Matthias Hein",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.02709"
  },
  {
    "id": "arXiv:2010.04434",
    "title": "Tuning Convolutional Spiking Neural Network with Biologically-plausible  Reward Propagation",
    "abstract": "Comments: Final Version. Accepted by IEEE Transactions on Neural Networks and Learning Systems",
    "descriptor": "\nComments: Final Version. Accepted by IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Tielin Zhang",
      "Shuncheng Jia",
      "Xiang Cheng",
      "Bo Xu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.04434"
  },
  {
    "id": "arXiv:2010.04643",
    "title": "Equitable Scheduling on a Single Machine",
    "abstract": "Equitable Scheduling on a Single Machine",
    "descriptor": "",
    "authors": [
      "Klaus Heeger",
      "Danny Hermelin",
      "George B. Mertzios",
      "Hendrik Molter",
      "Rolf Niedermeier",
      "Dvir Shabtay"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.04643"
  },
  {
    "id": "arXiv:2010.05991",
    "title": "On optimal designs using topology optimization for flow through porous  media applications",
    "abstract": "On optimal designs using topology optimization for flow through porous  media applications",
    "descriptor": "",
    "authors": [
      "T. Phatak",
      "K. B. Nakshatrala"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.05991"
  },
  {
    "id": "arXiv:2010.06100",
    "title": "Invariant Representation Learning for Infant Pose Estimation with Small  Data",
    "abstract": "Invariant Representation Learning for Infant Pose Estimation with Small  Data",
    "descriptor": "",
    "authors": [
      "Xiaofei Huang",
      "Nihang Fu",
      "Shuangjun Liu",
      "Sarah Ostadabbas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.06100"
  },
  {
    "id": "arXiv:2010.07799",
    "title": "Adaptive and Universal Algorithms for Variational Inequalities with  Optimal Convergence",
    "abstract": "Adaptive and Universal Algorithms for Variational Inequalities with  Optimal Convergence",
    "descriptor": "",
    "authors": [
      "Alina Ene",
      "Huy L. Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.07799"
  },
  {
    "id": "arXiv:2010.08762",
    "title": "Layer-wise Characterization of Latent Information Leakage in Federated  Learning",
    "abstract": "Comments: 9 pages, at ICLR workshop (Distributed and Private Machine Learning)",
    "descriptor": "\nComments: 9 pages, at ICLR workshop (Distributed and Private Machine Learning)\n",
    "authors": [
      "Fan Mo",
      "Anastasia Borovykh",
      "Mohammad Malekzadeh",
      "Hamed Haddadi",
      "Soteris Demetriou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.08762"
  },
  {
    "id": "arXiv:2010.09115",
    "title": "Shortest Paths Among Obstacles in the Plane Revisited",
    "abstract": "Comments: Published in SODA 2021. Observation 2 in the previous version (and also in SODA proceedings) is not correct. The issue is addressed in this version with slightly different analysis",
    "descriptor": "\nComments: Published in SODA 2021. Observation 2 in the previous version (and also in SODA proceedings) is not correct. The issue is addressed in this version with slightly different analysis\n",
    "authors": [
      "Haitao Wang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.09115"
  },
  {
    "id": "arXiv:2010.10468",
    "title": "Investigating Cross-Domain Losses for Speech Enhancement",
    "abstract": "Comments: 5 pages, 3 figures and 1 table",
    "descriptor": "\nComments: 5 pages, 3 figures and 1 table\n",
    "authors": [
      "Sherif Abdulatif",
      "Karim Armanious",
      "Jayasankar T. Sajeev",
      "Karim Guirguis",
      "Bin Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2010.10468"
  },
  {
    "id": "arXiv:2010.11939",
    "title": "Limitations of Autoregressive Models and Their Alternatives",
    "abstract": "Comments: NAACL 2021 (same content, more relaxed layout)",
    "descriptor": "\nComments: NAACL 2021 (same content, more relaxed layout)\n",
    "authors": [
      "Chu-Cheng Lin",
      "Aaron Jaech",
      "Xin Li",
      "Matthew R. Gormley",
      "Jason Eisner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.11939"
  },
  {
    "id": "arXiv:2010.12008",
    "title": "Towards Zero-Shot Multilingual Synthetic Question and Answer Generation  for Cross-Lingual Reading Comprehension",
    "abstract": "Towards Zero-Shot Multilingual Synthetic Question and Answer Generation  for Cross-Lingual Reading Comprehension",
    "descriptor": "",
    "authors": [
      "Siamak Shakeri",
      "Noah Constant",
      "Mihir Sanjay Kale",
      "Linting Xue"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.12008"
  },
  {
    "id": "arXiv:2010.13046",
    "title": "CLRGaze: Contrastive Learning of Representations for Eye Movement  Signals",
    "abstract": "Comments: Accepted to 29th European Signal Processing Conference (EUSIPCO 2021)",
    "descriptor": "\nComments: Accepted to 29th European Signal Processing Conference (EUSIPCO 2021)\n",
    "authors": [
      "Louise Gillian C. Bautista",
      "Prospero C. Naval Jr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.13046"
  },
  {
    "id": "arXiv:2011.00619",
    "title": "Support Recovery for Sparse Multidimensional Phase Retrieval",
    "abstract": "Support Recovery for Sparse Multidimensional Phase Retrieval",
    "descriptor": "",
    "authors": [
      "Alexei Novikov",
      "Stephen White"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2011.00619"
  },
  {
    "id": "arXiv:2011.01143",
    "title": "Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of  On-Screen Sounds",
    "abstract": "Comments: ICLR 2021, 27 pages",
    "descriptor": "\nComments: ICLR 2021, 27 pages\n",
    "authors": [
      "Efthymios Tzinis",
      "Scott Wisdom",
      "Aren Jansen",
      "Shawn Hershey",
      "Tal Remez",
      "Daniel P. W. Ellis",
      "John R. Hershey"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2011.01143"
  },
  {
    "id": "arXiv:2011.01454",
    "title": "Contact Mode Guided Sampling-Based Planning for Quasistatic Dexterous  Manipulation in 2D",
    "abstract": "Comments: IEEE International Conference on Robotics and Automation (ICRA) 2021",
    "descriptor": "\nComments: IEEE International Conference on Robotics and Automation (ICRA) 2021\n",
    "authors": [
      "Xianyi Cheng",
      "Eric Huang",
      "Yifan Hou",
      "Matthew T. Mason"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.01454"
  },
  {
    "id": "arXiv:2011.02100",
    "title": "Deoscillated Graph Collaborative Filtering",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Zhiwei Liu",
      "Lin Meng",
      "Fei Jiang",
      "Jiawei Zhang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2011.02100"
  },
  {
    "id": "arXiv:2011.02313",
    "title": "Physical ZKP for Connected Spanning Subgraph: Applications to Bridges  Puzzle and Other Problems",
    "abstract": "Physical ZKP for Connected Spanning Subgraph: Applications to Bridges  Puzzle and Other Problems",
    "descriptor": "",
    "authors": [
      "Suthee Ruangwises",
      "Toshiya Itoh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.02313"
  },
  {
    "id": "arXiv:2011.02407",
    "title": "Debiasing classifiers: is reality at variance with expectation?",
    "abstract": "Comments: 13 pages, under review",
    "descriptor": "\nComments: 13 pages, under review\n",
    "authors": [
      "Ashrya Agrawal",
      "Florian Pfisterer",
      "Bernd Bischl",
      "Francois Buet-Golfouse",
      "Srijan Sood",
      "Jiahao Chen",
      "Sameena Shah",
      "Sebastian Vollmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2011.02407"
  },
  {
    "id": "arXiv:2011.02930",
    "title": "Paralinguistic Privacy Protection at the Edge",
    "abstract": "Comments: 14 pages, 7 figures. arXiv admin note: text overlap with arXiv:2007.15064",
    "descriptor": "\nComments: 14 pages, 7 figures. arXiv admin note: text overlap with arXiv:2007.15064\n",
    "authors": [
      "Ranya Aloufi",
      "Hamed Haddadi",
      "David Boyle"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2011.02930"
  },
  {
    "id": "arXiv:2011.02980",
    "title": "Using Five Cards to Encode Each Integer in $\\mathbb{Z}/6\\mathbb{Z}$",
    "abstract": "Using Five Cards to Encode Each Integer in $\\mathbb{Z}/6\\mathbb{Z}$",
    "descriptor": "",
    "authors": [
      "Suthee Ruangwises"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.02980"
  },
  {
    "id": "arXiv:2011.04917",
    "title": "Towards Unifying Feature Attribution and Counterfactual Explanations:  Different Means to the Same End",
    "abstract": "Comments: 15 pages, 10 figures",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Ramaravind Kommiya Mothilal",
      "Divyat Mahajan",
      "Chenhao Tan",
      "Amit Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2011.04917"
  },
  {
    "id": "arXiv:2011.04942",
    "title": "Decision times of infinite computations",
    "abstract": "Decision times of infinite computations",
    "descriptor": "",
    "authors": [
      "Merlin Carl",
      "Philipp Schlicht",
      "Philip Welch"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2011.04942"
  },
  {
    "id": "arXiv:2011.05869",
    "title": "CRPO: A New Approach for Safe Reinforcement Learning with Convergence  Guarantee",
    "abstract": "Comments: Published in ICML 2021",
    "descriptor": "\nComments: Published in ICML 2021\n",
    "authors": [
      "Tengyu Xu",
      "Yingbin Liang",
      "Guanghui Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.05869"
  },
  {
    "id": "arXiv:2011.07143",
    "title": "Substring Query Complexity of String Reconstruction",
    "abstract": "Comments: Submitted",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Gabriele Fici",
      "Nicola Prezza",
      "Rossano Venturini"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.07143"
  },
  {
    "id": "arXiv:2011.09553",
    "title": "A Sequence-to-Sequence Approach to Dialogue State Tracking",
    "abstract": "Comments: Accepted by ACL 2021",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Yue Feng",
      "Yang Wang",
      "Hang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2011.09553"
  },
  {
    "id": "arXiv:2011.10931",
    "title": "Primal-dual Learning for the Model-free Risk-constrained Linear  Quadratic Regulator",
    "abstract": "Comments: To appear in the Annual Conference on Learning for Dynamics and Control (L4DC) 2021",
    "descriptor": "\nComments: To appear in the Annual Conference on Learning for Dynamics and Control (L4DC) 2021\n",
    "authors": [
      "Feiran Zhao",
      "Keyou You"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.10931"
  },
  {
    "id": "arXiv:2011.13137",
    "title": "Answering Ambiguous Questions through Generative Evidence Fusion and  Round-Trip Prediction",
    "abstract": "Comments: ACL 2021 main conference, 14 pages, 7 figures. Code will be released at this https URL",
    "descriptor": "\nComments: ACL 2021 main conference, 14 pages, 7 figures. Code will be released at this https URL\n",
    "authors": [
      "Yifan Gao",
      "Henghui Zhu",
      "Patrick Ng",
      "Cicero Nogueira dos Santos",
      "Zhiguo Wang",
      "Feng Nan",
      "Dejiao Zhang",
      "Ramesh Nallapati",
      "Andrew O. Arnold",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.13137"
  },
  {
    "id": "arXiv:2011.14195",
    "title": "Recursive Association Rule Mining",
    "abstract": "Recursive Association Rule Mining",
    "descriptor": "",
    "authors": [
      "Abdelkader Mokkadem",
      "Mariane Pelletier",
      "Louis Raimbault"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2011.14195"
  },
  {
    "id": "arXiv:2011.14387",
    "title": "Overcoming Measurement Inconsistency in Deep Learning for Linear Inverse  Problems: Applications in Medical Imaging",
    "abstract": "Comments: Accepted for publication at ICASSP 2021",
    "descriptor": "\nComments: Accepted for publication at ICASSP 2021\n",
    "authors": [
      "Marija Vella",
      "Jo\u00e3o F. C. Mota"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2011.14387"
  },
  {
    "id": "arXiv:2011.15124",
    "title": "Multimodal Pretraining Unmasked: A Meta-Analysis and a Unified Framework  of Vision-and-Language BERTs",
    "abstract": "Comments: To appear in TACL 2021",
    "descriptor": "\nComments: To appear in TACL 2021\n",
    "authors": [
      "Emanuele Bugliarello",
      "Ryan Cotterell",
      "Naoaki Okazaki",
      "Desmond Elliott"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.15124"
  },
  {
    "id": "arXiv:2012.00235",
    "title": "Fractal-based belief entropy",
    "abstract": "Fractal-based belief entropy",
    "descriptor": "",
    "authors": [
      "Qianli Zhou",
      "Yong Deng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.00235"
  },
  {
    "id": "arXiv:2012.00425",
    "title": "Edge-assisted Democratized Learning Towards Federated Analytics",
    "abstract": "Comments: Accepted for publication in IEEE Internet of Things Journal",
    "descriptor": "\nComments: Accepted for publication in IEEE Internet of Things Journal\n",
    "authors": [
      "Shashi Raj Pandey",
      "Minh N.H. Nguyen",
      "Tri Nguyen Dang",
      "Nguyen H. Tran",
      "Kyi Thar",
      "Zhu Han",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2012.00425"
  },
  {
    "id": "arXiv:2012.00489",
    "title": "Deep Gravity: enhancing mobility flows generation with deep neural  networks and geographic information",
    "abstract": "Deep Gravity: enhancing mobility flows generation with deep neural  networks and geographic information",
    "descriptor": "",
    "authors": [
      "Filippo Simini",
      "Gianni Barlacchi",
      "Massimiliano Luca",
      "Luca Pappalardo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2012.00489"
  },
  {
    "id": "arXiv:2012.00572",
    "title": "Trade-offs in Decentralized Multi-Antenna Architectures: The WAX  Decomposition",
    "abstract": "Comments: 14 pages, 9 figures, submitted to IEEE Transactions on Signal Processing. arXiv admin note: text overlap with arXiv:2003.01961",
    "descriptor": "\nComments: 14 pages, 9 figures, submitted to IEEE Transactions on Signal Processing. arXiv admin note: text overlap with arXiv:2003.01961\n",
    "authors": [
      "Juan Vidal Alegr\u00eda",
      "Fredrik Rusek",
      "Ove Edfors"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.00572"
  },
  {
    "id": "arXiv:2012.01065",
    "title": "FIT: a Fast and Accurate Framework for Solving Medical Inquiring and  Diagnosing Tasks",
    "abstract": "FIT: a Fast and Accurate Framework for Solving Medical Inquiring and  Diagnosing Tasks",
    "descriptor": "",
    "authors": [
      "Weijie He",
      "Xiaohao Mao",
      "Chao Ma",
      "Yu Huang",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
      "Ting Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.01065"
  },
  {
    "id": "arXiv:2012.01708",
    "title": "Feature-Based Software Design Pattern Detection",
    "abstract": "Comments: Submitted to the Journal of Systems and Software (JSS)",
    "descriptor": "\nComments: Submitted to the Journal of Systems and Software (JSS)\n",
    "authors": [
      "Najam Nazar",
      "Aldeida Aleti",
      "Yaokun Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2012.01708"
  },
  {
    "id": "arXiv:2012.02190",
    "title": "pixelNeRF: Neural Radiance Fields from One or Few Images",
    "abstract": "Comments: CVPR 2021",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Alex Yu",
      "Vickie Ye",
      "Matthew Tancik",
      "Angjoo Kanazawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.02190"
  },
  {
    "id": "arXiv:2012.03058",
    "title": "BayLIME: Bayesian Local Interpretable Model-Agnostic Explanations",
    "abstract": "Comments: Preprint accepted by UAI2021. The final version to appear in the UAI2021 volume of Proceedings of Machine Learning Research",
    "descriptor": "\nComments: Preprint accepted by UAI2021. The final version to appear in the UAI2021 volume of Proceedings of Machine Learning Research\n",
    "authors": [
      "Xingyu Zhao",
      "Wei Huang",
      "Xiaowei Huang",
      "Valentin Robu",
      "David Flynn"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.03058"
  },
  {
    "id": "arXiv:2012.03208",
    "title": "MOCA: A Modular Object-Centric Approach for Interactive Instruction  Following",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Kunal Pratap Singh",
      "Suvaansh Bhambri",
      "Byeonghwi Kim",
      "Roozbeh Mottaghi",
      "Jonghyun Choi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.03208"
  },
  {
    "id": "arXiv:2012.03322",
    "title": "A Pseudo-labelling Auto-Encoder for unsupervised image classification",
    "abstract": "Comments: 13 pages, 17 figures, 9 tables, title simplified, references added",
    "descriptor": "\nComments: 13 pages, 17 figures, 9 tables, title simplified, references added\n",
    "authors": [
      "Aymene Mohammed Bouayed",
      "Karim Atif",
      "Rachid Deriche",
      "Abdelhakim Saim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.03322"
  },
  {
    "id": "arXiv:2012.04345",
    "title": "Large-Scale Subspace Clustering via k-Factorization",
    "abstract": "Comments: Accepted to KDD'21",
    "descriptor": "\nComments: Accepted to KDD'21\n",
    "authors": [
      "Jicong Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.04345"
  },
  {
    "id": "arXiv:2012.04705",
    "title": "Structured Index Coding Problem and Multi-access Coded Caching",
    "abstract": "Comments: 42 pages, single column",
    "descriptor": "\nComments: 42 pages, single column\n",
    "authors": [
      "Kota Srinivas Reddy",
      "Nikhil Karamchandani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2012.04705"
  },
  {
    "id": "arXiv:2012.06508",
    "title": "Confidence Estimation via Auxiliary Models",
    "abstract": "Comments: Accepted to TPAMI 2021",
    "descriptor": "\nComments: Accepted to TPAMI 2021\n",
    "authors": [
      "Charles Corbi\u00e8re",
      "Nicolas Thome",
      "Antoine Saporta",
      "Tuan-Hung Vu",
      "Matthieu Cord",
      "Patrick P\u00e9rez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.06508"
  },
  {
    "id": "arXiv:2012.09331",
    "title": "Team Assignment for Heterogeneous Multi-Robot Sensor Coverage through  Graph Representation Learning",
    "abstract": "Team Assignment for Heterogeneous Multi-Robot Sensor Coverage through  Graph Representation Learning",
    "descriptor": "",
    "authors": [
      "Brian Reily",
      "Hao Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2012.09331"
  },
  {
    "id": "arXiv:2012.09334",
    "title": "Adaptation to Team Composition Changes for Heterogeneous Multi-Robot  Sensor Coverage",
    "abstract": "Adaptation to Team Composition Changes for Heterogeneous Multi-Robot  Sensor Coverage",
    "descriptor": "",
    "authors": [
      "Brian Reily",
      "Terran Mott",
      "Hao Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2012.09334"
  },
  {
    "id": "arXiv:2012.09422",
    "title": "The Variational Method of Moments",
    "abstract": "The Variational Method of Moments",
    "descriptor": "",
    "authors": [
      "Andrew Bennett",
      "Nathan Kallus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.09422"
  },
  {
    "id": "arXiv:2012.09778",
    "title": "Interval propagation through the discrete Fourier transform",
    "abstract": "Comments: This work will appear in proceedings of the 9th international workshop on Reliable Engineering Computing",
    "descriptor": "\nComments: This work will appear in proceedings of the 9th international workshop on Reliable Engineering Computing\n",
    "authors": [
      "Marco De Angelis",
      "Marco Behrendt",
      "Liam Comerford",
      "Yuanjin Zhang",
      "Michael Beer"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.09778"
  },
  {
    "id": "arXiv:2012.10146",
    "title": "Achieving State Machine Replication without Honest Players",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Conor McMenamin",
      "Vanesa Daza",
      "Matteo Pontecorvi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2012.10146"
  },
  {
    "id": "arXiv:2012.10219",
    "title": "Resource Allocation for Improved User Experience with Live Video  Streaming in 5G",
    "abstract": "Resource Allocation for Improved User Experience with Live Video  Streaming in 5G",
    "descriptor": "",
    "authors": [
      "Fidan Mehmeti",
      "Thomas F. La Porta"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2012.10219"
  },
  {
    "id": "arXiv:2012.10644",
    "title": "A Game-Theoretic Framework for Coexistence of WiFi and Cellular Networks  in the 6-GHz Unlicensed Spectrum",
    "abstract": "Comments: 25 pages, 13 figures, 1 table. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 25 pages, 13 figures, 1 table. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Aniq Ur Rahman",
      "Mustafa A. Kishk",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.10644"
  },
  {
    "id": "arXiv:2012.11207",
    "title": "On Success and Simplicity: A Second Look at Transferable Targeted  Attacks",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Zhengyu Zhao",
      "Zhuoran Liu",
      "Martha Larson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.11207"
  },
  {
    "id": "arXiv:2012.13869",
    "title": "Neural Closure Models for Dynamical Systems",
    "abstract": "Comments: 29 pages, 9 figures, 13 pages of supplementary information",
    "descriptor": "\nComments: 29 pages, 9 figures, 13 pages of supplementary information\n",
    "authors": [
      "Abhinav Gupta",
      "Pierre F.J. Lermusiaux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2012.13869"
  },
  {
    "id": "arXiv:2012.14116",
    "title": "Syntax-Enhanced Pre-trained Model",
    "abstract": "Comments: Accepted by ACL-IJCNLP 2021: The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021: The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing\n",
    "authors": [
      "Zenan Xu",
      "Daya Guo",
      "Duyu Tang",
      "Qinliang Su",
      "Linjun Shou",
      "Ming Gong",
      "Wanjun Zhong",
      "Xiaojun Quan",
      "Nan Duan",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.14116"
  },
  {
    "id": "arXiv:2012.14240",
    "title": "DeepSurfels: Learning Online Appearance Fusion",
    "abstract": "Comments: In Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2021",
    "descriptor": "\nComments: In Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2021\n",
    "authors": [
      "Marko Mihajlovic",
      "Silvan Weder",
      "Marc Pollefeys",
      "Martin R. Oswald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.14240"
  },
  {
    "id": "arXiv:2012.14763",
    "title": "CMV-BERT: Contrastive multi-vocab pretraining of BERT",
    "abstract": "Comments: will add more detailed technical contents, and more detailed experiments",
    "descriptor": "\nComments: will add more detailed technical contents, and more detailed experiments\n",
    "authors": [
      "Wei Zhu",
      "Daniel Cheung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.14763"
  },
  {
    "id": "arXiv:2012.14827",
    "title": "Dialogue Graph Modeling for Conversational Machine Reading",
    "abstract": "Comments: Findings of ACL: ACL 2021",
    "descriptor": "\nComments: Findings of ACL: ACL 2021\n",
    "authors": [
      "Siru Ouyang",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.14827"
  },
  {
    "id": "arXiv:2012.15005",
    "title": "Infer-AVAE: An Attribute Inference Model Based on Adversarial  Variational Autoencoder",
    "abstract": "Infer-AVAE: An Attribute Inference Model Based on Adversarial  Variational Autoencoder",
    "descriptor": "",
    "authors": [
      "Yadong Zhou",
      "Zhihao Ding",
      "Xiaoming Liu",
      "Chao Shen",
      "Lingling Tong",
      "Xiaohong Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.15005"
  },
  {
    "id": "arXiv:2012.15015",
    "title": "OpenViDial: A Large-Scale, Open-Domain Dialogue Dataset with Visual  Contexts",
    "abstract": "Comments: Dataset, visual features and code are found at this https URL",
    "descriptor": "\nComments: Dataset, visual features and code are found at this https URL\n",
    "authors": [
      "Yuxian Meng",
      "Shuhe Wang",
      "Qinghong Han",
      "Xiaofei Sun",
      "Fei Wu",
      "Rui Yan",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15015"
  },
  {
    "id": "arXiv:2012.15355",
    "title": "Optimizing Deeper Transformers on Small Datasets",
    "abstract": "Comments: Accepted at ACL 2021 main conference",
    "descriptor": "\nComments: Accepted at ACL 2021 main conference\n",
    "authors": [
      "Peng Xu",
      "Dhruv Kumar",
      "Wei Yang",
      "Wenjie Zi",
      "Keyi Tang",
      "Chenyang Huang",
      "Jackie Chi Kit Cheung",
      "Simon J.D. Prince",
      "Yanshuai Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.15355"
  },
  {
    "id": "arXiv:2101.00294",
    "title": "Reader-Guided Passage Reranking for Open-Domain Question Answering",
    "abstract": "Comments: Findings of ACL 2021 Camera-ready. TLDR: Reranking retrieved passages by reader predictions can achieve 10~20 gains in top-1 retrieval accuracy and 1~4 gains in Exact Match (EM) without any training",
    "descriptor": "\nComments: Findings of ACL 2021 Camera-ready. TLDR: Reranking retrieved passages by reader predictions can achieve 10~20 gains in top-1 retrieval accuracy and 1~4 gains in Exact Match (EM) without any training\n",
    "authors": [
      "Yuning Mao",
      "Pengcheng He",
      "Xiaodong Liu",
      "Yelong Shen",
      "Jianfeng Gao",
      "Jiawei Han",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2101.00294"
  },
  {
    "id": "arXiv:2101.00434",
    "title": "Coreference Resolution without Span Representations",
    "abstract": "Comments: Accepted to ACL 2021",
    "descriptor": "\nComments: Accepted to ACL 2021\n",
    "authors": [
      "Yuval Kirstain",
      "Ori Ram",
      "Omer Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00434"
  },
  {
    "id": "arXiv:2101.00536",
    "title": "Computing Cliques and Cavities in Networks",
    "abstract": "Comments: 20 pages, 4+2 figures, 3+3 tables",
    "descriptor": "\nComments: 20 pages, 4+2 figures, 3+3 tables\n",
    "authors": [
      "Dinghua Shi",
      "Zhifeng Chen",
      "Xiang Sun",
      "Qinghua Chen",
      "Chuang Ma",
      "Yang Lou",
      "Guanrong Chen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2101.00536"
  },
  {
    "id": "arXiv:2101.00942",
    "title": "Reiterman's Theorem on Finite Algebras for a Monad",
    "abstract": "Reiterman's Theorem on Finite Algebras for a Monad",
    "descriptor": "",
    "authors": [
      "Jiri Adamek",
      "Liang-Ting Chen",
      "Stefan Milius",
      "Henning Urbat"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2101.00942"
  },
  {
    "id": "arXiv:2101.01041",
    "title": "Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust  Control Design: Implicit Regularization and Sample Complexity",
    "abstract": "Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust  Control Design: Implicit Regularization and Sample Complexity",
    "descriptor": "",
    "authors": [
      "Kaiqing Zhang",
      "Xiangyuan Zhang",
      "Bin Hu",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.01041"
  },
  {
    "id": "arXiv:2101.01300",
    "title": "A Linearly Convergent Algorithm for Distributed Principal Component  Analysis",
    "abstract": "Comments: 33 pages; 15 figures; preprint of a journal paper",
    "descriptor": "\nComments: 33 pages; 15 figures; preprint of a journal paper\n",
    "authors": [
      "Arpita Gang",
      "Waheed U. Bajwa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.01300"
  },
  {
    "id": "arXiv:2101.03187",
    "title": "Nonlinear Data-Enabled Prediction and Control",
    "abstract": "Comments: Accepted to L4DC 2021, Zurich",
    "descriptor": "\nComments: Accepted to L4DC 2021, Zurich\n",
    "authors": [
      "Yingzhao Lian",
      "Colin N.Jones"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.03187"
  },
  {
    "id": "arXiv:2101.03196",
    "title": "Sketching Merge Trees for Scientific Data Visualization",
    "abstract": "Sketching Merge Trees for Scientific Data Visualization",
    "descriptor": "",
    "authors": [
      "Mingzhe Li",
      "Sourabh Palande",
      "Lin Yan",
      "Bei Wang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.03196"
  },
  {
    "id": "arXiv:2101.04631",
    "title": "Deep Gaussian Denoiser Epistemic Uncertainty and Decoupled  Dual-Attention Fusion",
    "abstract": "Comments: Code and models are publicly available on this https URL",
    "descriptor": "\nComments: Code and models are publicly available on this https URL\n",
    "authors": [
      "Xiaoqi Ma",
      "Xiaoyu Lin",
      "Majed El Helou",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.04631"
  },
  {
    "id": "arXiv:2101.05260",
    "title": "Hand-Based Person Identification using Global and Part-Aware Deep  Feature Representation Learning",
    "abstract": "Hand-Based Person Identification using Global and Part-Aware Deep  Feature Representation Learning",
    "descriptor": "",
    "authors": [
      "Nathanael L. Baisa",
      "Zheheng Jiang",
      "Ritesh Vyas",
      "Bryan Williams",
      "Hossein Rahmani",
      "Plamen Angelov",
      "Sue Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.05260"
  },
  {
    "id": "arXiv:2101.06005",
    "title": "SimGAN: Hybrid Simulator Identification for Domain Adaptation via  Adversarial Reinforcement Learning",
    "abstract": "Comments: ICRA 2021, Code Available at: this https URL ; Accompanying Video: this https URL",
    "descriptor": "\nComments: ICRA 2021, Code Available at: this https URL ; Accompanying Video: this https URL\n",
    "authors": [
      "Yifeng Jiang",
      "Tingnan Zhang",
      "Daniel Ho",
      "Yunfei Bai",
      "C. Karen Liu",
      "Sergey Levine",
      "Jie Tan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.06005"
  },
  {
    "id": "arXiv:2101.07621",
    "title": "Trading Transforms of Non-weighted Simple Games and Integer Weights of  Weighted Simple Games",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Akihiro Kawana",
      "Tomomi Matsui"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.07621"
  },
  {
    "id": "arXiv:2101.07752",
    "title": "Characterizing and Measuring the Similarity of Neural Networks with  Persistent Homology",
    "abstract": "Characterizing and Measuring the Similarity of Neural Networks with  Persistent Homology",
    "descriptor": "",
    "authors": [
      "David P\u00e9rez-Fern\u00e1ndez",
      "Asier Guti\u00e9rrez-Fandi\u00f1o",
      "Jordi Armengol-Estap\u00e9",
      "Marta Villegas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2101.07752"
  },
  {
    "id": "arXiv:2101.08533",
    "title": "A general multi-modal data learning method for Person Re-identification",
    "abstract": "A general multi-modal data learning method for Person Re-identification",
    "descriptor": "",
    "authors": [
      "Yunpeng Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.08533"
  },
  {
    "id": "arXiv:2101.10814",
    "title": "Spread and defend infection in graphs",
    "abstract": "Spread and defend infection in graphs",
    "descriptor": "",
    "authors": [
      "Arya Tanmay Gupta"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2101.10814"
  },
  {
    "id": "arXiv:2101.10856",
    "title": "BE-RAN: Blockchain-enabled Open RAN with Decentralized Identity  Management and Privacy-Preserving Communication",
    "abstract": "BE-RAN: Blockchain-enabled Open RAN with Decentralized Identity  Management and Privacy-Preserving Communication",
    "descriptor": "",
    "authors": [
      "Hao Xu",
      "Lei Zhang",
      "Yunqing Sun",
      "Chih-Lin I"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2101.10856"
  },
  {
    "id": "arXiv:2101.11037",
    "title": "Average Localised Proximity: A new data descriptor with good default  one-class classification performance",
    "abstract": "Comments: Accepted manuscript",
    "descriptor": "\nComments: Accepted manuscript\n",
    "authors": [
      "Oliver Urs Lenz",
      "Daniel Peralta",
      "Chris Cornelis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.11037"
  },
  {
    "id": "arXiv:2101.11665",
    "title": "On Statistical Bias In Active Learning: How and When To Fix It",
    "abstract": "Comments: Published at ICLR 2021 (Spotlight)",
    "descriptor": "\nComments: Published at ICLR 2021 (Spotlight)\n",
    "authors": [
      "Sebastian Farquhar",
      "Yarin Gal",
      "Tom Rainforth"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.11665"
  },
  {
    "id": "arXiv:2101.12370",
    "title": "An Automated Theorem Proving Framework for Information-Theoretic Results",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Cheuk Ting Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.12370"
  },
  {
    "id": "arXiv:2102.01017",
    "title": "Measuring and Improving Consistency in Pretrained Language Models",
    "abstract": "Comments: Accepted to the TACL journal, pre-MIT Press publication version",
    "descriptor": "\nComments: Accepted to the TACL journal, pre-MIT Press publication version\n",
    "authors": [
      "Yanai Elazar",
      "Nora Kassner",
      "Shauli Ravfogel",
      "Abhilasha Ravichander",
      "Eduard Hovy",
      "Hinrich Sch\u00fctze",
      "Yoav Goldberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.01017"
  },
  {
    "id": "arXiv:2102.01529",
    "title": "Conditional distributions for quantum systems",
    "abstract": "Comments: 11 pages + bibliography, expanded some results and examples",
    "descriptor": "\nComments: 11 pages + bibliography, expanded some results and examples\n",
    "authors": [
      "Arthur J. Parzygnat"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Category Theory (math.CT)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/2102.01529"
  },
  {
    "id": "arXiv:2102.01828",
    "title": "Analyzing the barren plateau phenomenon in training quantum neural  networks with the ZX-calculus",
    "abstract": "Analyzing the barren plateau phenomenon in training quantum neural  networks with the ZX-calculus",
    "descriptor": "",
    "authors": [
      "Chen Zhao",
      "Xiao-Shan Gao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.01828"
  },
  {
    "id": "arXiv:2102.02494",
    "title": "Permutation-invariant quantum coding for quantum deletion channels",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Yingkai Ouyang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.02494"
  },
  {
    "id": "arXiv:2102.02959",
    "title": "Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text  Reports Using Deep Learning",
    "abstract": "Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text  Reports Using Deep Learning",
    "descriptor": "",
    "authors": [
      "Vincent M. D'Anniballe",
      "Fakrul I. Tushar",
      "Khrystyna Faryna",
      "Songyue Han",
      "Maciej A. Mazurowski",
      "Geoffrey D. Rubin",
      "Joseph Y. Lo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02959"
  },
  {
    "id": "arXiv:2102.02992",
    "title": "Learning High Dimensional Wasserstein Geodesics",
    "abstract": "Learning High Dimensional Wasserstein Geodesics",
    "descriptor": "",
    "authors": [
      "Shu Liu",
      "Shaojun Ma",
      "Yongxin Chen",
      "Hongyuan Zha",
      "Haomin Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02992"
  },
  {
    "id": "arXiv:2102.03763",
    "title": "The Balanced Mode Decomposition Algorithm for Data-Driven LPV Low-Order  Models of Aeroservoelastic Systems",
    "abstract": "Comments: Accepted for publication in Aerospace Science and Technology (open-access version available)",
    "descriptor": "\nComments: Accepted for publication in Aerospace Science and Technology (open-access version available)\n",
    "authors": [
      "Andrea Iannelli",
      "Urban Fasel",
      "Roy S. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.03763"
  },
  {
    "id": "arXiv:2102.03888",
    "title": "OPT-GAN: Global Black-box Optimization by Learning Distribution of  Optima",
    "abstract": "Comments: 12 pages, 6 figures, 2 tables, M. Lu and F. Sun contribute equally",
    "descriptor": "\nComments: 12 pages, 6 figures, 2 tables, M. Lu and F. Sun contribute equally\n",
    "authors": [
      "Minfang Lu",
      "Fengyang Sun",
      "Lin Wang",
      "Shuai Ning",
      "Shuangrong Liu",
      "Bo Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2102.03888"
  },
  {
    "id": "arXiv:2102.03973",
    "title": "Solid Texture Synthesis using Generative Adversarial Networks",
    "abstract": "Solid Texture Synthesis using Generative Adversarial Networks",
    "descriptor": "",
    "authors": [
      "Xin Zhao",
      "Jifeng Guo",
      "Lin Wang",
      "Fanqi Li",
      "Junteng Zheng",
      "Bo Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2102.03973"
  },
  {
    "id": "arXiv:2102.04776",
    "title": "Generative Models as Distributions of Functions",
    "abstract": "Comments: Added point clouds experiments, quantitative evaluations and link to github repo",
    "descriptor": "\nComments: Added point clouds experiments, quantitative evaluations and link to github repo\n",
    "authors": [
      "Emilien Dupont",
      "Yee Whye Teh",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.04776"
  },
  {
    "id": "arXiv:2102.05378",
    "title": "Origami spring-inspired shape morphing for flexible robotics",
    "abstract": "Origami spring-inspired shape morphing for flexible robotics",
    "descriptor": "",
    "authors": [
      "Qianying Chen",
      "Fan Feng",
      "Pengyu Lv",
      "Huiling Duan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Soft Condensed Matter (cond-mat.soft)"
    ],
    "url": "https://arxiv.org/abs/2102.05378"
  },
  {
    "id": "arXiv:2102.05591",
    "title": "On the Distribution of the Sum of Double-Nakagami-m Random Vectors and  Application in Randomly Reconfigurable Surfaces",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Sotiris A. Tegos",
      "Dimitrios Tyrovolas",
      "Panagiotis D. Diamantoulakis",
      "George K. Karagiannidis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2102.05591"
  },
  {
    "id": "arXiv:2102.05624",
    "title": "NAST: Non-Autoregressive Spatial-Temporal Transformer for Time Series  Forecasting",
    "abstract": "Comments: Not a satisfying work and need to be reformed",
    "descriptor": "\nComments: Not a satisfying work and need to be reformed\n",
    "authors": [
      "Kai Chen",
      "Guang Chen",
      "Dan Xu",
      "Lijun Zhang",
      "Yuyao Huang",
      "Alois Knoll"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.05624"
  },
  {
    "id": "arXiv:2102.06322",
    "title": "Joint Dereverberation and Separation with Iterative Source Steering",
    "abstract": "Comments: 5 pages, 2 figures, accepted at ICASSP 2021",
    "descriptor": "\nComments: 5 pages, 2 figures, accepted at ICASSP 2021\n",
    "authors": [
      "Taishi Nakashima",
      "Robin Scheibler",
      "Masahito Togami",
      "Nobutaka Ono"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2102.06322"
  },
  {
    "id": "arXiv:2102.06361",
    "title": "SCOUT: Socially-COnsistent and UndersTandable Graph Attention Network  for Trajectory Prediction of Vehicles and VRUs",
    "abstract": "SCOUT: Socially-COnsistent and UndersTandable Graph Attention Network  for Trajectory Prediction of Vehicles and VRUs",
    "descriptor": "",
    "authors": [
      "Sandra Carrasco",
      "David Fern\u00e1ndez Llorca",
      "Miguel \u00c1ngel Sotelo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.06361"
  },
  {
    "id": "arXiv:2102.06559",
    "title": "Infinitely Deep Bayesian Neural Networks with Stochastic Differential  Equations",
    "abstract": "Infinitely Deep Bayesian Neural Networks with Stochastic Differential  Equations",
    "descriptor": "",
    "authors": [
      "Winnie Xu",
      "Ricky T.Q. Chen",
      "Xuechen Li",
      "David Duvenaud"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06559"
  },
  {
    "id": "arXiv:2102.06613",
    "title": "Improved LP-based Approximation Algorithms for Facility Location with  Hard Capacities",
    "abstract": "Improved LP-based Approximation Algorithms for Facility Location with  Hard Capacities",
    "descriptor": "",
    "authors": [
      "Mong-Jen Kao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.06613"
  },
  {
    "id": "arXiv:2102.06648",
    "title": "A Critical Look at the Consistency of Causal Estimation With Deep Latent  Variable Models",
    "abstract": "Comments: 9 pages for main text + 19 pages for references and supplementary. 18 Figures",
    "descriptor": "\nComments: 9 pages for main text + 19 pages for references and supplementary. 18 Figures\n",
    "authors": [
      "Severi Rissanen",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06648"
  },
  {
    "id": "arXiv:2102.06674",
    "title": "A model for traffic incident prediction using emergency braking data",
    "abstract": "Comments: 6 pages, 7 figures, accepted for publication in the 32nd IEEE Intelligent Vehicles Symposium (this https URL)",
    "descriptor": "\nComments: 6 pages, 7 figures, accepted for publication in the 32nd IEEE Intelligent Vehicles Symposium (this https URL)\n",
    "authors": [
      "Alexander Reichenbach",
      "J.-Emeterio Navarro-B"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2102.06674"
  },
  {
    "id": "arXiv:2102.06758",
    "title": "Towards automatic extraction and validation of on-street parking spaces  using park-out events data",
    "abstract": "Comments: 6 pages, 8 figures, submitted to 32nd IEEE Intelligent Vehicles Symposium (this https URL)",
    "descriptor": "\nComments: 6 pages, 8 figures, submitted to 32nd IEEE Intelligent Vehicles Symposium (this https URL)\n",
    "authors": [
      "Martin Gebert",
      "J.-Emeterio Navarro-B"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06758"
  },
  {
    "id": "arXiv:2102.06765",
    "title": "Generalizing Decision Making for Automated Driving with an Invariant  Environment Representation using Deep Reinforcement Learning",
    "abstract": "Generalizing Decision Making for Automated Driving with an Invariant  Environment Representation using Deep Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Karl Kurzer",
      "Philip Sch\u00f6rner",
      "Alexander Albers",
      "Hauke Thomsen",
      "Karam Daaboul",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06765"
  },
  {
    "id": "arXiv:2102.07507",
    "title": "CLNet: Complex Input Lightweight Neural Network designed for Massive  MIMO CSI Feedback",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice\n",
    "authors": [
      "Sijie Ji",
      "Mo Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2102.07507"
  },
  {
    "id": "arXiv:2102.07594",
    "title": "Fast End-to-End Speech Recognition via Non-Autoregressive Models and  Cross-Modal Knowledge Transferring from BERT",
    "abstract": "Comments: 14 pages, 7 figures",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Ye Bai",
      "Jiangyan Yi",
      "Jianhua Tao",
      "Zhengkun Tian",
      "Zhengqi Wen",
      "Shuai Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2102.07594"
  },
  {
    "id": "arXiv:2102.07766",
    "title": "Reflecting stochastic dynamics of active-passive populations with  applications in operations research and neuroscience",
    "abstract": "Comments: 25 pages, 9 figures",
    "descriptor": "\nComments: 25 pages, 9 figures\n",
    "authors": [
      "Thi Kim Thoa Thieu",
      "Roderick Melnik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.07766"
  },
  {
    "id": "arXiv:2102.07958",
    "title": "Importance of Instruction for Pedestrian-Automated Driving Vehicle  Interaction with an External Human Machine Interface: Effects on Pedestrians'  Situation Awareness, Trust, Perceived Risks and Decision Making",
    "abstract": "Comments: 5 figures, Accepted by IEEE IV2021",
    "descriptor": "\nComments: 5 figures, Accepted by IEEE IV2021\n",
    "authors": [
      "Hailong Liu",
      "Takatsugu Hirayama",
      "Masaya Watanabe"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2102.07958"
  },
  {
    "id": "arXiv:2102.08127",
    "title": "Learning curves of generic features maps for realistic datasets with a  teacher-student model",
    "abstract": "Comments: main: 11 pages, 5 figures; appendix: 50 pages, 4 figures; v2: revised version",
    "descriptor": "\nComments: main: 11 pages, 5 figures; appendix: 50 pages, 4 figures; v2: revised version\n",
    "authors": [
      "Bruno Loureiro",
      "C\u00e9dric Gerbelot",
      "Hugo Cui",
      "Sebastian Goldt",
      "Florent Krzakala",
      "Marc M\u00e9zard",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2102.08127"
  },
  {
    "id": "arXiv:2102.08833",
    "title": "DESED-FL and URBAN-FL: Federated Learning Datasets for Sound Event  Detection",
    "abstract": "Comments: To be published in EUSIPCO 2021",
    "descriptor": "\nComments: To be published in EUSIPCO 2021\n",
    "authors": [
      "David S. Johnson",
      "Wolfgang Lorenz",
      "Michael Taenzer",
      "Stylianos Mimilakis",
      "Sascha Grollmisch",
      "Jakob Abe\u00dfer",
      "Hanna Lukashevich"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2102.08833"
  },
  {
    "id": "arXiv:2102.09397",
    "title": "Meta-Transfer Learning for Low-Resource Abstractive Summarization",
    "abstract": "Comments: Accepted by AAAI 2021; Camera Ready Version",
    "descriptor": "\nComments: Accepted by AAAI 2021; Camera Ready Version\n",
    "authors": [
      "Yi-Syuan Chen",
      "Hong-Han Shuai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09397"
  },
  {
    "id": "arXiv:2102.09468",
    "title": "Near-optimal Local Convergence of Alternating Gradient Descent-Ascent  for Minimax Optimization",
    "abstract": "Near-optimal Local Convergence of Alternating Gradient Descent-Ascent  for Minimax Optimization",
    "descriptor": "",
    "authors": [
      "Guodong Zhang",
      "Yuanhao Wang",
      "Laurent Lessard",
      "Roger Grosse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09468"
  },
  {
    "id": "arXiv:2102.11010",
    "title": "Resilience of Bayesian Layer-Wise Explanations under Adversarial Attacks",
    "abstract": "Resilience of Bayesian Layer-Wise Explanations under Adversarial Attacks",
    "descriptor": "",
    "authors": [
      "Ginevra Carbone",
      "Guido Sanguinetti",
      "Luca Bortolussi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.11010"
  },
  {
    "id": "arXiv:2102.11866",
    "title": "Doubly Robust Off-Policy Actor-Critic: Convergence and Optimality",
    "abstract": "Comments: Published in ICML 2021",
    "descriptor": "\nComments: Published in ICML 2021\n",
    "authors": [
      "Tengyu Xu",
      "Zhuoran Yang",
      "Zhaoran Wang",
      "Yingbin Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.11866"
  },
  {
    "id": "arXiv:2102.12002",
    "title": "Adversarial Robustness with Non-uniform Perturbations",
    "abstract": "Comments: 21 pages, 9 figures",
    "descriptor": "\nComments: 21 pages, 9 figures\n",
    "authors": [
      "Ecenaz Erdemir",
      "Jeffrey Bickford",
      "Luca Melis",
      "Sergul Aydore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.12002"
  },
  {
    "id": "arXiv:2102.12959",
    "title": "Undefined class-label detection vs out-of-distribution detection",
    "abstract": "Undefined class-label detection vs out-of-distribution detection",
    "descriptor": "",
    "authors": [
      "Xi Wang",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12959"
  },
  {
    "id": "arXiv:2102.13130",
    "title": "Data-Driven Methods for Present and Future Pandemics: Monitoring,  Modelling and Managing",
    "abstract": "Comments: 24 pages, 2 figures. arXiv admin note: substantial text overlap with arXiv:2006.01731",
    "descriptor": "\nComments: 24 pages, 2 figures. arXiv admin note: substantial text overlap with arXiv:2006.01731\n",
    "authors": [
      "Teodoro Alamo",
      "Daniel G. Reina",
      "Pablo Mill\u00e1n Gata",
      "Victor M. Preciado",
      "Giulia Giordano"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2102.13130"
  },
  {
    "id": "arXiv:2103.00222",
    "title": "Variational Laplace for Bayesian neural networks",
    "abstract": "Variational Laplace for Bayesian neural networks",
    "descriptor": "",
    "authors": [
      "Ali Unlu",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00222"
  },
  {
    "id": "arXiv:2103.00397",
    "title": "Data-Efficient GAN Training Beyond (Just) Augmentations: A Lottery  Ticket Perspective",
    "abstract": "Data-Efficient GAN Training Beyond (Just) Augmentations: A Lottery  Ticket Perspective",
    "descriptor": "",
    "authors": [
      "Tianlong Chen",
      "Yu Cheng",
      "Zhe Gan",
      "Jingjing Liu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.00397"
  },
  {
    "id": "arXiv:2103.00497",
    "title": "Distilling Knowledge via Intermediate Classifiers",
    "abstract": "Comments: 8 pages, 2 figures",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Aryan Asadian",
      "Amirali Salehi-Abari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.00497"
  },
  {
    "id": "arXiv:2103.00823",
    "title": "M6: A Chinese Multimodal Pretrainer",
    "abstract": "Comments: 12 pages, technical report. Extension of paper \"M6\" accepted to KDD 2021",
    "descriptor": "\nComments: 12 pages, technical report. Extension of paper \"M6\" accepted to KDD 2021\n",
    "authors": [
      "Junyang Lin",
      "Rui Men",
      "An Yang",
      "Chang Zhou",
      "Ming Ding",
      "Yichang Zhang",
      "Peng Wang",
      "Ang Wang",
      "Le Jiang",
      "Xianyan Jia",
      "Jie Zhang",
      "Jianwei Zhang",
      "Xu Zou",
      "Zhikang Li",
      "Xiaodong Deng",
      "Jie Liu",
      "Jinbao Xue",
      "Huiling Zhou",
      "Jianxin Ma",
      "Jin Yu",
      "Yong Li",
      "Wei Lin",
      "Jingren Zhou",
      "Jie Tang",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.00823"
  },
  {
    "id": "arXiv:2103.02847",
    "title": "IMG-DNA: Approximate DNA Storage for Images",
    "abstract": "Comments: 11 pages, 12 figures",
    "descriptor": "\nComments: 11 pages, 12 figures\n",
    "authors": [
      "Bingzhe Li",
      "Li Ou",
      "David Du"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2103.02847"
  },
  {
    "id": "arXiv:2103.03027",
    "title": "Modeling Multi-Label Action Dependencies for Temporal Action  Localization",
    "abstract": "Modeling Multi-Label Action Dependencies for Temporal Action  Localization",
    "descriptor": "",
    "authors": [
      "Praveen Tirupattur",
      "Kevin Duarte",
      "Yogesh Rawat",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03027"
  },
  {
    "id": "arXiv:2103.03568",
    "title": "Can Pretext-Based Self-Supervised Learning Be Boosted by Downstream  Data? A Theoretical Analysis",
    "abstract": "Can Pretext-Based Self-Supervised Learning Be Boosted by Downstream  Data? A Theoretical Analysis",
    "descriptor": "",
    "authors": [
      "Jiaye Teng",
      "Weiran Huang",
      "Haowei He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.03568"
  },
  {
    "id": "arXiv:2103.04258",
    "title": "High-Resolution Segmentation of Tooth Root Fuzzy Edge Based on  Polynomial Curve Fitting with Landmark Detection",
    "abstract": "Comments: There are some mistakes in the description of the maximum number of the shortest distances algorithm (MNSDA)",
    "descriptor": "\nComments: There are some mistakes in the description of the maximum number of the shortest distances algorithm (MNSDA)\n",
    "authors": [
      "Yunxiang Li",
      "Yifan Zhang",
      "Yaqi Wang",
      "Shuai Wang",
      "Ruizi Peng",
      "Kai Tang",
      "Qianni Zhang",
      "Jun Wang",
      "Qun Jin",
      "Lingling Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.04258"
  },
  {
    "id": "arXiv:2103.04612",
    "title": "Beyond Max-Margin: Class Margin Equilibrium for Few-shot Object  Detection",
    "abstract": "Comments: This paper has been modified by the author due to errors",
    "descriptor": "\nComments: This paper has been modified by the author due to errors\n",
    "authors": [
      "Bohao Li",
      "Boyu Yang",
      "Chang Liu",
      "Feng Liu",
      "Rongrong Ji",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.04612"
  },
  {
    "id": "arXiv:2103.05405",
    "title": "Efficient learning of goal-oriented push-grasping synergy in clutter",
    "abstract": "Efficient learning of goal-oriented push-grasping synergy in clutter",
    "descriptor": "",
    "authors": [
      "Kechun Xu",
      "Hongxiang Yu",
      "Qianen Lai",
      "Yue Wang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.05405"
  },
  {
    "id": "arXiv:2103.05734",
    "title": "The dependence of integrated, instantaneous, and fluctuating entropy  production on the initial state in quantum and classical processes",
    "abstract": "The dependence of integrated, instantaneous, and fluctuating entropy  production on the initial state in quantum and classical processes",
    "descriptor": "",
    "authors": [
      "Artemy Kolchinsky",
      "David H. Wolpert"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.05734"
  },
  {
    "id": "arXiv:2103.06518",
    "title": "Data Collection and Utilization Framework for Edge AI Applications",
    "abstract": "Data Collection and Utilization Framework for Edge AI Applications",
    "descriptor": "",
    "authors": [
      "Hergys Rexha",
      "Sebastien Lafond"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2103.06518"
  },
  {
    "id": "arXiv:2103.08562",
    "title": "Is Medical Chest X-ray Data Anonymous?",
    "abstract": "Comments: Submission to Nature Communications",
    "descriptor": "\nComments: Submission to Nature Communications\n",
    "authors": [
      "Kai Packh\u00e4user",
      "Sebastian G\u00fcndel",
      "Nicolas M\u00fcnster",
      "Christopher Syben",
      "Vincent Christlein",
      "Andreas Maier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.08562"
  },
  {
    "id": "arXiv:2103.10134",
    "title": "Recent Advances in Data-Driven Wireless Communication Using Gaussian  Processes: A Comprehensive Survey",
    "abstract": "Recent Advances in Data-Driven Wireless Communication Using Gaussian  Processes: A Comprehensive Survey",
    "descriptor": "",
    "authors": [
      "Kai Chen",
      "Qinglei Kong",
      "Yijue Dai",
      "Yue Xu",
      "Feng Yin",
      "Lexi Xu",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.10134"
  },
  {
    "id": "arXiv:2103.10710",
    "title": "Sparse Algorithms for Markovian Gaussian Processes",
    "abstract": "Comments: Appearing in the 24th International Conference on Artificial Intelligence and Statistics (AISTATS) 2021",
    "descriptor": "\nComments: Appearing in the 24th International Conference on Artificial Intelligence and Statistics (AISTATS) 2021\n",
    "authors": [
      "William J. Wilkinson",
      "Arno Solin",
      "Vincent Adam"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10710"
  },
  {
    "id": "arXiv:2103.11933",
    "title": "PatentSBERTa: A Deep NLP based Hybrid Model for Patent Distance and  Classification using Augmented SBERT",
    "abstract": "Comments: 18 pages, 7 figures and 4 Tables",
    "descriptor": "\nComments: 18 pages, 7 figures and 4 Tables\n",
    "authors": [
      "Hamid Bekamiri",
      "Daniel S. Hain",
      "Roman Jurowetzki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2103.11933"
  },
  {
    "id": "arXiv:2103.12347",
    "title": "Shared Latent Space of Font Shapes and Impressions",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Jihun Kang",
      "Daichi Haraguchi",
      "Akisato Kimura",
      "Seiichi Uchida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12347"
  },
  {
    "id": "arXiv:2103.12726",
    "title": "Policy Information Capacity: Information-Theoretic Measure for Task  Complexity in Deep Reinforcement Learning",
    "abstract": "Comments: Accepted to ICML2021. The code is available at: this https URL",
    "descriptor": "\nComments: Accepted to ICML2021. The code is available at: this https URL\n",
    "authors": [
      "Hiroki Furuta",
      "Tatsuya Matsushima",
      "Tadashi Kozuno",
      "Yutaka Matsuo",
      "Sergey Levine",
      "Ofir Nachum",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.12726"
  },
  {
    "id": "arXiv:2103.12953",
    "title": "Supporting Clustering with Contrastive Learning",
    "abstract": "Comments: NAACL 2021",
    "descriptor": "\nComments: NAACL 2021\n",
    "authors": [
      "Dejiao Zhang",
      "Feng Nan",
      "Xiaokai Wei",
      "Shangwen Li",
      "Henghui Zhu",
      "Kathleen McKeown",
      "Ramesh Nallapati",
      "Andrew Arnold",
      "Bing Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.12953"
  },
  {
    "id": "arXiv:2103.13859",
    "title": "Group-CAM: Group Score-Weighted Visual Explanations for Deep  Convolutional Networks",
    "abstract": "Comments: Group-CAM is an efficient region-based saliency method, which can be used as an effective data augmentation trick",
    "descriptor": "\nComments: Group-CAM is an efficient region-based saliency method, which can be used as an effective data augmentation trick\n",
    "authors": [
      "Qinglong Zhang",
      "Lu Rao",
      "Yubin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.13859"
  },
  {
    "id": "arXiv:2103.14835",
    "title": "LiBRe: A Practical Bayesian Approach to Adversarial Detection",
    "abstract": "Comments: IEEE/ CVF International Conference on Computer Vision and Pattern Recognition (CVPR), 2021",
    "descriptor": "\nComments: IEEE/ CVF International Conference on Computer Vision and Pattern Recognition (CVPR), 2021\n",
    "authors": [
      "Zhijie Deng",
      "Xiao Yang",
      "Shizhen Xu",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14835"
  },
  {
    "id": "arXiv:2103.14919",
    "title": "You Can Do Better! If You Elaborate the Reason When Making Prediction",
    "abstract": "Comments: 14 pages, 1 figure, 7 tables",
    "descriptor": "\nComments: 14 pages, 1 figure, 7 tables\n",
    "authors": [
      "Dongfang Li",
      "Jingcong Tao",
      "Qingcai Chen",
      "Baotian Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.14919"
  },
  {
    "id": "arXiv:2103.15624",
    "title": "Shape-constrained Symbolic Regression -- Improving Extrapolation with  Prior Knowledge",
    "abstract": "Shape-constrained Symbolic Regression -- Improving Extrapolation with  Prior Knowledge",
    "descriptor": "",
    "authors": [
      "Gabriel Kronberger",
      "Fabricio Olivetti de Fran\u00e7a",
      "Bogdan Burlacu",
      "Christian Haider",
      "Michael Kommenda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.15624"
  },
  {
    "id": "arXiv:2103.16336",
    "title": "Model-based clustering of partial records",
    "abstract": "Comments: 14 pages, 4 figures, 1 table",
    "descriptor": "\nComments: 14 pages, 4 figures, 1 table\n",
    "authors": [
      "Emily M. Goren",
      "Ranjan Maitra"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.16336"
  },
  {
    "id": "arXiv:2103.16681",
    "title": "On-Chain Auctions with Deposits",
    "abstract": "On-Chain Auctions with Deposits",
    "descriptor": "",
    "authors": [
      "Jan Christoph Schlegel",
      "Akaki Mamageishvili"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2103.16681"
  },
  {
    "id": "arXiv:2103.16704",
    "title": "Probabilistic Analogical Mapping with Semantic Relation Networks",
    "abstract": "Probabilistic Analogical Mapping with Semantic Relation Networks",
    "descriptor": "",
    "authors": [
      "Hongjing Lu",
      "Nicholas Ichien",
      "Keith J. Holyoak"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.16704"
  },
  {
    "id": "arXiv:2103.17258",
    "title": "Co-Adaptation of Algorithmic and Implementational Innovations in  Inference-based Deep Reinforcement Learning",
    "abstract": "Comments: The implementation is available at: this https URL",
    "descriptor": "\nComments: The implementation is available at: this https URL\n",
    "authors": [
      "Hiroki Furuta",
      "Tadashi Kozuno",
      "Tatsuya Matsushima",
      "Yutaka Matsuo",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.17258"
  },
  {
    "id": "arXiv:2104.01398",
    "title": "Block Scrambling Image Encryption Used in Combination with Data  Augmentation for Privacy-Preserving DNNs",
    "abstract": "Comments: To be appeared in IEEE ICCE-TW 2021",
    "descriptor": "\nComments: To be appeared in IEEE ICCE-TW 2021\n",
    "authors": [
      "Tatsuya Chuman",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.01398"
  },
  {
    "id": "arXiv:2104.01577",
    "title": "Class-incremental Learning using a Sequence of Partial Implicitly  Regularized Classifiers",
    "abstract": "Class-incremental Learning using a Sequence of Partial Implicitly  Regularized Classifiers",
    "descriptor": "",
    "authors": [
      "Sobirdzhon Bobiev",
      "Adil Khan",
      "Syed Muhammad Ahsan Raza Kazmi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.01577"
  },
  {
    "id": "arXiv:2104.01808",
    "title": "Frequency Estimation Under Multiparty Differential Privacy: One-shot and  Streaming",
    "abstract": "Frequency Estimation Under Multiparty Differential Privacy: One-shot and  Streaming",
    "descriptor": "",
    "authors": [
      "Ziyue Huang",
      "Yuan Qiu",
      "Ke Yi",
      "Graham Cormode"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.01808"
  },
  {
    "id": "arXiv:2104.02141",
    "title": "Feedback linearization of nonlinear differential-algebraic control  systems",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Yahao Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.02141"
  },
  {
    "id": "arXiv:2104.02739",
    "title": "Differentially Private Histograms in the Shuffle Model from Fake Users",
    "abstract": "Comments: 29 pages. May 3 updates: (1) experiments that compared results with prior work. (2) moved count-min section to the main body (3) expanded introduction May 29 updates: (1) further improved introduction (2) enhanced reduction in communication complexity (3) included reference to GKMP20 protocol",
    "descriptor": "\nComments: 29 pages. May 3 updates: (1) experiments that compared results with prior work. (2) moved count-min section to the main body (3) expanded introduction May 29 updates: (1) further improved introduction (2) enhanced reduction in communication complexity (3) included reference to GKMP20 protocol\n",
    "authors": [
      "Albert Cheu",
      "Maxim Zhilyaev"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.02739"
  },
  {
    "id": "arXiv:2104.02963",
    "title": "The art of defense: letting networks fool the attacker",
    "abstract": "The art of defense: letting networks fool the attacker",
    "descriptor": "",
    "authors": [
      "Jinlai Zhang",
      "Binbin Liu",
      "Lyvjie Chen",
      "Bo Ouyang",
      "Jihong Zhu",
      "Minchi Kuang",
      "Houqing Wang",
      "Yanmei Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.02963"
  },
  {
    "id": "arXiv:2104.03224",
    "title": "Efficient and Accurate In-Database Machine Learning with SQL Code  Generation in Python",
    "abstract": "Efficient and Accurate In-Database Machine Learning with SQL Code  Generation in Python",
    "descriptor": "",
    "authors": [
      "Michael Kaufmann",
      "Gabriel Stechschulte",
      "Anna Huber"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.03224"
  },
  {
    "id": "arXiv:2104.04132",
    "title": "Replay in Deep Learning: Current Approaches and Missing Biological  Elements",
    "abstract": "Comments: Accepted for publication in the MIT Press journal of Neural Computation",
    "descriptor": "\nComments: Accepted for publication in the MIT Press journal of Neural Computation\n",
    "authors": [
      "Tyler L. Hayes",
      "Giri P. Krishnan",
      "Maxim Bazhenov",
      "Hava T. Siegelmann",
      "Terrence J. Sejnowski",
      "Christopher Kanan"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.04132"
  },
  {
    "id": "arXiv:2104.04547",
    "title": "High-Throughput Virtual Screening of Small Molecule Inhibitors for  SARS-CoV-2 Protein Targets with Deep Fusion Models",
    "abstract": "High-Throughput Virtual Screening of Small Molecule Inhibitors for  SARS-CoV-2 Protein Targets with Deep Fusion Models",
    "descriptor": "",
    "authors": [
      "Garrett A. Stevenson",
      "Derek Jones",
      "Hyojin Kim",
      "W. F. Drew Bennett",
      "Brian J. Bennion",
      "Monica Borucki",
      "Feliza Bourguet",
      "Aidan Epstein",
      "Magdalena Franco",
      "Brooke Harmon",
      "Stewart He",
      "Max P. Katz",
      "Daniel Kirshner",
      "Victoria Lao",
      "Edmond Y. Lau",
      "Jacky Lo",
      "Kevin McLoughlin",
      "Richard Mosesso",
      "Deepa K. Murugesh",
      "Oscar A. Negrete",
      "Edwin A. Saada",
      "Brent Segelke",
      "Maxwell Stefan",
      "Marisa W. Torres",
      "Dina Weilhammer",
      "Sergio Wong",
      "Yue Yang",
      "Adam Zemla",
      "Xiaohua Zhang",
      "Fangqiang Zhu",
      "Felice C. Lightstone",
      "Jonathan E. Allen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2104.04547"
  },
  {
    "id": "arXiv:2104.04692",
    "title": "Not All Attention Is All You Need",
    "abstract": "Not All Attention Is All You Need",
    "descriptor": "",
    "authors": [
      "Hongqiu Wu",
      "Hai Zhao",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.04692"
  },
  {
    "id": "arXiv:2104.05003",
    "title": "Multiple Run Ensemble Learning with Low-Dimensional Knowledge Graph  Embeddings",
    "abstract": "Comments: Accepted by the 2021 International Joint Conference on Neural Networks (IJCNN 2021)",
    "descriptor": "\nComments: Accepted by the 2021 International Joint Conference on Neural Networks (IJCNN 2021)\n",
    "authors": [
      "Chengjin Xu",
      "Mojtaba Nayyeri",
      "Sahar Vahdati",
      "Jens Lehmann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.05003"
  },
  {
    "id": "arXiv:2104.06135",
    "title": "Multivariate Deep Evidential Regression",
    "abstract": "Comments: 20 pages, 13 figures",
    "descriptor": "\nComments: 20 pages, 13 figures\n",
    "authors": [
      "Nis Meinert",
      "Alexander Lavin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.06135"
  },
  {
    "id": "arXiv:2104.06624",
    "title": "Device-Cloud Collaborative Learning for Recommendation",
    "abstract": "Comments: KDD 2021",
    "descriptor": "\nComments: KDD 2021\n",
    "authors": [
      "Jiangchao Yao",
      "Feng Wang",
      "KunYang Jia",
      "Bo Han",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.06624"
  },
  {
    "id": "arXiv:2104.08452",
    "title": "ALGAMES: A Fast Augmented Lagrangian Solver for Constrained Dynamic  Games",
    "abstract": "Comments: Submitted to Autonomous Robots (under review) as an extension of a paper accepted to RSS 2020. arXiv admin note: text overlap with arXiv:1910.09713",
    "descriptor": "\nComments: Submitted to Autonomous Robots (under review) as an extension of a paper accepted to RSS 2020. arXiv admin note: text overlap with arXiv:1910.09713\n",
    "authors": [
      "Simon Le Cleac'h",
      "Mac Schwager",
      "Zachary Manchester"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.08452"
  },
  {
    "id": "arXiv:2104.08755",
    "title": "DCH-2: A Parallel Customer-Helpdesk Dialogue Corpus with Distributions  of Annotators' Labels",
    "abstract": "Comments: 6 pages, 3 figures",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Zhaohao Zeng",
      "Tetsuya Sakai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2104.08755"
  },
  {
    "id": "arXiv:2104.10649",
    "title": "K-XLNet: A General Method for Combining Explicit Knowledge with Language  Model Pretraining",
    "abstract": "K-XLNet: A General Method for Combining Explicit Knowledge with Language  Model Pretraining",
    "descriptor": "",
    "authors": [
      "Ruiqing Yan",
      "Lanchang Sun",
      "Fang Wang",
      "Xiaoming Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.10649"
  },
  {
    "id": "arXiv:2104.10762",
    "title": "Image Distribution Estimation with Random Field and Random Cluster  Theories",
    "abstract": "Image Distribution Estimation with Random Field and Random Cluster  Theories",
    "descriptor": "",
    "authors": [
      "Robert A. Murphy"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.10762"
  },
  {
    "id": "arXiv:2104.10831",
    "title": "LVI-SAM: Tightly-coupled Lidar-Visual-Inertial Odometry via Smoothing  and Mapping",
    "abstract": "LVI-SAM: Tightly-coupled Lidar-Visual-Inertial Odometry via Smoothing  and Mapping",
    "descriptor": "",
    "authors": [
      "Tixiao Shan",
      "Brendan Englot",
      "Carlo Ratti",
      "Daniela Rus"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.10831"
  },
  {
    "id": "arXiv:2104.10903",
    "title": "Blockchain based Privacy-Preserved Federated Learning for Medical  Images: A Case Study of COVID-19 CT Scans",
    "abstract": "Comments: 15 Pages, 5 Tables, 11 Figures, Journal Paper, Elsevier format",
    "descriptor": "\nComments: 15 Pages, 5 Tables, 11 Figures, Journal Paper, Elsevier format\n",
    "authors": [
      "Rajesh Kumar",
      "WenYong Wang",
      "Cheng Yuan",
      "Jay Kumar",
      "Zakria",
      "He Qing",
      "Ting Yang",
      "Abdullah Aman Khan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.10903"
  },
  {
    "id": "arXiv:2104.12146",
    "title": "3D Adversarial Attacks Beyond Point Cloud",
    "abstract": "Comments: 9 pages, 5 figs",
    "descriptor": "\nComments: 9 pages, 5 figs\n",
    "authors": [
      "Jinlai Zhang",
      "Lyujie Chen",
      "Binbin Liu",
      "Bo Ouyang",
      "Qizhi Xie",
      "Jihong Zhu",
      "Weiming Li",
      "Yanmei Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.12146"
  },
  {
    "id": "arXiv:2104.12174",
    "title": "Demystification of Few-shot and One-shot Learning",
    "abstract": "Comments: IEEE International Joint Conference on Neural Networks, IJCNN 2021",
    "descriptor": "\nComments: IEEE International Joint Conference on Neural Networks, IJCNN 2021\n",
    "authors": [
      "Ivan Y. Tyukin",
      "Alexander N. Gorban",
      "Muhammad H. Alkhudaydi",
      "Qinghua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2104.12174"
  },
  {
    "id": "arXiv:2104.14060",
    "title": "WGCN: Graph Convolutional Networks with Weighted Structural Features",
    "abstract": "WGCN: Graph Convolutional Networks with Weighted Structural Features",
    "descriptor": "",
    "authors": [
      "Yunxiang Zhao",
      "Jianzhong Qi",
      "Qingwei Liu",
      "Rui Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.14060"
  },
  {
    "id": "arXiv:2104.14074",
    "title": "Statistical Inference with M-Estimators on Adaptively Collected Data",
    "abstract": "Statistical Inference with M-Estimators on Adaptively Collected Data",
    "descriptor": "",
    "authors": [
      "Kelly W. Zhang",
      "Lucas Janson",
      "Susan A. Murphy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14074"
  },
  {
    "id": "arXiv:2104.14118",
    "title": "REGRAD: A Large-Scale Relational Grasp Dataset for Safe and  Object-Specific Robotic Grasping in Clutter",
    "abstract": "REGRAD: A Large-Scale Relational Grasp Dataset for Safe and  Object-Specific Robotic Grasping in Clutter",
    "descriptor": "",
    "authors": [
      "Hanbo Zhang",
      "Deyu Yang",
      "Han Wang",
      "Binglei Zhao",
      "Xuguang Lan",
      "Jishiyu Ding",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14118"
  },
  {
    "id": "arXiv:2104.14654",
    "title": "Agent-Level Maximum Entropy Inverse Reinforcement Learning for Mean  Field Games",
    "abstract": "Agent-Level Maximum Entropy Inverse Reinforcement Learning for Mean  Field Games",
    "descriptor": "",
    "authors": [
      "Yang Chen",
      "Jiamou Liu",
      "Bakhadyr Khoussainov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14654"
  },
  {
    "id": "arXiv:2105.00132",
    "title": "Targeting the Weakest Link: Social Engineering Attacks in Ethereum Smart  Contracts",
    "abstract": "Comments: ACM ASIA Conference on Computer and Communications Security 2021, 15 pages",
    "descriptor": "\nComments: ACM ASIA Conference on Computer and Communications Security 2021, 15 pages\n",
    "authors": [
      "Nikolay Ivanov",
      "Jianzhi Lou",
      "Ting Chen",
      "Jin Li",
      "Qiben Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.00132"
  },
  {
    "id": "arXiv:2105.00149",
    "title": "SVT-Net: Super Light-Weight Sparse Voxel Transformer for Large Scale  Place Recognition",
    "abstract": "Comments: 14 pages, 7 figures",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Zhaoxin Fan",
      "Zhenbo Song",
      "Hongyan Liu",
      "Zhiwu Lu",
      "Jun He",
      "Xiaoyong Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.00149"
  },
  {
    "id": "arXiv:2105.00174",
    "title": "Blockchain-Based Decentralized Energy Management Platform for  Residential Distributed Energy Resources in A Virtual Power Plant",
    "abstract": "Blockchain-Based Decentralized Energy Management Platform for  Residential Distributed Energy Resources in A Virtual Power Plant",
    "descriptor": "",
    "authors": [
      "Qing Yang",
      "Hao Wang",
      "Taotao Wang",
      "Shengli Zhang",
      "Xiaoxiao Wu",
      "Hui Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.00174"
  },
  {
    "id": "arXiv:2105.00175",
    "title": "Distributed Energy Trading Management for Renewable Prosumers with HVAC  and Energy Storage",
    "abstract": "Distributed Energy Trading Management for Renewable Prosumers with HVAC  and Energy Storage",
    "descriptor": "",
    "authors": [
      "Qing Yang",
      "Hao Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.00175"
  },
  {
    "id": "arXiv:2105.00368",
    "title": "MarkerPose: Robust Real-time Planar Target Tracking for Accurate Stereo  Pose Estimation",
    "abstract": "Comments: Accepted at CVPR 2021 LXCV Workshop",
    "descriptor": "\nComments: Accepted at CVPR 2021 LXCV Workshop\n",
    "authors": [
      "Jhacson Meza",
      "Lenny A. Romero",
      "Andres G. Marrugo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.00368"
  },
  {
    "id": "arXiv:2105.00385",
    "title": "pyBKT: An Accessible Python Library of Bayesian Knowledge Tracing Models",
    "abstract": "Comments: Accepted to the 2021 Conference on Educational Data Mining (EDM '21)",
    "descriptor": "\nComments: Accepted to the 2021 Conference on Educational Data Mining (EDM '21)\n",
    "authors": [
      "Anirudhan Badrinath",
      "Frederic Wang",
      "Zachary Pardos"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00385"
  },
  {
    "id": "arXiv:2105.01275",
    "title": "Graph Pooling via Coarsened Graph Infomax",
    "abstract": "Graph Pooling via Coarsened Graph Infomax",
    "descriptor": "",
    "authors": [
      "Yunsheng Pang",
      "Yunxiang Zhao",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.01275"
  },
  {
    "id": "arXiv:2105.01648",
    "title": "On Lottery Tickets and Minimal Task Representations in Deep  Reinforcement Learning",
    "abstract": "Comments: 15 pages, 11 figures",
    "descriptor": "\nComments: 15 pages, 11 figures\n",
    "authors": [
      "Marc Aurel Vischer",
      "Robert Tjarko Lange",
      "Henning Sprekeler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.01648"
  },
  {
    "id": "arXiv:2105.02358",
    "title": "Beyond Self-attention: External Attention using Two Linear Layers for  Visual Tasks",
    "abstract": "Comments: 11 pages, 6 figures. external attention and EAMLP",
    "descriptor": "\nComments: 11 pages, 6 figures. external attention and EAMLP\n",
    "authors": [
      "Meng-Hao Guo",
      "Zheng-Ning Liu",
      "Tai-Jiang Mu",
      "Shi-Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.02358"
  },
  {
    "id": "arXiv:2105.02446",
    "title": "DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism",
    "abstract": "Comments: acoustic model, singing voice synthesis, text to speech, diffusion model, shallow diffusion",
    "descriptor": "\nComments: acoustic model, singing voice synthesis, text to speech, diffusion model, shallow diffusion\n",
    "authors": [
      "Jinglin Liu",
      "Chengxi Li",
      "Yi Ren",
      "Feiyang Chen",
      "Peng Liu",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.02446"
  },
  {
    "id": "arXiv:2105.03070",
    "title": "SpeechNet: A Universal Modularized Model for Speech Processing Tasks",
    "abstract": "SpeechNet: A Universal Modularized Model for Speech Processing Tasks",
    "descriptor": "",
    "authors": [
      "Yi-Chen Chen",
      "Po-Han Chi",
      "Shu-wen Yang",
      "Kai-Wei Chang",
      "Jheng-hao Lin",
      "Sung-Feng Huang",
      "Da-Rong Liu",
      "Chi-Liang Liu",
      "Cheng-Kuang Lee",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.03070"
  },
  {
    "id": "arXiv:2105.03074",
    "title": "Leakage-Resilient Secret Sharing with Constant Share Size",
    "abstract": "Leakage-Resilient Secret Sharing with Constant Share Size",
    "descriptor": "",
    "authors": [
      "Ivan Tjuawinata",
      "Chaoping Xing"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.03074"
  },
  {
    "id": "arXiv:2105.03075",
    "title": "A Survey of Data Augmentation Approaches for NLP",
    "abstract": "Comments: Accepted to ACL 2021 Findings. GitHub repo with paper list at this https URL",
    "descriptor": "\nComments: Accepted to ACL 2021 Findings. GitHub repo with paper list at this https URL\n",
    "authors": [
      "Steven Y. Feng",
      "Varun Gangal",
      "Jason Wei",
      "Sarath Chandar",
      "Soroush Vosoughi",
      "Teruko Mitamura",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03075"
  },
  {
    "id": "arXiv:2105.03571",
    "title": "Comprehensive Study: How the Context Information of Different  Granularity Affects Dialogue State Tracking?",
    "abstract": "Comments: Accepted as long paper at main conference of ACL 2021",
    "descriptor": "\nComments: Accepted as long paper at main conference of ACL 2021\n",
    "authors": [
      "Puhai Yang",
      "Heyan Huang",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03571"
  },
  {
    "id": "arXiv:2105.03620",
    "title": "ABCNet v2: Adaptive Bezier-Curve Network for Real-time End-to-end Text  Spotting",
    "abstract": "Comments: Table 7 updated. Code is at: this https URL Journal extension of arXiv:2002.10200",
    "descriptor": "\nComments: Table 7 updated. Code is at: this https URL Journal extension of arXiv:2002.10200\n",
    "authors": [
      "Yuliang Liu",
      "Chunhua Shen",
      "Lianwen Jin",
      "Tong He",
      "Peng Chen",
      "Chongyu Liu",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03620"
  },
  {
    "id": "arXiv:2105.03801",
    "title": "Long-Span Summarization via Local Attention and Content Selection",
    "abstract": "Comments: ACL 2021 (camera-ready)",
    "descriptor": "\nComments: ACL 2021 (camera-ready)\n",
    "authors": [
      "Potsawee Manakul",
      "Mark J. F. Gales"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03801"
  },
  {
    "id": "arXiv:2105.04037",
    "title": "Graph Attention Networks with Positional Embeddings",
    "abstract": "Graph Attention Networks with Positional Embeddings",
    "descriptor": "",
    "authors": [
      "Liheng Ma",
      "Reihaneh Rabbany",
      "Adriana Romero-Soriano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04037"
  },
  {
    "id": "arXiv:2105.04062",
    "title": "Approximate Fr\u00e9chet Mean for Data Sets of Sparse Graphs",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Daniel Ferguson",
      "Fran\u00e7ois G. Meyer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04062"
  },
  {
    "id": "arXiv:2105.04075",
    "title": "CFPNet-M: A Light-Weight Encoder-Decoder Based Network for Multimodal  Biomedical Image Real-Time Segmentation",
    "abstract": "CFPNet-M: A Light-Weight Encoder-Decoder Based Network for Multimodal  Biomedical Image Real-Time Segmentation",
    "descriptor": "",
    "authors": [
      "Ange Lou",
      "Shuyue Guan",
      "Murray Loew"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.04075"
  },
  {
    "id": "arXiv:2105.04297",
    "title": "How could Neural Networks understand Programs?",
    "abstract": "How could Neural Networks understand Programs?",
    "descriptor": "",
    "authors": [
      "Dinglan Peng",
      "Shuxin Zheng",
      "Yatao Li",
      "Guolin Ke",
      "Di He",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.04297"
  },
  {
    "id": "arXiv:2105.04350",
    "title": "tFold-TR: Combining Deep Learning Enhanced Hybrid Potential Energy for  Template-Based Modeling Structure Refinement",
    "abstract": "Comments: 28 pages, 9 figures",
    "descriptor": "\nComments: 28 pages, 9 figures\n",
    "authors": [
      "Liangzhen Zheng",
      "Haidong Lan",
      "Tao Shen",
      "Jiaxiang Wu",
      "Sheng Wang",
      "Wei Liu",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04350"
  },
  {
    "id": "arXiv:2105.04771",
    "title": "EBM-Fold: Fully-Differentiable Protein Folding Powered by Energy-based  Models",
    "abstract": "Comments: 18 pages, 12 figures",
    "descriptor": "\nComments: 18 pages, 12 figures\n",
    "authors": [
      "Jiaxiang Wu",
      "Shitong Luo",
      "Tao Shen",
      "Haidong Lan",
      "Sheng Wang",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04771"
  },
  {
    "id": "arXiv:2105.04776",
    "title": "Graph Consistency Based Mean-Teaching for Unsupervised Domain Adaptive  Person Re-Identification",
    "abstract": "Comments: IJCAI 2021",
    "descriptor": "\nComments: IJCAI 2021\n",
    "authors": [
      "Xiaobin Liu",
      "Shiliang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04776"
  },
  {
    "id": "arXiv:2105.04854",
    "title": "Improving Molecular Graph Neural Network Explainability with  Orthonormalization and Induced Sparsity",
    "abstract": "Comments: Accepted to ICML 2021",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Ryan Henderson",
      "Djork-Arn\u00e9 Clevert",
      "Floriane Montanari"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04854"
  },
  {
    "id": "arXiv:2105.04944",
    "title": "Predicting Gene-Disease Associations with Knowledge Graph Embeddings  over Multiple Ontologies",
    "abstract": "Comments: 4 pages, 1 figure, 2 tables",
    "descriptor": "\nComments: 4 pages, 1 figure, 2 tables\n",
    "authors": [
      "Susana Nunes",
      "Rita T. Sousa",
      "Catia Pesquita"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04944"
  },
  {
    "id": "arXiv:2105.05172",
    "title": "The explicit formula of the distributions of the nonoverlapping words  and its applications to statistical tests for random numbers",
    "abstract": "The explicit formula of the distributions of the nonoverlapping words  and its applications to statistical tests for random numbers",
    "descriptor": "",
    "authors": [
      "Hayato Takahashi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.05172"
  },
  {
    "id": "arXiv:2105.05418",
    "title": "Could you give me a hint? Generating inference graphs for defeasible  reasoning",
    "abstract": "Comments: Findings of the Association for Computational Linguistics: ACL 2021",
    "descriptor": "\nComments: Findings of the Association for Computational Linguistics: ACL 2021\n",
    "authors": [
      "Aman Madaan",
      "Dheeraj Rajagopal",
      "Niket Tandon",
      "Yiming Yang",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.05418"
  },
  {
    "id": "arXiv:2105.05498",
    "title": "Improving Lexically Constrained Neural Machine Translation with  Source-Conditioned Masked Span Prediction",
    "abstract": "Comments: To appear in ACL 2021",
    "descriptor": "\nComments: To appear in ACL 2021\n",
    "authors": [
      "Gyubok Lee",
      "Seongjun Yang",
      "Edward Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.05498"
  },
  {
    "id": "arXiv:2105.05553",
    "title": "Principal Components Bias in Deep Neural Networks",
    "abstract": "Principal Components Bias in Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Guy Hacohen",
      "Daphna Weinshall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.05553"
  },
  {
    "id": "arXiv:2105.05624",
    "title": "Turning the Tables: The View from Offshore During 60 Days in JST",
    "abstract": "Comments: 10 pages, 5 figures, 8 references",
    "descriptor": "\nComments: 10 pages, 5 figures, 8 references\n",
    "authors": [
      "James J. Cusick"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.05624"
  },
  {
    "id": "arXiv:2105.06625",
    "title": "Biometrics: Trust, but Verify",
    "abstract": "Comments: 20 pages, 15 figures",
    "descriptor": "\nComments: 20 pages, 15 figures\n",
    "authors": [
      "Anil K. Jain",
      "Debayan Deb",
      "Joshua J. Engelsma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.06625"
  },
  {
    "id": "arXiv:2105.06762",
    "title": "DialogSum: A Real-Life Scenario Dialogue Summarization Dataset",
    "abstract": "Comments: ACL findings",
    "descriptor": "\nComments: ACL findings\n",
    "authors": [
      "Yulong Chen",
      "Yang Liu",
      "Liang Chen",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.06762"
  },
  {
    "id": "arXiv:2105.06813",
    "title": "A cost-benefit analysis of cross-lingual transfer methods",
    "abstract": "A cost-benefit analysis of cross-lingual transfer methods",
    "descriptor": "",
    "authors": [
      "Guilherme Moraes Rosa",
      "Luiz Henrique Bonifacio",
      "Leandro Rodrigues de Souza",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.06813"
  },
  {
    "id": "arXiv:2105.07283",
    "title": "Calibrating sufficiently",
    "abstract": "Comments: 19 pages, 2 figures, appendices",
    "descriptor": "\nComments: 19 pages, 2 figures, appendices\n",
    "authors": [
      "Dirk Tasche"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.07283"
  },
  {
    "id": "arXiv:2105.07400",
    "title": "The interplay between language similarity and script on a novel  multi-layer Algerian dialect corpus",
    "abstract": "Comments: Accepted at Findings of ACL: ACL2021",
    "descriptor": "\nComments: Accepted at Findings of ACL: ACL2021\n",
    "authors": [
      "Samia Touileb",
      "Jeremy Barnes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.07400"
  },
  {
    "id": "arXiv:2105.07428",
    "title": "Openwifi CSI fuzzer for authorized sensing and covert channels",
    "abstract": "Comments: Accepted by ACM WiSec 2021",
    "descriptor": "\nComments: Accepted by ACM WiSec 2021\n",
    "authors": [
      "Xianjun Jiao",
      "Michael Mehari",
      "Wei Liu",
      "Muhammad Aslam",
      "Ingrid Moerman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.07428"
  },
  {
    "id": "arXiv:2105.07464",
    "title": "Few-NERD: A Few-Shot Named Entity Recognition Dataset",
    "abstract": "Comments: Accepted by ACL-IJCNLP 2021 (long paper)",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021 (long paper)\n",
    "authors": [
      "Ning Ding",
      "Guangwei Xu",
      "Yulin Chen",
      "Xiaobin Wang",
      "Xu Han",
      "Pengjun Xie",
      "Hai-Tao Zheng",
      "Zhiyuan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.07464"
  },
  {
    "id": "arXiv:2105.07574",
    "title": "SoundFence: Securing Ultrasonic Sensors in Vehicles Using Physical-Layer  Defense",
    "abstract": "SoundFence: Securing Ultrasonic Sensors in Vehicles Using Physical-Layer  Defense",
    "descriptor": "",
    "authors": [
      "Jianzhi Lou",
      "Qiben Yan",
      "Qing Hui",
      "Huacheng Zeng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.07574"
  },
  {
    "id": "arXiv:2105.07585",
    "title": "Leveraging Two Types of Global Graph for Sequential Fashion  Recommendation",
    "abstract": "Leveraging Two Types of Global Graph for Sequential Fashion  Recommendation",
    "descriptor": "",
    "authors": [
      "Yujuan Ding",
      "Yunshan Ma",
      "Wai Keung Wong",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2105.07585"
  },
  {
    "id": "arXiv:2105.07592",
    "title": "Dermoscopic Image Classification with Neural Style Transfer",
    "abstract": "Comments: 32 pages, 11 figures",
    "descriptor": "\nComments: 32 pages, 11 figures\n",
    "authors": [
      "Yutong Li",
      "Ruoqing Zhu",
      "Annie Qu",
      "Mike Yeh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.07592"
  },
  {
    "id": "arXiv:2105.07739",
    "title": "Toward the Design of Fault-Tolerance- and Peak- Power-Aware Multi-Core  Mixed-Criticality Systems",
    "abstract": "Comments: This is an extended version of the paper accepted to be published in IEEE TCAD 2021 which includes Appendices A-E",
    "descriptor": "\nComments: This is an extended version of the paper accepted to be published in IEEE TCAD 2021 which includes Appendices A-E\n",
    "authors": [
      "Behnaz Ranjbar",
      "Ali Hosseinghorban",
      "Mohammad Salehi",
      "Alireza Ejlali",
      "Akash Kumar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.07739"
  },
  {
    "id": "arXiv:2105.08021",
    "title": "Stage-wise Fine-tuning for Graph-to-Text Generation",
    "abstract": "Comments: 10 pages, Accepted by Proceedings of ACL-IJCNLP 2021 Student Research Workshop, Code and Resources at this https URL",
    "descriptor": "\nComments: 10 pages, Accepted by Proceedings of ACL-IJCNLP 2021 Student Research Workshop, Code and Resources at this https URL\n",
    "authors": [
      "Qingyun Wang",
      "Semih Yavuz",
      "Victoria Lin",
      "Heng Ji",
      "Nazneen Rajani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.08021"
  },
  {
    "id": "arXiv:2105.08039",
    "title": "Fine-grained Interpretation and Causation Analysis in Deep NLP Models",
    "abstract": "Comments: Accepted at NAACL Tutorial",
    "descriptor": "\nComments: Accepted at NAACL Tutorial\n",
    "authors": [
      "Hassan Sajjad",
      "Narine Kokhlikyan",
      "Fahim Dalvi",
      "Nadir Durrani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.08039"
  },
  {
    "id": "arXiv:2105.08095",
    "title": "Automatic Fault Detection for Deep Learning Programs Using Graph  Transformations",
    "abstract": "Automatic Fault Detection for Deep Learning Programs Using Graph  Transformations",
    "descriptor": "",
    "authors": [
      "Amin Nikanjam",
      "Houssem Ben Braiek",
      "Mohammad Mehdi Morovati",
      "Foutse Khomh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.08095"
  },
  {
    "id": "arXiv:2105.08620",
    "title": "Detecting Adversarial Examples with Bayesian Neural Network",
    "abstract": "Detecting Adversarial Examples with Bayesian Neural Network",
    "descriptor": "",
    "authors": [
      "Yao Li",
      "Tongyi Tang",
      "Cho-Jui Hsieh",
      "Thomas C. M. Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08620"
  },
  {
    "id": "arXiv:2105.08675",
    "title": "The Computational Complexity of ReLU Network Training Parameterized by  Data Dimensionality",
    "abstract": "The Computational Complexity of ReLU Network Training Parameterized by  Data Dimensionality",
    "descriptor": "",
    "authors": [
      "Vincent Froese",
      "Christoph Hertrich",
      "Rolf Niedermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.08675"
  },
  {
    "id": "arXiv:2105.08869",
    "title": "Incentivized Bandit Learning with Self-Reinforcing User Preferences",
    "abstract": "Incentivized Bandit Learning with Self-Reinforcing User Preferences",
    "descriptor": "",
    "authors": [
      "Tianchen Zhou",
      "Jia Liu",
      "Chaosheng Dong",
      "Jingyuan Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.08869"
  },
  {
    "id": "arXiv:2105.09085",
    "title": "Combining GCN and Transformer for Chinese Grammatical Error Detection",
    "abstract": "Combining GCN and Transformer for Chinese Grammatical Error Detection",
    "descriptor": "",
    "authors": [
      "Jinhong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.09085"
  },
  {
    "id": "arXiv:2105.09365",
    "title": "Exploring The Limits Of Data Augmentation For Retinal Vessel  Segmentation",
    "abstract": "Comments: 7 pages, 2 figures",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Enes Sadi Uysal",
      "M.\u015eafak Bilici",
      "B. Selin Zaza",
      "M. Yi\u011fit \u00d6zgen\u00e7",
      "Onur Boyar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09365"
  },
  {
    "id": "arXiv:2105.09509",
    "title": "Adaptive Knowledge-Enhanced Bayesian Meta-Learning for Few-shot Event  Detection",
    "abstract": "Comments: Accepted by ACL2021 Findings",
    "descriptor": "\nComments: Accepted by ACL2021 Findings\n",
    "authors": [
      "Shirong Shen",
      "Tongtong Wu",
      "Guilin Qi",
      "Yuan-Fang Li",
      "Gholamreza Haffari",
      "Sheng Bi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.09509"
  },
  {
    "id": "arXiv:2105.09553",
    "title": "A New Dynamic Optimal Relay Selection and RF interfaces Setting  Algorithm (DORSA) in M2M for IoT Applications",
    "abstract": "A New Dynamic Optimal Relay Selection and RF interfaces Setting  Algorithm (DORSA) in M2M for IoT Applications",
    "descriptor": "",
    "authors": [
      "Monireh Allah Gholi Ghasri",
      "Ali Mohammad Afshin Hemmatyar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.09553"
  },
  {
    "id": "arXiv:2105.09917",
    "title": "Neural networks with superexpressive activations and integer weights",
    "abstract": "Neural networks with superexpressive activations and integer weights",
    "descriptor": "",
    "authors": [
      "Aleksandr Beknazaryan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09917"
  },
  {
    "id": "arXiv:2105.09984",
    "title": "Multi-modal Sarcasm Detection and Humor Classification in Code-mixed  Conversations",
    "abstract": "Comments: 13 pages, 4 figures, 9 tables",
    "descriptor": "\nComments: 13 pages, 4 figures, 9 tables\n",
    "authors": [
      "Manjot Bedi",
      "Shivani Kumar",
      "Md Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.09984"
  },
  {
    "id": "arXiv:2105.09992",
    "title": "Don't Do What Doesn't Matter: Intrinsic Motivation with Action  Usefulness",
    "abstract": "Comments: Accepted at Internationnal Joint Conference on Artificial Intelligence (IJCAI'21) and Self-Supervision for Reinforcement Learning Workshop (SSL-RL @ICLR'21)",
    "descriptor": "\nComments: Accepted at Internationnal Joint Conference on Artificial Intelligence (IJCAI'21) and Self-Supervision for Reinforcement Learning Workshop (SSL-RL @ICLR'21)\n",
    "authors": [
      "Mathieu Seurin",
      "Florian Strub",
      "Philippe Preux",
      "Olivier Pietquin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09992"
  },
  {
    "id": "arXiv:2105.10077",
    "title": "Anomaly Mining -- Past, Present and Future",
    "abstract": "Comments: 6 pages",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.10077"
  },
  {
    "id": "arXiv:2105.10588",
    "title": "Soft robotic suits: State of the art, core technologies and open  challenges",
    "abstract": "Comments: Accepted as a Survey Paper on IEEE Transaction on Robotics",
    "descriptor": "\nComments: Accepted as a Survey Paper on IEEE Transaction on Robotics\n",
    "authors": [
      "Michele Xiloyannis",
      "Ryan Alicea",
      "Anna-Maria Georgarakis",
      "Florian L. Haufe",
      "Peter Wolf",
      "Lorenzo Masia",
      "Robert Riener"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.10588"
  },
  {
    "id": "arXiv:2105.10591",
    "title": "Detecting Treatment Effect Modifiers in Social Networks",
    "abstract": "Detecting Treatment Effect Modifiers in Social Networks",
    "descriptor": "",
    "authors": [
      "Amir Gilad",
      "Harsh Parikh",
      "Babak Salimi",
      "Sudeepa Roy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.10591"
  },
  {
    "id": "arXiv:2105.10852",
    "title": "Latency of Concatenating Unlicensed LPWAN with Cellular IoT: An  Experimental QoE Study",
    "abstract": "Comments: Experimental dataset is openly available here: this https URL",
    "descriptor": "\nComments: Experimental dataset is openly available here: this https URL\n",
    "authors": [
      "Alvin Ramoutar",
      "Zohreh Motamedi",
      "Mouhamed Abdulla"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Hardware Architecture (cs.AR)",
      "Information Theory (cs.IT)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.10852"
  },
  {
    "id": "arXiv:2105.11098",
    "title": "Prevent the Language Model from being Overconfident in Neural Machine  Translation",
    "abstract": "Comments: Accepted as a long paper at ACL 2021. Code is available at: this https URL",
    "descriptor": "\nComments: Accepted as a long paper at ACL 2021. Code is available at: this https URL\n",
    "authors": [
      "Mengqi Miao",
      "Fandong Meng",
      "Yijin Liu",
      "Xiao-Hua Zhou",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.11098"
  },
  {
    "id": "arXiv:2105.11225",
    "title": "Distantly-Supervised Long-Tailed Relation Extraction Using Constraint  Graphs",
    "abstract": "Distantly-Supervised Long-Tailed Relation Extraction Using Constraint  Graphs",
    "descriptor": "",
    "authors": [
      "Tianming Liang",
      "Yang Liu",
      "Xiaoyan Liu",
      "Gaurav Sharma",
      "Maozu Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.11225"
  },
  {
    "id": "arXiv:2105.11237",
    "title": "SiamRCR: Reciprocal Classification and Regression for Visual Object  Tracking",
    "abstract": "Comments: The 30th International Joint Conference on Artificial Intelligence (IJCAI 2021)",
    "descriptor": "\nComments: The 30th International Joint Conference on Artificial Intelligence (IJCAI 2021)\n",
    "authors": [
      "Jinlong Peng",
      "Zhengkai Jiang",
      "Yueyang Gu",
      "Yang Wu",
      "Yabiao Wang",
      "Ying Tai",
      "Chengjie Wang",
      "Weiyao Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11237"
  },
  {
    "id": "arXiv:2105.11259",
    "title": "PTR: Prompt Tuning with Rules for Text Classification",
    "abstract": "PTR: Prompt Tuning with Rules for Text Classification",
    "descriptor": "",
    "authors": [
      "Xu Han",
      "Weilin Zhao",
      "Ning Ding",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.11259"
  },
  {
    "id": "arXiv:2105.11522",
    "title": "Unbiased Estimation of the Gradient of the Log-Likelihood for a Class of  Continuous-Time State-Space Models",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Marco Ballesio",
      "Ajay Jasra"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.11522"
  },
  {
    "id": "arXiv:2105.11545",
    "title": "Uncertainty-Aware Signal Temporal Logic Inference",
    "abstract": "Comments: 11 pages, 7 figures, 2 tables",
    "descriptor": "\nComments: 11 pages, 7 figures, 2 tables\n",
    "authors": [
      "Nasim Baharisangari",
      "Jean-Rapha\u00ebl Gaglione",
      "Daniel Neider",
      "Ufuk Topcu",
      "Zhe Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.11545"
  },
  {
    "id": "arXiv:2105.11592",
    "title": "A Holistic View on Resource Management in Serverless Computing  Environments: Taxonomy, and Future Directions",
    "abstract": "Comments: 32 pages, 4 figures",
    "descriptor": "\nComments: 32 pages, 4 figures\n",
    "authors": [
      "Anupama Mampage",
      "Shanika Karunasekera",
      "Rajkumar Buyya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.11592"
  },
  {
    "id": "arXiv:2105.11686",
    "title": "Towards Understanding the Condensation of Two-layer Neural Networks at  Initial Training",
    "abstract": "Towards Understanding the Condensation of Two-layer Neural Networks at  Initial Training",
    "descriptor": "",
    "authors": [
      "Zhi-Qin John Xu",
      "Hanxu Zhou",
      "Tao Luo",
      "Yaoyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.11686"
  },
  {
    "id": "arXiv:2105.11752",
    "title": "Argument Undermining: Counter-Argument Generation by Attacking Weak  Premises",
    "abstract": "Comments: 9 pages, 3 figures",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Milad Alshomary",
      "Shahbaz Syed",
      "Arkajit Dhar",
      "Martin Potthast",
      "Henning Wachsmuth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.11752"
  },
  {
    "id": "arXiv:2105.11763",
    "title": "Efficiently Explaining CSPs with Unsatisfiable Subset Optimization",
    "abstract": "Efficiently Explaining CSPs with Unsatisfiable Subset Optimization",
    "descriptor": "",
    "authors": [
      "Emilio Gamba",
      "Bart Bogaerts",
      "Tias Guns"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.11763"
  },
  {
    "id": "arXiv:2105.12247",
    "title": "Graph Self Supervised Learning: the BT, the HSIC, and the VICReg",
    "abstract": "Graph Self Supervised Learning: the BT, the HSIC, and the VICReg",
    "descriptor": "",
    "authors": [
      "Sayan Nag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.12247"
  },
  {
    "id": "arXiv:2105.12273",
    "title": "Collision Recovery Control of a Foldable Quadrotor",
    "abstract": "Comments: 7 pages, 9 figures, accepted for publication in IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM) 2021",
    "descriptor": "\nComments: 7 pages, 9 figures, accepted for publication in IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM) 2021\n",
    "authors": [
      "Karishma Patnaik",
      "Shatadal Mishra",
      "Zachary Chase",
      "Wenlong Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.12273"
  },
  {
    "id": "arXiv:2105.12697",
    "title": "Intriguing Parameters of Structural Causal Models",
    "abstract": "Comments: Main paper: 9 pages, References: 2 pages, Supplement: 2 pages. Main paper: 3 figures, Supplement: 1 figure",
    "descriptor": "\nComments: Main paper: 9 pages, References: 2 pages, Supplement: 2 pages. Main paper: 3 figures, Supplement: 1 figure\n",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.12697"
  },
  {
    "id": "arXiv:2105.12827",
    "title": "Massive MIMO Adaptive Modulation and Coding Using Online Deep Learning",
    "abstract": "Comments: The paper has been submitted to the IEEE WCL journal and has 4 pages and 6 figures",
    "descriptor": "\nComments: The paper has been submitted to the IEEE WCL journal and has 4 pages and 6 figures\n",
    "authors": [
      "Evgeny Bobrov",
      "Dmitry Kropotov",
      "Hao Lu",
      "Danila Zaev"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.12827"
  },
  {
    "id": "arXiv:2105.12848",
    "title": "BERTifying the Hidden Markov Model for Multi-Source Weakly Supervised  Named Entity Recognition",
    "abstract": "BERTifying the Hidden Markov Model for Multi-Source Weakly Supervised  Named Entity Recognition",
    "descriptor": "",
    "authors": [
      "Yinghao Li",
      "Pranav Shetty",
      "Lucas Liu",
      "Chao Zhang",
      "Le Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.12848"
  },
  {
    "id": "arXiv:2105.12969",
    "title": "Improve Query Focused Abstractive Summarization by Incorporating Answer  Relevance",
    "abstract": "Comments: The two authors contribute equally. Accepted as a short paper in Findings of ACL 2021",
    "descriptor": "\nComments: The two authors contribute equally. Accepted as a short paper in Findings of ACL 2021\n",
    "authors": [
      "Dan Su",
      "Tiezheng Yu",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.12969"
  },
  {
    "id": "arXiv:2105.12972",
    "title": "Tight Lower Bounds for $\u03b1$-Divergences Under Moment Constraints and  Relations Between Different $\u03b1$",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Tomohiro Nishiyama"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.12972"
  },
  {
    "id": "arXiv:2105.13099",
    "title": "On the Universality of Graph Neural Networks on Large Random Graphs",
    "abstract": "On the Universality of Graph Neural Networks on Large Random Graphs",
    "descriptor": "",
    "authors": [
      "Nicolas Keriven",
      "Alberto Bietti",
      "Samuel Vaiter"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13099"
  },
  {
    "id": "arXiv:2105.13183",
    "title": "An Efficient Style Virtual Try on Network for Clothing Business Industry",
    "abstract": "Comments: 10 pages,9 figures",
    "descriptor": "\nComments: 10 pages,9 figures\n",
    "authors": [
      "Shanchen Pang",
      "Xixi Tao",
      "Neal N. Xiong",
      "Yukun Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13183"
  },
  {
    "id": "arXiv:2105.13228",
    "title": "Optimization Induced Equilibrium Networks",
    "abstract": "Optimization Induced Equilibrium Networks",
    "descriptor": "",
    "authors": [
      "Xingyu Xie",
      "Qiuhao Wang",
      "Zenan Ling",
      "Xia Li",
      "Yisen Wang",
      "Guangcan Liu",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.13228"
  },
  {
    "id": "arXiv:2105.13290",
    "title": "CogView: Mastering Text-to-Image Generation via Transformers",
    "abstract": "CogView: Mastering Text-to-Image Generation via Transformers",
    "descriptor": "",
    "authors": [
      "Ming Ding",
      "Zhuoyi Yang",
      "Wenyi Hong",
      "Wendi Zheng",
      "Chang Zhou",
      "Da Yin",
      "Junyang Lin",
      "Xu Zou",
      "Zhou Shao",
      "Hongxia Yang",
      "Jie Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13290"
  },
  {
    "id": "arXiv:2105.13345",
    "title": "Adversarial Intrinsic Motivation for Reinforcement Learning",
    "abstract": "Adversarial Intrinsic Motivation for Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Ishan Durugkar",
      "Mauricio Tec",
      "Scott Niekum",
      "Peter Stone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13345"
  },
  {
    "id": "arXiv:2105.13353",
    "title": "Unsupervised Activity Segmentation by Joint Representation Learning and  Online Clustering",
    "abstract": "Comments: Preprint. Under review",
    "descriptor": "\nComments: Preprint. Under review\n",
    "authors": [
      "Sateesh Kumar",
      "Sanjay Haresh",
      "Awais Ahmed",
      "Andrey Konin",
      "M. Zeeshan Zia",
      "Quoc-Huy Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13353"
  },
  {
    "id": "arXiv:2105.13396",
    "title": "Comparing Models for Extracting the Backbone of Bipartite Projections",
    "abstract": "Comparing Models for Extracting the Backbone of Bipartite Projections",
    "descriptor": "",
    "authors": [
      "Zachary P. Neal",
      "Rachel Domagalski",
      "Bruce Sagan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.13396"
  },
  {
    "id": "arXiv:2105.13480",
    "title": "Efficient distributed algorithms for Convolutional Neural Networks",
    "abstract": "Comments: Proceedings of the 33rd ACM Symposium on Parallelism in Algorithms and Architectures (SPAA '21), July 6--8, 2021, Virtual Event, USA",
    "descriptor": "\nComments: Proceedings of the 33rd ACM Symposium on Parallelism in Algorithms and Architectures (SPAA '21), July 6--8, 2021, Virtual Event, USA\n",
    "authors": [
      "Rui Li",
      "Yufan Xu",
      "Aravind Sukumaran-Rajam",
      "Atanas Rountev",
      "P Sadayappan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13480"
  },
  {
    "id": "arXiv:2105.13562",
    "title": "ILDC for CJPE: Indian Legal Documents Corpus for Court Judgment  Prediction and Explanation",
    "abstract": "Comments: Accepted at ACL 2021, 17 Pages (9 Pages main paper, 4 pages references, 4 pages appendix)",
    "descriptor": "\nComments: Accepted at ACL 2021, 17 Pages (9 Pages main paper, 4 pages references, 4 pages appendix)\n",
    "authors": [
      "Vijit Malik",
      "Rishabh Sanjay",
      "Shubham Kumar Nigam",
      "Kripa Ghosh",
      "Shouvik Kumar Guha",
      "Arnab Bhattacharya",
      "Ashutosh Modi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13562"
  },
  {
    "id": "arXiv:2105.13574",
    "title": "Parallel Programming Applied Research Projects for Teaching Parallel  Programming to Beginner Students",
    "abstract": "Parallel Programming Applied Research Projects for Teaching Parallel  Programming to Beginner Students",
    "descriptor": "",
    "authors": [
      "Youry Khmelevsky",
      "Gaetan J.D.R. Hains"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.13574"
  },
  {
    "id": "arXiv:2105.13607",
    "title": "Alleviating the Knowledge-Language Inconsistency: A Study for Deep  Commonsense Knowledge",
    "abstract": "Alleviating the Knowledge-Language Inconsistency: A Study for Deep  Commonsense Knowledge",
    "descriptor": "",
    "authors": [
      "Yi Zhang",
      "Lei Li",
      "Yunfang Wu",
      "Qi Su",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13607"
  },
  {
    "id": "arXiv:2105.13636",
    "title": "The Power of Log-Sum-Exp: Sequential Density Ratio Matrix Estimation for  Speed-Accuracy Optimization",
    "abstract": "Comments: Accepted to International Conference on Machine Learning (ICML) 2021",
    "descriptor": "\nComments: Accepted to International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Taiki Miyagawa",
      "Akinori F. Ebihara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13636"
  },
  {
    "id": "arXiv:2105.13648",
    "title": "Cross-Lingual Abstractive Summarization with Limited Parallel Resources",
    "abstract": "Comments: Accepted by ACL2021",
    "descriptor": "\nComments: Accepted by ACL2021\n",
    "authors": [
      "Yu Bai",
      "Yang Gao",
      "Heyan Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13648"
  },
  {
    "id": "arXiv:2105.13677",
    "title": "ResT: An Efficient Transformer for Visual Recognition",
    "abstract": "Comments: ResT is an efficient multi-scale vision Transformer that can tackle input images with arbitrary size. arXiv admin note: text overlap with arXiv:2103.14030 by other authors",
    "descriptor": "\nComments: ResT is an efficient multi-scale vision Transformer that can tackle input images with arbitrary size. arXiv admin note: text overlap with arXiv:2103.14030 by other authors\n",
    "authors": [
      "Qinglong Zhang",
      "Yubin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13677"
  },
  {
    "id": "arXiv:2105.13728",
    "title": "An Explanatory Query-Based Framework for Exploring Academic Expertise",
    "abstract": "An Explanatory Query-Based Framework for Exploring Academic Expertise",
    "descriptor": "",
    "authors": [
      "Oana Cocarascu",
      "Andrew McLean",
      "Paul French",
      "Francesca Toni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13728"
  },
  {
    "id": "arXiv:2105.13753",
    "title": "New Image Captioning Encoder via Semantic Visual Feature Matching for  Heavy Rain Images",
    "abstract": "New Image Captioning Encoder via Semantic Visual Feature Matching for  Heavy Rain Images",
    "descriptor": "",
    "authors": [
      "Chang-Hwan Son",
      "Pung-Hwi Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13753"
  },
  {
    "id": "arXiv:2105.13865",
    "title": "Recursive Contour Saliency Blending Network for Accurate Salient Object  Detection",
    "abstract": "Recursive Contour Saliency Blending Network for Accurate Salient Object  Detection",
    "descriptor": "",
    "authors": [
      "Yi Ke Yun",
      "Chun Wei Tan",
      "Takahiro Tsubono"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13865"
  },
  {
    "id": "arXiv:2105.13945",
    "title": "Quantum Optimisation of Complex Systems with a Quantum Annealer",
    "abstract": "Comments: 24 pages, 19 figures, V2 (replaced fig. 13 b)",
    "descriptor": "\nComments: 24 pages, 19 figures, V2 (replaced fig. 13 b)\n",
    "authors": [
      "Steve Abel",
      "Andrew Blance",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.13945"
  }
]
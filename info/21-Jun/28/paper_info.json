[
  {
    "id": "arXiv:2106.13233",
    "title": "Post Selections Using Test Sets (PSUTS) and How Developmental Networks  Avoid Them",
    "abstract": "This paper raises a rarely reported practice in Artificial Intelligence (AI)\ncalled Post Selection Using Test Sets (PSUTS). Consequently, the popular\nerror-backprop methodology in deep learning lacks an acceptable generalization\npower. All AI methods fall into two broad schools, connectionist and symbolic.\nThe PSUTS fall into two kinds, machine PSUTS and human PSUTS. The connectionist\nschool received criticisms for its \"scruffiness\" due to a huge number of\nnetwork parameters and now the worse machine PSUTS; but the seemingly \"clean\"\nsymbolic school seems more brittle because of a weaker generalization power\nusing human PSUTS. This paper formally defines what PSUTS is, analyzes why\nerror-backprop methods with random initial weights suffer from severe local\nminima, why PSUTS violates well-established research ethics, and how every\npaper that used PSUTS should have at least transparently reported PSUTS. For\nimproved transparency in future publications, this paper proposes a new\nstandard for performance evaluation of AI, called developmental errors for all\nnetworks trained, along with Three Learning Conditions: (1) an incremental\nlearning architecture, (2) a training experience and (3) a limited amount of\ncomputational resources. Developmental Networks avoid PSUTS and are not\n\"scruffy\" because they drive Emergent Turing Machines and are optimal in the\nsense of maximum-likelihood across lifetime.",
    "descriptor": "\nComments: 13 pages, 2 figures. The first part has been accepted as an IJCNN 2021 paper and the second has been accepted as an ICDL 2021 paper\n",
    "authors": [
      "Juyang Weng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.13233"
  },
  {
    "id": "arXiv:2106.13237",
    "title": "Towards Exploiting Geometry and Time for FastOff-Distribution Adaptation  in Multi-Task RobotLearning",
    "abstract": "We explore possible methods for multi-task transfer learning which seek to\nexploit the shared physical structure of robotics tasks. Specifically, we train\npolicies for a base set of pre-training tasks, then experiment with adapting to\nnew off-distribution tasks, using simple architectural approaches for re-using\nthese policies as black-box priors. These approaches include learning an\nalignment of either the observation space or action space from a base to a\ntarget task to exploit rigid body structure, and methods for learning a\ntime-domain switching policy across base tasks which solves the target task, to\nexploit temporal coherence. We find that combining low-complexity target policy\nclasses, base policies as black-box priors, and simple optimization algorithms\nallows us to acquire new tasks outside the base task distribution, using small\namounts of offline training data.",
    "descriptor": "\nComments: Accepted to Challenges of Real World Reinforcement Learning, Virtual Workshop at NeurIPS 2020\n",
    "authors": [
      "K.R. Zentner",
      "Ryan Julian",
      "Ujjwal Puri",
      "Yulun Zhang",
      "Gaurav Sukhatme"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13237"
  },
  {
    "id": "arXiv:2106.13238",
    "title": "Hate Speech Detection in Clubhouse",
    "abstract": "With high prevalence of offensive language against the minorities in social\nmedia, counter hate speech generation is considered as an automatic way to\ntackle this challenge. The counter hate speeches are supposed to appear as a\nthird voice to educate people and keep the social red lines bold without\nlimiting the freedom of speech principles. The counter hate speech generation\nis based on the optimistic assumption that, any attempt to intervene the hate\nspeeches in social media can play a positive role in this context. Beyond that,\nprevious works ignored to investigate the sequence of comments before and after\ncounter speech. To the best of our knowledge, no attempt has been made to\nmeasure the counter hate speech impact from statistical point of view. In this\npaper, we take the first step in this direction by measuring the counter hate\nspeech impact on the next comments in terms of Google Perspective Scores.\nFurthermore, our experiments show that, counter hate speech can cause negative\nimpacts, a phenomena which is called aggression in social media.",
    "descriptor": "\nComments: Accepted paper in International KDD Workshop on Misinformation and Misbehavior Mining on the Web 2021\n",
    "authors": [
      "Hadi Mansourifar",
      "Dana Alsagheer",
      "Reza Fathi",
      "Weidong Shi",
      "Lan Ni",
      "Yan Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13238"
  },
  {
    "id": "arXiv:2106.13239",
    "title": "Federated Noisy Client Learning",
    "abstract": "Federated learning (FL) collaboratively aggregates a shared global model\ndepending on multiple local clients, while keeping the training data\ndecentralized in order to preserve data privacy. However, standard FL methods\nignore the noisy client issue, which may harm the overall performance of the\naggregated model. In this paper, we first analyze the noisy client statement,\nand then model noisy clients with different noise distributions (e.g.,\nBernoulli and truncated Gaussian distributions). To learn with noisy clients,\nwe propose a simple yet effective FL framework, named Federated Noisy Client\nLearning (Fed-NCL), which is a plug-and-play algorithm and contains two main\ncomponents: a data quality measurement (DQM) to dynamically quantify the data\nquality of each participating client, and a noise robust aggregation (NRA) to\nadaptively aggregate the local models of each client by jointly considering the\namount of local training data and the data quality of each client. Our Fed-NCL\ncan be easily applied in any standard FL workflow to handle the noisy client\nissue. Experimental results on various datasets demonstrate that our algorithm\nboosts the performances of different state-of-the-art systems with noisy\nclients.",
    "descriptor": "",
    "authors": [
      "Li Li",
      "Huazhu Fu",
      "Bo Han",
      "Cheng-Zhong Xu",
      "Ling Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.13239"
  },
  {
    "id": "arXiv:2106.13241",
    "title": "A fuzzy take on the logical issues of statistical hypothesis testing",
    "abstract": "Statistical Hypothesis Testing (SHT) is a class of inference methods whereby\none makes use of empirical data to test a hypothesis and often emit a judgment\nabout whether to reject it or not. In this paper we focus on the logical aspect\nof this strategy, which is largely independent of the adopted school of\nthought, at least within the various frequentist approaches. We identify SHT as\ntaking the form of an unsound argument from Modus Tollens in classical logic,\nand, in order to rescue SHT from this difficulty, we propose that it can\ninstead be grounded in t-norm based fuzzy logics. We reformulate the\nfrequentists' SHT logic by making use of a fuzzy extension of modus Tollens to\ndevelop a model of truth valuation for its premises. Importantly, we show that\nit is possible to preserve the soundness of Modus Tollens by exploring the\nvarious conventions involved with constructing fuzzy negations and fuzzy\nimplications (namely, the S and R conventions). We find that under the S\nconvention, it is possible to conduct the Modus Tollens inference argument\nusing Zadeh's compositional extension and any possible t-norm. Under the R\nconvention we find that this is not necessarily the case, but that by mixing\nR-implication with S-negation we can salvage the product t-norm, for example.\nIn conclusion, we have shown that fuzzy logic is a legitimate framework to\ndiscuss and address the difficulties plaguing frequentist interpretations of\nSHT.",
    "descriptor": "\nComments: 15 pages, 3 figures. Preprint version of an amended version of the article published in Philosophies 2021, 6(1), 21\n",
    "authors": [
      "Matthew Booth",
      "Fabien Paillusson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "History and Philosophy of Physics (physics.hist-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.13241"
  },
  {
    "id": "arXiv:2106.13249",
    "title": "Modeling the Mistakes of Boundedly Rational Agents Within a Bayesian  Theory of Mind",
    "abstract": "When inferring the goals that others are trying to achieve, people\nintuitively understand that others might make mistakes along the way. This is\ncrucial for activities such as teaching, offering assistance, and deciding\nbetween blame or forgiveness. However, Bayesian models of theory of mind have\ngenerally not accounted for these mistakes, instead modeling agents as mostly\noptimal in achieving their goals. As a result, they are unable to explain\nphenomena like locking oneself out of one's house, or losing a game of chess.\nHere, we extend the Bayesian Theory of Mind framework to model boundedly\nrational agents who may have mistaken goals, plans, and actions. We formalize\nthis by modeling agents as probabilistic programs, where goals may be confused\nwith semantically similar states, plans may be misguided due to\nresource-bounded planning, and actions may be unintended due to execution\nerrors. We present experiments eliciting human goal inferences in two domains:\n(i) a gridworld puzzle with gems locked behind doors, and (ii) a block-stacking\ndomain. Our model better explains human inferences than alternatives, while\ngeneralizing across domains. These findings indicate the importance of modeling\nothers as bounded agents, in order to account for the full richness of human\nintuitive psychology.",
    "descriptor": "\nComments: Accepted to CogSci 2021. 6 pages, 5 figures. (Appendix: 1 page, 1 figure)\n",
    "authors": [
      "Arwa Alanqary",
      "Gloria Z. Lin",
      "Joie Le",
      "Tan Zhi-Xuan",
      "Vikash K. Mansinghka",
      "Joshua B. Tenenbaum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.13249"
  },
  {
    "id": "arXiv:2106.13263",
    "title": "AKER: A Design and Verification Framework for Safe andSecure SoC Access  Control",
    "abstract": "Modern systems on a chip (SoCs) utilize heterogeneous architectures where\nmultiple IP cores have concurrent access to on-chip shared resources. In\nsecurity-critical applications, IP cores have different privilege levels for\naccessing shared resources, which must be regulated by an access control\nsystem. AKER is a design and verification framework for SoC access control.\nAKER builds upon the Access Control Wrapper (ACW) -- a high performance and\neasy-to-integrate hardware module that dynamically manages access to shared\nresources. To build an SoC access control system, AKER distributes the ACWs\nthroughout the SoC, wrapping controller IP cores, and configuring the ACWs to\nperform local access control. To ensure the access control system is\nfunctioning correctly and securely, AKER provides a property-driven security\nverification using MITRE common weakness enumerations. AKER verifies the SoC\naccess control at the IP level to ensure the absence of bugs in the\nfunctionalities of the ACW module, at the firmware level to confirm the secure\noperation of the ACW when integrated with a hardware root-of-trust (HRoT), and\nat the system level to evaluate security threats due to the interactions among\nshared resources. The performance, resource usage, and security of access\ncontrol systems implemented through AKER is experimentally evaluated on a\nXilinx UltraScale+ programmable SoC, it is integrated with the OpenTitan\nhardware root-of-trust, and it is used to design an access control system for\nthe OpenPULP multicore architecture.",
    "descriptor": "",
    "authors": [
      "Francesco Restuccia",
      "Andres Meza",
      "Ryan Kastner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.13263"
  },
  {
    "id": "arXiv:2106.13264",
    "title": "You are AllSet: A Multiset Function Framework for Hypergraph Neural  Networks",
    "abstract": "Hypergraphs are used to model higher-order interactions amongst agents and\nthere exist many practically relevant instances of hypergraph datasets. To\nenable efficient processing of hypergraph-structured data, several hypergraph\nneural network platforms have been proposed for learning hypergraph properties\nand structure, with a special focus on node classification. However, almost all\nexisting methods use heuristic propagation rules and offer suboptimal\nperformance on many datasets. We propose AllSet, a new hypergraph neural\nnetwork paradigm that represents a highly general framework for (hyper)graph\nneural networks and for the first time implements hypergraph neural network\nlayers as compositions of two multiset functions that can be efficiently\nlearned for each task and each dataset. Furthermore, AllSet draws on new\nconnections between hypergraph neural networks and recent advances in deep\nlearning of multiset functions. In particular, the proposed architecture\nutilizes Deep Sets and Set Transformer architectures that allow for significant\nmodeling flexibility and offer high expressive power. To evaluate the\nperformance of AllSet, we conduct the most extensive experiments to date\ninvolving ten known benchmarking datasets and three newly curated datasets that\nrepresent significant challenges for hypergraph node classification. The\nresults demonstrate that AllSet has the unique ability to consistently either\nmatch or outperform all other hypergraph neural networks across the tested\ndatasets. Our implementation and dataset will be released upon acceptance.",
    "descriptor": "",
    "authors": [
      "Eli Chien",
      "Chao Pan",
      "Jianhao Peng",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13264"
  },
  {
    "id": "arXiv:2106.13265",
    "title": "Disease Progression Modeling Workbench 360",
    "abstract": "In this work we introduce Disease Progression Modeling workbench 360 (DPM360)\nopensource clinical informatics framework for collaborative research and\ndelivery of healthcare AI. DPM360, when fully developed, will manage the entire\nmodeling life cycle, from data analysis (e.g., cohort identification) to\nmachine learning algorithm development and prototyping. DPM360 augments the\nadvantages of data model standardization and tooling (OMOP-CDM, Athena, ATLAS)\nprovided by the widely-adopted OHDSI initiative with a powerful machine\nlearning training framework, and a mechanism for rapid prototyping through\nautomatic deployment of models as containerized services to a cloud\nenvironment.",
    "descriptor": "\nComments: Submitted to OHDSI Collaborator Showcase, 2021 (this https URL)\n",
    "authors": [
      "Parthasarathy Suryanarayanan",
      "Prithwish Chakraborty",
      "Piyush Madan",
      "Kibichii Bore",
      "William Ogallo",
      "Rachita Chandra",
      "Mohamed Ghalwash",
      "Italo Buleje",
      "Sekou Remy",
      "Shilpa Mahatma",
      "Pablo Meyer",
      "Jianying Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.13265"
  },
  {
    "id": "arXiv:2106.13266",
    "title": "DnS: Distill-and-Select for Efficient and Accurate Video Indexing and  Retrieval",
    "abstract": "In this paper, we address the problem of high performance and computationally\nefficient content-based video retrieval in large-scale datasets. Current\nmethods typically propose either: (i) fine-grained approaches employing\nspatio-temporal representations and similarity calculations, achieving high\nperformance at a high computational cost or (ii) coarse-grained approaches\nrepresenting/indexing videos as global vectors, where the spatio-temporal\nstructure is lost, providing low performance but also having low computational\ncost. In this work, we propose a Knowledge Distillation framework, which we\ncall Distill-and-Select (DnS), that starting from a well-performing\nfine-grained Teacher Network learns: a) Student Networks at different retrieval\nperformance and computational efficiency trade-offs and b) a Selection Network\nthat at test time rapidly directs samples to the appropriate student to\nmaintain both high retrieval performance and high computational efficiency. We\ntrain several students with different architectures and arrive at different\ntrade-offs of performance and efficiency, i.e., speed and storage requirements,\nincluding fine-grained students that store index videos using binary\nrepresentations. Importantly, the proposed scheme allows Knowledge Distillation\nin large, unlabelled datasets -- this leads to good students. We evaluate DnS\non five public datasets on three different video retrieval tasks and\ndemonstrate a) that our students achieve state-of-the-art performance in\nseveral cases and b) that our DnS framework provides an excellent trade-off\nbetween retrieval performance, computational speed, and storage space. In\nspecific configurations, our method achieves similar mAP with the teacher but\nis 20 times faster and requires 240 times less storage space. Our collected\ndataset and implementation are publicly available:\nhttps://github.com/mever-team/distill-and-select.",
    "descriptor": "",
    "authors": [
      "Giorgos Kordopatis-Zilos",
      "Christos Tzelepis",
      "Symeon Papadopoulos",
      "Ioannis Kompatsiaris",
      "Ioannis Patras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.13266"
  },
  {
    "id": "arXiv:2106.13271",
    "title": "On Fairness and Interpretability",
    "abstract": "Ethical AI spans a gamut of considerations. Among these, the most popular\nones, fairness and interpretability, have remained largely distinct in\ntechnical pursuits. We discuss and elucidate the differences between fairness\nand interpretability across a variety of dimensions. Further, we develop two\nprinciples-based frameworks towards developing ethical AI for the future that\nembrace aspects of both fairness and interpretability. First, interpretability\nfor fairness proposes instantiating interpretability within the realm of\nfairness to develop a new breed of ethical AI. Second, fairness and\ninterpretability initiates deliberations on bringing the best aspects of both\ntogether. We hope that these two frameworks will contribute to intensifying\nscholarly discussions on new frontiers of ethical AI that brings together\nfairness and interpretability.",
    "descriptor": "\nComments: in IJCAI 2021 Workshop on AI for Social Good, January 2021. [ Ref: this https URL ]\n",
    "authors": [
      "Deepak P",
      "Sanil V",
      "Joemon M. Jose"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.13271"
  },
  {
    "id": "arXiv:2106.13272",
    "title": "Generalized One-Class Learning Using Pairs of Complementary Classifiers",
    "abstract": "One-class learning is the classic problem of fitting a model to the data for\nwhich annotations are available only for a single class. In this paper, we\nexplore novel objectives for one-class learning, which we collectively refer to\nas Generalized One-class Discriminative Subspaces (GODS). Our key idea is to\nlearn a pair of complementary classifiers to flexibly bound the one-class data\ndistribution, where the data belongs to the positive half-space of one of the\nclassifiers in the complementary pair and to the negative half-space of the\nother. To avoid redundancy while allowing non-linearity in the classifier\ndecision surfaces, we propose to design each classifier as an orthonormal frame\nand seek to learn these frames via jointly optimizing for two conflicting\nobjectives, namely: i) to minimize the distance between the two frames, and ii)\nto maximize the margin between the frames and the data. The learned orthonormal\nframes will thus characterize a piecewise linear decision surface that allows\nfor efficient inference, while our objectives seek to bound the data within a\nminimal volume that maximizes the decision margin, thereby robustly capturing\nthe data distribution. We explore several variants of our formulation under\ndifferent constraints on the constituent classifiers, including kernelized\nfeature maps. We demonstrate the empirical benefits of our approach via\nexperiments on data from several applications in computer vision, such as\nanomaly detection in video sequences, human poses, and human activities. We\nalso explore the generality and effectiveness of GODS for non-vision tasks via\nexperiments on several UCI datasets, demonstrating state-of-the-art results.",
    "descriptor": "\nComments: Accepted at Trans. PAMI. arXiv admin note: text overlap with arXiv:1908.05884\n",
    "authors": [
      "Anoop Cherian",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13272"
  },
  {
    "id": "arXiv:2106.13275",
    "title": "Multitask Learning for Citation Purpose Classification",
    "abstract": "We present our entry into the 2021 3C Shared Task Citation Context\nClassification based on Purpose competition. The goal of the competition is to\nclassify a citation in a scientific article based on its purpose. This task is\nimportant because it could potentially lead to more comprehensive ways of\nsummarizing the purpose and uses of scientific articles, but it is also\ndifficult, mainly due to the limited amount of available training data in which\nthe purposes of each citation have been hand-labeled, along with the\nsubjectivity of these labels. Our entry in the competition is a multi-task\nmodel that combines multiple modules designed to handle the problem from\ndifferent perspectives, including hand-generated linguistic features, TF-IDF\nfeatures, and an LSTM-with-attention model. We also provide an ablation study\nand feature analysis whose insights could lead to future work.",
    "descriptor": "\nComments: Second Workshop on Scholarly Document Processing\n",
    "authors": [
      "Alex Oesterling",
      "Angikar Ghosal",
      "Haoyang Yu",
      "Rui Xin",
      "Yasa Baig",
      "Lesia Semenova",
      "Cynthia Rudin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13275"
  },
  {
    "id": "arXiv:2106.13276",
    "title": "Deep Learning for High-Impedance Fault Detection: Convolutional  Autoencoders",
    "abstract": "High-impedance faults (HIF) are difficult to detect because of their low\ncurrent amplitude and highly diverse characteristics. In recent years, machine\nlearning (ML) has been gaining popularity in HIF detection because ML\ntechniques learn patterns from data and successfully detect HIFs. However, as\nthese methods are based on supervised learning, they fail to reliably detect\nany scenario, fault or non-fault, not present in the training data.\nConsequently, this paper takes advantage of unsupervised learning and proposes\na convolutional autoencoder framework for HIF detection (CAE-HIFD). Contrary to\nthe conventional autoencoders that learn from normal behavior, the\nconvolutional autoencoder (CAE) in CAE-HIFD learns only from the HIF signals\neliminating the need for presence of diverse non-HIF scenarios in the CAE\ntraining. CAE distinguishes HIFs from non-HIF operating conditions by employing\ncross-correlation. To discriminate HIFs from transient disturbances such as\ncapacitor or load switching, CAE-HIFD uses kurtosis, a statistical measure of\nthe probability distribution shape. The performance evaluation studies\nconducted using the IEEE 13-node test feeder indicate that the CAE-HIFD\nreliably detects HIFs, outperforms the state-of-the-art HIF detection\ntechniques, and is robust against noise.",
    "descriptor": "",
    "authors": [
      "Khushwant Rai",
      "Farnam Hojatpanah",
      "Firouz Badrkhani Ajaei",
      "Katarina Grolinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.13276"
  },
  {
    "id": "arXiv:2106.13277",
    "title": "Geometric learning of the conformational dynamics of molecules using  dynamic graph neural networks",
    "abstract": "We apply a temporal edge prediction model for weighted dynamic graphs to\npredict time-dependent changes in molecular structure. Each molecule is\nrepresented as a complete graph in which each atom is a vertex and all vertex\npairs are connected by an edge weighted by the Euclidean distance between atom\npairs. We ingest a sequence of complete molecular graphs into a dynamic graph\nneural network (GNN) to predict the graph at the next time step. Our dynamic\nGNN predicts atom-to-atom distances with a mean absolute error of 0.017 \\r{A},\nwhich is considered ``chemically accurate'' for molecular simulations. We also\nexplored the transferability of a trained network to new molecular systems and\nfound that finetuning with less than 10% of the total trajectory provides a\nmean absolute error of the same order of magnitude as that when training from\nscratch on the full molecular trajectory.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Michael Hunter Ashby",
      "Jenna A. Bilbrey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.13277"
  },
  {
    "id": "arXiv:2106.13280",
    "title": "Multi-Robot Deep Reinforcement Learning for Mobile Navigation",
    "abstract": "Deep reinforcement learning algorithms require large and diverse datasets in\norder to learn successful policies for perception-based mobile navigation.\nHowever, gathering such datasets with a single robot can be prohibitively\nexpensive. Collecting data with multiple different robotic platforms with\npossibly different dynamics is a more scalable approach to large-scale data\ncollection. But how can deep reinforcement learning algorithms leverage such\nheterogeneous datasets? In this work, we propose a deep reinforcement learning\nalgorithm with hierarchically integrated models (HInt). At training time, HInt\nlearns separate perception and dynamics models, and at test time, HInt\nintegrates the two models in a hierarchical manner and plans actions with the\nintegrated model. This method of planning with hierarchically integrated models\nallows the algorithm to train on datasets gathered by a variety of different\nplatforms, while respecting the physical capabilities of the deployment robot\nat test time. Our mobile navigation experiments show that HInt outperforms\nconventional hierarchical policies and single-source approaches.",
    "descriptor": "",
    "authors": [
      "Katie Kang",
      "Gregory Kahn",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13280"
  },
  {
    "id": "arXiv:2106.13281",
    "title": "Brax -- A Differentiable Physics Engine for Large Scale Rigid Body  Simulation",
    "abstract": "We present Brax, an open source library for rigid body simulation with a\nfocus on performance and parallelism on accelerators, written in JAX. We\npresent results on a suite of tasks inspired by the existing reinforcement\nlearning literature, but remade in our engine. Additionally, we provide\nreimplementations of PPO, SAC, ES, and direct policy optimization in JAX that\ncompile alongside our environments, allowing the learning algorithm and the\nenvironment processing to occur on the same device, and to scale seamlessly on\naccelerators. Finally, we include notebooks that facilitate training of\nperformant policies on common OpenAI Gym MuJoCo-like tasks in minutes.",
    "descriptor": "\nComments: 9 pages + 12 pages of appendices and references. In submission at NeurIPS 2021 Datasets and Benchmarks Track\n",
    "authors": [
      "C. Daniel Freeman",
      "Erik Frey",
      "Anton Raichuk",
      "Sertan Girgin",
      "Igor Mordatch",
      "Olivier Bachem"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13281"
  },
  {
    "id": "arXiv:2106.13282",
    "title": "Why ex post peer review encourages high-risk research while ex ante  review discourages it",
    "abstract": "Peer review is an integral component of contemporary science. While peer\nreview focuses attention on promising and interesting science, it also\nencourages scientists to pursue some questions at the expense of others. Here,\nwe use ideas from forecasting assessment to examine how two modes of peer\nreview -- ex ante review of proposals for future work and ex post review of\ncompleted science -- motivate scientists to favor some questions instead of\nothers. Our main result is that ex ante and ex post peer review push\ninvestigators toward distinct sets of scientific questions. This tension arises\nbecause ex post review allows an investigator to leverage her own scientific\nbeliefs to generate results that others will find surprising, whereas ex ante\nreview does not. Moreover, ex ante review will favor different research\nquestions depending on whether reviewers rank proposals in anticipation of\nchanges to their own personal beliefs, or to the beliefs of their peers. The\ntension between ex ante and ex post review puts investigators in a bind,\nbecause most researchers need to find projects that will survive both. By\nunpacking the tension between these two modes of review, we can understand how\nthey shape the landscape of science and how changes to peer review might shift\nscientific activity in unforeseen directions.",
    "descriptor": "\nComments: 11 pages, 4 figures, 1 appendix\n",
    "authors": [
      "Kevin Gross",
      "Carl T. Bergstrom"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.13282"
  },
  {
    "id": "arXiv:2106.13285",
    "title": "Factor Graphs for Heterogeneous Bayesian Decentralized Data Fusion",
    "abstract": "This paper explores the use of factor graphs as an inference and analysis\ntool for Bayesian peer-to-peer decentralized data fusion. We propose a\nframework by which agents can each use local factor graphs to represent\nrelevant partitions of a complex global joint probability distribution, thus\nallowing them to avoid reasoning over the entirety of a more complex model and\nsaving communication as well as computation cost. This allows heterogeneous\nmulti-robot systems to cooperate on a variety of real world, task oriented\nmissions, where scalability and modularity are key. To develop the initial\ntheory and analyze the limits of this approach, we focus our attention on\nstatic linear Gaussian systems in tree-structured networks and use Channel\nFilters (also represented by factor graphs) to explicitly track common\ninformation. We discuss how this representation can be used to describe various\nmulti-robot applications and to design and analyze new heterogeneous data\nfusion algorithms. We validate our method in simulations of a multi-agent\nmulti-target tracking and cooperative multi-agent mapping problems, and discuss\nthe computation and communication gains of this approach.",
    "descriptor": "\nComments: 8 pages, 6 figures, 1 table, submitted to the 24th International Conference on Information Fusion\n",
    "authors": [
      "Ofer Dagan",
      "Nisar R. Ahmed"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.13285"
  },
  {
    "id": "arXiv:2106.13286",
    "title": "A Modelling and Experimental Framework for Battery Lifetime Estimation  in NB-IoT and LTE-M",
    "abstract": "To enable large-scale Internet of Things (IoT) deployment, Low-power\nwide-area networking (LPWAN) has attracted a lot of research attention with the\ndesign objectives of low-power consumption, wide-area coverage, and low cost.\nIn particular, long battery lifetime is central to these technologies since\nmany of the IoT devices will be deployed in hard-toaccess locations. Prediction\nof the battery lifetime depends on the accurate modelling of power consumption.\nThis paper presents detailed power consumption models for two cellular IoT\ntechnologies: Narrowband Internet of Things (NB-IoT) and Long Term Evolution\nfor Machines (LTE-M). A comprehensive power consumption model based on User\nEquipment (UE) states and procedures for device battery lifetime estimation is\npresented. An IoT device power measurement testbed has been setup and the\nproposed model has been validated via measurements with different coverage\nscenarios and traffic configurations, achieving the modelling inaccuracy within\n5%. The resulting estimated battery lifetime is promising, showing that the\n10-year battery lifetime requirement specified by 3GPP can be met with proper\nconfiguration of traffic profile, transmission, and network parameters.",
    "descriptor": "\nComments: submitted to IEEE Internet of Things Journal, 12 pages, 10 figures\n",
    "authors": [
      "Andr\u00e9 S\u00f8rensen",
      "Hua Wang",
      "Maxime J\u00e9r\u00f4me Remy",
      "Nicolaj Kjettrup",
      "Ren\u00e9 Brandborg S\u00f8rensen",
      "Jimmy Jessen Nielsen",
      "Petar Popovsky",
      "Germ\u00e1n Corrales Madue\u00f1o"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.13286"
  },
  {
    "id": "arXiv:2106.13291",
    "title": "Coordinated Scheduling of Electric Vehicles Within Zero Carbon Emission  Hybrid AC/DC Microgrids",
    "abstract": "Microgrids with AC/DC architecture benefit from advantages of both AC and DC\npower. In this paper, daily operation problem for a zero-carbon AC/DC microgrid\nin presence of electric vehicles (EVs) is considered. In this framework, EVs'\nbatteries are mobile energy storage systems, which allow desirable operation of\nthe microgrid during peak demand hours. This study shows in absence of storage\nsystem, EVs' batteries can be properly managed to satisfy the system\nrequirements. In the case studies, several sensitivity analyses based on\nvariations in battery degradation costs, solar irradiance, and inverter\ncapacity are investigated.",
    "descriptor": "\nComments: ITEC 2021\n",
    "authors": [
      "Reza Bayani",
      "Arash Farokhi Soofi",
      "Saeed D. Manshadi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13291"
  },
  {
    "id": "arXiv:2106.13292",
    "title": "Semi-supervised Meta-learning with Disentanglement for  Domain-generalised Medical Image Segmentation",
    "abstract": "Generalising deep models to new data from new centres (termed here domains)\nremains a challenge. This is largely attributed to shifts in data statistics\n(domain shifts) between source and unseen domains. Recently, gradient-based\nmeta-learning approaches where the training data are split into meta-train and\nmeta-test sets to simulate and handle the domain shifts during training have\nshown improved generalisation performance. However, the current fully\nsupervised meta-learning approaches are not scalable for medical image\nsegmentation, where large effort is required to create pixel-wise annotations.\nMeanwhile, in a low data regime, the simulated domain shifts may not\napproximate the true domain shifts well across source and unseen domains. To\naddress this problem, we propose a novel semi-supervised meta-learning\nframework with disentanglement. We explicitly model the representations related\nto domain shifts. Disentangling the representations and combining them to\nreconstruct the input image allows unlabeled data to be used to better\napproximate the true domain shifts for meta-learning. Hence, the model can\nachieve better generalisation performance, especially when there is a limited\namount of labeled data. Experiments show that the proposed method is robust on\ndifferent segmentation tasks and achieves state-of-the-art generalisation\nperformance on two public benchmarks.",
    "descriptor": "\nComments: Accepted by MICCAI 2021\n",
    "authors": [
      "Xiao Liu",
      "Spyridon Thermos",
      "Alison O'Neil",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13292"
  },
  {
    "id": "arXiv:2106.13299",
    "title": "Free-viewpoint Indoor Neural Relighting from Multi-view Stereo",
    "abstract": "We introduce a neural relighting algorithm for captured indoors scenes, that\nallows interactive free-viewpoint navigation. Our method allows illumination to\nbe changed synthetically, while coherently rendering cast shadows and complex\nglossy materials. We start with multiple images of the scene and a 3D mesh\nobtained by multi-view stereo (MVS) reconstruction. We assume that lighting is\nwell-explained as the sum of a view-independent diffuse component and a\nview-dependent glossy term concentrated around the mirror reflection direction.\nWe design a convolutional network around input feature maps that facilitate\nlearning of an implicit representation of scene materials and illumination,\nenabling both relighting and free-viewpoint navigation. We generate these input\nmaps by exploiting the best elements of both image-based and physically-based\nrendering. We sample the input views to estimate diffuse scene irradiance, and\ncompute the new illumination caused by user-specified light sources using path\ntracing. To facilitate the network's understanding of materials and synthesize\nplausible glossy reflections, we reproject the views and compute mirror images.\nWe train the network on a synthetic dataset where each scene is also\nreconstructed with MVS. We show results of our algorithm relighting real indoor\nscenes and performing free-viewpoint navigation with complex and realistic\nglossy reflections, which so far remained out of reach for view-synthesis\ntechniques.",
    "descriptor": "",
    "authors": [
      "Julien Philip",
      "S\u00e9bastien Morgenthaler",
      "Micha\u00ebl Gharbi",
      "George Drettakis"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13299"
  },
  {
    "id": "arXiv:2106.13300",
    "title": "Continual Competitive Memory: A Neural System for Online Task-Free  Lifelong Learning",
    "abstract": "In this article, we propose a novel form of unsupervised learning, continual\ncompetitive memory (CCM), as well as a computational framework to unify related\nneural models that operate under the principles of competition. The resulting\nneural system is shown to offer an effective approach for combating\ncatastrophic forgetting in online continual classification problems. We\ndemonstrate that the proposed CCM system not only outperforms other competitive\nlearning neural models but also yields performance that is competitive with\nseveral modern, state-of-the-art lifelong learning approaches on benchmarks\nsuch as Split MNIST and Split NotMNIST. CCM yields a promising path forward for\nacquiring representations that are robust to interference from data streams,\nespecially when the task is unknown to the model and must be inferred without\nexternal guidance.",
    "descriptor": "",
    "authors": [
      "Alexander G. Ororbia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13300"
  },
  {
    "id": "arXiv:2106.13301",
    "title": "Physics perception in sloshing scenes with guaranteed thermodynamic  consistency",
    "abstract": "Physics perception very often faces the problem that only limited data or\npartial measurements on the scene are available. In this work, we propose a\nstrategy to learn the full state of sloshing liquids from measurements of the\nfree surface. Our approach is based on recurrent neural networks (RNN) that\nproject the limited information available to a reduced-order manifold so as to\nnot only reconstruct the unknown information, but also to be capable of\nperforming fluid reasoning about future scenarios in real time. To obtain\nphysically consistent predictions, we train deep neural networks on the\nreduced-order manifold that, through the employ of inductive biases, ensure the\nfulfillment of the principles of thermodynamics. RNNs learn from history the\nrequired hidden information to correlate the limited information with the\nlatent space where the simulation occurs. Finally, a decoder returns data back\nto the high-dimensional manifold, so as to provide the user with insightful\ninformation in the form of augmented reality. This algorithm is connected to a\ncomputer vision system to test the performance of the proposed methodology with\nreal information, resulting in a system capable of understanding and predicting\nfuture states of the observed fluid in real-time.",
    "descriptor": "\nComments: 20 pages, 11 figures\n",
    "authors": [
      "Beatriz Moya",
      "Alberto Badias",
      "David Gonzalez",
      "Francisco Chinesta",
      "Elias Cueto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13301"
  },
  {
    "id": "arXiv:2106.13302",
    "title": "byteSteady: Fast Classification Using Byte-Level n-Gram Embeddings",
    "abstract": "This article introduces byteSteady -- a fast model for classification using\nbyte-level n-gram embeddings. byteSteady assumes that each input comes as a\nsequence of bytes. A representation vector is produced using the averaged\nembedding vectors of byte-level n-grams, with a pre-defined set of n. The\nhashing trick is used to reduce the number of embedding vectors. This input\nrepresentation vector is then fed into a linear classifier. A straightforward\napplication of byteSteady is text classification. We also apply byteSteady to\none type of non-language data -- DNA sequences for gene classification. For\nboth problems we achieved competitive classification results against strong\nbaselines, suggesting that byteSteady can be applied to both language and\nnon-language data. Furthermore, we find that simple compression using Huffman\ncoding does not significantly impact the results, which offers an\naccuracy-speed trade-off previously unexplored in machine learning.",
    "descriptor": "",
    "authors": [
      "Xiang Zhang",
      "Alexandre Drouin",
      "Raymond Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13302"
  },
  {
    "id": "arXiv:2106.13306",
    "title": "CEAZ: Accelerating Parallel I/O via Hardware-Algorithm Co-Design of  Efficient and Adaptive Lossy Compression",
    "abstract": "As supercomputers continue to grow to exascale, the amount of data that needs\nto be saved or transmitted is exploding. To this end, many previous works have\nstudied using error-bounded lossy compressors to reduce the data size and\nimprove the I/O performance. However, little work has been done for effectively\noffloading lossy compression onto FPGA-based SmartNICs to reduce the\ncompression overhead. In this paper, we propose a hardware-algorithm co-design\nof efficient and adaptive lossy compressor for scientific data on FPGAs (called\nCEAZ) to accelerate parallel I/O. Our contribution is fourfold: (1) We propose\nan efficient Huffman coding approach that can adaptively update Huffman\ncodewords online based on codewords generated offline (from a variety of\nrepresentative scientific datasets). (2) We derive a theoretical analysis to\nsupport a precise control of compression ratio under an error-bounded\ncompression mode, enabling accurate offline Huffman codewords generation. This\nalso helps us create a fixed-ratio compression mode for consistent throughput.\n(3) We develop an efficient compression pipeline by adopting cuSZ's\ndual-quantization algorithm to our hardware use case. (4) We evaluate CEAZ on\nfive real-world datasets with both a single FPGA board and 128 nodes from\nBridges-2 supercomputer. Experiments show that CEAZ outperforms the second-best\nFPGA-based lossy compressor by 2X of throughput and 9.6X of compression ratio.\nIt also improves MPI_File_write and MPI_Gather throughputs by up to 25.8X and\n24.8X, respectively.",
    "descriptor": "\nComments: 14 pages, 17 figures, 8 tables\n",
    "authors": [
      "Chengming Zhang",
      "Sian Jin",
      "Tong Geng",
      "Jiannan Tian",
      "Ang Li",
      "Dingwen Tao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.13306"
  },
  {
    "id": "arXiv:2106.13308",
    "title": "Overcoming barriers to scalability in variational quantum Monte Carlo",
    "abstract": "The variational quantum Monte Carlo (VQMC) method received significant\nattention in the recent past because of its ability to overcome the curse of\ndimensionality inherent in many-body quantum systems. Close parallels exist\nbetween VQMC and the emerging hybrid quantum-classical computational paradigm\nof variational quantum algorithms. VQMC overcomes the curse of dimensionality\nby performing alternating steps of Monte Carlo sampling from a parametrized\nquantum state followed by gradient-based optimization. While VQMC has been\napplied to solve high-dimensional problems, it is known to be difficult to\nparallelize, primarily owing to the Markov Chain Monte Carlo (MCMC) sampling\nstep. In this work, we explore the scalability of VQMC when autoregressive\nmodels, with exact sampling, are used in place of MCMC. This approach can\nexploit distributed-memory, shared-memory and/or GPU parallelism in the\nsampling task without any bottlenecks. In particular, we demonstrate the\nGPU-scalability of VQMC for solving up to ten-thousand dimensional\ncombinatorial optimization problems.",
    "descriptor": "",
    "authors": [
      "Tianchen Zhao",
      "Saibal De",
      "Brian Chen",
      "James Stokes",
      "Shravan Veerapaneni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.13308"
  },
  {
    "id": "arXiv:2106.13309",
    "title": "Consistent ultrafinitist logic",
    "abstract": "Ultrafinitism postulates that we can only compute on relatively short\nobjects, and numbers beyond certain value are not available. This approach\nwould also forbid many forms of infinitary reasoning and allow to remove\ncertain paradoxes stemming from enumeration theorems.\nHowever, philosophers still disagree of whether such a finitist logic would\nbe consistent. We present preliminary work on a proof system based on\nCurry-Howard isomorphism. We also try to present some well-known theorems that\nstop being true in such systems, whereas opposite statements become provable.\nThis approach presents certain impossibility results as logical paradoxes\nstemming from a profligate use of transfinite reasoning.",
    "descriptor": "\nComments: First submitted to CiE2021 in January, under review for GandALF2021. Contains inference rules, and polynomial reduction rules\n",
    "authors": [
      "Micha\u0142 J. Gajda"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.13309"
  },
  {
    "id": "arXiv:2106.13314",
    "title": "Promises and Pitfalls of Black-Box Concept Learning Models",
    "abstract": "Machine learning models that incorporate concept learning as an intermediate\nstep in their decision making process can match the performance of black-box\npredictive models while retaining the ability to explain outcomes in human\nunderstandable terms. However, we demonstrate that the concept representations\nlearned by these models encode information beyond the pre-defined concepts, and\nthat natural mitigation strategies do not fully work, rendering the\ninterpretation of the downstream prediction misleading. We describe the\nmechanism underlying the information leakage and suggest recourse for\nmitigating its effects.",
    "descriptor": "",
    "authors": [
      "Anita Mahinpei",
      "Justin Clark",
      "Isaac Lage",
      "Finale Doshi-Velez",
      "Weiwei Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13314"
  },
  {
    "id": "arXiv:2106.13316",
    "title": "VOGUE: Answer Verbalization through Multi-Task Learning",
    "abstract": "In recent years, there have been significant developments in Question\nAnswering over Knowledge Graphs (KGQA). Despite all the notable advancements,\ncurrent KGQA systems only focus on answer generation techniques and not on\nanswer verbalization. However, in real-world scenarios (e.g., voice assistants\nsuch as Alexa, Siri, etc.), users prefer verbalized answers instead of a\ngenerated response. This paper addresses the task of answer verbalization for\n(complex) question answering over knowledge graphs. In this context, we propose\na multi-task-based answer verbalization framework: VOGUE (Verbalization thrOuGh\nmUlti-task lEarning). The VOGUE framework attempts to generate a verbalized\nanswer using a hybrid approach through a multi-task learning paradigm. Our\nframework can generate results based on using questions and queries as inputs\nconcurrently. VOGUE comprises four modules that are trained simultaneously\nthrough multi-task learning. We evaluate our framework on existing datasets for\nanswer verbalization, and it outperforms all current baselines on both BLEU and\nMETEOR scores.",
    "descriptor": "\nComments: Machine Learning and Knowledge Discovery in Databases - European Conference, ECML PKDD 2021\n",
    "authors": [
      "Endri Kacupaj",
      "Shyamnath Premnadh",
      "Kuldeep Singh",
      "Jens Lehmann",
      "Maria Maleshkova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.13316"
  },
  {
    "id": "arXiv:2106.13319",
    "title": "A variational autoencoder approach for choice set generation and  implicit perception of alternatives in choice modeling",
    "abstract": "This paper derives the generalized extreme value (GEV) model with implicit\navailability/perception (IAP) of alternatives and proposes a variational\nautoencoder (VAE) approach for choice set generation and implicit perception of\nalternatives. Specifically, the cross-nested logit (CNL) model with IAP is\nderived as an example of IAP-GEV models. The VAE approach is adapted to model\nthe choice set generation process, in which the likelihood of perceiving chosen\nalternatives in the choice set is maximized. The VAE approach for route choice\nset generation is exemplified using a real dataset. IAP- CNL model estimated\nhas the best performance in terms of goodness-of-fit and prediction\nperformance, compared to multinomial logit models and conventional choice set\ngeneration methods.",
    "descriptor": "",
    "authors": [
      "Rui Yao",
      "Shlomo Bekhor"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.13319"
  },
  {
    "id": "arXiv:2106.13320",
    "title": "More Causes Less Effect: Destructive Interference in Decision Making",
    "abstract": "We present a new experiment demonstrating destructive interference in\ncustomers' estimates of conditional probabilities of product failure. We take\nthe perspective of a manufacturer of consumer products, and consider two\nsituations of cause and effect. Whereas individually the effect of the causes\nis similar, it is observed that when combined, the two causes produce the\nopposite effect. Such negative interference of two or more reasons may be\nexploited for better modeling the cognitive processes taking place in the\ncustomers' mind. Doing so can enhance the likelihood that a manufacturer will\nbe able to design a better product, or a feature within it. Quantum probability\nhas been used to explain some commonly observed deviations such as question\norder and response replicability effects, as well as in explaining paradoxes\nsuch as violations of the sure-thing principle, and Machina and Ellsberg\nparadoxes. In this work, we present results from a survey conducted regarding\nthe effect of multiple observed symptoms on the drivability of a vehicle. We\ndemonstrate that the set of responses cannot be explained using classical\nprobability, but quantum formulation easily models it, as it allows for both\npositive and negative \"interference\" between events. Since quantum formulism\nalso accounts for classical probability's predictions, it serves as a richer\nparadigm for modeling decision making behavior in engineering design and\nbehavioral economics.",
    "descriptor": "",
    "authors": [
      "Irina Basieva",
      "Vijitashwa Pandey",
      "Polina Khrennikova"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.13320"
  },
  {
    "id": "arXiv:2106.13322",
    "title": "Dr. Watson type Artificial Intellect (AI) Systems",
    "abstract": "The article proposes a new type of AI system that does not give solutions\ndirectly but rather points toward it, friendly prompting the user with\nquestions and adjusting messages. Models of AI human collaboration can be\ndeduced from the classic literary example of interaction between Mr. Holmes and\nDr. Watson from the stories by Conan Doyle, where the highly qualified expert\nMr. Holmes answers questions posed by Dr. Watson. Here Mr. Holmes, with his\nrule-based calculations, logic, and memory management, apparently plays the\nrole of an AI system, and Dr. Watson is the user. Looking into the same\nHolmes-Watson interaction, we find and promote another model in which the AI\nbehaves like Dr. Watson, who, by asking questions and acting in a particular\nway, helps Holmes (the AI user) make the right decisions. We call the systems\nbased on this principle \"Dr. Watson-type systems.\" The article describes the\nproperties of such systems and introduces two particular: Patient Management\nSystem for intensive care physicians and Data Error Prevention System.",
    "descriptor": "\nComments: 24 pages,13 figures\n",
    "authors": [
      "Saveli Goldberg",
      "Stanislav Belyaev",
      "Vladimir Sluchak"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13322"
  },
  {
    "id": "arXiv:2106.13323",
    "title": "Domain-guided Machine Learning for Remotely Sensed In-Season Crop Growth  Estimation",
    "abstract": "Advanced machine learning techniques have been used in remote sensing (RS)\napplications such as crop mapping and yield prediction, but remain\nunder-utilized for tracking crop progress. In this study, we demonstrate the\nuse of agronomic knowledge of crop growth drivers in a Long Short-Term\nMemory-based, Domain-guided neural network (DgNN) for in-season crop progress\nestimation. The DgNN uses a branched structure and attention to separate\nindependent crop growth drivers and capture their varying importance throughout\nthe growing season. The DgNN is implemented for corn, using RS data in Iowa for\nthe period 2003-2019, with USDA crop progress reports used as ground truth.\nState-wide DgNN performance shows significant improvement over sequential and\ndense-only NN structures, and a widely-used Hidden Markov Model method. The\nDgNN had a 3.5% higher Nash-Sutfliffe efficiency over all growth stages and 33%\nmore weeks with highest cosine similarity than the other NNs during test years.\nThe DgNN and Sequential NN were more robust during periods of abnormal crop\nprogress, though estimating the Silking-Grainfill transition was difficult for\nall methods. Finally, Uniform Manifold Approximation and Projection\nvisualizations of layer activations showed how LSTM-based NNs separate crop\ngrowth time-series differently from a dense-only structure. Results from this\nstudy exhibit both the viability of NNs in crop growth stage estimation (CGSE)\nand the benefits of using domain knowledge. The DgNN methodology presented here\ncan be extended to provide near-real time CGSE of other crops.",
    "descriptor": "\nComments: 7 pages, 7 tables, 11 figures\n",
    "authors": [
      "George Worrall",
      "Anand Rangarajan",
      "Jasmeet Judge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13323"
  },
  {
    "id": "arXiv:2106.13326",
    "title": "On the (Un-)Avoidability of Adversarial Examples",
    "abstract": "The phenomenon of adversarial examples in deep learning models has caused\nsubstantial concern over their reliability. While many deep neural networks\nhave shown impressive performance in terms of predictive accuracy, it has been\nshown that in many instances an imperceptible perturbation can falsely flip the\nnetwork's prediction. Most research has then focused on developing defenses\nagainst adversarial attacks or learning under a worst-case adversarial loss. In\nthis work, we take a step back and aim to provide a framework for determining\nwhether a model's label change under small perturbation is justified (and when\nit is not). We carefully argue that adversarial robustness should be defined as\na locally adaptive measure complying with the underlying distribution. We then\nsuggest a definition for an adaptive robust loss, derive an empirical version\nof it, and develop a resulting data-augmentation framework. We prove that our\nadaptive data-augmentation maintains consistency of 1-nearest neighbor\nclassification under deterministic labels and provide illustrative empirical\nevaluations.",
    "descriptor": "\nComments: ICML 2021 Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI\n",
    "authors": [
      "Sadia Chowdhury",
      "Ruth Urner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13326"
  },
  {
    "id": "arXiv:2106.13329",
    "title": "Covariance-Aware Private Mean Estimation Without Private Covariance  Estimation",
    "abstract": "We present two sample-efficient differentially private mean estimators for\n$d$-dimensional (sub)Gaussian distributions with unknown covariance.\nInformally, given $n \\gtrsim d/\\alpha^2$ samples from such a distribution with\nmean $\\mu$ and covariance $\\Sigma$, our estimators output $\\tilde\\mu$ such that\n$\\| \\tilde\\mu - \\mu \\|_{\\Sigma} \\leq \\alpha$, where $\\| \\cdot \\|_{\\Sigma}$ is\nthe Mahalanobis distance. All previous estimators with the same guarantee\neither require strong a priori bounds on the covariance matrix or require\n$\\Omega(d^{3/2})$ samples.\nEach of our estimators is based on a simple, general approach to designing\ndifferentially private mechanisms, but with novel technical steps to make the\nestimator private and sample-efficient. Our first estimator samples a point\nwith approximately maximum Tukey depth using the exponential mechanism, but\nrestricted to the set of points of large Tukey depth. Proving that this\nmechanism is private requires a novel analysis. Our second estimator perturbs\nthe empirical mean of the data set with noise calibrated to the empirical\ncovariance, without releasing the covariance itself. Its sample complexity\nguarantees hold more generally for subgaussian distributions, albeit with a\nslightly worse dependence on the privacy parameter. For both estimators,\ncareful preprocessing of the data is required to satisfy differential privacy.",
    "descriptor": "",
    "authors": [
      "Gavin Brown",
      "Marco Gaboardi",
      "Adam Smith",
      "Jonathan Ullman",
      "Lydia Zakynthinou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13329"
  },
  {
    "id": "arXiv:2106.13338",
    "title": "Distributed IDA-PBC for a Class of Nonholonomic Mechanical Systems",
    "abstract": "Nonholonomic mechanical systems encompass a large class of practically\ninteresting robotic structures, such as wheeled mobile robots, space\nmanipulators, and multi-fingered robot hands. However, few results exist on the\ncooperative control of such systems in a generic, distributed approach. In this\nwork we extend a recently developed distributed Interconnection and Damping\nAssignment Passivity-Based Control (IDA-PBC) method to such systems. More\nspecifically, relying on port-Hamiltonian system modelling for networks of\nmechanical systems, we propose a full-state stabilization control law for a\nclass of nonholonomic systems within the framework of distributed IDA-PBC. This\nenables the cooperative control of heterogeneous, underactuated and\nnonholonomic systems with a unified control law. This control law primarily\nrelies on the notion of Passive Configuration Decomposition (PCD) and a novel,\nnon-smooth desired potential energy function proposed here. A low-level\ncollision avoidance protocol is also implemented in order to achieve dynamic\ninter-agent collision avoidance, enhancing the practical relevance of this\nwork. Theoretical results are tested in different simulation scenarios in order\nto highlight the applicability of the derived method.",
    "descriptor": "\nComments: Longer version of a 6-page conference paper submitted to MICNON 2021 in order to illustrate more results\n",
    "authors": [
      "Anastasios Tsolakis",
      "Tamas Keviczky"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13338"
  },
  {
    "id": "arXiv:2106.13339",
    "title": "Blockchain-based Security Framework for Critical Industry 4.0  Cyber-physical System",
    "abstract": "There has been an intense concern for security alternatives because of the\nrecent rise of cyber attacks, mainly targeting critical systems such as\nindustry, medical, or energy ecosystem. Though the latest industry\ninfrastructures largely depend on AI-driven maintenance, the prediction based\non corrupted data undoubtedly results in loss of life and capital. Admittedly,\nan inadequate data-protection mechanism can readily challenge the security and\nreliability of the network. The shortcomings of the conventional cloud or\ntrusted certificate-driven techniques have motivated us to exhibit a unique\nBlockchain-based framework for a secure and efficient industry 4.0 system. The\ndemonstrated framework obviates the long-established certificate authority\nafter enhancing the consortium Blockchain that reduces the data processing\ndelay, and increases cost-effective throughput. Nonetheless, the distributed\nindustry 4.0 security model entails cooperative trust than depending on a\nsingle party, which in essence indulges the costs and threat of the single\npoint of failure. Therefore, multi-signature technique of the proposed\nframework accomplishes the multi-party authentication, which confirms its\napplicability for the real-time and collaborative cyber-physical system.",
    "descriptor": "\nComments: 07 Pages, 4 Figures, IEEE Communication Magazine\n",
    "authors": [
      "Ziaur Rahman",
      "Ibrahim Khalil",
      "Xun Yi",
      "Mohammed Atiquzzaman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.13339"
  },
  {
    "id": "arXiv:2106.13341",
    "title": "Guessing Based on Compressed Side Information",
    "abstract": "A source sequence is to be guessed with some fidelity based on a rate-limited\ndescription of an observed sequence with which it is correlated. The trade-off\nbetween the description rate and the exponential growth rate of the least power\nmean of the number of guesses is characterized.",
    "descriptor": "",
    "authors": [
      "Robert Graczyk",
      "Amos Lapidoth",
      "Neri Merhav",
      "Christoph Pfister"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.13341"
  },
  {
    "id": "arXiv:2106.13342",
    "title": "The Complexity of Boolean Conjunctive Queries with Intersection Joins",
    "abstract": "Intersection joins over interval data are relevant in spatial and temporal\ndata settings. A set of intervals join if their intersection is non-empty. In\ncase of point intervals, the intersection join becomes the standard equality\njoin.\nWe establish the complexity of Boolean conjunctive queries with intersection\njoins by a many-one equivalence to disjunctions of Boolean conjunctive queries\nwith equality joins. The complexity of any query with intersection joins is\nthat of the hardest query with equality joins in the disjunction exhibited by\nour equivalence. This is captured by a new width measure called the IJ-width.\nWe also introduce a new syntactic notion of acyclicity called iota-acyclicity\nto characterise the class of Boolean queries with intersection joins that admit\nlinear time computation modulo a poly-logarithmic factor in the data size.\nIota-acyclicity is for intersection joins what alpha-acyclicity is for equality\njoins. It strictly sits between gamma-acyclicity and Berge-acyclicity. The\nintersection join queries that are not iota-acyclic are at least as hard as the\nBoolean triangle query with equality joins, which is widely considered not\ncomputable in linear time.",
    "descriptor": "",
    "authors": [
      "Mahmoud Abo Khamis",
      "George Chichirim",
      "Antonia Kormpa",
      "Dan Olteanu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.13342"
  },
  {
    "id": "arXiv:2106.13346",
    "title": "What will it take to generate fairness-preserving explanations?",
    "abstract": "In situations where explanations of black-box models may be useful, the\nfairness of the black-box is also often a relevant concern. However, the link\nbetween the fairness of the black-box model and the behavior of explanations\nfor the black-box is unclear. We focus on explanations applied to tabular\ndatasets, suggesting that explanations do not necessarily preserve the fairness\nproperties of the black-box algorithm. In other words, explanation algorithms\ncan ignore or obscure critical relevant properties, creating incorrect or\nmisleading explanations. More broadly, we propose future research directions\nfor evaluating and generating explanations such that they are informative and\nrelevant from a fairness perspective.",
    "descriptor": "\nComments: Presented at ICML 2021 Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI\n",
    "authors": [
      "Jessica Dai",
      "Sohini Upadhyay",
      "Stephen H. Bach",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.13346"
  },
  {
    "id": "arXiv:2106.13349",
    "title": "Johnson-Lindenstrauss Embeddings with Kronecker Structure",
    "abstract": "We prove the Johnson-Lindenstrauss property for matrices $\\Phi D_\\xi$ where\n$\\Phi$ has the restricted isometry property and $D_\\xi$ is a diagonal matrix\ncontaining the entries of a Kronecker product $\\xi = \\xi^{(1)} \\otimes \\dots\n\\otimes \\xi^{(d)}$ of $d$ independent Rademacher vectors. Such embeddings have\nbeen proposed in recent works for a number of applications concerning\ncompression of tensor structured data, including the oblivious sketching\nprocedure by Ahle et al. for approximate tensor computations. For preserving\nthe norms of $p$ points simultaneously, our result requires $\\Phi$ to have the\nrestricted isometry property for sparsity $C(d) (\\log p)^d$. In the case of\nsubsampled Hadamard matrices, this can improve the dependence of the embedding\ndimension on $p$ to $(\\log p)^d$ while the best previously known result\nrequired $(\\log p)^{d + 1}$. That is, for the case of $d=2$ at the core of the\noblivious sketching procedure by Ahle et al., the scaling improves from cubic\nto quadratic. We provide a counterexample to prove that the scaling established\nin our result is optimal under mild assumptions.",
    "descriptor": "",
    "authors": [
      "Stefan Bamberger",
      "Felix Krahmer",
      "Rachel Ward"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.13349"
  },
  {
    "id": "arXiv:2106.13353",
    "title": "Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with  Language Models",
    "abstract": "Prompting language models (LMs) with training examples and task descriptions\nhas been seen as critical to recent successes in few-shot learning. In this\nwork, we show that finetuning LMs in the few-shot setting can considerably\nreduce the need for prompt engineering. In fact, one can use null prompts,\nprompts that contain neither task-specific templates nor training examples, and\nachieve competitive accuracy to manually-tuned prompts across a wide range of\ntasks. While finetuning LMs does introduce new parameters for each downstream\ntask, we show that this memory overhead can be substantially reduced:\nfinetuning only the bias terms can achieve comparable or better accuracy than\nstandard finetuning while only updating 0.1% of the parameters. All in all, we\nrecommend finetuning LMs for few-shot learning as it is more accurate, robust\nto different prompts, and can be made nearly as efficient as using frozen LMs.",
    "descriptor": "",
    "authors": [
      "Robert L. Logan IV",
      "Ivana Bala\u017eevi\u0107",
      "Eric Wallace",
      "Fabio Petroni",
      "Sameer Singh",
      "Sebastian Riedel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13353"
  },
  {
    "id": "arXiv:2106.13358",
    "title": "Scalable Perception-Action-Communication Loops with Convolutional and  Graph Neural Networks",
    "abstract": "In this paper, we present a perception-action-communication loop design using\nVision-based Graph Aggregation and Inference (VGAI). This multi-agent\ndecentralized learning-to-control framework maps raw visual observations to\nagent actions, aided by local communication among neighboring agents. Our\nframework is implemented by a cascade of a convolutional and a graph neural\nnetwork (CNN / GNN), addressing agent-level visual perception and feature\nlearning, as well as swarm-level communication, local information aggregation\nand agent action inference, respectively. By jointly training the CNN and GNN,\nimage features and communication messages are learned in conjunction to better\naddress the specific task. We use imitation learning to train the VGAI\ncontroller in an offline phase, relying on a centralized expert controller.\nThis results in a learned VGAI controller that can be deployed in a distributed\nmanner for online execution. Additionally, the controller exhibits good scaling\nproperties, with training in smaller teams and application in larger teams.\nThrough a multi-agent flocking application, we demonstrate that VGAI yields\nperformance comparable to or better than other decentralized controllers, using\nonly the visual input modality and without accessing precise location or motion\nstate information.",
    "descriptor": "",
    "authors": [
      "Ting-Kuei Hu",
      "Fernando Gama",
      "Tianlong Chen",
      "Wenqing Zheng",
      "Zhangyang Wang",
      "Alejandro Ribeiro",
      "Brian M. Sadler"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13358"
  },
  {
    "id": "arXiv:2106.13364",
    "title": "CausalCity: Complex Simulations with Agency for Causal Discovery and  Reasoning",
    "abstract": "The ability to perform causal and counterfactual reasoning are central\nproperties of human intelligence. Decision-making systems that can perform\nthese types of reasoning have the potential to be more generalizable and\ninterpretable. Simulations have helped advance the state-of-the-art in this\ndomain, by providing the ability to systematically vary parameters (e.g.,\nconfounders) and generate examples of the outcomes in the case of\ncounterfactual scenarios. However, simulating complex temporal causal events in\nmulti-agent scenarios, such as those that exist in driving and vehicle\nnavigation, is challenging. To help address this, we present a high-fidelity\nsimulation environment that is designed for developing algorithms for causal\ndiscovery and counterfactual reasoning in the safety-critical context. A core\ncomponent of our work is to introduce \\textit{agency}, such that it is simple\nto define and create complex scenarios using high-level definitions. The\nvehicles then operate with agency to complete these objectives, meaning\nlow-level behaviors need only be controlled if necessary. We perform\nexperiments with three state-of-the-art methods to create baselines and\nhighlight the affordances of this environment. Finally, we highlight challenges\nand opportunities for future work.",
    "descriptor": "",
    "authors": [
      "Daniel McDuff",
      "Yale Song",
      "Jiyoung Lee",
      "Vibhav Vineet",
      "Sai Vemprala",
      "Nicholas Gyde",
      "Hadi Salman",
      "Shuang Ma",
      "Kwanghoon Sohn",
      "Ashish Kapoor"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13364"
  },
  {
    "id": "arXiv:2106.13365",
    "title": "RSN: Range Sparse Net for Efficient, Accurate LiDAR 3D Object Detection",
    "abstract": "The detection of 3D objects from LiDAR data is a critical component in most\nautonomous driving systems. Safe, high speed driving needs larger detection\nranges, which are enabled by new LiDARs. These larger detection ranges require\nmore efficient and accurate detection models. Towards this goal, we propose\nRange Sparse Net (RSN), a simple, efficient, and accurate 3D object detector in\norder to tackle real time 3D object detection in this extended detection\nregime. RSN predicts foreground points from range images and applies sparse\nconvolutions on the selected foreground points to detect objects. The\nlightweight 2D convolutions on dense range images results in significantly\nfewer selected foreground points, thus enabling the later sparse convolutions\nin RSN to efficiently operate. Combining features from the range image further\nenhance detection accuracy. RSN runs at more than 60 frames per second on a\n150m x 150m detection region on Waymo Open Dataset (WOD) while being more\naccurate than previously published detectors. As of 11/2020, RSN is ranked\nfirst in the WOD leaderboard based on the APH/LEVEL 1 metrics for LiDAR-based\npedestrian and vehicle detection, while being several times faster than\nalternatives.",
    "descriptor": "",
    "authors": [
      "Pei Sun",
      "Weiyue Wang",
      "Yuning Chai",
      "Gamaleldin Elsayed",
      "Alex Bewley",
      "Xiao Zhang",
      "Cristian Sminchisescu",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13365"
  },
  {
    "id": "arXiv:2106.13367",
    "title": "Towards A Knowledge Graph Based Autonomic Management of Software Defined  Networks",
    "abstract": "Automatic network management driven by Artificial Intelligent technologies\nhas been heatedly discussed over decades. However, current reports mainly focus\non theoretic proposals and architecture designs, works on practical\nimplementations on real-life networks are yet to appear. This paper proposes\nour effort toward the implementation of knowledge graph driven approach for\nautonomic network management in software defined networks (SDNs), termed as\nSeaNet. Driven by the ToCo ontology, SeaNet is reprogrammed based on Mininet (a\nSDN emulator). It consists three core components, a knowledge graph generator,\na SPARQL engine, and a network management API. The knowledge graph generator\nrepresents the knowledge in the telecommunication network management tasks into\nformally represented ontology driven model. Expert experience and network\nmanagement rules can be formalized into knowledge graph and by automatically\ninferenced by SPARQL engine, Network management API is able to packet\ntechnology-specific details and expose technology-independent interfaces to\nusers. The Experiments are carried out to evaluate proposed work by comparing\nwith a commercial SDN controller Ryu implemented by the same language Python.\nThe evaluation results show that SeaNet is considerably faster in most\ncircumstances than Ryu and the SeaNet code is significantly more compact.\nBenefit from RDF reasoning, SeaNet is able to achieve O(1) time complexity on\ndifferent scales of the knowledge graph while the traditional database can\nachieve O(nlogn) at its best. With the developed network management API, SeaNet\nenables researchers to develop semantic-intelligent applications on their own\nSDNs.",
    "descriptor": "",
    "authors": [
      "Qianru Zhou",
      "Alasdair J.G. Gray",
      "Stephen McLaughlin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.13367"
  },
  {
    "id": "arXiv:2106.13368",
    "title": "On Kaczmarz method with oblique projection for solving large  overdetermined linear systems",
    "abstract": "In this paper, an extension of Kaczmarz method, the Kaczmarz method with\noblique projection (KO), is introduced and analyzed. Using this method, a\nnumber of iteration steps to solve the over-determined systems of linear\nequations are significantly reduced, and the the computing time is much saved,\nespecially for those problems that contain some linear equations with\nnear-linear correlation. Simultaneously, a randomized version--randomized\nKaczmarz method with oblique projection (RKO) is established. The convergence\nproofs of these two methods are given and numerical experiments show the\neffectiveness of the two methods for uniformly distributed random data.\nEspecially when the system has correlated rows, the improvement of experimental\nresults is very prominent.",
    "descriptor": "",
    "authors": [
      "Weiguo Li",
      "Qifeng Wang",
      "Wendi Bao",
      "Li Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13368"
  },
  {
    "id": "arXiv:2106.13369",
    "title": "Distributed Nash Equilibrium Seeking Algorithm Design for Multi-Cluster  Games with High-Order Players",
    "abstract": "In this paper, a multi-cluster game with high-order players is investigated.\nDifferent from the well-known multi-cluster games, the dynamics of players are\ntaken into account in our problem. Due to the high-order dynamics of players,\nexisting algorithms for multi-cluster games cannot solve the problem. For\npurpose of seeking the Nash equilibrium of the game, we design a distributed\nalgorithm based on gradient descent and state feedback, where a distributed\nestimator is embedded for the players to estimate the decisions of other\nplayers. Furthermore, we analyze the exponential convergence of the algorithm\nvia variational analysis and Lyapunov stability theory. Finally, a numerical\nsimulation verifies the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Zhenhua Deng",
      "Yangyang Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13369"
  },
  {
    "id": "arXiv:2106.13375",
    "title": "Domain-Specific Pretraining for Vertical Search: Case Study on  Biomedical Literature",
    "abstract": "Information overload is a prevalent challenge in many high-value domains. A\nprominent case in point is the explosion of the biomedical literature on\nCOVID-19, which swelled to hundreds of thousands of papers in a matter of\nmonths. In general, biomedical literature expands by two papers every minute,\ntotalling over a million new papers every year. Search in the biomedical realm,\nand many other vertical domains is challenging due to the scarcity of direct\nsupervision from click logs. Self-supervised learning has emerged as a\npromising direction to overcome the annotation bottleneck. We propose a general\napproach for vertical search based on domain-specific pretraining and present a\ncase study for the biomedical domain. Despite being substantially simpler and\nnot using any relevance labels for training or development, our method performs\ncomparably or better than the best systems in the official TREC-COVID\nevaluation, a COVID-related biomedical search competition. Using distributed\ncomputing in modern cloud infrastructure, our system can scale to tens of\nmillions of articles on PubMed and has been deployed as Microsoft Biomedical\nSearch, a new search experience for biomedical literature:\nhttps://aka.ms/biomedsearch.",
    "descriptor": "",
    "authors": [
      "Yu Wang",
      "Jinchao Li",
      "Tristan Naumann",
      "Chenyan Xiong",
      "Hao Cheng",
      "Robert Tinn",
      "Cliff Wong",
      "Naoto Usuyama",
      "Richard Rogahn",
      "Zhihong Shen",
      "Yang Qin",
      "Eric Horvitz",
      "Paul N. Bennett",
      "Jianfeng Gao",
      "Hoifung Poon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.13375"
  },
  {
    "id": "arXiv:2106.13379",
    "title": "Bayesian Inference in High-Dimensional Time-Serieswith the Orthogonal  Stochastic Linear Mixing Model",
    "abstract": "Many modern time-series datasets contain large numbers of output response\nvariables sampled for prolonged periods of time. For example, in neuroscience,\nthe activities of 100s-1000's of neurons are recorded during behaviors and in\nresponse to sensory stimuli. Multi-output Gaussian process models leverage the\nnonparametric nature of Gaussian processes to capture structure across multiple\noutputs. However, this class of models typically assumes that the correlations\nbetween the output response variables are invariant in the input space.\nStochastic linear mixing models (SLMM) assume the mixture coefficients depend\non input, making them more flexible and effective to capture complex output\ndependence. However, currently, the inference for SLMMs is intractable for\nlarge datasets, making them inapplicable to several modern time-series\nproblems. In this paper, we propose a new regression framework, the orthogonal\nstochastic linear mixing model (OSLMM) that introduces an orthogonal constraint\namongst the mixing coefficients. This constraint reduces the computational\nburden of inference while retaining the capability to handle complex output\ndependence. We provide Markov chain Monte Carlo inference procedures for both\nSLMM and OSLMM and demonstrate superior model scalability and reduced\nprediction error of OSLMM compared with state-of-the-art methods on several\nreal-world applications. In neurophysiology recordings, we use the inferred\nlatent functions for compact visualization of population responses to auditory\nstimuli, and demonstrate superior results compared to a competing method\n(GPFA). Together, these results demonstrate that OSLMM will be useful for the\nanalysis of diverse, large-scale time-series datasets.",
    "descriptor": "",
    "authors": [
      "Rui Meng",
      "Kristofer Bouchard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13379"
  },
  {
    "id": "arXiv:2106.13381",
    "title": "To the Point: Efficient 3D Object Detection in the Range Image with  Graph Convolution Kernels",
    "abstract": "3D object detection is vital for many robotics applications. For tasks where\na 2D perspective range image exists, we propose to learn a 3D representation\ndirectly from this range image view. To this end, we designed a 2D\nconvolutional network architecture that carries the 3D spherical coordinates of\neach pixel throughout the network. Its layers can consume any arbitrary\nconvolution kernel in place of the default inner product kernel and exploit the\nunderlying local geometry around each pixel. We outline four such kernels: a\ndense kernel according to the bag-of-words paradigm, and three graph kernels\ninspired by recent graph neural network advances: the Transformer, the\nPointNet, and the Edge Convolution. We also explore cross-modality fusion with\nthe camera image, facilitated by operating in the perspective range image view.\nOur method performs competitively on the Waymo Open Dataset and improves the\nstate-of-the-art AP for pedestrian detection from 69.7% to 75.5%. It is also\nefficient in that our smallest model, which still outperforms the popular\nPointPillars in quality, requires 180 times fewer FLOPS and model parameters",
    "descriptor": "",
    "authors": [
      "Yuning Chai",
      "Pei Sun",
      "Jiquan Ngiam",
      "Weiyue Wang",
      "Benjamin Caine",
      "Vijay Vasudevan",
      "Xiao Zhang",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13381"
  },
  {
    "id": "arXiv:2106.13382",
    "title": "A Source-Criticism Debiasing Method for GloVe Embeddings",
    "abstract": "It is well-documented that word embeddings trained on large public corpora\nconsistently exhibit known human social biases. Although many methods for\ndebiasing exist, almost all fixate on completely eliminating biased information\nfrom the embeddings and often diminish training set size in the process. In\nthis paper, we present a simple yet effective method for debiasing GloVe word\nembeddings (Pennington et al., 2014) which works by incorporating explicit\ninformation about training set bias rather than removing biased data outright.\nOur method runs quickly and efficiently with the help of a fast bias gradient\napproximation method from Brunet et al. (2019). As our approach is akin to the\nnotion of 'source criticism' in the humanities, we term our method\nSource-Critical GloVe (SC-GloVe). We show that SC-GloVe reduces the effect size\non Word Embedding Association Test (WEAT) sets without sacrificing training\ndata or TOP-1 performance.",
    "descriptor": "",
    "authors": [
      "Hope McGovern"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13382"
  },
  {
    "id": "arXiv:2106.13384",
    "title": "Finite elements for divdiv-conforming symmetric tensors in arbitrary  dimension",
    "abstract": "Several div-conforming and divdiv-conforming finite elements for symmetric\ntensors on simplexes in arbitrary dimension are constructed in this work. The\nshape function space is first split as the trace space and the bubble space.\nThe later is further decomposed into the null space of the differential\noperator and its orthogonal complement. Instead of characterization of these\nsubspaces of the shape function space, characterization of the duals spaces are\nprovided. Vector div-conforming finite elements are firstly constructed as an\nintroductory example. Then new symmetric div-conforming finite elements are\nconstructed. The dual subspaces are then used as build blocks to construct\ndivdiv conforming finite elements.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Long Chen",
      "Xuehai Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13384"
  },
  {
    "id": "arXiv:2106.13385",
    "title": "Trends, Politics, Sentiments, and Misinformation: Understanding People's  Reactions to COVID-19 During its Early Stages",
    "abstract": "The sudden outbreak of COVID-19 resulted in large volumes of data shared on\ndifferent social media platforms. Analyzing and visualizing these data is\ndoubtlessly essential to having a deep understanding of the pandemic's impacts\non people's lives and their reactions to them. In this work, we conduct a\nlarge-scale spatiotemporal data analytic study to understand peoples' reactions\nto the COVID-19 pandemic during its early stages. In particular, we analyze a\nJSON-based dataset that is collected from news/messages/boards/blogs in English\nabout COVID-19 over a period of 4 months, for a total of 5.2M posts. The data\nare collected from December 2019 to March 2020 from several social media\nplatforms such as Facebook, LinkedIn, Pinterest, StumbleUpon and VK. Our study\naims mainly to understand which implications of COVID-19 have interested social\nmedia users the most and how did they vary over time, the spatiotemporal\ndistribution of misinformation, and the public opinion toward public figures\nduring the pandemic. Our results can be used by many parties (e.g.,\ngovernments, psychologists, etc.) to make more informative decisions, taking\ninto account the actual interests and opinions of the people.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Omar Abdel Wahab",
      "Ali Mustafa",
      "Andr\u00e9 Bertrand Abisseck Bamatakina"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.13385"
  },
  {
    "id": "arXiv:2106.13386",
    "title": "Balancing Accuracy and Fairness for Interactive Recommendation with  Reinforcement Learning",
    "abstract": "Fairness in recommendation has attracted increasing attention due to bias and\ndiscrimination possibly caused by traditional recommenders. In Interactive\nRecommender Systems (IRS), user preferences and the system's fairness status\nare constantly changing over time. Existing fairness-aware recommenders mainly\nconsider fairness in static settings. Directly applying existing methods to IRS\nwill result in poor recommendation. To resolve this problem, we propose a\nreinforcement learning based framework, FairRec, to dynamically maintain a\nlong-term balance between accuracy and fairness in IRS. User preferences and\nthe system's fairness status are jointly compressed into the state\nrepresentation to generate recommendations. FairRec aims at maximizing our\ndesigned cumulative reward that combines accuracy and fairness. Extensive\nexperiments validate that FairRec can improve fairness, while preserving good\nrecommendation quality.",
    "descriptor": "",
    "authors": [
      "Weiwen Liu",
      "Feng Liu",
      "Ruiming Tang",
      "Ben Liao",
      "Guangyong Chen",
      "Pheng Ann Heng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.13386"
  },
  {
    "id": "arXiv:2106.13387",
    "title": "Bayesian Eye Tracking",
    "abstract": "Model-based eye tracking has been a dominant approach for eye gaze tracking\nbecause of its ability to generalize to different subjects, without the need of\nany training data and eye gaze annotations. Model-based eye tracking, however,\nis susceptible to eye feature detection errors, in particular for eye tracking\nin the wild. To address this issue, we propose a Bayesian framework for\nmodel-based eye tracking. The proposed system consists of a cascade-Bayesian\nConvolutional Neural Network (c-BCNN) to capture the probabilistic\nrelationships between eye appearance and its landmarks, and a geometric eye\nmodel to estimate eye gaze from the eye landmarks. Given a testing eye image,\nthe Bayesian framework can generate, through Bayesian inference, the eye gaze\ndistribution without explicit landmark detection and model training, based on\nwhich it not only estimates the most likely eye gaze but also its uncertainty.\nFurthermore, with Bayesian inference instead of point-based inference, our\nmodel can not only generalize better to different sub-jects, head poses, and\nenvironments but also is robust to image noise and landmark detection errors.\nFinally, with the estimated gaze uncertainty, we can construct a cascade\narchitecture that allows us to progressively improve gaze estimation accuracy.\nCompared to state-of-the-art model-based and learning-based methods, the\nproposed Bayesian framework demonstrates significant improvement in\ngeneralization capability across several benchmark datasets and in accuracy and\nrobustness under challenging real-world conditions.",
    "descriptor": "",
    "authors": [
      "Qiang Ji",
      "Kang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13387"
  },
  {
    "id": "arXiv:2106.13388",
    "title": "Influences on Drivers' Understandings of Systems by Presenting Image  Recognition Results",
    "abstract": "It is essential to help drivers have appropriate understandings of level 2\nautomated driving systems for keeping driving safety. A human machine interface\n(HMI) was proposed to present real time results of image recognition by the\nautomated driving systems to drivers. It was expected that drivers could better\nunderstand the capabilities of the systems by observing the proposed HMI.\nDriving simulator experiments with 18 participants were preformed to evaluate\nthe effectiveness of the proposed system. Experimental results indicated that\nthe proposed HMI could effectively inform drivers of potential risks\ncontinuously and help drivers better understand the level 2 automated driving\nsystems.",
    "descriptor": "",
    "authors": [
      "Bo Yang",
      "Koichiro Inoue",
      "Satoshi Kitazaki",
      "Kimihiko Nakano"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.13388"
  },
  {
    "id": "arXiv:2106.13389",
    "title": "Energy-Based Generative Cooperative Saliency Prediction",
    "abstract": "Conventional saliency prediction models typically learn a deterministic\nmapping from images to the corresponding ground truth saliency maps. In this\npaper, we study the saliency prediction problem from the perspective of\ngenerative models by learning a conditional probability distribution over\nsaliency maps given an image, and treating the prediction as a sampling\nprocess. Specifically, we propose a generative cooperative saliency prediction\nframework based on the generative cooperative networks, where a conditional\nlatent variable model and a conditional energy-based model are jointly trained\nto predict saliency in a cooperative manner. We call our model the SalCoopNets.\nThe latent variable model serves as a fast but coarse predictor to efficiently\nproduce an initial prediction, which is then refined by the iterative Langevin\nrevision of the energy-based model that serves as a fine predictor. Such a\ncoarse-to-fine cooperative saliency prediction strategy offers the best of both\nworlds. Moreover, we generalize our framework to the scenario of weakly\nsupervised saliency prediction, where saliency annotation of training images is\npartially observed, by proposing a cooperative learning while recovering\nstrategy. Lastly, we show that the learned energy function can serve as a\nrefinement module that can refine the results of other pre-trained saliency\nprediction models. Experimental results show that our generative model can\nachieve state-of-the-art performance. Our code is publicly available at:\n\\url{https://github.com/JingZhang617/SalCoopNets}.",
    "descriptor": "",
    "authors": [
      "Jing Zhang",
      "Jianwen Xie",
      "Zilong Zheng",
      "Nick Barnes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13389"
  },
  {
    "id": "arXiv:2106.13391",
    "title": "HAN: An Efficient Hierarchical Self-Attention Network for Skeleton-Based  Gesture Recognition",
    "abstract": "Previous methods for skeleton-based gesture recognition mostly arrange the\nskeleton sequence into a pseudo picture or spatial-temporal graph and apply\ndeep Convolutional Neural Network (CNN) or Graph Convolutional Network (GCN)\nfor feature extraction. Although achieving superior results, these methods have\ninherent limitations in dynamically capturing local features of interactive\nhand parts, and the computing efficiency still remains a serious issue. In this\nwork, the self-attention mechanism is introduced to alleviate this problem.\nConsidering the hierarchical structure of hand joints, we propose an efficient\nhierarchical self-attention network (HAN) for skeleton-based gesture\nrecognition, which is based on pure self-attention without any CNN, RNN or GCN\noperators. Specifically, the joint self-attention module is used to capture\nspatial features of fingers, the finger self-attention module is designed to\naggregate features of the whole hand. In terms of temporal features, the\ntemporal self-attention module is utilized to capture the temporal dynamics of\nthe fingers and the entire hand. Finally, these features are fused by the\nfusion self-attention module for gesture classification. Experiments show that\nour method achieves competitive results on three gesture recognition datasets\nwith much lower computational complexity.",
    "descriptor": "\nComments: Under peer review for TCSVT\n",
    "authors": [
      "Jianbo Liu",
      "Ying Wang",
      "Shiming Xiang",
      "Chunhong Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13391"
  },
  {
    "id": "arXiv:2106.13393",
    "title": "Interpreting Depression From Question-wise Long-term Video Recording of  SDS Evaluation",
    "abstract": "Self-Rating Depression Scale (SDS) questionnaire has frequently been used for\nefficient depression preliminary screening. However, the uncontrollable\nself-administered measure can be easily affected by insouciantly or deceptively\nanswering, and producing the different results with the clinician-administered\nHamilton Depression Rating Scale (HDRS) and the final diagnosis. Clinically,\nfacial expression (FE) and actions play a vital role in clinician-administered\nevaluation, while FE and action are underexplored for self-administered\nevaluations. In this work, we collect a novel dataset of 200 subjects to\nevidence the validity of self-rating questionnaires with their corresponding\nquestion-wise video recording. To automatically interpret depression from the\nSDS evaluation and the paired video, we propose an end-to-end hierarchical\nframework for the long-term variable-length video, which is also conditioned on\nthe questionnaire results and the answering time. Specifically, we resort to a\nhierarchical model which utilizes a 3D CNN for local temporal pattern\nexploration and a redundancy-aware self-attention (RAS) scheme for\nquestion-wise global feature aggregation. Targeting for the redundant long-term\nFE video processing, our RAS is able to effectively exploit the correlations of\neach video clip within a question set to emphasize the discriminative\ninformation and eliminate the redundancy based on feature pair-wise affinity.\nThen, the question-wise video feature is concatenated with the questionnaire\nscores for final depression detection. Our thorough evaluations also show the\nvalidity of fusing SDS evaluation and its video recording, and the superiority\nof our framework to the conventional state-of-the-art temporal modeling\nmethods.",
    "descriptor": "\nComments: Published in IEEE Journal of Biomedical and Health Informatics\n",
    "authors": [
      "Wanqing Xie",
      "Lizhong Liang",
      "Yao Lu",
      "Chen Wang",
      "Jihong Shen",
      "Hui Luo",
      "Xiaofeng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.13393"
  },
  {
    "id": "arXiv:2106.13394",
    "title": "Countering Adversarial Examples: Combining Input Transformation and  Noisy Training",
    "abstract": "Recent studies have shown that neural network (NN) based image classifiers\nare highly vulnerable to adversarial examples, which poses a threat to\nsecurity-sensitive image recognition task. Prior work has shown that JPEG\ncompression can combat the drop in classification accuracy on adversarial\nexamples to some extent. But, as the compression ratio increases, traditional\nJPEG compression is insufficient to defend those attacks but can cause an\nabrupt accuracy decline to the benign images. In this paper, with the aim of\nfully filtering the adversarial perturbations, we firstly make modifications to\ntraditional JPEG compression algorithm which becomes more favorable for NN.\nSpecifically, based on an analysis of the frequency coefficient, we design a\nNN-favored quantization table for compression. Considering compression as a\ndata augmentation strategy, we then combine our model-agnostic preprocess with\nnoisy training. We fine-tune the pre-trained model by training with images\nencoded at different compression levels, thus generating multiple classifiers.\nFinally, since lower (higher) compression ratio can remove both perturbations\nand original features slightly (aggressively), we use these trained multiple\nmodels for model ensemble. The majority vote of the ensemble of models is\nadopted as final predictions. Experiments results show our method can improve\ndefense efficiency while maintaining original accuracy.",
    "descriptor": "",
    "authors": [
      "Cheng Zhang",
      "Pan Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.13394"
  },
  {
    "id": "arXiv:2106.13397",
    "title": "Pheno-Mapper: An Interactive Toolbox for the Visual Exploration of  Phenomics Data",
    "abstract": "High-throughput technologies to collect field data have made observations\npossible at scale in several branches of life sciences. The data collected can\nrange from the molecular level (genotypes) to physiological (phenotypic traits)\nand environmental observations (e.g., weather, soil conditions). These vast\nswathes of data, collectively referred to as phenomics data, represent a\ntreasure trove of key scientific knowledge on the dynamics of the underlying\nbiological system. However, extracting information and insights from these\ncomplex datasets remains a significant challenge owing to their\nmultidimensionality and lack of prior knowledge about their complex structure.\nIn this paper, we present Pheno-Mapper, an interactive toolbox for the\nexploratory analysis and visualization of large-scale phenomics data. Our\napproach uses the mapper framework to perform a topological analysis of the\ndata, and subsequently render visual representations with built-in data\nanalysis and machine learning capabilities. We demonstrate the utility of this\nnew tool on real-world plant (e.g., maize) phenomics datasets. In comparison to\nexisting approaches, the main advantage of Pheno-Mapper is that it provides\nrich, interactive capabilities in the exploratory analysis of phenomics data,\nand it integrates visual analytics with data analysis and machine learning in\nan easily extensible way. In particular, Pheno-Mapper allows the interactive\nselection of subpopulations guided by a topological summary of the data and\napplies data mining and machine learning to these selected subpopulations for\nin-depth exploration.",
    "descriptor": "",
    "authors": [
      "Youjia Zhou",
      "Methun Kamruzzaman",
      "Patrick Schnable",
      "Bala Krishnamoorthy",
      "Ananth Kalyanaraman",
      "Bei Wang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Human-Computer Interaction (cs.HC)",
      "Algebraic Topology (math.AT)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2106.13397"
  },
  {
    "id": "arXiv:2106.13401",
    "title": "Decomposed Mutual Information Estimation for Contrastive Representation  Learning",
    "abstract": "Recent contrastive representation learning methods rely on estimating mutual\ninformation (MI) between multiple views of an underlying context. E.g., we can\nderive multiple views of a given image by applying data augmentation, or we can\nsplit a sequence into views comprising the past and future of some step in the\nsequence. Contrastive lower bounds on MI are easy to optimize, but have a\nstrong underestimation bias when estimating large amounts of MI. We propose\ndecomposing the full MI estimation problem into a sum of smaller estimation\nproblems by splitting one of the views into progressively more informed\nsubviews and by applying the chain rule on MI between the decomposed views.\nThis expression contains a sum of unconditional and conditional MI terms, each\nmeasuring modest chunks of the total MI, which facilitates approximation via\ncontrastive bounds. To maximize the sum, we formulate a contrastive lower bound\non the conditional MI which can be approximated efficiently. We refer to our\ngeneral approach as Decomposed Estimation of Mutual Information (DEMI). We show\nthat DEMI can capture a larger amount of MI than standard non-decomposed\ncontrastive bounds in a synthetic setting, and learns better representations in\na vision domain and for dialogue generation.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Alessandro Sordoni",
      "Nouha Dziri",
      "Hannes Schulz",
      "Geoff Gordon",
      "Phil Bachman",
      "Remi Tachet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13401"
  },
  {
    "id": "arXiv:2106.13402",
    "title": "Efficient algorithms for computing rank-revealing factorizations on a  GPU",
    "abstract": "Standard rank-revealing factorizations such as the singular value\ndecomposition and column pivoted QR factorization are challenging to implement\nefficiently on a GPU. A major difficulty in this regard is the inability of\nstandard algorithms to cast most operations in terms of the Level-3 BLAS. This\npaper presents two alternative algorithms for computing a rank-revealing\nfactorization of the form $A = U T V^*$, where $U$ and $V$ are orthogonal and\n$T$ is triangular. Both algorithms use randomized projection techniques to cast\nmost of the flops in terms of matrix-matrix multiplication, which is\nexceptionally efficient on the GPU. Numerical experiments illustrate that these\nalgorithms achieve an order of magnitude acceleration over finely tuned GPU\nimplementations of the SVD while providing low-rank approximation errors close\nto that of the SVD.",
    "descriptor": "",
    "authors": [
      "Nathan Heavner",
      "Chao Chen",
      "Abinand Gopal",
      "Per-Gunnar Martinsson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2106.13402"
  },
  {
    "id": "arXiv:2106.13403",
    "title": "ParaLaw Nets -- Cross-lingual Sentence-level Pretraining for Legal Text  Processing",
    "abstract": "Ambiguity is a characteristic of natural language, which makes expression\nideas flexible. However, in a domain that requires accurate statements, it\nbecomes a barrier. Specifically, a single word can have many meanings and\nmultiple words can have the same meaning. When translating a text into a\nforeign language, the translator needs to determine the exact meaning of each\nelement in the original sentence to produce the correct translation sentence.\nFrom that observation, in this paper, we propose ParaLaw Nets, a pretrained\nmodel family using sentence-level cross-lingual information to reduce ambiguity\nand increase the performance in legal text processing. This approach achieved\nthe best result in the Question Answering task of COLIEE-2021.",
    "descriptor": "\nComments: Also published in COLIEE 2021's Proceeding\n",
    "authors": [
      "Ha-Thanh Nguyen",
      "Vu Tran",
      "Phuong Minh Nguyen",
      "Thi-Hai-Yen Vuong",
      "Quan Minh Bui",
      "Chau Minh Nguyen",
      "Binh Tran Dang",
      "Minh Le Nguyen",
      "Ken Satoh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13403"
  },
  {
    "id": "arXiv:2106.13405",
    "title": "JNLP Team: Deep Learning Approaches for Legal Processing Tasks in COLIEE  2021",
    "abstract": "COLIEE is an annual competition in automatic computerized legal text\nprocessing. Automatic legal document processing is an ambitious goal, and the\nstructure and semantics of the law are often far more complex than everyday\nlanguage. In this article, we survey and report our methods and experimental\nresults in using deep learning in legal document processing. The results show\nthe difficulties as well as potentials in this family of approaches.",
    "descriptor": "\nComments: Also published in COLIEE 2021's proceeding\n",
    "authors": [
      "Ha-Thanh Nguyen",
      "Phuong Minh Nguyen",
      "Thi-Hai-Yen Vuong",
      "Quan Minh Bui",
      "Chau Minh Nguyen",
      "Binh Tran Dang",
      "Vu Tran",
      "Minh Le Nguyen",
      "Ken Satoh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.13405"
  },
  {
    "id": "arXiv:2106.13409",
    "title": "Generative Modeling for Multi-task Visual Learning",
    "abstract": "Generative modeling has recently shown great promise in computer vision, but\nit has mostly focused on synthesizing visually realistic images. In this paper,\nmotivated by multi-task learning of shareable feature representations, we\nconsider a novel problem of learning a shared generative model that is useful\nacross various visual perception tasks. Correspondingly, we propose a general\nmulti-task oriented generative modeling (MGM) framework, by coupling a\ndiscriminative multi-task network with a generative network. While it is\nchallenging to synthesize both RGB images and pixel-level annotations in\nmulti-task scenarios, our framework enables us to use synthesized images paired\nwith only weak annotations (i.e., image-level scene labels) to facilitate\nmultiple visual tasks. Experimental evaluation on challenging multi-task\nbenchmarks, including NYUv2 and Taskonomy, demonstrates that our MGM framework\nimproves the performance of all the tasks by large margins, consistently\noutperforming state-of-the-art multi-task approaches.",
    "descriptor": "",
    "authors": [
      "Zhipeng Bao",
      "Martial Hebert",
      "Yu-Xiong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13409"
  },
  {
    "id": "arXiv:2106.13411",
    "title": "Fine-grained Geolocation Prediction of Tweets with Human Machine  Collaboration",
    "abstract": "Twitter is a useful resource to analyze peoples' opinions on various topics.\nOften these topics are correlated or associated with locations from where these\nTweet posts are made. For example, restaurant owners may need to know where\ntheir target customers eat with respect to the sentiment of the posts made\nrelated to food, policy planners may need to analyze citizens' opinion on\nrelevant issues such as crime, safety, congestion, etc. with respect to\nspecific parts of the city, or county or state. As promising as this is, less\nthan $1\\%$ of the crawled Tweet posts come with geolocation tags. That makes\naccurate prediction of Tweet posts for the non geo-tagged tweets very critical\nto analyze data in various domains. In this research, we utilized millions of\nTwitter posts and end-users domain expertise to build a set of deep neural\nnetwork models using natural language processing (NLP) techniques, that\npredicts the geolocation of non geo-tagged Tweet posts at various level of\ngranularities such as neighborhood, zipcode, and longitude with latitudes. With\nmultiple neural architecture experiments, and a collaborative human-machine\nworkflow design, our ongoing work on geolocation detection shows promising\nresults that empower end-users to correlate relationship between variables of\nchoice with the location information.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Florina Dutt",
      "Subhajit Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13411"
  },
  {
    "id": "arXiv:2106.13414",
    "title": "The Price of Tolerance in Distribution Testing",
    "abstract": "We revisit the problem of tolerant distribution testing. That is, given\nsamples from an unknown distribution $p$ over $\\{1, \\dots, n\\}$, is it\n$\\varepsilon_1$-close to or $\\varepsilon_2$-far from a reference distribution\n$q$ (in total variation distance)? Despite significant interest over the past\ndecade, this problem is well understood only in the extreme cases. In the\nnoiseless setting (i.e., $\\varepsilon_1 = 0$) the sample complexity is\n$\\Theta(\\sqrt{n})$, strongly sublinear in the domain size. At the other end of\nthe spectrum, when $\\varepsilon_1 = \\varepsilon_2/2$, the sample complexity\njumps to the barely sublinear $\\Theta(n/\\log n)$. However, very little is known\nabout the intermediate regime. We fully characterize the price of tolerance in\ndistribution testing as a function of $n$, $\\varepsilon_1$, $\\varepsilon_2$, up\nto a single $\\log n$ factor. Specifically, we show the sample complexity to be\n\\[\\tilde \\Theta\\left(\\frac{\\sqrt{n}}{\\varepsilon_2^{2}} + \\frac{n}{\\log n}\n\\cdot \\max\n\\left\\{\\frac{\\varepsilon_1}{\\varepsilon_2^2},\\left(\\frac{\\varepsilon_1}{\\varepsilon_2^2}\\right)^{\\!\\!2}\\right\\}\\right),\\]\nproviding a smooth tradeoff between the two previously known cases. We also\nprovide a similar characterization for the problem of tolerant equivalence\ntesting, where both $p$ and $q$ are unknown. Surprisingly, in both cases, the\nmain quantity dictating the sample complexity is the ratio\n$\\varepsilon_1/\\varepsilon_2^2$, and not the more intuitive\n$\\varepsilon_1/\\varepsilon_2$. Of particular technical interest is our lower\nbound framework, which involves novel approximation-theoretic tools required to\nhandle the asymmetry between $\\varepsilon_1$ and $\\varepsilon_2$, a challenge\nabsent from previous works.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment L. Canonne",
      "Ayush Jain",
      "Gautam Kamath",
      "Jerry Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13414"
  },
  {
    "id": "arXiv:2106.13415",
    "title": "Building Intelligent Autonomous Navigation Agents",
    "abstract": "Breakthroughs in machine learning in the last decade have led to `digital\nintelligence', i.e. machine learning models capable of learning from vast\namounts of labeled data to perform several digital tasks such as speech\nrecognition, face recognition, machine translation and so on. The goal of this\nthesis is to make progress towards designing algorithms capable of `physical\nintelligence', i.e. building intelligent autonomous navigation agents capable\nof learning to perform complex navigation tasks in the physical world involving\nvisual perception, natural language understanding, reasoning, planning, and\nsequential decision making. Despite several advances in classical navigation\nmethods in the last few decades, current navigation agents struggle at\nlong-term semantic navigation tasks. In the first part of the thesis, we\ndiscuss our work on short-term navigation using end-to-end reinforcement\nlearning to tackle challenges such as obstacle avoidance, semantic perception,\nlanguage grounding, and reasoning. In the second part, we present a new class\nof navigation methods based on modular learning and structured explicit map\nrepresentations, which leverage the strengths of both classical and end-to-end\nlearning methods, to tackle long-term navigation tasks. We show that these\nmethods are able to effectively tackle challenges such as localization,\nmapping, long-term planning, exploration and learning semantic priors. These\nmodular learning methods are capable of long-term spatial and semantic\nunderstanding and achieve state-of-the-art results on various navigation tasks.",
    "descriptor": "\nComments: CMU Ph.D. Thesis, March 2021. For more details see this http URL\n",
    "authors": [
      "Devendra Singh Chaplot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.13415"
  },
  {
    "id": "arXiv:2106.13416",
    "title": "Diversifying Semantic Image Synthesis and Editing via Class- and  Layer-wise VAEs",
    "abstract": "Semantic image synthesis is a process for generating photorealistic images\nfrom a single semantic mask. To enrich the diversity of multimodal image\nsynthesis, previous methods have controlled the global appearance of an output\nimage by learning a single latent space. However, a single latent code is often\ninsufficient for capturing various object styles because object appearance\ndepends on multiple factors. To handle individual factors that determine object\nstyles, we propose a class- and layer-wise extension to the variational\nautoencoder (VAE) framework that allows flexible control over each object class\nat the local to global levels by learning multiple latent spaces. Furthermore,\nwe demonstrate that our method generates images that are both plausible and\nmore diverse compared to state-of-the-art methods via extensive experiments\nwith real and synthetic datasets inthree different domains. We also show that\nour method enables a wide range of applications in image synthesis and editing\ntasks.",
    "descriptor": "\nComments: Accepted to Pacific Graphics 2020, codes available at this https URL\n",
    "authors": [
      "Yuki Endo",
      "Yoshihiro Kanamori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.13416"
  },
  {
    "id": "arXiv:2106.13419",
    "title": "Basis-MelGAN: Efficient Neural Vocoder Based on Audio Decomposition",
    "abstract": "Recent studies have shown that neural vocoders based on generative\nadversarial network (GAN) can generate audios with high quality. While GAN\nbased neural vocoders have shown to be computationally much more efficient than\nthose based on autoregressive predictions, the real-time generation of the\nhighest quality audio on CPU is still a very challenging task. One major\ncomputation of all GAN-based neural vocoders comes from the stacked upsampling\nlayers, which were designed to match the length of the waveform's length of\noutput and temporal resolution. Meanwhile, the computational complexity of\nupsampling networks is closely correlated with the numbers of samples generated\nfor each window. To reduce the computation of upsampling layers, we propose a\nnew GAN based neural vocoder called Basis-MelGAN where the raw audio samples\nare decomposed with a learned basis and their associated weights. As the\nprediction targets of Basis-MelGAN are the weight values associated with each\nlearned basis instead of the raw audio samples, the upsampling layers in\nBasis-MelGAN can be designed with much simpler networks. Compared with other\nGAN based neural vocoders, the proposed Basis-MelGAN could produce comparable\nhigh-quality audio but significantly reduced computational complexity from\nHiFi-GAN V1's 17.74 GFLOPs to 7.95 GFLOPs.",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2021\n",
    "authors": [
      "Zhengxi Liu",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.13419"
  },
  {
    "id": "arXiv:2106.13420",
    "title": "Identifying malicious accounts in Blockchains using Domain Names and  associated temporal properties",
    "abstract": "The rise in the adoption of blockchain technology has led to increased\nillegal activities by cyber-criminals costing billions of dollars. Many machine\nlearning algorithms are applied to detect such illegal behavior. These\nalgorithms are often trained on the transaction behavior and, in some cases,\ntrained on the vulnerabilities that exist in the system. In our approach, we\nstudy the feasibility of using metadata such as Domain Name (DN) associated\nwith the account in the blockchain and identify whether an account should be\ntagged malicious or not. Here, we leverage the temporal aspects attached to the\nDNs. Our results identify 144930 DNs that show malicious behavior, and out of\nthese, 54114 DNs show persistent malicious behavior over time. Nonetheless,\nnone of these identified malicious DNs were reported in new officially tagged\nmalicious blockchain DNs.",
    "descriptor": "\nComments: Submitted to a journal\n",
    "authors": [
      "Rohit Kumar Sachan",
      "Rachit Agarwal",
      "Sandeep Kumar Shukla"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13420"
  },
  {
    "id": "arXiv:2106.13422",
    "title": "Vulnerability and Transaction behavior based detection of Malicious  Smart Contracts",
    "abstract": "Smart Contracts (SCs) in Ethereum can automate tasks and provide different\nfunctionalities to a user. Such automation is enabled by the `Turing-complete'\nnature of the programming language (Solidity) in which SCs are written. This\nalso opens up different vulnerabilities and bugs in SCs that malicious actors\nexploit to carry out malicious or illegal activities on the cryptocurrency\nplatform. In this work, we study the correlation between malicious activities\nand the vulnerabilities present in SCs and find that some malicious activities\nare correlated with certain types of vulnerabilities. We then develop and study\nthe feasibility of a scoring mechanism that corresponds to the severity of the\nvulnerabilities present in SCs to determine if it is a relevant feature to\nidentify suspicious SCs. We analyze the utility of severity score towards\ndetection of suspicious SCs using unsupervised machine learning (ML) algorithms\nacross different temporal granularities and identify behavioral changes. In our\nexperiments with on-chain SCs, we were able to find a total of 1094 benign SCs\nacross different granularities which behave similar to malicious SCs, with the\ninclusion of the smart contract vulnerability scores in the feature set.",
    "descriptor": "\nComments: Submitted to a conf\n",
    "authors": [
      "Rachit Agarwal",
      "Tanmay Thapliyal",
      "Sandeep Kumar Shukla"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13422"
  },
  {
    "id": "arXiv:2106.13423",
    "title": "Federated Graph Classification over Non-IID Graphs",
    "abstract": "Federated learning has emerged as an important paradigm for training machine\nlearning models in different domains. For graph-level tasks such as graph\nclassification, graphs can also be regarded as a special type of data samples,\nwhich can be collected and stored in separate local systems. Similar to other\ndomains, multiple local systems, each holding a small set of graphs, may\nbenefit from collaboratively training a powerful graph mining model, such as\nthe popular graph neural networks (GNNs). To provide more motivation towards\nsuch endeavors, we analyze real-world graphs from different domains to confirm\nthat they indeed share certain graph properties that are statistically\nsignificant compared with random graphs. However, we also find that different\nsets of graphs, even from the same domain or same dataset, are non-IID\nregarding both graph structures and node features. To handle this, we propose a\ngraph clustering federated learning (GCFL) framework that dynamically finds\nclusters of local systems based on the gradients of GNNs, and theoretically\njustify that such clusters can reduce the structure and feature heterogeneity\namong graphs owned by the local systems. Moreover, we observe the gradients of\nGNNs to be rather fluctuating in GCFL which impedes high-quality clustering,\nand design a gradient sequence-based clustering mechanism based on dynamic time\nwarping (GCFL+). Extensive experimental results and in-depth analysis\ndemonstrate the effectiveness of our proposed frameworks.",
    "descriptor": "",
    "authors": [
      "Han Xie",
      "Jing Ma",
      "Li Xiong",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13423"
  },
  {
    "id": "arXiv:2106.13425",
    "title": "Half-body Portrait Relighting with Overcomplete Lighting Representation",
    "abstract": "We present a neural-based model for relighting a half-body portrait image by\nsimply referring to another portrait image with the desired lighting condition.\nRather than following classical inverse rendering methodology that involves\nestimating normals, albedo and environment maps, we implicitly encode the\nsubject and lighting in a latent space, and use these latent codes to generate\nrelighted images by neural rendering. A key technical innovation is the use of\na novel overcomplete lighting representation, which facilitates lighting\ninterpolation in the latent space, as well as helping regularize the\nself-organization of the lighting latent space during training. In addition, we\npropose a novel multiplicative neural render that more effectively combines the\nsubject and lighting latent codes for rendering. We also created a large-scale\nphotorealistic rendered relighting dataset for training, which allows our model\nto generalize well to real images. Extensive experiments demonstrate that our\nsystem not only outperforms existing methods for referral-based portrait\nrelighting, but also has the capability generate sequences of relighted images\nvia lighting rotations.",
    "descriptor": "",
    "authors": [
      "Guoxian Song",
      "Tat-Jen Cham",
      "Jianfei Cai",
      "Jianmin Zheng"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.13425"
  },
  {
    "id": "arXiv:2106.13427",
    "title": "Reliable Graph Neural Network Explanations Through Adversarial Training",
    "abstract": "Graph neural network (GNN) explanations have largely been facilitated through\npost-hoc introspection. While this has been deemed successful, many post-hoc\nexplanation methods have been shown to fail in capturing a model's learned\nrepresentation. Due to this problem, it is worthwhile to consider how one might\ntrain a model so that it is more amenable to post-hoc analysis. Given the\nsuccess of adversarial training in the computer vision domain to train models\nwith more reliable representations, we propose a similar training paradigm for\nGNNs and analyze the respective impact on a model's explanations. In instances\nwithout ground truth labels, we also determine how well an explanation method\nis utilizing a model's learned representation through a new metric and\ndemonstrate adversarial training can help better extract domain-relevant\ninsights in chemistry.",
    "descriptor": "\nComments: 4 pages, 3 figures, ICML Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI\n",
    "authors": [
      "Donald Loveland",
      "Shusen Liu",
      "Bhavya Kailkhura",
      "Anna Hiszpanski",
      "Yong Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13427"
  },
  {
    "id": "arXiv:2106.13428",
    "title": "Temporal semi-discretizations of a backward semilinear stochastic  evolution equation",
    "abstract": "This paper studies the convergence of three temporal semi-discretizations for\na backward semilinear stochastic evolution equation. For general terminal value\nand general coefficient with Lipschitz continuity, the convergence of three\nEuler type temporal semi-discretizations is established without regularity\nassumption on the solution. Moreover, the third temporal semi-discretization is\napplied to a stochastic linear quadratic control problem, and an explicit\nconvergence rate is derived.",
    "descriptor": "",
    "authors": [
      "Binjie Li",
      "Xiaoping Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.13428"
  },
  {
    "id": "arXiv:2106.13429",
    "title": "Branch Prediction as a Reinforcement Learning Problem: Why, How and Case  Studies",
    "abstract": "Recent years have seen stagnating improvements to branch predictor (BP)\nefficacy and a dearth of fresh ideas in branch predictor design, calling for\nfresh thinking in this area. This paper argues that looking at BP from the\nviewpoint of Reinforcement Learning (RL) facilitates systematic reasoning\nabout, and exploration of, BP designs. We describe how to apply the RL\nformulation to branch predictors, show that existing predictors can be\nsuccinctly expressed in this formulation, and study two RL-based variants of\nconventional BPs.",
    "descriptor": "\nComments: 6 pages, appeared in ML workshop for Computer Architecture and Systems 2021\n",
    "authors": [
      "Anastasios Zouzias",
      "Kleovoulos Kalaitzidis",
      "Boris Grot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13429"
  },
  {
    "id": "arXiv:2106.13430",
    "title": "Subgraph Federated Learning with Missing Neighbor Generation",
    "abstract": "Graphs have been widely used in data mining and machine learning due to their\nunique representation of real-world objects and their interactions. As graphs\nare getting bigger and bigger nowadays, it is common to see their subgraphs\nseparately collected and stored in multiple local systems. Therefore, it is\nnatural to consider the subgraph federated learning setting, where each local\nsystem holding a small subgraph that may be biased from the distribution of the\nwhole graph. Hence, the subgraph federated learning aims to collaboratively\ntrain a powerful and generalizable graph mining model without directly sharing\ntheir graph data. In this work, towards the novel yet realistic setting of\nsubgraph federated learning, we propose two major techniques: (1) FedSage,\nwhich trains a GraphSage model based on FedAvg to integrate node features, link\nstructures, and task labels on multiple local subgraphs; (2) FedSage+, which\ntrains a missing neighbor generator along FedSage to deal with missing links\nacross local subgraphs. Empirical results on four real-world graph datasets\nwith synthesized subgraph federated learning settings demonstrate the\neffectiveness and efficiency of our proposed techniques. At the same time,\nconsistent theoretical implications are made towards their generalization\nability on the global graphs.",
    "descriptor": "",
    "authors": [
      "Ke Zhang",
      "Carl Yang",
      "Xiaoxiao Li",
      "Lichao Sun",
      "Siu Ming Yiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13430"
  },
  {
    "id": "arXiv:2106.13432",
    "title": "Hierarchical Object-oriented Spatio-Temporal Reasoning for Video  Question Answering",
    "abstract": "Video Question Answering (Video QA) is a powerful testbed to develop new AI\ncapabilities. This task necessitates learning to reason about objects,\nrelations, and events across visual and linguistic domains in space-time.\nHigh-level reasoning demands lifting from associative visual pattern\nrecognition to symbol-like manipulation over objects, their behavior and\ninteractions. Toward reaching this goal we propose an object-oriented reasoning\napproach in that video is abstracted as a dynamic stream of interacting\nobjects. At each stage of the video event flow, these objects interact with\neach other, and their interactions are reasoned about with respect to the query\nand under the overall context of a video. This mechanism is materialized into a\nfamily of general-purpose neural units and their multi-level architecture\ncalled Hierarchical Object-oriented Spatio-Temporal Reasoning (HOSTR) networks.\nThis neural model maintains the objects' consistent lifelines in the form of a\nhierarchically nested spatio-temporal graph. Within this graph, the dynamic\ninteractive object-oriented representations are built up along the video\nsequence, hierarchically abstracted in a bottom-up manner, and converge toward\nthe key information for the correct answer. The method is evaluated on multiple\nmajor Video QA datasets and establishes new state-of-the-arts in these tasks.\nAnalysis into the model's behavior indicates that object-oriented reasoning is\na reliable, interpretable and efficient approach to Video QA.",
    "descriptor": "\nComments: Accepted by IJCAI 2021\n",
    "authors": [
      "Long Hoang Dang",
      "Thao Minh Le",
      "Vuong Le",
      "Truyen Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13432"
  },
  {
    "id": "arXiv:2106.13435",
    "title": "NP-DRAW: A Non-Parametric Structured Latent Variable Modelfor Image  Generation",
    "abstract": "In this paper, we present a non-parametric structured latent variable model\nfor image generation, called NP-DRAW, which sequentially draws on a latent\ncanvas in a part-by-part fashion and then decodes the image from the canvas.\nOur key contributions are as follows. 1) We propose a non-parametric prior\ndistribution over the appearance of image parts so that the latent variable\n``what-to-draw'' per step becomes a categorical random variable. This improves\nthe expressiveness and greatly eases the learning compared to Gaussians used in\nthe literature. 2) We model the sequential dependency structure of parts via a\nTransformer, which is more powerful and easier to train compared to RNNs used\nin the literature. 3) We propose an effective heuristic parsing algorithm to\npre-train the prior. Experiments on MNIST, Omniglot, CIFAR-10, and CelebA show\nthat our method significantly outperforms previous structured image models like\nDRAW and AIR and is competitive to other generic generative models. Moreover,\nwe show that our model's inherent compositionality and interpretability bring\nsignificant benefits in the low-data learning regime and latent space editing.\nCode is available at \\url{https://github.com/ZENGXH/NPDRAW}.",
    "descriptor": "\nComments: UAI2021, code at this https URL\n",
    "authors": [
      "Xiaohui Zeng",
      "Raquel Urtasun",
      "Richard Zemel",
      "Sanja Fidler",
      "Renjie Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13435"
  },
  {
    "id": "arXiv:2106.13436",
    "title": "A hybrid model-based and learning-based approach for classification  using limited number of training samples",
    "abstract": "The fundamental task of classification given a limited number of training\ndata samples is considered for physical systems with known parametric\nstatistical models. The standalone learning-based and statistical model-based\nclassifiers face major challenges towards the fulfillment of the classification\ntask using a small training set. Specifically, classifiers that solely rely on\nthe physics-based statistical models usually suffer from their inability to\nproperly tune the underlying unobservable parameters, which leads to a\nmismatched representation of the system's behaviors. Learning-based\nclassifiers, on the other hand, typically rely on a large number of training\ndata from the underlying physical process, which might not be feasible in most\npractical scenarios. In this paper, a hybrid classification method -- termed\nHyPhyLearn -- is proposed that exploits both the physics-based statistical\nmodels and the learning-based classifiers. The proposed solution is based on\nthe conjecture that HyPhyLearn would alleviate the challenges associated with\nthe individual approaches of learning-based and statistical model-based\nclassifiers by fusing their respective strengths. The proposed hybrid approach\nfirst estimates the unobservable model parameters using the available\n(suboptimal) statistical estimation procedures, and subsequently use the\nphysics-based statistical models to generate synthetic data. Then, the training\ndata samples are incorporated with the synthetic data in a learning-based\nclassifier that is based on domain-adversarial training of neural networks.\nSpecifically, in order to address the mismatch problem, the classifier learns a\nmapping from the training data and the synthetic data to a common feature\nspace. Simultaneously, the classifier is trained to find discriminative\nfeatures within this space in order to fulfill the classification task.",
    "descriptor": "\nComments: 21 pages, 8 figures, Journal\n",
    "authors": [
      "Alireza Nooraiepour",
      "Waheed U. Bajwa",
      "Narayan B. Mandayam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.13436"
  },
  {
    "id": "arXiv:2106.13439",
    "title": "Extensions of the Maximum Bichromatic Separating Rectangle Problem",
    "abstract": "In this paper, we study two extensions of the maximum bichromatic separating\nrectangle (MBSR) problem introduced in \\cite{Armaselu-CCCG, Armaselu-arXiv}.\nOne of the extensions, introduced in \\cite{Armaselu-FWCG}, is called\n\\textit{MBSR with outliers} or MBSR-O, and is a more general version of the\nMBSR problem in which the optimal rectangle is allowed to contain up to $k$\noutliers, where $k$ is given as part of the input. For MBSR-O, we improve the\nprevious known running time bounds of $O(k^7 m \\log m + n)$ to $O(k^3 m + m\n\\log m + n)$. The other extension is called \\textit{MBSR among circles} or\nMBSR-C and asks for the largest axis-aligned rectangle separating red points\nfrom blue unit circles. For MBSR-C, we provide an algorithm that runs in $O(m^2\n+ n)$ time.",
    "descriptor": "\nComments: 14 pages, 14 figures, full version of CCCG paper\n",
    "authors": [
      "Bogdan Armaselu"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.13439"
  },
  {
    "id": "arXiv:2106.13440",
    "title": "A Computationally Efficient Hamilton-Jacobi-based Formula for  State-Constrained Optimal Control Problems",
    "abstract": "This paper investigates a Hamilton-Jacobi (HJ) analysis to solve\nfinite-horizon optimal control problems for high-dimensional systems. Although\ngrid-based methods, such as the level-set method [1], numerically solve a\ngeneral class of HJ partial differential equations, the computational\ncomplexity is exponential in the dimension of the continuous state. To manage\nthis computational complexity, methods based on Lax-Hopf theory have been\ndeveloped for the state-unconstrained optimal control problem under certain\nassumptions, such as affine dynamics and state-independent stage cost. Based on\nthe Lax formula [2], this paper proposes an HJ formula for the\nstate-constrained optimal control problem for nonlinear systems. We call this\nformula \\textit{the generalized Lax formula} for the optimal control problem.\nThe HJ formula provides both the optimal cost and an optimal control signal. We\nalso provide an efficient computational method for a class of problems for\nwhich the dynamics is affine in the state, and for which the stage and terminal\ncost, as well as the state constraints, are convex in the state. This class of\nproblems does not require affine dynamics and convex stage cost in the control.\nThis paper also provides three practical examples.",
    "descriptor": "",
    "authors": [
      "Donggun Lee",
      "Claire J. Tomlin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.13440"
  },
  {
    "id": "arXiv:2106.13445",
    "title": "A Picture May Be Worth a Hundred Words for Visual Question Answering",
    "abstract": "How far can we go with textual representations for understanding pictures? In\nimage understanding, it is essential to use concise but detailed image\nrepresentations. Deep visual features extracted by vision models, such as\nFaster R-CNN, are prevailing used in multiple tasks, and especially in visual\nquestion answering (VQA). However, conventional deep visual features may\nstruggle to convey all the details in an image as we humans do. Meanwhile, with\nrecent language models' progress, descriptive text may be an alternative to\nthis problem. This paper delves into the effectiveness of textual\nrepresentations for image understanding in the specific context of VQA. We\npropose to take description-question pairs as input, instead of deep visual\nfeatures, and fed them into a language-only Transformer model, simplifying the\nprocess and the computational cost. We also experiment with data augmentation\ntechniques to increase the diversity in the training set and avoid learning\nstatistical bias. Extensive evaluations have shown that textual representations\nrequire only about a hundred words to compete with deep visual features on both\nVQA 2.0 and VQA-CP v2.",
    "descriptor": "",
    "authors": [
      "Yusuke Hirota",
      "Noa Garcia",
      "Mayu Otani",
      "Chenhui Chu",
      "Yuta Nakashima",
      "Ittetsu Taniguchi",
      "Takao Onoye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13445"
  },
  {
    "id": "arXiv:2106.13446",
    "title": "Discovering executable routine specifications from user interaction logs",
    "abstract": "Robotic Process Automation (RPA) is a technology to automate routine work\nsuch as copying data across applications or filling in document templates using\ndata from multiple applications. RPA tools allow organizations to automate a\nwide range of routines. However, identifying and scoping routines that can be\nautomated using RPA tools is time consuming. Manual identification of candidate\nroutines via interviews, walk-throughs, or job shadowing allow analysts to\nidentify the most visible routines, but these methods are not suitable when it\ncomes to identifying the long tail of routines in an organization. This article\nproposes an approach to discover automatable routines from logs of user\ninteractions with IT systems and to synthesize executable specifications for\nsuch routines. The approach starts by discovering frequent routines at a\ncontrol-flow level (candidate routines). It then determines which of these\ncandidate routines are automatable and it synthetizes an executable\nspecification for each such routine. Finally, it identifies semantically\nequivalent routines so as to produce a set of non-redundant automatable\nroutines. The article reports on an evaluation of the approach using a\ncombination of synthetic and real-life logs. The evaluation results show that\nthe approach can discover automatable routines that are known to be present in\na UI log, and that it identifies automatable routines that users recognize as\nsuch in real-life logs.",
    "descriptor": "\nComments: 41 pages, 6 figures, 10 tables. arXiv admin note: text overlap with arXiv:2008.05782\n",
    "authors": [
      "Volodymyr Leno",
      "Adriano Augusto",
      "Marlon Dumas",
      "Marcello La Rosa",
      "Fabrizio Maria Maggi",
      "Artem Polyvyanyy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.13446"
  },
  {
    "id": "arXiv:2106.13451",
    "title": "Collision Avoidance for Unmanned Aerial Vehicles in the Presence of  Static and Moving Obstacles",
    "abstract": "This paper presents a new collision avoidance procedure for unmanned aerial\nvehicles in the presence of static and moving obstacles. The proposed procedure\nis based on a new form of local parametrized guidance vector fields, called\ncollision avoidance vector fields, that produce smooth and intuitive maneuvers\naround obstacles. The maneuvers follow nominal collision-free paths which we\nrefer to as streamlines of the collision avoidance vector fields. In the case\nof multiple obstacles, the proposed procedure determines a mixed vector field\nthat blends the collision avoidance vector field of each obstacle and assumes\nits form whenever a pre-defined distance threshold is reached. Then, in\naccordance to the computed guidance vector fields, different collision\navoidance controllers that generate collision-free maneuvers are developed.\nFurthermore, it is shown that any tracking controller with convergence\nguarantees can be used with the avoidance controllers to track the streamlines\nof the collision avoidance vector fields. Finally, numerical simulations\ndemonstrate the efficacy of the proposed approach and its ability to avoid\ncollisions with static and moving pop-up threats in three different practical\nscenarios.",
    "descriptor": "\nComments: This is a revised version of the original published in the AIAA Journal of Guidance, Controls and Dynamics, Vol. 43, Iss. 1\n",
    "authors": [
      "Andrei Marchidan",
      "Efstathios Bakolas"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.13451"
  },
  {
    "id": "arXiv:2106.13455",
    "title": "Fairness Deconstructed: A Sociotechnical View of 'Fair' Algorithms in  Criminal Justice",
    "abstract": "Early studies of risk assessment algorithms used in criminal justice revealed\nwidespread racial biases. In response, machine learning researchers have\ndeveloped methods for fairness, many of which rely on equalizing empirical\nmetrics across protected attributes. Here, I recall sociotechnical perspectives\nto delineate the significant gap between fairness in theory and practice,\nfocusing on criminal justice. I (1) illustrate how social context can undermine\nanalyses that are restricted to an AI system's outputs, and (2) argue that much\nof the fair ML literature fails to account for epistemological issues with\nunderlying crime data. Instead of building AI that reifies power imbalances,\nlike risk assessment algorithms, I ask whether data science can be used to\nunderstand the root causes of structural marginalization.",
    "descriptor": "\nComments: 9 pages + Works Cited\n",
    "authors": [
      "Rajiv Movva"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.13455"
  },
  {
    "id": "arXiv:2106.13456",
    "title": "Deep Interpretable Criminal Charge Prediction and Algorithmic Bias",
    "abstract": "While predictive policing has become increasingly common in assisting with\ndecisions in the criminal justice system, the use of these results is still\ncontroversial. Some software based on deep learning lacks accuracy (e.g., in\nF-1), and many decision processes are not transparent causing doubt about\ndecision bias, such as perceived racial, age, and gender disparities. This\npaper addresses bias issues with post-hoc explanations to provide a trustable\nprediction of whether a person will receive future criminal charges given one's\nprevious criminal records by learning temporal behavior patterns over twenty\nyears. Bi-LSTM relieves the vanishing gradient problem, and attentional\nmechanisms allows learning and interpretation of feature importance. Our\napproach shows consistent and reliable prediction precision and recall on a\nreal-life dataset. Our analysis of the importance of each input feature shows\nthe critical causal impact on decision-making, suggesting that criminal\nhistories are statistically significant factors, while identifiers, such as\nrace, gender, and age, are not. Finally, our algorithm indicates that a suspect\ntends to gradually rather than suddenly increase crime severity level over\ntime.",
    "descriptor": "\nComments: First two authors alphabetically ordered\n",
    "authors": [
      "Abdul Rafae Khan",
      "Jia Xu",
      "Peter Varsanyi",
      "Rachit Pabreja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13456"
  },
  {
    "id": "arXiv:2106.13460",
    "title": "CLOAK: A Framework For Development of Confidential Blockchain Smart  Contracts",
    "abstract": "In recent years, as blockchain adoption has been expanding across a wide\nrange of domains, e.g., digital asset, supply chain finance, etc., the\nconfidentiality of smart contracts is now a fundamental demand for practical\napplications. However, while new privacy protection techniques keep coming out,\nhow existing ones can best fit development settings is little studied.\nSuffering from limited architectural support in terms of programming\ninterfaces, state-of-the-art solutions can hardly reach general developers. In\nthis paper, we proposed the CLOAK framework for developing confidential smart\ncontracts. The key capability of CLOAK is allowing developers to implement and\ndeploy practical solutions to multi-party transaction (MPT) problems, i.e.,\ntransact with secret inputs and states owned by different parties by simply\nspecifying it. To this end, CLOAK introduced a domain-specific annotation\nlanguage for declaring privacy specifications and further automatically\ngenerating confidential smart contracts to be deployed with trusted execution\nenvironment (TEE) on blockchain. In our evaluation on both simple and\nreal-world applications, developers managed to deploy business services on\nblockchain in a concise manner by only developing CLOAK smart contracts whose\nsize is less than 30% of the deployed ones.",
    "descriptor": "\nComments: accepted by ICDCS'21 Demo & Poster Track\n",
    "authors": [
      "Qian Ren",
      "Han Liu",
      "Yue Li",
      "Hong Lei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.13460"
  },
  {
    "id": "arXiv:2106.13461",
    "title": "Detectability Conditions and State Estimation for Linear Time-Varying  and Nonlinear Systems",
    "abstract": "This work proposes a detectability condition for linear time-varying systems\nbased on the exponential dichotomy spectrum. The condition guarantees the\nexistence of an observer, whose gain is determined only by the unstable modes\nof the system. This allows for an observer design with low computational\ncomplexity compared to classical estimation approaches. An extension of this\nobserver design to a class of nonlinear systems is proposed and local\nconvergence of the corresponding estimation error dynamics is proven. Numerical\nresults show the efficacy of the proposed observer design technique.",
    "descriptor": "",
    "authors": [
      "Markus Tranninger",
      "Richard Seeber",
      "Martin Steinberger",
      "Martin Horn",
      "Christian P\u00f6tzsche"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.13461"
  },
  {
    "id": "arXiv:2106.13465",
    "title": "Introducing OpenMP Tasks into the HYDRO Benchmark",
    "abstract": "The HYDRO mini-application has been successfully used as a research vehicle\nin previous PRACE projects [6]. In this paper, we evaluate the benefits of the\ntasking model introduced in recent OpenMP standards [9]. We have developed a\nnew version of HYDRO using the concept of OpenMP tasks and this implementation\nis compared to already existing and optimized OpenMP versions of HYDRO.",
    "descriptor": "",
    "authors": [
      "J\u00e9r\u00e9mie Gaidamour",
      "Dimitri Lecas",
      "Pierre-Fran\u00e7ois Lavall\u00e9e"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.13465"
  },
  {
    "id": "arXiv:2106.13469",
    "title": "Digital libraries: textual analysis for a systematic review and  meta-analysis",
    "abstract": "Purpose: We seek to explore the realm of literature about digital libraries.\nWe specifically seek to ascertain how interest in this subject has evolved, its\nimpact, the most productive journals and countries, the number of occurrences\nof digital libraries, the relationships and dynamics of the main concepts\nmentioned, and the dynamics of metadata formats.Methods: We extracted corpora\nfrom the Google Scholar and Microsoft Academic Search bibliographic databases.\nWe analyzed the named entities and concepts contained within these corpora with\nthe help of text mining technologies, CorTexT in particular.Results: While the\nnumber of publications on the subject of digital libraries is increasing, their\naverage number of citations is decreasing. China, the United States and India\nare the most productive countries on the subject. Literature about conservation\nand national libraries has gradually been replaced by literature about open\naccess, university libraries and the relationship with users. Internet Archive\nis the most cited digital library in literature and continues to grow. Dublin\nCore is the most talked about metadata format, however the subject of metadata\nformats is declining in the corpus today.Conclusion: Digital libraries now seem\nto be reaching the age of maturity.",
    "descriptor": "",
    "authors": [
      "Mathieu Andro",
      "Marc Maisonneuve"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.13469"
  },
  {
    "id": "arXiv:2106.13474",
    "title": "Adapt-and-Distill: Developing Small, Fast and Effective Pretrained  Language Models for Domains",
    "abstract": "Large pre-trained models have achieved great success in many natural language\nprocessing tasks. However, when they are applied in specific domains, these\nmodels suffer from domain shift and bring challenges in fine-tuning and online\nserving for latency and capacity constraints. In this paper, we present a\ngeneral approach to developing small, fast and effective pre-trained models for\nspecific domains. This is achieved by adapting the off-the-shelf general\npre-trained models and performing task-agnostic knowledge distillation in\ntarget domains. Specifically, we propose domain-specific vocabulary expansion\nin the adaptation stage and employ corpus level occurrence probability to\nchoose the size of incremental vocabulary automatically. Then we systematically\nexplore different strategies to compress the large pre-trained models for\nspecific domains. We conduct our experiments in the biomedical and computer\nscience domain. The experimental results demonstrate that our approach achieves\nbetter performance over the BERT BASE model in domain-specific tasks while 3.3x\nsmaller and 5.1x faster than BERT BASE. The code and pre-trained models are\navailable at https://aka.ms/adalm.",
    "descriptor": "",
    "authors": [
      "Yunzhi Yao",
      "Shaohan Huang",
      "Wenhui Wang",
      "Li Dong",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.13474"
  },
  {
    "id": "arXiv:2106.13475",
    "title": "Limitations of machine learning for building energy prediction: ASHRAE  Great Energy Predictor III Kaggle competition error analysis",
    "abstract": "Machine learning for building energy prediction has exploded in popularity in\nrecent years, yet understanding its limitations and potential for improvement\nare lacking. The ASHRAE Great Energy Predictor III (GEPIII) Kaggle competition\nwas the largest building energy meter machine learning competition ever held\nwith 4,370 participants who submitted 39,403 predictions. The test data set\nincluded two years of hourly electricity, hot water, chilled water, and steam\nreadings from 2,380 meters in 1,448 buildings at 16 locations. This paper\nanalyzes the various sources and types of residual model error from an\naggregation of the competition's top 50 solutions. This analysis reveals the\nlimitations for machine learning using the standard model inputs of historical\nmeter, weather, and basic building metadata. The types of error are classified\naccording to the amount of time errors occur in each instance, abrupt versus\ngradual behavior, the magnitude of error, and whether the error existed on\nsingle buildings or several buildings at once from a single location. The\nresults show machine learning models have errors within a range of\nacceptability on 79.1% of the test data. Lower magnitude model errors occur in\n16.1% of the test data. These discrepancies can likely be addressed through\nadditional training data sources or innovations in machine learning. Higher\nmagnitude errors occur in 4.8% of the test data and are unlikely to be\naccurately predicted regardless of innovation. There is a diversity of error\nbehavior depending on the energy meter type (electricity prediction models have\nunacceptable error in under 10% of test data, while hot water is over 60%) and\nbuilding use type (public service less than 14%, while technology/science is\njust over 46%).",
    "descriptor": "",
    "authors": [
      "Clayton Miller",
      "Bianca Picchetti",
      "Chun Fu",
      "Jovan Pantelic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.13475"
  },
  {
    "id": "arXiv:2106.13476",
    "title": "An Edge Computing Paradigm for Massive IoT Connectivity over  High-Altitude Platform Networks",
    "abstract": "With the advent of the Internet-of-Things (IoT) era, the ever-increasing\nnumber of devices and emerging applications have triggered the need for\nubiquitous connectivity and more efficient computing paradigms. These stringent\ndemands have posed significant challenges to the current wireless networks and\ntheir computing architectures. In this article, we propose a high-altitude\nplatform (HAP) network-enabled edge computing paradigm to tackle the key issues\nof massive IoT connectivity. Specifically, we first provide a comprehensive\noverview of the recent advances in non-terrestrial network-based edge computing\narchitectures. Then, the limitations of the existing solutions are further\nsummarized from the perspectives of the network architecture, random access\nprocedure, and multiple access techniques. To overcome the limitations, we\npropose a HAP-enabled aerial cell-free massive multiple-input multiple-output\nnetwork to realize the edge computing paradigm, where multiple HAPs cooperate\nvia the edge servers to serve IoT devices. For the case of a massive number of\ndevices, we further adopt a grant-free massive access scheme to guarantee\nlow-latency and high-efficiency massive IoT connectivity to the network.\nBesides, a case study is provided to demonstrate the effectiveness of the\nproposed solution. Finally, to shed light on the future research directions of\nHAP network-enabled edge computing paradigms, the key challenges and open\nissues are discussed.",
    "descriptor": "\nComments: 8 pages, 6 figures. The current version has been accepted by IEEE Wireless Communications Magzine Special Issue on Aerial Computing: Drones for Multi-Access Edge Computing\n",
    "authors": [
      "Malong Ke",
      "Zhen Gao",
      "Yang Huang",
      "Guoru Ding",
      "Derrick Wing Kwan Ng",
      "Qihui Wu",
      "Jun Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.13476"
  },
  {
    "id": "arXiv:2106.13478",
    "title": "Crossing Cross-Domain Paths in the Current Web",
    "abstract": "The loading of resources from third-parties has evoked new security and\nprivacy concerns about the current world wide web. Building on the concepts of\nforced and implicit trust, this paper examines cross-domain transmission\ncontrol protocol (TCP) connections that are initiated to domains other than the\ndomain queried with a web browser. The dataset covers nearly ten thousand\ndomains and over three hundred thousand TCP connections initiated by querying\npopular Finnish websites and globally popular sites. According to the results,\n(i) cross-domain connections are extremely common in the current Web. (ii) Most\nof these transmit encrypted content, although mixed content delivery is\nrelatively common; many of the cross-domain connections deliver unencrypted\ncontent at the same time. (iii) Many of the cross-domain connections are\ninitiated to known web advertisement domains, but a much larger share traces to\nsocial media platforms and cloud infrastructures. Finally, (iv) the results\ndiffer slightly between the Finnish web sites sampled and the globally popular\nsites. With these results, the paper contributes to the ongoing work for better\nunderstanding cross-domain connections and dependencies in the world wide web.",
    "descriptor": "\nComments: Proceedings of the 16th Annual Conference on Privacy, Security and Trust (PST 2018), Belfast, IEEE, pp. 1-5\n",
    "authors": [
      "Jukka Ruohonen",
      "Joonas Salovaara",
      "Ville Lepp\u00e4nen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.13478"
  },
  {
    "id": "arXiv:2106.13479",
    "title": "Preliminary study on using vector quantization latent spaces for TTS/VC  systems with consistent performance",
    "abstract": "Generally speaking, the main objective when training a neural speech\nsynthesis system is to synthesize natural and expressive speech from the output\nlayer of the neural network without much attention given to the hidden layers.\nHowever, by learning useful latent representation, the system can be used for\nmany more practical scenarios. In this paper, we investigate the use of\nquantized vectors to model the latent linguistic embedding and compare it with\nthe continuous counterpart. By enforcing different policies over the latent\nspaces in the training, we are able to obtain a latent linguistic embedding\nthat takes on different properties while having a similar performance in terms\nof quality and speaker similarity. Our experiments show that the voice cloning\nsystem built with vector quantization has only a small degradation in terms of\nperceptive evaluations, but has a discrete latent space that is useful for\nreducing the representation bit-rate, which is desirable for data transferring,\nor limiting the information leaking, which is important for speaker\nanonymization and other tasks of that nature.",
    "descriptor": "\nComments: to be presented at SSW11\n",
    "authors": [
      "Hieu-Thi Luong",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.13479"
  },
  {
    "id": "arXiv:2106.13488",
    "title": "Probing Inter-modality: Visual Parsing with Self-Attention for  Vision-Language Pre-training",
    "abstract": "Vision-Language Pre-training (VLP) aims to learn multi-modal representations\nfrom image-text pairs and serves for downstream vision-language tasks in a\nfine-tuning fashion. The dominant VLP models adopt a CNN-Transformer\narchitecture, which embeds images with a CNN, and then aligns images and text\nwith a Transformer. Visual relationship between visual contents plays an\nimportant role in image understanding and is the basic for inter-modal\nalignment learning. However, CNNs have limitations in visual relation learning\ndue to local receptive field's weakness in modeling long-range dependencies.\nThus the two objectives of learning visual relation and inter-modal alignment\nare encapsulated in the same Transformer network. Such design might restrict\nthe inter-modal alignment learning in the Transformer by ignoring the\nspecialized characteristic of each objective. To tackle this, we propose a\nfully Transformer visual embedding for VLP to better learn visual relation and\nfurther promote inter-modal alignment. Specifically, we propose a metric named\nInter-Modality Flow (IMF) to measure the interaction between vision and\nlanguage modalities (i.e., inter-modality). We also design a novel masking\noptimization mechanism named Masked Feature Regression (MFR) in Transformer to\nfurther promote the inter-modality learning. To the best of our knowledge, this\nis the first study to explore the benefit of Transformer for visual feature\nlearning in VLP. We verify our method on a wide range of vision-language tasks,\nincluding Visual Question Answering (VQA), Visual Entailment and Visual\nReasoning. Our approach not only outperforms the state-of-the-art VLP\nperformance, but also shows benefits on the IMF metric.",
    "descriptor": "",
    "authors": [
      "Hongwei Xue",
      "Yupan Huang",
      "Bei Liu",
      "Houwen Peng",
      "Jianlong Fu",
      "Houqiang Li",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13488"
  },
  {
    "id": "arXiv:2106.13489",
    "title": "Semialgebras and Weak Distributive Laws",
    "abstract": "Motivated by recent work on weak distributive laws and their applications to\ncoalgebraic semantics, we investigate the algebraic nature of semialgebras for\na monad. These are algebras for the underlying functor of the monad subject to\nthe associativity axiom alone-the unit axiom from the definition of an\nEilenberg-Moore algebras is dropped. We prove that if the underlying category\nhas coproducts, then semialgebras for a monad M are in fact the Eilenberg-Moore\nalgebras for a suitable monad structure on the functor id + M , which we call\nthe semifree monad M^s. We also provide concrete algebraic presentations for\nsemialgebras for the maybe monad, the semigroup monad and the finite\ndistribution monad. A second contribution is characterizing the weak\ndistributive laws of the form M T $\\Rightarrow$ T M as strong distributive laws\nM^s T $\\Rightarrow$ T M^s subject to an additional condition.",
    "descriptor": "",
    "authors": [
      "Daniela Petri{\u015f}an",
      "Ralph Sarkis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2106.13489"
  },
  {
    "id": "arXiv:2106.13494",
    "title": "Investigating Modes of Activity and Guidance for Mediating Museum  Exhibits in Mixed Reality",
    "abstract": "We present an exploratory case study describing the design and realisation of\na ''pure mixed reality'' application in a museum setting, where we investigate\nthe potential of using Microsoft's HoloLens for object-centred museum\nmediation. Our prototype supports non-expert visitors observing a sculpture by\noffering interpretation that is linked to visual properties of the museum\nobject. The design and development of our research prototype is based on a\ntwo-stage visitor observation study and a formative study we conducted prior to\nthe design of the application. We present a summary of our findings from these\nstudies and explain how they have influenced our user-centred content creation\nand the interaction design of our prototype. We are specifically interested in\ninvestigating to what extent different constructs of initiative influence the\nlearning and user experience. Thus, we detail three modes of activity that we\nrealised in our prototype. Our case study is informed by research in the area\nof human-computer interaction, the humanities and museum practice. Accordingly,\nwe discuss core concepts, such as gaze-based interaction, object-centred\nlearning, presence, and modes of activity and guidance with a transdisciplinary\nperspective.",
    "descriptor": "",
    "authors": [
      "Katrin Glinka",
      "Patrick Tobias Fischer",
      "Claudia M\u00fcller-Birn",
      "Silke Krohn"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.13494"
  },
  {
    "id": "arXiv:2106.13495",
    "title": "Doubly-Exponential Identification via Channels: Code Constructions and  Bounds",
    "abstract": "Consider the identification (ID) via channels problem, where a receiver wants\nto decide whether the transmitted identifier is its identifier, rather than\ndecoding the identifier. This model allows to transmit identifiers whose size\nscales doubly-exponentially in the blocklength, unlike common transmission (or\nchannel) codes whose size scales exponentially. It suffices to use binary\nconstant-weight codes (CWCs) to achieve the ID capacity. By relating the\nparameters of a binary CWC to the minimum distance of a code and using\nhigher-order correlation moments, two upper bounds on the binary CWC size are\nproposed. These bounds are shown to be upper bounds also on the identifier\nsizes for ID codes constructed by using binary CWCs. We propose two code\nconstructions based on optical orthogonal codes, which are used in optical\nmultiple access schemes, have constant-weight codewords, and satisfy cyclic\ncross-correlation and auto-correlation constraints. These constructions are\nmodified and concatenated with outer Reed-Solomon codes to propose new binary\nCWCs optimal for ID. Improvements to the finite-parameter performance of both\nour and existing code constructions are shown by using outer codes with larger\nminimum distance vs. blocklength ratios. We also illustrate ID performance\nregimes for which our ID code constructions perform significantly better than\nexisting constructions.",
    "descriptor": "\nComments: To appear in the IEEE International Symposium on Information Theory 2021\n",
    "authors": [
      "Onur G\u00fcnl\u00fc",
      "Joerg Kliewer",
      "Rafael F. Schaefer",
      "Vladimir Sidorenko"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.13495"
  },
  {
    "id": "arXiv:2106.13497",
    "title": "On the Robustness of Pretraining and Self-Supervision for a Deep  Learning-based Analysis of Diabetic Retinopathy",
    "abstract": "There is an increasing number of medical use-cases where classification\nalgorithms based on deep neural networks reach performance levels that are\ncompetitive with human medical experts. To alleviate the challenges of small\ndataset sizes, these systems often rely on pretraining. In this work, we aim to\nassess the broader implications of these approaches. For diabetic retinopathy\ngrading as exemplary use case, we compare the impact of different training\nprocedures including recently established self-supervised pretraining methods\nbased on contrastive learning. To this end, we investigate different aspects\nsuch as quantitative performance, statistics of the learned feature\nrepresentations, interpretability and robustness to image distortions. Our\nresults indicate that models initialized from ImageNet pretraining report a\nsignificant increase in performance, generalization and robustness to image\ndistortions. In particular, self-supervised models show further benefits to\nsupervised models. Self-supervised models with initialization from ImageNet\npretraining not only report higher performance, they also reduce overfitting to\nlarge lesions along with improvements in taking into account minute lesions\nindicative of the progression of the disease. Understanding the effects of\npretraining in a broader sense that goes beyond simple performance comparisons\nis of crucial importance for the broader medical imaging community beyond the\nuse-case considered in this work.",
    "descriptor": "",
    "authors": [
      "Vignesh Srinivasan",
      "Nils Strodthoff",
      "Jackie Ma",
      "Alexander Binder",
      "Klaus-Robert M\u00fcller",
      "Wojciech Samek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13497"
  },
  {
    "id": "arXiv:2106.13498",
    "title": "Non-Parametric Neuro-Adaptive Control Subject to Task Specifications",
    "abstract": "We develop a learning-based algorithm for the control of robotic systems\ngoverned by unknown, nonlinear dynamics to satisfy tasks expressed as signal\ntemporal logic specifications. Most existing algorithms either assume certain\nparametric forms for the dynamic terms or resort to unnecessarily large control\ninputs (e.g., using reciprocal functions) in order to provide theoretical\nguarantees. The proposed algorithm avoids the aforementioned drawbacks by\ninnovatively integrating neural network-based learning with adaptive control.\nMore specifically, the algorithm learns a controller, represented as a neural\nnetwork, using training data that correspond to a collection of different tasks\nand robot parameters. It then incorporates this neural network into an online\nclosed-loop adaptive control mechanism in such a way that the resulting\nbehavior satisfies a user-defined task. The proposed algorithm does not use any\ninformation on the unknown dynamic terms or any approximation schemes. We\nprovide formal theoretical guarantees on the satisfaction of the task and we\ndemonstrate the effectiveness of the algorithm in a virtual simulator using a\n6-DOF robotic manipulator.",
    "descriptor": "",
    "authors": [
      "Christos K. Verginis",
      "Zhe Xu",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13498"
  },
  {
    "id": "arXiv:2106.13499",
    "title": "SaSeVAL: A Safety/Security-Aware Approach for Validation of  Safety-Critical Systems",
    "abstract": "Increasing communication and self-driving capabilities for road vehicles lead\nto threats imposed by attackers. Especially attacks leading to safety\nviolations have to be identified to address them by appropriate measures. The\nimpact of an attack depends on the threat exploited, potential countermeasures\nand the traffic situation. In order to identify such attacks and to use them\nfor testing, we propose the systematic approach SaSeVAL for deriving attacks of\nautonomous vehicles. SaSeVAL is based on threats identification and\nsafety-security analysis. The impact of automotive use cases to attacks is\nconsidered. The threat identification considers the attack interface of\nvehicles and classifies threat scenarios according to threat types, which are\nthen mapped to attack types. The safety-security analysis identifies the\nnecessary requirements which have to be tested based on the architecture of the\nsystem under test. lt determines which safety impact a security violation may\nhave, and in which traffic situations the highest impact is expected. Finally,\nthe results of threat identification and safety-security analysis are used to\ndescribe attacks. The goal of SaSeVAL is to achieve safety validation of the\nvehicle w.r.t. security concerns. lt traces safety goals to threats and to\nattacks explicitly. Hence, the coverage of safety concerns by security testing\nis assured. Two use cases of vehicle communication and autonomous driving are\ninvestigated to prove the applicability of the approach.",
    "descriptor": "\nComments: 8 pages, 2 figures Presented at the 7th International Workshop on Safety and Security of Intelligent Vehicles (SSIV+ 2021, held in conjunction with DSN2021)\n",
    "authors": [
      "Christian Wolschke",
      "Behrooz Sangchoolie",
      "Jacob Simon",
      "Stefan Marksteiner",
      "Tobias Braun",
      "Hayk Hamazaryan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.13499"
  },
  {
    "id": "arXiv:2106.13500",
    "title": "TableSense: Spreadsheet Table Detection with Convolutional Neural  Networks",
    "abstract": "Spreadsheet table detection is the task of detecting all tables on a given\nsheet and locating their respective ranges. Automatic table detection is a key\nenabling technique and an initial step in spreadsheet data intelligence.\nHowever, the detection task is challenged by the diversity of table structures\nand table layouts on the spreadsheet. Considering the analogy between a cell\nmatrix as spreadsheet and a pixel matrix as image, and encouraged by the\nsuccessful application of Convolutional Neural Networks (CNN) in computer\nvision, we have developed TableSense, a novel end-to-end framework for\nspreadsheet table detection. First, we devise an effective cell featurization\nscheme to better leverage the rich information in each cell; second, we develop\nan enhanced convolutional neural network model for table detection to meet the\ndomain-specific requirement on precise table boundary detection; third, we\npropose an effective uncertainty metric to guide an active learning based smart\nsampling algorithm, which enables the efficient build-up of a training dataset\nwith 22,176 tables on 10,220 sheets with broad coverage of diverse table\nstructures and layouts. Our evaluation shows that TableSense is highly\neffective with 91.3\\% recall and 86.5\\% precision in EoB-2 metric, a\nsignificant improvement over both the current detection algorithm that are used\nin commodity spreadsheet tools and state-of-the-art convolutional neural\nnetworks in computer vision.",
    "descriptor": "",
    "authors": [
      "Haoyu Dong",
      "Shijie Liu",
      "Shi Han",
      "Zhouyu Fu",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.13500"
  },
  {
    "id": "arXiv:2106.13503",
    "title": "Data-based Design of Inferential Sensors for Petrochemical Industry",
    "abstract": "Inferential (or soft) sensors are used in industry to infer the values of\nimprecisely and rarely measured (or completely unmeasured) variables from\nvariables measured online (e.g., pressures, temperatures). The main challenge,\nakin to classical model overfitting, in designing an effective inferential\nsensor is the selection of a correct structure of the sensor. The sensor\nstructure is represented by the number of inputs to the sensor, which\ncorrespond to the variables measured online and their (simple) combinations.\nThis work is focused on the design of inferential sensors for product\ncomposition of an industrial distillation column in two oil refinery units, a\nFluid Catalytic Cracking unit and a Vacuum Gasoil Hydrogenation unit. As the\nfirst design step, we use several well-known data pre-treatment (gross error\ndetection) methods and compare the ability of these approaches to indicate\nsystematic errors and outliers in the available industrial data. We then study\neffectiveness of various methods for design of the inferential sensors taking\ninto account the complexity and accuracy of the resulting model. The\neffectiveness analysis indicates that the improvements achieved over the\ncurrent inferential sensors are up to 19 %.",
    "descriptor": "",
    "authors": [
      "Martin Mojto",
      "Karol \u013dubu\u0161k\u00fd",
      "Miroslav Fikar",
      "Radoslav Paulen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.13503"
  },
  {
    "id": "arXiv:2106.13504",
    "title": "Usage-based Summaries of Learning Videos",
    "abstract": "Much of the delivery of University education is now by synchronous or\nasynchronous video. For students, one of the challenges is managing the sheer\nvolume of such video material as video presentations of taught material are\ndifficult to abbreviate and summarise because they do not have highlights which\nstand out. Apart from video bookmarks there are no tools available to determine\nwhich parts of video content should be replayed at revision time or just before\nexaminations. We have developed and deployed a digital library for managing\nvideo learning material which has many dozens of hours of short-form video\ncontent from a range of taught courses for hundreds of students at\nundergraduate level. Through a web browser we allow students to access and play\nthese videos and we log their anonymised playback usage. From these logs we\nscore to each segment of each video based on the amount of playback it receives\nfrom across all students, whether the segment has been re-wound and re-played\nin the same student session, whether the on-screen window is the window in\nfocus on the student's desktop/laptop, and speed of playback. We also\nincorporate negative scoring if a video segment is skipped or fast-forward, and\noverarching all this we include a decay function based on recency of playback,\nso the most recent days of playback contribute more to the video segment\nscores. For each video in the library we present a usage-based graph which\nallows students to see which parts of each video attract the most playback from\ntheir peers, which helps them select material at revision time. Usage of the\nsystem is fully anonymised and GDPR-compliant.",
    "descriptor": "\nComments: 16th European Conference on Technology-Enhanced Learning (EC-TEL), Bozen-Bolzano, Italy (online), September 2021\n",
    "authors": [
      "Hyowon Lee",
      "Mingming Liu",
      "Michael Scriney",
      "Alan F. Smeaton"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.13504"
  },
  {
    "id": "arXiv:2106.13507",
    "title": "Pilot Contamination Elimination for Channel Estimation with Complete  Knowledge of Large-Scale Fading in Downlink Massive MIMO Systems",
    "abstract": "Massive multiple-input multiple-output is a very important technology for\nfuture fifth-generation systems. However, massive massive multiple input\nmultiple output systems are still limited because of pilot contamination,\nimpacting the data rate due to the non-orthogonality of pilot sequences\ntransmitted by users in the same cell to the neighboring cells. We propose a\nchannel estimation with complete knowledge of large-scale fading by using an\northogonal pilot reuse sequence to eliminate PC in edge users with poor channel\nquality based on the estimation of large-scale fading and performance analysis\nof maximum ratio transmission and zero forcing precoding methods. We derived\nthe lower bounds on the achievable downlink DR and signal-to-interference noise\nratio based on assigning PRS to a user grouping that mitigated this problem\nwhen the number of antenna elements approaches infinity The simulation results\nshowed that a high DR can be achieved due to better channel estimation and\nreduced performance loss",
    "descriptor": "\nComments: 5pages\n",
    "authors": [
      "Qazwan Abdullah",
      "Norsaliza Abdullah",
      "Adeb Salh",
      "Lukman Audah",
      "Nabil Farah",
      "Abbas Ugurenver",
      "Abdu Saif"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.13507"
  },
  {
    "id": "arXiv:2106.13511",
    "title": "Evaluation of Deep-Learning-Based Voice Activity Detectors and Room  Impulse Response Models in Reverberant Environments",
    "abstract": "State-of-the-art deep-learning-based voice activity detectors (VADs) are\noften trained with anechoic data. However, real acoustic environments are\ngenerally reverberant, which causes the performance to significantly\ndeteriorate. To mitigate this mismatch between training data and real data, we\nsimulate an augmented training set that contains nearly five million\nutterances. This extension comprises of anechoic utterances and their\nreverberant modifications, generated by convolutions of the anechoic utterances\nwith a variety of room impulse responses (RIRs). We consider five different\nmodels to generate RIRs, and five different VADs that are trained with the\naugmented training set. We test all trained systems in three different real\nreverberant environments. Experimental results show $20\\%$ increase on average\nin accuracy, precision and recall for all detectors and response models,\ncompared to anechoic training. Furthermore, one of the RIR models consistently\nyields better performance than the other models, for all the tested VADs.\nAdditionally, one of the VADs consistently outperformed the other VADs in all\nexperiments.",
    "descriptor": "\nComments: Accepted to ICASSP 2020\n",
    "authors": [
      "Amir Ivry",
      "Israel Cohen",
      "Baruch Berdugo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.13511"
  },
  {
    "id": "arXiv:2106.13512",
    "title": "The L2L System for Second Language Learning Using Visualised Zoom Calls  Among Students",
    "abstract": "An important part of second language learning is conversation which is best\npractised with speakers whose native language is the language being learned. We\nfacilitate this by pairing students from different countries learning each\nothers' native language. Mixed groups of students have Zoom calls, half in one\nlanguage and half in the other, in order to practice and improve their\nconversation skills. We use Zoom video recordings with audio transcripts\nenabled which generates recognised speech from which we extract timestamped\nutterances and calculate and visualise conversation metrics on a dashboard. A\ntimeline highlights each utterance, colour coded per student, with links to the\nvideo in a playback window. L2L was deployed for a semester and recorded almost\n250 hours of zoom meetings. The conversation metrics visualised on the\ndashboard are a beneficial asset for both students and lecturers.",
    "descriptor": "\nComments: 16th European Conference on Technology-Enhanced Learning (EC-TEL), Bozen-Bolzano, Italy (online), September 2021\n",
    "authors": [
      "Aparajita Dey-Plissonneau",
      "Hyowon Lee",
      "Vincent Pradier",
      "Michael Scriney",
      "Alan F. Smeaton"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.13512"
  },
  {
    "id": "arXiv:2106.13513",
    "title": "Littlestone Classes are Privately Online Learnable",
    "abstract": "We consider the problem of online classification under a privacy constraint.\nIn this setting a learner observes sequentially a stream of labelled examples\n$(x_t, y_t)$, for $1 \\leq t \\leq T$, and returns at each iteration $t$ a\nhypothesis $h_t$ which is used to predict the label of each new example $x_t$.\nThe learner's performance is measured by her regret against a known hypothesis\nclass $\\mathcal{H}$. We require that the algorithm satisfies the following\nprivacy constraint: the sequence $h_1, \\ldots, h_T$ of hypotheses output by the\nalgorithm needs to be an $(\\epsilon, \\delta)$-differentially private function\nof the whole input sequence $(x_1, y_1), \\ldots, (x_T, y_T)$. We provide the\nfirst non-trivial regret bound for the realizable setting. Specifically, we\nshow that if the class $\\mathcal{H}$ has constant Littlestone dimension then,\ngiven an oblivious sequence of labelled examples, there is a private learner\nthat makes in expectation at most $O(\\log T)$ mistakes -- comparable to the\noptimal mistake bound in the non-private case, up to a logarithmic factor.\nMoreover, for general values of the Littlestone dimension $d$, the same mistake\nbound holds but with a doubly-exponential in $d$ factor. A recent line of work\nhas demonstrated a strong connection between classes that are online learnable\nand those that are differentially-private learnable. Our results strengthen\nthis connection and show that an online learning algorithm can in fact be\ndirectly privatized (in the realizable setting). We also discuss an adaptive\nsetting and provide a sublinear regret bound of $O(\\sqrt{T})$.",
    "descriptor": "",
    "authors": [
      "Noah Golowich",
      "Roi Livni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.13513"
  },
  {
    "id": "arXiv:2106.13514",
    "title": "Phoneme-aware and Channel-wise Attentive Learning for Text  DependentSpeaker Verification",
    "abstract": "This paper proposes a multi-task learning network with phoneme-aware and\nchannel-wise attentive learning strategies for text-dependent Speaker\nVerification (SV). In the proposed structure, the frame-level multi-task\nlearning along with the segment-level adversarial learning is adopted for\nspeaker embedding extraction. The phoneme-aware attentive pooling is exploited\non frame-level features in the main network for speaker classifier, with the\ncorresponding posterior probability for the phoneme distribution in the\nauxiliary subnet. Further, the introduction of Squeeze and Excitation\n(SE-block) performs dynamic channel-wise feature recalibration, which improves\nthe representational ability. The proposed method exploits speaker\nidiosyncrasies associated with pass-phrases, and is further improved by the\nphoneme-aware attentive pooling and SE-block from temporal and channel-wise\naspects, respectively. The experiments conducted on RSR2015 Part 1 database\nconfirm that the proposed system achieves outstanding results for textdependent\nSV.",
    "descriptor": "",
    "authors": [
      "Yan Liu",
      "Zheng Li",
      "Lin Li",
      "Qingyang Hong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.13514"
  },
  {
    "id": "arXiv:2106.13516",
    "title": "Multi-Domain Active Learning: A Comparative Study",
    "abstract": "Building classifiers on multiple domains is a practical problem in the real\nlife. Instead of building classifiers one by one, multi-domain learning (MDL)\nsimultaneously builds classifiers on multiple domains. MDL utilizes the\ninformation shared among the domains to improve the performance. As a\nsupervised learning problem, the labeling effort is still high in MDL problems.\nUsually, this high labeling cost issue could be relieved by using active\nlearning. Thus, it is natural to utilize active learning to reduce the labeling\neffort in MDL, and we refer this setting as multi-domain active learning\n(MDAL). However, there are only few works which are built on this setting. And\nwhen the researches have to face this problem, there is no off-the-shelf\nsolutions. Under this circumstance, combining the current multi-domain learning\nmodels and single-domain active learning strategies might be a preliminary\nsolution for MDAL problem. To find out the potential of this preliminary\nsolution, a comparative study over 5 models and 4 selection strategies is made\nin this paper. To the best of our knowledge, this is the first work provides\nthe formal definition of MDAL. Besides, this is the first comparative work for\nMDAL problem. From the results, the Multinomial Adversarial Networks (MAN)\nmodel with a simple best vs second best (BvSB) uncertainty strategy shows its\nsuperiority in most cases. We take this combination as our off-the-shelf\nrecommendation for the MDAL problem.",
    "descriptor": "",
    "authors": [
      "Rui He",
      "Shan He",
      "Ke Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13516"
  },
  {
    "id": "arXiv:2106.13517",
    "title": "Temporal Graph Signal Decomposition",
    "abstract": "Temporal graph signals are multivariate time series with individual\ncomponents associated with nodes of a fixed graph structure. Data of this kind\narises in many domains including activity of social network users, sensor\nnetwork readings over time, and time course gene expression within the\ninteraction network of a model organism. Traditional matrix decomposition\nmethods applied to such data fall short of exploiting structural regularities\nencoded in the underlying graph and also in the temporal patterns of the\nsignal. How can we take into account such structure to obtain a succinct and\ninterpretable representation of temporal graph signals?\nWe propose a general, dictionary-based framework for temporal graph signal\ndecomposition (TGSD). The key idea is to learn a low-rank, joint encoding of\nthe data via a combination of graph and time dictionaries. We propose a highly\nscalable decomposition algorithm for both complete and incomplete data, and\ndemonstrate its advantage for matrix decomposition, imputation of missing\nvalues, temporal interpolation, clustering, period estimation, and rank\nestimation in synthetic and real-world data ranging from traffic patterns to\nsocial media activity. Our framework achieves 28% reduction in RMSE compared to\nbaselines for temporal interpolation when as many as 75% of the observations\nare missing. It scales best among baselines taking under 20 seconds on 3.5\nmillion data points and produces the most parsimonious models. To the best of\nour knowledge, TGSD is the first framework to jointly model graph signals by\ntemporal and graph dictionaries.",
    "descriptor": "\nComments: 9 Main Pages 2 Supplement to be published in the research track in Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2021), August 14 through August 18, 2021,Virtual Event, Singapore\n",
    "authors": [
      "Maxwell McNeil",
      "Lin Zhang",
      "Petko Bogdanov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13517"
  },
  {
    "id": "arXiv:2106.13520",
    "title": "Complexity of Deciding Syntactic Equivalence up to Renaming for Term  Rewriting Systems (Extended Version)",
    "abstract": "Inspired by questions from program transformations, eight notions of\nisomorphisms between term rewriting systems are defined, analysed and\nclassified. The notions include global isomorphisms where the renaming of\nvariables and / or function symbols is the same for all term rewriting rules of\nthe system, and local ones where a single renaming for every rule is used. The\ncomplexity of the underlying decision problems are analysed and either shown to\nbe efficiently solvable or proved to be complete for the graph isomorphism\ncomplexity class.",
    "descriptor": "",
    "authors": [
      "Michael Christian Fink Amores",
      "David Sabel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.13520"
  },
  {
    "id": "arXiv:2106.13521",
    "title": "Manually Annotated Spelling Error Corpus for Amharic",
    "abstract": "This paper presents a manually annotated spelling error corpus for Amharic,\nlingua franca in Ethiopia. The corpus is designed to be used for the evaluation\nof spelling error detection and correction. The misspellings are tagged as\nnon-word and real-word errors. In addition, the contextual information\navailable in the corpus makes it useful in dealing with both types of spelling\nerrors.",
    "descriptor": "\nComments: Accepted to 2nd AfricaNLP Workshop at EACL 2021\n",
    "authors": [
      "Andargachew Mekonnen Gezmu",
      "Tirufat Tesifaye Lema",
      "Binyam Ephrem Seyoum",
      "Andreas N\u00fcrnberger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.13521"
  },
  {
    "id": "arXiv:2106.13524",
    "title": "Cost-efficient, QoS and Security aware Placement of Smart Farming IoT  Applications in Cloud-Fog Infrastructure",
    "abstract": "Smart farming is a recent innovation in the agriculture sector that can\nimprove the agricultural yield by using smarter, automated, and data driven\nfarm processes that interact with IoT devices deployed on farms. A cloud-fog\ninfrastructure provides an effective platform to execute IoT applications.\nWhile fog computing satisfies the real-time processing need of delay-sensitive\nIoT services by bringing virtualized services closer to the IoT devices, cloud\ncomputing provides allows execution of applications with higher computational\nrequirements. The deployment of IoT applications is a critical challenge as\ncloud and fog nodes vary in terms of their resource availability and use\ndifferent cost models. Moreover, diverse resource, quality of service (QoS) and\nsecurity requirements of IoT applications make the problem even more complex.\nIn this paper, we model IoT application placement as an optimization problem\nthat aims at minimizing the resource cost while satisfying the QoS and security\nconstraints. The problem is formulated using Integer Linear Programming (ILP).\nThe ILP model is evaluated for a small-scale scenario.",
    "descriptor": "",
    "authors": [
      "Jagruti Sahoo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.13524"
  },
  {
    "id": "arXiv:2106.13528",
    "title": "Interactive query expansion for professional search applications",
    "abstract": "Knowledge workers (such as healthcare information professionals, patent\nagents and recruitment professionals) undertake work tasks where search forms a\ncore part of their duties. In these instances, the search task is often complex\nand time-consuming and requires specialist expert knowledge to formulate\naccurate search strategies. Interactive features such as query expansion can\nplay a key role in supporting these tasks. However, generating query\nsuggestions within a professional search context requires that consideration be\ngiven to the specialist, structured nature of the search strategies they\nemploy. In this paper, we investigate a variety of query expansion methods\napplied to a collection of Boolean search strategies used in a variety of\nreal-world professional search tasks. The results demonstrate the utility of\ncontext-free distributional language models and the value of using linguistic\ncues such as ngram order to optimise the balance between precision and recall.",
    "descriptor": "\nComments: 34 pages, 5 figures\n",
    "authors": [
      "Tony Russell-Rose",
      "Philip Gooch",
      "Udo Kruschwitz"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.13528"
  },
  {
    "id": "arXiv:2106.13529",
    "title": "Navigating A Mobile Robot Using Switching Distributed Sensor Networks",
    "abstract": "This paper proposes a method to navigate a mobile robot by estimating its\nstate over a number of distributed sensor networks (DSNs) such that it can\nsuccessively accomplish a sequence of tasks, i.e., its state enters each\ntargeted set and stays inside no less than the desired time, under a\nresource-aware, time-efficient, and computation- and communication-constrained\nsetting.We propose a new robot state estimation and navigation architecture,\nwhich integrates an event-triggered task-switching feedback controller for the\nrobot and a two-time-scale distributed state estimator for each sensor. The\narchitecture has three major advantages over existing approaches: First, in\neach task only one DSN is active for sensing and estimating the robot state,\nand for different tasks the robot can switch the active DSN by taking resource\nsaving and system performance into account; Second, the robot only needs to\ncommunicate with one active sensor at each time to obtain its state information\nfrom the active DSN; Third, no online optimization is required. With the\ncontroller, the robot is able to accomplish a task by following a reference\ntrajectory and switch to the next task when an event-triggered condition is\nfulfilled. With the estimator, each active sensor is able to estimate the robot\nstate. Under proper conditions, we prove that the state estimation error and\nthe trajectory tracking deviation are upper bounded by two time-varying\nsequences respectively, which play an essential role in the event-triggered\ncondition. Furthermore, we find a sufficient condition for accomplishing a task\nand provide an upper bound of running time for the task. Numerical simulations\nof an indoor robot's localization and navigation are provided to validate the\nproposed architecture.",
    "descriptor": "",
    "authors": [
      "Xingkang He",
      "Ehsan Hashemi",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13529"
  },
  {
    "id": "arXiv:2106.13531",
    "title": "Deep Residual Echo Suppression with A Tunable Tradeoff Between Signal  Distortion and Echo Suppression",
    "abstract": "In this paper, we propose a residual echo suppression method using a UNet\nneural network that directly maps the outputs of a linear acoustic echo\ncanceler to the desired signal in the spectral domain. This system embeds a\ndesign parameter that allows a tunable tradeoff between the desired-signal\ndistortion and residual echo suppression in double-talk scenarios. The system\nemploys 136 thousand parameters, and requires 1.6 Giga floating-point\noperations per second and 10 Mega-bytes of memory. The implementation satisfies\nboth the timing requirements of the AEC challenge and the computational and\nmemory limitations of on-device applications. Experiments are conducted with\n161~h of data from the AEC challenge database and from real independent\nrecordings. We demonstrate the performance of the proposed system in real-life\nconditions and compare it with two competing methods regarding echo suppression\nand desired-signal distortion, generalization to various environments, and\nrobustness to high echo levels.",
    "descriptor": "\nComments: Accepted to ICASSP 2021\n",
    "authors": [
      "Amir Ivry",
      "Israel Cohen",
      "Baruch Berdugo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.13531"
  },
  {
    "id": "arXiv:2106.13537",
    "title": "Heat Waves -- a hot topic in climate change research",
    "abstract": "Research on heat waves (periods of excessively hot weather, which may be\naccompanied by high humidity) is a newly emerging research topic within the\nfield of climate change research with high relevance for the whole of society.\nIn this study, we analyzed the rapidly growing scientific literature dealing\nwith heat waves. No summarizing overview has been published on this literature\nhitherto. We developed a suitable search query to retrieve the relevant\nliterature covered by the Web of Science (WoS) as complete as possible and to\nexclude irrelevant literature (n = 6,569 papers). The time-evolution of the\npublications shows that research dealing with heat waves is a highly dynamic\nresearch topic, doubling within about 5 years. An analysis of the thematic\ncontent reveals the most severe heat wave events within the recent decades\n(1995, 2003, 2010), the cities and countries/regions affected (Australia,\nUnited States, and Europe), and the ecological and medical impacts (drought,\nurban heat islands, excess hospital admissions, and mortality). Risk estimation\nand future strategies for adaptation to hot weather are major political issues.\nWe identified 83 citation classics which include fundamental early works of\nresearch on heat waves and more recent works (which are characterized by a\nrelatively strong connection to climate change).",
    "descriptor": "\nComments: 38 pages, 2 tables, and 9 figures\n",
    "authors": [
      "Werner Marx",
      "Robin Haunschild",
      "Lutz Bornmann"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.13537"
  },
  {
    "id": "arXiv:2106.13538",
    "title": "Beam Alignment in mmWave User-Centric Cell-Free Massive MIMO Systems",
    "abstract": "The problem of beam alignment (BA) in a cell-free massive multiple-input\nmultiple-output (CF-mMIMO) system operating at millimeter wave (mmWaves)\ncarrier frequencies is considered in this paper. Two estimation algorithms are\nproposed, in association with a protocol that permits simultaneous estimation,\non a shared set of frequencies, for each user equipment (UE), of the direction\nof arrival and departure of the radio waves associated to the strongest\npropagation paths from each of the surrounding access points (APs), so that\nUE-AP association can take place. The proposed procedure relies on the\nexistence of a reliable control channel at sub-6 GHz frequency, so as to enable\nexchange of estimated values between the UEs and the network, and assumes that\nAPs can be identifies based on the prior knowledge of the orthogonal channels\nand transmit beamforming codebook. A strategy for assigning codebook entries to\nthe several APs is also proposed, with the aim of minimizing the mutual\ninterference between APs that are assigned the same entry. Numerical results\nshow the effectiveness of the proposed detection strategy, thus enabling one\nshot fast BA for CF-mMIMO systems.",
    "descriptor": "\nComments: 6 pages, 3 figures, submitted to the 2021 IEEE Global Communications Conference (GLOBECOM)\n",
    "authors": [
      "Stefano Buzzi",
      "Carmen D'Andrea",
      "Maria Fresia",
      "Xiaofeng Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.13538"
  },
  {
    "id": "arXiv:2106.13539",
    "title": "Dealing with Expert Bias in Collective Decision-Making",
    "abstract": "Quite some real-world problems can be formulated as decision-making problems\nwherein one must repeatedly make an appropriate choice from a set of\nalternatives. Expert judgements, whether human or artificial, can help in\ntaking correct decisions, especially when exploration of alternative solutions\nis costly. As expert opinions might deviate, the problem of finding the right\nalternative can be approached as a collective decision making problem (CDM).\nCurrent state-of-the-art approaches to solve CDM are limited by the quality of\nthe best expert in the group, and perform poorly if experts are not qualified\nor if they are overly biased, thus potentially derailing the decision-making\nprocess. In this paper, we propose a new algorithmic approach based on\ncontextual multi-armed bandit problems (CMAB) to identify and counteract such\nbiased expertises. We explore homogeneous, heterogeneous and polarised expert\ngroups and show that this approach is able to effectively exploit the\ncollective expertise, irrespective of whether the provided advice is directly\nconducive to good performance, outperforming state-of-the-art methods,\nespecially when the quality of the provided expertise degrades. Our novel\nCMAB-inspired approach achieves a higher final performance and does so while\nconverging more rapidly than previous adaptive algorithms, especially when\nheterogeneous expertise is readily available.",
    "descriptor": "",
    "authors": [
      "Axel Abels",
      "Tom Lenaerts",
      "Vito Trianni",
      "Ann Now\u00e9"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13539"
  },
  {
    "id": "arXiv:2106.13541",
    "title": "A nonlinear hidden layer enables actor-critic agents to learn multiple  paired association navigation",
    "abstract": "Navigation to multiple cued reward locations has been increasingly used to\nstudy rodent learning. Though deep reinforcement learning agents have been\nshown to be able to learn the task, they are not biologically plausible.\nBiologically plausible classic actor-critic agents have been shown to learn to\nnavigate to single reward locations, but which biologically plausible agents\nare able to learn multiple cue-reward location tasks has remained unclear. In\nthis computational study, we show versions of classic agents that learn to\nnavigate to a single reward location, and adapt to reward location\ndisplacement, but are not able to learn multiple paired association navigation.\nThe limitation is overcome by an agent in which place cell and cue information\nare first processed by a feedforward nonlinear hidden layer with synapses to\nthe actor and critic subject to temporal difference error-modulated plasticity.\nFaster learning is obtained when the feedforward layer is replaced by a\nrecurrent reservoir network.",
    "descriptor": "\nComments: 31 pages, 8 figures\n",
    "authors": [
      "M Ganesh Kumar",
      "Cheston Tan",
      "Camilo Libedinsky",
      "Shih-Cheng Yen",
      "Andrew Yong-Yi Tan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.13541"
  },
  {
    "id": "arXiv:2106.13542",
    "title": "Tensor-based framework for training flexible neural networks",
    "abstract": "Activation functions (AFs) are an important part of the design of neural\nnetworks (NNs), and their choice plays a predominant role in the performance of\na NN. In this work, we are particularly interested in the estimation of\nflexible activation functions using tensor-based solutions, where the AFs are\nexpressed as a weighted sum of predefined basis functions. To do so, we propose\na new learning algorithm which solves a constrained coupled matrix-tensor\nfactorization (CMTF) problem. This technique fuses the first and zeroth order\ninformation of the NN, where the first-order information is contained in a\nJacobian tensor, following a constrained canonical polyadic decomposition\n(CPD). The proposed algorithm can handle different decomposition bases. The\ngoal of this method is to compress large pretrained NN models, by replacing\nsubnetworks, {\\em i.e.,} one or multiple layers of the original network, by a\nnew flexible layer. The approach is applied to a pretrained convolutional\nneural network (CNN) used for character classification.",
    "descriptor": "\nComments: 26 pages, 13 figures\n",
    "authors": [
      "Yassine Zniyed",
      "Konstantin Usevich",
      "Sebastian Miron",
      "David Brie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13542"
  },
  {
    "id": "arXiv:2106.13543",
    "title": "Louvain-like Methods for Community Detection in Multi-Layer Networks",
    "abstract": "In many complex systems, entities interact with each other through\ncomplicated patterns that embed different relationships, thus generating\nnetworks with multiple levels and/or multiple types of edges. When trying to\nimprove our understanding of those complex networks, it is of paramount\nimportance to explicitly take the multiple layers of connectivity into account\nin the analysis. In this paper, we focus on detecting community structures in\nmulti-layer networks, i.e., detecting groups of well-connected nodes shared\namong the layers, a very popular task that poses a lot of interesting questions\nand challenges. Most of the available algorithms in this context either reduce\nmulti-layer networks to a single-layer network or try to extend algorithms for\nsingle-layer networks by using consensus clustering. Those approaches have\nanyway been criticized lately. They indeed ignore the connections among the\ndifferent layers, hence giving low accuracy. To overcome these issues, we\npropose new community detection methods based on tailored Louvain-like\nstrategies that simultaneously handle the multiple layers. We consider the\ninformative case, where all layers show a community structure, and the noisy\ncase, where some layers only add noise to the system. We report experiments on\nboth artificial and real-world networks showing the effectiveness of the\nproposed strategies.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Sara Venturini",
      "Andrea Cristofari",
      "Francesco Rinaldi",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13543"
  },
  {
    "id": "arXiv:2106.13544",
    "title": "Improving Human Decisions by Adjusting the Alerting Thresholds for  Computer Alerting Tools According to User and Task Characteristics",
    "abstract": "Objective: To investigate whether performance (number of correct decisions)\nof humans supported by a computer alerting tool can be improved by tailoring\nthe tool's alerting threshold (sensitivity/specificity combination) according\nto user ability and task difficulty. Background: Many researchers implicitly\nassume that for each tool there exists a single ideal threshold. But research\nshows the effects of alerting tools on decision errors to vary depending on\nvariables such as user ability and task difficulty. These findings motivated\nour investigation. Method: Forty-seven participants edited text passages, aided\nby a simulated spell-checker tool. We experimentally manipulated passage\ndifficulty and tool alerting threshold, measured participants' editing and\ndictation ability, and counted participants' decision errors (false positives +\nfalse negatives). We investigated whether alerting threshold, user ability,\ntask difficulty and their interactions affected error count. Results: Which\nalerting threshold better helped a user depended on an interaction between user\nability and passage difficulty. Some effects were large: for higher ability\nusers, a more sensitive threshold reduced errors by 30%, on the easier\npassages. Participants were not significantly more likely to prefer the\nalerting threshold with which they performed better. Conclusion: Adjusting\nalerting thresholds for individual users' ability and task difficulty could\nsubstantially improve effects of automated alerts on user decisions. This\npotential deserves further investigation. Improvement size and rules for\nadjustment will be application-specific. Application: Computer alerting tools\nhave critical roles in many domains. Designers should assess potential benefits\nof adjustable alerting thresholds for their specific CAT application. Guidance\nfor choosing thresholds will be essential for realizing these benefits in\npractice.",
    "descriptor": "\nComments: 25 pages, 5 figures\n",
    "authors": [
      "Marwa Gadala",
      "Lorenzo Strigini",
      "Peter Ayton"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.13544"
  },
  {
    "id": "arXiv:2106.13549",
    "title": "Connecting Sphere Manifolds Hierarchically for Regularization",
    "abstract": "This paper considers classification problems with hierarchically organized\nclasses. We force the classifier (hyperplane) of each class to belong to a\nsphere manifold, whose center is the classifier of its super-class. Then,\nindividual sphere manifolds are connected based on their hierarchical\nrelations. Our technique replaces the last layer of a neural network by\ncombining a spherical fully-connected layer with a hierarchical layer. This\nregularization is shown to improve the performance of widely used deep neural\nnetwork architectures (ResNet and DenseNet) on publicly available datasets\n(CIFAR100, CUB200, Stanford dogs, Stanford cars, and Tiny-ImageNet).",
    "descriptor": "",
    "authors": [
      "Damien Scieur",
      "Youngsung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13549"
  },
  {
    "id": "arXiv:2106.13552",
    "title": "Graph Pattern Loss based Diversified Attention Network for Cross-Modal  Retrieval",
    "abstract": "Cross-modal retrieval aims to enable flexible retrieval experience by\ncombining multimedia data such as image, video, text, and audio. One core of\nunsupervised approaches is to dig the correlations among different object\nrepresentations to complete satisfied retrieval performance without requiring\nexpensive labels. In this paper, we propose a Graph Pattern Loss based\nDiversified Attention Network(GPLDAN) for unsupervised cross-modal retrieval to\ndeeply analyze correlations among representations. First, we propose a\ndiversified attention feature projector by considering the interaction between\ndifferent representations to generate multiple representations of an instance.\nThen, we design a novel graph pattern loss to explore the correlations among\ndifferent representations, in this graph all possible distances between\ndifferent representations are considered. In addition, a modality classifier is\nadded to explicitly declare the corresponding modalities of features before\nfusion and guide the network to enhance discrimination ability. We test GPLDAN\non four public datasets. Compared with the state-of-the-art cross-modal\nretrieval methods, the experimental results demonstrate the performance and\ncompetitiveness of GPLDAN.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Xueying Chen",
      "Rong Zhang",
      "Yibing Zhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13552"
  },
  {
    "id": "arXiv:2106.13553",
    "title": "Exploring the Representation of Word Meanings in Context: A Case Study  on Homonymy and Synonymy",
    "abstract": "This paper presents a multilingual study of word meaning representations in\ncontext. We assess the ability of both static and contextualized models to\nadequately represent different lexical-semantic relations, such as homonymy and\nsynonymy. To do so, we created a new multilingual dataset that allows us to\nperform a controlled evaluation of several factors such as the impact of the\nsurrounding context or the overlap between words, conveying the same or\ndifferent senses. A systematic assessment on four scenarios shows that the best\nmonolingual models based on Transformers can adequately disambiguate homonyms\nin context. However, as they rely heavily on context, these models fail at\nrepresenting words with different senses when occurring in similar sentences.\nExperiments are performed in Galician, Portuguese, English, and Spanish, and\nboth the dataset (with more than 3,000 evaluation items) and new models are\nfreely released with this study.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Marcos Garcia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.13553"
  },
  {
    "id": "arXiv:2106.13555",
    "title": "Effects of current limit for grid forming converters on transient  stability: analysis and solution",
    "abstract": "Grid forming control applied to power converters that interface storage or\nrenewable generation to the power grid, has been identified as a potential\nsolution to facilitate a substantial share of converter-based renewable\ngeneration in the power system. Analyzing the response of grid forming\nconverters (GFC) for large frequency, phase, and voltage events, particularly\nwhen the GFC enters the current limit operation, is very important for system\nstability, but studies on this have been limited. This paper presents a\nquantitative and illustrative analysis of the impact of the current limit in\nGFC on the transient stability of a system comprising of GFC. Furthermore, a\nsolution based on virtual active power is proposed to improve the transient\nstability margin of the GFC when the GFC enters the current limit. Finally, the\nanalysis and the proposed method to enhance the transient stability are\nverified by Power hardware in the loop (PHIL) experimental tests.",
    "descriptor": "\nComments: 8 pages, 19 figures\n",
    "authors": [
      "Kanakesh Vatta Kkuni",
      "Guangya Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13555"
  },
  {
    "id": "arXiv:2106.13556",
    "title": "SRPN: similarity-based region proposal networks for nuclei and cells  detection in histology images",
    "abstract": "The detection of nuclei and cells in histology images is of great value in\nboth clinical practice and pathological studies. However, multiple reasons such\nas morphological variations of nuclei or cells make it a challenging task where\nconventional object detection methods cannot obtain satisfactory performance in\nmany cases. A detection task consists of two sub-tasks, classification and\nlocalization. Under the condition of dense object detection, classification is\na key to boost the detection performance. Considering this, we propose\nsimilarity based region proposal networks (SRPN) for nuclei and cells detection\nin histology images. In particular, a customized convolution layer termed as\nembedding layer is designed for network building. The embedding layer is added\ninto the region proposal networks, enabling the networks to learn\ndiscriminative features based on similarity learning. Features obtained by\nsimilarity learning can significantly boost the classification performance\ncompared to conventional methods. SRPN can be easily integrated into standard\nconvolutional neural networks architectures such as the Faster R-CNN and\nRetinaNet. We test the proposed approach on tasks of multi-organ nuclei\ndetection and signet ring cells detection in histological images. Experimental\nresults show that networks applying similarity learning achieved superior\nperformance on both tasks when compared to their counterparts. In particular,\nthe proposed SRPN achieve state-of-the-art performance on the MoNuSeg benchmark\nfor nuclei segmentation and detection while compared to previous methods, and\non the signet ring cell detection benchmark when compared with baselines. The\nsourcecode is publicly available at:\nhttps://github.com/sigma10010/nuclei_cells_det.",
    "descriptor": "\nComments: Accepted by Medical Image Analysis for publication\n",
    "authors": [
      "Yibao Sun",
      "Xingru Huang",
      "Huiyu Zhou",
      "Qianni Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13556"
  },
  {
    "id": "arXiv:2106.13560",
    "title": "Checking chordality on homomorphically encrypted graphs",
    "abstract": "The breakthrough of achieving fully homomorphic encryption sparked enormous\nstudies on where and how to apply homomorphic encryption schemes so that\noperations can be performed on encrypted data without the secret key while\nstill obtaining the correct outputs. Due to the computational cost, inflated\nciphertext size and limited arithmetic operations that are allowed in most\nencryption schemes, feasible applications of homomorphic encryption are few.\nWhile theorists are working on the mathematical and cryptographical foundations\nof homomorphic encryption in order to overcome the current limitations,\npractitioners are also re-designing queries and algorithms to adapt the\nfunctionalities of the current encryption schemes. As an initial study on\nworking with homomorphically encrypted graphs, this paper provides an\neasy-to-implement interactive algorithm to check whether or not a\nhomomorphically encrypted graph is chordal. This algorithm is simply a\nrefactoring of a current method to run on the encrypted adjacency matrices.",
    "descriptor": "",
    "authors": [
      "Yang Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.13560"
  },
  {
    "id": "arXiv:2106.13561",
    "title": "Singular solutions, graded meshes, and adaptivity for total-variation  regularized minimization problems",
    "abstract": "Recent quasi-optimal error estimates for the finite element approximation of\ntotal-variation regularized minimization problems require the existence of a\nLipschitz continuous dual solution. We discuss the validity of this condition\nand devise numerical methods using locally refined meshes that lead to improved\nconvergence rates despite the occurrence of discontinuities. It turns out that\nnearly linear convergence is possible on suitably constructed meshes.",
    "descriptor": "",
    "authors": [
      "S\u00f6ren Bartels",
      "Robert Tovey",
      "Friedrich Wassmer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13561"
  },
  {
    "id": "arXiv:2106.13566",
    "title": "Video Moment Retrieval with Text Query Considering Many-to-Many  Correspondence Using Potentially Relevant Pair",
    "abstract": "In this paper we undertake the task of text-based video moment retrieval from\na corpus of videos. To train the model, text-moment paired datasets were used\nto learn the correct correspondences. In typical training methods, ground-truth\ntext-moment pairs are used as positive pairs, whereas other pairs are regarded\nas negative pairs. However, aside from the ground-truth pairs, some text-moment\npairs should be regarded as positive. In this case, one text annotation can be\npositive for many video moments. Conversely, one video moment can be\ncorresponded to many text annotations. Thus, there are many-to-many\ncorrespondences between the text annotations and video moments. Based on these\ncorrespondences, we can form potentially relevant pairs, which are not given as\nground truth yet are not negative; effectively incorporating such relevant\npairs into training can improve the retrieval performance. The text query\nshould describe what is happening in a video moment. Hence, different video\nmoments annotated with similar texts, which contain a similar action, are\nlikely to hold the similar action, thus these pairs can be considered as\npotentially relevant pairs. In this paper, we propose a novel training method\nthat takes advantage of potentially relevant pairs, which are detected based on\nlinguistic analysis about text annotation. Experiments on two benchmark\ndatasets revealed that our method improves the retrieval performance both\nquantitatively and qualitatively.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Sho Maeoki",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13566"
  },
  {
    "id": "arXiv:2106.13571",
    "title": "Edge based stochastic block model statistical inference",
    "abstract": "Community detection in graphs often relies on ad hoc algorithms with no clear\nspecification about the node partition they define as the best, which leads to\nuninterpretable communities. Stochastic block models (SBM) offer a framework to\nrigorously define communities, and to detect them using statistical inference\nmethod to distinguish structure from random fluctuations. In this paper, we\nintroduce an alternative definition of SBM based on edge sampling. We derive\nfrom this definition a quality function to statistically infer the node\npartition used to generate a given graph. We then test it on synthetic graphs,\nand on the zachary karate club network.",
    "descriptor": "",
    "authors": [
      "Louis Duvivier",
      "R\u00e9my Cazabet",
      "C\u00e9line Robardet"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13571"
  },
  {
    "id": "arXiv:2106.13574",
    "title": "Multiview Video Compression Using Advanced HEVC Screen Content Coding",
    "abstract": "The paper presents a new approach to multiview video coding using Screen\nContent Coding. It is assumed that for a time instant the frames corresponding\nto all views are packed into a single frame, i.e. the frame-compatible approach\nto multiview coding is applied. For such coding scenario, the paper\ndemonstrates that Screen Content Coding can be efficiently used for multiview\nvideo coding. Two approaches are considered: the first using standard HEVC\nScreen Content Coding, and the second using Advanced Screen Content Coding. The\nlatter is the original proposal of the authors that exploits quarter-pel motion\nvectors and other nonstandard extensions of HEVC Screen Content Coding. The\nexperimental results demonstrate that multiview video coding even using\nstandard HEVC Screen Content Coding is much more efficient than simulcast HEVC\ncoding. The proposed Advanced Screen Content Coding provides virtually the same\ncoding efficiency as MV-HEVC, which is the state-of-the-art multiview video\ncompression technique. The authors suggest that Advanced Screen Content Coding\ncan be efficiently used within the new Versatile Video Coding (VVC) technology.\nNevertheless a reference multiview extension of VVC does not exist yet,\ntherefore, for VVC-based coding, the experimental comparisons are left for\nfuture work.",
    "descriptor": "",
    "authors": [
      "Jaros\u0142aw Samelak",
      "Marek Doma\u0144ski"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13574"
  },
  {
    "id": "arXiv:2106.13585",
    "title": "Learning Gradual Argumentation Frameworks using Genetic Algorithms",
    "abstract": "Gradual argumentation frameworks represent arguments and their relationships\nin a weighted graph. Their graphical structure and intuitive semantics makes\nthem a potentially interesting tool for interpretable machine learning. It has\nbeen noted recently that their mechanics are closely related to neural\nnetworks, which allows learning their weights from data by standard deep\nlearning frameworks. As a first proof of concept, we propose a genetic\nalgorithm to simultaneously learn the structure of argumentative classification\nmodels. To obtain a well interpretable model, the fitness function balances\nsparseness and accuracy of the classifier. We discuss our algorithm and present\nfirst experimental results on standard benchmarks from the UCI machine learning\nrepository. Our prototype learns argumentative classification models that are\ncomparable to decision trees in terms of learning performance and\ninterpretability.",
    "descriptor": "",
    "authors": [
      "Jonathan Spieler",
      "Nico Potyka",
      "Steffen Staab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.13585"
  },
  {
    "id": "arXiv:2106.13587",
    "title": "Graph space: using both geometric and probabilistic structure to  evaluate statistical graph models",
    "abstract": "Statistical graph models aim at modeling graphs as random realization among a\nset of possible graphs. One issue is to evaluate whether or not a graph is\nlikely to have been generated by one particular model. In this paper we\nintroduce the edit distance expected value (EDEV) and compare it with other\nmethods such as entropy and distance to the barycenter. We show that contrary\nto them, EDEV is able to distinguish between graphs that have a typical\nstructure with respect to a model, and those that do not. Finally we introduce\na statistical hypothesis testing methodology based on this distance to evaluate\nthe relevance of a candidate model with respect to an observed graph.",
    "descriptor": "",
    "authors": [
      "Louis Duvivier",
      "R\u00e9my Cazabet",
      "C\u00e9line Robardet"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13587"
  },
  {
    "id": "arXiv:2106.13590",
    "title": "Fostering Diversity in Spatial Evolutionary Generative Adversarial  Networks",
    "abstract": "Generative adversary networks (GANs) suffer from training pathologies such as\ninstability and mode collapse, which mainly arise from a lack of diversity in\ntheir adversarial interactions. Co-evolutionary GAN (CoE-GAN) training\nalgorithms have shown to be resilient to these pathologies. This article\nintroduces Mustangs, a spatially distributed CoE-GAN, which fosters diversity\nby using different loss functions during the training. Experimental analysis on\nMNIST and CelebA demonstrated that Mustangs trains statistically more accurate\ngenerators.",
    "descriptor": "\nComments: Accepted to be presented during Conference of the Spanish Association of Artificial Intelligence (CAEPIA 2021). arXiv admin note: substantial text overlap with arXiv:1905.12702\n",
    "authors": [
      "Jamal Toutouh",
      "Erik Hemberg",
      "Una-May O'Reilly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.13590"
  },
  {
    "id": "arXiv:2106.13591",
    "title": "The Problem of Distributed Consensus: A Survey",
    "abstract": "A survey is given of approaches to the problem of distributed consensus,\nfocusing particularly on methods based on cellular automata and related\nsystems. A variety of new results are given, as well as a history of the field\nand an extensive bibliography. Distributed consensus is of current relevance in\na new generation of blockchain-related systems.",
    "descriptor": "",
    "authors": [
      "Stephen Wolfram"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.13591"
  },
  {
    "id": "arXiv:2106.13594",
    "title": "Bayesian Neural Networks: Essentials",
    "abstract": "Bayesian neural networks utilize probabilistic layers that capture\nuncertainty over weights and activations, and are trained using Bayesian\ninference. Since these probabilistic layers are designed to be drop-in\nreplacement of their deterministic counter parts, Bayesian neural networks\nprovide a direct and natural way to extend conventional deep neural networks to\nsupport probabilistic deep learning. However, it is nontrivial to understand,\ndesign and train Bayesian neural networks due to their complexities. We discuss\nthe essentials of Bayesian neural networks including duality (deep neural\nnetworks, probabilistic models), approximate Bayesian inference, Bayesian\npriors, Bayesian posteriors, and deep variational learning. We use TensorFlow\nProbability APIs and code examples for illustration. The main problem with\nBayesian neural networks is that the architecture of deep neural networks makes\nit quite redundant, and costly, to account for uncertainty for a large number\nof successive layers. Hybrid Bayesian neural networks, which use few\nprobabilistic layers judicially positioned in the networks, provide a practical\nsolution.",
    "descriptor": "",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13594"
  },
  {
    "id": "arXiv:2106.13603",
    "title": "Partially fake it till you make it: mixing real and fake thermal images  for improved object detection",
    "abstract": "In this paper we propose a novel data augmentation approach for visual\ncontent domains that have scarce training datasets, compositing synthetic 3D\nobjects within real scenes. We show the performance of the proposed system in\nthe context of object detection in thermal videos, a domain where 1) training\ndatasets are very limited compared to visible spectrum datasets and 2) creating\nfull realistic synthetic scenes is extremely cumbersome and expensive due to\nthe difficulty in modeling the thermal properties of the materials of the\nscene. We compare different augmentation strategies, including state of the art\napproaches obtained through RL techniques, the injection of simulated data and\nthe employment of a generative model, and study how to best combine our\nproposed augmentation with these other techniques.Experimental results\ndemonstrate the effectiveness of our approach, and our single-modality detector\nachieves state-of-the-art results on the FLIR ADAS dataset.",
    "descriptor": "",
    "authors": [
      "Francesco Bongini",
      "Lorenzo Berlincioni",
      "Marco Bertini",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13603"
  },
  {
    "id": "arXiv:2106.13606",
    "title": "Greedy Randomized and Maximal Weighted Residual Kaczmarz Methods with  Oblique Projection",
    "abstract": "For solving large-scale consistent linear system, we combine two efficient\nrow index selection strategies with Kaczmarz-type method with oblique\nprojection, and propose a greedy randomized Kaczmarz method with oblique\nprojection (GRKO) and the maximal weighted residual Kaczmarz method with\noblique projection (MWRKO) . Through those method, the number of iteration\nsteps and running time can be reduced to a greater extent to find the\nleast-norm solution, especially when the rows of matrix A are close to linear\ncorrelation. Theoretical proof and numerical results show that GRKO method and\nMWRKO method are more effective than greedy randomized Kaczmarz method and\nmaximal weighted residual Kaczmarz method respectively.",
    "descriptor": "",
    "authors": [
      "Fang Wang",
      "Weiguo Li",
      "Wendi Bao",
      "Li Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13606"
  },
  {
    "id": "arXiv:2106.13610",
    "title": "Patch-Smoother and Multigrid for the Dual Formulation for Linear  Elasticity",
    "abstract": "The dual formulation for linear elasticity, in contrast to the primal\nformulation, is not affected by locking, as it is based on the stresses as main\nunknowns. Thus it is quite attractive for nearly incompressible and\nincompressible materials. Discretization with mixed finite elements will lead\nto -- possibly large -- linear saddle point systems with a particular\nstructure. Whereas efficient multigrid methods exist for solving problems in\nmixed plane elasticity, to the knowledge of the authors, no multigrid methods\nare readily available for the general dual formulation. Two are the main\nchallenges in constructing a multigrid method for the dual formulation for\nlinear elasticity. First, in the incompressible limit, the matrix block related\nto the stress is semi-positive definite. Second, the stress belongs to\n$\\textbf{H}_{\\text{div}}$ and standard smoothers, working for $\\textbf{H}^1$\nregular problems, cannot be applied. We present a novel patch-based smoother\nfor the dual formulation for linear elasticity. We discuss different types of\nlocal boundary conditions for the patch subproblems. Based on our\npatch-smoother, we build a multigrid method for the solution of the resulting\nsaddle point problem and investigate its efficiency and robustness. Numerical\nexperiments show that Robin conditions best fit the multigrid framework,\nleading eventually to multigrid performance.",
    "descriptor": "\nComments: 27 pages, 88 figures\n",
    "authors": [
      "Gabriele Rovi",
      "Rolf Krause"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13610"
  },
  {
    "id": "arXiv:2106.13618",
    "title": "A Modern Perspective on Query Likelihood with Deep Generative Retrieval  Models",
    "abstract": "Existing neural ranking models follow the text matching paradigm, where\ndocument-to-query relevance is estimated through predicting the matching score.\nDrawing from the rich literature of classical generative retrieval models, we\nintroduce and formalize the paradigm of deep generative retrieval models\ndefined via the cumulative probabilities of generating query terms. This\nparadigm offers a grounded probabilistic view on relevance estimation while\nstill enabling the use of modern neural architectures. In contrast to the\nmatching paradigm, the probabilistic nature of generative rankers readily\noffers a fine-grained measure of uncertainty. We adopt several current neural\ngenerative models in our framework and introduce a novel generative ranker\n(T-PGN), which combines the encoding capacity of Transformers with the Pointer\nGenerator Network model. We conduct an extensive set of evaluation experiments\non passage retrieval, leveraging the MS MARCO Passage Re-ranking and TREC Deep\nLearning 2019 Passage Re-ranking collections. Our results show the\nsignificantly higher performance of the T-PGN model when compared with other\ngenerative models. Lastly, we demonstrate that exploiting the uncertainty\ninformation of deep generative rankers opens new perspectives to\nquery/collection understanding, and significantly improves the cut-off\nprediction task.",
    "descriptor": "\nComments: ICTIR'21\n",
    "authors": [
      "Oleg Lesota",
      "Navid Rekabsaz",
      "Daniel Cohen",
      "Klaus Antonius Grasserbauer",
      "Carsten Eickhoff",
      "Markus Schedl"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.13618"
  },
  {
    "id": "arXiv:2106.13620",
    "title": "Shortcut Hulls: Vertex-restricted Outer Simplifications of Polygons",
    "abstract": "Let $P$ be a crossing-free polygon and $\\mathcal C$ a set of shortcuts, where\neach shortcut is a directed straight-line segment connecting two vertices of\n$P$. A shortcut hull of $P$ is another crossing-free polygon that encloses $P$\nand whose oriented boundary is composed of elements from $\\mathcal C$. Shortcut\nhulls find their application in geo-related problems such as the simplification\nof contour lines. We aim at a shortcut hull that linearly balances the enclosed\narea and perimeter. If no holes in the shortcut hull are allowed, the problem\nadmits a straight-forward solution via shortest paths. For the more challenging\ncase that the shortcut hull may contain holes, we present a polynomial-time\nalgorithm that is based on computing a constrained, weighted triangulation of\nthe input polygon's exterior. We use this problem as a starting point for\ninvestigating further variants, e.g., restricting the number of edges or bends.\nWe demonstrate that shortcut hulls can be used for drawing the rough extent of\npoint sets as well as for the schematization of polygons.",
    "descriptor": "\nComments: Appears in the Proceedings of 33rd Canadian Conference on Computational Geometry, 2021\n",
    "authors": [
      "Annika Bonerath",
      "Jan-Henrik Haunert",
      "Joseph S. B. Mitchell",
      "Benjamin Niedermann"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.13620"
  },
  {
    "id": "arXiv:2106.13624",
    "title": "Chebyshev-Cantelli PAC-Bayes-Bennett Inequality for the Weighted  Majority Vote",
    "abstract": "We present a new second-order oracle bound for the expected risk of a\nweighted majority vote. The bound is based on a novel parametric form of the\nChebyshev-Cantelli inequality (a.k.a.\\ one-sided Chebyshev's), which is\namenable to efficient minimization. The new form resolves the optimization\nchallenge faced by prior oracle bounds based on the Chebyshev-Cantelli\ninequality, the C-bounds [Germain et al., 2015], and, at the same time, it\nimproves on the oracle bound based on second order Markov's inequality\nintroduced by Masegosa et al. [2020]. We also derive the PAC-Bayes-Bennett\ninequality, which we use for empirical estimation of the oracle bound. The\nPAC-Bayes-Bennett inequality improves on the PAC-Bayes-Bernstein inequality by\nSeldin et al. [2012]. We provide an empirical evaluation demonstrating that the\nnew bounds can improve on the work by Masegosa et al. [2020]. Both the\nparametric form of the Chebyshev-Cantelli inequality and the PAC-Bayes-Bennett\ninequality may be of independent interest for the study of concentration of\nmeasure in other domains.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2007.13532\n",
    "authors": [
      "Yi-Shan Wu",
      "Andr\u00e9s R. Masegosa",
      "Stephan S. Lorenzen",
      "Christian Igel",
      "Yevgeny Seldin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13624"
  },
  {
    "id": "arXiv:2106.13627",
    "title": "Language Models are Good Translators",
    "abstract": "Recent years have witnessed the rapid advance in neural machine translation\n(NMT), the core of which lies in the encoder-decoder architecture. Inspired by\nthe recent progress of large-scale pre-trained language models on machine\ntranslation in a limited scenario, we firstly demonstrate that a single\nlanguage model (LM4MT) can achieve comparable performance with strong\nencoder-decoder NMT models on standard machine translation benchmarks, using\nthe same training data and similar amount of model parameters. LM4MT can also\neasily utilize source-side texts as additional supervision. Though modeling the\nsource- and target-language texts with the same mechanism, LM4MT can provide\nunified representations for both source and target sentences, which can better\ntransfer knowledge across languages. Extensive experiments on pivot-based and\nzero-shot translation tasks show that LM4MT can outperform the encoder-decoder\nNMT model by a large margin.",
    "descriptor": "\nComments: 12 pages. Work in progress. An earlier verison of this manuscript is under review\n",
    "authors": [
      "Shuo Wang",
      "Zhaopeng Tu",
      "Zhixing Tan",
      "Wenxuan Wang",
      "Maosong Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.13627"
  },
  {
    "id": "arXiv:2106.13629",
    "title": "Animatable Neural Radiance Fields from Monocular RGB Video",
    "abstract": "We present animatable neural radiance fields for detailed human avatar\ncreation from monocular videos. Our approach extends neural radiance fields\n(NeRF) to the dynamic scenes with human movements via introducing explicit\npose-guided deformation while learning the scene representation network. In\nparticular, we estimate the human pose for each frame and learn a constant\ncanonical space for the detailed human template, which enables natural shape\ndeformation from the observation space to the canonical space under the\nexplicit control of the pose parameters. To compensate for inaccurate pose\nestimation, we introduce the pose refinement strategy that updates the initial\npose during the learning process, which not only helps to learn more accurate\nhuman reconstruction but also accelerates the convergence. In experiments we\nshow that the proposed approach achieves 1) implicit human geometry and\nappearance reconstruction with high-quality details, 2) photo-realistic\nrendering of the human from arbitrary views, and 3) animation of the human with\narbitrary poses.",
    "descriptor": "\nComments: 9 pages, 9 figures\n",
    "authors": [
      "Jianchuan Chen",
      "Ying Zhang",
      "Di Kang",
      "Xuefei Zhe",
      "Linchao Bao",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13629"
  },
  {
    "id": "arXiv:2106.13632",
    "title": "DeepLoc: A Ubiquitous Accurate and Low-Overhead Outdoor Cellular  Localization System",
    "abstract": "Recent years have witnessed fast growth in outdoor location-based services.\nWhile GPS is considered a ubiquitous localization system, it is not supported\nby low-end phones, requires direct line of sight to the satellites, and can\ndrain the phone battery quickly.\nIn this paper, we propose DeepLoc: a deep learning-based outdoor localization\nsystem that obtains GPS-like localization accuracy without its limitations. In\nparticular, DeepLoc leverages the ubiquitous cellular signals received from the\ndifferent cell towers heard by the mobile device as hints to localize it. To do\nthat, crowd-sensed geo-tagged received signal strength information coming from\ndifferent cell towers is used to train a deep model that is used to infer the\nuser's position. As part of DeepLoc design, we introduce modules to address a\nnumber of practical challenges including scaling the data collection to large\nareas, handling the inherent noise in the cellular signal and geo-tagged data,\nas well as providing enough data that is required for deep learning models with\nlow-overhead.\nWe implemented DeepLoc on different Android devices. Evaluation results in\nrealistic urban and rural environments show that DeepLoc can achieve a median\nlocalization accuracy within 18.8m in urban areas and within 15.7m in rural\nareas. This accuracy outperforms the state-of-the-art cellular-based systems by\nmore than 470% and comes with 330% savings in power compared to the GPS. This\nhighlights the promise of DeepLoc as a ubiquitous accurate and low-overhead\nlocalization system.",
    "descriptor": "",
    "authors": [
      "Ahmed Shokry",
      "Marwan Torki",
      "Moustafa Youssef"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.13632"
  },
  {
    "id": "arXiv:2106.13638",
    "title": "Transient Stability Analysis with Physics-Informed Neural Networks",
    "abstract": "Solving the ordinary differential equations that govern the power system is\nan indispensable part in transient stability analysis. However, the\ntraditionally applied methods either carry a significant computational burden,\nrequire model simplifications, or use overly conservative surrogate models.\nNeural networks can circumvent these limitations but are faced with high\ndemands on the used datasets. Furthermore, they are agnostic to the underlying\ngoverning equations. Physics-informed neural network tackle this problem and we\nexplore their advantages and challenges in this paper. We illustrate the\nfindings on the Kundur two-area system and highlight possible pathways forward\nin developing this method further.",
    "descriptor": "",
    "authors": [
      "Jochen Stiasny",
      "Georgios S. Misyris",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13638"
  },
  {
    "id": "arXiv:2106.13641",
    "title": "On discretizing sea-ice dynamics on triangular meshes using vertex, cell  or edge velocities",
    "abstract": "Discretization of the equations of Viscous Plastic and Elastic Viscous\nPlastic (EVP) sea ice dynamics on triangular meshes can be done by placing\ndiscrete velocities at vertices, cells or edges. Since there are more cells and\nedges than vertices, the cell- and edge-based discretizations simulate more\nlinear kinematic features at the same mesh than the vertex discretization.\nHowever, the discretization based on cell and edge velocities suffer from\nkernels in the strain rate or stress divergence operators and need either\nspecial strain rate computations as proposed here for cell velocities, or\nstabilization as proposed earlier for edge velocities. An elementary Fourier\nanalysis clarifies how kernels are removed, and also shows that cell and edge\nvelocity placement leads to spurious branches of stress divergence operator\nwith large negative eigenvalues. Although spurious branches correspond to fast\ndecay and are not expected to distort sea ice dynamics, they demand either\nsmaller internal time steps or higher stability parameters in explicit EVP-like\nmethods.",
    "descriptor": "",
    "authors": [
      "S. Danilov",
      "C. Mehlmann",
      "V. Fofonova"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13641"
  },
  {
    "id": "arXiv:2106.13642",
    "title": "VEGN: Variant Effect Prediction with Graph Neural Networks",
    "abstract": "Genetic mutations can cause disease by disrupting normal gene function.\nIdentifying the disease-causing mutations from millions of genetic variants\nwithin an individual patient is a challenging problem. Computational methods\nwhich can prioritize disease-causing mutations have, therefore, enormous\napplications. It is well-known that genes function through a complex regulatory\nnetwork. However, existing variant effect prediction models only consider a\nvariant in isolation. In contrast, we propose VEGN, which models variant effect\nprediction using a graph neural network (GNN) that operates on a heterogeneous\ngraph with genes and variants. The graph is created by assigning variants to\ngenes and connecting genes with an gene-gene interaction network. In this\ncontext, we explore an approach where a gene-gene graph is given and another\nwhere VEGN learns the gene-gene graph and therefore operates both on given and\nlearnt edges. The graph neural network is trained to aggregate information\nbetween genes, and between genes and variants. Variants can exchange\ninformation via the genes they connect to. This approach improves the\nperformance of existing state-of-the-art models.",
    "descriptor": "\nComments: Accepted at Workshop on Computational Biology, co-located with the 38th International Conference on Machine Learning\n",
    "authors": [
      "Jun Cheng",
      "Carolin Lawrence",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13642"
  },
  {
    "id": "arXiv:2106.13645",
    "title": "FLASH 1.0: A Software Framework for Rapid Parallel Deployment and  Enhancing Host Code Portability in Heterogeneous Computing",
    "abstract": "In this paper, we present FLASH 1.0, a C++-based software framework for rapid\nparallel deployment and enhancing host code portability in heterogeneous\ncomputing. FLASH takes a novel approach in describing kernels and dynamically\ndispatching them in a hardware-agnostic manner. FLASH features truly\nhardware-agnostic frontend interfaces, which not only unify the compile-time\ncontrol flow but also enforces a portability-optimized code organization that\nimposes a demarcation between computational (performance-critical) and\nfunctional (non-performance-critical) codes as well as the separation of\nhardware-specific and hardware-agnostic codes in the host application. We use\nstatic code analysis to measure the hardware independence ratio of popular HPC\napplications and show that up to 99.72% code portability can be achieved with\nFLASH. Similarly, we measure the complexity of state-of-the-art portable\nprogramming models and show that a code reduction of up to 2.2x can be achieved\nfor two common HPC kernels while maintaining 100% code portability with a\nnormalized framework overhead between 1% - 13% of the total kernel runtime. The\ncodes are available at https://github.com/PSCLab-ASU/FLASH.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Michael Riera",
      "Masudul Hassan Quraishi",
      "Erfan Bank Tavakoli",
      "Fengbo Ren"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.13645"
  },
  {
    "id": "arXiv:2106.13646",
    "title": "Two Standard Decks of Playing Cards are Sufficient for a ZKP for Sudoku",
    "abstract": "Sudoku is a logic puzzle with an objective to fill a number between 1 and 9\nin each empty cell of a $9 \\times 9$ grid such that every number appears\nexactly once in each row, each column, and each $3 \\times 3$ block. In 2020,\nSasaki et al. proposed a physical zero-knowledge proof (ZKP) protocol for\nSudoku using 90 cards, which allows a prover to physically show that he/she\nknows a solution without revealing it. However, their protocol requires nine\nidentical copies of some cards, which cannot be found in a standard deck of\nplaying cards. Therefore, nine decks of cards are actually required in order to\nperform that protocol. In this paper, we propose a new ZKP protocol for Sudoku\nthat can be performed using only two standard decks of playing cards. In\ngeneral, we develop the first ZKP protocol for an $n \\times n$ Sudoku that can\nbe performed using a deck of all different cards.",
    "descriptor": "",
    "authors": [
      "Suthee Ruangwises"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.13646"
  },
  {
    "id": "arXiv:2106.13652",
    "title": "A mechanistic-based data-driven approach to accelerate structural  topology optimization through finite element convolutional neural network  (FE-CNN)",
    "abstract": "In this paper, a mechanistic data-driven approach is proposed to accelerate\nstructural topology optimization, employing an in-house developed finite\nelement convolutional neural network (FE-CNN). Our approach can be divided into\ntwo stages: offline training, and online optimization. During offline training,\na mapping function is built between high and low resolution representations of\na given design domain. The mapping is expressed by a FE-CNN, which targets a\ncommon objective function value (e.g., structural compliance) across design\ndomains of differing resolutions. During online optimization, an arbitrary\ndesign domain of high resolution is reduced to low resolution through the\ntrained mapping function. The original high-resolution domain is thus designed\nby computations performed on only the low-resolution version, followed by an\ninverse mapping back to the high-resolution domain. Numerical examples\ndemonstrate that this approach can accelerate optimization by up to an order of\nmagnitude in computational time. Our proposed approach therefore shows great\npotential to overcome the curse-of-dimensionality incurred by density-based\nstructural topology optimization. The limitation of our present approach is\nalso discussed.",
    "descriptor": "",
    "authors": [
      "Tianle Yue",
      "Hang Yang",
      "Zongliang Du",
      "Chang Liu",
      "Khalil I. Elkhodary",
      "Shan Tang",
      "Xu Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13652"
  },
  {
    "id": "arXiv:2106.13663",
    "title": "The Tale of Two Localization Technologies: Enabling Accurate  Low-Overhead WiFi-based Localization for Low-end Phones",
    "abstract": "WiFi fingerprinting is one of the mainstream technologies for indoor\nlocalization. However, it requires an initial calibration phase during which\nthe fingerprint database is built manually. This process is labour intensive\nand needs to be repeated with any change in the environment. While a number of\nsystems have been introduced to reduce the calibration effort through RF\npropagation models or crowdsourcing, these still have some limitations. Other\napproaches use the recently developed iBeacon technology as an alternative to\nWiFi for indoor localization. However, these beacon-based solutions are limited\nto a small subset of high-end phones. In this paper, we present HybridLoc: an\naccurate low-overhead indoor localization system. The basic idea HybridLoc\nbuilds on is to leverage the sensors of high-end phones to enable localization\nof lower-end phones. Specifically, the WiFi fingerprint is crowdsourced by\nopportunistically collecting WiFi-scans labeled with location data obtained\nfrom BLE-enabled high-end smart phones. These scans are used to automatically\nconstruct the WiFi-fingerprint, that is used later to localize any lower-end\ncell phone with the ubiquitous WiFi technology. HybridLoc also has provisions\nfor handling the inherent error in the estimated BLE locations used in\nconstructing the fingerprint as well as to handle practical deployment issues\nincluding the noisy wireless environment, heterogeneous devices, among others.\nEvaluation of HybridLoc using Android phones shows that it can provide accurate\nlocalization in the same range as manual fingerprinting techniques under the\nsame conditions. Moreover, the localization accuracy on low-end phones\nsupporting only WiFi is comparable to that achieved with high-end phones\nsupporting BLE. This accuracy is achieved with no training overhead, is robust\nto the different user devices, and is consistent under environment changes.",
    "descriptor": "",
    "authors": [
      "Ahmed Shokry",
      "Moustafa Elhamshary",
      "Moustafa Youssef"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.13663"
  },
  {
    "id": "arXiv:2106.13667",
    "title": "Move Beyond Trajectories: Distribution Space Coupling for Crowd  Navigation",
    "abstract": "Cooperatively avoiding collision is a critical functionality for robots\nnavigating in dense human crowds, failure of which could lead to either\noveraggressive or overcautious behavior. A necessary condition for cooperative\ncollision avoidance is to couple the prediction of the agents' trajectories\nwith the planning of the robot's trajectory. However, it is unclear that\ntrajectory based cooperative collision avoidance captures the correct agent\nattributes. In this work we migrate from trajectory based coupling to a\nformalism that couples agent preference distributions. In particular, we show\nthat preference distributions (probability density functions representing\nagents' intentions) can capture higher order statistics of agent behaviors,\nsuch as willingness to cooperate. Thus, coupling in distribution space exploits\nmore information about inter-agent cooperation than coupling in trajectory\nspace. We thus introduce a general objective for coupled prediction and\nplanning in distribution space, and propose an iterative best response\noptimization method based on variational analysis with guaranteed sufficient\ndecrease. Based on this analysis, we develop a sampling-based motion planning\nframework called DistNav that runs in real time on a laptop CPU. We evaluate\nour approach on challenging scenarios from both real world datasets and\nsimulation environments, and benchmark against a wide variety of model based\nand machine learning based approaches. The safety and efficiency statistics of\nour approach outperform all other models. Finally, we find that DistNav is\ncompetitive with human safety and efficiency performance.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Muchen Sun",
      "Francesca Baldini",
      "Peter Trautman",
      "Todd Murphey"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.13667"
  },
  {
    "id": "arXiv:2106.13669",
    "title": "Multi-player Multi-armed Bandits with Collision-Dependent Reward  Distributions",
    "abstract": "We study a new stochastic multi-player multi-armed bandits (MP-MAB) problem,\nwhere the reward distribution changes if a collision occurs on the arm.\nExisting literature always assumes a zero reward for involved players if\ncollision happens, but for applications such as cognitive radio, the more\nrealistic scenario is that collision reduces the mean reward but not\nnecessarily to zero. We focus on the more practical no-sensing setting where\nplayers do not perceive collisions directly, and propose the Error-Correction\nCollision Communication (EC3) algorithm that models implicit communication as a\nreliable communication over noisy channel problem, for which random coding\nerror exponent is used to establish the optimal regret that no communication\nprotocol can beat. Finally, optimizing the tradeoff between code length and\ndecoding error rate leads to a regret that approaches the centralized MP-MAB\nregret, which represents a natural lower bound. Experiments with practical\nerror-correction codes on both synthetic and real-world datasets demonstrate\nthe superiority of EC3. In particular, the results show that the choice of\ncoding schemes has a profound impact on the regret performance.",
    "descriptor": "\nComments: 17 pages, 14 figures. Accepted to IEEE Transactions on Signal Processing\n",
    "authors": [
      "Chengshuai Shi",
      "Cong Shen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13669"
  },
  {
    "id": "arXiv:2106.13672",
    "title": "Exposing individual differences through network topology",
    "abstract": "Social animals, including humans, have a broad range of personality traits,\nwhich can be used to predict individual behavioral responses and decisions.\nCurrent methods to quantify individual personality traits in humans rely on\nself-report questionnaires, which require time and effort to collect and rely\non active cooperation. However, personality differences naturally manifest in\nsocial interactions such as online social networks. Here, we demonstrate that\nthe topology of an online social network can be used to characterize the\npersonality traits of its members. We analyzed the directed social graph formed\nby the users of the LiveJournal (LJ) blogging platform. Individual users\npersonality traits, inferred from their self-reported domains of interest\n(DOIs), were associated with their network measures. Empirical clustering of\nDOIs by topological similarity exposed two main self-emergent DOI groups that\nwere in alignment with the personality meta-traits plasticity and stability.\nCloseness, a global topological measure of network centrality, was\nsignificantly higher for bloggers associated with plasticity (vs. stability). A\nlocal network motif (a triad of 3 connected bloggers) that correlated with\ncloseness also separated the personality meta-traits. Finally, topology-based\nclassification of DOIs (without analyzing the content of the blogs) attained >\n70% accuracy (average AUC of the test-set). These results indicate that\npersonality traits are evident and detectable in network topology. This has\nserious implications for user privacy. But, if used responsibly, network\nidentification of personality traits could aid in early identification of\nhealth-related risks, at the population level.",
    "descriptor": "",
    "authors": [
      "Yuval Samoilov-Katz",
      "Yoram Louzoun",
      "Lev Muchnik",
      "Adam Zaidel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13672"
  },
  {
    "id": "arXiv:2106.13673",
    "title": "Understanding Clipping for Federated Learning: Convergence and  Client-Level Differential Privacy",
    "abstract": "Providing privacy protection has been one of the primary motivations of\nFederated Learning (FL). Recently, there has been a line of work on\nincorporating the formal privacy notion of differential privacy with FL. To\nguarantee the client-level differential privacy in FL algorithms, the clients'\ntransmitted model updates have to be clipped before adding privacy noise. Such\nclipping operation is substantially different from its counterpart of gradient\nclipping in the centralized differentially private SGD and has not been\nwell-understood. In this paper, we first empirically demonstrate that the\nclipped FedAvg can perform surprisingly well even with substantial data\nheterogeneity when training neural networks, which is partly because the\nclients' updates become similar for several popular deep architectures. Based\non this key observation, we provide the convergence analysis of a differential\nprivate (DP) FedAvg algorithm and highlight the relationship between clipping\nbias and the distribution of the clients' updates. To the best of our\nknowledge, this is the first work that rigorously investigates theoretical and\nempirical issues regarding the clipping operation in FL algorithms.",
    "descriptor": "",
    "authors": [
      "Xinwei Zhang",
      "Xiangyi Chen",
      "Mingyi Hong",
      "Zhiwei Steven Wu",
      "Jinfeng Yi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.13673"
  },
  {
    "id": "arXiv:2106.13675",
    "title": "Creating and Implementing a Smart Speaker",
    "abstract": "We have seen significant advancements in Artificial Intelligence and Machine\nLearning in the 21st century. It has enabled a new technology where we can have\na human-like conversation with the machines. The most significant use of this\nspeech recognition and contextual understanding technology exists in the form\nof a Smart Speaker. We have a wide variety of Smart Speaker products available\nto us. This paper aims to decode its creation and explain the technology that\nmakes these Speakers, \"Smart.\"",
    "descriptor": "",
    "authors": [
      "Sanskar Jethi",
      "Avinash Kumar Choudhary",
      "Yash Gupta",
      "Abhishek Chaudhary"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.13675"
  },
  {
    "id": "arXiv:2106.13679",
    "title": "Shape registration in the time of transformers",
    "abstract": "In this paper, we propose a transformer-based procedure for the efficient\nregistration of non-rigid 3D point clouds. The proposed approach is data-driven\nand adopts for the first time the transformer architecture in the registration\ntask. Our method is general and applies to different settings. Given a fixed\ntemplate with some desired properties (e.g. skinning weights or other animation\ncues), we can register raw acquired data to it, thereby transferring all the\ntemplate properties to the input geometry. Alternatively, given a pair of\nshapes, our method can register the first onto the second (or vice-versa),\nobtaining a high-quality dense correspondence between the two. In both\ncontexts, the quality of our results enables us to target real applications\nsuch as texture transfer and shape interpolation. Furthermore, we also show\nthat including an estimation of the underlying density of the surface eases the\nlearning process. By exploiting the potential of this architecture, we can\ntrain our model requiring only a sparse set of ground truth correspondences\n($10\\sim20\\%$ of the total points). The proposed model and the analysis that we\nperform pave the way for future exploration of transformer-based architectures\nfor registration and matching applications. Qualitative and quantitative\nevaluations demonstrate that our pipeline outperforms state-of-the-art methods\nfor deformable and unordered 3D data registration on different datasets and\nscenarios.",
    "descriptor": "",
    "authors": [
      "Giovanni Trappolini",
      "Luca Cosmo",
      "Luca Moschella",
      "Riccardo Marin",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13679"
  },
  {
    "id": "arXiv:2106.13681",
    "title": "Robust Matrix Factorization with Grouping Effect",
    "abstract": "Although many techniques have been applied to matrix factorization (MF), they\nmay not fully exploit the feature structure. In this paper, we incorporate the\ngrouping effect into MF and propose a novel method called Robust Matrix\nFactorization with Grouping effect (GRMF). The grouping effect is a\ngeneralization of the sparsity effect, which conducts denoising by clustering\nsimilar values around multiple centers instead of just around 0. Compared with\nexisting algorithms, the proposed GRMF can automatically learn the grouping\nstructure and sparsity in MF without prior knowledge, by introducing a\nnaturally adjustable non-convex regularization to achieve simultaneous sparsity\nand grouping effect. Specifically, GRMF uses an efficient alternating\nminimization framework to perform MF, in which the original non-convex problem\nis first converted into a convex problem through Difference-of-Convex (DC)\nprogramming, and then solved by Alternating Direction Method of Multipliers\n(ADMM). In addition, GRMF can be easily extended to the Non-negative Matrix\nFactorization (NMF) settings. Extensive experiments have been conducted using\nreal-world data sets with outliers and contaminated noise, where the\nexperimental results show that GRMF has promoted performance and robustness,\ncompared to five benchmark algorithms.",
    "descriptor": "\nComments: 22 pages, 5 figures, 4 tables\n",
    "authors": [
      "Haiyan Jiang",
      "Shuyu Li",
      "Luwei Zhang",
      "Haoyi Xiong",
      "Dejing Dou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13681"
  },
  {
    "id": "arXiv:2106.13686",
    "title": "Cross-Modal Knowledge Distillation Method for Automatic Cued Speech  Recognition",
    "abstract": "Cued Speech (CS) is a visual communication system for the deaf or hearing\nimpaired people. It combines lip movements with hand cues to obtain a complete\nphonetic repertoire. Current deep learning based methods on automatic CS\nrecognition suffer from a common problem, which is the data scarcity. Until\nnow, there are only two public single speaker datasets for French (238\nsentences) and British English (97 sentences). In this work, we propose a\ncross-modal knowledge distillation method with teacher-student structure, which\ntransfers audio speech information to CS to overcome the limited data problem.\nFirstly, we pretrain a teacher model for CS recognition with a large amount of\nopen source audio speech data, and simultaneously pretrain the feature\nextractors for lips and hands using CS data. Then, we distill the knowledge\nfrom teacher model to the student model with frame-level and sequence-level\ndistillation strategies. Importantly, for frame-level, we exploit multi-task\nlearning to weigh losses automatically, to obtain the balance coefficient.\nBesides, we establish a five-speaker British English CS dataset for the first\ntime. The proposed method is evaluated on French and British English CS\ndatasets, showing superior CS recognition performance to the state-of-the-art\n(SOTA) by a large margin.",
    "descriptor": "",
    "authors": [
      "Jianrong Wang",
      "Ziyue Tang",
      "Xuewei Li",
      "Mei Yu",
      "Qiang Fang",
      "Li Liu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.13686"
  },
  {
    "id": "arXiv:2106.13687",
    "title": "Multi-Goal Reinforcement Learning environments for simulated Franka  Emika Panda robot",
    "abstract": "This technical report presents panda-gym, a set Reinforcement Learning (RL)\nenvironments for the Franka Emika Panda robot integrated with OpenAI Gym. Five\ntasks are included: reach, push, slide, pick & place and stack. They all follow\na Multi-Goal RL framework, allowing to use goal-oriented RL algorithms. To\nfoster open-research, we chose to use the open-source physics engine PyBullet.\nThe implementation chosen for this package allows to define very easily new\ntasks or new robots. This report also presents a baseline of results obtained\nwith state-of-the-art model-free off-policy algorithms. panda-gym is\nopen-source at https://github.com/qgallouedec/panda-gym.",
    "descriptor": "\nComments: 9 pages, 5 figures, 2 tables\n",
    "authors": [
      "Quentin Gallou\u00e9dec",
      "Nicolas Cazin",
      "Emmanuel Dellandr\u00e9a",
      "Liming Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13687"
  },
  {
    "id": "arXiv:2106.13695",
    "title": "CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG  Signals",
    "abstract": "Data augmentation is a key element of deep learning pipelines, as it informs\nthe network during training about transformations of the input data that keep\nthe label unchanged. Manually finding adequate augmentation methods and\nparameters for a given pipeline is however rapidly cumbersome. In particular,\nwhile intuition can guide this decision for images, the design and choice of\naugmentation policies remains unclear for more complex types of data, such as\nneuroscience signals. Moreover, label independent strategies might not be\nsuitable for such structured data and class-dependent augmentations might be\nnecessary. This idea has been surprisingly unexplored in the literature, while\nit is quite intuitive: changing the color of a car image does not change the\nobject class to be predicted, but doing the same to the picture of an orange\ndoes. This paper aims to increase the generalization power added through\nclass-wise data augmentation. Yet, as seeking transformations depending on the\nclass largely increases the complexity of the task, using gradient-free\noptimization techniques as done by most existing automatic approaches becomes\nintractable for real-world datasets. For this reason we propose to use\ndifferentiable data augmentation amenable to gradient-based learning. EEG\nsignals are a perfect example of data for which good augmentation policies are\nmostly unknown. In this work, we demonstrate the relevance of our approach on\nthe clinically relevant sleep staging classification task, for which we also\npropose differentiable transformations.",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Rommel",
      "Thomas Moreau",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13695"
  },
  {
    "id": "arXiv:2106.13696",
    "title": "Image-to-image Transformation with Auxiliary Condition",
    "abstract": "The performance of image recognition like human pose detection, trained with\nsimulated images would usually get worse due to the divergence between real and\nsimulated data. To make the distribution of a simulated image close to that of\nreal one, there are several works applying GAN-based image-to-image\ntransformation methods, e.g., SimGAN and CycleGAN. However, these methods would\nnot be sensitive enough to the various change in pose and shape of subjects,\nespecially when the training data are imbalanced, e.g., some particular poses\nand shapes are minor in the training data. To overcome this problem, we propose\nto introduce the label information of subjects, e.g., pose and type of objects\nin the training of CycleGAN, and lead it to obtain label-wise transforamtion\nmodels. We evaluate our proposed method called Label-CycleGAN, through\nexperiments on the digit image transformation from SVHN to MNIST and the\nsurveillance camera image transformation from simulated to real images.",
    "descriptor": "",
    "authors": [
      "Robert Leer",
      "Hessi Roma",
      "James Amelia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13696"
  },
  {
    "id": "arXiv:2106.13697",
    "title": "Active Learning in Robotics: A Review of Control Principles",
    "abstract": "Active learning is a decision-making process. In both abstract and physical\nsettings, active learning demands both analysis and action. This is a review of\nactive learning in robotics, focusing on methods amenable to the demands of\nembodied learning systems. Robots must be able to learn efficiently and\nflexibly through continuous online deployment. This poses a distinct set of\ncontrol-oriented challenges -- one must choose suitable measures as objectives,\nsynthesize real-time control, and produce analyses that guarantee performance\nand safety with limited knowledge of the environment or robot itself. In this\nwork, we survey the fundamental components of robotic active learning systems.\nWe discuss classes of learning tasks that robots typically encounter, measures\nwith which they gauge the information content of observations, and algorithms\nfor generating action plans. Moreover, we provide a variety of examples -- from\nenvironmental mapping to nonparametric shape estimation -- that highlight the\nqualitative differences between learning tasks, information measures, and\ncontrol techniques. We conclude with a discussion of control-oriented open\nchallenges, including safety-constrained learning and distributed learning.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Annalisa T. Taylor",
      "Thomas A. Berrueta",
      "Todd D. Murphey"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.13697"
  },
  {
    "id": "arXiv:2106.13700",
    "title": "Vision Transformer Architecture Search",
    "abstract": "Recently, transformers have shown great superiority in solving computer\nvision tasks by modeling images as a sequence of manually-split patches with\nself-attention mechanism. However, current architectures of vision transformers\n(ViTs) are simply inherited from natural language processing (NLP) tasks and\nhave not been sufficiently investigated and optimized. In this paper, we make a\nfurther step by examining the intrinsic structure of transformers for vision\ntasks and propose an architecture search method, dubbed ViTAS, to search for\nthe optimal architecture with similar hardware budgets. Concretely, we design a\nnew effective yet efficient weight sharing paradigm for ViTs, such that\narchitectures with different token embedding, sequence size, number of heads,\nwidth, and depth can be derived from a single super-transformer. Moreover, to\ncater for the variance of distinct architectures, we introduce \\textit{private}\nclass token and self-attention maps in the super-transformer. In addition, to\nadapt the searching for different budgets, we propose to search the sampling\nprobability of identity operation. Experimental results show that our ViTAS\nattains excellent results compared to existing pure transformer architectures.\nFor example, with $1.3$G FLOPs budget, our searched architecture achieves\n$74.7\\%$ top-$1$ accuracy on ImageNet and is $2.5\\%$ superior than the current\nbaseline ViT architecture. Code is available at\n\\url{https://github.com/xiusu/ViTAS}.",
    "descriptor": "",
    "authors": [
      "Xiu Su",
      "Shan You",
      "Jiyang Xie",
      "Mingkai Zheng",
      "Fei Wang",
      "Chen Qian",
      "Changshui Zhang",
      "Xiaogang Wang",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13700"
  },
  {
    "id": "arXiv:2106.13703",
    "title": "Task-Driven Out-of-Distribution Detection with Statistical Guarantees  for Robot Learning",
    "abstract": "Our goal is to perform out-of-distribution (OOD) detection, i.e., to detect\nwhen a robot is operating in environments that are drawn from a different\ndistribution than the environments used to train the robot. We leverage\nProbably Approximately Correct (PAC)-Bayes theory in order to train a policy\nwith a guaranteed bound on performance on the training distribution. Our key\nidea for OOD detection then relies on the following intuition: violation of the\nperformance bound on test environments provides evidence that the robot is\noperating OOD. We formalize this via statistical techniques based on p-values\nand concentration inequalities. The resulting approach (i) provides guaranteed\nconfidence bounds on OOD detection, and (ii) is task-driven and sensitive only\nto changes that impact the robot's performance. We demonstrate our approach on\na simulated example of grasping objects with unfamiliar poses or shapes. We\nalso present both simulation and hardware experiments for a drone performing\nvision-based obstacle avoidance in unfamiliar environments (including wind\ndisturbances and different obstacle densities). Our examples demonstrate that\nwe can perform task-driven OOD detection within just a handful of trials.\nComparisons with baselines also demonstrate the advantages of our approach in\nterms of providing statistical guarantees and being insensitive to\ntask-irrelevant distribution shifts.",
    "descriptor": "",
    "authors": [
      "Alec Farid",
      "Sushant Veer",
      "Anirudha Majumdar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.13703"
  },
  {
    "id": "arXiv:2106.13709",
    "title": "A constructive theory of shape",
    "abstract": "We formulate a theory of shape valid for objects of arbitrary dimension whose\ncontours are path connected. Infinite families of qualitatively similar shapes\nare constructed giving as input a finite ordered set of characteristic points\n(landmarks) and the value of a continuous parameter $\\kappa \\in (0,\\infty)$.\nThe theory is constructive in the sense that it provides a systematic means to\nbuild a mathematical model for any shape taken from the physical world. We\nillustrate this with a variety of examples: (chaotic) time series, plane\ncurves, space filling curves and knots. In particular, we construct an infinite\nfamily of fractal curves whose shape approaches the one of Hilbert's curve in\nthe limit $\\kappa \\to 0$, yielding, for $\\kappa$ finite, fractal space-filling\ncurves with nonlinear contours.",
    "descriptor": "\nComments: 17 pages, 9 figures. Submitted for publication\n",
    "authors": [
      "Vladimir Garc\u00eda-Morales"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13709"
  },
  {
    "id": "arXiv:2106.13710",
    "title": "L, Q, R, and T -- Which Spin Bit Cousin Is Here to Stay?",
    "abstract": "Network operators utilize traffic monitoring to locate and fix faults or\nperformance bottlenecks. This often relies on intrinsic protocol semantics,\ne.g., sequence numbers, that many protocols share implicitly through their\npacket headers. The arrival of (almost) fully encrypted transport protocols,\nsuch as QUIC, significantly complicates this monitoring as header data is no\nlonger visible to passive observers. Recognizing this challenge, QUIC offers\nexplicit measurement semantics by exposing the spin bit to measure a flow's\nRTT. Ongoing efforts in the IETF IPPM working group argue to expose further\ninformation and enable the passive quantification of packet loss. This work\nimplements and evaluates four currently proposed measurement techniques (L-,\nQ-, R-, and T-bit). We find that all techniques generally provide accurate loss\nestimations, but that longer algorithmic intervals for Q and R, yet foremost\nfor T, complicate detecting very small loss rates or loss on short connections.\nDeployment combinations of Q & R as well as Q & L, thus, have the best\npotential for accurately grasping the loss in networks.",
    "descriptor": "",
    "authors": [
      "Ike Kunze",
      "Klaus Wehrle",
      "Jan R\u00fcth"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.13710"
  },
  {
    "id": "arXiv:2106.13711",
    "title": "Multimodal Emergent Fake News Detection via Meta Neural Process Networks",
    "abstract": "Fake news travels at unprecedented speeds, reaches global audiences and puts\nusers and communities at great risk via social media platforms. Deep learning\nbased models show good performance when trained on large amounts of labeled\ndata on events of interest, whereas the performance of models tends to degrade\non other events due to domain shift. Therefore, significant challenges are\nposed for existing detection approaches to detect fake news on emergent events,\nwhere large-scale labeled datasets are difficult to obtain. Moreover, adding\nthe knowledge from newly emergent events requires to build a new model from\nscratch or continue to fine-tune the model, which can be challenging,\nexpensive, and unrealistic for real-world settings. In order to address those\nchallenges, we propose an end-to-end fake news detection framework named\nMetaFEND, which is able to learn quickly to detect fake news on emergent events\nwith a few verified posts. Specifically, the proposed model integrates\nmeta-learning and neural process methods together to enjoy the benefits of\nthese approaches. In particular, a label embedding module and a hard attention\nmechanism are proposed to enhance the effectiveness by handling categorical\ninformation and trimming irrelevant posts. Extensive experiments are conducted\non multimedia datasets collected from Twitter and Weibo. The experimental\nresults show our proposed MetaFEND model can detect fake news on never-seen\nevents effectively and outperform the state-of-the-art methods.",
    "descriptor": "\nComments: accepted by KDD 2021\n",
    "authors": [
      "Yaqing Wang",
      "Fenglong Ma",
      "Haoyu Wang",
      "Kishlay Jha",
      "Jing Gao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.13711"
  },
  {
    "id": "arXiv:2106.13712",
    "title": "Cybersecurity Challenges in Distributed Control",
    "abstract": "Cyber-physical systems are becoming core of the most modern systems\nconsisting control, data sharing and real-time monitoring. While centralized\ncontrol technique has been implemented in the past, recent innovation in\ndistributed control schemes makes it attractive due to various reasons. One of\nthem is the use of state-of-the-art communication protocols that makes the\nsystem more robust toward extreme conditions and ensures observability. Thus,\nas an application of cyber-physical systems, distributed control architectures\nare prone to various cyber-vulnerability which makes cybersecurity research\ncritical in this application domain. This paper reviews recent researches of\ndistributed control architectures, their cyber-vulnerabilities, and reported\nmitigation schemes. Finally, some research needs are addressed.",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Md Amimul Ehsan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13712"
  },
  {
    "id": "arXiv:2106.13713",
    "title": "The Numerical Unified Transform Method for the Nonlinear Schr\u00f6dinger  equation on the half-line",
    "abstract": "We implement the Numerical Unified Transform Method to solve the Nonlinear\nSchr\\\"odinger equation on the half-line. For so-called linearizable boundary\nconditions, the method solves the half-line problems with comparable complexity\nas the Numerical Inverse Scattering Transform solves whole-line problems. In\nparticular, the method computes the solution at any $x$ and $t$ without spatial\ndiscretization or time stepping. Contour deformations based on the method of\nnonlinear steepest descent are used so that the method's computational cost\ndoes not increase for large $x,t$ and the method is more accurate as $x,t$\nincrease. Our ideas also apply to some cases where the boundary conditions are\nnot linearizable.",
    "descriptor": "",
    "authors": [
      "Xin Yang",
      "Bernard Deconinck",
      "Thomas Trogdon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Exactly Solvable and Integrable Systems (nlin.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13713"
  },
  {
    "id": "arXiv:2106.13715",
    "title": "Learning to Sample Replacements for ELECTRA Pre-Training",
    "abstract": "ELECTRA pretrains a discriminator to detect replaced tokens, where the\nreplacements are sampled from a generator trained with masked language\nmodeling. Despite the compelling performance, ELECTRA suffers from the\nfollowing two issues. First, there is no direct feedback loop from\ndiscriminator to generator, which renders replacement sampling inefficient.\nSecond, the generator's prediction tends to be over-confident along with\ntraining, making replacements biased to correct tokens. In this paper, we\npropose two methods to improve replacement sampling for ELECTRA pre-training.\nSpecifically, we augment sampling with a hardness prediction mechanism, so that\nthe generator can encourage the discriminator to learn what it has not\nacquired. We also prove that efficient sampling reduces the training variance\nof the discriminator. Moreover, we propose to use a focal loss for the\ngenerator in order to relieve oversampling of correct tokens as replacements.\nExperimental results show that our method improves ELECTRA pre-training on\nvarious downstream tasks.",
    "descriptor": "\nComments: Accepted by Findings of ACL 2021\n",
    "authors": [
      "Yaru Hao",
      "Li Dong",
      "Hangbo Bao",
      "Ke Xu",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.13715"
  },
  {
    "id": "arXiv:2106.13717",
    "title": "Optimizing Rayleigh quotient with symmetric constraints and their  applications to perturbations of the structured polynomial eigenvalue problem",
    "abstract": "For a Hermitian matrix $H \\in \\mathbb C^{n,n}$ and symmetric matrices $S_0,\nS_1,\\ldots,S_k \\in \\mathbb C^{n,n}$, we consider the problem of computing the\nsupremum of $\\left\\{ \\frac{v^*Hv}{v^*v}:~v\\in \\mathbb C^{n}\\setminus\n\\{0\\},\\,v^TS_iv=0~\\text{for}~i=0,\\ldots,k\\right\\}$. For this, we derive an\nestimation in the form of minimizing the second largest eigenvalue of a\nparameter depending Hermitian matrix, which is exact when the eigenvalue at the\noptimal is simple. The results are then applied to compute the eigenvalue\nbackward errors of higher degree matrix polynomials with T-palindromic,\nT-antipalindromic, T-even, T-odd, and skew-symmetric structures. The results\nare illustrated by numerical experiments.",
    "descriptor": "",
    "authors": [
      "Anshul Prajapati",
      "Punit Sharma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.13717"
  },
  {
    "id": "arXiv:2106.13718",
    "title": "Black Box Probabilistic Numerics",
    "abstract": "Probabilistic numerics casts numerical tasks, such the numerical solution of\ndifferential equations, as inference problems to be solved. One approach is to\nmodel the unknown quantity of interest as a random variable, and to constrain\nthis variable using data generated during the course of a traditional numerical\nmethod. However, data may be nonlinearly related to the quantity of interest,\nrendering the proper conditioning of random variables difficult and limiting\nthe range of numerical tasks that can be addressed. Instead, this paper\nproposes to construct probabilistic numerical methods based only on the final\noutput from a traditional method. A convergent sequence of approximations to\nthe quantity of interest constitute a dataset, from which the limiting quantity\nof interest can be extrapolated, in a probabilistic analogue of Richardson's\ndeferred approach to the limit. This black box approach (1) massively expands\nthe range of tasks to which probabilistic numerics can be applied, (2) inherits\nthe features and performance of state-of-the-art numerical methods, and (3)\nenables provably higher orders of convergence to be achieved. Applications are\npresented for nonlinear ordinary and partial differential equations, as well as\nfor eigenvalue problems-a setting for which no probabilistic numerical methods\nhave yet been developed.",
    "descriptor": "",
    "authors": [
      "Onur Teymur",
      "Christopher N. Foley",
      "Philip G. Breen",
      "Toni Karvonen",
      "Chris. J. Oates"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13718"
  },
  {
    "id": "arXiv:2106.13722",
    "title": "A Curiously Effective Backtracking Strategy for Connection Tableaux",
    "abstract": "Automated proof search with connection tableaux, such as implemented by\nOtten's leanCoP prover, depends on backtracking for completeness. Otten's\nrestricted backtracking strategy loses completeness, yet for many problems, it\nsignificantly reduces the time required to find a proof. I introduce a new,\nless restricted backtracking strategy based on the notion of exclusive cuts. I\nimplement the strategy in a new prover called meanCoP and show that it greatly\nimproves upon the previous best strategy in leanCoP.",
    "descriptor": "\nComments: Submitted to TABLEAUX 2021\n",
    "authors": [
      "Michael F\u00e4rber"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.13722"
  },
  {
    "id": "arXiv:2106.13723",
    "title": "Scale-invariant multilevel Monte Carlo method",
    "abstract": "In this paper, the scale-invariant version of the mean and variance\nmulti-level Monte Carlo estimate is proposed. The optimization of the\ncomputation cost over the grid levels is done with the help of a novel\nnormalized error based on t-statistic. In this manner, the algorithm\nconvergence is made invariant to the physical scale at which the estimate is\ncomputed. The novel algorithm is tested on the linear elastic example, the\nconstitutive law of which is described by material uncertainty including both\nheterogeneity and anisotropy.",
    "descriptor": "",
    "authors": [
      "Sharana Kumar Shivanand",
      "Bojana Rosi\u0107"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.13723"
  },
  {
    "id": "arXiv:2106.13727",
    "title": "Interval and fuzzy physics-informed neural networks for uncertain fields",
    "abstract": "Temporally and spatially dependent uncertain parameters are regularly\nencountered in engineering applications. Commonly these uncertainties are\naccounted for using random fields and processes which require knowledge about\nthe appearing probability distributions functions which is not readily\navailable. In these cases non-probabilistic approaches such as interval\nanalysis and fuzzy set theory are helpful uncertainty measures. Partial\ndifferential equations involving fuzzy and interval fields are traditionally\nsolved using the finite element method where the input fields are sampled using\nsome basis function expansion methods. This approach however is problematic, as\nit is reliant on knowledge about the spatial correlation fields. In this work\nwe utilize physics-informed neural networks (PINNs) to solve interval and fuzzy\npartial differential equations. The resulting network structures termed\ninterval physics-informed neural networks (iPINNs) and fuzzy physics-informed\nneural networks (fPINNs) show promising results for obtaining bounded solutions\nof equations involving spatially uncertain parameter fields. In contrast to\nfinite element approaches, no correlation length specification of the input\nfields as well as no averaging via Monte-Carlo simulations are necessary. In\nfact, information about the input interval fields is obtained directly as a\nbyproduct of the presented solution scheme. Furthermore, all major advantages\nof PINNs are retained, i.e. meshfree nature of the scheme, and ease of inverse\nproblem set-up.",
    "descriptor": "\nComments: 13 pages,12 figures\n",
    "authors": [
      "Jan Niklas Fuhg",
      "Am\u00e9lie Fau",
      "Nikolaos Bouklas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13727"
  },
  {
    "id": "arXiv:2106.13728",
    "title": "Linking ghost penalty and aggregated unfitted methods",
    "abstract": "In this work, we analyse the links between ghost penalty stabilisation and\naggregation-based discrete extension operators for the numerical approximation\nof elliptic partial differential equations on unfitted meshes. We explore the\nbehavior of ghost penalty methods in the limit as the penalty parameter goes to\ninfinity, which returns a strong version of these methods. We observe that\nthese methods suffer locking in that limit. On the contrary, aggregated finite\nelement spaces are locking-free because they can be expressed as an extension\noperator from well-posed to ill-posed degrees of freedom. Next, we propose\nnovel ghost penalty methods that penalise the distance between the solution and\nits aggregation-based discrete extension. These methods are locking-free and\nconverge to aggregated finite element methods in the infinite penalty parameter\nlimit. We include an exhaustive set of numerical experiments in which we\ncompare weak (ghost penalty) and strong (aggregated finite elements) schemes in\nterms of error quantities, condition numbers and sensitivity with respect to\npenalty coefficients on different geometries, intersection locations and mesh\ntopologies.",
    "descriptor": "",
    "authors": [
      "Santiago Badia",
      "Eric Neiva",
      "Francesc Verdugo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.13728"
  },
  {
    "id": "arXiv:2106.13729",
    "title": "Python computations of general Heun functions from their integral series  representations",
    "abstract": "We present a numerical implementation in Python of the recently developed\nunconditionally convergent representation of general Heun functions as integral\nseries. We produce two codes available for download, one especially aimed at\nreproducing the output of Mathematica's HeunG function, the other for\ngeneral-purpose computations. We show that the present code compares favorably\nwith Mathematica's function, point to further improvements, and discuss the\nissue of singularities.",
    "descriptor": "",
    "authors": [
      "Tolga Birkandan",
      "Pierre-Louis Giscard",
      "Aditya Tamar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.13729"
  },
  {
    "id": "arXiv:2106.13731",
    "title": "Ranger21: a synergistic deep learning optimizer",
    "abstract": "As optimizers are critical to the performances of neural networks, every year\na large number of papers innovating on the subject are published. However,\nwhile most of these publications provide incremental improvements to existing\nalgorithms, they tend to be presented as new optimizers rather than composable\nalgorithms. Thus, many worthwhile improvements are rarely seen out of their\ninitial publication. Taking advantage of this untapped potential, we introduce\nRanger21, a new optimizer which combines AdamW with eight components, carefully\nselected after reviewing and testing ideas from the literature. We found that\nthe resulting optimizer provides significantly improved validation accuracy and\ntraining speed, smoother training curves, and is even able to train a ResNet50\non ImageNet2012 without Batch Normalization layers. A problem on which AdamW\nstays systematically stuck in a bad initial state.",
    "descriptor": "\nComments: for associated code, see this https URL\n",
    "authors": [
      "Less Wright",
      "Nestor Demeure"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13731"
  },
  {
    "id": "arXiv:2106.13732",
    "title": "Recurrent Coupled Topic Modeling over Sequential Documents",
    "abstract": "The abundant sequential documents such as online archival, social media and\nnews feeds are streamingly updated, where each chunk of documents is\nincorporated with smoothly evolving yet dependent topics. Such digital texts\nhave attracted extensive research on dynamic topic modeling to infer hidden\nevolving topics and their temporal dependencies. However, most of the existing\napproaches focus on single-topic-thread evolution and ignore the fact that a\ncurrent topic may be coupled with multiple relevant prior topics. In addition,\nthese approaches also incur the intractable inference problem when inferring\nlatent parameters, resulting in a high computational cost and performance\ndegradation. In this work, we assume that a current topic evolves from all\nprior topics with corresponding coupling weights, forming the\nmulti-topic-thread evolution. Our method models the dependencies between\nevolving topics and thoroughly encodes their complex multi-couplings across\ntime steps. To conquer the intractable inference challenge, a new solution with\na set of novel data augmentation techniques is proposed, which successfully\ndiscomposes the multi-couplings between evolving topics. A fully conjugate\nmodel is thus obtained to guarantee the effectiveness and efficiency of the\ninference technique. A novel Gibbs sampler with a backward-forward filter\nalgorithm efficiently learns latent timeevolving parameters in a closed-form.\nIn addition, the latent Indian Buffet Process (IBP) compound distribution is\nexploited to automatically infer the overall topic number and customize the\nsparse topic proportions for each sequential document without bias. The\nproposed method is evaluated on both synthetic and real-world datasets against\nthe competitive baselines, demonstrating its superiority over the baselines in\nterms of the low per-word perplexity, high coherent topics, and better document\ntime prediction.",
    "descriptor": "",
    "authors": [
      "Jinjin Guo",
      "Longbing Cao",
      "Zhiguo Gong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13732"
  },
  {
    "id": "arXiv:2106.13734",
    "title": "Projection-wise Disentangling for Fair and Interpretable Representation  Learning: Application to 3D Facial Shape Analysis",
    "abstract": "Confounding bias is a crucial problem when applying machine learning to\npractice, especially in clinical practice. We consider the problem of learning\nrepresentations independent to multiple biases. In literature, this is mostly\nsolved by purging the bias information from learned representations. We however\nexpect this strategy to harm the diversity of information in the\nrepresentation, and thus limiting its prospective usage (e.g., interpretation).\nTherefore, we propose to mitigate the bias while keeping almost all information\nin the latent representations, which enables us to observe and interpret them\nas well. To achieve this, we project latent features onto a learned vector\ndirection, and enforce the independence between biases and projected features\nrather than all learned features. To interpret the mapping between projected\nfeatures and input data, we propose projection-wise disentangling: a sampling\nand reconstruction along the learned vector direction. The proposed method was\nevaluated on the analysis of 3D facial shape and patient characteristics\n(N=5011). Experiments showed that this conceptually simple method achieved\nstate-of-the-art fair prediction performance and interpretability, showing its\ngreat potential for clinical applications.",
    "descriptor": "\nComments: Accepted at MICCAI 2021\n",
    "authors": [
      "Xianjing Liu",
      "Bo Li",
      "Esther Bron",
      "Wiro Niessen",
      "Eppo Wolvius",
      "Gennady Roshchupkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13734"
  },
  {
    "id": "arXiv:2106.13736",
    "title": "DeltaLM: Encoder-Decoder Pre-training for Language Generation and  Translation by Augmenting Pretrained Multilingual Encoders",
    "abstract": "While pretrained encoders have achieved success in various natural language\nunderstanding (NLU) tasks, there is a gap between these pretrained encoders and\nnatural language generation (NLG). NLG tasks are often based on the\nencoder-decoder framework, where the pretrained encoders can only benefit part\nof it. To reduce this gap, we introduce DeltaLM, a pretrained multilingual\nencoder-decoder model that regards the decoder as the task layer of\noff-the-shelf pretrained encoders. Specifically, we augment the pretrained\nmultilingual encoder with a decoder and pre-train it in a self-supervised way.\nTo take advantage of both the large-scale monolingual data and bilingual data,\nwe adopt the span corruption and translation span corruption as the\npre-training tasks. Experiments show that DeltaLM outperforms various strong\nbaselines on both natural language generation and translation tasks, including\nmachine translation, abstractive text summarization, data-to-text, and question\ngeneration.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Shuming Ma",
      "Li Dong",
      "Shaohan Huang",
      "Dongdong Zhang",
      "Alexandre Muzio",
      "Saksham Singhal",
      "Hany Hassan Awadalla",
      "Xia Song",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.13736"
  },
  {
    "id": "arXiv:2106.13739",
    "title": "Re-parameterizing VAEs for stability",
    "abstract": "We propose a theoretical approach towards the training numerical stability of\nVariational AutoEncoders (VAE). Our work is motivated by recent studies\nempowering VAEs to reach state of the art generative results on complex image\ndatasets. These very deep VAE architectures, as well as VAEs using more complex\noutput distributions, highlight a tendency to haphazardly produce high training\ngradients as well as NaN losses. The empirical fixes proposed to train them\ndespite their limitations are neither fully theoretically grounded nor\ngenerally sufficient in practice. Building on this, we localize the source of\nthe problem at the interface between the model's neural networks and their\noutput probabilistic distributions. We explain a common source of instability\nstemming from an incautious formulation of the encoded Normal distribution's\nvariance, and apply the same approach on other, less obvious sources. We show\nthat by implementing small changes to the way we parameterize the Normal\ndistributions on which they rely, VAEs can securely be trained.",
    "descriptor": "",
    "authors": [
      "David Dehaene",
      "R\u00e9my Brossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13739"
  },
  {
    "id": "arXiv:2106.13740",
    "title": "Advancing Methodology for Social Science Research Using Alternate  Reality Games: Proof-of-Concept Through Measuring Individual Differences and  Adaptability and their impact on Team Performance",
    "abstract": "While work in fields of CSCW (Computer Supported Collaborative Work),\nPsychology and Social Sciences have progressed our understanding of team\nprocesses and their effect performance and effectiveness, current methods rely\non observations or self-report, with little work directed towards studying team\nprocesses with quantifiable measures based on behavioral data. In this report\nwe discuss work tackling this open problem with a focus on understanding\nindividual differences and its effect on team adaptation, and further explore\nthe effect of these factors on team performance as both an outcome and a\nprocess. We specifically discuss our contribution in terms of methods that\naugment survey data and behavioral data that allow us to gain more insight on\nteam performance as well as develop a method to evaluate adaptation and\nperformance across and within a group. To make this problem more tractable we\nchose to focus on specific types of environments, Alternate Reality Games\n(ARGs), and for several reasons. First, these types of games involve setups\nthat are similar to a real-world setup, e.g., communication through slack or\nemail. Second, they are more controllable than real environments allowing us to\nembed stimuli if needed. Lastly, they allow us to collect data needed to\nunderstand decisions and communications made through the entire duration of the\nexperience, which makes team processes more transparent than otherwise\npossible. In this report we discuss the work we did so far and demonstrate the\nefficacy of the approach.",
    "descriptor": "",
    "authors": [
      "Magy Seif El-Nasr",
      "Casper Harteveld",
      "Paul Fombelle",
      "Truong-Huy Nguyen",
      "Paola Rizzo",
      "Dylan Schouten",
      "Abdelrahman Madkour",
      "Chaima Jemmali",
      "Erica Kleinman",
      "Nithesh Javvaji",
      "Zhaoqing Teng",
      "Extra Ludic Inc"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13740"
  },
  {
    "id": "arXiv:2106.13742",
    "title": "Glyph: Visualization Tool for Understanding Problem Solving Strategies  in Puzzle Games",
    "abstract": "Understanding player strategies is a key question when analyzing player\nbehavior both for academic researchers and industry practitioners. For game\ndesigners and game user researchers, it is important to gauge the distance\nbetween intended strategies and emergent strategies; this comparison allows\nidentification of glitches or undesirable behaviors. For academic researchers\nusing games for serious purposes such as education, the strategies adopted by\nplayers are indicative of their cognitive progress in relation to serious\ngoals, such as learning process. Current techniques and systems created to\naddress these needs present a few drawbacks. Qualitative methods are difficult\nto scale upwards to include large number of players and are prone to subjective\nbiases. Other approaches such as visualization and analytical tools are either\ndesigned to provide an aggregated overview of the data, losing the nuances of\nindividual player behaviors, or, in the attempt of accounting for individual\nbehavior, are not specifically designed to reduce the visual cognitive load. In\nthis work, we propose a novel visualization technique that specifically\naddresses the tasks of comparing behavior sequences in order to capture an\noverview of the strategies enacted by players and at the same time examine\nindividual player behaviors to identify differences and outliers. This approach\nallows users to form hypotheses about player strategies and verify them. We\ndemonstrate the effectiveness of the technique through a case study: utilizing\na prototype system to investigate data collected from a commercial educational\npuzzle game. While the prototype's usability can be improved, initial testing\nresults show that core features of the system proved useful to our potential\nusers for understanding player strategies.",
    "descriptor": "",
    "authors": [
      "Truong-Huy Dinh Nguyen",
      "Magy Seif El-Nasr",
      "Alessandro Canossa"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.13742"
  },
  {
    "id": "arXiv:2106.13743",
    "title": "Privileged Zero-Shot AutoML",
    "abstract": "This work improves the quality of automated machine learning (AutoML) systems\nby using dataset and function descriptions while significantly decreasing\ncomputation time from minutes to milliseconds by using a zero-shot approach.\nGiven a new dataset and a well-defined machine learning task, humans begin by\nreading a description of the dataset and documentation for the algorithms to be\nused. This work is the first to use these textual descriptions, which we call\nprivileged information, for AutoML. We use a pre-trained Transformer model to\nprocess the privileged text and demonstrate that using this information\nimproves AutoML performance. Thus, our approach leverages the progress of\nunsupervised representation learning in natural language processing to provide\na significant boost to AutoML. We demonstrate that using only textual\ndescriptions of the data and functions achieves reasonable classification\nperformance, and adding textual descriptions to data meta-features improves\nclassification across tabular datasets. To achieve zero-shot AutoML we train a\ngraph neural network with these description embeddings and the data\nmeta-features. Each node represents a training dataset, which we use to predict\nthe best machine learning pipeline for a new test dataset in a zero-shot\nfashion. Our zero-shot approach rapidly predicts a high-quality pipeline for a\nsupervised learning task and dataset. In contrast, most AutoML systems require\ntens or hundreds of pipeline evaluations. We show that zero-shot AutoML reduces\nrunning and prediction times from minutes to milliseconds, consistently across\ndatasets. By speeding up AutoML by orders of magnitude this work demonstrates\nreal-time AutoML.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Nikhil Singh",
      "Brandon Kates",
      "Jeff Mentch",
      "Anant Kharkar",
      "Madeleine Udell",
      "Iddo Drori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.13743"
  },
  {
    "id": "arXiv:2106.13747",
    "title": "Unpacking Adherence and Engagement in Pervasive Health Games",
    "abstract": "Pervasive health games have a potential to impact health-related behaviors.\nAnd, similar to other types of interventions, engagement and adherence in\nhealth games is the keystone for examining their short- and long-term effects.\nMany health-based applications have turned to gamification principles\nspecifically to. enhance their engagement. However, according to many reports,\nonly 41% of participants are retained in single player games and 29% in social\ngames after 90 days. These statistics raise multiple questions about factors\ninfluencing adherence and engagement. This paper presents an in-depth\nmixed-methods investigation of game design factors affecting engagement with\nand adherence to a pervasive commercial health game, called SpaPlay. We\nanalyzed interview and game behavior log data using theoretical constructs of\nsustained engagement to identify design elements affecting engagement and\nadherence. Our findings indicate that design elements associated with autonomy.\nand relatedness from the Self-Determination Theory and integrability, a measure\nof how well activities align with a person's life style, are important factors\naffecting engagement and adherence.",
    "descriptor": "",
    "authors": [
      "Magy Seif El-Nasr",
      "Shree Durga",
      "Mariya Shiyko",
      "Carmen Sceppa"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.13747"
  },
  {
    "id": "arXiv:2106.13749",
    "title": "Jitter: Random Jittering Loss Function",
    "abstract": "Regularization plays a vital role in machine learning optimization. One novel\nregularization method called flooding makes the training loss fluctuate around\nthe flooding level. It intends to make the model continue to random walk until\nit comes to a flat loss landscape to enhance generalization. However, the\nhyper-parameter flooding level of the flooding method fails to be selected\nproperly and uniformly. We propose a novel method called Jitter to improve it.\nJitter is essentially a kind of random loss function. Before training, we\nrandomly sample the Jitter Point from a specific probability distribution. The\nflooding level should be replaced by Jitter point to obtain a new target\nfunction and train the model accordingly. As Jitter point acting as a random\nfactor, we actually add some randomness to the loss function, which is\nconsistent with the fact that there exists innumerable random behaviors in the\nlearning process of the machine learning model and is supposed to make the\nmodel more robust. In addition, Jitter performs random walk randomly which\ndivides the loss curve into small intervals and then flipping them over,\nideally making the loss curve much flatter and enhancing generalization\nability. Moreover, Jitter can be a domain-, task-, and model-independent\nregularization method and train the model effectively after the training error\nreduces to zero. Our experimental results show that Jitter method can improve\nmodel performance more significantly than the previous flooding method and make\nthe test loss curve descend twice.",
    "descriptor": "\nComments: IJCNN 2021\n",
    "authors": [
      "Zhicheng Cai",
      "Chenglei Peng",
      "Sidan Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13749"
  },
  {
    "id": "arXiv:2106.13750",
    "title": "Assessing the Lockdown Effects on Air Quality during COVID-19 Era",
    "abstract": "In this work we investigate the short-term variations in air quality\nemissions, attributed to the prevention measures, applied in different cities,\nto mitigate the COVID-19 spread. In particular, we emphasize on the\nconcentration effects regarding specific pollutant gases, such as carbon\nmonoxide (CO), ozone (O3), nitrogen dioxide (NO2) and sulphur dioxide (SO2).\nThe assessment of the impact of lockdown on air quality focused on four\nEuropean Cities (Athens, Gladsaxe, Lodz and Rome). Available data on pollutant\nfactors were obtained using global satellite observations. The level of the\nemployed prevention measures is employed using the Oxford COVID-19 Government\nResponse Tracker. The second part of the analysis employed a variety of machine\nlearning tools, utilized for estimating the concentration of each pollutant,\ntwo days ahead. The results showed that a weak to moderate correlation exists\nbetween the corresponding measures and the pollutant factors and that it is\npossible to create models which can predict the behaviour of the pollutant\ngases under daily human activities.",
    "descriptor": "",
    "authors": [
      "Ioannis Kavouras",
      "Eftychios Protopapadakis",
      "Maria Kaselimia",
      "Emmanuel Sardis",
      "Nikolaos Doulamis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.13750"
  },
  {
    "id": "arXiv:2106.13753",
    "title": "Investigating behavior change indicators and cognitive measures in  persuasive health games",
    "abstract": "Outcome-driven studies designed to evaluate potential effects of games and\napps designed to promote healthy eating and exercising remain limited either\ntargeting design or usability factors while omitting out health-based outcomes\naltogether, or tend to be too narrowly focuses on behavioral outcomes within a\nshort periods of time thereby less likely to influence longitudinal factors\nthat can help sustain healthy habits. In this paper we argue for a unified\napproach to tackle behavioral change through focusing on both health outcomes\nand cognitive precursors, such as players' attitudes and behaviors around\nhealthy eating and exercising, motivation stage and knowledge and awareness\nabout nutrition or physical activity. Key findings from a 3-month long game\nplay study, with 47 female participants indicate that there are clear shifts in\nplayers' perceptions about health and knowledge about eating. This paper\nextends our current understandings about approaches for evaluating health games\nand presents a unified approach to assess effectiveness of game-based health\ninterventions through combining health-based outcomes and shifts in players'\ncognitive precursors.",
    "descriptor": "",
    "authors": [
      "S. Durga",
      "S. Hallinan",
      "M. Seif El-Nasr",
      "M. Shiyko",
      "C. Sceppa"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.13753"
  },
  {
    "id": "arXiv:2106.13754",
    "title": "Nonlinear Acoustic Echo Cancellation with Deep Learning",
    "abstract": "We propose a nonlinear acoustic echo cancellation system, which aims to model\nthe echo path from the far-end signal to the near-end microphone in two parts.\nInspired by the physical behavior of modern hands-free devices, we first\nintroduce a novel neural network architecture that is specifically designed to\nmodel the nonlinear distortions these devices induce between receiving and\nplaying the far-end signal. To account for variations between devices, we\nconstruct this network with trainable memory length and nonlinear activation\nfunctions that are not parameterized in advance, but are rather optimized\nduring the training stage using the training data. Second, the network is\nsucceeded by a standard adaptive linear filter that constantly tracks the echo\npath between the loudspeaker output and the microphone. During training, the\nnetwork and filter are jointly optimized to learn the network parameters. This\nsystem requires 17 thousand parameters that consume 500 Million floating-point\noperations per second and 40 Kilo-bytes of memory. It also satisfies hands-free\ncommunication timing requirements on a standard neural processor, which renders\nit adequate for embedding on hands-free communication devices. Using 280 hours\nof real and synthetic data, experiments show advantageous performance compared\nto competing methods.",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Amir Ivry",
      "Israel Cohen",
      "Baruch Berdugo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.13754"
  },
  {
    "id": "arXiv:2106.13756",
    "title": "Private Adaptive Gradient Methods for Convex Optimization",
    "abstract": "We study adaptive methods for differentially private convex optimization,\nproposing and analyzing differentially private variants of a Stochastic\nGradient Descent (SGD) algorithm with adaptive stepsizes, as well as the\nAdaGrad algorithm. We provide upper bounds on the regret of both algorithms and\nshow that the bounds are (worst-case) optimal. As a consequence of our\ndevelopment, we show that our private versions of AdaGrad outperform adaptive\nSGD, which in turn outperforms traditional SGD in scenarios with non-isotropic\ngradients where (non-private) Adagrad provably outperforms SGD. The major\nchallenge is that the isotropic noise typically added for privacy dominates the\nsignal in gradient geometry for high-dimensional problems; approaches to this\nthat effectively optimize over lower-dimensional subspaces simply ignore the\nactual problems that varying gradient geometries introduce. In contrast, we\nstudy non-isotropic clipping and noise addition, developing a principled\ntheoretical approach; the consequent procedures also enjoy significantly\nstronger empirical performance than prior approaches.",
    "descriptor": "\nComments: To appear in 38th International Conference on Machine Learning (ICML 2021)\n",
    "authors": [
      "Hilal Asi",
      "John Duchi",
      "Alireza Fallah",
      "Omid Javidbakht",
      "Kunal Talwar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13756"
  },
  {
    "id": "arXiv:2106.13763",
    "title": "Voice Activity Detection for Transient Noisy Environment Based on  Diffusion Nets",
    "abstract": "We address voice activity detection in acoustic environments of transients\nand stationary noises, which often occur in real life scenarios. We exploit\nunique spatial patterns of speech and non-speech audio frames by independently\nlearning their underlying geometric structure. This process is done through a\ndeep encoder-decoder based neural network architecture. This structure involves\nan encoder that maps spectral features with temporal information to their\nlow-dimensional representations, which are generated by applying the diffusion\nmaps method. The encoder feeds a decoder that maps the embedded data back into\nthe high-dimensional space. A deep neural network, which is trained to separate\nspeech from non-speech frames, is obtained by concatenating the decoder to the\nencoder, resembling the known Diffusion nets architecture. Experimental results\nshow enhanced performance compared to competing voice activity detection\nmethods. The improvement is achieved in both accuracy, robustness and\ngeneralization ability. Our model performs in a real-time manner and can be\nintegrated into audio-based communication systems. We also present a batch\nalgorithm which obtains an even higher accuracy for off-line applications.",
    "descriptor": "\nComments: Accepted to IEEE journal of selected topics in signal processing 2019\n",
    "authors": [
      "Amir Ivry",
      "Baruch Berdugo",
      "Israel Cohen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.13763"
  },
  {
    "id": "arXiv:2106.13764",
    "title": "To Block or Not to Block: Accelerating Mobile Web Pages On-The-Fly  Through JavaScript Classification",
    "abstract": "The increasing complexity of JavaScript in modern mobile web pages has become\na critical performance bottleneck for low-end mobile phone users, especially in\ndeveloping regions. In this paper, we propose SlimWeb, a novel approach that\nautomatically derives lightweight versions of mobile web pages on-the-fly by\neliminating the use of unnecessary JavaScript. SlimWeb consists of a JavaScript\nclassification service powered by a supervised Machine Learning (ML) model that\nprovides insights into each JavaScript element embedded in a web page. SlimWeb\naims to improve the web browsing experience by predicting the class of each\nelement, such that essential elements are preserved and non-essential elements\nare blocked by the browsers using the service. We motivate the core design of\nSlimWeb using a user preference survey of 306 users and perform a detailed\nevaluation of SlimWeb across 500 popular web pages in a developing region on\nreal 3G and 4G cellular networks, along with a user experience study with 20\nreal-world users and a usage willingness survey of 588 users. Evaluation\nresults show that SlimWeb achieves a 50% reduction in the page load time\ncompared to the original pages, and more than 30% reduction compared to\ncompeting solutions, while achieving high similarity scores to the original\npages measured via a qualitative evaluation study of 62 users. SlimWeb improves\nthe overall user experience by more than 60% compared to the original pages,\nwhile maintaining 90%-100% of the visual and functional components of most\npages. Finally, the SlimWeb classifier achieves a median accuracy of 90% in\npredicting the JavaScript category.",
    "descriptor": "\nComments: 11 pages, 11 figures\n",
    "authors": [
      "Moumena Chaqfeh",
      "Muhammad Haseeb",
      "Waleed Hashmi",
      "Patrick Inshuti",
      "Manesha Ramesh",
      "Matteo Varvello",
      "Fareed Zaffar",
      "Lakshmi Subramanian",
      "Yasir Zaki"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2106.13764"
  },
  {
    "id": "arXiv:2106.13765",
    "title": "\"Zero Shot\" Point Cloud Upsampling",
    "abstract": "Point cloud upsampling using deep learning has been paid various efforts in\nthe past few years. Recent supervised deep learning methods are restricted to\nthe size of training data and is limited in terms of covering all shapes of\npoint clouds. Besides, the acquisition of such amount of data is unrealistic,\nand the network generally performs less powerful than expected on unseen\nrecords. In this paper, we present an unsupervised approach to upsample point\nclouds internally referred as \"Zero Shot\" Point Cloud Upsampling (ZSPU) at\nholistic level. Our approach is solely based on the internal information\nprovided by a particular point cloud without patching in both self-training and\ntesting phases. This single-stream design significantly reduces the training\ntime of the upsampling task, by learning the relation between low-resolution\n(LR) point clouds and their high (original) resolution (HR) counterparts. This\nassociation will provide super-resolution (SR) outputs when original point\nclouds are loaded as input. We demonstrate competitive performance on benchmark\npoint cloud datasets when compared to other upsampling methods. Furthermore,\nZSPU achieves superior qualitative results on shapes with complex local details\nor high curvatures.",
    "descriptor": "",
    "authors": [
      "Kaiyue Zhou",
      "Ming Dong",
      "Suzan Arslanturk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13765"
  },
  {
    "id": "arXiv:2106.13767",
    "title": "Sentiment Progression based Searching and Indexing of Literary Textual  Artefacts",
    "abstract": "Literary artefacts are generally indexed and searched based on titles, meta\ndata and keywords over the years. This searching and indexing works well when\nuser/reader already knows about that particular creative textual artefact or\ndocument. This indexing and search hardly takes into account interest and\nemotional makeup of readers and its mapping to books. When a person is looking\nfor a literary textual artefact, he/she might be looking for not only\ninformation but also to seek the joy of reading. In case of literary artefacts,\nprogression of emotions across the key events could prove to be the key for\nindexing and searching. In this paper, we establish clusters among literary\nartefacts based on computational relationships among sentiment progressions\nusing intelligent text analysis. We have created a database of 1076 English\ntitles + 20 Marathi titles and also used database\nthis http URL with 16559 titles and their\nsummaries. We have proposed Sentiment Progression based Indexing for searching\nand recommending books. This can be used to create personalized clusters of\nbook titles of interest to readers. The analysis clearly suggests better\nsearching and indexing when we are targeting book lovers looking for a\nparticular type of book or creative artefact. This indexing and searching can\nfind many real-life applications for recommending books.",
    "descriptor": "\nComments: 12 pages, 2 figures, accepted at NLDB 2021\n",
    "authors": [
      "Hrishikesh Kulkarni",
      "Bradly Alicea"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.13767"
  },
  {
    "id": "arXiv:2106.13777",
    "title": "HyperNP: Interactive Visual Exploration of Multidimensional Projection  Hyperparameters",
    "abstract": "Projection algorithms such as t-SNE or UMAP are useful for the visualization\nof high dimensional data, but depend on hyperparameters which must be tuned\ncarefully. Unfortunately, iteratively recomputing projections to find the\noptimal hyperparameter value is computationally intensive and unintuitive due\nto the stochastic nature of these methods. In this paper we propose HyperNP, a\nscalable method that allows for real-time interactive hyperparameter\nexploration of projection methods by training neural network approximations.\nHyperNP can be trained on a fraction of the total data instances and\nhyperparameter configurations and can compute projections for new data and\nhyperparameters at interactive speeds. HyperNP is compact in size and fast to\ncompute, thus allowing it to be embedded in lightweight visualization systems\nsuch as web browsers. We evaluate the performance of the HyperNP across three\ndatasets in terms of performance and speed. The results suggest that HyperNP is\naccurate, scalable, interactive, and appropriate for use in real-world\nsettings.",
    "descriptor": "",
    "authors": [
      "Gabriel Appleby",
      "Mateus Espadoto",
      "Rui Chen",
      "Samuel Goree",
      "Alexandru Telea",
      "Erik W Anderson",
      "Remco Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.13777"
  },
  {
    "id": "arXiv:2106.13784",
    "title": "Programmable RO (PRO): A Multipurpose Countermeasure against  Side-channel and Fault Injection Attack",
    "abstract": "Side-channel and fault injection attacks reveal secret information by\nmonitoring or manipulating the physical effects of computations involving\nsecret variables. Circuit-level countermeasures help to deter these attacks,\nand traditionally such countermeasures have been developed for each attack\nvector separately. We demonstrate a multipurpose ring oscillator design -\nProgrammable Ring Oscillator (PRO) to address both fault attacks and\nside-channel attacks in a generic, application-independent manner. PRO, as an\nintegrated primitive, can provide on-chip side-channel resistance, power\nmonitoring, and fault detection capabilities to a secure design. We present a\ngrid of PROs monitoring the on-chip power network to detect anomalies. Such\npower anomalies may be caused by external factors such as electromagnetic fault\ninjection and power glitches, as well as by internal factors such as hardware\nTrojans. By monitoring the frequency of the ring oscillators, we are able to\ndetect the on-chip power anomaly in time as well as in location. Moreover, we\nshow that the PROs can also inject a random noise pattern into a design's power\nconsumption. By randomly switching the frequency of a ring oscillator, the\nresulting power-noise pattern significantly reduces the power-based\nside-channel leakage of a cipher. We discuss the design of PRO and present\nmeasurement results on a Xilinx Spartan-6 FPGA prototype, and we show that\nside-channel and fault vulnerabilities can be addressed at a low cost by\nintroducing PRO to the design. We conclude that PRO can serve as an\napplication-independent, multipurpose countermeasure.",
    "descriptor": "",
    "authors": [
      "Yuan Yao",
      "Pantea Kiaei",
      "Richa Singh",
      "Shahin Tajik",
      "Patrick Schaumont"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.13784"
  },
  {
    "id": "arXiv:2106.13786",
    "title": "Data efficiency in graph networks through equivariance",
    "abstract": "We introduce a novel architecture for graph networks which is equivariant to\nany transformation in the coordinate embeddings that preserves the distance\nbetween neighbouring nodes. In particular, it is equivariant to the Euclidean\nand conformal orthogonal groups in $n$-dimensions. Thanks to its equivariance\nproperties, the proposed model is extremely more data efficient with respect to\nclassical graph architectures and also intrinsically equipped with a better\ninductive bias. We show that, learning on a minimal amount of data, the\narchitecture we propose can perfectly generalise to unseen data in a synthetic\nproblem, while much more training data are required from a standard model to\nreach comparable performance.",
    "descriptor": "\nComments: Accepted at the ICML 2021 Workshop on Subset Selection in Machine Learning: From Theory to Practice. arXiv admin note: text overlap with arXiv:2105.14058\n",
    "authors": [
      "Francesco Farina",
      "Emma Slade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13786"
  },
  {
    "id": "arXiv:2106.13787",
    "title": "Interactive Multi-level Stroke Control for Neural Style Transfer",
    "abstract": "We present StyleTune, a mobile app for interactive multi-level control of\nneural style transfers that facilitates creative adjustments of style elements\nand enables high output fidelity. In contrast to current mobile neural style\ntransfer apps, StyleTune supports users to adjust both the size and orientation\nof style elements, such as brushstrokes and texture patches, on a global as\nwell as local level. To this end, we propose a novel stroke-adaptive\nfeed-forward style transfer network, that enables control over stroke size and\nintensity and allows a larger range of edits than current approaches. For\nadditional level-of-control, we propose a network agnostic method for\nstroke-orientation adjustment by utilizing the rotation-variance of CNNs. To\nachieve high output fidelity, we further add a patch-based style transfer\nmethod that enables users to obtain output resolutions of more than 20\nMegapixel. Our approach empowers users to create many novel results that are\nnot possible with current mobile neural style transfer apps.",
    "descriptor": "\nComments: International Conference on CyberWorlds (CW2021)\n",
    "authors": [
      "Max Reimann",
      "Benito Buchheim",
      "Amir Semmo",
      "J\u00fcrgen D\u00f6llner",
      "Matthias Trapp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13787"
  },
  {
    "id": "arXiv:2106.13792",
    "title": "Proxy Convexity: A Unified Framework for the Analysis of Neural Networks  Trained by Gradient Descent",
    "abstract": "Although the optimization objectives for learning neural networks are highly\nnon-convex, gradient-based methods have been wildly successful at learning\nneural networks in practice. This juxtaposition has led to a number of recent\nstudies on provable guarantees for neural networks trained by gradient descent.\nUnfortunately, the techniques in these works are often highly specific to the\nproblem studied in each setting, relying on different assumptions on the\ndistribution, optimization parameters, and network architectures, making it\ndifficult to generalize across different settings. In this work, we propose a\nunified non-convex optimization framework for the analysis of neural network\ntraining. We introduce the notions of proxy convexity and proxy\nPolyak-Lojasiewicz (PL) inequalities, which are satisfied if the original\nobjective function induces a proxy objective function that is implicitly\nminimized when using gradient methods. We show that stochastic gradient descent\n(SGD) on objectives satisfying proxy convexity or the proxy PL inequality leads\nto efficient guarantees for proxy objective functions. We further show that\nmany existing guarantees for neural networks trained by gradient descent can be\nunified through proxy convexity and proxy PL inequalities.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Spencer Frei",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13792"
  },
  {
    "id": "arXiv:2106.13797",
    "title": "PVTv2: Improved Baselines with Pyramid Vision Transformer",
    "abstract": "Transformer in computer vision has recently shown encouraging progress. In\nthis work, we improve the original Pyramid Vision Transformer (PVTv1) by adding\nthree improvement designs, which include (1) locally continuous features with\nconvolutions, (2) position encodings with zero paddings, and (3) linear\ncomplexity attention layers with average pooling. With these simple\nmodifications, our PVTv2 significantly improves PVTv1 on classification,\ndetection, and segmentation. Moreover, PVTv2 achieves much better performance\nthan recent works, including Swin Transformer, under ImageNet-1K pre-training.\nWe hope this work will make state-of-the-art vision Transformer research more\naccessible. Code is available at https://github.com/whai362/PVT .",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Wenhai Wang",
      "Enze Xie",
      "Xiang Li",
      "Deng-Ping Fan",
      "Kaitao Song",
      "Ding Liang",
      "Tong Lu",
      "Ping Luo",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13797"
  },
  {
    "id": "arXiv:2106.13798",
    "title": "Conjugate Energy-Based Models",
    "abstract": "In this paper, we propose conjugate energy-based models (CEBMs), a new class\nof energy-based models that define a joint density over data and latent\nvariables. The joint density of a CEBM decomposes into an intractable\ndistribution over data and a tractable posterior over latent variables. CEBMs\nhave similar use cases as variational autoencoders, in the sense that they\nlearn an unsupervised mapping from data to latent variables. However, these\nmodels omit a generator network, which allows them to learn more flexible\nnotions of similarity between data points. Our experiments demonstrate that\nconjugate EBMs achieve competitive results in terms of image modelling,\npredictive power of latent space, and out-of-domain detection on a variety of\ndatasets.",
    "descriptor": "",
    "authors": [
      "Hao Wu",
      "Babak Esmaeili",
      "Michael Wick",
      "Jean-Baptiste Tristan",
      "Jan-Willem van de Meent"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13798"
  },
  {
    "id": "arXiv:2106.13799",
    "title": "Assessing Generalization of SGD via Disagreement",
    "abstract": "We empirically show that the test error of deep networks can be estimated by\nsimply training the same architecture on the same training set but with a\ndifferent run of Stochastic Gradient Descent (SGD), and measuring the\ndisagreement rate between the two networks on unlabeled test data. This builds\non -- and is a stronger version of -- the observation in Nakkiran & Bansal '20,\nwhich requires the second run to be on an altogether fresh training set. We\nfurther theoretically show that this peculiar phenomenon arises from the\n\\emph{well-calibrated} nature of \\emph{ensembles} of SGD-trained models. This\nfinding not only provides a simple empirical measure to directly predict the\ntest error using unlabeled test data, but also establishes a new conceptual\nconnection between generalization and calibration.",
    "descriptor": "",
    "authors": [
      "Yiding Jiang",
      "Vaishnavh Nagarajan",
      "Christina Baek",
      "J. Zico Kolter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13799"
  },
  {
    "id": "arXiv:2106.13802",
    "title": "Efficient Document Image Classification Using Region-Based Graph Neural  Network",
    "abstract": "Document image classification remains a popular research area because it can\nbe commercialized in many enterprise applications across different industries.\nRecent advancements in large pre-trained computer vision and language models\nand graph neural networks has lent document image classification many tools.\nHowever using large pre-trained models usually requires substantial computing\nresources which could defeat the cost-saving advantages of automatic document\nimage classification. In the paper we propose an efficient document image\nclassification framework that uses graph convolution neural networks and\nincorporates textual, visual and layout information of the document. We have\nrigorously benchmarked our proposed algorithm against several state-of-art\nvision and language models on both publicly available dataset and a real-life\ninsurance document classification dataset. Empirical results on both publicly\navailable and real-world data show that our methods achieve near SOTA\nperformance yet require much less computing resources and time for model\ntraining and inference. This results in solutions than offer better cost\nadvantages, especially in scalable deployment for enterprise applications. The\nresults showed that our algorithm can achieve classification performance quite\nclose to SOTA. We also provide comprehensive comparisons of computing\nresources, model sizes, train and inference time between our proposed methods\nand baselines. In addition we delineate the cost per image using our method and\nother baselines.",
    "descriptor": "",
    "authors": [
      "Jaya Krishna Mandivarapu",
      "Eric Bunch",
      "Qian You",
      "Glenn Fung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13802"
  },
  {
    "id": "arXiv:2106.13804",
    "title": "Single Image Texture Translation for Data Augmentation",
    "abstract": "Recent advances in image synthesis enables one to translate images by\nlearning the mapping between a source domain and a target domain. Existing\nmethods tend to learn the distributions by training a model on a variety of\ndatasets, with results evaluated largely in a subjective manner. Relatively few\nworks in this area, however, study the potential use of semantic image\ntranslation methods for image recognition tasks. In this paper, we explore the\nuse of Single Image Texture Translation (SITT) for data augmentation. We first\npropose a lightweight model for translating texture to images based on a single\ninput of source texture, allowing for fast training and testing. Based on SITT,\nwe then explore the use of augmented data in long-tailed and few-shot image\nclassification tasks. We find the proposed method is capable of translating\ninput data into a target domain, leading to consistent improved image\nrecognition performance. Finally, we examine how SITT and related image\ntranslation methods can provide a basis for a data-efficient, augmentation\nengineering approach to model training.",
    "descriptor": "",
    "authors": [
      "Boyi Li",
      "Yin Cui",
      "Tsung-Yi Lin",
      "Serge Belongie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13804"
  },
  {
    "id": "arXiv:2106.13805",
    "title": "Self-training Converts Weak Learners to Strong Learners in Mixture  Models",
    "abstract": "We consider a binary classification problem when the data comes from a\nmixture of two isotropic distributions satisfying concentration and\nanti-concentration properties enjoyed by log-concave distributions among\nothers. We show that there exists a universal constant $C_{\\mathrm{err}}>0$\nsuch that if a pseudolabeler $\\boldsymbol{\\beta}_{\\mathrm{pl}}$ can achieve\nclassification error at most $C_{\\mathrm{err}}$, then for any $\\varepsilon>0$,\nan iterative self-training algorithm initialized at $\\boldsymbol{\\beta}_0 :=\n\\boldsymbol{\\beta}_{\\mathrm{pl}}$ using pseudolabels $\\hat y =\n\\mathrm{sgn}(\\langle \\boldsymbol{\\beta}_t, \\mathbf{x}\\rangle)$ and using at\nmost $\\tilde O(d/\\varepsilon^2)$ unlabeled examples suffices to learn the\nBayes-optimal classifier up to $\\varepsilon$ error, where $d$ is the ambient\ndimension. That is, self-training converts weak learners to strong learners\nusing only unlabeled examples. We additionally show that by running gradient\ndescent on the logistic loss one can obtain a pseudolabeler\n$\\boldsymbol{\\beta}_{\\mathrm{pl}}$ with classification error $C_{\\mathrm{err}}$\nusing only $O(d)$ labeled examples (i.e., independent of $\\varepsilon$).\nTogether our results imply that mixture models can be learned to within\n$\\varepsilon$ of the Bayes-optimal accuracy using at most $O(d)$ labeled\nexamples and $\\tilde O(d/\\varepsilon^2)$ unlabeled examples by way of a\nsemi-supervised self-training algorithm.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Spencer Frei",
      "Difan Zou",
      "Zixiang Chen",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13805"
  },
  {
    "id": "arXiv:2102.12525",
    "title": "Prior Image-Constrained Reconstruction using Style-Based Generative  Models",
    "abstract": "Obtaining a useful estimate of an object from highly incomplete imaging\nmeasurements remains a holy grail of imaging science. Deep learning methods\nhave shown promise in learning object priors or constraints to improve the\nconditioning of an ill-posed imaging inverse problem. In this study, a\nframework for estimating an object of interest that is semantically related to\na known prior image, is proposed. An optimization problem is formulated in the\ndisentangled latent space of a style-based generative model, and semantically\nmeaningful constraints are imposed using the disentangled latent representation\nof the prior image. Stable recovery from incomplete measurements with the help\nof a prior image is theoretically analyzed. Numerical experiments demonstrating\nthe superior performance of our approach as compared to related methods are\npresented.",
    "descriptor": "\nComments: Accepted for publication at the International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Varun A. Kelkar",
      "Mark A. Anastasio"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2102.12525"
  },
  {
    "id": "arXiv:2106.13240",
    "title": "Iterative LP-based Methods for the Multiperiod Optimal Electricity and  Gas Flow Problem",
    "abstract": "In light of the increasing coupling between electricity and gas networks,\nthis paper introduces two novel iterative methods for efficiently solving the\nmultiperiod optimal electricity and gas flow (MOEGF) problem. The first is an\niterative MILP-based method and the second is an iterative LP-based method with\nan elaborate procedure for ensuring an integral solution. The convergence of\nthe two approaches is founded on two key features. The first is a penalty term\nwith a single, automatically tuned, parameter for controlling the step size of\nthe gas network iterates. The second is a sequence of supporting hyperplanes\ntogether with an increasing number of carefully constructed halfspaces for\ncontrolling the convergence of the electricity network iterates. Moreover, the\ntwo proposed algorithms use as a warm start the solution from a novel\npolyhedral relaxation of the MOEGF problem, for a noticeable improvement in\ncomputation time as compared to a cold start. Unlike the first method, which\ninvokes a branch-and-bound algorithm to find an integral solution, the second\nmethod implements an elaborate steering procedure that guides the continuous\nvariables to take integral values at the solution. Numerical evaluation\ndemonstrates that the two proposed methods can converge to high-quality\nfeasible solutions in computation times at least two orders of magnitude faster\nthan both a state-of-the-art nonlinear branch-and-bound (NLBB) MINLP solver and\na mixed-integer convex programming (MICP) relaxation of the MOEGF problem. The\nexperimental setup consists of five test cases, three of which involve the real\nelectricity and gas transmission networks of the state of Victoria with actual\nlinepack and demand profiles.",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Power Systems\n",
    "authors": [
      "Sleiman Mhanna",
      "Isam Saedi",
      "Pierluigi Mancarella"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13240"
  },
  {
    "id": "arXiv:2106.13267",
    "title": "Free surface flow through rigid porous media -- An overview and  comparison of formulations",
    "abstract": "In many applications free surface flow through rigid porous media has to be\nmodeled. Examples refer to coastal engineering applications as well as\ngeotechnical or biomedical applications. Albeit the frequent applications,\nslight inconsistencies in the formulation of the governing equations can be\nfound in the literature. The main goal of this paper is to identify these\ndifferences and provide a quantitative assessment of different approaches.\nFollowing a review of the different formulations, simulation results obtained\nfrom three alternative formulations are compared with experimental and\nnumerical data. Results obtained by 2D and 3D test cases indicate that the\npredictive differences returned by the different formulations remain small for\nmost applications, in particular for small porous Reynolds number ReP < 5000.\nThus it seems justified to select a formulation that supports an efficient\nalgorithm and coding structure.",
    "descriptor": "\nComments: 27 pages, 20 figures\n",
    "authors": [
      "Wibke D\u00fcsterh\u00f6ft-Wriggers",
      "Antonia Larese",
      "Thomas Rung",
      "Eugenio O\u00f1ate"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.13267"
  },
  {
    "id": "arXiv:2106.13274",
    "title": "Prediction of geophysical properties of rocks on rare well data and  attributes of seismic waves by machine learning methods on the example of the  Achimov formation",
    "abstract": "Purpose of this research is to forecast the development of sand bodies in\nproductive sediments based on well log data and seismic attributes. The object\nof the study is the productive intervals of Achimov sedimentary complex in the\npart of oil field located in Western Siberia. The research shows a\ntechnological stack of machine learning algorithms, methods for enriching the\nsource data with synthetic ones and algorithms for creating new features. The\nresult was the model of regression relationship between the values of natural\nradioactivity of rocks and seismic wave field attributes with an acceptable\nprediction quality. Acceptable quality of the forecast is confirmed both by\nmodel cross validation, and by the data obtained following the results of new\nwell.",
    "descriptor": "\nComments: 15 pages, 10 figures, 1 table\n",
    "authors": [
      "Dmitry Ivlev"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13274"
  },
  {
    "id": "arXiv:2106.13289",
    "title": "Optimal Control, Numerics, and Applications of Fractional PDEs",
    "abstract": "This article provides a brief review of recent developments on two nonlocal\noperators: fractional Laplacian and fractional time derivative. We start by\naccounting for several applications of these operators in imaging science,\ngeophysics, harmonic maps and deep (machine) learning. Various notions of\nsolutions to linear fractional elliptic equations are provided and numerical\nschemes for fractional Laplacian and fractional time derivative are discussed.\nSpecial emphasis is given to exterior optimal control problems with a linear\nelliptic equation as constraints. In addition, optimal control problems with\ninterior control and state constraints are considered. We also provide a\ndiscussion on fractional deep neural networks, which is shown to be a\nminimization problem with fractional in time ordinary differential equation as\nconstraint. The paper concludes with a discussion on several open problems.",
    "descriptor": "",
    "authors": [
      "Harbir Antil",
      "Thomas S. Brown",
      "Ratna Khatri",
      "Akwum Onwunta",
      "Deepanshu Verma",
      "Mahamadi Warma"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13289"
  },
  {
    "id": "arXiv:2106.13295",
    "title": "Stochastic modeling of scientific impact",
    "abstract": "Recent research has found that select scientists have a disproportional share\nof highly cited papers. Researchers reasoned that this could not have happened\nif success in science was random and introduced a hidden parameter Q, or\ntalent, to explain this finding. So, the talented high-Q scientists have many\nhigh impact papers. Here I show that an upgrade of an old random citation\ncopying model could also explain this finding. In the new model the probability\nof citation copying is not the same for all papers but is proportional to the\nlogarithm of the total number of citations to all papers of its author.\nNumerical simulations of the model give results similar to the empirical\nfindings of the Q-factor article.",
    "descriptor": "\nComments: Accepted for publication by Europhysics Letters\n",
    "authors": [
      "M.V. Simkin"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.13295"
  },
  {
    "id": "arXiv:2106.13315",
    "title": "Generalized Unsupervised Clustering of Hyperspectral Images of  Geological Targets in the Near Infrared",
    "abstract": "The application of infrared hyperspectral imagery to geological problems is\nbecoming more popular as data become more accessible and cost-effective.\nClustering and classifying spectrally similar materials is often a first step\nin applications ranging from economic mineral exploration on Earth to planetary\nexploration on Mars. Semi-manual classification guided by expertly developed\nspectral parameters can be time consuming and biased, while supervised methods\nrequire abundant labeled data and can be difficult to generalize. Here we\ndevelop a fully unsupervised workflow for feature extraction and clustering\ninformed by both expert spectral geologist input and quantitative metrics. Our\npipeline uses a lightweight autoencoder followed by Gaussian mixture modeling\nto map the spectral diversity within any image. We validate the performance of\nour pipeline at submillimeter-scale with expert-labelled data from the Oman\nophiolite drill core and evaluate performance at meters-scale with partially\nclassified orbital data of Jezero Crater on Mars (the landing site for the\nPerseverance rover). We additionally examine the effects of various\npreprocessing techniques used in traditional analysis of hyperspectral imagery.\nThis pipeline provides a fast and accurate clustering map of similar geological\nmaterials and consistently identifies and separates major mineral classes in\nboth laboratory imagery and remote sensing imagery. We refer to our pipeline as\n\"Generalized Pipeline for Spectroscopic Unsupervised clustering of Minerals\n(GyPSUM).\"",
    "descriptor": "\nComments: 10 pages, 4 figures. Accepted, CVPR PBVS Workshop 2021\n",
    "authors": [
      "Angela F. Gao",
      "Brandon Rasmussen",
      "Peter Kulits",
      "Eva L. Scheller",
      "Rebecca Greenberger",
      "Bethany L. Ehlmann"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13315"
  },
  {
    "id": "arXiv:2106.13318",
    "title": "Realistic molecule optimization on a learned graph manifold",
    "abstract": "Deep learning based molecular graph generation and optimization has recently\nbeen attracting attention due to its great potential for de novo drug design.\nOn the one hand, recent models are able to efficiently learn a given graph\ndistribution, and many approaches have proven very effective to produce a\nmolecule that maximizes a given score. On the other hand, it was shown by\nprevious studies that generated optimized molecules are often unrealistic, even\nwith the inclusion of mechanics to enforce similarity to a dataset of real drug\nmolecules. In this work we use a hybrid approach, where the dataset\ndistribution is learned using an autoregressive model while the score\noptimization is done using the Metropolis algorithm, biased toward the learned\ndistribution. We show that the resulting method, that we call learned realism\nsampling (LRS), produces empirically more realistic molecules and outperforms\nall recent baselines in the task of molecule optimization with similarity\nconstraints.",
    "descriptor": "\nComments: 15 pages (9 page main article without refs or appendix) and 2 figures. In review at NEURIPS 2021\n",
    "authors": [
      "R\u00e9my Brossard",
      "Oriel Frigo",
      "David Dehaene"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13318"
  },
  {
    "id": "arXiv:2106.13321",
    "title": "Game theory and scholarly publishing: premises for an agreement around  open access",
    "abstract": "Actors in research and scientific publishing are gradually joining the\nOpen-Access (OA) movement, which is gaining momentum to become nowadays at the\nheart of scientific policies in high-income countries. The rise of OA generates\nprofound changes in the chain of production and dissemination of knowledge.\nFree access to peer-reviewed research methods and results has contributed to\nthe dynamics of science observed in recent years. The modes of publication and\naccess have also evolved; the classic model, based on journal subscriptions is\ngradually giving way to new economic models that have appeared with the arrival\nof OA. The objective of this article is twofold. First, propose a model for the\npublishing market based on the literature as well as on changes in open science\npolicies. Second, analyze publishing strategies of publishers and institutions.\nTo do so, we relied on game theory in economics. Results show that in the short\nterm, the publisher's equilibrium strategy is to adopt a hybridpublishing\nmodel, while the institutions' equilibrium strategy is to publish in OA. This\nequilibrium is not stable and that in the medium/long term, the two players\nwill converge on an OA publishing strategy. The analysis of the equilibrium in\nmixed-strategies confirms this result.",
    "descriptor": "",
    "authors": [
      "Abdelghani Maddi"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.13321"
  },
  {
    "id": "arXiv:2106.13327",
    "title": "Using Machine Learning and Data Mining to Leverage Community Knowledge  for the Engineering of Stable Metal-Organic Frameworks",
    "abstract": "Although the tailored metal active sites and porous architectures of MOFs\nhold great promise for engineering challenges ranging from gas separations to\ncatalysis, a lack of understanding of how to improve their stability limits\ntheir use in practice. To overcome this limitation, we extract thousands of\npublished reports of the key aspects of MOF stability necessary for their\npractical application: the ability to withstand high temperatures without\ndegrading and the capacity to be activated by removal of solvent molecules.\nFrom nearly 4,000 manuscripts, we use natural language processing and automated\nimage analysis to obtain over 2,000 solvent-removal stability measures and\n3,000 thermal degradation temperatures. We analyze the relationships between\nstability properties and the chemical and geometric structures in this set to\nidentify limits of prior heuristics derived from smaller sets of MOFs. By\ntraining predictive machine learning (ML, i.e., Gaussian process and artificial\nneural network) models to encode the structure-property relationships with\ngraph- and pore-structure-based representations, we are able to make\npredictions of stability orders of magnitude faster than conventional\nphysics-based modeling or experiment. Interpretation of important features in\nML models provides insights that we use to identify strategies to engineer\nincreased stability into typically unstable 3d-containing MOFs that are\nfrequently targeted for catalytic applications. We expect our approach to\naccelerate the time to discovery of stable, practical MOF materials for a wide\nrange of applications.",
    "descriptor": "",
    "authors": [
      "Aditya Nandy",
      "Chenru Duan",
      "Heather J. Kulik"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.13327"
  },
  {
    "id": "arXiv:2106.13328",
    "title": "FOVQA: Blind Foveated Video Quality Assessment",
    "abstract": "Previous blind or No Reference (NR) video quality assessment (VQA) models\nlargely rely on features drawn from natural scene statistics (NSS), but under\nthe assumption that the image statistics are stationary in the spatial domain.\nSeveral of these models are quite successful on standard pictures. However, in\nVirtual Reality (VR) applications, foveated video compression is regaining\nattention, and the concept of space-variant quality assessment is of interest,\ngiven the availability of increasingly high spatial and temporal resolution\ncontents and practical ways of measuring gaze direction. Distortions from\nfoveated video compression increase with increased eccentricity, implying that\nthe natural scene statistics are space-variant. Towards advancing the\ndevelopment of foveated compression / streaming algorithms, we have devised a\nno-reference (NR) foveated video quality assessment model, called FOVQA, which\nis based on new models of space-variant natural scene statistics (NSS) and\nnatural video statistics (NVS). Specifically, we deploy a space-variant\ngeneralized Gaussian distribution (SV-GGD) model and a space-variant\nasynchronous generalized Gaussian distribution (SV-AGGD) model of mean\nsubtracted contrast normalized (MSCN) coefficients and products of neighboring\nMSCN coefficients, respectively. We devise a foveated video quality predictor\nthat extracts radial basis features, and other features that capture\nperceptually annoying rapid quality fall-offs. We find that FOVQA achieves\nstate-of-the-art (SOTA) performance on the new 2D LIVE-FBT-FCVR database, as\ncompared with other leading FIQA / VQA models. we have made our implementation\nof FOVQA available at: this http URL",
    "descriptor": "",
    "authors": [
      "Yize Jin",
      "Anjul Patney",
      "Richard Webb",
      "Alan Bovik"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13328"
  },
  {
    "id": "arXiv:2106.13361",
    "title": "Multifidelity Modeling for Physics-Informed Neural Networks (PINNs)",
    "abstract": "Multifidelity simulation methodologies are often used in an attempt to\njudiciously combine low-fidelity and high-fidelity simulation results in an\naccuracy-increasing, cost-saving way. Candidates for this approach are\nsimulation methodologies for which there are fidelity differences connected\nwith significant computational cost differences. Physics-informed Neural\nNetworks (PINNs) are candidates for these types of approaches due to the\nsignificant difference in training times required when different fidelities\n(expressed in terms of architecture width and depth as well as optimization\ncriteria) are employed. In this paper, we propose a particular multifidelity\napproach applied to PINNs that exploits low-rank structure. We demonstrate that\nwidth, depth, and optimization criteria can be used as parameters related to\nmodel fidelity, and show numerical justification of cost differences in\ntraining due to fidelity parameter choices. We test our multifidelity scheme on\nvarious canonical forward PDE models that have been presented in the emerging\nPINNs literature.",
    "descriptor": "",
    "authors": [
      "Michael Penwarden",
      "Shandian Zhe",
      "Akil Narayan",
      "Robert M. Kirby"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13361"
  },
  {
    "id": "arXiv:2106.13398",
    "title": "Code-Verification Techniques for the Method-of-Moments Implementation of  the Electric-Field Integral Equation",
    "abstract": "The method-of-moments implementation of the electric-field integral equation\nyields many code-verification challenges due to the different sources of\nnumerical error and their possible interactions. Matters are further\ncomplicated by singular integrals, which arise from the presence of a Green's\nfunction. In this paper, we provide approaches to separately assess the\nnumerical errors arising from the use of basis functions to approximate the\nsolution and the use of quadrature to approximate the integration. Through\nthese approaches, we are able to verify the code and compare the error from\ndifferent quadrature options.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2012.08681\n",
    "authors": [
      "Brian A. Freno",
      "Neil R. Matula",
      "Justin I. Owen",
      "William A. Johnson"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13398"
  },
  {
    "id": "arXiv:2106.13417",
    "title": "On the continuum limit for the discrete Nonlinear Schr\u00f6dinger equation  on a large finite cubic lattice",
    "abstract": "In this study, we consider the nonlinear Sch\\\"odinger equation (NLS) with the\nzero-boundary condition on a two- or three-dimensional large finite cubic\nlattice. We prove that its solution converges to that of the NLS on the entire\nEuclidean space with simultaneous reduction in the lattice distance and\nexpansion of the domain. Moreover, we obtain a precise global-in-time bound for\nthe rate of convergence. Our proof heavily relies on Strichartz estimates on a\nfinite lattice. A key observation is that, compared to the case of a lattice\nwith a fixed size [Y. Hong, C. Kwak, S. Nakamura, and C. Yang, \\emph{Finite\ndifference scheme for two-dimensional periodic nonlinear {S}chr\\\"{o}dinger\nequations}, Journal of Evolution Equations \\textbf{21} (2021), no.~1,\n391--418.], the loss of regularity in Strichartz estimates can be reduced as\nthe domain expands, depending on the speed of expansion. This allows us to\naddress the physically important three-dimensional case.",
    "descriptor": "\nComments: 30 pages, Any comments are welcome\n",
    "authors": [
      "Younghun Hong",
      "Chulkwang Kwak",
      "Changhun Yang"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13417"
  },
  {
    "id": "arXiv:2106.13434",
    "title": "Binary Matrix Factorisation and Completion via Integer Programming",
    "abstract": "Binary matrix factorisation is an essential tool for identifying discrete\npatterns in binary data. In this paper we consider the rank-k binary matrix\nfactorisation problem (k-BMF) under Boolean arithmetic: we are given an n x m\nbinary matrix X with possibly missing entries and need to find two binary\nmatrices A and B of dimension n x k and k x m respectively, which minimise the\ndistance between X and the Boolean product of A and B in the squared Frobenius\ndistance. We present a compact and two exponential size integer programs (IPs)\nfor k-BMF and show that the compact IP has a weak LP relaxation, while the\nexponential size LPs have a stronger equivalent LP relaxation. We introduce a\nnew objective function, which differs from the traditional squared Frobenius\nobjective in attributing a weight to zero entries of the input matrix that is\nproportional to the number of times the zero is erroneously covered in a rank-k\nfactorisation. For one of the exponential size IPs we describe a computational\napproach based on column generation. Experimental results on synthetic and real\nword datasets suggest that our integer programming approach is competitive\nagainst available methods for k-BMF and provides accurate low-error\nfactorisations.",
    "descriptor": "",
    "authors": [
      "Reka A. Kovacs",
      "Oktay Gunluk",
      "Raphael A. Hauser"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13434"
  },
  {
    "id": "arXiv:2106.13477",
    "title": "Hessian informed mirror descent",
    "abstract": "Inspired by the recent paper (L. Ying, Mirror descent algorithms for\nminimizing interacting free energy, Journal of Scientific Computing, 84 (2020),\npp. 1-14),we explore the relationship between the mirror descent and the\nvariable metric method. When the metric in the mirror decent is induced by a\nconvex function, whose Hessian is close to the Hessian of the objective\nfunction, this method enjoys both robustness from the mirror descent and\nsuperlinear convergence for Newton type methods. When applied to a linearly\nconstrained minimization problem, we prove the global and local convergence,\nboth in the continuous and discrete settings. As applications, we compute the\nWasserstein gradient flows and Cahn-Hillard equation with degenerate mobility.\nWhen formulating these problems using a minimizing movement scheme with respect\nto a variable metric, our mirror descent algorithm offers a fast convergent\nspeed for the underlining optimization problem while maintaining the total mass\nand bounds of the solution.",
    "descriptor": "",
    "authors": [
      "Li Wang",
      "Ming Yan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13477"
  },
  {
    "id": "arXiv:2106.13493",
    "title": "Online Self-Attentive Gated RNNs for Real-Time Speaker Separation",
    "abstract": "Deep neural networks have recently shown great success in the task of blind\nsource separation, both under monaural and binaural settings. Although these\nmethods were shown to produce high-quality separations, they were mainly\napplied under offline settings, in which the model has access to the full input\nsignal while separating the signal. In this study, we convert a non-causal\nstate-of-the-art separation model into a causal and real-time model and\nevaluate its performance under both online and offline settings. We compare the\nperformance of the proposed model to several baseline methods under anechoic,\nnoisy, and noisy-reverberant recording conditions while exploring both monaural\nand binaural inputs and outputs. Our findings shed light on the relative\ndifference between causal and non-causal models when performing separation. Our\nstateful implementation for online separation leads to a minor drop in\nperformance compared to the offline model; 0.8dB for monaural inputs and 0.3dB\nfor binaural inputs while reaching a real-time factor of 0.65. Samples can be\nfound under the following link:\nhttps://kwanum.github.io/sagrnnc-stream-results/.",
    "descriptor": "",
    "authors": [
      "Ori Kabeli",
      "Yossi Adi",
      "Zhenyu Tang",
      "Buye Xu",
      "Anurag Kumar"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.13493"
  },
  {
    "id": "arXiv:2106.13550",
    "title": "Asymptotic bit frequency in Fibonacci words",
    "abstract": "It is known that binary words containing no $k$ consecutive 1s are enumerated\nby $k$-step Fibonacci numbers. In this note we discuss the expected value of a\nrandom bit in a random word of length $n$ having this property. This\nexpectation can reveal new properties of some telecommunication protocols or\ninterconnection networks.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Jean-Luc Baril",
      "Sergey Kirgizov",
      "Vincent Vajnovszki"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.13550"
  },
  {
    "id": "arXiv:2106.13551",
    "title": "Circumpapillary OCT-Focused Hybrid Learning for Glaucoma Grading Using  Tailored Prototypical Neural Networks",
    "abstract": "Glaucoma is one of the leading causes of blindness worldwide and Optical\nCoherence Tomography (OCT) is the quintessential imaging technique for its\ndetection. Unlike most of the state-of-the-art studies focused on glaucoma\ndetection, in this paper, we propose, for the first time, a novel framework for\nglaucoma grading using raw circumpapillary B-scans. In particular, we set out a\nnew OCT-based hybrid network which combines hand-driven and deep learning\nalgorithms. An OCT-specific descriptor is proposed to extract hand-crafted\nfeatures related to the retinal nerve fibre layer (RNFL). In parallel, an\ninnovative CNN is developed using skip-connections to include tailored residual\nand attention modules to refine the automatic features of the latent space. The\nproposed architecture is used as a backbone to conduct a novel few-shot\nlearning based on static and dynamic prototypical networks. The k-shot paradigm\nis redefined giving rise to a supervised end-to-end system which provides\nsubstantial improvements discriminating between healthy, early and advanced\nglaucoma samples. The training and evaluation processes of the dynamic\nprototypical network are addressed from two fused databases acquired via\nHeidelberg Spectralis system. Validation and testing results reach a\ncategorical accuracy of 0.9459 and 0.8788 for glaucoma grading, respectively.\nBesides, the high performance reported by the proposed model for glaucoma\ndetection deserves a special mention. The findings from the class activation\nmaps are directly in line with the clinicians' opinion since the heatmaps\npointed out the RNFL as the most relevant structure for glaucoma diagnosis.",
    "descriptor": "",
    "authors": [
      "Gabriel Garc\u00eda",
      "Roc\u00edo del Amor",
      "Adri\u00e1n Colomer",
      "Rafael Verd\u00fa-Monedero",
      "Juan Morales-S\u00e1nchez",
      "Valery Naranjo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13551"
  },
  {
    "id": "arXiv:2106.13559",
    "title": "A Novel Self-Learning Framework for Bladder Cancer Grading Using  Histopathological Images",
    "abstract": "Recently, bladder cancer has been significantly increased in terms of\nincidence and mortality. Currently, two subtypes are known based on tumour\ngrowth: non-muscle invasive (NMIBC) and muscle-invasive bladder cancer (MIBC).\nIn this work, we focus on the MIBC subtype because it is of the worst prognosis\nand can spread to adjacent organs. We present a self-learning framework to\ngrade bladder cancer from histological images stained via immunohistochemical\ntechniques. Specifically, we propose a novel Deep Convolutional Embedded\nAttention Clustering (DCEAC) which allows classifying histological patches into\ndifferent severity levels of the disease, according to the patterns established\nin the literature. The proposed DCEAC model follows a two-step fully\nunsupervised learning methodology to discern between non-tumour, mild and\ninfiltrative patterns from high-resolution samples of 512x512 pixels. Our\nsystem outperforms previous clustering-based methods by including a\nconvolutional attention module, which allows refining the features of the\nlatent space before the classification stage. The proposed network exceeds\nstate-of-the-art approaches by 2-3% across different metrics, achieving a final\naverage accuracy of 0.9034 in a multi-class scenario. Furthermore, the reported\nclass activation maps evidence that our model is able to learn by itself the\nsame patterns that clinicians consider relevant, without incurring prior\nannotation steps. This fact supposes a breakthrough in muscle-invasive bladder\ncancer grading which bridges the gap with respect to train the model on\nlabelled data.",
    "descriptor": "",
    "authors": [
      "Gabriel Garc\u00eda",
      "Anna Esteve",
      "Adri\u00e1n Colomer",
      "David Ramos",
      "Valery Naranjo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13559"
  },
  {
    "id": "arXiv:2106.13579",
    "title": "Graph model selection by edge probability sequential inference",
    "abstract": "Graphs are widely used for describing systems made up of many interacting\ncomponents and for understanding the structure of their interactions. Various\nstatistical models exist, which describe this structure as the result of a\ncombination of constraints and randomness. %Model selection techniques need to\nautomatically identify the best model, and the best set of parameters for a\ngiven graph. To do so, most authors rely on the minimum description length\nparadigm, and apply it to graphs by considering the entropy of probability\ndistributions defined on graph ensembles. In this paper, we introduce edge\nprobability sequential inference, a new approach to perform model selection,\nwhich relies on probability distributions on edge ensembles. From a theoretical\npoint of view, we show that this methodology provides a more consistent ground\nfor statistical inference with respect to existing techniques, due to the fact\nthat it relies on multiple realizations of the random variable. It also\nprovides better guarantees against overfitting, by making it possible to lower\nthe number of parameters of the model below the number of observations.\nExperimentally, we illustrate the benefits of this methodology in two\nsituations: to infer the partition of a stochastic blockmodel, and to identify\nthe most relevant model for a given graph between the stochastic blockmodel and\nthe configuration model.",
    "descriptor": "",
    "authors": [
      "Louis Duvivier",
      "R\u00e9my Cazabet",
      "C\u00e9line Robardet"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13579"
  },
  {
    "id": "arXiv:2106.13589",
    "title": "$\\ell^p$-Distances on Multiparameter Persistence Modules",
    "abstract": "Motivated both by theoretical and practical considerations in topological\ndata analysis, we generalize the $p$-Wasserstein distance on barcodes to\nmultiparameter persistence modules. For each $p\\in [1,\\infty]$, we in fact\nintroduce two such generalizations $d_{\\mathcal I}^p$ and $d_{\\mathcal M}^p$,\nsuch that $d_{\\mathcal I}^\\infty$ equals the interleaving distance and\n$d_{\\mathcal M}^\\infty$ equals the matching distance. We show that $d_{\\mathcal\nM}^p\\leq d_{\\mathcal I}^p$ for all $p\\in [1,\\infty]$, extending an observation\nof Landi in the $p=\\infty$ case. We observe that the distances $d_{\\mathcal\nM}^p$ can be efficiently approximated. Finally, we show that on 1- or\n2-parameter persistence modules over prime fields, $d_{\\mathcal I}^p$ is the\nuniversal (i.e., largest) metric satisfying a natural stability property; our\nresult extends a stability result of Skraba and Turner for the $p$-Wasserstein\ndistance on barcodes in the 1-parameter case, and is also a close analogue of a\nuniversality property for the interleaving distance given by the second author.\nIn a companion paper, we apply some of these results to study the stability of\n($2$-parameter) multicover persistent homology.",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "H\u00e5vard Bakke Bjerkevik",
      "Michael Lesnick"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.13589"
  },
  {
    "id": "arXiv:2106.13602",
    "title": "$\\mathcal{N}$IPM-HLSP: An Efficient Interior-Point Method for  Hierarchical Least-Squares Programs",
    "abstract": "Hierarchical least-squares programs with linear constraints (HLSP) are a type\nof optimization problem very common in robotics. Each priority level contains\nan objective in least-squares form which is subject to the linear constraints\nof the higher priority hierarchy levels. Active-set methods (ASM) are a popular\nchoice for solving them. However, they can perform poorly in terms of\ncomputational time if there are large changes of the active set. We therefore\npropose a computationally efficient primal-dual interior-point method (IPM) for\nHLSP's which is able to maintain constant numbers of solver iterations in these\nsituations. We base our IPM on the null-space method which requires only a\nsingle decomposition per Newton iteration instead of two as it is the case for\nother IPM solvers. After a priority level has converged we compose a set of\nactive constraints judging upon the dual and project lower priority levels into\ntheir null-space. We show that the IPM-HLSP can be expressed in least-squares\nform which avoids the formation of the quadratic Karush-Kuhn-Tucker (KKT)\nHessian. Due to our choice of the null-space basis the IPM-HLSP is as fast as\nthe state-of-the-art ASM-HLSP solver for equality only problems.",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Kai Pfeiffer",
      "Adrien Escande",
      "Ludovic Righetti"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Performance (cs.PF)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13602"
  },
  {
    "id": "arXiv:2106.13614",
    "title": "The Effect of Ground Truth Accuracy on the Evaluation of Localization  Systems",
    "abstract": "The ability to accurately evaluate the performance of location determination\nsystems is crucial for many applications. Typically, the performance of such\nsystems is obtained by comparing ground truth locations with estimated\nlocations. However, these ground truth locations are usually obtained by\nclicking on a map or using other worldwide available technologies like GPS.\nThis introduces ground truth errors that are due to the marking process, map\ndistortions, or inherent GPS inaccuracy.\nIn this paper, we present a theoretical framework for analyzing the effect of\nground truth errors on the evaluation of localization systems. Based on that,\nwe design two algorithms for computing the real algorithmic error from the\nvalidation error and marking/map ground truth errors, respectively. We further\nestablish bounds on different performance metrics.\nValidation of our theoretical assumptions and analysis using real data\ncollected in a typical environment shows the ability of our theoretical\nframework to correct the estimated error of a localization algorithm in the\npresence of ground truth errors. Specifically, our marking error algorithm\nmatches the real error CDF within 4%, and our map error algorithm provides a\nmore accurate estimate of the median/tail error by 150%/72% when the map is\nshifted by 6m.",
    "descriptor": "",
    "authors": [
      "Chen Gu",
      "Ahmed Shokry",
      "Moustafa Youssef"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.13614"
  },
  {
    "id": "arXiv:2106.13637",
    "title": "Boundary Output Feedback Stabilization of Reaction-Diffusion PDEs with  Delayed Boundary Measurement",
    "abstract": "This paper addresses the boundary output feedback stabilization of general\n1-D reaction-diffusion PDEs with delayed boundary measurement. The output takes\nthe form of a either Dirichlet or Neumann trace. The output delay can be\narbitrarily large. The control strategy is composed of a finite-dimensional\nobserver that is used to observe a delayed version of the first modes of the\nPDE and a predictor component which is employed to obtain the control input to\nbe applied at current time. For any given value of the output delay, we assess\nthe stability of the resulting closed-loop system provided the order of the\nobserver is selected large enough. Taking advantage of this result, we discuss\nthe extension of the control strategy to the case of simultaneous input and\noutput delays.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.08431\n",
    "authors": [
      "Hugo Lhachemi",
      "Christophe Prieur"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13637"
  },
  {
    "id": "arXiv:2106.13649",
    "title": "SnakeLines: integrated set of computational pipelines for sequencing  reads",
    "abstract": "Background: With the rapid growth of massively parallel sequencing\ntechnologies, still more laboratories are utilizing sequenced DNA fragments for\ngenomic analyses. Interpretation of sequencing data is, however, strongly\ndependent on bioinformatics processing, which is often too demanding for\nclinicians and researchers without a computational background. Another problem\nrepresents the reproducibility of computational analyses across separated\ncomputational centers with inconsistent versions of installed libraries and\nbioinformatics tools.\nResults: We propose an easily extensible set of computational pipelines,\ncalled SnakeLines, for processing sequencing reads; including mapping,\nassembly, variant calling, viral identification, transcriptomics, metagenomics,\nand methylation analysis. Individual steps of an analysis, along with methods\nand their parameters can be readily modified in a single configuration file.\nProvided pipelines are embedded in virtual environments that ensure isolation\nof required resources from the host operating system, rapid deployment, and\nreproducibility of analysis across different Unix-based platforms.\nConclusion: SnakeLines is a powerful framework for the automation of\nbioinformatics analyses, with emphasis on a simple set-up, modifications,\nextensibility, and reproducibility.\nKeywords: Computational pipeline, framework, massively parallel sequencing,\nreproducibility, virtual environment",
    "descriptor": "\nComments: 22 pages, 3 figures, 1 table\n",
    "authors": [
      "Jaroslav Budis",
      "Werner Krampl",
      "Marcel Kucharik",
      "Rastislav Hekel",
      "Adrian Goga",
      "Michal Lichvar",
      "David Smolak",
      "Miroslav Bohmer",
      "Andrej Balaz",
      "Frantisek Duris",
      "Juraj Gazdarica",
      "Katarina Soltys",
      "Jan Turna",
      "Jan Radvanszky",
      "Tomas Szemes"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.13649"
  },
  {
    "id": "arXiv:2106.13665",
    "title": "On Some Quasi-Variational Inequalities and Other Problems with Moving  Sets",
    "abstract": "Since its introduction over 50 years ago, the concept of Mosco convergence\nhas permeated through diverse areas of mathematics and applied sciences. These\ninclude applied analysis, the theory of partial differential equations,\nnumerical analysis, and infinite dimensional constrained optimization, among\nothers. In this paper we explore some of the consequences of Mosco convergence\non applied problems that involve moving sets, with some historical accounts,\nand modern trends and features. In particular, we focus on connections with\ndensity of convex intersections, finite element approximations,\nquasi-variational inequalities, and impulse problems.",
    "descriptor": "",
    "authors": [
      "Jos\u00e9-Luis Menaldi",
      "Carlos N. Rautenberg"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13665"
  },
  {
    "id": "arXiv:2106.13682",
    "title": "Prediction of Hereditary Cancers Using Neural Networks",
    "abstract": "Family history is a major risk factor for many types of cancer. Mendelian\nrisk prediction models translate family histories into cancer risk predictions\nbased on knowledge of cancer susceptibility genes. These models are widely used\nin clinical practice to help identify high-risk individuals. Mendelian models\nleverage the entire family history, but they rely on many assumptions about\ncancer susceptibility genes that are either unrealistic or challenging to\nvalidate due to low mutation prevalence. Training more flexible models, such as\nneural networks, on large databases of pedigrees can potentially lead to\naccuracy gains. In this paper, we develop a framework to apply neural networks\nto family history data and investigate their ability to learn inherited\nsusceptibility to cancer. While there is an extensive literature on neural\nnetworks and their state-of-the-art performance in many tasks, there is little\nwork applying them to family history data. We propose adaptations of\nfully-connected neural networks and convolutional neural networks to pedigrees.\nIn data simulated under Mendelian inheritance, we demonstrate that our proposed\nneural network models are able to achieve nearly optimal prediction\nperformance. Moreover, when the observed family history includes misreported\ncancer diagnoses, neural networks are able to outperform the Mendelian BRCAPRO\nmodel embedding the correct inheritance laws. Using a large dataset of over\n200,000 family histories, the Risk Service cohort, we train prediction models\nfor future risk of breast cancer. We validate the models using data from the\nCancer Genetics Network.",
    "descriptor": "",
    "authors": [
      "Zoe Guan",
      "Giovanni Parmigiani",
      "Danielle Braun",
      "Lorenzo Trippa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13682"
  },
  {
    "id": "arXiv:2106.13683",
    "title": "A proximal-proximal majorization-minimization algorithm for nonconvex  tuning-free robust regression problems",
    "abstract": "In this paper, we introduce a proximal-proximal majorization-minimization\n(PPMM) algorithm for nonconvex tuning-free robust regression problems. The\nbasic idea is to apply the proximal majorization-minimization algorithm to\nsolve the nonconvex problem with the inner subproblems solved by a sparse\nsemismooth Newton (SSN) method based proximal point algorithm (PPA). We must\nemphasize that the main difficulty in the design of the algorithm lies in how\nto overcome the singular difficulty of the inner subproblem. Furthermore, we\nalso prove that the PPMM algorithm converges to a d-stationary point. Due to\nthe Kurdyka-Lojasiewicz (KL) property of the problem, we present the\nconvergence rate of the PPMM algorithm. Numerical experiments demonstrate that\nour proposed algorithm outperforms the existing state-of-the-art algorithms.",
    "descriptor": "\nComments: 31 pages, 7 tables\n",
    "authors": [
      "Peipei Tang",
      "Chengjing Wang",
      "Bo Jiang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13683"
  },
  {
    "id": "arXiv:2106.13689",
    "title": "Semantic annotation for computational pathology: Multidisciplinary  experience and best practice recommendations",
    "abstract": "Recent advances in whole slide imaging (WSI) technology have led to the\ndevelopment of a myriad of computer vision and artificial intelligence (AI)\nbased diagnostic, prognostic, and predictive algorithms. Computational\nPathology (CPath) offers an integrated solution to utilize information embedded\nin pathology WSIs beyond what we obtain through visual assessment. For\nautomated analysis of WSIs and validation of machine learning (ML) models,\nannotations at the slide, tissue and cellular levels are required. The\nannotation of important visual constructs in pathology images is an important\ncomponent of CPath projects. Improper annotations can result in algorithms\nwhich are hard to interpret and can potentially produce inaccurate and\ninconsistent results. Despite the crucial role of annotations in CPath\nprojects, there are no well-defined guidelines or best practices on how\nannotations should be carried out. In this paper, we address this shortcoming\nby presenting the experience and best practices acquired during the execution\nof a large-scale annotation exercise involving a multidisciplinary team of\npathologists, ML experts and researchers as part of the Pathology image data\nLake for Analytics, Knowledge and Education (PathLAKE) consortium. We present a\nreal-world case study along with examples of different types of annotations,\ndiagnostic algorithm, annotation data dictionary and annotation constructs. The\nanalyses reported in this work highlight best practice recommendations that can\nbe used as annotation guidelines over the lifecycle of a CPath project.",
    "descriptor": "",
    "authors": [
      "Noorul Wahab",
      "Islam M Miligy",
      "Katherine Dodd",
      "Harvir Sahota",
      "Michael Toss",
      "Wenqi Lu",
      "Mostafa Jahanifar",
      "Mohsin Bilal",
      "Simon Graham",
      "Young Park",
      "Giorgos Hadjigeorghiou",
      "Abhir Bhalerao",
      "Ayat Lashen",
      "Asmaa Ibrahim",
      "Ayaka Katayama",
      "Henry O Ebili",
      "Matthew Parkin",
      "Tom Sorell",
      "Shan E Ahmed Raza",
      "Emily Hero",
      "Hesham Eldaly",
      "Yee Wah Tsang",
      "Kishore Gopalakrishnan",
      "David Snead",
      "Emad Rakha",
      "Nasir Rajpoot",
      "Fayyaz Minhas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13689"
  },
  {
    "id": "arXiv:2106.13693",
    "title": "Temporal Modes of Light in Satellite-to-Earth Quantum Communications",
    "abstract": "The photonic Temporal Mode (TM) represents a possible candidate for the\ndelivery of viable multidimensional quantum communications. However, relative\nto other multidimensional quantum information carriers such as the Orbital\nAngular Momentum (OAM), the TM has received less attention. Moreover, in the\ncontext of the emerging quantum internet and satellite-based quantum\ncommunications, the TM has received no attention. In this work, we remedy this\nsituation by considering the traversal through the satellite-to-Earth channel\nof single photons encoded in TM space. Our results indicate that for\nanticipated atmospheric conditions the photonic TM offers a promising avenue\nfor the delivery of high-throughput quantum communications from a satellite to\na terrestrial receiver. In particular, we show how these modes can provide for\nimproved multiplexing performance and superior quantum key distribution in the\nsatellite-to-Earth channel, relative to OAM single-photon states. The levels of\nTM discrimination that guarantee this outcome are outlined and implications of\nour results for the emerging satellite-based quantum internet are discussed.",
    "descriptor": "\nComments: 7 pages, 3 figures. Comments are welcome\n",
    "authors": [
      "Ziqing Wang",
      "Robert Malaney",
      "Ryan Aguinaldo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2106.13693"
  },
  {
    "id": "arXiv:2106.13706",
    "title": "Accelerated Computation of a High Dimensional Kolmogorov-Smirnov  Distance",
    "abstract": "Statistical testing is widespread and critical for a variety of scientific\ndisciplines. The advent of machine learning and the increase of computing power\nhas increased the interest in the analysis and statistical testing of\nmultidimensional data. We extend the powerful Kolmogorov-Smirnov two sample\ntest to a high dimensional form in a similar manner to Fasano (Fasano, 1987).\nWe call our result the d-dimensional Kolmogorov-Smirnov test (ddKS) and provide\nthree novel contributions therewith: we develop an analytical equation for the\nsignificance of a given ddKS score, we provide an algorithm for computation of\nddKS on modern computing hardware that is of constant time complexity for small\nsample sizes and dimensions, and we provide two approximate calculations of\nddKS: one that reduces the time complexity to linear at larger sample sizes,\nand another that reduces the time complexity to linear with increasing\ndimension. We perform power analysis of ddKS and its approximations on a corpus\nof datasets and compare to other common high dimensional two sample tests and\ndistances: Hotelling's T^2 test and Kullback-Leibler divergence. Our ddKS test\nperforms well for all datasets, dimensions, and sizes tested, whereas the other\ntests and distances fail to reject the null hypothesis on at least one dataset.\nWe therefore conclude that ddKS is a powerful multidimensional two sample test\nfor general use, and can be calculated in a fast and efficient manner using our\nparallel or approximate methods. Open source implementations of all methods\ndescribed in this work are located at https://github.com/pnnl/ddks.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Alex Hagen",
      "Shane Jackson",
      "James Kahn",
      "Jan Strube",
      "Isabel Haide",
      "Karl Pazdernik",
      "Connor Hainje"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13706"
  },
  {
    "id": "arXiv:2106.13724",
    "title": "Primordial non-Gaussianity from the Completed SDSS-IV extended Baryon  Oscillation Spectroscopic Survey I: Catalogue Preparation and Systematic  Mitigation",
    "abstract": "We investigate the large-scale clustering of the final spectroscopic sample\nof quasars from the recently completed extended Baryon Oscillation\nSpectroscopic Survey (eBOSS). The sample contains $343708$ objects in the\nredshift range $0.8<z<2.2$ and $72667$ objects with redshifts $2.2<z<3.5$,\ncovering an effective area of $4699~{\\rm deg}^{2}$. We develop a neural\nnetwork-based approach to mitigate spurious fluctuations in the density field\ncaused by spatial variations in the quality of the imaging data used to select\ntargets for follow-up spectroscopy. Simulations are used with the same angular\nand radial distributions as the real data to estimate covariance matrices,\nperform error analyses, and assess residual systematic uncertainties. We\nmeasure the mean density contrast and cross-correlations of the eBOSS quasars\nagainst maps of potential sources of imaging systematics to address algorithm\neffectiveness, finding that the neural network-based approach outperforms\nstandard linear regression. Stellar density is one of the most important\nsources of spurious fluctuations, and a new template constructed using data\nfrom the Gaia spacecraft provides the best match to the observed quasar\nclustering. The end-product from this work is a new value-added quasar\ncatalogue with the improved weights to correct for nonlinear imaging systematic\neffects, which will be made public. Our quasar catalogue is used to measure the\nlocal-type primordial non-Gaussianity in our companion paper, Mueller et al. in\npreparation.",
    "descriptor": "\nComments: 17 pages, 13 figures, 2 tables. Accepted for publication in MNRAS. For the associated code and value-added catalogs see this https URL and this https URL\n",
    "authors": [
      "Mehdi Rezaie",
      "Ashley J. Ross",
      "Hee-Jong Seo",
      "Eva-Maria Mueller",
      "Will J. Percival",
      "Grant Merz",
      "Reza Katebi",
      "Razvan C. Bunescu",
      "Julian Bautista",
      "Joel R. Brownstein",
      "Etienne Burtin",
      "Kyle Dawson",
      "H\u00e9ctor Gil-Mar\u00edn",
      "Jiamin Hou",
      "Eleanor B. Lyke",
      "Axel de la Macorra",
      "Graziano Rossi",
      "Donald P. Schneider",
      "Pauline Zarrouk",
      "Gong-Bo Zhao"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.13724"
  },
  {
    "id": "arXiv:2106.13733",
    "title": "Graph and hypergraph colouring via nibble methods: A survey",
    "abstract": "This paper provides a survey of methods, results, and open problems on graph\nand hypergraph colourings, with a particular emphasis on semi-random `nibble'\nmethods. We also give a detailed sketch of some aspects of the recent proof of\nthe Erd\\H{o}s-Faber-Lov\\'{a}sz conjecture.",
    "descriptor": "\nComments: to appear in the proceedings of the 8th European Congress of Mathematics; 31 pages, 2 figures\n",
    "authors": [
      "Dong Yeap Kang",
      "Tom Kelly",
      "Daniela K\u00fchn",
      "Abhishek Methuku",
      "Deryk Osthus"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.13733"
  },
  {
    "id": "arXiv:2106.13746",
    "title": "InteL-VAEs: Adding Inductive Biases to Variational Auto-Encoders via  Intermediary Latents",
    "abstract": "We introduce a simple and effective method for learning VAEs with\ncontrollable inductive biases by using an intermediary set of latent variables.\nThis allows us to overcome the limitations of the standard Gaussian prior\nassumption. In particular, it allows us to impose desired properties like\nsparsity or clustering on learned representations, and incorporate prior\ninformation into the learned model. Our approach, which we refer to as the\nIntermediary Latent Space VAE (InteL-VAE), is based around controlling the\nstochasticity of the encoding process with the intermediary latent variables,\nbefore deterministically mapping them forward to our target latent\nrepresentation, from which reconstruction is performed. This allows us to\nmaintain all the advantages of the traditional VAE framework, while\nincorporating desired prior information, inductive biases, and even topological\ninformation through the latent mapping. We show that this, in turn, allows\nInteL-VAEs to learn both better generative models and representations.",
    "descriptor": "",
    "authors": [
      "Ning Miao",
      "Emile Mathieu",
      "N. Siddharth",
      "Yee Whye Teh",
      "Tom Rainforth"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13746"
  },
  {
    "id": "arXiv:2106.13755",
    "title": "Reinforcement Learning for Mean Field Games, with Applications to  Economics",
    "abstract": "Mean field games (MFG) and mean field control problems (MFC) are frameworks\nto study Nash equilibria or social optima in games with a continuum of agents.\nThese problems can be used to approximate competitive or cooperative games with\na large finite number of agents and have found a broad range of applications,\nin particular in economics. In recent years, the question of learning in MFG\nand MFC has garnered interest, both as a way to compute solutions and as a way\nto model how large populations of learners converge to an equilibrium. Of\nparticular interest is the setting where the agents do not know the model,\nwhich leads to the development of reinforcement learning (RL) methods. After\nreviewing the literature on this topic, we present a two timescale approach\nwith RL for MFG and MFC, which relies on a unified Q-learning algorithm. The\nmain novelty of this method is to simultaneously update an action-value\nfunction and a distribution but with different rates, in a model-free fashion.\nDepending on the ratio of the two learning rates, the algorithm learns either\nthe MFG or the MFC solution. To illustrate this method, we apply it to a mean\nfield problem of accumulated consumption in finite horizon with HARA utility\nfunction, and to a trader's optimal liquidation problem.",
    "descriptor": "",
    "authors": [
      "Andrea Angiuli",
      "Jean-Pierre Fouque",
      "Mathieu Lauriere"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13755"
  },
  {
    "id": "arXiv:2106.13781",
    "title": "Tighter Analysis of Alternating Stochastic Gradient Method for  Stochastic Nested Problems",
    "abstract": "Stochastic nested optimization, including stochastic compositional, min-max\nand bilevel optimization, is gaining popularity in many machine learning\napplications. While the three problems share the nested structure, existing\nworks often treat them separately, and thus develop problem-specific algorithms\nand their analyses. Among various exciting developments, simple SGD-type\nupdates (potentially on multiple variables) are still prevalent in solving this\nclass of nested problems, but they are believed to have slower convergence rate\ncompared to that of the non-nested problems. This paper unifies several\nSGD-type updates for stochastic nested problems into a single SGD approach that\nwe term ALternating Stochastic gradient dEscenT (ALSET) method. By leveraging\nthe hidden smoothness of the problem, this paper presents a tighter analysis of\nALSET for stochastic nested problems. Under the new analysis, to achieve an\n$\\epsilon$-stationary point of the nested problem, it requires ${\\cal\nO}(\\epsilon^{-2})$ samples. Under certain regularity conditions, applying our\nresults to stochastic compositional, min-max and reinforcement learning\nproblems either improves or matches the best-known sample complexity in the\nrespective cases. Our results explain why simple SGD-type algorithms in\nstochastic nested problems all work very well in practice without the need for\nfurther modifications.",
    "descriptor": "\nComments: Submitted for publication\n",
    "authors": [
      "Tianyi Chen",
      "Yuejiao Sun",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.13781"
  },
  {
    "id": "arXiv:2106.13790",
    "title": "Active Learning with Multifidelity Modeling for Efficient Rare Event  Simulation",
    "abstract": "While multifidelity modeling provides a cost-effective way to conduct\nuncertainty quantification with computationally expensive models, much greater\nefficiency can be achieved by adaptively deciding the number of required\nhigh-fidelity (HF) simulations, depending on the type and complexity of the\nproblem and the desired accuracy in the results. We propose a framework for\nactive learning with multifidelity modeling emphasizing the efficient\nestimation of rare events. Our framework works by fusing a low-fidelity (LF)\nprediction with an HF-inferred correction, filtering the corrected LF\nprediction to decide whether to call the high-fidelity model, and for enhanced\nsubsequent accuracy, adapting the correction for the LF prediction after every\nHF model call. The framework does not make any assumptions as to the LF model\ntype or its correlations with the HF model. In addition, for improved\nrobustness when estimating smaller failure probabilities, we propose using\ndynamic active learning functions that decide when to call the HF model. We\ndemonstrate our framework using several academic case studies and two finite\nelement (FE) model case studies: estimating Navier-Stokes velocities using the\nStokes approximation and estimating stresses in a transversely isotropic model\nsubjected to displacements via a coarsely meshed isotropic model. Across these\ncase studies, not only did the proposed framework estimate the failure\nprobabilities accurately, but compared with either Monte Carlo or a standard\nvariance reduction method, it also required only a small fraction of the calls\nto the HF model.",
    "descriptor": "",
    "authors": [
      "S. L. N. Dhulipala",
      "M. D. Shields",
      "B. W. Spencer",
      "C. Bolisetti",
      "A. E. Slaughter",
      "V. M. Laboure",
      "P. Chakroborty"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.13790"
  },
  {
    "id": "arXiv:2106.13801",
    "title": "The H2-optimal Control Problem of CSVIU Systems: Discounted,  Counter-discounted and Long-Run Solutions -- Part I: The Norm",
    "abstract": "The paper deals with the H2-norm and associated energy or power measurements\nfor a class of processes known as CSVIU (Control and State Variation Increase\nUncertainty). These are system models for which a stochastic process conveys\nthe underlying uncertainties, and are able to give rise to cautious controls.\nThe paper delves into the non-controlled version and fundamental system and\nnorms notions associated with stochastic stability and mean-square convergence.\nOne pillar of the study is the connection between the finiteness of one of\nthese norms or a limited energy measurement growth with the corresponding\nstochastic stability notions. A detectability concept ties these notions, and\nthe analysis of linear-positive operators plays a fundamental role. The\nintroduction of various H2-norms and energy measurement performance criteria\nallows one to span the focus from transient to long-run behavior. As the\ndiscount parameter turns into a counter-discount, the criteria enforce stricter\nrequirements on the second-moment steady state errors and on the exponential\nconvergence rate. A tidy connection among this H2-performance measures cast\nemploys a unifying vanishing discount reasoning.",
    "descriptor": "",
    "authors": [
      "Jo\u00e3o B. R. do Val",
      "Daniel S. Campos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13801"
  },
  {
    "id": "arXiv:2106.13806",
    "title": "The H2-optimal Control Problem of CSVIU Systems: Discounted,  Counter-discounted and Long-run Solutions -- Part II: Optimal Control",
    "abstract": "The paper deals with stochastic control problems associated with $H_2$\nperformance indices such as energy or power norms or energy measurements when\nnorms are not defined. They apply to a class of systems for which a stochastic\nprocess conveys the underlying uncertainties, known as CSVIU (Control and State\nVariation Increase Uncertainty). These indices allow various emphases from\nfocusing on the transient behavior with the discounted norm to stricter\nconditions on stability, steady-state mean-square error and convergence rate,\nusing the optimal overtaking criterion -- the long-run average power control\nstands as a midpoint in this respect. A critical advance regards the explicit\nform of the optimal control law, expressed in two equivalent forms. One takes a\nperturbed affine Riccati-like form of feedback solution; the other comes from a\ngeneralized normal equation that arises from the nondifferentiable local\noptimal problem. They are equivalent, but the latter allows for a search method\nto attain the optimal law. A detectability notion and a Riccati solution grant\nstochastic stability from the behavior of the norms. The energy overtaking\ncriterion requires a further constraint on a matrix spectral radius. With these\nfindings, the paper revisits the emerging of the inaction solution, a prominent\nfeature of CSVIU models to deal with the uncertainty inherent to poorly known\nmodels. Besides, it provides the optimal solution and the tools to pursue it.",
    "descriptor": "",
    "authors": [
      "Jo\u00e3o B. R. do Val",
      "Daniel S. Campos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13806"
  },
  {
    "id": "arXiv:1808.00054",
    "title": "Modeling Task Effects in Human Reading with Neural Attention",
    "abstract": "Modeling Task Effects in Human Reading with Neural Attention",
    "descriptor": "",
    "authors": [
      "Michael Hahn",
      "Frank Keller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1808.00054"
  },
  {
    "id": "arXiv:1907.01241",
    "title": "On the VC-dimension of half-spaces with respect to convex sets",
    "abstract": "On the VC-dimension of half-spaces with respect to convex sets",
    "descriptor": "",
    "authors": [
      "Nicolas Grelier",
      "Saeed Gh. Ilchi",
      "Tillmann Miltzow",
      "Shakhar Smorodinsky"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1907.01241"
  },
  {
    "id": "arXiv:1909.07750",
    "title": "MDP Playground: A Design and Debug Testbed for Reinforcement Learning",
    "abstract": "Comments: NeurIPS 2021 Data and Benchmark Track submission (with slight formatting differences, most notably citation style)",
    "descriptor": "\nComments: NeurIPS 2021 Data and Benchmark Track submission (with slight formatting differences, most notably citation style)\n",
    "authors": [
      "Raghu Rajan",
      "Jessica Lizeth Borja Diaz",
      "Suresh Guttikonda",
      "Fabio Ferreira",
      "Andr\u00e9 Biedenkapp",
      "Jan Ole von Hartz",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.07750"
  },
  {
    "id": "arXiv:1909.08341",
    "title": "Bifurcation Spiking Neural Network",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Shao-Qun Zhang",
      "Zhao-Yu Zhang",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/1909.08341"
  },
  {
    "id": "arXiv:1909.11326",
    "title": "New results on quasi-subfield polynomials",
    "abstract": "Comments: 31 pages (Accepted manuscript) Finite Fields and Their Applications, Elsevier, In press, 75",
    "descriptor": "\nComments: 31 pages (Accepted manuscript) Finite Fields and Their Applications, Elsevier, In press, 75\n",
    "authors": [
      "M. Euler",
      "C. Petit"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/1909.11326"
  },
  {
    "id": "arXiv:1910.09734",
    "title": "Single and Union Non-parallel Support Vector Machine Frameworks",
    "abstract": "Single and Union Non-parallel Support Vector Machine Frameworks",
    "descriptor": "",
    "authors": [
      "Chun-Na Li",
      "Yuan-Hai Shao",
      "Huajun Wang",
      "Yu-Ting Zhao",
      "Ling-Wei Huang",
      "Naihua Xiu",
      "Nai-Yang Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.09734"
  },
  {
    "id": "arXiv:1911.00143",
    "title": "Multivariate Medians for Image and Shape Analysis",
    "abstract": "Comments: Minor corrections, one additional reference",
    "descriptor": "\nComments: Minor corrections, one additional reference\n",
    "authors": [
      "Martin Welk"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/1911.00143"
  },
  {
    "id": "arXiv:1912.07339",
    "title": "Synthetic topology in Homotopy Type Theory for probabilistic programming",
    "abstract": "Synthetic topology in Homotopy Type Theory for probabilistic programming",
    "descriptor": "",
    "authors": [
      "Martin E. Bidlingmaier",
      "Florian Faissole",
      "Bas Spitters"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/1912.07339"
  },
  {
    "id": "arXiv:2001.03040",
    "title": "Deep Network Approximation for Smooth Functions",
    "abstract": "Deep Network Approximation for Smooth Functions",
    "descriptor": "",
    "authors": [
      "Jianfeng Lu",
      "Zuowei Shen",
      "Haizhao Yang",
      "Shijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.03040"
  },
  {
    "id": "arXiv:2001.05364",
    "title": "Solving connectivity problems parameterized by treedepth in  single-exponential time and polynomial space",
    "abstract": "Comments: 27 pages; accepted at STACS 2020",
    "descriptor": "\nComments: 27 pages; accepted at STACS 2020\n",
    "authors": [
      "Falko Hegerfeld",
      "Stefan Kratsch"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2001.05364"
  },
  {
    "id": "arXiv:2002.10131",
    "title": "Modeling Aggression Propagation on Social Media",
    "abstract": "Comments: 13 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 13 pages, 5 figures, 3 tables\n",
    "authors": [
      "Chrysoula Terizi",
      "Despoina Chatzakou",
      "Evaggelia Pitoura",
      "Panayiotis Tsaparas",
      "Nicolas Kourtellis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2002.10131"
  },
  {
    "id": "arXiv:2003.12319",
    "title": "Boolean learning under noise-perturbations in hardware neural networks",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Louis Andreoli",
      "Xavier Porte",
      "St\u00e9phane Chr\u00e9tien",
      "Maxime Jacquot",
      "Laurent Larger",
      "Daniel Brunner"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.12319"
  },
  {
    "id": "arXiv:2004.05954",
    "title": "A General Framework for Approximating Min Sum Ordering Problems",
    "abstract": "A General Framework for Approximating Min Sum Ordering Problems",
    "descriptor": "",
    "authors": [
      "Felix Happach",
      "Lisa Hellerstein",
      "Thomas Lidbetter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2004.05954"
  },
  {
    "id": "arXiv:2004.08642",
    "title": "Resonant Beam Communications: Principles and Designs",
    "abstract": "Resonant Beam Communications: Principles and Designs",
    "descriptor": "",
    "authors": [
      "Mingliang Xiong",
      "Qingwen Liu",
      "Gang Wang",
      "Georgios B. Giannakis",
      "Chuan Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2004.08642"
  },
  {
    "id": "arXiv:2005.04377",
    "title": "A First Look into DeFi Oracles",
    "abstract": "Comments: To appear IEEE DAPPS'21, an extended version",
    "descriptor": "\nComments: To appear IEEE DAPPS'21, an extended version\n",
    "authors": [
      "Bowen Liu",
      "Pawel Szalachowski",
      "Jianying Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2005.04377"
  },
  {
    "id": "arXiv:2005.05144",
    "title": "TTS-Portuguese Corpus: a corpus for speech synthesis in Brazilian  Portuguese",
    "abstract": "Comments: This paper is under consideration at Language Resources and Evaluation (LREV)",
    "descriptor": "\nComments: This paper is under consideration at Language Resources and Evaluation (LREV)\n",
    "authors": [
      "Edresson Casanova",
      "Arnaldo Candido Junior",
      "Christopher Shulby",
      "Frederico Santos de Oliveira",
      "Jo\u00e3o Paulo Teixeira",
      "Moacir Antonelli Ponti",
      "Sandra Maria Aluisio"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.05144"
  },
  {
    "id": "arXiv:2005.05588",
    "title": "Repeated Quantum Games and Strategic Efficiency",
    "abstract": "Comments: 25 pages, 14 figures",
    "descriptor": "\nComments: 25 pages, 14 figures\n",
    "authors": [
      "Shoto Aoki",
      "Kazuki Ikeda"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2005.05588"
  },
  {
    "id": "arXiv:2005.05888",
    "title": "Safe Learning-based Observers for Unknown Nonlinear Systems using  Bayesian Optimization",
    "abstract": "Comments: 23 pages, post-review draft",
    "descriptor": "\nComments: 23 pages, post-review draft\n",
    "authors": [
      "Ankush Chakrabarty",
      "Mouhacine Benosman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2005.05888"
  },
  {
    "id": "arXiv:2006.05659",
    "title": "Optimal Participation of Price-maker Battery Energy Storage Systems in  Energy and Ancillary Services Markets Considering Degradation Cost",
    "abstract": "Optimal Participation of Price-maker Battery Energy Storage Systems in  Energy and Ancillary Services Markets Considering Degradation Cost",
    "descriptor": "",
    "authors": [
      "Reza Khalilisenobari",
      "Meng Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.05659"
  },
  {
    "id": "arXiv:2006.06964",
    "title": "Maximal inequalities for stochastic convolutions and pathwise uniform  convergence of time discretisation schemes",
    "abstract": "Comments: minor revision. Accepted for publication in Stochastics and Partial Differential Equations: Analysis and Computations",
    "descriptor": "\nComments: minor revision. Accepted for publication in Stochastics and Partial Differential Equations: Analysis and Computations\n",
    "authors": [
      "Jan van Neerven",
      "Mark Veraar"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.06964"
  },
  {
    "id": "arXiv:2006.10369",
    "title": "Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine  Translation",
    "abstract": "Comments: ICLR 2021 Final Version",
    "descriptor": "\nComments: ICLR 2021 Final Version\n",
    "authors": [
      "Jungo Kasai",
      "Nikolaos Pappas",
      "Hao Peng",
      "James Cross",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2006.10369"
  },
  {
    "id": "arXiv:2006.12135",
    "title": "Learning to Generate Noise for Multi-Attack Robustness",
    "abstract": "Comments: Accepted to ICML 2021. Code available at this https URL",
    "descriptor": "\nComments: Accepted to ICML 2021. Code available at this https URL\n",
    "authors": [
      "Divyam Madaan",
      "Jinwoo Shin",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.12135"
  },
  {
    "id": "arXiv:2006.13365",
    "title": "Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge  Graph Embedding Models Under a Unified Framework",
    "abstract": "Bringing Light Into the Dark: A Large-scale Evaluation of Knowledge  Graph Embedding Models Under a Unified Framework",
    "descriptor": "",
    "authors": [
      "Mehdi Ali",
      "Max Berrendorf",
      "Charles Tapley Hoyt",
      "Laurent Vermue",
      "Mikhail Galkin",
      "Sahand Sharifzadeh",
      "Asja Fischer",
      "Volker Tresp",
      "Jens Lehmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.13365"
  },
  {
    "id": "arXiv:2007.11752",
    "title": "Joslim: Joint Widths and Weights Optimization for Slimmable Neural  Networks",
    "abstract": "Comments: Accepted at ECML-PKDD 2021 (Research Track), 4-page abridged versions have been accepted at non-archival venues including RealML and DMMLSys workshops at ICML'20 and DLP-KDD and AdvML workshops at KDD'20",
    "descriptor": "\nComments: Accepted at ECML-PKDD 2021 (Research Track), 4-page abridged versions have been accepted at non-archival venues including RealML and DMMLSys workshops at ICML'20 and DLP-KDD and AdvML workshops at KDD'20\n",
    "authors": [
      "Ting-Wu Chin",
      "Ari S. Morcos",
      "Diana Marculescu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.11752"
  },
  {
    "id": "arXiv:2007.15779",
    "title": "Domain-Specific Language Model Pretraining for Biomedical Natural  Language Processing",
    "abstract": "Domain-Specific Language Model Pretraining for Biomedical Natural  Language Processing",
    "descriptor": "",
    "authors": [
      "Yu Gu",
      "Robert Tinn",
      "Hao Cheng",
      "Michael Lucas",
      "Naoto Usuyama",
      "Xiaodong Liu",
      "Tristan Naumann",
      "Jianfeng Gao",
      "Hoifung Poon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.15779"
  },
  {
    "id": "arXiv:2008.00583",
    "title": "Decision problems for linear recurrences involving arbitrary real  numbers",
    "abstract": "Decision problems for linear recurrences involving arbitrary real  numbers",
    "descriptor": "",
    "authors": [
      "Eike Neumann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2008.00583"
  },
  {
    "id": "arXiv:2008.01839",
    "title": "Sketching Datasets for Large-Scale Learning (long version)",
    "abstract": "Sketching Datasets for Large-Scale Learning (long version)",
    "descriptor": "",
    "authors": [
      "R\u00e9mi Gribonval",
      "Antoine Chatalic",
      "Nicolas Keriven",
      "Vincent Schellekens",
      "Laurent Jacques",
      "Philip Schniter"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.01839"
  },
  {
    "id": "arXiv:2008.01855",
    "title": "DAEMON: Dataset-Agnostic Explainable Malware Classification Using  Multi-Stage Feature Mining",
    "abstract": "DAEMON: Dataset-Agnostic Explainable Malware Classification Using  Multi-Stage Feature Mining",
    "descriptor": "",
    "authors": [
      "Ron Korine",
      "Danny Hendler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.01855"
  },
  {
    "id": "arXiv:2008.02691",
    "title": "Adaptive Coordination Offsets for Signalized Arterial Intersections  using Deep Reinforcement Learning",
    "abstract": "Adaptive Coordination Offsets for Signalized Arterial Intersections  using Deep Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Keith Anshilo Diaz",
      "Damian Dailisan",
      "Umang Sharaf",
      "Carissa Santos",
      "Qijian Gan",
      "Francis Aldrine Uy",
      "May T. Lim",
      "Alexandre M. Bayen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.02691"
  },
  {
    "id": "arXiv:2008.03326",
    "title": "Optimal Combination of Linear and Spectral Estimators for Generalized  Linear Models",
    "abstract": "Comments: 49 pages, 6 figures",
    "descriptor": "\nComments: 49 pages, 6 figures\n",
    "authors": [
      "Marco Mondelli",
      "Christos Thrampoulidis",
      "Ramji Venkataramanan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2008.03326"
  },
  {
    "id": "arXiv:2008.12334",
    "title": "Link Budget Analysis for Reconfigurable Smart Surfaces in Aerial  Platforms",
    "abstract": "Comments: 14 pages, 13 figures",
    "descriptor": "\nComments: 14 pages, 13 figures\n",
    "authors": [
      "Safwan Alfattani",
      "Wael Jaafar",
      "Yassine Hmamouche",
      "Halim Yanikomeroglu",
      "Abbas Yonga\u00e7oglu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.12334"
  },
  {
    "id": "arXiv:2009.01534",
    "title": "Fairness in the Eyes of the Data: Certifying Machine-Learning Models",
    "abstract": "Comments: Accepted to AIES-2021",
    "descriptor": "\nComments: Accepted to AIES-2021\n",
    "authors": [
      "Shahar Segal",
      "Yossi Adi",
      "Benny Pinkas",
      "Carsten Baum",
      "Chaya Ganesh",
      "Joseph Keshet"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.01534"
  },
  {
    "id": "arXiv:2009.02176",
    "title": "Separated response surfaces for flows in parametrised domains:  comparison of a priori and a posteriori PGD algorithms",
    "abstract": "Comments: 58 pages, 31 figures",
    "descriptor": "\nComments: 58 pages, 31 figures\n",
    "authors": [
      "Matteo Giacomini",
      "Luca Borchini",
      "Ruben Sevilla",
      "Antonio Huerta"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2009.02176"
  },
  {
    "id": "arXiv:2009.04899",
    "title": "Meta-learning for Multi-variable Non-convex Optimization Problems:  Iterating Non-optimums Makes Optimum Possible",
    "abstract": "Comments: 15 pages, 8 figures, update content",
    "descriptor": "\nComments: 15 pages, 8 figures, update content\n",
    "authors": [
      "Jingyuan Xia",
      "Jun-Jie Huang",
      "Imad Jaimoukha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.04899"
  },
  {
    "id": "arXiv:2009.05654",
    "title": "Reinforcement Learning for Optimal Frequency Control: A Lyapunov  Approach",
    "abstract": "Reinforcement Learning for Optimal Frequency Control: A Lyapunov  Approach",
    "descriptor": "",
    "authors": [
      "Wenqi Cui",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2009.05654"
  },
  {
    "id": "arXiv:2009.07619",
    "title": "Value Alignment Equilibrium in Multiagent Systems",
    "abstract": "Comments: 1st TAILOR Workshop at ECAI 2020",
    "descriptor": "\nComments: 1st TAILOR Workshop at ECAI 2020\n",
    "authors": [
      "Nieves Montes",
      "Carles Sierra"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2009.07619"
  },
  {
    "id": "arXiv:2009.07936",
    "title": "How to marry a star: probabilistic constraints for meaning in context",
    "abstract": "How to marry a star: probabilistic constraints for meaning in context",
    "descriptor": "",
    "authors": [
      "Katrin Erk",
      "Aurelie Herbelot"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.07936"
  },
  {
    "id": "arXiv:2010.02787",
    "title": "Efficiently Approximating Vertex Cover on Scale-Free Networks with  Underlying Hyperbolic Geometry",
    "abstract": "Efficiently Approximating Vertex Cover on Scale-Free Networks with  Underlying Hyperbolic Geometry",
    "descriptor": "",
    "authors": [
      "Thomas Bl\u00e4sius",
      "Tobias Friedrich",
      "Maximilian Katzmann"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.02787"
  },
  {
    "id": "arXiv:2010.08230",
    "title": "Graph Rewriting and Relabeling with PBPO+",
    "abstract": "Comments: 20 pages, accepted to the International Conference on Graph Transformation 2021 (ICGT 2021)",
    "descriptor": "\nComments: 20 pages, accepted to the International Conference on Graph Transformation 2021 (ICGT 2021)\n",
    "authors": [
      "Roy Overbeek",
      "J\u00f6rg Endrullis",
      "Alo\u00efs Rosset"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2010.08230"
  },
  {
    "id": "arXiv:2010.10907",
    "title": "Analyzing the Source and Target Contributions to Predictions in Neural  Machine Translation",
    "abstract": "Comments: ACL 2021 (more accurate results with the improved LRP code)",
    "descriptor": "\nComments: ACL 2021 (more accurate results with the improved LRP code)\n",
    "authors": [
      "Elena Voita",
      "Rico Sennrich",
      "Ivan Titov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.10907"
  },
  {
    "id": "arXiv:2010.11462",
    "title": "Linear-Delay Enumeration for Minimal Steiner Problems",
    "abstract": "Linear-Delay Enumeration for Minimal Steiner Problems",
    "descriptor": "",
    "authors": [
      "Yasuaki Kobayashi",
      "Kazuhiro Kurita",
      "Kunihiro Wasa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.11462"
  },
  {
    "id": "arXiv:2010.12133",
    "title": "An Inertial Block Majorization Minimization Framework for Nonsmooth  Nonconvex Optimization",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Le Thi Khanh Hien",
      "Duy Nhat Phan",
      "Nicolas Gillis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2010.12133"
  },
  {
    "id": "arXiv:2010.15676",
    "title": "Optimization Fabrics for Behavioral Design",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2008.02399",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2008.02399\n",
    "authors": [
      "Nathan D. Ratliff",
      "Karl Van Wyk",
      "Mandy Xie",
      "Anqi Li",
      "Muhammad Asif Rana"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2010.15676"
  },
  {
    "id": "arXiv:2011.03882",
    "title": "Multi-Modal Learning of Keypoint Predictive Models for Visual Object  Manipulation",
    "abstract": "Multi-Modal Learning of Keypoint Predictive Models for Visual Object  Manipulation",
    "descriptor": "",
    "authors": [
      "Sarah Bechtle",
      "Neha Das",
      "Franziska Meier"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.03882"
  },
  {
    "id": "arXiv:2011.04491",
    "title": "Masked Proxy Loss For Text-Independent Speaker Verification",
    "abstract": "Comments: Accepted at Interspeech 2021",
    "descriptor": "\nComments: Accepted at Interspeech 2021\n",
    "authors": [
      "Jiachen Lian",
      "Aiswarya Vinod Kumar",
      "Hira Dhamyal",
      "Bhiksha Raj",
      "Rita Singh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2011.04491"
  },
  {
    "id": "arXiv:2011.05418",
    "title": "Self-supervised Learning of LiDAR Odometry for Robotic Applications",
    "abstract": "Comments: 7 pages, 6 figures, 3 tables",
    "descriptor": "\nComments: 7 pages, 6 figures, 3 tables\n",
    "authors": [
      "Julian Nubert",
      "Shehryar Khattak",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.05418"
  },
  {
    "id": "arXiv:2011.06375",
    "title": "Iterative Surface Mapping Using Local Geometry Approximation with Sparse  Measurements During Robotic Tooling Tasks",
    "abstract": "Comments: Accepted for presentation at and publication in the proceedings of the 2021 IEEE 17th International Conference on Automation Science and Engineering (CASE), 7 pages, 6 figures",
    "descriptor": "\nComments: Accepted for presentation at and publication in the proceedings of the 2021 IEEE 17th International Conference on Automation Science and Engineering (CASE), 7 pages, 6 figures\n",
    "authors": [
      "Manuel Amersdorfer",
      "Thomas Meurer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.06375"
  },
  {
    "id": "arXiv:2011.08485",
    "title": "Robustness and Generalization to Nearest Categories",
    "abstract": "Robustness and Generalization to Nearest Categories",
    "descriptor": "",
    "authors": [
      "Yao-Yuan Yang",
      "Cyrus Rashtchian",
      "Ruslan Salakhutdinov",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.08485"
  },
  {
    "id": "arXiv:2011.13451",
    "title": "Strongly-Normalizing Higher-Order Relational Queries",
    "abstract": "Comments: 33 pages, 6 figures. Extended version of paper published in the proceedings of FSCD 2020",
    "descriptor": "\nComments: 33 pages, 6 figures. Extended version of paper published in the proceedings of FSCD 2020\n",
    "authors": [
      "Wilmer Ricciotti",
      "James Cheney"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2011.13451"
  },
  {
    "id": "arXiv:2012.00467",
    "title": "A Survey on ML4VIS: Applying Machine Learning Advances to Data  Visualization",
    "abstract": "Comments: 19 pages, 12 figures, 4 tables",
    "descriptor": "\nComments: 19 pages, 12 figures, 4 tables\n",
    "authors": [
      "Qianwen Wang",
      "Zhutian Chen",
      "Yong Wang",
      "Huamin Qu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2012.00467"
  },
  {
    "id": "arXiv:2012.02785",
    "title": "Unsupervised embedding of trajectories captures the latent structure of  mobility",
    "abstract": "Comments: 36 pages (main text), 79 pages total. 6 figures (main text), 25 figures in supporting information",
    "descriptor": "\nComments: 36 pages (main text), 79 pages total. 6 figures (main text), 25 figures in supporting information\n",
    "authors": [
      "Dakota Murray",
      "Jisung Yoon",
      "Sadamori Kojaku",
      "Rodrigo Costas",
      "Woo-Sung Jung",
      "Sta\u0161a Milojevi\u0107",
      "Yong-Yeol Ahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.02785"
  },
  {
    "id": "arXiv:2012.03085",
    "title": "Graph Mixture Density Networks",
    "abstract": "Graph Mixture Density Networks",
    "descriptor": "",
    "authors": [
      "Federico Errica",
      "Davide Bacciu",
      "Alessio Micheli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.03085"
  },
  {
    "id": "arXiv:2012.05023",
    "title": "NSL: Hybrid Interpretable Learning From Noisy Raw Data",
    "abstract": "Comments: This article has been replaced with arXiv:2106.13103",
    "descriptor": "\nComments: This article has been replaced with arXiv:2106.13103\n",
    "authors": [
      "Daniel Cunnington",
      "Alessandra Russo",
      "Mark Law",
      "Jorge Lobo",
      "Lance Kaplan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.05023"
  },
  {
    "id": "arXiv:2012.07300",
    "title": "Unsupervised Summarization for Chat Logs with Topic-Oriented Ranking and  Context-Aware Auto-Encoders",
    "abstract": "Comments: Accepted by AAAI 2021, 9 pages",
    "descriptor": "\nComments: Accepted by AAAI 2021, 9 pages\n",
    "authors": [
      "Yicheng Zou",
      "Jun Lin",
      "Lujun Zhao",
      "Yangyang Kang",
      "Zhuoren Jiang",
      "Changlong Sun",
      "Qi Zhang",
      "Xuanjing Huang",
      "Xiaozhong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.07300"
  },
  {
    "id": "arXiv:2012.07311",
    "title": "Topic-Oriented Spoken Dialogue Summarization for Customer Service with  Saliency-Aware Topic Modeling",
    "abstract": "Comments: Accepted by AAAI 2021, 9 pages",
    "descriptor": "\nComments: Accepted by AAAI 2021, 9 pages\n",
    "authors": [
      "Yicheng Zou",
      "Lujun Zhao",
      "Yangyang Kang",
      "Jun Lin",
      "Minlong Peng",
      "Zhuoren Jiang",
      "Changlong Sun",
      "Qi Zhang",
      "Xuanjing Huang",
      "Xiaozhong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.07311"
  },
  {
    "id": "arXiv:2012.08334",
    "title": "Masksembles for Uncertainty Estimation",
    "abstract": "Masksembles for Uncertainty Estimation",
    "descriptor": "",
    "authors": [
      "Nikita Durasov",
      "Timur Bagautdinov",
      "Pierre Baque",
      "Pascal Fua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.08334"
  },
  {
    "id": "arXiv:2012.08940",
    "title": "A Distributed Methodology for Approximate Uniform Global Minimum Sharing",
    "abstract": "A Distributed Methodology for Approximate Uniform Global Minimum Sharing",
    "descriptor": "",
    "authors": [
      "Michelangelo Bin",
      "Thomas Parisini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.08940"
  },
  {
    "id": "arXiv:2101.00488",
    "title": "Non-conservative Design of Robust Tracking Controllers Based on  Input-output Data",
    "abstract": "Non-conservative Design of Robust Tracking Controllers Based on  Input-output Data",
    "descriptor": "",
    "authors": [
      "Liang Xu",
      "Mustafa Sahin Turan",
      "Baiwei Guo",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.00488"
  },
  {
    "id": "arXiv:2101.08547",
    "title": "Robust spectral compressive sensing via vanilla gradient descent",
    "abstract": "Robust spectral compressive sensing via vanilla gradient descent",
    "descriptor": "",
    "authors": [
      "Xunmeng Wu",
      "Zai Yang",
      "Zongben Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.08547"
  },
  {
    "id": "arXiv:2101.08712",
    "title": "A variational discrete element method for the computation of Cosserat  elasticity",
    "abstract": "A variational discrete element method for the computation of Cosserat  elasticity",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Marazzato"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.08712"
  },
  {
    "id": "arXiv:2101.08909",
    "title": "Study of Pre-processing Defenses against Adversarial Attacks on  State-of-the-art Speaker Recognition Systems",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sonal Joshi",
      "Jes\u00fas Villalba",
      "Piotr \u017belasko",
      "Laureano Moro-Vel\u00e1zquez",
      "Najim Dehak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2101.08909"
  },
  {
    "id": "arXiv:2101.09899",
    "title": "MultiFace: A Generic Training Mechanism for Boosting Face Recognition  Performance",
    "abstract": "Comments: 7 pages, 7 figures",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Jing Xu",
      "Tszhang Guo",
      "Yong Xu",
      "Zenglin Xu",
      "Kun Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.09899"
  },
  {
    "id": "arXiv:2101.10048",
    "title": "A Process to Facilitate Automated Automotive Cybersecurity Testing",
    "abstract": "Comments: 7 pages, 2 figures paper presented at IEEE VTC2021-Spring. Full published version at this https URL",
    "descriptor": "\nComments: 7 pages, 2 figures paper presented at IEEE VTC2021-Spring. Full published version at this https URL\n",
    "authors": [
      "Stefan Marksteiner",
      "Nadja Marko",
      "Andre Smulders",
      "Stelios Karagiannis",
      "Florian Stahl",
      "Hayk Hamazaryan",
      "Rupert Schlick",
      "Stefan Kraxberger",
      "Alexandr Vasenev"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2101.10048"
  },
  {
    "id": "arXiv:2101.12459",
    "title": "On $f$-divergences between Cauchy distributions",
    "abstract": "Comments: 56 pages, 1 figure, 1 table",
    "descriptor": "\nComments: 56 pages, 1 figure, 1 table\n",
    "authors": [
      "Frank Nielsen",
      "Kazuki Okamura"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2101.12459"
  },
  {
    "id": "arXiv:2102.00147",
    "title": "Retro-Reflective Beam Communications with Spatially Separated Laser  Resonator",
    "abstract": "Retro-Reflective Beam Communications with Spatially Separated Laser  Resonator",
    "descriptor": "",
    "authors": [
      "Mingliang Xiong",
      "Mingqing Liu",
      "Qingwei Jiang",
      "Jie Zhou",
      "Qingwen Liu",
      "Hao Deng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2102.00147"
  },
  {
    "id": "arXiv:2102.00630",
    "title": "How can one test if a binary sequence is exchangeable? Fork-convex  hulls, supermartingales, and e-processes",
    "abstract": "Comments: 34 pages, 7 figures, accepted at the International Journal of Approximate Reasoning",
    "descriptor": "\nComments: 34 pages, 7 figures, accepted at the International Journal of Approximate Reasoning\n",
    "authors": [
      "Aaditya Ramdas",
      "Johannes Ruf",
      "Martin Larsson",
      "Wouter Koolen"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2102.00630"
  },
  {
    "id": "arXiv:2102.01604",
    "title": "Model-based multi-parameter mapping",
    "abstract": "Comments: 20 pages, 6 figures, accepted at Medical Image Analysis",
    "descriptor": "\nComments: 20 pages, 6 figures, accepted at Medical Image Analysis\n",
    "authors": [
      "Yael Balbastre",
      "Mikael Brudfors",
      "Michela Azzarito",
      "Christian Lambert",
      "Martina F. Callaghan",
      "John Ashburner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2102.01604"
  },
  {
    "id": "arXiv:2102.02472",
    "title": "Transfer Learning in Bandits with Latent Continuity",
    "abstract": "Transfer Learning in Bandits with Latent Continuity",
    "descriptor": "",
    "authors": [
      "Hyejin Park",
      "Seiyun Shin",
      "Kwang-Sung Jun",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.02472"
  },
  {
    "id": "arXiv:2102.03758",
    "title": "Non-stationary Online Learning with Memory and Non-stochastic Control",
    "abstract": "Non-stationary Online Learning with Memory and Non-stochastic Control",
    "descriptor": "",
    "authors": [
      "Peng Zhao",
      "Yu-Xiang Wang",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.03758"
  },
  {
    "id": "arXiv:2102.05015",
    "title": "Optimal SIC Ordering and Power Allocation in Downlink Multi-Cell NOMA  Systems",
    "abstract": "Comments: 55 pages, 33 figures",
    "descriptor": "\nComments: 55 pages, 33 figures\n",
    "authors": [
      "Sepehr Rezvani",
      "Eduard A. Jorswieck",
      "Nader Mokari",
      "Mohammad R. Javan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.05015"
  },
  {
    "id": "arXiv:2102.06258",
    "title": "Using Echo State Networks to Approximate Value Functions for Control",
    "abstract": "Using Echo State Networks to Approximate Value Functions for Control",
    "descriptor": "",
    "authors": [
      "Allen G. Hart",
      "Kevin R. Olding",
      "A. M. G. Cox",
      "Olga Isupova",
      "J. H. P. Dawes"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.06258"
  },
  {
    "id": "arXiv:2102.12756",
    "title": "Learning a Probabilistic Relaxation of Discrete Variables for Soft  Detection with Low Complexity: CMDNet",
    "abstract": "Comments: Submitted for publication",
    "descriptor": "\nComments: Submitted for publication\n",
    "authors": [
      "Edgar Beck",
      "Carsten Bockelmann",
      "Armin Dekorsy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.12756"
  },
  {
    "id": "arXiv:2102.13092",
    "title": "Quantitative approximation results for complex-valued neural networks",
    "abstract": "Quantitative approximation results for complex-valued neural networks",
    "descriptor": "",
    "authors": [
      "A. Caragea",
      "D.G. Lee",
      "J. Maly",
      "G. Pfander",
      "F. Voigtlaender"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.13092"
  },
  {
    "id": "arXiv:2103.00239",
    "title": "Dev2PQ: Planar Quadrilateral Strip Remeshing of Developable Surfaces",
    "abstract": "Dev2PQ: Planar Quadrilateral Strip Remeshing of Developable Surfaces",
    "descriptor": "",
    "authors": [
      "Floor Verhoeven",
      "Amir Vaxman",
      "Tim Hoffmann",
      "Olga Sorkine-Hornung"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2103.00239"
  },
  {
    "id": "arXiv:2103.01627",
    "title": "Pixel-level Extrinsic Self Calibration of High Resolution LiDAR and  Camera in Targetless Environments",
    "abstract": "Comments: 8 pages, 19 figures",
    "descriptor": "\nComments: 8 pages, 19 figures\n",
    "authors": [
      "Chongjian Yuan",
      "Xiyuan Liu",
      "Xiaoping Hong",
      "Fu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.01627"
  },
  {
    "id": "arXiv:2103.02840",
    "title": "Estimation and Planning of Exploration Over Grid Map Using A  Spatiotemporal Model with Incomplete State Observations",
    "abstract": "Estimation and Planning of Exploration Over Grid Map Using A  Spatiotemporal Model with Incomplete State Observations",
    "descriptor": "",
    "authors": [
      "Hyung-Jin Yoon",
      "Hunmin Kim",
      "Kripash Shrestha",
      "Naira Hovakimyan",
      "Petros Voulgaris"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.02840"
  },
  {
    "id": "arXiv:2103.03231",
    "title": "DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields  using Depth Oracle Networks",
    "abstract": "Comments: Accepted to EGSR 2021 in the CGF track; Project website: this https URL",
    "descriptor": "\nComments: Accepted to EGSR 2021 in the CGF track; Project website: this https URL\n",
    "authors": [
      "Thomas Neff",
      "Pascal Stadlbauer",
      "Mathias Parger",
      "Andreas Kurz",
      "Joerg H. Mueller",
      "Chakravarty R. Alla Chaitanya",
      "Anton Kaplanyan",
      "Markus Steinberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2103.03231"
  },
  {
    "id": "arXiv:2103.04876",
    "title": "Scale invariant robot behavior with fractals",
    "abstract": "Scale invariant robot behavior with fractals",
    "descriptor": "",
    "authors": [
      "Sam Kriegman",
      "Amir Mohammadi Nasab",
      "Douglas Blackiston",
      "Hannah Steele",
      "Michael Levin",
      "Rebecca Kramer-Bottiglio",
      "Josh Bongard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.04876"
  },
  {
    "id": "arXiv:2103.05391",
    "title": "Semantic Communications in Networked Systems",
    "abstract": "Comments: 9 pages, 6 figures, 1500 words",
    "descriptor": "\nComments: 9 pages, 6 figures, 1500 words\n",
    "authors": [
      "Elif Uysal",
      "Onur Kaya",
      "Anthony Ephremides",
      "James Gross",
      "Marian Codreanu",
      "Petar Popovski",
      "Mohamad Assaad",
      "Gianluigi Liva",
      "Andrea Munari",
      "Touraj Soleymani",
      "Beatriz Soret",
      "Karl Henrik Johansson"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.05391"
  },
  {
    "id": "arXiv:2103.05690",
    "title": "Multitask 3D CBCT-to-CT Translation and Organs-at-Risk Segmentation  Using Physics-Based Data Augmentation",
    "abstract": "Comments: Medical Physics 2021",
    "descriptor": "\nComments: Medical Physics 2021\n",
    "authors": [
      "Navdeep Dahiya",
      "Sadegh R Alam",
      "Pengpeng Zhang",
      "Si-Yuan Zhang",
      "Anthony Yezzi",
      "Saad Nadeem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.05690"
  },
  {
    "id": "arXiv:2103.05793",
    "title": "Universal Approximation of Residual Flows in Maximum Mean Discrepancy",
    "abstract": "Universal Approximation of Residual Flows in Maximum Mean Discrepancy",
    "descriptor": "",
    "authors": [
      "Zhifeng Kong",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.05793"
  },
  {
    "id": "arXiv:2103.06859",
    "title": "Understanding the Origin of Information-Seeking Exploration in  Probabilistic Objectives for Control",
    "abstract": "Comments: 11-03-21 initial upload. 14-03-21 fix Charnov citation. 16-03-21 another fix. 25-06-21 more fixes plus numerical simulations",
    "descriptor": "\nComments: 11-03-21 initial upload. 14-03-21 fix Charnov citation. 16-03-21 another fix. 25-06-21 more fixes plus numerical simulations\n",
    "authors": [
      "Beren Millidge",
      "Alexander Tschantz",
      "Anil Seth",
      "Christopher Buckley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.06859"
  },
  {
    "id": "arXiv:2103.07877",
    "title": "R-GSN: The Relation-based Graph Similar Network for Heterogeneous Graph",
    "abstract": "R-GSN: The Relation-based Graph Similar Network for Heterogeneous Graph",
    "descriptor": "",
    "authors": [
      "Xinliang Wu",
      "Mengying Jiang",
      "Guizhong Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.07877"
  },
  {
    "id": "arXiv:2103.09474",
    "title": "STYLER: Style Factor Modeling with Rapidity and Robustness via Speech  Decomposition for Expressive and Controllable Neural Text to Speech",
    "abstract": "Comments: 5 pages, 2 figures, Accepted to Interspeech 2021",
    "descriptor": "\nComments: 5 pages, 2 figures, Accepted to Interspeech 2021\n",
    "authors": [
      "Keon Lee",
      "Kyumin Park",
      "Daeyoung Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2103.09474"
  },
  {
    "id": "arXiv:2103.11078",
    "title": "AD-NeRF: Audio Driven Neural Radiance Fields for Talking Head Synthesis",
    "abstract": "Comments: Project: this https URL Code: this https URL",
    "descriptor": "\nComments: Project: this https URL Code: this https URL\n",
    "authors": [
      "Yudong Guo",
      "Keyu Chen",
      "Sen Liang",
      "Yongjin Liu",
      "Hujun Bao",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11078"
  },
  {
    "id": "arXiv:2103.11512",
    "title": "Robust Multi-Modal Policies for Industrial Assembly via Reinforcement  Learning and Demonstrations: A Large-Scale Study",
    "abstract": "Comments: RSS 2021",
    "descriptor": "\nComments: RSS 2021\n",
    "authors": [
      "Jianlan Luo",
      "Oleg Sushkov",
      "Rugile Pevceviciute",
      "Wenzhao Lian",
      "Chang Su",
      "Mel Vecerik",
      "Ning Ye",
      "Stefan Schaal",
      "Jon Scholz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.11512"
  },
  {
    "id": "arXiv:2103.15208",
    "title": "Unified Shape and SVBRDF Recovery using Differentiable Monte Carlo  Rendering",
    "abstract": "Unified Shape and SVBRDF Recovery using Differentiable Monte Carlo  Rendering",
    "descriptor": "",
    "authors": [
      "Fujun Luan",
      "Shuang Zhao",
      "Kavita Bala",
      "Zhao Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15208"
  },
  {
    "id": "arXiv:2103.16104",
    "title": "Session-aware Linear Item-Item Models for Session-based Recommendation",
    "abstract": "Comments: In Proceedings of the Web Conference 2021. 12 pages",
    "descriptor": "\nComments: In Proceedings of the Web Conference 2021. 12 pages\n",
    "authors": [
      "Minjin Choi",
      "jinhong Kim",
      "Joonseok Lee",
      "Hyunjung Shim",
      "Jongwuk Lee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.16104"
  },
  {
    "id": "arXiv:2104.02222",
    "title": "Minimizing network bandwidth under latency constraints: The single node  case",
    "abstract": "Minimizing network bandwidth under latency constraints: The single node  case",
    "descriptor": "",
    "authors": [
      "Jiayi Song",
      "Roch Gu\u00e9rin",
      "Henry Sariowan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2104.02222"
  },
  {
    "id": "arXiv:2104.03543",
    "title": "Extended Parallel Corpus for Amharic-English Machine Translation",
    "abstract": "Comments: Accepted to 2nd AfricanNLP workshop at EACL 2021",
    "descriptor": "\nComments: Accepted to 2nd AfricanNLP workshop at EACL 2021\n",
    "authors": [
      "Andargachew Mekonnen Gezmu",
      "Andreas N\u00fcrnberger",
      "Tesfaye Bayu Bati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.03543"
  },
  {
    "id": "arXiv:2104.03882",
    "title": "An Information-Theoretic Proof of a Finite de Finetti Theorem",
    "abstract": "Comments: 5 pages. Revised version with some minor typos fixed and discussion slightly expanded",
    "descriptor": "\nComments: 5 pages. Revised version with some minor typos fixed and discussion slightly expanded\n",
    "authors": [
      "Lampros Gavalakis",
      "Ioannis Kontoyiannis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2104.03882"
  },
  {
    "id": "arXiv:2104.06214",
    "title": "BlockGNN: Towards Efficient GNN Acceleration Using Block-Circulant  Weight Matrices",
    "abstract": "BlockGNN: Towards Efficient GNN Acceleration Using Block-Circulant  Weight Matrices",
    "descriptor": "",
    "authors": [
      "Zhe Zhou",
      "Bizhao Shi",
      "Zhe Zhang",
      "Yijin Guan",
      "Guangyu Sun",
      "Guojie Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.06214"
  },
  {
    "id": "arXiv:2104.07006",
    "title": "Fast quantum state reconstruction via accelerated non-convex programming",
    "abstract": "Comments: 46 pages",
    "descriptor": "\nComments: 46 pages\n",
    "authors": [
      "Junhyung Lyle Kim",
      "George Kollias",
      "Amir Kalev",
      "Ken X. Wei",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.07006"
  },
  {
    "id": "arXiv:2104.08153",
    "title": "An Empirical Study of Graph-Based Approaches for Semi-Supervised Time  Series Classification",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Dominik Alfke",
      "Miriam Gondos",
      "Lucile Peroche",
      "Martin Stoll"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.08153"
  },
  {
    "id": "arXiv:2104.08383",
    "title": "Optimal Pose and Shape Estimation for Category-level 3D Object  Perception",
    "abstract": "Optimal Pose and Shape Estimation for Category-level 3D Object  Perception",
    "descriptor": "",
    "authors": [
      "Jingnan Shi",
      "Heng Yang",
      "Luca Carlone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.08383"
  },
  {
    "id": "arXiv:2104.09502",
    "title": "CodeAPeel: An Integrated and Layered Learning Technology For Computer  Architecture Courses",
    "abstract": "Comments: Minor revision and some typos are fixed",
    "descriptor": "\nComments: Minor revision and some typos are fixed\n",
    "authors": [
      "A. Yavuz Oruc",
      "A. Atmaca",
      "Y. Nevzat Sengun",
      "A. Semi Yeniyol"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.09502"
  },
  {
    "id": "arXiv:2104.12311",
    "title": "Stochastic Recurrent Neural Network for Multistep Time Series  Forecasting",
    "abstract": "Stochastic Recurrent Neural Network for Multistep Time Series  Forecasting",
    "descriptor": "",
    "authors": [
      "Zexuan Yin",
      "Paolo Barucca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.12311"
  },
  {
    "id": "arXiv:2104.15083",
    "title": "Learning Linear Temporal Properties from Noisy Data: A MaxSAT Approach",
    "abstract": "Learning Linear Temporal Properties from Noisy Data: A MaxSAT Approach",
    "descriptor": "",
    "authors": [
      "Jean-Rapha\u00ebl Gaglione",
      "Daniel Neider",
      "Rajarshi Roy",
      "Ufuk Topcu",
      "Zhe Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2104.15083"
  },
  {
    "id": "arXiv:2105.01041",
    "title": "On the Stability of Multilinear Dynamical Systems",
    "abstract": "Comments: 20 pages, 2 figures, 2 table",
    "descriptor": "\nComments: 20 pages, 2 figures, 2 table\n",
    "authors": [
      "Can Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.01041"
  },
  {
    "id": "arXiv:2105.02470",
    "title": "Generalized Multimodal ELBO",
    "abstract": "Comments: 2021 ICLR",
    "descriptor": "\nComments: 2021 ICLR\n",
    "authors": [
      "Thomas M. Sutter",
      "Imant Daunhawer",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.02470"
  },
  {
    "id": "arXiv:2105.05610",
    "title": "A Statistical Threshold for Adversarial Classification in Laplace  Mechanisms",
    "abstract": "A Statistical Threshold for Adversarial Classification in Laplace  Mechanisms",
    "descriptor": "",
    "authors": [
      "Ay\u015fe \u00dcnsal",
      "Melek \u00d6nen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.05610"
  },
  {
    "id": "arXiv:2105.11085",
    "title": "Fed-NILM: A Federated Learning-based Non-Intrusive Load Monitoring  Method for Privacy-Protection",
    "abstract": "Fed-NILM: A Federated Learning-based Non-Intrusive Load Monitoring  Method for Privacy-Protection",
    "descriptor": "",
    "authors": [
      "Haijin Wang",
      "Caomingzhe Si",
      "Junhua Zhao",
      "Guolong Liu",
      "Fushuan Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.11085"
  },
  {
    "id": "arXiv:2105.11108",
    "title": "Pre-trained Language Model based Ranking in Baidu Search",
    "abstract": "Comments: 9-pages, 3 figures, 7 tables, SIGKDD 2021 accepted paper",
    "descriptor": "\nComments: 9-pages, 3 figures, 7 tables, SIGKDD 2021 accepted paper\n",
    "authors": [
      "Lixin Zou",
      "Shengqiang Zhang",
      "Hengyi Cai",
      "Dehong Ma",
      "Suqi Cheng",
      "Daiting Shi",
      "Zhifan Zhu",
      "Weiyue Su",
      "Shuaiqiang Wang",
      "Zhicong Cheng",
      "Dawei Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.11108"
  },
  {
    "id": "arXiv:2105.13094",
    "title": "Rethinking Grid-Forming and Grid-Following Inverters: A Duality Theory",
    "abstract": "Rethinking Grid-Forming and Grid-Following Inverters: A Duality Theory",
    "descriptor": "",
    "authors": [
      "Yitong Li",
      "Yunjie Gu",
      "Timothy C. Green"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13094"
  },
  {
    "id": "arXiv:2105.14888",
    "title": "An Exploratory Analysis of the Relation Between Offensive Language and  Mental Health",
    "abstract": "Comments: Accepted to Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    "descriptor": "\nComments: Accepted to Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\n",
    "authors": [
      "Ana-Maria Bucur",
      "Marcos Zampieri",
      "Liviu P. Dinu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14888"
  },
  {
    "id": "arXiv:2105.15082",
    "title": "Exploring Sparse Expert Models and Beyond",
    "abstract": "Comments: 16 pages, 8 figures",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "An Yang",
      "Junyang Lin",
      "Rui Men",
      "Chang Zhou",
      "Le Jiang",
      "Xianyan Jia",
      "Ang Wang",
      "Jie Zhang",
      "Jiamang Wang",
      "Yong Li",
      "Di Zhang",
      "Wei Lin",
      "Lin Qu",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15082"
  },
  {
    "id": "arXiv:2106.00565",
    "title": "Robust and accurate fine-grain power models for embedded systems with no  on-chip PMU",
    "abstract": "Robust and accurate fine-grain power models for embedded systems with no  on-chip PMU",
    "descriptor": "",
    "authors": [
      "Kris Nikov",
      "Marcos Martinez",
      "Simon Wegener",
      "Jose Nunez-Yanez",
      "Zbigniew Chamski",
      "Kyriakos Georgiou",
      "Kerstin Eder"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.00565"
  },
  {
    "id": "arXiv:2106.02992",
    "title": "Distributed Task Allocation in Homogeneous Swarms Using Language Measure  Theory",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Devesh K. Jha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02992"
  },
  {
    "id": "arXiv:2106.03373",
    "title": "Pre-trained Language Model for Web-scale Retrieval in Baidu Search",
    "abstract": "Comments: Accepted by KDD 2021",
    "descriptor": "\nComments: Accepted by KDD 2021\n",
    "authors": [
      "Yiding Liu",
      "Guan Huang",
      "Jiaxiang Liu",
      "Weixue Lu",
      "Suqi Cheng",
      "Yukun Li",
      "Daiting Shi",
      "Shuaiqiang Wang",
      "Zhicong Cheng",
      "Dawei Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.03373"
  },
  {
    "id": "arXiv:2106.05397",
    "title": "From inexact optimization to learning via gradient concentration",
    "abstract": "From inexact optimization to learning via gradient concentration",
    "descriptor": "",
    "authors": [
      "Bernhard Stankewitz",
      "Nicole M\u00fccke",
      "Lorenzo Rosasco"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.05397"
  },
  {
    "id": "arXiv:2106.05444",
    "title": "Multiplicative perturbation bounds for the Generalized block Cholesky  downdating problem",
    "abstract": "Comments: There are servals reasons. 1) We need to modify the results of section four for weak multiplication perturbation. 2) the authors list need to change 3) The affiliation needs to change 4) we want to add more numerical example to show our results good 5) We want to add the comparison in section three. 6) There are some errors, we need to solve it first",
    "descriptor": "\nComments: There are servals reasons. 1) We need to modify the results of section four for weak multiplication perturbation. 2) the authors list need to change 3) The affiliation needs to change 4) we want to add more numerical example to show our results good 5) We want to add the comparison in section three. 6) There are some errors, we need to solve it first\n",
    "authors": [
      "Mahvish Samara",
      "Aamir Farooq"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.05444"
  },
  {
    "id": "arXiv:2106.05819",
    "title": "Adversarial Graph Augmentation to Improve Graph Contrastive Learning",
    "abstract": "Comments: link to code is added (this https URL)",
    "descriptor": "\nComments: link to code is added (this https URL)\n",
    "authors": [
      "Susheel Suresh",
      "Pan Li",
      "Cong Hao",
      "Jennifer Neville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05819"
  },
  {
    "id": "arXiv:2106.06445",
    "title": "Coded-InvNet for Resilient Prediction Serving Systems",
    "abstract": "Coded-InvNet for Resilient Prediction Serving Systems",
    "descriptor": "",
    "authors": [
      "Tuan Dinh",
      "Kangwook Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.06445"
  },
  {
    "id": "arXiv:2106.06631",
    "title": "Optimal Counterfactual Explanations in Tree Ensembles",
    "abstract": "Comments: Authors Accepted Manuscript (AAM), to be published in the Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021. Additional typo corrections. Open source code available at this https URL",
    "descriptor": "\nComments: Authors Accepted Manuscript (AAM), to be published in the Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021. Additional typo corrections. Open source code available at this https URL\n",
    "authors": [
      "Axel Parmentier",
      "Thibaut Vidal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.06631"
  },
  {
    "id": "arXiv:2106.07268",
    "title": "FastICARL: Fast Incremental Classifier and Representation Learning with  Efficient Budget Allocation in Audio Sensing Applications",
    "abstract": "Comments: Accepted for publication at INTERSPEECH 2021",
    "descriptor": "\nComments: Accepted for publication at INTERSPEECH 2021\n",
    "authors": [
      "Young D. Kwon",
      "Jagmohan Chauhan",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.07268"
  },
  {
    "id": "arXiv:2106.07428",
    "title": "Audio Attacks and Defenses against AED Systems -- A Practical Study",
    "abstract": "Audio Attacks and Defenses against AED Systems -- A Practical Study",
    "descriptor": "",
    "authors": [
      "Rodrigo dos Santos",
      "Shirin Nilizadeh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.07428"
  },
  {
    "id": "arXiv:2106.08886",
    "title": "Over-and-Under Complete Convolutional RNN for MRI Reconstruction",
    "abstract": "Comments: Accepted to MICCAI 2021",
    "descriptor": "\nComments: Accepted to MICCAI 2021\n",
    "authors": [
      "Pengfei Guo",
      "Jeya Maria Jose Valanarasu",
      "Puyang Wang",
      "Jinyuan Zhou",
      "Shanshan Jiang",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08886"
  },
  {
    "id": "arXiv:2106.09474",
    "title": "Optimising simulations for diphoton production at hadron colliders using  amplitude neural networks",
    "abstract": "Comments: 31 pages, 12 figures, 2 tables",
    "descriptor": "\nComments: 31 pages, 12 figures, 2 tables\n",
    "authors": [
      "Joseph Aylett-Bullock",
      "Simon Badger",
      "Ryan Moodie"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09474"
  },
  {
    "id": "arXiv:2106.09862",
    "title": "Medical Image Analysis on Left Atrial LGE MRI for Atrial Fibrillation  Studies: A Review",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Lei Li",
      "Veronika A. Zimmer",
      "Julia A. Schnabel",
      "Xiahai Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09862"
  },
  {
    "id": "arXiv:2106.10382",
    "title": "Effects of VLSI Circuit Constraints on Temporal-Coding Multilayer  Spiking Neural Networks",
    "abstract": "Comments: corrected typos",
    "descriptor": "\nComments: corrected typos\n",
    "authors": [
      "Yusuke Sakemi",
      "Takashi Morie",
      "Takeo Hosomi",
      "Kazuyuki Aihara"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.10382"
  },
  {
    "id": "arXiv:2106.10745",
    "title": "Calliar: An Online Handwritten Dataset for Arabic Calligraphy",
    "abstract": "Calliar: An Online Handwritten Dataset for Arabic Calligraphy",
    "descriptor": "",
    "authors": [
      "Zaid Alyafeai",
      "Maged S. Al-shaibani",
      "Mustafa Ghaleb",
      "Yousif Ahmed Al-Wajih"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10745"
  },
  {
    "id": "arXiv:2106.10814",
    "title": "On Simple Mechanisms for Dependent Items",
    "abstract": "On Simple Mechanisms for Dependent Items",
    "descriptor": "",
    "authors": [
      "Yang Cai",
      "Argyris Oikonomou"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.10814"
  },
  {
    "id": "arXiv:2106.11160",
    "title": "Effects of boundary conditions in fully convolutional networks for  learning spatio-temporal dynamics",
    "abstract": "Comments: 17 pages, 8 figures, submitted to ECML PKDD 2021 Conference",
    "descriptor": "\nComments: 17 pages, 8 figures, submitted to ECML PKDD 2021 Conference\n",
    "authors": [
      "Antonio Alguacil",
      "Gon\u00e7alves Pinto",
      "Michael Bauerheim",
      "Marc C. Jacob",
      "St\u00e9phane Moreau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2106.11160"
  },
  {
    "id": "arXiv:2106.11372",
    "title": "First Approximation for Uniform Lower and Upper Bounded Facility  Location Problem avoiding violation in Lower Bounds",
    "abstract": "First Approximation for Uniform Lower and Upper Bounded Facility  Location Problem avoiding violation in Lower Bounds",
    "descriptor": "",
    "authors": [
      "Sapna Grover",
      "Neelima Gupta",
      "Rajni Dabas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.11372"
  },
  {
    "id": "arXiv:2106.11456",
    "title": "Querying in the Age of Graph Databases and Knowledge Graphs",
    "abstract": "Querying in the Age of Graph Databases and Knowledge Graphs",
    "descriptor": "",
    "authors": [
      "Marcelo Arenas",
      "Claudio Gutierrez",
      "Juan F. Sequeda"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11456"
  },
  {
    "id": "arXiv:2106.11740",
    "title": "LV-BERT: Exploiting Layer Variety for BERT",
    "abstract": "Comments: Accepted to Findings of ACL 2021. The code and pre-trained models are available at this https URL",
    "descriptor": "\nComments: Accepted to Findings of ACL 2021. The code and pre-trained models are available at this https URL\n",
    "authors": [
      "Weihao Yu",
      "Zihang Jiang",
      "Fei Chen",
      "Qibin Hou",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11740"
  },
  {
    "id": "arXiv:2106.11808",
    "title": "Fully CMOS-compatible passive TiO2-based memristor crossbars for  in-memory computing",
    "abstract": "Comments: 14 pages, 4 figures in main text, 2 figures in SI",
    "descriptor": "\nComments: 14 pages, 4 figures in main text, 2 figures in SI\n",
    "authors": [
      "Abdelouadoud El Mesoudy",
      "Gw\u00e9na\u00eblle Lamri",
      "Rapha\u00ebl Dawant",
      "Javier Arias-Zapata",
      "Pierre Gliech",
      "Yann Beilliard",
      "Serge Ecoffey",
      "Andreas Ruediger",
      "Fabien Alibart",
      "Dominique Drouin"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.11808"
  },
  {
    "id": "arXiv:2106.11891",
    "title": "On the Evaluation of Machine Translation for Terminology Consistency",
    "abstract": "Comments: preprint",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Md Mahfuz ibn Alam",
      "Antonios Anastasopoulos",
      "Laurent Besacier",
      "James Cross",
      "Matthias Gall\u00e9",
      "Philipp Koehn",
      "Vassilina Nikoulina"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11891"
  },
  {
    "id": "arXiv:2106.12011",
    "title": "P2T: Pyramid Pooling Transformer for Scene Understanding",
    "abstract": "P2T: Pyramid Pooling Transformer for Scene Understanding",
    "descriptor": "",
    "authors": [
      "Yu-Huan Wu",
      "Yun Liu",
      "Xin Zhan",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.12011"
  },
  {
    "id": "arXiv:2106.12312",
    "title": "Calibrating the Lee-Carter and the Poisson Lee-Carter models via Neural  Networks",
    "abstract": "Calibrating the Lee-Carter and the Poisson Lee-Carter models via Neural  Networks",
    "descriptor": "",
    "authors": [
      "Salvatore Scognamiglio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12312"
  },
  {
    "id": "arXiv:2106.12372",
    "title": "Real-time Neural Radiance Caching for Path Tracing",
    "abstract": "Comments: To appear at SIGGRAPH 2021. 16 pages, 16 figures",
    "descriptor": "\nComments: To appear at SIGGRAPH 2021. 16 pages, 16 figures\n",
    "authors": [
      "Thomas M\u00fcller",
      "Fabrice Rousselle",
      "Jan Nov\u00e1k",
      "Alexander Keller"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12372"
  },
  {
    "id": "arXiv:2106.12435",
    "title": "Existence of dissipative solutions to the compressible Navier-Stokes  system with potential temperature transport",
    "abstract": "Existence of dissipative solutions to the compressible Navier-Stokes  system with potential temperature transport",
    "descriptor": "",
    "authors": [
      "M\u00e1ria Luk\u00e1\u010dov\u00e1-Medvid'ov\u00e1",
      "Andreas Sch\u00f6mer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.12435"
  },
  {
    "id": "arXiv:2106.12481",
    "title": "Decentralized Spatial-Temporal Trajectory Planning for Multicopter  Swarms",
    "abstract": "Comments: A technical report from FAST Lab, Zhejiang University. (v2 update: fixed a mistake in equation 6)",
    "descriptor": "\nComments: A technical report from FAST Lab, Zhejiang University. (v2 update: fixed a mistake in equation 6)\n",
    "authors": [
      "Xin Zhou",
      "Zhepei Wang",
      "Xiangyong Wen",
      "Jiangchao Zhu",
      "Chao Xu",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.12481"
  },
  {
    "id": "arXiv:2106.12496",
    "title": "Threaded Code Generation with a Meta-tracing JIT Compiler",
    "abstract": "Comments: In Proceedings of ICOOLPS '21: Workshop on Implementation, Compilation, Optimization of OO Languages, Programs and Systems (ICOOOLPS '21)",
    "descriptor": "\nComments: In Proceedings of ICOOLPS '21: Workshop on Implementation, Compilation, Optimization of OO Languages, Programs and Systems (ICOOOLPS '21)\n",
    "authors": [
      "Yusuke Izawa",
      "Hidehiko Masuhara",
      "Carl Friedrich Bolz-Tereick",
      "Youyou Cong"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.12496"
  },
  {
    "id": "arXiv:2106.12699",
    "title": "Distilling the Knowledge from Normalizing Flows",
    "abstract": "Comments: ICML Workshop: INNF+2021 (Spotlight)",
    "descriptor": "\nComments: ICML Workshop: INNF+2021 (Spotlight)\n",
    "authors": [
      "Dmitry Baranchuk",
      "Vladimir Aliev",
      "Artem Babenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12699"
  },
  {
    "id": "arXiv:2106.12700",
    "title": "Bidding via Clustering Ads Intentions: an Efficient Search Engine  Marketing System for E-commerce",
    "abstract": "Bidding via Clustering Ads Intentions: an Efficient Search Engine  Marketing System for E-commerce",
    "descriptor": "",
    "authors": [
      "Cheng Jie",
      "Da Xu",
      "Zigeng Wang",
      "Lu Wang",
      "Wei Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.12700"
  },
  {
    "id": "arXiv:2106.12735",
    "title": "Multi-Modal 3D Object Detection in Autonomous Driving: a Survey",
    "abstract": "Multi-Modal 3D Object Detection in Autonomous Driving: a Survey",
    "descriptor": "",
    "authors": [
      "Yingjie Wang",
      "Qiuyu Mao",
      "Hanqi Zhu",
      "Yu Zhang",
      "Jianmin Ji",
      "Yanyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.12735"
  },
  {
    "id": "arXiv:2106.12950",
    "title": "Learning Multiple Stock Trading Patterns with Temporal Routing Adaptor  and Optimal Transport",
    "abstract": "Comments: Accepted by KDD 2021 (research track)",
    "descriptor": "\nComments: Accepted by KDD 2021 (research track)\n",
    "authors": [
      "Hengxu Lin",
      "Dong Zhou",
      "Weiqing Liu",
      "Jiang Bian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.12950"
  },
  {
    "id": "arXiv:2106.12958",
    "title": "Self-Supervised Monocular Depth Estimation of Untextured Indoor Rotated  Scenes",
    "abstract": "Comments: Added references for related works section",
    "descriptor": "\nComments: Added references for related works section\n",
    "authors": [
      "Benjamin Keltjens",
      "Tom van Dijk",
      "Guido de Croon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12958"
  },
  {
    "id": "arXiv:2106.13082",
    "title": "On the relationship between predictive coding and backpropagation",
    "abstract": "On the relationship between predictive coding and backpropagation",
    "descriptor": "",
    "authors": [
      "Robert Rosenbaum"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.13082"
  },
  {
    "id": "arXiv:2106.13203",
    "title": "When Differential Privacy Meets Interpretability: A Case Study",
    "abstract": "Comments: 4 pages, 7 figures; Extended abstract presented at RCV-CVPR'21",
    "descriptor": "\nComments: 4 pages, 7 figures; Extended abstract presented at RCV-CVPR'21\n",
    "authors": [
      "Rakshit Naidu",
      "Aman Priyanshu",
      "Aadith Kumar",
      "Sasikanth Kotti",
      "Haofan Wang",
      "Fatemehsadat Mireshghallah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.13203"
  }
]
[
  {
    "id": "arXiv:2106.09719",
    "title": "Machining Cycle Time Prediction: Data-driven Modelling of Machine Tool  Feedrate Behavior with Neural Networks",
    "abstract": "Accurate prediction of machining cycle times is important in the\nmanufacturing industry. Usually, Computer Aided Manufacturing (CAM) software\nestimates the machining times using the commanded feedrate from the toolpath\nfile using basic kinematic settings. Typically, the methods do not account for\ntoolpath geometry or toolpath tolerance and therefore under estimate the\nmachining cycle times considerably. Removing the need for machine specific\nknowledge, this paper presents a data-driven feedrate and machining cycle time\nprediction method by building a neural network model for each machine tool\naxis. In this study, datasets composed of the commanded feedrate, nominal\nacceleration, toolpath geometry and the measured feedrate were used to train a\nneural network model. Validation trials using a representative industrial thin\nwall structure component on a commercial machining centre showed that this\nmethod estimated the machining time with more than 90% accuracy. This method\nshowed that neural network models have the capability to learn the behavior of\na complex machine tool system and predict cycle times. Further integration of\nthe methods will be critical in the implantation of digital twins in Industry\n4.0.",
    "descriptor": "",
    "authors": [
      "Chao Sun",
      "Javier Dominguez-Caballero",
      "Rob Ward",
      "Sabino Ayvar-Soberanis",
      "David Curtis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09719"
  },
  {
    "id": "arXiv:2106.09748",
    "title": "DeepLab2: A TensorFlow Library for Deep Labeling",
    "abstract": "DeepLab2 is a TensorFlow library for deep labeling, aiming to provide a\nstate-of-the-art and easy-to-use TensorFlow codebase for general dense pixel\nprediction problems in computer vision. DeepLab2 includes all our recently\ndeveloped DeepLab model variants with pretrained checkpoints as well as model\ntraining and evaluation code, allowing the community to reproduce and further\nimprove upon the state-of-art systems. To showcase the effectiveness of\nDeepLab2, our Panoptic-DeepLab employing Axial-SWideRNet as network backbone\nachieves 68.0% PQ or 83.5% mIoU on Cityscaspes validation set, with only\nsingle-scale inference and ImageNet-1K pretrained checkpoints. We hope that\npublicly sharing our library could facilitate future research on dense pixel\nlabeling tasks and envision new applications of this technology. Code is made\npublicly available at \\url{https://github.com/google-research/deeplab2}.",
    "descriptor": "\nComments: 4-page technical report. The first three authors contributed equally to this work\n",
    "authors": [
      "Mark Weber",
      "Huiyu Wang",
      "Siyuan Qiao",
      "Jun Xie",
      "Maxwell D. Collins",
      "Yukun Zhu",
      "Liangzhe Yuan",
      "Dahun Kim",
      "Qihang Yu",
      "Daniel Cremers",
      "Laura Leal-Taixe",
      "Alan L. Yuille",
      "Florian Schroff",
      "Hartwig Adam",
      "Liang-Chieh Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09748"
  },
  {
    "id": "arXiv:2106.09749",
    "title": "Optimizing robotic swarm based construction tasks",
    "abstract": "Social insects in nature such as ants, termites and bees construct their\ncolonies collaboratively in a very efficient process. In these swarms, each\ninsect contributes to the construction task individually showing redundant and\nparallel behavior of individual entities. But the robotics adaptations of these\nswarm's behaviors haven't yet made it to the real world at a large enough scale\nof commonly being used due to the limitations in the existing approaches to the\nswarm robotics construction. This paper presents an approach that combines the\nexisting swarm construction approaches which results in a swarm robotic system,\ncapable of constructing a given 2 dimensional shape in an optimized manner.",
    "descriptor": "\nComments: 4 pages, 3 figures, submitted to 2021 7th International Conference on Control, Automation and Robotics (ICCAR) Singapore\n",
    "authors": [
      "Teshan Liyanage",
      "Subha Fernando"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.09749"
  },
  {
    "id": "arXiv:2106.09754",
    "title": "Towards Real-Time Routing Optimization with Deep Reinforcement Learning:  Open Challenges",
    "abstract": "The digital transformation is pushing the existing network technologies\ntowards new horizons, enabling new applications (e.g., vehicular networks). As\na result, the networking community has seen a noticeable increase in the\nrequirements of emerging network applications. One main open challenge is the\nneed to accommodate control systems to highly dynamic network scenarios.\nNowadays, existing network optimization technologies do not meet the needed\nrequirements to effectively operate in real time. Some of them are based on\nhand-crafted heuristics with limited performance and adaptability, while some\ntechnologies use optimizers which are often too time-consuming. Recent advances\nin Deep Reinforcement Learning (DRL) have shown a dramatic improvement in\ndecision-making and automated control problems. Consequently, DRL represents a\npromising technique to efficiently solve a variety of relevant network\noptimization problems, such as online routing. In this paper, we explore the\nuse of state-of-the-art DRL technologies for real-time routing optimization and\noutline some relevant open challenges to achieve production-ready DRL-based\nsolutions.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Paul Almasan",
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Bo Wu",
      "Shihan Xiao",
      "Pere Barlet-Ros",
      "Albert Cabellos-Aparicio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.09754"
  },
  {
    "id": "arXiv:2106.09756",
    "title": "PyKale: Knowledge-Aware Machine Learning from Multiple Sources in Python",
    "abstract": "Machine learning is a general-purpose technology holding promises for many\ninterdisciplinary research problems. However, significant barriers exist in\ncrossing disciplinary boundaries when most machine learning tools are developed\nin different areas separately. We present Pykale - a Python library for\nknowledge-aware machine learning on graphs, images, texts, and videos to enable\nand accelerate interdisciplinary research. We formulate new green machine\nlearning guidelines based on standard software engineering practices and\npropose a novel pipeline-based application programming interface (API). PyKale\nfocuses on leveraging knowledge from multiple sources for accurate and\ninterpretable prediction, thus supporting multimodal learning and transfer\nlearning (particularly domain adaptation) with latest deep learning and\ndimensionality reduction models. We build PyKale on PyTorch and leverage the\nrich PyTorch ecosystem. Our pipeline-based API design enforces standardization\nand minimalism, embracing green machine learning concepts via reducing\nrepetitions and redundancy, reusing existing resources, and recycling learning\nmodels across areas. We demonstrate its interdisciplinary nature via examples\nin bioinformatics, knowledge graph, image/video recognition, and medical\nimaging.",
    "descriptor": "\nComments: This library is available at this https URL\n",
    "authors": [
      "Haiping Lu",
      "Xianyuan Liu",
      "Robert Turner",
      "Peizhen Bai",
      "Raivo E Koot",
      "Shuo Zhou",
      "Mustafa Chasmai",
      "Lawrence Schobs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09756"
  },
  {
    "id": "arXiv:2106.09757",
    "title": "CIRA Guide to Custom Loss Functions for Neural Networks in Environmental  Sciences -- Version 1",
    "abstract": "Neural networks are increasingly used in environmental science applications.\nFurthermore, neural network models are trained by minimizing a loss function,\nand it is crucial to choose the loss function very carefully for environmental\nscience applications, as it determines what exactly is being optimized.\nStandard loss functions do not cover all the needs of the environmental\nsciences, which makes it important for scientists to be able to develop their\nown custom loss functions so that they can implement many of the classic\nperformance measures already developed in environmental science, including\nmeasures developed for spatial model verification. However, there are very few\nresources available that cover the basics of custom loss function development\ncomprehensively, and to the best of our knowledge none that focus on the needs\nof environmental scientists. This document seeks to fill this gap by providing\na guide on how to write custom loss functions targeted toward environmental\nscience applications. Topics include the basics of writing custom loss\nfunctions, common pitfalls, functions to use in loss functions, examples such\nas fractions skill score as loss function, how to incorporate physical\nconstraints, discrete and soft discretization, and concepts such as focal,\nrobust, and adaptive loss. While examples are currently provided in this guide\nfor Python with Keras and the TensorFlow backend, the basic concepts also apply\nto other environments, such as Python with PyTorch. Similarly, while the sample\nloss functions provided here are from meteorology, these are just examples of\nhow to create custom loss functions. Other fields in the environmental sciences\nhave very similar needs for custom loss functions, e.g., for evaluating spatial\nforecasts effectively, and the concepts discussed here can be applied there as\nwell. All code samples are provided in a GitHub repository.",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Imme Ebert-Uphoff",
      "Ryan Lagerquist",
      "Kyle Hilburn",
      "Yoonjin Lee",
      "Katherine Haynes",
      "Jason Stock",
      "Christina Kumler",
      "Jebb Q. Stewart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.09757"
  },
  {
    "id": "arXiv:2106.09758",
    "title": "Discovering Relationships between Object Categories via Universal  Canonical Maps",
    "abstract": "We tackle the problem of learning the geometry of multiple categories of\ndeformable objects jointly. Recent work has shown that it is possible to learn\na unified dense pose predictor for several categories of related objects.\nHowever, training such models requires to initialize inter-category\ncorrespondences by hand. This is suboptimal and the resulting models fail to\nmaintain correct correspondences as individual categories are learned. In this\npaper, we show that improved correspondences can be learned automatically as a\nnatural byproduct of learning category-specific dense pose predictors. To do\nthis, we express correspondences between different categories and between\nimages and categories using a unified embedding. Then, we use the latter to\nenforce two constraints: symmetric inter-category cycle consistency and a new\nasymmetric image-to-category cycle consistency. Without any manual annotations\nfor the inter-category correspondences, we obtain state-of-the-art alignment\nresults, outperforming dedicated methods for matching 3D shapes. Moreover, the\nnew model is also better at the task of dense pose prediction than prior work.",
    "descriptor": "\nComments: Accepted at CVPR 2021; Project page: this https URL\n",
    "authors": [
      "Natalia Neverova",
      "Artsiom Sanakoyeu",
      "Patrick Labatut",
      "David Novotny",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09758"
  },
  {
    "id": "arXiv:2106.09761",
    "title": "Unsupervised Resource Allocation with Graph Neural Networks",
    "abstract": "We present an approach for maximizing a global utility function by learning\nhow to allocate resources in an unsupervised way. We expect interactions\nbetween allocation targets to be important and therefore propose to learn the\nreward structure for near-optimal allocation policies with a GNN. By relaxing\nthe resource constraint, we can employ gradient-based optimization in contrast\nto more standard evolutionary algorithms. Our algorithm is motivated by a\nproblem in modern astronomy, where one needs to select-based on limited initial\ninformation-among $10^9$ galaxies those whose detailed measurement will lead to\noptimal inference of the composition of the universe. Our technique presents a\nway of flexibly learning an allocation strategy by only requiring forward\nsimulators for the physics of interest and the measurement process. We\nanticipate that our technique will also find applications in a range of\nresource allocation problems.",
    "descriptor": "\nComments: Accepted to PMLR/contributed oral at NeurIPS 2020 Pre-registration Workshop. Code at this https URL\n",
    "authors": [
      "Miles Cranmer",
      "Peter Melchior",
      "Brian Nord"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09761"
  },
  {
    "id": "arXiv:2106.09763",
    "title": "Sensory Modality Mapping for Game Adaptation and Design",
    "abstract": "In this paper we examine methods for taking game-related information provided\nin one sensory modality and transforming it to another sensor modality in order\nto more effectively accommodate sensory-constrained players. We then consider\nmethods for the adaptation and design of games for which gameplay interactions\nare constrained to a subset of sensory modalities in ways that preserve a\ncommon level of novelty-of-experience for players with different sensory\ncapabilities. It is hoped that improved shared experiences can promote\ninteractions among a more diverse spectrum of players.",
    "descriptor": "",
    "authors": [
      "Jeffrey Uhlmann"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.09763"
  },
  {
    "id": "arXiv:2106.09764",
    "title": "Autoencoder-based cleaning in probabilistic databases",
    "abstract": "In the field of data integration, data quality problems are often encountered\nwhen extracting, combining, and merging data. The probabilistic data\nintegration approach represents information about such problems as\nuncertainties in a probabilistic database. In this paper, we propose a\ndata-cleaning autoencoder capable of near-automatic data quality improvement.\nIt learns the structure and dependencies in the data to identify and correct\ndoubtful values. A theoretical framework is provided, and experiments show that\nit can remove significant amounts of noise from categorical and numeric\nprobabilistic data. Our method does not require clean data. We do, however,\nshow that manually cleaning a small fraction of the data significantly improves\nperformance.",
    "descriptor": "\nComments: Submitted to ACM Journal of Data and Information Quality, Special Issue on Deep Learning for Data Quality\n",
    "authors": [
      "R.R. Mauritz",
      "F.P.J. Nijweide",
      "J. Goseling",
      "M. van Keulen"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09764"
  },
  {
    "id": "arXiv:2106.09766",
    "title": "On Use of the Moore-Penrose Pseudoinverse for Evaluating the RGA of  Non-Square Systems",
    "abstract": "A recently-derived alternative method for computing the relative gain array\n(RGA) for singular and/or non-square systems has been proposed that provably\nguarantees unit invariance. This property is not offered by the conventional\nmethod that uses the Moore-Penrose (MP) pseudoinverse. In this paper we note\nthat the absence of the scale-invariance property by the conventional MP-RGA\ndoes not necessarily imply a practical disadvantage in real-world applications.\nIn other words, while it is true that performance of a controller should not\ndepend on the choice of units on its input and output variables, this does not\n{\\em necessarily} imply that the resulting MP-RGA measures of component\ninteraction lead to different controller-design input-output pairings. In this\npaper we consider the application of the MP-RGA to a realistic system (a Sakai\nfractional distillation system) to assess whether or not the choice of unit,\nwhich in this case relates to temperature, affects the choice of input-output\npairings determined by the resulting RGA matrix. Our results show that it does,\nthus confirming that unit-sensitivity of the MP-RGA undermines its rigorous use\nfor MIMO controller design.",
    "descriptor": "",
    "authors": [
      "Rafal Qasim Al Yousuf",
      "Jeffrey Uhlmann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09766"
  },
  {
    "id": "arXiv:2106.09770",
    "title": "Is Channel Estimation Necessary to Select Phase-Shifts for RIS-Assisted  Massive MIMO?",
    "abstract": "Reconfigurable intelligent surfaces (RISs) have attracted great attention as\na potential beyond 5G technology. These surfaces consist of many passive\nelements of metamaterials whose impedance can be controllable to change the\ncharacteristics of wireless signals impinging on them. Channel estimation is a\ncritical task when it comes to the control of a large RIS when having a channel\nwith a large number of multipath components. In this paper, we propose novel\nchannel estimation schemes for different RIS-assisted massive multiple-input\nmultiple-output (MIMO) configurations. The proposed methods exploit spatial\ncorrelation characteristics at both the base station and the planar RISs, and\nother statistical characteristics of multi-specular fading in a mobile\nenvironment. Moreover, a novel heuristic for phase-shift selection at the RISs\nis developed. For the RIS-assisted massive MIMO, a new receive combining method\nand a fixed-point algorithm, which solves the max-min fairness power control\noptimally, are proposed. Simulation results demonstrate that the proposed\nuplink RIS-aided framework improves the spectral efficiency of the cell-edge\nmobile user equipments substantially in comparison to a conventional\nsingle-cell massive MIMO system. The impact of several channel effects are\nstudied to gain insight about which RIS configuration is preferable and when\nthe channel estimation is necessary to boost the spectral efficiency.",
    "descriptor": "\nComments: 30 pages, 9 figures, submitted to IEEE Journal\n",
    "authors": [
      "\u00d6zlem Tu\u011ffe Demir",
      "Emil Bj\u00f6rnson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.09770"
  },
  {
    "id": "arXiv:2106.09775",
    "title": "An Information Retrieval Approach to Building Datasets for Hate Speech  Detection",
    "abstract": "Building a benchmark dataset for hate speech detection presents several\nchallenges. Firstly, because hate speech is relatively rare -- e.g., less than\n3\\% of Twitter posts are hateful \\citep{founta2018large} -- random sampling of\ntweets to annotate is inefficient in capturing hate speech. A common practice\nis to only annotate tweets containing known ``hate words'', but this risks\nyielding a biased benchmark that only partially captures the real-world\nphenomenon of interest. A second challenge is that definitions of hate speech\ntend to be highly variable and subjective. Annotators having diverse prior\nnotions of hate speech may not only disagree with one another but also struggle\nto conform to specified labeling guidelines. Our key insight is that the rarity\nand subjectivity of hate speech are akin to that of relevance in information\nretrieval (IR). This connection suggests that well-established methodologies\nfor creating IR test collections might also be usefully applied to create\nbetter benchmark datasets for hate speech detection. Firstly, to intelligently\nand efficiently select which tweets to annotate, we apply established IR\ntechniques of {\\em pooling} and {\\em active learning}. Secondly, to improve\nboth consistency and value of annotations, we apply {\\em task decomposition}\n\\cite{Zhang-sigir14} and {\\em annotator rationale} \\cite{mcdonnell16-hcomp}\ntechniques. Using the above techniques, we create and share a new benchmark\ndataset\\footnote{We will release the dataset upon publication.} for hate speech\ndetection with broader coverage than prior datasets. We also show a dramatic\ndrop in accuracy of existing detection models when tested on these broader\nforms of hate. Collected annotator rationales not only provide documented\nsupport for labeling decisions but also create exciting future work\nopportunities for dual-supervision and/or explanation generation in modeling.",
    "descriptor": "\nComments: 10 pages (Under review in CIKM 2021)\n",
    "authors": [
      "Md Mustafizur Rahman",
      "Dinesh Balakrishnan",
      "Dhiraj Murthy",
      "Mucahid Kutlu",
      "Matthew Lease"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.09775"
  },
  {
    "id": "arXiv:2106.09776",
    "title": "Adapting the Function Approximation Architecture in Online Reinforcement  Learning",
    "abstract": "The performance of a reinforcement learning (RL) system depends on the\ncomputational architecture used to approximate a value function. Deep learning\nmethods provide both optimization techniques and architectures for\napproximating nonlinear functions from noisy, high-dimensional observations.\nHowever, prevailing optimization techniques are not designed for\nstrictly-incremental online updates. Nor are standard architectures designed\nfor observations with an a priori unknown structure: for example, light sensors\nrandomly dispersed in space. This paper proposes an online RL prediction\nalgorithm with an adaptive architecture that efficiently finds useful nonlinear\nfeatures. The algorithm is evaluated in a spatial domain with high-dimensional,\nstochastic observations. The algorithm outperforms non-adaptive baseline\narchitectures and approaches the performance of an architecture given\nside-channel information. These results are a step towards scalable RL\nalgorithms for more general problems, where the observation structure is not\navailable.",
    "descriptor": "",
    "authors": [
      "John D. Martin",
      "Joseph Modayil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09776"
  },
  {
    "id": "arXiv:2106.09777",
    "title": "On Invariance Penalties for Risk Minimization",
    "abstract": "The Invariant Risk Minimization (IRM) principle was first proposed by\nArjovsky et al. [2019] to address the domain generalization problem by\nleveraging data heterogeneity from differing experimental conditions.\nSpecifically, IRM seeks to find a data representation under which an optimal\nclassifier remains invariant across all domains. Despite the conceptual appeal\nof IRM, the effectiveness of the originally proposed invariance penalty has\nrecently been brought into question. In particular, there exists\ncounterexamples for which that invariance penalty can be arbitrarily small for\nnon-invariant data representations. We propose an alternative invariance\npenalty by revisiting the Gramian matrix of the data representation. We discuss\nthe role of its eigenvalues in the relationship between the risk and the\ninvariance penalty, and demonstrate that it is ill-conditioned for said\ncounterexamples. The proposed approach is guaranteed to recover an invariant\nrepresentation for linear settings under mild non-degeneracy conditions. Its\neffectiveness is substantiated by experiments on DomainBed and\nInvarianceUnitTest, two extensive test beds for domain generalization.",
    "descriptor": "",
    "authors": [
      "Kia Khezeli",
      "Arno Blaas",
      "Frank Soboczenski",
      "Nicholas Chia",
      "John Kalantari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09777"
  },
  {
    "id": "arXiv:2106.09779",
    "title": "Locally Differentially Private Federated Learning: Efficient Algorithms  with Tight Risk Bounds",
    "abstract": "Federated learning (FL) is a distributed learning paradigm in which many\nclients with heterogeneous, unbalanced, and often sensitive local data,\ncollaborate to learn a model. Local Differential Privacy (LDP) provides a\nstrong guarantee that each client's data cannot be leaked during and after\ntraining, without relying on a trusted third party. While LDP is often believed\nto be too stringent to allow for satisfactory utility, our paper challenges\nthis belief. We consider a general setup with unbalanced, heterogeneous data,\ndisparate privacy needs across clients, and unreliable communication, where a\nrandom number/subset of clients is available each round. We propose three LDP\nalgorithms for smooth (strongly) convex FL; each are noisy variations of\ndistributed minibatch SGD. One is accelerated and one involves novel\ntime-varying noise, which we use to obtain the first non-trivial LDP excess\nrisk bound for the fully general non-i.i.d. FL problem. Specializing to i.i.d.\nclients, our risk bounds interpolate between the best known and/or optimal\nbounds in the centralized setting and the cross-device setting, where each\nclient represents just one person's data. Furthermore, we show that in certain\nregimes, our convergence rate (nearly) matches the corresponding non-private\nlower bound or outperforms state of the art non-private algorithms (``privacy\nfor free''). Finally, we validate our theoretical results and illustrate the\npractical utility of our algorithm with numerical experiments.",
    "descriptor": "",
    "authors": [
      "Andrew Lowy",
      "Meisam Razaviyayn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09779"
  },
  {
    "id": "arXiv:2106.09782",
    "title": "Calculation of chemical reactions in electrophoresis",
    "abstract": "The main goal of the work is to find stationary solutions of the equations of\nchemical kinematics for mixtures of complex composition. According to the given\nresearch goal the system of nonlinear equations for determining the equilibria\nof reversible chemical dissociation reactions was obtained and transformed in\nthe work, an algorithm for solving the problem for tris-borate mixture was\ncreated and tested, allowing to calculate the pH of the solution taking into\naccount the ionic force at given concentrations of the initial reagents of the\nmixture, as well as to process the results.",
    "descriptor": "",
    "authors": [
      "T. A. Petrukhina",
      "M. Yu. Zhukov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09782"
  },
  {
    "id": "arXiv:2106.09785",
    "title": "Efficient Self-supervised Vision Transformers for Representation  Learning",
    "abstract": "This paper investigates two techniques for developing efficient\nself-supervised vision transformers (EsViT) for visual representation learning.\nFirst, we show through a comprehensive empirical study that multi-stage\narchitectures with sparse self-attentions can significantly reduce modeling\ncomplexity but with a cost of losing the ability to capture fine-grained\ncorrespondences between image regions. Second, we propose a new pre-training\ntask of region matching which allows the model to capture fine-grained region\ndependencies and as a result significantly improves the quality of the learned\nvision representations. Our results show that combining the two techniques,\nEsViT achieves 81.3% top-1 on the ImageNet linear probe evaluation,\noutperforming prior arts with around an order magnitude of higher throughput.\nWhen transferring to downstream linear classification tasks, EsViT outperforms\nits supervised counterpart on 17 out of 18 datasets. The code and models will\nbe publicly available.",
    "descriptor": "\nComments: 24 pages, 12 figures, file size 13.6MB\n",
    "authors": [
      "Chunyuan Li",
      "Jianwei Yang",
      "Pengchuan Zhang",
      "Mei Gao",
      "Bin Xiao",
      "Xiyang Dai",
      "Lu Yuan",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09785"
  },
  {
    "id": "arXiv:2106.09787",
    "title": "Comparing the behavior of OpenMP Implementations with various  Applications on two different Fujitsu A64FX platforms",
    "abstract": "The development of the A64FX processor by Fujitsu has been a massive\ninnovation in vectorized processors and led to Fugaku: the current world's\nfastest supercomputer. We use a variety of tools to analyze the behavior and\nperformance of several OpenMP applications with different compilers, and how\nthese applications scale on the different A64FX processors on clusters at Stony\nBrook University and RIKEN.",
    "descriptor": "",
    "authors": [
      "Benjamin Michalowicz",
      "Eric Raut",
      "Yan Kang",
      "Tony Curtis",
      "Barbara Chapman",
      "Dossay Oryspayev"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2106.09787"
  },
  {
    "id": "arXiv:2106.09788",
    "title": "Guided Integrated Gradients: An Adaptive Path Method for Removing Noise",
    "abstract": "Integrated Gradients (IG) is a commonly used feature attribution method for\ndeep neural networks. While IG has many desirable properties, the method often\nproduces spurious/noisy pixel attributions in regions that are not related to\nthe predicted class when applied to visual models. While this has been\npreviously noted, most existing solutions are aimed at addressing the symptoms\nby explicitly reducing the noise in the resulting attributions. In this work,\nwe show that one of the causes of the problem is the accumulation of noise\nalong the IG path. To minimize the effect of this source of noise, we propose\nadapting the attribution path itself -- conditioning the path not just on the\nimage but also on the model being explained. We introduce Adaptive Path Methods\n(APMs) as a generalization of path methods, and Guided IG as a specific\ninstance of an APM. Empirically, Guided IG creates saliency maps better aligned\nwith the model's prediction and the input image that is being explained. We\nshow through qualitative and quantitative experiments that Guided IG\noutperforms other, related methods in nearly every experiment.",
    "descriptor": "\nComments: 13 pages, 11 figures, for implementation sources see this https URL\n",
    "authors": [
      "Andrei Kapishnikov",
      "Subhashini Venugopalan",
      "Besim Avci",
      "Ben Wedin",
      "Michael Terry",
      "Tolga Bolukbasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09788"
  },
  {
    "id": "arXiv:2106.09789",
    "title": "Topological Indoor Mapping through WiFi Signals",
    "abstract": "The ubiquitous presence of WiFi access points and mobile devices capable of\nmeasuring WiFi signal strengths allow for real-world applications in indoor\nlocalization and mapping. In particular, no additional infrastructure is\nrequired. Previous approaches in this field were, however, often hindered by\nproblems such as effortful map-building processes, changing environments and\nhardware differences. We tackle these problems focussing on topological maps.\nThese represent discrete locations, such as rooms, and their relations, e.g.,\ndistances and transition frequencies. In our unsupervised method, we employ\nWiFi signal strength distributions, dimension reduction and clustering. It can\nbe used in settings where users carry mobile devices and follow their normal\nroutine. We aim for applications in short-lived indoor events such as\nconferences.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Bastian Schaefermeier",
      "Gerd Stumme",
      "Tom Hanika"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.09789"
  },
  {
    "id": "arXiv:2106.09790",
    "title": "Multi-Task Learning and Adapted Knowledge Models for Emotion-Cause  Extraction",
    "abstract": "Detecting what emotions are expressed in text is a well-studied problem in\nnatural language processing. However, research on finer grained emotion\nanalysis such as what causes an emotion is still in its infancy. We present\nsolutions that tackle both emotion recognition and emotion cause detection in a\njoint fashion. Considering that common-sense knowledge plays an important role\nin understanding implicitly expressed emotions and the reasons for those\nemotions, we propose novel methods that combine common-sense knowledge via\nadapted knowledge models with multi-task learning to perform joint emotion\nclassification and emotion cause tagging. We show performance improvement on\nboth tasks when including common-sense reasoning and a multitask framework. We\nprovide a thorough analysis to gain insights into model performance.",
    "descriptor": "\nComments: 15 pages, 6 figures. Findings of ACL 2021\n",
    "authors": [
      "Elsbeth Turcan",
      "Shuai Wang",
      "Rishita Anubhai",
      "Kasturi Bhattacharjee",
      "Yaser Al-Onaizan",
      "Smaranda Muresan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09790"
  },
  {
    "id": "arXiv:2106.09794",
    "title": "A Distance-based Separability Measure for Internal Cluster Validation",
    "abstract": "To evaluate clustering results is a significant part of cluster analysis.\nSince there are no true class labels for clustering in typical unsupervised\nlearning, many internal cluster validity indices (CVIs), which use predicted\nlabels and data, have been created. Without true labels, to design an effective\nCVI is as difficult as to create a clustering method. And it is crucial to have\nmore CVIs because there are no universal CVIs that can be used to measure all\ndatasets and no specific methods of selecting a proper CVI for clusters without\ntrue labels. Therefore, to apply a variety of CVIs to evaluate clustering\nresults is necessary. In this paper, we propose a novel internal CVI -- the\nDistance-based Separability Index (DSI), based on a data separability measure.\nWe compared the DSI with eight internal CVIs including studies from early Dunn\n(1974) to most recent CVDD (2019) and an external CVI as ground truth, by using\nclustering results of five clustering algorithms on 12 real and 97 synthetic\ndatasets. Results show DSI is an effective, unique, and competitive CVI to\nother compared CVIs. We also summarized the general process to evaluate CVIs\nand created the rank-difference metric for comparison of CVIs' results.",
    "descriptor": "\nComments: It is an extended version of the paper: arXiv:2009.01328\n",
    "authors": [
      "Shuyue Guan",
      "Murray Loew"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.09794"
  },
  {
    "id": "arXiv:2106.09795",
    "title": "LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking",
    "abstract": "Entity linking (EL), the task of disambiguating mentions in text by linking\nthem to entities in a knowledge graph, is crucial for text understanding,\nquestion answering or conversational systems. Entity linking on short text\n(e.g., single sentence or question) poses particular challenges due to limited\ncontext. While prior approaches use either heuristics or black-box neural\nmethods, here we propose LNN-EL, a neuro-symbolic approach that combines the\nadvantages of using interpretable rules based on first-order logic with the\nperformance of neural learning. Even though constrained to using rules, LNN-EL\nperforms competitively against SotA black-box neural approaches, with the added\nbenefits of extensibility and transferability. In particular, we show that we\ncan easily blend existing rule templates given by a human expert, with multiple\ntypes of features (priors, BERT encodings, box embeddings, etc), and even\nscores resulting from previous EL methods, thus improving on such methods. For\ninstance, on the LC-QuAD-1.0 dataset, we show more than $4$\\% increase in F1\nscore over previous SotA. Finally, we show that the inductive bias offered by\nusing logic results in learned rules that transfer well across datasets, even\nwithout fine tuning, while maintaining high accuracy.",
    "descriptor": "\nComments: Accepted to ACL 2021\n",
    "authors": [
      "Hang Jiang",
      "Sairam Gurajada",
      "Qiuhao Lu",
      "Sumit Neelam",
      "Lucian Popa",
      "Prithviraj Sen",
      "Yunyao Li",
      "Alexander Gray"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2106.09795"
  },
  {
    "id": "arXiv:2106.09799",
    "title": "Introducing PathQuery, Google's Graph Query Language",
    "abstract": "We introduce PathQuery, a graph query language developed to scale with\nGoogle's query and data volumes as well as its internal developer community.\nPathQuery supports flexible and declarative semantics. We have found that this\nenables query developers to think in a naturally \"graphy\" design space and to\navoid the additional cognitive effort of coordinating numerous joins and\nsubqueries often required to express an equivalent query in a relational space.\nDespite its traversal-oriented syntactic style, PathQuery has a foundation on a\ncustom variant of relational algebra -- the exposition of which we presently\ndefer -- allowing for the application of both common and novel optimizations.\nWe believe that PathQuery has withstood a \"test of time\" at Google, under both\nlarge scale and low latency requirements. We thus share herein a language\ndesign that admits a rigorous declarative semantics, has scaled well in\npractice, and provides a natural syntax for graph traversals while also\nadmitting complex graph patterns.",
    "descriptor": "",
    "authors": [
      "Jesse Weaver",
      "Eric Paniagua",
      "Tushar Agarwal",
      "Nicholas Guy",
      "Alexandre Mattos"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.09799"
  },
  {
    "id": "arXiv:2106.09802",
    "title": "Intentional Forgetting",
    "abstract": "Many damaging cybersecurity attacks are enabled when an attacker can access\nresidual sensitive information (e.g. cryptographic keys, personal identifiers)\nleft behind from earlier computation. Attackers can sometimes use residual\ninformation to take control of a system, impersonate a user, or manipulate\ndata. Current approaches to addressing access to residual sensitive information\naim to patch individual software or hardware vulnerabilities. While such\npatching approaches are necessary to mitigate sometimes serious security\nvulnerabilities in the near term, they cannot address the underlying issue:\nexplicit requirements for adequately eliminating residual information and\nexplicit representations of the erasure capabilities of systems are necessary\nto ensure that sensitive information is handled as expected.\nThis position paper introduces the concept of intentional forgetting and the\ncapabilities that are needed to achieve it. Intentional forgetting enables\nsoftware and hardware system designers at every level of abstraction to clearly\nspecify and rigorously reason about the forgetting capabilities required of and\nprovided by a system. We identify related work that may help to illuminate\nchallenges or contribute to solutions and consider conceptual and engineering\ntradeoffs in implementations of forgetting capabilities. We discuss approaches\nto modeling intentional forgetting and then modeling the strength of a system's\nforgetting capability by its resistance to disclosing information to different\ntypes of detectors. Research is needed in a variety of domains to advance the\ntheory, specification techniques, system foundations, implementation tools, and\nmethodologies for effective, practical forgetting. We highlight research\nchallenges in several domains and encourage cross-disciplinary collaboration to\none day create a robust theory and practice of intentional forgetting.",
    "descriptor": "",
    "authors": [
      "Deborah Shands",
      "Carolyn Talcott"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09802"
  },
  {
    "id": "arXiv:2106.09805",
    "title": "Shuffle Private Stochastic Convex Optimization",
    "abstract": "In shuffle privacy, each user sends a collection of randomized messages to a\ntrusted shuffler, the shuffler randomly permutes these messages, and the\nresulting shuffled collection of messages must satisfy differential privacy.\nPrior work in this model has largely focused on protocols that use a single\nround of communication to compute algorithmic primitives like means,\nhistograms, and counts. In this work, we present interactive shuffle protocols\nfor stochastic convex optimization. Our optimization protocols rely on a new\nnoninteractive protocol for summing vectors of bounded $\\ell_2$ norm. By\ncombining this sum subroutine with techniques including mini-batch stochastic\ngradient descent, accelerated gradient descent, and Nesterov's smoothing\nmethod, we obtain loss guarantees for a variety of convex loss functions that\nsignificantly improve on those of the local model and sometimes match those of\nthe central model.",
    "descriptor": "",
    "authors": [
      "Albert Cheu",
      "Matthew Joseph",
      "Jieming Mao",
      "Binghui Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.09805"
  },
  {
    "id": "arXiv:2106.09806",
    "title": "Error bounds for Lanczos-based matrix function approximation",
    "abstract": "We analyze the Lanczos method for matrix function approximation (Lanczos-FA),\nan iterative algorithm for computing $f(\\mathbf{A}) \\mathbf{b}$ when\n$\\mathbf{A}$ is a Hermitian matrix and $\\mathbf{b}$ is a given mathbftor.\nAssuming that $f : \\mathbb{C} \\rightarrow \\mathbb{C}$ is piecewise analytic, we\ngive a framework, based on the Cauchy integral formula, which can be used to\nderive {\\em a priori} and \\emph{a posteriori} error bounds for Lanczos-FA in\nterms of the error of Lanczos used to solve linear systems. Unlike many error\nbounds for Lanczos-FA, these bounds account for fine-grained properties of the\nspectrum of $\\mathbf{A}$, such as clustered or isolated eigenvalues. Our\nresults are derived assuming exact arithmetic, but we show that they are easily\nextended to finite precision computations using existing theory about the\nLanczos algorithm in finite precision. We also provide generalized bounds for\nthe Lanczos method used to approximate quadratic forms $\\mathbf{b}^\\textsf{H}\nf(\\mathbf{A}) \\mathbf{b}$, and demonstrate the effectiveness of our bounds with\nnumerical experiments.",
    "descriptor": "",
    "authors": [
      "Tyler Chen",
      "Anne Greenbaum",
      "Cameron Musco",
      "Christopher Musco"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09806"
  },
  {
    "id": "arXiv:2106.09812",
    "title": "Deep reinforcement learning with automated label extraction from  clinical reports accurately classifies 3D MRI brain volumes",
    "abstract": "Purpose: Image classification is perhaps the most fundamental task in imaging\nAI. However, labeling images is time-consuming and tedious. We have recently\ndemonstrated that reinforcement learning (RL) can classify 2D slices of MRI\nbrain images with high accuracy. Here we make two important steps toward\nspeeding image classification: Firstly, we automatically extract class labels\nfrom the clinical reports. Secondly, we extend our prior 2D classification work\nto fully 3D image volumes from our institution. Hence, we proceed as follows:\nin Part 1, we extract labels from reports automatically using the SBERT natural\nlanguage processing approach. Then, in Part 2, we use these labels with RL to\ntrain a classification Deep-Q Network (DQN) for 3D image volumes.\nMethods: For Part 1, we trained SBERT with 90 radiology report impressions.\nWe then used the trained SBERT to predict class labels for use in Part 2. In\nPart 2, we applied multi-step image classification to allow for combined Deep-Q\nlearning using 3D convolutions and TD(0) Q learning. We trained on a set of 90\nimages. We tested on a separate set of 61 images, again using the classes\npredicted from patient reports by the trained SBERT in Part 1. For comparison,\nwe also trained and tested a supervised deep learning classification network on\nthe same set of training and testing images using the same labels.\nResults: Part 1: Upon training with the corpus of radiology reports, the\nSBERT model had 100% accuracy for both normal and metastasis-containing scans.\nPart 2: Then, using these labels, whereas the supervised approach quickly\noverfit the training data and as expected performed poorly on the testing set\n(66% accuracy, just over random guessing), the reinforcement learning approach\nachieved an accuracy of 92%. The results were found to be statistically\nsignificant, with a p-value of 3.1 x 10^-5.",
    "descriptor": "",
    "authors": [
      "Joseph Stember",
      "Hrithwik Shalu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09812"
  },
  {
    "id": "arXiv:2106.09814",
    "title": "PixInWav: Residual Steganography for Hiding Pixels in Audio",
    "abstract": "Steganography comprises the mechanics of hiding data in a host media that may\nbe publicly available. While previous works focused on unimodal setups (e.g.,\nhiding images in images, or hiding audio in audio), PixInWav targets the\nmultimodal case of hiding images in audio. To this end, we propose a novel\nresidual architecture operating on top of short-time discrete cosine transform\n(STDCT) audio spectrograms. Among our results, we find that the residual audio\nsteganography setup we propose allows independent encoding of the hidden image\nfrom the host audio without compromising quality. Accordingly, while previous\nworks require both host and hidden signals to hide a signal, PixInWav can\nencode images offline -- which can be later hidden, in a residual fashion, into\nany audio signal. Finally, we test our scheme in a lab setting to transmit\nimages over airwaves from a loudspeaker to a microphone verifying our\ntheoretical insights and obtaining promising results.",
    "descriptor": "\nComments: Extended abstract presented in CVPR 2021 Women in Computer Vision Workshop\n",
    "authors": [
      "Margarita Geleta",
      "Cristina Punti",
      "Kevin McGuinness",
      "Jordi Pons",
      "Cristian Canton",
      "Xavier Giro-i-Nieto"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.09814"
  },
  {
    "id": "arXiv:2106.09816",
    "title": "Degree Tables for Secure Distributed Matrix Multiplication",
    "abstract": "We consider the problem of secure distributed matrix multiplication (SDMM) in\nwhich a user wishes to compute the product of two matrices with the assistance\nof honest but curious servers. We construct polynomial codes for SDMM by\nstudying a recently introduced combinatorial tool called the degree table. For\na fixed partitioning, minimizing the total communication cost of a polynomial\ncode for SDMM is equivalent to minimizing $N$, the number of distinct elements\nin the corresponding degree table.\nWe propose new constructions of degree tables with a low number of distinct\nelements. These new constructions lead to a general family of polynomial codes\nfor SDMM, which we call $\\mathsf{GASP}_{r}$ (Gap Additive Secure Polynomial\ncodes) parametrized by an integer $r$. $\\mathsf{GASP}_{r}$ outperforms all\npreviously known polynomial codes for SDMM under an outer product partitioning.\nWe also present lower bounds on $N$ and prove the optimality or asymptotic\noptimality of our constructions for certain regimes. Moreover, we formulate the\nconstruction of optimal degree tables as an integer linear program and use it\nto prove the optimality of $\\mathsf{GASP}_{r}$ for all the system parameters\nthat we were able to test.",
    "descriptor": "",
    "authors": [
      "Rafael G. L. D'Oliveira",
      "Salim El Rouayheb",
      "Daniel Heinlein",
      "David Karpuk"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.09816"
  },
  {
    "id": "arXiv:2106.09820",
    "title": "Adversarial Detection Avoidance Attacks: Evaluating the robustness of  perceptual hashing-based client-side scanning",
    "abstract": "End-to-end encryption (E2EE) by messaging platforms enable people to securely\nand privately communicate with one another. Its widespread adoption however\nraised concerns that illegal content might now be shared undetected. Following\nthe global pushback against key escrow systems, client-side scanning based on\nperceptual hashing has been recently proposed by governments and researchers to\ndetect illegal content in E2EE communications. We here propose the first\nframework to evaluate the robustness of perceptual hashing-based client-side\nscanning to detection avoidance attacks and show current systems to not be\nrobust. More specifically, we propose three adversarial attacks -- a general\nblack-box attack and two white-box attacks for discrete cosine-based-based\nalgorithms -- against perceptual hashing algorithms. In a large-scale\nevaluation, we show perceptual hashing-based client-side scanning mechanisms to\nbe highly vulnerable to detection avoidance attacks in a black-box setting,\nwith more than 99.9% of images successfully attacked while preserving the\ncontent of the image. We furthermore show our attack to generate diverse\nperturbations, strongly suggesting that straightforward mitigation strategies\nwould be ineffective. Finally, we show that the larger thresholds necessary to\nmake the attack harder would probably require more than one billion images to\nbe flagged and decrypted daily, raising strong privacy concerns.Taken together,\nour results shed serious doubts on the robustness of perceptual hashing-based\nclient-side scanning mechanisms currently proposed by governments,\norganizations, and researchers around the world.",
    "descriptor": "",
    "authors": [
      "Shubham Jain",
      "Ana-Maria Cretu",
      "Yves-Alexandre de Montjoye"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09820"
  },
  {
    "id": "arXiv:2106.09821",
    "title": "Generalized Learning Vector Quantization for Classification in  Randomized Neural Networks and Hyperdimensional Computing",
    "abstract": "Machine learning algorithms deployed on edge devices must meet certain\nresource constraints and efficiency requirements. Random Vector Functional Link\n(RVFL) networks are favored for such applications due to their simple design\nand training efficiency. We propose a modified RVFL network that avoids\ncomputationally expensive matrix operations during training, thus expanding the\nnetwork's range of potential applications. Our modification replaces the\nleast-squares classifier with the Generalized Learning Vector Quantization\n(GLVQ) classifier, which only employs simple vector and distance calculations.\nThe GLVQ classifier can also be considered an improvement upon certain\nclassification algorithms popularly used in the area of Hyperdimensional\nComputing. The proposed approach achieved state-of-the-art accuracy on a\ncollection of datasets from the UCI Machine Learning Repository - higher than\npreviously proposed RVFL networks. We further demonstrate that our approach\nstill achieves high accuracy while severely limited in training iterations\n(using on average only 21% of the least-squares classifier computational\ncosts).",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Cameron Diao",
      "Denis Kleyko",
      "Jan M. Rabaey",
      "Bruno A. Olshausen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09821"
  },
  {
    "id": "arXiv:2106.09825",
    "title": "Many Agent Reinforcement Learning Under Partial Observability",
    "abstract": "Recent renewed interest in multi-agent reinforcement learning (MARL) has\ngenerated an impressive array of techniques that leverage deep reinforcement\nlearning, primarily actor-critic architectures, and can be applied to a limited\nrange of settings in terms of observability and communication. However, a\ncontinuing limitation of much of this work is the curse of dimensionality when\nit comes to representations based on joint actions, which grow exponentially\nwith the number of agents. In this paper, we squarely focus on this challenge\nof scalability. We apply the key insight of action anonymity, which leads to\npermutation invariance of joint actions, to two recently presented deep MARL\nalgorithms, MADDPG and IA2C, and compare these instantiations to another recent\ntechnique that leverages action anonymity, viz., mean-field MARL. We show that\nour instantiations can learn the optimal behavior in a broader class of agent\nnetworks than the mean-field method, using a recently introduced pragmatic\ndomain.",
    "descriptor": "",
    "authors": [
      "Keyang He",
      "Prashant Doshi",
      "Bikramjit Banerjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.09825"
  },
  {
    "id": "arXiv:2106.09826",
    "title": "Intrusion Detection and Localization for Networked Embedded Control  Systems",
    "abstract": "Closed-loop control systems employ continuous sensing and actuation to\nmaintain controlled variables within preset bounds and achieve the desired\nsystem output. Intentional disturbances in the system, such as in the case of\ncyberattacks, can compromise reachability of control goals, and in several\ncases jeopardize safety. The increasing connectivity and exposure of networked\ncontrol to external networks has enabled attackers to compromise these systems\nby exploiting security vulnerabilities. Attacks against safety-critical control\nloops can not only drive the system over a trajectory different from the\ndesired, but also cause fatal consequences to humans. In this paper we present\na physics-based Intrusion Detection System (IDS) aimed at increasing the\nsecurity in control systems. In addition to conventional process state\nestimation for intrusion detection, since the controller cannot be trusted, we\nintroduce a controller state estimator. Additionally, we make our detector\ncontext-aware by utilizing sensor measurements from other control loops, which\nallows to distinguish and characterize disturbances from attacks. We introduce\nadaptive thresholding and adaptive filtering as means to achieve\ncontext-awareness. Together, these methodologies allow detection and\nlocalization of attacks in closed-loop controls. Finally, we demonstrate\nfeasibility of the approach by mounting a series of attacks against a networked\nDirect Current (DC) motor closed-loop speed control deployed on an ECU testbed,\nas well as on a simulated automated lane keeping system. Among other\napplication domains, this set of approaches is key to support security in\nautomotive systems, and ultimately increase road and passenger safety.",
    "descriptor": "\nComments: Embedded Security in Cars (ESCAR) USA 2021\n",
    "authors": [
      "Vuk Lesi",
      "Marcio Juliato",
      "Shabbir Ahmed",
      "Christopher Gutierrez",
      "Qian Wang",
      "Manoj Sastry"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09826"
  },
  {
    "id": "arXiv:2106.09830",
    "title": "Faster Sparse Matrix Inversion and Rank Computation in Finite Fields",
    "abstract": "We improve the current best running time value to invert sparse matrices over\nfinite fields, lowering it to an expected $O\\big(n^{2.2131}\\big)$ time for the\ncurrent values of fast rectangular matrix multiplication. We achieve the same\nrunning time for the computation of the rank and nullspace of a sparse matrix\nover a finite field. This improvement relies on two key techniques. First, we\nadopt the decomposition of an arbitrary matrix into block Krylov and Hankel\nmatrices from Eberly et al. (ISSAC 2007). Second, we show how to recover the\nexplicit inverse of a block Hankel matrix using low displacement rank\ntechniques for structured matrices and fast rectangular matrix multiplication\nalgorithms. We generalize our inversion method to block structured matrices\nwith other displacement operators and strengthen the best known upper bounds\nfor explicit inversion of block Toeplitz-like and block Hankel-like matrices,\nas well as for explicit inversion of block Vandermonde-like matrices with\nstructured blocks. As a further application, we improve the complexity of\nseveral algorithms in topological data analysis and in finite group theory.",
    "descriptor": "",
    "authors": [
      "S\u00edlvia Casacuberta",
      "Rasmus Kyng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Symbolic Computation (cs.SC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09830"
  },
  {
    "id": "arXiv:2106.09831",
    "title": "On Effects of Compression with Hyperdimensional Computing in Distributed  Randomized Neural Networks",
    "abstract": "A change of the prevalent supervised learning techniques is foreseeable in\nthe near future: from the complex, computational expensive algorithms to more\nflexible and elementary training ones. The strong revitalization of randomized\nalgorithms can be framed in this prospect steering. We recently proposed a\nmodel for distributed classification based on randomized neural networks and\nhyperdimensional computing, which takes into account cost of information\nexchange between agents using compression. The use of compression is important\nas it addresses the issues related to the communication bottleneck, however,\nthe original approach is rigid in the way the compression is used. Therefore,\nin this work, we propose a more flexible approach to compression and compare it\nto conventional compression algorithms, dimensionality reduction, and\nquantization techniques.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Antonello Rosato",
      "Massimo Panella",
      "Evgeny Osipov",
      "Denis Kleyko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.09831"
  },
  {
    "id": "arXiv:2106.09835",
    "title": "Dual-Teacher Class-Incremental Learning With Data-Free Generative Replay",
    "abstract": "This paper proposes two novel knowledge transfer techniques for\nclass-incremental learning (CIL). First, we propose data-free generative replay\n(DF-GR) to mitigate catastrophic forgetting in CIL by using synthetic samples\nfrom a generative model. In the conventional generative replay, the generative\nmodel is pre-trained for old data and shared in extra memory for later\nincremental learning. In our proposed DF-GR, we train a generative model from\nscratch without using any training data, based on the pre-trained\nclassification model from the past, so we curtail the cost of sharing\npre-trained generative models. Second, we introduce dual-teacher information\ndistillation (DT-ID) for knowledge distillation from two teachers to one\nstudent. In CIL, we use DT-ID to learn new classes incrementally based on the\npre-trained model for old classes and another model (pre-)trained on the new\ndata for new classes. We implemented the proposed schemes on top of one of the\nstate-of-the-art CIL methods and showed the performance improvement on\nCIFAR-100 and ImageNet datasets.",
    "descriptor": "\nComments: CVPR 2021 Workshop on Continual Learning in Computer Vision (CLVision)\n",
    "authors": [
      "Yoojin Choi",
      "Mostafa El-Khamy",
      "Jungwon Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.09835"
  },
  {
    "id": "arXiv:2106.09837",
    "title": "Future Ultra-Dense LEO Satellite Networks: A Cell-Free Massive MIMO  Approach",
    "abstract": "Low Earth orbit (LEO) satellite networks (SatNets) are envisioned to play a\ncrucial role in providing global and ubiquitous connectivity efficiently.\nAccordingly, in the coming years, thousands of LEO satellites will be launched\nto create ultradense LEO mega-constellations, and the Third Generation\nPartnership Project (3GPP) is working on evolving fifth-generation (5G) systems\nto support such non-terrestrial networks (NTN). However, many challenges are\nassociated with the deployment of LEOs from communications and networking\nperspectives. In this paper, we propose a novel cell-free massive\nmultiple-input multiple-output (CF-mMIMO) based architecture for future\nultra-dense LEO SatNets. We discuss various aspects of network design, such as\nduplexing mode, pilot assignment, beamforming, and handover management. In\naddition, we propose a joint optimization framework for the power allocation\nand handover management processes to maximize the network throughput and\nminimize the handover rate while ensuring quality-of-service (QoS) satisfaction\nfor users. To the best of our knowledge, this is the first work to introduce\nand study CF-mMIMO-based LEO SatNets. Extensive simulation results demonstrate\nthe superior performance of the proposed architecture and solutions compared to\nthose of conventional single-satellite connectivity and handover techniques\nfrom the literature.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Mohammed Y. Abdelsadek",
      "Halim Yanikomeroglu",
      "Gunes Karabulut Kurt"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09837"
  },
  {
    "id": "arXiv:2106.09841",
    "title": "Enabling Security-Oriented Orchestration of Microservices",
    "abstract": "As cloud providers push multi-tenancy to new levels to meet growing\nscalability demands, ensuring that externally developed untrusted microservices\nwill preserve tenant isolation has become a high priority. Developers, in turn,\nlack a means for expressing and automatically enforcing high-level application\nsecurity requirements at deployment time. In this paper, we observe that\norchestration systems are ideally situated between developers and the cloud\nprovider to address these issues. We propose a security policy framework that\nenables security-oriented orchestration of microservices by capturing and\nauditing code properties that are incorporated into microservice code\nthroughout the software supply chain. Orchestrators can leverage these\nproperties to deploy microservices on a node that matches both the developer's\nand cloud provider's security policy and their resource requirements. We\ndemonstrate our approach with a proof-of-concept based on the Private Data\nObjects [1] confidential smart contract framework, deploying code only after\nchecking its provenance.",
    "descriptor": "",
    "authors": [
      "Marcela S. Melara",
      "Mic Bowman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09841"
  },
  {
    "id": "arXiv:2106.09843",
    "title": "Hardware-Enforced Integrity and Provenance for Distributed Code  Deployments",
    "abstract": "Deployed microservices must adhere to a multitude of application-level\nsecurity requirements and regulatory constraints imposed by mutually\ndistrusting application principals--software developers, cloud providers, and\neven data owners. Although these principals wish to enforce their individual\nsecurity requirements, they do not currently have a common way of easily\nidentifying, expressing and automatically enforcing these requirements at\ndeployment time. CDI (Code Deployment Integrity) is a security policy framework\nthat enables distributed application principals to establish trust in deployed\ncode through high-integrity provenance information. We observe that principals\nexpect the software supply chain to preserve certain code security properties\nthroughout the creation of an executable bundle, even if the code is\ntransformed or inspected through various tools (e.g., compilation inserts stack\ncanaries for memory safety). Our key insight in designing CDI is that even if\napplication principals do not trust each other directly, they can trust a\nmicroservice bundle to meet their security policies if they can trust the tools\ninvolved in creating the bundle.",
    "descriptor": "\nComments: 2 pages, NIST Workshop on Enhancing Software Supply Chain Security (2021), see this https URL\n",
    "authors": [
      "Marcela S. Melara",
      "Mic Bowman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09843"
  },
  {
    "id": "arXiv:2106.09844",
    "title": "Conclusion Stability for Natural Language Based Mining of Design  Discussions",
    "abstract": "Developer discussions range from in-person hallway chats to comment chains on\nbug reports. Being able to identify discussions that touch on software design\nwould be helpful in documentation and refactoring software. Design mining is\nthe application of machine learning techniques to correctly label a given\ndiscussion artifact, such as a pull request, as pertaining (or not) to design.\nIn this paper we demonstrate a simple example of how design mining works. We\nthen show how conclusion stability is poor on different artifact types and\ndifferent projects. We show two techniques -- augmentation and context\nspecificity -- that greatly improve the conclusion stability and cross-project\nrelevance of design mining. Our new approach achieves AUC of 0.88 on within\ndataset classification and 0.80 on the cross-dataset classification task.",
    "descriptor": "\nComments: Accepted at Empirical Software Engineering Journal. Replication package at this https URL and this https URL arXiv admin note: substantial text overlap with arXiv:2001.01424\n",
    "authors": [
      "Alvi Mahadi",
      "Neil A. Ernst",
      "Karan Tongay"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.09844"
  },
  {
    "id": "arXiv:2106.09847",
    "title": "Disinformation, Stochastic Harm, and Costly Filtering: A Principal-Agent  Analysis of Regulating Social Media Platforms",
    "abstract": "The spread of disinformation on social media platforms such as Facebook is\nharmful to society. This harm can take the form of a gradual degradation of\npublic discourse; but it can also take the form of sudden dramatic events such\nas the recent insurrection on Capitol Hill. The platforms themselves are in the\nbest position to prevent the spread of disinformation, as they have the best\naccess to relevant data and the expertise to use it. However, filtering\ndisinformation is costly, not only for implementing filtering algorithms or\nemploying manual filtering effort, but also because removing such highly viral\ncontent impacts user growth and thus potential advertising revenue. Since the\ncosts of harmful content are borne by other entities, the platform will\ntherefore have no incentive to filter at a socially-optimal level. This problem\nis similar to the problem of environmental regulation, in which the costs of\nadverse events are not directly borne by a firm, the mitigation effort of a\nfirm is not observable, and the causal link between a harmful consequence and a\nspecific failure is difficult to prove. In the environmental regulation domain,\none solution to this issue is to perform costly monitoring to ensure that the\nfirm takes adequate precautions according a specified rule. However,\nclassifying disinformation is performative, and thus a fixed rule becomes less\neffective over time. Encoding our domain as a Markov decision process, we\ndemonstrate that no penalty based on a static rule, no matter how large, can\nincentivize adequate filtering by the platform. Penalties based on an adaptive\nrule can incentivize optimal effort, but counterintuitively, only if the\nregulator sufficiently overreacts to harmful events by requiring a\ngreater-than-optimal level of filtering.",
    "descriptor": "",
    "authors": [
      "Shehroze Khan",
      "James R. Wright"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2106.09847"
  },
  {
    "id": "arXiv:2106.09848",
    "title": "PAC Prediction Sets Under Covariate Shift",
    "abstract": "An important challenge facing modern machine learning is how to rigorously\nquantify the uncertainty of model predictions. Conveying uncertainty is\nespecially important when there are changes to the underlying data distribution\nthat might invalidate the predictive model. Yet, most existing uncertainty\nquantification algorithms break down in the presence of such shifts. We propose\na novel approach that addresses this challenge by constructing \\emph{probably\napproximately correct (PAC)} prediction sets in the presence of covariate\nshift. Our approach focuses on the setting where there is a covariate shift\nfrom the source distribution (where we have labeled training examples) to the\ntarget distribution (for which we want to quantify uncertainty). Our algorithm\nassumes given importance weights that encode how the probabilities of the\ntraining examples change under the covariate shift. In practice, importance\nweights typically need to be estimated; thus, we extend our algorithm to the\nsetting where we are given confidence intervals for the importance weights\nrather than their true value. We demonstrate the effectiveness of our approach\non various covariate shifts designed based on the DomainNet and ImageNet\ndatasets.",
    "descriptor": "",
    "authors": [
      "Sangdon Park",
      "Edgar Dobriban",
      "Insup Lee",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09848"
  },
  {
    "id": "arXiv:2106.09849",
    "title": "Latency-aware and Survivable Mapping of VNFs in 5G Network Edge Cloud",
    "abstract": "Network Functions Virtualization (NFV) and Multi-access Edge Computing (MEC)\nplay crucial roles in 5G networks for dynamically provisioning diverse\ncommunication services with heterogeneous service requirements. In particular,\nwhile NFV improves flexibility and scalability by softwarizing physical network\nfunctions as Virtual Network Functions (VNFs), MEC enables to provide\ndelay-sensitive/time-critical services by moving computing facilities to the\nnetwork edge. However, these new paradigms introduce challenges in terms of\nlatency, availability, and resource allocation. In this paper, we first explore\nMEC cloud facility location selection and then latency-aware placement of VNFs\nin different selected locations of NFV enabled MEC cloud facilities in order to\nmeet the ultra-low latency requirements of different applications (e.g.,\nTactile Internet, virtual reality, and mission-critical applications).\nFurthermore, we also aim to guarantee the survivability of VNFs and an edge\nserver against failures in resource limited MEC cloud facility due to software\nbugs, configuration faults, etc. To this end, we formulate the problem of\nlatency-aware and survivable mapping of VNFs in different MEC cloud facilities\nas an Integer Linear Programming (ILP) to minimize the overall service\nprovisioning cost, and show that the problem is NP-hard. Owing to the high\ncomputational complexity of solving the ILP, we propose a simulated annealing\nbased heuristic algorithm to obtain near-optimal solution in polynomial time.\nWith extensive simulations, we show the effectiveness of our proposed solution\nin a real-world network topology, which performs close to the optimal solution.",
    "descriptor": "",
    "authors": [
      "Prabhu Kaliyammal Thiruvasagam",
      "Abhishek Chakraborty",
      "C. Siva Ram Murthy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.09849"
  },
  {
    "id": "arXiv:2106.09852",
    "title": "LSEC: Large-scale spectral ensemble clustering",
    "abstract": "Ensemble clustering is a fundamental problem in the machine learning field,\ncombining multiple base clusterings into a better clustering result. However,\nmost of the existing methods are unsuitable for large-scale ensemble clustering\ntasks due to the efficiency bottleneck. In this paper, we propose a large-scale\nspectral ensemble clustering (LSEC) method to strike a good balance between\nefficiency and effectiveness. In LSEC, a large-scale spectral clustering based\nefficient ensemble generation framework is designed to generate various base\nclusterings within a low computational complexity. Then all based clustering\nare combined through a bipartite graph partition based consensus function into\na better consensus clustering result. The LSEC method achieves a lower\ncomputational complexity than most existing ensemble clustering methods.\nExperiments conducted on ten large-scale datasets show the efficiency and\neffectiveness of the LSEC method. The MATLAB code of the proposed method and\nexperimental datasets are available at https://github.com/Li-\nHongmin/MyPaperWithCode.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Hongmin Li",
      "Xiucai Ye",
      "Akira Imakura",
      "Tetsuya Sakurai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09852"
  },
  {
    "id": "arXiv:2106.09857",
    "title": "Effective Model Sparsification by Scheduled Grow-and-Prune Methods",
    "abstract": "Deep neural networks (DNNs) are effective in solving many real-world\nproblems. Larger DNN models usually exhibit better quality (e.g., accuracy) but\ntheir excessive computation results in long training and inference time. Model\nsparsification can reduce the computation and memory cost while maintaining\nmodel quality. Most existing sparsification algorithms unidirectionally remove\nweights, while others randomly or greedily explore a small subset of weights in\neach layer. The inefficiency of the algorithms reduces the achievable sparsity\nlevel. In addition, many algorithms still require pre-trained dense models and\nthus suffer from large memory footprint and long training time. In this paper,\nwe propose a novel scheduled grow-and-prune (GaP) methodology without\npre-training the dense models. It addresses the shortcomings of the previous\nworks by repeatedly growing a subset of layers to dense and then pruning back\nto sparse after some training. Experiments have shown that such models can\nmatch or beat the quality of highly optimized dense models at 80% sparsity on a\nvariety of tasks, such as image classification, objective detection, 3D object\npart segmentation, and translation. They also outperform other state-of-the-art\n(SOTA) pruning methods, including pruning from pre-trained dense models. As an\nexample, a 90% sparse ResNet-50 obtained via GaP achieves 77.9% top-1 accuracy\non ImageNet, improving the SOTA results by 1.5%.",
    "descriptor": "",
    "authors": [
      "Xiaolong Ma",
      "Minghai Qin",
      "Fei Sun",
      "Zejiang Hou",
      "Kun Yuan",
      "Yi Xu",
      "Yanzhi Wang",
      "Yen-Kuang Chen",
      "Rong Jin",
      "Yuan Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.09857"
  },
  {
    "id": "arXiv:2106.09859",
    "title": "RSG: A Simple but Effective Module for Learning Imbalanced Datasets",
    "abstract": "Imbalanced datasets widely exist in practice and area great challenge for\ntraining deep neural models with agood generalization on infrequent classes. In\nthis work, wepropose a new rare-class sample generator (RSG) to solvethis\nproblem. RSG aims to generate some new samplesfor rare classes during training,\nand it has in particularthe following advantages: (1) it is convenient to use\nandhighly versatile, because it can be easily integrated intoany kind of\nconvolutional neural network, and it works wellwhen combined with different\nloss functions, and (2) it isonly used during the training phase, and\ntherefore, no ad-ditional burden is imposed on deep neural networks duringthe\ntesting phase. In extensive experimental evaluations, weverify the\neffectiveness of RSG. Furthermore, by leveragingRSG, we obtain competitive\nresults on Imbalanced CIFARand new state-of-the-art results on Places-LT,\nImageNet-LT, and iNaturalist 2018. The source code is available at\nhttps://github.com/Jianf-Wang/RSG.",
    "descriptor": "\nComments: To appear at CVPR 2021. We propose a flexible data generation/data augmentation module for long-tailed classification. Codes are available at: this https URL\n",
    "authors": [
      "Jianfeng Wang",
      "Thomas Lukasiewicz",
      "Xiaolin Hu",
      "Jianfei Cai",
      "Zhenghua Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09859"
  },
  {
    "id": "arXiv:2106.09862",
    "title": "Medical Image Analysis on Left Atrial LGE MRI for Atrial Fibrillation  Studies: A Review",
    "abstract": "Late gadolinium enhancement magnetic resonance imaging (LGE MRI) is commonly\nused to visualize and quantify left atrial (LA) scars. The position and extent\nof scars provide important information of the pathophysiology and progression\nof atrial fibrillation (AF). Hence, LA scar segmentation and quantification\nfrom LGE MRI can be useful in computer-assisted diagnosis and treatment\nstratification of AF patients. Since manual delineation can be time-consuming\nand subject to intra- and inter-expert variability, automating this computing\nis highly desired, which nevertheless is still challenging and\nunder-researched.\nThis paper aims to provide a systematic review on computing methods for LA\ncavity, wall, scar and ablation gap segmentation and quantification from LGE\nMRI, and the related literature for AF studies. Specifically, we first\nsummarize AF-related imaging techniques, particularly LGE MRI. Then, we review\nthe methodologies of the four computing tasks in detail, and summarize the\nvalidation strategies applied in each task. Finally, the possible future\ndevelopments are outlined, with a brief survey on the potential clinical\napplications of the aforementioned methods. The review shows that the research\ninto this topic is still in early stages. Although several methods have been\nproposed, especially for LA segmentation, there is still large scope for\nfurther algorithmic developments due to performance issues related to the high\nvariability of enhancement appearance and differences in image acquisition.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Lei Li",
      "Veronika A. Zimmer",
      "Julia A. Schnabel",
      "Xiahai Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09862"
  },
  {
    "id": "arXiv:2106.09866",
    "title": "On Minimizing Cost in Legal Document Review Workflows",
    "abstract": "Technology-assisted review (TAR) refers to human-in-the-loop machine learning\nworkflows for document review in legal discovery and other high recall review\ntasks. Attorneys and legal technologists have debated whether review should be\na single iterative process (one-phase TAR workflows) or whether model training\nand review should be separate (two-phase TAR workflows), with implications for\nthe choice of active learning algorithm. The relative cost of manual labeling\nfor different purposes (training vs. review) and of different documents\n(positive vs. negative examples) is a key and neglected factor in this debate.\nUsing a novel cost dynamics analysis, we show analytically and empirically that\nthese relative costs strongly impact whether a one-phase or two-phase workflow\nminimizes cost. We also show how category prevalence, classification task\ndifficulty, and collection size impact the optimal choice not only of workflow\ntype, but of active learning method and stopping point.",
    "descriptor": "\nComments: 10 pages, 3 figures. Accepted at DocEng 21\n",
    "authors": [
      "Eugene Yang",
      "David D. Lewis",
      "Ophir Frieder"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.09866"
  },
  {
    "id": "arXiv:2106.09871",
    "title": "Heuristic Stopping Rules For Technology-Assisted Review",
    "abstract": "Technology-assisted review (TAR) refers to human-in-the-loop active learning\nworkflows for finding relevant documents in large collections. These workflows\noften must meet a target for the proportion of relevant documents found (i.e.\nrecall) while also holding down costs. A variety of heuristic stopping rules\nhave been suggested for striking this tradeoff in particular settings, but none\nhave been tested against a range of recall targets and tasks. We propose two\nnew heuristic stopping rules, Quant and QuantCI based on model-based estimation\ntechniques from survey research. We compare them against a range of proposed\nheuristics and find they are accurate at hitting a range of recall targets\nwhile substantially reducing review costs.",
    "descriptor": "\nComments: 10 pages, 2 figures. Accepted at DocEng 21\n",
    "authors": [
      "Eugene Yang",
      "David D. Lewis",
      "Ophir Frieder"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09871"
  },
  {
    "id": "arXiv:2106.09872",
    "title": "Analyzing Adversarial Robustness of Deep Neural Networks in Pixel Space:  a Semantic Perspective",
    "abstract": "The vulnerability of deep neural networks to adversarial examples, which are\ncrafted maliciously by modifying the inputs with imperceptible perturbations to\nmisled the network produce incorrect outputs, reveals the lack of robustness\nand poses security concerns. Previous works study the adversarial robustness of\nimage classifiers on image level and use all the pixel information in an image\nindiscriminately, lacking of exploration of regions with different semantic\nmeanings in the pixel space of an image. In this work, we fill this gap and\nexplore the pixel space of the adversarial image by proposing an algorithm to\nlooking for possible perturbations pixel by pixel in different regions of the\nsegmented image. The extensive experimental results on CIFAR-10 and ImageNet\nverify that searching for the modified pixel in only some pixels of an image\ncan successfully launch the one-pixel adversarial attacks without requiring all\nthe pixels of the entire image, and there exist multiple vulnerable points\nscattered in different regions of an image. We also demonstrate that the\nadversarial robustness of different regions on the image varies with the amount\nof semantic information contained.",
    "descriptor": "\nComments: 13 pages, 6figures\n",
    "authors": [
      "Lina Wang",
      "Xingshu Chen",
      "Yulong Wang",
      "Yawei Yue",
      "Yi Zhu",
      "Xuemei Zeng",
      "Wei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.09872"
  },
  {
    "id": "arXiv:2106.09874",
    "title": "Towards Clustering-friendly Representations: Subspace Clustering via  Graph Filtering",
    "abstract": "Finding a suitable data representation for a specific task has been shown to\nbe crucial in many applications. The success of subspace clustering depends on\nthe assumption that the data can be separated into different subspaces.\nHowever, this simple assumption does not always hold since the raw data might\nnot be separable into subspaces. To recover the ``clustering-friendly''\nrepresentation and facilitate the subsequent clustering, we propose a graph\nfiltering approach by which a smooth representation is achieved. Specifically,\nit injects graph similarity into data features by applying a low-pass filter to\nextract useful data representations for clustering. Extensive experiments on\nimage and document clustering datasets demonstrate that our method improves\nupon state-of-the-art subspace clustering techniques. Especially, its\ncomparable performance with deep learning methods emphasizes the effectiveness\nof the simple graph filtering scheme for many real-world applications. An\nablation study shows that graph filtering can remove noise, preserve structure\nin the image, and increase the separability of classes.",
    "descriptor": "\nComments: Published in ACM Multimedia 2020\n",
    "authors": [
      "Zhengrui Ma",
      "Zhao Kang",
      "Guangchun Luo",
      "Ling Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09874"
  },
  {
    "id": "arXiv:2106.09875",
    "title": "Smoothed Multi-View Subspace Clustering",
    "abstract": "In recent years, multi-view subspace clustering has achieved impressive\nperformance due to the exploitation of complementary imformation across\nmultiple views. However, multi-view data can be very complicated and are not\neasy to cluster in real-world applications. Most existing methods operate on\nraw data and may not obtain the optimal solution. In this work, we propose a\nnovel multi-view clustering method named smoothed multi-view subspace\nclustering (SMVSC) by employing a novel technique, i.e., graph filtering, to\nobtain a smooth representation for each view, in which similar data points have\nsimilar feature values. Specifically, it retains the graph geometric features\nthrough applying a low-pass filter. Consequently, it produces a\n``clustering-friendly\" representation and greatly facilitates the downstream\nclustering task. Extensive experiments on benchmark datasets validate the\nsuperiority of our approach. Analysis shows that graph filtering increases the\nseparability of classes.",
    "descriptor": "\nComments: Accepted by International Conference on Neural Computing for Advanced Applications 2021\n",
    "authors": [
      "Peng Chen",
      "Liang Liu",
      "Zhengrui Ma",
      "Zhao Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09875"
  },
  {
    "id": "arXiv:2106.09876",
    "title": "Anomaly Detection in Dynamic Graphs via Transformer",
    "abstract": "Detecting anomalies for dynamic graphs has drawn increasing attention due to\ntheir wide applications in social networks, e-commerce, and cybersecurity. The\nrecent deep learning-based approaches have shown promising results over shallow\nmethods. However, they fail to address two core challenges of anomaly detection\nin dynamic graphs: the lack of informative encoding for unattributed nodes and\nthe difficulty of learning discriminate knowledge from coupled spatial-temporal\ndynamic graphs. To overcome these challenges, in this paper, we present a novel\nTransformer-based Anomaly Detection framework for DYnamic graph (TADDY). Our\nframework constructs a comprehensive node encoding strategy to better represent\neach node's structural and temporal roles in an evolving graphs stream.\nMeanwhile, TADDY captures informative representation from dynamic graphs with\ncoupled spatial-temporal patterns via a dynamic graph transformer model. The\nextensive experimental results demonstrate that our proposed TADDY framework\noutperforms the state-of-the-art methods by a large margin on four real-world\ndatasets.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Yixin Liu",
      "Shirui Pan",
      "Yu Guang Wang",
      "Fei Xiong",
      "Liang Wang",
      "Vincent CS Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09876"
  },
  {
    "id": "arXiv:2106.09877",
    "title": "HIFIR: Hybrid Incomplete Factorization with Iterative Refinement for  Preconditioning Ill-conditioned and Singular Systems",
    "abstract": "We introduce a software package called HIFIR for preconditioning sparse,\nunsymmetric, ill-conditioned, and potentially singular systems. HIFIR computes\na hybrid incomplete factorization, which combines multilevel incomplete LU\nfactorization with a truncated, rank-revealing QR factorization on the final\nSchur complement. This novel hybridization is based on the new theory of\napproximate generalized inverse and $\\epsilon$-accuracy. It enables\nnear-optimal preconditioners for consistent systems and enables flexible GMRES\nto solve inconsistent systems when coupled with iterative refinement. In this\npaper, we focus on some practical algorithmic and software issues of HIFIR. In\nparticular, we introduce a new inverse-based rook pivoting into ILU, which\nimproves the robustness and the overall efficiency for some ill-conditioned\nsystems by significantly reducing the size of the final Schur complement for\nsome systems. We also describe the software design of HIFIR in terms of its\nefficient data structures for supporting rook pivoting in a multilevel setting,\nits template-based generic programming interfaces for mixed-precision real and\ncomplex values in C++, and its user-friendly high-level interfaces in MATLAB\nand Python. We demonstrate the effectiveness of HIFIR for ill-conditioned or\nsingular systems arising from several applications, including the Helmholtz\nequation, linear elasticity, stationary incompressible Navier--Stokes\nequations, and time-dependent advection-diffusion equation.",
    "descriptor": "\nComments: Submitted to ACM Transactions on Mathematical Software (TOMS)\n",
    "authors": [
      "Qiao Chen",
      "Xiangmin Jiao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2106.09877"
  },
  {
    "id": "arXiv:2106.09881",
    "title": "Identifying intracity freight trip ends from heavy truck GPS  trajectories",
    "abstract": "Intracity heavy truck freight trips are basic data in city freight system\nplanning and management. In the big data era, massive heavy truck GPS\ntrajectories can be acquired cost effectively in real-time. Identifying freight\ntrip ends (origins and destinations) from heavy truck GPS trajectories is an\noutstanding problem. Although previous studies proposed a variety of trip end\nidentification methods from different perspectives, these studies subjectively\ndefined key threshold parameters and ignored the complex intracity heavy truck\ntravel characteristics. Here, we propose a data-driven trip end identification\nmethod in which the speed threshold for identifying truck stops and the\nmultilevel time thresholds for distinguishing temporary stops and freight trip\nends are objectively defined. Moreover, an appropriate time threshold level is\ndynamically selected by considering the intracity activity patterns of heavy\ntrucks. Furthermore, we use urban road networks and point-of-interest (POI)\ndata to eliminate misidentified trip ends to improve method accuracy. The\nvalidation results show that the accuracy of the method we propose is 87.45%.\nOur method incorporates the impact of the city freight context on truck\ntrajectory characteristics, and its results can reflect the spatial\ndistribution and chain patterns of intracity heavy truck freight trips, which\nhave a wide range of practical applications.",
    "descriptor": "",
    "authors": [
      "Yitao Yanga",
      "Bin Jia",
      "Xiao-Yong Yan",
      "Rui Jiang",
      "Hao Ji",
      "Ziyou Gao"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2106.09881"
  },
  {
    "id": "arXiv:2106.09884",
    "title": "Batch Multi-Fidelity Bayesian Optimization with Deep Auto-Regressive  Networks",
    "abstract": "Bayesian optimization (BO) is a powerful approach for optimizing black-box,\nexpensive-to-evaluate functions. To enable a flexible trade-off between the\ncost and accuracy, many applications allow the function to be evaluated at\ndifferent fidelities. In order to reduce the optimization cost while maximizing\nthe benefit-cost ratio, in this paper, we propose Batch Multi-fidelity Bayesian\nOptimization with Deep Auto-Regressive Networks (BMBO-DARN). We use a set of\nBayesian neural networks to construct a fully auto-regressive model, which is\nexpressive enough to capture strong yet complex relationships across all the\nfidelities, so as to improve the surrogate learning and optimization\nperformance. Furthermore, to enhance the quality and diversity of queries, we\ndevelop a simple yet efficient batch querying method, without any combinatorial\nsearch over the fidelities. We propose a batch acquisition function based on\nMax-value Entropy Search (MES) principle, which penalizes highly correlated\nqueries and encourages diversity. We use posterior samples and moment matching\nto fulfill efficient computation of the acquisition function and conduct\nalternating optimization over every fidelity-input pair, which guarantees an\nimprovement at each step. We demonstrate the advantage of our approach on four\nreal-world hyperparameter optimization applications.",
    "descriptor": "",
    "authors": [
      "Shibo Li",
      "Robert M. Kirby",
      "Shandian Zhe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09884"
  },
  {
    "id": "arXiv:2106.09886",
    "title": "Quantized Neural Networks via {-1, +1} Encoding Decomposition and  Acceleration",
    "abstract": "The training of deep neural networks (DNNs) always requires intensive\nresources for both computation and data storage. Thus, DNNs cannot be\nefficiently applied to mobile phones and embedded devices, which severely\nlimits their applicability in industrial applications. To address this issue,\nwe propose a novel encoding scheme using {-1, +1} to decompose quantized neural\nnetworks (QNNs) into multi-branch binary networks, which can be efficiently\nimplemented by bitwise operations (i.e., xnor and bitcount) to achieve model\ncompression, computational acceleration, and resource saving. By using our\nmethod, users can achieve different encoding precisions arbitrarily according\nto their requirements and hardware resources. The proposed mechanism is highly\nsuitable for the use of FPGA and ASIC in terms of data storage and computation,\nwhich provides a feasible idea for smart chips. We validate the effectiveness\nof our method on large-scale image classification (e.g., ImageNet), object\ndetection, and semantic segmentation tasks. In particular, our method with\nlow-bit encoding can still achieve almost the same performance as its high-bit\ncounterparts.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1905.13389\n",
    "authors": [
      "Qigong Sun",
      "Xiufang Li",
      "Fanhua Shang",
      "Hongying Liu",
      "Kang Yang",
      "Licheng Jiao",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09886"
  },
  {
    "id": "arXiv:2106.09887",
    "title": "Medical Matting: A New Perspective on Medical Segmentation with  Uncertainty",
    "abstract": "In medical image segmentation, it is difficult to mark ambiguous areas\naccurately with binary masks, especially when dealing with small lesions.\nTherefore, it is a challenge for radiologists to reach a consensus by using\nbinary masks under the condition of multiple annotations. However, these areas\nmay contain anatomical structures that are conducive to diagnosis. Uncertainty\nis introduced to study these situations. Nevertheless, the uncertainty is\nusually measured by the variances between predictions in a multiple trial way.\nIt is not intuitive, and there is no exact correspondence in the image.\nInspired by image matting, we introduce matting as a soft segmentation method\nand a new perspective to deal with and represent uncertain regions into medical\nscenes, namely medical matting. More specifically, because there is no\navailable medical matting dataset, we first labeled two medical datasets with\nalpha matte. Secondly, the matting method applied to the natural image is not\nsuitable for the medical scene, so we propose a new architecture to generate\nbinary masks and alpha matte in a row. Thirdly, the uncertainty map is\nintroduced to highlight the ambiguous regions from the binary results and\nimprove the matting performance. Evaluated on these datasets, the proposed\nmodel outperformed state-of-the-art matting algorithms by a large margin, and\nalpha matte is proved to be a more efficient labeling form than a binary mask.",
    "descriptor": "",
    "authors": [
      "Lin Wang",
      "Lie Ju",
      "Donghao Zhang",
      "Xin Wang",
      "Wanji He",
      "Yelin Huang",
      "Zhiwen Yang",
      "Xuan Yao",
      "Xin Zhao",
      "Xiufen Ye",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09887"
  },
  {
    "id": "arXiv:2106.09889",
    "title": "GEM: A General Evaluation Benchmark for Multimodal Tasks",
    "abstract": "In this paper, we present GEM as a General Evaluation benchmark for\nMultimodal tasks. Different from existing datasets such as GLUE, SuperGLUE,\nXGLUE and XTREME that mainly focus on natural language tasks, GEM is a\nlarge-scale vision-language benchmark, which consists of GEM-I for\nimage-language tasks and GEM-V for video-language tasks. Comparing with\nexisting multimodal datasets such as MSCOCO and Flicker30K for image-language\ntasks, YouCook2 and MSR-VTT for video-language tasks, GEM is not only the\nlargest vision-language dataset covering image-language tasks and\nvideo-language tasks at the same time, but also labeled in multiple languages.\nWe also provide two baseline models for this benchmark. We will release the\ndataset, code and baseline models, aiming to advance the development of\nmultilingual multimodal research.",
    "descriptor": "\nComments: Accepted by Findings of ACL 2021\n",
    "authors": [
      "Lin Su",
      "Nan Duan",
      "Edward Cui",
      "Lei Ji",
      "Chenfei Wu",
      "Huaishao Luo",
      "Yongfei Liu",
      "Ming Zhong",
      "Taroon Bharti",
      "Arun Sacheti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.09889"
  },
  {
    "id": "arXiv:2106.09890",
    "title": "Gradual Domain Adaptation via Self-Training of Auxiliary Models",
    "abstract": "Domain adaptation becomes more challenging with increasing gaps between\nsource and target domains. Motivated from an empirical analysis on the\nreliability of labeled source data for the use of distancing target domains, we\npropose self-training of auxiliary models (AuxSelfTrain) that learns models for\nintermediate domains and gradually combats the distancing shifts across\ndomains. We introduce evolving intermediate domains as combinations of\ndecreasing proportion of source data and increasing proportion of target data,\nwhich are sampled to minimize the domain distance between consecutive domains.\nThen the source model could be gradually adapted for the use in the target\ndomain by self-training of auxiliary models on evolving intermediate domains.\nWe also introduce an enhanced indicator for sample selection via implicit\nensemble and extend the proposed method to semi-supervised domain adaptation.\nExperiments on benchmark datasets of unsupervised and semi-supervised domain\nadaptation verify its efficacy.",
    "descriptor": "\nComments: code will be released at: this https URL\n",
    "authors": [
      "Yabin Zhang",
      "Bin Deng",
      "Kui Jia",
      "Lei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09890"
  },
  {
    "id": "arXiv:2106.09894",
    "title": "Development of a conversing and body temperature scanning autonomously  navigating robot to help screen for COVID-19",
    "abstract": "Throughout the COVID-19 pandemic, the most common symptom displayed by\npatients has been a fever, leading to the use of temperature scanning as a\npreemptive measure to detect potential carriers of the virus. Human employees\nwith handheld thermometers have been used to fulfill this task, however this\nputs them at risk as they cannot be physically distanced and the sequential\nnature of this method leads to great inconveniences and inefficiency. The\nproposed solution is an autonomously navigating robot capable of conversing and\nscanning people's temperature to detect fevers and help screen for COVID-19. To\nsatisfy this objective, the robot must be able to (1) navigate autonomously,\n(2) detect and track people, and (3) get individuals' temperature reading and\nconverse with them if it exceeds 38{\\deg}C. An autonomously navigating mobile\nrobot is used with a manipulator controlled using a face tracking algorithm,\nand an end effector consisting of a thermal camera, smartphone, and chatbot.\nThe goal is to develop a functioning solution that performs the above tasks. In\naddition, technical challenges encountered and their engineering solutions will\nbe presented, and recommendations will be made for enhancements that could be\nincorporated when approaching commercialization.",
    "descriptor": "",
    "authors": [
      "Ryan Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.09894"
  },
  {
    "id": "arXiv:2106.09895",
    "title": "PRGC: Potential Relation and Global Correspondence Based Joint  Relational Triple Extraction",
    "abstract": "Joint extraction of entities and relations from unstructured texts is a\ncrucial task in information extraction. Recent methods achieve considerable\nperformance but still suffer from some inherent limitations, such as redundancy\nof relation prediction, poor generalization of span-based extraction and\ninefficiency. In this paper, we decompose this task into three subtasks,\nRelation Judgement, Entity Extraction and Subject-object Alignment from a novel\nperspective and then propose a joint relational triple extraction framework\nbased on Potential Relation and Global Correspondence (PRGC). Specifically, we\ndesign a component to predict potential relations, which constrains the\nfollowing entity extraction to the predicted relation subset rather than all\nrelations; then a relation-specific sequence tagging component is applied to\nhandle the overlapping problem between subjects and objects; finally, a global\ncorrespondence component is designed to align the subject and object into a\ntriple with low-complexity. Extensive experiments show that PRGC achieves\nstate-of-the-art performance on public benchmarks with higher efficiency and\ndelivers consistent performance gain on complex scenarios of overlapping\ntriples.",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Hengyi Zheng",
      "Rui Wen",
      "Xi Chen",
      "Yifan Yang",
      "Yunyan Zhang",
      "Ziheng Zhang",
      "Ningyu Zhang",
      "Bin Qin",
      "Ming Xu",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09895"
  },
  {
    "id": "arXiv:2106.09896",
    "title": "Continuity of Topic, Interaction, and Query: Learning to Quote in Online  Conversations",
    "abstract": "Quotations are crucial for successful explanations and persuasions in\ninterpersonal communications. However, finding what to quote in a conversation\nis challenging for both humans and machines. This work studies automatic\nquotation generation in an online conversation and explores how language\nconsistency affects whether a quotation fits the given context. Here, we\ncapture the contextual consistency of a quotation in terms of latent topics,\ninteractions with the dialogue history, and coherence to the query turn's\nexisting content. Further, an encoder-decoder neural framework is employed to\ncontinue the context with a quotation via language generation. Experiment\nresults on two large-scale datasets in English and Chinese demonstrate that our\nquotation generation model outperforms the state-of-the-art models. Further\nanalysis shows that topic, interaction, and query consistency are all helpful\nto learn how to quote in online conversations.",
    "descriptor": "\nComments: Accepted by EMNLP 2020, updated with dataset link\n",
    "authors": [
      "Lingzhi Wang",
      "Jing Li",
      "Xingshan Zeng",
      "Haisong Zhang",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09896"
  },
  {
    "id": "arXiv:2106.09898",
    "title": "Bad Characters: Imperceptible NLP Attacks",
    "abstract": "Several years of research have shown that machine-learning systems are\nvulnerable to adversarial examples, both in theory and in practice. Until now,\nsuch attacks have primarily targeted visual models, exploiting the gap between\nhuman and machine perception. Although text-based models have also been\nattacked with adversarial examples, such attacks struggled to preserve semantic\nmeaning and indistinguishability. In this paper, we explore a large class of\nadversarial examples that can be used to attack text-based models in a\nblack-box setting without making any human-perceptible visual modification to\ninputs. We use encoding-specific perturbations that are imperceptible to the\nhuman eye to manipulate the outputs of a wide range of Natural Language\nProcessing (NLP) systems from neural machine-translation pipelines to web\nsearch engines. We find that with a single imperceptible encoding injection --\nrepresenting one invisible character, homoglyph, reordering, or deletion -- an\nattacker can significantly reduce the performance of vulnerable models, and\nwith three injections most models can be functionally broken. Our attacks work\nagainst currently-deployed commercial systems, including those produced by\nMicrosoft and Google, in addition to open source models published by Facebook\nand IBM. This novel series of attacks presents a significant threat to many\nlanguage processing systems: an attacker can affect systems in a targeted\nmanner without any assumptions about the underlying model. We conclude that\ntext-based NLP systems require careful input sanitization, just like\nconventional applications, and that given such systems are now being deployed\nrapidly at scale, the urgent attention of architects and operators is required.",
    "descriptor": "",
    "authors": [
      "Nicholas Boucher",
      "Ilia Shumailov",
      "Ross Anderson",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09898"
  },
  {
    "id": "arXiv:2106.09899",
    "title": "Networks obtained by Implicit-Explicit Method: Discrete-time distributed  median solver",
    "abstract": "In the purpose of making the consensus algorithm robust to outliers,\nconsensus on the median value has recently attracted some attention. It has its\napplicability in for instance constructing a resilient distributed state\nestimator. Meanwhile, most of the existing works consider continuous-time\nalgorithms and uses high-gain and discontinuous vector fields. This issues a\nproblem of the need for smaller time steps and yielding chattering when\ndiscretizing by explicit method for its practical use. Thus, in this paper, we\nhighlight that these issues vanish when we utilize instead Implicit-Explicit\nMethod, for a broader class of networks designed by the blended dynamics\napproach. In particular, for undirected and connected graphs, we propose a\ndiscrete-time distributed median solver that does not suffer from chattering.\nWe also verify by simulation that it has a smaller iteration number required to\narrive at a steady-state.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Jin Gyu Lee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09899"
  },
  {
    "id": "arXiv:2106.09900",
    "title": "A Neural Edge-Editing Approach for Document-Level Relation Graph  Extraction",
    "abstract": "In this paper, we propose a novel edge-editing approach to extract relation\ninformation from a document. We treat the relations in a document as a relation\ngraph among entities in this approach. The relation graph is iteratively\nconstructed by editing edges of an initial graph, which might be a graph\nextracted by another system or an empty graph. The way to edit edges is to\nclassify them in a close-first manner using the document and\ntemporally-constructed graph information; each edge is represented with a\ndocument context information by a pretrained transformer model and a graph\ncontext information by a graph convolutional neural network model. We evaluate\nour approach on the task to extract material synthesis procedures from\nmaterials science texts. The experimental results show the effectiveness of our\napproach in editing the graphs initialized by our in-house rule-based system\nand empty graphs.",
    "descriptor": "\nComments: Accepted for publication at the Findings of the Association for Computational Linguistics (Findings-ACL2021), 2021. 10 pages, 6 figures, 8 tables\n",
    "authors": [
      "Kohei Makino",
      "Makoto Miwa",
      "Yutaka Sasaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09900"
  },
  {
    "id": "arXiv:2106.09901",
    "title": "Generating various airfoil shapes with required lift coefficient using  conditional variational autoencoders",
    "abstract": "Multiple shapes must be obtained in the mechanical design process to satisfy\nthe required design specifications. The inverse design problem has been\nanalyzed in previous studies to obtain such shapes. However, finding multiple\nshapes in a short computation period is difficult while using the conventional\nmethods. This paper proposes the use of the conditional variational\nautoencoders (CVAE) with normal distribution, denoted by N-CVAE, along with the\nvon Mises-Fischer distribution, denoted by S-CVAE, to find multiple solutions\nfor the inverse design problems. Both the CVAE models embed shapes into a\nlatent space. The S-CVAE enables the separation of data in the latent space,\nwhereas the N-CVAE embeds the data in a narrow space. These different features\nare used for various tasks in this study. In one of the tasks, the dataset\nconsists of only one type of data and generates similar airfoils. Here, S-CVAE\noutperforms N-CVAE because it can separate the data. Another task involves\ncombining different types of airfoils and generating new types of data. N-CVAE\nis useful in this instance since it embeds different shapes in the same latent\narea, due to which, the model outputs intermediate shapes of different types.\nThe shape-generation capability of S-CVAE and N-CVAE are experimentally\ncompared in this study.",
    "descriptor": "",
    "authors": [
      "Kazuo Yonekura",
      "Kazunari Wada",
      "Katsuyuki Suzuki"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.09901"
  },
  {
    "id": "arXiv:2106.09903",
    "title": "Stability of the semi-implicit method for the Cahn-Hilliard equation  with logarithmic potentials",
    "abstract": "We consider the two-dimensional Cahn-Hilliard equation with logarithmic\npotentials and periodic boundary conditions. We employ the standard\nsemi-implicit numerical scheme which treats\nthe linear fourth-order dissipation term implicitly and the nonlinear term\nexplicitly. Under natural\nconstraints on the time step we prove strict phase separation and energy\nstability of the semi-implicit scheme. This appears to be the first rigorous\nresult for the semi-implicit discretization\nof the Cahn-Hilliard equation with singular potentials.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Dong Li",
      "Tao Tang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.09903"
  },
  {
    "id": "arXiv:2106.09904",
    "title": "Sharing in a Trustless World: Privacy-Preserving Data Analytics with  Potentially Cheating Participants",
    "abstract": "Lack of trust between organisations and privacy concerns about their data are\nimpediments to an otherwise potentially symbiotic joint data analysis. We\npropose DataRing, a data sharing system that allows mutually mistrusting\nparticipants to query each others' datasets in a privacy-preserving manner\nwhile ensuring the correctness of input datasets and query answers even in the\npresence of (cheating) participants deviating from their true datasets. By\nrelying on the assumption that if only a small subset of rows of the true\ndataset are known, participants cannot submit answers to queries deviating\nsignificantly from their true datasets. We employ differential privacy and a\nsuite of cryptographic tools to ensure individual privacy for each\nparticipant's dataset and data confidentiality from the system. Our results\nshow that the evaluation of 10 queries on a dataset with 10 attributes and\n500,000 records is achieved in 90.63 seconds. DataRing could detect cheating\nparticipant that deviates from its true dataset in few queries with high\naccuracy.",
    "descriptor": "",
    "authors": [
      "Tham Nguyen",
      "Hassan Jameel Asghar",
      "Raghav Bhakar",
      "Dali Kaafar",
      "Farhad Farokhi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09904"
  },
  {
    "id": "arXiv:2106.09906",
    "title": "Facilitation of human empathy through self-disclosure of anthropomorphic  agents",
    "abstract": "As AI technologies progress, social acceptance of AI agents including\nintelligent virtual agents and robots is getting to be even more important for\nmore applications of AI in human society. One way to improve the relationship\nbetween humans and anthropomorphic agents is to have humans empathize with the\nagents. By empathizing, humans take positive and kind actions toward agents,\nand emphasizing makes it easier for humans to accept agents. In this study, we\nfocused on self-disclosure from agents to humans in order to realize\nanthropomorphic agents that elicit empathy from humans. Then, we experimentally\ninvestigated the possibility that an agent's self-disclosure facilitates human\nempathy. We formulate hypotheses and experimentally analyze and discuss the\nconditions in which humans have more empathy for agents. This experiment was\nconducted with a three-way mixed plan, and the factors were the agents'\nappearance (human, robot), self-disclosure (high-relevance self-disclosure,\nlow-relevance self-disclosure, no self-disclosure), and empathy before and\nafter a video stimulus. An analysis of variance was performed using data from\n576 participants. As a result, we found that the appearance factor did not have\na main effect, and self-disclosure, which is highly relevant to the scenario\nused, facilitated more human empathy with statistically significant difference.\nWe also found that no self-disclosure suppressed empathy. These results support\nour hypotheses.",
    "descriptor": "\nComments: 20 pages, 8 figures, 2 tables, submitted to PLOS ONE Journal\n",
    "authors": [
      "Takahiro Tsumura",
      "Seiji Yamada"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.09906"
  },
  {
    "id": "arXiv:2106.09908",
    "title": "Light Lies: Optical Adversarial Attack",
    "abstract": "A significant amount of work has been done on adversarial attacks that inject\nimperceptible noise to images to deteriorate the image classification\nperformance of deep models. However, most of the existing studies consider\nattacks in the digital (pixel) domain where an image acquired by an image\nsensor with sampling and quantization has been recorded. This paper, for the\nfirst time, introduces an optical adversarial attack, which physically alters\nthe light field information arriving at the image sensor so that the\nclassification model yields misclassification. More specifically, we modulate\nthe phase of the light in the Fourier domain using a spatial light modulator\nplaced in the photographic system. The operative parameters of the modulator\nare obtained by gradient-based optimization to maximize cross-entropy and\nminimize distortions. We present experiments based on both simulation and a\nreal hardware optical system, from which the feasibility of the proposed\noptical attack is demonstrated. It is also verified that the proposed attack is\ncompletely different from common optical-domain distortions such as spherical\naberration, defocus, and astigmatism in terms of both perturbation patterns and\nclassification results.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Kyu-Lim Kim",
      "Jeong-Soo Kim",
      "Seung-Ri Song",
      "Jun-Ho Choi",
      "Chul-Min Joo",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.09908"
  },
  {
    "id": "arXiv:2106.09910",
    "title": "Message Passing in Graph Convolution Networks via Adaptive Filter Banks",
    "abstract": "Graph convolution networks, like message passing graph convolution networks\n(MPGCNs), have been a powerful tool in representation learning of networked\ndata. However, when data is heterogeneous, most architectures are limited as\nthey employ a single strategy to handle multi-channel graph signals and they\ntypically focus on low-frequency information. In this paper, we present a novel\ngraph convolution operator, termed BankGCN, which keeps benefits of message\npassing models, but extends their capabilities beyond `low-pass' features. It\ndecomposes multi-channel signals on graphs into subspaces and handles\nparticular information in each subspace with an adapted filter. The filters of\nall subspaces have different frequency responses and together form a filter\nbank. Furthermore, each filter in the spectral domain corresponds to a message\npassing scheme, and diverse schemes are implemented via the filter bank.\nImportantly, the filter bank and the signal decomposition are jointly learned\nto adapt to the spectral characteristics of data and to target applications.\nFurthermore, this is implemented almost without extra parameters in comparison\nwith most existing MPGCNs. Experimental results show that the proposed\nconvolution operator permits to achieve excellent performance in graph\nclassification on a collection of benchmark graph datasets.",
    "descriptor": "",
    "authors": [
      "Xing Gao",
      "Wenrui Dai",
      "Chenglin Li",
      "Junni Zou",
      "Hongkai Xiong",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09910"
  },
  {
    "id": "arXiv:2106.09913",
    "title": "Iterative Feature Matching: Toward Provable Domain Generalization with  Logarithmic Environments",
    "abstract": "Domain generalization aims at performing well on unseen test environments\nwith data from a limited number of training environments. Despite a\nproliferation of proposal algorithms for this task, assessing their\nperformance, both theoretically and empirically is still very challenging.\nMoreover, recent approaches such as Invariant Risk Minimization (IRM) require a\nprohibitively large number of training environments - linear in the dimension\nof the spurious feature space $d_s$ - even on simple data models like the one\nproposed by [Rosenfeld et al., 2021]. Under a variant of this model, we show\nthat both ERM and IRM cannot generalize with $o(d_s)$ environments. We then\npresent a new algorithm based on performing iterative feature matching that is\nguaranteed with high probability to yield a predictor that generalizes after\nseeing only $O(\\log{d_s})$ environments.",
    "descriptor": "",
    "authors": [
      "Yining Chen",
      "Elan Rosenfeld",
      "Mark Sellke",
      "Tengyu Ma",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09913"
  },
  {
    "id": "arXiv:2106.09914",
    "title": "A Unified Generative Adversarial Network Training via Self-Labeling and  Self-Attention",
    "abstract": "We propose a novel GAN training scheme that can handle any level of labeling\nin a unified manner. Our scheme introduces a form of artificial labeling that\ncan incorporate manually defined labels, when available, and induce an\nalignment between them. To define the artificial labels, we exploit the\nassumption that neural network generators can be trained more easily to map\nnearby latent vectors to data with semantic similarities, than across separate\ncategories. We use generated data samples and their corresponding artificial\nconditioning labels to train a classifier. The classifier is then used to\nself-label real data. To boost the accuracy of the self-labeling, we also use\nthe exponential moving average of the classifier. However, because the\nclassifier might still make mistakes, especially at the beginning of the\ntraining, we also refine the labels through self-attention, by using the\nlabeling of real data samples only when the classifier outputs a high\nclassification probability score. We evaluate our approach on CIFAR-10, STL-10\nand SVHN, and show that both self-labeling and self-attention consistently\nimprove the quality of generated data. More surprisingly, we find that the\nproposed scheme can even outperform class-conditional GANs.",
    "descriptor": "",
    "authors": [
      "Tomoki Watanabe",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09914"
  },
  {
    "id": "arXiv:2106.09917",
    "title": "Envy-freeness and Relaxed Stability for Lower-Quotas: A Parameterized  Perspective",
    "abstract": "We consider the problem of assigning agents to resources in the two-sided\npreference model with upper and lower-quota requirements on resources. This\nsetting (known as the HRLQ setting) models real-world applications like\nassigning students to colleges or courses, resident doctors to hospitals and so\non. In presence of lower-quotas, an instance may not admit a stable matching\nthat fulfils the lower-quotas. Prem Krishnaa et al. [SAGT 2020] study two\nalternative notions of optimality for the HRLQ instances -- envy-freeness and\nrelaxed stability. They investigate the complexity of computing a maximum size\nenvy-free matching (MAXEFM) and a maximum size relaxed stable matching(MAXRSM)\nthat fulfils the lower-quotas. They show that both these optimization problems\nare NP-hard and not approximable within a constant factor unless P=NP.\nIn this work, we investigate the parameterized complexity of MAXEFM and\nMAXRSM. We consider natural parameters derived from the instance -- the number\nof lower-quota hospitals, deficiency of the instance, size of a maximum\nmatching, size of a stable matching, length of the preference list of a\nlower-quota hospital, to name a few. We show that MAXEFM problem is W[1]-hard\nfor several interesting parameters but admits a polynomial size kernel for a\ncombination of parameters. We show that MAXRSM problem does not admit an FPT\nalgorithm unless P=NP for two natural parameters but admits a polynomial size\nkernel for a combination of parameters in a special case. We also show that\nboth these problems admit FPT algorithms on a set of parameters.",
    "descriptor": "\nComments: 19 pages, 2 figures. This submission essentially replaces the following results from arXiv:1910.07159 - Theorem 4(I) MAXEFM result, Section 4.1 and 4.3 (Parameterized complexity). The consent of the remaining authors of arXiv:1910.07159 is taken before making this submission\n",
    "authors": [
      "Girija Limaye"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.09917"
  },
  {
    "id": "arXiv:2106.09919",
    "title": "Approximation Algorithms for Two-Bar Charts Packing Problem",
    "abstract": "In the Two-Bar Charts Packing Problem (2-BCPP), it is required to pack the\nbar charts (BCs) consisting of two bars into the horizontal unit-height strip\nof minimal length. The bars may move vertically within the strip, but it is\nforbidden to change the order and separate the chart's bars. Recently, for this\nnew problem, which is a generalization of the Bin Packing Problem (BPP) and\n2-Dimensional Vector Packing Problem (2-DVPP), several approximation algorithms\nwith guaranteed estimates were proposed. However, after a preliminary analysis\nof the solutions constructed by approximation algorithms, we discerned that the\nguaranteed estimates are inaccurate. This fact inspired us to conduct a\nnumerical experiment in which the approximate solutions are compared to each\nother and with the optimal ones. To construct the optimal solutions or lower\nbounds for optimum, we use the Boolean Linear Programming (BLP) formulation of\n2-BCPP proposed earlier and apply the CPLEX package. We also use a database of\ninstances for BPP with known optimal solutions to construct the instances for\nthe 2-BCPP with known minimal packing length. The results of the simulation\nmake up the main content of this paper.",
    "descriptor": "",
    "authors": [
      "Adil Erzin",
      "Georgii Melidi",
      "Stepan Nazarenko",
      "Roman Plotnikov"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.09919"
  },
  {
    "id": "arXiv:2106.09920",
    "title": "Being Properly Improper",
    "abstract": "In today's ML, data can be twisted (changed) in various ways, either for bad\nor good intent. Such twisted data challenges the founding theory of properness\nfor supervised losses which form the basis for many popular losses for class\nprobability estimation. Unfortunately, at its core, properness ensures that the\noptimal models also learn the twist. In this paper, we analyse such class\nprobability-based losses when they are stripped off the mandatory properness;\nwe define twist-proper losses as losses formally able to retrieve the optimum\n(untwisted) estimate off the twists, and show that a natural extension of a\nhalf-century old loss introduced by S. Arimoto is twist proper. We then turn to\na theory that has provided some of the best off-the-shelf algorithms for proper\nlosses, boosting. Boosting can require access to the derivative of the convex\nconjugate of a loss to compute examples weights. Such a function can be hard to\nget, for computational or mathematical reasons; this turns out to be the case\nfor Arimoto's loss. We bypass this difficulty by inverting the problem as\nfollows: suppose a blueprint boosting algorithm is implemented with a general\nweight update function. What are the losses for which boosting-compliant\nminimisation happens? Our answer comes as a general boosting algorithm which\nmeets the optimal boosting dependence on the number of calls to the weak\nlearner; when applied to Arimoto's loss, it leads to a simple optimisation\nalgorithm whose performances are showcased on several domains and twists.",
    "descriptor": "",
    "authors": [
      "Richard Nock",
      "Tyler Sypherd",
      "Lalitha Sankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.09920"
  },
  {
    "id": "arXiv:2106.09922",
    "title": "A Fresh Approach to Evaluate Performance in Distributed Parallel Genetic  Algorithms",
    "abstract": "This work proposes a novel approach to evaluate and analyze the behavior of\nmulti-population parallel genetic algorithms (PGAs) when running on a cluster\nof multi-core processors. In particular, we deeply study their numerical and\ncomputational behavior by proposing a mathematical model representing the\nobserved performance curves. In them, we discuss the emerging mathematical\ndescriptions of PGA performance instead of, e.g., individual isolated results\nsubject to visual inspection, for a better understanding of the effects of the\nnumber of cores used (scalability), their migration policy (the migration gap,\nin this paper), and the features of the solved problem (type of encoding and\nproblem size). The conclusions based on the real figures and the numerical\nmodels fitting them represent a fresh way of understanding their speed-up,\nrunning time, and numerical effort, allowing a comparison based on a few\nmeaningful numeric parameters. This represents a set of conclusions beyond the\nusual textual lessons found in past works on PGAs. It can be used as an\nestimation tool for the future performance of the algorithms and a way of\nfinding out their limitations.",
    "descriptor": "\nComments: 22 pages, submitted to Applied Soft Computing and under review\n",
    "authors": [
      "Tomohiro Harada",
      "Enrique Alba",
      "Gabriel Luque"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.09922"
  },
  {
    "id": "arXiv:2106.09923",
    "title": "Embedding Heterogeneous Networks into Hyperbolic Space Without Meta-path",
    "abstract": "Networks found in the real-world are numerous and varied. A common type of\nnetwork is the heterogeneous network, where the nodes (and edges) can be of\ndifferent types. Accordingly, there have been efforts at learning\nrepresentations of these heterogeneous networks in low-dimensional space.\nHowever, most of the existing heterogeneous network embedding methods suffer\nfrom the following two drawbacks: (1) The target space is usually Euclidean.\nConversely, many recent works have shown that complex networks may have\nhyperbolic latent anatomy, which is non-Euclidean. (2) These methods usually\nrely on meta-paths, which require domain-specific prior knowledge for meta-path\nselection. Additionally, different down-streaming tasks on the same network\nmight require different meta-paths in order to generate task-specific\nembeddings. In this paper, we propose a novel self-guided random walk method\nthat does not require meta-path for embedding heterogeneous networks into\nhyperbolic space. We conduct thorough experiments for the tasks of network\nreconstruction and link prediction on two public datasets, showing that our\nmodel outperforms a variety of well-known baselines across all tasks.",
    "descriptor": "\nComments: In proceedings of the 35th AAAI Conference on Artificial Intelligence\n",
    "authors": [
      "Lili Wang",
      "Chongyang Gao",
      "Chenghan Huang",
      "Ruibo Liu",
      "Weicheng Ma",
      "Soroush Vosoughi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09923"
  },
  {
    "id": "arXiv:2106.09925",
    "title": "Realizing Neural Decoder at the Edge with Ensembled BNN",
    "abstract": "In this work, we propose extreme compression techniques like binarization,\nternarization for Neural Decoders such as TurboAE. These methods reduce memory\nand computation by a factor of 64 with a performance better than the quantized\n(with 1-bit or 2-bits) Neural Decoders. However, because of the limited\nrepresentation capability of the Binary and Ternary networks, the performance\nis not as good as the real-valued decoder. To fill this gap, we further propose\nto ensemble 4 such weak performers to deploy in the edge to achieve a\nperformance similar to the real-valued network. These ensemble decoders give 16\nand 64 times saving in memory and computation respectively and help to achieve\nperformance similar to real-valued TurboAE.",
    "descriptor": "",
    "authors": [
      "Devannagari Vikas",
      "Nancy Nayak",
      "Sheetal Kalyani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.09925"
  },
  {
    "id": "arXiv:2106.09928",
    "title": "A transformation-based approach for solving stiff two-point boundary  value problems",
    "abstract": "A new approach for solving stiff boundary value problems for systems of\nordinary differential equations is presented. Its idea essentially generalizes\nand extends that from arXiv:1601.04272v8. The approach can be viewed as a\nmethodology framework that allows to enhance \"stiffness resistance\" of pretty\nmuch all the known numerical methods for solving two-point BVPs. The latter is\ndemonstrated on the example of the {\\it trapezoidal scheme} with the\ncorresponding C++ source code available at\n\\url{https://github.com/imathsoft/MathSoftDevelopment}.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Denys Dragunov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09928"
  },
  {
    "id": "arXiv:2106.09929",
    "title": "Graph-based Joint Pandemic Concern and Relation Extraction on Twitter",
    "abstract": "Public concern detection provides potential guidance to the authorities for\ncrisis management before or during a pandemic outbreak. Detecting people's\nconcerns and attention from online social media platforms has been widely\nacknowledged as an effective approach to relieve public panic and prevent a\nsocial crisis. However, detecting concerns in time from massive information in\nsocial media turns out to be a big challenge, especially when sufficient\nmanually labeled data is in the absence of public health emergencies, e.g.,\nCOVID-19. In this paper, we propose a novel end-to-end deep learning model to\nidentify people's concerns and the corresponding relations based on Graph\nConvolutional Network and Bi-directional Long Short Term Memory integrated with\nConcern Graph. Except for the sequential features from BERT embeddings, the\nregional features of tweets can be extracted by the Concern Graph module, which\nnot only benefits the concern detection but also enables our model to be high\nnoise-tolerant. Thus, our model can address the issue of insufficient manually\nlabeled data. We conduct extensive experiments to evaluate the proposed model\nby using both manually labeled tweets and automatically labeled tweets. The\nexperimental results show that our model can outperform the state-of-art models\non real-world datasets.",
    "descriptor": "",
    "authors": [
      "Jingli Shi",
      "Weihua Li",
      "Sira Yongchareon",
      "Yi Yang",
      "Quan Bai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.09929"
  },
  {
    "id": "arXiv:2106.09932",
    "title": "A Framework for Real-time Traffic Trajectory Tracking, Speed Estimation,  and Driver Behavior Calibration at Urban Intersections Using Virtual Traffic  Lanes",
    "abstract": "In a previous study, we presented VT-Lane, a three-step framework for\nreal-time vehicle detection, tracking, and turn movement classification at\nurban intersections. In this study, we present a case study incorporating the\nhighly accurate trajectories and movement classification obtained via VT-Lane\nfor the purpose of speed estimation and driver behavior calibration for traffic\nat urban intersections. First, we use a highly instrumented vehicle to verify\nthe estimated speeds obtained from video inference. The results of the speed\nvalidation show that our method can estimate the average travel speed of\ndetected vehicles in real-time with an error of 0.19 m/sec, which is equivalent\nto 2% of the average observed travel speeds in the intersection of the study.\nInstantaneous speeds (at the resolution of 30 Hz) were found to be estimated\nwith an average error of 0.21 m/sec and 0.86 m/sec respectively for\nfree-flowing and congested traffic conditions. We then use the estimated speeds\nto calibrate the parameters of a driver behavior model for the vehicles in the\narea of study. The results show that the calibrated model replicates the\ndriving behavior with an average error of 0.45 m/sec, indicating the high\npotential for using this framework for automated, large-scale calibration of\ncar-following models from roadside traffic video data, which can lead to\nsubstantial improvements in traffic modeling via microscopic simulation.",
    "descriptor": "",
    "authors": [
      "Awad Abdelhalim",
      "Montasir Abbas",
      "Bhavi Bharat Kotha",
      "Alfred Wicks"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09932"
  },
  {
    "id": "arXiv:2106.09933",
    "title": "Data Enforced: An Exploratory Impact Analysis of Automated Speed  Enforcement in the District of Columbia",
    "abstract": "In 2015, the District of Columbia framed a Vision Zero mission and action\nplan, with a target of achieving zero traffic fatalities by 2024. This study\nexamines the impacts of Automated Speed Enforcement (ASE) and its role in\nachieving the goals of Vision Zero. Independent datasets containing detailed\ninformation about traffic crashes, ASE camera locations, and citation records,\nand driving speeds across the District's streets were collected, combined, and\nanalyzed to identify patterns and trends in crashes, speed limit violations,\nand speeding behavior before and after the ASE camera installation. The results\nof this exploratory analysis confirm the safety benefits of ASE systems in\nWashington, D.C. The study also provides a blueprint for the different means of\nevaluating the short-term impact of ASE systems using different data sources\nwhich can aid practitioners in better evaluating existing systems and support\nthe decision-making process regarding future installations.",
    "descriptor": "",
    "authors": [
      "Awad Abdelhalim",
      "Linda Bailey",
      "Emily Dalphy",
      "Kelli Raboy"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.09933"
  },
  {
    "id": "arXiv:2106.09937",
    "title": "Detox Browser -- Towards Filtering Sensitive Content On the Web",
    "abstract": "The annual consumption of web-based resources is increasing at a very fast\nrate, mainly due to an increase in affordability and accessibility of the\ninternet. Many are relying on the web to get diverse perspectives, but at the\nsame time, it can expose them to content that is harmful to their mental\nwell-being. Catchy headlines and emotionally charged articles increase the\nnumber of readers which in turn increases ad revenue for websites. When a user\nconsumes a large quantity of negative content, it adversely impacts the user's\nhappiness and has a significant impact on his/her mood and state of mind. Many\nstudies carried out during the COVID-19 pandemic has shown that people across\nthe globe irrespective of their country of origin have experienced higher\nlevels of anxiety and depression. Web filters can help in constructing a\ndigital environment that is more suitable for people prone to depression,\nanxiety and stress. A significant amount of work has been done in the field of\nweb filtering, but there has been limited focus on helping Highly Sensitive\nPersons (HSP's) or those with stress disorders induced by trauma. Through this\npaper, we propose detox Browser, a simple tool that enables end-users to tune\nout of or control their exposure to topics that can affect their mental well\nbeing. The extension makes use of sentiment analysis and keywords to filter out\nflagged content from google search results and warns users if any blacklisted\ntopics are detected when navigating across websites",
    "descriptor": "\nComments: 6 pages, 2 figures, CSCW\n",
    "authors": [
      "Noble Saji Mathews",
      "Sridhar Chimalakonda"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.09937"
  },
  {
    "id": "arXiv:2106.09938",
    "title": "Goal-Directed Planning by Reinforcement Learning and Active Inference",
    "abstract": "What is the difference between goal-directed and habitual behavior? We\npropose a novel computational framework of decision making with Bayesian\ninference, in which everything is integrated as an entire neural network model.\nThe model learns to predict environmental state transitions by self-exploration\nand generating motor actions by sampling stochastic internal states $z$.\nHabitual behavior, which is obtained from the prior distribution of $z$, is\nacquired by reinforcement learning. Goal-directed behavior is determined from\nthe posterior distribution of $z$ by planning, using active inference, to\nminimize the free energy for goal observation. We demonstrate the effectiveness\nof the proposed framework by experiments in a sensorimotor navigation task with\ncamera observations and continuous motor actions.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Dongqi Han",
      "Kenji Doya",
      "Jun Tani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09938"
  },
  {
    "id": "arXiv:2106.09942",
    "title": "Does gamification affect flow experience? A systematic literature review",
    "abstract": "In recent years, studies in different areas have used gamification to improve\nusers' flow experience. However, due to the high variety of the conducted\nstudies and the lack of secondary studies (e.g., systematic literature reviews)\nin this field, it is difficult to get the state-of-the-art of this research\ndomain. To address this problem, we conducted a systematic literature review to\nidentify i) which gamification design methods have been used in the studies\nabout gamification and Flow Theory, ii) which gamification elements have been\nused in these studies, iii) which methods have been used to evaluate the users'\nflow experience in gamified settings, and iv) how gamification affects users'\nflow experience. The main results show that there is growing interest to this\nfield, as the number of publications is increasing. The most significant\ninterest is in the area of gamification in education. However, there is no\nunanimity regarding the preferred method of the study or the effects of\ngamification on users' experience. Our results highlight the importance of\nconducting new experimental studies investigating how gamification affects the\nusers' flow experience in different gamified settings, applications and\ndomains.",
    "descriptor": "\nComments: 5th International GamiFIN Conference 2021 (GamiFIN 2021), April 7-10, 2021, Finland\n",
    "authors": [
      "Wilk Oliveira",
      "Olena Pastushenko",
      "Luiz Rodrigues",
      "Armando M. Toda",
      "Paula T. Palomino",
      "Juho Hamari",
      "Seiji Isotani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.09942"
  },
  {
    "id": "arXiv:2106.09943",
    "title": "Investigating the Role of Negatives in Contrastive Representation  Learning",
    "abstract": "Noise contrastive learning is a popular technique for unsupervised\nrepresentation learning. In this approach, a representation is obtained via\nreduction to supervised learning, where given a notion of semantic similarity,\nthe learner tries to distinguish a similar (positive) example from a collection\nof random (negative) examples. The success of modern contrastive learning\npipelines relies on many parameters such as the choice of data augmentation,\nthe number of negative examples, and the batch size; however, there is limited\nunderstanding as to how these parameters interact and affect downstream\nperformance. We focus on disambiguating the role of one of these parameters:\nthe number of negative examples. Theoretically, we show the existence of a\ncollision-coverage trade-off suggesting that the optimal number of negative\nexamples should scale with the number of underlying concepts in the data.\nEmpirically, we scrutinize the role of the number of negatives in both NLP and\nvision tasks. In the NLP task, we find that the results broadly agree with our\ntheory, while our vision experiments are murkier with performance sometimes\neven being insensitive to the number of negatives. We discuss plausible\nexplanations for this behavior and suggest future directions to better align\ntheory and practice.",
    "descriptor": "",
    "authors": [
      "Jordan T. Ash",
      "Surbhi Goel",
      "Akshay Krishnamurthy",
      "Dipendra Misra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09943"
  },
  {
    "id": "arXiv:2106.09946",
    "title": "Evolving GANs: When Contradictions Turn into Compliance",
    "abstract": "Limited availability of labeled-data makes any supervised learning problem\nchallenging. Alternative learning settings like semi-supervised and universum\nlearning alleviate the dependency on labeled data, but still require a large\namount of unlabeled data, which may be unavailable or expensive to acquire.\nGAN-based synthetic data generation methods have recently shown promise by\ngenerating synthetic samples to improve task at hand. However, these samples\ncannot be used for other purposes. In this paper, we propose a GAN game which\nprovides improved discriminator accuracy under limited data settings, while\ngenerating realistic synthetic data. This provides the added advantage that now\nthe generated data can be used for other similar tasks. We provide the\ntheoretical guarantees and empirical results in support of our approach.",
    "descriptor": "\nComments: Generative Adversarial Networks, Universum Learning, Semi-Supervised Learning\n",
    "authors": [
      "Sauptik Dhar",
      "Javad Heydari",
      "Samarth Tripathi",
      "Unmesh Kurup",
      "Mohak Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09946"
  },
  {
    "id": "arXiv:2106.09947",
    "title": "Indicators of Attack Failure: Debugging and Improving Optimization of  Adversarial Examples",
    "abstract": "Evaluating robustness of machine-learning models to adversarial examples is a\nchallenging problem. Many defenses have been shown to provide a false sense of\nsecurity by causing gradient-based attacks to fail, and they have been broken\nunder more rigorous evaluations. Although guidelines and best practices have\nbeen suggested to improve current adversarial robustness evaluations, the lack\nof automatic testing and debugging tools makes it difficult to apply these\nrecommendations in a systematic manner. In this work, we overcome these\nlimitations by (i) defining a set of quantitative indicators which unveil\ncommon failures in the optimization of gradient-based attacks, and (ii)\nproposing specific mitigation strategies within a systematic evaluation\nprotocol. Our extensive experimental analysis shows that the proposed\nindicators of failure can be used to visualize, debug and improve current\nadversarial robustness evaluations, providing a first concrete step towards\nautomatizing and systematizing current adversarial robustness evaluations. Our\nopen-source code is available at:\nhttps://github.com/pralab/IndicatorsOfAttackFailure.",
    "descriptor": "",
    "authors": [
      "Maura Pintor",
      "Luca Demetrio",
      "Angelo Sotgiu",
      "Giovanni Manca",
      "Ambra Demontis",
      "Nicholas Carlini",
      "Battista Biggio",
      "Fabio Roli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09947"
  },
  {
    "id": "arXiv:2106.09951",
    "title": "Labelling Drifts in a Fault Detection System for Wind Turbine  Maintenance",
    "abstract": "A failure detection system is the first step towards predictive maintenance\nstrategies. A popular data-driven method to detect incipient failures and\nanomalies is the training of normal behaviour models by applying a machine\nlearning technique like feed-forward neural networks (FFNN) or extreme learning\nmachines (ELM). However, the performance of any of these modelling techniques\ncan be deteriorated by the unexpected rise of non-stationarities in the dynamic\nenvironment in which industrial assets operate. This unpredictable statistical\nchange in the measured variable is known as concept drift. In this article a\nwind turbine maintenance case is presented, where non-stationarities of various\nkinds can happen unexpectedly. Such concept drift events are desired to be\ndetected by means of statistical detectors and window-based approaches.\nHowever, in real complex systems, concept drifts are not as clear and evident\nas in artificially generated datasets. In order to evaluate the effectiveness\nof current drift detectors and also to design an appropriate novel technique\nfor this specific industrial application, it is essential to dispose beforehand\nof a characterization of the existent drifts. Under the lack of information in\nthis regard, a methodology for labelling concept drift events in the lifetime\nof wind turbines is proposed. This methodology will facilitate the creation of\na drift database that will serve both as a training ground for concept drift\ndetectors and as a valuable information to enhance the knowledge about\nmaintenance of complex systems.",
    "descriptor": "\nComments: 11 pages, 2 figures, 1 table\n",
    "authors": [
      "I\u00f1igo Martinez",
      "Elisabeth Viles",
      "I\u00f1aki Cabrejas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09951"
  },
  {
    "id": "arXiv:2106.09957",
    "title": "Variable-Grasping-Mode Gripper With Different Finger Structures For  Grasping Small-Sized Items",
    "abstract": "This letter presents a novel small gripper capable of grasping various types\nof small-sized items from flat surfaces for the assembly of small devices.\nUsing a single actuator, the proposed gripper realizes two grasping modes:\nparallel-grip and turn-over modes. The gripper's mode can be switched via\ncontact with a flat surface, such as a table. Handling thin thicknesses and\nlight weights are the key challenges faced in attempts to grasp small-sized\nitems. Although parallel grippers are effective in handling small items, there\nis a limit to the thinness of objects that can be grasped by parallel grippers.\nAccordingly, the turn-over mode was adopted to grasp items that exceeded this\nthreshold. In the turn-over mode, one finger lifts the item, while another\nfinger holds the item from above to keep it from flicking out. The proposed\ngripper is capable of picking up several types of items from a table, including\nthin (0.05 mm) and lightweight (0.007 g) items.",
    "descriptor": "\nComments: 8 pages, 12 figures\n",
    "authors": [
      "Tetsuyou Watanabe",
      "Kota Morino",
      "Yoshitatsu Asama",
      "Seiji Nishitani",
      "Ryo Toshima"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09957"
  },
  {
    "id": "arXiv:2106.09958",
    "title": "Novelty Detection via Contrastive Learning with Negative Data  Augmentation",
    "abstract": "Novelty detection is the process of determining whether a query example\ndiffers from the learned training distribution. Previous methods attempt to\nlearn the representation of the normal samples via generative adversarial\nnetworks (GANs). However, they will suffer from instability training, mode\ndropping, and low discriminative ability. Recently, various pretext tasks (e.g.\nrotation prediction and clustering) have been proposed for self-supervised\nlearning in novelty detection. However, the learned latent features are still\nlow discriminative. We overcome such problems by introducing a novel\ndecoder-encoder framework. Firstly, a generative network (a.k.a. decoder)\nlearns the representation by mapping the initialized latent vector to an image.\nIn particular, this vector is initialized by considering the entire\ndistribution of training data to avoid the problem of mode-dropping. Secondly,\na contrastive network (a.k.a. encoder) aims to ``learn to compare'' through\nmutual information estimation, which directly helps the generative network to\nobtain a more discriminative representation by using a negative data\naugmentation strategy. Extensive experiments show that our model has\nsignificant superiority over cutting-edge novelty detectors and achieves new\nstate-of-the-art results on some novelty detection benchmarks, e.g. CIFAR10 and\nDCASE. Moreover, our model is more stable for training in a non-adversarial\nmanner, compared to other adversarial based novelty detection methods.",
    "descriptor": "",
    "authors": [
      "Chengwei Chen",
      "Yuan Xie",
      "Shaohui Lin",
      "Ruizhi Qiao",
      "Jian Zhou",
      "Xin Tan",
      "Yi Zhang",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09958"
  },
  {
    "id": "arXiv:2106.09964",
    "title": "Multi-Granularity Network with Modal Attention for Dense Affective  Understanding",
    "abstract": "Video affective understanding, which aims to predict the evoked expressions\nby the video content, is desired for video creation and recommendation. In the\nrecent EEV challenge, a dense affective understanding task is proposed and\nrequires frame-level affective prediction. In this paper, we propose a\nmulti-granularity network with modal attention (MGN-MA), which employs\nmulti-granularity features for better description of the target frame.\nSpecifically, the multi-granularity features could be divided into frame-level,\nclips-level and video-level features, which corresponds to visual-salient\ncontent, semantic-context and video theme information. Then the modal attention\nfusion module is designed to fuse the multi-granularity features and emphasize\nmore affection-relevant modals. Finally, the fused feature is fed into a\nMixtures Of Experts (MOE) classifier to predict the expressions. Further\nemploying model-ensemble post-processing, the proposed method achieves the\ncorrelation score of 0.02292 in the EEV challenge.",
    "descriptor": "\nComments: Oral presentation at AUVi Workshop - CVPR 2021\n",
    "authors": [
      "Baoming Yan",
      "Lin Wang",
      "Ke Gao",
      "Bo Gao",
      "Xiao Liu",
      "Chao Ban",
      "Jiang Yang",
      "Xiaobo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09964"
  },
  {
    "id": "arXiv:2106.09965",
    "title": "HifiFace: 3D Shape and Semantic Prior Guided High Fidelity Face Swapping",
    "abstract": "In this work, we propose a high fidelity face swapping method, called\nHifiFace, which can well preserve the face shape of the source face and\ngenerate photo-realistic results. Unlike other existing face swapping works\nthat only use face recognition model to keep the identity similarity, we\npropose 3D shape-aware identity to control the face shape with the geometric\nsupervision from 3DMM and 3D face reconstruction method. Meanwhile, we\nintroduce the Semantic Facial Fusion module to optimize the combination of\nencoder and decoder features and make adaptive blending, which makes the\nresults more photo-realistic. Extensive experiments on faces in the wild\ndemonstrate that our method can preserve better identity, especially on the\nface shape, and can generate more photo-realistic results than previous\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted to IJCAI 2021, project website: this https URL\n",
    "authors": [
      "Yuhan Wang",
      "Xu Chen",
      "Junwei Zhu",
      "Wenqing Chu",
      "Ying Tai",
      "Chengjie Wang",
      "Jilin Li",
      "Yongjian Wu",
      "Feiyue Huang",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09965"
  },
  {
    "id": "arXiv:2106.09966",
    "title": "Introducing Fast and Secure Deterministic Stash Free Write Only  Oblivious RAMs for Demand Paging in Keystone",
    "abstract": "Keystone is a trusted execution environment, based on RISC-V architecture. It\ndivides the memory into a secure Keystone private memory and an unsecure\nnon-Keystone memory, and allows code that lies inside the Keystone private\nmemory to execute securely. Simple demand paging in Keystone ends up leaking\nsensitive access patterns of Keystone application to the Operating System(OS),\nthat is assumed to be malicious. This is because, to access the unsecure\nnon-Keystone memory, Keystone needs support of the OS. To mitigate this,\nKeystone needs to implement oblivious demand paging while obfuscating its page\naccess patterns by using Oblivious RAM(ORAM) techniques. This causes\nsubstantial slowdown in the application execution.\nIn this paper, we bridge the performance gap between application execution\ntime with unsecure and secure demand paging in Keystone by using Deterministic,\nstash free, Write only ORAM (DetWoORAM) for oblivious demand paging. We also\nshow why DetWoORAM, that is a write-only ORAM, is sufficient for oblivious\ndemand paging. DetWoORAM logically partitions the memory into a main area and a\nholding area. The actual pages are stored in main area. We propose two\nenhancements over DetWoORAM that improves the application execution slowdown.\nThe first enhancement, which we call the Eager DetWoORAM, involves page\npreloading that exploits the deterministic access pattern of DetWoORAM, and\ntries to hide the ORAM latency. The second enhancement, which we call the\nParallel DetWoORAM, involves spawning multiple threads and each thread performs\na part of the DetWoORAM memory access algorithm. Compared to DetWoORAM that\nshows slowdown of [1.4x, 2x, and 3.24x], Eager DetWoORAM and Parallel DetWoORAM\nprovide slowdown of [1.2x, 1.8x, and 3.2x] and [1.1x, 1.1x, and 1.4x], for k=\n3, 7, and 15, respectively.",
    "descriptor": "",
    "authors": [
      "Mriganka Shekhar Chakravarty",
      "Biswabandan Panda"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2106.09966"
  },
  {
    "id": "arXiv:2106.09967",
    "title": "Extending the GLS endomorphism to speed up GHS Weil descent using Magma",
    "abstract": "Let $q = 2^n$, and let $E / \\mathbb{F}_{q^{\\ell}}$ be a generalized\nGalbraith--Lin--Scott (GLS) binary curve, with $\\ell \\ge 2$ and $(\\ell, n) =\n1$.We show that the GLS endomorphism on $E / \\mathbb{F}_{q^{\\ell}}$ induces an\nefficient endomorphism on the Jacobian $J_H(\\mathbb{F}_q)$ of the genus-$g$\nhyperelliptic curve $H$ corresponding to the image of the GHS Weil-descent\nattack applied to $E/\\mathbb{F}_{q^\\ell}$, and that this endomorphism yields a\nfactor-$n$ speedup when using standard index-calculus procedures for solving\nthe Discrete Logarithm Problem (DLP) on $J_H(\\mathbb{F}_q)$. Our analysis is\nbacked up by the explicit computation of a discrete logarithm defined on a\nprime-order subgroup of a GLS elliptic curve over the field\n$\\mathbb{F}_{2^{5\\cdot 31}}$. A Magma implementation of our algorithm finds the\naforementioned discrete logarithm in about $1,035$ CPU-days.",
    "descriptor": "\nComments: Finite Fields and Their Applications, Elsevier, In press, 75\n",
    "authors": [
      "Jes\u00fas-Javier Chi-Dom\u00ednguez",
      "Francisco Rodr\u00edguez-Henr\u00edquez",
      "Benjamin Smith"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09967"
  },
  {
    "id": "arXiv:2106.09971",
    "title": "Human-Aware Navigation Planner for Diverse Human-Robot Contexts",
    "abstract": "As more robots are being deployed into human environments, a human-aware\nnavigation planner needs to handle multiple contexts that occur in indoor and\noutdoor environments. In this paper, we propose a tunable human-aware robot\nnavigation planner that can handle a variety of humanrobot contexts. We present\nthe architecture of the planner and discuss the features and some\nimplementation details. Then we present a detailed analysis of various\nsimulated humanrobot contexts using the proposed planner along with some\nquantitative results. Finally, we show the results in a real-world scenario\nafter deploying our system on a real robot.",
    "descriptor": "",
    "authors": [
      "Phani Singamaneni",
      "Anthony Favier",
      "Rachid Alami"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09971"
  },
  {
    "id": "arXiv:2106.09972",
    "title": "Curvature of point clouds through principal component analysis",
    "abstract": "In this article, we study curvature-like feature value of data sets in\nEuclidean spaces. First we formulate such curvature functions with desirable\nproperties under the manifold hypothesis. Then we make a test property for the\nvalidity of the curvature function by the law of large numbers, and check it\nfor the function we construct by numerical experiments. These experiments also\nsuggest us to conjecture that mean of the curvature of sample manifolds\ncoincides with the curvature of the mean manifold. Our construction is based on\nthe dimension estimation by the principal component analysis and the Gaussian\ncurvature of hypersurfaces. Our function depends on provisional parameters\n$\\varepsilon, \\delta$, and we suggest to deal with the resulting functions as a\nfunction of these parameters to get some robustness. As an application, we\npropose a method to decompose data sets into some parts reflecting local\nstructure. For this, we embed the data sets into higher dimensional Euclidean\nspace by using curvature values and cluster them in the embedded space. We also\ngive some computational experiments that support effectiveness of our methods.",
    "descriptor": "\nComments: 22 pages, 10 figures\n",
    "authors": [
      "Yasuhiko Asao",
      "Yuichi Ike"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.09972"
  },
  {
    "id": "arXiv:2106.09973",
    "title": "On the Sample Complexity of Batch Reinforcement Learning with  Policy-Induced Data",
    "abstract": "We study the fundamental question of the sample complexity of learning a good\npolicy in finite Markov decision processes (MDPs) when the data available for\nlearning is obtained by following a logging policy that must be chosen without\nknowledge of the underlying MDP. Our main results show that the sample\ncomplexity, the minimum number of transitions necessary and sufficient to\nobtain a good policy, is an exponential function of the relevant quantities\nwhen the planning horizon $H$ is finite. In particular, we prove that the\nsample complexity of obtaining $\\epsilon$-optimal policies is at least\n$\\Omega(\\mathrm{A}^{\\min(\\mathrm{S}-1, H+1)})$ for $\\gamma$-discounted\nproblems, where $\\mathrm{S}$ is the number of states, $\\mathrm{A}$ is the\nnumber of actions, and $H$ is the effective horizon defined as $H=\\lfloor\n\\tfrac{\\ln(1/\\epsilon)}{\\ln(1/\\gamma)} \\rfloor$; and it is at least\n$\\Omega(\\mathrm{A}^{\\min(\\mathrm{S}-1, H)}/\\varepsilon^2)$ for finite horizon\nproblems, where $H$ is the planning horizon of the problem. This lower bound is\nessentially matched by an upper bound. For the average-reward setting we show\nthat there is no algorithm finding $\\epsilon$-optimal policies with a finite\namount of data.",
    "descriptor": "\nComments: 26 pages, 2 figures\n",
    "authors": [
      "Chenjun Xiao",
      "Ilbin Lee",
      "Bo Dai",
      "Dale Schuurmans",
      "Csaba Szepesvari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09973"
  },
  {
    "id": "arXiv:2106.09974",
    "title": "Separating Geometric Data with Minimum Cost: Two Disjoint Convex Hulls",
    "abstract": "In this study, a geometric version of an NP-hard problem (\"Almost $2-SAT$\"\nproblem) is introduced which has potential applications in clustering,\nseparation axis, binary sensor networks, shape separation, image processing,\netc. Furthermore, it has been illustrated that the new problem known as \"Two\nDisjoint Convex Hulls\" can be solved in polynomial time due to some\ncombinatorial aspects and geometric properties. For this purpose, an $O(n^2)$\nalgorithm has also been presented which employs the Separating Axis Theorem\n(SAT) and the duality of points/lines.",
    "descriptor": "\nComments: A new paper related to Convex Hull, Algorithm, Clustering, Binary Sensor Network, SAT and Separation Axis Theorem\n",
    "authors": [
      "Bahram Sadeghi Bigham"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.09974"
  },
  {
    "id": "arXiv:2106.09975",
    "title": "A System-Level Voltage/Frequency Scaling Characterization Framework for  Multicore CPUs",
    "abstract": "Supply voltage scaling is one of the most effective techniques to reduce the\npower consumption of microprocessors. However, technology limitations such as\naging and process variability enforce microprocessor designers to apply\npessimistic voltage guardbands to guarantee correct operation in the field for\nany foreseeable workload. This worst-case design practice makes energy\nefficiency hard to scale with technology evolution. Improving energy-efficiency\nrequires the identification of the chip design margins through time-consuming\nand comprehensive characterization of its operational limits. Such a\ncharacterization of state-of-the-art multi-core CPUs fabricated in aggressive\ntechnologies is a multi-parameter process, which requires statistically\nsignificant information. In this paper, we present an automated framework to\nsupport system-level voltage and frequency scaling characterization of Applied\nMicro's state-of-the-art ARMv8-based multicore CPUs used in the X-Gene 2\nmicro-server family. The fully automated framework can provide fine-grained\ninformation of the system's state by monitoring any abnormal behavior that may\noccur during reduced supply voltage conditions. We also propose a new metric to\nquantify the behavior of a microprocessor when it operates beyond nominal\nconditions. Our experimental results demonstrate potential uses of the\ncharacterization framework to identify the limits of operation for improved\nenergy efficiency.",
    "descriptor": "\nComments: 7 pages, 6 figures, SELSE '17, March 21-22, 2017, Boston, MA, USA\n",
    "authors": [
      "George Papadimitriou",
      "Manolis Kaliorakis",
      "Athanasios Chatzidimitriou",
      "Dimitris Gizopoulos",
      "Greg Favor",
      "Kumar Sankaran",
      "Shidhartha Das"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.09975"
  },
  {
    "id": "arXiv:2106.09981",
    "title": "How COVID-19 Have Changed Crowdfunding: Evidence From GoFundMe",
    "abstract": "While the long-term effects of COVID-19 are yet to be determined, its\nimmediate impact on crowdfunding is nonetheless significant. This study takes a\ncomputational approach to more deeply comprehend this change. Using a unique\ndata set of all the campaigns published over the past two years on GoFundMe, we\nexplore the factors that have led to the successful funding of a crowdfunding\nproject. In particular, we study a corpus of crowdfunded projects, analyzing\ncover images and other variables commonly present on crowdfunding sites.\nFurthermore, we construct a classifier and a regression model to assess the\nsignificance of features based on XGBoost. In addition, we employ\ncounterfactual analysis to investigate the causality between features and the\nsuccess of crowdfunding. More importantly, sentiment analysis and the paired\nsample t-test are performed to examine the differences in crowdfunding\ncampaigns before and after the COVID-19 outbreak that started in March 2020.\nFirst, we note that there is significant racial disparity in crowdfunding\nsuccess. Second, we find that sad emotion expressed through the campaign's\ndescription became significant after the COVID-19 outbreak. Considering all\nthese factors, our findings shed light on the impact of COVID-19 on\ncrowdfunding campaigns.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Junda Wang",
      "Xupin Zhang",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.09981"
  },
  {
    "id": "arXiv:2106.09982",
    "title": "Towards interpreting computer vision based on transformation invariant  optimization",
    "abstract": "Interpreting how does deep neural networks (DNNs) make predictions is a vital\nfield in artificial intelligence, which hinders wide applications of DNNs.\nVisualization of learned representations helps we humans understand the vision\nof DNNs. In this work, visualized images that can activate the neural network\nto the target classes are generated by back-propagation method. Here, rotation\nand scaling operations are applied to introduce the transformation invariance\nin the image generating process, which we find a significant improvement on\nvisualization effect. Finally, we show some cases that such method can help us\nto gain insight into neural networks.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Chen Li",
      "Jinzhe Jiang",
      "Xin Zhang",
      "Tonghuan Zhang",
      "Yaqian Zhao",
      "Dongdong Jiang",
      "RenGang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09982"
  },
  {
    "id": "arXiv:2106.09983",
    "title": "Weakly Supervised Pre-Training for Multi-Hop Retriever",
    "abstract": "In multi-hop QA, answering complex questions entails iterative document\nretrieval for finding the missing entity of the question. The main steps of\nthis process are sub-question detection, document retrieval for the\nsub-question, and generation of a new query for the final document retrieval.\nHowever, building a dataset that contains complex questions with sub-questions\nand their corresponding documents requires costly human annotation. To address\nthe issue, we propose a new method for weakly supervised multi-hop retriever\npre-training without human efforts. Our method includes 1) a pre-training task\nfor generating vector representations of complex questions, 2) a scalable data\ngeneration method that produces the nested structure of question and\nsub-question as weak supervision for pre-training, and 3) a pre-training model\nstructure based on dense encoders. We conduct experiments to compare the\nperformance of our pre-trained retriever with several state-of-the-art models\non end-to-end multi-hop QA as well as document retrieval. The experimental\nresults show that our pre-trained retriever is effective and also robust on\nlimited data and computational resources.",
    "descriptor": "\nComments: ACL-Findings 2021\n",
    "authors": [
      "Yeon Seonwoo",
      "Sang-Woo Lee",
      "Ji-Hoon Kim",
      "Jung-Woo Ha",
      "Alice Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09983"
  },
  {
    "id": "arXiv:2106.09986",
    "title": "A Survey on Human and Personality Vulnerability Assessment in  Cyber-security: Challenges, Approaches, and Open Issues",
    "abstract": "These days, cyber-criminals target humans rather than machines since they try\nto accomplish their malicious intentions by exploiting the weaknesses of end\nusers. Thus, human vulnerabilities pose a serious threat to the security and\nintegrity of computer systems and data. The human tendency to trust and help\nothers, as well as personal, social, and cultural characteristics, are\nindicative of the level of susceptibility that one may exhibit towards certain\nattack types and deception strategies. This work aims to investigate the\nfactors that affect human susceptibility by studying the existing literature\nrelated to this subject. The objective is also to explore and describe state of\nthe art human vulnerability assessment models, current prevention, and\nmitigation approaches regarding user susceptibility, as well as educational and\nawareness raising training strategies. Following the review of the literature,\nseveral conclusions are reached. Among them, Human Vulnerability Assessment has\nbeen included in various frameworks aiming to assess the cyber security\ncapacity of organizations, but it concerns a one time assessment rather than a\ncontinuous practice. Moreover, human maliciousness is still neglected from\ncurrent Human Vulnerability Assessment frameworks; thus, insider threat actors\nevade identification, which may lead to an increased cyber security risk.\nFinally, this work proposes a user susceptibility profile according to the\nfactors stemming from our research.",
    "descriptor": "\nComments: 39 pages, 4 figures Submitted for Review to Association for Computing Machinery (ACM) - Computing Surveys\n",
    "authors": [
      "Dimitra Papatsaroucha",
      "Yannis Nikoloudakis",
      "Ioannis Kefaloukos",
      "Evangelos Pallis",
      "Evangelos Markakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09986"
  },
  {
    "id": "arXiv:2106.09987",
    "title": "Advanced Hough-based method for on-device document localization",
    "abstract": "The demand for on-device document recognition systems increases in\nconjunction with the emergence of more strict privacy and security\nrequirements. In such systems, there is no data transfer from the end device to\na third-party information processing servers. The response time is vital to the\nuser experience of on-device document recognition. Combined with the\nunavailability of discrete GPUs, powerful CPUs, or a large RAM capacity on\nconsumer-grade end devices such as smartphones, the time limitations put\nsignificant constraints on the computational complexity of the applied\nalgorithms for on-device execution.\nIn this work, we consider document location in an image without prior\nknowledge of the document content or its internal structure. In accordance with\nthe published works, at least 5 systems offer solutions for on-device document\nlocation. All these systems use a location method which can be considered\nHough-based. The precision of such systems seems to be lower than that of the\nstate-of-the-art solutions which were not designed to account for the limited\ncomputational resources.\nWe propose an advanced Hough-based method. In contrast with other approaches,\nit accounts for the geometric invariants of the central projection model and\ncombines both edge and color features for document boundary detection. The\nproposed method allowed for the second best result for SmartDoc dataset in\nterms of precision, surpassed by U-net like neural network. When evaluated on a\nmore challenging MIDV-500 dataset, the proposed algorithm guaranteed the best\nprecision compared to published methods. Our method retained the applicability\nto on-device computations.",
    "descriptor": "\nComments: This is a preprint of the article submitted for publication in the journal \"Computer Optics\"\n",
    "authors": [
      "D.V. Tropin",
      "A.M. Ershov",
      "D.P. Nikolaev",
      "V.V. Arlazarov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09987"
  },
  {
    "id": "arXiv:2106.09989",
    "title": "BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly  Detection",
    "abstract": "Graph-based Anomaly Detection (GAD) is becoming prevalent due to the powerful\nrepresentation abilities of graphs as well as recent advances in graph mining\ntechniques. These GAD tools, however, expose a new attacking surface,\nironically due to their unique advantage of being able to exploit the relations\namong data. That is, attackers now can manipulate those relations (i.e., the\nstructure of the graph) to allow some target nodes to evade detection. In this\npaper, we exploit this vulnerability by designing a new type of targeted\nstructural poisoning attacks to a representative regression-based GAD system\ntermed OddBall. Specially, we formulate the attack against OddBall as a\nbi-level optimization problem, where the key technical challenge is to\nefficiently solve the problem in a discrete domain. We propose a novel attack\nmethod termed BinarizedAttack based on gradient descent. Comparing to prior\narts, BinarizedAttack can better use the gradient information, making it\nparticularly suitable for solving combinatorial optimization problems.\nFurthermore, we investigate the attack transferability of BinarizedAttack by\nemploying it to attack other representation-learning-based GAD systems. Our\ncomprehensive experiments demonstrate that BinarizedAttack is very effective in\nenabling target nodes to evade graph-based anomaly detection tools with limited\nattackers' budget, and in the black-box transfer attack setting,\nBinarizedAttack is also tested effective and in particular, can significantly\nchange the node embeddings learned by the GAD systems. Our research thus opens\nthe door to studying a new type of attack against security analytic tools that\nrely on graph data.",
    "descriptor": "",
    "authors": [
      "Yulin Zhu",
      "Yuni Lai",
      "Kaifa Zhao",
      "Xiapu Luo",
      "Mingquan Yuan",
      "Jian Ren",
      "Kai Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09989"
  },
  {
    "id": "arXiv:2106.09991",
    "title": "Towards Accurate Performance Modeling of RISC-V Designs",
    "abstract": "Microprocessor design, debug, and validation research and development are\nincreasingly based on modeling and simulation at different abstraction layers.\nMicroarchitecture-level simulators have become the most commonly used tools for\nperformance evaluation, due to their high simulation throughput, compared to\nlower levels of abstraction, but usually come at the cost of loss of hardware\naccuracy. As a result, the implementation, speed, and accuracy of\nmicroarchitectural simulators are becoming more and more crucial for\nresearchers and microprocessor architects. One of the most critical aspects of\na microarchitectural simulator is its ability to accurately express design\nstandards as various aspects of the microarchitecture change during design\nrefinement. On the other hand, modern microprocessor models rely on dedicated\nhardware implementations, making the design space exploration a time-consuming\nprocess that can be performed using a variety of methods, ranging from\nhigh-level models to hardware prototyping. Therefore, the tradeoff between\nsimulation speed and accuracy, can be significantly varied, and an\napplication's performance measurements uncertain. In this paper, we present a\nmicroarchitecture-level simulation modeling study, which enables as accurate as\npossible performance modeling of a RISC-V out-of-order superscalar\nmicroprocessor core. By diligently adjusting several important\nmicroarchitectural parameters of the widely used gem5 simulator, we investigate\nthe challenges of accurate performance modeling on microarchitecture-level\nsimulation compared to accuracy and low simulation throughput of RTL simulation\nof the target design. Further, we demonstrate the main sources of errors that\nprevent high accuracy levels of the microarchitecture-level modeling.",
    "descriptor": "\nComments: 8 pages, 4 figures, CARRV '21, June 17, 2021, Co-located with ISCA 2021\n",
    "authors": [
      "Odysseas Chatzopoulos",
      "George-Marios Fragkoulis",
      "George Papadimitriou",
      "Dimitris Gizopoulos"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.09991"
  },
  {
    "id": "arXiv:2106.09992",
    "title": "On the Connections between Counterfactual Explanations and Adversarial  Examples",
    "abstract": "Counterfactual explanations and adversarial examples have emerged as critical\nresearch areas for addressing the explainability and robustness goals of\nmachine learning (ML). While counterfactual explanations were developed with\nthe goal of providing recourse to individuals adversely impacted by algorithmic\ndecisions, adversarial examples were designed to expose the vulnerabilities of\nML models. While prior research has hinted at the commonalities between these\nframeworks, there has been little to no work on systematically exploring the\nconnections between the literature on counterfactual explanations and\nadversarial examples. In this work, we make one of the first attempts at\nformalizing the connections between counterfactual explanations and adversarial\nexamples. More specifically, we theoretically analyze salient counterfactual\nexplanation and adversarial example generation methods, and highlight the\nconditions under which they behave similarly. Our analysis demonstrates that\nseveral popular counterfactual explanation and adversarial example generation\nmethods such as the ones proposed by Wachter et. al. and Carlini and Wagner\n(with mean squared error loss), and C-CHVAE and natural adversarial examples by\nZhao et. al. are equivalent. We also bound the distance between counterfactual\nexplanations and adversarial examples generated by Wachter et. al. and DeepFool\nmethods for linear models. Finally, we empirically validate our theoretical\nfindings using extensive experimentation with synthetic and real world\ndatasets.",
    "descriptor": "",
    "authors": [
      "Martin Pawelczyk",
      "Shalmali Joshi",
      "Chirag Agarwal",
      "Sohini Upadhyay",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09992"
  },
  {
    "id": "arXiv:2106.09993",
    "title": "Accumulative Poisoning Attacks on Real-time Data",
    "abstract": "Collecting training data from untrusted sources exposes machine learning\nservices to poisoning adversaries, who maliciously manipulate training data to\ndegrade the model accuracy. When trained on offline datasets, poisoning\nadversaries have to inject the poisoned data in advance before training, and\nthe order of feeding these poisoned batches into the model is stochastic. In\ncontrast, practical systems are more usually trained/fine-tuned on sequentially\ncaptured real-time data, in which case poisoning adversaries could dynamically\npoison each data batch according to the current model state. In this paper, we\nfocus on the real-time settings and propose a new attacking strategy, which\naffiliates an accumulative phase with poisoning attacks to secretly (i.e.,\nwithout affecting accuracy) magnify the destructive effect of a (poisoned)\ntrigger batch. By mimicking online learning and federated learning on CIFAR-10,\nwe show that the model accuracy will significantly drop by a single update step\non the trigger batch after the accumulative phase. Our work validates that a\nwell-designed but straightforward attacking strategy can dramatically amplify\nthe poisoning effects, with no need to explore complex techniques.",
    "descriptor": "",
    "authors": [
      "Tianyu Pang",
      "Xiao Yang",
      "Yinpeng Dong",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09993"
  },
  {
    "id": "arXiv:2106.09994",
    "title": "A Note on Optimizing Distributions using Kernel Mean Embeddings",
    "abstract": "Kernel mean embeddings are a popular tool that consists in representing\nprobability measures by their infinite-dimensional mean embeddings in a\nreproducing kernel Hilbert space. When the kernel is characteristic, mean\nembeddings can be used to define a distance between probability measures, known\nas the maximum mean discrepancy (MMD). A well-known advantage of mean\nembeddings and MMD is their low computational cost and low sample complexity.\nHowever, kernel mean embeddings have had limited applications to problems that\nconsist in optimizing distributions, due to the difficulty of characterizing\nwhich Hilbert space vectors correspond to a probability distribution. In this\nnote, we propose to leverage the kernel sums-of-squares parameterization of\npositive functions of Marteau-Ferey et al. [2020] to fit distributions in the\nMMD geometry. First, we show that when the kernel is characteristic,\ndistributions with a kernel sum-of-squares density are dense. Then, we provide\nalgorithms to optimize such distributions in the finite-sample setting, which\nwe illustrate in a density fitting numerical experiment.",
    "descriptor": "",
    "authors": [
      "Boris Muzellec",
      "Francis Bach",
      "Alessandro Rudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09994"
  },
  {
    "id": "arXiv:2106.09996",
    "title": "Equivariance-bridged SO(2)-Invariant Representation Learning using Graph  Convolutional Network",
    "abstract": "Training a Convolutional Neural Network (CNN) to be robust against rotation\nhas mostly been done with data augmentation. In this paper, another progressive\nvision of research direction is highlighted to encourage less dependence on\ndata augmentation by achieving structural rotational invariance of a network.\nThe deep equivariance-bridged SO(2) invariant network is proposed to echo such\nvision. First, Self-Weighted Nearest Neighbors Graph Convolutional Network\n(SWN-GCN) is proposed to implement Graph Convolutional Network (GCN) on the\ngraph representation of an image to acquire rotationally equivariant\nrepresentation, as GCN is more suitable for constructing deeper network than\nspectral graph convolution-based approaches. Then, invariant representation is\neventually obtained with Global Average Pooling (GAP), a permutation-invariant\noperation suitable for aggregating high-dimensional representations, over the\nequivariant set of vertices retrieved from SWN-GCN. Our method achieves the\nstate-of-the-art image classification performance on rotated MNIST and CIFAR-10\nimages, where the models are trained with a non-augmented dataset only.\nQuantitative validations over invariance of the representations also\ndemonstrate strong invariance of deep representations of SWN-GCN over\nrotations.",
    "descriptor": "",
    "authors": [
      "Sungwon Hwang",
      "Hyungtae Lim",
      "Hyun Myung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09996"
  },
  {
    "id": "arXiv:2106.09997",
    "title": "SPBERT: Pre-training BERT on SPARQL Queries for End-to-end Question  Answering over Knowledge Graphs",
    "abstract": "We aim to create an unprecedented attempt to build an end-to-end Question\nAnswering (QA) over Knowledge Graphs (KGs), which can construct SPARQL queries\nfrom natural language questions and generate a verbalized answer to its\nqueries. Hence, we introduce SPBERT, a Transformer-based language model\npre-trained on massive SPARQL query logs. By incorporating masked language\nmodelling objective and word structural objective, SPBERT can learn\ngeneral-purpose representations in both natural language and SPARQL query\nlanguage and make the most of the sequential order of words that are crucial\nfor structured language like SPARQL. In this paper, we investigate how SPBERT\nand encoder-decoder architecture can be adapted for Knowledge-based QA corpora.\nWe conduct exhaustive experiments on two auxiliary tasks, including SPARQL\nQuery Construction and Answer Verbalization Generation. Results show that\nSPBERT obtains promising performance and achieves state-of-the-art results on\nseveral of these tasks.",
    "descriptor": "",
    "authors": [
      "Hieu Tran",
      "Long Phan",
      "Truong-Son Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09997"
  },
  {
    "id": "arXiv:2106.10000",
    "title": "Improved Radar Localization on Lidar Maps Using Shared Embedding",
    "abstract": "We present a heterogeneous localization framework for solving radar global\nlocalization and pose tracking on pre-built lidar maps. To bridge the gap of\nsensing modalities, deep neural networks are constructed to create shared\nembedding space for radar scans and lidar maps. Herein learned feature\nembeddings are supportive for similarity measurement, thus improving map\nretrieval and data matching respectively. In RobotCar and MulRan datasets, we\ndemonstrate the effectiveness of the proposed framework with the comparison to\nScan Context and RaLL. In addition, the proposed pose tracking pipeline is with\nless neural networks compared to the original RaLL.",
    "descriptor": "\nComments: Extended abstract. Spotlight Talk at Radar Perception for All-Weather Autonomy Workshop of ICRA 2021\n",
    "authors": [
      "Huan Yin",
      "Yue Wang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10000"
  },
  {
    "id": "arXiv:2106.10002",
    "title": "Recurrent Stacking of Layers in Neural Networks: An Application to  Neural Machine Translation",
    "abstract": "In deep neural network modeling, the most common practice is to stack a\nnumber of recurrent, convolutional, or feed-forward layers in order to obtain\nhigh-quality continuous space representations which in turn improves the\nquality of the network's prediction. Conventionally, each layer in the stack\nhas its own parameters which leads to a significant increase in the number of\nmodel parameters. In this paper, we propose to share parameters across all\nlayers thereby leading to a recurrently stacked neural network model. We report\non an extensive case study on neural machine translation (NMT), where we apply\nour proposed method to an encoder-decoder based neural network model, i.e., the\nTransformer model, and experiment with three Japanese--English translation\ndatasets. We empirically demonstrate that the translation quality of a model\nthat recurrently stacks a single layer 6 times, despite having significantly\nfewer parameters, approaches that of a model that stacks 6 layers where each\nlayer has different parameters. We also explore the limits of recurrent\nstacking where we train extremely deep NMT models. This paper also examines the\nutility of our recurrently stacked model as a student model through transfer\nlearning via leveraging pre-trained parameters and knowledge distillation, and\nshows that it compensates for the performance drops in translation quality that\nthe direct training of recurrently stacked model brings. We also show how\ntransfer learning helps in faster decoding on top of the already reduced number\nof parameters due to recurrent stacking. Finally, we analyze the effects of\nrecurrently stacked layers by visualizing the attentions of models that use\nrecurrently stacked layers and models that do not.",
    "descriptor": "\nComments: 22 pages. Under review. Work in progress. Extended version of this https URL which is an extension of arXiv:1807.05353 . The focus is on analyzing the limitations of recurrently stacked layers and methods to overcome said limitations\n",
    "authors": [
      "Raj Dabre",
      "Atsushi Fujita"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10002"
  },
  {
    "id": "arXiv:2106.10003",
    "title": "Improving Performance of Seen and Unseen Speech Style Transfer in  End-to-end Neural TTS",
    "abstract": "End-to-end neural TTS training has shown improved performance in speech style\ntransfer. However, the improvement is still limited by the training data in\nboth target styles and speakers. Inadequate style transfer performance occurs\nwhen the trained TTS tries to transfer the speech to a target style from a new\nspeaker with an unknown, arbitrary style. In this paper, we propose a new\napproach to style transfer for both seen and unseen styles, with disjoint,\nmulti-style datasets, i.e., datasets of different styles are recorded, each\nindividual style is by one speaker with multiple utterances. To encode the\nstyle information, we adopt an inverse autoregressive flow (IAF) structure to\nimprove the variational inference. The whole system is optimized to minimize a\nweighed sum of four different loss functions: 1) a reconstruction loss to\nmeasure the distortions in both source and target reconstructions; 2) an\nadversarial loss to \"fool\" a well-trained discriminator; 3) a style distortion\nloss to measure the expected style loss after the transfer; 4) a cycle\nconsistency loss to preserve the speaker identity of the source after the\ntransfer. Experiments demonstrate, both objectively and subjectively, the\neffectiveness of the proposed approach for seen and unseen style transfer\ntasks. The performance of the new approach is better and more robust than those\nof four baseline systems of the prior art.",
    "descriptor": "",
    "authors": [
      "Xiaochun An",
      "Frank K. Soong",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.10003"
  },
  {
    "id": "arXiv:2106.10004",
    "title": "Towards Financial Sentiment Analysis in a South African Landscape",
    "abstract": "Sentiment analysis as a sub-field of natural language processing has received\nincreased attention in the past decade enabling organisations to more\neffectively manage their reputation through online media monitoring. Many\ndrivers impact reputation, however, this thesis focuses only the aspect of\nfinancial performance and explores the gap with regards to financial sentiment\nanalysis in a South African context. Results showed that pre-trained sentiment\nanalysers are least effective for this task and that traditional lexicon-based\nand machine learning approaches are best suited to predict financial sentiment\nof news articles. The evaluated methods produced accuracies of 84\\%-94\\%. The\npredicted sentiments correlated quite well with share price and highlighted the\npotential use of sentiment as an indicator of financial performance. A main\ncontribution of the study was updating an existing sentiment dictionary for\nfinancial sentiment analysis. Model generalisation was less acceptable due to\nthe limited amount of training data used. Future work includes expanding the\ndata set to improve general usability and contribute to an open-source\nfinancial sentiment analyser for South African data.",
    "descriptor": "\nComments: Accepted for publication in Proceedings of CD-MAKE 2021 Conference\n",
    "authors": [
      "Michelle Terblanche",
      "Vukosi Marivate"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10004"
  },
  {
    "id": "arXiv:2106.10006",
    "title": "Energy Prioritized Caching for Cellular D2D Networks",
    "abstract": "Multimedia content transmission heavily taxes network resources and puts a\nsignificant burden on wireless systems in terms of capacity and energy\nconsumption. In this context, device-to-device (D2D) paradigm has a utilitarian\nvalue to alleviate the network burden by utilizing short-range transmissions\nwith less energy cost. For the realization of proper D2D networking, caching in\ndevices is essential. Additionally, caching needs to operate efficiently with\nthe aim of realizing network-wide energy improvements. To this end, we study\nmultimedia caching in cellular D2D networks and propose an energy prioritized\nD2D caching (EPDC) algorithm in this work. We also investigate the optimal\ncaching policy in that system setting. The impact of device capacity and D2D\ntransmission range on energy consumption is studied by focusing on different\noperation modes such as D2D and base station transmissions. According to the\nsimulation results, EPDC algorithm has substantial energy-efficiency gains over\nthe commonly utilized Least Recently Used (LRU) algorithm and content-based\ncaching algorithms PDC and SXO. For larger D2D transmission ranges, this\nimprovement becomes more evident.",
    "descriptor": "",
    "authors": [
      "S. Sinem Kaf\u0131lo\u011flu",
      "G\u00fcrkan G\u00fcr",
      "Fatih Alag\u00f6z"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.10006"
  },
  {
    "id": "arXiv:2106.10013",
    "title": "Shape Prior Non-Uniform Sampling Guided Real-time Stereo 3D Object  Detection",
    "abstract": "Pseudo-LiDAR based 3D object detectors have gained popularity due to their\nhigh accuracy. However, these methods need dense depth supervision and suffer\nfrom inferior speed. To solve these two issues, a recently introduced RTS3D\nbuilds an efficient 4D Feature-Consistency Embedding (FCE) space for the\nintermediate representation of object without depth supervision. FCE space\nsplits the entire object region into 3D uniform grid latent space for feature\nsampling point generation, which ignores the importance of different object\nregions. However, we argue that, compared with the inner region, the outer\nregion plays a more important role for accurate 3D detection. To encode more\ninformation from the outer region, we propose a shape prior non-uniform\nsampling strategy that performs dense sampling in outer region and sparse\nsampling in inner region. As a result, more points are sampled from the outer\nregion and more useful features are extracted for 3D detection. Further, to\nenhance the feature discrimination of each sampling point, we propose a\nhigh-level semantic enhanced FCE module to exploit more contextual information\nand suppress noise better. Experiments on the KITTI dataset are performed to\nshow the effectiveness of the proposed method. Compared with the baseline\nRTS3D, our proposed method has 2.57% improvement on AP3d almost without extra\nnetwork parameters. Moreover, our proposed method outperforms the\nstate-of-the-art methods without extra supervision at a real-time speed.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "A. Gao",
      "J. Cao",
      "Y. Pang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10013"
  },
  {
    "id": "arXiv:2106.10014",
    "title": "Software-Defined Networking for Data Centre Network Management: A Survey",
    "abstract": "Data centres are growing in numbers and size, and their networks expanding to\ncarry larger amounts of traffic. The traffic profile is constantly varying,\nparticularly in cloud data centres where tenants arrive, leave, and may change\ntheir resource requirements in between, and so the network configuration must\nchange at a commensurate rate. Software-Defined Networking - programmatic\ncontrol of network configuration - has been critical to meeting the demands of\nmodern data centre network management, and has been the subject of intense\nfocus by the research community, working in conjunction with industry. In this\nsurvey, we review Software-Defined Networking research targeting the management\nand operation of data centre networks.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Jonathan Sherwin",
      "Cormac J. Sreenan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.10014"
  },
  {
    "id": "arXiv:2106.10015",
    "title": "Meta-control of social learning strategies",
    "abstract": "Social learning, copying other's behavior without actual experience, offers a\ncost-effective means of knowledge acquisition. However, it raises the\nfundamental question of which individuals have reliable information: successful\nindividuals versus the majority. The former and the latter are known\nrespectively as success-based and conformist social learning strategies. We\nshow here that while the success-based strategy fully exploits the benign\nenvironment of low uncertainly, it fails in uncertain environments. On the\nother hand, the conformist strategy can effectively mitigate this adverse\neffect. Based on these findings, we hypothesized that meta-control of\nindividual and social learning strategies provides effective and\nsample-efficient learning in volatile and uncertain environments. Simulations\non a set of environments with various levels of volatility and uncertainty\nconfirmed our hypothesis. The results imply that meta-control of social\nlearning affords agents the leverage to resolve environmental uncertainty with\nminimal exploration cost, by exploiting others' learning as an external\nknowledge base.",
    "descriptor": "",
    "authors": [
      "Anil Yaman",
      "Nicolas Bredeche",
      "Onur \u00c7aylak",
      "Joel Z. Leibo",
      "Sang Wan Lee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.10015"
  },
  {
    "id": "arXiv:2106.10016",
    "title": "Centrality Measures in Interval-Weighted Networks",
    "abstract": "Centrality measures are used in network science to evaluate the centrality of\nvertices or the position they occupy in a network. There are a large number of\ncentrality measures according to some criterion. However, the generalizations\nof the most well-known centrality measures for weighted networks, degree\ncentrality, closeness centrality, and betweenness centrality have solely\nassumed the edge weights to be constants. This paper proposes a methodology to\ngeneralize degree, closeness and betweenness centralities taking into account\nthe variability of edge weights in the form of closed intervals\n(Interval-Weighted Networks -- IWN). We apply our centrality measures approach\nto two real-world IWN. The first is a commuter network in mainland Portugal,\nbetween the 23 NUTS 3 Regions. The second focuses on annual merchandise trade\nbetween 28 European countries, from 2003 to 2015.",
    "descriptor": "",
    "authors": [
      "H\u00e9lder Alves",
      "Paula Brito",
      "Pedro Campos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10016"
  },
  {
    "id": "arXiv:2106.10019",
    "title": "Zero-Shot Federated Learning with New Classes for Audio Classification",
    "abstract": "Federated learning is an effective way of extracting insights from different\nuser devices while preserving the privacy of users. However, new classes with\ncompletely unseen data distributions can stream across any device in a\nfederated learning setting, whose data cannot be accessed by the global server\nor other users. To this end, we propose a unified zero-shot framework to handle\nthese aforementioned challenges during federated learning. We simulate two\nscenarios here -- 1) when the new class labels are not reported by the user,\nthe traditional FL setting is used; 2) when new class labels are reported by\nthe user, we synthesize Anonymized Data Impressions by calculating class\nsimilarity matrices corresponding to each device's new classes followed by\nunsupervised clustering to distinguish between new classes across different\nusers. Moreover, our proposed framework can also handle statistical\nheterogeneities in both labels and models across the participating users. We\nempirically evaluate our framework on-device across different communication\nrounds (FL iterations) with new classes in both local and global updates, along\nwith heterogeneous labels and models, on two widely used audio classification\napplications -- keyword spotting and urban sound classification, and observe an\naverage deterministic accuracy increase of ~4.041% and ~4.258% respectively.",
    "descriptor": "\nComments: Accepted at Interspeech 2021. Also accepted at the Distributed and Private Machine Learning (DPML) and Hardware Aware Efficient Training (HAET) workshops at ICLR 2021\n",
    "authors": [
      "Gautham Krishna Gudur",
      "Satheesh K. Perepu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.10019"
  },
  {
    "id": "arXiv:2106.10020",
    "title": "Pressure-robustness for the Stokes equations on anisotropic meshes",
    "abstract": "Pressure-robustness has been widely studied since the conception of the\nnotion and the introduction of the reconstruction approach for classical mixed\nmethods in [5]. Using discretizations capable of yielding velocity solutions\nthat are independent of the pressure approximation has been recognized as\nessential, and a large number of recent articles attest to this fact, e.g.,\n[1,6]. Apart from the pressure-robustness aspect, incompressible flows exhibit\nanisotropic phenomena in the solutions which can be dealt with by using\nanisotropic mesh grading. The recent publications [3,4] deal with the\ncombination of both challenges. We briefly revisit the results from [4] and\nprovide an insightful new numerical example.",
    "descriptor": "",
    "authors": [
      "Volker Kempf"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10020"
  },
  {
    "id": "arXiv:2106.10022",
    "title": "Local AdaGrad-Type Algorithm for Stochastic Convex-Concave Minimax  Problems",
    "abstract": "Large scale convex-concave minimax problems arise in numerous applications,\nincluding game theory, robust training, and training of generative adversarial\nnetworks. Despite their wide applicability, solving such problems efficiently\nand effectively is challenging in the presence of large amounts of data using\nexisting stochastic minimax methods. We study a class of stochastic minimax\nmethods and develop a communication-efficient distributed stochastic\nextragradient algorithm, LocalAdaSEG, with an adaptive learning rate suitable\nfor solving convex-concave minimax problem in the Parameter-Server model.\nLocalAdaSEG has three main features: (i) periodic communication strategy\nreduces the communication cost between workers and the server; (ii) an adaptive\nlearning rate that is computed locally and allows for tuning-free\nimplementation; and (iii) theoretically, a nearly linear speed-up with respect\nto the dominant variance term, arising from estimation of the stochastic\ngradient, is proven in both the smooth and nonsmooth convex-concave settings.\nLocalAdaSEG is used to solve a stochastic bilinear game, and train generative\nadversarial network. We compare LocalAdaSEG against several existing optimizers\nfor minimax problems and demonstrate its efficacy through several experiments\nin both the homogeneous and heterogeneous settings.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Luofeng Liao",
      "Li Shen",
      "Jia Duan",
      "Mladen Kolar",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10022"
  },
  {
    "id": "arXiv:2106.10026",
    "title": "EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action  Recognition 2021: Team M3EM Technical Report",
    "abstract": "In this report, we describe the technical details of our submission to the\n2021 EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action\nRecognition. Leveraging multiple modalities has been proved to benefit the\nUnsupervised Domain Adaptation (UDA) task. In this work, we present Multi-Modal\nMutual Enhancement Module (M3EM), a deep module for jointly considering\ninformation from multiple modalities to find the most transferable\nrepresentations across domains. We achieve this by implementing two sub-modules\nfor enhancing each modality using the context of other modalities. The first\nsub-module exchanges information across modalities through the semantic space,\nwhile the second sub-module finds the most transferable spatial region based on\nthe consensus of all modalities.",
    "descriptor": "",
    "authors": [
      "Lijin Yang",
      "Yifei Huang",
      "Yusuke Sugano",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10026"
  },
  {
    "id": "arXiv:2106.10031",
    "title": "Learning and Meshing from Deep Implicit Surface Networks Using an  Efficient Implementation of Analytic Marching",
    "abstract": "Reconstruction of object or scene surfaces has tremendous applications in\ncomputer vision, computer graphics, and robotics. In this paper, we study a\nfundamental problem in this context about recovering a surface mesh from an\nimplicit field function whose zero-level set captures the underlying surface.\nTo achieve the goal, existing methods rely on traditional meshing algorithms;\nwhile promising, they suffer from loss of precision learned in the implicit\nsurface networks, due to the use of discrete space sampling in marching cubes.\nGiven that an MLP with activations of Rectified Linear Unit (ReLU) partitions\nits input space into a number of linear regions, we are motivated to connect\nthis local linearity with a same property owned by the desired result of\npolygon mesh. More specifically, we identify from the linear regions,\npartitioned by an MLP based implicit function, the analytic cells and analytic\nfaces that are associated with the function's zero-level isosurface. We prove\nthat under mild conditions, the identified analytic faces are guaranteed to\nconnect and form a closed, piecewise planar surface. Based on the theorem, we\npropose an algorithm of analytic marching, which marches among analytic cells\nto exactly recover the mesh captured by an implicit surface network. We also\nshow that our theory and algorithm are equally applicable to advanced MLPs with\nshortcut connections and max pooling. Given the parallel nature of analytic\nmarching, we contribute AnalyticMesh, a software package that supports\nefficient meshing of implicit surface networks via CUDA parallel computing, and\nmesh simplification for efficient downstream processing. We apply our method to\ndifferent settings of generative shape modeling using implicit surface\nnetworks. Extensive experiments demonstrate our advantages over existing\nmethods in terms of both meshing accuracy and efficiency.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2002.06597\n",
    "authors": [
      "Jiabao Lei",
      "Kui Jia",
      "Yi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.10031"
  },
  {
    "id": "arXiv:2106.10034",
    "title": "Performance Analysis of Synergetic UAV-RIS Communication Networks",
    "abstract": "The effective integration of unmanned aerial vehicles (UAVs) in future\nwireless communication systems depends on the conscious use of their limited\nenergy, which constrains their flight time. Reconfigurable intelligent surfaces\n(RISs) can be used in combination with UAVs with the aim to improve the\ncommunication performance without increasing complexity at the UAVs' side. In\nthis paper, we propose a synergetic UAV-RIS communication system, utilizing a\nUAV with a directional antenna aiming to the RIS. Also, we present the link\nbudget analysis and closed-form expressions for the outage probability as well\nas for an important second order statistical parameter of the proposed\nsynergetic UAV-RIS communication system, the average outage duration. Finally,\nnumerical results illustrate the effectiveness of the proposed synergetic\nsystem.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Dimitrios Tyrovolas",
      "Sotiris A. Tegos",
      "Panagiotis D. Diamantoulakis",
      "George K. Karagiannidis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10034"
  },
  {
    "id": "arXiv:2106.10035",
    "title": "Longitudinal Compliance Analysis of AndroidApplications with Privacy  Policies",
    "abstract": "Contemporary mobile applications (apps) are designed to track, use, and share\nusers data, often without their consent, which result in potential privacy and\ntransparency issues. To investigate whether mobile apps are transparent about\nthe collect information about users and apps comply with their privacy\npolicies, we performed longitudinal analysis of the different versions of 268\nAndroid applications comprising 5,240 app releases or versions between 2008 and\n2016. We detect inconsistencies between apps' behaviors and stated use of data\ncollection, to reveal compliance issues. We utilize machine learning techniques\nto classify the privacy policy text to identify the purported practices that\ncollect and/or share users' personal information such as phone numbers and\nemail addresses. We then uncover the actual data leaks of an app through static\nand dynamic analysis. Over time, our results show a steady increase in the\noverall number of apps' data collection practices that are undisclosed in the\nprivacy policies. This is particularly troubling since privacy policy is the\nprimary tool for describing the app's privacy protection practices. We find\nthat newer versions of the apps are likely to be more non-compliant than their\npreceding versions. The discrepancies between the purported and actual data\npractices show that privacy policies are often incoherent with the apps'\nbehaviors, thus defying the `notice and choice' principle when users install\napps.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Saad Sajid Hashmi",
      "Nazar Waheed",
      "Gioacchino Tangari",
      "Muhammad Ikram",
      "Stephen Smith"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.10035"
  },
  {
    "id": "arXiv:2106.10038",
    "title": "Anomalous diffusion in the citation time series of scientific  publications",
    "abstract": "We analyze the citation time-series of manuscripts in three different fields\nof science; physics, social science and technology. The evolution of the\ntime-series of the yearly number of citations, namely the citation\ntrajectories, diffuse anomalously, their variance scales with time $\\propto\nt^{2H}$, where $H\\neq 1/2$. We provide detailed analysis of the various factors\nthat lead to the anomalous behavior: non-stationarity, long-ranged correlations\nand a fat-tailed increment distribution. The papers exhibit high degree of\nheterogeneity, across the various fields, as the statistics of the highest\ncited papers is fundamentally different from that of the lower ones. The\ncitation data is shown to be highly correlated and non-stationary; as all the\npapers except the small percentage of them with high number of citations, die\nout in time.",
    "descriptor": "\nComments: 12 pages, 12 figures\n",
    "authors": [
      "Maryam Zamani",
      "Erez Aghion",
      "Peter Pollner",
      "Tamas Vicsek",
      "Holger Kantz"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10038"
  },
  {
    "id": "arXiv:2106.10044",
    "title": "Training or Architecture? How to Incorporate Invariance in Neural  Networks",
    "abstract": "Many applications require the robustness, or ideally the invariance, of a\nneural network to certain transformations of input data. Most commonly, this\nrequirement is addressed by either augmenting the training data, using\nadversarial training, or defining network architectures that include the\ndesired invariance automatically. Unfortunately, the latter often relies on the\nability to enlist all possible transformations, which make such approaches\nlargely infeasible for infinite sets of transformations, such as arbitrary\nrotations or scaling. In this work, we propose a method for provably invariant\nnetwork architectures with respect to group actions by choosing one element\nfrom a (possibly continuous) orbit based on a fixed criterion. In a nutshell,\nwe intend to 'undo' any possible transformation before feeding the data into\nthe actual network. We analyze properties of such approaches, extend them to\nequivariant networks, and demonstrate their advantages in terms of robustness\nas well as computational efficiency in several numerical examples. In\nparticular, we investigate the robustness with respect to rotations of images\n(which can possibly hold up to discretization artifacts only) as well as the\nprovable rotational and scaling invariance of 3D point cloud classification.",
    "descriptor": "",
    "authors": [
      "Kanchana Vaishnavi Gandikota",
      "Jonas Geiping",
      "Zorah L\u00e4hner",
      "Adam Czapli\u0144ski",
      "Michael Moeller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10044"
  },
  {
    "id": "arXiv:2106.10045",
    "title": "Synchronising speech segments with musical beats in Mandarin and English  singing",
    "abstract": "Generating synthesised singing voice with models trained on speech data has\nmany advantages due to the models' flexibility and controllability. However,\nsince the information about the temporal relationship between segments and\nbeats are lacking in speech training data, the synthesised singing may sound\noff-beat at times. Therefore, the availability of the information on the\ntemporal relationship between speech segments and music beats is crucial. The\ncurrent study investigated the segment-beat synchronisation in singing data,\nwith hypotheses formed based on the linguistics theories of P-centre and\nsonority hierarchy. A Mandarin corpus and an English corpus of professional\nsinging data were manually annotated and analysed. The results showed that the\npresence of musical beats was more dependent on segment duration than sonority.\nHowever, the sonority hierarchy and the P-centre theory were highly related to\nthe location of beats. Mandarin and English demonstrated cross-linguistic\nvariations despite exhibiting common patterns.",
    "descriptor": "\nComments: To be published in the Proceeding of Interspeech 2021\n",
    "authors": [
      "Cong Zhang",
      "Jian Zhu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.10045"
  },
  {
    "id": "arXiv:2106.10046",
    "title": "Light Pollution Reduction in Nighttime Photography",
    "abstract": "Nighttime photographers are often troubled by light pollution of unwanted\nartificial lights. Artificial lights, after scattered by aerosols in the\natmosphere, can inundate the starlight and degrade the quality of nighttime\nimages, by reducing contrast and dynamic range and causing hazes. In this paper\nwe develop a physically-based light pollution reduction (LPR) algorithm that\ncan substantially alleviate the aforementioned degradations of perceptual\nquality and restore the pristine state of night sky. The key to the success of\nthe proposed LPR algorithm is an inverse method to estimate the spatial\nradiance distribution and spectral signature of ground artificial lights.\nExtensive experiments are carried out to evaluate the efficacy and limitations\nof the LPR algorithm.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Chang Liu",
      "Xiaolin Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.10046"
  },
  {
    "id": "arXiv:2106.10048",
    "title": "Comparative assessment of typical controlrealizations of grid forming  converters based ontheir voltage source behaviour",
    "abstract": "The converter control functions to provide the capabilities similar to\nsynchronous generators are referred to as grid forming converters (GFC).\nIdentical to a synchronous machine, a grid forming converter is expected to\nbehave as a voltage source behind an impedance beyond the control bandwidth.\nHowever, GFC's realization has been different, with some utilizes inner current\nand voltage controllers while others do not. This paper studies the impact of\nthe inner loop on the grid forming converter's ability to behave as a voltage\nsource behind an impedance. Three of the most popular GFC structures, 1) GFC\nwith cascaded voltage and current control, 2) with inner current control, 3)\nwith no inner loop, are chosen for the comparison. The analysis revealed that\nMW level GFC with inner loops could potentially go unstable under weak power\nsystem. Additionally, the GFC with cascaded control can only operate stably\nwithin a narrow range of network impedances. Furthermore, it is also shown that\nslow response behavior based on cascaded inner loop can impact on dynamic\nreactive and active power-sharing.",
    "descriptor": "\nComments: 22 pages, 28 figures\n",
    "authors": [
      "Kanakesh Vatta Kkuni",
      "Sibin Mohan",
      "Guangya Yang",
      "Wilsun Xu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10048"
  },
  {
    "id": "arXiv:2106.10050",
    "title": "A note on augmented unprojected Krylov subspace methods",
    "abstract": "Subspace recycling iterative methods and other subspace augmentation schemes\nare a successful extension to Krylov subspace methods in which a Krylov\nsubspace is augmented with a fixed subspace spanned by vectors deemed to be\nhelpful in accelerating convergence or conveying knowledge of the solution.\nRecently, a survey was published, in which a framework describing the vast\nmajority of such methods was proposed [Soodhalter et al, GAMM-Mitt. 2020]. In\nmany of these methods, the Krylov subspace is one generated by the system\nmatrix composed with a projector that depends on the augmentation space.\nHowever, it is not a requirement that a projected Krylov subspace be used.\nThere are augmentation methods built on using Krylov subspaces generated by the\noriginal system matrix, and these methods also fit into the general framework.\nIn this note, we observe that one gains implementation benefits by\nconsidering such augmentation methods with unprojected Krylov subspaces in the\ngeneral framework. We demonstrate this by applying the idea to the R$^3$GMRES\nmethod proposed in [Dong et al. ETNA 2014] to obtain a simplified\nimplementation and to connect that algorithm to early augmentation schemes\nbased on flexible preconditioning [Saad. SIMAX 1997].",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Kirk M. Soodhalter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10050"
  },
  {
    "id": "arXiv:2106.10053",
    "title": "Stopping Rules for Algebraic Iterative Reconstruction Methods in  Computed Tomography",
    "abstract": "Algebraic models for the reconstruction problem in X-ray computed tomography\n(CT) provide a flexible framework that applies to many measurement geometries.\nFor large-scale problems we need to use iterative solvers, and we need stopping\nrules for these methods that terminate the iterations when we have computed a\nsatisfactory reconstruction that balances the reconstruction error and the\ninfluence of noise from the measurements. Many such stopping rules are\ndeveloped in the inverse problems communities, but they have not attained much\nattention in the CT world. The goal of this paper is to describe and illustrate\nfour stopping rules that are relevant for CT reconstructions.",
    "descriptor": "\nComments: 11 pages, 10 figures\n",
    "authors": [
      "Per Christian Hansen",
      "Jakob Sauer J\u00f8rgensen",
      "Peter Winkel Rasmussen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10053"
  },
  {
    "id": "arXiv:2106.10056",
    "title": "A Vertical Federated Learning Framework for Horizontally Partitioned  Labels",
    "abstract": "Vertical federated learning is a collaborative machine learning framework to\ntrain deep leaning models on vertically partitioned data with\nprivacy-preservation. It attracts much attention both from academia and\nindustry. Unfortunately, applying most existing vertical federated learning\nmethods in real-world applications still faces two daunting challenges. First,\nmost existing vertical federated learning methods have a strong assumption that\nat least one party holds the complete set of labels of all data samples, while\nthis assumption is not satisfied in many practical scenarios, where labels are\nhorizontally partitioned and the parties only hold partial labels. Existing\nvertical federated learning methods can only utilize partial labels, which may\nlead to inadequate model update in end-to-end backpropagation. Second,\ncomputational and communication resources vary in parties. Some parties with\nlimited computational and communication resources will become the stragglers\nand slow down the convergence of training. Such straggler problem will be\nexaggerated in the scenarios of horizontally partitioned labels in vertical\nfederated learning. To address these challenges, we propose a novel vertical\nfederated learning framework named Cascade Vertical Federated Learning (CVFL)\nto fully utilize all horizontally partitioned labels to train neural networks\nwith privacy-preservation. To mitigate the straggler problem, we design a novel\noptimization objective which can increase straggler's contribution to the\ntrained models. We conduct a series of qualitative experiments to rigorously\nverify the effectiveness of CVFL. It is demonstrated that CVFL can achieve\ncomparable performance (e.g., accuracy for classification tasks) with\ncentralized training. The new optimization objective can further mitigate the\nstraggler problem comparing with only using the asynchronous aggregation\nmechanism during training.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Wensheng Xia",
      "Ying Li",
      "Lan Zhang",
      "Zhonghai Wu",
      "Xiaoyong Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10056"
  },
  {
    "id": "arXiv:2106.10060",
    "title": "Contrastive Learning of Generalized Game Representations",
    "abstract": "Representing games through their pixels offers a promising approach for\nbuilding general-purpose and versatile game models. While games are not merely\nimages, neural network models trained on game pixels often capture differences\nof the visual style of the image rather than the content of the game. As a\nresult, such models cannot generalize well even within similar games of the\nsame genre. In this paper we build on recent advances in contrastive learning\nand showcase its benefits for representation learning in games. Learning to\ncontrast images of games not only classifies games in a more efficient manner;\nit also yields models that separate games in a more meaningful fashion by\nignoring the visual style and focusing, instead, on their content. Our results\nin a large dataset of sports video games containing 100k images across 175\ngames and 10 game genres suggest that contrastive learning is better suited for\nlearning generalized game representations compared to conventional supervised\nlearning. The findings of this study bring us closer to universal visual\nencoders for games that can be reused across previously unseen games without\nrequiring retraining or fine-tuning.",
    "descriptor": "\nComments: 8 pages, 7 figures, CoG\n",
    "authors": [
      "Chintan Trivedi",
      "Antonios Liapis",
      "Georgios N. Yannakakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10060"
  },
  {
    "id": "arXiv:2106.10062",
    "title": "The ensemble Kalman filter for rare event estimation",
    "abstract": "We present a novel sampling-based method for estimating probabilities of rare\nor failure events. Our approach is founded on the Ensemble Kalman filter (EnKF)\nfor inverse problems. Therefore, we reformulate the rare event problem as an\ninverse problem and apply the EnKF to generate failure samples. To estimate the\nprobability of failure, we use the final EnKF samples to fit a distribution\nmodel and apply Importance Sampling with respect to the fitted distribution.\nThis leads to an unbiased estimator if the density of the fitted distribution\nadmits positive values within the whole failure domain. To handle multi-modal\nfailure domains, we localise the covariance matrices in the EnKF update step\naround each particle and fit a mixture distribution model in the Importance\nSampling step. For affine linear limit-state functions, we investigate the\ncontinuous-time limit and large time properties of the EnKF update. We prove\nthat the mean of the particles converges to a convex combination of the most\nlikely failure point and the mean of the optimal Importance Sampling density if\nthe EnKF is applied without noise. We provide numerical experiments to compare\nthe performance of the EnKF with Sequential Importance Sampling.",
    "descriptor": "",
    "authors": [
      "Fabian Wagner",
      "Iason Papaioannou",
      "Elisabeth Ullmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10062"
  },
  {
    "id": "arXiv:2106.10063",
    "title": "V-Edge: Virtual Edge Computing as an Enabler for Novel Microservices and  Cooperative Computing",
    "abstract": "As we move from 5G to 6G, edge computing is one of the concepts that needs\nrevisiting. Its core idea is still intriguing: instead of sending all data and\ntasks from an end user's device to the cloud, possibly covering thousands of\nkilometers and introducing delays that are just owed to limited propagation\nspeed, edge servers deployed in close proximity to the user, e.g., at some 5G\ngNB, serve as proxy for the cloud. Yet this promising idea is hampered by the\nlimited availability of such edge servers. In this paper, we discuss a way\nforward, namely the virtual edge computing (V-Edge) concept. V-Edge bridges the\ngap between cloud, edge, and fog by virtualizing all available resources\nincluding the end users' devices and making these resources widely available\nusing well-defined interfaces. V-Edge also acts as an enabler for novel\nmicroservices as well as cooperative computing solutions. We introduce the\ngeneral V-Edge architecture and we characterize some of the key research\nchallenges to overcome, in order to enable wide-spread and even more powerful\nedge services.",
    "descriptor": "",
    "authors": [
      "Falko Dressler",
      "Carla Fabiana Chiasserini",
      "Frank H.P. Fitzek",
      "Holger Karl",
      "Renato Lo Cigno",
      "Antonio Capone",
      "Claudio Casetti",
      "Francesco Malandrino",
      "Vincenzo Mancuso",
      "Florian Klingler",
      "Gianluca Rizzo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.10063"
  },
  {
    "id": "arXiv:2106.10065",
    "title": "Being a Bit Frequentist Improves Bayesian Neural Networks",
    "abstract": "Despite their compelling theoretical properties, Bayesian neural networks\n(BNNs) tend to perform worse than frequentist methods in classification-based\nuncertainty quantification (UQ) tasks such as out-of-distribution (OOD)\ndetection and dataset-shift robustness. In this work, based on empirical\nfindings in prior works, we hypothesize that this issue is due to the avoidance\nof Bayesian methods in the so-called \"OOD training\" -- a family of techniques\nfor incorporating OOD data during training process, which has since been an\nintegral part of state-of-the-art frequentist UQ methods. To validate this, we\ntreat OOD data as a first-class citizen in BNN training by exploring four\ndifferent ways of incorporating OOD data in Bayesian inference. We show in\nextensive experiments that OOD-trained BNNs are competitive to, if not better\nthan recent frequentist baselines. This work thus provides strong baselines for\nfuture work in both Bayesian and frequentist UQ.",
    "descriptor": "",
    "authors": [
      "Agustinus Kristiadi",
      "Matthias Hein",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10065"
  },
  {
    "id": "arXiv:2106.10068",
    "title": "Differentially private sparse vectors with low error, optimal space, and  fast access",
    "abstract": "Representing a sparse histogram, or more generally a sparse vector, is a\nfundamental task in differential privacy. An ideal solution would use space\nclose to information-theoretical lower bounds, have an error distribution that\ndepends optimally on the desired privacy level, and allow fast random access to\nentries in the vector. However, existing approaches have only achieved two of\nthese three goals.\nIn this paper we introduce the Approximate Laplace Projection (ALP) mechanism\nfor approximating k-sparse vectors. This mechanism is shown to simultaneously\nhave information-theoretically optimal space (up to constant factors), fast\naccess to vector entries, and error of the same magnitude as the\nLaplace-mechanism applied to dense vectors. A key new technique is a unary\nrepresentation of small integers, which is shown to be robust against\n``randomized response'' noise. This representation is combined with hashing, in\nthe spirit of Bloom filters, to obtain a space-efficient, differentially\nprivate representation. Our theoretical performance bounds are complemented by\nsimulations which show that the constant factors on the main performance\nparameters are quite small, suggesting practicality of the technique.",
    "descriptor": "",
    "authors": [
      "Martin Aum\u00fcller",
      "Christian Janos Lebeda",
      "Rasmus Pagh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.10068"
  },
  {
    "id": "arXiv:2106.10069",
    "title": "Point-of-Interest Recommender Systems: A Survey from an Experimental  Perspective",
    "abstract": "Point-of-Interest recommendation is an increasing research and developing\narea within the widely adopted technologies known as Recommender Systems. Among\nthem, those that exploit information coming from Location-Based Social Networks\n(LBSNs) are very popular nowadays and could work with different information\nsources, which pose several challenges and research questions to the community\nas a whole. We present a systematic review focused on the research done in the\nlast 10 years about this topic. We discuss and categorize the algorithms and\nevaluation methodologies used in these works and point out the opportunities\nand challenges that remain open in the field. More specifically, we report the\nleading recommendation techniques and information sources that have been\nexploited more often (such as the geographical signal and deep learning\napproaches) while we also alert about the lack of reproducibility in the field\nthat may hinder real performance improvements.",
    "descriptor": "\nComments: Submitted in Jul 2020 (revised in Jun 2021, still under review) to ACM Computing Surveys\n",
    "authors": [
      "Pablo S\u00e1nchez",
      "Alejandro Bellog\u00edn"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.10069"
  },
  {
    "id": "arXiv:2106.10070",
    "title": "Residual Contrastive Learning for Joint Demosaicking and Denoising",
    "abstract": "The breakthrough of contrastive learning (CL) has fueled the recent success\nof self-supervised learning (SSL) in high-level vision tasks on RGB images.\nHowever, CL is still ill-defined for low-level vision tasks, such as joint\ndemosaicking and denoising (JDD), in the RAW domain. To bridge this\nmethodological gap, we present a novel CL approach on RAW images, residual\ncontrastive learning (RCL), which aims to learn meaningful representations for\nJDD. Our work is built on the assumption that noise contained in each RAW image\nis signal-dependent, thus two crops from the same RAW image should have more\nsimilar noise distribution than two crops from different RAW images. We use\nresiduals as a discriminative feature and the earth mover's distance to measure\nthe distribution divergence for the contrastive loss. To evaluate the proposed\nCL strategy, we simulate a series of unsupervised JDD experiments with\nlarge-scale data corrupted by synthetic signal-dependent noise, where we set a\nnew benchmark for unsupervised JDD tasks with unknown (random) noise variance.\nOur empirical study not only validates that CL can be applied on distributions\n(c.f. features), but also exposes the lack of robustness of previous non-ML and\nSSL JDD methods when the statistics of the noise are unknown, thus providing\nsome further insight into signal-dependent noise problems.",
    "descriptor": "",
    "authors": [
      "Nanqing Dong",
      "Matteo Maggioni",
      "Yongxin Yang",
      "Eduardo P\u00e9rez-Pellitero",
      "Ales Leonardis",
      "Steven McDonagh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10070"
  },
  {
    "id": "arXiv:2106.10075",
    "title": "Learning to Plan via a Multi-Step Policy Regression Method",
    "abstract": "We propose a new approach to increase inference performance in environments\nthat require a specific sequence of actions in order to be solved. This is for\nexample the case for maze environments where ideally an optimal path is\ndetermined. Instead of learning a policy for a single step, we want to learn a\npolicy that can predict n actions in advance. Our proposed method called policy\nhorizon regression (PHR) uses knowledge of the environment sampled by A2C to\nlearn an n dimensional policy vector in a policy distillation setup which\nyields n sequential actions per observation. We test our method on the MiniGrid\nand Pong environments and show drastic speedup during inference time by\nsuccessfully predicting sequences of actions on a single observation.",
    "descriptor": "\nComments: Accepted at the 30th International Conference on Artificial Neural Networks (ICANN 2021)\n",
    "authors": [
      "Stefan Wagner",
      "Michael Janschek",
      "Tobias Uelwer",
      "Stefan Harmeling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10075"
  },
  {
    "id": "arXiv:2106.10076",
    "title": "Label Mask for Multi-Label Text Classification",
    "abstract": "One of the key problems in multi-label text classification is how to take\nadvantage of the correlation among labels. However, it is very challenging to\ndirectly model the correlations among labels in a complex and unknown label\nspace. In this paper, we propose a Label Mask multi-label text classification\nmodel (LM-MTC), which is inspired by the idea of cloze questions of language\nmodel. LM-MTC is able to capture implicit relationships among labels through\nthe powerful ability of pre-train language models. On the basis, we assign a\ndifferent token to each potential label, and randomly mask the token with a\ncertain probability to build a label based Masked Language Model (MLM). We\ntrain the MTC and MLM together, further improving the generalization ability of\nthe model. A large number of experiments on multiple datasets demonstrate the\neffectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Rui Song",
      "Xingbing Chen",
      "Zelong Liu",
      "Haining An",
      "Zhiqi Zhang",
      "Xiaoguang Wang",
      "Hao Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10076"
  },
  {
    "id": "arXiv:2106.10077",
    "title": "Combined Person Classification with Airborne Optical Sectioning",
    "abstract": "Fully autonomous drones have been demonstrated to find lost or injured\npersons under strongly occluding forest canopy. Airborne Optical Sectioning\n(AOS), a novel synthetic aperture imaging technique, together with\ndeep-learning-based classification enables high detection rates under realistic\nsearch-and-rescue conditions. We demonstrate that false detections can be\nsignificantly suppressed and true detections boosted by combining\nclassifications from multiple AOS rather than single integral images. This\nimproves classification rates especially in the presence of occlusion. To make\nthis possible, we modified the AOS imaging process to support large overlaps\nbetween subsequent integrals, enabling real-time and on-board scanning and\nprocessing of groundspeeds up to 10 m/s.",
    "descriptor": "\nComments: 9 Pages, 7 Figures, 1 Table. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Indrajit Kurmi",
      "David C. Schedl",
      "Oliver Bimber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10077"
  },
  {
    "id": "arXiv:2106.10083",
    "title": "An Analysis of Transaction Handling in Bitcoin",
    "abstract": "Bitcoin has become the leading cryptocurrency system, but the limit on its\ntransaction processing capacity has resulted in increased transaction fees and\ndelayed transaction confirmation. As such, it is pertinent to understand and\nprobably predict how transactions are handled by Bitcoin such that a user may\nadapt the transaction requests and a miner may adjust the block generation\nstrategy and/or the mining pool to join. To this aim, the present paper\nintroduces results from an analysis of transaction handling in Bitcoin.\nSpecifically, the analysis consists of two-part. The first part is an\nexploratory data analysis revealing key characteristics in Bitcoin transaction\nhandling. The second part is a predictability analysis intended to provide\ninsights on transaction handling such as (i) transaction confirmation time,\n(ii) block attributes, and (iii) who has created the block. The result shows\nthat some models do reasonably well for (ii), but surprisingly not for (i) or\n(iii).",
    "descriptor": "",
    "authors": [
      "Befekadu G. Gebraselase",
      "Bjarne E. Helvik",
      "Yuming Jiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.10083"
  },
  {
    "id": "arXiv:2106.10084",
    "title": "Subjective Bias in Abstractive Summarization",
    "abstract": "Due to the subjectivity of the summarization, it is a good practice to have\nmore than one gold summary for each training document. However, many modern\nlarge-scale abstractive summarization datasets have only one-to-one samples\nwritten by different human with different styles. The impact of this phenomenon\nis understudied. We formulate the differences among possible multiple\nexpressions summarizing the same content as subjective bias and examine the\nrole of this bias in the context of abstractive summarization. In this paper a\nlightweight and effective method to extract the feature embeddings of\nsubjective styles is proposed. Results of summarization models trained on\nstyle-clustered datasets show that there are certain types of styles that lead\nto better convergence, abstraction and generalization. The reproducible code\nand generated summaries are available online.",
    "descriptor": "\nComments: 10 pages, 7 figures, 4 tables\n",
    "authors": [
      "Lei Li",
      "Wei Liu",
      "Marina Litvak",
      "Natalia Vanetik",
      "Jiacheng Pei",
      "Yinan Liu",
      "Siya Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10084"
  },
  {
    "id": "arXiv:2106.10086",
    "title": "It's FLAN time! Summing feature-wise latent representations for  interpretability",
    "abstract": "Interpretability has become a necessary feature for machine learning models\ndeployed in critical scenarios, e.g. legal systems, healthcare. In these\nsituations, algorithmic decisions may have (potentially negative) long-lasting\neffects on the end-user affected by the decision. In many cases, the\nrepresentational power of deep learning models is not needed, therefore simple\nand interpretable models (e.g. linear models) should be preferred. However, in\nhigh-dimensional and/or complex domains (e.g. computer vision), the universal\napproximation capabilities of neural networks is required. Inspired by linear\nmodels and the Kolmogorov-Arnol representation theorem, we propose a novel\nclass of structurally-constrained neural networks, which we call FLANs\n(Feature-wise Latent Additive Networks). Crucially, FLANs process each input\nfeature separately, computing for each of them a representation in a common\nlatent space. These feature-wise latent representations are then simply summed,\nand the aggregated representation is used for prediction. These constraints\n(which are at the core of the interpretability of linear models) allow an user\nto estimate the effect of each individual feature independently from the\nothers, enhancing interpretability. In a set of experiments across different\ndomains, we show how without compromising excessively the test performance, the\nstructural constraints proposed in FLANs indeed increase the interpretability\nof deep learning models.",
    "descriptor": "",
    "authors": [
      "An-phi Nguyen",
      "Maria Rodriguez Martinez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10086"
  },
  {
    "id": "arXiv:2106.10088",
    "title": "Conservative iterative methods for implicit discretizations of  conservation laws",
    "abstract": "Conservation properties of iterative methods applied to implicit finite\nvolume discretizations of nonlinear conservation laws are analyzed. It is shown\nthat any consistent multistep or Runge-Kutta method is globally conservative.\nFurther, it is shown that Newton's method, Krylov subspace methods and\npseudo-time iterations are globally conservative while the Jacobi and\nGauss-Seidel methods are not in general. If pseudo-time iterations using an\nexplicit Runge-Kutta method are applied to a locally conservative\ndiscretization, then the resulting scheme is also locally conservative.\nHowever, the corresponding numerical flux can be inconsistent with the\nconservation law. We prove an extension of the Lax-Wendroff theorem, which\nreveals that numerical solutions based on these methods converge to weak\nsolutions of a modified conservation law where the flux function is multiplied\nby a particular constant. This constant depends on the choice of Runge-Kutta\nmethod but is independent of both the conservation law and the discretization.\nConsistency is maintained by ensuring that this constant equals unity and a\nstrategy for achieving this is presented. Experiments show that this strategy\nimproves the convergence rate of the pseudo-time iterations.",
    "descriptor": "\nComments: 39 pages, 14 figures\n",
    "authors": [
      "Philipp Birken",
      "Viktor Linders"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10088"
  },
  {
    "id": "arXiv:2106.10090",
    "title": "Discerning Generic Event Boundaries in Long-Form Wild Videos",
    "abstract": "Detecting generic, taxonomy-free event boundaries invideos represents a major\nstride forward towards holisticvideo understanding. In this paper we present a\ntechnique forgeneric event boundary detection based on a two stream in-flated\n3D convolutions architecture, which can learn spatio-temporal features from\nvideos. Our work is inspired from theGeneric Event Boundary Detection Challenge\n(part of CVPR2021 Long Form Video Understanding- LOVEU Workshop).Throughout the\npaper we provide an in-depth analysis ofthe experiments performed along with an\ninterpretation ofthe results obtained.",
    "descriptor": "\nComments: Technical Report for Generic Event Boundary Challenge - LOVEU Challenge (CVPR 2021)\n",
    "authors": [
      "Ayush K Rai",
      "Tarun Krishna",
      "Julia Dietlmeier",
      "Kevin McGuinness",
      "Alan F Smeaton",
      "Noel E O'Connor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10090"
  },
  {
    "id": "arXiv:2106.10093",
    "title": "Remarks about the Arithmetic of Graphs",
    "abstract": "The arithmetic of N, Z, Q, R can be extended to a graph arithmetic where N is\nthe semiring of finite simple graphs and where Z and Q are integral domains,\nculminating in a Banach algebra R. A single network completes to the Wiener\nalgebra. We illustrate the compatibility with topology and spectral theory.\nMultiplicative linear functionals like Euler characteristic, the Poincare\npolynomial or the zeta functions can be extended naturally. These functionals\ncan also help with number theoretical questions. The story of primes is a bit\ndifferent as the integers are not a unique factorization domain, because there\nare many additive primes. Most graphs are multiplicative primes.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Oliver Knill"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2106.10093"
  },
  {
    "id": "arXiv:2106.10097",
    "title": "The Graphical Traveling Salesperson Problem has no Integer Programming  Formulation in the Original Space",
    "abstract": "The Graphical Traveling Salesperson Problem (GTSP) is the problem of\nassigning, for a given weighted graph, a nonnegative number $x_e$ each edge $e$\nsuch that the induced multi-subgraph is of minimum weight among those that are\nspanning, connected and Eulerian. Naturally, known mixed-integer programming\nformulations use integer variables $x_e$ in addition to others. Denis Naddef\nposed the challenge of finding a (reasonably simple) mixed-integer programming\nformulation that has integrality constraints only on these edge variables.\nRecently, Carr and Simonetti (IPCO 2021) showed that such a formulation cannot\nconsist of polynomial-time certifyiable inequality classes unless\n$\\mathsf{NP}=\\mathsf{coNP}$. In this note we establish a more rigorous result,\nnamely that no such MIP formulation exists at all.",
    "descriptor": "\nComments: 3 pages, 1 figure\n",
    "authors": [
      "Matthias Walter"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10097"
  },
  {
    "id": "arXiv:2106.10102",
    "title": "hSMAL: Detailed Horse Shape and Pose Reconstruction for Motion Pattern  Recognition",
    "abstract": "In this paper we present our preliminary work on model-based behavioral\nanalysis of horse motion. Our approach is based on the SMAL model, a 3D\narticulated statistical model of animal shape. We define a novel SMAL model for\nhorses based on a new template, skeleton and shape space learned from $37$\nhorse toys. We test the accuracy of our hSMAL model in reconstructing a horse\nfrom 3D mocap data and images. We apply the hSMAL model to the problem of\nlameness detection from video, where we fit the model to images to recover 3D\npose and train an ST-GCN network on pose data. A comparison with the same\nnetwork trained on mocap points illustrates the benefit of our approach.",
    "descriptor": "\nComments: CV4Animals Workshop in CVPR 2021\n",
    "authors": [
      "Ci Li",
      "Nima Ghorbani",
      "Sofia Broom\u00e9",
      "Maheen Rashid",
      "Michael J. Black",
      "Elin Hernlund",
      "Hedvig Kjellstr\u00f6m",
      "Silvia Zuffi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10102"
  },
  {
    "id": "arXiv:2106.10104",
    "title": "ELMOPP: An Application of Graph Theory and Machine Learning to Traffic  Light Coordination",
    "abstract": "Traffic light management is a broad subject with various papers published\nthat put forth algorithms to efficiently manage traffic using traffic lights.\nTwo such algorithms are the OAF (oldest arrival first) and ITLC (intelligent\ntraffic light controller) algorithms. However, many traffic light algorithms do\nnot consider future traffic flow and therefore cannot mitigate traffic in such\na way as to reduce future traffic in the present. This paper presents the Edge\nLoad Management and Optimization through Pseudoflow Prediction (ELMOPP)\nalgorithm, which aims to solve problems detailed in previous algorithms;\nthrough machine learning with nested long short-term memory (NLSTM) modules and\ngraph theory, the algorithm attempts to predict the near future using past data\nand traffic patterns to inform its real-time decisions and better mitigate\ntraffic by predicting future traffic flow based on past flow and using those\npredictions to both maximize present traffic flow and decrease future traffic\ncongestion. Furthermore, while ITLC and OAF require the use of GPS\ntransponders; and GPS, speed sensors, and radio, respectively, ELMOPP only uses\ntraffic light camera footage, something that is almost always readily available\nin contrast to GPS and speed sensors. ELMOPP was tested against the ITLC and\nOAF traffic management algorithms using a simulation modeled after the one\npresented in the ITLC paper, a single-intersection simulation, and the\ncollected data supports the conclusion that ELMOPP statistically significantly\noutperforms both algorithms in throughput rate, a measure of how many vehicles\nare able to exit inroads every second.",
    "descriptor": "\nComments: 13 pages, 3 figures, published in Applied Computing and Informatics (2021)\n",
    "authors": [
      "Fareed Sheriff"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.10104"
  },
  {
    "id": "arXiv:2106.10105",
    "title": "Boolean Matrix Factorization with SAT and MaxSAT",
    "abstract": "The Boolean matrix factorization problem consists in approximating a matrix\nby the Boolean product of two smaller Boolean matrices. To obtain optimal\nsolutions when the matrices to be factorized are small, we propose SAT and\nMaxSAT encoding; however, when the matrices to be factorized are large, we\npropose a heuristic based on the search for maximal biclique edge cover. We\nexperimentally demonstrate that our approaches allow a better factorization\nthan existing approaches while keeping reasonable computation times. Our\nmethods also allow the handling of incomplete matrices with missing entries.",
    "descriptor": "",
    "authors": [
      "Florent Avellaneda",
      "Roger Villemaire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10105"
  },
  {
    "id": "arXiv:2106.10108",
    "title": "Under the Sand: Navigation and Localization of a Small Unmanned Aerial  Vehicle for Landmine Detection with Ground Penetrating Synthetic Aperture  Radar",
    "abstract": "Ground penetrating radar mounted on a small unmanned aerial vehicle (UAV) is\na promising tool to assist humanitarian landmine clearance. However, the\nquality of synthetic aperture radar images depends on accurate and precise\nmotion estimation of the radar antennas as well as generating informative\nviewpoints with the UAV. This paper presents a complete and automatic airborne\nground-penetrating synthetic aperture radar (GPSAR) system. The system consists\nof a spatially calibrated and temporally synchronized industrial grade sensor\nsuite that enables navigation above ground level, radar imaging, and optical\nimaging. A custom mission planning framework allows generation and automatic\nexecution of stripmap and circular GPSAR trajectories controlled above ground\nlevel as well as aerial imaging survey flights. A factor graph based state\nestimator fuses measurements from dual receiver real-time kinematic (RTK)\nglobal navigation satellite system (GNSS) and an inertial measurement unit\n(IMU) to obtain precise, high rate platform positions and orientations. Ground\ntruth experiments showed sensor timing as accurate as 0.8 {\\mu}s and as precise\nas 0.1 {\\mu}s with localization rates of 1 kHz. The dual position factor\nformulation improves online localization accuracy up to 40 % and batch\nlocalization accuracy up to 59 % compared to a single position factor with\nuncertain heading initialization. Our field trials validated a localization\naccuracy and precision that enables coherent radar measurement addition and\ndetection of radar targets buried in sand. This validates the potential as an\naerial landmine detection system.",
    "descriptor": "\nComments: Submitted to Field Robotics journal in June 2021\n",
    "authors": [
      "Rik B\u00e4hnemann",
      "Nicholas Lawrance",
      "Lucas Streichenberg",
      "Jen Jen Chung",
      "Michael Pantic",
      "Alexander Grathwohl",
      "Christian Waldschmidt",
      "Roland Siegwart"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10108"
  },
  {
    "id": "arXiv:2106.10110",
    "title": "Towards Distraction-Robust Active Visual Tracking",
    "abstract": "In active visual tracking, it is notoriously difficult when distracting\nobjects appear, as distractors often mislead the tracker by occluding the\ntarget or bringing a confusing appearance. To address this issue, we propose a\nmixed cooperative-competitive multi-agent game, where a target and multiple\ndistractors form a collaborative team to play against a tracker and make it\nfail to follow. Through learning in our game, diverse distracting behaviors of\nthe distractors naturally emerge, thereby exposing the tracker's weakness,\nwhich helps enhance the distraction-robustness of the tracker. For effective\nlearning, we then present a bunch of practical methods, including a reward\nfunction for distractors, a cross-modal teacher-student learning strategy, and\na recurrent attention mechanism for the tracker. The experimental results show\nthat our tracker performs desired distraction-robust active visual tracking and\ncan be well generalized to unseen environments. We also show that the\nmulti-agent game can be used to adversarially test the robustness of trackers.",
    "descriptor": "\nComments: To appear in ICML2021\n",
    "authors": [
      "Fangwei Zhong",
      "Peng Sun",
      "Wenhan Luo",
      "Tingyun Yan",
      "Yizhou Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10110"
  },
  {
    "id": "arXiv:2106.10112",
    "title": "Deep Reinforcement Learning Models Predict Visual Responses in the  Brain: A Preliminary Result",
    "abstract": "Supervised deep convolutional neural networks (DCNNs) are currently one of\nthe best computational models that can explain how the primate ventral visual\nstream solves object recognition. However, embodied cognition has not been\nconsidered in the existing visual processing models. From the ecological\nstandpoint, humans learn to recognize objects by interacting with them,\nallowing better classification, specialization, and generalization. Here, we\nask if computational models under the embodied learning framework can explain\nmechanisms underlying object recognition in the primate visual system better\nthan the existing supervised models? To address this question, we use\nreinforcement learning to train neural network models to play a 3D computer\ngame and we find that these reinforcement learning models achieve neural\nresponse prediction accuracy scores in the early visual areas (e.g., V1 and V2)\nin the levels that are comparable to those accomplished by the supervised\nneural network model. In contrast, the supervised neural network models yield\nbetter neural response predictions in the higher visual areas, compared to the\nreinforcement learning models. Our preliminary results suggest the future\ndirection of visual neuroscience in which deep reinforcement learning should be\nincluded to fill the missing embodiment concept.",
    "descriptor": "",
    "authors": [
      "Maytus Piriyajitakonkij",
      "Sirawaj Itthipuripat",
      "Theerawit Wilaiprasitporn",
      "Nat Dilokthanakul"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.10112"
  },
  {
    "id": "arXiv:2106.10118",
    "title": "Virtual Temporal Samples for Recurrent Neural Networks: applied to  semantic segmentation in agriculture",
    "abstract": "This paper explores the potential for performing temporal semantic\nsegmentation in the context of agricultural robotics without temporally\nlabelled data. We achieve this by proposing to generate virtual temporal\nsamples from labelled still images. This allows us, with no extra annotation\neffort, to generate virtually labelled temporal sequences. Normally, to train a\nrecurrent neural network (RNN), labelled samples from a video (temporal)\nsequence are required which is laborious and has stymied work in this\ndirection. By generating virtual temporal samples, we demonstrate that it is\npossible to train a lightweight RNN to perform semantic segmentation on two\nchallenging agricultural datasets. Our results show that by training a temporal\nsemantic segmenter using virtual samples we can increase the performance by an\nabsolute amount of 4.6 and 4.9 on sweet pepper and sugar beet datasets,\nrespectively. This indicates that our virtual data augmentation technique is\nable to accurately classify agricultural images temporally without the use of\ncomplicated synthetic data generation techniques nor with the overhead of\nlabelling large amounts of temporal sequences.",
    "descriptor": "",
    "authors": [
      "Alireza Ahmadi",
      "Michael Halstead",
      "Chris McCool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10118"
  },
  {
    "id": "arXiv:2106.10121",
    "title": "ScoreGrad: Multivariate Probabilistic Time Series Forecasting with  Continuous Energy-based Generative Models",
    "abstract": "Multivariate time series prediction has attracted a lot of attention because\nof its wide applications such as intelligence transportation, AIOps. Generative\nmodels have achieved impressive results in time series modeling because they\ncan model data distribution and take noise into consideration. However, many\nexisting works can not be widely used because of the constraints of functional\nform of generative models or the sensitivity to hyperparameters. In this paper,\nwe propose ScoreGrad, a multivariate probabilistic time series forecasting\nframework based on continuous energy-based generative models. ScoreGrad is\ncomposed of time series feature extraction module and conditional stochastic\ndifferential equation based score matching module. The prediction can be\nachieved by iteratively solving reverse-time SDE. To the best of our knowledge,\nScoreGrad is the first continuous energy based generative model used for time\nseries forecasting. Furthermore, ScoreGrad achieves state-of-the-art results on\nsix real-world datasets. The impact of hyperparameters and sampler types on the\nperformance are also explored. Code is available at\nhttps://github.com/yantijin/ScoreGradPred.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Tijin Yan",
      "Hongwei Zhang",
      "Tong Zhou",
      "Yufeng Zhan",
      "Yuanqing Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10121"
  },
  {
    "id": "arXiv:2106.10122",
    "title": "Asymptotic elimination of partially continuous aggregation functions in  directed graphical models",
    "abstract": "In Statistical Relational Artificial Intelligence, a branch of AI and machine\nlearning which combines the logical and statistical schools of AI, one uses the\nconcept {\\em para\\-metrized probabilistic graphical model (PPGM)} to model\n(conditional) dependencies between random variables and to make probabilistic\ninferences about events on a space of ``possible worlds''. The set of possible\nworlds with underlying domain $D$ (a set of objects) can be represented by the\nset $\\mathbf{W}_D$ of all first-order structures (for a suitable signature)\nwith domain $D$. Using a formal logic we can describe events on $\\mathbf{W}_D$.\nBy combining a logic and a PPGM we can also define a probability distribution\n$\\mathbb{P}_D$ on $\\mathbf{W}_D$ and use it to compute the probability of an\nevent. We consider a logic, denoted $PLA$, with truth values in the unit\ninterval, which uses aggregation functions, such as arithmetic mean, geometric\nmean, maximum and minimum instead of quantifiers. However we face the problem\nof computational efficiency and this problem is an obstacle to the wider use of\nmethods from Statistical Relational AI in practical applications. We address\nthis problem by proving that the described probability will, under certain\nassumptions on the PPGM and the sentence $\\varphi$, converge as the size of $D$\ntends to infinity. The convergence result is obtained by showing that every\nformula $\\varphi(x_1, \\ldots, x_k)$ which contains only ``admissible''\naggregation functions (e.g. arithmetic and geometric mean, max and min) is\nasymptotically equivalent to a formula $\\psi(x_1, \\ldots, x_k)$ without\naggregation functions.",
    "descriptor": "",
    "authors": [
      "Vera Koponen",
      "Felix Weitk\u00e4mper"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.10122"
  },
  {
    "id": "arXiv:2106.10123",
    "title": "Challenges and Limitations with the Metrics Measuring the Complexity of  Code-Mixed Text",
    "abstract": "Code-mixing is a frequent communication style among multilingual speakers\nwhere they mix words and phrases from two different languages in the same\nutterance of text or speech. Identifying and filtering code-mixed text is a\nchallenging task due to its co-existence with monolingual and noisy text. Over\nthe years, several code-mixing metrics have been extensively used to identify\nand validate code-mixed text quality. This paper demonstrates several inherent\nlimitations of code-mixing metrics with examples from the already existing\ndatasets that are popularly used across various experiments.",
    "descriptor": "",
    "authors": [
      "Vivek Srivastava",
      "Mayank Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10123"
  },
  {
    "id": "arXiv:2106.10124",
    "title": "Graph Context Encoder: Graph Feature Inpainting for Graph Generation and  Self-supervised Pretraining",
    "abstract": "We propose the Graph Context Encoder (GCE), a simple but efficient approach\nfor graph representation learning based on graph feature masking and\nreconstruction.\nGCE models are trained to efficiently reconstruct input graphs similarly to a\ngraph autoencoder where node and edge labels are masked. In particular, our\nmodel is also allowed to change graph structures by masking and reconstructing\ngraphs augmented by random pseudo-edges.\nWe show that GCE can be used for novel graph generation, with applications\nfor molecule generation. Used as a pretraining method, we also show that GCE\nimproves baseline performances in supervised classification tasks tested on\nmultiple standard benchmark graph datasets.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Oriel Frigo",
      "R\u00e9my Brossard",
      "David Dehaene"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10124"
  },
  {
    "id": "arXiv:2106.10129",
    "title": "Towards Robotic Laboratory Automation Plug & Play: The \"LAPP\" Framework",
    "abstract": "Increasing the level of automation in pharmaceutical laboratories and\nproduction facilities plays a crucial role in delivering medicine to patients.\nHowever, the particular requirements of this field make it challenging to adapt\ncutting-edge technologies present in other industries. This article provides an\noverview of relevant approaches and how they can be utilized in the\npharmaceutical industry, especially in development laboratories. Recent\nadvancements include the application of flexible mobile manipulators capable of\nhandling complex tasks. However, integrating devices from many different\nvendors into an end-to-end automation system is complicated due to the\ndiversity of protocols. Therefore, various approaches for standardization have\nbeen considered, and a concept has been proposed for taking them a step\nfurther. This concept enables a mobile manipulator with a vision system to\n``learn'' the pose of each device and - utilizing a barcode - fetch interface\ninformation from a universal cloud database. This information includes control\nand communication protocol definitions and a representation of robot actions\nneeded to operate the device. In order to define the movements in relation to\nthe device, devices have to feature - besides the barcode - a fiducial marker\nas standard. The concept will be elaborated following appropriate research\nactivities in follow-up papers.",
    "descriptor": "",
    "authors": [
      "\u00c1d\u00e1m Wolf",
      "David Wolton",
      "Josef Trapl",
      "Julien Janda",
      "Stefan Romeder-Finger",
      "Thomas Gatternig",
      "Jean-Baptiste Farcet",
      "P\u00e9ter Galambos",
      "K\u00e1roly Sz\u00e9ll"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10129"
  },
  {
    "id": "arXiv:2106.10131",
    "title": "Enhancing user creativity: Semantic measures for idea generation",
    "abstract": "Human creativity generates novel ideas to solve real-world problems. This\nthereby grants us the power to transform the surrounding world and extend our\nhuman attributes beyond what is currently possible. Creative ideas are not just\nnew and unexpected, but are also successful in providing solutions that are\nuseful, efficient and valuable. Thus, creativity optimizes the use of available\nresources and increases wealth. The origin of human creativity, however, is\npoorly understood, and semantic measures that could predict the success of\ngenerated ideas are currently unknown. Here, we analyze a dataset of design\nproblem-solving conversations in real-world settings by using 49 semantic\nmeasures based on WordNet 3.1 and demonstrate that a divergence of semantic\nsimilarity, an increased information content, and a decreased polysemy predict\nthe success of generated ideas. The first feedback from clients also enhances\ninformation content and leads to a divergence of successful ideas in creative\nproblem solving. These results advance cognitive science by identifying\nreal-world processes in human problem solving that are relevant to the success\nof produced solutions and provide tools for real-time monitoring of problem\nsolving, student training and skill acquisition. A selected subset of\ninformation content (IC S\\'anchez-Batet) and semantic similarity\n(Lin/S\\'anchez-Batet) measures, which are both statistically powerful and\ncomputationally fast, could support the development of technologies for\ncomputer-assisted enhancements of human creativity or for the implementation of\ncreativity in machines endowed with general artificial intelligence.",
    "descriptor": "\nComments: 42 pages, 10 figures, 2 tables\n",
    "authors": [
      "Georgi V. Georgiev",
      "Danko D. Georgiev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10131"
  },
  {
    "id": "arXiv:2106.10134",
    "title": "An Audio-Driven System For Real-Time Music Visualisation",
    "abstract": "Computer-generated visualisations can accompany recorded or live music to\ncreate novel audiovisual experiences for audiences. We present a system to\nstreamline the creation of audio-driven visualisations based on audio feature\nextraction and mapping interfaces. Its architecture is based on three modular\nsoftware components: backend (audio plugin), frontend (3D game-like\nenvironment), and middleware (visual mapping interface). We conducted a user\nevaluation comprising two stages. Results from the first stage (34\nparticipants) indicate that music visualisations generated with the system were\nsignificantly better at complementing the music than a baseline visualisation.\nNine participants took part in the second stage involving interactive tasks.\nOverall, the system yielded a Creativity Support Index above average (68.1) and\na System Usability Scale index (58.6) suggesting that ease of use can be\nimproved. Thematic analysis revealed that participants enjoyed the system's\nsynchronicity and expressive capabilities, but found technical problems and\ndifficulties understanding the audio feature terminology.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Max Graf",
      "Harold Chijioke Opara",
      "Mathieu Barthet"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.10134"
  },
  {
    "id": "arXiv:2106.10137",
    "title": "Self-supervised Video Representation Learning with Cross-Stream  Prototypical Contrasting",
    "abstract": "Instance-level contrastive learning techniques, which rely on data\naugmentation and a contrastive loss function, have found great success in the\ndomain of visual representation learning. They are not suitable for exploiting\nthe rich dynamical structure of video however, as operations are done on many\naugmented instances. In this paper we propose \"Video Cross-Stream Prototypical\nContrasting\", a novel method which predicts consistent prototype assignments\nfrom both RGB and optical flow views, operating on sets of samples.\nSpecifically, we alternate the optimization process; while optimizing one of\nthe streams, all views are mapped to one set of stream prototype vectors. Each\nof the assignments is predicted with all views except the one matching the\nprediction, pushing representations closer to their assigned prototypes. As a\nresult, more efficient video embeddings with ingrained motion information are\nlearned, without the explicit need for optical flow computation during\ninference. We obtain state-of-the-art results on nearest neighbour video\nretrieval and action recognition, outperforming previous best by +3.2% on\nUCF101 using the S3D backbone (90.5% Top-1 acc), and by +7.2% on UCF101 and\n+15.1% on HMDB51 using the R(2+1)D backbone.",
    "descriptor": "",
    "authors": [
      "Martine Toering",
      "Ioannis Gatopoulos",
      "Maarten Stol",
      "Vincent Tao Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10137"
  },
  {
    "id": "arXiv:2106.10138",
    "title": "Classical Planning as QBF without Grounding (extended version)",
    "abstract": "Most classical planners use grounding as a preprocessing step, reducing\nplanning to propositional logic. However, grounding comes with a severe cost in\nmemory, resulting in large encodings for SAT/QBF based planners. Despite the\noptimisations in SAT/QBF encodings such as action splitting, compact encodings\nand using parallel plans, the memory usage due to grounding remains a\nbottleneck when actions have many parameters, such as in the Organic Synthesis\nproblems from the IPC 2018 planning competition (in its original non-split\nform).\nIn this paper, we provide a compact QBF encoding that is logarithmic in the\nnumber of objects and avoids grounding completely by using universal\nquantification for object combinations. We compare the ungrounded QBF encoding\nwith the simple SAT encoding and also show that we can solve some of the\nOrganic Synthesis problems, which could not be handled before by any SAT/QBF\nbased planners due to grounding.",
    "descriptor": "",
    "authors": [
      "Irfansha Shaik",
      "Jaco van de Pol"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10138"
  },
  {
    "id": "arXiv:2106.10139",
    "title": "Stochastic parareal: an application of probabilistic methods to  time-parallelisation",
    "abstract": "Parareal is a well-studied algorithm for numerically integrating systems of\ntime-dependent differential equations by parallelising the temporal domain.\nGiven approximate initial values at each temporal sub-interval, the algorithm\nlocates a solution in a fixed number of iterations using a predictor-corrector,\nstopping once a tolerance is met. This iterative process combines solutions\nlocated by inexpensive (coarse resolution) and expensive (fine resolution)\nnumerical integrators. In this paper, we introduce a \\textit{stochastic\nparareal} algorithm with the aim of accelerating the convergence of the\ndeterministic parareal algorithm. Instead of providing the predictor-corrector\nwith a deterministically located set of initial values, the stochastic\nalgorithm samples initial values from dynamically varying probability\ndistributions in each temporal sub-interval. All samples are then propagated by\nthe numerical method in parallel. The initial values yielding the most\ncontinuous (smoothest) trajectory across consecutive sub-intervals are chosen\nas the new, more accurate, set of initial values. These values are fed into the\npredictor-corrector, converging in fewer iterations than the deterministic\nalgorithm with a given probability. The performance of the stochastic\nalgorithm, implemented using various probability distributions, is illustrated\non systems of ordinary differential equations. When the number of sampled\ninitial values is large enough, we show that stochastic parareal converges\nalmost certainly in fewer iterations than the deterministic algorithm while\nmaintaining solution accuracy. Additionally, it is shown that the expected\nvalue of the convergence rate decreases with increasing numbers of samples.",
    "descriptor": "",
    "authors": [
      "Kamran Pentland",
      "Massimiliano Tamborrino",
      "D. Samaddar",
      "L. C. Appel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.10139"
  },
  {
    "id": "arXiv:2106.10147",
    "title": "Evaluating the Robustness of Trigger Set-Based Watermarks Embedded in  Deep Neural Networks",
    "abstract": "Trigger set-based watermarking schemes have gained emerging attention as they\nprovide a means to prove ownership for deep neural network model owners. In\nthis paper, we argue that state-of-the-art trigger set-based watermarking\nalgorithms do not achieve their designed goal of proving ownership. We posit\nthat this impaired capability stems from two common experimental flaws that the\nexisting research practice has committed when evaluating the robustness of\nwatermarking algorithms: (1) incomplete adversarial evaluation and (2)\noverlooked adaptive attacks.\nWe conduct a comprehensive adversarial evaluation of 10 representative\nwatermarking schemes against six of the existing attacks and demonstrate that\neach of these watermarking schemes lacks robustness against at least two\nattacks. We also propose novel adaptive attacks that harness the adversary's\nknowledge of the underlying watermarking algorithm of a target model. We\ndemonstrate that the proposed attacks effectively break all of the 10\nwatermarking schemes, consequently allowing adversaries to obscure the\nownership of any watermarked model. We encourage follow-up studies to consider\nour guidelines when evaluating the robustness of their watermarking schemes via\nconducting comprehensive adversarial evaluation that include our adaptive\nattacks to demonstrate a meaningful upper bound of watermark robustness.",
    "descriptor": "",
    "authors": [
      "Suyoung Lee",
      "Wonho Song",
      "Suman Jana",
      "Meeyoung Cha",
      "Sooel Son"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10147"
  },
  {
    "id": "arXiv:2106.10148",
    "title": "Do people's user types change over time? An exploratory study",
    "abstract": "In recent years, different studies have proposed and validated user models\n(e.g., Bartle, BrainHex, and Hexad) to represent the different user profiles in\ngames and gamified settings. However, the results of applying these user models\nin practice (e.g., to personalize gamified systems) are still contradictory.\nOne of the hypotheses for these results is that the user types can change over\ntime (i.e., user types are dynamic). To start to understand whether user types\ncan change over time, we conducted an exploratory study analyzing data from 74\nparticipants to identify if their user type (Achiever, Philanthropist,\nSocialiser, Free Spirit, Player, and Disruptor) had changed over time (six\nmonths). The results indicate that there is a change in the dominant user type\nof the participants, as well as the average scores in the Hexad sub-scales.\nThese results imply that all the scores should be considered when defining the\nHexad's user type and that the user types are dynamic. Our results contribute\nwith practical implications, indicating that the personalization currently made\n(generally static) may be insufficient to improve the users' experience,\nrequiring user types to be analyzed continuously and personalization to be done\ndynamically.",
    "descriptor": "\nComments: 5th International GamiFIN Conference 2021 (GamiFIN 2021), April 7-10, 2021, Finland\n",
    "authors": [
      "Ana Cl\u00e1udia Guimar\u00e3es Santos",
      "Wilk Oliveira",
      "Juho Hamari",
      "Seiji Isotani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.10148"
  },
  {
    "id": "arXiv:2106.10149",
    "title": "Searching for Point Locations using Lines",
    "abstract": "Versions of the following problem appear in several topics such as Gamma\nKnife radiosurgery, studying objects with the X-ray transform, the 3SUM\nproblem, and the $k$-linear degeneracy testing. Suppose there are $n$ points on\na plane whose specific locations are unknown. We are given all the lines that\ngo through the points with a given slope. We show that the minimum number of\nslopes needed, in general, to find all the point locations is $n+1$ and we\nprovide an algorithm to do so.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Michelle Cordier",
      "Meaghan Wheeler"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.10149"
  },
  {
    "id": "arXiv:2106.10151",
    "title": "The Dimpled Manifold Model of Adversarial Examples in Machine Learning",
    "abstract": "The extreme fragility of deep neural networks when presented with tiny\nperturbations in their inputs was independently discovered by several research\ngroups in 2013, but in spite of enormous effort these adversarial examples\nremained a baffling phenomenon with no clear explanation. In this paper we\nintroduce a new conceptual framework (which we call the Dimpled Manifold Model)\nwhich provides a simple explanation for why adversarial examples exist, why\ntheir perturbations have such tiny norms, why these perturbations look like\nrandom noise, and why a network which was adversarially trained with\nincorrectly labeled images can still correctly classify test images. In the\nlast part of the paper we describe the results of numerous experiments which\nstrongly support this new model, and in particular our assertion that\nadversarial perturbations are roughly perpendicular to the low dimensional\nmanifold which contains all the training examples.",
    "descriptor": "",
    "authors": [
      "Adi Shamir",
      "Odelia Melamed",
      "Oriel BenShmuel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10151"
  },
  {
    "id": "arXiv:2106.10153",
    "title": "All You Can Embed: Natural Language based Vehicle Retrieval with  Spatio-Temporal Transformers",
    "abstract": "Combining Natural Language with Vision represents a unique and interesting\nchallenge in the domain of Artificial Intelligence. The AI City Challenge Track\n5 for Natural Language-Based Vehicle Retrieval focuses on the problem of\ncombining visual and textual information, applied to a smart-city use case. In\nthis paper, we present All You Can Embed (AYCE), a modular solution to\ncorrelate single-vehicle tracking sequences with natural language. The main\nbuilding blocks of the proposed architecture are (i) BERT to provide an\nembedding of the textual descriptions, (ii) a convolutional backbone along with\na Transformer model to embed the visual information. For the training of the\nretrieval model, a variation of the Triplet Margin Loss is proposed to learn a\ndistance measure between the visual and language embeddings. The code is\npublicly available at https://github.com/cscribano/AYCE_2021.",
    "descriptor": "\nComments: CVPR 2021 AI CITY CHALLENGE Natural Language-Based Vehicle Retrieval\n",
    "authors": [
      "Carmelo Scribano",
      "Davide Sapienza",
      "Giorgia Franchini",
      "Micaela Verucchi",
      "Marko Bertogna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10153"
  },
  {
    "id": "arXiv:2106.10154",
    "title": "A Survey of Privacy Vulnerabilities of Mobile Device Sensors",
    "abstract": "The number of mobile devices, such as smartphones and smartwatches, is\nrelentlessly increasing to almost 6.8 billion by 2022, and along with it, the\namount of personal and sensitive data captured by them. This survey overviews\nthe state of the art of what personal and sensitive user attributes can be\nextracted from mobile device sensors, emphasising critical aspects such as\ndemographics, health and body features, activity and behaviour recognition,\netc. In addition, we review popular metrics in the literature to quantify the\ndegree of privacy, and discuss powerful privacy methods to protect the\nsensitive data while preserving data utility for analysis. Finally, open\nresearch questions a represented for further advancements in the field.",
    "descriptor": "",
    "authors": [
      "Paula Delgado-Santos",
      "Giuseppe Stragapede",
      "Ruben Tolosana",
      "Richard Guest",
      "Farzin Deravi",
      "Ruben Vera-Rodriguez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.10154"
  },
  {
    "id": "arXiv:2106.10155",
    "title": "World-GAN: a Generative Model for Minecraft Worlds",
    "abstract": "This work introduces World-GAN, the first method to perform data-driven\nProcedural Content Generation via Machine Learning in Minecraft from a single\nexample. Based on a 3D Generative Adversarial Network (GAN) architecture, we\nare able to create arbitrarily sized world snippets from a given sample. We\nevaluate our approach on creations from the community as well as structures\ngenerated with the Minecraft World Generator. Our method is motivated by the\ndense representations used in Natural Language Processing (NLP) introduced with\nword2vec [1]. The proposed block2vec representations make World-GAN independent\nfrom the number of different blocks, which can vary a lot in Minecraft, and\nenable the generation of larger levels. Finally, we demonstrate that changing\nthis new representation space allows us to change the generated style of an\nalready trained generator. World-GAN enables its users to generate Minecraft\nworlds based on parts of their creations.",
    "descriptor": "\nComments: 8 pages, 8 figures, IEEE Conference on Games (CoG) 2021\n",
    "authors": [
      "Maren Awiszus",
      "Frederik Schubert",
      "Bodo Rosenhahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.10155"
  },
  {
    "id": "arXiv:2106.10156",
    "title": "Predicting gender of Brazilian names using deep learning",
    "abstract": "Predicting gender by the name is not a simple task. In many applications,\nespecially in the natural language processing (NLP) field, this task may be\nnecessary, mainly when considering foreign names. Some machine learning\nalgorithms can satisfactorily perform the prediction. In this paper, we\nexamined and implemented feedforward and recurrent deep neural network models,\nsuch as MLP, RNN, GRU, CNN, and BiLSTM, to classify gender through the first\nname. A dataset of Brazilian names is used to train and evaluate the models. We\nanalyzed the accuracy, recall, precision, and confusion matrix to measure the\nmodels' performances. The results indicate that the gender prediction can be\nperformed from the feature extraction strategy looking at the names as a set of\nstrings. Some models accurately predict the gender in more than 90% of the\ncases. The recurrent models overcome the feedforward models in this binary\nclassification problem.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Rosana C. B. Rego",
      "Ver\u00f4nica M. L. Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10156"
  },
  {
    "id": "arXiv:2106.10157",
    "title": "pyWATTS: Python Workflow Automation Tool for Time Series",
    "abstract": "Time series data are fundamental for a variety of applications, ranging from\nfinancial markets to energy systems. Due to their importance, the number and\ncomplexity of tools and methods used for time series analysis is constantly\nincreasing. However, due to unclear APIs and a lack of documentation,\nresearchers struggle to integrate them into their research projects and\nreplicate results. Additionally, in time series analysis there exist many\nrepetitive tasks, which are often re-implemented for each project,\nunnecessarily costing time. To solve these problems we present\n\\texttt{pyWATTS}, an open-source Python-based package that is a non-sequential\nworkflow automation tool for the analysis of time series data. pyWATTS includes\nmodules with clearly defined interfaces to enable seamless integration of new\nor existing methods, subpipelining to easily reproduce repetitive tasks, load\nand save functionality to simply replicate results, and native support for key\nPython machine learning libraries such as scikit-learn, PyTorch, and Keras.",
    "descriptor": "",
    "authors": [
      "Benedikt Heidrich",
      "Andreas Bartschat",
      "Marian Turowski",
      "Oliver Neumann",
      "Kaleb Phipps",
      "Stefan Meisenbacher",
      "Kai Schmieder",
      "Nicole Ludwig",
      "Ralf Mikut",
      "Veit Hagenmeyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10157"
  },
  {
    "id": "arXiv:2106.10158",
    "title": "Learning to Generate Code Sketches",
    "abstract": "Traditional generative models are limited to predicting sequences of terminal\ntokens. However, ambiguities in the generation task may lead to incorrect\noutputs. Towards addressing this, we introduce Grammformers, transformer-based\ngrammar-guided models that learn (without explicit supervision) to generate\nsketches -- sequences of tokens with holes. Through reinforcement learning,\nGrammformers learn to introduce holes avoiding the generation of incorrect\ntokens where there is ambiguity in the target task.\nWe train Grammformers for statement-level source code completion, i.e., the\ngeneration of code snippets given an ambiguous user intent, such as a partial\ncode context. We evaluate Grammformers on code completion for C# and Python and\nshow that it generates 10-50% more accurate sketches compared to traditional\ngenerative models and 37-50% longer sketches compared to sketch-generating\nbaselines trained with similar techniques.",
    "descriptor": "",
    "authors": [
      "Daya Guo",
      "Alexey Svyatkovskiy",
      "Jian Yin",
      "Nan Duan",
      "Marc Brockschmidt",
      "Miltiadis Allamanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.10158"
  },
  {
    "id": "arXiv:2106.10159",
    "title": "FinGAT: Financial Graph Attention Networks for Recommending Top-K  Profitable Stocks",
    "abstract": "Financial technology (FinTech) has drawn much attention among investors and\ncompanies. While conventional stock analysis in FinTech targets at predicting\nstock prices, less effort is made for profitable stock recommendation. Besides,\nin existing approaches on modeling time series of stock prices, the\nrelationships among stocks and sectors (i.e., categories of stocks) are either\nneglected or pre-defined. Ignoring stock relationships will miss the\ninformation shared between stocks while using pre-defined relationships cannot\ndepict the latent interactions or influence of stock prices between stocks. In\nthis work, we aim at recommending the top-K profitable stocks in terms of\nreturn ratio using time series of stock prices and sector information. We\npropose a novel deep learning-based model, Financial Graph Attention Networks\n(FinGAT), to tackle the task under the setting that no pre-defined\nrelationships between stocks are given. The idea of FinGAT is three-fold.\nFirst, we devise a hierarchical learning component to learn short-term and\nlong-term sequential patterns from stock time series. Second, a fully-connected\ngraph between stocks and a fully-connected graph between sectors are\nconstructed, along with graph attention networks, to learn the latent\ninteractions among stocks and sectors. Third, a multi-task objective is devised\nto jointly recommend the profitable stocks and predict the stock movement.\nExperiments conducted on Taiwan Stock, S&P 500, and NASDAQ datasets exhibit\nremarkable recommendation performance of our FinGAT, comparing to\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted to IEEE TKDE 2021. The first two authors equally contribute to this work. Code is available at this https URL\n",
    "authors": [
      "Yi-Ling Hsu",
      "Yu-Che Tsai",
      "Cheng-Te Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.10159"
  },
  {
    "id": "arXiv:2106.10160",
    "title": "Toward Fault Detection in Industrial Welding Processes with Deep  Learning and Data Augmentation",
    "abstract": "With the rise of deep learning models in the field of computer vision, new\npossibilities for their application in industrial processes proves to return\ngreat benefits. Nevertheless, the actual fit of machine learning for highly\nstandardised industrial processes is still under debate. This paper addresses\nthe challenges on the industrial realization of the AI tools, considering the\nuse case of Laser Beam Welding quality control as an example. We use object\ndetection algorithms from the TensorFlow object detection API and adapt them to\nour use case using transfer learning. The baseline models we develop are used\nas benchmarks and evaluated and compared to models that undergo dataset scaling\nand hyperparameter tuning. We find that moderate scaling of the dataset via\nimage augmentation leads to improvements in intersection over union (IoU) and\nrecall, whereas high levels of augmentation and scaling may lead to\ndeterioration of results. Finally, we put our results into perspective of the\nunderlying use case and evaluate their fit.",
    "descriptor": "",
    "authors": [
      "Jibinraj Antony",
      "Dr. Florian Schlather",
      "Georgij Safronov",
      "Markus Schmitz",
      "Prof. Dr. Kristof Van Laerhoven"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10160"
  },
  {
    "id": "arXiv:2106.10163",
    "title": "Steerable Partial Differential Operators for Equivariant Neural Networks",
    "abstract": "Recent work in equivariant deep learning bears strong similarities to\nphysics. Fields over a base space are fundamental entities in both subjects, as\nare equivariant maps between these fields. In deep learning, however, these\nmaps are usually defined by convolutions with a kernel, whereas they are\npartial differential operators (PDOs) in physics. Developing the theory of\nequivariant PDOs in the context of deep learning could bring these subjects\neven closer together and lead to a stronger flow of ideas. In this work, we\nderive a $G$-steerability constraint that completely characterizes when a PDO\nbetween feature vector fields is equivariant, for arbitrary symmetry groups\n$G$. We then fully solve this constraint for several important groups. We use\nour solutions as equivariant drop-in replacements for convolutional layers and\nbenchmark them in that role. Finally, we develop a framework for equivariant\nmaps based on Schwartz distributions that unifies classical convolutions and\ndifferential operators and gives insight about the relation between the two.",
    "descriptor": "\nComments: 43 pages, 4 figures, code available at this https URL\n",
    "authors": [
      "Erik Jenner",
      "Maurice Weiler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10163"
  },
  {
    "id": "arXiv:2106.10165",
    "title": "The Principles of Deep Learning Theory",
    "abstract": "This book develops an effective theory approach to understanding deep neural\nnetworks of practical relevance. Beginning from a first-principles\ncomponent-level picture of networks, we explain how to determine an accurate\ndescription of the output of trained networks by solving layer-to-layer\niteration equations and nonlinear learning dynamics. A main result is that the\npredictions of networks are described by nearly-Gaussian distributions, with\nthe depth-to-width aspect ratio of the network controlling the deviations from\nthe infinite-width Gaussian description. We explain how these effectively-deep\nnetworks learn nontrivial representations from training and more broadly\nanalyze the mechanism of representation learning for nonlinear models. From a\nnearly-kernel-methods perspective, we find that the dependence of such models'\npredictions on the underlying learning algorithm can be expressed in a simple\nand universal way. To obtain these results, we develop the notion of\nrepresentation group flow (RG flow) to characterize the propagation of signals\nthrough the network. By tuning networks to criticality, we give a practical\nsolution to the exploding and vanishing gradient problem. We further explain\nhow RG flow leads to near-universal behavior and lets us categorize networks\nbuilt from different activation functions into universality classes.\nAltogether, we show that the depth-to-width ratio governs the effective model\ncomplexity of the ensemble of trained networks. By using information-theoretic\ntechniques, we estimate the optimal aspect ratio at which we expect the network\nto be practically most useful and show how residual connections can be used to\npush this scale to arbitrary depths. With these tools, we can learn in detail\nabout the inductive bias of architectures, hyperparameters, and optimizers.",
    "descriptor": "\nComments: 451 pages, to be published by Cambridge University Press\n",
    "authors": [
      "Daniel A. Roberts",
      "Sho Yaida",
      "Boris Hanin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10165"
  },
  {
    "id": "arXiv:2106.10169",
    "title": "Fusion of Embeddings Networks for Robust Combination of Text Dependent  and Independent Speaker Recognition",
    "abstract": "By implicitly recognizing a user based on his/her speech input, speaker\nidentification enables many downstream applications, such as personalized\nsystem behavior and expedited shopping checkouts. Based on whether the speech\ncontent is constrained or not, both text-dependent (TD) and text-independent\n(TI) speaker recognition models may be used. We wish to combine the advantages\nof both types of models through an ensemble system to make more reliable\npredictions. However, any such combined approach has to be robust to incomplete\ninputs, i.e., when either TD or TI input is missing. As a solution we propose a\nfusion of embeddings network foenet architecture, combining joint learning with\nneural attention. We compare foenet with four competitive baseline methods on a\ndataset of voice assistant inputs, and show that it achieves higher accuracy\nthan the baseline and score fusion methods, especially in the presence of\nincomplete inputs.",
    "descriptor": "",
    "authors": [
      "Ruirui Li",
      "Chelsea J.-T. Ju",
      "Zeya Chen",
      "Hongda Mao",
      "Oguz Elibol",
      "Andreas Stolcke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.10169"
  },
  {
    "id": "arXiv:2106.10176",
    "title": "Self-supervised Incremental Deep Graph Learning for Ethereum Phishing  Scam Detection",
    "abstract": "In recent years, phishing scams have become the crime type with the largest\nmoney involved on Ethereum, the second-largest blockchain platform. Meanwhile,\ngraph neural network (GNN) has shown promising performance in various node\nclassification tasks. However, for Ethereum transaction data, which could be\nnaturally abstracted to a real-world complex graph, the scarcity of labels and\nthe huge volume of transaction data make it difficult to take advantage of GNN\nmethods. Here in this paper, to address the two challenges, we propose a\nSelf-supervised Incremental deep Graph learning model (SIEGE), for the phishing\nscam detection problem on Ethereum. In our model, two pretext tasks designed\nfrom spatial and temporal perspectives help us effectively learn useful node\nembedding from the huge amount of unlabelled transaction data. And the\nincremental paradigm allows us to efficiently handle large-scale transaction\ndata and help the model maintain good performance when the data distribution is\ndrastically changing. We collect transaction records about half a year from\nEthereum and our extensive experiments show that our model consistently\noutperforms strong baselines in both transductive and inductive settings.",
    "descriptor": "",
    "authors": [
      "Shucheng Li",
      "Fengyuan Xu",
      "Runchuan Wang",
      "Sheng Zhong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10176"
  },
  {
    "id": "arXiv:2106.10177",
    "title": "Efficient partitioning and reordering of conforming virtual element  discretizations for large scale Discrete Fracture Network flow parallel  solvers",
    "abstract": "Discrete Fracture Network models are largely used for very large scale\ngeological flow simulations. For this reason numerical methods require an\ninvestigation of tools for efficient parallel solutions on High Performance\nComputing systems. In this paper we discuss and compare several partitioning\nand reordering strategies, that result to be highly efficient and scalable,\noverperforming the classical mesh partitioning approach used to partition a\nconforming mesh among several processes.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Stefano Berrone",
      "Alice Raeli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10177"
  },
  {
    "id": "arXiv:2106.10180",
    "title": "Determining when a truncated generalised Reed-Solomon code is Hermitian  self-orthogonal",
    "abstract": "We prove that there is a Hermitian self-orthogonal $k$-dimensional truncated\ngeneralised Reed-Solomon of length $n \\leqslant q^2$ over ${\\mathbb F}_{q^2}$\nif and only if there is a polynomial $g \\in {\\mathbb F}_{q^2}$ of degree at\nmost $(q-k)q-1$ such that $g+g^q$ has $q^2-n$ zeros. This allows us to\ndetermine the smallest $n$ for which there is a Hermitian self-orthogonal\n$k$-dimensional truncated generalised Reed-Solomon of length $n$ over ${\\mathbb\nF}_{q^2}$, verifying a conjecture of Grassl and R\\\"otteler. We also provide\nexamples of Hermitian self-orthogonal $k$-dimensional generalised Reed-Solomon\ncodes of length $q^2+1$ over ${\\mathbb F}_{q^2}$, for $k=q-1$ and $q$ an odd\npower of two.",
    "descriptor": "",
    "authors": [
      "Simeon Ball",
      "Ricard Vilar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10180"
  },
  {
    "id": "arXiv:2106.10185",
    "title": "NoiseGrad: enhancing explanations by introducing stochasticity to model  weights",
    "abstract": "Attribution methods remain a practical instrument that is used in real-world\napplications to explain the decision-making process of complex learning\nmachines. It has been shown that a simple method called SmoothGrad can\neffectively reduce the visual diffusion of gradient-based attribution methods\nand has established itself among both researchers and practitioners. What\nremains unexplored in research, however, is how explanations can be improved by\nintroducing stochasticity to the model weights. In the light of this, we\nintroduce - NoiseGrad - a stochastic, method-agnostic explanation-enhancing\nmethod that adds noise to the weights instead of the input data. We investigate\nour proposed method through various experiments including different datasets,\nexplanation methods and network architectures and conclude that NoiseGrad (and\nits extension NoiseGrad++) with multiplicative Gaussian noise offers a clear\nadvantage compared to SmoothGrad on several evaluation criteria. We connect our\nproposed method to Bayesian Learning and provide the user with a heuristic for\nchoosing hyperparameters.",
    "descriptor": "\nComments: 20 pages, 11 figures\n",
    "authors": [
      "Kirill Bykov",
      "Anna Hedstr\u00f6m",
      "Shinichi Nakajima",
      "Marina M.-C. H\u00f6hne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10185"
  },
  {
    "id": "arXiv:2106.10189",
    "title": "Adversarial Training Helps Transfer Learning via Better Representations",
    "abstract": "Transfer learning aims to leverage models pre-trained on source data to\nefficiently adapt to target setting, where only limited data are available for\nmodel fine-tuning. Recent works empirically demonstrate that adversarial\ntraining in the source data can improve the ability of models to transfer to\nnew domains. However, why this happens is not known. In this paper, we provide\na theoretical model to rigorously analyze how adversarial training helps\ntransfer learning. We show that adversarial training in the source data\ngenerates provably better representations, so fine-tuning on top of this\nrepresentation leads to a more accurate predictor of the target data. We\nfurther demonstrate both theoretically and empirically that semi-supervised\nlearning in the source data can also improve transfer learning by similarly\nimproving the representation. Moreover, performing adversarial training on top\nof semi-supervised learning can further improve transferability, suggesting\nthat the two approaches have complementary benefits on representations. We\nsupport our theories with experiments on popular data sets and deep learning\narchitectures.",
    "descriptor": "",
    "authors": [
      "Zhun Deng",
      "Linjun Zhang",
      "Kailas Vodrahalli",
      "Kenji Kawaguchi",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10189"
  },
  {
    "id": "arXiv:2106.10191",
    "title": "Rational Shapley Values",
    "abstract": "Explaining the predictions of opaque machine learning algorithms is an\nimportant and challenging task, especially as complex models are increasingly\nused to assist in high-stakes decisions such as those arising in healthcare and\nfinance. Most popular tools for post-hoc explainable artificial intelligence\n(XAI) are either insensitive to context (e.g., feature attributions) or\ndifficult to summarize (e.g., counterfactuals). In this paper, I introduce\n\\emph{rational Shapley values}, a novel XAI method that synthesizes and extends\nthese seemingly incompatible approaches in a rigorous, flexible manner. I\nleverage tools from decision theory and causal modeling to formalize and\nimplement a pragmatic approach that resolves a number of known challenges in\nXAI. By pairing the distribution of random variables with the appropriate\nreference class for a given explanation task, I illustrate through theory and\nexperiments how user goals and knowledge can inform and constrain the solution\nset in an iterative fashion. The method compares favorably to state of the art\nXAI tools in a range of quantitative and qualitative comparisons.",
    "descriptor": "\nComments: 20 pages, 3 figures, 7 tables\n",
    "authors": [
      "David S. Watson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10191"
  },
  {
    "id": "arXiv:2106.10192",
    "title": "Equilibrium Design for Concurrent Games",
    "abstract": "In game theory, mechanism design is concerned with the design of incentives\nso that a desired outcome of the game can be achieved. In this paper, we study\nthe design of incentives so that a desirable equilibrium is obtained, for\ninstance, an equilibrium satisfying a given temporal logic property -- a\nproblem that we call equilibrium design. We base our study on a framework where\nsystem specifications are represented as temporal logic formulae, games as\nquantitative concurrent game structures, and players' goals as mean-payoff\nobjectives. In particular, we consider system specifications given by LTL and\nGR(1) formulae, and show that implementing a mechanism to ensure that a given\ntemporal logic property is satisfied on some/every Nash equilibrium of the\ngame, whenever such a mechanism exists, can be done in PSPACE for LTL\nproperties and in NP/$\\Sigma^{P}_{2}$ for GR(1) specifications. We also study\nthe complexity of various related decision and optimisation problems, such as\noptimality and uniqueness of solutions, and show that the complexities of all\nsuch problems lie within the polynomial hierarchy. As an application,\nequilibrium design can be used as an alternative solution to the rational\nsynthesis and verification problems for concurrent games with mean-payoff\nobjectives whenever no solution exists, or as a technique to repair, whenever\npossible, concurrent games with undesirable rational outcomes (Nash equilibria)\nin an optimal way.",
    "descriptor": "\nComments: CONCUR 2019 with appendix\n",
    "authors": [
      "Julian Gutierrez",
      "Muhammad Najib",
      "Giuseppe Perelli",
      "Michael Wooldridge"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.10192"
  },
  {
    "id": "arXiv:2106.10196",
    "title": "Federated Robustness Propagation: Sharing Adversarial Robustness in  Federated Learning",
    "abstract": "Federated learning (FL) emerges as a popular distributed learning schema that\nlearns a model from a set of participating users without requiring raw data to\nbe shared. One major challenge of FL comes from heterogeneity in users, which\nmay have distributionally different (or non-iid) data and varying computation\nresources. Just like in centralized learning, FL users also desire model\nrobustness against malicious attackers at test time. Whereas adversarial\ntraining (AT) provides a sound solution for centralized learning, extending its\nusage for FL users has imposed significant challenges, as many users may have\nvery limited training data as well as tight computational budgets, to afford\nthe data-hungry and costly AT. In this paper, we study a novel learning setting\nthat propagates adversarial robustness from high-resource users that can afford\nAT, to those low-resource users that cannot afford it, during the FL process.\nWe show that existing FL techniques cannot effectively propagate adversarial\nrobustness among non-iid users, and propose a simple yet effective propagation\napproach that transfers robustness through carefully designed\nbatch-normalization statistics. We demonstrate the rationality and\neffectiveness of our method through extensive experiments. Especially, the\nproposed method is shown to grant FL remarkable robustness even when only a\nsmall portion of users afford AT during learning. Codes will be published upon\nacceptance.",
    "descriptor": "",
    "authors": [
      "Junyuan Hong",
      "Haotao Wang",
      "Zhangyang Wang",
      "Jiayu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10196"
  },
  {
    "id": "arXiv:2106.10197",
    "title": "A Dynamic Spatial-temporal Attention Network for Early Anticipation of  Traffic Accidents",
    "abstract": "Recently, autonomous vehicles and those equipped with an Advanced Driver\nAssistance System (ADAS) are emerging. They share the road with regular ones\noperated by human drivers entirely. To ensure guaranteed safety for passengers\nand other road users, it becomes essential for autonomous vehicles and ADAS to\nanticipate traffic accidents from natural driving scenes. The dynamic\nspatial-temporal interaction of the traffic agents is complex, and visual cues\nfor predicting a future accident are embedded deeply in dashcam video data.\nTherefore, early anticipation of traffic accidents remains a challenge. To this\nend, the paper presents a dynamic spatial-temporal attention (DSTA) network for\nearly anticipation of traffic accidents from dashcam videos. The proposed\nDSTA-network learns to select discriminative temporal segments of a video\nsequence with a module named Dynamic Temporal Attention (DTA). It also learns\nto focus on the informative spatial regions of frames with another module named\nDynamic Spatial Attention (DSA). The spatial-temporal relational features of\naccidents, along with scene appearance features, are learned jointly with a\nGated Recurrent Unit (GRU) network. The experimental evaluation of the\nDSTA-network on two benchmark datasets confirms that it has exceeded the\nstate-of-the-art performance. A thorough ablation study evaluates the\ncontributions of individual components of the DSTA-network, revealing how the\nnetwork achieves such performance. Furthermore, this paper proposes a new\nstrategy that fuses the prediction scores from two complementary models and\nverifies its effectiveness in further boosting the performance of early\naccident anticipation.",
    "descriptor": "\nComments: 10 pages, 4 figures, submitted to a journal\n",
    "authors": [
      "Muhammad Monjurul Karim",
      "Yu Li",
      "Ruwen Qin",
      "Zhaozheng Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10197"
  },
  {
    "id": "arXiv:2106.10199",
    "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based  Masked Language-models",
    "abstract": "We show that with small-to-medium training data, fine-tuning only the bias\nterms (or a subset of the bias terms) of pre-trained BERT models is competitive\nwith (and sometimes better than) fine-tuning the entire model. For larger data,\nbias-only fine-tuning is competitive with other sparse fine-tuning methods.\nBesides their practical utility, these findings are relevant for the question\nof understanding the commonly-used process of finetuning: they support the\nhypothesis that finetuning is mainly about exposing knowledge induced by\nlanguage-modeling training, rather than learning new task-specific linguistic\nknowledge.",
    "descriptor": "",
    "authors": [
      "Elad Ben Zaken",
      "Shauli Ravfogel",
      "Yoav Goldberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10199"
  },
  {
    "id": "arXiv:2106.10201",
    "title": "A time and space optimal stable population protocol solving exact  majority",
    "abstract": "We study population protocols, a model of distributed computing appropriate\nfor modeling well-mixed chemical reaction networks and other physical systems\nwhere agents exchange information in pairwise interactions, but have no control\nover their schedule of interaction partners. The well-studied *majority*\nproblem is that of determining in an initial population of $n$ agents, each\nwith one of two opinions $A$ or $B$, whether there are more $A$, more $B$, or a\ntie. A *stable* protocol solves this problem with probability 1 by eventually\nentering a configuration in which all agents agree on a correct consensus\ndecision of $\\mathsf{A}$, $\\mathsf{B}$, or $\\mathsf{T}$, from which the\nconsensus cannot change. We describe a protocol that solves this problem using\n$O(\\log n)$ states ($\\log \\log n + O(1)$ bits of memory) and optimal expected\ntime $O(\\log n)$. The number of states $O(\\log n)$ is known to be optimal for\nthe class of polylogarithmic time stable protocols that are \"output dominant\"\nand \"monotone\". These are two natural constraints satisfied by our protocol,\nmaking it simultaneously time- and state-optimal for that class. We introduce a\nkey technique called a \"fixed resolution clock\" to achieve partial\nsynchronization.\nOur protocol is *nonuniform*: the transition function has the value $\\left\n\\lceil {\\log n} \\right \\rceil$ encoded in it. We show that the protocol can be\nmodified to be uniform, while increasing the state complexity to $\\Theta(\\log n\n\\log \\log n)$.",
    "descriptor": "\nComments: combined paper that replaces both arXiv:2012.15800 and arXiv:2011.07392\n",
    "authors": [
      "David Doty",
      "Mahsa Eftekhari",
      "Leszek G\u0105sieniec",
      "Eric Severson",
      "Grzegorz Stachowiak",
      "Przemys\u0142aw Uzna\u0144ski"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.10201"
  },
  {
    "id": "arXiv:2106.10202",
    "title": "An Investigation into Mini-Batch Rule Learning",
    "abstract": "We investigate whether it is possible to learn rule sets efficiently in a\nnetwork structure with a single hidden layer using iterative refinements over\nmini-batches of examples. A first rudimentary version shows an acceptable\nperformance on all but one dataset, even though it does not yet reach the\nperformance levels of Ripper.",
    "descriptor": "",
    "authors": [
      "Florian Beck",
      "Johannes F\u00fcrnkranz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10202"
  },
  {
    "id": "arXiv:2106.10206",
    "title": "Position-based Dynamics Simulator of Brain Deformations for Path  Planning and Intra-Operative Control in Keyhole Neurosurgery",
    "abstract": "Many tasks in robot-assisted surgery require planning and controlling\nmanipulators' motions that interact with highly deformable objects. This study\nproposes a realistic, time-bounded simulator based on Position-based Dynamics\n(PBD) simulation that mocks brain deformations due to catheter insertion for\npre-operative path planning and intra-operative guidance in keyhole surgical\nprocedures. It maximizes the probability of success by accounting for\nuncertainty in deformation models, noisy sensing, and unpredictable actuation.\nThe PBD deformation parameters were initialized on a parallelepiped-shaped\nsimulated phantom to obtain a reasonable starting guess for the brain white\nmatter. They were calibrated by comparing the obtained displacements with\ndeformation data for catheter insertion in a composite hydrogel phantom.\nKnowing the gray matter brain structures' different behaviors, the parameters\nwere fine-tuned to obtain a generalized human brain model. The brain\nstructures' average displacement was compared with values in the literature.\nThe simulator's numerical model uses a novel approach with respect to the\nliterature, and it has proved to be a close match with real brain deformations\nthrough validation using recorded deformation data of in-vivo animal trials\nwith a mean mismatch of 4.73$\\pm$2.15%. The stability, accuracy, and real-time\nperformance make this model suitable for creating a dynamic environment for KN\npath planning, pre-operative path planning, and intra-operative guidance.",
    "descriptor": "\nComments: 8 pages, 8 figures. This article has been accepted for publication in a future issue of IEEE Robotics and Automation Letters, but has not been fully edited. Content may change prior to final publication. 2377-3766 (c) 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. A. Segato and C. Di Vece equally contributed\n",
    "authors": [
      "Alice Segato",
      "Chiara Di Vece",
      "Sara Zucchelli",
      "Marco Di Marzo",
      "Thomas Wendler",
      "Mohammad Farid Azampour",
      "Stefano Galvan",
      "Riccardo Secoli",
      "Elena De Momi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10206"
  },
  {
    "id": "arXiv:2106.10207",
    "title": "Distributed Deep Learning in Open Collaborations",
    "abstract": "Modern deep learning applications require increasingly more compute to train\nstate-of-the-art models. To address this demand, large corporations and\ninstitutions use dedicated High-Performance Computing clusters, whose\nconstruction and maintenance are both environmentally costly and well beyond\nthe budget of most organizations. As a result, some research directions become\nthe exclusive domain of a few large industrial and even fewer academic actors.\nTo alleviate this disparity, smaller groups may pool their computational\nresources and run collaborative experiments that benefit all participants. This\nparadigm, known as grid- or volunteer computing, has seen successful\napplications in numerous scientific areas. However, using this approach for\nmachine learning is difficult due to high latency, asymmetric bandwidth, and\nseveral challenges unique to volunteer computing. In this work, we carefully\nanalyze these constraints and propose a novel algorithmic framework designed\nspecifically for collaborative training. We demonstrate the effectiveness of\nour approach for SwAV and ALBERT pretraining in realistic conditions and\nachieve performance comparable to traditional setups at a fraction of the cost.\nFinally, we provide a detailed report of successful collaborative language\nmodel pretraining with 40 participants.",
    "descriptor": "\nComments: 30 pages, 9 figures. Code: this https URL\n",
    "authors": [
      "Michael Diskin",
      "Alexey Bukhtiyarov",
      "Max Ryabinin",
      "Lucile Saulnier",
      "Quentin Lhoest",
      "Anton Sinitsin",
      "Dmitry Popov",
      "Dmitry Pyrkin",
      "Maxim Kashirin",
      "Alexander Borzunov",
      "Albert Villanova del Moral",
      "Denis Mazur",
      "Ilia Kobelev",
      "Yacine Jernite",
      "Thomas Wolf",
      "Gennady Pekhimenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.10207"
  },
  {
    "id": "arXiv:2106.10210",
    "title": "Combining Pseudo-Point and State Space Approximations for Sum-Separable  Gaussian Processes",
    "abstract": "Gaussian processes (GPs) are important probabilistic tools for inference and\nlearning in spatio-temporal modelling problems such as those in climate science\nand epidemiology. However, existing GP approximations do not simultaneously\nsupport large numbers of off-the-grid spatial data-points and long time-series\nwhich is a hallmark of many applications.\nPseudo-point approximations, one of the gold-standard methods for scaling GPs\nto large data sets, are well suited for handling off-the-grid spatial data.\nHowever, they cannot handle long temporal observation horizons effectively\nreverting to cubic computational scaling in the time dimension. State space GP\napproximations are well suited to handling temporal data, if the temporal GP\nprior admits a Markov form, leading to linear complexity in the number of\ntemporal observations, but have a cubic spatial cost and cannot handle\noff-the-grid spatial data.\nIn this work we show that there is a simple and elegant way to combine\npseudo-point methods with the state space GP approximation framework to get the\nbest of both worlds. The approach hinges on a surprising conditional\nindependence property which applies to space--time separable GPs. We\ndemonstrate empirically that the combined approach is more scalable and\napplicable to a greater range of spatio-temporal problems than either method on\nits own.",
    "descriptor": "",
    "authors": [
      "Will Tebbutt",
      "Arno Solin",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10210"
  },
  {
    "id": "arXiv:2106.10212",
    "title": "Residual Error: a New Performance Measure for Adversarial Robustness",
    "abstract": "Despite the significant advances in deep learning over the past decade, a\nmajor challenge that limits the wide-spread adoption of deep learning has been\ntheir fragility to adversarial attacks. This sensitivity to making erroneous\npredictions in the presence of adversarially perturbed data makes deep neural\nnetworks difficult to adopt for certain real-world, mission-critical\napplications. While much of the research focus has revolved around adversarial\nexample creation and adversarial hardening, the area of performance measures\nfor assessing adversarial robustness is not well explored. Motivated by this,\nthis study presents the concept of residual error, a new performance measure\nfor not only assessing the adversarial robustness of a deep neural network at\nthe individual sample level, but also can be used to differentiate between\nadversarial and non-adversarial examples to facilitate for adversarial example\ndetection. Furthermore, we introduce a hybrid model for approximating the\nresidual error in a tractable manner. Experimental results using the case of\nimage classification demonstrates the effectiveness and efficacy of the\nproposed residual error metric for assessing several well-known deep neural\nnetwork architectures. These results thus illustrate that the proposed measure\ncould be a useful tool for not only assessing the robustness of deep neural\nnetworks used in mission-critical scenarios, but also in the design of\nadversarially robust models.",
    "descriptor": "",
    "authors": [
      "Hossein Aboutalebi",
      "Mohammad Javad Shafiee",
      "Michelle Karg",
      "Christian Scharfenberger",
      "Alexander Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10212"
  },
  {
    "id": "arXiv:2106.10213",
    "title": "A Coarse-to-Fine Instance Segmentation Network with Learning Boundary  Representation",
    "abstract": "Boundary-based instance segmentation has drawn much attention since of its\nattractive efficiency. However, existing methods suffer from the difficulty in\nlong-distance regression. In this paper, we propose a coarse-to-fine module to\naddress the problem. Approximate boundary points are generated at the coarse\nstage and then features of these points are sampled and fed to a refined\nregressor for fine prediction. It is end-to-end trainable since differential\nsampling operation is well supported in the module. Furthermore, we design a\nholistic boundary-aware branch and introduce instance-agnostic supervision to\nassist regression. Equipped with ResNet-101, our approach achieves 31.7\\% mask\nAP on COCO dataset with single-scale training and testing, outperforming the\nbaseline 1.3\\% mask AP with less than 1\\% additional parameters and GFLOPs.\nExperiments also show that our proposed method achieves competitive performance\ncompared to existing boundary-based methods with a lightweight design and a\nsimple pipeline.",
    "descriptor": "\nComments: 8 pages, Accepted by IJCNN 2021\n",
    "authors": [
      "Feng Luo",
      "Bin-Bin Gao",
      "Jiangpeng Yan",
      "Xiu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10213"
  },
  {
    "id": "arXiv:2106.10217",
    "title": "Community Detection in Interval-Weighted Networks",
    "abstract": "In this paper we introduce and develop the concept of Interval-Weighted\nNetworks (IWN), a novel approach in Social Network Analysis, where the edge\nweights are represented by closed intervals composed with precise information,\ncomprehending intrinsic variability. We extend IWN for both Newman's modularity\nand modularity gain and the Louvain algorithm (LA), considering a tabular\nrepresentation of networks by contingency tables. We apply our methodology in a\nreal-world commuter network in mainland Portugal between the twenty three NUTS\n3 regions. The optimal partition of regions is developed and compared using two\nnew different approaches, designated as ``Classic Louvain'' (CL) and ``Hybrid\nLouvain'' (HL), which allow taking into account the variability observed in the\noriginal network, thereby minimizing the loss of information present in the raw\ndata. Our findings suggest the division of the twenty three Portuguese regions\nin three main communities. However, we find different geographical partitions\naccording to the community detection methodology used. This analysis can be\nuseful in many real-world applications, since it takes into account that the\nweights may vary within the ranges, rather than being constant.",
    "descriptor": "",
    "authors": [
      "H\u00e9lder Alves",
      "Paula Brito",
      "Pedro Campos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.10217"
  },
  {
    "id": "arXiv:2106.10220",
    "title": "Semantic navigation with domain knowledge",
    "abstract": "Several deployment locations of mobile robotic systems are human made (i.e.\nurban firefighter, building inspection, property security) and the manager may\nhave access to domain-specific knowledge about the place, which can provide\nsemantic contextual information allowing better reasoning and decision making.\nIn this paper we propose a system that allows a mobile robot to operate in a\nlocation-aware and operator-friendly way, by leveraging semantic information\nfrom the deployment location and integrating it to the robots localization and\nnavigation systems. We integrate Building Information Models (BIM) into the\nRobotic Operating System (ROS), to generate topological and metric maps fed to\nan layered path planner (global and local). A map merging algorithm integrates\nnewly discovered obstacles into the metric map, while a UWB-based localization\nsystem detects equipment to be registered back into the semantic database. The\nresults are validated in simulation and real-life deployments in buildings and\nconstruction sites.",
    "descriptor": "\nComments: 12 pages, 10 figures. arXiv admin note: substantial text overlap with arXiv:2104.10296\n",
    "authors": [
      "Rafael Gomes Braga",
      "Sina Karimi",
      "Ulrich Dah-Achinanon",
      "Ivanka Iordanova",
      "David St-Onge"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10220"
  },
  {
    "id": "arXiv:2106.10224",
    "title": "A new approach to proper orthogonal decomposition with difference  quotients",
    "abstract": "In a recent work [B. Koc et al., arXiv:2010.03750, SIAM J. Numer. Anal., to\nappear], the authors showed that including difference quotients (DQs) is\nnecessary in order to prove optimal pointwise in time error bounds for proper\northogonal decomposition (POD) reduced order models of the heat equation. In\nthis work, we introduce a new approach to including DQs in the POD procedure.\nInstead of computing the POD modes using all of the snapshot data and DQs, we\nonly use the first snapshot along with all of the DQs and special POD weights.\nWe show that this approach retains all of the numerical analysis benefits of\nthe standard POD DQ approach, while using a POD data set that has half the\nnumber of snapshots as the standard POD DQ approach, i.e., the new approach is\nmore computationally efficient. We illustrate our theoretical results with\nnumerical experiments.",
    "descriptor": "",
    "authors": [
      "Sarah K. Locke",
      "John R. Singler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10224"
  },
  {
    "id": "arXiv:2106.10232",
    "title": "A Benchmarks Library for Extended Parametric Timed Automata",
    "abstract": "Parametric timed automata are a powerful formalism for reasoning on\nconcurrent real-time systems with unknown or uncertain timing constants. In\norder to test the efficiency of new algorithms, a fair set of benchmarks is\nrequired. We present an extension of the IMITATOR benchmarks library, that\naccumulated over the years a number of case studies from academic and\nindustrial contexts. We extend here the library with several dozens of new\nbenchmarks; these benchmarks highlight several new features: liveness\nproperties, extensions of (parametric) timed automata (including stopwatches or\nmulti-rate clocks), and unsolvable toy benchmarks. These latter additions help\nto emphasize the limits of state-of-the-art parameter synthesis techniques,\nwith the hope to develop new dedicated algorithms in the future.",
    "descriptor": "\nComments: This is the author (and extended) version of the manuscript of the same name published in the proceedings of the 15th International Conference on Tests and Proofs (TAP 2021)\n",
    "authors": [
      "\u00c9tienne Andr\u00e9",
      "Dylan Marinho",
      "Jaco van de Pol"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.10232"
  },
  {
    "id": "arXiv:2106.10238",
    "title": "Nonparametric Hamiltonian Monte Carlo",
    "abstract": "Probabilistic programming uses programs to express generative models whose\nposterior probability is then computed by built-in inference engines. A\nchallenging goal is to develop general purpose inference algorithms that work\nout-of-the-box for arbitrary programs in a universal probabilistic programming\nlanguage (PPL). The densities defined by such programs, which may use\nstochastic branching and recursion, are (in general) nonparametric, in the\nsense that they correspond to models on an infinite-dimensional parameter\nspace. However standard inference algorithms, such as the Hamiltonian Monte\nCarlo (HMC) algorithm, target distributions with a fixed number of parameters.\nThis paper introduces the Nonparametric Hamiltonian Monte Carlo (NP-HMC)\nalgorithm which generalises HMC to nonparametric models. Inputs to NP-HMC are a\nnew class of measurable functions called \"tree representable\", which serve as a\nlanguage-independent representation of the density functions of probabilistic\nprograms in a universal PPL. We provide a correctness proof of NP-HMC, and\nempirically demonstrate significant performance improvements over existing\napproaches on several nonparametric examples.",
    "descriptor": "\nComments: 33 pages, 13 figures. To appear in Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021\n",
    "authors": [
      "Carol Mak",
      "Fabian Zaiser",
      "Luke Ong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10238"
  },
  {
    "id": "arXiv:2106.10240",
    "title": "VSAC: Efficient and Accurate Estimator for H and F",
    "abstract": "We present VSAC, a RANSAC-type robust estimator with a number of novelties.\nIt benefits from the introduction of the concept of independent inliers that\nimproves significantly the efficacy of the dominant plane handling and, also,\nallows near error-free rejection of incorrect models, without false positives.\nThe local optimization process and its application is improved so that it is\nrun on average only once. Further technical improvements include adaptive\nsequential hypothesis verification and efficient model estimation via Gaussian\nelimination. Experiments on four standard datasets show that VSAC is\nsignificantly faster than all its predecessors and runs on average in 1-2 ms,\non a CPU. It is two orders of magnitude faster and yet as precise as MAGSAC++,\nthe currently most accurate estimator of two-view geometry. In the repeated\nruns on EVD, HPatches, PhotoTourism, and Kusvod2 datasets, it never failed.",
    "descriptor": "",
    "authors": [
      "Maksym Ivashechkin",
      "Daniel Barath",
      "Jiri Matas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10240"
  },
  {
    "id": "arXiv:2106.10251",
    "title": "Active Offline Policy Selection",
    "abstract": "This paper addresses the problem of policy selection in domains with abundant\nlogged data, but with a very restricted interaction budget. Solving this\nproblem would enable safe evaluation and deployment of offline reinforcement\nlearning policies in industry, robotics, and healthcare domain among others.\nSeveral off-policy evaluation (OPE) techniques have been proposed to assess the\nvalue of policies using only logged data. However, there is still a big gap\nbetween the evaluation by OPE and the full online evaluation in the real\nenvironment. To reduce this gap, we introduce a novel \\emph{active offline\npolicy selection} problem formulation, which combined logged data and limited\nonline interactions to identify the best policy. We rely on the advances in OPE\nto warm start the evaluation. We build upon Bayesian optimization to\niteratively decide which policies to evaluate in order to utilize the limited\nenvironment interactions wisely. Many candidate policies could be proposed,\nthus, we focus on making our approach scalable and introduce a kernel function\nto model similarity between policies. We use several benchmark environments to\nshow that the proposed approach improves upon state-of-the-art OPE estimates\nand fully online policy evaluation with limited budget. Additionally, we show\nthat each component of the proposed method is important, it works well with\nvarious number and quality of OPE estimates and even with a large number of\ncandidate policies.",
    "descriptor": "",
    "authors": [
      "Ksenia Konyushkova",
      "Yutian Chen",
      "Thomas Paine",
      "Caglar Gulcehre",
      "Cosmin Paduraru",
      "Daniel J Mankowitz",
      "Misha Denil",
      "Nando de Freitas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10251"
  },
  {
    "id": "arXiv:2106.10252",
    "title": "Less is More: Feature Selection for Adversarial Robustness with  Compressive Counter-Adversarial Attacks",
    "abstract": "A common observation regarding adversarial attacks is that they mostly give\nrise to false activation at the penultimate layer to fool the classifier.\nAssuming that these activation values correspond to certain features of the\ninput, the objective becomes choosing the features that are most useful for\nclassification. Hence, we propose a novel approach to identify the important\nfeatures by employing counter-adversarial attacks, which highlights the\nconsistency at the penultimate layer with respect to perturbations on input\nsamples. First, we empirically show that there exist a subset of features,\nclassification based in which bridge the gap between the clean and robust\naccuracy. Second, we propose a simple yet efficient mechanism to identify those\nfeatures by searching the neighborhood of input sample. We then select features\nby observing the consistency of the activation values at the penultimate layer.",
    "descriptor": "",
    "authors": [
      "Emre Ozfatura",
      "Muhammad Zaid Hameed",
      "Kerem Ozfatura",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.10252"
  },
  {
    "id": "arXiv:2106.10254",
    "title": "An Empirical Investigation into Deep and Shallow Rule Learning",
    "abstract": "Inductive rule learning is arguably among the most traditional paradigms in\nmachine learning. Although we have seen considerable progress over the years in\nlearning rule-based theories, all state-of-the-art learners still learn\ndescriptions that directly relate the input features to the target concept. In\nthe simplest case, concept learning, this is a disjunctive normal form (DNF)\ndescription of the positive class. While it is clear that this is sufficient\nfrom a logical point of view because every logical expression can be reduced to\nan equivalent DNF expression, it could nevertheless be the case that more\nstructured representations, which form deep theories by forming intermediate\nconcepts, could be easier to learn, in very much the same way as deep neural\nnetworks are able to outperform shallow networks, even though the latter are\nalso universal function approximators. In this paper, we empirically compare\ndeep and shallow rule learning with a uniform general algorithm, which relies\non greedy mini-batch based optimization. Our experiments on both artificial and\nreal-world benchmark data indicate that deep rule networks outperform shallow\nnetworks.",
    "descriptor": "",
    "authors": [
      "Florian Beck",
      "Johannes F\u00fcrnkranz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10254"
  },
  {
    "id": "arXiv:2106.10258",
    "title": "Bridging the Gap Between Object Detection and User Intent via  Query-Modulation",
    "abstract": "When interacting with objects through cameras, or pictures, users often have\na specific intent. For example, they may want to perform a visual search.\nHowever, most object detection models ignore the user intent, relying on image\npixels as their only input. This often leads to incorrect results, such as lack\nof a high-confidence detection on the object of interest, or detection with a\nwrong class label. In this paper we investigate techniques to modulate standard\nobject detectors to explicitly account for the user intent, expressed as an\nembedding of a simple query. Compared to standard object detectors,\nquery-modulated detectors show superior performance at detecting objects for a\ngiven label of interest. Thanks to large-scale training data synthesized from\nstandard object detection annotations, query-modulated detectors can also\noutperform specialized referring expression recognition systems. Furthermore,\nthey can be simultaneously trained to solve for both query-modulated detection\nand standard object detection.",
    "descriptor": "",
    "authors": [
      "Marco Fornoni",
      "Chaochao Yan",
      "Liangchen Luo",
      "Kimberly Wilber",
      "Alex Stark",
      "Yin Cui",
      "Boqing Gong",
      "Andrew Howard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10258"
  },
  {
    "id": "arXiv:2106.10262",
    "title": "A Probabilistic Representation of DNNs: Bridging Mutual Information and  Generalization",
    "abstract": "Recently, Mutual Information (MI) has attracted attention in bounding the\ngeneralization error of Deep Neural Networks (DNNs). However, it is intractable\nto accurately estimate the MI in DNNs, thus most previous works have to relax\nthe MI bound, which in turn weakens the information theoretic explanation for\ngeneralization. To address the limitation, this paper introduces a\nprobabilistic representation of DNNs for accurately estimating the MI.\nLeveraging the proposed MI estimator, we validate the information theoretic\nexplanation for generalization, and derive a tighter generalization bound than\nthe state-of-the-art relaxations.",
    "descriptor": "\nComments: To appear in the ICML 2021 Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI\n",
    "authors": [
      "Xinjie Lan",
      "Kenneth Barner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10262"
  },
  {
    "id": "arXiv:2106.10268",
    "title": "MADE: Exploration via Maximizing Deviation from Explored Regions",
    "abstract": "In online reinforcement learning (RL), efficient exploration remains\nparticularly challenging in high-dimensional environments with sparse rewards.\nIn low-dimensional environments, where tabular parameterization is possible,\ncount-based upper confidence bound (UCB) exploration methods achieve minimax\nnear-optimal rates. However, it remains unclear how to efficiently implement\nUCB in realistic RL tasks that involve non-linear function approximation. To\naddress this, we propose a new exploration approach via \\textit{maximizing} the\ndeviation of the occupancy of the next policy from the explored regions. We add\nthis term as an adaptive regularizer to the standard RL objective to balance\nexploration vs. exploitation. We pair the new objective with a provably\nconvergent algorithm, giving rise to a new intrinsic reward that adjusts\nexisting bonuses. The proposed intrinsic reward is easy to implement and\ncombine with other existing RL algorithms to conduct exploration. As a proof of\nconcept, we evaluate the new intrinsic reward on tabular examples across a\nvariety of model-based and model-free algorithms, showing improvements over\ncount-only exploration strategies. When tested on navigation and locomotion\ntasks from MiniGrid and DeepMind Control Suite benchmarks, our approach\nsignificantly improves sample efficiency over state-of-the-art methods. Our\ncode is available at https://github.com/tianjunz/MADE.",
    "descriptor": "\nComments: 28 pages, 10 figures\n",
    "authors": [
      "Tianjun Zhang",
      "Paria Rashidinejad",
      "Jiantao Jiao",
      "Yuandong Tian",
      "Joseph Gonzalez",
      "Stuart Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10268"
  },
  {
    "id": "arXiv:2106.10270",
    "title": "How to train your ViT? Data, Augmentation, and Regularization in Vision  Transformers",
    "abstract": "Vision Transformers (ViT) have been shown to attain highly competitive\nperformance for a wide range of vision applications, such as image\nclassification, object detection and semantic image segmentation. In comparison\nto convolutional neural networks, the Vision Transformer's weaker inductive\nbias is generally found to cause an increased reliance on model regularization\nor data augmentation (``AugReg'' for short) when training on smaller training\ndatasets. We conduct a systematic empirical study in order to better understand\nthe interplay between the amount of training data, AugReg, model size and\ncompute budget. As one result of this study we find that the combination of\nincreased compute and AugReg can yield models with the same performance as\nmodels trained on an order of magnitude more training data: we train ViT models\nof various sizes on the public ImageNet-21k dataset which either match or\noutperform their counterparts trained on the larger, but not publicly available\nJFT-300M dataset.",
    "descriptor": "\nComments: Andreas, Alex, Xiaohua and Lucas contributed equally. We release more than 50'000 ViT models trained under diverse settings on various datasets. We believe this to be a treasure trove for model analysis. Available at this https URL and this https URL\n",
    "authors": [
      "Andreas Steiner",
      "Alexander Kolesnikov",
      "Xiaohua Zhai",
      "Ross Wightman",
      "Jakob Uszkoreit",
      "Lucas Beyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10270"
  },
  {
    "id": "arXiv:2106.10271",
    "title": "End-to-end Temporal Action Detection with Transformer",
    "abstract": "Temporal action detection (TAD) aims to determine the semantic label and the\nboundaries of every action instance in an untrimmed video. It is a fundamental\ntask in video understanding and significant progress has been made in TAD.\nPrevious methods involve multiple stages or networks and hand-designed rules or\noperations, which fall short in efficiency and flexibility. Here, we construct\nan end-to-end framework for TAD upon Transformer, termed \\textit{TadTR}, which\nsimultaneously predicts all action instances as a set of labels and temporal\nlocations in parallel. TadTR is able to adaptively extract temporal context\ninformation needed for making action predictions, by selectively attending to a\nnumber of snippets in a video. It greatly simplifies the pipeline of TAD and\nruns much faster than previous detectors. Our method achieves state-of-the-art\nperformance on HACS Segments and THUMOS14 and competitive performance on\nActivityNet-1.3. Our code will be made available at\n\\url{https://github.com/xlliu7/TadTR}.",
    "descriptor": "",
    "authors": [
      "Xiaolong Liu",
      "Qimeng Wang",
      "Yao Hu",
      "Xu Tang",
      "Song Bai",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10271"
  },
  {
    "id": "arXiv:2106.10272",
    "title": "Riemannian Convex Potential Maps",
    "abstract": "Modeling distributions on Riemannian manifolds is a crucial component in\nunderstanding non-Euclidean data that arises, e.g., in physics and geology. The\nbudding approaches in this space are limited by representational and\ncomputational tradeoffs. We propose and study a class of flows that uses convex\npotentials from Riemannian optimal transport. These are universal and can model\ndistributions on any compact Riemannian manifold without requiring domain\nknowledge of the manifold to be integrated into the architecture. We\ndemonstrate that these flows can model standard distributions on spheres, and\ntori, on synthetic and geological data. Our source code is freely available\nonline at this http URL",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Samuel Cohen",
      "Brandon Amos",
      "Yaron Lipman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10272"
  },
  {
    "id": "arXiv:2106.08727",
    "title": "AtrialGeneral: Domain Generalization for Left Atrial Segmentation of  Multi-Center LGE MRIs",
    "abstract": "Left atrial (LA) segmentation from late gadolinium enhanced magnetic\nresonance imaging (LGE MRI) is a crucial step needed for planning the treatment\nof atrial fibrillation. However, automatic LA segmentation from LGE MRI is\nstill challenging, due to the poor image quality, high variability in LA\nshapes, and unclear LA boundary. Though deep learning-based methods can provide\npromising LA segmentation results, they often generalize poorly to unseen\ndomains, such as data from different scanners and/or sites. In this work, we\ncollect 210 LGE MRIs from different centers with different levels of image\nquality. To evaluate the domain generalization ability of models on the LA\nsegmentation task, we employ four commonly used semantic segmentation networks\nfor the LA segmentation from multi-center LGE MRIs. Besides, we investigate\nthree domain generalization strategies, i.e., histogram matching, mutual\ninformation based disentangled representation, and random style transfer, where\na simple histogram matching is proved to be most effective.",
    "descriptor": "\nComments: 10 pages, 4 figures, MICCAI2021\n",
    "authors": [
      "Lei Li",
      "Veronika A. Zimmer",
      "Julia A. Schnabel",
      "Xiahai Zhuang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08727"
  },
  {
    "id": "arXiv:2106.09474",
    "title": "Optimising simulations for diphoton production at hadron colliders using  amplitude neural networks",
    "abstract": "Machine learning technology has the potential to dramatically optimise event\ngeneration and simulations. We continue to investigate the use of neural\nnetworks to approximate matrix elements for high-multiplicity scattering\nprocesses. We focus on the case of loop-induced diphoton production through\ngluon fusion and develop a realistic simulation method that can be applied to\nhadron collider observables. Neural networks are trained using the one-loop\namplitudes implemented in the NJet C++ library and interfaced to the Sherpa\nMonte Carlo event generator where we perform a detailed study for $2\\to3$ and\n$2\\to4$ scattering problems. We also consider how the trained networks perform\nwhen varying the kinematic cuts effecting the phase space and the reliability\nof the neural network simulations.",
    "descriptor": "\nComments: 31 pages, 12 figures, 2 tables\n",
    "authors": [
      "Joseph Aylett-Bullock",
      "Simon Badger",
      "Ryan Moodie"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09474"
  },
  {
    "id": "arXiv:2106.09759",
    "title": "Synthetic COVID-19 Chest X-ray Dataset for Computer-Aided Diagnosis",
    "abstract": "We introduce a new dataset called Synthetic COVID-19 Chest X-ray Dataset for\ntraining machine learning models. The dataset consists of 21,295 synthetic\nCOVID-19 chest X-ray images to be used for computer-aided diagnosis. These\nimages, generated via an unsupervised domain adaptation approach, are of high\nquality. We find that the synthetic images not only improve performance of\nvarious deep learning architectures when used as additional training data under\nheavy imbalance conditions, but also detect the target class with high\nconfidence. We also find that comparable performance can also be achieved when\ntrained only on synthetic images. Further, salient features of the synthetic\nCOVID-19 images indicate that the distribution is significantly different from\nNon-COVID-19 classes, enabling a proper decision boundary. We hope the\navailability of such high fidelity chest X-ray images of COVID-19 will\nencourage advances in the development of diagnostic and/or management tools.",
    "descriptor": "",
    "authors": [
      "Hasib Zunair",
      "A. Ben Hamza"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09759"
  },
  {
    "id": "arXiv:2106.09760",
    "title": "Multi-mode Transformer Transducer with Stochastic Future Context",
    "abstract": "Automatic speech recognition (ASR) models make fewer errors when more\nsurrounding speech information is presented as context. Unfortunately,\nacquiring a larger future context leads to higher latency. There exists an\ninevitable trade-off between speed and accuracy. Naively, to fit different\nlatency requirements, people have to store multiple models and pick the best\none under the constraints. Instead, a more desirable approach is to have a\nsingle model that can dynamically adjust its latency based on different\nconstraints, which we refer to as Multi-mode ASR. A Multi-mode ASR model can\nfulfill various latency requirements during inference -- when a larger latency\nbecomes acceptable, the model can process longer future context to achieve\nhigher accuracy and when a latency budget is not flexible, the model can be\nless dependent on future context but still achieve reliable accuracy. In\npursuit of Multi-mode ASR, we propose Stochastic Future Context, a simple\ntraining procedure that samples one streaming configuration in each iteration.\nThrough extensive experiments on AISHELL-1 and LibriSpeech datasets, we show\nthat a Multi-mode ASR model rivals, if not surpasses, a set of competitive\nstreaming baselines trained with different latency budgets.",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Kwangyoun Kim",
      "Felix Wu",
      "Prashant Sridhar",
      "Kyu J. Han",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09760"
  },
  {
    "id": "arXiv:2106.09762",
    "title": "Causal Bias Quantification for Continuous Treatment",
    "abstract": "In this work we develop a novel characterization of marginal causal effect\nand causal bias in the continuous treatment setting. We show they can be\nexpressed as an expectation with respect to a conditional probability\ndistribution, which can be estimated via standard statistical and probabilistic\nmethods. All terms in the expectations can be computed via automatic\ndifferentiation, also for highly non-linear models. We further develop a new\ncomplete criterion for identifiability of causal effects via covariate\nadjustment, showing the bias equals zero if the criterion is met. We study the\neffectiveness of our framework in three different scenarios: linear models\nunder confounding, overcontrol and endogenous selection bias; a non-linear\nmodel where full identifiability cannot be achieved because of missing data; a\nsimulated medical study of statins and atherosclerotic cardiovascular disease.",
    "descriptor": "",
    "authors": [
      "Gianluca Detommaso",
      "Michael Br\u00fcckner",
      "Philip Schulz",
      "Victor Chernozhukov"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09762"
  },
  {
    "id": "arXiv:2106.09780",
    "title": "Gradient-free optimization of chaotic acoustics with reservoir computing",
    "abstract": "We develop a versatile optimization method, which finds the design parameters\nthat minimize time-averaged acoustic cost functionals. The method is\ngradient-free, model-informed, and data-driven with reservoir computing based\non echo state networks. First, we analyse the predictive capabilities of echo\nstate networks both in the short- and long-time prediction of the dynamics. We\nfind that both fully data-driven and model-informed architectures learn the\nchaotic acoustic dynamics, both time-accurately and statistically. Informing\nthe training with a physical reduced-order model with one acoustic mode\nmarkedly improves the accuracy and robustness of the echo state networks,\nwhilst keeping the computational cost low. Echo state networks offer accurate\npredictions of the long-time dynamics, which would be otherwise expensive by\nintegrating the governing equations to evaluate the time-averaged quantity to\noptimize. Second, we couple echo state networks with a Bayesian technique to\nexplore the design thermoacoustic parameter space. The computational method is\nminimally intrusive. Third, we find the set of flame parameters that minimize\nthe time-averaged acoustic energy of chaotic oscillations, which are caused by\nthe positive feedback with a heat source, such as a flame in gas turbines or\nrocket motors. These oscillations are known as thermoacoustic oscillations. The\noptimal set of flame parameters is found with the same accuracy as brute-force\ngrid search, but with a convergence rate that is more than one order of\nmagnitude faster. This work opens up new possibilities for non-intrusive\n(``hands-off'') optimization of chaotic systems, in which the cost of\ngenerating data, for example from high-fidelity simulations and experiments, is\nhigh.",
    "descriptor": "\nComments: 15 figures, 23 pages\n",
    "authors": [
      "Francisco Huhn",
      "Luca Magri"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2106.09780"
  },
  {
    "id": "arXiv:2106.09798",
    "title": "Wide stochastic networks: Gaussian limit and PAC-Bayesian training",
    "abstract": "The limit of infinite width allows for substantial simplifications in the\nanalytical study of overparameterized neural networks. With a suitable random\ninitialization, an extremely large network is well approximated by a Gaussian\nprocess, both before and during training. In the present work, we establish a\nsimilar result for a simple stochastic architecture whose parameters are random\nvariables. The explicit evaluation of the output distribution allows for a\nPAC-Bayesian training procedure that directly optimizes the generalization\nbound. For a large but finite-width network, we show empirically on MNIST that\nthis training approach can outperform standard PAC-Bayesian methods.",
    "descriptor": "\nComments: 20 pages, 2 figures\n",
    "authors": [
      "Eugenio Clerico",
      "George Deligiannidis",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09798"
  },
  {
    "id": "arXiv:2106.09815",
    "title": "Escaping strict saddle points of the Moreau envelope in nonsmooth  optimization",
    "abstract": "Recent work has shown that stochastically perturbed gradient methods can\nefficiently escape strict saddle points of smooth functions. We extend this\nbody of work to nonsmooth optimization, by analyzing an inexact analogue of a\nstochastically perturbed gradient method applied to the Moreau envelope. The\nmain conclusion is that a variety of algorithms for nonsmooth optimization can\nescape strict saddle points of the Moreau envelope at a controlled rate. The\nmain technical insight is that typical algorithms applied to the proximal\nsubproblem yield directions that approximate the gradient of the Moreau\nenvelope in relative terms.",
    "descriptor": "\nComments: 29 pages, 1 figure\n",
    "authors": [
      "Damek Davis",
      "Mateo D\u00edaz",
      "Dmitriy Drusvyatskiy"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09815"
  },
  {
    "id": "arXiv:2106.09832",
    "title": "Hybrid graph convolutional neural networks for landmark-based anatomical  segmentation",
    "abstract": "In this work we address the problem of landmark-based segmentation for\nanatomical structures. We propose HybridGNet, an encoder-decoder neural\narchitecture which combines standard convolutions for image feature encoding,\nwith graph convolutional neural networks to decode plausible representations of\nanatomical structures. We benchmark the proposed architecture considering other\nstandard landmark and pixel-based models for anatomical segmentation in chest\nx-ray images, and found that HybridGNet is more robust to image occlusions. We\nalso show that it can be used to construct landmark-based segmentations from\npixel level annotations. Our experimental results suggest that HybridGNet\nproduces accurate and anatomically plausible landmark-based segmentations, by\nnaturally incorporating shape constraints within the decoding process via\nspectral convolutions.",
    "descriptor": "\nComments: Accepted for publication at MICCAI 2021\n",
    "authors": [
      "Nicol\u00e1s Gaggion",
      "Lucas Mansilla",
      "Diego Milone",
      "Enzo Ferrante"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09832"
  },
  {
    "id": "arXiv:2106.09834",
    "title": "AI-Enabled Ultra-Low-Dose CT Reconstruction",
    "abstract": "By the ALARA (As Low As Reasonably Achievable) principle, ultra-low-dose CT\nreconstruction is a holy grail to minimize cancer risks and genetic damages,\nespecially for children. With the development of medical CT technologies, the\niterative algorithms are widely used to reconstruct decent CT images from a\nlow-dose scan. Recently, artificial intelligence (AI) techniques have shown a\ngreat promise in further reducing CT radiation dose to the next level. In this\npaper, we demonstrate that AI-powered CT reconstruction offers diagnostic image\nquality at an ultra-low-dose level comparable to that of radiography.\nSpecifically, here we develop a Split Unrolled Grid-like Alternative\nReconstruction (SUGAR) network, in which deep learning, physical modeling and\nimage prior are integrated. The reconstruction results from clinical datasets\nshow that excellent images can be reconstructed using SUGAR from 36\nprojections. This approach has a potential to change future healthcare.",
    "descriptor": "\nComments: 19 pages, 10 figures, 1 table, 44 references\n",
    "authors": [
      "Weiwen Wu",
      "Chuang Niu",
      "Shadi Ebrahimian",
      "Hengyong Yu",
      "Mannu Kalra",
      "Ge Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09834"
  },
  {
    "id": "arXiv:2106.09855",
    "title": "On the Prandtl-Kolmogorov 1-equation model of turbulence",
    "abstract": "We prove an estimate of total (viscous plus modelled turbulent) energy\ndissipation in general eddy viscosity models for shear flows. For general eddy\nviscosity models, we show that the ratio of the near wall average viscosity to\nthe effective global viscosity is the key parameter. This result is then\napplied to the 1-equation, URANS model of turbulence for which this ratio\ndepends on the specification of the turbulence length scale. The model, which\nwas derived by Prandtl in 1945, is a component of a 2-equation model derived by\nKolmogorov in 1942 and is the core of many unsteady, Reynolds averaged models\nfor prediction of turbulent flows. Away from walls, interpreting an early\nsuggestion of Prandtl, we set \\begin{equation*} l=\\sqrt{2}k^{+1/2}\\tau,\n\\hspace{50mm} \\end{equation*} where $\\tau =$ selected time scale. In the near\nwall region analysis suggests replacing the traditional $l=0.41d$ ($d=$ wall\nnormal distance) with $l=0.41d\\sqrt{d/L}$ giving, e.g., \\begin{equation*}\nl=\\min \\left\\{ \\sqrt{2}k{}^{+1/2}\\tau ,\\text{ }0.41d\\sqrt{\\frac{d}{L}} \\right\\}\n. \\hspace{50mm} \\end{equation*} This $l(\\cdot )$ results in a simpler model\nwith correct near wall asymptotics. Its energy dissipation rate scales no\nlarger than the physically correct $O(U^{3}/L)$, balancing energy input with\nenergy dissipation.",
    "descriptor": "",
    "authors": [
      "Kiera Kean",
      "William Layton",
      "Michael Schneier"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.09855"
  },
  {
    "id": "arXiv:2106.09882",
    "title": "Engineered Bacteria Computationally Solve Chemically Generated 2X2 Maze  Problems",
    "abstract": "Maze generating and solving are challenging problems in mathematics and\ncomputing. Here we generated simple 2X2 maze problems applying four chemicals\nand created a set of engineered bacteria, which in a mixed population worked as\na computational solver for any such problem. The input-output matrices of a\nmathematical maze were mapped through a truth table, where the logic values of\nfour chemical inputs determined the sixteen different 2X2 maze problems on a\nchemical space. Our engineered bacteria, which consisted of six different\ngenetic logic circuits and distributed among six cell populations processed the\nchemical information and solved the problems by expressing or not expressing\nfour different fluorescent proteins. The three available solutions were\nvisualized by glowing bacteria and for the thirteen no solution cases no\nbacteria glowed. Thus, our system not only solved the maze problems but also\nshowed the number of solvable and unsolvable problems. This work presented a\nnew and abstract cellular computational way towards maze problems and may have\nsignificance in biocomputation and synthetic biology.",
    "descriptor": "",
    "authors": [
      "Kathakali Sarkar",
      "Deepro Bonnerjee",
      "Sangram Bagh"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Emerging Technologies (cs.ET)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2106.09882"
  },
  {
    "id": "arXiv:2106.09883",
    "title": "On Logics of Perfect Paradefinite Algebras",
    "abstract": "The present study shows how any De Morgan algebra may be enriched by a\n'perfection operator' that allows one to express the Boolean properties of\nnegation-consistency and negation-determinedness. The corresponding variety of\n'perfect paradefinite algebras' (PP-algebras) is shown to be term-equivalent to\nthe variety of involutive Stone algebras, introduced by R. Cignoli and M.\nSagastume, and more recently studied from a logical perspective by M. Figallo\nand L. Cant\\'u. Such equivalence then plays an important role in the\ninvestigation of the 1-assertional logic and also the order-preserving logic\nasssociated to the PP-algebras. The latter logic, which we call PP$\\leq$,\nhappens to be characterised by a single 6-valued matrix and consists very\nnaturally in a Logic of Formal Inconsistency and Formal Undeterminedness. The\nlogic PP$\\leq$ is here axiomatised, by means of an analytic finite\nHilbert-style calculus, and a related axiomatization procedure is presented\nthat covers the logics of other classes of De Morgan algebras as well as\nsuper-Belnap logics enriched by a perfection connective.",
    "descriptor": "",
    "authors": [
      "Joel Gomes",
      "Vitor Greati",
      "S\u00e9rgio Marcelino",
      "Jo\u00e3o Marcos",
      "Umberto Rivieccio"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.09883"
  },
  {
    "id": "arXiv:2106.09885",
    "title": "An Improved Single Step Non-autoregressive Transformer for Automatic  Speech Recognition",
    "abstract": "Non-autoregressive mechanisms can significantly decrease inference time for\nspeech transformers, especially when the single step variant is applied.\nPrevious work on CTC alignment-based single step non-autoregressive transformer\n(CASS-NAT) has shown a large real time factor (RTF) improvement over\nautoregressive transformers (AT). In this work, we propose several methods to\nimprove the accuracy of the end-to-end CASS-NAT, followed by performance\nanalyses. First, convolution augmented self-attention blocks are applied to\nboth the encoder and decoder modules. Second, we propose to expand the trigger\nmask (acoustic boundary) for each token to increase the robustness of CTC\nalignments. In addition, iterated loss functions are used to enhance the\ngradient update of low-layer parameters. Without using an external language\nmodel, the WERs of the improved CASS-NAT, when using the three methods, are\n3.1%/7.2% on Librispeech test clean/other sets and the CER is 5.4% on the\nAishell1 test set, achieving a 7%~21% relative WER/CER improvement. For the\nanalyses, we plot attention weight distributions in the decoders to visualize\nthe relationships between token-level acoustic embeddings. When the acoustic\nembeddings are visualized, we find that they have a similar behavior to word\nembeddings, which explains why the improved CASS-NAT performs similarly to AT.",
    "descriptor": "\nComments: To appear in Interspeech2021\n",
    "authors": [
      "Ruchao Fan",
      "Wei Chu",
      "Peng Chang",
      "Jing Xiao",
      "Abeer Alwan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09885"
  },
  {
    "id": "arXiv:2106.09891",
    "title": "ICINet: ICI-Aware Neural Network Based Channel Estimation for Rapidly  Time-Varying OFDM Systems",
    "abstract": "A novel intercarrier interference (ICI)-aware orthogonal frequency division\nmultiplexing (OFDM) channel estimation network ICINet is presented for rapidly\ntime-varying channels. ICINet consists of two components: a preprocessing deep\nneural subnetwork (PreDNN) and a cascaded residual learning-based neural\nsubnetwork (CasResNet). By fully taking into account the impact of ICI, the\nproposed PreDNN first refines the initial channel estimates in a\nsubcarrier-wise fashion. In addition, the CasResNet is designed to further\nenhance the estimation accuracy. The proposed cascaded network is compatible\nwith any pilot patterns and robust against mismatched system configurations.\nSimulation results verify the superiority of ICINet over existing networks in\nterms of better performance and much less complexity.",
    "descriptor": "",
    "authors": [
      "Yi Sun",
      "Hong Shen",
      "Zhenguo Du",
      "Lan Peng",
      "Chunming Zhao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.09891"
  },
  {
    "id": "arXiv:2106.09907",
    "title": "The dihedral hidden subgroup problem",
    "abstract": "We give an exposition of the hidden subgroup problem for dihedral groups from\nthe point of view of the standard hidden subgroup quantum algorithm for finite\ngroups. In particular, we recall the obstructions for strong Fourier sampling\nto succeed, but at the same time, show how the standard algorithm can be\nmodified to establish polynomial quantum query complexity. Finally, we explain\na new connection between the dihedral coset problem and cloning of quantum\nstates.",
    "descriptor": "",
    "authors": [
      "Imin Chen",
      "David Sun"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.09907"
  },
  {
    "id": "arXiv:2106.09963",
    "title": "Low Resource German ASR with Untranscribed Data Spoken by Non-native  Children -- INTERSPEECH 2021 Shared Task SPAPL System",
    "abstract": "This paper describes the SPAPL system for the INTERSPEECH 2021 Challenge:\nShared Task on Automatic Speech Recognition for Non-Native Children's Speech in\nGerman. ~ 5 hours of transcribed data and ~ 60 hours of untranscribed data are\nprovided to develop a German ASR system for children. For the training of the\ntranscribed data, we propose a non-speech state discriminative loss (NSDL) to\nmitigate the influence of long-duration non-speech segments within speech\nutterances. In order to explore the use of the untranscribed data, various\napproaches are implemented and combined together to incrementally improve the\nsystem performance. First, bidirectional autoregressive predictive coding\n(Bi-APC) is used to learn initial parameters for acoustic modelling using the\nprovided untranscribed data. Second, incremental semi-supervised learning is\nfurther used to iteratively generate pseudo-transcribed data. Third, different\ndata augmentation schemes are used at different training stages to increase the\nvariability and size of the training data. Finally, a recurrent neural network\nlanguage model (RNNLM) is used for rescoring. Our system achieves a word error\nrate (WER) of 39.68% on the evaluation data, an approximately 12% relative\nimprovement over the official baseline (45.21%).",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2021\n",
    "authors": [
      "Jinhan Wang",
      "Yunzheng Zhu",
      "Ruchao Fan",
      "Wei Chu",
      "Abeer Alwan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09963"
  },
  {
    "id": "arXiv:2106.10049",
    "title": "Graphs with at most two moplexes",
    "abstract": "A moplex is a natural graph structure that arises when lifting Dirac's\nclassical theorem from chordal graphs to general graphs. However, while every\nnon-complete graph has at least two moplexes, little is known about structural\nproperties of graphs with a bounded number of moplexes. The study of these\ngraphs is motivated by the parallel between moplexes in general graphs and\nsimplicial modules in chordal graphs: Unlike in the moplex setting, properties\nof chordal graphs with a bounded number of simplicial modules are well\nunderstood. For instance, chordal graphs having at most two simplicial modules\nare interval. In this work we initiate an investigation of $k$-moplex graphs,\nwhich are defined as graphs containing at most $k$ moplexes. Of particular\ninterest is the smallest nontrivial case $k=2$, which forms a counterpart to\nthe class of interval graphs. As our main structural result, we show that the\nclass of connected $2$-moplex graphs is sandwiched between the classes of\nproper interval graphs and cocomparability graphs; moreover, both inclusions\nare tight for hereditary classes. From a complexity theoretic viewpoint, this\nleads to the natural question of whether the presence of at most two moplexes\nguarantees a sufficient amount of structure to efficiently solve problems that\nare known to be intractable on cocomparability graphs, but not on proper\ninterval graphs. We develop new reductions that answer this question negatively\nfor two prominent problems fitting this profile, namely Graph Isomorphism and\nMax-Cut. On the other hand, we prove that every connected $2$-moplex graph\ncontains a Hamiltonian path, generalising the same property of connected proper\ninterval graphs. Furthermore, for graphs with a higher number of moplexes, we\nlift the previously known result that graphs without asteroidal triples have at\nmost two moplexes to the more general setting of larger asteroidal sets.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Robert Ganian",
      "Meike Hatzel",
      "Matja\u017e Krnc",
      "Martin Milani\u010d"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.10049"
  },
  {
    "id": "arXiv:2106.10051",
    "title": "Distributed optimal power flow",
    "abstract": "Abstract Objective: The objectives of this paper are to 1) construct a new\nnetwork model compatible with distributed computation, 2) construct the full\noptimal power flow (OPF) in a distributed fashion so that an effective,\nnon-inferior solution can be found, and 3) develop a scalable algorithm that\nguarantees the convergence to a local minimum.",
    "descriptor": "",
    "authors": [
      "HyungSeon Oh"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.10051"
  },
  {
    "id": "arXiv:2106.10052",
    "title": "On Contrastive Representations of Stochastic Processes",
    "abstract": "Learning representations of stochastic processes is an emerging problem in\nmachine learning with applications from meta-learning to physical object models\nto time series. Typical methods rely on exact reconstruction of observations,\nbut this approach breaks down as observations become high-dimensional or noise\ndistributions become complex. To address this, we propose a unifying framework\nfor learning contrastive representations of stochastic processes (CRESP) that\ndoes away with exact reconstruction. We dissect potential use cases for\nstochastic process representations, and propose methods that accommodate each.\nEmpirically, we show that our methods are effective for learning\nrepresentations of periodic functions, 3D objects and dynamical processes. Our\nmethods tolerate noisy high-dimensional observations better than traditional\napproaches, and the learned representations transfer to a range of downstream\ntasks.",
    "descriptor": "",
    "authors": [
      "Emile Mathieu",
      "Adam Foster",
      "Yee Whye Teh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10052"
  },
  {
    "id": "arXiv:2106.10064",
    "title": "Fitting summary statistics of neural data with a differentiable spiking  network simulator",
    "abstract": "Fitting network models to neural activity is becoming an important tool in\nneuroscience. A popular approach is to model a brain area with a probabilistic\nrecurrent spiking network whose parameters maximize the likelihood of the\nrecorded activity. Although this is widely used, we show that the resulting\nmodel does not produce realistic neural activity and wrongly estimates the\nconnectivity matrix when neurons that are not recorded have a substantial\nimpact on the recorded network. To correct for this, we suggest to augment the\nlog-likelihood with terms that measure the dissimilarity between simulated and\nrecorded activity. This dissimilarity is defined via summary statistics\ncommonly used in neuroscience, and the optimization is efficient because it\nrelies on back-propagation through the stochastically simulated spike trains.\nWe analyze this method theoretically and show empirically that it generates\nmore realistic activity statistics and recovers the connectivity matrix better\nthan other methods.",
    "descriptor": "",
    "authors": [
      "Guillaume Bellec",
      "Shuqi Wang",
      "Alireza Modirshanechi",
      "Johanni Brea",
      "Wulfram Gerstner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.10064"
  },
  {
    "id": "arXiv:2106.10080",
    "title": "Debiased Subjective Assessment of Real-World Image Enhancement",
    "abstract": "In real-world image enhancement, it is often challenging (if not impossible)\nto acquire ground-truth data, preventing the adoption of distance metrics for\nobjective quality assessment. As a result, one often resorts to subjective\nquality assessment, the most straightforward and reliable means of evaluating\nimage enhancement. Conventional subjective testing requires manually\npre-selecting a small set of visual examples, which may suffer from three\nsources of biases: 1) sampling bias due to the extremely sparse distribution of\nthe selected samples in the image space; 2) algorithmic bias due to potential\noverfitting the selected samples; 3) subjective bias due to further potential\ncherry-picking test results. This eventually makes the field of real-world\nimage enhancement more of an art than a science. Here we take steps towards\ndebiasing conventional subjective assessment by automatically sampling a set of\nadaptive and diverse images for subsequent testing. This is achieved by casting\nsample selection into a joint maximization of the discrepancy between the\nenhancers and the diversity among the selected input images. Careful visual\ninspection on the resulting enhanced images provides a debiased ranking of the\nenhancement algorithms. We demonstrate our subjective assessment method using\nthree popular and practically demanding image enhancement tasks: dehazing,\nsuper-resolution, and low-light enhancement.",
    "descriptor": "",
    "authors": [
      "Cao Peibei. Wang Zhangyang",
      "Ma Kede"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10080"
  },
  {
    "id": "arXiv:2106.10166",
    "title": "Problem Dependent View on Structured Thresholding Bandit Problems",
    "abstract": "We investigate the problem dependent regime in the stochastic Thresholding\nBandit problem (TBP) under several shape constraints. In the TBP, the objective\nof the learner is to output, at the end of a sequential game, the set of arms\nwhose means are above a given threshold. The vanilla, unstructured, case is\nalready well studied in the literature. Taking $K$ as the number of arms, we\nconsider the case where (i) the sequence of arm's means $(\\mu_k)_{k=1}^K$ is\nmonotonically increasing (MTBP) and (ii) the case where $(\\mu_k)_{k=1}^K$ is\nconcave (CTBP). We consider both cases in the problem dependent regime and\nstudy the probability of error - i.e. the probability to mis-classify at least\none arm. In the fixed budget setting, we provide upper and lower bounds for the\nprobability of error in both the concave and monotone settings, as well as\nassociated algorithms. In both settings the bounds match in the problem\ndependent regime up to universal constants in the exponential.",
    "descriptor": "\nComments: 25 pages. arXiv admin note: text overlap with arXiv:2006.10006\n",
    "authors": [
      "James Cheshire",
      "Pierre M\u00e9nard",
      "Alexandra Carpentier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10166"
  },
  {
    "id": "arXiv:2106.10188",
    "title": "Deterministic Gibbs Sampling via Ordinary Differential Equations",
    "abstract": "Deterministic dynamics is an essential part of many MCMC algorithms, e.g.\nHybrid Monte Carlo or samplers utilizing normalizing flows. This paper presents\na general construction of deterministic measure-preserving dynamics using\nautonomous ODEs and tools from differential geometry. We show how Hybrid Monte\nCarlo and other deterministic samplers follow as special cases of our theory.\nWe then demonstrate the utility of our approach by constructing a continuous\nnon-sequential version of Gibbs sampling in terms of an ODE flow and extending\nit to discrete state spaces. We find that our deterministic samplers are more\nsample efficient than stochastic counterparts, even if the latter generate\nindependent samples.",
    "descriptor": "",
    "authors": [
      "Kirill Neklyudov",
      "Roberto Bondesan",
      "Max Welling"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10188"
  },
  {
    "id": "arXiv:2106.10195",
    "title": "Non-Iterative Phase Retrieval With Cascaded Neural Networks",
    "abstract": "Fourier phase retrieval is the problem of reconstructing a signal given only\nthe magnitude of its Fourier transformation. Optimization-based approaches,\nlike the well-established Gerchberg-Saxton or the hybrid input output\nalgorithm, struggle at reconstructing images from magnitudes that are not\noversampled. This motivates the application of learned methods, which allow\nreconstruction from non-oversampled magnitude measurements after a learning\nphase. In this paper, we want to push the limits of these learned methods by\nmeans of a deep neural network cascade that reconstructs the image successively\non different resolutions from its non-oversampled Fourier magnitude. We\nevaluate our method on four different datasets (MNIST, EMNIST, Fashion-MNIST,\nand KMNIST) and demonstrate that it yields improved performance over other\nnon-iterative methods and optimization-based methods.",
    "descriptor": "\nComments: Accepted at the 30th International Conference on Artificial Neural Networks (ICANN 2021)\n",
    "authors": [
      "Tobias Uelwer",
      "Tobias Hoffmann",
      "Stefan Harmeling"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10195"
  },
  {
    "id": "arXiv:2106.10198",
    "title": "Systematic comparison of graph embedding methods in practical tasks",
    "abstract": "Network embedding techniques aim at representing structural properties of\ngraphs in geometric space. Those representations are considered useful in\ndownstream tasks such as link prediction and clustering. However, the number of\ngraph embedding methods available on the market is large, and practitioners\nface the non-trivial choice of selecting the proper approach for a given\napplication. The present work attempts to close this gap of knowledge through a\nsystematic comparison of eleven different methods for graph embedding. We\nconsider methods for embedding networks in the hyperbolic and Euclidean metric\nspaces, as well as non-metric community-based embedding methods. We apply these\nmethods to embed more than one hundred real-world and synthetic networks. Three\ncommon downstream tasks -- mapping accuracy, greedy routing, and link\nprediction -- are considered to evaluate the quality of the various embedding\nmethods. Our results show that some Euclidean embedding methods excel in greedy\nrouting. As for link prediction, community-based and hyperbolic embedding\nmethods yield overall performance superior than that of Euclidean-space-based\napproaches. We compare the running time for different methods and further\nanalyze the impact of different network characteristics such as degree\ndistribution, modularity, and clustering coefficients on the quality of the\ndifferent embedding methods. We release our evaluation framework to provide a\nstandardized benchmark for arbitrary embedding methods.",
    "descriptor": "\nComments: 13 pages, 6 figures, Supplemental Material available at this this http URL\n",
    "authors": [
      "Yi-Jiao Zhang",
      "Kai-Cheng Yang",
      "Filippo Radicchi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.10198"
  },
  {
    "id": "arXiv:2106.10229",
    "title": "A learned conditional prior for the VAE acoustic space of a TTS system",
    "abstract": "Many factors influence speech yielding different renditions of a given\nsentence. Generative models, such as variational autoencoders (VAEs), capture\nthis variability and allow multiple renditions of the same sentence via\nsampling. The degree of prosodic variability depends heavily on the prior that\nis used when sampling. In this paper, we propose a novel method to compute an\ninformative prior for the VAE latent space of a neural text-to-speech (TTS)\nsystem. By doing so, we aim to sample with more prosodic variability, while\ngaining controllability over the latent space's structure.\nBy using as prior the posterior distribution of a secondary VAE, which we\ncondition on a speaker vector, we can sample from the primary VAE taking\nexplicitly the conditioning into account and resulting in samples from a\nspecific region of the latent space for each condition (i.e. speaker). A formal\npreference test demonstrates significant preference of the proposed approach\nover standard Conditional VAE. We also provide visualisations of the latent\nspace where well-separated condition-specific clusters appear, as well as\nablation studies to better understand the behaviour of the system.",
    "descriptor": "\nComments: in Proceedings of Interspeech 2021\n",
    "authors": [
      "Penny Karanasou",
      "Sri Karlapati",
      "Alexis Moinet",
      "Arnaud Joly",
      "Ammar Abbas",
      "Simon Slangen",
      "Jaime Lorenzo Trueba",
      "Thomas Drugman"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.10229"
  },
  {
    "id": "arXiv:2106.10230",
    "title": "CT Image Synthesis Using Weakly Supervised Segmentation and Geometric  Inter-Label Relations For COVID Image Analysis",
    "abstract": "While medical image segmentation is an important task for computer aided\ndiagnosis, the high expertise requirement for pixelwise manual annotations\nmakes it a challenging and time consuming task. Since conventional data\naugmentations do not fully represent the underlying distribution of the\ntraining set, the trained models have varying performance when tested on images\ncaptured from different sources. Most prior work on image synthesis for data\naugmentation ignore the interleaved geometric relationship between different\nanatomical labels. We propose improvements over previous GAN-based medical\nimage synthesis methods by learning the relationship between different\nanatomical labels. We use a weakly supervised segmentation method to obtain\npixel level semantic label map of images which is used learn the intrinsic\nrelationship of geometry and shape across semantic labels. Latent space\nvariable sampling results in diverse generated images from a base image and\nimproves robustness. We use the synthetic images from our method to train\nnetworks for segmenting COVID-19 infected areas from lung CT images. The\nproposed method outperforms state-of-the-art segmentation methods on a public\ndataset. Ablation studies also demonstrate benefits of integrating geometry and\ndiversity.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2003.14119; text overlap with arXiv:1908.10555, arXiv:2004.14133 by other authors\n",
    "authors": [
      "Dwarikanath Mahapatra",
      "Ankur Singh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10230"
  },
  {
    "id": "arXiv:2106.10234",
    "title": "Dual-view Molecule Pre-training",
    "abstract": "Inspired by its success in natural language processing and computer vision,\npre-training has attracted substantial attention in cheminformatics and\nbioinformatics, especially for molecule based tasks. A molecule can be\nrepresented by either a graph (where atoms are connected by bonds) or a SMILES\nsequence (where depth-first-search is applied to the molecular graph with\nspecific rules). Existing works on molecule pre-training use either graph\nrepresentations only or SMILES representations only. In this work, we propose\nto leverage both the representations and design a new pre-training algorithm,\ndual-view molecule pre-training (briefly, DMP), that can effectively combine\nthe strengths of both types of molecule representations. The model of DMP\nconsists of two branches: a Transformer branch that takes the SMILES sequence\nof a molecule as input, and a GNN branch that takes a molecular graph as input.\nThe training of DMP contains three tasks: (1) predicting masked tokens in a\nSMILES sequence by the Transformer branch, (2) predicting masked atoms in a\nmolecular graph by the GNN branch, and (3) maximizing the consistency between\nthe two high-level representations output by the Transformer and GNN branches\nseparately. After pre-training, we can use either the Transformer branch (this\none is recommended according to empirical results), the GNN branch, or both for\ndownstream tasks. DMP is tested on nine molecular property prediction tasks and\nachieves state-of-the-art performances on seven of them. Furthermore, we test\nDMP on three retrosynthesis tasks and achieve state-of-the-result on the\nUSPTO-full dataset. Our code will be released soon.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Jinhua Zhu",
      "Yingce Xia",
      "Tao Qin",
      "Wengang Zhou",
      "Houqiang Li",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10234"
  },
  {
    "id": "arXiv:2106.10236",
    "title": "Efficient Black-Box Importance Sampling for VaR and CVaR Estimation",
    "abstract": "This paper considers Importance Sampling (IS) for the estimation of tail\nrisks of a loss defined in terms of a sophisticated object such as a machine\nlearning feature map or a mixed integer linear optimisation formulation.\nAssuming only black-box access to the loss and the distribution of the\nunderlying random vector, the paper presents an efficient IS algorithm for\nestimating the Value at Risk and Conditional Value at Risk. The key challenge\nin any IS procedure, namely, identifying an appropriate change-of-measure, is\nautomated with a self-structuring IS transformation that learns and replicates\nthe concentration properties of the conditional excess from less rare samples.\nThe resulting estimators enjoy asymptotically optimal variance reduction when\nviewed in the logarithmic scale. Simulation experiments highlight the efficacy\nand practicality of the proposed scheme",
    "descriptor": "",
    "authors": [
      "Anand Deo",
      "Karthyek Murthy"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10236"
  },
  {
    "id": "arXiv:2106.10241",
    "title": "An Analysis of the Deployment of Models Trained on Private Tabular  Synthetic Data: Unexpected Surprises",
    "abstract": "Diferentially private (DP) synthetic datasets are a powerful approach for\ntraining machine learning models while respecting the privacy of individual\ndata providers. The effect of DP on the fairness of the resulting trained\nmodels is not yet well understood. In this contribution, we systematically\nstudy the effects of differentially private synthetic data generation on\nclassification. We analyze disparities in model utility and bias caused by the\nsynthetic dataset, measured through algorithmic fairness metrics. Our first set\nof results show that although there seems to be a clear negative correlation\nbetween privacy and utility (the more private, the less accurate) across all\ndata synthesizers we evaluated, more privacy does not necessarily imply more\nbias. Additionally, we assess the effects of utilizing synthetic datasets for\nmodel training and model evaluation. We show that results obtained on synthetic\ndata can misestimate the actual model performance when it is deployed on real\ndata. We hence advocate on the need for defining proper testing protocols in\nscenarios where differentially private synthetic datasets are utilized for\nmodel training and evaluation.",
    "descriptor": "",
    "authors": [
      "Mayana Pereira",
      "Meghana Kshirsagar",
      "Sumit Mukherjee",
      "Rahul Dodhia",
      "Juan Lavista Ferres"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10241"
  },
  {
    "id": "arXiv:2106.10259",
    "title": "On-Device Personalization of Automatic Speech Recognition Models for  Disordered Speech",
    "abstract": "While current state-of-the-art Automatic Speech Recognition (ASR) systems\nachieve high accuracy on typical speech, they suffer from significant\nperformance degradation on disordered speech and other atypical speech\npatterns. Personalization of ASR models, a commonly applied solution to this\nproblem, is usually performed in a server-based training environment posing\nproblems around data privacy, delayed model-update times, and communication\ncost for copying data and models between mobile device and server\ninfrastructure. In this paper, we present an approach to on-device based ASR\npersonalization with very small amounts of speaker-specific data. We test our\napproach on a diverse set of 100 speakers with disordered speech and find\nmedian relative word error rate improvement of 71% with only 50 short\nutterances required per speaker. When tested on a voice-controlled home\nautomation platform, on-device personalized models show a median task success\nrate of 81%, compared to only 40% of the unadapted models.",
    "descriptor": "",
    "authors": [
      "Katrin Tomanek",
      "Fran\u00e7oise Beaufays",
      "Julie Cattiau",
      "Angad Chandorkar",
      "Khe Chai Sim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.10259"
  },
  {
    "id": "arXiv:1808.05612",
    "title": "Universal Covertness for Discrete Memoryless Sources",
    "abstract": "Comments: 11 pages, two-column, 2 figures, accepted to IEEE Transactions on Information Theory",
    "descriptor": "\nComments: 11 pages, two-column, 2 figures, accepted to IEEE Transactions on Information Theory\n",
    "authors": [
      "Remi A. Chou",
      "Matthieu R. Bloch",
      "Aylin Yener"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1808.05612"
  },
  {
    "id": "arXiv:1905.05976",
    "title": "Information criteria for non-normalized models",
    "abstract": "Information criteria for non-normalized models",
    "descriptor": "",
    "authors": [
      "Takeru Matsuda",
      "Masatoshi Uehara",
      "Aapo Hyvarinen"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.05976"
  },
  {
    "id": "arXiv:1906.01183",
    "title": "Back Attention Knowledge Transfer for Low-Resource Named Entity  Recognition",
    "abstract": "Back Attention Knowledge Transfer for Low-Resource Named Entity  Recognition",
    "descriptor": "",
    "authors": [
      "Shengfei Lyu",
      "Linghao Sun",
      "Huixiong Yi",
      "Yong Liu",
      "Huanhuan Chen",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1906.01183"
  },
  {
    "id": "arXiv:1907.00856",
    "title": "SLSNet: Skin lesion segmentation using a lightweight generative  adversarial network",
    "abstract": "Comments: Accepted in Expert Systems with Applications",
    "descriptor": "\nComments: Accepted in Expert Systems with Applications\n",
    "authors": [
      "Md. Mostafa Kamal Sarker",
      "Hatem A. Rashwan",
      "Farhan Akram",
      "Vivek Kumar Singh",
      "Syeda Furruka Banu",
      "Forhad U H Chowdhury",
      "Kabir Ahmed Choudhury",
      "Sylvie Chambon",
      "Petia Radeva",
      "Domenec Puig",
      "Mohamed Abdel-Nasser"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1907.00856"
  },
  {
    "id": "arXiv:1908.03840",
    "title": "LoRMIkA: Local rule-based model interpretability with k-optimal  associations",
    "abstract": "Comments: 26 pages, 3 figures",
    "descriptor": "\nComments: 26 pages, 3 figures\n",
    "authors": [
      "Dilini Rajapaksha",
      "Christoph Bergmeir",
      "Wray Buntine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1908.03840"
  },
  {
    "id": "arXiv:1909.05006",
    "title": "Boltzmann machine learning and regularization methods for inferring  evolutionary fields and couplings from a multiple sequence alignment",
    "abstract": "Comments: In this version, the value of selective temperature for protein PF00153, $T_s$ in Table 5 and $k_B T_s$ in the last line of the section 2.8, has been corrected. The version 2 (arXiv:1909.05006v2) was published in the IEEE/ACM Transactions on Computational Biology and Bioinformatics. The program and multiple sequence alignments are available from this https URL",
    "descriptor": "\nComments: In this version, the value of selective temperature for protein PF00153, $T_s$ in Table 5 and $k_B T_s$ in the last line of the section 2.8, has been corrected. The version 2 (arXiv:1909.05006v2) was published in the IEEE/ACM Transactions on Computational Biology and Bioinformatics. The program and multiple sequence alignments are available from this https URL\n",
    "authors": [
      "Sanzo Miyazawa"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.05006"
  },
  {
    "id": "arXiv:1910.01210",
    "title": "Embodied Language Grounding with 3D Visual Feature Representations",
    "abstract": "Embodied Language Grounding with 3D Visual Feature Representations",
    "descriptor": "",
    "authors": [
      "Mihir Prabhudesai",
      "Hsiao-Yu Fish Tung",
      "Syed Ashar Javed",
      "Maximilian Sieb",
      "Adam W. Harley",
      "Katerina Fragkiadaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1910.01210"
  },
  {
    "id": "arXiv:1911.08782",
    "title": "Joint Emotion Label Space Modelling for Affect Lexica",
    "abstract": "Comments: Computer Speech and Language journal, to appear",
    "descriptor": "\nComments: Computer Speech and Language journal, to appear\n",
    "authors": [
      "Luna De Bruyne",
      "Pepa Atanasova",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1911.08782"
  },
  {
    "id": "arXiv:1911.12151",
    "title": "Decentralized Data-Enabled Predictive Control for Power System  Oscillation Damping",
    "abstract": "Decentralized Data-Enabled Predictive Control for Power System  Oscillation Damping",
    "descriptor": "",
    "authors": [
      "Linbin Huang",
      "Jeremy Coulson",
      "John Lygeros",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1911.12151"
  },
  {
    "id": "arXiv:1912.03217",
    "title": "The fundamental thermodynamic bounds on finite models",
    "abstract": "Comments: Author accepted manuscript",
    "descriptor": "\nComments: Author accepted manuscript\n",
    "authors": [
      "Andrew J. P. Garner"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/1912.03217"
  },
  {
    "id": "arXiv:2001.08026",
    "title": "ResDepth: Learned Residual Stereo Reconstruction",
    "abstract": "Comments: updated supplementary material",
    "descriptor": "\nComments: updated supplementary material\n",
    "authors": [
      "Corinne Stucker",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2001.08026"
  },
  {
    "id": "arXiv:2001.09590",
    "title": "Energy conserving SUPG methods for compatible finite element schemes in  numerical weather prediction",
    "abstract": "Comments: 27 pages, 9 figures, first version: all comments welcome",
    "descriptor": "\nComments: 27 pages, 9 figures, first version: all comments welcome\n",
    "authors": [
      "Golo A. Wimmer",
      "Colin J. Cotter",
      "Werner Bauer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2001.09590"
  },
  {
    "id": "arXiv:2002.00391",
    "title": "A Novel Graph based Trajectory Predictor with Pseudo Oracle",
    "abstract": "Comments: 17 apges, 8 figures",
    "descriptor": "\nComments: 17 apges, 8 figures\n",
    "authors": [
      "Biao Yang",
      "Guocheng Yan",
      "Pin Wang",
      "Chingyao Chan",
      "Xiang Song",
      "Yang Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2002.00391"
  },
  {
    "id": "arXiv:2002.05551",
    "title": "PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees",
    "abstract": "Comments: International Conference on Machine Learning (ICML) 2021",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Jonas Rothfuss",
      "Vincent Fortuin",
      "Martin Josifoski",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.05551"
  },
  {
    "id": "arXiv:2003.03369",
    "title": "A Survey on Deep Hashing Methods",
    "abstract": "Comments: 20 pages, 1 figure",
    "descriptor": "\nComments: 20 pages, 1 figure\n",
    "authors": [
      "Xiao Luo",
      "Daqing Wu",
      "Chong Chen",
      "Minghua Deng",
      "Jianqiang Huang",
      "Xian-Sheng Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2003.03369"
  },
  {
    "id": "arXiv:2003.06511",
    "title": "Optimal Change-Point Detection with Training Sequences in the Large and  Moderate Deviations Regimes",
    "abstract": "Comments: 31 pages, 11 figures",
    "descriptor": "\nComments: 31 pages, 11 figures\n",
    "authors": [
      "Haiyun He",
      "Qiaosheng Zhang",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.06511"
  },
  {
    "id": "arXiv:2003.07060",
    "title": "Finding Fair and Efficient Allocations When Valuations Don't Add Up",
    "abstract": "Finding Fair and Efficient Allocations When Valuations Don't Add Up",
    "descriptor": "",
    "authors": [
      "Nawal Benabbou",
      "Mithun Chakraborty",
      "Ayumi Igarashi",
      "Yair Zick"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2003.07060"
  },
  {
    "id": "arXiv:2003.08877",
    "title": "Abstraction, Up-to Techniques and Games for Systems of Fixpoint  Equations",
    "abstract": "Abstraction, Up-to Techniques and Games for Systems of Fixpoint  Equations",
    "descriptor": "",
    "authors": [
      "Paolo Baldan",
      "Barbara K\u00f6nig",
      "Tommaso Padoan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2003.08877"
  },
  {
    "id": "arXiv:2003.12786",
    "title": "Robust Output Regulation: Optimization-Based Synthesis and  Event-Triggered Implementation",
    "abstract": "Robust Output Regulation: Optimization-Based Synthesis and  Event-Triggered Implementation",
    "descriptor": "",
    "authors": [
      "Mohammad Saeed Sarafraz",
      "Anton V. Proskurnikov",
      "Mohammad Saleh Tavazoei",
      "Peyman Mohajerin Esfahani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2003.12786"
  },
  {
    "id": "arXiv:2003.14162",
    "title": "Deep State Space Models for Nonlinear System Identification",
    "abstract": "Deep State Space Models for Nonlinear System Identification",
    "descriptor": "",
    "authors": [
      "Daniel Gedon",
      "Niklas Wahlstr\u00f6m",
      "Thomas B. Sch\u00f6n",
      "Lennart Ljung"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.14162"
  },
  {
    "id": "arXiv:2005.01607",
    "title": "Pseudo-healthy synthesis with pathology disentanglement and adversarial  learning",
    "abstract": "Comments: This paper has been accepted by Medical Image Analysis",
    "descriptor": "\nComments: This paper has been accepted by Medical Image Analysis\n",
    "authors": [
      "Tian Xia",
      "Agisilaos Chartsias",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.01607"
  },
  {
    "id": "arXiv:2005.03180",
    "title": "Model Reduction and Neural Networks for Parametric PDEs",
    "abstract": "Comments: 39 pages, 13 figures",
    "descriptor": "\nComments: 39 pages, 13 figures\n",
    "authors": [
      "Kaushik Bhattacharya",
      "Bamdad Hosseini",
      "Nikola B. Kovachki",
      "Andrew M. Stuart"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.03180"
  },
  {
    "id": "arXiv:2005.07662",
    "title": "Guided interactive image segmentation using machine learning and color  based data set clustering",
    "abstract": "Guided interactive image segmentation using machine learning and color  based data set clustering",
    "descriptor": "",
    "authors": [
      "Adrian Friebel",
      "Tim Johann",
      "Dirk Drasdo",
      "Stefan Hoehme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2005.07662"
  },
  {
    "id": "arXiv:2005.07880",
    "title": "Topology Inference with Multivariate Cumulants: The M\u00f6bius Inference  Algorithm",
    "abstract": "Topology Inference with Multivariate Cumulants: The M\u00f6bius Inference  Algorithm",
    "descriptor": "",
    "authors": [
      "Kevin D. Smith",
      "Saber Jafarpour",
      "Ananthram Swami",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2005.07880"
  },
  {
    "id": "arXiv:2005.09021",
    "title": "The Trimmed Lasso: Sparse Recovery Guarantees and Practical Optimization  by the Generalized Soft-Min Penalty",
    "abstract": "Comments: 49 pages; 7 figures; To appear in SIAM Journal on Mathematics of Data Science (SIMODS)",
    "descriptor": "\nComments: 49 pages; 7 figures; To appear in SIAM Journal on Mathematics of Data Science (SIMODS)\n",
    "authors": [
      "Tal Amir",
      "Ronen Basri",
      "Boaz Nadler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.09021"
  },
  {
    "id": "arXiv:2005.11115",
    "title": "Consistency of Extreme Learning Machines and Regression under  Non-Stationarity and Dependence for ML-Enhanced Moving Objects",
    "abstract": "Consistency of Extreme Learning Machines and Regression under  Non-Stationarity and Dependence for ML-Enhanced Moving Objects",
    "descriptor": "",
    "authors": [
      "Ansgar Steland"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2005.11115"
  },
  {
    "id": "arXiv:2006.02682",
    "title": "Some Theoretical Insights into Wasserstein GANs",
    "abstract": "Some Theoretical Insights into Wasserstein GANs",
    "descriptor": "",
    "authors": [
      "G\u00e9rard Biau",
      "Maxime Sangnier",
      "Ugo Tanielian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.02682"
  },
  {
    "id": "arXiv:2006.06231",
    "title": "Why Mixup Improves the Model Performance",
    "abstract": "Why Mixup Improves the Model Performance",
    "descriptor": "",
    "authors": [
      "Masanari Kimura"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.06231"
  },
  {
    "id": "arXiv:2006.07267",
    "title": "Leakage of Dataset Properties in Multi-Party Machine Learning",
    "abstract": "Comments: Published in USENIX Security Symposium, 2021",
    "descriptor": "\nComments: Published in USENIX Security Symposium, 2021\n",
    "authors": [
      "Wanrong Zhang",
      "Shruti Tople",
      "Olga Ohrimenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07267"
  },
  {
    "id": "arXiv:2006.09447",
    "title": "Local Information Agent Modelling in Partially-Observable Environments",
    "abstract": "Local Information Agent Modelling in Partially-Observable Environments",
    "descriptor": "",
    "authors": [
      "Georgios Papoudakis",
      "Filippos Christianos",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.09447"
  },
  {
    "id": "arXiv:2006.10859",
    "title": "MARS: Masked Automatic Ranks Selection in Tensor Decompositions",
    "abstract": "MARS: Masked Automatic Ranks Selection in Tensor Decompositions",
    "descriptor": "",
    "authors": [
      "Maxim Kodryan",
      "Dmitry Kropotov",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10859"
  },
  {
    "id": "arXiv:2006.15714",
    "title": "Active Finite Reward Automaton Inference and Reinforcement Learning  Using Queries and Counterexamples",
    "abstract": "Active Finite Reward Automaton Inference and Reinforcement Learning  Using Queries and Counterexamples",
    "descriptor": "",
    "authors": [
      "Zhe Xu",
      "Bo Wu",
      "Aditya Ojha",
      "Daniel Neider",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2006.15714"
  },
  {
    "id": "arXiv:2006.16094",
    "title": "Level Set Stereo for Cooperative Grouping with Occlusion",
    "abstract": "Comments: ICIP 2021 Code and data: this https URL",
    "descriptor": "\nComments: ICIP 2021 Code and data: this https URL\n",
    "authors": [
      "Jialiang Wang",
      "Todd Zickler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2006.16094"
  },
  {
    "id": "arXiv:2007.01420",
    "title": "CoPhy-PGNN: Learning Physics-guided Neural Networks with Competing Loss  Functions for Solving Eigenvalue Problems",
    "abstract": "Comments: Submitted to SDM 2021, preprint version",
    "descriptor": "\nComments: Submitted to SDM 2021, preprint version\n",
    "authors": [
      "Mohannad Elhamod",
      "Jie Bu",
      "Christopher Singh",
      "Matthew Redell",
      "Abantika Ghosh",
      "Viktor Podolskiy",
      "Wei-Cheng Lee",
      "Anuj Karpatne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.01420"
  },
  {
    "id": "arXiv:2007.01496",
    "title": "Few-Shot Semantic Segmentation Augmented with Image-Level Weak  Annotations",
    "abstract": "Comments: Accpeted to ICME2021",
    "descriptor": "\nComments: Accpeted to ICME2021\n",
    "authors": [
      "Shuo Lei",
      "Xuchao Zhang",
      "Jianfeng He",
      "Fanglan Chen",
      "Chang-Tien Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2007.01496"
  },
  {
    "id": "arXiv:2007.12489",
    "title": "Algorithms for Persuasion with Limited Communication",
    "abstract": "Algorithms for Persuasion with Limited Communication",
    "descriptor": "",
    "authors": [
      "Ronen Gradwohl",
      "Niklas Hahn",
      "Martin Hoefer",
      "Rann Smorodinsky"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2007.12489"
  },
  {
    "id": "arXiv:2007.12824",
    "title": "Multi-Armed Bandits for Minesweeper: Profiting from  Exploration-Exploitation Synergy",
    "abstract": "Comments: To be published in IEEE Transactions on Games (ISSN 2475-1510 / 2475-1502)",
    "descriptor": "\nComments: To be published in IEEE Transactions on Games (ISSN 2475-1510 / 2475-1502)\n",
    "authors": [
      "Igor Q. Lordeiro",
      "Diego B. Haddad",
      "Douglas O. Cardoso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.12824"
  },
  {
    "id": "arXiv:2008.00549",
    "title": "Edge Computing for Real-Time Near-Crash Detection for Smart  Transportation Applications",
    "abstract": "Edge Computing for Real-Time Near-Crash Detection for Smart  Transportation Applications",
    "descriptor": "",
    "authors": [
      "Ruimin Ke",
      "Zhiyong Cui",
      "Yanlong Chen",
      "Meixin Zhu",
      "Yang",
      "Yinhai Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2008.00549"
  },
  {
    "id": "arXiv:2008.05189",
    "title": "Dispersed Federated Learning: Vision, Taxonomy, and Future Directions",
    "abstract": "Comments: This paper has been accepted for publication in IEEE Wireless Communications",
    "descriptor": "\nComments: This paper has been accepted for publication in IEEE Wireless Communications\n",
    "authors": [
      "Latif U. Khan",
      "Walid Saad",
      "Zhu Han",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2008.05189"
  },
  {
    "id": "arXiv:2008.06368",
    "title": "Error analysis for probabilities of rare events with approximate models",
    "abstract": "Error analysis for probabilities of rare events with approximate models",
    "descriptor": "",
    "authors": [
      "Fabian Wagner",
      "Jonas Latz",
      "Iason Papaioannou",
      "Elisabeth Ullmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2008.06368"
  },
  {
    "id": "arXiv:2008.10351",
    "title": "Model Generalization in Deep Learning Applications for Land Cover  Mapping",
    "abstract": "Comments: 9 pages, 7 figures, 5 tables",
    "descriptor": "\nComments: 9 pages, 7 figures, 5 tables\n",
    "authors": [
      "Lucas Hu",
      "Caleb Robinson",
      "Bistra Dilkina"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.10351"
  },
  {
    "id": "arXiv:2008.10847",
    "title": "Solving Stochastic Compositional Optimization is Nearly as Easy as  Solving Stochastic Optimization",
    "abstract": "Comments: Accepted in IEEE Transactions on Signal Processing. The short version of this paper has been awarded the IEEE ICASSP Best Student Paper Award",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Signal Processing. The short version of this paper has been awarded the IEEE ICASSP Best Student Paper Award\n",
    "authors": [
      "Tianyi Chen",
      "Yuejiao Sun",
      "Wotao Yin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.10847"
  },
  {
    "id": "arXiv:2009.01209",
    "title": "Understanding Peer Review of Software Engineering Papers",
    "abstract": "Comments: published in Empirical Software Engineering Journal. Replication package at this http URL",
    "descriptor": "\nComments: published in Empirical Software Engineering Journal. Replication package at this http URL\n",
    "authors": [
      "Neil A. Ernst",
      "Jeffrey C. Carver",
      "Daniel Mendez",
      "Marco Torchiano"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2009.01209"
  },
  {
    "id": "arXiv:2009.13012",
    "title": "Federated Learning for Internet of Things: Recent Advances, Taxonomy,  and Open Challenges",
    "abstract": "Comments: This paper has been accepted for publication in IEEE Communications Surveys and Tutorials",
    "descriptor": "\nComments: This paper has been accepted for publication in IEEE Communications Surveys and Tutorials\n",
    "authors": [
      "Latif U. Khan",
      "Walid Saad",
      "Zhu Han",
      "Ekram Hossain",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2009.13012"
  },
  {
    "id": "arXiv:2009.14610",
    "title": "Concurrent Neural Network : A model of competition between times series",
    "abstract": "Concurrent Neural Network : A model of competition between times series",
    "descriptor": "",
    "authors": [
      "R\u00e9my Garnier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2009.14610"
  },
  {
    "id": "arXiv:2010.03409",
    "title": "Learning Mesh-Based Simulation with Graph Networks",
    "abstract": "Learning Mesh-Based Simulation with Graph Networks",
    "descriptor": "",
    "authors": [
      "Tobias Pfaff",
      "Meire Fortunato",
      "Alvaro Sanchez-Gonzalez",
      "Peter W. Battaglia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2010.03409"
  },
  {
    "id": "arXiv:2010.05050",
    "title": "Symbolic Parallel Adaptive Importance Sampling for Probabilistic Program  Analysis",
    "abstract": "Comments: Extended pre-print version of ESEC/FSE '21 paper",
    "descriptor": "\nComments: Extended pre-print version of ESEC/FSE '21 paper\n",
    "authors": [
      "Yicheng Luo",
      "Antonio Filieri",
      "Yuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2010.05050"
  },
  {
    "id": "arXiv:2010.07904",
    "title": "Probabilistic Sequential Shrinking: A Best Arm Identification Algorithm  for Stochastic Bandits with Corruptions",
    "abstract": "Comments: 22 pages, 9 figures",
    "descriptor": "\nComments: 22 pages, 9 figures\n",
    "authors": [
      "Zixin Zhong",
      "Wang Chi Cheung",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.07904"
  },
  {
    "id": "arXiv:2010.10783",
    "title": "Self-supervised Graph Learning for Recommendation",
    "abstract": "Comments: 11 pages, 7 figures, 5 tables. Accepted by SIGIR 2021",
    "descriptor": "\nComments: 11 pages, 7 figures, 5 tables. Accepted by SIGIR 2021\n",
    "authors": [
      "Jiancan Wu",
      "Xiang Wang",
      "Fuli Feng",
      "Xiangnan He",
      "Liang Chen",
      "Jianxun Lian",
      "Xing Xie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.10783"
  },
  {
    "id": "arXiv:2010.14110",
    "title": "Full-Duplex Cell-Free mMIMO Systems: Analysis and Decentralized  Optimization",
    "abstract": "Comments: Under review for possible publication to IEEE Transactions in Green Communications and Networking",
    "descriptor": "\nComments: Under review for possible publication to IEEE Transactions in Green Communications and Networking\n",
    "authors": [
      "Soumyadeep Datta",
      "Ekant Sharma",
      "Dheeraj Naidu Amudala",
      "Rohit Budhiraja",
      "Shivendra S. Panwar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.14110"
  },
  {
    "id": "arXiv:2010.15761",
    "title": "A Helmholtz equation solver using unsupervised learning: Application to  transcranial ultrasound",
    "abstract": "Comments: 23 pages, 13 figures",
    "descriptor": "\nComments: 23 pages, 13 figures\n",
    "authors": [
      "Antonio Stanziola",
      "Simon R. Arridge",
      "Ben T. Cox",
      "Bradley E. Treeby"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2010.15761"
  },
  {
    "id": "arXiv:2011.01630",
    "title": "PCEDNet : A Lightweight Neural Network for Fast and Interactive Edge  Detection in 3D Point Clouds",
    "abstract": "PCEDNet : A Lightweight Neural Network for Fast and Interactive Edge  Detection in 3D Point Clouds",
    "descriptor": "",
    "authors": [
      "Chems-Eddine Himeur",
      "Thibault Lejemble",
      "Thomas Pellegrini",
      "Mathias Paulin",
      "Loic Barthe",
      "Nicolas Mellado"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2011.01630"
  },
  {
    "id": "arXiv:2011.02601",
    "title": "Fast, Exact and Scalable Dynamic Ridesharing",
    "abstract": "Comments: Previous version augmented in several ways",
    "descriptor": "\nComments: Previous version augmented in several ways\n",
    "authors": [
      "Valentin Buchhold",
      "Peter Sanders",
      "Dorothea Wagner"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.02601"
  },
  {
    "id": "arXiv:2011.02654",
    "title": "Superconvergent Non-Polynomial Approximations",
    "abstract": "Superconvergent Non-Polynomial Approximations",
    "descriptor": "",
    "authors": [
      "Andrew Christlieb",
      "William Sands",
      "Hyoseon Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.02654"
  },
  {
    "id": "arXiv:2011.03384",
    "title": "Noise2Sim -- Similarity-based Self-Learning for Image Denoising",
    "abstract": "Noise2Sim -- Similarity-based Self-Learning for Image Denoising",
    "descriptor": "",
    "authors": [
      "Chuang Niu",
      "Fenglei Fan",
      "Qing Lyu",
      "Ge Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2011.03384"
  },
  {
    "id": "arXiv:2011.05369",
    "title": "Predicting Water Temperature Dynamics of Unmonitored Lakes with Meta  Transfer Learning",
    "abstract": "Comments: 28 pages, 8 figures, Water Resources Research",
    "descriptor": "\nComments: 28 pages, 8 figures, Water Resources Research\n",
    "authors": [
      "Jared D. Willard",
      "Jordan S. Read",
      "Alison P. Appling",
      "Samantha K. Oliver",
      "Xiaowei Jia",
      "Vipin Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.05369"
  },
  {
    "id": "arXiv:2011.06818",
    "title": "A new iterative method for solving a class of two-by-two block complex  linear systems",
    "abstract": "Comments: 17 Pages, Revised, Submitted",
    "descriptor": "\nComments: 17 Pages, Revised, Submitted\n",
    "authors": [
      "Davod Khojasteh Salkuyeh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.06818"
  },
  {
    "id": "arXiv:2011.08809",
    "title": "Facial Expressions as a Vulnerability in Face Recognition",
    "abstract": "Comments: Proc. of IEEE Int. Conf. on Image Processing (ICIP)",
    "descriptor": "\nComments: Proc. of IEEE Int. Conf. on Image Processing (ICIP)\n",
    "authors": [
      "Alejandro Pe\u00f1a",
      "Ignacio Serna",
      "Aythami Morales",
      "Julian Fierrez",
      "Agata Lapedriza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.08809"
  },
  {
    "id": "arXiv:2011.12696",
    "title": "Bootstrap an end-to-end ASR system by multilingual training, transfer  learning, text-to-text mapping and synthetic audio",
    "abstract": "Bootstrap an end-to-end ASR system by multilingual training, transfer  learning, text-to-text mapping and synthetic audio",
    "descriptor": "",
    "authors": [
      "Manuel Giollo",
      "Deniz Gunceler",
      "Yulan Liu",
      "Daniel Willett"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.12696"
  },
  {
    "id": "arXiv:2011.12728",
    "title": "On limitations of learning algorithms in competitive environments",
    "abstract": "Comments: 8 pages, 1 figure",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Alexander Y Klimenko",
      "Dimitri A Klimenko"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.12728"
  },
  {
    "id": "arXiv:2011.14579",
    "title": "End-to-End 3D Point Cloud Learning for Registration Task Using Virtual  Correspondences",
    "abstract": "Comments: Accepted to IROS 2020",
    "descriptor": "\nComments: Accepted to IROS 2020\n",
    "authors": [
      "Zhijian Qiao",
      "Huanshu Wei",
      "Zhe Liu",
      "Chuanzhe Suo",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.14579"
  },
  {
    "id": "arXiv:2011.14611",
    "title": "SIR: Self-supervised Image Rectification via Seeing the Same Scene from  Multiple Different Lenses",
    "abstract": "SIR: Self-supervised Image Rectification via Seeing the Same Scene from  Multiple Different Lenses",
    "descriptor": "",
    "authors": [
      "Jinlong Fan",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2011.14611"
  },
  {
    "id": "arXiv:2012.01466",
    "title": "Learnability and Positive Equivalence Relations",
    "abstract": "Comments: 31 pages, 0 figures",
    "descriptor": "\nComments: 31 pages, 0 figures\n",
    "authors": [
      "David Belanger",
      "Ziyuan Gao",
      "Sanjay Jain",
      "Wei Li",
      "Frank Stephan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2012.01466"
  },
  {
    "id": "arXiv:2012.09030",
    "title": "CompositeTasking: Understanding Images by Spatial Composition of Tasks",
    "abstract": "CompositeTasking: Understanding Images by Spatial Composition of Tasks",
    "descriptor": "",
    "authors": [
      "Nikola Popovic",
      "Danda Pani Paudel",
      "Thomas Probst",
      "Guolei Sun",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.09030"
  },
  {
    "id": "arXiv:2012.09102",
    "title": "FedADC: Accelerated Federated Learning with Drift Control",
    "abstract": "Comments: Accepted to ISIT 2021",
    "descriptor": "\nComments: Accepted to ISIT 2021\n",
    "authors": [
      "Emre Ozfatura",
      "Kerem Ozfatura",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.09102"
  },
  {
    "id": "arXiv:2012.09403",
    "title": "Minimizing Age of Information via Scheduling over Heterogeneous Channels",
    "abstract": "Minimizing Age of Information via Scheduling over Heterogeneous Channels",
    "descriptor": "",
    "authors": [
      "Jiayu Pan",
      "Ahmed M. Bedewy",
      "Yin Sun",
      "Ness B. Shroff"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.09403"
  },
  {
    "id": "arXiv:2101.00147",
    "title": "Quantitative Evaluation of Hardware Binary Stochastic Neurons",
    "abstract": "Quantitative Evaluation of Hardware Binary Stochastic Neurons",
    "descriptor": "",
    "authors": [
      "Orchi Hassan",
      "Supriyo Datta",
      "Kerem Y. Camsari"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)"
    ],
    "url": "https://arxiv.org/abs/2101.00147"
  },
  {
    "id": "arXiv:2101.01364",
    "title": "Run-Time Monitoring of Machine Learning for Robotic Perception: A Survey  of Emerging Trends",
    "abstract": "Comments: Updated version of 10.1109/ACCESS.2021.3055015. Published at IEEE Access. 27 January 2021",
    "descriptor": "\nComments: Updated version of 10.1109/ACCESS.2021.3055015. Published at IEEE Access. 27 January 2021\n",
    "authors": [
      "Quazi Marufur Rahman",
      "Peter Corke",
      "Feras Dayoub"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.01364"
  },
  {
    "id": "arXiv:2101.02373",
    "title": "Architectural Patterns for the Design of Federated Learning Systems",
    "abstract": "Comments: Resubmitted after minor revision to Elsevier's Journal of Systems and Software, Special issue on Software Architecture and Artificial Intelligence",
    "descriptor": "\nComments: Resubmitted after minor revision to Elsevier's Journal of Systems and Software, Special issue on Software Architecture and Artificial Intelligence\n",
    "authors": [
      "Sin Kit Lo",
      "Qinghua Lu",
      "Liming Zhu",
      "Hye-young Paik",
      "Xiwei Xu",
      "Chen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2101.02373"
  },
  {
    "id": "arXiv:2101.02452",
    "title": "RobustSleepNet: Transfer learning for automated sleep staging at scale",
    "abstract": "RobustSleepNet: Transfer learning for automated sleep staging at scale",
    "descriptor": "",
    "authors": [
      "Antoine Guillot",
      "Valentin Thorey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2101.02452"
  },
  {
    "id": "arXiv:2101.05325",
    "title": "Learning Kinematic Feasibility for Mobile Manipulation through Deep  Reinforcement Learning",
    "abstract": "Comments: Accepted for publication in RA-L. Code and Models: this http URL",
    "descriptor": "\nComments: Accepted for publication in RA-L. Code and Models: this http URL\n",
    "authors": [
      "Daniel Honerkamp",
      "Tim Welschehold",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.05325"
  },
  {
    "id": "arXiv:2101.08482",
    "title": "Exponential Moving Average Normalization for Self-supervised and  Semi-supervised Learning",
    "abstract": "Comments: accepted by CVPR21 as Oral presentation",
    "descriptor": "\nComments: accepted by CVPR21 as Oral presentation\n",
    "authors": [
      "Zhaowei Cai",
      "Avinash Ravichandran",
      "Subhransu Maji",
      "Charless Fowlkes",
      "Zhuowen Tu",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.08482"
  },
  {
    "id": "arXiv:2102.01377",
    "title": "Effective Mori-Zwanzig equation for the reduced-order modeling of  stochastic systems",
    "abstract": "Effective Mori-Zwanzig equation for the reduced-order modeling of  stochastic systems",
    "descriptor": "",
    "authors": [
      "Yuanran Zhu",
      "Huan Lei"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2102.01377"
  },
  {
    "id": "arXiv:2102.01547",
    "title": "WeNet: Production oriented Streaming and Non-streaming End-to-End Speech  Recognition Toolkit",
    "abstract": "Comments: 5 pages, 2 figures, 4 tables",
    "descriptor": "\nComments: 5 pages, 2 figures, 4 tables\n",
    "authors": [
      "Zhuoyuan Yao",
      "Di Wu",
      "Xiong Wang",
      "Binbin Zhang",
      "Fan Yu",
      "Chao Yang",
      "Zhendong Peng",
      "Xiaoyu Chen",
      "Lei Xie",
      "Xin Lei"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2102.01547"
  },
  {
    "id": "arXiv:2102.01886",
    "title": "Learning Diverse-Structured Networks for Adversarial Robustness",
    "abstract": "Comments: ICML2021, code: this https URL",
    "descriptor": "\nComments: ICML2021, code: this https URL\n",
    "authors": [
      "Xuefeng Du",
      "Jingfeng Zhang",
      "Bo Han",
      "Tongliang Liu",
      "Yu Rong",
      "Gang Niu",
      "Junzhou Huang",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.01886"
  },
  {
    "id": "arXiv:2102.04761",
    "title": "Quasi-Global Momentum: Accelerating Decentralized Deep Learning on  Heterogeneous Data",
    "abstract": "Quasi-Global Momentum: Accelerating Decentralized Deep Learning on  Heterogeneous Data",
    "descriptor": "",
    "authors": [
      "Tao Lin",
      "Sai Praneeth Karimireddy",
      "Sebastian U. Stich",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.04761"
  },
  {
    "id": "arXiv:2102.04828",
    "title": "Consensus Control for Decentralized Deep Learning",
    "abstract": "Comments: LK and TL contribute equally - ICML 2021",
    "descriptor": "\nComments: LK and TL contribute equally - ICML 2021\n",
    "authors": [
      "Lingjing Kong",
      "Tao Lin",
      "Anastasia Koloskova",
      "Martin Jaggi",
      "Sebastian U. Stich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.04828"
  },
  {
    "id": "arXiv:2102.04960",
    "title": "Radar-to-Lidar: Heterogeneous Place Recognition via Joint Learning",
    "abstract": "Comments: Published by Frontiers in Robotics and AI. The published version is available at this https URL . The source code is available at this https URL",
    "descriptor": "\nComments: Published by Frontiers in Robotics and AI. The published version is available at this https URL . The source code is available at this https URL\n",
    "authors": [
      "Huan Yin",
      "Xuecheng Xu",
      "Yue Wang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.04960"
  },
  {
    "id": "arXiv:2102.06780",
    "title": "Newton Method over Networks is Fast up to the Statistical Precision",
    "abstract": "Comments: In proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021",
    "descriptor": "\nComments: In proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021\n",
    "authors": [
      "Amir Daneshmand",
      "Gesualdo Scutari",
      "Pavel Dvurechensky",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.06780"
  },
  {
    "id": "arXiv:2102.07030",
    "title": "Diffusion Approximations for a Class of Sequential Testing Problems",
    "abstract": "Diffusion Approximations for a Class of Sequential Testing Problems",
    "descriptor": "",
    "authors": [
      "Victor F. Araman",
      "Rene Caldentey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07030"
  },
  {
    "id": "arXiv:2102.07214",
    "title": "Communication-Efficient Distributed Optimization with Quantized  Preconditioners",
    "abstract": "Communication-Efficient Distributed Optimization with Quantized  Preconditioners",
    "descriptor": "",
    "authors": [
      "Foivos Alimisis",
      "Peter Davies",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.07214"
  },
  {
    "id": "arXiv:2102.07927",
    "title": "Structured Dropout Variational Inference for Bayesian Neural Networks",
    "abstract": "Comments: 39 pages, 8 figures",
    "descriptor": "\nComments: 39 pages, 8 figures\n",
    "authors": [
      "Son Nguyen",
      "Duong Nguyen",
      "Khai Nguyen",
      "Nhat Ho",
      "Khoat Than",
      "Hung Bui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.07927"
  },
  {
    "id": "arXiv:2102.08341",
    "title": "Faster Kernel Matrix Algebra via Density Estimation",
    "abstract": "Faster Kernel Matrix Algebra via Density Estimation",
    "descriptor": "",
    "authors": [
      "Arturs Backurs",
      "Piotr Indyk",
      "Cameron Musco",
      "Tal Wagner"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.08341"
  },
  {
    "id": "arXiv:2102.09225",
    "title": "Continuous Doubly Constrained Batch Reinforcement Learning",
    "abstract": "Continuous Doubly Constrained Batch Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Rasool Fakoor",
      "Jonas Mueller",
      "Kavosh Asadi",
      "Pratik Chaudhari",
      "Alexander J. Smola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09225"
  },
  {
    "id": "arXiv:2102.10558",
    "title": "Inconsistency thresholds for incomplete pairwise comparison matrices",
    "abstract": "Comments: 13 pages, 2 figures, 4 tables",
    "descriptor": "\nComments: 13 pages, 2 figures, 4 tables\n",
    "authors": [
      "Kolos Csaba \u00c1goston",
      "L\u00e1szl\u00f3 Csat\u00f3"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2102.10558"
  },
  {
    "id": "arXiv:2102.11218",
    "title": "Neural Pharmacodynamic State Space Modeling",
    "abstract": "Comments: To appear at the International Conference on Machine Learning (ICML) 2021",
    "descriptor": "\nComments: To appear at the International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Zeshan Hussain",
      "Rahul G. Krishnan",
      "David Sontag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.11218"
  },
  {
    "id": "arXiv:2102.11784",
    "title": "Ray-based framework for state identification in quantum dot devices",
    "abstract": "Comments: 9 pages, 4 figures",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Justyna P. Zwolak",
      "Thomas McJunkin",
      "Sandesh S. Kalantre",
      "Samuel F. Neyens",
      "E. R. MacQuarrie",
      "Mark A. Eriksson",
      "Jacob M. Taylor"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.11784"
  },
  {
    "id": "arXiv:2103.01059",
    "title": "Comparing acoustic analyses of speech data collected remotely",
    "abstract": "Comparing acoustic analyses of speech data collected remotely",
    "descriptor": "",
    "authors": [
      "Cong Zhang",
      "Kathleen Jepson",
      "Georg Lohfink",
      "Amalia Arvaniti"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2103.01059"
  },
  {
    "id": "arXiv:2103.01287",
    "title": "DEUS: A Data-driven Approach to Estimate User Satisfaction in Multi-turn  Dialogues",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Ziming Li",
      "Dookun Park",
      "Julia Kiseleva",
      "Young-Bum Kim",
      "Sungjin Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.01287"
  },
  {
    "id": "arXiv:2103.03840",
    "title": "Self-Supervised Longitudinal Neighbourhood Embedding",
    "abstract": "Comments: Provisional Accepted by Medical Image Computing and Computer Assisted Intervention (MICCAI) 2021",
    "descriptor": "\nComments: Provisional Accepted by Medical Image Computing and Computer Assisted Intervention (MICCAI) 2021\n",
    "authors": [
      "Jiahong Ouyang",
      "Qingyu Zhao",
      "Ehsan Adeli",
      "Edith V Sullivan",
      "Adolf Pfefferbaum",
      "Greg Zaharchuk",
      "Kilian M Pohl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03840"
  },
  {
    "id": "arXiv:2103.04717",
    "title": "Multi-Source Domain Adaptation with Collaborative Learning for Semantic  Segmentation",
    "abstract": "Comments: CVPR2021",
    "descriptor": "\nComments: CVPR2021\n",
    "authors": [
      "Jianzhong He",
      "Xu Jia",
      "Shuaijun Chen",
      "Jianzhuang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.04717"
  },
  {
    "id": "arXiv:2103.06759",
    "title": "Automatic Social Distance Estimation From Images: Performance  Evaluation, Test Benchmark, and Algorithm",
    "abstract": "Comments: 14 pages, 12 figures, 6 tables",
    "descriptor": "\nComments: 14 pages, 12 figures, 6 tables\n",
    "authors": [
      "Mert Seker",
      "Anssi M\u00e4nnist\u00f6",
      "Alexandros Iosifidis",
      "Jenni Raitoharju"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06759"
  },
  {
    "id": "arXiv:2103.07825",
    "title": "Radar Camera Fusion via Representation Learning in Autonomous Driving",
    "abstract": "Radar Camera Fusion via Representation Learning in Autonomous Driving",
    "descriptor": "",
    "authors": [
      "Xu Dong",
      "Binnan Zhuang",
      "Yunxiang Mao",
      "Langechuan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.07825"
  },
  {
    "id": "arXiv:2103.08145",
    "title": "Exergy-based analysis for hybrid and electric ground vehicles",
    "abstract": "Exergy-based analysis for hybrid and electric ground vehicles",
    "descriptor": "",
    "authors": [
      "Federico Dett\u00f9",
      "Gabriele Pozzato",
      "Denise M. Rizzo",
      "Simona Onori"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.08145"
  },
  {
    "id": "arXiv:2103.08987",
    "title": "SoK: Privacy-Preserving Collaborative Tree-based Model Learning",
    "abstract": "SoK: Privacy-Preserving Collaborative Tree-based Model Learning",
    "descriptor": "",
    "authors": [
      "Sylvain Chatel",
      "Apostolos Pyrgelis",
      "Juan Ramon Troncoso-Pastoriza",
      "Jean-Pierre Hubaux"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.08987"
  },
  {
    "id": "arXiv:2103.09097",
    "title": "Consistent Posterior Distributions under Vessel-Mixing: A Regularization  for Cross-Domain Retinal Artery/Vein Classification",
    "abstract": "Comments: Accepted to ICIP2021",
    "descriptor": "\nComments: Accepted to ICIP2021\n",
    "authors": [
      "Chenxin Li",
      "Yunlong Zhang",
      "Zhehan Liang",
      "Wenao Ma",
      "Yue Huang",
      "Xinghao Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.09097"
  },
  {
    "id": "arXiv:2103.12906",
    "title": "CSFCube -- A Test Collection of Computer Science Research Articles for  Faceted Query by Example",
    "abstract": "Comments: Submitted for single-blind review at the CIKM 2021 Resource Track",
    "descriptor": "\nComments: Submitted for single-blind review at the CIKM 2021 Resource Track\n",
    "authors": [
      "Sheshera Mysore",
      "Tim O'Gorman",
      "Andrew McCallum",
      "Hamed Zamani"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.12906"
  },
  {
    "id": "arXiv:2103.13748",
    "title": "Compressed Gradient Tracking Methods for Decentralized Optimization with  Linear Convergence",
    "abstract": "Compressed Gradient Tracking Methods for Decentralized Optimization with  Linear Convergence",
    "descriptor": "",
    "authors": [
      "Yiwei Liao",
      "Zhuorui Li",
      "Kun Huang",
      "Shi Pu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2103.13748"
  },
  {
    "id": "arXiv:2104.00816",
    "title": "Partition-Guided GANs",
    "abstract": "Comments: Accepted for publication at CVPR 2021",
    "descriptor": "\nComments: Accepted for publication at CVPR 2021\n",
    "authors": [
      "Mohammadreza Armandpour",
      "Ali Sadeghian",
      "Chunyuan Li",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.00816"
  },
  {
    "id": "arXiv:2104.02532",
    "title": "End-To-End Bias Mitigation: Removing Gender Bias in Deep Learning",
    "abstract": "Comments: 9 pages, 1 figure",
    "descriptor": "\nComments: 9 pages, 1 figure\n",
    "authors": [
      "Tal Feldman",
      "Ashley Peake"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2104.02532"
  },
  {
    "id": "arXiv:2104.03603",
    "title": "AISHELL-4: An Open Source Dataset for Speech Enhancement, Separation,  Recognition and Speaker Diarization in Conference Scenario",
    "abstract": "Comments: Accepted by Interspeech 2021",
    "descriptor": "\nComments: Accepted by Interspeech 2021\n",
    "authors": [
      "Yihui Fu",
      "Luyao Cheng",
      "Shubo Lv",
      "Yukai Jv",
      "Yuxiang Kong",
      "Zhuo Chen",
      "Yanxin Hu",
      "Lei Xie",
      "Jian Wu",
      "Hui Bu",
      "Xin Xu",
      "Jun Du",
      "Jingdong Chen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.03603"
  },
  {
    "id": "arXiv:2104.08189",
    "title": "TalkNet 2: Non-Autoregressive Depth-Wise Separable Convolutional Model  for Speech Synthesis with Explicit Pitch and Duration Prediction",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2005.05514",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2005.05514\n",
    "authors": [
      "Stanislav Beliaev",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.08189"
  },
  {
    "id": "arXiv:2104.09791",
    "title": "B-PROP: Bootstrapped Pre-training with Representative Words Prediction  for Ad-hoc Retrieval",
    "abstract": "Comments: Accepted by SIGIR 2021. arXiv admin note: text overlap with arXiv:2010.10137",
    "descriptor": "\nComments: Accepted by SIGIR 2021. arXiv admin note: text overlap with arXiv:2010.10137\n",
    "authors": [
      "Xinyu Ma",
      "Jiafeng Guo",
      "Ruqing Zhang",
      "Yixing Fan",
      "Yingyan Li",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2104.09791"
  },
  {
    "id": "arXiv:2104.10339",
    "title": "Discriminative Self-training for Punctuation Prediction",
    "abstract": "Comments: Accepted by INTERSPEECH 2021",
    "descriptor": "\nComments: Accepted by INTERSPEECH 2021\n",
    "authors": [
      "Qian Chen",
      "Wen Wang",
      "Mengzhe Chen",
      "Qinglin Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.10339"
  },
  {
    "id": "arXiv:2104.10357",
    "title": "Pre-training for Spoken Language Understanding with Joint Textual and  Phonetic Representation Learning",
    "abstract": "Comments: Accepted by INTERSPEECH 2021",
    "descriptor": "\nComments: Accepted by INTERSPEECH 2021\n",
    "authors": [
      "Qian Chen",
      "Wen Wang",
      "Qinglin Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.10357"
  },
  {
    "id": "arXiv:2104.10380",
    "title": "End-to-end Speech Translation via Cross-modal Progressive Training",
    "abstract": "Comments: Accepted at InterSpeech2021",
    "descriptor": "\nComments: Accepted at InterSpeech2021\n",
    "authors": [
      "Rong Ye",
      "Mingxuan Wang",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.10380"
  },
  {
    "id": "arXiv:2104.12825",
    "title": "Conforming Finite Elements for $H(\\text{sym}\\,\\text{Curl})$ and  $H(\\text{dev}\\,\\text{sym}\\,\\text{Curl})$",
    "abstract": "Comments: Fixed update of the previous version",
    "descriptor": "\nComments: Fixed update of the previous version\n",
    "authors": [
      "Oliver Sander"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.12825"
  },
  {
    "id": "arXiv:2104.15038",
    "title": "Envisioning security control in renewable dominated power systems  through stochastic multi-period AC security constrained optimal power flow",
    "abstract": "Envisioning security control in renewable dominated power systems  through stochastic multi-period AC security constrained optimal power flow",
    "descriptor": "",
    "authors": [
      "Mohammad Iman Alizadeh",
      "Muhammad Usman",
      "Florin Capitanescu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.15038"
  },
  {
    "id": "arXiv:2105.01774",
    "title": "Envisioning Communities: A Participatory Approach Towards AI for Social  Good",
    "abstract": "Comments: Bondi and Xu Equal contribution. 12 pages, 5 figures. Accepted at the Fourth AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES-21)",
    "descriptor": "\nComments: Bondi and Xu Equal contribution. 12 pages, 5 figures. Accepted at the Fourth AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES-21)\n",
    "authors": [
      "Elizabeth Bondi",
      "Lily Xu",
      "Diana Acosta-Navas",
      "Jackson A. Killian"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.01774"
  },
  {
    "id": "arXiv:2105.03814",
    "title": "Benchmarking a New Paradigm: An Experimental Analysis of a Real  Processing-in-Memory Architecture",
    "abstract": "Comments: Our open source software is available at this https URL",
    "descriptor": "\nComments: Our open source software is available at this https URL\n",
    "authors": [
      "Juan G\u00f3mez-Luna",
      "Izzat El Hajj",
      "Ivan Fernandez",
      "Christina Giannoula",
      "Geraldo F. Oliveira",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.03814"
  },
  {
    "id": "arXiv:2105.05496",
    "title": "A Consensual Collaborative Learning Method for Remote Sensing Image  Classification Under Noisy Multi-Labels",
    "abstract": "Comments: Accepted in ICIP 2021. Our code is available at this https URL",
    "descriptor": "\nComments: Accepted in ICIP 2021. Our code is available at this https URL\n",
    "authors": [
      "Ahmet Kerem Aksoy",
      "Mahdyar Ravanbakhsh",
      "Tristan Kreuziger",
      "Begum Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.05496"
  },
  {
    "id": "arXiv:2105.07729",
    "title": "Data Assimilation Predictive GAN (DA-PredGAN): applied to determine the  spread of COVID-19",
    "abstract": "Data Assimilation Predictive GAN (DA-PredGAN): applied to determine the  spread of COVID-19",
    "descriptor": "",
    "authors": [
      "Vinicius L. S. Silva",
      "Claire E. Heaney",
      "Yaqi Li",
      "Christopher C. Pain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.07729"
  },
  {
    "id": "arXiv:2105.09624",
    "title": "Semantic segmentation of multispectral photoacoustic images using deep  learning",
    "abstract": "Comments: 8 pages, 7 figures, 3 tables",
    "descriptor": "\nComments: 8 pages, 7 figures, 3 tables\n",
    "authors": [
      "Janek Gr\u00f6hl",
      "Melanie Schellenberg",
      "Kris Dreher",
      "Niklas Holzwarth",
      "Minu D. Tizabi",
      "Alexander Seitel",
      "Lena Maier-Hein"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.09624"
  },
  {
    "id": "arXiv:2105.10013",
    "title": "Opening Deep Neural Networks with Generative Models",
    "abstract": "Opening Deep Neural Networks with Generative Models",
    "descriptor": "",
    "authors": [
      "Marcos Vendramini",
      "Hugo Oliveira",
      "Alexei Machado",
      "Jefersson A. dos Santos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10013"
  },
  {
    "id": "arXiv:2105.10969",
    "title": "Every Steiner triple system contains an almost spanning d-ary hypertree",
    "abstract": "Comments: 18 pages, 1 figure",
    "descriptor": "\nComments: 18 pages, 1 figure\n",
    "authors": [
      "Andrii Arman",
      "Vojt\u011bch R\u00f6dl",
      "Marcelo Tadeu Sales"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.10969"
  },
  {
    "id": "arXiv:2105.11292",
    "title": "A Polynomial-time, Truthful, Individually Rational and Budget Balanced  Ridesharing Mechanism",
    "abstract": "A Polynomial-time, Truthful, Individually Rational and Budget Balanced  Ridesharing Mechanism",
    "descriptor": "",
    "authors": [
      "Tatsuya Iwase",
      "Sebastian Stein",
      "Enrico H. Gerding"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2105.11292"
  },
  {
    "id": "arXiv:2105.12866",
    "title": "Augmented KRnet for density estimation and approximation",
    "abstract": "Augmented KRnet for density estimation and approximation",
    "descriptor": "",
    "authors": [
      "Xiaoliang Wan",
      "Kejun Tang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.12866"
  },
  {
    "id": "arXiv:2105.12964",
    "title": "Feature Reuse and Fusion for Real-time Semantic segmentation",
    "abstract": "Feature Reuse and Fusion for Real-time Semantic segmentation",
    "descriptor": "",
    "authors": [
      "Tan Sixiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.12964"
  },
  {
    "id": "arXiv:2105.13287",
    "title": "Differentially Private Densest Subgraph Detection",
    "abstract": "Comments: Accepted by ICML 2021",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Dung Nguyen",
      "Anil Vullikanti"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.13287"
  },
  {
    "id": "arXiv:2105.13396",
    "title": "Comparing Models for Extracting the Backbone of Bipartite Projections",
    "abstract": "Comparing Models for Extracting the Backbone of Bipartite Projections",
    "descriptor": "",
    "authors": [
      "Zachary P. Neal",
      "Rachel Domagalski",
      "Bruce Sagan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.13396"
  },
  {
    "id": "arXiv:2105.13727",
    "title": "Slow Momentum with Fast Reversion: A Trading Strategy Using Deep  Learning and Changepoint Detection",
    "abstract": "Comments: minor corrections, strategy comparison for 2015-2020 made more robust by repeated trials",
    "descriptor": "\nComments: minor corrections, strategy comparison for 2015-2020 made more robust by repeated trials\n",
    "authors": [
      "Kieran Wood",
      "Stephen Roberts",
      "Stefan Zohren"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2105.13727"
  },
  {
    "id": "arXiv:2105.13859",
    "title": "GAN for time series prediction, data assimilation and uncertainty  quantification",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2105.07729",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.07729\n",
    "authors": [
      "Vinicius L. S. Silva",
      "Claire E. Heaney",
      "Christopher C. Pain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13859"
  },
  {
    "id": "arXiv:2105.14417",
    "title": "Overparameterization of deep ResNet: zero loss and mean-field analysis",
    "abstract": "Overparameterization of deep ResNet: zero loss and mean-field analysis",
    "descriptor": "",
    "authors": [
      "Zhiyan Ding",
      "Shi Chen",
      "Qin Li",
      "Stephen Wright"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14417"
  },
  {
    "id": "arXiv:2105.15069",
    "title": "Max-Margin is Dead, Long Live Max-Margin!",
    "abstract": "Max-Margin is Dead, Long Live Max-Margin!",
    "descriptor": "",
    "authors": [
      "Alex Nowak-Vila",
      "Alessandro Rudi",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.15069"
  },
  {
    "id": "arXiv:2106.00075",
    "title": "Variational Combinatorial Sequential Monte Carlo Methods for Bayesian  Phylogenetic Inference",
    "abstract": "Comments: 15 pages, 9 figures",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Antonio Khalil Moretti",
      "Liyi Zhang",
      "Christian A. Naesseth",
      "Hadiah Venner",
      "David Blei",
      "Itsik Pe'er"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.00075"
  },
  {
    "id": "arXiv:2106.00198",
    "title": "Gradient Play in Multi-Agent Markov Stochastic Games: Stationary Points  and Convergence",
    "abstract": "Gradient Play in Multi-Agent Markov Stochastic Games: Stationary Points  and Convergence",
    "descriptor": "",
    "authors": [
      "Runyu Zhang",
      "Zhaolin Ren",
      "Na Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00198"
  },
  {
    "id": "arXiv:2106.00655",
    "title": "The Impact of Network Connectivity on Collective Learning",
    "abstract": "Comments: 13 pages, 5 figures. To appear at the 15th International Symposium on Distributed Autonomous Robotic Systems 2021. Presented at the joint DARS-SWARM 2021 symposium held (virtually) in Kyoto, Japan",
    "descriptor": "\nComments: 13 pages, 5 figures. To appear at the 15th International Symposium on Distributed Autonomous Robotic Systems 2021. Presented at the joint DARS-SWARM 2021 symposium held (virtually) in Kyoto, Japan\n",
    "authors": [
      "Michael Crosscombe",
      "Jonathan Lawry"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00655"
  },
  {
    "id": "arXiv:2106.01939",
    "title": "Graph Intervention Networks for Causal Effect Estimation",
    "abstract": "Graph Intervention Networks for Causal Effect Estimation",
    "descriptor": "",
    "authors": [
      "Jean Kaddour",
      "Qi Liu",
      "Yuchen Zhu",
      "Matt J. Kusner",
      "Ricardo Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01939"
  },
  {
    "id": "arXiv:2106.02225",
    "title": "Materials Representation and Transfer Learning for Multi-Property  Prediction",
    "abstract": "Comments: This is accepted at the Applied Physics Reviews journal",
    "descriptor": "\nComments: This is accepted at the Applied Physics Reviews journal\n",
    "authors": [
      "Shufeng Kong",
      "Dan Guevarra",
      "Carla P. Gomes",
      "John M. Gregoire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02225"
  },
  {
    "id": "arXiv:2106.02242",
    "title": "Scalable Transformers for Neural Machine Translation",
    "abstract": "Comments: Mostly overlapping with version 1, with minor updates/revisions",
    "descriptor": "\nComments: Mostly overlapping with version 1, with minor updates/revisions\n",
    "authors": [
      "Peng Gao",
      "Shijie Geng",
      "Yu Qiao",
      "Xiaogang Wang",
      "Jifeng Dai",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02242"
  },
  {
    "id": "arXiv:2106.02473",
    "title": "A New Gastric Histopathology Subsize Image Database (GasHisSDB) for  Classification Algorithm Test: from Linear Regression to Visual Transformer",
    "abstract": "A New Gastric Histopathology Subsize Image Database (GasHisSDB) for  Classification Algorithm Test: from Linear Regression to Visual Transformer",
    "descriptor": "",
    "authors": [
      "Weiming Hu",
      "Chen Li",
      "Xiaoyan Li",
      "Md Mamunur Rahaman",
      "Jiquan Ma",
      "Haoyuan Chen",
      "Wanli Liu",
      "Changhao Sun",
      "Yudong Yao",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02473"
  },
  {
    "id": "arXiv:2106.03135",
    "title": "Go with the Flows: Mixtures of Normalizing Flows for Point Cloud  Generation and Reconstruction",
    "abstract": "Go with the Flows: Mixtures of Normalizing Flows for Point Cloud  Generation and Reconstruction",
    "descriptor": "",
    "authors": [
      "Janis Postels",
      "Mengya Liu",
      "Riccardo Spezialetti",
      "Luc Van Gool",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03135"
  },
  {
    "id": "arXiv:2106.03194",
    "title": "Robust Implicit Networks via Non-Euclidean Contractions",
    "abstract": "Robust Implicit Networks via Non-Euclidean Contractions",
    "descriptor": "",
    "authors": [
      "Saber Jafarpour",
      "Alexander Davydov",
      "Anton V. Proskurnikov",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03194"
  },
  {
    "id": "arXiv:2106.03458",
    "title": "A Grounded Theory of the Role of Coordination in Software Security Patch  Management",
    "abstract": "Comments: Accepted for publication at the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE '21)",
    "descriptor": "\nComments: Accepted for publication at the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE '21)\n",
    "authors": [
      "Nesara Dissanayake",
      "Mansooreh Zahedi",
      "Asangi Jayatilaka",
      "Muhammad Ali Babar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.03458"
  },
  {
    "id": "arXiv:2106.04254",
    "title": "Coresets for Classification -- Simplified and Strengthened",
    "abstract": "Coresets for Classification -- Simplified and Strengthened",
    "descriptor": "",
    "authors": [
      "Tung Mai",
      "Anup B. Rao",
      "Cameron Musco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.04254"
  },
  {
    "id": "arXiv:2106.04675",
    "title": "Streetonomics: Quantifying Culture Using Street Names",
    "abstract": "Comments: 17 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 17 pages, 6 figures, 2 tables\n",
    "authors": [
      "Melanie Bancilhon",
      "Marios Constantinides",
      "Edyta Paulina Bogucka",
      "Luca Maria Aiello",
      "Daniele Quercia"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.04675"
  },
  {
    "id": "arXiv:2106.04778",
    "title": "SHARP: Shape-Aware Reconstruction of People In Loose Clothing",
    "abstract": "SHARP: Shape-Aware Reconstruction of People In Loose Clothing",
    "descriptor": "",
    "authors": [
      "Sai Sagar Jinka",
      "Rohan Chacko",
      "Astitva Srivastava",
      "Avinash Sharma",
      "P.J. Narayanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04778"
  },
  {
    "id": "arXiv:2106.05187",
    "title": "Geometry-Consistent Neural Shape Representation with Implicit  Displacement Fields",
    "abstract": "Comments: includes supplementary; ver2 corrected typos in eq(1)",
    "descriptor": "\nComments: includes supplementary; ver2 corrected typos in eq(1)\n",
    "authors": [
      "Wang Yifan",
      "Lukas Rahmann",
      "Olga Sorkine-Hornung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05187"
  },
  {
    "id": "arXiv:2106.05522",
    "title": "A Mathematical Foundation for Robust Machine Learning based on  Bias-Variance Trade-off",
    "abstract": "A Mathematical Foundation for Robust Machine Learning based on  Bias-Variance Trade-off",
    "descriptor": "",
    "authors": [
      "Ou Wu",
      "Weiyao Zhu",
      "Yingjun Deng",
      "Haixiang Zhang",
      "Qinghu Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05522"
  },
  {
    "id": "arXiv:2106.06054",
    "title": "Fair Preprocessing: Towards Understanding Compositional Fairness of Data  Transformers in Machine Learning Pipeline",
    "abstract": "Comments: ESEC/FSE'2021: The 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, Athens, Greece, August 23-28, 2021",
    "descriptor": "\nComments: ESEC/FSE'2021: The 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, Athens, Greece, August 23-28, 2021\n",
    "authors": [
      "Sumon Biswas",
      "Hridesh Rajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06054"
  },
  {
    "id": "arXiv:2106.06300",
    "title": "DG-LMC: A Turn-key and Scalable Synchronous Distributed MCMC Algorithm  via Langevin Monte Carlo within Gibbs",
    "abstract": "Comments: 77 pages. Accepted for publication at ICML 2021, to appear",
    "descriptor": "\nComments: 77 pages. Accepted for publication at ICML 2021, to appear\n",
    "authors": [
      "Vincent Plassier",
      "Maxime Vono",
      "Alain Durmus",
      "Eric Moulines"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.06300"
  },
  {
    "id": "arXiv:2106.06822",
    "title": "A Pseudo Label-wise Attention Network for Automatic ICD Coding",
    "abstract": "A Pseudo Label-wise Attention Network for Automatic ICD Coding",
    "descriptor": "",
    "authors": [
      "Yifan Wu",
      "Min Zeng",
      "Ying Yu",
      "Min Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06822"
  },
  {
    "id": "arXiv:2106.06848",
    "title": "Guaranteed Fixed-Confidence Best Arm Identification in Multi-Armed  Bandits: Simple Sequential Elimination Algorithms",
    "abstract": "Guaranteed Fixed-Confidence Best Arm Identification in Multi-Armed  Bandits: Simple Sequential Elimination Algorithms",
    "descriptor": "",
    "authors": [
      "MohammadJavad Azizi",
      "Sheldon M Ross",
      "Zhengyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06848"
  },
  {
    "id": "arXiv:2106.07371",
    "title": "A2MM: Mitigating Frontrunning, Transaction Reordering and Consensus  Instability in Decentralized Exchanges",
    "abstract": "A2MM: Mitigating Frontrunning, Transaction Reordering and Consensus  Instability in Decentralized Exchanges",
    "descriptor": "",
    "authors": [
      "Liyi Zhou",
      "Kaihua Qin",
      "Arthur Gervais"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.07371"
  },
  {
    "id": "arXiv:2106.07468",
    "title": "On the stability of conservative discontinuous Galerkin/Hermite spectral  methods for the Vlasov-Poisson system",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2004.02685",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2004.02685\n",
    "authors": [
      "Marianne Bessemoulin-Chatard",
      "Francis Filbet"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07468"
  },
  {
    "id": "arXiv:2106.07505",
    "title": "Modeling Profanity and Hate Speech in Social Media with Semantic  Subspaces",
    "abstract": "Comments: 9 pages, 4 figures, accepted as a long paper at Workshop on Online Abuse and Harms 2021",
    "descriptor": "\nComments: 9 pages, 4 figures, accepted as a long paper at Workshop on Online Abuse and Harms 2021\n",
    "authors": [
      "Vanessa Hahn",
      "Dana Ruiter",
      "Thomas Kleinbauer",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07505"
  },
  {
    "id": "arXiv:2106.07617",
    "title": "Delving Deep into the Generalization of Vision Transformers under  Distribution Shifts",
    "abstract": "Comments: Our code is available at this https URL",
    "descriptor": "\nComments: Our code is available at this https URL\n",
    "authors": [
      "Chongzhi Zhang",
      "Mingyuan Zhang",
      "Shanghang Zhang",
      "Daisheng Jin",
      "Qiang Zhou",
      "Zhongang Cai",
      "Haiyu Zhao",
      "Shuai Yi",
      "Xianglong Liu",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07617"
  },
  {
    "id": "arXiv:2106.07704",
    "title": "Text Generation with Efficient (Soft) Q-Learning",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Han Guo",
      "Bowen Tan",
      "Zhengzhong Liu",
      "Eric P. Xing",
      "Zhiting Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07704"
  },
  {
    "id": "arXiv:2106.07822",
    "title": "Canonical Face Embeddings",
    "abstract": "Comments: 10 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 10 pages, 6 figures, 2 tables\n",
    "authors": [
      "David McNeely-White",
      "Ben Sattelberg",
      "Nathaniel Blanchard",
      "Ross Beveridge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07822"
  },
  {
    "id": "arXiv:2106.07864",
    "title": "User-specific Adaptive Fine-tuning for Cross-domain Recommendations",
    "abstract": "User-specific Adaptive Fine-tuning for Cross-domain Recommendations",
    "descriptor": "",
    "authors": [
      "Lei Chen",
      "Fajie Yuan",
      "Jiaxi Yang",
      "Xiangnan He",
      "Chengming Li",
      "Min Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.07864"
  },
  {
    "id": "arXiv:2106.08429",
    "title": "Optimal control of a 2D diffusion-advection process with a team of  mobile actuators under jointly optimal guidance",
    "abstract": "Comments: Proofs for Lemmas~2.3, 2.5, and D.1 are attached in the supplement at the end",
    "descriptor": "\nComments: Proofs for Lemmas~2.3, 2.5, and D.1 are attached in the supplement at the end\n",
    "authors": [
      "Sheng Cheng",
      "Derek A. Paley"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08429"
  },
  {
    "id": "arXiv:2106.08493",
    "title": "Multi-scale Neural ODEs for 3D Medical Image Registration",
    "abstract": "Multi-scale Neural ODEs for 3D Medical Image Registration",
    "descriptor": "",
    "authors": [
      "Junshen Xu",
      "Eric Z. Chen",
      "Xiao Chen",
      "Terrence Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08493"
  },
  {
    "id": "arXiv:2106.08613",
    "title": "FastAno: Fast Anomaly Detection via Spatio-temporal Patch Transformation",
    "abstract": "Comments: 10 pages, 2022WACV under review",
    "descriptor": "\nComments: 10 pages, 2022WACV under review\n",
    "authors": [
      "Chaewon Park",
      "MyeongAh Cho",
      "Minhyeok Lee",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08613"
  },
  {
    "id": "arXiv:2106.08640",
    "title": "Counterfactual Graphs for Explainable Classification of Brain Networks",
    "abstract": "Comments: In proceedings of KDD 2021",
    "descriptor": "\nComments: In proceedings of KDD 2021\n",
    "authors": [
      "Carlo Abrate",
      "Francesco Bonchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08640"
  },
  {
    "id": "arXiv:2106.08834",
    "title": "A Low Rank Tensor Representation of Linear Transport and Nonlinear  Vlasov Solutions and Their Associated Flow Maps",
    "abstract": "A Low Rank Tensor Representation of Linear Transport and Nonlinear  Vlasov Solutions and Their Associated Flow Maps",
    "descriptor": "",
    "authors": [
      "Wei Guo",
      "Jing-Mei Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08834"
  },
  {
    "id": "arXiv:2106.09076",
    "title": "Deformation Driven Seq2Seq Longitudinal Tumor and Organs-at-Risk  Prediction for Radiotherapy",
    "abstract": "Comments: Medical Physics 2021, Saad Nadeem and Yu-Chi Hu contributed equally",
    "descriptor": "\nComments: Medical Physics 2021, Saad Nadeem and Yu-Chi Hu contributed equally\n",
    "authors": [
      "Donghoon Lee",
      "Sadegh R Alam",
      "Jue Jiang",
      "Pengpeng Zhang",
      "Saad Nadeem",
      "Yu-Chi Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09076"
  },
  {
    "id": "arXiv:2106.09109",
    "title": "QuantumFed: A Federated Learning Framework for Collaborative Quantum  Training",
    "abstract": "QuantumFed: A Federated Learning Framework for Collaborative Quantum  Training",
    "descriptor": "",
    "authors": [
      "Qi Xia",
      "Qun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.09109"
  },
  {
    "id": "arXiv:2106.09119",
    "title": "Behavioral Priors and Dynamics Models: Improving Performance and Domain  Transfer in Offline RL",
    "abstract": "Behavioral Priors and Dynamics Models: Improving Performance and Domain  Transfer in Offline RL",
    "descriptor": "",
    "authors": [
      "Catherine Cang",
      "Aravind Rajeswaran",
      "Pieter Abbeel",
      "Michael Laskin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09119"
  },
  {
    "id": "arXiv:2106.09157",
    "title": "Positional Contrastive Learning for Volumetric Medical Image  Segmentation",
    "abstract": "Comments: 8 pages, conference",
    "descriptor": "\nComments: 8 pages, conference\n",
    "authors": [
      "Dewen Zeng",
      "Yawen Wu",
      "Xinrong Hu",
      "Xiaowei Xu",
      "Haiyun Yuan",
      "Meiping Huang",
      "Jian Zhuang",
      "Jingtong Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09157"
  },
  {
    "id": "arXiv:2106.09161",
    "title": "Mungojerrie: Reinforcement Learning of Linear-Time Objectives",
    "abstract": "Comments: Mungojerrie is available at this https URL",
    "descriptor": "\nComments: Mungojerrie is available at this https URL\n",
    "authors": [
      "Ernst Moritz Hahn",
      "Mateo Perez",
      "Sven Schewe",
      "Fabio Somenzi",
      "Ashutosh Trivedi",
      "Dominik Wojtczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.09161"
  },
  {
    "id": "arXiv:2106.09191",
    "title": "The Biot-Stokes coupling using total pressure: formulation, analysis and  application to interfacial flow in the eye",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Ricardo Ruiz-Baier",
      "Matteo Taffetani",
      "Hans D. Westermeyer",
      "Ivan Yotov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.09191"
  },
  {
    "id": "arXiv:2106.09303",
    "title": "A Multi-task convolutional neural network for blind stereoscopic image  quality assessment using naturalness analysis",
    "abstract": "A Multi-task convolutional neural network for blind stereoscopic image  quality assessment using naturalness analysis",
    "descriptor": "",
    "authors": [
      "Salima Bourbia",
      "Ayoub Karine",
      "Aladine Chetouani",
      "Mohammed El Hassouni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09303"
  },
  {
    "id": "arXiv:2106.09316",
    "title": "Optimized Power Control Design for Over-the-Air Federated Edge Learning",
    "abstract": "Comments: This is an extended version of a conference paper",
    "descriptor": "\nComments: This is an extended version of a conference paper\n",
    "authors": [
      "Cao Xiaowen",
      "Zhu Guangxu",
      "Xu Jie",
      "Wang Zhiqin",
      "Cui Shuguang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.09316"
  },
  {
    "id": "arXiv:2106.09407",
    "title": "A Fait Accompli? An Empirical Study into the Absence of Consent to  Third-Party Tracking in Android Apps",
    "abstract": "Comments: This paper will be presented at the 7th Symposium on Usable Privacy and Security (SOUPS 2021), 8th-10th August 2021",
    "descriptor": "\nComments: This paper will be presented at the 7th Symposium on Usable Privacy and Security (SOUPS 2021), 8th-10th August 2021\n",
    "authors": [
      "Konrad Kollnig",
      "Reuben Binns",
      "Pierre Dewitte",
      "Max Van Kleek",
      "Ge Wang",
      "Daniel Omeiza",
      "Helena Webb",
      "Nigel Shadbolt"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.09407"
  },
  {
    "id": "arXiv:2106.09526",
    "title": "Exploring the Properties and Evolution of Neural Network Eigenspaces  during Training",
    "abstract": "Exploring the Properties and Evolution of Neural Network Eigenspaces  during Training",
    "descriptor": "",
    "authors": [
      "Mats L. Richter",
      "Leila Malihi",
      "Anne-Kathrin Patricia Windler",
      "Ulf Krumnack"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09526"
  },
  {
    "id": "arXiv:2106.09647",
    "title": "Deep Learning Through the Lens of Example Difficulty",
    "abstract": "Comments: Main paper: 15 pages, 8 figures. Appendix: 31 pages, 40 figures",
    "descriptor": "\nComments: Main paper: 15 pages, 8 figures. Appendix: 31 pages, 40 figures\n",
    "authors": [
      "Robert J. N. Baldock",
      "Hartmut Maennel",
      "Behnam Neyshabur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09647"
  },
  {
    "id": "arXiv:2106.09681",
    "title": "XCiT: Cross-Covariance Image Transformers",
    "abstract": "XCiT: Cross-Covariance Image Transformers",
    "descriptor": "",
    "authors": [
      "Alaaeldin El-Nouby",
      "Hugo Touvron",
      "Mathilde Caron",
      "Piotr Bojanowski",
      "Matthijs Douze",
      "Armand Joulin",
      "Ivan Laptev",
      "Natalia Neverova",
      "Gabriel Synnaeve",
      "Jakob Verbeek",
      "Herv\u00e9 Jegou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09681"
  },
  {
    "id": "arXiv:2106.09686",
    "title": "How Low Can We Go: Trading Memory for Error in Low-Precision Training",
    "abstract": "How Low Can We Go: Trading Memory for Error in Low-Precision Training",
    "descriptor": "",
    "authors": [
      "Chengrun Yang",
      "Ziyang Wu",
      "Jerry Chee",
      "Christopher De Sa",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09686"
  }
]
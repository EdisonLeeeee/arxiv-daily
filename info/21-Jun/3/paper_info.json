[
  {
    "id": "arXiv:2106.00687",
    "title": "Online Detection of Vibration Anomalies Using Balanced Spiking Neural  Networks",
    "abstract": "Vibration patterns yield valuable information about the health state of a\nrunning machine, which is commonly exploited in predictive maintenance tasks\nfor large industrial systems. However, the overhead, in terms of size,\ncomplexity and power budget, required by classical methods to exploit this\ninformation is often prohibitive for smaller-scale applications such as\nautonomous cars, drones or robotics. Here we propose a neuromorphic approach to\nperform vibration analysis using spiking neural networks that can be applied to\na wide range of scenarios. We present a spike-based end-to-end pipeline able to\ndetect system anomalies from vibration data, using building blocks that are\ncompatible with analog-digital neuromorphic circuits. This pipeline operates in\nan online unsupervised fashion, and relies on a cochlea model, on feedback\nadaptation and on a balanced spiking neural network. We show that the proposed\nmethod achieves state-of-the-art performance or better against two publicly\navailable data sets. Further, we demonstrate a working proof-of-concept\nimplemented on an asynchronous neuromorphic processor device. This work\nrepresents a significant step towards the design and implementation of\nautonomous low-power edge-computing devices for online vibration monitoring.",
    "descriptor": "\nComments: This work is presented at the 2021 IEEE AICAS\n",
    "authors": [
      "Nik Dennler",
      "Germain Haessig",
      "Matteo Cartiglia",
      "Giacomo Indiveri"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00687"
  },
  {
    "id": "arXiv:2106.00694",
    "title": "Symmetry-via-Duality: Invariant Neural Network Densities from  Parameter-Space Correlators",
    "abstract": "Parameter-space and function-space provide two different duality frames in\nwhich to study neural networks. We demonstrate that symmetries of network\ndensities may be determined via dual computations of network correlation\nfunctions, even when the density is unknown and the network is not equivariant.\nSymmetry-via-duality relies on invariance properties of the correlation\nfunctions, which stem from the choice of network parameter distributions. Input\nand output symmetries of neural network densities are determined, which recover\nknown Gaussian process results in the infinite width limit. The mechanism may\nalso be utilized to determine symmetries during training, when parameters are\ncorrelated, as well as symmetries of the Neural Tangent Kernel. We demonstrate\nthat the amount of symmetry in the initialization density affects the accuracy\nof networks trained on Fashion-MNIST, and that symmetry breaking helps only\nwhen it is in the direction of ground truth.",
    "descriptor": "\nComments: 20 pages, 3 figures\n",
    "authors": [
      "Anindita Maiti",
      "Keegan Stoner",
      "James Halverson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00694"
  },
  {
    "id": "arXiv:2106.00706",
    "title": "A Non-stiff Summation-By-Parts Finite Difference Method for the Wave  Equation in Second Order Form: Characteristic Boundary Conditions and  Nonlinear Interfaces",
    "abstract": "Curvilinear, multiblock summation-by-parts finite difference methods with the\nsimultaneous approximation term method provide a stable and accurate method for\nsolving the wave equation in second order form. That said, the standard method\ncan become arbitrarily stiff when characteristic boundary conditions and\nnonlinear interface conditions are used. Here we propose a new technique that\navoids this stiffness by using characteristic variables to \"upwind\" the\nboundary and interface treatment. This is done through the introduction of an\nadditional block boundary displacement variable. Using a unified energy, which\nexpresses both the standard as well as characteristic boundary and interface\ntreatment, we show that the resulting scheme has semidiscrete energy stability\nfor the anistropic wave equation. The theoretical stability results are\nconfirmed with numerical experiments that also demonstrate the accuracy and\nrobustness of the proposed scheme. The numerical results also show that the\ncharacteristic scheme has a time step restriction based on standard wave\npropagation considerations and not the boundary closure.",
    "descriptor": "\nComments: 31 pages, 6 figures\n",
    "authors": [
      "Jeremy E Kozdon",
      "Brittany A Erickson",
      "Tobias Harvey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00706"
  },
  {
    "id": "arXiv:2106.00707",
    "title": "An Entropy Regularization Free Mechanism for Policy-based Reinforcement  Learning",
    "abstract": "Policy-based reinforcement learning methods suffer from the policy collapse\nproblem. We find valued-based reinforcement learning methods with\n{\\epsilon}-greedy mechanism are capable of enjoying three characteristics,\nClosed-form Diversity, Objective-invariant Exploration and Adaptive Trade-off,\nwhich help value-based methods avoid the policy collapse problem. However,\nthere does not exist a parallel mechanism for policy-based methods that\nachieves all three characteristics. In this paper, we propose an entropy\nregularization free mechanism that is designed for policy-based methods, which\nachieves Closed-form Diversity, Objective-invariant Exploration and Adaptive\nTrade-off. Our experiments show that our mechanism is super sample-efficient\nfor policy-based methods and boosts a policy-based baseline to a new\nState-Of-The-Art on Arcade Learning Environment.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.03923\n",
    "authors": [
      "Changnan Xiao",
      "Haosen Shi",
      "Jiajun Fan",
      "Shihong Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00707"
  },
  {
    "id": "arXiv:2106.00714",
    "title": "Parallel Polynomial Permanent Mod Powers of 2 and Shortest Disjoint  Cycles",
    "abstract": "We present a parallel algorithm for permanent mod 2^k of a matrix of\nunivariate integer polynomials. It places the problem in ParityL subset of\nNC^2. This extends the techniques of [Valiant], [Braverman, Kulkarni, Roy] and\n[Bj\\\"orklund, Husfeldt], and yields a (randomized) parallel algorithm for\nshortest 2-disjoint paths improving upon the recent result from (randomized)\npolynomial time.\nWe also recognize the disjoint paths problem as a special case of finding\ndisjoint cycles, and present (randomized) parallel algorithms for finding a\nshortest cycle and shortest 2-disjoint cycles passing through any given fixed\nnumber of vertices or edges.",
    "descriptor": "",
    "authors": [
      "Samir Datta",
      "Kishlaya Jaiswal"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.00714"
  },
  {
    "id": "arXiv:2106.00717",
    "title": "Low Complexity Recruitment for Collaborative Mobile Crowdsourcing Using  Graph Neural Networks",
    "abstract": "Collaborative Mobile crowdsourcing (CMCS) allows entities, e.g., local\nauthorities or individuals, to hire a team of workers from the crowd of\nconnected people, to execute complex tasks. In this paper, we investigate two\ndifferent CMCS recruitment strategies allowing task requesters to form teams of\nsocially connected and skilled workers: i) a platform-based strategy where the\nplatform exploits its own knowledge about the workers to form a team and ii) a\nleader-based strategy where the platform designates a group leader that\nrecruits its own suitable team given its own knowledge about its Social Network\n(SN) neighbors. We first formulate the recruitment as an Integer Linear Program\n(ILP) that optimally forms teams according to four fuzzy-logic-based criteria:\nlevel of expertise, social relationship strength, recruitment cost, and\nrecruiter's confidence level. To cope with NP-hardness, we design a novel\nlow-complexity CMCS recruitment approach relying on Graph Neural Networks\n(GNNs), specifically graph embedding and clustering techniques, to shrink the\nworkers' search space and afterwards, exploiting a meta-heuristic genetic\nalgorithm to select appropriate workers. Simulation results applied on a\nreal-world dataset illustrate the performance of both proposed CMCS recruitment\napproaches. It is shown that our proposed low-complexity GNN-based recruitment\nalgorithm achieves close performances to those of the baseline ILP with\nsignificant computational time saving and ability to operate on large-scale\nmobile crowdsourcing platforms. It is also shown that compared to the\nleader-based strategy, the platform-based strategy recruits a more skilled team\nbut with lower SN relationships and higher cost.",
    "descriptor": "\nComments: 16 pages, 20 figures, 2 tables. Accepted for publications in IEEE Internet-of-things Journal\n",
    "authors": [
      "Aymen Hamrouni",
      "Hakim Ghazzai",
      "Turki Alelyani",
      "Yehia Massoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.00717"
  },
  {
    "id": "arXiv:2106.00718",
    "title": "Public Good Games in Directed Networks",
    "abstract": "Public goods games in undirected networks are generally known to have pure\nNash equilibria, which are easy to find. In contrast, we prove that, in\ndirected networks, a broad range of public goods games have intractable\nequilibrium problems: The existence of pure Nash equilibria is NP-hard to\ndecide, and mixed Nash equilibria are PPAD-hard to find. We define general\nutility public goods games, and prove a complexity dichotomy result for finding\npure equilibria, and a PPAD-completeness proof for mixed Nash equilibria. Even\nin the divisible goods variant of the problem, where existence is easy to\nprove, finding the equilibrium is PPAD-complete. Finally, when the treewidth of\nthe directed network is appropriately bounded, we prove that polynomial-time\nalgorithms are possible.",
    "descriptor": "",
    "authors": [
      "Christos Papadimitriou",
      "Binghui Peng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00718"
  },
  {
    "id": "arXiv:2106.00719",
    "title": "Collaborative Nonstationary Multivariate Gaussian Process Model",
    "abstract": "Currently, multi-output Gaussian process regression models either do not\nmodel nonstationarity or are associated with severe computational burdens and\nstorage demands. Nonstationary multi-variate Gaussian process models (NMGP) use\na nonstationary covariance function with an input-dependent linear model of\ncoregionalisation to jointly model input-dependent correlation, scale, and\nsmoothness of outputs. Variational sparse approximation relies on inducing\npoints to enable scalable computations. Here, we take the best of both worlds:\nconsidering an inducing variable framework on the underlying latent functions\nin NMGP, we propose a novel model called the collaborative nonstationary\nGaussian process model(CNMGP). For CNMGP, we derive computationally tractable\nvariational bounds amenable to doubly stochastic variational inference.\nTogether, this allows us to model data in which outputs do not share a common\ninput set, with a computational complexity that is independent of the size of\nthe inputs and outputs. We illustrate the performance of our method on\nsynthetic data and three real datasets and show that our model generally\npro-vides better predictive performance than the state-of-the-art, and also\nprovides estimates of time-varying correlations that differ across outputs.",
    "descriptor": "",
    "authors": [
      "Rui Meng",
      "Herbie Lee",
      "Kristofer Bouchard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00719"
  },
  {
    "id": "arXiv:2106.00720",
    "title": "Fair-Net: A Network Architecture For Reducing Performance Disparity  Between Identifiable Sub-Populations",
    "abstract": "In real world datasets, particular groups are under-represented, much rarer\nthan others, and machine learning classifiers will often preform worse on\nunder-represented populations. This problem is aggravated across many domains\nwhere datasets are class imbalanced, with a minority class far rarer than the\nmajority class. Naive approaches to handle under-representation and class\nimbalance include training sub-population specific classifiers that handle\nclass imbalance or training a global classifier that overlooks sub-population\ndisparities and aims to achieve high overall accuracy by handling class\nimbalance. In this study, we find that these approaches are vulnerable in class\nimbalanced datasets with minority sub-populations. We introduced Fair-Net, a\nbranched multitask neural network architecture that improves both\nclassification accuracy and probability calibration across identifiable\nsub-populations in class imbalanced datasets. Fair-Nets is a straightforward\nextension to the output layer and error function of a network, so can be\nincorporated in far more complex architectures. Empirical studies with three\nreal world benchmark datasets demonstrate that Fair-Net improves classification\nand calibration performance, substantially reducing performance disparity\nbetween gender and racial sub-populations.",
    "descriptor": "",
    "authors": [
      "Arghya Datta",
      "S. Joshua Swamidass"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00720"
  },
  {
    "id": "arXiv:2106.00727",
    "title": "Surgical navigation systems based on augmented reality technologies",
    "abstract": "This study considers modern surgical navigation systems based on augmented\nreality technologies. Augmented reality glasses are used to construct holograms\nof the patient's organs from MRI and CT data, subsequently transmitted to the\nglasses. This, in addition to seeing the actual patient, the surgeon gains\nvisualization inside the patient's body (bones, soft tissues, blood vessels,\netc.). The solutions developed at Peter the Great St. Petersburg Polytechnic\nUniversity allow reducing the invasiveness of the procedure and preserving\nhealthy tissues. This also improves the navigation process, making it easier to\nestimate the location and size of the tumor to be removed. We describe the\napplication of developed systems to different types of surgical operations\n(removal of a malignant brain tumor, removal of a cyst of the cervical spine).\nWe consider the specifics of novel navigation systems designed for anesthesia,\nfor endoscopic operations. Furthermore, we discuss the construction of novel\nvisualization systems for ultrasound machines. Our findings indicate that the\ntechnologies proposed show potential for telemedicine.",
    "descriptor": "",
    "authors": [
      "Vladimir Ivanov",
      "Anton Krivtsov",
      "Sergey Strelkov",
      "Dmitry Gulyaev",
      "Denis Godanyuk",
      "Nikolay Kalakutsky",
      "Artyom Pavlov",
      "Marina Petropavloskaya",
      "Alexander Smirnov",
      "Andrew Yaremenko"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00727"
  },
  {
    "id": "arXiv:2106.00728",
    "title": "Evaluating Recipes Generated from Functional Object-Oriented Network",
    "abstract": "The functional object-oriented network (FOON) has been introduced as a\nknowledge representation, which takes the form of a graph, for symbolic task\nplanning. To get a sequential plan for a manipulation task, a robot can obtain\na task tree through a knowledge retrieval process from the FOON. To evaluate\nthe quality of an acquired task tree, we compare it with a conventional form of\ntask knowledge, such as recipes or manuals. We first automatically convert task\ntrees to recipes, and we then compare them with the human-created recipes in\nthe Recipe1M+ dataset via a survey. Our preliminary study finds no significant\ndifference between the recipes in Recipe1M+ and the recipes generated from FOON\ntask trees in terms of correctness, completeness, and clarity.",
    "descriptor": "\nComments: This manuscript has been accepted at Ubiquitous Robots 2021\n",
    "authors": [
      "Md Sadman Sakib",
      "Hailey Baez",
      "David Paulius",
      "Yu Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00728"
  },
  {
    "id": "arXiv:2106.00730",
    "title": "Enabling Efficiency-Precision Trade-offs for Label Trees in Extreme  Classification",
    "abstract": "Extreme multi-label classification (XMC) aims to learn a model that can tag\ndata points with a subset of relevant labels from an extremely large label set.\nReal world e-commerce applications like personalized recommendations and\nproduct advertising can be formulated as XMC problems, where the objective is\nto predict for a user a small subset of items from a catalog of several million\nproducts. For such applications, a common approach is to organize these labels\ninto a tree, enabling training and inference times that are logarithmic in the\nnumber of labels. While training a model once a label tree is available is well\nstudied, designing the structure of the tree is a difficult task that is not\nyet well understood, and can dramatically impact both model latency and\nstatistical performance. Existing approaches to tree construction fall at an\nextreme point, either optimizing exclusively for statistical performance, or\nfor latency. We propose an efficient information theory inspired algorithm to\nconstruct intermediary operating points that trade off between the benefits of\nboth. Our algorithm enables interpolation between these objectives, which was\nnot previously possible. We corroborate our theoretical analysis with numerical\nresults, showing that on the Wiki-500K benchmark dataset our method can reduce\na proxy for expected latency by up to 28% while maintaining the same accuracy\nas Parabel. On several datasets derived from e-commerce customer logs, our\nmodified label tree is able to improve this expected latency metric by up to\n20% while maintaining the same accuracy. Finally, we discuss challenges in\nrealizing these latency improvements in deployed models.",
    "descriptor": "",
    "authors": [
      "Tavor Z. Baharav",
      "Daniel L. Jiang",
      "Kedarnath Kolluri",
      "Sujay Sanghavi",
      "Inderjit S. Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00730"
  },
  {
    "id": "arXiv:2106.00732",
    "title": "Modular Verification of Concurrent Programs via Sequential Model  Checking",
    "abstract": "This work utilizes the plethora of work on verification of sequential\nprograms for the purpose of verifying concurrent programs. We reduce the\nverification of a concurrent program to a series of verification tasks of\nsequential programs. Our approach is modular in the sense that each sequential\nverification task roughly corresponds to the verification of a single thread,\nwith some additional information about the environment in which it operates.\nInformation regarding the environment is gathered during the run of the\nalgorithm, by need.\nWhile our approach is general, it specializes on concurrent programs where\nthe threads are structured hierarchically. The idea is to exploit the hierarchy\nin order to minimize the amount of information that needs to be transferred\nbetween threads. To that end, we verify one of the threads, considered \"main\",\nas a sequential program. Its verification process initiates queries to its\n\"environment\" (which may contain multiple threads). Those queries are answered\nby sequential verification, if the environment consists of a single thread, or,\notherwise, by applying the same hierarchical algorithm on the environment.\nOur technique is fully automatic, and allows us to use any off-the-shelf\nsequential model checker. We implemented our technique in a tool called CoMuS\nand evaluated it against established tools for concurrent verification. Our\nexperiments show that it works particularly well on hierarchically structured\nprograms.",
    "descriptor": "",
    "authors": [
      "Dan Rasin",
      "Orna Grumberg",
      "Sharon Shoham"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.00732"
  },
  {
    "id": "arXiv:2106.00734",
    "title": "Post-mortem on a deep learning contest: a Simpson's paradox and the  complementary roles of scale metrics versus shape metrics",
    "abstract": "To understand better the causes of good generalization performance in\nstate-of-the-art neural network (NN) models, we analyze of a corpus of models\nthat was made publicly-available for a contest to predict the generalization\naccuracy of NNs. These models include a wide range of qualities and were\ntrained with a range of architectures and regularization hyperparameters. We\nidentify what amounts to a Simpson's paradox: where \"scale\" metrics (from\ntraditional statistical learning theory) perform well overall but perform\npoorly on subpartitions of the data of a given depth, when regularization\nhyperparameters are varied; and where \"shape\" metrics (from Heavy-Tailed Self\nRegularization theory) perform well on subpartitions of the data, when\nhyperparameters are varied for models of a given depth, but perform poorly\noverall when models with varying depths are aggregated. Our results highlight\nthe subtly of comparing models when both architectures and hyperparameters are\nvaried, as well as the complementary role of implicit scale versus implicit\nshape parameters in understanding NN model quality. Our results also suggest\ncaution when one tries to extract causal insight with a single metric applied\nto aggregate data, and they highlight the need to go beyond one-size-fits-all\nmetrics based on upper bounds from generalization theory to describe the\nperformance of state-of-the-art NN models. Based on these findings, we present\ntwo novel shape metrics, one data-independent, and the other data-dependent,\nwhich can predict trends in the test accuracy of a series of NNs, of a fixed\narchitecture/depth, when varying solver hyperparameters.",
    "descriptor": "\nComments: 23 pages; 9 figures; 6 tables\n",
    "authors": [
      "Charles H. Martin",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00734"
  },
  {
    "id": "arXiv:2106.00736",
    "title": "Large-Scale Wasserstein Gradient Flows",
    "abstract": "Wasserstein gradient flows provide a powerful means of understanding and\nsolving many diffusion equations. Specifically, Fokker-Planck equations, which\nmodel the diffusion of probability measures, can be understood as gradient\ndescent over entropy functionals in Wasserstein space. This equivalence,\nintroduced by Jordan, Kinderlehrer and Otto, inspired the so-called JKO scheme\nto approximate these diffusion processes via an implicit discretization of the\ngradient flow in Wasserstein space. Solving the optimization problem associated\nto each JKO step, however, presents serious computational challenges. We\nintroduce a scalable method to approximate Wasserstein gradient flows, targeted\nto machine learning applications. Our approach relies on input-convex neural\nnetworks (ICNNs) to discretize the JKO steps, which can be optimized by\nstochastic gradient descent. Unlike previous work, our method does not require\ndomain discretization or particle simulation. As a result, we can sample from\nthe measure at each time step of the diffusion and compute its probability\ndensity. We demonstrate our algorithm's performance by computing diffusions\nfollowing the Fokker-Planck equation and apply it to unnormalized density\nsampling as well as nonlinear filtering.",
    "descriptor": "",
    "authors": [
      "Petr Mokrov",
      "Alexander Korotin",
      "Lingxiao Li",
      "Aude Genevay",
      "Justin Solomon",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00736"
  },
  {
    "id": "arXiv:2106.00737",
    "title": "Implicit Representations of Meaning in Neural Language Models",
    "abstract": "Does the effectiveness of neural language models derive entirely from\naccurate modeling of surface word co-occurrence statistics, or do these models\nrepresent and reason about the world they describe? In BART and T5 transformer\nlanguage models, we identify contextual word representations that function as\nmodels of entities and situations as they evolve throughout a discourse. These\nneural representations have functional similarities to linguistic models of\ndynamic semantics: they support a linear readout of each entity's current\nproperties and relations, and can be manipulated with predictable effects on\nlanguage generation. Our results indicate that prediction in pretrained neural\nlanguage models is supported, at least in part, by dynamic representations of\nmeaning and implicit simulation of entity state, and that this behavior can be\nlearned with only text as training data. Code and data are available at\nhttps://github.com/belindal/state-probes .",
    "descriptor": "\nComments: 15 pages, 6 figures; accepted to ACL 2021\n",
    "authors": [
      "Belinda Z. Li",
      "Maxwell Nye",
      "Jacob Andreas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00737"
  },
  {
    "id": "arXiv:2106.00739",
    "title": "ICDAR 2021 Competition on On-Line Signature Verification",
    "abstract": "This paper describes the experimental framework and results of the ICDAR 2021\nCompetition on On-Line Signature Verification (SVC 2021). The goal of SVC 2021\nis to evaluate the limits of on-line signature verification systems on popular\nscenarios (office/mobile) and writing inputs (stylus/finger) through\nlarge-scale public databases. Three different tasks are considered in the\ncompetition, simulating realistic scenarios as both random and skilled\nforgeries are simultaneously considered on each task. The results obtained in\nSVC 2021 prove the high potential of deep learning methods. In particular, the\nbest on-line signature verification system of SVC 2021 obtained Equal Error\nRate (EER) values of 3.33% (Task 1), 7.41% (Task 2), and 6.04% (Task 3).\nSVC 2021 will be established as an on-going competition, where researchers\ncan easily benchmark their systems against the state of the art in an open\ncommon platform using large-scale public databases such as DeepSignDB and\nSVC2021_EvalDB, and standard experimental protocols.",
    "descriptor": "",
    "authors": [
      "Ruben Tolosana",
      "Ruben Vera-Rodriguez",
      "Carlos Gonzalez-Garcia",
      "Julian Fierrez",
      "Santiago Rengifo",
      "Aythami Morales",
      "Javier Ortega-Garcia",
      "Juan Carlos Ruiz-Garcia",
      "Sergio Romero-Tapiador",
      "Jiajia Jiang",
      "Songxuan Lai",
      "Lianwen Jin",
      "Yecheng Zhu",
      "Javier Galbally",
      "Moises Diaz",
      "Miguel Angel Ferrer",
      "Marta Gomez-Barrero",
      "Ilya Hodashinsky",
      "Konstantin Sarin",
      "Artem Slezkin",
      "Marina Bardamova",
      "Mikhail Svetlakov",
      "Mohammad Saleem",
      "Cintia Lia Sz\u00fccs",
      "Bence Kovari",
      "Falk Pulsmeyer",
      "Mohamad Wehbi",
      "Dario Zanca",
      "Sumaiya Ahmad",
      "Sarthak Mishra",
      "Suraiya Jabin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00739"
  },
  {
    "id": "arXiv:2106.00740",
    "title": "Intermittent Private Information Retrieval with Application to Location  Privacy",
    "abstract": "We study the problem of intermittent private information retrieval with\nmultiple servers, in which a user consecutively requests one of K messages from\nN replicated databases such that part of requests need to be protected while\nothers do not need privacy. Because of the correlation between requests, the\nuser cannot simply ignore the privacy for the non-private requests.\nWe start by studying a basic two-requests system where one request is private\nand the other is non-private. We propose a scheme for any correlation structure\nbetween two requests, which concatenates an obfuscation scheme and a standard\nPIR scheme to prevent leakage when retrieving information for the non-private\nrequest. The general problem beyond two-requests would require a specification\nof the correlation structure. Motivated by the location privacy application, we\nstudy the Markov model as the correlation structure. To be concrete, we study\nthe problem in the context of location privacy and we apply the basic\ntwo-requests intermittent private information retrieval scheme as a building\nblock to design a location privacy protection mechanism that preserves privacy\nfor locations in the trace level.",
    "descriptor": "",
    "authors": [
      "Fangwei Ye",
      "Salim El Rouayheb"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00740"
  },
  {
    "id": "arXiv:2106.00742",
    "title": "A systematic review of Hate Speech automatic detection using Natural  Language Processing",
    "abstract": "With the multiplication of social media platforms, which offer anonymity,\neasy access and online community formation, and online debate, the issue of\nhate speech detection and tracking becomes a growing challenge to society,\nindividual, policy-makers and researchers. Despite efforts for leveraging\nautomatic techniques for automatic detection and monitoring, their performances\nare still far from satisfactory, which constantly calls for future research on\nthe issue. This paper provides a systematic review of literature in this field,\nwith a focus on natural language processing and deep learning technologies,\nhighlighting the terminology, processing pipeline, core methods employed, with\na focal point on deep learning architecture. From a methodological perspective,\nwe adopt PRISMA guideline of systematic review of the last 10 years literature\nfrom ACM Digital Library and Google Scholar. In the sequel, existing surveys,\nlimitations, and future research directions are extensively discussed.",
    "descriptor": "\nComments: 34 pages, 22 Figure, 14 Table\n",
    "authors": [
      "Md Saroar Jahan",
      "Mourad Oussalah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00742"
  },
  {
    "id": "arXiv:2106.00745",
    "title": "Part of Speech and Universal Dependency effects on English Arabic  Machine Translation",
    "abstract": "In this research paper, I will elaborate on a method to evaluate machine\ntranslation models based on their performance on underlying syntactical\nphenomena between English and Arabic languages. This method is especially\nimportant as such \"neural\" and \"machine learning\" are hard to fine-tune and\nchange. Thus, finding a way to evaluate them easily and diversely would greatly\nhelp the task of bettering them.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Omri Abend",
      "Leshem Choshen",
      "Dmitry Nikolaev",
      "Ofek Rafaeli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00745"
  },
  {
    "id": "arXiv:2106.00749",
    "title": "Higher-order Derivatives of Weighted Finite-state Machines",
    "abstract": "Weighted finite-state machines are a fundamental building block of NLP\nsystems. They have withstood the test of time -- from their early use in noisy\nchannel models in the 1990s up to modern-day neurally parameterized conditional\nrandom fields. This work examines the computation of higher-order derivatives\nwith respect to the normalization constant for weighted finite-state machines.\nWe provide a general algorithm for evaluating derivatives of all orders, which\nhas not been previously described in the literature. In the case of\nsecond-order derivatives, our scheme runs in the optimal $\\mathcal{O}(A^2 N^4)$\ntime where $A$ is the alphabet size and $N$ is the number of states. Our\nalgorithm is significantly faster than prior algorithms. Additionally, our\napproach leads to a significantly faster algorithm for computing second-order\nexpectations, such as covariance matrices and gradients of first-order\nexpectations.",
    "descriptor": "",
    "authors": [
      "Ran Zmigrod",
      "Tim Vieira",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00749"
  },
  {
    "id": "arXiv:2106.00750",
    "title": "Unsupervised Representation Learning for Time Series with Temporal  Neighborhood Coding",
    "abstract": "Time series are often complex and rich in information but sparsely labeled\nand therefore challenging to model. In this paper, we propose a self-supervised\nframework for learning generalizable representations for non-stationary time\nseries. Our approach, called Temporal Neighborhood Coding (TNC), takes\nadvantage of the local smoothness of a signal's generative process to define\nneighborhoods in time with stationary properties. Using a debiased contrastive\nobjective, our framework learns time series representations by ensuring that in\nthe encoding space, the distribution of signals from within a neighborhood is\ndistinguishable from the distribution of non-neighboring signals. Our\nmotivation stems from the medical field, where the ability to model the dynamic\nnature of time series data is especially valuable for identifying, tracking,\nand predicting the underlying patients' latent states in settings where\nlabeling data is practically impossible. We compare our method to recently\ndeveloped unsupervised representation learning approaches and demonstrate\nsuperior performance on clustering and classification tasks for multiple\ndatasets.",
    "descriptor": "\nComments: Camera-ready at ICLR 2021\n",
    "authors": [
      "Sana Tonekaboni",
      "Danny Eytan",
      "Anna Goldenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00750"
  },
  {
    "id": "arXiv:2106.00759",
    "title": "Covid-19 Spread Detection and Controlling with Fog-based Infection  Probability Evaluation Model",
    "abstract": "COVID-19 has created a pandemic around the world, paused the path of building\nthe future, and still ongoing without having any long-term solution shortly.\nThe time taken in vaccine distribution is too slow compared to the spread of\nCOVID-19. Hence, it is important to aware and takes precautions on time without\ndelaying and waiting for long-duration after getting infected with the virus.\nCurrently used technology is more advanced than ever before. Almost everyone\nhas access to at least one mobile device with an Internet connection.\nTherefore, we propose a Fog Server (FS) based system that can be used to create\nawareness about the spread of COVID-19 within the surroundings of individuals\nutilizing the concept of Hidden Markov Models (HMM) and Bluetooth contact\ntracing, in polynomial computational time complexity. Moreover, we evaluate the\neffectiveness of the proposed model through real-world data analysis on\ndifferent simulation parameter settings.",
    "descriptor": "",
    "authors": [
      "Suraj Mahawar",
      "Ajay Pratap"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.00759"
  },
  {
    "id": "arXiv:2106.00761",
    "title": "Motif Prediction with Graph Neural Networks",
    "abstract": "Link prediction is one of the central problems in graph mining. However,\nrecent studies highlight the importance of the higher-order network analysis,\nwhere complex structures called motifs are the first-class citizens. We\nillustrate that existing link prediction schemes fail to predict the appearance\nof complex motifs in graph data. To address this issue, we propose a general\nmotif prediction problem. We establish the theoretical foundation of motif\nprediction and we propose several heuristics that, for a fixed set of nodes in\na graph and a specified motif, assess the chances for this motif to appear. To\nmake the scores realistic, our heuristics - among others - consider\ncorrelations between links, i.e., the potential impact of some arriving links\non the appearance of other parts of a given motif. Finally, for highest\naccuracy, we develop a graph neural network (GNN) architecture for motif\nprediction. Our architecture offers vertex features and sampling schemes that\ncapture the rich structural properties of motifs. While our heuristics are fast\nand do not need any training, using GNNs ensures highest accuracy when\npredicting the arrival of complex graph structures, both dense (e.g.,\nk-cliques) and sparse (e.g., k-stars). Importantly, its advantages over schemes\nbased on uncorrelated link prediction increase with the increasing motif size\nand complexity. We also successfully apply our architecture for predicting more\narbitrary clusters and communities, illustrating its potential for graph mining\nbeyond motif analysis.",
    "descriptor": "",
    "authors": [
      "Maciej Besta",
      "Raphael Grob",
      "Cesare Miglioli",
      "Nicola Bernold",
      "Grzegorz Kwasniewski",
      "Gabriel Gjini",
      "Raghavendra Kanakagiri",
      "Saleh Ashkboos",
      "Lukas Gianinazzi",
      "Nikoli Dryden",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00761"
  },
  {
    "id": "arXiv:2106.00762",
    "title": "A/B Testing for Recommender Systems in a Two-sided Marketplace",
    "abstract": "Two-sided marketplaces are standard business models of many online platforms\n(e.g., Amazon, Facebook, LinkedIn), wherein the platforms have consumers,\nbuyers or content viewers on one side and producers, sellers or\ncontent-creators on the other. Consumer side measurement of the impact of a\ntreatment variant can be done via simple online A/B testing. \\textit{Producer\nside measurement is more challenging because the producer experience depends on\nthe treatment assignment of the consumers}. Existing approaches for producer\nside measurement are either based on graph cluster-based randomization or on\ncertain treatment propagation assumptions. The former approach results in\nlow-powered experiments as the producer-consumer network density increases and\nthe latter approach lacks a strict notion of error control. In this paper, we\npropose (i) a quantification of the quality of a producer side experiment, and\n(ii) a new experiment design mechanism that generates high quality experiments\nbased on this quantification. Our approach, called UniCoRn ({Uni}fying\n{Co}unterfactual {R}a{n}kings), provides explicit control over the quality of\nthe experiment and its computation cost. Further, we prove that our experiment\ndesign is optimal. Our approach is agnostic to the density of the\nproducer-consumer network and does not rely on any treatment propagation\nassumption. Moreover, unlike the existing approaches, we do not need to know\nthe underlying network in advance, making this widely applicable to the\nindustrial setting where the underlying network is unknown and challenging to\npredict a priori due to its dynamic nature. We use simulations to thoroughly\nvalidate our approach and compare it against existing methods. We also\nimplement UniCoRn in an edge recommendation application that serves tens of\nmillions of members and billions of edge recommendations daily.",
    "descriptor": "",
    "authors": [
      "Preetam Nandy",
      "Divya Venugopalan",
      "Chun Lo",
      "Shaunak Chatterjee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.00762"
  },
  {
    "id": "arXiv:2106.00764",
    "title": "HisVA: A Visual Analytics Systemfor Studying History",
    "abstract": "Studying history involves many difficult tasks. Examples include searching\nfor proper data in a large event space, understanding stories of historical\nevents by time and space, and finding relationships among events that may not\nbe apparent. Instructors who extensively use well-organized and well-argued\nmaterials (e.g., textbooks and online resources) can lead students to a narrow\nperspective in understanding history and prevent spontaneous investigation of\nhistorical events, with the students asking their own questions. In this work,\nwe proposed HisVA, a visual analytics system that allows the efficient\nexploration of historical events from Wikipedia using three views: event, map,\nand resource. HisVA provides an effective event exploration space, where users\ncan investigate relationships among historical events by reviewing and linking\nthem in terms of space and time. To evaluate our system, we present two usage\nscenarios, a user study with a qualitative analysis of user exploration\nstrategies, and %expert feedback with in-class deployment results.",
    "descriptor": "",
    "authors": [
      "Dongyun Han",
      "Gorakh Parsad",
      "Hwiyeon Kim",
      "Jaekyom Shim",
      "Oh-Sang Kwon",
      "Kyung A Son",
      "Jooyoung Lee",
      "Isaac Cho",
      "Sungahn Ko"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00764"
  },
  {
    "id": "arXiv:2106.00767",
    "title": "A Simulation-Optimization Technique for Service Level Analysis in  Conjunction with Reorder Point Estimation and Lead-Time consideration: A Case  Study in Sea Port",
    "abstract": "This study offers a step-by-step practical procedure from the analysis of the\ncurrent status of the spare parts inventory system to advanced service-level\nanalysis by virtue of simulation-optimization technique for a real-world case\nstudy associated with a seaport. The remarkable variety and immense diversity\non one hand, and extreme complexities not only in consumption patterns but in\nthe supply of spare parts in an international port with technically advance\nport operator machinery, on the other hand, have convinced the managers to deal\nwith this issue in a structural framework. The huge available data require\ncleaning and classification to properly process them and derive reorder point\n(ROP) estimation, reorder quantity (ROQ) estimation, and associated service\nlevel analysis. Finally, from 247000 items used in 9 years long, 1416 inventory\nitems are elected as a result of ABC analysis integrating with the Analytic\nHierarchy Process (AHP), which led to the main items that need to be kept under\nstrict inventory control. The ROPs and the pertinent quantities are simulated\nby Arena software for all the main items, each of which took approximately 30\nminutes run-time on a personal computer to determine near-optimal estimations.",
    "descriptor": "\nComments: will be available this https URL\n",
    "authors": [
      "Mohammad Arani",
      "Saeed Abdolmaleki",
      "Maryam Maleki",
      "Mohsen Momenitabar",
      "Xian Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00767"
  },
  {
    "id": "arXiv:2106.00769",
    "title": "Improving Compositionality of Neural Networks by Decoding  Representations to Inputs",
    "abstract": "In traditional software programs, we take for granted how easy it is to debug\ncode by tracing program logic from variables back to input, apply unit tests\nand assertion statements to block erroneous behavior, and compose programs\ntogether. But as the programs we write grow more complex, it becomes hard to\napply traditional software to applications like computer vision or natural\nlanguage. Although deep learning programs have demonstrated strong performance\non these applications, they sacrifice many of the functionalities of\ntraditional software programs. In this paper, we work towards bridging the\nbenefits of traditional and deep learning programs by jointly training a\ngenerative model to constrain neural network activations to \"decode\" back to\ninputs. Doing so enables practitioners to probe and track information encoded\nin activation(s), apply assertion-like constraints on what information is\nencoded in an activation, and compose separate neural networks together in a\nplug-and-play fashion. In our experiments, we demonstrate applications of\ndecodable representations to out-of-distribution detection, adversarial\nexamples, calibration, and fairness -- while matching standard neural networks\nin accuracy.",
    "descriptor": "\nComments: 9 pages content; 2 pages appendix\n",
    "authors": [
      "Mike Wu",
      "Noah Goodman",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00769"
  },
  {
    "id": "arXiv:2106.00771",
    "title": "SWIPT with Intelligent Reflecting Surfaces under Spatial Correlation",
    "abstract": "Intelligent reflecting surfaces (IRSs) can be beneficial to both information\nand energy transfer, due to the gains achieved by their multiple elements. In\nthis work, we deal with the impact of spatial correlation between the IRS\nelements, in the context of simultaneous wireless information and power\ntransfer. The performance is evaluated in terms of the average harvested energy\nand the outage probability for random and equal phase shifts. Closed-form\nanalytical expressions for both metrics under spatial correlation are derived.\nMoreover, the optimal case is considered when the elements are uncorrelated and\nfully correlated. In the uncorrelated case, random and equal phase shifts\nprovide the same performance. However, the performance of correlated elements\nattains significant gains when there are equal phase shifts. Finally, we show\nthat correlation is always beneficial to energy transfer, whereas it is a\ndegrading factor for information transfer under random and optimal\nconfigurations.",
    "descriptor": "\nComments: IEEE Wireless Communications Letters\n",
    "authors": [
      "Constantinos Psomas",
      "Ioannis Krikidis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00771"
  },
  {
    "id": "arXiv:2106.00772",
    "title": "Information Theoretic Measures for Fairness-aware Feature Selection",
    "abstract": "Machine earning algorithms are increasingly used for consequential decision\nmaking regarding individuals based on their relevant features. Features that\nare relevant for accurate decisions may however lead to either explicit or\nimplicit forms of discrimination against unprivileged groups, such as those of\ncertain race or gender. This happens due to existing biases in the training\ndata, which are often replicated or even exacerbated by the learning algorithm.\nIdentifying and measuring these biases at the data level is a challenging\nproblem due to the interdependence among the features, and the decision\noutcome. In this work, we develop a framework for fairness-aware feature\nselection, based on information theoretic measures for the accuracy and\ndiscriminatory impacts of features. Specifically, our goal is to design a\nfairness utility score for each feature which quantifies how this feature\ninfluences accurate as well as nondiscriminatory decisions. We first propose\ninformation theoretic measures for the impact of different subsets of features\non the accuracy and discrimination of the model. Subsequently, we deduce the\nmarginal impact of each feature using Shapley value function. Our framework\ndepends on the joint statistics of the data rather than a particular classifier\ndesign. We examine our proposed framework on real and synthetic data to\nevaluate its performance.",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Sajad Khodadadian",
      "Mohamed Nafea",
      "AmirEmad Ghassami",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00772"
  },
  {
    "id": "arXiv:2106.00776",
    "title": "Risk-sensitive safety analysis via state-space augmentation",
    "abstract": "Risk-sensitive safety analysis is a safety analysis method for stochastic\nsystems on Borel spaces that uses a risk functional from finance called\nConditional Value-at-Risk (CVaR). CVaR provides a particularly expressive way\nto quantify the safety of a control system, as it represents the average cost\nin a fraction of worst cases. In prior work, the notion of a risk-sensitive\nsafe set was defined in terms of a non-standard optimal control problem, in\nwhich a maximum cost is assessed via CVaR. Here, we provide a method to compute\nrisk-sensitive safe sets exactly in principle by utilizing a state-space\naugmentation technique. In addition, we prove the existence of an optimal\npre-commitment policy under a measurable selection condition. The proposed\nframework assumes continuous system dynamics and cost functions, but is\notherwise flexible. In particular, it can accommodate probabilistic control\npolicies, fairly general disturbance distributions, and control-dependent,\nnon-monotonic, and non-convex stage costs. We demonstrate how risk-sensitive\nsafety analysis is useful for a stormwater infrastructure application. Our\nnumerical examples are inspired by current challenges that cities face in\nmanaging precipitation uncertainty.",
    "descriptor": "\nComments: under review for IEEE Transactions on Automatic Control, submitted June 2021\n",
    "authors": [
      "Margaret P. Chapman",
      "Michael Fauss",
      "H. Vincent Poor",
      "Kevin M. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00776"
  },
  {
    "id": "arXiv:2106.00780",
    "title": "On Finding the $K$-best Non-projective Dependency Trees",
    "abstract": "The connection between the maximum spanning tree in a directed graph and the\nbest dependency tree of a sentence has been exploited by the NLP community.\nHowever, for many dependency parsing schemes, an important detail of this\napproach is that the spanning tree must have exactly one edge emanating from\nthe root. While work has been done to efficiently solve this problem for\nfinding the one-best dependency tree, no research has attempted to extend this\nsolution to finding the $K$-best dependency trees. This is arguably a more\nimportant extension as a larger proportion of decoded trees will not be subject\nto the root constraint of dependency trees. Indeed, we show that the rate of\nroot constraint violations increases by an average of $13$ times when decoding\nwith $K\\!=\\!50$ as opposed to $K\\!=\\!1$. In this paper, we provide a\nsimplification of the $K$-best spanning tree algorithm of Camerini et al.\n(1980). Our simplification allows us to obtain a constant time speed-up over\nthe original algorithm. Furthermore, we present a novel extension of the\nalgorithm for decoding the $K$-best dependency trees of a graph which are\nsubject to a root constraint.",
    "descriptor": "",
    "authors": [
      "Ran Zmigrod",
      "Tim Vieira",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00780"
  },
  {
    "id": "arXiv:2106.00782",
    "title": "Resource allocation for D2D-Based AMI Communications Underlaying LTE  Cellular Networks",
    "abstract": "Smart meters are utilized to transmit the consumption information to the\nmetering data management system for observing and management in smart grid\nadvanced metering infrastructure systems. In the meantime, for efficient\nutilization for spectrum, Device-to-Device (D2D) communications underlaying LTE\nnetworks are a promising wireless communication technology for advanced\nmetering infrastructure which supporting a technique for reusing the same radio\nresources (RRs) of LTE networks. Therefore, we examine the utilization of D2D\ncommunication technology for advanced metering infrastructure communications\nunderlaying LTE networks. A novel approach is suggested for provisioning the\nmandatory communication between serving data concentrator and its set of smart\nmeters using this technology. The suggested approach is dependent on two main\nstages. The group of permissible cellular user equipment reuse candidates for\nevery smart meter is calculated with taking the quality of service demands for\ncellular user devices and smart meters into consideration in the first stage.\nThe optimal RR allocation for every smart meter is determined based on\nmaximizing the access rate of smart meters which can be accepted and operated\nin D2D reuse mode in the second stage. Simulation results prove the efficacy of\nthe suggested approach for efficient advanced metering infrastructure\ncommunication underlaying LTE systems with accepting remarkable number of SMs\nand accomplishing outstanding throughput gain.",
    "descriptor": "",
    "authors": [
      "H. H. Esmat",
      "Mahmoud M. Elmesalawy",
      "I. I. Ibrahim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00782"
  },
  {
    "id": "arXiv:2106.00786",
    "title": "Search Methods for Sufficient, Socially-Aligned Feature Importance  Explanations with In-Distribution Counterfactuals",
    "abstract": "Feature importance (FI) estimates are a popular form of explanation, and they\nare commonly created and evaluated by computing the change in model confidence\ncaused by removing certain input features at test time. For example, in the\nstandard Sufficiency metric, only the top-k most important tokens are kept. In\nthis paper, we study several under-explored dimensions of FI-based\nexplanations, providing conceptual and empirical improvements for this form of\nexplanation. First, we advance a new argument for why it can be problematic to\nremove features from an input when creating or evaluating explanations: the\nfact that these counterfactual inputs are out-of-distribution (OOD) to models\nimplies that the resulting explanations are socially misaligned. The crux of\nthe problem is that the model prior and random weight initialization influence\nthe explanations (and explanation metrics) in unintended ways. To resolve this\nissue, we propose a simple alteration to the model training process, which\nresults in more socially aligned explanations and metrics. Second, we compare\namong five approaches for removing features from model inputs. We find that\nsome methods produce more OOD counterfactuals than others, and we make\nrecommendations for selecting a feature-replacement function. Finally, we\nintroduce four search-based methods for identifying FI explanations and compare\nthem to strong baselines, including LIME, Integrated Gradients, and random\nsearch. On experiments with six diverse text classification datasets, we find\nthat the only method that consistently outperforms random search is a Parallel\nLocal Search that we introduce. Improvements over the second-best method are as\nlarge as 5.4 points for Sufficiency and 17 points for Comprehensiveness. All\nsupporting code is publicly available at\nhttps://github.com/peterbhase/ExplanationSearch.",
    "descriptor": "\nComments: 26 pages, 4 figures, 8 tables\n",
    "authors": [
      "Peter Hase",
      "Harry Xie",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00786"
  },
  {
    "id": "arXiv:2106.00787",
    "title": "Image-Audio Encoding to Improve C2 Decision-Making in Multi-Domain  Environment",
    "abstract": "The military is investigating methods to improve communication and agility in\nits multi-domain operations (MDO). Nascent popularity of Internet of Things\n(IoT) has gained traction in public and government domains. Its usage in MDO\nmay revolutionize future battlefields and may enable strategic advantage. While\nthis technology offers leverage to military capabilities, it comes with\nchallenges where one is the uncertainty and associated risk. A key question is\nhow can these uncertainties be addressed. Recently published studies proposed\ninformation camouflage to transform information from one data domain to\nanother. As this is comparatively a new approach, we investigate challenges of\nsuch transformations and how these associated uncertainties can be detected and\naddressed, specifically unknown-unknowns to improve decision-making.",
    "descriptor": "\nComments: Published in: International Command and Control Research and Technology Symposium (ICCRTS - 2017)\n",
    "authors": [
      "Piyush K. Sharma",
      "Adrienne Raglin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.00787"
  },
  {
    "id": "arXiv:2106.00791",
    "title": "DYPLOC: Dynamic Planning of Content Using Mixed Language Models for Text  Generation",
    "abstract": "We study the task of long-form opinion text generation, which faces at least\ntwo distinct challenges. First, existing neural generation models fall short of\ncoherence, thus requiring efficient content planning. Second, diverse types of\ninformation are needed to guide the generator to cover both subjective and\nobjective content. To this end, we propose DYPLOC, a generation framework that\nconducts dynamic planning of content while generating the output based on a\nnovel design of mixed language models. To enrich the generation with diverse\ncontent, we further propose to use large pre-trained models to predict relevant\nconcepts and to generate claims. We experiment with two challenging tasks on\nnewly collected datasets: (1) argument generation with Reddit ChangeMyView, and\n(2) writing articles using New York Times' Opinion section. Automatic\nevaluation shows that our model significantly outperforms competitive\ncomparisons. Human judges further confirm that our generations are more\ncoherent with richer content.",
    "descriptor": "\nComments: Accepted at ACL 2021. Project page: this https URL\n",
    "authors": [
      "Xinyu Hua",
      "Ashwin Sreevatsa",
      "Lu Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00791"
  },
  {
    "id": "arXiv:2106.00793",
    "title": "CoRI: Collective Relation Integration with Data Augmentation for Open  Information Extraction",
    "abstract": "Integrating extracted knowledge from the Web to knowledge graphs (KGs) can\nfacilitate tasks like question answering. We study relation integration that\naims to align free-text relations in subject-relation-object extractions to\nrelations in a target KG. To address the challenge that free-text relations are\nambiguous, previous methods exploit neighbor entities and relations for\nadditional context. However, the predictions are made independently, which can\nbe mutually inconsistent. We propose a two-stage Collective Relation\nIntegration (CoRI) model, where the first stage independently makes candidate\npredictions, and the second stage employs a collective model that accesses all\ncandidate predictions to make globally coherent predictions. We further improve\nthe collective model with augmented data from the portion of the target KG that\nis otherwise unused. Experiment results on two datasets show that CoRI can\nsignificantly outperform the baselines, improving AUC from .677 to .748 and\nfrom .716 to .780, respectively.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Zhengbao Jiang",
      "Jialong Han",
      "Bunyamin Sisman",
      "Xin Luna Dong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00793"
  },
  {
    "id": "arXiv:2106.00794",
    "title": "What Ingredients Make for an Effective Crowdsourcing Protocol for  Difficult NLU Data Collection Tasks?",
    "abstract": "Crowdsourcing is widely used to create data for common natural language\nunderstanding tasks. Despite the importance of these datasets for measuring and\nrefining model understanding of language, there has been little focus on the\ncrowdsourcing methods used for collecting the datasets. In this paper, we\ncompare the efficacy of interventions that have been proposed in prior work as\nways of improving data quality. We use multiple-choice question answering as a\ntestbed and run a randomized trial by assigning crowdworkers to write questions\nunder one of four different data collection protocols. We find that asking\nworkers to write explanations for their examples is an ineffective stand-alone\nstrategy for boosting NLU example difficulty. However, we find that training\ncrowdworkers, and then using an iterative process of collecting data, sending\nfeedback, and qualifying workers based on expert judgments is an effective\nmeans of collecting challenging data. But using crowdsourced, instead of expert\njudgments, to qualify workers and send feedback does not prove to be effective.\nWe observe that the data from the iterative protocol with expert assessments is\nmore challenging by several measures. Notably, the human--model gap on the\nunanimous agreement portion of this data is, on average, twice as large as the\ngap for the baseline protocol data.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Nikita Nangia",
      "Saku Sugawara",
      "Harsh Trivedi",
      "Alex Warstadt",
      "Clara Vania",
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00794"
  },
  {
    "id": "arXiv:2106.00795",
    "title": "On Classification of MIMO Equalizers",
    "abstract": "In this theoretical work, the DSP-perceived channel in optical coherent\ncommunications is first simplified, based on which we categorize linear MIMO\nequalizers into four classes according to their reference locations. The entire\nchannel inverse can be represented by a complex conjugate-dependent system,\ncoinciding with the widely linear equalization theory. Suboptimally removing FO\ndynamics, relatively static channel inverses parameterized with common device\nand channel parameters are presented for monitoring or calibration purposes.",
    "descriptor": "\nComments: This work was submitted to ECOC 2021. This theoretical paper also explains the principle of the experimental demonstration in Joint Transmitter and Receiver IQ Differential Phase Calibration using a single 4x8 MIMO Equalizer, Proc. Advanced Photonics Congress 2021 (SPPCom), SpTh1D.4\n",
    "authors": [
      "Wing Chau Ng",
      "Chuandong Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00795"
  },
  {
    "id": "arXiv:2106.00796",
    "title": "Quadrature for Implicitly-defined Finite Element Functions on  Curvilinear Polygons",
    "abstract": "$H^1$-conforming Galerkin methods on polygonal meshes such as VEM, BEM-FEM\nand Trefftz-FEM employ local finite element functions that are implicitly\ndefined as solutions of Poisson problems having polynomial source and boundary\ndata. Recently, such methods have been extended to allow for mesh cells that\nare curvilinear polygons. Such extensions present new challenges for\ndetermining suitable quadratures. We describe an approach for integrating\nproducts of these implicitly defined functions, as well as products of their\ngradients, that reduces integrals on cells to integrals along their boundaries.\nNumerical experiments illustrate the practical performance of the proposed\nmethods.",
    "descriptor": "",
    "authors": [
      "Jeffrey Ovall",
      "Samuel Reynolds"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00796"
  },
  {
    "id": "arXiv:2106.00797",
    "title": "QLSD: Quantised Langevin stochastic dynamics for Bayesian federated  learning",
    "abstract": "Federated learning aims at conducting inference when data are decentralised\nand locally stored on several clients, under two main constraints: data\nownership and communication overhead. In this paper, we address these issues\nunder the Bayesian paradigm. To this end, we propose a novel Markov chain Monte\nCarlo algorithm coined \\texttt{QLSD} built upon quantised versions of\nstochastic gradient Langevin dynamics. To improve performance in a big data\nregime, we introduce variance-reduced alternatives of our methodology referred\nto as \\texttt{QLSD}$^\\star$ and \\texttt{QLSD}$^{++}$. We provide both\nnon-asymptotic and asymptotic convergence guarantees for the proposed\nalgorithms and illustrate their benefits on several federated learning\nbenchmarks.",
    "descriptor": "",
    "authors": [
      "Maxime Vono",
      "Vincent Plassier",
      "Alain Durmus",
      "Aymeric Dieuleveut",
      "Eric Moulines"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00797"
  },
  {
    "id": "arXiv:2106.00799",
    "title": "Multi-task fully convolutional network for tree species mapping in dense  forests using small training hyperspectral data",
    "abstract": "This work proposes a multi-task fully convolutional architecture for tree\nspecies mapping in dense forests from sparse and scarce polygon-level\nannotations using hyperspectral UAV-borne data. Our model implements a partial\nloss function that enables dense tree semantic labeling outcomes from non-dense\ntraining samples, and a distance regression complementary task that enforces\ntree crown boundary constraints and substantially improves the model\nperformance. Our multi-task architecture uses a shared backbone network that\nlearns common representations for both tasks and two task-specific decoders,\none for the semantic segmentation output and one for the distance map\nregression. We report that introducing the complementary task boosts the\nsemantic segmentation performance compared to the single-task counterpart in up\nto 10% reaching an overall F1 score of 87.5% and an overall accuracy of 85.9%,\nachieving state-of-art performance for tree species classification in tropical\nforests.",
    "descriptor": "",
    "authors": [
      "Laura Elena Cu\u00e9 La Rosa",
      "Camile Sothe",
      "Raul Queiroz Feitosa",
      "Cl\u00e1udia Maria de Almeida",
      "Marcos Benedito Schimalski",
      "Dario Augusto Borges Oliveira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00799"
  },
  {
    "id": "arXiv:2106.00805",
    "title": "Lattices of sensors reconsidered when less information is preferred",
    "abstract": "To treat sensing limitations (with uncertainty in both conflation of\ninformation and noise) we model sensors as covers. This leads to a semilattice\norganization of abstract sensors that is appropriate even when additional\ninformation is problematic (e.g., for tasks involving privacy considerations).",
    "descriptor": "\nComments: 3 pages, 2 figures, accepted by 2021 ICRA Workshop on Compositional Robotics: Mathematics and Tools\n",
    "authors": [
      "Yulin Zhang",
      "Dylan A. Shell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.00805"
  },
  {
    "id": "arXiv:2106.00806",
    "title": "Exploring Exotic Counterpoint Compositions",
    "abstract": "In this paper, first musical compositions are presented, which are created\nusing the mathematical counterpoint theory of Guerino Mazzola and his\ncollaborators. These compositions also use the RUBATO(R) software's components\nfor counterpoint constructions. The present work aims at opening new \"exotic\"\ndirections of contrapuntal composition in non-Fuxian worlds. The authors would\nlike to receive first impressions about these compositions, which are available\nas scores and audio files.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Octavio A. Agust\u00edn-Aquino",
      "Jeffery Liu",
      "Guerino Mazzola"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00806"
  },
  {
    "id": "arXiv:2106.00808",
    "title": "Invariant Policy Learning: A Causal Perspective",
    "abstract": "In the past decade, contextual bandit and reinforcement learning algorithms\nhave been successfully used in various interactive learning systems such as\nonline advertising, recommender systems, and dynamic pricing. However, they\nhave yet to be widely adopted in high-stakes application domains, such as\nhealthcare. One reason may be that existing approaches assume that the\nunderlying mechanisms are static in the sense that they do not change over time\nor over different environments. In many real world systems, however, the\nmechanisms are subject to shifts across environments which may invalidate the\nstatic environment assumption. In this paper, we tackle the problem of\nenvironmental shifts under the framework of offline contextual bandits. We view\nthe environmental shift problem through the lens of causality and propose\nmulti-environment contextual bandits that allow for changes in the underlying\nmechanisms. We adopt the concept of invariance from the causality literature\nand introduce the notion of policy invariance. We argue that policy invariance\nis only relevant if unobserved confounders are present and show that, in that\ncase, an optimal invariant policy is guaranteed, under certain assumptions, to\ngeneralize across environments. Our results do not only provide a solution to\nthe environmental shift problem but also establish concrete connections among\ncausality, invariance and contextual bandits.",
    "descriptor": "",
    "authors": [
      "Sorawit Saengkyongam",
      "Nikolaj Thams",
      "Jonas Peters",
      "Niklas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00808"
  },
  {
    "id": "arXiv:2106.00810",
    "title": "Some Ethical Issues in the Review Process of Machine Learning  Conferences",
    "abstract": "Recent successes in the Machine Learning community have led to a steep\nincrease in the number of papers submitted to conferences. This increase made\nmore prominent some of the issues that affect the current review process used\nby these conferences. The review process has several issues that may undermine\nthe nature of scientific research, which is of being fully objective,\napolitical, unbiased and free of misconduct (such as plagiarism, cheating,\nimproper influence, and other improprieties). In this work, we study the\nproblem of reviewers' recruitment, infringements of the double-blind process,\nfraudulent behaviors, biases in numerical ratings, and the appendix phenomenon\n(i.e., the fact that it is becoming more common to publish results in the\nappendix section of a paper). For each of these problems, we provide a short\ndescription and possible solutions. The goal of this work is to raise awareness\nin the Machine Learning community regarding these issues.",
    "descriptor": "",
    "authors": [
      "Alessio Russo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00810"
  },
  {
    "id": "arXiv:2106.00815",
    "title": "Cleaning and Structuring the Label Space of the iMet Collection 2020",
    "abstract": "The iMet 2020 dataset is a valuable resource in the space of fine-grained art\nattribution recognition, but we believe it has yet to reach its true potential.\nWe document the unique properties of the dataset and observe that many of the\nattribute labels are noisy, more than is implied by the dataset description.\nOftentimes, there are also semantic relationships between the labels (e.g.,\nidentical, mutual exclusion, subsumption, overlap with uncertainty) which we\nbelieve are underutilized. We propose an approach to cleaning and structuring\nthe iMet 2020 labels, and discuss the implications and value of doing so.\nFurther, we demonstrate the benefits of our proposed approach through several\nexperiments. Our code and cleaned labels are available at\nhttps://github.com/sunniesuhyoung/iMet2020cleaned.",
    "descriptor": "\nComments: A shorter version of this work was accepted to the CVPR 2021 FGVC Workshop\n",
    "authors": [
      "Vivien Nguyen",
      "Sunnie S. Y. Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00815"
  },
  {
    "id": "arXiv:2106.00817",
    "title": "nnDetection: A Self-configuring Method for Medical Object Detection",
    "abstract": "Simultaneous localisation and categorization of objects in medical images,\nalso referred to as medical object detection, is of high clinical relevance\nbecause diagnostic decisions often depend on rating of objects rather than e.g.\npixels. For this task, the cumbersome and iterative process of method\nconfiguration constitutes a major research bottleneck. Recently, nnU-Net has\ntackled this challenge for the task of image segmentation with great success.\nFollowing nnU-Net's agenda, in this work we systematize and automate the\nconfiguration process for medical object detection. The resulting\nself-configuring method, nnDetection, adapts itself without any manual\nintervention to arbitrary medical detection problems while achieving results en\npar with or superior to the state-of-the-art. We demonstrate the effectiveness\nof nnDetection on two public benchmarks, ADAM and LUNA16, and propose 10\nfurther medical object detection tasks on public data sets for comprehensive\nmethod evaluation. Code is at https://github.com/MIC-DKFZ/nnDetection .",
    "descriptor": "\nComments: *Michael Baumgartner and Paul F. J\\\"ager contributed equally\n",
    "authors": [
      "Michael Baumgartner",
      "Paul F. Jaeger",
      "Fabian Isensee",
      "Klaus H. Maier-Hein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00817"
  },
  {
    "id": "arXiv:2106.00827",
    "title": "Weighting vectors for machine learning: numerical harmonic analysis  applied to boundary detection",
    "abstract": "Metric space magnitude, an active field of research in algebraic topology, is\na scalar quantity that summarizes the effective number of distinct points that\nlive in a general metric space. The {\\em weighting vector} is a closely-related\nconcept that captures, in a nontrivial way, much of the underlying geometry of\nthe original metric space. Recent work has demonstrated that when the metric\nspace is Euclidean, the weighting vector serves as an effective tool for\nboundary detection. We recast this result and show the weighting vector may be\nviewed as a solution to a kernelized SVM. As one consequence, we apply this new\ninsight to the task of outlier detection, and we demonstrate performance that\nis competitive or exceeds performance of state-of-the-art techniques on\nbenchmark data sets. Under mild assumptions, we show the weighting vector,\nwhich has computational cost of matrix inversion, can be efficiently\napproximated in linear time. We show how nearest neighbor methods can\napproximate solutions to the minimization problems defined by SVMs.",
    "descriptor": "\nComments: 16 pages. arXiv admin note: text overlap with arXiv:2006.14063\n",
    "authors": [
      "Eric Bunch",
      "Jeffery Kline",
      "Daniel Dickinson",
      "Suhaas Bhat",
      "Glenn Fung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00827"
  },
  {
    "id": "arXiv:2106.00828",
    "title": "Refining the bounding volumes for lossless compression of voxelized  point clouds geometry",
    "abstract": "This paper describes a novel lossless compression method for point cloud\ngeometry, building on a recent lossy compression method that aimed at\nreconstructing only the bounding volume of a point cloud. The proposed scheme\nstarts by partially reconstructing the geometry from the two depthmaps\nassociated to a single projection direction. The partial reconstruction\nobtained from the depthmaps is completed to a full reconstruction of the point\ncloud by sweeping section by section along one direction and encoding the\npoints which were not contained in the two depthmaps. The main ingredient is a\nlist-based encoding of the inner points (situated inside the feasible regions)\nby a novel arithmetic three dimensional context coding procedure that\nefficiently utilizes rotational invariances present in the input data.\nState-of-the-art bits-per-voxel results are obtained on benchmark datasets.",
    "descriptor": "\nComments: ICIP \\c{opyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Emre Can Kaya",
      "Sebastian Schwarz",
      "Ioan Tabus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.00828"
  },
  {
    "id": "arXiv:2106.00829",
    "title": "ConvoSumm: Conversation Summarization Benchmark and Improved Abstractive  Summarization with Argument Mining",
    "abstract": "While online conversations can cover a vast amount of information in many\ndifferent formats, abstractive text summarization has primarily focused on\nmodeling solely news articles. This research gap is due, in part, to the lack\nof standardized datasets for summarizing online discussions. To address this\ngap, we design annotation protocols motivated by an\nissues--viewpoints--assertions framework to crowdsource four new datasets on\ndiverse online conversation forms of news comments, discussion forums,\ncommunity question answering forums, and email threads. We benchmark\nstate-of-the-art models on our datasets and analyze characteristics associated\nwith the data. To create a comprehensive benchmark, we also evaluate these\nmodels on widely-used conversation summarization datasets to establish strong\nbaselines in this domain. Furthermore, we incorporate argument mining through\ngraph construction to directly model the issues, viewpoints, and assertions\npresent in a conversation and filter noisy input, showing comparable or\nimproved results according to automatic and human evaluations.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Alexander R. Fabbri",
      "Faiaz Rahman",
      "Imad Rizvi",
      "Borui Wang",
      "Haoran Li",
      "Yashar Mehdad",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00829"
  },
  {
    "id": "arXiv:2106.00834",
    "title": "Green IoT System Architecture for Applied Autonomous Network  Cybersecurity Monitoring",
    "abstract": "Network security morning (NSM) is essential for any cybersecurity system,\nwhere the average cost of a cyberattack is $1.1 million. No matter how much a\nsystem is secure, it will eventually fail without proper and continuous\nmonitoring. No wonder that the cybersecurity market is expected to grow up to\n$170.4 billion in 2022. However, the majority of legacy industries do not\ninvest in NSM implementation until it is too late due to the initial and\noperation cost and static unutilized resources. Thus, this paper proposes a\nnovel dynamic Internet of things (IoT) architecture for an industrial NSM that\nfeatures a low installation and operation cost, low power consumption,\nintelligent organization behavior, and environmentally friendly operation. As a\ncase study, the system is implemented in a midrange oil a gas manufacture\nfacility in the southern states with more than 300 machines and servers over\nthree remote locations and a production plant that features a challenging\natmosphere condition. The proposed system successfully shows a significant\nsaving (>65%) in power consumption, acquires one-tenth the installation cost,\ndevelops an intelligent operation expert system tools as well as saves the\nenvironment from more than 500 mg of CO2 pollution per hour, promoting green\nIoT systems.",
    "descriptor": "\nComments: Cybersecurity, IoT, NSM, packet capture, sensor, green systems, oil and gas, Network Security Monitoring. Accepted in IEEE WF-IoT 2021\n",
    "authors": [
      "Zaghloul Saad Zaghloul",
      "Nelly Elsayed",
      "Chengcheng Li",
      "Magdy Bayoumi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.00834"
  },
  {
    "id": "arXiv:2106.00837",
    "title": "On stimulating fungi $Pleurotus~ostreatus$ with Cortisol",
    "abstract": "Fungi cells are capable of sensing extracellular cues through reception,\ntransduction and response systems which allow them to communicate with their\nhost and adapt to their environment. They display effective regulatory protein\nexpressions which enhance and regulate their response and adaptation to a\nvariety of triggers such as stress, hormones, light, chemicals and host\nfactors. In our recent studies, we have shown that $Pleurotus$ oyster fungi\ngenerate electrical potential impulses in the form of spike events as a result\nof their exposure to environmental, mechanical and chemical triggers,\ndemonstrating that it is possible to discern the nature of stimuli from the\nfungi electrical responses. Harnessing the power of fungi sensing and\nintelligent capabilities, we explored the communication protocols of fungi as\nreporters of human chemical secretions such as hormones, addressing the\nquestion if fungi can sense human signals. We exposed $Pleurotus$ oyster fungi\nto cortisol, directly applied to a surface of a hemp shavings substrate\ncolonised by fungi, and recorded the electrical activity of fungi. The response\nof fungi to cortisol was also supplementary studied through the application of\nX-ray to identify changes in the fungi tissue, where receiving cortisol by the\nsubstrate can inhibit the flow of calcium and, in turn, reduce its\nphysiological changes. This study could pave the way for future research on\nadaptive fungal wearables capable for detecting physiological states of humans\nand biosensors made of living fungi.",
    "descriptor": "",
    "authors": [
      "Mohammad Mahdi Dehshibi",
      "Alessandro Chiolerio",
      "Anna Nikolaidou",
      "Richard Mayne",
      "Antoni Gandia",
      "Mona Ashtari",
      "Andrew Adamatzky"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2106.00837"
  },
  {
    "id": "arXiv:2106.00839",
    "title": "Pricing Algorithmic Insurance",
    "abstract": "As machine learning algorithms start to get integrated into the\ndecision-making process of companies and organizations, insurance products will\nbe developed to protect their owners from risk. We introduce the concept of\nalgorithmic insurance and present a quantitative framework to enable the\npricing of the derived insurance contracts. We propose an optimization\nformulation to estimate the risk exposure and price for a binary classification\nmodel. Our approach outlines how properties of the model, such as accuracy,\ninterpretability and generalizability, can influence the insurance contract\nevaluation. To showcase a practical implementation of the proposed framework,\nwe present a case study of medical malpractice in the context of breast cancer\ndetection. Our analysis focuses on measuring the effect of the model parameters\non the expected financial loss and identifying the aspects of algorithmic\nperformance that predominantly affect the price of the contract.",
    "descriptor": "",
    "authors": [
      "Dimitris Bertsimas",
      "Agni Orfanoudaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Risk Management (q-fin.RM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00839"
  },
  {
    "id": "arXiv:2106.00840",
    "title": "Comparing Test Sets with Item Response Theory",
    "abstract": "Recent years have seen numerous NLP datasets introduced to evaluate the\nperformance of fine-tuned models on natural language understanding tasks.\nRecent results from large pretrained models, though, show that many of these\ndatasets are largely saturated and unlikely to be able to detect further\nprogress. What kind of datasets are still effective at discriminating among\nstrong models, and what kind of datasets should we expect to be able to detect\nfuture improvements? To measure this uniformly across datasets, we draw on Item\nResponse Theory and evaluate 29 datasets using predictions from 18 pretrained\nTransformer models on individual test examples. We find that Quoref, HellaSwag,\nand MC-TACO are best suited for distinguishing among state-of-the-art models,\nwhile SNLI, MNLI, and CommitmentBank seem to be saturated for current strong\nmodels. We also observe span selection task format, which is used for QA\ndatasets like QAMR or SQuAD2.0, is effective in differentiating between strong\nand weak models.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Clara Vania",
      "Phu Mon Htut",
      "William Huang",
      "Dhara Mungra",
      "Richard Yuanzhe Pang",
      "Jason Phang",
      "Haokun Liu",
      "Kyunghyun Cho",
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00840"
  },
  {
    "id": "arXiv:2106.00841",
    "title": "Two Birds With One Stone: Fairness and Welfare via Transfers",
    "abstract": "We study the question of dividing a collection of indivisible goods amongst a\nset of agents. The main objective of research in the area is to achieve one of\ntwo goals: fairness or efficiency. On the fairness side, envy-freeness is the\ncentral fairness criterion in economics, but envy-free allocations typically do\nnot exist when the goods are indivisible. A recent line of research shows that\nenvy-freeness can be achieved if a small quantity of a homogeneous divisible\ngood (money) is introduced into the system, or equivalently, if transfer\npayments are allowed between the agents. A natural question to explore, then,\nis whether transfer payments can be used to provide high welfare in addition to\nenvy-freeness, and if so, how much money is needed to be transferred.\nWe show that for general monotone valuations, there always exists an\nallocation with transfers that is envy-free and whose Nash social welfare (NSW)\nis at least an $e^{-1/e}$-fraction of the optimal Nash social welfare.\nAdditionally, when the agents have additive valuations, an envy-free allocation\nwith negligible transfers and whose NSW is within a constant factor of optimal\ncan be found in polynomial time. Consequently, we demonstrate that the\nseemingly incompatible objectives of fairness and high welfare can be achieved\nsimultaneously via transfer payments, even for general valuations, when the\nwelfare objective is NSW. On the other hand, we show that a similar result is\nimpossible for utilitarian social welfare: any envy-freeable allocation that\nachieves a constant fraction of the optimal welfare requires non-negligible\ntransfers. To complement this result we present algorithms that compute an\nenvy-free allocation with a given target welfare and with bounded transfers.",
    "descriptor": "",
    "authors": [
      "Vishnu V. Narayan",
      "Mashbat Suzuki",
      "Adrian Vetta"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.00841"
  },
  {
    "id": "arXiv:2106.00842",
    "title": "Leveraging Pre-Images to Discover Nonlinear Relationships in  Multivariate Environments",
    "abstract": "Causal discovery, beyond the inference of a network as a collection of\nconnected dots, offers a crucial functionality in scientific discovery using\nartificial intelligence. The questions that arise in multiple domains, such as\nphysics, physiology, the strategic decision in uncertain environments with\nmultiple agents, climatology, among many others, have roots in causality and\nreasoning. It became apparent that many real-world temporal observations are\nnonlinearly related to each other. While the number of observations can be as\nhigh as millions of points, the number of temporal samples can be minimal due\nto ethical or practical reasons, leading to the curse-of-dimensionality in\nlarge-scale systems. This paper proposes a novel method using kernel principal\ncomponent analysis and pre-images to obtain nonlinear dependencies of\nmultivariate time-series data. We show that our method outperforms\nstate-of-the-art causal discovery methods when the observations are restricted\nby time and are nonlinearly related. Extensive simulations on both real-world\nand synthetic datasets with various topologies are provided to evaluate our\nproposed methods.",
    "descriptor": "\nComments: 5 pages, 4 Figures, Conference paper\n",
    "authors": [
      "M. Ali Vosoughi",
      "Axel Wismuller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00842"
  },
  {
    "id": "arXiv:2106.00845",
    "title": "Energy-aware placement optimization of UAV base stations via  decentralized multi-agent Q-learning",
    "abstract": "Unmanned aerial vehicles serving as aerial base stations (UAV-BSs) can be\ndeployed to provide wireless connectivity to ground devices in events of\nincreased network demand, points-of-failure in existing infrastructure, or\ndisasters. However, it is challenging to conserve the energy of UAVs during\nprolonged coverage tasks, considering their limited on-board battery capacity.\nReinforcement learning-based (RL) approaches have been previously used to\nimprove energy utilization of multiple UAVs, however, a central cloud\ncontroller is assumed to have complete knowledge of the end-devices' locations,\ni.e., the controller periodically scans and sends updates for UAV\ndecision-making. This assumption is impractical in dynamic network environments\nwith mobile ground devices. To address this problem, we propose a decentralized\nQ-learning approach, where each UAV-BS is equipped with an autonomous agent\nthat maximizes the connectivity to ground devices while improving its energy\nutilization. Experimental results show that the proposed design significantly\noutperforms the centralized approaches in jointly maximizing the number of\nconnected ground devices and the energy utilization of the UAV-BSs.",
    "descriptor": "\nComments: Submitted to IEEE Globecom SAC 2021, Spain\n",
    "authors": [
      "Babatunji Omoniwa",
      "Boris Galkin",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.00845"
  },
  {
    "id": "arXiv:2106.00846",
    "title": "An Optimal Relay Scheme for Outage Minimization in Fog-based  Internet-of-Things (IoT) Networks",
    "abstract": "Fog devices are beginning to play a key role in relaying data and services\nwithin the Internet-of-Things (IoT) ecosystem. These relays may be static or\nmobile, with the latter offering a new degree of freedom for performance\nimprovement via careful relay mobility design. Besides that, power conservation\nhas been a prevalent issue in IoT networks with devices being\npower-constrained, requiring optimal power-control mechanisms. In this paper,\nwe consider a multi-tier fog-based IoT architecture where a mobile/static fog\nnode acts as an amplify and forward relay that transmits received information\nfrom a sensor node to a higher hierarchically-placed static fog device, which\noffers some localized services. The outage probability of the presented\nscenario was efficiently minimized by jointly optimizing the mobility pattern\nand the transmit power of the fog relay. A closed-form analytical expression\nfor the outage probability was derived. Furthermore, due to the intractability\nand non-convexity of the formulated problem, we applied an iterative algorithm\nbased on the steepest descent method to arrive at a desirable objective.\nSimulations reveal that the outage probability was improved by 62.7% in the\noptimized-location fixed-power (OLFP) scheme, 79.3% in the optimized-power\nfixed-location (OPFL) scheme, and 94.2% in the optimized-location\noptimized-power (OLOP) scheme, as against the fixed-location and fixed-power\n(FLFP) scheme (i.e., without optimization). Lastly, we present an optimal relay\nselection strategy that chooses an appropriate relay node from randomly\ndistributed relaying candidates.",
    "descriptor": "\nComments: Accepted and Published in IEEE Internet of Things Journal\n",
    "authors": [
      "Babatunji Omoniwa",
      "Riaz Hussain",
      "Muhammad Adil",
      "Atif Shakeel",
      "Ahmed Kamal Tahir",
      "Qadeer Ul Hasan",
      "Shahzad A. Malik"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.00846"
  },
  {
    "id": "arXiv:2106.00851",
    "title": "Parameter-Efficient Neural Question Answering Models via Graph-Enriched  Document Representations",
    "abstract": "As the computational footprint of modern NLP systems grows, it becomes\nincreasingly important to arrive at more efficient models. We show that by\nemploying graph convolutional document representation, we can arrive at a\nquestion answering system that performs comparably to, and in some cases\nexceeds the SOTA solutions, while using less than 5\\% of their resources in\nterms of trainable parameters. As it currently stands, a major issue in\napplying GCNs to NLP is document representation. In this paper, we show that a\nGCN enriched document representation greatly improves the results seen in\nHotPotQA, even when using a trivial topology. Our model (gQA), performs\nadmirably when compared to the current SOTA, and requires little to no\npreprocessing. In Shao et al. 2020, the authors suggest that graph networks are\nnot necessary for good performance in multi-hop QA. In this paper, we suggest\nthat large language models are not necessary for good performance by showing a\nna\\\"{i}ve implementation of a GCN performs comparably to SoTA models based on\npretrained language models.",
    "descriptor": "",
    "authors": [
      "Louis Castricato",
      "Stephen Fitz",
      "Won Young Shin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00851"
  },
  {
    "id": "arXiv:2106.00853",
    "title": "Claim Matching Beyond English to Scale Global Fact-Checking",
    "abstract": "Manual fact-checking does not scale well to serve the needs of the internet.\nThis issue is further compounded in non-English contexts. In this paper, we\ndiscuss claim matching as a possible solution to scale fact-checking. We define\nclaim matching as the task of identifying pairs of textual messages containing\nclaims that can be served with one fact-check. We construct a novel dataset of\nWhatsApp tipline and public group messages alongside fact-checked claims that\nare first annotated for containing \"claim-like statements\" and then matched\nwith potentially similar items and annotated for claim matching. Our dataset\ncontains content in high-resource (English, Hindi) and lower-resource (Bengali,\nMalayalam, Tamil) languages. We train our own embedding model using knowledge\ndistillation and a high-quality \"teacher\" model in order to address the\nimbalance in embedding quality between the low- and high-resource languages in\nour dataset. We provide evaluations on the performance of our solution and\ncompare with baselines and existing state-of-the-art multilingual embedding\nmodels, namely LASER and LaBSE. We demonstrate that our performance exceeds\nLASER and LaBSE in all settings. We release our annotated datasets, codebooks,\nand trained embedding model to allow for further research.",
    "descriptor": "\nComments: to appear in ACL 2021 as a long paper\n",
    "authors": [
      "Ashkan Kazemi",
      "Kiran Garimella",
      "Devin Gaffney",
      "Scott A. Hale"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00853"
  },
  {
    "id": "arXiv:2106.00854",
    "title": "Smart Online Charging Algorithm for Electric Vehicles via Customized  Actor-Critic Learning",
    "abstract": "With the advances in the Internet of Things technology, electric vehicles\n(EVs) have become easier to schedule in daily life, which is reshaping the\nelectric load curve. It is important to design efficient charging algorithms to\nmitigate the negative impact of EV charging on the power grid. This paper\ninvestigates an EV charging scheduling problem to reduce the charging cost\nwhile shaving the peak charging load, under unknown future information about\nEVs, such as arrival time, departure time, and charging demand. First, we\nformulate an EV charging problem to minimize the electricity bill of the EV\nfleet and study the EV charging problem in an online setting without knowing\nfuture information. We develop an actor-critic learning-based smart charging\nalgorithm (SCA) to schedule the EV charging against the uncertainties in EV\ncharging behaviors. The SCA learns an optimal EV charging strategy with\ncontinuous charging actions instead of discrete approximation of charging. We\nfurther develop a more computationally efficient customized actor-critic\nlearning charging algorithm (CALC) by reducing the state dimension and thus\nimproving the computational efficiency. Finally, simulation results show that\nour proposed SCA can reduce EVs' expected cost by 24.03%, 21.49%, 13.80%,\ncompared with the Eagerly Charging Algorithm, Online Charging Algorithm,\nRL-based Adaptive Energy Management Algorithm, respectively. CALC is more\ncomputationally efficient, and its performance is close to that of SCA with\nonly a gap of 5.56% in the cost.",
    "descriptor": "\nComments: 11 pages, 11 figures\n",
    "authors": [
      "Yongsheng Cao",
      "Hao Wang",
      "Demin Li",
      "Guanglin Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00854"
  },
  {
    "id": "arXiv:2106.00857",
    "title": "Fine-grained Finger Gesture Recognition Using WiFi Signals",
    "abstract": "Gesture recognition has become increasingly important in human-computer\ninteraction and can support different applications such as smart home, VR, and\ngaming. Traditional approaches usually rely on dedicated sensors that are worn\nby the user or cameras that require line of sight. In this paper, we present\nfine-grained finger gesture recognition by using commodity WiFi without\nrequiring user to wear any sensors. Our system takes advantages of the\nfine-grained Channel State Information available from commodity WiFi devices\nand the prevalence of WiFi network infrastructures. It senses and identifies\nsubtle movements of finger gestures by examining the unique patterns exhibited\nin the detailed CSI. We devise environmental noise removal mechanism to\nmitigate the effect of signal dynamic due to the environment changes. Moreover,\nwe propose to capture the intrinsic gesture behavior to deal with individual\ndiversity and gesture inconsistency. Lastly, we utilize multiple WiFi links and\nlarger bandwidth at 5GHz to achieve finger gesture recognition under multi-user\nscenario. Our experimental evaluation in different environments demonstrates\nthat our system can achieve over 90% recognition accuracy and is robust to both\nenvironment changes and individual diversity. Results also show that our system\ncan provide accurate gesture recognition under different scenarios.",
    "descriptor": "",
    "authors": [
      "Sheng Tan",
      "Jie Yang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00857"
  },
  {
    "id": "arXiv:2106.00858",
    "title": "Uncertainty Characteristics Curves: A Systematic Assessment of  Prediction Intervals",
    "abstract": "Accurate quantification of model uncertainty has long been recognized as a\nfundamental requirement for trusted AI. In regression tasks, uncertainty is\ntypically quantified using prediction intervals calibrated to a specific\noperating point, making evaluation and comparison across different studies\ndifficult. Our work leverages: (1) the concept of operating characteristics\ncurves and (2) the notion of a gain over a simple reference, to derive a novel\noperating point agnostic assessment methodology for prediction intervals. The\npaper describes the corresponding algorithm, provides a theoretical analysis,\nand demonstrates its utility in multiple scenarios. We argue that the proposed\nmethod addresses the current need for comprehensive assessment of prediction\nintervals and thus represents a valuable addition to the uncertainty\nquantification toolbox.",
    "descriptor": "\nComments: 10 pages main paper, 9 pages appendix\n",
    "authors": [
      "Jiri Navratil",
      "Benjamin Elder",
      "Matthew Arnold",
      "Soumya Ghosh",
      "Prasanna Sattigeri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00858"
  },
  {
    "id": "arXiv:2106.00859",
    "title": "A Continuous Liveness Detection for Voice Authentication on Smart  Devices",
    "abstract": "Voice biometrics is drawing increasing attention as it is a promising\nalternative to legacy passwords for user authentication. Recently, a growing\nbody of work shows that voice biometrics is vulnerable to spoofing through\nreplay attacks, where an adversary tries to spoof voice authentication systems\nby using a pre-recorded voice sample collected from a genuine user. To this\nend, we propose VoiceGesture, a liveness detection solution for voice\nauthentication on smart devices such as smartphones and smart speakers.\nVoiceGesture detects a live user by leveraging both the unique articulatory\ngesture of the user when speaking a passphrase and the audio hardware advances\non these smart devices. Specifically, our system re-uses a pair of built-in\nspeaker and microphone on a smart device as a Doppler radar, which transmits a\nhigh-frequency acoustic sound from the speaker and listens to the reflections\nat the microphone when a user speaks a passphrase. Then we extract Doppler\nshifts resulted from the user's articulatory gestures for liveness detection.\nVoiceGesture is practical as it requires neither cumbersome operations nor\nadditional hardware but a speaker and a microphone commonly available on smart\ndevices that support voice input. Our experimental evaluation with 21\nparticipants and different smart devices shows that VoiceGesture achieves over\n99% and around 98% detection accuracy for text-dependent and text-independent\nliveness detection, respectively. Results also show that VoiceGesture is robust\nto different device placements, low audio sampling frequency, and supports\nmedium range liveness detection on smart speakers in various use scenarios like\nsmart homes and smart vehicles.",
    "descriptor": "",
    "authors": [
      "Linghan Zhang",
      "Jie Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00859"
  },
  {
    "id": "arXiv:2106.00860",
    "title": "Object Sensing for Fruit Ripeness Detection Using WiFi Signals",
    "abstract": "This paper presents FruitSense, a novel fruit ripeness sensing system that\nleverages wireless signals to enable non-destructive and low-cost detection of\nfruit ripeness. Such a system can reuse existing WiFi devices in homes without\nthe need for additional sensors. It uses WiFi signals to sense the\nphysiological changes associated with fruit ripening for detecting the ripeness\nof fruit. FruitSense leverages the larger bandwidth at 5GHz (i.e., over 600MHz)\nto extract the multipath-independent signal components to characterize the\nphysiological compounds of the fruit. It then measures the similarity between\nthe extracted features and the ones in ripeness profiles for identifying the\nripeness level. We evaluate FruitSense in different multipath environments with\ntwo types of fruits (i.e, kiwi and avocado) under four levels of ripeness.\nExperimental results show that FruitSense can detect the ripeness levels of\nfruits with an accuracy of over 90%.",
    "descriptor": "",
    "authors": [
      "Sheng Tan",
      "Jie Yang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00860"
  },
  {
    "id": "arXiv:2106.00861",
    "title": "Necessary and Sufficient Girth Conditions for LDPC Tanner Graphs with  Denser Protographs",
    "abstract": "This paper gives necessary and sufficient conditions for the Tanner graph of\na quasi-cyclic (QC) low-density parity-check (LDPC) code based on the all-one\nprotograph to have girth 6, 8, 10, and 12, respectively, in the case of\nparity-check matrices with column weight 4. These results are a natural\nextension of the girth results of the already-studied cases of column weight 2\nand 3, and it is based on the connection between the girth of a Tanner graph\ngiven by a parity-check matrix and the properties of powers of the product\nbetween the matrix and its transpose. The girth conditions can be easily\nincorporated into fast algorithms that construct codes of desired girth between\n6 and 12; our own algorithms are presented for each girth, together with\nconstructions obtained from them and corresponding computer simulations. More\nimportantly, this paper emphasizes how the girth conditions of the Tanner graph\ncorresponding to a parity-check matrix composed of circulants relate to the\nmatrix obtained by adding (over the integers) the circulant columns of the\nparity-check matrix. In particular, we show that imposing girth conditions on a\nparity-check matrix is equivalent to imposing conditions on a square circulant\nsubmatrix of size 4 obtained from it.",
    "descriptor": "\nComments: Submitted to the International Symposium on Topics in Coding 2021. arXiv admin note: text overlap with arXiv:2105.03462\n",
    "authors": [
      "Anthony G\u00f3mez-Fonseca",
      "Roxana Smarandache",
      "David G. M. Mitchell"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00861"
  },
  {
    "id": "arXiv:2106.00865",
    "title": "Multi-User Activity Recognition and Tracking Using Commodity WiFi",
    "abstract": "This paper presents MultiTrack, a commodity WiFi-based human sensing system\nthat can track multiple users and recognize the activities of multiple users\nperforming them simultaneously. Such a system can enable easy and large-scale\ndeployment for multi-user tracking and sensing without the need for additional\nsensors through the use of existing WiFi devices (e.g., desktops, laptops, and\nsmart appliances). The basic idea is to identify and extract the signal\nreflection corresponding to each individual user with the help of multiple WiFi\nlinks and all the available WiFi channels at 5GHz. Given the extracted signal\nreflection of each user, MultiTrack examines the path of the reflected signals\nat multiple links to simultaneously track multiple users. It further\nreconstructs the signal profile of each user as if only a single user has\nperformed activity in the environment to facilitate multi-user activity\nrecognition. We evaluate MultiTrack in different multipath environments with up\nto 4 users for multi-user tracking and up to 3 users for activity recognition.\nExperimental results show that our system can achieve decimeter localization\naccuracy and over 92% activity recognition accuracy under multi-user scenarios.",
    "descriptor": "",
    "authors": [
      "Sheng Tan",
      "Jie Yang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00865"
  },
  {
    "id": "arXiv:2106.00872",
    "title": "On the Efficacy of Adversarial Data Collection for Question Answering:  Results from a Large-Scale Randomized Study",
    "abstract": "In adversarial data collection (ADC), a human workforce interacts with a\nmodel in real time, attempting to produce examples that elicit incorrect\npredictions. Researchers hope that models trained on these more challenging\ndatasets will rely less on superficial patterns, and thus be less brittle.\nHowever, despite ADC's intuitive appeal, it remains unclear when training on\nadversarial datasets produces more robust models. In this paper, we conduct a\nlarge-scale controlled study focused on question answering, assigning workers\nat random to compose questions either (i) adversarially (with a model in the\nloop); or (ii) in the standard fashion (without a model). Across a variety of\nmodels and datasets, we find that models trained on adversarial data usually\nperform better on other adversarial datasets but worse on a diverse collection\nof out-of-domain evaluation sets. Finally, we provide a qualitative analysis of\nadversarial (vs standard) data, identifying key differences and offering\nguidance for future research.",
    "descriptor": "\nComments: Accepted at ACL-IJCNLP 2021\n",
    "authors": [
      "Divyansh Kaushik",
      "Douwe Kiela",
      "Zachary C. Lipton",
      "Wen-tau Yih"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00872"
  },
  {
    "id": "arXiv:2106.00873",
    "title": "Coverage-based Scene Fuzzing for Virtual Autonomous Driving Testing",
    "abstract": "Simulation-based virtual testing has become an essential step to ensure the\nsafety of autonomous driving systems. Testers need to handcraft the virtual\ndriving scenes and configure various environmental settings like surrounding\ntraffic, weather conditions, etc. Due to the huge amount of configuration\npossibilities, the human efforts are subject to the inefficiency in detecting\nflaws in industry-class autonomous driving system. This paper proposes a\ncoverage-driven fuzzing technique to automatically generate diverse\nconfiguration parameters to form new driving scenes. Experimental results show\nthat our fuzzing method can significantly reduce the cost in deriving new risky\nscenes from the initial setup designed by testers. We expect automated fuzzing\nwill become a common practice in virtual testing for autonomous driving\nsystems.",
    "descriptor": "",
    "authors": [
      "Zhisheng Hu",
      "Shengjian Guo",
      "Zhenyu Zhong",
      "Kang Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.00873"
  },
  {
    "id": "arXiv:2106.00874",
    "title": "Conversational Question Answering: A Survey",
    "abstract": "Question answering (QA) systems provide a way of querying the information\navailable in various formats including, but not limited to, unstructured and\nstructured data in natural languages. It constitutes a considerable part of\nconversational artificial intelligence (AI) which has led to the introduction\nof a special research topic on Conversational Question Answering (CQA), wherein\na system is required to understand the given context and then engages in\nmulti-turn QA to satisfy the user's information needs. Whilst the focus of most\nof the existing research work is subjected to single-turn QA, the field of\nmulti-turn QA has recently grasped attention and prominence owing to the\navailability of large-scale, multi-turn QA datasets and the development of\npre-trained language models. With a good amount of models and research papers\nadding to the literature every year recently, there is a dire need of arranging\nand presenting the related work in a unified manner to streamline future\nresearch. This survey, therefore, is an effort to present a comprehensive\nreview of the state-of-the-art research trends of CQA primarily based on\nreviewed papers from 2016-2021. Our findings show that there has been a trend\nshift from single-turn to multi-turn QA which empowers the field of\nConversational AI from different perspectives. This survey is intended to\nprovide an epitome for the research community with the hope of laying a strong\nfoundation for the field of CQA.",
    "descriptor": "",
    "authors": [
      "Munazza Zaib",
      "Wei Emma Zhang",
      "Quan Z. Sheng",
      "Adnan Mahmood",
      "Yang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.00874"
  },
  {
    "id": "arXiv:2106.00875",
    "title": "The Hardest Explicit Construction",
    "abstract": "We investigate the complexity of explicit construction problems, where the\ngoal is to produce a particular object of size $n$ possessing some pseudorandom\nproperty in time polynomial in $n$. We give overwhelming evidence that ${\\bf\nAPEPP}$, defined originally by Kleinberg et al., is the natural complexity\nclass associated with explicit constructions for objects whose existence\nfollows from the probabilistic method, by proving that a host of well-studied\nexplicit construction problems lie in this class. We then observe that a result\nof Je\\v{r}\\'{a}bek on provability in Bounded Arithmetic, when reinterpreted as\na reduction between search problems, shows that constructing a truth table of\nhigh circuit complexity is complete for ${\\bf APEPP}$ under ${\\bf P}^{\\bf NP}$\nreductions. This demonstrates that constructing a hard truth table is a\nuniversal explicit construction problem in a concrete sense. This result in\nfact gives a precise algorithmic characterization of proving $2^{\\Omega(n)}$\ncircuit lower bounds for ${\\bf E}^{\\bf NP}$: the complete problem for ${\\bf\nAPEPP}$ has a ${\\bf P}^{\\bf NP}$ algorithm if and only if such a lower bound\nholds. Together with our proof that pseudorandom generators can be constructed\nin ${\\bf APEPP}$, this also yields a self-contained and significantly\nsimplified proof of the celebrated result of Impagliazzo and Wigderson that\nworst-case-hard truth tables can be used to derandomize algorithms (although\nthe conclusion is weaker as our derandomization requires an ${\\bf NP}$ oracle).\nAs another corollary of this completeness result, we show that ${\\bf E}^{\\bf\nNP}$ contains a language of circuit complexity $2^{\\Omega(n)}$ if and only if\nit contains a language of circuit complexity $\\frac{2^n}{3n}$. Finally, for\nseveral of the problems shown to lie in ${\\bf APEPP}$, we demonstrate direct\npolynomial time reductions to the explicit construction of hard truth tables.",
    "descriptor": "",
    "authors": [
      "Oliver Korten"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.00875"
  },
  {
    "id": "arXiv:2106.00877",
    "title": "Evaluating Word Embeddings with Categorical Modularity",
    "abstract": "We introduce categorical modularity, a novel low-resource intrinsic metric to\nevaluate word embedding quality. Categorical modularity is a graph modularity\nmetric based on the $k$-nearest neighbor graph constructed with embedding\nvectors of words from a fixed set of semantic categories, in which the goal is\nto measure the proportion of words that have nearest neighbors within the same\ncategories. We use a core set of 500 words belonging to 59 neurobiologically\nmotivated semantic categories in 29 languages and analyze three word embedding\nmodels per language (FastText, MUSE, and subs2vec). We find moderate to strong\npositive correlations between categorical modularity and performance on the\nmonolingual tasks of sentiment analysis and word similarity calculation and on\nthe cross-lingual task of bilingual lexicon induction both to and from English.\nOverall, we suggest that categorical modularity provides non-trivial predictive\ninformation about downstream task performance, with breakdowns of correlations\nby model suggesting some meta-predictive properties about semantic information\nloss as well.",
    "descriptor": "\nComments: Accepted to Findings of ACL 2021 (Long Paper)\n",
    "authors": [
      "S\u00edlvia Casacuberta",
      "Karina Halevy",
      "Dami\u00e1n E. Blasi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00877"
  },
  {
    "id": "arXiv:2106.00880",
    "title": "Rotation Equivariant Feature Image Pyramid Network for Object Detection  in Optical Remote Sensing Imagery",
    "abstract": "Over the last few years, there has been substantial progress in object\ndetection on remote sensing images (RSIs) where objects are generally\ndistributed with large-scale variations and have different types of\norientations. Nevertheless, most of the current convolution neural network\napproaches lack the ability to deal with the challenges such as size and\nrotation variations. To address these problems, we propose the rotation\nequivariant feature image pyramid network (REFIPN), an image pyramid network\nbased on rotation equivariance convolution. The proposed pyramid network\nextracts features in a wide range of scales and orientations by using novel\nconvolution filters. These features are used to generate vector fields and\ndetermine the weight and angle of the highest-scoring orientation for all\nspatial locations on an image. Finally, the extracted features go through the\nprediction layers of the detector. The detection performance of the proposed\nmodel is validated on two commonly used aerial benchmarks and the results show\nour propose model can achieve state-of-the-art performance with satisfactory\nefficiency.",
    "descriptor": "",
    "authors": [
      "Pourya Shamsolmoali",
      "Masoumeh Zareapoor",
      "Jocelyn Chanussot",
      "Huiyu Zhou",
      "Jie Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00880"
  },
  {
    "id": "arXiv:2106.00881",
    "title": "Hyperdimensional Computing for Efficient Distributed Classification with  Randomized Neural Networks",
    "abstract": "In the supervised learning domain, considering the recent prevalence of\nalgorithms with high computational cost, the attention is steering towards\nsimpler, lighter, and less computationally extensive training and inference\napproaches. In particular, randomized algorithms are currently having a\nresurgence, given their generalized elementary approach. By using randomized\nneural networks, we study distributed classification, which can be employed in\nsituations were data cannot be stored at a central location nor shared. We\npropose a more efficient solution for distributed classification by making use\nof a lossy compression approach applied when sharing the local classifiers with\nother agents. This approach originates from the framework of hyperdimensional\ncomputing, and is adapted herein. The results of experiments on a collection of\ndatasets demonstrate that the proposed approach has usually higher accuracy\nthan local classifiers and getting close to the benchmark - the centralized\nclassifier. This work can be considered as the first step towards analyzing the\nvariegated horizon of distributed randomized neural networks.",
    "descriptor": "\nComments: 1 table, 5 figures\n",
    "authors": [
      "Antonello Rosato",
      "Massimo Panella",
      "Denis Kleyko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.00881"
  },
  {
    "id": "arXiv:2106.00882",
    "title": "Efficient Passage Retrieval with Hashing for Open-domain Question  Answering",
    "abstract": "Most state-of-the-art open-domain question answering systems use a neural\nretrieval model to encode passages into continuous vectors and extract them\nfrom a knowledge source. However, such retrieval models often require large\nmemory to run because of the massive size of their passage index. In this\npaper, we introduce Binary Passage Retriever (BPR), a memory-efficient neural\nretrieval model that integrates a learning-to-hash technique into the\nstate-of-the-art Dense Passage Retriever (DPR) to represent the passage index\nusing compact binary codes rather than continuous vectors. BPR is trained with\na multi-task objective over two tasks: efficient candidate generation based on\nbinary codes and accurate reranking based on continuous vectors. Compared with\nDPR, BPR substantially reduces the memory cost from 65GB to 2GB without a loss\nof accuracy on two standard open-domain question answering benchmarks: Natural\nQuestions and TriviaQA. Our code and trained models are available at\nhttps://github.com/studio-ousia/bpr.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Ikuya Yamada",
      "Akari Asai",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.00882"
  },
  {
    "id": "arXiv:2106.00883",
    "title": "Towards proteinoid computers",
    "abstract": "Proteinoids -- thermal proteins -- are produced by heating amino acids to\ntheir melting point and initiation of polymerisation to produce polymeric\nchains. Proteinoids swell in aqueous solution into hollow microspheres. The\nproteinoid microspheres produce endogenous burst of electrical potential spikes\nand change patterns of their electrical activity in response to illumination.\nThe microspheres can interconnect by pores and tubes and form networks with a\nprogrammable growth. We speculate on how ensembles of the proteinoid\nmicrospheres can be developed into unconventional computing devices.",
    "descriptor": "",
    "authors": [
      "Andrew Adamatzky"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2106.00883"
  },
  {
    "id": "arXiv:2106.00884",
    "title": "Deep Personalized Glucose Level Forecasting Using Attention-based  Recurrent Neural Networks",
    "abstract": "In this paper, we study the problem of blood glucose forecasting and provide\na deep personalized solution. Predicting blood glucose level in people with\ndiabetes has significant value because health complications of abnormal glucose\nlevel are serious, sometimes even leading to death. Therefore, having a model\nthat can accurately and quickly warn patients of potential problems is\nessential. To develop a better deep model for blood glucose forecasting, we\nanalyze the data and detect important patterns. These observations helped us to\npropose a method that has several key advantages over existing methods: 1- it\nlearns a personalized model for each patient as well as a global model; 2- it\nuses an attention mechanism and extracted time features to better learn\nlong-term dependencies in the data; 3- it introduces a new, robust training\nprocedure for time series data. We empirically show the efficacy of our model\non a real dataset.",
    "descriptor": "\nComments: 8 pages, submitted to IJCNN 2021\n",
    "authors": [
      "Mohammadreza Armandpour",
      "Brian Kidd",
      "Yu Du",
      "Jianhua Z. Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.00884"
  },
  {
    "id": "arXiv:2106.00886",
    "title": "Partial Wasserstein Covering",
    "abstract": "We consider a general task called partial Wasserstein covering with the goal\nof emulating a large dataset (e.g., application dataset) using a small dataset\n(e.g., development dataset) in terms of the empirical distribution by selecting\na small subset from a candidate dataset and adding it to the small dataset. We\nmodel this task as a discrete optimization problem with partial Wasserstein\ndivergence as an objective function. Although this problem is NP-hard, we prove\nthat it has the submodular property, allowing us to use a greedy algorithm with\na 0.63 approximation. However, the greedy algorithm is still inefficient\nbecause it requires linear programming for each objective function evaluation.\nTo overcome this difficulty, we propose quasi-greedy algorithms for\nacceleration, which consist of a series of techniques such as sensitivity\nanalysis based on strong duality and the so-called $C$-transform in the optimal\ntransport field. Experimentally, we demonstrate that we can efficiently make\ntwo datasets similar in terms of partial Wasserstein divergence, including\ndriving scene datasets.",
    "descriptor": "",
    "authors": [
      "Keisuke Kawano",
      "Satoshi Koide",
      "Keisuke Otaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00886"
  },
  {
    "id": "arXiv:2106.00887",
    "title": "Exploiting Global Contextual Information for Document-level Named Entity  Recognition",
    "abstract": "Most existing named entity recognition (NER) approaches are based on sequence\nlabeling models, which focus on capturing the local context dependencies.\nHowever, the way of taking one sentence as input prevents the modeling of\nnon-sequential global context, which is useful especially when local context\ninformation is limited or ambiguous. To this end, we propose a model called\nGlobal Context enhanced Document-level NER (GCDoc) to leverage global\ncontextual information from two levels, i.e., both word and sentence. At\nword-level, a document graph is constructed to model a wider range of\ndependencies between words, then obtain an enriched contextual representation\nfor each word via graph neural networks (GNN). To avoid the interference of\nnoise information, we further propose two strategies. First we apply the\nepistemic uncertainty theory to find out tokens whose representations are less\nreliable, thereby helping prune the document graph. Then a selective auxiliary\nclassifier is proposed to effectively learn the weight of edges in document\ngraph and reduce the importance of noisy neighbour nodes. At sentence-level,\nfor appropriately modeling wider context beyond single sentence, we employ a\ncross-sentence module which encodes adjacent sentences and fuses it with the\ncurrent sentence representation via attention and gating mechanisms. Extensive\nexperiments on two benchmark NER datasets (CoNLL 2003 and Ontonotes 5.0 English\ndataset) demonstrate the effectiveness of our proposed model. Our model reaches\nF1 score of 92.22 (93.40 with BERT) on CoNLL 2003 dataset and 88.32 (90.49 with\nBERT) on Ontonotes 5.0 dataset, achieving new state-of-the-art performance.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Zanbo Wang",
      "Wei Wei",
      "Xianling Mao",
      "Shanshan Feng",
      "Pan Zhou",
      "Zhiyong He",
      "Sheng Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00887"
  },
  {
    "id": "arXiv:2106.00891",
    "title": "High-Quality Diversification for Task-Oriented Dialogue Systems",
    "abstract": "Many task-oriented dialogue systems use deep reinforcement learning (DRL) to\nlearn policies that respond to the user appropriately and complete the tasks\nsuccessfully. Training DRL agents with diverse dialogue trajectories prepare\nthem well for rare user requests and unseen situations. One effective\ndiversification method is to let the agent interact with a diverse set of\nlearned user models. However, trajectories created by these artificial user\nmodels may contain generation errors, which can quickly propagate into the\nagent's policy. It is thus important to control the quality of the\ndiversification and resist the noise. In this paper, we propose a novel\ndialogue diversification method for task-oriented dialogue systems trained in\nsimulators. Our method, Intermittent Short Extension Ensemble (I-SEE),\nconstrains the intensity to interact with an ensemble of diverse user models\nand effectively controls the quality of the diversification. Evaluations on the\nMultiwoz dataset show that I-SEE successfully boosts the performance of several\nstate-of-the-art DRL dialogue agents.",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021 (Findings of ACL)\n",
    "authors": [
      "Zhiwen Tang",
      "Hrishikesh Kulkarni",
      "Grace Hui Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00891"
  },
  {
    "id": "arXiv:2106.00893",
    "title": "Solving Arithmetic Word Problems with Transformers and Preprocessing of  Problem Text",
    "abstract": "This paper outlines the use of Transformer networks trained to translate math\nword problems to equivalent arithmetic expressions in infix, prefix, and\npostfix notations. We compare results produced by many neural configurations\nand find that most configurations outperform previously reported approaches on\nthree of four datasets with significant increases in accuracy of over 20\npercentage points. The best neural approaches boost accuracy by 30% when\ncompared to the previous state-of-the-art on some datasets.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1912.00871\n",
    "authors": [
      "Kaden Griffith",
      "Jugal Kalita"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00893"
  },
  {
    "id": "arXiv:2106.00895",
    "title": "Field Estimation using Robotic Swarms through Bayesian Regression and  Mean-Field Feedback",
    "abstract": "Recent years have seen an increased interest in using mean-field density\nbased modelling and control strategy for deploying robotic swarms. In this\npaper, we study how to dynamically deploy the robots subject to their physical\nconstraints to efficiently measure and reconstruct certain unknown spatial\nfield (e.g. the air pollution index over a city). Specifically, the evolution\nof the robots' density is modelled by mean-field partial differential equations\n(PDEs) which are uniquely determined by the robots' individual dynamics.\nBayesian regression models are used to obtain predictions and return a variance\nfunction that represents the confidence of the prediction. We formulate a PDE\nconstrained optimization problem based on this variance function to dynamically\ngenerate a reference density signal which guides the robots to uncertain areas\nto collect new data, and design mean-field feedback-based control laws such\nthat the robots' density converges to this reference signal. We also show that\nthe proposed feedback law is robust to density estimation errors in the sense\nof input-to-state stability. Simulations are included to verify the\neffectiveness of the algorithms.",
    "descriptor": "",
    "authors": [
      "Tongjia Zheng",
      "Hai Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00895"
  },
  {
    "id": "arXiv:2106.00896",
    "title": "Asymptotics of Sequential Composite Hypothesis Testing under  Probabilistic Constraints",
    "abstract": "We consider the sequential composite binary hypothesis testing problem in\nwhich one of the hypotheses is governed by a single distribution while the\nother is governed by a family of distributions whose parameters belong to a\nknown set $\\Gamma$. We would like to design a test to decide which hypothesis\nis in effect. Under the constraints that the probabilities that the length of\nthe test, a stopping time, exceeds $n$ are bounded by a certain threshold\n$\\epsilon$, we obtain certain fundamental limits on the asymptotic behavior of\nthe sequential test as $n$ tends to infinity. Assuming that $\\Gamma$ is a\nconvex and compact set, we obtain the set of all first-order error exponents\nfor the problem. We also prove a strong converse. Additionally, we obtain the\nset of second-order error exponents under the assumption that $\\mathcal{X}$ is\na finite alphabet. In the proof of second-order asymptotics, a main technical\ncontribution is the derivation of a central limit-type result for a maximum of\nan uncountable set of log-likelihood ratios under suitable conditions. This\nresult may be of independent interest. We also show that some important\nstatistical models satisfy the conditions.",
    "descriptor": "\nComments: The paper was presented in part at the 2021 International Symposium on Information Theory (ISIT). It was submitted to Transactions on Information Theory\n",
    "authors": [
      "Jiachun Pan",
      "Yonglong Li",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.00896"
  },
  {
    "id": "arXiv:2106.00897",
    "title": "Solving Large-Scale Extensive-Form Network Security Games via Neural  Fictitious Self-Play",
    "abstract": "Securing networked infrastructures is important in the real world. The\nproblem of deploying security resources to protect against an attacker in\nnetworked domains can be modeled as Network Security Games (NSGs).\nUnfortunately, existing approaches, including the deep learning-based\napproaches, are inefficient to solve large-scale extensive-form NSGs. In this\npaper, we propose a novel learning paradigm, NSG-NFSP, to solve large-scale\nextensive-form NSGs based on Neural Fictitious Self-Play (NFSP). Our main\ncontributions include: i) reforming the best response (BR) policy network in\nNFSP to be a mapping from action-state pair to action-value, to make the\ncalculation of BR possible in NSGs; ii) converting the average policy network\nof an NFSP agent into a metric-based classifier, helping the agent to assign\ndistributions only on legal actions rather than all actions; iii) enabling NFSP\nwith high-level actions, which can benefit training efficiency and stability in\nNSGs; and iv) leveraging information contained in graphs of NSGs by learning\nefficient graph node embeddings. Our algorithm significantly outperforms\nstate-of-the-art algorithms in both scalability and solution quality.",
    "descriptor": "\nComments: Published as a conference paper in IJCAI 2021\n",
    "authors": [
      "Wanqi Xue",
      "Youzhi Zhang",
      "Shuxin Li",
      "Xinrun Wang",
      "Bo An",
      "Chai Kiat Yeo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.00897"
  },
  {
    "id": "arXiv:2106.00898",
    "title": "Trajectory Optimization for Manipulation of Deformable Objects: Assembly  of Belt Drive Units",
    "abstract": "This paper presents a novel trajectory optimization formulation to solve the\nrobotic assembly of the belt drive unit. Robotic manipulations involving\ncontacts and deformable objects are challenging in both dynamic modeling and\ntrajectory planning. For modeling, variations in the belt tension and contact\nforces between the belt and the pulley could dramatically change the system\ndynamics. For trajectory planning, it is computationally expensive to plan\ntrajectories for such hybrid dynamical systems as it usually requires planning\nfor discrete modes separately. In this work, we formulate the belt drive unit\nassembly task as a trajectory optimization problem with complementarity\nconstraints to avoid explicitly imposing contact mode sequences. The problem is\nsolved as a mathematical program with complementarity constraints (MPCC) to\nobtain feasible and efficient assembly trajectories. We validate the proposed\nmethod both in simulations with a physics engine and in real-world experiments\nwith a robotic manipulator.",
    "descriptor": "",
    "authors": [
      "Shiyu Jin",
      "Diego Romeres",
      "Arvind Ragunathan",
      "Devesh K. Jha",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.00898"
  },
  {
    "id": "arXiv:2106.00899",
    "title": "Feedback Interconnected Mean-Field Estimation and Control",
    "abstract": "Swarm robotic systems have foreseeable applications in the near future.\nRecently, there has been an increasing amount of literature that employs\nmean-field partial differential equations (PDEs) to model the time-evolution of\nthe probability density of swarm robotic systems and uses mean-field feedback\nto design stable control laws that act on individuals such that their density\nconverges to a target profile. However, it remains largely unexplored\nconsidering problems of how to estimate the mean-field density, how the density\nestimation algorithms affect the control performance, and whether the\nestimation performance in turn depends on the control algorithms. In this work,\nwe focus on studying the interplay of these algorithms. Specially, we propose\nnew mean-field control laws which use the real-time density and its gradient as\nfeedback, and prove that they are globally input-to-state stable (ISS) to\nestimation errors. Then, we design filtering algorithms to obtain estimates of\nthe density and its gradient, and prove that these estimates are convergent\nassuming the control laws are known. Finally, we show that the feedback\ninterconnection of these estimation and control algorithms is still globally\nISS, which is attributed to the bilinearity of the mean-field PDE system. An\nagent-based simulation is included to verify the stability of these algorithms\nand their feedback interconnection.",
    "descriptor": "",
    "authors": [
      "Tongjia Zheng",
      "Qing Han",
      "Hai Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00899"
  },
  {
    "id": "arXiv:2106.00901",
    "title": "A Differentiable Point Process with Its Application to Spiking Neural  Networks",
    "abstract": "This paper is concerned about a learning algorithm for a probabilistic model\nof spiking neural networks (SNNs). Jimenez Rezende & Gerstner (2014) proposed a\nstochastic variational inference algorithm to train SNNs with hidden neurons.\nThe algorithm updates the variational distribution using the score function\ngradient estimator, whose high variance often impedes the whole learning\nalgorithm. This paper presents an alternative gradient estimator for SNNs based\non the path-wise gradient estimator. The main technical difficulty is a lack of\na general method to differentiate a realization of an arbitrary point process,\nwhich is necessary to derive the path-wise gradient estimator. We develop a\ndifferentiable point process, which is the technical highlight of this paper,\nand apply it to derive the path-wise gradient estimator for SNNs. We\ninvestigate the effectiveness of our gradient estimator through numerical\nsimulation.",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Hiroshi Kajino"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00901"
  },
  {
    "id": "arXiv:2106.00903",
    "title": "Rejuvenating Low-Frequency Words: Making the Most of Parallel Data in  Non-Autoregressive Translation",
    "abstract": "Knowledge distillation (KD) is commonly used to construct synthetic data for\ntraining non-autoregressive translation (NAT) models. However, there exists a\ndiscrepancy on low-frequency words between the distilled and the original data,\nleading to more errors on predicting low-frequency words. To alleviate the\nproblem, we directly expose the raw data into NAT by leveraging pretraining. By\nanalyzing directed alignments, we found that KD makes low-frequency source\nwords aligned with targets more deterministically but fails to align sufficient\nlow-frequency words from target to source. Accordingly, we propose reverse KD\nto rejuvenate more alignments for low-frequency target words. To make the most\nof authentic and synthetic data, we combine these complementary approaches as a\nnew training strategy for further boosting NAT performance. We conduct\nexperiments on five translation benchmarks over two advanced architectures.\nResults demonstrate that the proposed approach can significantly and\nuniversally improve translation quality by reducing translation errors on\nlow-frequency words. Encouragingly, our approach achieves 28.2 and 33.9 BLEU\npoints on the WMT14 English-German and WMT16 Romanian-English datasets,\nrespectively. Our code, data, and trained models are available at\n\\url{https://github.com/longyuewangdcu/RLFW-NAT}.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Liang Ding",
      "Longyue Wang",
      "Xuebo Liu",
      "Derek F. Wong",
      "Dacheng Tao",
      "Zhaopeng Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00903"
  },
  {
    "id": "arXiv:2106.00905",
    "title": "Low-cost Stereovision system (disparity map) for few dollars",
    "abstract": "The paper presents an analysis of the latest developments in the field of\nstereo vision in the low-cost segment, both for prototypes and for industrial\ndesigns. We described the theory of stereo vision and presented information\nabout cameras and data transfer protocols and their compatibility with various\ndevices. The theory in the field of image processing for stereo vision\nprocesses is considered and the calibration process is described in detail.\nUltimately, we presented the developed stereo vision system and provided the\nmain points that need to be considered when developing such systems. The final,\nwe presented software for adjusting stereo vision parameters in real-time in\nthe python language in the Windows operating system.",
    "descriptor": "",
    "authors": [
      "R. Ildar",
      "E. Pomazov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00905"
  },
  {
    "id": "arXiv:2106.00906",
    "title": "Learn to Predict Equilibria via Fixed Point Networks",
    "abstract": "Systems of interacting agents can often be modeled as contextual games, where\nthe context encodes additional information, beyond the control of any agent\n(e.g. weather for traffic and fiscal policy for market economies). In such\nsystems, the most likely outcome is given by a Nash equilibrium. In many\npractical settings, only game equilibria are observed, while the optimal\nparameters for a game model are unknown. This work introduces Nash Fixed Point\nNetworks (N-FPNs), a class of implicit-depth neural networks that output Nash\nequilibria of contextual games. The N-FPN architecture fuses data-driven\nmodeling with provided constraints. Given equilibrium observations of a\ncontextual game, N-FPN parameters are learnt to predict equilibria outcomes\ngiven only the context. We present an end-to-end training scheme for N-FPNs\nthat is simple and memory efficient to implement with existing\nautodifferentiation tools. N-FPNs also exploit a novel constraint decoupling\nscheme to avoid costly projections. Provided numerical examples show the\nefficacy of N-FPNs on atomic and non-atomic games (e.g. traffic routing).",
    "descriptor": "",
    "authors": [
      "Howard Heaton",
      "Daniel McKenzie",
      "Qiuwei Li",
      "Samy Wu Fung",
      "Stanley Osher",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00906"
  },
  {
    "id": "arXiv:2106.00908",
    "title": "TransMIL: Transformer based Correlated Multiple Instance Learning for  Whole Slide Image Classication",
    "abstract": "Multiple instance learning (MIL) is a powerful tool to solve the weakly\nsupervised classification in whole slide image (WSI) based pathology diagnosis.\nHowever, the current MIL methods are usually based on independent and identical\ndistribution hypothesis, thus neglect the correlation among different\ninstances. To address this problem, we proposed a new framework, called\ncorrelated MIL, and provided a proof for convergence. Based on this framework,\nwe devised a Transformer based MIL (TransMIL), which explored both\nmorphological and spatial information. The proposed TransMIL can effectively\ndeal with unbalanced/balanced and binary/multiple classification with great\nvisualization and interpretability. We conducted various experiments for three\ndifferent computational pathology problems and achieved better performance and\nfaster convergence compared with state-of-the-art methods. The test AUC for the\nbinary tumor classification can be up to 93.09% over CAMELYON16 dataset. And\nthe AUC over the cancer subtypes classification can be up to 96.03% and 98.82%\nover TCGA-NSCLC dataset and TCGA-RCC dataset, respectively.",
    "descriptor": "",
    "authors": [
      "Zhuchen Shao",
      "Hao Bian",
      "Yang Chen",
      "Yifeng Wang",
      "Jian Zhang",
      "Xiangyang Ji",
      "Yongbing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00908"
  },
  {
    "id": "arXiv:2106.00909",
    "title": "The Generalized Mean Densest Subgraph Problem",
    "abstract": "Finding dense subgraphs of a large graph is a standard problem in graph\nmining that has been studied extensively both for its theoretical richness and\nits many practical applications. In this paper we introduce a new family of\ndense subgraph objectives, parameterized by a single parameter $p$, based on\ncomputing generalized means of degree sequences of a subgraph. Our objective\ncaptures both the standard densest subgraph problem and the maximum $k$-core as\nspecial cases, and provides a way to interpolate between and extrapolate beyond\nthese two objectives when searching for other notions of dense subgraphs. In\nterms of algorithmic contributions, we first show that our objective can be\nminimized in polynomial time for all $p \\geq 1$ using repeated submodular\nminimization. A major contribution of our work is analyzing the performance of\ndifferent types of peeling algorithms for dense subgraphs both in theory and\npractice. We prove that the standard peeling algorithm can perform arbitrarily\npoorly on our generalized objective, but we then design a more sophisticated\npeeling method which for $p \\geq 1$ has an approximation guarantee that is\nalways at least $1/2$ and converges to 1 as $p \\rightarrow \\infty$. In\npractice, we show that this algorithm obtains extremely good approximations to\nthe optimal solution, scales to large graphs, and highlights a range of\ndifferent meaningful notions of density on graphs coming from numerous domains.\nFurthermore, it is typically able to approximate the densest subgraph problem\nbetter than the standard peeling algorithm, by better accounting for how the\nremoval of one node affects other nodes in its neighborhood.",
    "descriptor": "",
    "authors": [
      "Nate Veldt",
      "Austin R. Benson",
      "Jon Kleinberg"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.00909"
  },
  {
    "id": "arXiv:2106.00910",
    "title": "Concurrent Learning Based Tracking Control of Nonlinear Systems using  Gaussian Process",
    "abstract": "This paper demonstrates the applicability of the combination of concurrent\nlearning as a tool for parameter estimation and non-parametric Gaussian Process\nfor online disturbance learning. A control law is developed by using both\ntechniques sequentially in the context of feedback linearization. The\nconcurrent learning algorithm estimates the system parameters of structured\nuncertainty without requiring persistent excitation, which are used in the\ndesign of the feedback linearization law. Then, a non-parametric Gaussian\nProcess learns unstructured uncertainty. The closed-loop system stability for\nthe nth-order system is proven using the Lyapunov stability theorem. The\nsimulation results show that the tracking error is minimized (i) when true\nvalues of model parameters have not been provided, (ii) in the presence of\ndisturbances introduced once the parameters have converged to their true values\nand (iii) when system parameters have not converged to their true values in the\npresence of disturbances.",
    "descriptor": "\nComments: 6 pages, 3 figures, conference paper\n",
    "authors": [
      "Vedant Bhandari",
      "Erkan Kayacan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00910"
  },
  {
    "id": "arXiv:2106.00912",
    "title": "Translational Symmetry-Aware Facade Parsing for 3D Building  Reconstruction",
    "abstract": "Effectively parsing the facade is essential to 3D building reconstruction,\nwhich is an important computer vision problem with a large amount of\napplications in high precision map for navigation, computer aided design, and\ncity generation for digital entertainments. To this end, the key is how to\nobtain the shape grammars from 2D images accurately and efficiently. Although\nenjoying the merits of promising results on the semantic parsing, deep learning\nmethods cannot directly make use of the architectural rules, which play an\nimportant role for man-made structures. In this paper, we present a novel\ntranslational symmetry-based approach to improving the deep neural networks.\nOur method employs deep learning models as the base parser, and a module taking\nadvantage of translational symmetry is used to refine the initial parsing\nresults. In contrast to conventional semantic segmentation or bounding box\nprediction, we propose a novel scheme to fuse segmentation with anchor-free\ndetection in a single stage network, which enables the efficient training and\nbetter convergence. After parsing the facades into shape grammars, we employ an\noff-the-shelf rendering engine like Blender to reconstruct the realistic\nhigh-quality 3D models using procedural modeling. We conduct experiments on\nthree public datasets, where our proposed approach outperforms the\nstate-of-the-art methods. In addition, we have illustrated the 3D building\nmodels built from 2D facade images.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Hantang Liu",
      "Wentong Li",
      "Jianke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00912"
  },
  {
    "id": "arXiv:2106.00918",
    "title": "Consumer Image Quality Prediction using Recurrent Neural Networks for  Spatial Pooling",
    "abstract": "Promising results for subjective image quality prediction have been achieved\nduring the past few years by using convolutional neural networks (CNN).\nHowever, the use of CNNs for high resolution image quality assessment remains a\nchallenge, since typical CNN architectures have been designed for small\nresolution input images. In this study, we propose an image quality model that\nattempts to mimic the attention mechanism of human visual system (HVS) by using\na recurrent neural network (RNN) for spatial pooling of the features extracted\nfrom different spatial areas (patches) by a deep CNN-based feature extractor.\nThe experimental study, conducted by using images with different resolutions\nfrom two recently published image quality datasets, indicates that the quality\nprediction accuracy of the proposed method is competitive against benchmark\nmodels representing the state-of-the-art, and the proposed method also performs\nconsistently on different resolution versions of the same dataset.",
    "descriptor": "",
    "authors": [
      "Jari Korhonen",
      "Yicheng Su",
      "Junyong You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00918"
  },
  {
    "id": "arXiv:2106.00920",
    "title": "DialoGraph: Incorporating Interpretable Strategy-Graph Networks into  Negotiation Dialogues",
    "abstract": "To successfully negotiate a deal, it is not enough to communicate fluently:\npragmatic planning of persuasive negotiation strategies is essential. While\nmodern dialogue agents excel at generating fluent sentences, they still lack\npragmatic grounding and cannot reason strategically. We present DialoGraph, a\nnegotiation system that incorporates pragmatic strategies in a negotiation\ndialogue using graph neural networks. DialoGraph explicitly incorporates\ndependencies between sequences of strategies to enable improved and\ninterpretable prediction of next optimal strategies, given the dialogue\ncontext. Our graph-based method outperforms prior state-of-the-art negotiation\nmodels both in the accuracy of strategy/dialogue act prediction and in the\nquality of downstream dialogue response generation. We qualitatively show\nfurther benefits of learned strategy-graphs in providing explicit associations\nbetween effective negotiation strategies over the course of the dialogue,\nleading to interpretable and strategic dialogues.",
    "descriptor": "\nComments: Accepted at ICLR 2021; this https URL\n",
    "authors": [
      "Rishabh Joshi",
      "Vidhisha Balachandran",
      "Shikhar Vashishth",
      "Alan Black",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00920"
  },
  {
    "id": "arXiv:2106.00922",
    "title": "An Empirical Comparison of Off-policy Prediction Learning Algorithms on  the Collision Task",
    "abstract": "Off-policy prediction -- learning the value function for one policy from data\ngenerated while following another policy -- is one of the most challenging\nsubproblems in reinforcement learning. This paper presents empirical results\nwith eleven prominent off-policy learning algorithms that use linear function\napproximation: five Gradient-TD methods, two Emphatic-TD methods, Off-policy\nTD($\\lambda$), Vtrace, and versions of Tree Backup and ABQ modified to apply to\na prediction setting. Our experiments used the Collision task, a small\nidealized off-policy problem analogous to that of an autonomous car trying to\npredict whether it will collide with an obstacle. We assessed the performance\nof the algorithms according to their learning rate, asymptotic error level, and\nsensitivity to step-size and bootstrapping parameters. By these measures, the\neleven algorithms can be partially ordered on the Collision task. In the top\ntier, the two Emphatic-TD algorithms learned the fastest, reached the lowest\nerrors, and were robust to parameter settings. In the middle tier, the five\nGradient-TD algorithms and Off-policy TD($\\lambda$) were more sensitive to the\nbootstrapping parameter. The bottom tier comprised Vtrace, Tree Backup, and\nABQ; these algorithms were no faster and had higher asymptotic error than the\nothers. Our results are definitive for this task, though of course experiments\nwith more tasks are needed before an overall assessment of the algorithms'\nmerits can be made.",
    "descriptor": "",
    "authors": [
      "Sina Ghiassian",
      "Richard S. Sutton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00922"
  },
  {
    "id": "arXiv:2106.00925",
    "title": "Contrastive ACE: Domain Generalization Through Alignment of Causal  Mechanisms",
    "abstract": "Domain generalization aims to learn knowledge invariant across different\ndistributions while semantically meaningful for downstream tasks from multiple\nsource domains, to improve the model's generalization ability on unseen target\ndomains. The fundamental objective is to understand the underlying \"invariance\"\nbehind these observational distributions and such invariance has been shown to\nhave a close connection to causality. While many existing approaches make use\nof the property that causal features are invariant across domains, we consider\nthe causal invariance of the average causal effect of the features to the\nlabels. This invariance regularizes our training approach in which\ninterventions are performed on features to enforce stability of the causal\nprediction by the classifier across domains. Our work thus sheds some light on\nthe domain generalization problem by introducing invariance of the mechanisms\ninto the learning process. Experiments on several benchmark datasets\ndemonstrate the performance of the proposed method against SOTAs.",
    "descriptor": "",
    "authors": [
      "Yunqi Wang",
      "Furui Liu",
      "Zhitang Chen",
      "Qing Lian",
      "Shoubo Hu",
      "Jianye Hao",
      "Yik-Chung Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00925"
  },
  {
    "id": "arXiv:2106.00926",
    "title": "A systematic mapping on quantum software development in the context of  software engineering",
    "abstract": "Quantum Computing is a new paradigm that enables several advances which are\nimpossible using classical technology. With the rise of quantum computers, the\nsoftware is also invited to change so that it can better fit this new\ncomputation way. However, although a lot of research is being conducted in the\nquantum computing field, it is still scarce studies about the differences of\nthe software and software engineering in this new context. Therefore, this\narticle presents a systematic mapping study to present a wide review on the\nparticularities and characteristics of software that are developed for quantum\ncomputers. A total of 24 papers were selected using digital libraries with the\nobjective of answering three research questions elaborated in the conduct of\nthis research.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Paulo Eduardo Zanni Junior",
      "Valter Vieira de Camargo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.00926"
  },
  {
    "id": "arXiv:2106.00931",
    "title": "Understanding the Design Space of Mouth Microgestures",
    "abstract": "As wearable devices move toward the face (i.e. smart earbuds, glasses), there\nis an increasing need to facilitate intuitive interactions with these devices.\nCurrent sensing techniques can already detect many mouth-based gestures;\nhowever, users' preferences of these gestures are not fully understood. In this\npaper, we investigate the design space and usability of mouth-based\nmicrogestures. We first conducted brainstorming sessions (N=16) and compiled an\nextensive set of 86 user-defined gestures. Then, with an online survey (N=50),\nwe assessed the physical and mental demand of our gesture set and identified a\nsubset of 14 gestures that can be performed easily and naturally. Finally, we\nconducted a remote Wizard-of-Oz usability study (N=11) mapping gestures to\nvarious daily smartphone operations under a sitting and walking context. From\nthese studies, we develop a taxonomy for mouth gestures, finalize a practical\ngesture set for common applications, and provide design guidelines for future\nmouth-based gesture interactions.",
    "descriptor": "\nComments: 14 page, 5 figures; Accepted to DIS 2021\n",
    "authors": [
      "Victor Chen",
      "Xuhai Xu",
      "Richard Li",
      "Yuanchun Shi",
      "Shwetak Patel",
      "Yuntao Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00931"
  },
  {
    "id": "arXiv:2106.00932",
    "title": "Proposed DBMS for OTT platforms in line with new age requirements",
    "abstract": "Database management has become an enormous tool for on-demand content\ndistribution services, proffering required information and providing custom\nservices to the user. Also plays a major role for the platforms to manage their\ndata in such a way that data redundancy is minimized. This paper emphasizes\nimproving the user experience for the platform by efficiently managing data.\nKeeping in mind all the new age requirements, especially after COVID-19 the\nsudden surge in subscription has led the stakeholders to try new things to lead\nthe OTT market. Collection of shows being the root of the tree here, this paper\nimprovises the currently existing branches via various tables and suggests some\nnew features on how the data collected can be utilized for introducing new and\nmuch-required query results for the consumer.",
    "descriptor": "",
    "authors": [
      "Khushi Shah",
      "Aryan Shah",
      "Charmi Shah",
      "Devansh Shah",
      "Mustafa Africawala",
      "Rushabh Shah",
      "Nishant Doshi"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.00932"
  },
  {
    "id": "arXiv:2106.00933",
    "title": "OntoGUM: Evaluating Contextualized SOTA Coreference Resolution on 12  More Genres",
    "abstract": "SOTA coreference resolution produces increasingly impressive scores on the\nOntoNotes benchmark. However lack of comparable data following the same scheme\nfor more genres makes it difficult to evaluate generalizability to open domain\ndata. This paper provides a dataset and comprehensive evaluation showing that\nthe latest neural LM based end-to-end systems degrade very substantially out of\ndomain. We make an OntoNotes-like coreference dataset called OntoGUM publicly\navailable, converted from GUM, an English corpus covering 12 genres, using\ndeterministic rules, which we evaluate. Thanks to the rich syntactic and\ndiscourse annotations in GUM, we are able to create the largest human-annotated\ncoreference corpus following the OntoNotes guidelines, and the first to be\nevaluated for consistency with the OntoNotes scheme. Out-of-domain evaluation\nacross 12 genres shows nearly 15-20% degradation for both deterministic and\ndeep learning systems, indicating a lack of generalizability or covert\noverfitting in existing coreference resolution models.",
    "descriptor": "",
    "authors": [
      "Yilun Zhu",
      "Sameer Pradhan",
      "Amir Zeldes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00933"
  },
  {
    "id": "arXiv:2106.00934",
    "title": "Discrete Cosine Transform as Universal Sentence Encoder",
    "abstract": "Modern sentence encoders are used to generate dense vector representations\nthat capture the underlying linguistic characteristics for a sequence of words,\nincluding phrases, sentences, or paragraphs. These kinds of representations are\nideal for training a classifier for an end task such as sentiment analysis,\nquestion answering and text classification. Different models have been proposed\nto efficiently generate general purpose sentence representations to be used in\npretraining protocols. While averaging is the most commonly used efficient\nsentence encoder, Discrete Cosine Transform (DCT) was recently proposed as an\nalternative that captures the underlying syntactic characteristics of a given\ntext without compromising practical efficiency compared to averaging. However,\nas with most other sentence encoders, the DCT sentence encoder was only\nevaluated in English. To this end, we utilize DCT encoder to generate universal\nsentence representation for different languages such as German, French, Spanish\nand Russian. The experimental results clearly show the superior effectiveness\nof DCT encoding in which consistent performance improvements are achieved over\nstrong baselines on multiple standardized datasets.",
    "descriptor": "\nComments: to be published in ACL-IJCNLP 2021\n",
    "authors": [
      "Nada Almarwani",
      "Mona Diab"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00934"
  },
  {
    "id": "arXiv:2106.00936",
    "title": "Least-Restrictive Multi-Agent Collision Avoidance via Deep Meta  Reinforcement Learning and Optimal Control",
    "abstract": "Multi-agent collision-free trajectory planning and control subject to\ndifferent goal requirements and system dynamics has been extensively studied,\nand is gaining recent attention in the realm of machine and reinforcement\nlearning. However, in particular when using a large number of agents,\nconstructing a least-restrictive collision avoidance policy is of utmost\nimportance for both classical and learning-based methods. In this paper, we\npropose a Least-Restrictive Collision Avoidance Module (LR-CAM) that evaluates\nthe safety of multi-agent systems and takes over control only when needed to\nprevent collisions. The LR-CAM is a single policy that can be wrapped around\npolicies of all agents in a multi-agent system. It allows each agent to pursue\nany objective as long as it is safe to do so. The benefit of the proposed\nleast-restrictive policy is to only interrupt and overrule the default\ncontroller in case of an upcoming inevitable danger. We use a Long Short-Term\nMemory (LSTM) based Variational Auto-Encoder (VAE) to enable the LR-CAM to\naccount for a varying number of agents in the environment. Moreover, we propose\nan off-policy meta-reinforcement learning framework with a novel reward\nfunction based on a Hamilton-Jacobi value function to train the LR-CAM. The\nproposed method is fully meta-trained through a ROS based simulation and tested\non real multi-agent system. Our results show that LR-CAM outperforms the\nclassical least-restrictive baseline by 30 percent. In addition, we show that\neven if a subset of agents in a multi-agent system use LR-CAM, the success rate\nof all agents will increase significantly.",
    "descriptor": "",
    "authors": [
      "Salar Asayesh",
      "Mo Chen",
      "Mehran Mehrandezh",
      "Kamal Gupta"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.00936"
  },
  {
    "id": "arXiv:2106.00937",
    "title": "Putting the Squeeze on Array Programs: Loop Verification via Inductive  Rank Reduction",
    "abstract": "Automatic verification of array manipulating programs is a challenging\nproblem because it often amounts to the inference of in ductive quantified loop\ninvariants which, in some cases, may not even be firstorder expressible. In\nthis paper, we suggest a novel verification tech nique that is based on\ninduction on userdefined rank of program states as an alternative to\nloopinvariants. Our technique, dubbed inductive rank reduction, works in two\nsteps. Firstly, we simplify the verification problem and prove that the program\nis correct when the input state con tains an input array of length B or less,\nusing the length of the array as the rank of the state. Secondly, we employ a\nsqueezing function g which converts a program state sigma with an array of\nlength > B to a state g(sigma) containing an array of length minus 1 or less.\nWe prove that when g satisfies certain natural conditions then if the program\nviolates its specification on sigma then it does so also on g(sigma). The\ncorrectness of the program on inputs with arrays of arbitrary lengths follows\nby induction. We make our technique automatic for array programs whose length\nof execution is proportional to the length of the input arrays by (i) perform\ning the first step using symbolic execution, (ii) verifying the conditions\nrequired of g using Z3, and (iii) providing a heuristic procedure for syn\nthesizing g. We implemented our technique and applied it successfully to\nseveral interesting arraymanipulating programs, including a bidirec tional\nsummation program whose loop invariant cannot be expressed in firstorder logic\nwhile its specification is quantifier free.",
    "descriptor": "",
    "authors": [
      "Oren Ish Shalom",
      "Shachar Itzhaky",
      "Noam Rinetzky",
      "Sharon Shoham"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.00937"
  },
  {
    "id": "arXiv:2106.00941",
    "title": "Self-Training Sampling with Monolingual Data Uncertainty for Neural  Machine Translation",
    "abstract": "Self-training has proven effective for improving NMT performance by\naugmenting model training with synthetic parallel data. The common practice is\nto construct synthetic data based on a randomly sampled subset of large-scale\nmonolingual data, which we empirically show is sub-optimal. In this work, we\npropose to improve the sampling procedure by selecting the most informative\nmonolingual sentences to complement the parallel data. To this end, we compute\nthe uncertainty of monolingual sentences using the bilingual dictionary\nextracted from the parallel data. Intuitively, monolingual sentences with lower\nuncertainty generally correspond to easy-to-translate patterns which may not\nprovide additional gains. Accordingly, we design an uncertainty-based sampling\nstrategy to efficiently exploit the monolingual data for self-training, in\nwhich monolingual sentences with higher uncertainty would be sampled with\nhigher probability. Experimental results on large-scale WMT\nEnglish$\\Rightarrow$German and English$\\Rightarrow$Chinese datasets demonstrate\nthe effectiveness of the proposed approach. Extensive analyses suggest that\nemphasizing the learning on uncertain monolingual sentences by our approach\ndoes improve the translation quality of high-uncertainty sentences and also\nbenefits the prediction of low-frequency words at the target side.",
    "descriptor": "\nComments: ACL 2021 main conference, long paper, 11 pages\n",
    "authors": [
      "Wenxiang Jiao",
      "Xing Wang",
      "Zhaopeng Tu",
      "Shuming Shi",
      "Michael R. Lyu",
      "Irwin King"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00941"
  },
  {
    "id": "arXiv:2106.00942",
    "title": "JUMBO: Scalable Multi-task Bayesian Optimization using Offline Data",
    "abstract": "The goal of Multi-task Bayesian Optimization (MBO) is to minimize the number\nof queries required to accurately optimize a target black-box function, given\naccess to offline evaluations of other auxiliary functions. When offline\ndatasets are large, the scalability of prior approaches comes at the expense of\nexpressivity and inference quality. We propose JUMBO, an MBO algorithm that\nsidesteps these limitations by querying additional data based on a combination\nof acquisition signals derived from training two Gaussian Processes (GP): a\ncold-GP operating directly in the input domain and a warm-GP that operates in\nthe feature space of a deep neural network pretrained using the offline data.\nSuch a decomposition can dynamically control the reliability of information\nderived from the online and offline data and the use of pretrained neural\nnetworks permits scalability to large offline datasets. Theoretically, we\nderive regret bounds for JUMBO and show that it achieves no-regret under\nconditions analogous to GP-UCB (Srinivas et. al. 2010). Empirically, we\ndemonstrate significant performance improvements over existing approaches on\ntwo real-world optimization problems: hyper-parameter optimization and\nautomated circuit design.",
    "descriptor": "",
    "authors": [
      "Kourosh Hakhamaneshi",
      "Pieter Abbeel",
      "Vladimir Stojanovic",
      "Aditya Grover"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00942"
  },
  {
    "id": "arXiv:2106.00943",
    "title": "A Topological Solution of Entanglement for Complex-shaped Parts in  Robotic Bin-picking",
    "abstract": "This paper addresses the problem of picking up only one object at a time\navoiding any entanglement in bin-picking. To cope with a difficult case where\nthe complex-shaped objects are heavily entangled together, we propose a\ntopology-based method that can generate non-tangle grasp positions on a single\ndepth image. The core technique is entanglement map, which is a feature map to\nmeasure the entanglement possibilities obtained from the input image. We use\nthe entanglement map to select probable regions containing graspable objects.\nThe optimum grasping pose is detected from the selected regions considering the\ncollision between robot hand and objects. Experimental results show that our\nanalytic method provides a more comprehensive and intuitive observation of\nentanglement and exceeds previous learning-based work in success rates.\nEspecially, our topology-based method does not rely on any object models or\ntime-consuming training process, so that it can be easily adapted to more\ncomplex bin-picking scenes.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Xinyi Zhang",
      "Keisuke Koyama",
      "Yukiyasu Domae",
      "Weiwei Wan",
      "Kensuke Harada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.00943"
  },
  {
    "id": "arXiv:2106.00948",
    "title": "Unsupervised Out-of-Domain Detection via Pre-trained Transformers",
    "abstract": "Deployed real-world machine learning applications are often subject to\nuncontrolled and even potentially malicious inputs. Those out-of-domain inputs\ncan lead to unpredictable outputs and sometimes catastrophic safety issues.\nPrior studies on out-of-domain detection require in-domain task labels and are\nlimited to supervised classification scenarios. Our work tackles the problem of\ndetecting out-of-domain samples with only unsupervised in-domain data. We\nutilize the latent representations of pre-trained transformers and propose a\nsimple yet effective method to transform features across all layers to\nconstruct out-of-domain detectors efficiently. Two domain-specific fine-tuning\napproaches are further proposed to boost detection accuracy. Our empirical\nevaluations of related methods on two datasets validate that our method greatly\nimproves out-of-domain detection ability in a more general scenario.",
    "descriptor": "\nComments: Accepted by ACL 2021. Code is available at this https URL\n",
    "authors": [
      "Keyang Xu",
      "Tongzheng Ren",
      "Shikun Zhang",
      "Yihao Feng",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00948"
  },
  {
    "id": "arXiv:2106.00950",
    "title": "A Multi-Level Attention Model for Evidence-Based Fact Checking",
    "abstract": "Evidence-based fact checking aims to verify the truthfulness of a claim\nagainst evidence extracted from textual sources. Learning a representation that\neffectively captures relations between a claim and evidence can be challenging.\nRecent state-of-the-art approaches have developed increasingly sophisticated\nmodels based on graph structures. We present a simple model that can be trained\non sequence structures. Our model enables inter-sentence attentions at\ndifferent levels and can benefit from joint training. Results on a large-scale\ndataset for Fact Extraction and VERification (FEVER) show that our model\noutperforms the graph-based approaches and yields 1.09% and 1.42% improvements\nin label accuracy and FEVER score, respectively, over the best published model.",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Canasai Kruengkrai",
      "Junichi Yamagishi",
      "Xin Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00950"
  },
  {
    "id": "arXiv:2106.00952",
    "title": "End-to-End Information Extraction by Character-Level Embedding and  Multi-Stage Attentional U-Net",
    "abstract": "Information extraction from document images has received a lot of attention\nrecently, due to the need for digitizing a large volume of unstructured\ndocuments such as invoices, receipts, bank transfers, etc. In this paper, we\npropose a novel deep learning architecture for end-to-end information\nextraction on the 2D character-grid embedding of the document, namely the\n\\textit{Multi-Stage Attentional U-Net}. To effectively capture the textual and\nspatial relations between 2D elements, our model leverages a specialized\nmulti-stage encoder-decoders design, in conjunction with efficient uses of the\nself-attention mechanism and the box convolution. Experimental results on\ndifferent datasets show that our model outperforms the baseline U-Net\narchitecture by a large margin while using 40\\% fewer parameters. Moreover, it\nalso significantly improved the baseline in erroneous OCR and limited training\ndata scenario, thus becomes practical for real-world applications.",
    "descriptor": "\nComments: Accepted to BMVC 2019\n",
    "authors": [
      "Tuan-Anh Nguyen Dang",
      "Dat-Thanh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.00952"
  },
  {
    "id": "arXiv:2106.00953",
    "title": "Convergence analysis of a Lagrangian numerical scheme in computing  effective diffusivity of 3D time-dependent flows",
    "abstract": "In this paper, we study the convergence analysis for a robust stochastic\nstructure-preserving Lagrangian numerical scheme in computing effective\ndiffusivity of time-dependent chaotic flows, which are modeled by stochastic\ndifferential equations (SDEs). Our numerical scheme is based on a splitting\nmethod to solve the corresponding SDEs in which the deterministic subproblem is\ndiscretized using structure-preserving schemes while the random subproblem is\ndiscretized using the Euler-Maruyama scheme. We obtain a sharp and\nuniform-in-time convergence analysis for the proposed numerical scheme that\nallows us to accurately compute long-time solutions of the SDEs. As such, we\ncan compute the effective diffusivity for time-dependent flows. Finally, we\npresent numerical results to demonstrate the accuracy and efficiency of the\nproposed method in computing effective diffusivity for the time-dependent\nArnold-Beltrami-Childress (ABC) flow and Kolmogorov flow in three-dimensional\nspace.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1808.06309\n",
    "authors": [
      "Zhongjian Wang",
      "Jack Xin",
      "Zhiwen Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00953"
  },
  {
    "id": "arXiv:2106.00954",
    "title": "When and Why does a Model Fail? A Human-in-the-loop Error Detection  Framework for Sentiment Analysis",
    "abstract": "Although deep neural networks have been widely employed and proven effective\nin sentiment analysis tasks, it remains challenging for model developers to\nassess their models for erroneous predictions that might exist prior to\ndeployment. Once deployed, emergent errors can be hard to identify in\nprediction run-time and impossible to trace back to their sources. To address\nsuch gaps, in this paper we propose an error detection framework for sentiment\nanalysis based on explainable features. We perform global-level feature\nvalidation with human-in-the-loop assessment, followed by an integration of\nglobal and local-level feature contribution analysis. Experimental results show\nthat, given limited human-in-the-loop intervention, our method is able to\nidentify erroneous model predictions on unseen data with high precision.",
    "descriptor": "\nComments: NAACL2021\n",
    "authors": [
      "Zhe Liu",
      "Yufan Guo",
      "Jalal Mahmud"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00954"
  },
  {
    "id": "arXiv:2106.00955",
    "title": "Answer Generation for Retrieval-based Question Answering Systems",
    "abstract": "Recent advancements in transformer-based models have greatly improved the\nability of Question Answering (QA) systems to provide correct answers; in\nparticular, answer sentence selection (AS2) models, core components of\nretrieval-based systems, have achieved impressive results. While generally\neffective, these models fail to provide a satisfying answer when all retrieved\ncandidates are of poor quality, even if they contain correct information. In\nAS2, models are trained to select the best answer sentence among a set of\ncandidates retrieved for a given question. In this work, we propose to generate\nanswers from a set of AS2 top candidates. Rather than selecting the best\ncandidate, we train a sequence to sequence transformer model to generate an\nanswer from a candidate set. Our tests on three English AS2 datasets show\nimprovement up to 32 absolute points in accuracy over the state of the art.",
    "descriptor": "\nComments: Short paper, Accepted at Findings of ACL 2021\n",
    "authors": [
      "Chao-Chun Hsu",
      "Eric Lind",
      "Luca Soldaini",
      "Alessandro Moschitti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00955"
  },
  {
    "id": "arXiv:2106.00957",
    "title": "RevCore: Review-augmented Conversational Recommendation",
    "abstract": "Existing conversational recommendation (CR) systems usually suffer from\ninsufficient item information when conducted on short dialogue history and\nunfamiliar items. Incorporating external information (e.g., reviews) is a\npotential solution to alleviate this problem. Given that reviews often provide\na rich and detailed user experience on different interests, they are potential\nideal resources for providing high-quality recommendations within an\ninformative conversation. In this paper, we design a novel end-to-end\nframework, namely, Review-augmented Conversational Recommender (RevCore), where\nreviews are seamlessly incorporated to enrich item information and assist in\ngenerating both coherent and informative responses. In detail, we extract\nsentiment-consistent reviews, perform review-enriched and entity-based\nrecommendations for item suggestions, as well as use a review-attentive\nencoder-decoder for response generation. Experimental results demonstrate the\nsuperiority of our approach in yielding better performance on both\nrecommendation and conversation responding.",
    "descriptor": "\nComments: Accepted by ACL-Findings 2021. 13 pages, 3 figures, and 10 tables\n",
    "authors": [
      "Yu Lu",
      "Junwei Bao",
      "Yan Song",
      "Zichen Ma",
      "Shuguang Cui",
      "Youzheng Wu",
      "Xiaodong He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00957"
  },
  {
    "id": "arXiv:2106.00958",
    "title": "A Generalizable Approach to Learning Optimizers",
    "abstract": "A core issue with learning to optimize neural networks has been the lack of\ngeneralization to real world problems. To address this, we describe a system\ndesigned from a generalization-first perspective, learning to update optimizer\nhyperparameters instead of model parameters directly using novel features,\nactions, and a reward function. This system outperforms Adam at all neural\nnetwork tasks including on modalities not seen during training. We achieve 2x\nspeedups on ImageNet, and a 2.5x speedup on a language modeling task using over\n5 orders of magnitude more compute than the training tasks.",
    "descriptor": "",
    "authors": [
      "Diogo Almeida",
      "Clemens Winter",
      "Jie Tang",
      "Wojciech Zaremba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00958"
  },
  {
    "id": "arXiv:2106.00961",
    "title": "Distributed Control-Estimation Synthesis for Stochastic Multi-Agent  Systems via Virtual Interaction between Non-neighboring Agents",
    "abstract": "This paper considers the optimal distributed control problem for a linear\nstochastic multi-agent system (MAS). Due to the distributed nature of MAS\nnetwork, the information available to an individual agent is limited to its\nvicinity. From the entire MAS aspect, this imposes the structural constraint on\nthe control law, making the optimal control law computationally intractable.\nThis paper attempts to relax such a structural constraint by expanding the\nneighboring information for each agent to the entire MAS, enabled by the\ndistributed estimation algorithm embedded in each agent. By exploiting the\nestimated information, each agent is not limited to interact with its\nneighborhood but further establishing the `virtual interactions' with the\nnon-neighboring agents. Then the optimal distributed MAS control problem is\ncast as a synthesized control-estimation problem. An iterative optimization\nprocedure is developed to find the control-estimation law, minimizing the\nglobal objective cost of MAS.",
    "descriptor": "\nComments: 13 pages, 5 figures, to be published in IEEE/Control Systems Letters (L-CSS) 2021\n",
    "authors": [
      "Hojin Lee",
      "Cheolhyeon Kwon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00961"
  },
  {
    "id": "arXiv:2106.00962",
    "title": "Convergent dynamics of optimal nonlinear damping control",
    "abstract": "Following Demidovich's concept and definition of convergent systems, we\nanalyze the optimal nonlinear damping control, recently proposed [1] for the\nsecond-order systems. Targeting the problem of output regulation,\ncorrespondingly tracking of $\\mathcal{C}^1$-trajectories, it is shown that all\nsolutions of the control system are globally uniformly asymptotically stable.\nThe existence of the unique limit solution in the origin of the control error\nand its time derivative coordinates are shown in the sense of Demidovich's\nconvergent dynamics. Explanative numerical examples are also provided along\nwith analysis.",
    "descriptor": "\nComments: 4 pages, 5 figures\n",
    "authors": [
      "Michael Ruderman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00962"
  },
  {
    "id": "arXiv:2106.00965",
    "title": "ALFRED: a methodology to enable component fault trees for layered  architectures",
    "abstract": "Identifying drawbacks or insufficiencies in terms of safety is important also\nin early development stages of safety critical systems. In industry,\ndevelopment artefacts such as components or units, are often reused from\nexisting artefacts to save time and costs. When development artefacts are\nreused, their existing safety analysis models are an important input for an\nearly safety assessment for the new system, since they already provide a valid\nmodel. Component fault trees support such reuse strategies by a compositional\nhorizontal approach. But current development strategies do not only divide\nsystems horizontally, e.g., By encapsulating different functionality into\nseparate components and hierarchies of components, but also vertically, e.g.\nInto software and hardware architecture layers. Current safety analysis\nmethodologies, such as component fault trees, do not support such vertical\nlayers. Therefore, we present here a methodology that is able to divide safety\nanalysis models into different layers of a systems architecture. We use so\ncalled Architecture Layer Failure Dependencies to enable component fault trees\non different layers of an architecture. These dependencies are then used to\ngenerate safety evidence for the entire system and over all different\narchitecture layers. A case study applies the approach to hardware and software\nlayers.",
    "descriptor": "",
    "authors": [
      "Kai Hoefig",
      "Marc Zeller",
      "Reiner Heilmann"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.00965"
  },
  {
    "id": "arXiv:2106.00966",
    "title": "Temporal Prophecy for Proving Temporal Properties of Infinite-State  Systems",
    "abstract": "Various verification techniques for temporal properties transform temporal\nverification to safety verification. For infinite-state systems, these\ntransformations are inherently imprecise. That is, for some instances, the\ntemporal property holds, but the resulting safety property does not. This paper\nintroduces a mechanism for tackling this imprecision. This mechanism, which we\ncall temporal prophecy, is inspired by prophecy variables. Temporal prophecy\nrefines an infinite-state system using first-order linear temporal logic\nformulas, via a suitable tableau construction. For a specific\nliveness-to-safety transformation based on first-order logic, we show that\nusing temporal prophecy strictly increases the precision. Furthermore, temporal\nprophecy leads to robustness of the proof method, which is manifested by a cut\nelimination theorem. We integrate our approach into the Ivy deductive\nverification system, and show that it can handle challenging temporal\nverification examples.",
    "descriptor": "\nComments: 11 pages, presented at FMCAD 2018\n",
    "authors": [
      "Oded Padon",
      "Jochen Hoenicke",
      "Kenneth L. McMillan",
      "Andreas Podelski",
      "Mooly Sagiv",
      "Sharon Shoham"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.00966"
  },
  {
    "id": "arXiv:2106.00967",
    "title": "Multiresolution Graph Variational Autoencoder",
    "abstract": "In this paper, we propose Multiresolution Graph Networks (MGN) and\nMultiresolution Graph Variational Autoencoders (MGVAE) to learn and generate\ngraphs in a multiresolution and equivariant manner. At each resolution level,\nMGN employs higher order message passing to encode the graph while learning to\npartition it into mutually exclusive clusters and coarsening into a lower\nresolution. MGVAE constructs a hierarchical generative model based on MGN to\nvariationally autoencode the hierarchy of coarsened graphs. Our proposed\nframework is end-to-end permutation equivariant with respect to node ordering.\nOur methods have been successful with several generative tasks including link\nprediction on citation graphs, unsupervised molecular representation learning\nto predict molecular properties, molecular generation, general graph generation\nand graph-based image generation.",
    "descriptor": "",
    "authors": [
      "Truong Son Hy",
      "Risi Kondor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00967"
  },
  {
    "id": "arXiv:2106.00969",
    "title": "COM2SENSE: A Commonsense Reasoning Benchmark with Complementary  Sentences",
    "abstract": "Commonsense reasoning is intuitive for humans but has been a long-term\nchallenge for artificial intelligence (AI). Recent advancements in pretrained\nlanguage models have shown promising results on several commonsense benchmark\ndatasets. However, the reliability and comprehensiveness of these benchmarks\ntowards assessing model's commonsense reasoning ability remains unclear. To\nthis end, we introduce a new commonsense reasoning benchmark dataset comprising\nnatural language true/false statements, with each sample paired with its\ncomplementary counterpart, resulting in 4k sentence pairs. We propose a\npairwise accuracy metric to reliably measure an agent's ability to perform\ncommonsense reasoning over a given situation. The dataset is crowdsourced and\nenhanced with an adversarial model-in-the-loop setup to incentivize challenging\nsamples. To facilitate a systematic analysis of commonsense capabilities, we\ndesign our dataset along the dimensions of knowledge domains, reasoning\nscenarios and numeracy. Experimental results demonstrate that our strongest\nbaseline (UnifiedQA-3B), after fine-tuning, achieves ~71% standard accuracy and\n~51% pairwise accuracy, well below human performance (~95% for both metrics).\nThe dataset is available at https://github.com/PlusLabNLP/Com2Sense.",
    "descriptor": "\nComments: In Proceedings of Findings of the Association for Computational Linguistics: ACL 2021 (ACL-Findings). Contains 16 pages, 14 figures and 11 tables\n",
    "authors": [
      "Shikhar Singh",
      "Nuan Wen",
      "Yu Hou",
      "Pegah Alipoormolabashi",
      "Te-Lin Wu",
      "Xuezhe Ma",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00969"
  },
  {
    "id": "arXiv:2106.00974",
    "title": "Meta model application for consistency management of models for avionic  systems design",
    "abstract": "This paper presents the application of a meta model and single underlying\nmodel on an applied avionics system design use case. System models, safety\nassurance cases and safety requirements are maintained in a central repository.\nThis enables to link these data which are originally developed in unrelated\ntools. By having such a central repository, traceability can be established,\nand consistency can be ensured, which leads to less errors and a shorter\ndevelopment time. A meta model was constructed which matches the central\nrepository to enable bidirectional synchronization with an external authoring\ntool.",
    "descriptor": "",
    "authors": [
      "Jef Stegen",
      "Stefan Dutre",
      "Joe Zhensheng Guo",
      "Marc Zeller",
      "Stefan Rothbauer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.00974"
  },
  {
    "id": "arXiv:2106.00976",
    "title": "Exploring Discourse Structures for Argument Impact Classification",
    "abstract": "Discourse relations among arguments reveal logical structures of a debate\nconversation. However, no prior work has explicitly studied how the sequence of\ndiscourse relations influence a claim's impact. This paper empirically shows\nthat the discourse relations between two arguments along the context path are\nessential factors for identifying the persuasive power of an argument. We\nfurther propose DisCOC to inject and fuse the sentence-level structural\ndiscourse information with contextualized features derived from large-scale\nlanguage models. Experimental results and extensive analysis show that the\nattention and gate mechanisms that explicitly model contexts and texts can\nindeed help the argument impact classification task defined by Durmus et al.\n(2019), and discourse structures among the context path of the claim to be\nclassified can further boost the performance.",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Xin Liu",
      "Jiefu Ou",
      "Yangqiu Song",
      "Xin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00976"
  },
  {
    "id": "arXiv:2106.00978",
    "title": "A Span Extraction Approach for Information Extraction on Visually-Rich  Documents",
    "abstract": "Information extraction (IE) from visually-rich documents (VRDs) has achieved\nSOTA performance recently thanks to the adaptation of Transformer-based\nlanguage models, which demonstrates great potential of pre-training methods. In\nthis paper, we present a new approach to improve the capability of language\nmodel pre-training on VRDs. Firstly, we introduce a new IE model that is\nquery-based and employs the span extraction formulation instead of the commonly\nused sequence labelling approach. Secondly, to further extend the span\nextraction formulation, we propose a new training task which focuses on\nmodelling the relationships between semantic entities within a document. This\ntask enables the spans to be extracted recursively and can be used as both a\npre-training objective as well as an IE downstream task. Evaluation on various\ndatasets of popular business documents (invoices, receipts) shows that our\nproposed method can improve the performance of existing models significantly,\nwhile providing a mechanism to accumulate model knowledge from multiple\ndownstream IE tasks.",
    "descriptor": "",
    "authors": [
      "Tuan-Anh D. Nguyen",
      "Hieu M. Vu",
      "Nguyen Hong Son",
      "Minh-Tien Nguyen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00978"
  },
  {
    "id": "arXiv:2106.00980",
    "title": "End-to-End Hierarchical Relation Extraction for Generic Form  Understanding",
    "abstract": "Form understanding is a challenging problem which aims to recognize semantic\nentities from the input document and their hierarchical relations. Previous\napproaches face significant difficulty dealing with the complexity of the task,\nthus treat these objectives separately. To this end, we present a novel deep\nneural network to jointly perform both entity detection and link prediction in\nan end-to-end fashion. Our model extends the Multi-stage Attentional U-Net\narchitecture with the Part-Intensity Fields and Part-Association Fields for\nlink prediction, enriching the spatial information flow with the additional\nsupervision from entity linking. We demonstrate the effectiveness of the model\non the Form Understanding in Noisy Scanned Documents (FUNSD) dataset, where our\nmethod substantially outperforms the original model and state-of-the-art\nbaselines in both Entity Labeling and Entity Linking task.",
    "descriptor": "\nComments: Accepted to ICPR 2020\n",
    "authors": [
      "Tuan-Anh Nguyen Dang",
      "Duc-Thanh Hoang",
      "Quang-Bach Tran",
      "Chih-Wei Pan",
      "Thanh-Dat Nguyen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00980"
  },
  {
    "id": "arXiv:2106.00982",
    "title": "A monolithic one-velocity-field optimal control formulation for  fluid-structure interaction problems with large solid deformation",
    "abstract": "In this article, we formulate a monolithic optimal control method for general\ntime-dependent Fluid-Structure Interaction (FSI) systems with large solid\ndeformation. We consider a displacement-tracking type of objective with a\nconstraint of the solid velocity, tackle the time-dependent control problems by\na piecewise-in-time control, cope with large solid displacement using a\none-velocity fictitious domain method, and solve the fully-coupled FSI and the\ncorresponding adjoint equations in a monolithic manner. We implement the\nproposed method in the open-source software package FreeFEM++ and assess it by\nthree numerical experiments, in the aspects of stability of the numerical\nscheme for different regularisation parameters, and efficiency of reducing the\nobjective function with control of the solid velocity.",
    "descriptor": "",
    "authors": [
      "Yongxing Wang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00982"
  },
  {
    "id": "arXiv:2106.00984",
    "title": "Few-Shot Partial-Label Learning",
    "abstract": "Partial-label learning (PLL) generally focuses on inducing a noise-tolerant\nmulti-class classifier by training on overly-annotated samples, each of which\nis annotated with a set of labels, but only one is the valid label. A basic\npromise of existing PLL solutions is that there are sufficient partial-label\n(PL) samples for training. However, it is more common than not to have just few\nPL samples at hand when dealing with new tasks. Furthermore, existing few-shot\nlearning algorithms assume precise labels of the support set; as such,\nirrelevant labels may seriously mislead the meta-learner and thus lead to a\ncompromised performance. How to enable PLL under a few-shot learning setting is\nan important problem, but not yet well studied. In this paper, we introduce an\napproach called FsPLL (Few-shot PLL). FsPLL first performs adaptive distance\nmetric learning by an embedding network and rectifying prototypes on the tasks\npreviously encountered. Next, it calculates the prototype of each class of a\nnew task in the embedding network. An unseen example can then be classified via\nits distance to each prototype. Experimental results on widely-used few-shot\ndatasets (Omniglot and miniImageNet) demonstrate that our FsPLL can achieve a\nsuperior performance than the state-of-the-art methods across different\nsettings, and it needs fewer samples for quickly adapting to new tasks.",
    "descriptor": "\nComments: Accepted by International Joint Conference on Artificial Intelligence (IJCAI2021)\n",
    "authors": [
      "Yunfeng Zhao",
      "Guoxian Yu",
      "Lei Liu",
      "Zhongmin Yan",
      "Lizhen Cui",
      "Carlotta Domeniconi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00984"
  },
  {
    "id": "arXiv:2106.00985",
    "title": "Feedback Network for Mutually Boosted Stereo Image Super-Resolution and  Disparity Estimation",
    "abstract": "Under stereo settings, the problem of image super-resolution (SR) and\ndisparity estimation are interrelated that the result of each problem could\nhelp to solve the other. The effective exploitation of correspondence between\ndifferent views facilitates the SR performance, while the high-resolution (HR)\nfeatures with richer details benefit the correspondence estimation. According\nto this motivation, we propose a Stereo Super-Resolution and Disparity\nEstimation Feedback Network (SSRDE-FNet), which simultaneously handles the\nstereo image super-resolution and disparity estimation in a unified framework\nand interact them with each other to further improve their performance.\nSpecifically, the SSRDE-FNet is composed of two dual recursive sub-networks for\nleft and right views. Besides the cross-view information exploitation in the\nlow-resolution (LR) space, HR representations produced by the SR process are\nutilized to perform HR disparity estimation with higher accuracy, through which\nthe HR features can be aggregated to generate a finer SR result. Afterward, the\nproposed HR Disparity Information Feedback (HRDIF) mechanism delivers\ninformation carried by HR disparity back to previous layers to further refine\nthe SR image reconstruction. Extensive experiments demonstrate the\neffectiveness and advancement of SSRDE-FNet.",
    "descriptor": "",
    "authors": [
      "Qinyan Dai",
      "Juncheng Li",
      "Qiaosi Yi",
      "Faming Fang",
      "Guixu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00985"
  },
  {
    "id": "arXiv:2106.00988",
    "title": "OctoPath: An OcTree Based Self-Supervised Learning Approach to Local  Trajectory Planning for Mobile Robots",
    "abstract": "Autonomous mobile robots are usually faced with challenging situations when\ndriving in complex environments. Namely, they have to recognize the static and\ndynamic obstacles, plan the driving path and execute their motion. For\naddressing the issue of perception and path planning, in this paper, we\nintroduce OctoPath , which is an encoder-decoder deep neural network, trained\nin a self-supervised manner to predict the local optimal trajectory for the\nego-vehicle. Using the discretization provided by a 3D octree environment\nmodel, our approach reformulates trajectory prediction as a classification\nproblem with a configurable resolution. During training, OctoPath minimizes the\nerror between the predicted and the manually driven trajectories in a given\ntraining dataset. This allows us to avoid the pitfall of regression-based\ntrajectory estimation, in which there is an infinite state space for the output\ntrajectory points. Environment sensing is performed using a 40-channel\nmechanical LiDAR sensor, fused with an inertial measurement unit and wheels\nodometry for state estimation. The experiments are performed both in simulation\nand real-life, using our own developed GridSim simulator and RovisLab's\nAutonomous Mobile Test Unit platform. We evaluate the predictions of OctoPath\nin different driving scenarios, both indoor and outdoor, while benchmarking our\nsystem against a baseline hybrid A-Star algorithm and a regression-based\nsupervised learning method, as well as against a CNN learning-based optimal\npath planning method.",
    "descriptor": "",
    "authors": [
      "Bogdan Trasnea",
      "Cosmin Ginerica",
      "Mihai Zaha",
      "Gigel Macesanu",
      "Claudiu Pozna",
      "Sorin Grigorescu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00988"
  },
  {
    "id": "arXiv:2106.00990",
    "title": "Sequence to General Tree: Knowledge-Guided Geometry Word Problem Solving",
    "abstract": "With the recent advancements in deep learning, neural solvers have gained\npromising results in solving math word problems. However, these SOTA solvers\nonly generate binary expression trees that contain basic arithmetic operators\nand do not explicitly use the math formulas. As a result, the expression trees\nthey produce are lengthy and uninterpretable because they need to use multiple\noperators and constants to represent one single formula. In this paper, we\npropose sequence-to-general tree (S2G) that learns to generate interpretable\nand executable operation trees where the nodes can be formulas with an\narbitrary number of arguments. With nodes now allowed to be formulas, S2G can\nlearn to incorporate mathematical domain knowledge into problem-solving, making\nthe results more interpretable. Experiments show that S2G can achieve a better\nperformance against strong baselines on problems that require domain knowledge.",
    "descriptor": "\nComments: ACL2021\n",
    "authors": [
      "Shih-hung Tsai",
      "Chao-Chun Liang",
      "Hsin-Min Wang",
      "Keh-Yih Su"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00990"
  },
  {
    "id": "arXiv:2106.00992",
    "title": "NVC-Net: End-to-End Adversarial Voice Conversion",
    "abstract": "Voice conversion has gained increasing popularity in many applications of\nspeech synthesis. The idea is to change the voice identity from one speaker\ninto another while keeping the linguistic content unchanged. Many voice\nconversion approaches rely on the use of a vocoder to reconstruct the speech\nfrom acoustic features, and as a consequence, the speech quality heavily\ndepends on such a vocoder. In this paper, we propose NVC-Net, an end-to-end\nadversarial network, which performs voice conversion directly on the raw audio\nwaveform of arbitrary length. By disentangling the speaker identity from the\nspeech content, NVC-Net is able to perform non-parallel traditional\nmany-to-many voice conversion as well as zero-shot voice conversion from a\nshort utterance of an unseen target speaker. Importantly, NVC-Net is\nnon-autoregressive and fully convolutional, achieving fast inference. Our model\nis capable of producing samples at a rate of more than 3600 kHz on an NVIDIA\nV100 GPU, being orders of magnitude faster than state-of-the-art methods under\nthe same hardware configurations. Objective and subjective evaluations on\nnon-parallel many-to-many voice conversion tasks show that NVC-Net obtains\ncompetitive results with significantly fewer parameters.",
    "descriptor": "",
    "authors": [
      "Bac Nguyen",
      "Fabien Cardinaux"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00992"
  },
  {
    "id": "arXiv:2106.00993",
    "title": "On the Convergence Rate of Off-Policy Policy Optimization Methods with  Density-Ratio Correction",
    "abstract": "In this paper, we study the convergence properties of off-policy policy\nimprovement algorithms with state-action density ratio correction under\nfunction approximation setting, where the objective function is formulated as a\nmax-max-min optimization problem. We characterize the bias of the learning\nobjective and present two strategies with finite-time convergence guarantees.\nIn our first strategy, we present algorithm P-SREDA with convergence rate\n$O(\\epsilon^{-3})$, whose dependency on $\\epsilon$ is optimal. In our second\nstrategy, we propose a new off-policy actor-critic style algorithm named\nO-SPIM. We prove that O-SPIM converges to a stationary point with total\ncomplexity $O(\\epsilon^{-4})$, which matches the convergence rate of some\nrecent actor-critic algorithms in the on-policy setting.",
    "descriptor": "\nComments: 47 Pages\n",
    "authors": [
      "Jiawei Huang",
      "Nan Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00993"
  },
  {
    "id": "arXiv:2106.00995",
    "title": "Energy-Efficient Model Compression and Splitting for Collaborative  Inference Over Time-Varying Channels",
    "abstract": "Today's intelligent applications can achieve high performance accuracy using\nmachine learning (ML) techniques, such as deep neural networks (DNNs).\nTraditionally, in a remote DNN inference problem, an edge device transmits raw\ndata to a remote node that performs the inference task. However, this may incur\nhigh transmission energy costs and puts data privacy at risk. In this paper, we\npropose a technique to reduce the total energy bill at the edge device by\nutilizing model compression and time-varying model split between the edge and\nremote nodes. The time-varying representation accounts for time-varying\nchannels and can significantly reduce the total energy at the edge device while\nmaintaining high accuracy (low loss). We implement our approach in an image\nclassification task using the MNIST dataset, and the system environment is\nsimulated as a trajectory navigation scenario to emulate different channel\nconditions. Numerical simulations show that our proposed solution results in\nminimal energy consumption and $CO_2$ emission compared to the considered\nbaselines while exhibiting robust performance across different channel\nconditions and bandwidth regime choices.",
    "descriptor": "",
    "authors": [
      "Mounssif Krouka",
      "Anis Elgabli",
      "Chaouki Ben Issaid",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00995"
  },
  {
    "id": "arXiv:2106.00999",
    "title": "Communication-Efficient Split Learning Based on Analog Communication and  Over the Air Aggregation",
    "abstract": "Split-learning (SL) has recently gained popularity due to its inherent\nprivacy-preserving capabilities and ability to enable collaborative inference\nfor devices with limited computational power. Standard SL algorithms assume an\nideal underlying digital communication system and ignore the problem of scarce\ncommunication bandwidth. However, for a large number of agents, limited\nbandwidth resources, and time-varying communication channels, the communication\nbandwidth can become the bottleneck. To address this challenge, in this work,\nwe propose a novel SL framework to solve the remote inference problem that\nintroduces an additional layer at the agent side and constrains the choices of\nthe weights and the biases to ensure over the air aggregation. Hence, the\nproposed approach maintains constant communication cost with respect to the\nnumber of agents enabling remote inference under limited bandwidth. Numerical\nresults show that our proposed algorithm significantly outperforms the digital\nimplementation in terms of communication-efficiency, especially as the number\nof agents grows large.",
    "descriptor": "",
    "authors": [
      "Mounssif Krouka",
      "Anis Elgabli",
      "Chaouki ben Issaid",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00999"
  },
  {
    "id": "arXiv:2106.01000",
    "title": "Tangential Errors of Tensor Surface Finite Elements",
    "abstract": "We discretize a tangential tensor field equation using a surface-finite\nelement approach with a penalization term to ensure almost tangentiality. It is\nnatural to measure the quality of such a discretization intrinsically, i.e., to\nexamine the tangential convergence behavior in contrast to the normal behavior.\nWe show optimal order convergence with respect to the tangential quantities in\nparticular for an isogeometric penalization term that is based only on the\ngeometric information of the discrete surface.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Hanne Hardering",
      "Simon Praetorius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01000"
  },
  {
    "id": "arXiv:2106.01001",
    "title": "Warming-up recurrent neural networks to maximize reachable  multi-stability greatly improves learning",
    "abstract": "Training recurrent neural networks is known to be difficult when time\ndependencies become long. Consequently, training standard gated cells such as\ngated recurrent units and long-short term memory on benchmarks where long-term\nmemory is required remains an arduous task. In this work, we propose a general\nway to initialize any recurrent network connectivity through a process called\n\"warm-up\" to improve its capability to learn arbitrarily long time\ndependencies. This initialization process is designed to maximize network\nreachable multi-stability, i.e. the number of attractors within the network\nthat can be reached through relevant input trajectories. Warming-up is\nperformed before training, using stochastic gradient descent on a specifically\ndesigned loss. We show that warming-up greatly improves recurrent neural\nnetwork performance on long-term memory benchmarks for multiple recurrent cell\ntypes, but can sometimes impede precision. We therefore introduce a parallel\nrecurrent network structure with partial warm-up that is shown to greatly\nimprove learning on long time-series while maintaining high levels of\nprecision. This approach provides a general framework for improving learning\nabilities of any recurrent cell type when long-term memory is required.",
    "descriptor": "",
    "authors": [
      "Nicolas Vecoven",
      "Damien Ernst",
      "Guillaume Drion"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01001"
  },
  {
    "id": "arXiv:2106.01006",
    "title": "SocAoG: Incremental Graph Parsing for Social Relation Inference in  Dialogues",
    "abstract": "Inferring social relations from dialogues is vital for building emotionally\nintelligent robots to interpret human language better and act accordingly. We\nmodel the social network as an And-or Graph, named SocAoG, for the consistency\nof relations among a group and leveraging attributes as inference cues.\nMoreover, we formulate a sequential structure prediction task, and propose an\n$\\alpha$-$\\beta$-$\\gamma$ strategy to incrementally parse SocAoG for the\ndynamic inference upon any incoming utterance: (i) an $\\alpha$ process\npredicting attributes and relations conditioned on the semantics of dialogues,\n(ii) a $\\beta$ process updating the social relations based on related\nattributes, and (iii) a $\\gamma$ process updating individual's attributes based\non interpersonal social relations. Empirical results on DialogRE and MovieGraph\nshow that our model infers social relations more accurately than the\nstate-of-the-art methods. Moreover, the ablation study shows the three\nprocesses complement each other, and the case study demonstrates the dynamic\nrelational inference.",
    "descriptor": "\nComments: Long paper accepted by ACL 2021\n",
    "authors": [
      "Liang Qiu",
      "Yuan Liang",
      "Yizhou Zhao",
      "Pan Lu",
      "Baolin Peng",
      "Zhou Yu",
      "Ying Nian Wu",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01006"
  },
  {
    "id": "arXiv:2106.01008",
    "title": "Convergence and Optimal Complexity of the Adaptive Planewave Method for  Eigenvalue Computations",
    "abstract": "In this paper, we study an adaptive planewave method for multiple eigenvalues\nof second-order elliptic partial equations. Inspired by the technique for the\nadaptive finite element analysis, we prove that the adaptive planewave method\nhas the linear convergence rate and optimal complexity.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Xiaoying Dai",
      "Yan Pan",
      "Bin Yang",
      "Aihui Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01008"
  },
  {
    "id": "arXiv:2106.01009",
    "title": "FedHealth 2: Weighted Federated Transfer Learning via Batch  Normalization for Personalized Healthcare",
    "abstract": "The success of machine learning applications often needs a large quantity of\ndata. Recently, federated learning (FL) is attracting increasing attention due\nto the demand for data privacy and security, especially in the medical field.\nHowever, the performance of existing FL approaches often deteriorates when\nthere exist domain shifts among clients, and few previous works focus on\npersonalization in healthcare. In this article, we propose FedHealth 2, an\nextension of FedHealth \\cite{chen2020fedhealth} to tackle domain shifts and get\npersonalized models for local clients. FedHealth 2 obtains the client\nsimilarities via a pretrained model, and then it averages all weighted models\nwith preserving local batch normalization. Wearable activity recognition and\nCOVID-19 auxiliary diagnosis experiments have evaluated that FedHealth 2 can\nachieve better accuracy (10%+ improvement for activity recognition) and\npersonalized healthcare without compromising privacy and security.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Yiqiang Chen",
      "Wang Lu",
      "Jindong Wang",
      "Xin Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01009"
  },
  {
    "id": "arXiv:2106.01013",
    "title": "Debate on Online Social Networks at the Time of COVID-19: An Italian  Case Study",
    "abstract": "The COVID-19 pandemic is not only having a heavy impact on healthcare but\nalso changing people's habits and the society we live in. Countries such as\nItaly have enforced a total lockdown lasting several months, with most of the\npopulation forced to remain at home. During this time, online social networks,\nmore than ever, have represented an alternative solution for social life,\nallowing users to interact and debate with each other. Hence, it is of\nparamount importance to understand the changing use of social networks brought\nabout by the pandemic. In this paper, we analyze how the interaction patterns\naround popular influencers in Italy changed during the first six months of\n2020, within Instagram and Facebook social networks. We collected a large\ndataset for this group of public figures, including more than 54 million\ncomments on over 140 thousand posts for these months. We analyze and compare\nengagement on the posts of these influencers and provide quantitative figures\nfor aggregated user activity. We further show the changes in the patterns of\nusage before and during the lockdown, which demonstrated a growth of activity\nand sizable daily and weekly variations. We also analyze the user sentiment\nthrough the psycholinguistic properties of comments, and the results testified\nthe rapid boom and disappearance of topics related to the pandemic. To support\nfurther analyses, we release the anonymized dataset.",
    "descriptor": "",
    "authors": [
      "Martino Trevisan",
      "Luca Vassio",
      "Danilo Giordano"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.01013"
  },
  {
    "id": "arXiv:2106.01016",
    "title": "Deep Reinforcement Learning-based UAV Navigation and Control: A Soft  Actor-Critic with Hindsight Experience Replay Approach",
    "abstract": "In this paper, we propose SACHER (soft actor-critic (SAC) with hindsight\nexperience replay (HER)), which constitutes a class of deep reinforcement\nlearning (DRL) algorithms. SAC is known as an off-policy model-free DRL\nalgorithm based on the maximum entropy framework, which outperforms earlier DRL\nalgorithms in terms of exploration, robustness and learning performance.\nHowever, in SAC, maximizing the entropy-augmented objective may degrade the\noptimality of the learning outcomes. HER is known as a sample-efficient replay\nmethod that enhances the performance of off-policy DRL algorithms by allowing\nthem to learn from both failures and successes. We apply HER to SAC and propose\nSACHER to improve the learning performance of SAC. More precisely, SACHER\nachieves the desired optimal outcomes faster and more accurately than SAC,\nsince HER improves the sample efficiency of SAC. We apply SACHER to the\nnavigation and control problem of unmanned aerial vehicles (UAVs), where SACHER\ngenerates the optimal navigation path of the UAV under various obstacles in\noperation. Specifically, we show the effectiveness of SACHER in terms of the\ntracking error and cumulative reward in UAV operation by comparing them with\nthose of state-of-the-art DRL algorithms, SAC and DDPG. Note that SACHER in UAV\nnavigation and control problems can be applied to arbitrary models of UAVs.",
    "descriptor": "\nComments: 12 page, 9 figures\n",
    "authors": [
      "Myoung Hoon Lee",
      "Jun Moon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.01016"
  },
  {
    "id": "arXiv:2106.01019",
    "title": "Simple Economies are Almost Optimal",
    "abstract": "Consider a seller that intends to auction some item. The seller can invest\nmoney and effort in advertising in different market segments in order to\nrecruit $n$ bidders to the auction. Alternatively, the seller can have a much\ncheaper and focused marketing operation and recruit the same number of bidders\nfrom a single market segment. Which marketing operation should the seller\nchoose?\nMore formally, let $D=\\{\\mathcal D_1,\\ldots, \\mathcal D_n\\}$ be a set of\ndistributions. Our main result shows that there is always $\\mathcal D_i\\in D$\nsuch that the revenue that can be extracted from $n$ bidders, where the value\nof each is independently drawn from $\\mathcal D_i$, is at least $\\frac 1 2\n\\cdot (1-\\frac 1 e)$ of the revenue that can be obtained by any possible mix of\nbidders, where the value of each bidder is drawn from some (possibly different)\ndistribution that belongs to $D$.\nWe next consider situations in which the auctioneer cannot use the optimal\nauction and is required to use a second price auction. We show that there is\nalways $\\mathcal D_i\\in D$ such that if the value of all bidders is\nindependently drawn from $\\mathcal D_i$ then running a second price auction\nguarantees a constant fraction of the revenue that can be obtained by a\nsecond-price auction by any possible mix of bidders. Finally, we show that for\nany $\\varepsilon>0$ there exists a function $f$ that depends only on\n$\\varepsilon$ (in particular, the function does not depend on $n$ or on the set\n$D$), such that recruiting $n$ bidders which have at most $f(\\varepsilon)$\ndifferent distributions, all from $D$, guarantees $(1-\\varepsilon)$-fraction of\nthe revenue that can be obtained by a second-price auction by any possible mix\nof bidders.",
    "descriptor": "",
    "authors": [
      "Amir Ban",
      "Avi Cohen",
      "Shahar Dobzinski",
      "Itai Ashlagi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01019"
  },
  {
    "id": "arXiv:2106.01021",
    "title": "Decision-making Oriented Clustering: Application to Pricing and Power  Consumption Scheduling",
    "abstract": "Data clustering is an instrumental tool in the area of energy resource\nmanagement. One problem with conventional clustering is that it does not take\nthe final use of the clustered data into account, which may lead to a very\nsuboptimal use of energy or computational resources. When clustered data are\nused by a decision-making entity, it turns out that significant gains can be\nobtained by tailoring the clustering scheme to the final task performed by the\ndecision-making entity. The key to having good final performance is to\nautomatically extract the important attributes of the data space that are\ninherently relevant to the subsequent decision-making entity, and partition the\ndata space based on these attributes instead of partitioning the data space\nbased on predefined conventional metrics. For this purpose, we formulate the\nframework of decision-making oriented clustering and propose an algorithm\nproviding a decision-based partition of the data space and good representative\ndecisions. By applying this novel framework and algorithm to a typical problem\nof real-time pricing and that of power consumption scheduling, we obtain\nseveral insightful analytical results such as the expression of the best\nrepresentative price profiles for real-time pricing and a very significant\nreduction in terms of required clusters to perform power consumption scheduling\nas shown by our simulations.",
    "descriptor": "\nComments: Published in Applied Energy\n",
    "authors": [
      "Chao Zhang",
      "Samson Lasaulce",
      "Martin Hennebel",
      "Lucas Saludjian",
      "Patrick Panciatici",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01021"
  },
  {
    "id": "arXiv:2106.01023",
    "title": "One Teacher is Enough? Pre-trained Language Model Distillation from  Multiple Teachers",
    "abstract": "Pre-trained language models (PLMs) achieve great success in NLP. However,\ntheir huge model sizes hinder their applications in many practical systems.\nKnowledge distillation is a popular technique to compress PLMs, which learns a\nsmall student model from a large teacher PLM. However, the knowledge learned\nfrom a single teacher may be limited and even biased, resulting in low-quality\nstudent model. In this paper, we propose a multi-teacher knowledge distillation\nframework named MT-BERT for pre-trained language model compression, which can\ntrain high-quality student model from multiple teacher PLMs. In MT-BERT we\ndesign a multi-teacher co-finetuning method to jointly finetune multiple\nteacher PLMs in downstream tasks with shared pooling and prediction layers to\nalign their output space for better collaborative teaching. In addition, we\npropose a multi-teacher hidden loss and a multi-teacher distillation loss to\ntransfer the useful knowledge in both hidden states and soft labels from\nmultiple teacher PLMs to the student model. Experiments on three benchmark\ndatasets validate the effectiveness of MT-BERT in compressing PLMs.",
    "descriptor": "\nComments: Findings of ACL-IJCNLP 2021\n",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01023"
  },
  {
    "id": "arXiv:2106.01024",
    "title": "Why Machine Reading Comprehension Models Learn Shortcuts?",
    "abstract": "Recent studies report that many machine reading comprehension (MRC) models\ncan perform closely to or even better than humans on benchmark datasets.\nHowever, existing works indicate that many MRC models may learn shortcuts to\noutwit these benchmarks, but the performance is unsatisfactory in real-world\napplications. In this work, we attempt to explore, instead of the expected\ncomprehension skills, why these models learn the shortcuts. Based on the\nobservation that a large portion of questions in current datasets have shortcut\nsolutions, we argue that larger proportion of shortcut questions in training\ndata make models rely on shortcut tricks excessively. To investigate this\nhypothesis, we carefully design two synthetic datasets with annotations that\nindicate whether a question can be answered using shortcut solutions. We\nfurther propose two new methods to quantitatively analyze the learning\ndifficulty regarding shortcut and challenging questions, and revealing the\ninherent learning mechanism behind the different performance between the two\nkinds of questions. A thorough empirical analysis shows that MRC models tend to\nlearn shortcut questions earlier than challenging questions, and the high\nproportions of shortcut questions in training sets hinder models from exploring\nthe sophisticated reasoning skills in the later stage of training.",
    "descriptor": "\nComments: 13 pages, 8 figures, ACL 2021 (findings)\n",
    "authors": [
      "Yuxuan Lai",
      "Chen Zhang",
      "Yansong Feng",
      "Quzhe Huang",
      "Dongyan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01024"
  },
  {
    "id": "arXiv:2106.01028",
    "title": "A Hypergraph Convolutional Neural Network for Molecular Properties  Prediction using Functional Group",
    "abstract": "We propose a Molecular Hypergraph Convolutional Network (MolHGCN) that\npredicts the molecular properties of a molecule using the atom and functional\ngroup information as inputs. Molecules can contain many types of functional\ngroups, which will affect the properties the molecules. For example, the\ntoxicity of a molecule is associated with toxicophores, such as nitroaromatic\ngroups and thiourea. Conventional graph-based methods that consider the\npair-wise interactions between nodes are inefficient in expressing the complex\nrelationship between multiple nodes in a graph flexibly, and applying\nmulti-hops may result in oversmoothing and overfitting problems. Hence, we\npropose MolHGCN to capture the substructural difference between molecules using\nthe atom and functional group information. MolHGCN constructs a hypergraph\nrepresentation of a molecule using functional group information from the input\nSMILES strings, extracts hidden representation using a two-stage message\npassing process (atom and functional group message passing), and predicts the\nproperties of the molecules using the extracted hidden representation. We\nevaluate the performance of our model using Tox21, ClinTox, SIDER, BBBP, BACE,\nESOL, FreeSolv and Lipophilicity datasets. We show that our model is able to\noutperform other baseline methods for most of the datasets. We particularly\nshow that incorporating functional group information along with atom\ninformation results in better separability in the latent space, thus increasing\nthe prediction accuracy of the molecule property prediction.",
    "descriptor": "\nComments: 9 pages, 9 figures\n",
    "authors": [
      "Fangying Chen",
      "Junyoung Park",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.01028"
  },
  {
    "id": "arXiv:2106.01030",
    "title": "Some Complexity Results for Stateful Network Verification",
    "abstract": "In modern networks, forwarding of packets often depends on the history of\npreviously transmitted traffic. Such networks contain stateful middleboxes,\nwhose forwarding behaviour depends on a mutable internal state. Firewalls and\nload balancers are typical examples of stateful middleboxes.\nThis work addresses the complexity of verifying safety properties, such as\nisolation, in networks with finite-state middleboxes. Unfortunately, we show\nthat even in the absence of forwarding loops, reasoning about such networks is\nundecidable due to interactions between middleboxes connected by unbounded\nordered channels. We therefore abstract away channel ordering. This abstraction\nis sound for safety, and makes the problem decidable. Specifically, safety\nchecking becomes EXPSPACE-complete in the number of hosts and middleboxes in\nthe network. To tackle the high complexity, we identify two useful subclasses\nof finite-state middleboxes which admit better complexities. The simplest class\nincludes, e.g., firewalls and permits polynomial-time verification. The second\nclass includes, e.g., cache servers and learning switches, and makes the safety\nproblem coNP-complete.\nFinally, we implement a tool for verifying the correctness of stateful\nnetworks.",
    "descriptor": "\nComments: This is a pre-print of an article published in Formal Methods in System Design. The final authenticated version is available online at: this https URL\n",
    "authors": [
      "Kalev Alpernas",
      "Aurojit Panda",
      "Alexander Rabinovich",
      "Mooly Sagiv",
      "Scott Shenker",
      "Sharon Shoham",
      "Yaron Velner"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.01030"
  },
  {
    "id": "arXiv:2106.01033",
    "title": "Who Blames or Endorses Whom? Entity-to-Entity Directed Sentiment  Extraction in News Text",
    "abstract": "Understanding who blames or supports whom in news text is a critical research\nquestion in computational social science. Traditional methods and datasets for\nsentiment analysis are, however, not suitable for the domain of political text\nas they do not consider the direction of sentiments expressed between entities.\nIn this paper, we propose a novel NLP task of identifying directed sentiment\nrelationship between political entities from a given news document, which we\ncall directed sentiment extraction. From a million-scale news corpus, we\nconstruct a dataset of news sentences where sentiment relations of political\nentities are manually annotated. We present a simple but effective approach for\nutilizing a pretrained transformer, which infers the target class by predicting\nmultiple question-answering tasks and combining the outcomes. We demonstrate\nthe utility of our proposed method for social science research questions by\nanalyzing positive and negative opinions between political entities in two\nmajor events: 2016 U.S. presidential election and COVID-19. The newly proposed\nproblem, data, and method will facilitate future studies on interdisciplinary\nNLP methods and applications.",
    "descriptor": "\nComments: To appear at ACL-IJCNLP 2021 (Long paper, Findings)\n",
    "authors": [
      "Kunwoo Park",
      "Zhufeng Pan",
      "Jungseock Joo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.01033"
  },
  {
    "id": "arXiv:2106.01034",
    "title": "Deficit Round-Robin: A Second Network Calculus Analysis",
    "abstract": "Deficit Round-Robin (DRR) is a widespread scheduling algorithm that provides\nfair queueing with variable-length packets. Bounds on worst-case delays for DRR\nwere found by Boyer et al., who used a rigorous network calculus approach and\ncharacterized the service obtained by one flow of interest by means of a convex\nstrict service curve. These bounds do not make any assumptions on the\ninterfering traffic hence are pessimistic when the interfering traffic is\nconstrained by some arrival curves. For such cases, two improvements were\nproposed. The former, by Soni et al., uses a correction term derived from a\nsemi-rigorous heuristic; unfortunately, these bounds are incorrect, as we show\nby exhibiting a counter-example. The latter, by Bouillard, rigorously derive\nconvex strict service curves for DRR that account for the arrival curve\nconstraints of the interfering traffic. In this paper, we improve on these\nresults in two ways. First, we derive a non-convex strict service curve for DRR\nthat improves on Boyer et al. when there is no arrival constraint on the\ninterfering traffic. Second, we provide an iterative method to improve any\nstrict service curve (including Bouillard's) when there are arrival constraints\nfor the interfering traffic. As of today, our results provide the best-known\nworst-case delay bounds for DRR. They are obtained by using the method of the\npseudo-inverse.",
    "descriptor": "",
    "authors": [
      "Seyed Mohammadhossein Tabatabaee",
      "Jean-Yves Le Boudec"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2106.01034"
  },
  {
    "id": "arXiv:2106.01035",
    "title": "Towards Unified Surgical Skill Assessment",
    "abstract": "Surgical skills have a great influence on surgical safety and patients'\nwell-being. Traditional assessment of surgical skills involves strenuous manual\nefforts, which lacks efficiency and repeatability. Therefore, we attempt to\nautomatically predict how well the surgery is performed using the surgical\nvideo. In this paper, a unified multi-path framework for automatic surgical\nskill assessment is proposed, which takes care of multiple composing aspects of\nsurgical skills, including surgical tool usage, intraoperative event pattern,\nand other skill proxies. The dependency relationships among these different\naspects are specially modeled by a path dependency module in the framework. We\nconduct extensive experiments on the JIGSAWS dataset of simulated surgical\ntasks, and a new clinical dataset of real laparoscopic surgeries. The proposed\nframework achieves promising results on both datasets, with the\nstate-of-the-art on the simulated dataset advanced from 0.71 Spearman's\ncorrelation to 0.80. It is also shown that combining multiple skill aspects\nyields better performance than relying on a single aspect.",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Daochang Liu",
      "Qiyue Li",
      "Tingting Jiang",
      "Yizhou Wang",
      "Rulin Miao",
      "Fei Shan",
      "Ziyu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01035"
  },
  {
    "id": "arXiv:2106.01036",
    "title": "Ultra-Sparse Near-Additive Emulators",
    "abstract": "Near-additive (aka $(1+\\epsilon,\\beta)$-) emulators and spanners are a\nfundamental graph-algorithmic construct, with numerous applications for\ncomputing approximate shortest paths and related problems in distributed,\nstreaming and dynamic settings.\nKnown constructions of near-additive emulators enable one to trade between\ntheir sparsity (i.e., number of edges) and the additive stretch $\\beta$.\nSpecifically, for any pair of parameters $\\epsilon >0$, $ \\kappa=1,2,\\dots$,\none can have a $(1+\\epsilon,\\beta)$-emulator with $O(n^{1+1/\\kappa})$ edges,\nwith $\\beta = \\left(\\frac{\\log \\kappa}{\\epsilon}\\right)^{\\log \\kappa}$. At\ntheir sparsest, these emulators employ $c\\cdot n$ edges, for some constant\n$c\\geq 2$.\nWe tighten this bound, and show that in fact precisely $n^{1+1/\\kappa}$ edges\nsuffice.\nIn particular, our emulators can be \\emph{ultra-sparse}, i.e., we can have an\nemulator with $n+o(n)$ edges and $\\beta = \\left(\\frac{\\log {\\log n}}{\\epsilon\n}\\right)^{{\\log {\\log n}}(1+o(1))}$.\nWe also devise a distributed deterministic algorithm in the CONGEST model\nthat builds these emulators in low polynomial time (i.e., in $O(n^\\rho)$ time,\nfor an arbitrarily small constant parameter $\\rho >0$).\nFinally, we also improve the state-of-the-art distributed deterministic\n\\congest-model construction of\n$(1+\\epsilon,\\beta)$-spanners devised in the PODC'19 paper\n[ElkinM19]. Specifically, the spanners of [ElkinM19] have $O(\\beta\\cdot\nn^{1+1/\\kappa})$ edges, i.e., at their sparsest they employ\n$ O\\left(\\frac{\\log {\\log n}}{\\epsilon }\\right)^{{\\log {\\log n}}}\\cdot n$\nedges. In this paper, we devise an efficient distributed deterministic\nCONGEST-model algorithm that builds such spanners with $O(n^{1+1/\\kappa})$\nedges for $\\kappa = O\\left(\\frac{\\log n}{\\log ^{(3)}n}\\right)$. At their\nsparsest, these spanners employ only $O(n\\cdot {\\log {\\log n}})$ edges.",
    "descriptor": "",
    "authors": [
      "Michael Elkin",
      "Shaked Matar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.01036"
  },
  {
    "id": "arXiv:2106.01040",
    "title": "Hi-Transformer: Hierarchical Interactive Transformer for Efficient and  Effective Long Document Modeling",
    "abstract": "Transformer is important for text modeling. However, it has difficulty in\nhandling long documents due to the quadratic complexity with input text length.\nIn order to handle this problem, we propose a hierarchical interactive\nTransformer (Hi-Transformer) for efficient and effective long document\nmodeling. Hi-Transformer models documents in a hierarchical way, i.e., first\nlearns sentence representations and then learns document representations. It\ncan effectively reduce the complexity and meanwhile capture global document\ncontext in the modeling of each sentence. More specifically, we first use a\nsentence Transformer to learn the representations of each sentence. Then we use\na document Transformer to model the global document context from these sentence\nrepresentations. Next, we use another sentence Transformer to enhance sentence\nmodeling using the global document context. Finally, we use hierarchical\npooling method to obtain document embedding. Extensive experiments on three\nbenchmark datasets validate the efficiency and effectiveness of Hi-Transformer\nin long document modeling.",
    "descriptor": "\nComments: ACL-IJCNLP 2021\n",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Tao Qi",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01040"
  },
  {
    "id": "arXiv:2106.01043",
    "title": "Causal Discovery in Knowledge Graphs by Exploiting Asymmetric Properties  of Non-Gaussian Distributions",
    "abstract": "In recent years, causal modelling has been used widely to improve\ngeneralization and to provide interpretability in machine learning models. To\ndetermine cause-effect relationships in the absence of a randomized trial, we\ncan model causal systems with counterfactuals and interventions given enough\ndomain knowledge. However, there are several cases where domain knowledge is\nalmost absent and the only recourse is using a statistical method to estimate\ncausal relationships. While there have been several works done in estimating\ncausal relationships in unstructured data, we are yet to find a well-defined\nframework for estimating causal relationships in Knowledge Graphs (KG). It is\ncommonly used to provide a semantic framework for data with complex\ninter-domain relationships. In this work, we define a hybrid approach that\nallows us to discover cause-effect relationships in KG. The proposed approach\nis based around the finding of the instantaneous causal structure of a\nnon-experimental matrix using a non-Gaussian model, i.e; finding the causal\nordering of the variables in a non-Gaussian setting. The non-experimental\nmatrix is a low-dimensional tensor projection obtained by decomposing the\nadjacency tensor of a KG. We use two different pre-existing algorithms, one for\nthe causal discovery and the other for decomposing the KG and combining them to\nget the causal structure in a KG.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Rohan Giriraj",
      "Sinnu Susan Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01043"
  },
  {
    "id": "arXiv:2106.01044",
    "title": "Examining the Inductive Bias of Neural Language Models with Artificial  Languages",
    "abstract": "Since language models are used to model a wide variety of languages, it is\nnatural to ask whether the neural architectures used for the task have\ninductive biases towards modeling particular types of languages. Investigation\nof these biases has proved complicated due to the many variables that appear in\nthe experimental setup. Languages vary in many typological dimensions, and it\nis difficult to single out one or two to investigate without the others acting\nas confounders. We propose a novel method for investigating the inductive\nbiases of language models using artificial languages. These languages are\nconstructed to allow us to create parallel corpora across languages that differ\nonly in the typological feature being investigated, such as word order. We then\nuse them to train and test language models. This constitutes a fully controlled\ncausal framework, and demonstrates how grammar engineering can serve as a\nuseful tool for analyzing neural models. Using this method, we find that\ncommonly used neural architectures exhibit different inductive biases: LSTMs\ndisplay little preference with respect to word ordering, while transformers\ndisplay a clear preference for some orderings over others. Further, we find\nthat neither the inductive bias of the LSTM nor that of the transformer appears\nto reflect any tendencies that we see in attested natural languages.",
    "descriptor": "\nComments: Accepted at ACL 2021\n",
    "authors": [
      "Jennifer C. White",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01044"
  },
  {
    "id": "arXiv:2106.01045",
    "title": "Cascade versus Direct Speech Translation: Do the Differences Still Make  a Difference?",
    "abstract": "Five years after the first published proofs of concept, direct approaches to\nspeech translation (ST) are now competing with traditional cascade solutions.\nIn light of this steady progress, can we claim that the performance gap between\nthe two is closed? Starting from this question, we present a systematic\ncomparison between state-of-the-art systems representative of the two\nparadigms. Focusing on three language directions\n(English-German/Italian/Spanish), we conduct automatic and manual evaluations,\nexploiting high-quality professional post-edits and annotations. Our\nmulti-faceted analysis on one of the few publicly available ST benchmarks\nattests for the first time that: i) the gap between the two paradigms is now\nclosed, and ii) the subtle differences observed in their behavior are not\nsufficient for humans neither to distinguish them nor to prefer one over the\nother.",
    "descriptor": "\nComments: Accepted at ACL2021\n",
    "authors": [
      "Luisa Bentivogli",
      "Mauro Cettolo",
      "Marco Gaido",
      "Alina Karakanta",
      "Alberto Martinelli",
      "Matteo Negri",
      "Marco Turchi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01045"
  },
  {
    "id": "arXiv:2106.01048",
    "title": "Expected Scalarised Returns Dominance: A New Solution Concept for  Multi-Objective Decision Making",
    "abstract": "In many real-world scenarios, the utility of a user is derived from the\nsingle execution of a policy. In this case, to apply multi-objective\nreinforcement learning, the expected utility of the returns must be optimised.\nVarious scenarios exist where a user's preferences over objectives (also known\nas the utility function) are unknown or difficult to specify. In such\nscenarios, a set of optimal policies must be learned. However, settings where\nthe expected utility must be maximised have been largely overlooked by the\nmulti-objective reinforcement learning community and, as a consequence, a set\nof optimal solutions has yet to be defined. In this paper we address this\nchallenge by proposing first-order stochastic dominance as a criterion to build\nsolution sets to maximise expected utility. We also propose a new dominance\ncriterion, known as expected scalarised returns (ESR) dominance, that extends\nfirst-order stochastic dominance to allow a set of optimal policies to be\nlearned in practice. We then define a new solution concept called the ESR set,\nwhich is a set of policies that are ESR dominant. Finally, we define a new\nmulti-objective distributional tabular reinforcement learning (MOT-DRL)\nalgorithm to learn the ESR set in a multi-objective multi-armed bandit setting.",
    "descriptor": "",
    "authors": [
      "Conor F. Hayes",
      "Timothy Verstraeten",
      "Diederik M. Roijers",
      "Enda Howley",
      "Patrick Mannion"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01048"
  },
  {
    "id": "arXiv:2106.01051",
    "title": "Minimax and Neyman-Pearson Meta-Learning for Outlier Languages",
    "abstract": "Model-agnostic meta-learning (MAML) has been recently put forth as a strategy\nto learn resource-poor languages in a sample-efficient fashion. Nevertheless,\nthe properties of these languages are often not well represented by those\navailable during training. Hence, we argue that the i.i.d. assumption ingrained\nin MAML makes it ill-suited for cross-lingual NLP. In fact, under a\ndecision-theoretic framework, MAML can be interpreted as minimising the\nexpected risk across training languages (with a uniform prior), which is known\nas Bayes criterion. To increase its robustness to outlier languages, we create\ntwo variants of MAML based on alternative criteria: Minimax MAML reduces the\nmaximum risk across languages, while Neyman-Pearson MAML constrains the risk in\neach language to a maximum threshold. Both criteria constitute fully\ndifferentiable two-player games. In light of this, we propose a new adaptive\noptimiser solving for a local approximation to their Nash equilibrium. We\nevaluate both model variants on two popular NLP tasks, part-of-speech tagging\nand question answering. We report gains for their average and minimum\nperformance across low-resource languages in zero- and few-shot settings,\ncompared to joint multi-source transfer and vanilla MAML.",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Edoardo Maria Ponti",
      "Rahul Aralikatte",
      "Disha Shrivastava",
      "Siva Reddy",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01051"
  },
  {
    "id": "arXiv:2106.01053",
    "title": "The Seventh International Olympiad in Cryptography NSUCRYPTO: problems  and solutions",
    "abstract": "The International Olympiad in Cryptography NSUCRYPTO is the unique Olympiad\ncontaining scientific mathematical problems for professionals, school and\nuniversity students from any country. Its aim is to involve young researchers\nin solving curious and tough scientific problems of modern cryptography. In\n2020, it was held for the seventh time. Prizes and diplomas were awarded to 84\nparticipants in the first round and 49 teams in the second round from 32\ncountries. In this paper, problems and their solutions of NSUCRYPTO'2020 are\npresented. We consider problems related to attacks on ciphers and hash\nfunctions, protocols, permutations, primality tests, etc. We discuss several\nopen problems on JPEG encoding, Miller -- Rabin primality test, special bases\nin the vector space, AES-GCM. The problem of a modified Miller -- Rabin\nprimality test was solved during the Olympiad. The problem for finding special\nbases was partially solved.",
    "descriptor": "",
    "authors": [
      "A. Gorodilova",
      "N. Tokareva",
      "S. Agievich",
      "C. Carlet",
      "V. Idrisova",
      "K. Kalgin",
      "D. Kolegov",
      "A. Kutsenko",
      "N. Mouha",
      "M. Pudovkina",
      "A. Udovenko"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.01053"
  },
  {
    "id": "arXiv:2106.01055",
    "title": "A Novel Edge Detection Operator for Identifying Buildings in Augmented  Reality Applications",
    "abstract": "Augmented Reality is an environment-enhancing technology, widely applied in\nmany domains, such as tourism and culture. One of the major challenges in this\nfield is precise detection and extraction of building information through\nComputer Vision techniques. Edge detection is one of the building blocks\noperations for many feature extraction solutions in Computer Vision. AR systems\nuse edge detection for building extraction or for extraction of facade details\nfrom buildings. In this paper, we propose a novel filter operator for edge\ndetection that aims to extract building contours or facade features better. The\nproposed filter gives more weight for finding vertical and horizontal edges\nthat is an important feature for our aim.",
    "descriptor": "",
    "authors": [
      "Ciprian Orhei",
      "Silviu Vert",
      "Radu Vasiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01055"
  },
  {
    "id": "arXiv:2106.01056",
    "title": "Comparison of Random Sampling and Heuristic Optimization-Based Methods  for Determining the Flexibility Potential at Vertical System Interconnections",
    "abstract": "In order to prevent conflicting or counteracting use of flexibility options,\nthe coordination between distribution system operator and transmission system\noperator has to be strengthened. For this purpose, methods for the standardized\ndescription and identification of the aggregated flexibility potential of\ndistribution grids are developed. Approaches for identifying the feasible\noperation region (FOR) of distribution grids can be categorized into two main\nclasses: Random sampling/stochastic approaches and optimization-based\napproaches. While the latter have the advantage of working in real-world\nscenarios where no full grid models exist, when relying on naive sampling\nstrategies, they suffer from poor coverage of the edges of the FOR due to\nconvoluted distributions. In this paper, we tackle the problem from two\ndifferent angles. First, we present a random sampling approach which mitigates\nthe convolution problem by drawing sample values from a multivariate Dirichlet\ndistribution. Second, we come up with a hybrid approach which solves the\nunderlying optimal power flow problems of the optimization-based approach by\nmeans of a stochastic evolutionary optimization algorithm codenamed REvol. By\nmeans of synthetic feeders, we compare the two proposed FOR identification\nmethods with regard to how well the FOR is covered and number of power flow\ncalculations required.",
    "descriptor": "\nComments: 9pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2102.03430\n",
    "authors": [
      "Gerster Johannes",
      "Marcel Sarstedt",
      "Eric MSP Veith",
      "Sebastian Lehnhoff",
      "Lutz Hofmann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01056"
  },
  {
    "id": "arXiv:2106.01060",
    "title": "John praised Mary because he? Implicit Causality Bias and Its  Interaction with Explicit Cues in LMs",
    "abstract": "Some interpersonal verbs can implicitly attribute causality to either their\nsubject or their object and are therefore said to carry an implicit causality\n(IC) bias. Through this bias, causal links can be inferred from a narrative,\naiding language comprehension. We investigate whether pre-trained language\nmodels (PLMs) encode IC bias and use it at inference time. We find that to be\nthe case, albeit to different degrees, for three distinct PLM architectures.\nHowever, causes do not always need to be implicit -- when a cause is explicitly\nstated in a subordinate clause, an incongruent IC bias associated with the verb\nin the main clause leads to a delay in human processing. We hypothesize that\nthe temporary challenge humans face in integrating the two contradicting\nsignals, one from the lexical semantics of the verb, one from the\nsentence-level semantics, would be reflected in higher error rates for models\non tasks dependent on causal links. The results of our study lend support to\nthis hypothesis, suggesting that PLMs tend to prioritize lexical patterns over\nhigher-order signals.",
    "descriptor": "\nComments: To appear at Findings of ACL 2021\n",
    "authors": [
      "Yova Kementchedjhieva",
      "Mark Anderson",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01060"
  },
  {
    "id": "arXiv:2106.01061",
    "title": "Rethinking Cross-modal Interaction from a Top-down Perspective for  Referring Video Object Segmentation",
    "abstract": "Referring video object segmentation (RVOS) aims to segment video objects with\nthe guidance of natural language reference. Previous methods typically tackle\nRVOS through directly grounding linguistic reference over the image lattice.\nSuch bottom-up strategy fails to explore object-level cues, easily leading to\ninferior results. In this work, we instead put forward a two-stage, top-down\nRVOS solution. First, an exhaustive set of object tracklets is constructed by\npropagating object masks detected from several sampled frames to the entire\nvideo. Second, a Transformer-based tracklet-language grounding module is\nproposed, which models instance-level visual relations and cross-modal\ninteractions simultaneously and efficiently. Our model ranks first place on\nCVPR2021 Referring Youtube-VOS challenge.",
    "descriptor": "",
    "authors": [
      "Chen Liang",
      "Yu Wu",
      "Tianfei Zhou",
      "Wenguan Wang",
      "Zongxin Yang",
      "Yunchao Wei",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01061"
  },
  {
    "id": "arXiv:2106.01062",
    "title": "Hilbert's spacefilling curve described by automatic, regular, and  synchronized sequences",
    "abstract": "We describe Hilbert's spacefilling curve in several different ways: as an\nautomatic sequence of directions,as a regular and synchronized sequence of\ncoordinates of lattice points encountered, and as an automatic bitmap image.",
    "descriptor": "",
    "authors": [
      "Jeffrey Shallit"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.01062"
  },
  {
    "id": "arXiv:2106.01063",
    "title": "Tolerance in Model-Driven Engineering: A Systematic Literature Review  with Model-Driven Tool Support",
    "abstract": "Managing models in a consistent manner is an important task in the field of\nModel-Driven Engineering (MDE). Although restoring and maintaining consistency\nis desired in general, recent work has pointed out that always strictly\nenforcing consistency at any point of time is often not feasible in real-world\nscenarios, and sometimes even contrary to what a user expects from a\ntrustworthy MDE tool. The challenge of tolerating inconsistencies has been\ndiscussed from different viewpoints within and outside the modelling community,\nbut there exists no structured overview of existing and current work in this\nregard. In this paper, we provide such an overview to help join forces tackling\nthe unresolved problems of tolerating inconsistencies in MDE. We follow the\nstandard process of a Systematic Literature Review (SLR) to point out what\ntolerance means, how it relates to uncertainty, which examples for tolerant\nsoftware systems have already been discussed, and which benefits and drawbacks\ntolerating inconsistencies entails. Furthermore, we propose a tool-chain that\nhelps conducting SLRs in computer science and also eases the reproduction of\nresults. Relevant meta-data of the collected sources is uniformly described in\na textual modelling language and exported to the graph database Neo4j to query\naggregated information.",
    "descriptor": "",
    "authors": [
      "Nils Weidmann",
      "Suganya Kannan",
      "Anthony Anjorin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.01063"
  },
  {
    "id": "arXiv:2106.01064",
    "title": "Generating Informative Conclusions for Argumentative Texts",
    "abstract": "The purpose of an argumentative text is to support a certain conclusion. Yet,\nthey are often omitted, expecting readers to infer them rather. While\nappropriate when reading an individual text, this rhetorical device limits\naccessibility when browsing many texts (e.g., on a search engine or on social\nmedia). In these scenarios, an explicit conclusion makes for a good candidate\nsummary of an argumentative text. This is especially true if the conclusion is\ninformative, emphasizing specific concepts from the text. With this paper we\nintroduce the task of generating informative conclusions: First,\nWebis-ConcluGen-21 is compiled, a large-scale corpus of 136,996 samples of\nargumentative texts and their conclusions. Second, two paradigms for conclusion\ngeneration are investigated; one extractive, the other abstractive in nature.\nThe latter exploits argumentative knowledge that augment the data via control\ncodes and finetuning the BART model on several subsets of the corpus. Third,\ninsights are provided into the suitability of our corpus for the task, the\ndifferences between the two generation paradigms, the trade-off between\ninformativeness and conciseness, and the impact of encoding argumentative\nknowledge. The corpus, code, and the trained models are publicly available.",
    "descriptor": "",
    "authors": [
      "Shahbaz Syed",
      "Khalid Al-Khatib",
      "Milad Alshomary",
      "Henning Wachsmuth",
      "Martin Potthast"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01064"
  },
  {
    "id": "arXiv:2106.01065",
    "title": "Towards Robustness of Text-to-SQL Models against Synonym Substitution",
    "abstract": "Recently, there has been significant progress in studying neural networks to\ntranslate text descriptions into SQL queries. Despite achieving good\nperformance on some public benchmarks, existing text-to-SQL models typically\nrely on the lexical matching between words in natural language (NL) questions\nand tokens in table schemas, which may render the models vulnerable to attacks\nthat break the schema linking mechanism. In this work, we investigate the\nrobustness of text-to-SQL models to synonym substitution. In particular, we\nintroduce Spider-Syn, a human-curated dataset based on the Spider benchmark for\ntext-to-SQL translation. NL questions in Spider-Syn are modified from Spider,\nby replacing their schema-related words with manually selected synonyms that\nreflect real-world question paraphrases. We observe that the accuracy\ndramatically drops by eliminating such explicit correspondence between NL\nquestions and table schemas, even if the synonyms are not adversarially\nselected to conduct worst-case adversarial attacks. Finally, we present two\ncategories of approaches to improve the model robustness. The first category of\napproaches utilizes additional synonym annotations for table schemas by\nmodifying the model input, while the second category is based on adversarial\ntraining. We demonstrate that both categories of approaches significantly\noutperform their counterparts without the defense, and the first category of\napproaches are more effective.",
    "descriptor": "\nComments: To appear in ACL 2021\n",
    "authors": [
      "Yujian Gan",
      "Xinyun Chen",
      "Qiuping Huang",
      "Matthew Purver",
      "John R. Woodward",
      "Jinxia Xie",
      "Pengsheng Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01065"
  },
  {
    "id": "arXiv:2106.01071",
    "title": "Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion  Detection",
    "abstract": "Emotion detection in dialogues is challenging as it often requires the\nidentification of thematic topics underlying a conversation, the relevant\ncommonsense knowledge, and the intricate transition patterns between the\naffective states. In this paper, we propose a Topic-Driven Knowledge-Aware\nTransformer to handle the challenges above. We firstly design a topic-augmented\nlanguage model (LM) with an additional layer specialized for topic detection.\nThe topic-augmented LM is then combined with commonsense statements derived\nfrom a knowledge base based on the dialogue contextual information. Finally, a\ntransformer-based encoder-decoder architecture fuses the topical and\ncommonsense information, and performs the emotion label sequence prediction.\nThe model has been experimented on four datasets in dialogue emotion detection,\ndemonstrating its superiority empirically over the existing state-of-the-art\napproaches. Quantitative and qualitative results show that the model can\ndiscover topics which help in distinguishing emotion categories.",
    "descriptor": "",
    "authors": [
      "Lixing Zhu",
      "Gabriele Pergola",
      "Lin Gui",
      "Deyu Zhou",
      "Yulan He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01071"
  },
  {
    "id": "arXiv:2106.01072",
    "title": "Evidence-based Factual Error Correction",
    "abstract": "This paper introduces the task of factual error correction: performing edits\nto a claim so that the generated rewrite is better supported by evidence. This\nextends the well-studied task of fact verification by providing a mechanism to\ncorrect written texts that are refuted or only partially supported by evidence.\nWe demonstrate that it is feasible to train factual error correction systems\nfrom existing fact checking datasets which only contain labeled claims\naccompanied by evidence, but not the correction. We achieve this by employing a\ntwo-stage distant supervision approach that incorporates evidence into masked\nclaims when generating corrections. Our approach, based on the T5 transformer\nand using retrieved evidence, achieved better results than existing work which\nused a pointer copy network and gold evidence, producing accurate factual error\ncorrections for 5x more instances in human evaluation and a .125 increase in\nSARI score. The evaluation is conducted on a dataset of 65,000 instances based\non a recent fact verification shared task and we release it to enable further\nwork on the task.",
    "descriptor": "\nComments: To appear at ACL2021. arXiv admin note: text overlap with arXiv:2012.15788\n",
    "authors": [
      "James Thorne",
      "Andreas Vlachos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01072"
  },
  {
    "id": "arXiv:2106.01074",
    "title": "Database Reasoning Over Text",
    "abstract": "Neural models have shown impressive performance gains in answering queries\nfrom natural language text. However, existing works are unable to support\ndatabase queries, such as \"List/Count all female athletes who were born in 20th\ncentury\", which require reasoning over sets of relevant facts with operations\nsuch as join, filtering and aggregation. We show that while state-of-the-art\ntransformer models perform very well for small databases, they exhibit\nlimitations in processing noisy data, numerical operations, and queries that\naggregate facts. We propose a modular architecture to answer these\ndatabase-style queries over multiple spans from text and aggregating these at\nscale. We evaluate the architecture using WikiNLDB, a novel dataset for\nexploring such queries. Our architecture scales to databases containing\nthousands of facts whereas contemporary models are limited by how many facts\ncan be encoded. In direct comparison on small databases, our approach increases\noverall answer accuracy from 85% to 90%. On larger databases, our approach\nretains its accuracy whereas transformer baselines could not encode the\ncontext.",
    "descriptor": "\nComments: To appear at ACL2021\n",
    "authors": [
      "James Thorne",
      "Majid Yazdani",
      "Marzieh Saeidi",
      "Fabrizio Silvestri",
      "Sebastian Riedel",
      "Alon Halevy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.01074"
  },
  {
    "id": "arXiv:2106.01077",
    "title": "SyGNS: A Systematic Generalization Testbed Based on Natural Language  Semantics",
    "abstract": "Recently, deep neural networks (DNNs) have achieved great success in\nsemantically challenging NLP tasks, yet it remains unclear whether DNN models\ncan capture compositional meanings, those aspects of meaning that have been\nlong studied in formal semantics. To investigate this issue, we propose a\nSystematic Generalization testbed based on Natural language Semantics (SyGNS),\nwhose challenge is to map natural language sentences to multiple forms of\nscoped meaning representations, designed to account for various semantic\nphenomena. Using SyGNS, we test whether neural networks can systematically\nparse sentences involving novel combinations of logical expressions such as\nquantifiers and negation. Experiments show that Transformer and GRU models can\ngeneralize to unseen combinations of quantifiers, negations, and modifiers that\nare similar to given training instances in form, but not to the others. We also\nfind that the generalization performance to unseen combinations is better when\nthe form of meaning representations is simpler. The data and code for SyGNS are\npublicly available at https://github.com/verypluming/SyGNS.",
    "descriptor": "\nComments: Findings (long paper) of ACL-IJCNLP2021\n",
    "authors": [
      "Hitomi Yanaka",
      "Koji Mineshima",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01077"
  },
  {
    "id": "arXiv:2106.01078",
    "title": "KO-PDE: Kernel Optimized Discovery of Partial Differential Equations  with Varying Coefficients",
    "abstract": "Partial differential equations (PDEs) fitting scientific data can represent\nphysical laws with explainable mechanisms for various mathematically-oriented\nsubjects. Most natural dynamics are expressed by PDEs with varying coefficients\n(PDEs-VC), which highlights the importance of PDE discovery. Previous\nalgorithms can discover some simple instances of PDEs-VC but fail in the\ndiscovery of PDEs with coefficients of higher complexity, as a result of\ncoefficient estimation inaccuracy. In this paper, we propose KO-PDE, a kernel\noptimized regression method that incorporates the kernel density estimation of\nadjacent coefficients to reduce the coefficient estimation error. KO-PDE can\ndiscover PDEs-VC on which previous baselines fail and is more robust against\ninevitable noise in data. In experiments, the PDEs-VC of seven challenging\nspatiotemporal scientific datasets in fluid dynamics are all discovered by\nKO-PDE, while the three baselines render false results in most cases. With\nstate-of-the-art performance, KO-PDE sheds light on the automatic description\nof natural phenomenons using discovered PDEs in the real world.",
    "descriptor": "\nComments: Preprint. Under review\n",
    "authors": [
      "Yingtao Luo",
      "Qiang Liu",
      "Yuntian Chen",
      "Wenbo Hu",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01078"
  },
  {
    "id": "arXiv:2106.01079",
    "title": "Using Predicted Weights for Ad Delivery",
    "abstract": "We study the performance of a proportional weights algorithm for online\ncapacitated bipartite matching modeling the delivery of impression ads. The\nalgorithm uses predictions on the advertiser nodes to match arriving impression\nnodes fractionally in proportion to the weights of its neighbors. This paper\ngives a thorough empirical study of the performance of the algorithm on a\ndata-set of ad impressions from Yahoo! and shows its superior performance\ncompared to natural baselines such as a greedy water-filling algorithm and the\nranking algorithm. The proportional weights algorithm has recently received\ninterest in the theoretical literature where it was shown to have strong\nguarantees beyond the worst-case model of algorithms augmented with\npredictions. We extend these results to the case where the advertisers'\ncapacities are no longer stationary over time. Additionally, we show the\nalgorithm has near optimal performance in the random-order arrival model when\nthe number of impressions and the optimal matching are sufficiently large.",
    "descriptor": "\nComments: 15 pages, 10 figures. To appear in ACDA 2021\n",
    "authors": [
      "Thomas Lavastida",
      "Benjamin Moseley",
      "R. Ravi",
      "Chenyang Xu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.01079"
  },
  {
    "id": "arXiv:2106.01080",
    "title": "Comparison of Convexificated SQCQP and PSO for the Optimal Transmission  System Operation based on Incremental In-Phase and Quadrature Voltage  Controlled Transformers",
    "abstract": "The optimal operation of electrical energy systems by solving a security\nconstrained optimal power flow (SCOPF) problem is still a challenging research\naspect. Especially, for conventional optimization methods like sequential\nquadratic constrained quadratic programming (SQCQP) the formulation of the\nincremental control variables like in-phase and quadrature voltage controlled\ntransformers in a solver suitable way is complex. Compared to this, the\nimplementation of these control variables within heuristic approaches like the\nparticle swarm optimization (PSO) is simple but problem specific adaptations of\nthe classic PSO algorithm are necessary to avoid an unfortunate swarm behavior\nand local convergence in bad results. The objective of this paper is to\nintroduce a SQCQP and a modified PSO approach in detail to solve the SCOPF\nproblem adequately under consideration of flexible incremental in-phase and\nquadrature transformers tap sets and to compare and benchmark the results of\nboth approaches for an adapted IEEE 118-bus system. The casestudy shows that\nboth approaches lead to suitable results of the SCOPF with individual\nadvantages of the SQCQP concerning the quality and the reproducibility of the\nresults while the PSO lead to faster solutions when the complexity of the\ninvestigation scenario increases.",
    "descriptor": "\nComments: 8 pager, 7 figures, conference, under review\n",
    "authors": [
      "Marcel Sarstedt",
      "Thomas Leveringhaus",
      "Leonard Klu\u00df",
      "Lutz Hofmann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01080"
  },
  {
    "id": "arXiv:2106.01083",
    "title": "The data paper as a socio-linguistic epistemic object: A content  analysis on the rhetorical moves used in data paper abstracts",
    "abstract": "The data paper is an emerging academic genre that focuses on the description\nof research data objects. However, there is a lack of empirical knowledge about\nthis rising genre in quantitative science studies, particularly from the\nperspective of its linguistic features. To fill this gap, this research aims to\noffer a first quantitative examination of which rhetorical moves-rhetorical\nunits performing a coherent narrative function-are used in data paper\nabstracts, as well as how these moves are used. To this end, we developed a new\nclassification scheme for rhetorical moves in data paper abstracts by expanding\na well-received system that focuses on English-language research article\nabstracts. We used this expanded scheme to classify and analyze rhetorical\nmoves used in two flagship data journals, Scientific Data and Data in Brief. We\nfound that data papers exhibit a combination of IMRaD- and data-oriented moves\nand that the usage differences between the journals can be largely explained by\njournal policies concerning abstract and paper structure. This research offers\na novel examination of how the data paper, a novel data-oriented knowledge\nrepresentation, is composed, which greatly contributes to a deeper\nunderstanding of data and data publication in the scholarly communication\nsystem.",
    "descriptor": "",
    "authors": [
      "Kai Li",
      "Chenyue Jiao"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.01083"
  },
  {
    "id": "arXiv:2106.01084",
    "title": "Asymptotic Characterisation of Regularised Zero-Forcing Receiver for  Imperfect and Correlated Massive MIMO Systems with Optimal Power Allocation",
    "abstract": "In this paper, we present asymptotic high dimensional analysis of the\nregularised zero-forcing (RZF) receiver in terms of its mean squared error\n(MSE) and bit error rate (BER) when used for the recovery of binary phase shift\nkeying (BPSK) modulated signals in a massive multiple-input multiple-output\n(MIMO) communication system. We assume that the channel matrix is spatially\ncorrelated and not perfectly known. We use the linear minimum mean squared\nerror (LMMSE) method to estimate the channel matrix. The asymptotic\napproximations of the MSE and BER enable us to solve various practical\noptimisation problems. Under MSE/BER minimisation, we derive 1) the optimal\nregularisation factor for RZF; 2) the optimal power allocation scheme.\nNumerical simulations show a close match to the derived asymptotic results even\nfor a few dozens of the problem dimensions.",
    "descriptor": "",
    "authors": [
      "Ayed M. Alrashsi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.01084"
  },
  {
    "id": "arXiv:2106.01085",
    "title": "Online Coreset Selection for Rehearsal-based Continual Learning",
    "abstract": "A dataset is a shred of crucial evidence to describe a task. However, each\ndata point in the dataset does not have the same potential, as some of the data\npoints can be more representative or informative than others. This unequal\nimportance among the data points may have a large impact in rehearsal-based\ncontinual learning, where we store a subset of the training examples (coreset)\nto be replayed later to alleviate catastrophic forgetting. In continual\nlearning, the quality of the samples stored in the coreset directly affects the\nmodel's effectiveness and efficiency. The coreset selection problem becomes\neven more important under realistic settings, such as imbalanced continual\nlearning or noisy data scenarios. To tackle this problem, we propose Online\nCoreset Selection (OCS), a simple yet effective method that selects the most\nrepresentative and informative coreset at each iteration and trains them in an\nonline manner. Our proposed method maximizes the model's adaptation to a target\ndataset while selecting high-affinity samples to past tasks, which directly\ninhibits catastrophic forgetting. We validate the effectiveness of our coreset\nselection mechanism over various standard, imbalanced, and noisy datasets\nagainst strong continual learning baselines, demonstrating that it improves\ntask adaptation and prevents catastrophic forgetting in a sample-efficient\nmanner.",
    "descriptor": "",
    "authors": [
      "Jaehong Yoon",
      "Divyam Madaan",
      "Eunho Yang",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01085"
  },
  {
    "id": "arXiv:2106.01086",
    "title": "Learning to schedule job-shop problems: Representation and policy  learning using graph neural network and reinforcement learning",
    "abstract": "We propose a framework to learn to schedule a job-shop problem (JSSP) using a\ngraph neural network (GNN) and reinforcement learning (RL). We formulate the\nscheduling process of JSSP as a sequential decision-making problem with graph\nrepresentation of the state to consider the structure of JSSP. In solving the\nformulated problem, the proposed framework employs a GNN to learn that node\nfeatures that embed the spatial structure of the JSSP represented as a graph\n(representation learning) and derive the optimum scheduling policy that maps\nthe embedded node features to the best scheduling action (policy learning). We\nemploy Proximal Policy Optimization (PPO) based RL strategy to train these two\nmodules in an end-to-end fashion. We empirically demonstrate that the GNN\nscheduler, due to its superb generalization capability, outperforms practically\nfavored dispatching rules and RL-based schedulers on various benchmark JSSP. We\nalso confirmed that the proposed framework learns a transferable scheduling\npolicy that can be employed to schedule a completely new JSSP (in terms of size\nand parameters) without further training.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Junyoung Park",
      "Jaehyeong Chun",
      "Sang Hun Kim",
      "Youngkook Kim",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.01086"
  },
  {
    "id": "arXiv:2106.01087",
    "title": "Is Sparse Attention more Interpretable?",
    "abstract": "Sparse attention has been claimed to increase model interpretability under\nthe assumption that it highlights influential inputs. Yet the attention\ndistribution is typically over representations internal to the model rather\nthan the inputs themselves, suggesting this assumption may not have merit. We\nbuild on the recent work exploring the interpretability of attention; we design\na set of experiments to help us understand how sparsity affects our ability to\nuse attention as an explainability tool. On three text classification tasks, we\nverify that only a weak relationship between inputs and co-indexed intermediate\nrepresentations exists -- under sparse attention and otherwise. Further, we do\nnot find any plausible mappings from sparse attention distributions to a sparse\nset of influential inputs through other avenues. Rather, we observe in this\nsetting that inducing sparsity may make it less plausible that attention can be\nused as a tool for understanding model behavior.",
    "descriptor": "",
    "authors": [
      "Clara Meister",
      "Stefan Lazov",
      "Isabelle Augenstein",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01087"
  },
  {
    "id": "arXiv:2106.01088",
    "title": "TSI: Temporal Saliency Integration for Video Action Recognition",
    "abstract": "Efficient spatiotemporal modeling is an important yet challenging problem for\nvideo action recognition. Existing state-of-the-art methods exploit motion\nclues to assist in short-term temporal modeling through temporal difference\nover consecutive frames. However, background noises will be inevitably\nintroduced due to the camera movement. Besides, movements of different actions\ncan vary greatly. In this paper, we propose a Temporal Saliency Integration\n(TSI) block, which mainly contains a Salient Motion Excitation (SME) module and\na Cross-scale Temporal Integration (CTI) module. Specifically, SME aims to\nhighlight the motion-sensitive area through local-global motion modeling, where\nthe background suppression and pyramidal feature difference are conducted\nsuccessively between neighboring frames to capture motion dynamics with less\nbackground noises. CTI is designed to perform multi-scale temporal modeling\nthrough a group of separate 1D convolutions respectively. Meanwhile, temporal\ninteractions across different scales are integrated with attention mechanism.\nThrough these two modules, long short-term temporal relationships can be\nencoded efficiently by introducing limited additional parameters. Extensive\nexperiments are conducted on several popular benchmarks (i.e.,\nSomething-Something v1 & v2, Kinetics-400, UCF-101, and HMDB-51), which\ndemonstrate the effectiveness and superiority of our proposed method.",
    "descriptor": "",
    "authors": [
      "Haisheng Su",
      "Jinyuan Feng",
      "Dongliang Wang",
      "Weihao Gan",
      "Wei Wu",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01088"
  },
  {
    "id": "arXiv:2106.01090",
    "title": "Minimal residual space-time discretizations of parabolic equations:  Asymmetric spatial operators",
    "abstract": "We consider a minimal residual discretization of a simultaneous space-time\nvariational formulation of parabolic evolution equations. Under the usual `LBB'\nstability condition on pairs of trial- and test spaces we show quasi-optimality\nof the numerical approximations without assuming symmetry of the spatial part\nof the differential operator. Under a stronger LBB condition we show error\nestimates in an energy-norm which are independent of this spatial differential\noperator.",
    "descriptor": "",
    "authors": [
      "Rob Stevenson",
      "Jan Westerdiep"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01090"
  },
  {
    "id": "arXiv:2106.01091",
    "title": "belabBERT: a Dutch RoBERTa-based language model applied to psychiatric  classification",
    "abstract": "Natural language processing (NLP) is becoming an important means for\nautomatic recognition of human traits and states, such as intoxication,\npresence of psychiatric disorders, presence of airway disorders and states of\nstress. Such applications have the potential to be an important pillar for\nonline help lines, and may gradually be introduced into eHealth modules.\nHowever, NLP is language specific and for languages such as Dutch, NLP models\nare scarce. As a result, recent Dutch NLP models have a low capture of long\nrange semantic dependencies over sentences. To overcome this, here we present\nbelabBERT, a new Dutch language model extending the RoBERTa architecture.\nbelabBERT is trained on a large Dutch corpus (+32 GB) of web crawled texts. We\napplied belabBERT to the classification of psychiatric illnesses. First, we\nevaluated the strength of text-based classification using belabBERT, and\ncompared the results to the existing RobBERT model. Then, we compared the\nperformance of belabBERT to audio classification for psychiatric disorders.\nFinally, a brief exploration was performed, extending the framework to a hybrid\ntext- and audio-based classification. Our results show that belabBERT\noutperformed the current best text classification network for Dutch, RobBERT.\nbelabBERT also outperformed classification based on audio alone.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2008.01543\n",
    "authors": [
      "Joppe Wouts",
      "Janna de Boer",
      "Alban Voppel",
      "Sanne Brederoo",
      "Sander van Splunter",
      "Iris Sommer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01091"
  },
  {
    "id": "arXiv:2106.01092",
    "title": "Statistical optimality conditions for compressive ensembles",
    "abstract": "We present a framework for the theoretical analysis of ensembles of\nlow-complexity empirical risk minimisers trained on independent random\ncompressions of high-dimensional data. First we introduce a general\ndistribution-dependent upper-bound on the excess risk, framed in terms of a\nnatural notion of compressibility. This bound is independent of the dimension\nof the original data representation, and explains the in-built regularisation\neffect of the compressive approach. We then instantiate this general bound to\nclassification and regression tasks, considering Johnson-Lindenstrauss mappings\nas the compression scheme. For each of these tasks, our strategy is to develop\na tight upper bound on the compressibility function, and by doing so we\ndiscover distributional conditions of geometric nature under which the\ncompressive algorithm attains minimax-optimal rates up to at most\npoly-logarithmic factors. In the case of compressive classification, this is\nachieved with a mild geometric margin condition along with a flexible moment\ncondition that is significantly more general than the assumption of bounded\ndomain. In the case of regression with strongly convex smooth loss functions we\nfind that compressive regression is capable of exploiting spectral decay with\nnear-optimal guarantees. In addition, a key ingredient for our central upper\nbound is a high probability uniform upper bound on the integrated deviation of\ndependent empirical processes, which may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Henry W. J. Reeve",
      "Ata Kaban"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.01092"
  },
  {
    "id": "arXiv:2106.01093",
    "title": "LGESQL: Line Graph Enhanced Text-to-SQL Model with Mixed Local and  Non-Local Relations",
    "abstract": "This work aims to tackle the challenging heterogeneous graph encoding problem\nin the text-to-SQL task. Previous methods are typically node-centric and merely\nutilize different weight matrices to parameterize edge types, which 1) ignore\nthe rich semantics embedded in the topological structure of edges, and 2) fail\nto distinguish local and non-local relations for each node. To this end, we\npropose a Line Graph Enhanced Text-to-SQL (LGESQL) model to mine the underlying\nrelational features without constructing meta-paths. By virtue of the line\ngraph, messages propagate more efficiently through not only connections between\nnodes, but also the topology of directed edges. Furthermore, both local and\nnon-local relations are integrated distinctively during the graph iteration. We\nalso design an auxiliary task called graph pruning to improve the\ndiscriminative capability of the encoder. Our framework achieves\nstate-of-the-art results (62.8% with Glove, 72.0% with Electra) on the\ncross-domain text-to-SQL benchmark Spider at the time of writing.",
    "descriptor": "\nComments: 15 pages, 8 figures, accepted to ACL 2021 main conference\n",
    "authors": [
      "Ruisheng Cao",
      "Lu Chen",
      "Zhi Chen",
      "Su Zhu",
      "Kai Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01093"
  },
  {
    "id": "arXiv:2106.01096",
    "title": "Learning to Rehearse in Long Sequence Memorization",
    "abstract": "Existing reasoning tasks often have an important assumption that the input\ncontents can be always accessed while reasoning, requiring unlimited storage\nresources and suffering from severe time delay on long sequences. To achieve\nefficient reasoning on long sequences with limited storage resources, memory\naugmented neural networks introduce a human-like write-read memory to compress\nand memorize the long input sequence in one pass, trying to answer subsequent\nqueries only based on the memory. But they have two serious drawbacks: 1) they\ncontinually update the memory from current information and inevitably forget\nthe early contents; 2) they do not distinguish what information is important\nand treat all contents equally. In this paper, we propose the Rehearsal Memory\n(RM) to enhance long-sequence memorization by self-supervised rehearsal with a\nhistory sampler. To alleviate the gradual forgetting of early information, we\ndesign self-supervised rehearsal training with recollection and familiarity\ntasks. Further, we design a history sampler to select informative fragments for\nrehearsal training, making the memory focus on the crucial information. We\nevaluate the performance of our rehearsal memory by the synthetic bAbI task and\nseveral downstream tasks, including text/video question answering and\nrecommendation on long sequences.",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Zhu Zhang",
      "Chang Zhou",
      "Jianxin Ma",
      "Zhijie Lin",
      "Jingren Zhou",
      "Hongxia Yang",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01096"
  },
  {
    "id": "arXiv:2106.01097",
    "title": "T-BERT -- Model for Sentiment Analysis of Micro-blogs Integrating Topic  Model and BERT",
    "abstract": "Sentiment analysis (SA) has become an extensive research area in recent years\nimpacting diverse fields including ecommerce, consumer business, and politics,\ndriven by increasing adoption and usage of social media platforms. It is\nchallenging to extract topics and sentiments from unsupervised short texts\nemerging in such contexts, as they may contain figurative words, strident data,\nand co-existence of many possible meanings for a single word or phrase, all\ncontributing to obtaining incorrect topics. Most prior research is based on a\nspecific theme/rhetoric/focused-content on a clean dataset. In the work\nreported here, the effectiveness of BERT(Bidirectional Encoder Representations\nfrom Transformers) in sentiment classification tasks from a raw live dataset\ntaken from a popular microblogging platform is demonstrated. A novel T-BERT\nframework is proposed to show the enhanced performance obtainable by combining\nlatent topics with contextual BERT embeddings. Numerical experiments were\nconducted on an ensemble with about 42000 datasets using NimbleBox.ai platform\nwith a hardware configuration consisting of Nvidia Tesla K80(CUDA), 4 core CPU,\n15GB RAM running on an isolated Google Cloud Platform instance. The empirical\nresults show that the model improves in performance while adding topics to BERT\nand an accuracy rate of 90.81% on sentiment classification using BERT with the\nproposed approach.",
    "descriptor": "",
    "authors": [
      "Sarojadevi Palani",
      "Prabhu Rajagopal",
      "Sidharth Pancholi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01097"
  },
  {
    "id": "arXiv:2106.01098",
    "title": "Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and  Practical Solutions",
    "abstract": "Graph generative models are a highly active branch of machine learning. Given\nthe steady development of new models of ever-increasing complexity, it is\nnecessary to provide a principled way to evaluate and compare them. In this\npaper, we enumerate the desirable criteria for comparison metrics, discuss the\ndevelopment of such metrics, and provide a comparison of their respective\nexpressive power. We perform a systematic evaluation of the main metrics in use\ntoday, highlighting some of the challenges and pitfalls researchers\ninadvertently can run into. We then describe a collection of suitable metrics,\ngive recommendations as to their practical suitability, and analyse their\nbehaviour on synthetically generated perturbed graphs as well as on recently\nproposed graph generative models.",
    "descriptor": "",
    "authors": [
      "Leslie O'Bray",
      "Max Horn",
      "Bastian Rieck",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01098"
  },
  {
    "id": "arXiv:2106.01101",
    "title": "Learning a Single Neuron with Bias Using Gradient Descent",
    "abstract": "We theoretically study the fundamental problem of learning a single neuron\nwith a bias term ($\\mathbf{x} \\mapsto \\sigma(<\\mathbf{w},\\mathbf{x}> + b)$) in\nthe realizable setting with the ReLU activation, using gradient descent.\nPerhaps surprisingly, we show that this is a significantly different and more\nchallenging problem than the bias-less case (which was the focus of previous\nworks on single neurons), both in terms of the optimization geometry as well as\nthe ability of gradient methods to succeed in some scenarios. We provide a\ndetailed study of this problem, characterizing the critical points of the\nobjective, demonstrating failure cases, and providing positive convergence\nguarantees under different sets of assumptions. To prove our results, we\ndevelop some tools which may be of independent interest, and improve previous\nresults on learning single neurons.",
    "descriptor": "",
    "authors": [
      "Gal Vardi",
      "Gilad Yehudai",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01101"
  },
  {
    "id": "arXiv:2106.01105",
    "title": "Use of Formal Ethical Reviews in NLP Literature: Historical Trends and  Current Practices",
    "abstract": "Ethical aspects of research in language technologies have received much\nattention recently. It is a standard practice to get a study involving human\nsubjects reviewed and approved by a professional ethics committee/board of the\ninstitution. How commonly do we see mention of ethical approvals in NLP\nresearch? What types of research or aspects of studies are usually subject to\nsuch reviews? With the rising concerns and discourse around the ethics of NLP,\ndo we also observe a rise in formal ethical reviews of NLP studies? And, if so,\nwould this imply that there is a heightened awareness of ethical issues that\nwas previously lacking? We aim to address these questions by conducting a\ndetailed quantitative and qualitative analysis of the ACL Anthology, as well as\ncomparing the trends in our field to those of other related disciplines, such\nas cognitive science, machine learning, data mining, and systems.",
    "descriptor": "\nComments: Accepted at ACL 2021 Findings (7 pages)\n",
    "authors": [
      "Sebastin Santy",
      "Anku Rani",
      "Monojit Choudhury"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01105"
  },
  {
    "id": "arXiv:2106.01108",
    "title": "Efficient Deterministic Leader Election for Programmable Matter",
    "abstract": "It was suggested that a programmable matter system (composed of multiple\ncomputationally weak mobile particles) should remain connected at all times\nsince otherwise, reconnection is difficult and may be impossible. At the same\ntime, it was not clear that allowing the system to disconnect carried a\nsignificant advantage in terms of time complexity. We demonstrate for a\nfundamental task, that of leader election, an algorithm where the system\ndisconnects and then reconnects automatically in a non-trivial way (particles\ncan move far away from their former neighbors and later reconnect to others).\nMoreover, the runtime of the temporarily disconnecting deterministic leader\nelection algorithm is linear in the diameter. Hence, the disconnecting --\nreconnecting algorithm is as fast as previous randomized algorithms. When\ncomparing to previous deterministic algorithms, we note that some of the\nprevious work assumed weaker schedulers. Still, the runtime of all the previous\ndeterministic algorithms that did not assume special shapes of the particle\nsystem (shapes with no holes) was at least quadratic in $n$, where $n$ is the\nnumber of particles in the system. (Moreover, the new algorithm is even faster\nin some parameters than the deterministic algorithms that did assume special\ninitial shapes.)\nSince leader election is an important module in algorithms for various other\ntasks, the presented algorithm can be useful for speeding up other algorithms\nunder the assumption of a strong scheduler. This leaves open the question: \"can\na deterministic algorithm be as fast as the randomized ones also under weaker\nschedulers?\"",
    "descriptor": "\nComments: PODC 2021\n",
    "authors": [
      "Fabien Dufoulon",
      "Shay Kutten",
      "William K. Moses Jr."
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.01108"
  },
  {
    "id": "arXiv:2106.01109",
    "title": "Improvement over Pinball Loss Support Vector Machine",
    "abstract": "Recently, there have been several papers that discuss the extension of the\nPinball loss Support Vector Machine (Pin-SVM) model, originally proposed by\nHuang et al.,[1][2]. Pin-SVM classifier deals with the pinball loss function,\nwhich has been defined in terms of the parameter $\\tau$. The parameter $\\tau$\ncan take values in $[ -1,1]$. The existing Pin-SVM model requires to solve the\nsame optimization problem for all values of $\\tau$ in $[ -1,1]$. In this paper,\nwe improve the existing Pin-SVM model for the binary classification task. At\nfirst, we note that there is major difficulty in Pin-SVM model (Huang et al.\n[1]) for $ -1 \\leq \\tau < 0$. Specifically, we show that the Pin-SVM model\nrequires the solution of different optimization problem for $ -1 \\leq \\tau <\n0$. We further propose a unified model termed as Unified Pin-SVM which results\nin a QPP valid for all $-1\\leq \\tau \\leq 1$ and hence more convenient to use.\nThe proposed Unified Pin-SVM model can obtain a significant improvement in\naccuracy over the existing Pin-SVM model which has also been empirically\njustified by extensive numerical experiments with real-world datasets.",
    "descriptor": "\nComments: The numerical results presented in this paper can be regenerated by the code available at this https URL . We hope that our this work will let the researchers to use the correct formulation of Pin-SVM model in future and improve the predictions across different domain of technologies\n",
    "authors": [
      "Pritam Anand",
      "Reshma Rastogi",
      "Suresh Chandra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01109"
  },
  {
    "id": "arXiv:2106.01110",
    "title": "A robust controller for stable 3D pinching using tactile sensing",
    "abstract": "This paper proposes a controller for stable grasping of unknown-shaped\nobjects by two robotic fingers with tactile fingertips. The grasp is stabilised\nby rolling the fingertips on the contact surface and applying a desired\ngrasping force to reach an equilibrium state. The validation is both in\nsimulation and on a fully-actuated robot hand (the Shadow Modular Grasper)\nfitted with custom-built optical tactile sensors (based on the BRL TacTip). The\ncontroller requires the orientations of the contact surfaces, which are\nestimated by regressing a deep convolutional neural network over the tactile\nimages. Overall, the grasp system is demonstrated to achieve stable equilibrium\nposes on a range of objects varying in shape and softness, with the system\nbeing robust to perturbations and measurement errors. This approach also has\npromise to extend beyond grasping to stable in-hand object manipulation with\nmultiple fingers.",
    "descriptor": "\nComments: 8 pages, 10 figures, 1 appendix\n",
    "authors": [
      "Efi Psomopoulou",
      "Nicholas Pestell",
      "Fotios Papadopoulos",
      "John Lloyd",
      "Zoe Doulgeri",
      "Nathan F. Lepora"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01110"
  },
  {
    "id": "arXiv:2106.01112",
    "title": "DynaEval: Unifying Turn and Dialogue Level Evaluation",
    "abstract": "A dialogue is essentially a multi-turn interaction among interlocutors.\nEffective evaluation metrics should reflect the dynamics of such interaction.\nExisting automatic metrics are focused very much on the turn-level quality,\nwhile ignoring such dynamics. To this end, we propose DynaEval, a unified\nautomatic evaluation framework which is not only capable of performing\nturn-level evaluation, but also holistically considers the quality of the\nentire dialogue. In DynaEval, the graph convolutional network (GCN) is adopted\nto model a dialogue in totality, where the graph nodes denote each individual\nutterance and the edges represent the dependency between pairs of utterances. A\ncontrastive loss is then applied to distinguish well-formed dialogues from\ncarefully constructed negative samples. Experiments show that DynaEval\nsignificantly outperforms the state-of-the-art dialogue coherence model, and\ncorrelates strongly with human judgements across multiple dialogue evaluation\naspects at both turn and dialogue level.",
    "descriptor": "\nComments: ACL-IJCNLP 2021 (main conference, long paper)\n",
    "authors": [
      "Chen Zhang",
      "Yiming Chen",
      "Luis Fernando D'Haro",
      "Yan Zhang",
      "Thomas Friedrichs",
      "Grandee Lee",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01112"
  },
  {
    "id": "arXiv:2106.01114",
    "title": "Design and Comparison of Reward Functions in Reinforcement Learning for  Energy Management of Sensor Nodes",
    "abstract": "Interest in remote monitoring has grown thanks to recent advancements in\nInternet-of-Things (IoT) paradigms. New applications have emerged, using small\ndevices called sensor nodes capable of collecting data from the environment and\nprocessing it. However, more and more data are processed and transmitted with\nlonger operational periods. At the same, the battery technologies have not\nimproved fast enough to cope with these increasing needs. This makes the energy\nconsumption issue increasingly challenging and thus, miniaturized energy\nharvesting devices have emerged to complement traditional energy sources.\nNevertheless, the harvested energy fluctuates significantly during the node\noperation, increasing uncertainty in actually available energy resources.\nRecently, approaches in energy management have been developed, in particular\nusing reinforcement learning approaches. However, in reinforcement learning,\nthe algorithm's performance relies greatly on the reward function. In this\npaper, we present two contributions. First, we explore five different reward\nfunctions to identify the most suitable variables to use in such functions to\nobtain the desired behaviour. Experiments were conducted using the Q-learning\nalgorithm to adjust the energy consumption depending on the energy harvested.\nResults with the five reward functions illustrate how the choice thereof\nimpacts the energy consumption of the node. Secondly, we propose two additional\nreward functions able to find the compromise between energy consumption and a\nnode performance using a non-fixed balancing parameter. Our simulation results\nshow that the proposed reward functions adjust the node's performance depending\non the battery level and reduce the learning time.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Yohann Rioual",
      "Yannick Le Moullec",
      "Johann Laurent",
      "Muhidul Islam Khan",
      "Jean-Philippe Diguet"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01114"
  },
  {
    "id": "arXiv:2106.01115",
    "title": "Efficient and Expressive Bytecode-Level Instrumentation for Java  Programs",
    "abstract": "We present an efficient and expressive tool for the instrumentation of Java\nprograms at the bytecode-level. BISM (Bytecode-Level Instrumentation for\nSoftware Monitoring) is a light-weight Java bytecode instrumentation tool that\nfeatures an expressive high-level control-flow-aware instrumentation language.\nThe language is inspired by the aspect-oriented programming paradigm in\nmodularizing instrumentation into separate transformers, that encapsulate\njoinpoint selection and advice inlining. BISM allows capturing joinpoints\nranging from bytecode instructions to methods execution and provides\ncomprehensive static and dynamic context information. It runs in two\ninstrumentation modes: build-time and load-time. BISM also provides a mechanism\nto compose transformers and automatically detect their collision in the base\nprogram. Transformers in a composition can control the visibility of their\nadvice and other instructions from the base program. We show several example\napplications for BISM and demonstrate its effectiveness using three\nexperiments: a security scenario, a financial transaction system, and a general\nruntime verification case. The results show that BISM instrumentation incurs\nlow runtime and memory overheads.",
    "descriptor": "",
    "authors": [
      "Chukri Soueidi",
      "Marius Monnier",
      "Ali Kassem",
      "Yli\u00e8s Falcone"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.01115"
  },
  {
    "id": "arXiv:2106.01116",
    "title": "MOBS (Matrices Over Bit Strings) public key exchange",
    "abstract": "We use matrices over bit strings as platforms for Diffie-Hellman-like public\nkey exchange protocols. When multiplying matrices like that, we use Boolean OR\noperation on bit strings in place of addition and Boolean AND operation in\nplace of multiplication. As a result, (1) computations with these matrices are\nvery efficient; (2) standard methods of attacking Diffie-Hellman-like protocols\nare not applicable.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Nael Rahman",
      "Vladimir Shpilrain"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.01116"
  },
  {
    "id": "arXiv:2106.01122",
    "title": "Tikhonov regularization continuation methods and the trust-region  updating strategy for linearly equality-constrained optimization problems",
    "abstract": "This paper considers the Tikhonv regularization continuation method and the\ntrust-region updating strategy for the linearly equality-constrained\noptimization problem (Trcmtr). Moreover, in order to improve its computational\nefficiency and robustness, the new method uses the switching preconditioned\ntechnique. That is to say, the new method uses the L-BFGS method as the\npreconditioned technique to improve its computational efficiency in the\nwell-posed phase. Otherwise, it uses the inverse of the regularization\ntwo-sided projected Hessian matrix as the pre-conditioner to improve its\nrobustness. Numerical results also show that the new method is more robust and\nfaster than the traditional optimization method such as the sequential\nquadratic programming (SQP), the alternating direction method of multipliers\n(ADMM) and the latest continuation method (Ptctr). The computational time of\nthe new method is about one fifth of that of SQP for the large-scale problem.\nFinally, the global convergence analysis of the new method is also given.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2101.07055, arXiv:2012.14808\n",
    "authors": [
      "Xin-long Luo",
      "Hang Xiao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.01122"
  },
  {
    "id": "arXiv:2106.01127",
    "title": "Towards Robust Classification Model by Counterfactual and Invariant Data  Generation",
    "abstract": "Despite the success of machine learning applications in science, industry,\nand society in general, many approaches are known to be non-robust, often\nrelying on spurious correlations to make predictions. Spuriousness occurs when\nsome features correlate with labels but are not causal; relying on such\nfeatures prevents models from generalizing to unseen environments where such\ncorrelations break. In this work, we focus on image classification and propose\ntwo data generation processes to reduce spuriousness. Given human annotations\nof the subset of the features responsible (causal) for the labels (e.g.\nbounding boxes), we modify this causal set to generate a surrogate image that\nno longer has the same label (i.e. a counterfactual image). We also alter\nnon-causal features to generate images still recognized as the original labels,\nwhich helps to learn a model invariant to these features. In several\nchallenging datasets, our data generations outperform state-of-the-art methods\nin accuracy when spurious correlations break, and increase the saliency focus\non causal features providing better explanations.",
    "descriptor": "\nComments: 2021 CVPR\n",
    "authors": [
      "Chun-Hao Chang",
      "George Alexandru Adam",
      "Anna Goldenberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01127"
  },
  {
    "id": "arXiv:2106.01128",
    "title": "Linear-Time Gromov Wasserstein Distances using Low Rank Couplings and  Costs",
    "abstract": "The ability to compare and align related datasets living in heterogeneous\nspaces plays an increasingly important role in machine learning. The\nGromov-Wasserstein (GW) formalism can help tackle this problem. Its main goal\nis to seek an assignment (more generally a coupling matrix) that can register\npoints across otherwise incomparable datasets. As a non-convex and quadratic\ngeneralization of optimal transport (OT), GW is NP-hard. Yet, heuristics are\nknown to work reasonably well in practice, the state of the art approach being\nto solve a sequence of nested regularized OT problems. While popular, that\nheuristic remains too costly to scale, with cubic complexity in the number of\nsamples $n$. We show in this paper how a recent variant of the Sinkhorn\nalgorithm can substantially speed up the resolution of GW. That variant\nrestricts the set of admissible couplings to those admitting a low rank\nfactorization as the product of two sub-couplings. By updating alternatively\neach sub-coupling, our algorithm computes a stationary point of the problem in\nquadratic time with respect to the number of samples. When cost matrices have\nthemselves low rank, our algorithm has time complexity $\\mathcal{O}(n)$. We\ndemonstrate the efficiency of our method on simulated and real data.",
    "descriptor": "",
    "authors": [
      "Meyer Scetbon",
      "Gabriel Peyr\u00e9",
      "Marco Cuturi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01128"
  },
  {
    "id": "arXiv:2106.01131",
    "title": "Performance and Usability of Visual and Verbal Verification of  Word-based Key Fingerprints",
    "abstract": "The security of messaging applications against person-in-the-middle attacks\nrelies on the authenticity of the exchanged keys. For users unable to meet in\nperson, a manual key fingerprint verification is necessary to ascertain key\nauthenticity. Such fingerprints can be exchanged visually or verbally, and it\nis not clear in which condition users perform best. This paper reports the\nresults of a 62-participant study that investigated differences in performance\nand perceived usability of visual and verbal comparisons of word-based key\nfingerprints, and the influence of the individual's cognitive learning style.\nThe results show visual comparisons to be more effective against non-security\ncritical errors and are perceived to provide increased confidence, yet\nparticipants perceive verbal comparisons to be easier and require less mental\neffort. Besides, limited evidence was found on the influence of the\nindividual's learning style on their performance.",
    "descriptor": "\nComments: This is an accepted manuscript to appear in the proceedings of the 15th International Symposium on Human Aspects of Information Security & Assurance, HAISA 2021\n",
    "authors": [
      "Lee Livsey",
      "Helen Petrie",
      "Siamak F. Shahandashti",
      "Aidan Fray"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.01131"
  },
  {
    "id": "arXiv:2106.01132",
    "title": "Benchmarking CNN on 3D Anatomical Brain MRI: Architectures, Data  Augmentation and Deep Ensemble Learning",
    "abstract": "Deep Learning (DL) and specifically CNN models have become a de facto method\nfor a wide range of vision tasks, outperforming traditional machine learning\n(ML) methods. Consequently, they drew a lot of attention in the neuroimaging\nfield in particular for phenotype prediction or computer-aided diagnosis.\nHowever, most of the current studies often deal with small single-site cohorts,\nalong with a specific pre-processing pipeline and custom CNN architectures,\nwhich make them difficult to compare to. We propose an extensive benchmark of\nrecent state-of-the-art (SOTA) 3D CNN, evaluating also the benefits of data\naugmentation and deep ensemble learning, on both Voxel-Based Morphometry (VBM)\npre-processing and quasi-raw images. Experiments were conducted on a large\nmulti-site 3D brain anatomical MRI data-set comprising N=10k scans on 3\nchallenging tasks: age prediction, sex classification, and schizophrenia\ndiagnosis. We found that all models provide significantly better predictions\nwith VBM images than quasi-raw data. This finding evolved as the training set\napproaches 10k samples where quasi-raw data almost reach the performance of\nVBM. Moreover, we showed that linear models perform comparably with SOTA CNN on\nVBM data. We also demonstrated that DenseNet and tiny-DenseNet, a lighter\nversion that we proposed, provide a good compromise in terms of performance in\nall data regime. Therefore, we suggest to employ them as the architectures by\ndefault. Critically, we also showed that current CNN are still very biased\ntowards the acquisition site, even when trained with N=10k multi-site images.\nIn this context, VBM pre-processing provides an efficient way to limit this\nsite effect. Surprisingly, we did not find any clear benefit from data\naugmentation techniques. Finally, we proved that deep ensemble learning is well\nsuited to re-calibrate big CNN models without sacrificing performance.",
    "descriptor": "\nComments: 17 pages, 6 figures, 3 tables\n",
    "authors": [
      "Benoit Dufumier",
      "Pietro Gori",
      "Ilaria Battaglia",
      "Julie Victor",
      "Antoine Grigis",
      "Edouard Duchesnay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.01132"
  },
  {
    "id": "arXiv:2106.01134",
    "title": "Smooth Q-learning: Accelerate Convergence of Q-learning Using Similarity",
    "abstract": "An improvement of Q-learning is proposed in this paper. It is different from\nclassic Q-learning in that the similarity between different states and actions\nis considered in the proposed method. During the training, a new updating\nmechanism is used, in which the Q value of the similar state-action pairs are\nupdated synchronously. The proposed method can be used in combination with both\ntabular Q-learning function and deep Q-learning. And the results of numerical\nexamples illustrate that compared to the classic Q-learning, the proposed\nmethod has a significantly better performance.",
    "descriptor": "",
    "authors": [
      "Wei Liao",
      "Xiaohui Wei",
      "Jizhou Lai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01134"
  },
  {
    "id": "arXiv:2106.01135",
    "title": "MNL-Bandit with Knapsacks",
    "abstract": "We consider a dynamic assortment selection problem where a seller has a fixed\ninventory of $N$ substitutable products and faces an unknown demand that\narrives sequentially over $T$ periods. In each period, the seller needs to\ndecide on the assortment of products (of cardinality at most $K$) to offer to\nthe customers. The customer's response follows an unknown multinomial logit\nmodel (MNL) with parameters $v$. The goal of the seller is to maximize the\ntotal expected revenue given the fixed initial inventory of $N$ products. We\ngive a policy that achieves a regret of $\\tilde O\\left(K \\sqrt{K N T}\\left(1 +\n\\frac{\\sqrt{v_{\\max}}}{q_{\\min}}\\text{OPT}\\right) \\right)$ under a mild\nassumption on the model parameters. In particular, our policy achieves a\nnear-optimal $\\tilde O(\\sqrt{T})$ regret in the large inventory setting.\nOur policy builds upon the UCB-based approach for MNL-bandit without\ninventory constraints in [1] and addresses the inventory constraints through an\nexponentially sized LP for which we present a tractable approximation while\nkeeping the $\\tilde O(\\sqrt{T})$ regret bound.",
    "descriptor": "",
    "authors": [
      "Abdellah Aznag",
      "Vineet Goyal",
      "Noemie Perivier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.01135"
  },
  {
    "id": "arXiv:2106.01139",
    "title": "How Flexible is Your Computing System",
    "abstract": "In literature computer architectures are frequently claimed to be highly\nflexible, typically implying there exist trade-offs between flexibility and\nperformance or energy efficiency. Processor flexibility, however, is not very\nsharply defined, and as such these claims can not be validated, nor can such\nhypothetical relations be fully understood and exploited in the design of\ncomputing systems. This paper is an attempt to introduce scientific rigour to\nthe notion of flexibility in computing systems.",
    "descriptor": "\nComments: Partial preprint pending peer review\n",
    "authors": [
      "Shihua Huang",
      "Luc Waeijen",
      "Henk Corporaal"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.01139"
  },
  {
    "id": "arXiv:2106.01143",
    "title": "Accurate and Robust Deep Learning Framework for Solving Wave-Based  Inverse Problems in the Super-Resolution Regime",
    "abstract": "We propose an end-to-end deep learning framework that comprehensively solves\nthe inverse wave scattering problem across all length scales. Our framework\nconsists of the newly introduced wide-band butterfly network coupled with a\nsimple training procedure that dynamically injects noise during training. While\nour trained network provides competitive results in classical imaging regimes,\nmost notably it also succeeds in the super-resolution regime where other\ncomparable methods fail. This encompasses both (i) reconstruction of scatterers\nwith sub-wavelength geometric features, and (ii) accurate imaging when two or\nmore scatterers are separated by less than the classical diffraction limit. We\ndemonstrate these properties are retained even in the presence of strong noise\nand extend to scatterers not previously seen in the training set. In addition,\nour network is straightforward to train requiring no restarts and has an online\nruntime that is an order of magnitude faster than optimization-based\nalgorithms. We perform experiments with a variety of wave scattering mediums\nand we demonstrate that our proposed framework outperforms both classical\ninversion and competing network architectures that specialize in oscillatory\nwave scattering data.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Matthew Li",
      "Laurent Demanet",
      "Leonardo Zepeda-N\u00fa\u00f1ez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01143"
  },
  {
    "id": "arXiv:2106.01144",
    "title": "Towards Emotional Support Dialog Systems",
    "abstract": "Emotional support is a crucial ability for many conversation scenarios,\nincluding social interactions, mental health support, and customer service\nchats. Following reasonable procedures and using various support skills can\nhelp to effectively provide support. However, due to the lack of a\nwell-designed task and corpora of effective emotional support conversations,\nresearch on building emotional support into dialog systems remains untouched.\nIn this paper, we define the Emotional Support Conversation (ESC) task and\npropose an ESC Framework, which is grounded on the Helping Skills Theory. We\nconstruct an Emotion Support Conversation dataset (ESConv) with rich annotation\n(especially support strategy) in a help-seeker and supporter mode. To ensure a\ncorpus of high-quality conversations that provide examples of effective\nemotional support, we take extensive effort to design training tutorials for\nsupporters and several mechanisms for quality control during data collection.\nFinally, we evaluate state-of-the-art dialog models with respect to the ability\nto provide emotional support. Our results show the importance of support\nstrategies in providing effective emotional support and the utility of ESConv\nin training more emotional support systems.",
    "descriptor": "\nComments: Accepted to ACL 2021 (Long Paper)\n",
    "authors": [
      "Siyang Liu",
      "Chujie Zheng",
      "Orianna Demasi",
      "Sahand Sabour",
      "Yu Li",
      "Zhou Yu",
      "Yong Jiang",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01144"
  },
  {
    "id": "arXiv:2106.01146",
    "title": "Multi-stage, multi-swarm PSO for joint optimization of well placement  and control",
    "abstract": "Evolutionary optimization algorithms, including particle swarm optimization\n(PSO), have been successfully applied in oil industry for production planning\nand control. Such optimization studies are quite challenging due to large\nnumber of decision variables, production scenarios, and subsurface\nuncertainties. In this work, a multi-stage, multi-swarm PSO (MS2PSO) is\nproposed to fix certain issues with canonical PSO algorithm such as premature\nconvergence, excessive influence of global best solution, and oscillation.\nMultiple experiments are conducted using Olympus benchmark to compare the\nefficacy of algorithms. Canonical PSO hyperparameters are first tuned to\nprioritize exploration in early phase and exploitation in late phase. Next, a\ntwo-stage multi-swarm PSO (2SPSO) is used where multiple-swarms of the first\nstage collapse into a single swarm in the second stage. Finally, MS2PSO with\nmultiple stages and multiple swarms is used in which swarms recursively\ncollapse after each stage. Multiple swarm strategy ensures that diversity is\nretained within the population and multiple modes are explored. Staging ensures\nthat local optima found during initial stage does not lead to premature\nconvergence. Optimization test case comprises of 90 control variables and a\ntwenty year period of flow simulation. It is observed that different algorithm\ndesigns have their own benefits and drawbacks. Multiple swarms and stages help\nalgorithm to move away from local optima, but at the same time they may also\nnecessitate larger number of iterations for convergence. Both 2SPSO and MS2PSO\nare found to be helpful for problems with high dimensions and multiple modes\nwhere greater degree of exploration is desired.",
    "descriptor": "",
    "authors": [
      "Ajitabh Kumar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01146"
  },
  {
    "id": "arXiv:2106.01148",
    "title": "Your Tribe Decides Your Vibe: Analyzing Local Popularity in the US  Patent Citation Network",
    "abstract": "In many networks, the indegree of a vertex is a measure of its popularity.\nPast research has studied indegree distributions treating the network as a\nwhole. In the US Patent citation network (USPCN), patents are classified into\ncategories and subcategories. A natural question arises: How do patents gather\ntheir popularity from various (sub)categories? We analyse local indegree\ndistributions to answer this question.\nThe citation (indegree) of a patent within the same category indicates its\ninternal popularity, while a cross-category citation indicates its external\npopularity. We analyze the internal and external indegree distributions at each\nlevel of USPCN hierarchy to learn how the internal and external popularity of\npatents varies across (sub)categories.\nWe find that all (sub)categories have local preferences that decide internal\nand external patents' popularities. Different patents are popular in different\ngroups: Groups C1, C2 and C3 may not agree on popular patents in C1. In\ngeneral, patent popularity appears to be a highly local phenomenon with\nsubcategories (not even categories) deciding their own popular patents\nindependent of the other (sub)categories.",
    "descriptor": "",
    "authors": [
      "Nishit Narang",
      "Manoj Kumar Ganji",
      "Amit Anil Nanavati"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.01148"
  },
  {
    "id": "arXiv:2106.01149",
    "title": "Exploring modality-agnostic representations for music classification",
    "abstract": "Music information is often conveyed or recorded across multiple data\nmodalities including but not limited to audio, images, text and scores.\nHowever, music information retrieval research has almost exclusively focused on\nsingle modality recognition, requiring development of separate models for each\nmodality. Some multi-modal works require multiple coexisting modalities given\nto the model as inputs, constraining the use of these models to the few cases\nwhere data from all modalities are available. To the best of our knowledge, no\nexisting model has the ability to take inputs from varying modalities, e.g.\nimages or sounds, and classify them into unified music categories. We explore\nthe use of cross-modal retrieval as a pretext task to learn modality-agnostic\nrepresentations, which can then be used as inputs to classifiers that are\nindependent of modality. We select instrument classification as an example task\nfor our study as both visual and audio components provide relevant semantic\ninformation. We train music instrument classifiers that can take both images or\nsounds as input, and perform comparably to sound-only or image-only\nclassifiers. Furthermore, we explore the case when there is limited labeled\ndata for a given modality, and the impact in performance by using labeled data\nfrom other modalities. We are able to achieve almost 70% of best performing\nsystem in a zero-shot setting. We provide a detailed analysis of experimental\nresults to understand the potential and limitations of the approach, and\ndiscuss future steps towards modality-agnostic classifiers.",
    "descriptor": "",
    "authors": [
      "Ho-Hsiang Wu",
      "Magdalena Fuentes",
      "Juan P. Bello"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.01149"
  },
  {
    "id": "arXiv:2106.01151",
    "title": "Towards Deeper Deep Reinforcement Learning",
    "abstract": "In computer vision and natural language processing, innovations in model\narchitecture that lead to increases in model capacity have reliably translated\ninto gains in performance. In stark contrast with this trend, state-of-the-art\nreinforcement learning (RL) algorithms often use only small MLPs, and gains in\nperformance typically originate from algorithmic innovations. It is natural to\nhypothesize that small datasets in RL necessitate simple models to avoid\noverfitting; however, this hypothesis is untested. In this paper we investigate\nhow RL agents are affected by exchanging the small MLPs with larger modern\nnetworks with skip connections and normalization, focusing specifically on soft\nactor-critic (SAC) algorithms. We verify, empirically, that na\\\"ively adopting\nsuch architectures leads to instabilities and poor performance, likely\ncontributing to the popularity of simple models in practice. However, we show\nthat dataset size is not the limiting factor, and instead argue that intrinsic\ninstability from the actor in SAC taking gradients through the critic is the\nculprit. We demonstrate that a simple smoothing method can mitigate this issue,\nwhich enables stable training with large modern architectures. After smoothing,\nlarger models yield dramatic performance improvements for state-of-the-art\nagents -- suggesting that more \"easy\" gains may be had by focusing on model\narchitectures in addition to algorithmic innovations.",
    "descriptor": "",
    "authors": [
      "Johan Bjorck",
      "Carla P. Gomes",
      "Kilian Q. Weinberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01151"
  },
  {
    "id": "arXiv:2106.01153",
    "title": "Online and Real-Time Tracking in a Surveillance Scenario",
    "abstract": "This paper presents an approach for tracking in a surveillance scenario.\nTypical aspects for this scenario are a 24/7 operation with a static camera\nmounted above the height of a human with many objects or people. The Multiple\nObject Tracking Benchmark 20 (MOT20) reflects this scenario best. We can show\nthat our approach is real-time capable on this benchmark and outperforms all\nother real-time capable approaches in HOTA, MOTA, and IDF1. We achieve this by\ncontributing a fast Siamese network reformulated for linear runtime (instead of\nquadratic) to generate fingerprints from detections. Thus, it is possible to\nassociate the detections to Kalman filters based on multiple tracking specific\nratings: Cosine similarity of fingerprints, Intersection over Union, and pixel\ndistance ratio in the image.",
    "descriptor": "",
    "authors": [
      "Oliver Urbann",
      "Oliver Bredtmann",
      "Maximilian Otten",
      "Jan-Philip Richter",
      "Thilo Bauer",
      "David Zibriczky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01153"
  },
  {
    "id": "arXiv:2106.01154",
    "title": "Controlled Update of Software Components using Concurrent Exection of  Patched and Unpatched Versions",
    "abstract": "Software patching is a common method of removing vulnerabilities in software\ncomponents to make IT systems more secure. However, there are many cases where\nsoftware patching is not possible due to the critical nature of the\napplication, especially when the vendor providing the application guarantees\ncorrect operation only in a specific configuration. In this paper, we propose a\nmethod to solve this problem. The idea is to run unpatched and patched\napplication instances concurrently, with the unpatched one having complete\ncontrol and the output of the patched one being used only for comparison, to\nwatch for differences that are consequences of introduced bugs. To test this\nidea, we developed a system that allows us to run web applications in parallel\nand tested three web applications. The experiments have shown that the idea is\npromising for web applications from the technical side. Furthermore, we discuss\nthe potential limitations of this system and the idea in general, how long two\ninstances should run in order to be able to claim with some probability that\nthe patched version has not introduced any new bugs, other potential use cases\nof the proposed system where two application instances run concurrently, and\nfinally the potential uses of this system with different types of applications,\nsuch as SCADA systems.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Stjepan Gro\u0161",
      "Ivan Kova\u010devi\u0107",
      "Ivan Dujmi\u0107",
      "Matej Petrinovi\u0107"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.01154"
  },
  {
    "id": "arXiv:2106.01157",
    "title": "Social Engineering in Cybersecurity: A Domain Ontology and Knowledge  Graph Application Examples",
    "abstract": "Social engineering has posed a serious threat to cyberspace security. To\nprotect against social engineering attacks, a fundamental work is to know what\nconstitutes social engineering. This paper first develops a domain ontology of\nsocial engineering in cybersecurity and conducts ontology evaluation by its\nknowledge graph application. The domain ontology defines 11 concepts of core\nentities that significantly constitute or affect social engineering domain,\ntogether with 22 kinds of relations describing how these entities related to\neach other. It provides a formal and explicit knowledge schema to understand,\nanalyze, reuse and share domain knowledge of social engineering. Furthermore,\nthis paper builds a knowledge graph based on 15 social engineering attack\nincidents and scenarios. 7 knowledge graph application examples (in 6 analysis\npatterns) demonstrate that the ontology together with knowledge graph is useful\nto 1) understand and analyze social engineering attack scenario and incident,\n2) find the top ranked social engineering threat elements (e.g. the most\nexploited human vulnerabilities and most used attack mediums), 3) find\npotential social engineering threats to victims, 4) find potential targets for\nsocial engineering attackers, 5) find potential attack paths from specific\nattacker to specific target, and 6) analyze the same origin attacks.",
    "descriptor": "\nComments: Z. Wang, H. Zhu, P. Liu and L. Sun. \"Social Engineering in Cybersecurity: A Domain Ontology and Knowledge Graph Application Examples.\" Cybersecurity 4(1), 2021. doi: 10.1186/s42400-021-00094-6\n",
    "authors": [
      "Zuoguang Wang",
      "Hongsong Zhu",
      "Peipei Liu",
      "Limin Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.01157"
  },
  {
    "id": "arXiv:2106.01161",
    "title": "Babel Fees via Limited Liabilities",
    "abstract": "Custom currencies (ERC-20) on Ethereum are wildly popular, but they are\nsecond class to the primary currency Ether. Custom currencies are more complex\nand more expensive to handle than the primary currency as their accounting is\nnot natively performed by the underlying ledger, but instead in user-defined\ncontract code. Furthermore, and quite importantly, transaction fees can only be\npaid in Ether.\nIn this paper, we focus on being able to pay transaction fees in custom\ncurrencies. We achieve this by way of a mechanism permitting short term\nliabilities to pay transaction fees in conjunction with offers of custom\ncurrencies to compensate for those liabilities. This enables block producers to\naccept custom currencies in exchange for settling liabilities of transactions\nthat they process.\nWe present formal ledger rules to handle liabilities together with the\nconcept of babel fees to pay transaction fees in custom currencies. We also\ndiscuss how clients can determine what fees they have to pay, and we present a\nsolution to the knapsack problem variant that block producers have to solve in\nthe presence of babel fees to optimise their profits.",
    "descriptor": "",
    "authors": [
      "Manuel M. T. Chakravarty",
      "Nikos Karayannidis",
      "Aggelos Kiayias",
      "Michael Peyton Jones",
      "Polina Vinogradova"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.01161"
  },
  {
    "id": "arXiv:2106.01167",
    "title": "End-to-End NLP Knowledge Graph Construction",
    "abstract": "This paper studies the end-to-end construction of an NLP Knowledge Graph (KG)\nfrom scientific papers. We focus on extracting four types of relations:\nevaluatedOn between tasks and datasets, evaluatedBy between tasks and\nevaluation metrics, as well as coreferent and related relations between the\nsame type of entities. For instance, F1-score is coreferent with F-measure. We\nintroduce novel methods for each of these relation types and apply our final\nframework (SciNLP-KG) to 30,000 NLP papers from ACL Anthology to build a\nlarge-scale KG, which can facilitate automatically constructing scientific\nleaderboards for the NLP community. The results of our experiments indicate\nthat the resulting KG contains high-quality information.",
    "descriptor": "\nComments: Accepted in ACL 2021\n",
    "authors": [
      "Ishani Mondal",
      "Yufang Hou",
      "Charles Jochim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01167"
  },
  {
    "id": "arXiv:2106.01170",
    "title": "Detecting Bot-Generated Text by Characterizing Linguistic Accommodation  in Human-Bot Interactions",
    "abstract": "Language generation models' democratization benefits many domains, from\nanswering health-related questions to enhancing education by providing\nAI-driven tutoring services. However, language generation models'\ndemocratization also makes it easier to generate human-like text at-scale for\nnefarious activities, from spreading misinformation to targeting specific\ngroups with hate speech. Thus, it is essential to understand how people\ninteract with bots and develop methods to detect bot-generated text. This paper\nshows that bot-generated text detection methods are more robust across datasets\nand models if we use information about how people respond to it rather than\nusing the bot's text directly. We also analyze linguistic alignment, providing\ninsight into differences between human-human and human-bot conversations.",
    "descriptor": "\nComments: 13 pages, to be published in Findings of ACL-IJCNLP 2021\n",
    "authors": [
      "Paras Bhatt",
      "Anthony Rios"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01170"
  },
  {
    "id": "arXiv:2106.01173",
    "title": "On the approximation ratio of LZ-End to LZ77",
    "abstract": "A family of Lempel-Ziv factorizations is a well-studied string structure. The\nLZ-End factorization is a member of the family that achieved faster extraction\nof any substrings (Kreft & Navarro, TCS 2013). One of the interests for LZ-End\nfactorizations is the possible difference between the size of LZ-End and LZ77\nfactorizations. They also showed families of strings where the approximation\nratio of the number of LZ-End phrases to the number of LZ77 phrases\nasymptotically approaches 2. However, the alphabet size of these strings is\nunbounded. In this paper, we analyze the LZ-End factorization of the\nperiod-doubling sequence. We also show that the approximation ratio for the\nperiod-doubling sequence asymptotically approaches 2 for the binary alphabet.",
    "descriptor": "",
    "authors": [
      "Takumi Ideue",
      "Takuya Mieno",
      "Mitsuru Funakoshi",
      "Yuto Nakashima",
      "Shunsuke Inenaga",
      "Masayuki Takeda"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.01173"
  },
  {
    "id": "arXiv:2106.01174",
    "title": "Nitsche's Finite Element Method for Model Coupling in Elasticity",
    "abstract": "We develop a Nitsche finite element method for a model of Euler--Bernoulli\nbeams with axial stiffness embedded in a two--dimensional elastic bulk domain.\nThe beams have their own displacement fields, and the elastic subdomains\ncreated by the beam network are triangulated independently and are coupled to\nthe beams weakly by use of Nitsche's method in the framework of hybridization.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Peter Hansbo",
      "Mats G. Larson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01174"
  },
  {
    "id": "arXiv:2106.01176",
    "title": "Hybrid Ensemble optimized algorithm based on Genetic Programming for  imbalanced data classification",
    "abstract": "One of the most significant current discussions in the field of data mining\nis classifying imbalanced data. In recent years, several ways are proposed such\nas algorithm level (internal) approaches, data level (external) techniques, and\ncost-sensitive methods. Although extensive research has been carried out on\nimbalanced data classification, however, several unsolved challenges remain\nsuch as no attention to the importance of samples to balance, determine the\nappropriate number of classifiers, and no optimization of classifiers in the\ncombination of classifiers. The purpose of this paper is to improve the\nefficiency of the ensemble method in the sampling of training data sets,\nespecially in the minority class, and to determine better basic classifiers for\ncombining classifiers than existing methods. We proposed a hybrid ensemble\nalgorithm based on Genetic Programming (GP) for two classes of imbalanced data\nclassification. In this study uses historical data from UCI Machine Learning\nRepository to assess minority classes in imbalanced datasets. The performance\nof our proposed algorithm is evaluated by Rapid-miner studio v.7.5.\nExperimental results show the performance of the proposed method on the\nspecified data sets in the size of the training set shows 40% and 50% better\naccuracy than other dimensions of the minority class prediction.",
    "descriptor": "\nComments: 11 pages, 4 Tables, 7 Figures Accepted in Twelfth International Conference on Information Technology, Computer and Telecommunications\n",
    "authors": [
      "Maliheh Roknizadeh",
      "Hossein Monshizadeh Naeen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01176"
  },
  {
    "id": "arXiv:2106.01177",
    "title": "Learning to Time-Decode in Spiking Neural Networks Through the  Information Bottleneck",
    "abstract": "One of the key challenges in training Spiking Neural Networks (SNNs) is that\ntarget outputs typically come in the form of natural signals, such as labels\nfor classification or images for generative models, and need to be encoded into\nspikes. This is done by handcrafting target spiking signals, which in turn\nimplicitly fixes the mechanisms used to decode spikes into natural signals,\ne.g., rate decoding. The arbitrary choice of target signals and decoding rule\ngenerally impairs the capacity of the SNN to encode and process information in\nthe timing of spikes. To address this problem, this work introduces a hybrid\nvariational autoencoder architecture, consisting of an encoding SNN and a\ndecoding Artificial Neural Network (ANN). The role of the decoding ANN is to\nlearn how to best convert the spiking signals output by the SNN into the target\nnatural signal. A novel end-to-end learning rule is introduced that optimizes a\ndirected information bottleneck training criterion via surrogate gradients. We\ndemonstrate the applicability of the technique in an experimental settings on\nvarious tasks, including real-life datasets.",
    "descriptor": "\nComments: Under review for conference publication\n",
    "authors": [
      "Nicolas Skatchkovsky",
      "Osvaldo Simeone",
      "Hyeryung Jang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.01177"
  },
  {
    "id": "arXiv:2106.01178",
    "title": "ImVoxelNet: Image to Voxels Projection for Monocular and Multi-View  General-Purpose 3D Object Detection",
    "abstract": "In this paper, we introduce the task of multi-view RGB-based 3D object\ndetection as an end-to-end optimization problem. To address this problem, we\npropose ImVoxelNet, a novel fully convolutional method of 3D object detection\nbased on monocular or multi-view RGB images. The number of monocular images in\neach multi-view input can variate during training and inference; actually, this\nnumber might be unique for each multi-view input. ImVoxelNet successfully\nhandles both indoor and outdoor scenes, which makes it general-purpose.\nSpecifically, it achieves state-of-the-art results in car detection on KITTI\n(monocular) and nuScenes (multi-view) benchmarks among all methods that accept\nRGB images. Moreover, it surpasses existing RGB-based 3D object detection\nmethods on the SUN RGB-D dataset. On ScanNet, ImVoxelNet sets a new benchmark\nfor multi-view 3D object detection. The source code and the trained models are\navailable at \\url{https://github.com/saic-vul/imvoxelnet}.",
    "descriptor": "",
    "authors": [
      "Danila Rukhovich",
      "Anna Vorontsova",
      "Anton Konushin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01178"
  },
  {
    "id": "arXiv:2106.01182",
    "title": "Automating Speedrun Routing: Overview and Vision",
    "abstract": "Speedrunning in general means to play a video game fast, i.e. using all means\nat one's disposal to achieve a given goal in the least amount of time possible.\nTo do so, a speedrun must be planned in advance, or routed, as it is referred\nto by the community. This paper focuses on discovering challenges and defining\nmodels needed when trying to approach the problem of routing algorithmically.\nIt provides an overview of relevant speedrunning literature, extracting vital\ninformation and formulating criticism. Important categorizations are pointed\nout and a nomenclature is build to support professional discussion. Different\nconcepts of graph representations are presented and their potential is\ndiscussed with regard to solving the speedrun routing optimization problem.\nVisions both for problem modeling as well as solving are presented and assessed\nregarding suitability and expected challenges. This results in a vision of\npotential solutions and what will be addressed in the future.",
    "descriptor": "\nComments: 8 pages, submitted to IEEE Conference on Games 2021\n",
    "authors": [
      "Matthias Gro\u00df",
      "Dietlind Z\u00fchlke",
      "Boris Naujoks"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01182"
  },
  {
    "id": "arXiv:2106.01183",
    "title": "A Cluster-based Approach for Improving Isotropy in Contextual Embedding  Space",
    "abstract": "The representation degeneration problem in Contextual Word Representations\n(CWRs) hurts the expressiveness of the embedding space by forming an\nanisotropic cone where even unrelated words have excessively positive\ncorrelations. Existing techniques for tackling this issue require a learning\nprocess to re-train models with additional objectives and mostly employ a\nglobal assessment to study isotropy. Our quantitative analysis over isotropy\nshows that a local assessment could be more accurate due to the clustered\nstructure of CWRs. Based on this observation, we propose a local cluster-based\nmethod to address the degeneration issue in contextual embedding spaces. We\nshow that in clusters including punctuations and stop words, local dominant\ndirections encode structural information, removing which can improve CWRs\nperformance on semantic tasks. Moreover, we find that tense information in verb\nrepresentations dominates sense semantics. We show that removing dominant\ndirections of verb representations can transform the space to better suit\nsemantic applications. Our experiments demonstrate that the proposed\ncluster-based method can mitigate the degeneration problem on multiple tasks.",
    "descriptor": "\nComments: To appear in ACL 2021 main conference\n",
    "authors": [
      "Sara Rajaee",
      "Mohammad Taher Pilehvar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01183"
  },
  {
    "id": "arXiv:2106.01184",
    "title": "Formally Verified Convergence of Policy-Rich DBF Routing Protocols",
    "abstract": "In this paper we present new general convergence results about the behaviour\nof Distributed Bellman-Ford (DBF) family of routing protocols, which includes\ndistance-vector protocols (e.g. RIP) and path-vector protocols (e.g. BGP).\nFirst, we propose a new algebraic model for abstract routing problems which\nhas fewer primitives than previous models and can represent more expressive\npolicy languages. The new model is also the first to allow concurrent reasoning\nabout distance-vector and path-vector protocols.\nSecond, we explicitly demonstrate how DBF routing protocols are instances of\na larger class of asynchronous iterative algorithms, for which there already\nexist powerful results about convergence. These results allow us to build upon\nconditions previously shown by Sobrinho to be sufficient and necessary for the\nconvergence of path-vector protocols and generalise and strengthen them in\nvarious ways: we show that, with a minor modification, they also apply to\ndistance-vector protocols; we prove they guarantee that the final routing\nsolution reached is unique, thereby eliminating the possibility of anomalies\nsuch as BGP wedgies; we relax the model of asynchronous communication, showing\nthat the results still hold if routing messages can be lost, reordered, and\nduplicated.\nThirdly, our model and our accompanying theoretical results have been fully\nformalised in the Agda theorem prover. The resulting library is a powerful tool\nfor quickly prototyping and formally verifying new policy languages. As an\nexample, we formally verify the correctness of a policy language with many of\nthe features of BGP including communities, conditional policy, path-inflation\nand route filtering.",
    "descriptor": "",
    "authors": [
      "Matthew L. Daggitt",
      "Timothy G. Griffin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.01184"
  },
  {
    "id": "arXiv:2106.01186",
    "title": "Self-Supervised Document Similarity Ranking via Contextualized Language  Models and Hierarchical Inference",
    "abstract": "We present a novel model for the problem of ranking a collection of documents\naccording to their semantic similarity to a source (query) document. While the\nproblem of document-to-document similarity ranking has been studied, most\nmodern methods are limited to relatively short documents or rely on the\nexistence of \"ground-truth\" similarity labels. Yet, in most common real-world\ncases, similarity ranking is an unsupervised problem as similarity labels are\nunavailable. Moreover, an ideal model should not be restricted by documents'\nlength. Hence, we introduce SDR, a self-supervised method for document\nsimilarity that can be applied to documents of arbitrary length. Importantly,\nSDR can be effectively applied to extremely long documents, exceeding the 4,096\nmaximal token limits of Longformer. Extensive evaluations on large document\ndatasets show that SDR significantly outperforms its alternatives across all\nmetrics. To accelerate future research on unlabeled long document similarity\nranking, and as an additional contribution to the community, we herein publish\ntwo human-annotated test sets of long documents similarity evaluation. The SDR\ncode and datasets are publicly available.",
    "descriptor": "",
    "authors": [
      "Dvir Ginzburg",
      "Itzik Malkiel",
      "Oren Barkan",
      "Avi Caciularu",
      "Noam Koenigstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01186"
  },
  {
    "id": "arXiv:2106.01191",
    "title": "Topic-Aware Evidence Reasoning and Stance-Aware Aggregation for Fact  Verification",
    "abstract": "Fact verification is a challenging task that requires simultaneously\nreasoning and aggregating over multiple retrieved pieces of evidence to\nevaluate the truthfulness of a claim. Existing approaches typically (i) explore\nthe semantic interaction between the claim and evidence at different\ngranularity levels but fail to capture their topical consistency during the\nreasoning process, which we believe is crucial for verification; (ii) aggregate\nmultiple pieces of evidence equally without considering their implicit stances\nto the claim, thereby introducing spurious information. To alleviate the above\nissues, we propose a novel topic-aware evidence reasoning and stance-aware\naggregation model for more accurate fact verification, with the following four\nkey properties: 1) checking topical consistency between the claim and evidence;\n2) maintaining topical coherence among multiple pieces of evidence; 3) ensuring\nsemantic similarity between the global topic information and the semantic\nrepresentation of evidence; 4) aggregating evidence based on their implicit\nstances to the claim. Extensive experiments conducted on the two benchmark\ndatasets demonstrate the superiority of the proposed model over several\nstate-of-the-art approaches for fact verification. The source code can be\nobtained from https://github.com/jasenchn/TARSA.",
    "descriptor": "\nComments: Accepted by ACL2021\n",
    "authors": [
      "Jiasheng Si",
      "Deyu Zhou",
      "Tongzhe Li",
      "Xingyu Shi",
      "Yulan He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01191"
  },
  {
    "id": "arXiv:2106.01195",
    "title": "Figurative Language in Recognizing Textual Entailment",
    "abstract": "We introduce a collection of recognizing textual entailment (RTE) datasets\nfocused on figurative language. We leverage five existing datasets annotated\nfor a variety of figurative language -- simile, metaphor, and irony -- and\nframe them into over 12,500 RTE examples.We evaluate how well state-of-the-art\nmodels trained on popular RTE datasets capture different aspects of figurative\nlanguage. Our results and analyses indicate that these models might not\nsufficiently capture figurative language, struggling to perform pragmatic\ninference and reasoning about world knowledge. Ultimately, our datasets provide\na challenging testbed for evaluating RTE models.",
    "descriptor": "\nComments: ACL 2021 (Findings)\n",
    "authors": [
      "Tuhin Chakrabarty",
      "Debanjan Ghosh",
      "Adam Poliak",
      "Smaranda Muresan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01195"
  },
  {
    "id": "arXiv:2106.01199",
    "title": "IrEne: Interpretable Energy Prediction for Transformers",
    "abstract": "Existing software-based energy measurements of NLP models are not accurate\nbecause they do not consider the complex interactions between energy\nconsumption and model execution. We present IrEne, an interpretable and\nextensible energy prediction system that accurately predicts the inference\nenergy consumption of a wide range of Transformer-based NLP models. IrEne\nconstructs a model tree graph that breaks down the NLP model into modules that\nare further broken down into low-level machine learning (ML) primitives. IrEne\npredicts the inference energy consumption of the ML primitives as a function of\ngeneralizable features and fine-grained runtime resource usage. IrEne then\naggregates these low-level predictions recursively to predict the energy of\neach module and finally of the entire model. Experiments across multiple\nTransformer models show IrEne predicts inference energy consumption of\ntransformer models with an error of under 7% compared to the ground truth. In\ncontrast, existing energy models see an error of over 50%. We also show how\nIrEne can be used to conduct energy bottleneck analysis and to easily evaluate\nthe energy impact of different architectural choices. We release the code and\ndata at https://github.com/StonyBrookNLP/irene.",
    "descriptor": "\nComments: ACL 2021 camera ready\n",
    "authors": [
      "Qingqing Cao",
      "Yash Kumar Lal",
      "Harsh Trivedi",
      "Aruna Balasubramanian",
      "Niranjan Balasubramanian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01199"
  },
  {
    "id": "arXiv:2106.01200",
    "title": "Numerical valuation of American basket options via partial differential  complementarity problems",
    "abstract": "We study the principal component analysis based approach introduced by\nReisinger & Wittum (2007) and the comonotonic approach considered by Hanbali &\nLinders (2019) for the approximation of American basket option values via\nmultidimensional partial differential complementarity problems (PDCPs). Both\napproximation approaches require the solution of just a limited number of\nlow-dimensional PDCPs. It is demonstrated by ample numerical experiments that\nthey define approximations that lie close to each other. Next, an efficient\ndiscretisation of the pertinent PDCPs is presented that leads to a favourable\nconvergence behaviour.",
    "descriptor": "",
    "authors": [
      "Karel in 't Hout",
      "Jacob Snoeijer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2106.01200"
  },
  {
    "id": "arXiv:2106.01207",
    "title": "Uncovering Constraint-Based Behavior in Neural Models via Targeted  Fine-Tuning",
    "abstract": "A growing body of literature has focused on detailing the linguistic\nknowledge embedded in large, pretrained language models. Existing work has\nshown that non-linguistic biases in models can drive model behavior away from\nlinguistic generalizations. We hypothesized that competing linguistic processes\nwithin a language, rather than just non-linguistic model biases, could obscure\nunderlying linguistic knowledge. We tested this claim by exploring a single\nphenomenon in four languages: English, Chinese, Spanish, and Italian. While\nhuman behavior has been found to be similar across languages, we find\ncross-linguistic variation in model behavior. We show that competing processes\nin a language act as constraints on model behavior and demonstrate that\ntargeted fine-tuning can re-weight the learned constraints, uncovering\notherwise dormant linguistic knowledge in models. Our results suggest that\nmodels need to learn both the linguistic constraints in a language and their\nrelative ranking, with mismatches in either producing non-human-like behavior.",
    "descriptor": "\nComments: Proceedings of 59th Annual Meeting of the Association for Computational Linguistics (ACL 2021)\n",
    "authors": [
      "Forrest Davis",
      "Marten van Schijndel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01207"
  },
  {
    "id": "arXiv:2106.01210",
    "title": "Cross-document Coreference Resolution over Predicted Mentions",
    "abstract": "Coreference resolution has been mostly investigated within a single document\nscope, showing impressive progress in recent years based on end-to-end models.\nHowever, the more challenging task of cross-document (CD) coreference\nresolution remained relatively under-explored, with the few recent models\napplied only to gold mentions. Here, we introduce the first end-to-end model\nfor CD coreference resolution from raw text, which extends the prominent model\nfor within-document coreference to the CD setting. Our model achieves\ncompetitive results for event and entity coreference resolution on gold\nmentions. More importantly, we set first baseline results, on the standard ECB+\ndataset, for CD coreference resolution over predicted mentions. Further, our\nmodel is simpler and more efficient than recent CD coreference resolution\nsystems, while not using any external resources.",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Arie Cattan",
      "Alon Eirew",
      "Gabriel Stanovsky",
      "Mandar Joshi",
      "Ido Dagan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01210"
  },
  {
    "id": "arXiv:2106.01215",
    "title": "Visual Analysis of Electronic Densities and Transitions in Molecules",
    "abstract": "The study of electronic transitions within a molecule connected to the\nabsorption or emission of light is a common task in the process of the design\nof new materials. The transitions are complex quantum mechanical processes and\na detailed analysis requires a breakdown of these processes into components\nthat can be interpreted via characteristic chemical properties. We approach\nthese tasks by providing a detailed analysis of the electron density field.\nThis entails methods to quantify and visualize electron localization and\ntransfer from molecular subgroups combining spatial and abstract\nrepresentations. The core of our method uses geometric segmentation of the\nelectronic density field coupled with a graph-theoretic formulation of charge\ntransfer between molecular subgroups. The design of the methods has been guided\nby the goal of providing a generic and objective analysis following fundamental\nconcepts. We illustrate the proposed approach using several case studies\ninvolving the study of electronic transitions in different molecular systems.",
    "descriptor": "\nComments: 15 pages, 9 figures, To appear in EuroVis 2021\n",
    "authors": [
      "Talha Bin Masood",
      "Signe Sidwall Thygesen",
      "Mathieu Linares",
      "Alexei I. Abrikosov",
      "Vijay Natarajan",
      "Ingrid Hotz"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computational Geometry (cs.CG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.01215"
  },
  {
    "id": "arXiv:2106.01216",
    "title": "Evidential Turing Processes",
    "abstract": "A probabilistic classifier with reliable predictive uncertainties i) fits\nsuccessfully to the target domain data, ii) provides calibrated class\nprobabilities in difficult regions of the target domain (e.g. class overlap),\nand iii) accurately identifies queries coming out of the target domain and\nreject them. We introduce an original combination of evidential deep learning,\nneural processes, and neural Turing machines capable of providing all three\nessential properties mentioned above for total uncertainty quantification. We\nobserve our method on three image classification benchmarks and two neural net\narchitectures to consistently give competitive or superior scores with respect\nto multiple uncertainty quantification metrics against state-of-the-art methods\nexplicitly tailored to one or a few of them. Our unified solution delivers an\nimplementation-friendly and computationally efficient recipe for safety\nclearance and provides intellectual economy to an investigation of algorithmic\nroots of epistemic awareness in deep neural nets.",
    "descriptor": "",
    "authors": [
      "Melih Kandemir",
      "Abdullah Akg\u00fcl",
      "Manuel Haussmann",
      "Gozde Unal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01216"
  },
  {
    "id": "arXiv:2106.01217",
    "title": "DFGC 2021: A DeepFake Game Competition",
    "abstract": "This paper presents a summary of the DFGC 2021 competition. DeepFake\ntechnology is developing fast, and realistic face-swaps are increasingly\ndeceiving and hard to detect. At the same time, DeepFake detection methods are\nalso improving. There is a two-party game between DeepFake creators and\ndetectors. This competition provides a common platform for benchmarking the\nadversarial game between current state-of-the-art DeepFake creation and\ndetection methods. In this paper, we present the organization, results and top\nsolutions of this competition and also share our insights obtained during this\nevent. We also release the DFGC-21 testing dataset collected from our\nparticipants to further benefit the research community.",
    "descriptor": "",
    "authors": [
      "Bo Peng",
      "Hongxing Fan",
      "Wei Wang",
      "Jing Dong",
      "Yuezun Li",
      "Siwei Lyu",
      "Qi Li",
      "Zhenan Sun",
      "Han Chen",
      "Baoying Chen",
      "Yanjie Hu",
      "Shenghai Luo",
      "Junrui Huang",
      "Yutong Yao",
      "Boyuan Liu",
      "Hefei Ling",
      "Guosheng Zhang",
      "Zhiliang Xu",
      "Changtao Miao",
      "Changlei Lu",
      "Shan He",
      "Xiaoyan Wu",
      "Wanyi Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01217"
  },
  {
    "id": "arXiv:2106.01221",
    "title": "Differential Privacy for Text Analytics via Natural Text Sanitization",
    "abstract": "Texts convey sophisticated knowledge. However, texts also convey sensitive\ninformation. Despite the success of general-purpose language models and\ndomain-specific mechanisms with differential privacy (DP), existing text\nsanitization mechanisms still provide low utility, as cursed by the\nhigh-dimensional text representation. The companion issue of utilizing\nsanitized texts for downstream analytics is also under-explored. This paper\ntakes a direct approach to text sanitization. Our insight is to consider both\nsensitivity and similarity via our new local DP notion. The sanitized texts\nalso contribute to our sanitization-aware pretraining and fine-tuning, enabling\nprivacy-preserving natural language processing over the BERT language model\nwith promising utility. Surprisingly, the high utility does not boost up the\nsuccess rate of inference attacks.",
    "descriptor": "\nComments: ACL-ICJNLP'21 Findings; The first two authors contributed equally\n",
    "authors": [
      "Xiang Yue",
      "Minxin Du",
      "Tianhao Wang",
      "Yaliang Li",
      "Huan Sun",
      "Sherman S. M. Chow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.01221"
  },
  {
    "id": "arXiv:2106.01223",
    "title": "A Unified Generative Framework for Various NER Subtasks",
    "abstract": "Named Entity Recognition (NER) is the task of identifying spans that\nrepresent entities in sentences. Whether the entity spans are nested or\ndiscontinuous, the NER task can be categorized into the flat NER, nested NER,\nand discontinuous NER subtasks. These subtasks have been mainly solved by the\ntoken-level sequence labelling or span-level classification. However, these\nsolutions can hardly tackle the three kinds of NER subtasks concurrently. To\nthat end, we propose to formulate the NER subtasks as an entity span sequence\ngeneration task, which can be solved by a unified sequence-to-sequence\n(Seq2Seq) framework. Based on our unified framework, we can leverage the\npre-trained Seq2Seq model to solve all three kinds of NER subtasks without the\nspecial design of the tagging schema or ways to enumerate spans. We exploit\nthree types of entity representations to linearize entities into a sequence.\nOur proposed framework is easy-to-implement and achieves state-of-the-art\n(SoTA) or near SoTA performance on eight English NER datasets, including two\nflat NER datasets, three nested NER datasets, and three discontinuous NER\ndatasets.",
    "descriptor": "\nComments: Accepted in the main conference of ACL-IJCNLP 2021\n",
    "authors": [
      "Hang Yan",
      "Tao Gui",
      "Junqi Dai",
      "Qipeng Guo",
      "Zheng Zhang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01223"
  },
  {
    "id": "arXiv:2106.01226",
    "title": "Semi-Supervised Semantic Segmentation with Cross Pseudo Supervision",
    "abstract": "In this paper, we study the semi-supervised semantic segmentation problem via\nexploring both labeled data and extra unlabeled data. We propose a novel\nconsistency regularization approach, called cross pseudo supervision (CPS). Our\napproach imposes the consistency on two segmentation networks perturbed with\ndifferent initialization for the same input image. The pseudo one-hot label\nmap, output from one perturbed segmentation network, is used to supervise the\nother segmentation network with the standard cross-entropy loss, and vice\nversa. The CPS consistency has two roles: encourage high similarity between the\npredictions of two perturbed networks for the same input image, and expand\ntraining data by using the unlabeled data with pseudo labels. Experiment\nresults show that our approach achieves the state-of-the-art semi-supervised\nsegmentation performance on Cityscapes and PASCAL VOC 2012.",
    "descriptor": "\nComments: Accepted by CVPR 2021\n",
    "authors": [
      "Xiaokang Chen",
      "Yuhui Yuan",
      "Gang Zeng",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01226"
  },
  {
    "id": "arXiv:2106.01227",
    "title": "Improving low-resource ASR performance with untranscribed out-of-domain  data",
    "abstract": "Semi-supervised training (SST) is a common approach to leverage\nuntranscribed/unlabeled speech data to improve automatic speech recognition\nperformance in low-resource languages. However, if the available unlabeled\nspeech is mismatched to the target domain, SST is not as effective, and in many\ncases performs worse than the original system. In this paper, we address the\nissue of low-resource ASR when only untranscribed out-of-domain speech data is\nreadily available in the target language. Specifically, we look to improve\nperformance on conversational/telephony speech (target domain) using web\nresources, in particular YouTube data, which more closely resembles\nnews/topical broadcast data. Leveraging SST, we show that while in some cases\nsimply pooling the out-of-domain data with the training data lowers word error\nrate (WER), in all cases, we see improvements if we train first with the\nout-of-domain data and then fine-tune the resulting model with the original\ntraining data. Using 2000 hours of speed perturbed YouTube audio in each target\nlanguage, with semi-supervised transcripts, we show improvements on multiple\nlanguages/data sets, of up to 16.3% relative improvement in WER over the\nbaseline systems and up to 7.4% relative improvement in WER over a system that\nsimply pools the out-of-domain data with the training data.",
    "descriptor": "",
    "authors": [
      "Jayadev Billa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.01227"
  },
  {
    "id": "arXiv:2106.01228",
    "title": "Metaphor Generation with Conceptual Mappings",
    "abstract": "Generating metaphors is a difficult task as it requires understanding nuanced\nrelationships between abstract concepts. In this paper, we aim to generate a\nmetaphoric sentence given a literal expression by replacing relevant verbs.\nGuided by conceptual metaphor theory, we propose to control the generation\nprocess by encoding conceptual mappings between cognitive domains to generate\nmeaningful metaphoric expressions. To achieve this, we develop two methods: 1)\nusing FrameNet-based embeddings to learn mappings between domains and applying\nthem at the lexical level (CM-Lex), and 2) deriving source/target pairs to\ntrain a controlled seq-to-seq generation model (CM-BART). We assess our methods\nthrough automatic and human evaluation for basic metaphoricity and conceptual\nmetaphor presence. We show that the unsupervised CM-Lex model is competitive\nwith recent deep learning metaphor generation systems, and CM-BART outperforms\nall other models both in automatic and human evaluations.",
    "descriptor": "\nComments: 13 pages, 3 figures, to be published in the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)\n",
    "authors": [
      "Kevin Stowe",
      "Tuhin Chakrabarty",
      "Nanyun Peng",
      "Smaranda Muresan",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01228"
  },
  {
    "id": "arXiv:2106.01229",
    "title": "Lower Perplexity is Not Always Human-Like",
    "abstract": "In computational psycholinguistics, various language models have been\nevaluated against human reading behavior (e.g., eye movement) to build\nhuman-like computational models. However, most previous efforts have focused\nalmost exclusively on English, despite the recent trend towards linguistic\nuniversal within the general community. In order to fill the gap, this paper\ninvestigates whether the established results in computational psycholinguistics\ncan be generalized across languages. Specifically, we re-examine an established\ngeneralization -- the lower perplexity a language model has, the more\nhuman-like the language model is -- in Japanese with typologically different\nstructures from English. Our experiments demonstrate that this established\ngeneralization exhibits a surprising lack of universality; namely, lower\nperplexity is not always human-like. Moreover, this discrepancy between English\nand Japanese is further explored from the perspective of (non-)uniform\ninformation density. Overall, our results suggest that a cross-lingual\nevaluation will be necessary to construct human-like computational models.",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Tatsuki Kuribayashi",
      "Yohei Oseki",
      "Takumi Ito",
      "Ryo Yoshida",
      "Masayuki Asahara",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01229"
  },
  {
    "id": "arXiv:2106.01232",
    "title": "A weighted unified informetrics based on Scopus and WoS",
    "abstract": "Numerous indexing databases keep track of the number of publications,\ncitations, etc. in order to maintain the progress of science and individual.\nHowever, the choice of journals and articles varies among these indexing\ndatabases, hence the number of citations and h-index varies. There is no common\nplatform exists that can provide a single count for the number of publications,\ncitations, h-index, etc. To overcome this limitation, we have proposed a\nweighted unified informetrics, named \"conflate\". The proposed system takes into\naccount the input from multiple indexing databases and generates a single\noutput. Here, we have used the data from Scopus and WoS to generate a conflate\ndataset. Further, a comparative analysis of conflate has been performed with\nScopus and WoS at three levels: author, organization, and journal. Finally, a\nmapping is proposed between research publications and distributed ledger\ntechnology in order to provide a transparent and distributed view to its\nstakeholders.",
    "descriptor": "\nComments: 22 pages, 8 figures\n",
    "authors": [
      "Parul Khurana",
      "Geetha Ganesan",
      "Gulshan Kumar",
      "Kiran Sharma"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.01232"
  },
  {
    "id": "arXiv:2106.01236",
    "title": "Improved Spanning on Theta-5",
    "abstract": "We show an upper bound of $\\frac{\n\\sin\\left(\\frac{3\\pi}{10}\\right)\n}{\n\\sin\\left(\\frac{2\\pi}{5}\\right)-\\sin\\left(\\frac{3\\pi}{10}\\right)\n}\n<5.70$ on the spanning ratio of $\\Theta_5$-graphs, improving on the previous\nbest known upper bound of $9.96$ [Bose, Morin, van Renssen, and Verdonschot.\nThe Theta-5-graph is a spanner. Computational Geometry, 2015.]",
    "descriptor": "\nComments: 21 pages, 30 figures, to be published in the proceedings of WADS 2021, The 17th Algorithms and Data Structures Symposium\n",
    "authors": [
      "Prosenjit Bose",
      "Darryl Hill",
      "Aur\u00e9lien Ooms"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.01236"
  },
  {
    "id": "arXiv:2106.01240",
    "title": "Phoenix: A Formally Verified Regenerating Vault",
    "abstract": "An attacker that gains access to a cryptocurrency user's private keys can\nperform any operation in her stead. Due to the decentralized nature of most\ncryptocurrencies, no entity can revert those operations. This is a central\nchallenge for decentralized systems, illustrated by numerous high-profile\nheists. Vault contracts reduce this risk by introducing artificial delay on\noperations, allowing abortion by the contract owner during the delay. However,\nthe theft of a key still renders the vault unusable and puts funds at risk.\nWe introduce Phoenix, a novel contract architecture that allows the user to\nrestore its security properties after key loss. Phoenix takes advantage of\nusers' ability to store keys in easily-available but less secure storage\n(tier-two) as well as more secure storage that is harder to access (tier-one).\nUnlike previous solutions, the user can restore Phoenix security after the\ntheft of tier-two keys and does not lose funds despite losing keys in either\ntier. Phoenix also introduces a mechanism to reduce the damage an attacker can\ncause in case of a tier-one compromise.\nWe formally specify Phoenix's required behavior and provide a prototype\nimplementation of Phoenix as an Ethereum contract. Since such an implementation\nis highly sensitive and vulnerable to subtle bugs, we apply a formal\nverification tool to prove specific code properties and identify faults. We\nhighlight a bug identified by the tool that could be exploited by an attacker\nto compromise Phoenix. After fixing the bug, the tool proved the low-level\nexecutable code's correctness.",
    "descriptor": "",
    "authors": [
      "Uri Kirstein",
      "Shelly Grossman",
      "Michael Mirkin",
      "James Wilcox",
      "Ittay Eyal",
      "Mooly Sagiv"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.01240"
  },
  {
    "id": "arXiv:2106.01242",
    "title": "A Privacy-Preserving and Trustable Multi-agent Learning Framework",
    "abstract": "Distributed multi-agent learning enables agents to cooperatively train a\nmodel without requiring to share their datasets. While this setting ensures\nsome level of privacy, it has been shown that, even when data is not directly\nshared, the training process is vulnerable to privacy attacks including data\nreconstruction and model inversion attacks. Additionally, malicious agents that\ntrain on inverted labels or random data, may arbitrarily weaken the accuracy of\nthe global model. This paper addresses these challenges and presents\nPrivacy-preserving and trustable Distributed Learning (PT-DL), a fully\ndecentralized framework that relies on Differential Privacy to guarantee strong\nprivacy protections of the agents' data, and Ethereum smart contracts to ensure\ntrustability. The paper shows that PT-DL is resilient up to a 50% collusion\nattack, with high probability, in a malicious trust model and the experimental\nevaluation illustrates the benefits of the proposed model as a\nprivacy-preserving and trustable distributed multi-agent learning system on\nseveral classification tasks.",
    "descriptor": "\nComments: This paper is an extended version of Reference [32]\n",
    "authors": [
      "Anudit Nagar",
      "Cuong Tran",
      "Ferdinando Fioretto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.01242"
  },
  {
    "id": "arXiv:2106.01250",
    "title": "Generic Programming with Combinators and Objects",
    "abstract": "We present a generic programming framework for OCAML which makes it possible\nto implement extensible transformations for a large scale of type definitions.\nOur framework makes use of objectoriented features of OCAML, utilising late\nbinding to override the default behaviour of generated transformations. The\nsupport for polymorphic variant types complements the ability to describe\ncomposable data types with the ability to implement composable transformations.",
    "descriptor": "",
    "authors": [
      "Dmitrii Kosarev",
      "Dmitry Boulytchev"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.01250"
  },
  {
    "id": "arXiv:2106.01251",
    "title": "Multilingual Medical Question Answering and Information Retrieval for  Rural Health Intelligence Access",
    "abstract": "In rural regions of several developing countries, access to quality\nhealthcare, medical infrastructure, and professional diagnosis is largely\nunavailable. Many of these regions are gradually gaining access to internet\ninfrastructure, although not with a strong enough connection to allow for\nsustained communication with a medical practitioner. Several deaths resulting\nfrom this lack of medical access, absence of patient's previous health records,\nand the unavailability of information in indigenous languages can be easily\nprevented. In this paper, we describe an approach leveraging the phenomenal\nprogress in Machine Learning and NLP (Natural Language Processing) techniques\nto design a model that is low-resource, multilingual, and a preliminary\nfirst-point-of-contact medical assistant. Our contribution includes defining\nthe NLP pipeline required for named-entity-recognition, language-agnostic\nsentence embedding, natural language translation, information retrieval,\nquestion answering, and generative pre-training for final query processing. We\nobtain promising results for this pipeline and preliminary results for EHR\n(Electronic Health Record) analysis with text summarization for medical\npractitioners to peruse for their diagnosis. Through this NLP pipeline, we aim\nto provide preliminary medical information to the user and do not claim to\nsupplant diagnosis from qualified medical practitioners. Using the input from\nsubject matter experts, we have compiled a large corpus to pre-train and\nfine-tune our BioBERT based NLP model for the specific tasks. We expect recent\nadvances in NLP architectures, several of which are efficient and\nprivacy-preserving models, to further the impact of our solution and improve on\nindividual task performance.",
    "descriptor": "",
    "authors": [
      "Vishal Vinod",
      "Susmit Agrawal",
      "Vipul Gaurav",
      "Pallavi R",
      "Savita Choudhary"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.01251"
  },
  {
    "id": "arXiv:2106.01254",
    "title": "Survey Equivalence: A Procedure for Measuring Classifier Accuracy  Against Human Labels",
    "abstract": "In many classification tasks, the ground truth is either noisy or subjective.\nExamples include: which of two alternative paper titles is better? is this\ncomment toxic? what is the political leaning of this news article? We refer to\nsuch tasks as survey settings because the ground truth is defined through a\nsurvey of one or more human raters. In survey settings, conventional\nmeasurements of classifier accuracy such as precision, recall, and\ncross-entropy confound the quality of the classifier with the level of\nagreement among human raters. Thus, they have no meaningful interpretation on\ntheir own. We describe a procedure that, given a dataset with predictions from\na classifier and K ratings per item, rescales any accuracy measure into one\nthat has an intuitive interpretation. The key insight is to score the\nclassifier not against the best proxy for the ground truth, such as a majority\nvote of the raters, but against a single human rater at a time. That score can\nbe compared to other predictors' scores, in particular predictors created by\ncombining labels from several other human raters. The survey equivalence of any\nclassifier is the minimum number of raters needed to produce the same expected\nscore as that found for the classifier.",
    "descriptor": "",
    "authors": [
      "Paul Resnick",
      "Yuqing Kong",
      "Grant Schoenebeck",
      "Tim Weninger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.01254"
  },
  {
    "id": "arXiv:2106.01258",
    "title": "Assessing the Reliability of Deep Learning Classifiers Through  Robustness Evaluation and Operational Profiles",
    "abstract": "The utilisation of Deep Learning (DL) is advancing into increasingly more\nsophisticated applications. While it shows great potential to provide\ntransformational capabilities, DL also raises new challenges regarding its\nreliability in critical functions. In this paper, we present a model-agnostic\nreliability assessment method for DL classifiers, based on evidence from\nrobustness evaluation and the operational profile (OP) of a given application.\nWe partition the input space into small cells and then \"assemble\" their\nrobustness (to the ground truth) according to the OP, where estimators on the\ncells' robustness and OPs are provided. Reliability estimates in terms of the\nprobability of misclassification per input (pmi) can be derived together with\nconfidence levels. A prototype tool is demonstrated with simplified case\nstudies. Model assumptions and extension to real-world applications are also\ndiscussed. While our model easily uncovers the inherent difficulties of\nassessing the DL dependability (e.g. lack of data with ground truth and\nscalability issues), we provide preliminary/compromised solutions to advance in\nthis research direction.",
    "descriptor": "\nComments: Accepted by the AISafety'21 Workshop at IJCAI-21. To appear in a volume of CEUR Workshop Proceedings\n",
    "authors": [
      "Xingyu Zhao",
      "Wei Huang",
      "Alec Banks",
      "Victoria Cox",
      "David Flynn",
      "Sven Schewe",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01258"
  },
  {
    "id": "arXiv:2106.01263",
    "title": "Global-Selector: A New Benchmark Dataset and Model Architecture for  Multi-turn Response Selection",
    "abstract": "As an essential component of dialogue systems, multi-turn response selection\naims to pick out the optimal response among a set of candidates to improve the\ndialogue fluency. In this paper, we investigate three problems of current\nresponse selection approaches, especially for generation-based conversational\nagents: (i) Existing approaches are often formulated as a sentence scoring\nproblem, which does not consider relationships between responses. (ii) Existing\nmodels tend to select undesirable candidates that have large overlaps with the\ndialogue history. (iii) Negative instances in training are mainly constructed\nby random sampling from the corpus, whereas generated candidates in practice\ntypically have a closer distribution. To address the above problems, we create\na new dataset called ConvAI2+ and propose a new response selector called\nGlobal-Selector. Experimental results show that Global-Selector trained on\nConvAI2+ have noticeable improvements in both accuracy and inference speed.",
    "descriptor": "",
    "authors": [
      "Chiyu Song",
      "Hongliang He",
      "Huachuan Qiu",
      "Haofei Yu",
      "Zhenzhong Lan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01263"
  },
  {
    "id": "arXiv:2106.01266",
    "title": "Sound-to-Imagination: Unsupervised Crossmodal Translation Using Deep  Dense Network Architecture",
    "abstract": "The motivation of our research is to develop a sound-to-image (S2I)\ntranslation system for enabling a human receiver to visually infer the\noccurrence of sound related events. We expect the computer to 'imagine' the\nscene from the captured sound, generating original images that picture the\nsound emitting source. Previous studies on similar topics opted for simplified\napproaches using data with low content diversity and/or strong supervision.\nDifferently, we propose to perform unsupervised S2I translation using thousands\nof distinct and unknown scenes, with slightly pre-cleaned data, just enough to\nguarantee aural-visual semantic coherence. To that end, we employ conditional\ngenerative adversarial networks (GANs) with a deep densely connected generator.\nBesides, we implemented a moving-average adversarial loss to address GANs\ntraining instability. Though the specified S2I translation problem is quite\nchallenging, we were able to generalize the translator model enough to obtain\nmore than 14%, in average, of interpretable and semantically coherent images\ntranslated from unknown sounds. Additionally, we present a solution using\ninformativity classifiers to perform quantitative evaluation of S2I\ntranslation.",
    "descriptor": "",
    "authors": [
      "Leonardo A. Fanzeres",
      "Climent Nadeu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.01266"
  },
  {
    "id": "arXiv:2106.01269",
    "title": "More Identifiable yet Equally Performant Transformers for Text  Classification",
    "abstract": "Interpretability is an important aspect of the trustworthiness of a model's\npredictions. Transformer's predictions are widely explained by the attention\nweights, i.e., a probability distribution generated at its self-attention unit\n(head). Current empirical studies provide shreds of evidence that attention\nweights are not explanations by proving that they are not unique. A recent\nstudy showed theoretical justifications to this observation by proving the\nnon-identifiability of attention weights. For a given input to a head and its\noutput, if the attention weights generated in it are unique, we call the\nweights identifiable. In this work, we provide deeper theoretical analysis and\nempirical observations on the identifiability of attention weights. Ignored in\nthe previous works, we find the attention weights are more identifiable than we\ncurrently perceive by uncovering the hidden role of the key vector. However,\nthe weights are still prone to be non-unique attentions that make them unfit\nfor interpretation. To tackle this issue, we provide a variant of the encoder\nlayer that decouples the relationship between key and value vector and provides\nidentifiable weights up to the desired length of the input. We prove the\napplicability of such variations by providing empirical justifications on\nvaried text classification tasks. The implementations are available at\nhttps://github.com/declare-lab/identifiable-transformers.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Rishabh Bhardwaj",
      "Navonil Majumder",
      "Soujanya Poria",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01269"
  },
  {
    "id": "arXiv:2106.01271",
    "title": "Deep learning-based multi-output quantile forecasting of PV generation",
    "abstract": "This paper develops probabilistic PV forecasters by taking advantage of\nrecent breakthroughs in deep learning. It tailored forecasting tool, named\nencoder-decoder, is implemented to compute intraday multi-output PV quantiles\nforecasts to efficiently capture the time correlation. The models are trained\nusing quantile regression, a non-parametric approach that assumes no prior\nknowledge of the probabilistic forecasting distribution. The case study is\ncomposed of PV production monitored on-site at the University of Li\\`ege\n(ULi\\`ege), Belgium. The weather forecasts from the regional climate model\nprovided by the Laboratory of Climatology are used as inputs of the deep\nlearning models. The forecast quality is quantitatively assessed by the\ncontinuous ranked probability and interval scores. The results indicate this\narchitecture improves the forecast quality and is computationally efficient to\nbe incorporated in an intraday decision-making tool for robust optimization.",
    "descriptor": "",
    "authors": [
      "Jonathan Dumas",
      "Colin Cointe",
      "Xavier Fettweis",
      "Bertrand Corn\u00e9lusse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01271"
  },
  {
    "id": "arXiv:2106.01272",
    "title": "Grasp stability prediction with time series data based on STFT and LSTM",
    "abstract": "With an increasing demand for robots, robotic grasping will has a more\nimportant role in future applications. This paper takes grasp stability\nprediction as the key technology for grasping and tries to solve the problem\nwith time series data inputs including the force and pressure data. Widely\napplied to more fields to predict unstable grasping with time series data,\nalgorithms can significantly promote the application of artificial intelligence\nin traditional industries. This research investigates models that combine\nshort-time Fourier transform (STFT) and long short-term memory (LSTM) and then\ntested generalizability with dexterous hand and suction cup gripper. The\nexperiments suggest good results for grasp stability prediction with the force\ndata and the generalized results in the pressure data. Among the 4 models,\n(Data + STFT) & LSTM delivers the best performance. We plan to perform more\nwork on grasp stability prediction, generalize the findings to different types\nof sensors, and apply the grasp stability prediction in more grasping use cases\nin real life.",
    "descriptor": "",
    "authors": [
      "Tao Wang",
      "Frank Kirchner"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.01272"
  },
  {
    "id": "arXiv:2106.01273",
    "title": "Chunk Content is not Enough: Chunk-Context Aware Resemblance Detection  for Deduplication Delta Compression",
    "abstract": "With the growing popularity of cloud storage, removing duplicated data across\nusers is getting more critical for service providers to reduce costs. Recently,\nData resemblance detection is a novel technology to detect redundancy among\nsimilarity. It extracts feature from each chunk content and treat chunks with\nhigh similarity as candidates for removing redundancy. However, popular\nresemblance methods such as \"N-transform\" and \"Finesse\" use only the chunk data\nfor feature extraction. A minor modification on the data chunk could seriously\ndeteriorate its capability for resemblance detection. In this paper, we\nproposes a novel chunk-context aware resemblance detection algorithm, called\nCARD, to mitigate this issue. CARD introduces a BP-Neural network-based\nchunk-context aware model, and uses N-sub-chunk shingles-based initial feature\nextraction strategy. It effectively integrates each data chunk content's\ninternal structure with the context information for feature extraction, the\nimpact of small changes in data chunks is significantly reduced. To evaluate\nits performance, we implement a CARD prototype and conduct extensive\nexperiments using real-world data sets. The results show that CARD can detect\nup to 75.03% more redundant data and accelerate the resemblance detection\noperations by 5.6 to 17.8 times faster compared with the state-of-the-art\nresemblance detection approaches.",
    "descriptor": "",
    "authors": [
      "Xuming Ye",
      "Xiaoye Xue",
      "Wenlong Tian",
      "Zhiyong Xu",
      "Weijun Xiao",
      "Ruixuan Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.01273"
  },
  {
    "id": "arXiv:2106.01277",
    "title": "Data augmentation and pre-trained networks for extremely low data  regimes unsupervised visual inspection",
    "abstract": "The use of deep features coming from pre-trained neural networks for\nunsupervised anomaly detection purposes has recently gathered momentum in the\ncomputer vision field. In particular, industrial inspection applications can\ntake advantage of such features, as demonstrated by the multiple successes of\nrelated methods on the MVTec Anomaly Detection (MVTec AD) dataset. These\nmethods make use of neural networks pre-trained on auxiliary classification\ntasks such as ImageNet. However, to our knowledge, no comparative study of\nrobustness to the low data regimes between these approaches has been conducted\nyet. For quality inspection applications, the handling of limited sample sizes\nmay be crucial as large quantities of images are not available for small\nseries. In this work, we aim to compare three approaches based on deep\npre-trained features when varying the quantity of available data in MVTec AD:\nKNN, Mahalanobis, and PaDiM. We show that although these methods are mostly\nrobust to small sample sizes, they still can benefit greatly from using data\naugmentation in the original image space, which allows to deal with very small\nproduction runs.",
    "descriptor": "\nComments: 16 pages, 8 figures, 9 tables, SPIE proceedings of Optical Metrology conference (this https URL)\n",
    "authors": [
      "Pierre Gutierrez",
      "Antoine Cordier",
      "Tha\u00efs Caldeira",
      "Th\u00e9ophile Sautory"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01277"
  },
  {
    "id": "arXiv:2106.01285",
    "title": "Sample-based Approximation of Nash in Large Many-Player Games via  Gradient Descent",
    "abstract": "Nash equilibrium is a central concept in game theory. Several Nash solvers\nexist, yet none scale to normal-form games with many actions and many players,\nespecially those with payoff tensors too big to be stored in memory. In this\nwork, we propose an approach that iteratively improves an approximation to a\nNash equilibrium through joint play. It accomplishes this by tracing a\npreviously established homotopy which connects instances of the game defined\nwith decaying levels of entropy regularization. To encourage iterates to remain\nnear this path, we efficiently minimize \\emph{average deviation incentive} via\nstochastic gradient descent, intelligently sampling entries in the payoff\ntensor as needed. This process can also be viewed as constructing and reacting\nto a polymatrix approximation to the game. In these ways, our proposed\napproach, \\emph{average deviation incentive descent with adaptive sampling}\n(ADIDAS), is most similar to three classical approaches, namely homotopy-type,\nLyapunov, and iterative polymatrix solvers. We demonstrate through experiments\nthe ability of this approach to approximate a Nash equilibrium in normal-form\ngames with as many as seven players and twenty one actions (over one trillion\noutcomes) that are orders of magnitude larger than those possible with prior\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Ian Gemp",
      "Rahul Savani",
      "Marc Lanctot",
      "Yoram Bachrach",
      "Thomas Anthony",
      "Richard Everett",
      "Andrea Tacchetti",
      "Tom Eccles",
      "J\u00e1nos Kram\u00e1r"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01285"
  },
  {
    "id": "arXiv:2106.01286",
    "title": "Cooperative Encoding and Decoding of Mixed Delay Traffic under  Random-User Activity",
    "abstract": "This paper analyses the multiplexing gain (MG) achievable over Wyner's\nsymmetric network with random user activity and random arrival of mixed-delay\ntraffic. The mixed-delay traffic is composed of delay-tolerant traffic and\ndelay-sensitive traffic where only the former can benefit from transmitter and\nreceiver cooperation since the latter is subject to stringent decoding delays.\nThe total number of cooperation rounds at transmitter and receiver sides is\nlimited to $\\D$ rounds. We derive inner and outer bounds on the MG region. In\nthe limit as $\\D\\to \\infty$, the bounds coincide and the results show that\ntransmitting delay-sensitive messages does not cause any penalty on the sum MG.\nFor finite $\\D$ our bounds are still close and prove that the penalty caused by\ndelay-sensitive transmissions is small.",
    "descriptor": "",
    "authors": [
      "Homa Nikbakht",
      "Mich\u00e8le Wigger",
      "Shlomo Shamai",
      "Jean-Marie Gorce"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.01286"
  },
  {
    "id": "arXiv:2106.01288",
    "title": "Bottom-Up and Top-Down Neural Processing Systems Design: Neuromorphic  Intelligence as the Convergence of Natural and Artificial Intelligence",
    "abstract": "While Moore's law has driven exponential computing power expectations, its\nnearing end calls for new avenues for improving the overall system performance.\nOne of these avenues is the exploration of new alternative brain-inspired\ncomputing architectures that promise to achieve the flexibility and\ncomputational efficiency of biological neural processing systems. Within this\ncontext, neuromorphic intelligence represents a paradigm shift in computing\nbased on the implementation of spiking neural network architectures tightly\nco-locating processing and memory. In this paper, we provide a comprehensive\noverview of the field, highlighting the different levels of granularity present\nin existing silicon implementations, comparing approaches that aim at\nreplicating natural intelligence (bottom-up) versus those that aim at solving\npractical artificial intelligence applications (top-down), and assessing the\nbenefits of the different circuit design styles used to achieve these goals.\nFirst, we present the analog, mixed-signal and digital circuit design styles,\nidentifying the boundary between processing and memory through time\nmultiplexing, in-memory computation and novel devices. Next, we highlight the\nkey tradeoffs for each of the bottom-up and top-down approaches, survey their\nsilicon implementations, and carry out detailed comparative analyses to extract\ndesign guidelines. Finally, we identify both necessary synergies and missing\nelements required to achieve a competitive advantage for neuromorphic edge\ncomputing over conventional machine-learning accelerators, and outline the key\nelements for a framework toward neuromorphic intelligence.",
    "descriptor": "",
    "authors": [
      "Charlotte Frenkel",
      "David Bol",
      "Giacomo Indiveri"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2106.01288"
  },
  {
    "id": "arXiv:2106.01300",
    "title": "PP-Rec: News Recommendation with Personalized User Interest and  Time-aware News Popularity",
    "abstract": "Personalized news recommendation methods are widely used in online news\nservices. These methods usually recommend news based on the matching between\nnews content and user interest inferred from historical behaviors. However,\nthese methods usually have difficulties in making accurate recommendations to\ncold-start users, and tend to recommend similar news with those users have\nread. In general, popular news usually contain important information and can\nattract users with different interests. Besides, they are usually diverse in\ncontent and topic. Thus, in this paper we propose to incorporate news\npopularity information to alleviate the cold-start and diversity problems for\npersonalized news recommendation. In our method, the ranking score for\nrecommending a candidate news to a target user is the combination of a\npersonalized matching score and a news popularity score. The former is used to\ncapture the personalized user interest in news. The latter is used to measure\ntime-aware popularity of candidate news, which is predicted based on news\ncontent, recency, and real-time CTR using a unified framework. Besides, we\npropose a popularity-aware user encoder to eliminate the popularity bias in\nuser behaviors for accurate interest modeling. Experiments on two real-world\ndatasets show our method can effectively improve the accuracy and diversity for\nnews recommendation.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Tao Qi",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.01300"
  },
  {
    "id": "arXiv:2106.01315",
    "title": "Assessing the Causal Impact of COVID-19 Related Policies on Outbreak  Dynamics: A Case Study in the US",
    "abstract": "To mitigate the spread of COVID-19 pandemic, decision-makers and public\nauthorities have announced various non-pharmaceutical policies. Analyzing the\ncausal impact of these policies in reducing the spread of COVID-19 is important\nfor future policy-making. The main challenge here is the existence of\nunobserved confounders (e.g., vigilance of residents). Besides, as the\nconfounders may be time-varying during COVID-19 (e.g., vigilance of residents\nchanges in the course of the pandemic), it is even more difficult to capture\nthem. In this paper, we study the problem of assessing the causal effects of\ndifferent COVID-19 related policies on the outbreak dynamics in different\ncounties at any given time period. To this end, we integrate data about\ndifferent COVID-19 related policies (treatment) and outbreak dynamics (outcome)\nfor different United States counties over time and analyze them with respect to\nvariables that can infer the confounders, including the covariates of different\ncounties, their relational information and historical information. Based on\nthese data, we develop a neural network based causal effect estimation\nframework which leverages above information in observational data and learns\nthe representations of time-varying (unobserved) confounders. In this way, it\nenables us to quantify the causal impact of policies at different\ngranularities, ranging from a category of policies with a certain goal to a\nspecific policy type in this category. Besides, experimental results also\nindicate the effectiveness of our proposed framework in capturing the\nconfounders for quantifying the causal impact of different policies. More\nspecifically, compared with several baseline methods, our framework captures\nthe outbreak dynamics more accurately, and our assessment of policies is more\nconsistent with existing epidemiological studies of COVID-19.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Jing Ma",
      "Yushun Dong",
      "Zheng Huang",
      "Daniel Mietchen",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.01315"
  },
  {
    "id": "arXiv:2106.01317",
    "title": "Enriching Transformers with Structured Tensor-Product Representations  for Abstractive Summarization",
    "abstract": "Abstractive summarization, the task of generating a concise summary of input\ndocuments, requires: (1) reasoning over the source document to determine the\nsalient pieces of information scattered across the long document, and (2)\ncomposing a cohesive text by reconstructing these salient facts into a shorter\nsummary that faithfully reflects the complex relations connecting these facts.\nIn this paper, we adapt TP-TRANSFORMER (Schlag et al., 2019), an architecture\nthat enriches the original Transformer (Vaswani et al., 2017) with the\nexplicitly compositional Tensor Product Representation (TPR), for the task of\nabstractive summarization. The key feature of our model is a structural bias\nthat we introduce by encoding two separate representations for each token to\nrepresent the syntactic structure (with role vectors) and semantic content\n(with filler vectors) separately. The model then binds the role and filler\nvectors into the TPR as the layer output. We argue that the structured\nintermediate representations enable the model to take better control of the\ncontents (salient facts) and structures (the syntax that connects the facts)\nwhen generating the summary. Empirically, we show that our TP-TRANSFORMER\noutperforms the Transformer and the original TP-TRANSFORMER significantly on\nseveral abstractive summarization datasets based on both automatic and human\nevaluations. On several syntactic and semantic probing tasks, we demonstrate\nthe emergent structural information in the role vectors and improved syntactic\ninterpretability in the TPR layer outputs. Code and models are available at\nhttps://github.com/jiangycTarheel/TPT-Summ.",
    "descriptor": "\nComments: NAACL 2021 (14 pages)\n",
    "authors": [
      "Yichen Jiang",
      "Asli Celikyilmaz",
      "Paul Smolensky",
      "Paul Soulos",
      "Sudha Rao",
      "Hamid Palangi",
      "Roland Fernandez",
      "Caitlin Smith",
      "Mohit Bansal",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01317"
  },
  {
    "id": "arXiv:2106.01325",
    "title": "Addressing the Long-term Impact of ML Decisions via Policy Regret",
    "abstract": "Machine Learning (ML) increasingly informs the allocation of opportunities to\nindividuals and communities in areas such as lending, education, employment,\nand beyond. Such decisions often impact their subjects' future characteristics\nand capabilities in an a priori unknown fashion. The decision-maker, therefore,\nfaces exploration-exploitation dilemmas akin to those in multi-armed bandits.\nFollowing prior work, we model communities as arms. To capture the long-term\neffects of ML-based allocation decisions, we study a setting in which the\nreward from each arm evolves every time the decision-maker pulls that arm. We\nfocus on reward functions that are initially increasing in the number of pulls\nbut may become (and remain) decreasing after a certain point. We argue that an\nacceptable sequential allocation of opportunities must take an arm's potential\nfor growth into account. We capture these considerations through the notion of\npolicy regret, a much stronger notion than the often-studied external regret,\nand present an algorithm with provably sub-linear policy regret for\nsufficiently long time horizons. We empirically compare our algorithm with\nseveral baselines and find that it consistently outperforms them, in particular\nfor long time horizons.",
    "descriptor": "\nComments: Accepted to IJCAI 2021\n",
    "authors": [
      "David Lindner",
      "Hoda Heidari",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01325"
  },
  {
    "id": "arXiv:2106.01326",
    "title": "Robust Voxelization and Visualization by Improved Tetrahedral Mesh  Generation",
    "abstract": "When obtaining interior 3D voxel data from triangular meshes, most existing\nmethods fail to handle low quality meshes which happens to take up a big\nportion on the internet. In this work we present a robust voxelization method\nthat is based on tetrahedral mesh generation within a user defined error bound.\nComparing to other tetrahedral mesh generation methods, our method produces\nmuch higher quality tetrahedral meshes as the intermediate outcome, which\nallows us to utilize a faster voxelization algorithm that is based on a\nstronger assumption. We show the results comparing to various methods including\nthe state-of-the-art. Our contribution includes a framework which takes\ntriangular mesh as an input and produces voxelized data, a proof to an unproved\nalgorithm that performs better than the state-of-the-art, and various\nexperiments including parallelization built on the GPU and CPU. We further\ntested our method on various dataset including Princeton ModelNet and Thingi10k\nto show the robustness of the framework, where near 100% availability is\nachieved, while others can only achieve around 50%.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Joseph Chen",
      "Ko-Wei Tai",
      "Wen-Chin Chen",
      "Ming Ouhyoung"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.01326"
  },
  {
    "id": "arXiv:2106.01329",
    "title": "Introducing \"Neuromorphic Computing and Engineering\"",
    "abstract": "The standard nature of computing is currently being challenged by a range of\nproblems that start to hinder technological progress. One of the strategies\nbeing proposed to address some of these problems is to develop novel\nbrain-inspired processing methods and technologies, and apply them to a wide\nrange of application scenarios. This is an extremely challenging endeavor that\nrequires researchers in multiple disciplines to combine their efforts and\nco-design at the same time the processing methods, the supporting computing\narchitectures, and their underlying technologies. The journal ``Neuromorphic\nComputing and Engineering'' (NCE) has been launched to support this new\ncommunity in this effort and provide a forum and repository for presenting and\ndiscussing its latest advances. Through close collaboration with our colleagues\non the editorial team, the scope and characteristics of NCE have been designed\nto ensure it serves a growing transdisciplinary and dynamic community across\nacademia and industry.",
    "descriptor": "\nComments: NCE Editorial\n",
    "authors": [
      "Giacomo Indiveri"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.01329"
  },
  {
    "id": "arXiv:2106.01331",
    "title": "Multi-Objectivizing Software Configuration Tuning (for a single  performance concern)",
    "abstract": "Automatically tuning software configuration for optimizing a single\nperformance attribute (e.g., minimizing latency) is not trivial, due to the\nnature of the configuration systems (e.g., complex landscape and expensive\nmeasurement). To deal with the problem, existing work has been focusing on\ndeveloping various effective optimizers. However, a prominent issue that all\nthese optimizers need to take care of is how to avoid the search being trapped\nin local optima -- a hard nut to crack for software configuration tuning due to\nits rugged and sparse landscape, and neighboring configurations tending to\nbehave very differently. Overcoming such in an expensive measurement setting is\neven more challenging. In this paper, we take a different perspective to tackle\nthis issue. Instead of focusing on improving the optimizer, we work on the\nlevel of optimization model. We do this by proposing a meta\nmulti-objectivization model (MMO) that considers an auxiliary performance\nobjective (e.g., throughput in addition to latency). What makes this model\nunique is that we do not optimize the auxiliary performance objective, but\nrather use it to make similarly-performing while different configurations less\ncomparable (i.e. Pareto nondominated to each other), thus preventing the search\nfrom being trapped in local optima.\nExperiments on eight real-world software systems/environments with diverse\nperformance attributes reveal that our MMO model is statistically more\neffective than state-of-the-art single-objective counterparts in overcoming\nlocal optima (up to 42% gain), while using as low as 24% of their measurements\nto achieve the same (or better) performance result.",
    "descriptor": "\nComments: 13 pages, 7 figures, 4 tables. In Proceedings of the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE'21), 2021\n",
    "authors": [
      "Tao Chen",
      "Miqing Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01331"
  },
  {
    "id": "arXiv:2106.01335",
    "title": "On the Distribution, Sparsity, and Inference-time Quantization of  Attention Values in Transformers",
    "abstract": "How much information do NLP tasks really need from a transformer's attention\nmechanism at application-time (inference)? From recent work, we know that there\nis sparsity in transformers and that the floating-points within its computation\ncan be discretized to fewer values with minimal loss to task accuracies.\nHowever, this requires retraining or even creating entirely new models, both of\nwhich can be expensive and carbon-emitting. Focused on optimizations that do\nnot require training, we systematically study the full range of typical\nattention values necessary. This informs the design of an inference-time\nquantization technique using both pruning and log-scaled mapping which produces\nonly a few (e.g. $2^3$) unique values. Over the tasks of question answering and\nsentiment analysis, we find nearly 80% of attention values can be pruned to\nzeros with minimal ($< 1.0\\%$) relative loss in accuracy. We use this pruning\ntechnique in conjunction with quantizing the attention values to only a 3-bit\nformat, without retraining, resulting in only a 0.8% accuracy reduction on\nquestion answering with fine-tuned RoBERTa.",
    "descriptor": "",
    "authors": [
      "Tianchu Ji",
      "Shraddhan Jain",
      "Michael Ferdman",
      "Peter Milder",
      "H. Andrew Schwartz",
      "Niranjan Balasubramanian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01335"
  },
  {
    "id": "arXiv:2106.01336",
    "title": "Improved Rates for Differentially Private Stochastic Convex Optimization  with Heavy-Tailed Data",
    "abstract": "We study stochastic convex optimization with heavy-tailed data under the\nconstraint of differential privacy. Most prior work on this problem is\nrestricted to the case where the loss function is Lipschitz. Instead, as\nintroduced by Wang, Xiao, Devadas, and Xu, we study general convex loss\nfunctions with the assumption that the distribution of gradients has bounded\n$k$-th moments. We provide improved upper bounds on the excess population risk\nunder approximate differential privacy of\n$\\tilde{O}\\left(\\sqrt{\\frac{d}{n}}+\\left(\\frac{d}{\\epsilon\nn}\\right)^{\\frac{k-1}{k}}\\right)$ and\n$\\tilde{O}\\left(\\frac{d}{n}+\\left(\\frac{d}{\\epsilon\nn}\\right)^{\\frac{2k-2}{k}}\\right)$ for convex and strongly convex loss\nfunctions, respectively. We also prove nearly-matching lower bounds under the\nconstraint of pure differential privacy, giving strong evidence that our bounds\nare tight.",
    "descriptor": "",
    "authors": [
      "Gautam Kamath",
      "Xingtu Liu",
      "Huanyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01336"
  },
  {
    "id": "arXiv:2106.01340",
    "title": "Transaction Fee Mechanism Design",
    "abstract": "Demand for blockchains such as Bitcoin and Ethereum is far larger than\nsupply, necessitating a mechanism that selects a subset of transactions to\ninclude \"on-chain\" from the pool of all pending transactions. EIP-1559 is a\nproposal to make several tightly coupled changes to the Ethereum blockchain's\ntransaction fee mechanism, including the introduction of variable-size blocks\nand a burned base fee that rises and falls with demand. These changes are\nslated for deployment in Ethereum's \"London fork,\" scheduled for late\nsummer~2021, at which point it will be the biggest economic change made to a\nmajor blockchain to date.\nThe first goal of this paper is to formalize the problem of designing a\ntransaction fee mechanism, taking into account the many idiosyncrasies of the\nblockchain setting (ranging from off-chain collusion between miners and users\nto the ease of money-burning). The second goal is to situate the specific\nmechanism proposed in EIP-1559 in this framework and rigorously interrogate its\ngame-theoretic properties. The third goal is to suggest competing designs that\noffer alternative sets of trade-offs. The final goal is to highlight research\nopportunities for the EC community that could help shape the future of\nblockchain transaction fee mechanisms.",
    "descriptor": "\nComments: Appears in the 22nd ACM Conference on Economics and Computation (EC '21). This conference paper is derived from Sections 2, 4, 5, 6, and 8 of the longer general-audience report published as arXiv:2012.00854\n",
    "authors": [
      "Tim Roughgarden"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2106.01340"
  },
  {
    "id": "arXiv:2106.01342",
    "title": "SAINT: Improved Neural Networks for Tabular Data via Row Attention and  Contrastive Pre-Training",
    "abstract": "Tabular data underpins numerous high-impact applications of machine learning\nfrom fraud detection to genomics and healthcare. Classical approaches to\nsolving tabular problems, such as gradient boosting and random forests, are\nwidely used by practitioners. However, recent deep learning methods have\nachieved a degree of performance competitive with popular techniques. We devise\na hybrid deep learning approach to solving tabular data problems. Our method,\nSAINT, performs attention over both rows and columns, and it includes an\nenhanced embedding method. We also study a new contrastive self-supervised\npre-training method for use when labels are scarce. SAINT consistently improves\nperformance over previous deep learning methods, and it even outperforms\ngradient boosting methods, including XGBoost, CatBoost, and LightGBM, on\naverage over a variety of benchmark tasks.",
    "descriptor": "",
    "authors": [
      "Gowthami Somepalli",
      "Micah Goldblum",
      "Avi Schwarzschild",
      "C. Bayan Bruss",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01342"
  },
  {
    "id": "arXiv:2106.01343",
    "title": "Reconciling interoperability with efficient Verification and Validation  within open source simulation environments",
    "abstract": "A Cyber-Physical System (CPS) comprises physical as well as software\nsubsystems. Simulation-based approaches are typically used to support design\nand Verification and Validation (V&V) of CPSs in several domains such as:\naerospace, defence, automotive, smart grid and healthcare. Accordingly, many\nsimulation-based tools are available, and this poses huge interoperability\nchallenges. To overcome them, in 2010 the Functional Mock-up Interface (FMI)\nwas proposed as an open standard to support both Model Exchange (ME) and\nCo-Simulation (CS). Models adhering to such a standard are called Functional\nMock-up Units (FMUs). FMUs play an essential role in defining complex CPSs\nthrough, e.g., the SSP standard. Simulation-based V&V of CPSs typically\nrequires exploring different scenarios (i.e., exogenous CPS input sequences),\nmany of them showing a shared prefix. Accordingly, the simulator state at the\nend of a shared prefix is saved and then restored and used as a start state for\nthe simulation of the next scenario. In this context, an important FMI feature\nis the capability to save and restore the internal FMU state on demand.\nUnfortunately, the implementation of this feature is not mandatory and it is\navailable only within some commercial software. This motivates developing such\na feature for open-source CPS simulation environments. In this paper, we focus\non JModelica, an open-source modelling and simulation environment for CPSs\ndefined in the Modelica language. We describe how we have endowed JModelica\nwith our open-source implementation of the FMI 2.0 functions to save and\nrestore internal states of FMUs for ME. Furthermore, we present results\nevaluating, through 934 benchmark models, correctness and efficiency of our\nextended JModelica. Our results show that simulation-based V&V is, on average,\n22 times faster with our get/set functionality than without it.",
    "descriptor": "\nComments: Abridged abstract. This article is 29 pages long\n",
    "authors": [
      "Stefano Sinisi",
      "Vadim Alimguzhin",
      "Toni Mancini",
      "Enrico Tronci"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2106.01343"
  },
  {
    "id": "arXiv:2106.01344",
    "title": "Random walk approximation for irreversible drift-diffusion process on  manifold: ergodicity, unconditional stability and convergence",
    "abstract": "Irreversible drift-diffusion processes are very common in biochemical\nreactions. They have a non-equilibrium stationary state (invariant measure)\nwhich does not satisfy detailed balance. For the corresponding Fokker-Planck\nequation on a closed manifold, via Voronoi tessellation, we propose two upwind\nfinite volume schemes with or without the information of the invariant measure.\nBoth two schemes enjoy stochastic $Q$-matrix structures and can be decomposed\nas a gradient flow part and a Hamiltonian flow part, which enable us to prove\nunconditional stability, ergodicity and error estimates. Based on two upwind\nschemes, several numerical examples - including sampling accelerated by a\nmixture flow, image transformations and simulations for stochastic model of\nchaotic system - are conducted. These two structure-preserving schemes also\ngive a natural random walk approximation for a generic irreversible\ndrift-diffusion process on a manifold. Thus they can be adapted to\nmanifold-related computations induced from high dimensional molecular dynamics.",
    "descriptor": "\nComments: 28 pages, 8 figures\n",
    "authors": [
      "Yuan Gao",
      "Jian-Guo Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.01344"
  },
  {
    "id": "arXiv:2106.01345",
    "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling",
    "abstract": "We present a framework that abstracts Reinforcement Learning (RL) as a\nsequence modeling problem. This allows us to draw upon the simplicity and\nscalability of the Transformer architecture, and associated advances in\nlanguage modeling such as GPT-x and BERT. In particular, we present Decision\nTransformer, an architecture that casts the problem of RL as conditional\nsequence modeling. Unlike prior approaches to RL that fit value functions or\ncompute policy gradients, Decision Transformer simply outputs the optimal\nactions by leveraging a causally masked Transformer. By conditioning an\nautoregressive model on the desired return (reward), past states, and actions,\nour Decision Transformer model can generate future actions that achieve the\ndesired return. Despite its simplicity, Decision Transformer matches or exceeds\nthe performance of state-of-the-art model-free offline RL baselines on Atari,\nOpenAI Gym, and Key-to-Door tasks.",
    "descriptor": "\nComments: First two authors contributed equally. Last two authors advised equally\n",
    "authors": [
      "Lili Chen",
      "Kevin Lu",
      "Aravind Rajeswaran",
      "Kimin Lee",
      "Aditya Grover",
      "Michael Laskin",
      "Pieter Abbeel",
      "Aravind Srinivas",
      "Igor Mordatch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01345"
  },
  {
    "id": "arXiv:2106.01350",
    "title": "On Efficiently Explaining Graph-Based Classifiers",
    "abstract": "Recent work has shown that not only decision trees (DTs) may not be\ninterpretable but also proposed a polynomial-time algorithm for computing one\nPI-explanation of a DT. This paper shows that for a wide range of classifiers,\nglobally referred to as decision graphs, and which include decision trees and\nbinary decision diagrams, but also their multi-valued variants, there exist\npolynomial-time algorithms for computing one PI-explanation. In addition, the\npaper also proposes a polynomial-time algorithm for computing one contrastive\nexplanation. These novel algorithms build on explanation graphs (XpG's). XpG's\ndenote a graph representation that enables both theoretical and practically\nefficient computation of explanations for decision graphs. Furthermore, the\npaper pro- poses a practically efficient solution for the enumeration of\nexplanations, and studies the complexity of deciding whether a given feature is\nincluded in some explanation. For the concrete case of decision trees, the\npaper shows that the set of all contrastive explanations can be enumerated in\npolynomial time. Finally, the experimental results validate the practical\napplicability of the algorithms proposed in the paper on a wide range of\npublicly available benchmarks.",
    "descriptor": "",
    "authors": [
      "Xuanxiang Huang",
      "Yacine Izza",
      "Alexey Ignatiev",
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01350"
  },
  {
    "id": "arXiv:2106.01352",
    "title": "NeRP: Neural Rearrangement Planning for Unknown Objects",
    "abstract": "Robots will be expected to manipulate a wide variety of objects in complex\nand arbitrary ways as they become more widely used in human environments. As\nsuch, the rearrangement of objects has been noted to be an important benchmark\nfor AI capabilities in recent years. We propose NeRP (Neural Rearrangement\nPlanning), a deep learning based approach for multi-step neural object\nrearrangement planning which works with never-before-seen objects, that is\ntrained on simulation data, and generalizes to the real world. We compare NeRP\nto several naive and model-based baselines, demonstrating that our approach is\nmeasurably better and can efficiently arrange unseen objects in fewer steps and\nwith less planning time. Finally, we demonstrate it on several challenging\nrearrangement problems in the real world.",
    "descriptor": "",
    "authors": [
      "Ahmed H. Qureshi",
      "Arsalan Mousavian",
      "Chris Paxton",
      "Michael C. Yip",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01352"
  },
  {
    "id": "arXiv:2106.01354",
    "title": "multiPRover: Generating Multiple Proofs for Improved Interpretability in  Rule Reasoning",
    "abstract": "We focus on a type of linguistic formal reasoning where the goal is to reason\nover explicit knowledge in the form of natural language facts and rules (Clark\net al., 2020). A recent work, named PRover (Saha et al., 2020), performs such\nreasoning by answering a question and also generating a proof graph that\nexplains the answer. However, compositional reasoning is not always unique and\nthere may be multiple ways of reaching the correct answer. Thus, in our work,\nwe address a new and challenging problem of generating multiple proof graphs\nfor reasoning over natural language rule-bases. Each proof provides a different\nrationale for the answer, thereby improving the interpretability of such\nreasoning systems. In order to jointly learn from all proof graphs and exploit\nthe correlations between multiple proofs for a question, we pose this task as a\nset generation problem over structured output spaces where each proof is\nrepresented as a directed graph. We propose two variants of a proof-set\ngeneration model, multiPRover. Our first model, Multilabel-multiPRover,\ngenerates a set of proofs via multi-label classification and implicit\nconditioning between the proofs; while the second model, Iterative-multiPRover,\ngenerates proofs iteratively by explicitly conditioning on the previously\ngenerated proofs. Experiments on multiple synthetic, zero-shot, and\nhuman-paraphrased datasets reveal that both multiPRover models significantly\noutperform PRover on datasets containing multiple gold proofs.\nIterative-multiPRover obtains state-of-the-art proof F1 in zero-shot scenarios\nwhere all examples have single correct proofs. It also generalizes better to\nquestions requiring higher depths of reasoning where multiple proofs are more\nfrequent. Our code and models are publicly available at\nhttps://github.com/swarnaHub/multiPRover",
    "descriptor": "\nComments: NAACL 2021 (16 pages)\n",
    "authors": [
      "Swarnadeep Saha",
      "Prateek Yadav",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.01354"
  },
  {
    "id": "arXiv:2106.01364",
    "title": "The Semi-Supervised iNaturalist Challenge at the FGVC8 Workshop",
    "abstract": "Semi-iNat is a challenging dataset for semi-supervised classification with a\nlong-tailed distribution of classes, fine-grained categories, and domain shifts\nbetween labeled and unlabeled data. This dataset is behind the second iteration\nof the semi-supervised recognition challenge to be held at the FGVC8 workshop\nat CVPR 2021. Different from the previous one, this dataset (i) includes images\nof species from different kingdoms in the natural taxonomy, (ii) is at a larger\nscale --- with 810 in-class and 1629 out-of-class species for a total of 330k\nimages, and (iii) does not provide in/out-of-class labels, but provides coarse\ntaxonomic labels (kingdom and phylum) for the unlabeled images. This document\ndescribes baseline results and the details of the dataset which is available\nhere: \\url{https://github.com/cvl-umass/semi-inat-2021}.",
    "descriptor": "\nComments: Tech report for Semi-iNat 2021 challenge, competition page: this https URL\n",
    "authors": [
      "Jong-Chyi Su",
      "Subhransu Maji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01364"
  },
  {
    "id": "arXiv:2104.08135",
    "title": "Sharp bounds for the number of regions of maxout networks and vertices  of Minkowski sums",
    "abstract": "We present results on the number of linear regions of the functions that can\nbe represented by artificial feedforward neural networks with maxout units. A\nrank-k maxout unit is a function computing the maximum of $k$ linear functions.\nFor networks with a single layer of maxout units, the linear regions correspond\nto the upper vertices of a Minkowski sum of polytopes. We obtain face counting\nformulas in terms of the intersection posets of tropical hypersurfaces or the\nnumber of upper faces of partial Minkowski sums, along with explicit sharp\nupper bounds for the number of regions for any input dimension, any number of\nunits, and any ranks, in the cases with and without biases. Based on these\nresults we also obtain asymptotically sharp upper bounds for networks with\nmultiple layers.",
    "descriptor": "\nComments: 25 pages, 5 figures\n",
    "authors": [
      "Guido Mont\u00fafar",
      "Yue Ren",
      "Leon Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08135"
  },
  {
    "id": "arXiv:2106.00703",
    "title": "Excluding a Planar Matching Minor in Bipartite Graphs",
    "abstract": "Matching minors are a specialisation of minors fit for the study of graph\nwith perfect matchings. The notion of matching minors has been used to give a\nstructural description of bipartite graphs on which the number of perfect\nmatchings can becomputed efficiently, based on a result of Little, by McCuaig\net al. in 1999.In this paper we generalise basic ideas from the graph minor\nseries by Robertson and Seymour to the setting of bipartite graphs with perfect\nmatchings. We introducea version of Erdos-Posa property for matching minors and\nfind a direct link between this property and planarity. From this, it follows\nthat a class of bipartite graphs withperfect matchings has bounded perfect\nmatching width if and only if it excludes aplanar matching minor. We also\npresent algorithms for bipartite graphs of bounded perfect matching width for a\nmatching version of the disjoint paths problem, matching minor containment, and\nfor counting the number of perfect matchings. From our structural results, we\nobtain that recognising whether a bipartite graphGcontains afixed planar\ngraphHas a matching minor, and that counting the number of perfect matchings of\na bipartite graph that excludes a fixed planar graph as a matching minor are\nboth polynomial time solvable.",
    "descriptor": "",
    "authors": [
      "Archontia C Giannopoulou",
      "Stephan Kreutzer",
      "Sebastian Wiederrecht"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.00703"
  },
  {
    "id": "arXiv:2106.00715",
    "title": "A Theory for Locus Ellipticity of Poncelet 3-Periodics",
    "abstract": "We provide a theory as to why the locus of a triangle center over Poncelet\n3-periodics in an ellipse pair is an ellipse or not. For the confocal pair\n(elliptic billiard), we show that if the center can be expressed as a fixed\naffine combination of barycenter, circumcenter, and mittenpunkt (which is\nstationary over the confocal family), then its locus will be an ellipse. We\nalso provide conditions under which a particular locus will be a circle or a\nsegment. We also analyze locus turning number and monotonicity with respect to\nvertices of the 3-periodic family. Finally we write out expressions for the\nconvex quartic locus of the incenter for a generic Poncelet family,\nconjecturing it can only be an ellipse if the pair is confocal.",
    "descriptor": "\nComments: 13 pages, 5 figures, 3 tables, and 5 video links\n",
    "authors": [
      "Mark Helman",
      "Dominique Laurain",
      "Dan Reznik",
      "Ronaldo Garcia"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)",
      "Robotics (cs.RO)",
      "Algebraic Geometry (math.AG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00715"
  },
  {
    "id": "arXiv:2106.00746",
    "title": "On-Line Policy Iteration for Infinite Horizon Dynamic Programming",
    "abstract": "In this paper we propose an on-line policy iteration (PI) algorithm for\nfinite-state infinite horizon discounted dynamic programming, whereby the\npolicy improvement operation is done on-line, only for the states that are\nencountered during operation of the system. This allows the continuous\nupdating/improvement of the current policy, thus resulting in a form of on-line\nPI that incorporates the improved controls into the current policy as new\nstates and controls are generated. The algorithm converges in a finite number\nof stages to a type of locally optimal policy, and suggests the possibility of\nvariants of PI and multiagent PI where the policy improvement is simplified.\nMoreover, the algorithm can be used with on-line replanning, and is also\nwell-suited for on-line PI algorithms with value and policy approximations.",
    "descriptor": "",
    "authors": [
      "Dimitri Bertsekas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00746"
  },
  {
    "id": "arXiv:2106.00753",
    "title": "Is good old GRAPPA dead?",
    "abstract": "We perform a qualitative analysis of performance of XPDNet, a\nstate-of-the-art deep learning approach for MRI reconstruction, compared to\nGRAPPA, a classical approach. We do this in multiple settings, in particular\ntesting the robustness of the XPDNet to unseen settings, and show that the\nXPDNet can to some degree generalize well.",
    "descriptor": "\nComments: Presented at ISMRM 2021\n",
    "authors": [
      "Zaccharie Ramzi",
      "Alexandre Vignaud",
      "Jean-Luc Starck",
      "Philippe Ciuciu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00753"
  },
  {
    "id": "arXiv:2106.00755",
    "title": "Assessment of a transient homogeneous reactor through in situ adaptive  tabulation",
    "abstract": "The development of computational models for the numerical simulation of\nchemically reacting flows operating in the turbulent regime requires the\nsolution of partial differential equations that represent the balance of mass,\nlinear momentum, chemical species, and energy. The chemical reactions of the\nmodel may involve detailed reaction mechanisms for the description of the\nphysicochemical phenomena. One of the biggest challenges is the stiffness of\nthe numerical simulation of these models and the nonlinear nature of species\nrate of reaction. This work presents a study of in situ adaptive tabulation\n(ISAT) technique, focusing on the accuracy, efficiency, and memory usage in the\nsimulation of homogeneous stirred reactor models using simple and complex\nreaction mechanisms. The combustion of carbon monoxide with oxygen and methane\nwith air mixtures are considered, using detailed reaction mechanisms with 4 and\n53 species, 3 and 325 reactions, respectively. The results of these simulations\nindicate that the developed implementation of ISAT technique has a absolute\nglobal error smaller than 1 %. Moreover, ISAT technique provides gains, in\nterms of computational time, of up to 80% when compared with the direct\nintegration of the full chemical kinetics. However, in terms of memory usage\nthe present implementation of ISAT technique is found to be excessively\ndemanding.",
    "descriptor": "",
    "authors": [
      "Americo Cunha Jr",
      "Luis Fernando Figueira da Silva"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Dynamical Systems (math.DS)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.00755"
  },
  {
    "id": "arXiv:2106.00757",
    "title": "Neural message passing for joint paratope-epitope prediction",
    "abstract": "Antibodies are proteins in the immune system which bind to antigens to detect\nand neutralise them. The binding sites in an antibody-antigen interaction are\nknown as the paratope and epitope, respectively, and the prediction of these\nregions is key to vaccine and synthetic antibody development. Contrary to prior\nart, we argue that paratope and epitope predictors require asymmetric\ntreatment, and propose distinct neural message passing architectures that are\ngeared towards the specific aspects of paratope and epitope prediction,\nrespectively. We obtain significant improvements on both tasks, setting the new\nstate-of-the-art and recovering favourable qualitative predictions on antigens\nof relevance to COVID-19.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Alice Del Vecchio",
      "Andreea Deac",
      "Pietro Li\u00f2",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2106.00757"
  },
  {
    "id": "arXiv:2106.00765",
    "title": "Connectivity constrains quantum codes",
    "abstract": "Quantum low-density parity-check (LDPC) codes are an important class of\nquantum error correcting codes. In such codes, each qubit only affects a\nconstant number of syndrome bits, and each syndrome bit only relies on some\nconstant number of qubits. Constructing quantum LDPC codes is challenging. It\nis an open problem to understand if there exist good quantum LDPC codes, i.e.\nwith constant rate and relative distance. Furthermore, techniques to perform\nfault-tolerant gates are poorly understood. We present a unified way to address\nthese problems. Our main results are a) a bound on the distance, b) a bound on\nthe code dimension and c) limitations on certain fault-tolerant gates that can\nbe applied to quantum LDPC codes. All three of these bounds are cast as a\nfunction of the graph separator of the connectivity graph representation of the\nquantum code. We find that unless the connectivity graph contains an expander,\nthe code is severely limited. This implies a necessary, but not sufficient,\ncondition to construct good codes. This is the first bound that studies the\nlimitations of quantum LDPC codes that does not rely on locality. As an\napplication, we present novel bounds on quantum LDPC codes associated with\nlocal graphs in $D$-dimensional hyperbolic space.",
    "descriptor": "",
    "authors": [
      "Nou\u00e9dyn Baspin",
      "Anirudh Krishna"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00765"
  },
  {
    "id": "arXiv:2106.00774",
    "title": "Optimizing Functionals on the Space of Probabilities with Input Convex  Neural Networks",
    "abstract": "Gradient flows are a powerful tool for optimizing functionals in general\nmetric spaces, including the space of probabilities endowed with the\nWasserstein metric. A typical approach to solving this optimization problem\nrelies on its connection to the dynamic formulation of optimal transport and\nthe celebrated Jordan-Kinderlehrer-Otto (JKO) scheme. However, this formulation\ninvolves optimization over convex functions, which is challenging, especially\nin high dimensions. In this work, we propose an approach that relies on the\nrecently introduced input-convex neural networks (ICNN) to parameterize the\nspace of convex functions in order to approximate the JKO scheme, as well as in\ndesigning functionals over measures that enjoy convergence guarantees. We\nderive a computationally efficient implementation of this JKO-ICNN framework\nand use various experiments to demonstrate its feasibility and validity in\napproximating solutions of low-dimensional partial differential equations with\nknown solutions. We also explore the use of our JKO-ICNN approach in high\ndimensions with an experiment in controlled generation for molecular discovery.",
    "descriptor": "",
    "authors": [
      "David Alvarez-Melis",
      "Yair Schiff",
      "Youssef Mroueh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00774"
  },
  {
    "id": "arXiv:2106.00783",
    "title": "Fourier Space Losses for Efficient Perceptual Image Super-Resolution",
    "abstract": "Many super-resolution (SR) models are optimized for high performance only and\ntherefore lack efficiency due to large model complexity. As large models are\noften not practical in real-world applications, we investigate and propose\nnovel loss functions, to enable SR with high perceptual quality from much more\nefficient models. The representative power for a given low-complexity generator\nnetwork can only be fully leveraged by strong guidance towards the optimal set\nof parameters. We show that it is possible to improve the performance of a\nrecently introduced efficient generator architecture solely with the\napplication of our proposed loss functions. In particular, we use a Fourier\nspace supervision loss for improved restoration of missing high-frequency (HF)\ncontent from the ground truth image and design a discriminator architecture\nworking directly in the Fourier domain to better match the target HF\ndistribution. We show that our losses' direct emphasis on the frequencies in\nFourier-space significantly boosts the perceptual image quality, while at the\nsame time retaining high restoration quality in comparison to previously\nproposed loss functions for this task. The performance is further improved by\nutilizing a combination of spatial and frequency domain losses, as both\nrepresentations provide complementary information during training. On top of\nthat, the trained generator achieves comparable results with and is 2.4x and\n48x faster than state-of-the-art perceptual SR methods RankSRGAN and SRFlow\nrespectively.",
    "descriptor": "",
    "authors": [
      "Dario Fuoli",
      "Luc Van Gool",
      "Radu Timofte"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00783"
  },
  {
    "id": "arXiv:2106.00790",
    "title": "Statistical Mechanics of Neural Processing of Object Manifolds",
    "abstract": "Invariant object recognition is one of the most fundamental cognitive tasks\nperformed by the brain. In the neural state space, different objects with\nstimulus variabilities are represented as different manifolds. In this\ngeometrical perspective, object recognition becomes the problem of linearly\nseparating different object manifolds. In feedforward visual hierarchy, it has\nbeen suggested that the object manifold representations are reformatted across\nthe layers, to become more linearly separable. Thus, a complete theory of\nperception requires characterizing the ability of linear readout networks to\nclassify object manifolds from variable neural responses.\nA theory of the perceptron of isolated points was pioneered by E. Gardner who\nformulated it as a statistical mechanics problem and analyzed it using replica\ntheory. In this thesis, we generalize Gardner's analysis and establish a theory\nof linear classification of manifolds synthesizing statistical and geometric\nproperties of high dimensional signals. [..] Next, we generalize our theory\nfurther to linear classification of general perceptual manifolds, such as point\nclouds. We identify that the capacity of a manifold is determined that\neffective radius, R_M, and effective dimension, D_M. Finally, we show\nextensions relevant for applications to real data, incorporating correlated\nmanifolds, heterogenous manifold geometries, sparse labels and nonlinear\nclassifications. Then, we demonstrate how object-based manifolds transform in\nstandard deep networks.\nThis thesis lays the groundwork for a computational theory of neuronal\nprocessing of objects, providing quantitative measures for linear separability\nof object manifolds. We hope this theory will provide new insights into the\ncomputational principles underlying processing of sensory representations in\nbiological and artificial neural networks.",
    "descriptor": "\nComments: PhD thesis, Harvard University, Cambridge, Massachusetts, USA. 2017. Some chapters report joint work\n",
    "authors": [
      "SueYeon Chung"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00790"
  },
  {
    "id": "arXiv:2106.00792",
    "title": "Latent Space Refinement for Deep Generative Models",
    "abstract": "Deep generative models are becoming widely used across science and industry\nfor a variety of purposes. A common challenge is achieving a precise implicit\nor explicit representation of the data probability density. Recent proposals\nhave suggested using classifier weights to refine the learned density of deep\ngenerative models. We extend this idea to all types of generative models and\nshow how latent space refinement via iterated generative modeling can\ncircumvent topological obstructions and improve precision. This methodology\nalso applies to cases were the target model is non-differentiable and has many\ninternal latent dimensions which must be marginalized over before refinement.\nWe demonstrate our Latent Space Refinement (LaSeR) protocol on a variety of\nexamples, focusing on the combinations of Normalizing Flows and Generative\nAdversarial Networks.",
    "descriptor": "\nComments: 14 pages, 5 figures, 3 tables\n",
    "authors": [
      "Ramon Winterhalder",
      "Marco Bellagente",
      "Benjamin Nachman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.00792"
  },
  {
    "id": "arXiv:2106.00801",
    "title": "Insertion in constructed normal numbers",
    "abstract": "Defined by Borel, a real number is normal to an integer base $b$, greater\nthan or equal to $2$, if in its base-$b$ expansion every block of digits occurs\nwith the same limiting frequency as every other block of the same length. We\nconsider the problem of insertion in constructed base-$b$ normal expansions to\nobtain normality to base $(b+1)$.",
    "descriptor": "",
    "authors": [
      "Ver\u00f3nica Becher"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.00801"
  },
  {
    "id": "arXiv:2106.00822",
    "title": "An arbitrary-order predefined-time exact differentiator for signals with  exponential growth bound",
    "abstract": "Constructing differentiation algorithms with a fixed-time convergence and a\npredefined Upper Bound on their Settling Time (\\textit{UBST}), i.e.,\npredefined-time differentiators, is attracting attention for solving estimation\nand control problems under time constraints. However, existing methods are\nlimited to signals having an $n$-th Lipschitz derivative. Here, we introduce a\ngeneral methodology to design $n$-th order predefined-time differentiators for\na broader class of signals: for signals, whose $(n+1)$-th derivative is bounded\nby a function with bounded logarithmic derivative, i.e., whose $(n+1)$-th\nderivative grows at most exponentially. Our approach is based on a class of\ntime-varying gains known as Time-Base Generators (\\textit{TBG}). The only\nassumption to construct the differentiator is that the class of signals to be\ndifferentiated $n$-times have a $(n+1)$-th derivative bounded by a known\nfunction with a known bound for its $(n+1)$-th logarithmic derivative. We show\nhow our methodology achieves an \\textit{UBST} equal to the predefined time,\nbetter transient responses with smaller error peaks than autonomous\npredefined-time differentiators, and a \\textit{TBG} gain that is bounded at the\nsettling time instant.",
    "descriptor": "",
    "authors": [
      "David G\u00f3mez-Guti\u00e9rrez",
      "Rodrigo Aldana-L\u00f3pez",
      "Richard Seeber",
      "Marco Tulio Angulo",
      "Leonid Fridman"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00822"
  },
  {
    "id": "arXiv:2106.00831",
    "title": "Stability Analysis of a Quantum Network with Max-Weight Scheduling",
    "abstract": "We study a quantum network that distributes entangled quantum states to\nmultiple sets of users that are connected to the network. Each user is\nconnected to a switch of the network via a link. All the links of the network\ngenerate bipartite Bell-state entangled states in each time-slot with certain\nprobabilities, and each end node stores one qubit of the entanglement generated\nby the link. To create shared entanglements for a set of users, measurement\noperations are performed on qubits of link-level entanglements on a set of\nrelated links, and these operations are probabilistic in nature and are\nsuccessful with certain probabilities. Requests arrive to the system seeking\nshared entanglements for different sets of users. Each request is for the\ncreation of shared entanglements for a fixed set of users using link-level\nentanglements on a fixed set of links. Requests are processed according to\nFirst-Come-First-Served service discipline and unserved requests are stored in\nbuffers. Once a request is selected for service, measurement operations are\nperformed on qubits of link-level entanglements on related links to create a\nshared entanglement. For given set of request arrival rates and link-level\nentanglement generation rates, we obtain necessary conditions for the stability\nof queues of requests. In each time-slot, the scheduler has to schedule\nentanglement swapping operations for different sets of users to stabilize the\nnetwork. Next, we propose a Max-Weight scheduling policy and show that this\npolicy stabilizes the network for all feasible arrival rates. We also provide\nnumerical results to support our analysis. The analysis of a single quantum\nswitch that creates multipartite entanglements for different sets of users is a\nspecial case of our work.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Thirupathaiah Vasantam",
      "Don Towsley"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2106.00831"
  },
  {
    "id": "arXiv:2106.00847",
    "title": "Sparse, Efficient, and Semantic Mixture Invariant Training: Taming  In-the-Wild Unsupervised Sound Separation",
    "abstract": "Supervised neural network training has led to significant progress on\nsingle-channel sound separation. This approach relies on ground truth isolated\nsources, which precludes scaling to widely available mixture data and limits\nprogress on open-domain tasks. The recent mixture invariant training (MixIT)\nmethod enables training on in-the wild data; however, it suffers from two\noutstanding problems. First, it produces models which tend to over-separate,\nproducing more output sources than are present in the input. Second, the\nexponential computational complexity of the MixIT loss limits the number of\nfeasible output sources. These problems interact: increasing the number of\noutput sources exacerbates over-separation. In this paper we address both\nissues. To combat over-separation we introduce new losses: sparsity losses that\nfavor fewer output sources and a covariance loss that discourages correlated\noutputs. We also experiment with a semantic classification loss by predicting\nweak class labels for each mixture. To extend MixIT to larger numbers of\nsources, we introduce an efficient approximation using a fast least-squares\nsolution, projected onto the MixIT constraint set. Our experiments show that\nthe proposed losses curtail over-separation and improve overall performance.\nThe best performance is achieved using larger numbers of output sources,\nenabled by our efficient MixIT loss, combined with sparsity losses to prevent\nover-separation. On the FUSS test set, we achieve over 13 dB in multi-source\nSI-SNR improvement, while boosting single-source reconstruction SI-SNR by over\n17 dB.",
    "descriptor": "\nComments: 5 pages, 1 figure. submitted to WASPAA 2021\n",
    "authors": [
      "Scott Wisdom",
      "Aren Jansen",
      "Ron J. Weiss",
      "Hakan Erdogan",
      "John R. Hershey"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.00847"
  },
  {
    "id": "arXiv:2106.00856",
    "title": "A Neural Acoustic Echo Canceller Optimized Using An Automatic Speech  Recognizer And Large Scale Synthetic Data",
    "abstract": "We consider the problem of recognizing speech utterances spoken to a device\nwhich is generating a known sound waveform; for example, recognizing queries\nissued to a digital assistant which is generating responses to previous user\ninputs. Previous work has proposed building acoustic echo cancellation (AEC)\nmodels for this task that optimize speech enhancement metrics using both neural\nnetwork as well as signal processing approaches.\nSince our goal is to recognize the input speech, we consider enhancements\nwhich improve word error rates (WERs) when the predicted speech signal is\npassed to an automatic speech recognition (ASR) model. First, we augment the\nloss function with a term that produces outputs useful to a pre-trained ASR\nmodel and show that this augmented loss function improves WER metrics. Second,\nwe demonstrate that augmenting our training dataset of real world examples with\na large synthetic dataset improves performance. Crucially, applying SpecAugment\nstyle masks to the reference channel during training aids the model in adapting\nfrom synthetic to real domains. In experimental evaluations, we find the\nproposed approaches improve performance, on average, by 57% over a signal\nprocessing baseline and 45% over the neural AEC model without the proposed\nchanges.",
    "descriptor": "\nComments: To appear in ICASSP 2021\n",
    "authors": [
      "Nathan Howard",
      "Alex Park",
      "Turaj Zakizadeh Shabestary",
      "Alexander Gruenstein",
      "Rohit Prabhavalkar"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.00856"
  },
  {
    "id": "arXiv:2106.00885",
    "title": "Robustifying Algorithms of Learning Latent Trees with Vector Variables",
    "abstract": "We consider learning the structures of Gaussian latent tree models with\nvector observations when a subset of them are arbitrarily corrupted. First, we\npresent the sample complexities of Recursive Grouping (RG) and Chow-Liu\nRecursive Grouping (CLRG) without the assumption that the effective depth is\nbounded in the number of observed nodes, significantly generalizing the results\nin Choi et al. (2011). We show that Chow-Liu initialization in CLRG greatly\nreduces the sample complexity of RG from being exponential in the diameter of\nthe tree to only logarithmic in the diameter for the hidden Markov model (HMM).\nSecond, we robustify RG, CLRG, Neighbor Joining (NJ) and Spectral NJ (SNJ) by\nusing the truncated inner product. These robustified algorithms can tolerate a\nnumber of corruptions up to the square root of the number of clean samples.\nFinally, we derive the first known instance-dependent impossibility result for\nstructure learning of latent trees. The optimalities of the robust version of\nCLRG and NJ are verified by comparing their sample complexities and the\nimpossibility result.",
    "descriptor": "",
    "authors": [
      "Fengzhuo Zhang",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00885"
  },
  {
    "id": "arXiv:2106.00917",
    "title": "An inverse random source problem for the time-space fractional diffusion  equation driven by fractional Brownian motion",
    "abstract": "We study the inverse random source problem for the time-space fractional\ndiffusion equation driven by fractional Brownian motion with Hurst index\n$H\\in(0,1)$. With the aid of a novel estimate, by using the operator approach\nwe propose regularity analyses for the direct problem. Then we provide a\nreconstruction scheme for the source terms $f$ and $g$ up to the sign. Next,\ncombining the properties of Mittag-Leffler function, the complete uniqueness\nand instability analyses are provided. It's worth mentioning that all the\nanalyses are unified for $H\\in(0,1)$.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Daxin Nie",
      "Weihua Deng"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00917"
  },
  {
    "id": "arXiv:2106.00919",
    "title": "Self-supervised Lesion Change Detection and Localisation in Longitudinal  Multiple Sclerosis Brain Imaging",
    "abstract": "Longitudinal imaging forms an essential component in the management and\nfollow-up of many medical conditions. The presence of lesion changes on serial\nimaging can have significant impact on clinical decision making, highlighting\nthe important role for automated change detection. Lesion changes can represent\nanomalies in serial imaging, which implies a limited availability of\nannotations and a wide variety of possible changes that need to be considered.\nHence, we introduce a new unsupervised anomaly detection and localisation\nmethod trained exclusively with serial images that do not contain any lesion\nchanges. Our training automatically synthesises lesion changes in serial\nimages, introducing detection and localisation pseudo-labels that are used to\nself-supervise the training of our model. Given the rarity of these lesion\nchanges in the synthesised images, we train the model with the imbalance robust\nfocal Tversky loss. When compared to supervised models trained on different\ndatasets, our method shows competitive performance in the detection and\nlocalisation of new demyelinating lesions on longitudinal magnetic resonance\nimaging in multiple sclerosis patients. Code for the models will be made\navailable on GitHub.",
    "descriptor": "\nComments: Provisional accepted for MICCAI 2021\n",
    "authors": [
      "Minh-Son To",
      "Ian G Sarno",
      "Chee Chong",
      "Mark Jenkinson",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00919"
  },
  {
    "id": "arXiv:2106.00927",
    "title": "An Extendible, Graph-Neural-Network-Based Approach for Accurate Force  Field Development of Large Flexible Organic Molecules",
    "abstract": "An accurate force field is the key to the success of all molecular mechanics\nsimulations on organic polymers and biomolecules. Accuracy beyond density\nfunctional theory is often needed to describe the intermolecular interactions,\nwhile most correlated wavefunction (CW) methods are prohibitively expensive for\nlarge molecules. Therefore, it posts a great challenge to develop an extendible\nab initio force field for large flexible organic molecules at CW level of\naccuracy. In this work, we face this challenge by combining the physics-driven\nnonbonding potential with a data-driven subgraph neural network bonding model\n(named sGNN). Tests on polyethylene glycol polymer chains show that our\nstrategy is highly accurate and robust for molecules of different sizes.\nTherefore, we can develop the force field from small molecular fragments (with\nsizes easily accessible to CW methods) and safely transfer it to large\npolymers, thus opening a new path to the next-generation organic force fields.",
    "descriptor": "",
    "authors": [
      "Xufei Wang",
      "Yuanda Xu",
      "Han Zheng",
      "Kuang Yu"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00927"
  },
  {
    "id": "arXiv:2106.00944",
    "title": "Teaching MPC: Which Way to the Promised Land?",
    "abstract": "Since the earliest conceptualizations by Lee and Markus, and Propoi in the\n1960s, Model Predictive Control (MPC) has become a major success story of\nsystems and control with respect to industrial impact and with respect to\ncontinued and wide-spread research interest. The field has evolved from\nconceptually simple linear-quadratic (convex) settings in discrete and\ncontinuous time to nonlinear and distributed settings including hybrid,\nstochastic, and infinite-dimensional systems. Put differently, essentially the\nentire spectrum of dynamic systems can be considered in the MPC framework with\nrespect to both -- system theoretic analysis and tailored numerics. Moreover,\nrecent developments in machine learning also leverage MPC concepts and\nlearning-based and data-driven MPC have become highly active research areas.\nHowever, this evident and continued success renders it increasingly complex\nto live up to industrial expectations while enabling graduate students for\nstate-of-the-art research in teaching MPC. Hence, this position paper attempts\nto trigger a discussion on teaching MPC. To lay the basis for a fruitful\ndebate, we subsequently investigate the prospect of covering MPC in\nundergraduate courses; we comment on teaching textbooks; and we discuss the\nincreasing complexity of research-oriented graduate teaching of~MPC.",
    "descriptor": "",
    "authors": [
      "Timm Faulwasser",
      "Sergio Lucia",
      "Moritz Schulze Darup",
      "Martin M\u00f6nnigmann"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00944"
  },
  {
    "id": "arXiv:2106.00951",
    "title": "Finite-time bearing-only maneuver of acyclic leader-follower formations",
    "abstract": "This letter proposes two finite-time bearing-based control laws for acyclic\nleader-follower formations. The leaders in formation move with a bounded\ncontinuous reference velocity and each follower controls its position with\nregard to three agents in the formation. The first control law uses only\nbearing vectors, and finite-time convergence is achieved by properly selecting\ntwo state-dependent control gains. The second control law requires both bearing\nvectors and communications between agents. Each agent simultaneously localizes\nand follows a virtual target. Finite-time convergence of the desired formation\nunder both control laws is proved by mathematical induction and supported by\nnumerical simulations.",
    "descriptor": "\nComments: 6 pages, 2 figures, preprint, accepted to L-CSS\n",
    "authors": [
      "Minh Hoang Trinh",
      "Hyo-Sung Ahn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00951"
  },
  {
    "id": "arXiv:2106.00997",
    "title": "Tips and Tricks to Improve CNN-based Chest X-ray Diagnosis: A Survey",
    "abstract": "Convolutional Neural Networks (CNNs) intrinsically requires large-scale data\nwhereas Chest X-Ray (CXR) images tend to be data/annotation-scarce, leading to\nover-fitting. Therefore, based on our development experience and related work,\nthis paper thoroughly introduces tricks to improve generalization in the CXR\ndiagnosis: how to (i) leverage additional data, (ii) augment/distillate data,\n(iii) regularize training, and (iv) conduct efficient segmentation. As a\ndevelopment example based on such optimization techniques, we also feature\nLPIXEL's CNN-based CXR solution, EIRL Chest Nodule, which improved\nradiologists/non-radiologists' nodule detection sensitivity by 0.100/0.131,\nrespectively, while maintaining specificity.",
    "descriptor": "\nComments: 7 pages, 2 figures, to be published in Japanese Journal of Medical Imaging and Information Sciences\n",
    "authors": [
      "Changhee Han",
      "Takayuki Okamoto",
      "Koichi Takeuchi",
      "Dimitris Katsios",
      "Andrey Grushnikov",
      "Masaaki Kobayashi",
      "Antoine Choppin",
      "Yutaka Kurashina",
      "Yuki Shimahara"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00997"
  },
  {
    "id": "arXiv:2106.01011",
    "title": "Refinement of Direction of Arrival Estimators by  Majorization-Minimization Optimization on the Array Manifold",
    "abstract": "We propose a generalized formulation of direction of arrival estimation that\nincludes many existing methods such as steered response power, subspace,\ncoherent and incoherent, as well as speech sparsity-based methods. Unlike most\nconventional methods that rely exclusively on grid search, we introduce a\ncontinuous optimization algorithm to refine DOA estimates beyond the resolution\nof the initial grid. The algorithm is derived from the\nmajorization-minimization (MM) technique. We derive two surrogate functions,\none quadratic and one linear. Both lead to efficient iterative algorithms that\ndo not require hyperparameters, such as step size, and ensure that the DOA\nestimates never leave the array manifold, without the need for a projection\nstep. In numerical experiments, we show that the accuracy after a few\niterations of the MM algorithm nearly removes dependency on the resolution of\nthe initial grid used. We find that the quadratic surrogate function leads to\nvery fast convergence, but the simplicity of the linear algorithm is very\nattractive, and the performance gap small.",
    "descriptor": "\nComments: 5 pages, 2 figures, 2 tables. Presented at IEEE ICASSP 2021\n",
    "authors": [
      "Robin Scheibler",
      "Masahito Togami"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.01011"
  },
  {
    "id": "arXiv:2106.01031",
    "title": "On Topology Inference for Networked Dynamical Systems: Principles and  Performances",
    "abstract": "Topology inference for networked dynamical systems (NDSs) plays a crucial\nrole in many areas. Knowledge of the system topology can aid in detecting\nanomalies, spotting trends, predicting future behavior and so on. Different\nfrom the majority of pioneering works, this paper investigates the principles\nand performances of topology inference from the perspective of node causality\nand correlation. Specifically, we advocate a comprehensive analysis framework\nto unveil the mutual relationship, convergence and accuracy of the proposed\nmethods and other benchmark methods, i.e., the Granger and ordinary least\nsquare (OLS) estimators. Our method allows for unknown observation noises, both\nasymptotic and marginal stabilities for NDSs, while encompasses a\ncorrelation-based modification design to alleviate performance degradation in\nsmall observation scale. To explicitly demonstrate the inference performance of\nthe estimators, we leverage the concentration measure in Gaussian space, and\nderive the non-asymptotic rates of the inference errors for linear\ntime-invariant (LTI) cases. Considering when the observations are not\nsufficient to support the estimators, we provide an excitation-based method to\ninfer the one-hop and multi-hop neighbors with probability guarantees.\nFurthermore, we point out the theoretical results can be extended to switching\ntopologies and nonlinear dynamics cases. Extensive simulations highlight the\noutperformance of the proposed method.",
    "descriptor": "",
    "authors": [
      "Yushan Li",
      "Jianping He",
      "Cailian Chen",
      "Xinping Guan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.01031"
  },
  {
    "id": "arXiv:2106.01070",
    "title": "Testing Group Fairness via Optimal Transport Projections",
    "abstract": "We present a statistical testing framework to detect if a given machine\nlearning classifier fails to satisfy a wide range of group fairness notions.\nThe proposed test is a flexible, interpretable, and statistically rigorous tool\nfor auditing whether exhibited biases are intrinsic to the algorithm or due to\nthe randomness in the data. The statistical challenges, which may arise from\nmultiple impact criteria that define group fairness and which are discontinuous\non model parameters, are conveniently tackled by projecting the empirical\nmeasure onto the set of group-fair probability models using optimal transport.\nThis statistic is efficiently computed using linear programming and its\nasymptotic distribution is explicitly obtained. The proposed framework can also\nbe used to test for testing composite fairness hypotheses and fairness with\nmultiple sensitive attributes. The optimal transport testing formulation\nimproves interpretability by characterizing the minimal covariate perturbations\nthat eliminate the bias observed in the audit.",
    "descriptor": "",
    "authors": [
      "Nian Si",
      "Karthyek Murthy",
      "Jose Blanchet",
      "Viet Anh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.01070"
  },
  {
    "id": "arXiv:2106.01099",
    "title": "Towards Verification of Dynamic Quantum Circuits",
    "abstract": "Quantum computers are reaching a level where interactions between classical\nand quantum computations can happen in real-time. This marks the advent of a\nnew, broader class of quantum circuits: dynamic quantum circuits. They offer a\nbroader range of available computing primitives that lead to new challenges for\ndesign tasks such as simulation, compilation, and verification. Due to the\nnon-unitary nature of dynamic circuit primitives, existing techniques for these\ntasks are no longer applicable in an out-of-the-box fashion. In this work, we\ndiscuss the resulting consequences for quantum circuit verification and present\nfirst ideas for corresponding automatic methods. More precisely, we propose two\ndifferent schemes that eventually allow to treat the involved circuits as if\nthey were not dynamic at all. By this, we provide a basis for applying existing\ntechniques for quantum circuit verification to this broader class of circuits.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Lukas Burgholzer",
      "Robert Wille"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2106.01099"
  },
  {
    "id": "arXiv:2106.01100",
    "title": "Prediction of the Position of External Markers Using a Recurrent Neural  Network Trained With Unbiased Online Recurrent Optimization for Safe Lung  Cancer Radiotherapy",
    "abstract": "During lung cancer radiotherapy, the position of infrared reflective objects\non the chest can be recorded to estimate the tumor location. However,\nradiotherapy systems usually have a latency inherent to robot control\nlimitations that impedes the radiation delivery precision. Not taking this\nphenomenon into account may cause unwanted damage to healthy tissues and lead\nto side effects such as radiation pneumonitis. In this research, we use nine\nobservation records of the three-dimensional position of three external markers\non the chest and abdomen of healthy individuals breathing during intervals from\n73s to 222s. The sampling frequency is equal to 10Hz and the amplitudes of the\nrecorded trajectories range from 6mm to 40mm in the superior-inferior\ndirection. We forecast the location of each marker simultaneously with a\nhorizon value (the time interval in advance for which the prediction is made)\nbetween 0.1s and 2.0s, using a recurrent neural network (RNN) trained with\nunbiased online recurrent optimization (UORO). We compare its performance with\nan RNN trained with real-time recurrent learning, least mean squares (LMS), and\noffline linear regression. Training and cross-validation are performed during\nthe first minute of each sequence. On average, UORO achieves the lowest\nroot-mean-square (RMS) and maximum error, equal respectively to 1.3mm and\n8.8mm, with a prediction time per time step lower than 2.8ms (Dell Intel core\ni9-9900K 3.60Ghz). Linear regression has the lowest RMS error for the horizon\nvalues 0.1s and 0.2s, followed by LMS for horizon values between 0.3s and 0.5s,\nand UORO for horizon values greater than 0.6s.",
    "descriptor": "\nComments: 20 pages, 14 figures\n",
    "authors": [
      "Michel Pohl",
      "Mitsuru Uesaka",
      "Hiroyuki Takahashi",
      "Kazuyuki Demachi",
      "Ritu Bhusal Chhatkuli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01100"
  },
  {
    "id": "arXiv:2106.01111",
    "title": "Deep Learning based Full-reference and No-reference Quality Assessment  Models for Compressed UGC Videos",
    "abstract": "In this paper, we propose a deep learning based video quality assessment\n(VQA) framework to evaluate the quality of the compressed user's generated\ncontent (UGC) videos. The proposed VQA framework consists of three modules, the\nfeature extraction module, the quality regression module, and the quality\npooling module. For the feature extraction module, we fuse the features from\nintermediate layers of the convolutional neural network (CNN) network into\nfinal quality-aware feature representation, which enables the model to make\nfull use of visual information from low-level to high-level. Specifically, the\nstructure and texture similarities of feature maps extracted from all\nintermediate layers are calculated as the feature representation for the full\nreference (FR) VQA model, and the global mean and standard deviation of the\nfinal feature maps fused by intermediate feature maps are calculated as the\nfeature representation for the no reference (NR) VQA model. For the quality\nregression module, we use the fully connected (FC) layer to regress the\nquality-aware features into frame-level scores. Finally, a\nsubjectively-inspired temporal pooling strategy is adopted to pool frame-level\nscores into the video-level score. The proposed model achieves the best\nperformance among the state-of-the-art FR and NR VQA models on the Compressed\nUGC VQA database and also achieves pretty good performance on the in-the-wild\nUGC VQA databases.",
    "descriptor": "",
    "authors": [
      "Wei Sun",
      "Tao Wang",
      "Xiongkuo Min",
      "Fuwang Yi",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.01111"
  },
  {
    "id": "arXiv:2106.01121",
    "title": "Connections and Equivalences between the Nystr\u00f6m Method and Sparse  Variational Gaussian Processes",
    "abstract": "We investigate the connections between sparse approximation methods for\nmaking kernel methods and Gaussian processes (GPs) scalable to massive data,\nfocusing on the Nystr\\\"om method and the Sparse Variational Gaussian Processes\n(SVGP). While sparse approximation methods for GPs and kernel methods share\nsome algebraic similarities, the literature lacks a deep understanding of how\nand why they are related. This is a possible obstacle for the communications\nbetween the GP and kernel communities, making it difficult to transfer results\nfrom one side to the other. Our motivation is to remove this possible obstacle,\nby clarifying the connections between the sparse approximations for GPs and\nkernel methods. In this work, we study the two popular approaches, the\nNystr\\\"om and SVGP approximations, in the context of a regression problem, and\nestablish various connections and equivalences between them. In particular, we\nprovide an RKHS interpretation of the SVGP approximation, and show that the\nEvidence Lower Bound of the SVGP contains the objective function of the\nNystr\\\"om approximation, revealing the origin of the algebraic equivalence\nbetween the two approaches. We also study recently established convergence\nresults for the SVGP and how they are related to the approximation quality of\nthe Nystr\\\"om method.",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Veit Wild",
      "Motonobu Kanagawa",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.01121"
  },
  {
    "id": "arXiv:2106.01124",
    "title": "Opening the Black Box of Deep Neural Networks in Physical Layer  Communication",
    "abstract": "Deep Neural Network (DNN)-based physical layer techniques are attracting\nconsiderable interest due to their potential to enhance communication systems.\nHowever, most studies in the physical layer have tended to focus on the\nimplement of DNN but not to theoretically understand how does a DNN work in a\ncommunication system. In this letter, we aim to quantitatively analyse why DNNs\ncan achieve comparable performance in the physical layer comparing with\ntraditional techniques and its cost in terms of computational complexity. We\nfurther investigate and also experimentally validate how information is flown\nin a DNN-based communication system under the information theoretic concepts.",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to IEEE Wireless Communications Letters\n",
    "authors": [
      "Jun Liu",
      "Kai Mei",
      "Dongtang Ma",
      "Jibo Wei"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01124"
  },
  {
    "id": "arXiv:2106.01138",
    "title": "Learning neural network potentials from experimental data via  Differentiable Trajectory Reweighting",
    "abstract": "In molecular dynamics (MD), neural network (NN) potentials trained bottom-up\non quantum mechanical data have seen tremendous success recently. Top-down\napproaches that learn NN potentials directly from experimental data have\nreceived less attention, typically facing numerical and computational\nchallenges when backpropagating through MD simulations. We present the\nDifferentiable Trajectory Reweighting (DiffTRe) method, which bypasses\ndifferentiation through the MD simulation for time-independent observables.\nLeveraging thermodynamic perturbation theory, we avoid exploding gradients and\nachieve around 2 orders of magnitude speed-up in gradient computation for\ntop-down learning. We show effectiveness of DiffTRe in learning NN potentials\nfor an atomistic model of diamond and a coarse-grained model of water based on\ndiverse experimental observables including thermodynamic, structural and\nmechanical properties. Importantly, DiffTRe also generalizes bottom-up\nstructural coarse-graining methods such as iterative Boltzmann inversion to\narbitrary potentials. The presented method constitutes an important milestone\ntowards enriching NN potentials with experimental data, particularly when\naccurate bottom-up data is unavailable.",
    "descriptor": "",
    "authors": [
      "Stephan Thaler",
      "Julija Zavadlav"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.01138"
  },
  {
    "id": "arXiv:2106.01140",
    "title": "semopy 2: A Structural Equation Modeling Package with Random Effects in  Python",
    "abstract": "Structural Equation Modeling (SEM) is an umbrella term that includes numerous\nmultivariate statistical techniques that are employed throughout a plethora of\nresearch areas, ranging from social to natural sciences. Until recently, SEM\nsoftware was either commercial or restricted to niche languages, and the lack\nof SEM packages compatible with more mainstream programming languages was dire.\nTo combat that, we introduced a Python package semopy 1 that surpassed other\nstate-of-the-art software in terms of performance and estimation accuracy. Yet,\nit was lacking in functionality and its usage was burdened with unnecessary\nboilerplate code. Here, we introduce a complete overhaul of semopy that\nimproves upon the previous results and comes with lots of new capabilities.\nFurthermore, we propose a novel SEM model that combines in itself a notion of\nrandom effects from linear mixed models (LMMs) to model numerous phenomena,\nsuch as spatial data, time series or population stratification in genetics.",
    "descriptor": "",
    "authors": [
      "Georgy Meshcheryakov",
      "Anna A. Igolkina",
      "Maria G. Samsonova"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2106.01140"
  },
  {
    "id": "arXiv:2106.01171",
    "title": "Digital homotopy relations and digital homology theories",
    "abstract": "In this paper we prove results relating to two homotopy relations and four\nhomology theories developed in the topology of digital images.\nWe introduce a new type of homotopy relation for digitally continuous\nfunctions which we call \"strong homotopy.\" Both digital homotopy and strong\nhomotopy are natural digitizations of classical topological homotopy: the\ndifference between them is analogous to the difference between digital\n4-adjacency and 8-adjacency in the plane.\nWe also consider four different digital homology theories: a simplicial\nhomology theory by Arslan et al which is the homology of the clique complex, a\nsingular simplicial homology theory by D. W. Lee, a cubical homology theory by\nJamil and Ali, and a new kind of cubical homology for digital images with\n$c_1$-adjacency which is easily computed, and generalizes a construction by\nKaraca \\& Ege. We show that the two simplicial homology theories are isomorphic\nto each other, but distinct from the two cubical theories.\nWe also show that homotopic maps have the same induced homomorphisms in the\ncubical homology theory, and strong homotopic maps additionally have the same\ninduced homomorphisms in the simplicial theory.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1907.00473, arXiv:1903.00706\n",
    "authors": [
      "P. Christopher Staecker"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "General Topology (math.GN)"
    ],
    "url": "https://arxiv.org/abs/2106.01171"
  },
  {
    "id": "arXiv:2106.01175",
    "title": "Generators and Relations for the Group $\\mathrm{O}_n(\\mathbb{Z}[1/2])$",
    "abstract": "We give a finite presentation by generators and relations for the group\n$\\mathrm{O}_n(\\mathbb{Z}[1/2])$ of $n$-dimensional orthogonal matrices with\nentries in $\\mathbb{Z}[1/2]$. We then obtain a similar presentation for the\ngroup of $n$-dimensional orthogonal matrices of the form $M/\\sqrt{2}{}^k$,\nwhere $k$ is a nonnegative integer and $M$ is an integer matrix. Both groups\narise in the study of quantum circuits. In particular, when the dimension is a\npower of $2$, the elements of the latter group are precisely the unitary\nmatrices that can be represented by a quantum circuit over the universal gate\nset consisting of the Toffoli gate, the Hadamard gate, and the computational\nancilla.",
    "descriptor": "",
    "authors": [
      "Sarah Meng Li",
      "Neil J. Ross",
      "Peter Selinger"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.01175"
  },
  {
    "id": "arXiv:2106.01190",
    "title": "Counting Lyndon Subsequences",
    "abstract": "Counting substrings/subsequences that preserve some property (e.g.,\npalindromes, squares) is an important mathematical interest in stringology.\nRecently, Glen et al. studied the number of Lyndon factors in a string. A\nstring $w = uv$ is called a Lyndon word if it is the lexicographically smallest\namong all of its conjugates $vu$. In this paper, we consider a more general\nproblem \"counting Lyndon subsequences\". We show (1) the maximum total number of\nLyndon subsequences in a string, (2) the expected total number of Lyndon\nsubsequences in a string, (3) the expected number of distinct Lyndon\nsubsequences in a string.",
    "descriptor": "",
    "authors": [
      "Ryo Hirakawa",
      "Yuto Nakashima",
      "Shunsuke Inenaga",
      "Masayuki Takeda"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.01190"
  },
  {
    "id": "arXiv:2106.01202",
    "title": "Framing RNN as a kernel method: A neural ODE approach",
    "abstract": "Building on the interpretation of a recurrent neural network (RNN) as a\ncontinuous-time neural differential equation, we show, under appropriate\nconditions, that the solution of a RNN can be viewed as a linear function of a\nspecific feature set of the input sequence, known as the signature. This\nconnection allows us to frame a RNN as a kernel method in a suitable\nreproducing kernel Hilbert space. As a consequence, we obtain theoretical\nguarantees on generalization and stability for a large class of recurrent\nnetworks. Our results are illustrated on simulated datasets.",
    "descriptor": "\nComments: 32 pages, 7 figures\n",
    "authors": [
      "Adeline Fermanian",
      "Pierre Marion",
      "Jean-Philippe Vert",
      "G\u00e9rard Biau"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01202"
  },
  {
    "id": "arXiv:2106.01205",
    "title": "Refined method to extract frequency-noise components of lasers by  delayed self-heterodyne",
    "abstract": "An essential metric to quantify the stability of a laser is its frequency\nnoise (FN). This metric yields information on the linewidth and on noise\ncomponents which limit its usage for high precision purposes such as coherent\ncommunication. Its experimental determination relies on challenging optical\nphase measurements, for which dedicated commercial instruments have been\ndeveloped. In contrast, this work presents a simple and cost-effective method\nfor extracting FN features employing a delayed self-heterodyne (DSH) setup.\nUsing delay lengths much shorter than the coherence length of the laser, the\nDSH trace reveals a correspondence with the FN power spectral density (PSD)\nmeasured with commercial instruments. Results are found for multiple lasers,\nwith discrepancies in intense dither tone frequencies below 0.2 percent",
    "descriptor": "\nComments: 7 pages, 7 figures. To be published in Journal of Lightwave Technology. Measurements and data analysis carried out by Niklas Arent and Monica Brusatori Far. Nicolas acted as supervisor on this work\n",
    "authors": [
      "Niklas Hedegaard Arent",
      "M\u00f3nica Brusatori Far",
      "Nicolas Volet"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2106.01205"
  },
  {
    "id": "arXiv:2106.01225",
    "title": "Intelligent Surface Optimization in Terahertz under Two Manifestations  of Molecular Re-radiation",
    "abstract": "The operation of Terahertz (THz) communication can be significantly impacted\nby the interaction between the transmitted wave and the molecules in the\natmosphere. In particular, it has been observed experimentally that the signal\nundergoes not only molecular absorption, but also molecular re-radiation. Two\nextreme modeling assumptions are prevalent in the literature, where the\nre-radiated energy is modeled in the first as additive Gaussian noise and in\nthe second as a scattered component strongly correlated to the actual signal.\nSince the exact characterization is still an open problem, we provide in this\npaper the first comparative study of the performance of a reconfigurable\nintelligent surface (RIS) assisted THz system under these two extreme models of\nre-radiation. In particular, we employ an RIS to overcome the large pathloss by\ncreating a virtual line-of-sight (LOS) path. We then develop an optimization\nframework for this setup and utilize the block-coordinate descent (BCD) method\nto iteratively optimize both RIS configuration vector and receive beamforming\nweight resulting in significant throughput gains for the user of interest\ncompared to random RIS configurations. As expected, our results reveal that\nbetter throughput is achieved under the scattering assumption for the molecular\nre-radiation than the noise assumption.",
    "descriptor": "",
    "authors": [
      "Anish Pradhan",
      "J. Kartheek Devineni",
      "Harpreet S. Dhillon",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.01225"
  },
  {
    "id": "arXiv:2106.01255",
    "title": "A 4-Element 800MHz-BW 29mW True-Time-Delay Spatial Signal Processor  Enabling Fast Beam-Training with Data Communications",
    "abstract": "Spatial signal processors (SSP) for emerging millimeter-wave wireless\nnetworks are critically dependent on link discovery. To avoid loss in\ncommunication, mobile devices need to locate narrow directional beams with\nmillisecond latency. In this work, we demonstrate a true-time-delay (TTD) array\nwith digitally reconfigurable delay elements enabling both fast beam-training\nat the receiver with wideband data communications. In beam-training mode, large\ndelay-bandwidth products are implemented to accelerate beam training using\nfrequency-dependent probing beams. In data communications mode, precise beam\nalignment is achieved to mitigate spatial effects during beam-forming for\nwideband signals. The 4-element switched-capacitor based time-interleaved array\nuses a compact closed-loop integrator for signal combining with the delay\ncompensation implemented in the clock domain to achieve high precision and\nlarge delay range. Prototyped in TSMC 65nm CMOS, the TTD SSP successfully\ndemonstrates unique frequency-to-angle mapping with 3.8ns maximum delay and\n800MHz bandwidth in the beam-training mode. In the data communications mode,\nnearly 12dB uniform beamforming gain is achieved from 80MHz to 800MHz. The TTD\nSSP consumes 29mW at 1V supply achieving 122MB/s with 16-QAM at 9.8% EVM.",
    "descriptor": "\nComments: to be presented at the IEEE European Solid-State Circuits Conference in September 2021\n",
    "authors": [
      "Chung-Ching Lin",
      "Chase Puglisi",
      "Veljko Boljanovic",
      "Soumen Mohapatra",
      "Han Yan",
      "Erfan Ghaderi",
      "Deukhyoun Heo",
      "Danijela Cabric",
      "Subhanshu Gupta"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01255"
  },
  {
    "id": "arXiv:2106.01257",
    "title": "Tight High Probability Bounds for Linear Stochastic Approximation with  Fixed Stepsize",
    "abstract": "This paper provides a non-asymptotic analysis of linear stochastic\napproximation (LSA) algorithms with fixed stepsize. This family of methods\narises in many machine learning tasks and is used to obtain approximate\nsolutions of a linear system $\\bar{A}\\theta = \\bar{b}$ for which $\\bar{A}$ and\n$\\bar{b}$ can only be accessed through random estimates $\\{({\\bf A}_n, {\\bf\nb}_n): n \\in \\mathbb{N}^*\\}$. Our analysis is based on new results regarding\nmoments and high probability bounds for products of matrices which are shown to\nbe tight. We derive high probability bounds on the performance of LSA under\nweaker conditions on the sequence $\\{({\\bf A}_n, {\\bf b}_n): n \\in\n\\mathbb{N}^*\\}$ than previous works. However, in contrast, we establish\npolynomial concentration bounds with order depending on the stepsize. We show\nthat our conclusions cannot be improved without additional assumptions on the\nsequence of random matrices $\\{{\\bf A}_n: n \\in \\mathbb{N}^*\\}$, and in\nparticular that no Gaussian or exponential high probability bounds can hold.\nFinally, we pay a particular attention to establishing bounds with sharp order\nwith respect to the number of iterations and the stepsize and whose leading\nterms contain the covariance matrices appearing in the central limit theorems.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Alain Durmus",
      "Eric Moulines",
      "Alexey Naumov",
      "Sergey Samsonov",
      "Kevin Scaman",
      "Hoi-To Wai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.01257"
  },
  {
    "id": "arXiv:2106.01260",
    "title": "Matrix factorisation and the interpretation of geodesic distance",
    "abstract": "Given a graph or similarity matrix, we consider the problem of recovering a\nnotion of true distance between the nodes, and so their true positions. Through\nnew insights into the manifold geometry underlying a generic latent position\nmodel, we show that this can be accomplished in two steps: matrix\nfactorisation, followed by nonlinear dimension reduction. This combination is\neffective because the point cloud obtained in the first step lives close to a\nmanifold in which latent distance is encoded as geodesic distance. Hence, a\nnonlinear dimension reduction tool, approximating geodesic distance, can\nrecover the latent positions, up to a simple transformation. We give a detailed\naccount of the case where spectral embedding is used, followed by Isomap, and\nprovide encouraging experimental evidence for other combinations of techniques.",
    "descriptor": "\nComments: 28 pages; 13 figures\n",
    "authors": [
      "Nick Whiteley",
      "Annie Gray",
      "Patrick Rubin-Delanchy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01260"
  },
  {
    "id": "arXiv:2106.01262",
    "title": "End-To-End Deep Learning-Based Adaptation Control for Frequency-Domain  Adaptive System Identification",
    "abstract": "We present a novel end-to-end deep learning-based adaptation control\nalgorithm for frequency-domain adaptive system identification. The proposed\nmethod exploits a deep neural network to map observed signal features to\ncorresponding step-sizes which control the filter adaptation. The parameters of\nthe network are optimized in an end-to-end fashion by minimizing the average\nsystem distance of the adaptive filter. This avoids the need of explicit signal\npower spectral density estimation as required for model-based adaptation\ncontrol and further auxiliary mechanisms to deal with model inaccuracies. The\nproposed algorithm achieves fast convergence and robust steady-state\nperformance for scenarios characterized by non-white and non-stationary noise\nsignals, time-varying environment changes and additional model inaccuracies.",
    "descriptor": "",
    "authors": [
      "Thomas Haubner",
      "Andreas Brendel",
      "Walter Kellermann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.01262"
  },
  {
    "id": "arXiv:2106.01275",
    "title": "Probing for the Trace Estimation of a Permuted Matrix Inverse  Corresponding to a Lattice Displacement",
    "abstract": "Probing is a general technique that is used to reduce the variance of the\nHutchinson stochastic estimator for the trace of the inverse of a large, sparse\nmatrix $A$. The variance of the estimator is the sum of the squares of the\noff-diagonal elements of $A^{-1}$. Therefore, this technique computes probing\nvectors that when used in the estimator they annihilate the largest\noff-diagonal elements. For matrices that display decay of the magnitude of\n$|A^{-1}_{ij}|$ with the graph distance between nodes $i$ and $j$, this is\nachieved through graph coloring of increasing powers $A^p$. Equivalently, when\na matrix stems from a lattice discretization, it is computationally beneficial\nto find a distance-$p$ coloring of the lattice.\nIn this work, we study probing for the more general problem of computing the\ntrace of a permutation of $A^{-1}$, say $PA^{-1}$, motivated from Lattice QCD\nwhere we need to construct \"disconnected diagrams\" to extract flavor-separated\nGeneralized Parton functions. In Lattice QCD, where the matrix has a 4D\ntoroidal lattice structure, these non-local operators correspond to a $PA^{-1}$\nwhere $P$ is the permutation relating to some displacement in one or more\ndimensions. We focus on a single dimension displacement ($k$) but our methods\nare general. We show that probing on $A^p$ or $(PA)^p$ do not annihilate the\nlargest magnitude elements. To resolve this issue, our displacement-based\nprobing works on $PA^p$ using a new coloring scheme that works directly on\nappropriately displaced neighborhoods on the lattice. We prove lower bounds on\nthe number of colors needed, and study the effect of this scheme on variance\nreduction, both theoretically and experimentally on a real-world Lattice QCD\ncalculation. We achieve orders of magnitude speedup over the un-probed or the\nnaively probed methods.",
    "descriptor": "",
    "authors": [
      "Heather Switzer",
      "Andreas Stathopoulos",
      "Eloy Romero",
      "Jesse Laeuchli",
      "Kostas Orginos"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01275"
  },
  {
    "id": "arXiv:2106.01282",
    "title": "Spectral embedding for dynamic networks with stability guarantees",
    "abstract": "We consider the problem of embedding a dynamic network, to obtain\ntime-evolving vector representations of each node, which can then be used to\ndescribe the changes in behaviour of a single node, one or more communities, or\nthe entire graph. Given this open-ended remit, we wish to guarantee stability\nin the spatio-temporal positioning of the nodes: assigning the same position,\nup to noise, to nodes behaving similarly at a given time (cross-sectional\nstability) and a constant position, up to noise, to a single node behaving\nsimilarly across different times (longitudinal stability). These properties are\ndefined formally within a generic dynamic latent position model. By showing how\nthis model can be recast as a multilayer random dot product graph, we\ndemonstrate that unfolded adjacency spectral embedding satisfies both stability\nconditions, allowing, for example, spatio-temporal clustering under the dynamic\nstochastic block model. We also show how alternative methods, such as omnibus,\nindependent or time-averaged spectral embedding, lack one or the other form of\nstability.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Ian Gallagher",
      "Andrew Jones",
      "Patrick Rubin-Delanchy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01282"
  },
  {
    "id": "arXiv:2106.01309",
    "title": "Benchmarking the Performance of Bayesian Optimization across Multiple  Experimental Materials Science Domains",
    "abstract": "In the field of machine learning (ML) for materials optimization, active\nlearning algorithms, such as Bayesian Optimization (BO), have been leveraged\nfor guiding autonomous and high-throughput experimentation systems. However,\nvery few studies have evaluated the efficiency of BO as a general optimization\nalgorithm across a broad range of experimental materials science domains. In\nthis work, we evaluate the performance of BO algorithms with a collection of\nsurrogate model and acquisition function pairs across five diverse experimental\nmaterials systems, namely carbon nanotube polymer blends, silver nanoparticles,\nlead-halide perovskites, as well as additively manufactured polymer structures\nand shapes. By defining acceleration and enhancement metrics for general\nmaterials optimization objectives, we find that for surrogate model selection,\nGaussian Process (GP) with anisotropic kernels (automatic relevance detection,\nARD) and Random Forests (RF) have comparable performance and both outperform\nthe commonly used GP without ARD. We discuss the implicit distributional\nassumptions of RF and GP, and the benefits of using GP with anisotropic kernels\nin detail. We provide practical insights for experimentalists on surrogate\nmodel selection of BO during materials optimization campaigns.",
    "descriptor": "",
    "authors": [
      "Qiaohao Liang",
      "Aldair E. Gongora",
      "Zekun Ren",
      "Armi Tiihonen",
      "Zhe Liu",
      "Shijing Sun",
      "James R. Deneault",
      "Daniil Bash",
      "Flore Mekki-Berrada",
      "Saif A. Khan",
      "Kedar Hippalgaonkar",
      "Benji Maruyama",
      "Keith A. Brown",
      "John Fisher III",
      "Tonio Buonassisi"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.01309"
  },
  {
    "id": "arXiv:2106.01351",
    "title": "Deep Clustering Activation Maps for Emphysema Subtyping",
    "abstract": "We propose a deep learning clustering method that exploits dense features\nfrom a segmentation network for emphysema subtyping from computed tomography\n(CT) scans. Using dense features enables high-resolution visualization of image\nregions corresponding to the cluster assignment via dense clustering activation\nmaps (dCAMs). This approach provides model interpretability. We evaluated\nclustering results on 500 subjects from the COPDGenestudy, where radiologists\nmanually annotated emphysema sub-types according to their visual CT assessment.\nWe achieved a 43% unsupervised clustering accuracy, outperforming our baseline\nat 41% and yielding results comparable to supervised classification at 45%. The\nproposed method also offers a better cluster formation than the baseline,\nachieving0.54 in silhouette coefficient and 0.55 in David-Bouldin scores.",
    "descriptor": "",
    "authors": [
      "Weiyi Xie",
      "Colin Jacobs",
      "Bram van Ginneken"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01351"
  },
  {
    "id": "arXiv:2106.01355",
    "title": "A method using deep learning to discover new predictors of CRT response  from mechanical dyssynchrony on gated SPECT MPI",
    "abstract": "Background. Studies have shown that the conventional left ventricular\nmechanical dyssynchrony (LVMD) parameters have their own statistical\nlimitations. The purpose of this study is to extract new LVMD parameters from\nthe phase analysis of gated SPECT MPI by deep learning to help CRT patient\nselection. Methods. One hundred and three patients who underwent rest gated\nSPECT MPI were enrolled in this study. CRT response was defined as a decrease\nin left ventricular end-systolic volume (LVESV) >= 15% at 6 +- 1 month follow\nup. Autoencoder (AE), an unsupervised deep learning method, was trained by the\nraw LV systolic phase polar maps to extract new LVMD parameters, called\nAE-based LVMD parameters. Correlation analysis was used to explain the\nrelationships between new parameters with conventional LVMD parameters.\nUnivariate and multivariate analyses were used to establish a multivariate\nmodel for predicting CRT response. Results. Complete data were obtained in 102\npatients, 44.1% of them were classified as CRT responders. AE-based LVMD\nparameter was significant in the univariate (OR 1.24, 95% CI 1.07 - 1.44, P =\n0.006) and multivariate analyses (OR 1.03, 95% CI 1.01 - 1.06, P = 0.006).\nMoreover, it had incremental value over PSD (AUC 0.72 vs. 0.63, LH 8.06, P =\n0.005) and PBW (AUC 0.72 vs. 0.64, LH 7.87, P = 0.005), combined with\nsignificant clinic characteristics, including LVEF and gender. Conclusions. The\nnew LVMD parameters extracted by autoencoder from the baseline gated SPECT MPI\nhas the potential to improve the prediction of CRT response.",
    "descriptor": "\nComments: 10 pages, 3 figures, will submit to journal of nuclear cardiology\n",
    "authors": [
      "Zhuo He",
      "Xinwei Zhang",
      "Chen Zhao",
      "Zhiyong Qian",
      "Yao Wang",
      "Xiaofeng Hou",
      "Jiangang Zou",
      "Weihua Zhou"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01355"
  },
  {
    "id": "arXiv:2106.01357",
    "title": "Diffusion Schr\u00f6dinger Bridge with Applications to Score-Based  Generative Modeling",
    "abstract": "Progressively applying Gaussian noise transforms complex data distributions\nto approximately Gaussian. Reversing this dynamic defines a generative model.\nWhen the forward noising process is given by a Stochastic Differential Equation\n(SDE), Song et al. (2021) demonstrate how the time inhomogeneous drift of the\nassociated reverse-time SDE may be estimated using score-matching. A limitation\nof this approach is that the forward-time SDE must be run for a sufficiently\nlong time for the final distribution to be approximately Gaussian. In contrast,\nsolving the Schr\\\"odinger Bridge problem (SB), i.e. an entropy-regularized\noptimal transport problem on path spaces, yields diffusions which generate\nsamples from the data distribution in finite time. We present Diffusion SB\n(DSB), an original approximation of the Iterative Proportional Fitting (IPF)\nprocedure to solve the SB problem, and provide theoretical analysis along with\ngenerative modeling experiments. The first DSB iteration recovers the\nmethodology proposed by Song et al. (2021), with the flexibility of using\nshorter time intervals, as subsequent DSB iterations reduce the discrepancy\nbetween the final-time marginal of the forward (resp. backward) SDE with\nrespect to the prior (resp. data) distribution. Beyond generative modeling, DSB\noffers a widely applicable computational optimal transport tool as the\ncontinuous state-space analogue of the popular Sinkhorn algorithm (Cuturi,\n2013).",
    "descriptor": "",
    "authors": [
      "Valentin De Bortoli",
      "James Thornton",
      "Jeremy Heng",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.01357"
  },
  {
    "id": "arXiv:1806.06103",
    "title": "Robust Approaches to Handling Complex Geometries with Galerkin  Difference Methods",
    "abstract": "Comments: 30 pages, 14 figures",
    "descriptor": "\nComments: 30 pages, 14 figures\n",
    "authors": [
      "Jeremy E. Kozdon",
      "Lucas C. Wilcox",
      "Thomas Hagstrom",
      "Jeffrey W. Banks"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1806.06103"
  },
  {
    "id": "arXiv:1807.01261",
    "title": "On the Connection between Residual Distribution Schemes and Flux  Reconstruction",
    "abstract": "On the Connection between Residual Distribution Schemes and Flux  Reconstruction",
    "descriptor": "",
    "authors": [
      "Remi Abgrall",
      "Elise le Meledo",
      "Philipp Oeffner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1807.01261"
  },
  {
    "id": "arXiv:1903.11287",
    "title": "Convexly independent subsets of Minkowski sums of convex polygons",
    "abstract": "Comments: v1: 9 pages, 3 figures; v2: minor revision, 10 pages, 5 figures",
    "descriptor": "\nComments: v1: 9 pages, 3 figures; v2: minor revision, 10 pages, 5 figures\n",
    "authors": [
      "Mateusz Skomra",
      "St\u00e9phan Thomass\u00e9"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1903.11287"
  },
  {
    "id": "arXiv:1904.06984",
    "title": "Depth Separations in Neural Networks: What is Actually Being Separated?",
    "abstract": "Depth Separations in Neural Networks: What is Actually Being Separated?",
    "descriptor": "",
    "authors": [
      "Itay Safran",
      "Ronen Eldan",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1904.06984"
  },
  {
    "id": "arXiv:1905.08671",
    "title": "Topological Feature Vectors for Chatter Detection in Turning Processes",
    "abstract": "Comments: Implementations of parallel computing and Bezier curve approximation for persistence diagram computation are added into the manuscript. Abstract and results section are updated with respect to the results obtained from persistence diagrams computed with Bezier approximation",
    "descriptor": "\nComments: Implementations of parallel computing and Bezier curve approximation for persistence diagram computation are added into the manuscript. Abstract and results section are updated with respect to the results obtained from persistence diagrams computed with Bezier approximation\n",
    "authors": [
      "Melih C. Yesilli",
      "Firas A. Khasawneh",
      "Andreas Otto"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.08671"
  },
  {
    "id": "arXiv:1907.01495",
    "title": "Efficient Isomorphism for $S_d$-graphs and $T$-graphs",
    "abstract": "Efficient Isomorphism for $S_d$-graphs and $T$-graphs",
    "descriptor": "",
    "authors": [
      "Deniz A\u011fao\u011flu",
      "Petr Hlin\u011bn\u00fd"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1907.01495"
  },
  {
    "id": "arXiv:1907.02170",
    "title": "On Open-Universe Causal Reasoning",
    "abstract": "Comments: UAI 2019",
    "descriptor": "\nComments: UAI 2019\n",
    "authors": [
      "Duligur Ibeling",
      "Thomas Icard"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1907.02170"
  },
  {
    "id": "arXiv:1907.08559",
    "title": "An Algorithm and Estimates for the Erd\u0151s-Selfridge Function (work in  progress)",
    "abstract": "Comments: 25 pages, 5 figures; See the DOI link for the published version in ANTS; This update contains a few new minor results",
    "descriptor": "\nComments: 25 pages, 5 figures; See the DOI link for the published version in ANTS; This update contains a few new minor results\n",
    "authors": [
      "Brianna Sorenson",
      "Jonathan P Sorenson",
      "Jonathan Webster"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1907.08559"
  },
  {
    "id": "arXiv:1908.00045",
    "title": "How Good is SGD with Random Shuffling?",
    "abstract": "How Good is SGD with Random Shuffling?",
    "descriptor": "",
    "authors": [
      "Itay Safran",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1908.00045"
  },
  {
    "id": "arXiv:1909.03396",
    "title": "Quality Estimation for Image Captions Based on Large-scale Human  Evaluations",
    "abstract": "Comments: 10 pages, 6 figures, 3 tables. Accepted to NAACL2021. this https URL",
    "descriptor": "\nComments: 10 pages, 6 figures, 3 tables. Accepted to NAACL2021. this https URL\n",
    "authors": [
      "Tomer Levinboim",
      "Ashish V. Thapliyal",
      "Piyush Sharma",
      "Radu Soricut"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1909.03396"
  },
  {
    "id": "arXiv:1909.04261",
    "title": "Interpretable Biomanufacturing Process Risk and Sensitivity Analyses for  Quality-by-Design and Stability Control",
    "abstract": "Comments: 41 pages, 8 figures",
    "descriptor": "\nComments: 41 pages, 8 figures\n",
    "authors": [
      "Wei Xie",
      "Bo Wang",
      "Cheng Li",
      "Dongming Xie",
      "Jared Auclair"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1909.04261"
  },
  {
    "id": "arXiv:1910.02126",
    "title": "Quantum Physical Unclonable Functions: Possibilities and Impossibilities",
    "abstract": "Comments: 32 pages including the appendix",
    "descriptor": "\nComments: 32 pages including the appendix\n",
    "authors": [
      "Myrto Arapinis",
      "Mahshid Delavar",
      "Mina Doosti",
      "Elham Kashefi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1910.02126"
  },
  {
    "id": "arXiv:1911.01542",
    "title": "embComp: Visual Interactive Comparison of Vector Embeddings",
    "abstract": "Comments: published in IEEE Transactions on Visualization and Computer Graphics (2020)",
    "descriptor": "\nComments: published in IEEE Transactions on Visualization and Computer Graphics (2020)\n",
    "authors": [
      "Florian Heimerl",
      "Christoph Kralj",
      "Torsten M\u00f6ller",
      "Michael Gleicher"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1911.01542"
  },
  {
    "id": "arXiv:1911.03663",
    "title": "Style is NOT a single variable: Case Studies for Cross-Style Language  Understanding",
    "abstract": "Comments: Accepted to ACL 2021",
    "descriptor": "\nComments: Accepted to ACL 2021\n",
    "authors": [
      "Dongyeop Kang",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.03663"
  },
  {
    "id": "arXiv:1911.12099",
    "title": "Multilevel quasi Monte Carlo methods for elliptic PDEs with random field  coefficients via fast white noise sampling",
    "abstract": "Multilevel quasi Monte Carlo methods for elliptic PDEs with random field  coefficients via fast white noise sampling",
    "descriptor": "",
    "authors": [
      "M. Croci",
      "M. B. Giles",
      "P. E. Farrell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1911.12099"
  },
  {
    "id": "arXiv:2001.02889",
    "title": "Probabilistic Reasoning across the Causal Hierarchy",
    "abstract": "Comments: AAAI-20",
    "descriptor": "\nComments: AAAI-20\n",
    "authors": [
      "Duligur Ibeling",
      "Thomas Icard"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2001.02889"
  },
  {
    "id": "arXiv:2001.07417",
    "title": "Explaining Data-Driven Decisions made by AI Systems: The Counterfactual  Approach",
    "abstract": "Explaining Data-Driven Decisions made by AI Systems: The Counterfactual  Approach",
    "descriptor": "",
    "authors": [
      "Carlos Fern\u00e1ndez-Lor\u00eda",
      "Foster Provost",
      "Xintian Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.07417"
  },
  {
    "id": "arXiv:2002.00116",
    "title": "Hybridized Summation-By-Parts Finite Difference Methods",
    "abstract": "Comments: 26 pages, 6 figures, 3 tables",
    "descriptor": "\nComments: 26 pages, 6 figures, 3 tables\n",
    "authors": [
      "Jeremy E. Kozdon",
      "Brittany A. Erickson",
      "Lucas C. Wilcox"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2002.00116"
  },
  {
    "id": "arXiv:2002.06557",
    "title": "Fair Principal Component Analysis and Filter Design",
    "abstract": "Fair Principal Component Analysis and Filter Design",
    "descriptor": "",
    "authors": [
      "Gad Zalcberg",
      "Ami Wiesel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.06557"
  },
  {
    "id": "arXiv:2002.06716",
    "title": "Predicting trends in the quality of state-of-the-art neural networks  without access to training or testing data",
    "abstract": "Comments: 35 pages, 8 tables, 17 figures. To appear in Nature Communications",
    "descriptor": "\nComments: 35 pages, 8 tables, 17 figures. To appear in Nature Communications\n",
    "authors": [
      "Charles H. Martin",
      "Tongsu",
      "Peng",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.06716"
  },
  {
    "id": "arXiv:2002.07767",
    "title": "Learning by Semantic Similarity Makes Abstractive Summarization Better",
    "abstract": "Comments: The initial version of the manuscript includes a model design (semsim), experimental results, and discussions on the results. We found that our model has flaws in its implementation and design. This final version of the manuscript is from the rest of the initial paper; we included our findings on the benchmark dataset, BART generated results and human evaluations, and we excluded our model semsim",
    "descriptor": "\nComments: The initial version of the manuscript includes a model design (semsim), experimental results, and discussions on the results. We found that our model has flaws in its implementation and design. This final version of the manuscript is from the rest of the initial paper; we included our findings on the benchmark dataset, BART generated results and human evaluations, and we excluded our model semsim\n",
    "authors": [
      "Wonjin Yoon",
      "Yoon Sun Yeo",
      "Minbyul Jeong",
      "Bong-Jun Yi",
      "Jaewoo Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2002.07767"
  },
  {
    "id": "arXiv:2002.11985",
    "title": "Compressing Large-Scale Transformer-Based Models: A Case Study on BERT",
    "abstract": "Comments: To appear in TACL 2021. The arXiv version is a pre-MIT Press publication version",
    "descriptor": "\nComments: To appear in TACL 2021. The arXiv version is a pre-MIT Press publication version\n",
    "authors": [
      "Prakhar Ganesh",
      "Yao Chen",
      "Xin Lou",
      "Mohammad Ali Khan",
      "Yin Yang",
      "Hassan Sajjad",
      "Preslav Nakov",
      "Deming Chen",
      "Marianne Winslett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.11985"
  },
  {
    "id": "arXiv:2003.02422",
    "title": "Deep Reinforcement Learning-BasedRobust Protection in DER-Rich  Distribution Grids",
    "abstract": "Comments: Submitted to IEEE Transactions of Smart Grid, under review",
    "descriptor": "\nComments: Submitted to IEEE Transactions of Smart Grid, under review\n",
    "authors": [
      "Dongqi Wu",
      "Dileep Kalathil",
      "Miroslav Begovic",
      "Le Xie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2003.02422"
  },
  {
    "id": "arXiv:2003.07132",
    "title": "GAMI-Net: An Explainable Neural Network based on Generalized Additive  Models with Structured Interactions",
    "abstract": "GAMI-Net: An Explainable Neural Network based on Generalized Additive  Models with Structured Interactions",
    "descriptor": "",
    "authors": [
      "Zebin Yang",
      "Aijun Zhang",
      "Agus Sudjianto"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2003.07132"
  },
  {
    "id": "arXiv:2003.11067",
    "title": "Punishing defectors and rewarding cooperators: Do people discriminate  between genders?",
    "abstract": "Comments: Forthcoming in the Journal of the Economic Science Association",
    "descriptor": "\nComments: Forthcoming in the Journal of the Economic Science Association\n",
    "authors": [
      "H\u00e9l\u00e8ne Barcelo",
      "Valerio Capraro"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computer Science and Game Theory (cs.GT)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2003.11067"
  },
  {
    "id": "arXiv:2004.09317",
    "title": "How Do Neural Networks Estimate Optical Flow? A Neuropsychology-Inspired  Study",
    "abstract": "Comments: 16 pages, 15 figures",
    "descriptor": "\nComments: 16 pages, 15 figures\n",
    "authors": [
      "D. B. de Jong",
      "F. Paredes-Vall\u00e9s",
      "G. C. H. E. de Croon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2004.09317"
  },
  {
    "id": "arXiv:2004.12019",
    "title": "Finite-sample Analysis of Interpolating Linear Classifiers in the  Overparameterized Regime",
    "abstract": "Comments: Corrected typographical errors from the previous version of this paper",
    "descriptor": "\nComments: Corrected typographical errors from the previous version of this paper\n",
    "authors": [
      "Niladri S. Chatterji",
      "Philip M. Long"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2004.12019"
  },
  {
    "id": "arXiv:2004.12764",
    "title": "\"Call me sexist, but...\": Revisiting Sexism Detection Using  Psychological Scales and Adversarial Samples",
    "abstract": "Comments: Indira Sen and Julian Kohne contributed equally to this work",
    "descriptor": "\nComments: Indira Sen and Julian Kohne contributed equally to this work\n",
    "authors": [
      "Mattia Samory",
      "Indira Sen",
      "Julian Kohne",
      "Fabian Floeck",
      "Claudia Wagner"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2004.12764"
  },
  {
    "id": "arXiv:2005.01795",
    "title": "Generating SOAP Notes from Doctor-Patient Conversations Using Modular  Summarization Techniques",
    "abstract": "Comments: Published at ACL 2021 Main Conference",
    "descriptor": "\nComments: Published at ACL 2021 Main Conference\n",
    "authors": [
      "Kundan Krishna",
      "Sopan Khosla",
      "Jeffrey P. Bigham",
      "Zachary C. Lipton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.01795"
  },
  {
    "id": "arXiv:2005.07478",
    "title": "Evaluating Mixed-Initiative Procedural Level Design Tools using a  Triple-Blind Mixed-Method User Study",
    "abstract": "Comments: Accepted to be Published in: IEEE Transactions on Games",
    "descriptor": "\nComments: Accepted to be Published in: IEEE Transactions on Games\n",
    "authors": [
      "Sean P. Walton",
      "Alma A. M. Rahat",
      "James Stovold"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2005.07478"
  },
  {
    "id": "arXiv:2005.10360",
    "title": "VideoForensicsHQ: Detecting High-quality Manipulated Face Videos",
    "abstract": "Comments: ICME 2021 camera-ready",
    "descriptor": "\nComments: ICME 2021 camera-ready\n",
    "authors": [
      "Gereon Fox",
      "Wentao Liu",
      "Hyeongwoo Kim",
      "Hans-Peter Seidel",
      "Mohamed Elgharib",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.10360"
  },
  {
    "id": "arXiv:2005.11791",
    "title": "Better Late than Never; Scaling Computation in Blockchains by Delaying  Execution",
    "abstract": "Better Late than Never; Scaling Computation in Blockchains by Delaying  Execution",
    "descriptor": "",
    "authors": [
      "Sourav Das",
      "Nitin Awathare",
      "Ling Ren",
      "Vinay Joseph Ribeiro",
      "Umesh Bellur"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2005.11791"
  },
  {
    "id": "arXiv:2006.00262",
    "title": "Data Augmentation with Unsupervised Machine Translation Improvesthe  Structural Similarity of Cross-lingual Word Embeddings",
    "abstract": "Comments: Accepted to ACL-IJCNLP 2021 SRW",
    "descriptor": "\nComments: Accepted to ACL-IJCNLP 2021 SRW\n",
    "authors": [
      "Sosuke Nishikawa",
      "Ryokan Ri",
      "Yoshimasa Tsuruoka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2006.00262"
  },
  {
    "id": "arXiv:2006.01414",
    "title": "Enhanced Universal Dependency Parsing with Second-Order Inference and  Mixture of Training Data",
    "abstract": "Comments: IWPT 2020 shared task. After fixing the bug, our proposed parser performs better than the team that ranked 1st in the official results",
    "descriptor": "\nComments: IWPT 2020 shared task. After fixing the bug, our proposed parser performs better than the team that ranked 1st in the official results\n",
    "authors": [
      "Xinyu Wang",
      "Yong Jiang",
      "Kewei Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.01414"
  },
  {
    "id": "arXiv:2006.05656",
    "title": "Why is Attention Not So Interpretable?",
    "abstract": "Comments: Proceedings of the 27th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
    "descriptor": "\nComments: Proceedings of the 27th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining\n",
    "authors": [
      "Bing Bai",
      "Jian Liang",
      "Guanhua Zhang",
      "Hao Li",
      "Kun Bai",
      "Fei Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.05656"
  },
  {
    "id": "arXiv:2006.05681",
    "title": "Off-Policy Risk-Sensitive Reinforcement Learning Based Constrained  Robust Optimal Control",
    "abstract": "Off-Policy Risk-Sensitive Reinforcement Learning Based Constrained  Robust Optimal Control",
    "descriptor": "",
    "authors": [
      "Cong Li",
      "Fangzhou Liu",
      "Zhehua Zhou",
      "Martin Buss"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.05681"
  },
  {
    "id": "arXiv:2006.06963",
    "title": "Needle in a Haystack: Label-Efficient Evaluation under Extreme Class  Imbalance",
    "abstract": "Comments: 30 pages, 8 figures, updated to match version accepted for publication at KDD'21",
    "descriptor": "\nComments: 30 pages, 8 figures, updated to match version accepted for publication at KDD'21\n",
    "authors": [
      "Neil G. Marchant",
      "Benjamin I. P. Rubinstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.06963"
  },
  {
    "id": "arXiv:2006.08973",
    "title": "Deterministic Variational Inference for Neural SDEs",
    "abstract": "Deterministic Variational Inference for Neural SDEs",
    "descriptor": "",
    "authors": [
      "Andreas Look",
      "Melih Kandemir",
      "Jan Peters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.08973"
  },
  {
    "id": "arXiv:2007.06504",
    "title": "Towards Practical Lipreading with Distilled and Efficient Models",
    "abstract": "Comments: Accepted to ICASSP 2021",
    "descriptor": "\nComments: Accepted to ICASSP 2021\n",
    "authors": [
      "Pingchuan Ma",
      "Brais Martinez",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.06504"
  },
  {
    "id": "arXiv:2007.09261",
    "title": "Frequency Estimation in Data Streams: Learning the Optimal Hashing  Scheme",
    "abstract": "Comments: Submitted to IEEE Transactions on Knowledge and Data Engineering on 07/2020. Revised on 05/2021",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Knowledge and Data Engineering on 07/2020. Revised on 05/2021\n",
    "authors": [
      "Dimitris Bertsimas",
      "Vassilis Digalakis Jr"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.09261"
  },
  {
    "id": "arXiv:2007.14573",
    "title": "FIVES: Feature Interaction Via Edge Search for Large-Scale Tabular Data",
    "abstract": "Comments: Accepted by KDD-21",
    "descriptor": "\nComments: Accepted by KDD-21\n",
    "authors": [
      "Yuexiang Xie",
      "Zhen Wang",
      "Yaliang Li",
      "Bolin Ding",
      "Nezihe Merve G\u00fcrel",
      "Ce Zhang",
      "Minlie Huang",
      "Wei Lin",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.14573"
  },
  {
    "id": "arXiv:2008.08808",
    "title": "BGC: Multi-Agent Group Belief with Graph Clustering",
    "abstract": "Comments: 7 pages, 5 figures",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Tianze Zhou",
      "Fubiao Zhang",
      "Pan Tang",
      "Chenfei Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.08808"
  },
  {
    "id": "arXiv:2008.11552",
    "title": "Parameterization of All Output-Rectifying Retrofit Controllers",
    "abstract": "Comments: to be published at IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: to be published at IEEE Transactions on Automatic Control\n",
    "authors": [
      "Hampei Sasahara",
      "Takayuki Ishizaki",
      "Jun-ichi Imura"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.11552"
  },
  {
    "id": "arXiv:2009.00606",
    "title": "Semi-Supervised Empirical Risk Minimization: When can unlabeled data  improve prediction?",
    "abstract": "Comments: 36 pages, 4 figures",
    "descriptor": "\nComments: 36 pages, 4 figures\n",
    "authors": [
      "Oren Yuval",
      "Saharon Rosset"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2009.00606"
  },
  {
    "id": "arXiv:2009.03979",
    "title": "A Distance-preserving Matrix Sketch",
    "abstract": "Comments: 46 pages, 11 figures, submitted",
    "descriptor": "\nComments: 46 pages, 11 figures, submitted\n",
    "authors": [
      "Leland Wilkinson",
      "Hengrui Luo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.03979"
  },
  {
    "id": "arXiv:2009.05366",
    "title": "Distributed Density Filtering for Large-Scale Systems Using Mean-Filed  Models",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2006.11461",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.11461\n",
    "authors": [
      "Tongjia Zheng",
      "Hai Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.05366"
  },
  {
    "id": "arXiv:2009.06236",
    "title": "Consensus of Multi-agent System via Constrained Invariant Set of a class  of Unstable System",
    "abstract": "Comments: 13 pages, 8 figures",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Chong Jin Ong",
      "Bonan Hou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.06236"
  },
  {
    "id": "arXiv:2009.08330",
    "title": "More Embeddings, Better Sequence Labelers?",
    "abstract": "Comments: Accepted to Findings of EMNLP 2020. Camera-ready, 16 pages",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2020. Camera-ready, 16 pages\n",
    "authors": [
      "Xinyu Wang",
      "Yong Jiang",
      "Nguyen Bach",
      "Tao Wang",
      "Zhongqiang Huang",
      "Fei Huang",
      "Kewei Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.08330"
  },
  {
    "id": "arXiv:2009.13145",
    "title": "Adversarial Robustness of Stabilized NeuralODEs Might be from Obfuscated  Gradients",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Yifei Huang",
      "Yaodong Yu",
      "Hongyang Zhang",
      "Yi Ma",
      "Yuan Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.13145"
  },
  {
    "id": "arXiv:2010.00538",
    "title": "Avoiding coherent errors with rotated concatenated stabilizer codes",
    "abstract": "Comments: 8 pages, 5 figures, two columns",
    "descriptor": "\nComments: 8 pages, 5 figures, two columns\n",
    "authors": [
      "Yingkai Ouyang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.00538"
  },
  {
    "id": "arXiv:2010.01845",
    "title": "Unbiased Gradient Estimation for Variational Auto-Encoders using Coupled  Markov Chains",
    "abstract": "Unbiased Gradient Estimation for Variational Auto-Encoders using Coupled  Markov Chains",
    "descriptor": "",
    "authors": [
      "Francisco J. R. Ruiz",
      "Michalis K. Titsias",
      "Taylan Cemgil",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.01845"
  },
  {
    "id": "arXiv:2010.02172",
    "title": "Speakers Fill Lexical Semantic Gaps with Context",
    "abstract": "Comments: Camera ready version of EMNLP 2020 publication. Code is available in this https URL",
    "descriptor": "\nComments: Camera ready version of EMNLP 2020 publication. Code is available in this https URL\n",
    "authors": [
      "Tiago Pimentel",
      "Rowan Hall Maudslay",
      "Dami\u00e1n Blasi",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.02172"
  },
  {
    "id": "arXiv:2010.02716",
    "title": "AI Lifecycle Models Need To Be Revised. An Exploratory Study in Fintech",
    "abstract": "Comments: Accepted in Empirical Software Engineering in April, 2021",
    "descriptor": "\nComments: Accepted in Empirical Software Engineering in April, 2021\n",
    "authors": [
      "Mark Haakman",
      "Lu\u00eds Cruz",
      "Hennie Huijgens",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2010.02716"
  },
  {
    "id": "arXiv:2010.02823",
    "title": "Tight Polynomial Bounds for Loop Programs in Polynomial Space",
    "abstract": "Comments: 50 pages",
    "descriptor": "\nComments: 50 pages\n",
    "authors": [
      "A. M. Ben-Amram",
      "G. W. Hamilton"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2010.02823"
  },
  {
    "id": "arXiv:2010.04690",
    "title": "Robust Isometric Non-Rigid Structure-from-Motion",
    "abstract": "Comments: Accepted in TPAMI 2021",
    "descriptor": "\nComments: Accepted in TPAMI 2021\n",
    "authors": [
      "Shaifali Parashar",
      "Adrien Bartoli",
      "Daniel Pizarro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.04690"
  },
  {
    "id": "arXiv:2010.05003",
    "title": "Second-Order Neural Dependency Parsing with Message Passing and  End-to-End Training",
    "abstract": "Comments: Accepted to AACL 2020. 7 pages",
    "descriptor": "\nComments: Accepted to AACL 2020. 7 pages\n",
    "authors": [
      "Xinyu Wang",
      "Kewei Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.05003"
  },
  {
    "id": "arXiv:2010.05010",
    "title": "Structural Knowledge Distillation: Tractably Distilling Information for  Structured Predictor",
    "abstract": "Comments: Accepted to Proceedings of ACL-IJCNLP 2021. 15 pages",
    "descriptor": "\nComments: Accepted to Proceedings of ACL-IJCNLP 2021. 15 pages\n",
    "authors": [
      "Xinyu Wang",
      "Yong Jiang",
      "Zhaohui Yan",
      "Zixia Jia",
      "Nguyen Bach",
      "Tao Wang",
      "Zhongqiang Huang",
      "Fei Huang",
      "Kewei Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.05010"
  },
  {
    "id": "arXiv:2010.08264",
    "title": "Theta functions and optimal lattices for a grid cells model",
    "abstract": "Comments: 22 pages. 11 Figures. Version accepted by SIAM Journal of Applied Mathematics (SIAP)",
    "descriptor": "\nComments: 22 pages. 11 Figures. Version accepted by SIAM Journal of Applied Mathematics (SIAP)\n",
    "authors": [
      "Laurent B\u00e9termin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2010.08264"
  },
  {
    "id": "arXiv:2010.09181",
    "title": "Multiscale simulations for multi-continuum Richards equations",
    "abstract": "Comments: 45 pages, 4 figures, 2 tables, major revision. This is the accepted manuscript by Journal of Computational and Applied Mathematics (2021). The published journal article is available at this https URL (2021)",
    "descriptor": "\nComments: 45 pages, 4 figures, 2 tables, major revision. This is the accepted manuscript by Journal of Computational and Applied Mathematics (2021). The published journal article is available at this https URL (2021)\n",
    "authors": [
      "Jun Sur Richard Park",
      "Siu Wun Cheung",
      "Tina Mai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2010.09181"
  },
  {
    "id": "arXiv:2010.09559",
    "title": "Multilayer Network Analysis for Improved Credit Risk Prediction",
    "abstract": "Comments: 25 pages, 13 figures. v3 - revised and resubmitted",
    "descriptor": "\nComments: 25 pages, 13 figures. v3 - revised and resubmitted\n",
    "authors": [
      "Mar\u00eda \u00d3skarsd\u00f3ttir",
      "Cristi\u00e1n Bravo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.09559"
  },
  {
    "id": "arXiv:2010.10035",
    "title": "Elaborative Simplification: Content Addition and Explanation Generation  in Text Simplification",
    "abstract": "Comments: Findings of ACL 2021 Camera-Ready",
    "descriptor": "\nComments: Findings of ACL 2021 Camera-Ready\n",
    "authors": [
      "Neha Srikanth",
      "Junyi Jessy Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.10035"
  },
  {
    "id": "arXiv:2010.10805",
    "title": "SeqTrans: Automatic Vulnerability Fix via Sequence to Sequence Learning",
    "abstract": "Comments: 20 pages, 18 figures, 5 tables",
    "descriptor": "\nComments: 20 pages, 18 figures, 5 tables\n",
    "authors": [
      "Jianlei Chi",
      "Yu Qu",
      "Ting Liu",
      "Qinghua Zheng",
      "Heng Yin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2010.10805"
  },
  {
    "id": "arXiv:2010.11660",
    "title": "Detecting Rewards Deterioration in Episodic Reinforcement Learning",
    "abstract": "Detecting Rewards Deterioration in Episodic Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Ido Greenberg",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.11660"
  },
  {
    "id": "arXiv:2010.12725",
    "title": "Compositional Generalization and Natural Language Variation: Can a  Semantic Parsing Approach Handle Both?",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Peter Shaw",
      "Ming-Wei Chang",
      "Panupong Pasupat",
      "Kristina Toutanova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12725"
  },
  {
    "id": "arXiv:2010.15843",
    "title": "deep21: a Deep Learning Method for 21cm Foreground Removal",
    "abstract": "Comments: Published in JCAP 30 April 2021. 30 pages, 11 figures",
    "descriptor": "\nComments: Published in JCAP 30 April 2021. 30 pages, 11 figures\n",
    "authors": [
      "T. Lucas Makinen",
      "Lachlan Lancaster",
      "Francisco Villaescusa-Navarro",
      "Peter Melchior",
      "Shirley Ho",
      "Laurence Perreault-Levasseur",
      "David N. Spergel"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.15843"
  },
  {
    "id": "arXiv:2010.16046",
    "title": "VECO: Variable and Flexible Cross-lingual Pre-training for Language  Understanding and Generation",
    "abstract": "Comments: Accepted by ACL 2021 (long paper)",
    "descriptor": "\nComments: Accepted by ACL 2021 (long paper)\n",
    "authors": [
      "Fuli Luo",
      "Wei Wang",
      "Jiahao Liu",
      "Yijia Liu",
      "Bin Bi",
      "Songfang Huang",
      "Fei Huang",
      "Luo Si"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.16046"
  },
  {
    "id": "arXiv:2011.04026",
    "title": "Pathwise Conditioning of Gaussian Processes",
    "abstract": "Pathwise Conditioning of Gaussian Processes",
    "descriptor": "",
    "authors": [
      "James T. Wilson",
      "Viacheslav Borovitskiy",
      "Alexander Terenin",
      "Peter Mostowsky",
      "Marc Peter Deisenroth"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2011.04026"
  },
  {
    "id": "arXiv:2011.05049",
    "title": "Human-centric Spatio-Temporal Video Grounding With Visual Transformers",
    "abstract": "Comments: Accept at TCSVT",
    "descriptor": "\nComments: Accept at TCSVT\n",
    "authors": [
      "Zongheng Tang",
      "Yue Liao",
      "Si Liu",
      "Guanbin Li",
      "Xiaojie Jin",
      "Hongxu Jiang",
      "Qian Yu",
      "Dong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2011.05049"
  },
  {
    "id": "arXiv:2011.05707",
    "title": "Low-resource expressive text-to-speech using data augmentation",
    "abstract": "Low-resource expressive text-to-speech using data augmentation",
    "descriptor": "",
    "authors": [
      "Goeric Huybrechts",
      "Thomas Merritt",
      "Giulia Comini",
      "Bartek Perz",
      "Raahil Shah",
      "Jaime Lorenzo-Trueba"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2011.05707"
  },
  {
    "id": "arXiv:2011.05878",
    "title": "Kings in Multipartite Hypertournaments",
    "abstract": "Kings in Multipartite Hypertournaments",
    "descriptor": "",
    "authors": [
      "Jiangdong Ai",
      "Stefanie Gerke",
      "Gregory Gutin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2011.05878"
  },
  {
    "id": "arXiv:2011.07542",
    "title": "Automatic and perceptual discrimination between dysarthria, apraxia of  speech, and neurotypical speech",
    "abstract": "Comments: ICASSP 2021",
    "descriptor": "\nComments: ICASSP 2021\n",
    "authors": [
      "I. Kodrasi",
      "M. Pernon",
      "M. Laganaro",
      "H. Bourlard"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2011.07542"
  },
  {
    "id": "arXiv:2011.08019",
    "title": "On the Effectiveness of Vision Transformers for Zero-shot Face  Anti-Spoofing",
    "abstract": "Comments: 8 pages, 3 figures, Accepted for Publication in IJCB2021",
    "descriptor": "\nComments: 8 pages, 3 figures, Accepted for Publication in IJCB2021\n",
    "authors": [
      "Anjith George",
      "Sebastien Marcel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.08019"
  },
  {
    "id": "arXiv:2011.08826",
    "title": "Deep Active Surface Models",
    "abstract": "Comments: 11 pages, 7 figures, 6 tables",
    "descriptor": "\nComments: 11 pages, 7 figures, 6 tables\n",
    "authors": [
      "Udaranga Wickramasinghe",
      "Graham Knott",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.08826"
  },
  {
    "id": "arXiv:2011.10185",
    "title": "ConvTransformer: A Convolutional Transformer Network for Video Frame  Synthesis",
    "abstract": "ConvTransformer: A Convolutional Transformer Network for Video Frame  Synthesis",
    "descriptor": "",
    "authors": [
      "Zhouyong Liu",
      "Shun Luo",
      "Wubin Li",
      "Jingben Lu",
      "Yufan Wu",
      "Shilei Sun",
      "Chunguo Li",
      "Luxi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.10185"
  },
  {
    "id": "arXiv:2011.13055",
    "title": "Rethinking conditional GAN training: An approach using geometrically  structured latent manifolds",
    "abstract": "Rethinking conditional GAN training: An approach using geometrically  structured latent manifolds",
    "descriptor": "",
    "authors": [
      "Sameera Ramasinghe",
      "Moshiur Farazi",
      "Salman Khan",
      "Nick Barnes",
      "Stephen Gould"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.13055"
  },
  {
    "id": "arXiv:2012.00212",
    "title": "UPFlow: Upsampling Pyramid for Unsupervised Optical Flow Learning",
    "abstract": "UPFlow: Upsampling Pyramid for Unsupervised Optical Flow Learning",
    "descriptor": "",
    "authors": [
      "Kunming Luo",
      "Chuan Wang",
      "Shuaicheng Liu",
      "Haoqiang Fan",
      "Jue Wang",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.00212"
  },
  {
    "id": "arXiv:2012.00517",
    "title": "One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer",
    "abstract": "One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer",
    "descriptor": "",
    "authors": [
      "Joni Korpihalkola",
      "Tuomo Sipola",
      "Samir Puuska",
      "Tero Kokkonen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.00517"
  },
  {
    "id": "arXiv:2012.01696",
    "title": "FairBatch: Batch Selection for Model Fairness",
    "abstract": "Comments: In Proceedings of the 9th International Conference on Learning Representations (ICLR), 2021",
    "descriptor": "\nComments: In Proceedings of the 9th International Conference on Learning Representations (ICLR), 2021\n",
    "authors": [
      "Yuji Roh",
      "Kangwook Lee",
      "Steven Euijong Whang",
      "Changho Suh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.01696"
  },
  {
    "id": "arXiv:2012.01707",
    "title": "Leveraging Abstract Meaning Representation for Knowledge Base Question  Answering",
    "abstract": "Comments: Accepted to Findings of ACL",
    "descriptor": "\nComments: Accepted to Findings of ACL\n",
    "authors": [
      "Pavan Kapanipathi",
      "Ibrahim Abdelaziz",
      "Srinivas Ravishankar",
      "Salim Roukos",
      "Alexander Gray",
      "Ramon Astudillo",
      "Maria Chang",
      "Cristina Cornelio",
      "Saswati Dana",
      "Achille Fokoue",
      "Dinesh Garg",
      "Alfio Gliozzo",
      "Sairam Gurajada",
      "Hima Karanam",
      "Naweed Khan",
      "Dinesh Khandelwal",
      "Young-Suk Lee",
      "Yunyao Li",
      "Francois Luus",
      "Ndivhuwo Makondo",
      "Nandana Mihindukulasooriya",
      "Tahira Naseem",
      "Sumit Neelam",
      "Lucian Popa",
      "Revanth Reddy",
      "Ryan Riegel",
      "Gaetano Rossiello",
      "Udit Sharma",
      "G P Shrivatsa Bhargav",
      "Mo Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.01707"
  },
  {
    "id": "arXiv:2012.04012",
    "title": "Learning an Animatable Detailed 3D Face Model from In-The-Wild Images",
    "abstract": "Comments: SIGGRAPH 2021",
    "descriptor": "\nComments: SIGGRAPH 2021\n",
    "authors": [
      "Yao Feng",
      "Haiwen Feng",
      "Michael J. Black",
      "Timo Bolkart"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04012"
  },
  {
    "id": "arXiv:2012.04028",
    "title": "On-Road Motion Planning for Automated Vehicles at Ulm University",
    "abstract": "Comments: Maximilian Graf and Oliver Speidel contributed equally",
    "descriptor": "\nComments: Maximilian Graf and Oliver Speidel contributed equally\n",
    "authors": [
      "Maximilian Graf",
      "Oliver Speidel",
      "Jona Ruof",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.04028"
  },
  {
    "id": "arXiv:2012.04174",
    "title": "WSR: A WiFi Sensor for Collaborative Robotics",
    "abstract": "Comments: 28 pages, 25 figures, *co-primary authors",
    "descriptor": "\nComments: 28 pages, 25 figures, *co-primary authors\n",
    "authors": [
      "Ninad Jadhav",
      "Weiying Wang",
      "Diana Zhang",
      "Oussama Khatib",
      "Swarun Kumar",
      "Stephanie Gil"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2012.04174"
  },
  {
    "id": "arXiv:2012.04731",
    "title": "Long Term Motion Prediction Using Keyposes",
    "abstract": "Comments: See supplementary video at: this https URL",
    "descriptor": "\nComments: See supplementary video at: this https URL\n",
    "authors": [
      "Sena Kiciroglu",
      "Wei Wang",
      "Mathieu Salzmann",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04731"
  },
  {
    "id": "arXiv:2012.04808",
    "title": "Fusing Context Into Knowledge Graph for Commonsense Question Answering",
    "abstract": "Comments: To appear at ACL 2021",
    "descriptor": "\nComments: To appear at ACL 2021\n",
    "authors": [
      "Yichong Xu",
      "Chenguang Zhu",
      "Ruochen Xu",
      "Yang Liu",
      "Michael Zeng",
      "Xuedong Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.04808"
  },
  {
    "id": "arXiv:2012.05395",
    "title": "Infusing Finetuning with Semantic Dependencies",
    "abstract": "Comments: TACL 2021",
    "descriptor": "\nComments: TACL 2021\n",
    "authors": [
      "Zhaofeng Wu",
      "Hao Peng",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.05395"
  },
  {
    "id": "arXiv:2012.06390",
    "title": "Closeness and Uncertainty Aware Adversarial Examples Detection in  Adversarial Machine Learning",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Omer Faruk Tuna",
      "Ferhat Ozgur Catak",
      "M. Taner Eskil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.06390"
  },
  {
    "id": "arXiv:2012.08346",
    "title": "On the Integrality Gap of Binary Integer Programs with Gaussian Data",
    "abstract": "On the Integrality Gap of Binary Integer Programs with Gaussian Data",
    "descriptor": "",
    "authors": [
      "Sander Borst",
      "Daniel Dadush",
      "Sophie Huiberts",
      "Samarth Tiwari"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.08346"
  },
  {
    "id": "arXiv:2012.09432",
    "title": "On the experimental feasibility of quantum state reconstruction via  machine learning",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Sanjaya Lohani",
      "Thomas A. Searles",
      "Brian T. Kirby",
      "Ryan T. Glasser"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.09432"
  },
  {
    "id": "arXiv:2012.10589",
    "title": "A Comparison of Three Measurement Models for the Wheel-mounted MEMS  IMU-based Dead Reckoning System",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1912.07805",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1912.07805\n",
    "authors": [
      "Yibin Wu",
      "Xiaoji Niu",
      "Jian Kuang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.10589"
  },
  {
    "id": "arXiv:2012.12624",
    "title": "Learning Dense Representations of Phrases at Scale",
    "abstract": "Comments: ACL 2021. Code available at this https URL",
    "descriptor": "\nComments: ACL 2021. Code available at this https URL\n",
    "authors": [
      "Jinhyuk Lee",
      "Mujeen Sung",
      "Jaewoo Kang",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.12624"
  },
  {
    "id": "arXiv:2012.14681",
    "title": "Faster Re-translation Using Non-Autoregressive Model For Simultaneous  Neural Machine Translation",
    "abstract": "Faster Re-translation Using Non-Autoregressive Model For Simultaneous  Neural Machine Translation",
    "descriptor": "",
    "authors": [
      "Hyojung Han",
      "Sathish Indurthi",
      "Mohd Abbas Zaidi",
      "Nikhil Kumar Lakumarapu",
      "Beomseok Lee",
      "Sangha Kim",
      "Chanwoo Kim",
      "Inchul Hwang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.14681"
  },
  {
    "id": "arXiv:2012.14862",
    "title": "Few-Shot Text Ranking with Meta Adapted Synthetic Weak Supervision",
    "abstract": "Comments: 14 pages, accepted by ACL-IJCNLP 2021 (long paper)",
    "descriptor": "\nComments: 14 pages, accepted by ACL-IJCNLP 2021 (long paper)\n",
    "authors": [
      "Si Sun",
      "Yingzhuo Qian",
      "Zhenghao Liu",
      "Chenyan Xiong",
      "Kaitao Zhang",
      "Jie Bao",
      "Zhiyuan Liu",
      "Paul Bennett"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.14862"
  },
  {
    "id": "arXiv:2012.14919",
    "title": "WikiTableT: A Large-Scale Data-to-Text Dataset for Generating Wikipedia  Article Sections",
    "abstract": "Comments: Findings of ACL 2021, camera-ready version",
    "descriptor": "\nComments: Findings of ACL 2021, camera-ready version\n",
    "authors": [
      "Mingda Chen",
      "Sam Wiseman",
      "Kevin Gimpel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.14919"
  },
  {
    "id": "arXiv:2012.15045",
    "title": "Reservoir Transformers",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Sheng Shen",
      "Alexei Baevski",
      "Ari S. Morcos",
      "Kurt Keutzer",
      "Michael Auli",
      "Douwe Kiela"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15045"
  },
  {
    "id": "arXiv:2012.15229",
    "title": "Can Sequence-to-Sequence Models Crack Substitution Ciphers?",
    "abstract": "Comments: ACL 2021 main conference",
    "descriptor": "\nComments: ACL 2021 main conference\n",
    "authors": [
      "Nada Aldarrab",
      "Jonathan May"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15229"
  },
  {
    "id": "arXiv:2012.15243",
    "title": "Unsupervised Label-aware Event Trigger and Argument Classification",
    "abstract": "Comments: ACL 2021 Findings",
    "descriptor": "\nComments: ACL 2021 Findings\n",
    "authors": [
      "Hongming Zhang",
      "Haoyu Wang",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15243"
  },
  {
    "id": "arXiv:2012.15613",
    "title": "How Good is Your Tokenizer? On the Monolingual Performance of  Multilingual Language Models",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Phillip Rust",
      "Jonas Pfeiffer",
      "Ivan Vuli\u0107",
      "Sebastian Ruder",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15613"
  },
  {
    "id": "arXiv:2012.15682",
    "title": "A Closer Look at Few-Shot Crosslingual Transfer: The Choice of Shots  Matters",
    "abstract": "Comments: ACL-IJCNLP 2021",
    "descriptor": "\nComments: ACL-IJCNLP 2021\n",
    "authors": [
      "Mengjie Zhao",
      "Yi Zhu",
      "Ehsan Shareghi",
      "Ivan Vuli\u0107",
      "Roi Reichart",
      "Anna Korhonen",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15682"
  },
  {
    "id": "arXiv:2012.15723",
    "title": "Making Pre-trained Language Models Better Few-shot Learners",
    "abstract": "Comments: Accepted to ACL 2021. The code is publicly available at this https URL",
    "descriptor": "\nComments: Accepted to ACL 2021. The code is publicly available at this https URL\n",
    "authors": [
      "Tianyu Gao",
      "Adam Fisch",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.15723"
  },
  {
    "id": "arXiv:2012.15859",
    "title": "Intrinsic Bias Metrics Do Not Correlate with Application Bias",
    "abstract": "Comments: In Proceedings of ACL 2021, 9 pages",
    "descriptor": "\nComments: In Proceedings of ACL 2021, 9 pages\n",
    "authors": [
      "Seraphina Goldfarb-Tarrant",
      "Rebecca Marchant",
      "Ricardo Mu\u00f1oz Sanchez",
      "Mugdha Pandya",
      "Adam Lopez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15859"
  },
  {
    "id": "arXiv:2101.00121",
    "title": "WARP: Word-level Adversarial ReProgramming",
    "abstract": "Comments: Accepted ACL 2021 Long Paper",
    "descriptor": "\nComments: Accepted ACL 2021 Long Paper\n",
    "authors": [
      "Karen Hambardzumyan",
      "Hrant Khachatrian",
      "Jonathan May"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00121"
  },
  {
    "id": "arXiv:2101.00403",
    "title": "Superbizarre Is Not Superb: Derivational Morphology Improves BERT's  Interpretation of Complex Words",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Valentin Hofmann",
      "Janet B. Pierrehumbert",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00403"
  },
  {
    "id": "arXiv:2101.00408",
    "title": "End-to-End Training of Neural Retrievers for Open-Domain Question  Answering",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Devendra Singh Sachan",
      "Mostofa Patwary",
      "Mohammad Shoeybi",
      "Neel Kant",
      "Wei Ping",
      "William L Hamilton",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.00408"
  },
  {
    "id": "arXiv:2101.00438",
    "title": "Few-Shot Question Answering by Pretraining Span Selection",
    "abstract": "Comments: Accepted to ACL 2021",
    "descriptor": "\nComments: Accepted to ACL 2021\n",
    "authors": [
      "Ori Ram",
      "Yuval Kirstain",
      "Jonathan Berant",
      "Amir Globerson",
      "Omer Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00438"
  },
  {
    "id": "arXiv:2101.00588",
    "title": "Style Normalization and Restitution for Domain Generalization and  Adaptation",
    "abstract": "Comments: We have extended our SNR for domain generalization and adaptation to various computer vision tasks, e.g., image classification, object detection, semantic segmentation",
    "descriptor": "\nComments: We have extended our SNR for domain generalization and adaptation to various computer vision tasks, e.g., image classification, object detection, semantic segmentation\n",
    "authors": [
      "Xin Jin",
      "Cuiling Lan",
      "Wenjun Zeng",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.00588"
  },
  {
    "id": "arXiv:2101.01308",
    "title": "CycleSegNet: Object Co-segmentation with Cycle Refinement and Region  Correspondence",
    "abstract": "Comments: Accept to TIP",
    "descriptor": "\nComments: Accept to TIP\n",
    "authors": [
      "Chi Zhang",
      "Guankai Li",
      "Guosheng Lin",
      "Qingyao Wu",
      "Rui Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.01308"
  },
  {
    "id": "arXiv:2101.01785",
    "title": "ARBERT & MARBERT: Deep Bidirectional Transformers for Arabic",
    "abstract": "Comments: All authors contributed equally. The order is alphabetical",
    "descriptor": "\nComments: All authors contributed equally. The order is alphabetical\n",
    "authors": [
      "Muhammad Abdul-Mageed",
      "AbdelRahim Elmadany",
      "El Moatez Billah Nagoudi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.01785"
  },
  {
    "id": "arXiv:2101.04017",
    "title": "A Commonsense Reasoning Framework for Explanatory Emotion Attribution,  Generation and Re-classification",
    "abstract": "Comments: 50 pages. This work has been partially funded from the European Research Council (ERC) under the European Union'sHorizon 2020 research and innovation programme, grant agreement n{\\deg}870811",
    "descriptor": "\nComments: 50 pages. This work has been partially funded from the European Research Council (ERC) under the European Union'sHorizon 2020 research and innovation programme, grant agreement n{\\deg}870811\n",
    "authors": [
      "Antonio Lieto",
      "Gian Luca Pozzato",
      "Stefano Zoia",
      "Viviana Patti",
      "Rossana Damiano"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.04017"
  },
  {
    "id": "arXiv:2101.06291",
    "title": "Trading on-chain: How Feasible is Regulators' Worst-Case Scenario?",
    "abstract": "Trading on-chain: How Feasible is Regulators' Worst-Case Scenario?",
    "descriptor": "",
    "authors": [
      "Mahsa Moosavi",
      "Jeremy Clark"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2101.06291"
  },
  {
    "id": "arXiv:2101.06718",
    "title": "On the Design of Structured Stabilizers for LTI Systems",
    "abstract": "Comments: V1 fixes a few minor typos in the published version. V2 includes a clarification and fixes some minor typos in the proof of Theorem 2",
    "descriptor": "\nComments: V1 fixes a few minor typos in the published version. V2 includes a clarification and fixes some minor typos in the proof of Theorem 2\n",
    "authors": [
      "Francesco Ferrante",
      "Fabrizio Dabbene",
      "Chiara Ravazzi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.06718"
  },
  {
    "id": "arXiv:2101.06781",
    "title": "Demystifying Pythia: A Survey of ChainLink Oracles Usage on Ethereum",
    "abstract": "Demystifying Pythia: A Survey of ChainLink Oracles Usage on Ethereum",
    "descriptor": "",
    "authors": [
      "Mudabbir Kaleem",
      "Weidong Shi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2101.06781"
  },
  {
    "id": "arXiv:2101.06968",
    "title": "Motor-Imagery-Based Brain Computer Interface using Signal Derivation and  Aggregation Functions",
    "abstract": "Comments: IEEE Transactions on Cybernetics (2021)",
    "descriptor": "\nComments: IEEE Transactions on Cybernetics (2021)\n",
    "authors": [
      "Javier Fumanal-Idocin",
      "Yu-Kai Wang",
      "Chin-Teng Lin",
      "Javier Fern\u00e1ndez",
      "Jose Antonio Sanz",
      "Humberto Bustince"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.06968"
  },
  {
    "id": "arXiv:2101.07994",
    "title": "Distributed Motion Coordination Using Convex Feasible Set Based Model  Predictive Control",
    "abstract": "Comments: 7 pages, 10 figures. ICRA 2021",
    "descriptor": "\nComments: 7 pages, 10 figures. ICRA 2021\n",
    "authors": [
      "Hongyu Zhou",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.07994"
  },
  {
    "id": "arXiv:2101.08141",
    "title": "Positive spectrahedra: Invariance principles and Pseudorandom generators",
    "abstract": "Comments: 63 pages. v2: Minor revisions and Improvements in presentation",
    "descriptor": "\nComments: 63 pages. v2: Minor revisions and Improvements in presentation\n",
    "authors": [
      "Srinivasan Arunachalam",
      "Penghui Yao"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2101.08141"
  },
  {
    "id": "arXiv:2101.08609",
    "title": "MPASNET: Motion Prior-Aware Siamese Network for Unsupervised Deep Crowd  Segmentation in Video Scenes",
    "abstract": "Comments: ICIP 2021 Camera Ready",
    "descriptor": "\nComments: ICIP 2021 Camera Ready\n",
    "authors": [
      "Jinhai Yang",
      "Hua Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.08609"
  },
  {
    "id": "arXiv:2101.08658",
    "title": "Fidelity and Privacy of Synthetic Medical Data",
    "abstract": "Fidelity and Privacy of Synthetic Medical Data",
    "descriptor": "",
    "authors": [
      "Ofer Mendelevitch",
      "Michael D. Lesh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2101.08658"
  },
  {
    "id": "arXiv:2101.10423",
    "title": "Online Continual Learning in Image Classification: An Empirical Survey",
    "abstract": "Comments: Submitted to Neurocomputing. Codes available at this https URL",
    "descriptor": "\nComments: Submitted to Neurocomputing. Codes available at this https URL\n",
    "authors": [
      "Zheda Mai",
      "Ruiwen Li",
      "Jihwan Jeong",
      "David Quispe",
      "Hyunwoo Kim",
      "Scott Sanner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.10423"
  },
  {
    "id": "arXiv:2101.10478",
    "title": "A unifying algebraic framework for discontinuous Galerkin and flux  reconstruction methods based on the summation-by-parts property",
    "abstract": "Comments: 41 pages, 4 figures",
    "descriptor": "\nComments: 41 pages, 4 figures\n",
    "authors": [
      "Tristan Montoya",
      "David W. Zingg"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2101.10478"
  },
  {
    "id": "arXiv:2102.01189",
    "title": "GraphDF: A Discrete Flow Model for Molecular Graph Generation",
    "abstract": "Comments: Accepted by ICML 2021",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Youzhi Luo",
      "Keqiang Yan",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.01189"
  },
  {
    "id": "arXiv:2102.02504",
    "title": "Meta-strategy for Learning Tuning Parameters with Guarantees",
    "abstract": "Meta-strategy for Learning Tuning Parameters with Guarantees",
    "descriptor": "",
    "authors": [
      "Dimitri Meunier",
      "Pierre Alquier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2102.02504"
  },
  {
    "id": "arXiv:2102.05504",
    "title": "Energy-Aware Adaptive Offloading of Soft Real-Time Jobs in Mobile Edge  Clouds",
    "abstract": "Energy-Aware Adaptive Offloading of Soft Real-Time Jobs in Mobile Edge  Clouds",
    "descriptor": "",
    "authors": [
      "Joaquim Silva",
      "Eduardo R.B. Marques",
      "Lu\u00eds M.B Lopes",
      "Fernando Silva"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.05504"
  },
  {
    "id": "arXiv:2102.07926",
    "title": "Have Attention Heads in BERT Learned Constituency Grammar?",
    "abstract": "Comments: Accept at the EACL 2021 Student Research Workshop",
    "descriptor": "\nComments: Accept at the EACL 2021 Student Research Workshop\n",
    "authors": [
      "Ziyang Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.07926"
  },
  {
    "id": "arXiv:2102.08019",
    "title": "A Thorough View of Exact Inference in Graphs from the Degree-4  Sum-of-Squares Hierarchy",
    "abstract": "Comments: 17 pages, 5 figures",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Kevin Bello",
      "Chuyang Ke",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.08019"
  },
  {
    "id": "arXiv:2102.08431",
    "title": "Complex Momentum for Optimization in Games",
    "abstract": "Complex Momentum for Optimization in Games",
    "descriptor": "",
    "authors": [
      "Jonathan Lorraine",
      "David Acuna",
      "Paul Vicol",
      "David Duvenaud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2102.08431"
  },
  {
    "id": "arXiv:2102.11075",
    "title": "SENTINEL: Taming Uncertainty with Ensemble-based Distributional  Reinforcement Learning",
    "abstract": "Comments: 30 pages, 9 figures, 8 tables",
    "descriptor": "\nComments: 30 pages, 9 figures, 8 tables\n",
    "authors": [
      "Hannes Eriksson",
      "Debabrota Basu",
      "Mina Alibeigi",
      "Christos Dimitrakakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.11075"
  },
  {
    "id": "arXiv:2102.11630",
    "title": "Decision Power of Weak Asynchronous Models of Distributed Computing",
    "abstract": "Comments: Various minor revisions",
    "descriptor": "\nComments: Various minor revisions\n",
    "authors": [
      "Philipp Czerner",
      "Roland Guttenberg",
      "Martin Helfrich",
      "Javier Esparza"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2102.11630"
  },
  {
    "id": "arXiv:2102.13177",
    "title": "Efficient and Interpretable Robot Manipulation with Graph Neural  Networks",
    "abstract": "Efficient and Interpretable Robot Manipulation with Graph Neural  Networks",
    "descriptor": "",
    "authors": [
      "Yixin Lin",
      "Austin S. Wang",
      "Akshara Rai"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.13177"
  },
  {
    "id": "arXiv:2103.00368",
    "title": "PairRank: Online Pairwise Learning to Rank by Divide-and-Conquer",
    "abstract": "Comments: The Web Conference 2021",
    "descriptor": "\nComments: The Web Conference 2021\n",
    "authors": [
      "Yiling Jia",
      "Huazheng Wang",
      "Stephen Guo",
      "Hongning Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2103.00368"
  },
  {
    "id": "arXiv:2103.01924",
    "title": "Masked Face Recognition: Human vs. Machine",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Naser Damer",
      "Fadi Boutros",
      "Marius S\u00fc\u00dfmilch",
      "Meiling Fang",
      "Florian Kirchbuchner",
      "Arjan Kuijper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2103.01924"
  },
  {
    "id": "arXiv:2103.01948",
    "title": "Offline Reinforcement Learning with Pseudometric Learning",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Robert Dadashi",
      "Shideh Rezaeifar",
      "Nino Vieillard",
      "L\u00e9onard Hussenot",
      "Olivier Pietquin",
      "Matthieu Geist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01948"
  },
  {
    "id": "arXiv:2103.03000",
    "title": "SpectralDefense: Detecting Adversarial Attacks on CNNs in the Fourier  Domain",
    "abstract": "SpectralDefense: Detecting Adversarial Attacks on CNNs in the Fourier  Domain",
    "descriptor": "",
    "authors": [
      "Paula Harder",
      "Franz-Josef Pfreundt",
      "Margret Keuper",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.03000"
  },
  {
    "id": "arXiv:2103.03142",
    "title": "Error-driven Fixed-Budget ASR Personalization for Accented Speakers",
    "abstract": "Comments: In ICASSP 2021",
    "descriptor": "\nComments: In ICASSP 2021\n",
    "authors": [
      "Abhijeet Awasthi",
      "Aman Kansal",
      "Sunita Sarawagi",
      "Preethi Jyothi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2103.03142"
  },
  {
    "id": "arXiv:2103.04205",
    "title": "Matroid Secretary is Equivalent to Contention Resolution",
    "abstract": "Matroid Secretary is Equivalent to Contention Resolution",
    "descriptor": "",
    "authors": [
      "Shaddin Dughmi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2103.04205"
  },
  {
    "id": "arXiv:2103.06393",
    "title": "Compression of volume-surface integral equation matrices via Tucker  decomposition for magnetic resonance applications",
    "abstract": "Comments: 13 pages, 11 figures",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Ilias I. Giannakopoulos",
      "Georgy D. Guryev",
      "Jose E. C. Serralles",
      "Ioannis P. Georgakis",
      "Luca Daniel",
      "Jacob K. White",
      "Riccardo Lattanzi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2103.06393"
  },
  {
    "id": "arXiv:2103.09118",
    "title": "Balancing Biases and Preserving Privacy on Balanced Faces in the Wild",
    "abstract": "Balancing Biases and Preserving Privacy on Balanced Faces in the Wild",
    "descriptor": "",
    "authors": [
      "Joseph P Robinson",
      "Can Qin",
      "Yann Henon",
      "Samson Timoner",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.09118"
  },
  {
    "id": "arXiv:2103.11233",
    "title": "Spark Deficient Gabor Frame Provides a Novel Analysis Operator for  Compressed Sensing",
    "abstract": "Spark Deficient Gabor Frame Provides a Novel Analysis Operator for  Compressed Sensing",
    "descriptor": "",
    "authors": [
      "Vasiliki Kouni",
      "Holger Rauhut"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.11233"
  },
  {
    "id": "arXiv:2103.12983",
    "title": "Counterfactual Explanation with Multi-Agent Reinforcement Learning for  Drug Target Prediction",
    "abstract": "Counterfactual Explanation with Multi-Agent Reinforcement Learning for  Drug Target Prediction",
    "descriptor": "",
    "authors": [
      "Tri Minh Nguyen",
      "Thomas P Quinn",
      "Thin Nguyen",
      "Truyen Tran"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.12983"
  },
  {
    "id": "arXiv:2103.15551",
    "title": "Toward Building Science Discovery Machines",
    "abstract": "Toward Building Science Discovery Machines",
    "descriptor": "",
    "authors": [
      "Abdullah Khalili",
      "Abdelhamid Bouchachia"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.15551"
  },
  {
    "id": "arXiv:2104.01378",
    "title": "speechocean762: An Open-Source Non-native English Speech Corpus For  Pronunciation Assessment",
    "abstract": "Comments: Accepted in INTERSPEECH 2021",
    "descriptor": "\nComments: Accepted in INTERSPEECH 2021\n",
    "authors": [
      "Junbo Zhang",
      "Zhiwen Zhang",
      "Yongqing Wang",
      "Zhiyong Yan",
      "Qiong Song",
      "Yukai Huang",
      "Ke Li",
      "Daniel Povey",
      "Yujun Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.01378"
  },
  {
    "id": "arXiv:2104.01504",
    "title": "Adaptive Self-Interference Cancellation for Full-Duplex Wireless  Communication Systems",
    "abstract": "Adaptive Self-Interference Cancellation for Full-Duplex Wireless  Communication Systems",
    "descriptor": "",
    "authors": [
      "Elyes Balti",
      "Brian L. Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.01504"
  },
  {
    "id": "arXiv:2104.04637",
    "title": "A Novel Provably Secure Key Agreement Protocol Based On Binary Matrices",
    "abstract": "A Novel Provably Secure Key Agreement Protocol Based On Binary Matrices",
    "descriptor": "",
    "authors": [
      "Abdelhaliem Babiker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.04637"
  },
  {
    "id": "arXiv:2104.04940",
    "title": "Dissecting the square into seven congruent parts",
    "abstract": "Dissecting the square into seven congruent parts",
    "descriptor": "",
    "authors": [
      "Gerardo L. Maldonado",
      "Edgardo Rold\u00e1n-Pensado"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2104.04940"
  },
  {
    "id": "arXiv:2104.05571",
    "title": "Using a Neural Network to Detect Anomalies given an N-gram Profile",
    "abstract": "Comments: 17 pages, 7 figures, 5th International Symposium on Cyber Security Cryptology and Machine Learning (CSCML 2021)",
    "descriptor": "\nComments: 17 pages, 7 figures, 5th International Symposium on Cyber Security Cryptology and Machine Learning (CSCML 2021)\n",
    "authors": [
      "Byunggu Yu",
      "Junwhan Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.05571"
  },
  {
    "id": "arXiv:2104.06624",
    "title": "Device-Cloud Collaborative Learning for Recommendation",
    "abstract": "Comments: KDD 2021",
    "descriptor": "\nComments: KDD 2021\n",
    "authors": [
      "Jiangchao Yao",
      "Feng Wang",
      "KunYang Jia",
      "Bo Han",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.06624"
  },
  {
    "id": "arXiv:2104.08700",
    "title": "Lottery Jackpots Exist in Pre-trained Models",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Yuxin Zhang",
      "Mingbao Lin",
      "Fei Chao",
      "Yan Wang",
      "Yongjian Wu",
      "Feiyue Huang",
      "Mingliang Xu",
      "Yonghong Tian",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08700"
  },
  {
    "id": "arXiv:2104.08736",
    "title": "Stochastic Optimization of Areas Under Precision-Recall Curves with  Provable Convergence",
    "abstract": "Comments: 25 pages, 8 figures",
    "descriptor": "\nComments: 25 pages, 8 figures\n",
    "authors": [
      "Qi Qi",
      "Youzhi Luo",
      "Zhao Xu",
      "Shuiwang Ji",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.08736"
  },
  {
    "id": "arXiv:2104.09696",
    "title": "X-METRA-ADA: Cross-lingual Meta-Transfer Learning Adaptation to Natural  Language Understanding and Question Answering",
    "abstract": "Comments: Accepted at NAACL 2021",
    "descriptor": "\nComments: Accepted at NAACL 2021\n",
    "authors": [
      "Meryem M'hamdi",
      "Doo Soon Kim",
      "Franck Dernoncourt",
      "Trung Bui",
      "Xiang Ren",
      "Jonathan May"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.09696"
  },
  {
    "id": "arXiv:2104.09959",
    "title": "Identifying Driver Interactions via Conditional Behavior Prediction",
    "abstract": "Identifying Driver Interactions via Conditional Behavior Prediction",
    "descriptor": "",
    "authors": [
      "Ekaterina Tolstaya",
      "Reza Mahjourian",
      "Carlton Downey",
      "Balakrishnan Varadarajan",
      "Benjamin Sapp",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.09959"
  },
  {
    "id": "arXiv:2104.09976",
    "title": "Finding Geometric Representations of Apex Graphs is NP-Hard",
    "abstract": "Finding Geometric Representations of Apex Graphs is NP-Hard",
    "descriptor": "",
    "authors": [
      "Dibyayan Chakraborty",
      "Kshitij Gajjar"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2104.09976"
  },
  {
    "id": "arXiv:2104.10083",
    "title": "Personalized News Recommendation with Knowledge-aware Interactive  Matching",
    "abstract": "Comments: SIGIR 2021",
    "descriptor": "\nComments: SIGIR 2021\n",
    "authors": [
      "Tao Qi",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2104.10083"
  },
  {
    "id": "arXiv:2104.10283",
    "title": "GraghVQA: Language-Guided Graph Neural Networks for Graph-based Visual  Question Answering",
    "abstract": "Comments: NAACL 2021 MAI-Workshop. Code available at this https URL",
    "descriptor": "\nComments: NAACL 2021 MAI-Workshop. Code available at this https URL\n",
    "authors": [
      "Weixin Liang",
      "Yanhao Jiang",
      "Zixuan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.10283"
  },
  {
    "id": "arXiv:2104.10747",
    "title": "Accented Speech Recognition: A Survey",
    "abstract": "Accented Speech Recognition: A Survey",
    "descriptor": "",
    "authors": [
      "Arthur Hinsvark",
      "Natalie Delworth",
      "Miguel Del Rio",
      "Quinten McNamara",
      "Joshua Dong",
      "Ryan Westerman",
      "Michelle Huang",
      "Joseph Palakapilly",
      "Jennifer Drexler",
      "Ilya Pirkin",
      "Nishchal Bhandari",
      "Miguel Jette"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.10747"
  },
  {
    "id": "arXiv:2104.14937",
    "title": "Federated Learning with Fair Averaging",
    "abstract": "Comments: to be published in IJCAI2021",
    "descriptor": "\nComments: to be published in IJCAI2021\n",
    "authors": [
      "Zheng Wang",
      "Xiaoliang Fan",
      "Jianzhong Qi",
      "Chenglu Wen",
      "Cheng Wang",
      "Rongshan Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14937"
  },
  {
    "id": "arXiv:2104.14963",
    "title": "Determining Chess Game State From an Image",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Georg W\u00f6lflein",
      "Ognjen Arandjelovi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14963"
  },
  {
    "id": "arXiv:2105.00113",
    "title": "IPatch: A Remote Adversarial Patch",
    "abstract": "IPatch: A Remote Adversarial Patch",
    "descriptor": "",
    "authors": [
      "Yisroel Mirsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00113"
  },
  {
    "id": "arXiv:2105.03229",
    "title": "VAULT: VAriable Unified Long Text Representation for Machine Reading  Comprehension",
    "abstract": "Comments: Accepted at ACL 2021",
    "descriptor": "\nComments: Accepted at ACL 2021\n",
    "authors": [
      "Haoyang Wen",
      "Anthony Ferritto",
      "Heng Ji",
      "Radu Florian",
      "Avirup Sil"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03229"
  },
  {
    "id": "arXiv:2105.03482",
    "title": "Measuring and Increasing Context Usage in Context-Aware Machine  Translation",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Patrick Fernandes",
      "Kayo Yin",
      "Graham Neubig",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03482"
  },
  {
    "id": "arXiv:2105.03654",
    "title": "Improving Named Entity Recognition by External Context Retrieving and  Cooperative Learning",
    "abstract": "Comments: Accepted to ACL 2021, 12 pages",
    "descriptor": "\nComments: Accepted to ACL 2021, 12 pages\n",
    "authors": [
      "Xinyu Wang",
      "Yong Jiang",
      "Nguyen Bach",
      "Tao Wang",
      "Zhongqiang Huang",
      "Fei Huang",
      "Kewei Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03654"
  },
  {
    "id": "arXiv:2105.04165",
    "title": "Inter-GPS: Interpretable Geometry Problem Solving with Formal Language  and Symbolic Reasoning",
    "abstract": "Comments: Accepted to ACL 2021, 13 pages, 6 figures",
    "descriptor": "\nComments: Accepted to ACL 2021, 13 pages, 6 figures\n",
    "authors": [
      "Pan Lu",
      "Ran Gong",
      "Shibiao Jiang",
      "Liang Qiu",
      "Siyuan Huang",
      "Xiaodan Liang",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.04165"
  },
  {
    "id": "arXiv:2105.06041",
    "title": "HyKnow: End-to-End Task-Oriented Dialog Modeling with Hybrid Knowledge  Management",
    "abstract": "Comments: Findings of ACL-IJCNLP 2021, long paper",
    "descriptor": "\nComments: Findings of ACL-IJCNLP 2021, long paper\n",
    "authors": [
      "Silin Gao",
      "Ryuichi Takanobu",
      "Wei Peng",
      "Qun Liu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.06041"
  },
  {
    "id": "arXiv:2105.06451",
    "title": "Outage Common Randomness Capacity Characterization of Multiple-Antenna  Slow Fading Channels",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2102.01197",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.01197\n",
    "authors": [
      "Rami Ezzine",
      "Moritz Wiese",
      "Christian Deppe",
      "Holger Boche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.06451"
  },
  {
    "id": "arXiv:2105.07246",
    "title": "An End-to-End Framework for Molecular Conformation Generation via  Bilevel Programming",
    "abstract": "Comments: Accepted by ICML 2021",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Minkai Xu",
      "Wujie Wang",
      "Shitong Luo",
      "Chence Shi",
      "Yoshua Bengio",
      "Rafael Gomez-Bombarelli",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2105.07246"
  },
  {
    "id": "arXiv:2105.07464",
    "title": "Few-NERD: A Few-Shot Named Entity Recognition Dataset",
    "abstract": "Comments: Accepted by ACL-IJCNLP 2021 (long paper)",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021 (long paper)\n",
    "authors": [
      "Ning Ding",
      "Guangwei Xu",
      "Yulin Chen",
      "Xiaobin Wang",
      "Xu Han",
      "Pengjun Xie",
      "Hai-Tao Zheng",
      "Zhiyuan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.07464"
  },
  {
    "id": "arXiv:2105.07889",
    "title": "Simultaneous Meta-Learning with Diverse Task Spaces",
    "abstract": "Comments: Submitted to CIKM 2021. The original title and abstract has been changed due to the double-blind policy",
    "descriptor": "\nComments: Submitted to CIKM 2021. The original title and abstract has been changed due to the double-blind policy\n",
    "authors": [
      "Jiayi Chen",
      "Aidong Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.07889"
  },
  {
    "id": "arXiv:2105.08050",
    "title": "Pay Attention to MLPs",
    "abstract": "Pay Attention to MLPs",
    "descriptor": "",
    "authors": [
      "Hanxiao Liu",
      "Zihang Dai",
      "David R. So",
      "Quoc V. Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.08050"
  },
  {
    "id": "arXiv:2105.08304",
    "title": "Parametrization invariant interpretation of priors and posteriors",
    "abstract": "Parametrization invariant interpretation of priors and posteriors",
    "descriptor": "",
    "authors": [
      "Jesus Cerquides"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.08304"
  },
  {
    "id": "arXiv:2105.08339",
    "title": "DRIVE: One-bit Distributed Mean Estimation",
    "abstract": "DRIVE: One-bit Distributed Mean Estimation",
    "descriptor": "",
    "authors": [
      "Shay Vargaftik",
      "Ran Ben Basat",
      "Amit Portnoy",
      "Gal Mendelson",
      "Yaniv Ben-Itzhak",
      "Michael Mitzenmacher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.08339"
  },
  {
    "id": "arXiv:2105.08765",
    "title": "Moving Mesh with Streamline Upwind Petrov-Galerkin (MM-SUPG) Method for  Convection-Diffusion Problems",
    "abstract": "Comments: There are 17 pages, 12 figures, and 3 tables. Added additional references and fixed typos",
    "descriptor": "\nComments: There are 17 pages, 12 figures, and 3 tables. Added additional references and fixed typos\n",
    "authors": [
      "Xianping Li",
      "Matthew McCoy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.08765"
  },
  {
    "id": "arXiv:2105.09511",
    "title": "Medical Image Segmentation Using Squeeze-and-Expansion Transformers",
    "abstract": "Comments: Camera ready for IJCAI'2021",
    "descriptor": "\nComments: Camera ready for IJCAI'2021\n",
    "authors": [
      "Shaohua Li",
      "Xiuchao Sui",
      "Xiangde Luo",
      "Xinxing Xu",
      "Yong Liu",
      "Rick Goh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.09511"
  },
  {
    "id": "arXiv:2105.10005",
    "title": "Robust Unsupervised Multi-Object Tracking in Noisy Environments",
    "abstract": "Comments: Accepted to IEEE ICIP 2021",
    "descriptor": "\nComments: Accepted to IEEE ICIP 2021\n",
    "authors": [
      "C.-H. Huck Yang",
      "Mohit Chhabra",
      "Y.-C. Liu",
      "Quan Kong",
      "Tomoaki Yoshinaga",
      "Tomokazu Murakami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.10005"
  },
  {
    "id": "arXiv:2105.10591",
    "title": "Detecting Treatment Effect Modifiers in Social Networks",
    "abstract": "Detecting Treatment Effect Modifiers in Social Networks",
    "descriptor": "",
    "authors": [
      "Amir Gilad",
      "Harsh Parikh",
      "Sudeepa Roy",
      "Babak Salimi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.10591"
  },
  {
    "id": "arXiv:2105.10606",
    "title": "CEREC: A Corpus for Entity Resolution in Email Conversations",
    "abstract": "CEREC: A Corpus for Entity Resolution in Email Conversations",
    "descriptor": "",
    "authors": [
      "Parag Pravin Dakle",
      "Dan I. Moldovan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.10606"
  },
  {
    "id": "arXiv:2105.10755",
    "title": "SDN assisted UAV communication systems : Efficient Deployment Strategies",
    "abstract": "Comments: 7 pages, 17 figures",
    "descriptor": "\nComments: 7 pages, 17 figures\n",
    "authors": [
      "Sai Teja Suggala",
      "Siddhartha Pothukuchi",
      "Naimat Ali Khan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.10755"
  },
  {
    "id": "arXiv:2105.10783",
    "title": "3DARVisualizer: Debugging 3D Models using Augmented Reality",
    "abstract": "Comments: Presented virtually as a Demo at the FabLearn Flagship conference, NYC 2020",
    "descriptor": "\nComments: Presented virtually as a Demo at the FabLearn Flagship conference, NYC 2020\n",
    "authors": [
      "Srinjita Bhaduri",
      "Peter Gyory",
      "Tamara Sumner"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.10783"
  },
  {
    "id": "arXiv:2105.10968",
    "title": "HOME: Heatmap Output for future Motion Estimation",
    "abstract": "HOME: Heatmap Output for future Motion Estimation",
    "descriptor": "",
    "authors": [
      "Thomas Gilles",
      "Stefano Sabatini",
      "Dzmitry Tsishkou",
      "Bogdan Stanciulescu",
      "Fabien Moutarde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.10968"
  },
  {
    "id": "arXiv:2105.11160",
    "title": "Out-of-Distribution Detection in Dermatology using Input Perturbation  and Subset Scanning",
    "abstract": "Comments: Under review for 6th Outlier Detection & Description Workshop",
    "descriptor": "\nComments: Under review for 6th Outlier Detection & Description Workshop\n",
    "authors": [
      "Hannah Kim",
      "Girmaw Abebe Tadesse",
      "Celia Cintas",
      "Skyler Speakman",
      "Kush Varshney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11160"
  },
  {
    "id": "arXiv:2105.11269",
    "title": "Neural Machine Translation with Monolingual Translation Memory",
    "abstract": "Comments: ACL2021",
    "descriptor": "\nComments: ACL2021\n",
    "authors": [
      "Deng Cai",
      "Yan Wang",
      "Huayang Li",
      "Wai Lam",
      "Lemao Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.11269"
  },
  {
    "id": "arXiv:2105.11992",
    "title": "An Optimal Monotone Contention Resolution Scheme for Uniform and  Partition Matroids",
    "abstract": "An Optimal Monotone Contention Resolution Scheme for Uniform and  Partition Matroids",
    "descriptor": "",
    "authors": [
      "Danish Kashaev",
      "Richard Santiago"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.11992"
  },
  {
    "id": "arXiv:2105.12152",
    "title": "Density estimation on low-dimensional manifolds: an inflation-deflation  approach",
    "abstract": "Density estimation on low-dimensional manifolds: an inflation-deflation  approach",
    "descriptor": "",
    "authors": [
      "Christian Horvat",
      "Jean-Pascal Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.12152"
  },
  {
    "id": "arXiv:2105.12964",
    "title": "Feature Reuse and Fusion for Real-time Semantic segmentation",
    "abstract": "Feature Reuse and Fusion for Real-time Semantic segmentation",
    "descriptor": "",
    "authors": [
      "Tan Sixiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.12964"
  },
  {
    "id": "arXiv:2105.13011",
    "title": "Neural Network Training Using $\\ell_1$-Regularization and Bi-fidelity  Data",
    "abstract": "Comments: 28 pages, 14 figures",
    "descriptor": "\nComments: 28 pages, 14 figures\n",
    "authors": [
      "Subhayan De",
      "Alireza Doostan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13011"
  },
  {
    "id": "arXiv:2105.13014",
    "title": "A projection method for Navier-Stokes equations with a boundary  condition including the total pressure",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Kazunori Matsui"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.13014"
  },
  {
    "id": "arXiv:2105.13150",
    "title": "When Liebig's Barrel Meets Facial Landmark Detection: A Practical Model",
    "abstract": "Comments: Fix minor errors",
    "descriptor": "\nComments: Fix minor errors\n",
    "authors": [
      "Haibo Jin",
      "Jinpeng Li",
      "Shengcai Liao",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13150"
  },
  {
    "id": "arXiv:2105.13184",
    "title": "Modelling of coupled surface and subsurface water flows",
    "abstract": "Comments: CSCE 2021 Annual Conference",
    "descriptor": "\nComments: CSCE 2021 Annual Conference\n",
    "authors": [
      "Hasan Karjoun",
      "Abdelaziz Beljadid"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13184"
  },
  {
    "id": "arXiv:2105.13471",
    "title": "Inspecting the concept knowledge graph encoded by modern language models",
    "abstract": "Inspecting the concept knowledge graph encoded by modern language models",
    "descriptor": "",
    "authors": [
      "Carlos Aspillaga",
      "Marcelo Mendoza",
      "Alvaro Soto"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13471"
  },
  {
    "id": "arXiv:2105.13608",
    "title": "Not Far Away, Not So Close: Sample Efficient Nearest Neighbour Data  Augmentation via MiniMax",
    "abstract": "Comments: Findings of ACL 2021",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Ehsan Kamalloo",
      "Mehdi Rezagholizadeh",
      "Peyman Passban",
      "Ali Ghodsi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13608"
  },
  {
    "id": "arXiv:2105.13719",
    "title": "On the condition number of the shifted real Ginibre ensemble",
    "abstract": "Comments: 10 pages, 3 figures. Updated references",
    "descriptor": "\nComments: 10 pages, 3 figures. Updated references\n",
    "authors": [
      "Giorgio Cipolloni",
      "L\u00e1szl\u00f3 Erd\u0151s",
      "Dominik Schr\u00f6der"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.13719"
  },
  {
    "id": "arXiv:2105.14158",
    "title": "Unsupervised Action Segmentation with Self-supervised Feature Learning  and Co-occurrence Parsing",
    "abstract": "Unsupervised Action Segmentation with Self-supervised Feature Learning  and Co-occurrence Parsing",
    "descriptor": "",
    "authors": [
      "Zhe Wang",
      "Hao Chen",
      "Xinyu Li",
      "Chunhui Liu",
      "Yuanjun Xiong",
      "Joseph Tighe",
      "Charless Fowlkes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14158"
  },
  {
    "id": "arXiv:2105.14231",
    "title": "Development, Implementation, and Experimental Outdoor Evaluation of  Quadcopter Controllers for Computationally Limited Embedded Systems",
    "abstract": "Development, Implementation, and Experimental Outdoor Evaluation of  Quadcopter Controllers for Computationally Limited Embedded Systems",
    "descriptor": "",
    "authors": [
      "Juan Paredes",
      "Prashin Sharma",
      "Brian Ha",
      "Manuel Lanchares",
      "Ella Atkins",
      "Peter Gaskell",
      "Ilya Kolmanovsky"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14231"
  },
  {
    "id": "arXiv:2105.14422",
    "title": "Periodic-GP: Learning Periodic World with Gaussian Process Bandits",
    "abstract": "Periodic-GP: Learning Periodic World with Gaussian Process Bandits",
    "descriptor": "",
    "authors": [
      "Hengrui Cai",
      "Zhihao Cen",
      "Ling Leng",
      "Rui Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.14422"
  },
  {
    "id": "arXiv:2105.14540",
    "title": "Attention Based Semantic Segmentation on UAV Dataset for Natural  Disaster Damage Assessment",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2009.01193",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2009.01193\n",
    "authors": [
      "Tashnim Chowdhury",
      "Maryam Rahnemoonfar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14540"
  },
  {
    "id": "arXiv:2105.15071",
    "title": "Adapting High-resource NMT Models to Translate Low-resource Related  Languages without Parallel Data",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Wei-Jen Ko",
      "Ahmed El-Kishky",
      "Adithya Renduchintala",
      "Vishrav Chaudhary",
      "Naman Goyal",
      "Francisco Guzm\u00e1n",
      "Pascale Fung",
      "Philipp Koehn",
      "Mona Diab"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15071"
  },
  {
    "id": "arXiv:2105.15131",
    "title": "Towards a trustful digital world: exploring self-sovereign identity  ecosystems",
    "abstract": "Comments: This is a preprint (the authors' version) of an article accepted for publication in Twenty-fifth Pacific Asia Conference on Information Systems, Dubai, UAE, 2021 (PACIS 2021) conference",
    "descriptor": "\nComments: This is a preprint (the authors' version) of an article accepted for publication in Twenty-fifth Pacific Asia Conference on Information Systems, Dubai, UAE, 2021 (PACIS 2021) conference\n",
    "authors": [
      "Gabriella Laatikainen",
      "Taija Kolehmainen",
      "Mengcheng Li",
      "Markus Hautala",
      "Antti Kettunen",
      "Pekka Abrahamsson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15131"
  },
  {
    "id": "arXiv:2105.15196",
    "title": "A novel second-order nonstandard finite difference method for solving  one-dimensional autonomous dynamical systems",
    "abstract": "Comments: 20 pages, 2 figure",
    "descriptor": "\nComments: 20 pages, 2 figure\n",
    "authors": [
      "Manh Tuan Hoang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.15196"
  },
  {
    "id": "arXiv:2106.00026",
    "title": "Machine-Learning Non-Conservative Dynamics for New-Physics Detection",
    "abstract": "Comments: 17 pages, 7 figs, 2 tables; typo correction",
    "descriptor": "\nComments: 17 pages, 7 figs, 2 tables; typo correction\n",
    "authors": [
      "Ziming Liu",
      "Bohan Wang",
      "Qi Meng",
      "Wei Chen",
      "Max Tegmark",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00026"
  },
  {
    "id": "arXiv:2106.00085",
    "title": "Language Model Evaluation Beyond Perplexity",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Clara Meister",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00085"
  },
  {
    "id": "arXiv:2106.00120",
    "title": "Probabilistic Deep Learning with Probabilistic Neural Networks and Deep  Probabilistic Models",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1811.06622",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1811.06622\n",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00120"
  },
  {
    "id": "arXiv:2106.00162",
    "title": "HERALD: An Annotation Efficient Method to Detect User Disengagement in  Social Conversations",
    "abstract": "Comments: ACL 2021. Code & data available at this https URL",
    "descriptor": "\nComments: ACL 2021. Code & data available at this https URL\n",
    "authors": [
      "Weixin Liang",
      "Kai-Hui Liang",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00162"
  },
  {
    "id": "arXiv:2106.00196",
    "title": "All-Hex Meshing Strategies For Densely Packed Spheres",
    "abstract": "Comments: 13 pages, 10 figures",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Yu-Hsiang Lan",
      "Paul Fischer",
      "Elia Merzari",
      "Misun Min"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.00196"
  },
  {
    "id": "arXiv:2106.00243",
    "title": "Comprehensive Energy Footprint Benchmarking of Strong Parallel  Electrified Powertrain",
    "abstract": "Comments: Updated title, fixed typos",
    "descriptor": "\nComments: Updated title, fixed typos\n",
    "authors": [
      "Aashrith Vishwanath",
      "Hamza Anwar",
      "Apurva Chunodkar",
      "Qadeer Ahmed"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00243"
  },
  {
    "id": "arXiv:2106.00352",
    "title": "Replicating and Extending \"Because Their Treebanks Leak\": Graph  Isomorphism, Covariants, and Parser Performance",
    "abstract": "Comments: To appear in the Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics",
    "descriptor": "\nComments: To appear in the Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics\n",
    "authors": [
      "Mark Anderson",
      "Anders S\u00f8gaard",
      "Carlos G\u00f3mez Rodr\u00edguez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00352"
  },
  {
    "id": "arXiv:2106.00517",
    "title": "Cooperative Multi-Agent Transfer Learning with Level-Adaptive Credit  Assignment",
    "abstract": "Comments: 12 pages, 9 figures",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Tianze Zhou",
      "Fubiao Zhang",
      "Kun Shao",
      "Kai Li",
      "Wenhan Huang",
      "Jun Luo",
      "Weixun Wang",
      "Yaodong Yang",
      "Hangyu Mao",
      "Bin Wang",
      "Dong Li",
      "Wulong Liu",
      "Jianye Hao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00517"
  },
  {
    "id": "arXiv:2106.00545",
    "title": "Counterfactual Invariance to Spurious Correlations: Why and How to Pass  Stress Tests",
    "abstract": "Counterfactual Invariance to Spurious Correlations: Why and How to Pass  Stress Tests",
    "descriptor": "",
    "authors": [
      "Victor Veitch",
      "Alexander D'Amour",
      "Steve Yadlowsky",
      "Jacob Eisenstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00545"
  }
]
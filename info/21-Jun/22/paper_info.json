[
  {
    "id": "arXiv:2106.10275",
    "title": "A Systematic Review of Computational Thinking in Early Ages",
    "abstract": "Nowadays, technology has become dominant in the daily lives of most people\naround the world. From children to older people, technology is present, helping\nin the most diverse daily tasks and allowing accessibility. However, many times\nthese people are just end-users, without any incentive to the development of\ncomputational thinking (CT). With advances in technologies, the abstraction of\ncoding, programming languages, and the hardware resources involved will become\na reality. However, while we have not progressed to this stage, it is necessary\nto encourage the development of CT teaching from an early age. This work will\npresent state of the art concerning teaching initiatives and tools on\nprogramming (e.g., ScratchJr), robotics (e.g., KIBO), and other playful tools\n(e.g., Happy Maps) for the development of CT in the early ages, specifically\nfilling the gap of CT at the kindergarten level. This survey presents a\nsystematic review of the literature, emphasizing computational and robotic\ntools used in preschool classes to develop the CT. The systematic review\nevaluated more than 60 papers from 2010 to December 2020, electing 31 papers\nand adding three papers from the qualitative stage. The paper's amount was\nclassified in taxonomy to show CT's principal tools and initiates applied to\nchildren early. To conclude this survey, an extensive discussion about the\nterms and authors related to this research area is present.",
    "descriptor": "\nComments: a systematic review submitted to Elsevier\n",
    "authors": [
      "Edelberto Franco Silva",
      "Bruno Jos\u00e9 Dembogurski",
      "Gustavo Silva Semaan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.10275"
  },
  {
    "id": "arXiv:2106.10281",
    "title": "Say Their Names: Resurgence in the collective attention toward Black  victims of fatal police violence following the death of George Floyd",
    "abstract": "The murder of George Floyd by police in May 2020 sparked international\nprotests and renewed attention in the Black Lives Matter movement. Here, we\ncharacterize ways in which the online activity following George Floyd's death\nwas unparalleled in its volume and intensity, including setting records for\nactivity on Twitter, prompting the saddest day in the platform's history, and\ncausing George Floyd's name to appear among the ten most frequently used\nphrases in a day, where he is the only individual to have ever received that\nlevel of attention who was not known to the public earlier that same week.\nFurther, we find this attention extended beyond George Floyd and that more\nBlack victims of fatal police violence received attention following his death\nthan during other past moments in Black Lives Matter's history. We place that\nattention within the context of prior online racial justice activism by showing\nhow the names of Black victims of police violence have been lifted and\nmemorialized over the last 12 years on Twitter. Our results suggest that the\n2020 wave of attention to the Black Lives Matter movement centered past\ninstances of police violence in an unprecedented way, demonstrating the impact\nof the movement's rhetorical strategy to \"say their names.\"",
    "descriptor": "",
    "authors": [
      "Henry H. Wu",
      "Ryan J. Gallagher",
      "Thayer Alshaabi",
      "Jane L. Adams",
      "Joshua R. Minot",
      "Michael V. Arnold",
      "Brooke Foucault Welles",
      "Randall Harp",
      "Peter Sheridan Dodds",
      "Christopher M. Danforth"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10281"
  },
  {
    "id": "arXiv:2106.10302",
    "title": "Dependency Structure Misspecification in Multi-Source Weak Supervision  Models",
    "abstract": "Data programming (DP) has proven to be an attractive alternative to costly\nhand-labeling of data.\nIn DP, users encode domain knowledge into \\emph{labeling functions} (LF),\nheuristics that label a subset of the data noisily and may have complex\ndependencies. A label model is then fit to the LFs to produce an estimate of\nthe unknown class label.\nThe effects of label model misspecification on test set performance of a\ndownstream classifier are understudied. This presents a serious awareness gap\nto practitioners, in particular since the dependency structure among LFs is\nfrequently ignored in field applications of DP.\nWe analyse modeling errors due to structure over-specification.\nWe derive novel theoretical bounds on the modeling error and empirically show\nthat this error can be substantial, even when modeling a seemingly sensible\nstructure.",
    "descriptor": "\nComments: Oral presentation at the Workshop on Weakly Supervised Learning at ICLR 2021\n",
    "authors": [
      "Salva R\u00fchling Cachay",
      "Benedikt Boecking",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10302"
  },
  {
    "id": "arXiv:2106.10305",
    "title": "Multi-Task Learning for User Engagement and Adoption in Live Video  Streaming Events",
    "abstract": "Nowadays, live video streaming events have become a mainstay in viewer's\ncommunication in large international enterprises. Provided that viewers are\ndistributed worldwide, the main challenge resides on how to schedule the\noptimal event's time so as to improve both the viewer's engagement and\nadoption. In this paper we present a multi-task deep reinforcement learning\nmodel to select the time of a live video streaming event, aiming to optimize\nthe viewer's engagement and adoption at the same time. We consider the\nengagement and adoption of the viewers as independent tasks and formulate a\nunified loss function to learn a common policy. In addition, we account for the\nfact that each task might have different contribution to the training strategy\nof the agent. Therefore, to determine the contribution of each task to the\nagent's training, we design a Transformer's architecture for the state-action\ntransitions of each task. We evaluate our proposed model on four real-world\ndatasets, generated by the live video streaming events of four large\nenterprises spanning from January 2019 until March 2021. Our experiments\ndemonstrate the effectiveness of the proposed model when compared with several\nstate-of-the-art strategies. For reproduction purposes, our evaluation datasets\nand implementation are publicly available at\nhttps://github.com/stefanosantaris/merlin.",
    "descriptor": "",
    "authors": [
      "Stefanos Antaris",
      "Dimitrios Rafailidis",
      "Romina Arriaza"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10305"
  },
  {
    "id": "arXiv:2106.10307",
    "title": "Deep Learning for Intelligent Wireless MAC: Exploiting Real Data Sampled  on 2.4GHz Frequency Band",
    "abstract": "The existing medium access control (MAC) protocol of Wi-Fi networks (i.e.,\nCSMA/CA) suffers from poor performance in large networks due to its\nincapability of handling transmission collisions. This drawback dramatically\nreduces the spectrum efficiency of Wi-Fi networks. To cope with this issue, we\ninvestigate a deep-learning (DL) based intelligent wireless MAC protocol,\nreferred to as DL-MAC, to improve the spectrum efficiency of Wi-Fi networks.\nThe goal of DL-MAC is to enable not only intelligent channel access, but also\nintelligent rate adaption to increase the throughput. Notably, our DL-MAC\nprotocol is designed for the 2.4GHz frequency band and exploits the real\nwireless data sampled from actual environments that consist of many working\ndevices. We design a deep neural network (DNN) that is trained using the\nsampled real data after data processing and exploit the trained DNN to\nimplement our DL-MAC. The experimental results demonstrate that the DL-MAC\nprotocol can achieve high throughput than CSMA/CA channel access and\ntraditional rate adaptions.",
    "descriptor": "",
    "authors": [
      "Jiantao Xin",
      "Wensen Xu",
      "Yucheng Cai",
      "Taotao Wang",
      "Shengli Zhang",
      "Peng Liu",
      "Ziyang Guo",
      "Jiajun Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.10307"
  },
  {
    "id": "arXiv:2106.10309",
    "title": "Towards Single Stage Weakly Supervised Semantic Segmentation",
    "abstract": "The costly process of obtaining semantic segmentation labels has driven\nresearch towards weakly supervised semantic segmentation (WSSS) methods, using\nonly image-level, point, or box labels. The lack of dense scene representation\nrequires methods to increase complexity to obtain additional semantic\ninformation about the scene, often done through multiple stages of training and\nrefinement. Current state-of-the-art (SOTA) models leverage image-level labels\nto produce class activation maps (CAMs) which go through multiple stages of\nrefinement before they are thresholded to make pseudo-masks for supervision.\nThe multi-stage approach is computationally expensive, and dependency on\nimage-level labels for CAMs generation lacks generalizability to more complex\nscenes. In contrary, our method offers a single-stage approach generalizable to\narbitrary dataset, that is trainable from scratch, without any dependency on\npre-trained backbones, classification, or separate refinement tasks. We utilize\npoint annotations to generate reliable, on-the-fly pseudo-masks through refined\nand filtered features. While our method requires point annotations that are\nonly slightly more expensive than image-level annotations, we are to\ndemonstrate SOTA performance on benchmark datasets (PascalVOC 2012), as well as\nsignificantly outperform other SOTA WSSS methods on recent real-world datasets\n(CRAID, CityPersons, IAD).",
    "descriptor": "",
    "authors": [
      "Peri Akiva",
      "Kristin Dana"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10309"
  },
  {
    "id": "arXiv:2106.10310",
    "title": "Verifying Safe Transitions between Dynamic Motion Primitives on Legged  Robots",
    "abstract": "Functional autonomous systems often realize complex tasks by utilizing state\nmachines comprised of discrete primitive behaviors and transitions between\nthese behaviors. This architecture has been widely studied in the context of\nquasi-static and dynamics-independent systems. However, applications of this\nconcept to dynamical systems are relatively sparse, despite extensive research\non individual dynamic primitive behaviors, which we refer to as \"motion\nprimitives.\" This paper formalizes a process to determine dynamic-state aware\nconditions for transitions between motion primitives in the context of safety.\nThe result is framed as a \"motion primitive graph\" that can be traversed by\nstandard graph search and planning algorithms to realize functional autonomy.\nTo demonstrate this framework, dynamic motion primitives -- including standing\nup, walking, and jumping -- and the transitions between these behaviors are\nexperimentally realized on a quadrupedal robot.",
    "descriptor": "",
    "authors": [
      "Wyatt Ubellacker",
      "Noel Csomay-Shanklin",
      "Tamas G. Molnar",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10310"
  },
  {
    "id": "arXiv:2106.10311",
    "title": "Universal Rate-Distortion-Perception Representations for Lossy  Compression",
    "abstract": "In the context of lossy compression, Blau & Michaeli (2019) adopt a\nmathematical notion of perceptual quality and define the information\nrate-distortion-perception function, generalizing the classical rate-distortion\ntradeoff. We consider the notion of universal representations in which one may\nfix an encoder and vary the decoder to achieve any point within a collection of\ndistortion and perception constraints. We prove that the corresponding\ninformation-theoretic universal rate-distortion-perception function is\noperationally achievable in an approximate sense. Under MSE distortion, we show\nthat the entire distortion-perception tradeoff of a Gaussian source can be\nachieved by a single encoder of the same rate asymptotically. We then\ncharacterize the achievable distortion-perception region for a fixed\nrepresentation in the case of arbitrary distributions, identify conditions\nunder which the aforementioned results continue to hold approximately, and\nstudy the case when the rate is not fixed in advance. This motivates the study\nof practical constructions that are approximately universal across the RDP\ntradeoff, thereby alleviating the need to design a new encoder for each\nobjective. We provide experimental results on MNIST and SVHN suggesting that on\nimage compression tasks, the operational tradeoffs achieved by machine learning\nmodels with a fixed encoder suffer only a small penalty when compared to their\nvariable encoder counterparts.",
    "descriptor": "",
    "authors": [
      "George Zhang",
      "Jingjing Qian",
      "Jun Chen",
      "Ashish Khisti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10311"
  },
  {
    "id": "arXiv:2106.10316",
    "title": "Proper Value Equivalence",
    "abstract": "One of the main challenges in model-based reinforcement learning (RL) is to\ndecide which aspects of the environment should be modeled. The\nvalue-equivalence (VE) principle proposes a simple answer to this question: a\nmodel should capture the aspects of the environment that are relevant for\nvalue-based planning. Technically, VE distinguishes models based on a set of\npolicies and a set of functions: a model is said to be VE to the environment if\nthe Bellman operators it induces for the policies yield the correct result when\napplied to the functions. As the number of policies and functions increase, the\nset of VE models shrinks, eventually collapsing to a single point corresponding\nto a perfect model. A fundamental question underlying the VE principle is thus\nhow to select the smallest sets of policies and functions that are sufficient\nfor planning. In this paper we take an important step towards answering this\nquestion. We start by generalizing the concept of VE to order-$k$ counterparts\ndefined with respect to $k$ applications of the Bellman operator. This leads to\na family of VE classes that increase in size as $k \\rightarrow \\infty$. In the\nlimit, all functions become value functions, and we have a special\ninstantiation of VE which we call proper VE or simply PVE. Unlike VE, the PVE\nclass may contain multiple models even in the limit when all value functions\nare used. Crucially, all these models are sufficient for planning, meaning that\nthey will yield an optimal policy despite the fact that they may ignore many\naspects of the environment. We construct a loss function for learning PVE\nmodels and argue that popular algorithms such as MuZero and Muesli can be\nunderstood as minimizing an upper bound for this loss. We leverage this\nconnection to propose a modification to MuZero and show that it can lead to\nimproved performance in practice.",
    "descriptor": "",
    "authors": [
      "Christopher Grimm",
      "Andr\u00e9 Barreto",
      "Gregory Farquhar",
      "David Silver",
      "Satinder Singh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10316"
  },
  {
    "id": "arXiv:2106.10318",
    "title": "Sample Efficient Social Navigation Using Inverse Reinforcement Learning",
    "abstract": "In this paper, we present an algorithm to efficiently learn\nsocially-compliant navigation policies from observations of human trajectories.\nAs mobile robots come to inhabit and traffic social spaces, they must account\nfor social cues and behave in a socially compliant manner. We focus on learning\nsuch cues from examples. We describe an inverse reinforcement learning based\nalgorithm which learns from human trajectory observations without knowing their\nspecific actions. We increase the sample-efficiency of our approach over\nalternative methods by leveraging the notion of a replay buffer (found in many\noff-policy reinforcement learning methods) to eliminate the additional sample\ncomplexity associated with inverse reinforcement learning. We evaluate our\nmethod by training agents using publicly available pedestrian motion data sets\nand compare it to related methods. We show that our approach yields better\nperformance while also decreasing training time and sample complexity.",
    "descriptor": "",
    "authors": [
      "Bobak H. Baghi",
      "Gregory Dudek"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10318"
  },
  {
    "id": "arXiv:2106.10319",
    "title": "A system of vision sensor based deep neural networks for complex driving  scene analysis in support of crash risk assessment and prevention",
    "abstract": "To assist human drivers and autonomous vehicles in assessing crash risks,\ndriving scene analysis using dash cameras on vehicles and deep learning\nalgorithms is of paramount importance. Although these technologies are\nincreasingly available, driving scene analysis for this purpose still remains a\nchallenge. This is mainly due to the lack of annotated large image datasets for\nanalyzing crash risk indicators and crash likelihood, and the lack of an\neffective method to extract lots of required information from complex driving\nscenes. To fill the gap, this paper develops a scene analysis system. The\nMulti-Net of the system includes two multi-task neural networks that perform\nscene classification to provide four labels for each scene. The DeepLab v3 and\nYOLO v3 are combined by the system to detect and locate risky pedestrians and\nthe nearest vehicles. All identified information can provide the situational\nawareness to autonomous vehicles or human drivers for identifying crash risks\nfrom the surrounding traffic. To address the scarcity of annotated image\ndatasets for studying traffic crashes, two completely new datasets have been\ndeveloped by this paper and made available to the public, which were proved to\nbe effective in training the proposed deep neural networks. The paper further\nevaluates the performance of the Multi-Net and the efficiency of the developed\nsystem. Comprehensive scene analysis is further illustrated with representative\nexamples. Results demonstrate the effectiveness of the developed system and\ndatasets for driving scene analysis, and their supportiveness for crash risk\nassessment and crash prevention.",
    "descriptor": "\nComments: 11 Pages, 8 Figures, Presented in TRB conference\n",
    "authors": [
      "Muhammad Monjurul Karim",
      "Yu Li",
      "Ruwen Qin",
      "Zhaozheng Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10319"
  },
  {
    "id": "arXiv:2106.10321",
    "title": "Beating the Folklore Algorithm for Dynamic Matching",
    "abstract": "The maximum matching problem in dynamic graphs subject to edge updates\n(insertions and deletions) has received much attention over the last few years;\na multitude of approximation/time tradeoffs were obtained, improving upon the\nfolklore algorithm, which maintains a maximal (and hence $2$-approximate)\nmatching in $O(n)$ worst-case update time in $n$-node graphs.\nWe present the first deterministic algorithm which outperforms the folklore\nalgorithm in terms of {\\em both} approximation ratio and worst-case update\ntime. Specifically, we give a $(2-\\Omega(1))$-approximate algorithm with\n$O(\\sqrt{n}\\sqrt[8]{m})=O(n^{3/4})$ worst-case update time in $n$-node,\n$m$-edge graphs. For sufficiently small constant $\\epsilon>0$, no deterministic\n$(2+\\epsilon)$-approximate algorithm with worst-case update time $O(n^{0.99})$\nwas known. Our second result is the first deterministic\n$(2+\\epsilon)$-approximate (weighted) matching algorithm with\n$O_\\epsilon(1)\\cdot O(\\sqrt[4]{m}) = O_\\epsilon(1)\\cdot O(\\sqrt{n})$ worst-case\nupdate time.",
    "descriptor": "",
    "authors": [
      "Mohammad Roghani",
      "Amin Saberi",
      "David Wajc"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.10321"
  },
  {
    "id": "arXiv:2106.10324",
    "title": "Group-Structured Adversarial Training",
    "abstract": "Robust training methods against perturbations to the input data have received\ngreat attention in the machine learning literature. A standard approach in this\ndirection is adversarial training which learns a model using\nadversarially-perturbed training samples. However, adversarial training\nperforms suboptimally against perturbations structured across samples such as\nuniversal and group-sparse shifts that are commonly present in biological data\nsuch as gene expression levels of different tissues. In this work, we seek to\nclose this optimality gap and introduce Group-Structured Adversarial Training\n(GSAT) which learns a model robust to perturbations structured across samples.\nWe formulate GSAT as a non-convex concave minimax optimization problem which\nminimizes a group-structured optimal transport cost. Specifically, we focus on\nthe applications of GSAT for group-sparse and rank-constrained perturbations\nmodeled using group and nuclear norm penalties. In order to solve GSAT's\nnon-smooth optimization problem in those cases, we propose a new minimax\noptimization algorithm called GDADMM by combining Gradient Descent Ascent (GDA)\nand Alternating Direction Method of Multipliers (ADMM). We present several\napplications of the GSAT framework to gain robustness against structured\nperturbations for image recognition and computational biology datasets.",
    "descriptor": "",
    "authors": [
      "Farzan Farnia",
      "Amirali Aghazadeh",
      "James Zou",
      "David Tse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10324"
  },
  {
    "id": "arXiv:2106.10328",
    "title": "Process for Adapting Language Models to Society (PALMS) with  Values-Targeted Datasets",
    "abstract": "Language models can generate harmful and biased outputs and exhibit\nundesirable behavior. We propose a Process for Adapting Language Models to\nSociety (PALMS) with Values-Targeted Datasets, an iterative process to\nsignificantly change model behavior by crafting and fine-tuning on a dataset\nthat reflects a predetermined set of target values. We evaluate our process\nusing three metrics: quantitative metrics with human evaluations that score\noutput adherence to a target value, and toxicity scoring on outputs; and\nqualitative metrics analyzing the most common word associated with a given\nsocial category. Through each iteration, we add additional training dataset\nexamples based on observed shortcomings from evaluations. PALMS performs\nsignificantly better on all metrics compared to baseline and control models for\na broad range of GPT-3 language model sizes without compromising capability\nintegrity. We find that the effectiveness of PALMS increases with model size.\nWe show that significantly adjusting language model behavior is feasible with a\nsmall, hand-curated dataset.",
    "descriptor": "\nComments: Both authors contributed equally. Submitted to NeurIPS 2021\n",
    "authors": [
      "Irene Solaiman",
      "Christy Dennison"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.10328"
  },
  {
    "id": "arXiv:2106.10331",
    "title": "Exoskeleton-Based Multimodal Action and Movement Recognition:  Identifying and Developing the Optimal Boosted Learning Approach",
    "abstract": "This paper makes two scientific contributions to the field of\nexoskeleton-based action and movement recognition. First, it presents a novel\nmachine learning and pattern recognition-based framework that can detect a wide\nrange of actions and movements - walking, walking upstairs, walking downstairs,\nsitting, standing, lying, stand to sit, sit to stand, sit to lie, lie to sit,\nstand to lie, and lie to stand, with an overall accuracy of 82.63%. Second, it\npresents a comprehensive comparative study of different learning approaches -\nRandom Forest, Artificial Neural Network, Decision Tree, Multiway Decision\nTree, Support Vector Machine, k-NN, Gradient Boosted Trees, Decision Stump,\nAuto MLP, Linear Regression, Vector Linear Regression, Random Tree, Na\\\"ive\nBayes, Na\\\"ive Bayes (Kernel), Linear Discriminant Analysis, Quadratic\nDiscriminant Analysis, and Deep Learning applied to this framework. The\nperformance of each of these learning approaches was boosted by using the\nAdaBoost algorithm, and the Cross Validation approach was used for training and\ntesting. The results show that in boosted form, the k- NN classifier\noutperforms all the other boosted learning approaches and is, therefore, the\noptimal learning method for this purpose. The results presented and discussed\nuphold the importance of this work to contribute towards augmenting the\nabilities of exoskeleton-based assisted and independent living of the elderly\nin the future of Internet of Things-based living environments, such as Smart\nHomes. As a specific use case, we also discuss how the findings of our work are\nrelevant for augmenting the capabilities of the Hybrid Assistive Limb\nexoskeleton, a highly functional lower limb exoskeleton.",
    "descriptor": "",
    "authors": [
      "Nirmalya Thakur",
      "Chia Y. Han"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10331"
  },
  {
    "id": "arXiv:2106.10333",
    "title": "Non-parametric Differentially Private Confidence Intervals for the  Median",
    "abstract": "Differential privacy is a restriction on data processing algorithms that\nprovides strong confidentiality guarantees for individual records in the data.\nHowever, research on proper statistical inference, that is, research on\nproperly quantifying the uncertainty of the (noisy) sample estimate regarding\nthe true value in the population, is currently still limited. This paper\nproposes and evaluates several strategies to compute valid differentially\nprivate confidence intervals for the median. Instead of computing a\ndifferentially private point estimate and deriving its uncertainty, we directly\nestimate the interval bounds and discuss why this approach is superior if\nensuring privacy is important. We also illustrate that addressing both sources\nof uncertainty--the error from sampling and the error from protecting the\noutput--simultaneously should be preferred over simpler approaches that\nincorporate the uncertainty in a sequential fashion. We evaluate the\nperformance of the different algorithms under various parameter settings in\nextensive simulation studies and demonstrate how the findings could be applied\nin practical settings using data from the 1940 Decennial Census.",
    "descriptor": "\nComments: 44 pages, 15 figures\n",
    "authors": [
      "Joerg Drechsler",
      "Ira Globus-Harris",
      "Audra McMillan",
      "Jayshree Sarathy",
      "Adam Smith"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10333"
  },
  {
    "id": "arXiv:2106.10334",
    "title": "AutoTune: Improving End-to-end Performance and Resource Efficiency for  Microservice Applications",
    "abstract": "Most large web-scale applications are now built by composing collections\n(from a few up to 100s or 1000s) of microservices. Operators need to decide how\nmany resources are allocated to each microservice, and these allocations can\nhave a large impact on application performance. Manually determining\nallocations that are both cost-efficient and meet performance requirements is\nchallenging, even for experienced operators. In this paper we present AutoTune,\nan end-to-end tool that automatically minimizes resource utilization while\nmaintaining good application performance.",
    "descriptor": "",
    "authors": [
      "Michael Alan Chang",
      "Aurojit Panda",
      "Hantao Wang",
      "Yuancheng Tsai",
      "Rahul Balakrishnan",
      "Scott Shenker"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.10334"
  },
  {
    "id": "arXiv:2106.10335",
    "title": "Single View Physical Distance Estimation using Human Pose",
    "abstract": "We propose a fully automated system that simultaneously estimates the camera\nintrinsics, the ground plane, and physical distances between people from a\nsingle RGB image or video captured by a camera viewing a 3-D scene from a fixed\nvantage point. To automate camera calibration and distance estimation, we\nleverage priors about human pose and develop a novel direct formulation for\npose-based auto-calibration and distance estimation, which shows\nstate-of-the-art performance on publicly available datasets. The proposed\napproach enables existing camera systems to measure physical distances without\nneeding a dedicated calibration process or range sensors, and is applicable to\na broad range of use cases such as social distancing and workplace safety.\nFurthermore, to enable evaluation and drive research in this area, we\ncontribute to the publicly available MEVA dataset with additional distance\nannotations, resulting in MEVADA -- the first evaluation benchmark in the world\nfor the pose-based auto-calibration and distance estimation problem.",
    "descriptor": "",
    "authors": [
      "Xiaohan Fei",
      "Henry Wang",
      "Xiangyu Zeng",
      "Lin Lee Cheong",
      "Meng Wang",
      "Joseph Tighe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10335"
  },
  {
    "id": "arXiv:2106.10336",
    "title": "Risk-Oriented Design Approach For Forensic-Ready Software Systems",
    "abstract": "Digital forensic investigation is a complex and time-consuming activity in\nresponse to a cybersecurity incident or cybercrime to answer questions related\nto it. These typically are what happened, when, where, how, and who is\nresponsible. However, answering them is often very laborious and sometimes\noutright impossible due to a lack of useable data. The forensic-ready software\nsystems are designed to produce valuable on-point data for use in the\ninvestigation with potentially high evidence value. Still, the particular ways\nto develop these systems are currently not explored.\nThis paper proposes consideration of forensic readiness within security risk\nmanagement to refine specific requirements on forensic-ready software systems.\nThe idea is to re-evaluate the taken security risk decisions with the aim to\nprovide trustable data when the security measures fail. Additionally, it also\nconsiders possible disputes, which the digital evidence can solve. Our proposed\napproach, risk-oriented forensic-ready design, composes of two parts: (1)\nprocess guiding the identification of the requirements in the form of potential\nevidence sources, and (2) supporting BPMN notation capturing the potential\nevidence sources and their relationship. Together they are aimed to provide a\nhigh-level overview of the forensic-ready requirements within the system.\nFinally, the approach is demonstrated on an automated valet parking scenario,\nfollowed by a discussion regarding its impact and usefulness within the\nforensic readiness effort.",
    "descriptor": "\nComments: The 16th International Conference on Availability, Reliability and Security (ARES 2021), August 17--20, 2021, Vienna, Austria\n",
    "authors": [
      "Lukas Daubner",
      "Raimundas Matulevi\u010dius"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.10336"
  },
  {
    "id": "arXiv:2106.10339",
    "title": "Privacy-preserving Publication and Sharing of COVID-19 Pandemic Data",
    "abstract": "A huge amount of data of various types are collected during the COVID-19\npandemic, the analysis and interpretation of which has been indispensable for\ncurbing the spread of the coronavirus. As the pandemic slows down, the\ncollected data during the pandemic will continue to be rich sources for further\nstudying the pandemic and understanding its impacts on public health,\neconomics, and societies. On the other hand, na\\\"{i}ve release and sharing of\nthe information can be associated with serious privacy concerns. In this paper,\naiming at shedding light on privacy-preserving sharing of pandemic data and\nthus promoting and encouraging more data sharing for research and public use,\nwe examine three common data types -- case surveillance, patient location\nhistories and hot spot maps, and contact tracing networks -- collected during\nthe pandemic and develop and apply privacy-preserving approaches for publishing\nor sharing each data type. We illustrate the applications and examine the\nutility of released privacy-preserving data in examples and experiments at\nvarious levels of privacy guarantees.",
    "descriptor": "",
    "authors": [
      "Dong Wang",
      "Fang Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.10339"
  },
  {
    "id": "arXiv:2106.10347",
    "title": "On the Impact of the Capacity Drop Phenomenon for Freeway Traffic Flow  Control",
    "abstract": "Capacity drop is an empirically observed phenomenon in vehicular traffic flow\non freeways whereby, after a critical density is reached, a state of congestion\nsets in, but the freeway does not become decongested again until the density\ndrops well below the critical density. This introduces a hysteresis effect so\nthat it is easier to enter the congested state than to leave it. However, many\nexisting first-order models of traffic flow, particularly those used for\ncontrol design, ignore capacity drop, leading to suboptimal controllers. In\nthis paper, we consider a cell transmission model of traffic flow that\nincorporates capacity drop to study the problem of optimal freeway ramp\nmetering. We show that, if capacity drop is ignored in the control design, then\nthe resulting controller, obtained via a convex program, may be significantly\nsuboptimal. We then propose an alternative model predictive controller that\naccounts for capacity drop via a mixed integer linear program and show that,\nfor sufficiently large rollout horizon, this controller is optimal. We also\ncompare these approaches to a heuristic hand-crafted controller that is viewed\nas a modification of an integral feedback controller to account for capacity\ndrop. This heuristic controller outperforms the controller that ignores\ncapacity drop but underperforms compared to the proposed alternative model\npredictive controller. These results suggest that it is generally important to\ninclude capacity drop in the controller design process, and we demonstrate this\ninsight on several case studies.",
    "descriptor": "\nComments: Extended version of paper accepted to IEEE Conference on Control Technology and Applications (CCTA) 2021\n",
    "authors": [
      "Michael Enqi Cao",
      "Gustav Nilsson",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10347"
  },
  {
    "id": "arXiv:2106.10349",
    "title": "The Perils of Learning Before Optimizing",
    "abstract": "Formulating real-world optimization problems often begins with making\npredictions from historical data (e.g., an optimizer that aims to recommend\nfast routes relies upon travel-time predictions). Typically, learning the\nprediction model used to generate the optimization problem and solving that\nproblem are performed in two separate stages. Recent work has showed how such\nprediction models can be learned end-to-end by differentiating through the\noptimization task. Such methods often yield empirical improvements, which are\ntypically attributed to end-to-end making better error tradeoffs than the\nstandard loss function used in a two-stage solution. We refine this explanation\nand more precisely characterize when end-to-end can improve performance. When\nprediction targets are stochastic, a two-stage solution must make an a priori\nchoice about which statistics of the target distribution to model -- we\nconsider expectations over prediction targets -- while an end-to-end solution\ncan make this choice adaptively. We show that the performance gap between a\ntwo-stage and end-to-end approach is closely related to the \\emph{price of\ncorrelation} concept in stochastic optimization and show the implications of\nsome existing POC results for our predict-then-optimize problem. We then\nconsider a novel and particularly practical setting, where coefficients in the\nobjective function depend on multiple prediction targets. We give explicit\nconstructions where (1) two-stage performs unboundedly worse than end-to-end;\nand (2) two-stage is optimal. We identify a large set of real-world\napplications whose objective functions rely on multiple prediction targets but\nwhich nevertheless deploy two-stage solutions. We also use simulations to\nexperimentally quantify performance gaps.",
    "descriptor": "",
    "authors": [
      "Chris Cameron",
      "Jason Hartford",
      "Taylor Lundy",
      "Kevin Leyton-Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10349"
  },
  {
    "id": "arXiv:2106.10352",
    "title": "Semi-supervised Optimal Transport with Self-paced Ensemble for  Cross-hospital Sepsis Early Detection",
    "abstract": "The utilization of computer technology to solve problems in medical scenarios\nhas attracted considerable attention in recent years, which still has great\npotential and space for exploration. Among them, machine learning has been\nwidely used in the prediction, diagnosis and even treatment of Sepsis. However,\nstate-of-the-art methods require large amounts of labeled medical data for\nsupervised learning. In real-world applications, the lack of labeled data will\ncause enormous obstacles if one hospital wants to deploy a new Sepsis detection\nsystem. Different from the supervised learning setting, we need to use known\ninformation (e.g., from another hospital with rich labeled data) to help build\na model with acceptable performance, i.e., transfer learning. In this paper, we\npropose a semi-supervised optimal transport with self-paced ensemble framework\nfor Sepsis early detection, called SPSSOT, to transfer knowledge from the other\nthat has rich labeled data. In SPSSOT, we first extract the same clinical\nindicators from the source domain (e.g., hospital with rich labeled data) and\nthe target domain (e.g., hospital with little labeled data), then we combine\nthe semi-supervised domain adaptation based on optimal transport theory with\nself-paced under-sampling to avoid a negative transfer possibly caused by\ncovariate shift and class imbalance. On the whole, SPSSOT is an end-to-end\ntransfer learning method for Sepsis early detection which can automatically\nselect suitable samples from two domains respectively according to the number\nof iterations and align feature space of two domains. Extensive experiments on\ntwo open clinical datasets demonstrate that comparing with other methods, our\nproposed SPSSOT, can significantly improve the AUC values with only 1% labeled\ndata in the target domain in two transfer learning scenarios, MIMIC\n$rightarrow$ Challenge and Challenge $rightarrow$ MIMIC.",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Ruiqing Ding",
      "Yu Zhou",
      "Jie Xu",
      "Yan Xie",
      "Qiqiang Liang",
      "He Ren",
      "Yixuan Wang",
      "Yanlin Chen",
      "Leye Wang",
      "Man Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.10352"
  },
  {
    "id": "arXiv:2106.10354",
    "title": "High-level Features for Resource Economy and Fast Learning in Skill  Transfer",
    "abstract": "Abstraction is an important aspect of intelligence which enables agents to\nconstruct robust representations for effective decision making. In the last\ndecade, deep networks are proven to be effective due to their ability to form\nincreasingly complex abstractions. However, these abstractions are distributed\nover many neurons, making the re-use of a learned skill costly. Previous work\neither enforced formation of abstractions creating a designer bias, or used a\nlarge number of neural units without investigating how to obtain high-level\nfeatures that may more effectively capture the source task. For avoiding\ndesigner bias and unsparing resource use, we propose to exploit neural response\ndynamics to form compact representations to use in skill transfer. For this, we\nconsider two competing methods based on (1) maximum information compression\nprinciple and (2) the notion that abstract events tend to generate slowly\nchanging signals, and apply them to the neural signals generated during task\nexecution. To be concrete, in our simulation experiments, we either apply\nprincipal component analysis (PCA) or slow feature analysis (SFA) on the\nsignals collected from the last hidden layer of a deep network while it\nperforms a source task, and use these features for skill transfer in a new\ntarget task. We compare the generalization performance of these alternatives\nwith the baselines of skill transfer with full layer output and no-transfer\nsettings. Our results show that SFA units are the most successful for skill\ntransfer. SFA as well as PCA, incur less resources compared to usual skill\ntransfer, whereby many units formed show a localized response reflecting\nend-effector-obstacle-goal relations. Finally, SFA units with lowest\neigenvalues resembles symbolic representations that highly correlate with\nhigh-level features such as joint angles which might be thought of precursors\nfor fully symbolic systems.",
    "descriptor": "",
    "authors": [
      "Alper Ahmetoglu",
      "Emre Ugur",
      "Minoru Asada",
      "Erhan Oztop"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10354"
  },
  {
    "id": "arXiv:2106.10360",
    "title": "Prediction-Free, Real-Time Flexible Control of Tidal Lagoons through  Proximal Policy Optimisation: A Case Study for the Swansea Lagoon",
    "abstract": "Tidal range structures have been considered for large scale electricity\ngeneration for their potential ability to produce reasonable predictable energy\nwithout the emission of greenhouse gases. Once the main forcing components for\ndriving the tides have deterministic dynamics, the available energy in a given\ntidal power plant has been estimated, through analytical and numerical\noptimisation routines, as a mostly predictable event. This constraint imposes\nstate-of-art flexible operation methods to rely on tidal predictions\n(concurrent with measured data and up to a multiple of half-tidal cycles into\nthe future) to infer best operational strategies for tidal lagoons, with the\nadditional cost of requiring to run optimisation routines for every new tide.\nIn this paper, we propose a novel optimised operation of tidal lagoons with\nproximal policy optimisation through Unity ML-Agents. We compare this technique\nwith 6 different operation optimisation approaches (baselines) devised from the\nliterature, utilising the Swansea Bay Tidal Lagoon as a case study. We show\nthat our approach is successful in maximising energy generation through an\noptimised operational policy of turbines and sluices, yielding competitive\nresults with state-of-the-art methods of optimisation, regardless of test data\nused, requiring training once and performing real-time flexible control with\nmeasured ocean data only.",
    "descriptor": "\nComments: 33 pages, 10 figures and 11 tables\n",
    "authors": [
      "T\u00falio Marcondes Moreira",
      "Jackson Geraldo de Faria Jr",
      "Pedro O.S. Vaz de Melo",
      "Luiz Chaimowicz",
      "Gilberto Medeiros-Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10360"
  },
  {
    "id": "arXiv:2106.10362",
    "title": "Jolteon and Ditto: Network-Adaptive Efficient Consensus with  Asynchronous Fallback",
    "abstract": "Existing committee-based Byzantine state machine replication (SMR) protocols,\ntypically deployed in production blockchains, face a clear trade-off: (1) they\neither achieve linear communication cost in the happy path, but sacrifice\nliveness during periods of asynchrony, or (2) they are robust (progress with\nprobability one) but pay quadratic communication cost. We believe this\ntrade-off is unwarranted since existing linear protocols still have asymptotic\nquadratic cost in the worst case. We design Ditto, a Byzantine SMR protocol\nthat enjoys the best of both worlds: optimal communication on and off the happy\npath (linear and quadratic, respectively) and progress guarantee under\nasynchrony and DDoS attacks. We achieve this by replacing the\nview-synchronization of partially synchronous protocols with an asynchronous\nfallback mechanism at no extra asymptotic cost. Specifically, we start from\nHotStuff, a state-of-the-art linear protocol, and gradually build Ditto. As a\nseparate contribution and an intermediate step, we design a 2-chain version of\nHotStuff, Jolteon, which leverages a quadratic view-change mechanism to reduce\nthe latency of the standard 3-chain HotStuff. We implement and experimentally\nevaluate all our systems. Notably, Jolteon's commit latency outperforms\nHotStuff by 200-300ms with varying system size. Additionally, Ditto adapts to\nthe network and provides better performance than Jolteon under faulty\nconditions and better performance than VABA (a state-of-the-art asynchronous\nprotocol) under faultless conditions. This proves our case that breaking the\nrobustness-efficiency trade-off is in the realm of practicality.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.03181\n",
    "authors": [
      "Rati Gelashvili",
      "Lefteris Kokoris-Kogias",
      "Alberto Sonnino",
      "Alexander Spiegelman",
      "Zhuolun Xiang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.10362"
  },
  {
    "id": "arXiv:2106.10363",
    "title": "Construction of Planar and Symmetric Truss Structures with Interlocking  Edge Elements",
    "abstract": "In this paper, we present an algorithmic approach to design and construct\nplanar truss structures based on symmetric lattices using modular elements. The\nmethod of assembly is similar to Leonardo grids as they both rely on the\nproperty of interlocking. In theory, our modular elements can be assembled by\nthe same type of binary operations. Our modular elements embody the principle\nof geometric interlocking, a principle recently introduced in literature that\nallows for pieces of an assembly to be interlocked in a way that they can\nneither be assembled nor disassembled unless the pieces are subjected to\ndeformation or breakage. We demonstrate that breaking the pieces can indeed\nfacilitate the effective assembly of these pieces through the use of a simple\nkey-in-hole concept. As a result, these modular elements can be assembled\ntogether to form an interlocking structure, in which the locking pieces apply\nthe force necessary to hold the entire assembly together.",
    "descriptor": "",
    "authors": [
      "Anantha Natarajan",
      "Jiaqi Cui",
      "Ergun Akleman",
      "Vinayak Krishnamurthy"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.10363"
  },
  {
    "id": "arXiv:2106.10365",
    "title": "Scenic4RL: Programmatic Modeling and Generation of Reinforcement  Learning Environments",
    "abstract": "The capability of reinforcement learning (RL) agent directly depends on the\ndiversity of learning scenarios the environment generates and how closely it\ncaptures real-world situations. However, existing environments/simulators lack\nthe support to systematically model distributions over initial states and\ntransition dynamics. Furthermore, in complex domains such as soccer, the space\nof possible scenarios is infinite, which makes it impossible for one research\ngroup to provide a comprehensive set of scenarios to train, test, and benchmark\nRL algorithms. To address this issue, for the first time, we adopt an existing\nformal scenario specification language, SCENIC, to intuitively model and\ngenerate interactive scenarios. We interfaced SCENIC to Google Research Soccer\nenvironment to create a platform called SCENIC4RL. Using this platform, we\nprovide a dataset consisting of 36 scenario programs encoded in SCENIC and\ndemonstration data generated from a subset of them. We share our experimental\nresults to show the effectiveness of our dataset and the platform to train,\ntest, and benchmark RL algorithms. More importantly, we open-source our\nplatform to enable RL community to collectively contribute to constructing a\ncomprehensive set of scenarios.",
    "descriptor": "\nComments: First two authors contributed equally. Currently Under Review\n",
    "authors": [
      "Abdus Salam Azad",
      "Edward Kim",
      "Qiancheng Wu",
      "Kimin Lee",
      "Ion Stoica",
      "Pieter Abbeel",
      "Sanjit A. Seshia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10365"
  },
  {
    "id": "arXiv:2106.10374",
    "title": "Towards a Query-Optimal and Time-Efficient Algorithm for Clustering with  a Faulty Oracle",
    "abstract": "Motivated by applications in crowdsourced entity resolution in database,\nsigned edge prediction in social networks and correlation clustering, Mazumdar\nand Saha [NIPS 2017] proposed an elegant theoretical model for studying\nclustering with a faulty oracle. In this model, given a set of $n$ items which\nbelong to $k$ unknown groups (or clusters), our goal is to recover the clusters\nby asking pairwise queries to an oracle. This oracle can answer the query that\n``do items $u$ and $v$ belong to the same cluster?''. However, the answer to\neach pairwise query errs with probability $\\varepsilon$, for some\n$\\varepsilon\\in(0,\\frac12)$. Mazumdar and Saha provided two algorithms under\nthis model: one algorithm is query-optimal while time-inefficient (i.e.,\nrunning in quasi-polynomial time), the other is time efficient (i.e., in\npolynomial time) while query-suboptimal. Larsen, Mitzenmacher and Tsourakakis\n[WWW 2020] then gave a new time-efficient algorithm for the special case of $2$\nclusters, which is query-optimal if the bias $\\delta:=1-2\\varepsilon$ of the\nmodel is large. It was left as an open question whether one can obtain a\nquery-optimal, time-efficient algorithm for the general case of $k$ clusters\nand other regimes of $\\delta$.\nIn this paper, we make progress on the above question and provide a\ntime-efficient algorithm with nearly-optimal query complexity (up to a factor\nof $O(\\log^2 n)$) for all constant $k$ and any $\\delta$ in the regime when\ninformation-theoretic recovery is possible. Our algorithm is built on a\nconnection to the stochastic block model.",
    "descriptor": "\nComments: Accepted for presentation at the Conference on Learning Theory (COLT) 2021\n",
    "authors": [
      "Pan Peng",
      "Jiapeng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10374"
  },
  {
    "id": "arXiv:2106.10377",
    "title": "The Animal ID Problem: Continual Curation",
    "abstract": "Hoping to stimulate new research in individual animal identification from\nimages, we propose to formulate the problem as the human-machine Continual\nCuration of images and animal identities. This is an open world recognition\nproblem, where most new animals enter the system after its algorithms are\ninitially trained and deployed. Continual Curation, as defined here, requires\n(1) an improvement in the effectiveness of current recognition methods, (2) a\npairwise verification algorithm that allows the possibility of no decision, and\n(3) an algorithmic decision mechanism that seeks human input to guide the\ncuration process. Error metrics must evaluate the ability of recognition\nalgorithms to identify not only animals that have been seen just once or twice\nbut also recognize new animals not in the database. An important measure of\noverall system performance is accuracy as a function of the amount of human\ninput required.",
    "descriptor": "\nComments: 4 pages, 2 figures, non-archival in 2021 CVPR workshop\n",
    "authors": [
      "Charles V. Stewart",
      "Jason R. Parham",
      "Jason Holmberg",
      "Tanya Y. Berger-Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10377"
  },
  {
    "id": "arXiv:2106.10382",
    "title": "Effects of VLSI Circuit Constrains on Temporal-Coding Multilayer Spiking  Neural Networks",
    "abstract": "The spiking neural network (SNN) has been attracting considerable attention\nnot only as a mathematical model for the brain, but also as an energy-efficient\ninformation processing model for real-world applications. In particular, SNNs\nbased on temporal coding are expected to be much more efficient than those\nbased on rate coding, because the former requires substantially fewer spikes to\ncarry out tasks. As SNNs are continuous-state and continuous-time models, it is\nfavorable to implement them with analog VLSI circuits. However, the\nconstruction of the entire system with continuous-time analog circuits would be\ninfeasible when the system size is very large. Therefore, mixed-signal circuits\nmust be employed, and the time discretization and quantization of the synaptic\nweights are necessary. Moreover, the analog VLSI implementation of SNNs\nexhibits non-idealities, such as the effects of noise and device mismatches, as\nwell as other constraints arising from the analog circuit operation. In this\nstudy, we investigated the effects of the time discretization and/or weight\nquantization on the performance of SNNs. Furthermore, we elucidated the effects\nthe lower bound of the membrane potentials and the temporal fluctuation of the\nfiring threshold. Finally, we propose an optimal approach for the mapping of\nmathematical SNN models to analog circuits with discretized time.",
    "descriptor": "",
    "authors": [
      "Yusuke Sakemi",
      "Takashi Morie",
      "Takeo Hosomi",
      "Kazuyuki Aihara"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.10382"
  },
  {
    "id": "arXiv:2106.10386",
    "title": "Sublinear Time Hypergraph Sparsification via Cut and Edge Sampling  Queries",
    "abstract": "The problem of sparsifying a graph or a hypergraph while approximately\npreserving its cut structure has been extensively studied and has many\napplications. In a seminal work, Bencz\\'ur and Karger (1996) showed that given\nany $n$-vertex undirected weighted graph $G$ and a parameter $\\varepsilon \\in\n(0,1)$, there is a near-linear time algorithm that outputs a weighted subgraph\n$G'$ of $G$ of size $\\tilde{O}(n/\\varepsilon^2)$ such that the weight of every\ncut in $G$ is preserved to within a $(1 \\pm \\varepsilon)$-factor in $G'$. The\ngraph $G'$ is referred to as a {\\em $(1 \\pm \\varepsilon)$-approximate cut\nsparsifier} of $G$. Subsequent recent work has obtained a similar result for\nthe more general problem of hypergraph cut sparsifiers. However, all known\nsparsification algorithms require $\\Omega(n + m)$ time where $n$ denotes the\nnumber of vertices and $m$ denotes the number of hyperedges in the hypergraph.\nSince $m$ can be exponentially large in $n$, a natural question is if it is\npossible to create a hypergraph cut sparsifier in time polynomial in $n$, {\\em\nindependent of the number of edges}. We resolve this question in the\naffirmative, giving the first sublinear time algorithm for this problem, given\nappropriate query access to the hypergraph.",
    "descriptor": "\nComments: ICALP 2021\n",
    "authors": [
      "Yu Chen",
      "Sanjeev Khanna",
      "Ansh Nagda"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.10386"
  },
  {
    "id": "arXiv:2106.10392",
    "title": "Effective Pre-Silicon Verification of Processor Cores by Breaking the  Bounds of Symbolic Quick Error Detection",
    "abstract": "We present a novel approach to pre-silicon verification of processor designs.\nThe purpose of pre-silicon verification is to find logic bugs in a design at an\nearly stage and thus avoid time- and cost-intensive post-silicon debugging. Our\napproach relies on symbolic quick error detection (Symbolic QED, or SQED). SQED\nis targeted at finding logic bugs in a symbolic representation of a design by\ncombining bounded model checking (BMC) with QED tests. QED tests are powerful\nin generating short sequences of instructions (traces) that trigger bugs. We\nextend an existing SQED approach with symbolic starting states. This way, we\nenable the BMC tool to select starting states arbitrarily when generating a\ntrace. To avoid false positives, (e.g., traces starting in unreachable states\nthat may not be-have in accordance with the processor instruction-set\narchitecture), we define constraints to restrict the set of possible starting\nstates. We demonstrate that these constraints, togeth-er with reasonable\nassumptions about the system behavior, allow us to avoid false positives. Using\nour approach, we discovered previously unknown bugs in open-source RISC-V\nprocessor cores that existing methods cannot detect. Moreover, our novel\napproach out-performs existing ones in the detection of bugs having long traces\nand in the detection of hardware Trojans, i.e., unauthorized modifications of a\ndesign.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1908.06757\n",
    "authors": [
      "Karthik Ganesan",
      "Florian Lonsing",
      "Srinivasa Shashank Nuthakki",
      "Eshan Singh",
      "Mohammad Rahmani Fadiheh",
      "Wolfgang Kunz",
      "Dominik Stoffel",
      "Clark Barrett",
      "Subhasish Mitra"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.10392"
  },
  {
    "id": "arXiv:2106.10393",
    "title": "Dynamical Deep Generative Latent Modeling of 3D Skeletal Motion",
    "abstract": "In this paper, we propose a Bayesian switching dynamical model for\nsegmentation of 3D pose data over time that uncovers interpretable patterns in\nthe data and is generative. Our model decomposes highly correlated skeleton\ndata into a set of few spatial basis of switching temporal processes in a\nlow-dimensional latent framework. We parameterize these temporal processes with\nregard to a switching deep vector autoregressive prior in order to accommodate\nboth multimodal and higher-order nonlinear inter-dependencies. This results in\na dynamical deep generative latent model that parses the meaningful intrinsic\nstates in the dynamics of 3D pose data using approximate variational inference,\nand enables a realistic low-level dynamical generation and segmentation of\ncomplex skeleton movements. Our experiments on four biological motion data\ncontaining bat flight, salsa dance, walking, and golf datasets substantiate\nsuperior performance of our model in comparison with the state-of-the-art\nmethods.",
    "descriptor": "",
    "authors": [
      "Amirreza Farnoosh",
      "Sarah Ostadabbas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10393"
  },
  {
    "id": "arXiv:2106.10402",
    "title": "Grasping Benchmarks: Normalizing for Object Size \\& Approximating Hand  Workspaces",
    "abstract": "The varied landscape of robotic hand designs makes it difficult to set a\nstandard for how to measure hand size and to communicate the size of objects it\ncan grasp. Defining consistent workspace measurements would greatly assist\nscientific communication in robotic grasping research because it would allow\nresearchers to 1) quantitatively communicate an object's relative size to a\nhand's and 2) approximate a functional subspace of a hand's kinematic workspace\nin a human-readable way. The goal of this paper is to specify a measurement\nprocedure that quantitatively captures a hand's workspace size for both a\nprecision and power grasp. This measurement procedure uses a {\\em functional}\napproach -- based on a generic grasping scenario of a hypothetical object -- in\norder to make the procedure as generalizable and repeatable as possible,\nregardless of the actual hand design. This functional approach lets the\nmeasurer choose the exact finger configurations and contact points that satisfy\nthe generic grasping scenario, while ensuring that the measurements are {\\em\nfunctionally} comparable. We demonstrate these functional measurements on seven\nhand configurations. Additional hand measurements and instructions are provided\nin a GitHub Repository.",
    "descriptor": "\nComments: Submitted to IROS 2021, waiting for response\n",
    "authors": [
      "John Morrow",
      "Nuha Nishat",
      "Joshua Campbell",
      "Ravi Balasubramanian",
      "Cindy Grimm"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10402"
  },
  {
    "id": "arXiv:2106.10404",
    "title": "Sparse Training via Boosting Pruning Plasticity with Neuroregeneration",
    "abstract": "Works on lottery ticket hypothesis (LTH) and single-shot network pruning\n(SNIP) have raised a lot of attention currently on post-training pruning\n(iterative magnitude pruning), and before-training pruning (pruning at\ninitialization). The former method suffers from an extremely large computation\ncost and the latter category of methods usually struggles with insufficient\nperformance. In comparison, during-training pruning, a class of pruning methods\nthat simultaneously enjoys the training/inference efficiency and the comparable\nperformance, temporarily, has been less explored. To better understand\nduring-training pruning, we quantitatively study the effect of pruning\nthroughout training from the perspective of pruning plasticity (the ability of\nthe pruned networks to recover the original performance). Pruning plasticity\ncan help explain several other empirical observations about neural network\npruning in literature. We further find that pruning plasticity can be\nsubstantially improved by injecting a brain-inspired mechanism called\nneuroregeneration, i.e., to regenerate the same number of connections as\npruned. Based on the insights from pruning plasticity, we design a novel\ngradual magnitude pruning (GMP) method, named gradual pruning with zero-cost\nneuroregeneration (GraNet), and its dynamic sparse training (DST) variant\n(GraNet-ST). Both of them advance state of the art. Perhaps most impressively,\nthe latter for the first time boosts the sparse-to-sparse training performance\nover various dense-to-sparse methods by a large margin with ResNet-50 on\nImageNet. We will release all codes.",
    "descriptor": "",
    "authors": [
      "Shiwei Liu",
      "Tianlong Chen",
      "Xiaohan Chen",
      "Zahra Atashgahi",
      "Lu Yin",
      "Huanyu Kou",
      "Li Shen",
      "Mykola Pechenizkiy",
      "Zhangyang Wang",
      "Decebal Constantin Mocanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10404"
  },
  {
    "id": "arXiv:2106.10406",
    "title": "Improving robustness of one-shot voice conversion with deep  discriminative speaker encoder",
    "abstract": "One-shot voice conversion has received significant attention since only one\nutterance from source speaker and target speaker respectively is required.\nMoreover, source speaker and target speaker do not need to be seen during\ntraining. However, available one-shot voice conversion approaches are not\nstable for unseen speakers as the speaker embedding extracted from one\nutterance of an unseen speaker is not reliable. In this paper, we propose a\ndeep discriminative speaker encoder to extract speaker embedding from one\nutterance more effectively. Specifically, the speaker encoder first integrates\nresidual network and squeeze-and-excitation network to extract discriminative\nspeaker information in frame level by modeling frame-wise and channel-wise\ninterdependence in features. Then attention mechanism is introduced to further\nemphasize speaker related information via assigning different weights to frame\nlevel speaker information. Finally a statistic pooling layer is used to\naggregate weighted frame level speaker information to form utterance level\nspeaker embedding. The experimental results demonstrate that our proposed\nspeaker encoder can improve the robustness of one-shot voice conversion for\nunseen speakers and outperforms baseline systems in terms of speech quality and\nspeaker similarity.",
    "descriptor": "",
    "authors": [
      "Hongqiang Du",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.10406"
  },
  {
    "id": "arXiv:2106.10407",
    "title": "When Efficiency meets Equity in Congestion Pricing and Revenue Refunding  Schemes",
    "abstract": "Congestion pricing has long been hailed as a means to mitigate traffic\ncongestion; however, its practical adoption has been limited due to the\nresulting social inequity issue, e.g., low-income users are priced out off\ncertain roads. This issue has spurred interest in the design of equitable\nmechanisms that aim to refund the collected toll revenues as lump-sum transfers\nto users. Although revenue refunding has been extensively studied, there has\nbeen no thorough characterization of how such schemes can be designed to\nsimultaneously achieve system efficiency and equity objectives.\nIn this work, we bridge this gap through the study of congestion pricing and\nrevenue refunding (CPRR) schemes in non-atomic congestion games. We first\ndevelop CPRR schemes, which in comparison to the untolled case, simultaneously\n(i) increase system efficiency and (ii) decrease wealth inequality, while being\n(iii) user-favorable: irrespective of their initial wealth or values-of-time\n(which may differ across users) users would experience a lower travel cost\nafter the implementation of the proposed scheme. We then characterize the set\nof optimal user-favorable CPRR schemes that simultaneously maximize system\nefficiency and minimize wealth inequality. These results assume a well-studied\nbehavior model of users minimizing a linear function of their travel times and\ntolls, without considering refunds. We also study a more complex behavior model\nwherein users are influenced by and react to the amount of refund that they\nreceive. Although, in general, the two models can result in different outcomes\nin terms of system efficiency and wealth inequality, we establish that those\noutcomes coincide when the aforementioned optimal CPRR scheme is implemented.\nOverall, our work demonstrates that through appropriate refunding policies we\ncan achieve system efficiency while reducing wealth inequality.",
    "descriptor": "\nComments: This paper was submitted to the inaugural ACM conference on Equity and Access in Algorithms, Mechanisms, and Optimization (EAAMO)\n",
    "authors": [
      "Devansh Jalota",
      "Kiril Solovey",
      "Karthik Gopalakrishnan",
      "Stephen Zoepf",
      "Hamsa Balakrishnan",
      "Marco Pavone"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10407"
  },
  {
    "id": "arXiv:2106.10408",
    "title": "Step Out of Your Comfort Zone: More Inclusive Content Recommendation for  Networked Systems",
    "abstract": "Networked systems are widely applicable in real-world scenarios such as\nsocial networks, infrastructure networks, and biological networks. Among those\napplications, we are interested in social networks due to their complexity and\npopularity. One crucial task on the social network is to recommend new content\nbased on special characteristics of the graph structure. In this project, we\naim to enhance the recommender systems by preventing the recommendations from\nleaning towards contents from closed communities. To counteract the bias, we\nwill consider information dissemination across network as a metric to assess\nthe recommendation for contents e.g. new connections and news feed. We use\nacademic collaboration network and user-item interaction datasets from Yelp to\nsimulate an environment for connection recommendations and to validate the\nproposed algorithm.",
    "descriptor": "",
    "authors": [
      "Jiaxin Wu",
      "Supawit Chockchowwat"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.10408"
  },
  {
    "id": "arXiv:2106.10409",
    "title": "AdaZoom: Adaptive Zoom Network for Multi-Scale Object Detection in Large  Scenes",
    "abstract": "Detection in large-scale scenes is a challenging problem due to small objects\nand extreme scale variation. It is essential to focus on the image regions of\nsmall objects. In this paper, we propose a novel Adaptive Zoom (AdaZoom)\nnetwork as a selective magnifier with flexible shape and focal length to\nadaptively zoom the focus regions for object detection. Based on policy\ngradient, we construct a reinforcement learning framework for focus region\ngeneration, with the reward formulated by object distributions. The scales and\naspect ratios of the generated regions are adaptive to the scales and\ndistribution of objects inside. We apply variable magnification according to\nthe scale of the region for adaptive multi-scale detection. We further propose\ncollaborative training to complementarily promote the performance of AdaZoom\nand the detection network. To validate the effectiveness, we conduct extensive\nexperiments on VisDrone2019, UAVDT, and DOTA datasets. The experiments show\nAdaZoom brings a consistent and significant improvement over different\ndetection networks, achieving state-of-the-art performance on these datasets,\nespecially outperforming the existing methods by AP of 4.64% on Vis-Drone2019.",
    "descriptor": "",
    "authors": [
      "Jingtao Xu",
      "Yali Li",
      "Shengjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10409"
  },
  {
    "id": "arXiv:2106.10410",
    "title": "Deep Generative Learning via Schr\u00f6dinger Bridge",
    "abstract": "We propose to learn a generative model via entropy interpolation with a\nSchr\\\"{o}dinger Bridge. The generative learning task can be formulated as\ninterpolating between a reference distribution and a target distribution based\non the Kullback-Leibler divergence. At the population level, this entropy\ninterpolation is characterized via an SDE on $[0,1]$ with a time-varying drift\nterm. At the sample level, we derive our Schr\\\"{o}dinger Bridge algorithm by\nplugging the drift term estimated by a deep score estimator and a deep density\nratio estimator into the Euler-Maruyama method. Under some mild smoothness\nassumptions of the target distribution, we prove the consistency of both the\nscore estimator and the density ratio estimator, and then establish the\nconsistency of the proposed Schr\\\"{o}dinger Bridge approach. Our theoretical\nresults guarantee that the distribution learned by our approach converges to\nthe target distribution. Experimental results on multimodal synthetic data and\nbenchmark data support our theoretical findings and indicate that the\ngenerative model via Schr\\\"{o}dinger Bridge is comparable with state-of-the-art\nGANs, suggesting a new formulation of generative learning. We demonstrate its\nusefulness in image interpolation and image inpainting.",
    "descriptor": "",
    "authors": [
      "Gefei Wang",
      "Yuling Jiao",
      "Qian Xu",
      "Yang Wang",
      "Can Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10410"
  },
  {
    "id": "arXiv:2106.10411",
    "title": "Boosting Offline Reinforcement Learning with Residual Generative  Modeling",
    "abstract": "Offline reinforcement learning (RL) tries to learn the near-optimal policy\nwith recorded offline experience without online exploration. Current offline RL\nresearch includes: 1) generative modeling, i.e., approximating a policy using\nfixed data; and 2) learning the state-action value function. While most\nresearch focuses on the state-action function part through reducing the\nbootstrapping error in value function approximation induced by the distribution\nshift of training data, the effects of error propagation in generative modeling\nhave been neglected. In this paper, we analyze the error in generative\nmodeling. We propose AQL (action-conditioned Q-learning), a residual generative\nmodel to reduce policy approximation error for offline RL. We show that our\nmethod can learn more accurate policy approximations in different benchmark\ndatasets. In addition, we show that the proposed offline RL method can learn\nmore competitive AI agents in complex control tasks under the multiplayer\nonline battle arena (MOBA) game Honor of Kings.",
    "descriptor": "\nComments: Accepted by IJCAI 2021, appendix included, 9 pages, 4 figures, 2 tables\n",
    "authors": [
      "Hua Wei",
      "Deheng Ye",
      "Zhao Liu",
      "Hao Wu",
      "Bo Yuan",
      "Qiang Fu",
      "Wei Yang",
      "Zhenhui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10411"
  },
  {
    "id": "arXiv:2106.10412",
    "title": "Fisher Markets with Linear Constraints: Equilibrium Properties and  Efficient Distributed Algorithms",
    "abstract": "The Fisher market is one of the most fundamental models for resource\nallocation problems in economic theory, wherein agents spend a budget of\ncurrency to buy goods that maximize their utilities, while producers sell\ncapacity constrained goods in exchange for currency. However, the consideration\nof only two types of constraints, i.e., budgets of individual buyers and\ncapacities of goods, makes Fisher markets less amenable for resource allocation\nsettings when agents have additional linear constraints, e.g., knapsack and\nproportionality constraints. In this work, we introduce a modified Fisher\nmarket, where each agent may have additional linear constraints and show that\nthis modification to classical Fisher markets fundamentally alters the\nproperties of the market equilibrium as well as the optimal allocations. These\nproperties of the modified Fisher market prompt us to introduce a budget\nperturbed social optimization problem (BP-SOP) and set prices based on the dual\nvariables of BP-SOP's capacity constraints. To compute the budget\nperturbations, we develop a fixed point iterative scheme and validate its\nconvergence through numerical experiments.\nSince this fixed point iterative scheme involves solving a centralized\nproblem at each step, we propose a new class of distributed algorithms to\ncompute equilibrium prices. In particular, we develop an Alternating Direction\nMethod of Multipliers (ADMM) algorithm with strong convergence guarantees for\nFisher markets with homogeneous linear constraints as well as for classical\nFisher markets. In this algorithm, the prices are updated based on the\ntatonnement process, with a step size that is completely independent of the\nutilities of individual agents. Thus, our mechanism, both theoretically and\ncomputationally, overcomes a fundamental limitation of classical Fisher\nmarkets, which only consider capacity and budget constraints.",
    "descriptor": "",
    "authors": [
      "Devansh Jalota",
      "Marco Pavone",
      "Qi Qi",
      "Yinyu Ye"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.10412"
  },
  {
    "id": "arXiv:2106.10417",
    "title": "Variance-Dependent Best Arm Identification",
    "abstract": "We study the problem of identifying the best arm in a stochastic multi-armed\nbandit game. Given a set of $n$ arms indexed from $1$ to $n$, each arm $i$ is\nassociated with an unknown reward distribution supported on $[0,1]$ with mean\n$\\theta_i$ and variance $\\sigma_i^2$. Assume $\\theta_1 > \\theta_2 \\geq \\cdots\n\\geq\\theta_n$. We propose an adaptive algorithm which explores the gaps and\nvariances of the rewards of the arms and makes future decisions based on the\ngathered information using a novel approach called \\textit{grouped median\nelimination}. The proposed algorithm guarantees to output the best arm with\nprobability $(1-\\delta)$ and uses at most $O \\left(\\sum_{i = 1}^n\n\\left(\\frac{\\sigma_i^2}{\\Delta_i^2} + \\frac{1}{\\Delta_i}\\right)(\\ln \\delta^{-1}\n+ \\ln \\ln \\Delta_i^{-1})\\right)$ samples, where $\\Delta_i$ ($i \\geq 2$) denotes\nthe reward gap between arm $i$ and the best arm and we define $\\Delta_1 =\n\\Delta_2$. This achieves a significant advantage over the variance-independent\nalgorithms in some favorable scenarios and is the first result that removes the\nextra $\\ln n$ factor on the best arm compared with the state-of-the-art. We\nfurther show that $\\Omega \\left( \\sum_{i = 1}^n \\left(\n\\frac{\\sigma_i^2}{\\Delta_i^2} + \\frac{1}{\\Delta_i} \\right) \\ln \\delta^{-1}\n\\right)$ samples are necessary for an algorithm to achieve the same goal,\nthereby illustrating that our algorithm is optimal up to doubly logarithmic\nterms.",
    "descriptor": "",
    "authors": [
      "Pinyan Lu",
      "Chao Tao",
      "Xiaojin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10417"
  },
  {
    "id": "arXiv:2106.10419",
    "title": "Predicting Critical Nodes in Temporal Networks by Dynamic Graph  Convolutional Networks",
    "abstract": "Many real-world systems can be expressed in temporal networks with nodes\nplaying far different roles in structure and function and edges representing\nthe relationships between nodes. Identifying critical nodes can help us control\nthe spread of public opinions or epidemics, predict leading figures in\nacademia, conduct advertisements for various commodities, and so on. However,\nit is rather difficult to identify critical nodes because the network structure\nchanges over time in temporal networks. In this paper, considering the sequence\ntopological information of temporal networks, a novel and effective learning\nframework based on the combination of special GCNs and RNNs is proposed to\nidentify nodes with the best spreading ability. The effectiveness of the\napproach is evaluated by weighted Susceptible-Infected-Recovered model.\nExperimental results on four real-world temporal networks demonstrate that the\nproposed method outperforms both traditional and deep learning benchmark\nmethods in terms of the Kendall $\\tau$ coefficient and top $k$ hit rate.",
    "descriptor": "",
    "authors": [
      "En-Yu Yu",
      "Yan Fu",
      "Jun-Lin Zhou",
      "Hong-Liang Sun",
      "Duan-Bing Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10419"
  },
  {
    "id": "arXiv:2106.10420",
    "title": "Finding critical edges in complex networks through local information",
    "abstract": "In transportation, communication, social and other real networks, there are\nsome critical edges play an important role in the delivery of traffic flow and\ninformation packets. Identifying critical edges in complex networks is of great\nsignificance in both theoretical studies and practical applications.\nConsidering the overlap of communities in the neighborhood of edges, a novel\nand effective index named subgraph overlap (SO) is proposed in this paper.\nExperimental results on one synthetic and eight real networks show that SO\noutperforms five benchmark methods in identifying critical edges which are\ncrucial in maintaining the integrity of the structure and functions of\nnetworks.",
    "descriptor": "",
    "authors": [
      "En-Yu Yu",
      "Yan Fu",
      "Jun-Lin Zhou",
      "Hong-Liang Sun",
      "Duan-Bing Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10420"
  },
  {
    "id": "arXiv:2106.10422",
    "title": "Robust M-estimation-based Tensor Ring Completion: a Half-quadratic  Minimization Approach",
    "abstract": "Tensor completion is the problem of estimating the missing values of\nhigh-order data from partially observed entries. Among several definitions of\ntensor rank, tensor ring rank affords the flexibility and accuracy needed to\nmodel tensors of different orders, which motivated recent efforts on\ntensor-ring completion. However, data corruption due to prevailing outliers\nposes major challenges to existing algorithms. In this paper, we develop a\nrobust approach to tensor ring completion that uses an M-estimator as its error\nstatistic, which can significantly alleviate the effect of outliers. Leveraging\na half-quadratic (HQ) method, we reformulate the problem as one of weighted\ntensor completion. We present two HQ-based algorithms based on truncated\nsingular value decomposition and matrix factorization along with their\nconvergence and complexity analysis. Extendibility of the proposed approach to\nalternative definitions of tensor rank is also discussed. The experimental\nresults demonstrate the superior performance of the proposed approach over\nstate-of-the-art robust algorithms for tensor completion.",
    "descriptor": "",
    "authors": [
      "Yicong He",
      "George K. Atia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10422"
  },
  {
    "id": "arXiv:2106.10423",
    "title": "Joint Speed Control and Energy Replenishment Optimization for  UAV-assisted IoT Data Collection with Deep Reinforcement Transfer Learning",
    "abstract": "Unmanned aerial vehicle (UAV)-assisted data collection has been emerging as a\nprominent application due to its flexibility, mobility, and low operational\ncost. However, under the dynamic and uncertainty of IoT data collection and\nenergy replenishment processes, optimizing the performance for UAV collectors\nis a very challenging task. Thus, this paper introduces a novel framework that\njointly optimizes the flying speed and energy replenishment for each UAV to\nsignificantly improve the data collection performance. Specifically, we first\ndevelop a Markov decision process to help the UAV automatically and dynamically\nmake optimal decisions under the dynamics and uncertainties of the environment.\nWe then propose a highly-effective reinforcement learning algorithm leveraging\ndeep Q-learning, double deep Q-learning, and a deep dueling neural network\narchitecture to quickly obtain the UAV's optimal policy. The core ideas of this\nalgorithm are to estimate the state values and action advantages separately and\nsimultaneously and to employ double estimators for estimating the action\nvalues. Thus, these proposed techniques can stabilize the learning process and\neffectively address the overestimation problem of conventional Q-learning\nalgorithms. To further reduce the learning time as well as significantly\nimprove learning quality, we develop advanced transfer learning techniques to\nallow UAVs to ``share'' and ``transfer'' learning knowledge. Extensive\nsimulations demonstrate that our proposed solution can improve the average data\ncollection performance of the system up to 200% compared with those of current\nmethods.",
    "descriptor": "",
    "authors": [
      "Nam H.Chu",
      "Dinh Thai Hoang",
      "Diep N. Nguyen",
      "Nguyen Van Huynh",
      "Eryk Dutkiewicz"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10423"
  },
  {
    "id": "arXiv:2106.10424",
    "title": "Nearly Minimax Optimal Adversarial Imitation Learning with Known and  Unknown Transitions",
    "abstract": "This paper is dedicated to designing provably efficient adversarial imitation\nlearning (AIL) algorithms that directly optimize policies from expert\ndemonstrations. Firstly, we develop a transition-aware AIL algorithm named TAIL\nwith an expert sample complexity of $\\tilde{O}(H^{3/2} |S|/\\varepsilon)$ under\nthe known transition setting, where $H$ is the planning horizon, $|S|$ is the\nstate space size and $\\varepsilon$ is desired policy value gap. This improves\nupon the previous best bound of $\\tilde{O}(H^2 |S| / \\varepsilon^2)$ for AIL\nmethods and matches the lower bound of $\\tilde{\\Omega} (H^{3/2}\n|S|/\\varepsilon)$ in [Rajaraman et al., 2021] up to a logarithmic factor. The\nkey ingredient of TAIL is a fine-grained estimator for expert state-action\ndistribution, which explicitly utilizes the transition function information.\nSecondly, considering practical settings where the transition functions are\nusually unknown but environment interaction is allowed, we accordingly develop\na model-based transition-aware AIL algorithm named MB-TAIL. In particular,\nMB-TAIL builds an empirical transition model by interacting with the\nenvironment and performs imitation under the recovered empirical model. The\ninteraction complexity of MB-TAIL is $\\tilde{O} (H^3 |S|^2 |A| /\n\\varepsilon^2)$, which improves the best known result of $\\tilde{O} (H^4 |S|^2\n|A| / \\varepsilon^2)$ in [Shani et al., 2021]. Finally, our theoretical results\nare supported by numerical evaluation and detailed analysis on two challenging\nMDPs.",
    "descriptor": "",
    "authors": [
      "Tian Xu",
      "Ziniu Li",
      "Yang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10424"
  },
  {
    "id": "arXiv:2106.10426",
    "title": "Algorithm Unrolling for Massive Access via Deep Neural Network with  Theoretical Guarantee",
    "abstract": "Massive access is a critical design challenge of Internet of Things (IoT)\nnetworks. In this paper, we consider the grant-free uplink transmission of an\nIoT network with a multiple-antenna base station (BS) and a large number of\nsingle-antenna IoT devices. Taking into account the sporadic nature of IoT\ndevices, we formulate the joint activity detection and channel estimation\n(JADCE) problem as a group-sparse matrix estimation problem. This problem can\nbe solved by applying the existing compressed sensing techniques, which however\neither suffer from high computational complexities or lack of algorithm\nrobustness. To this end, we propose a novel algorithm unrolling framework based\non the deep neural network to simultaneously achieve low computational\ncomplexity and high robustness for solving the JADCE problem. Specifically, we\nmap the original iterative shrinkage thresholding algorithm (ISTA) into an\nunrolled recurrent neural network (RNN), thereby improving the convergence rate\nand computational efficiency through end-to-end training. Moreover, the\nproposed algorithm unrolling approach inherits the structure and domain\nknowledge of the ISTA, thereby maintaining the algorithm robustness, which can\nhandle non-Gaussian preamble sequence matrix in massive access. With rigorous\ntheoretical analysis, we further simplify the unrolled network structure by\nreducing the redundant training parameters. Furthermore, we prove that the\nsimplified unrolled deep neural network structures enjoy a linear convergence\nrate. Extensive simulations based on various preamble signatures show that the\nproposed unrolled networks outperform the existing methods in terms of the\nconvergence rate, robustness and estimation accuracy.",
    "descriptor": "\nComments: 15 pages, 15 figures, this paper has been submitted to IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Yandong Shi",
      "Hayoung Choi",
      "Yuanming Shi",
      "Yong Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10426"
  },
  {
    "id": "arXiv:2106.10427",
    "title": "Reassessing Measures for Press Freedom",
    "abstract": "There has been a newly refound interest in press freedom in the face of\nvarious global scandals, transformation of media, technological change,\nobstacles to deliberative democracy, and other factors. Press freedom is\nfrequently used also as an explanatory factor in comparative empirical\nresearch. However, validations of existing measurement instruments on press\nfreedom have been far and few between. Given these points, this paper evaluates\neight cross-country instruments on press freedom in 147 countries between 2001\nand 2020, replicating an earlier study with a comparable research setup. The\nmethodology is based on principal component analysis and multi-level regression\nmodeling. According to the results, the construct (convergence) validity of the\ninstruments is good; they all measure the same underlying semi-narrow\ndefinition for press freedom elaborated in the paper. In addition, any of the\nindices seems suitable to be used interchangeability in empirical research.\nLimitations and future research directions are further discussed.",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Jukka Ruohonen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.10427"
  },
  {
    "id": "arXiv:2106.10430",
    "title": "Multi-Contextual Design of Convolutional Neural Network for Steganalysis",
    "abstract": "In recent times, deep learning-based steganalysis classifiers became popular\ndue to their state-of-the-art performance. Most deep steganalysis classifiers\nusually extract noise residuals using high-pass filters as preprocessing steps\nand feed them to their deep model for classification. It is observed that\nrecent steganographic embedding does not always restrict their embedding in the\nhigh-frequency zone; instead, they distribute it as per embedding policy.\nTherefore, besides noise residual, learning the embedding zone is another\nchallenging task. In this work, unlike the conventional approaches, the\nproposed model first extracts the noise residual using learned denoising\nkernels to boost the signal-to-noise ratio. After preprocessing, the sparse\nnoise residuals are fed to a novel Multi-Contextual Convolutional Neural\nNetwork (M-CNET) that uses heterogeneous context size to learn the sparse and\nlow-amplitude representation of noise residuals. The model performance is\nfurther improved by incorporating the Self-Attention module to focus on the\nareas prone to steganalytic embedding. A set of comprehensive experiments is\nperformed to show the proposed scheme's efficacy over the prior arts. Besides,\nan ablation study is given to justify the contribution of various modules of\nthe proposed architecture.",
    "descriptor": "\nComments: This work has been submitted to the IEEE Transactions on Information Forensics and Security (IEEE-TIFS) for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Brijesh Singh",
      "Arijit Sur",
      "Pinaki Mitra"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.10430"
  },
  {
    "id": "arXiv:2106.10432",
    "title": "Neural Network Facial Authentication for Public Electric Vehicle  Charging Station",
    "abstract": "This study is to investigate and compare the facial recognition accuracy\nperformance of Dlib ResNet against a K-Nearest Neighbour (KNN) classifier.\nParticularly when used against a dataset from an Asian ethnicity as Dlib ResNet\nwas reported to have an accuracy deficiency when it comes to Asian faces. The\ncomparisons are both implemented on the facial vectors extracted using the\nHistogram of Oriented Gradients (HOG) method and use the same dataset for a\nfair comparison. Authentication of a user by facial recognition in an electric\nvehicle (EV) charging station demonstrates a practical use case for such an\nauthentication system.",
    "descriptor": "",
    "authors": [
      "Muhamad Amin Husni Abdul Haris",
      "Sin Liang Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.10432"
  },
  {
    "id": "arXiv:2106.10434",
    "title": "Improving Compositional Generalization in Classification Tasks via  Structure Annotations",
    "abstract": "Compositional generalization is the ability to generalize systematically to a\nnew data distribution by combining known components. Although humans seem to\nhave a great ability to generalize compositionally, state-of-the-art neural\nmodels struggle to do so. In this work, we study compositional generalization\nin classification tasks and present two main contributions. First, we study\nways to convert a natural language sequence-to-sequence dataset to a\nclassification dataset that also requires compositional generalization. Second,\nwe show that providing structural hints (specifically, providing parse trees\nand entity links as attention masks for a Transformer model) helps\ncompositional generalization.",
    "descriptor": "\nComments: Accepted as a short paper at ACL 2021\n",
    "authors": [
      "Juyong Kim",
      "Pradeep Ravikumar",
      "Joshua Ainslie",
      "Santiago Onta\u00f1\u00f3n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10434"
  },
  {
    "id": "arXiv:2106.10435",
    "title": "STEM: A Stochastic Two-Sided Momentum Algorithm Achieving Near-Optimal  Sample and Communication Complexities for Federated Learning",
    "abstract": "Federated Learning (FL) refers to the paradigm where multiple worker nodes\n(WNs) build a joint model by using local data. Despite extensive research, for\na generic non-convex FL problem, it is not clear, how to choose the WNs' and\nthe server's update directions, the minibatch sizes, and the local update\nfrequency, so that the WNs use the minimum number of samples and communication\nrounds to achieve the desired solution. This work addresses the above question\nand considers a class of stochastic algorithms where the WNs perform a few\nlocal updates before communication. We show that when both the WN's and the\nserver's directions are chosen based on a stochastic momentum estimator, the\nalgorithm requires $\\tilde{\\mathcal{O}}(\\epsilon^{-3/2})$ samples and\n$\\tilde{\\mathcal{O}}(\\epsilon^{-1})$ communication rounds to compute an\n$\\epsilon$-stationary solution. To the best of our knowledge, this is the first\nFL algorithm that achieves such {\\it near-optimal} sample and communication\ncomplexities simultaneously. Further, we show that there is a trade-off curve\nbetween local update frequencies and local minibatch sizes, on which the above\nsample and communication complexities can be maintained. Finally, we show that\nfor the classical FedAvg (a.k.a. Local SGD, which is a momentum-less special\ncase of the STEM), a similar trade-off curve exists, albeit with worse sample\nand communication complexities. Our insights on this trade-off provides\nguidelines for choosing the four important design elements for FL algorithms,\nthe update frequency, directions, and minibatch sizes to achieve the best\nperformance.",
    "descriptor": "",
    "authors": [
      "Prashant Khanduri",
      "Pranay Sharma",
      "Haibo Yang",
      "Mingyi Hong",
      "Jia Liu",
      "Ketan Rajawat",
      "Pramod K. Varshney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10435"
  },
  {
    "id": "arXiv:2106.10436",
    "title": "On spectral Petrov-Galerkin method for solving optimal control problem  governed by a two-sided fractional diffusion equation",
    "abstract": "In this paper, we investigate a spectral Petrov-Galerkin method for an\noptimal control problem governed by a two-sided space-fractional\ndiffusion-advection-reaction equation. Taking into account the effect of\nsingularities near the boundary generated by the weak singular kernel of the\nfractional operator, we establish the regularity of the problem in weighted\nSobolev space. Error estimates are provided for the presented spectral\nPetrov-Galerkin method and the convergence orders of the state and control\nvariables are determined. Furthermore, a fast projected gradient algorithm with\na quasi-linear complexity is presented to solve the resulting discrete system.\nNumerical experiments show the validity of theoretical findings and efficiency\nof the proposed fast algorithm.",
    "descriptor": "",
    "authors": [
      "Shengyue Li",
      "Wanrong Cao",
      "Yibo Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10436"
  },
  {
    "id": "arXiv:2106.10438",
    "title": "ML and MAP Device Activity Detections for Grant-Free Massive Access in  Multi-Cell Networks",
    "abstract": "Device activity detection is one main challenge in grant-free massive access,\nwhich is recently proposed to support massive machine-type communications\n(mMTC). Existing solutions for device activity detection fail to consider\ninter-cell interference generated by massive IoT devices or important prior\ninformation on device activities and inter-cell interference. In this paper,\ngiven different numbers of observations and network parameters, we consider\nboth non-cooperative device activity detection and cooperative device activity\ndetection in a multi-cell network, consisting of many access points (APs) and\nIoT devices. Under each activity detection mechanism, we consider the joint\nmaximum likelihood (ML) estimation and joint maximum a posterior probability\n(MAP) estimation of both device activities and interference powers, utilizing\ntools from probability, stochastic geometry, and optimization. Each estimation\nproblem is a challenging non-convex problem, and a coordinate descent algorithm\nis proposed to obtain a stationary point. Each proposed joint ML estimation\nextends the existing one for a single-cell network by considering the\nestimation of interference powers, together with the estimation of device\nactivities. Each proposed joint MAP estimation further enhances the\ncorresponding joint ML estimation by exploiting prior distributions of device\nactivities and interference powers. The proposed joint ML estimation and joint\nMAP estimation under cooperative detection outperform the respective ones under\nnon-cooperative detection at the costs of increasing backhaul burden, knowledge\nof network parameters, and computational complexities.",
    "descriptor": "",
    "authors": [
      "Dongdong Jiang",
      "Ying Cui"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10438"
  },
  {
    "id": "arXiv:2106.10442",
    "title": "A Unified View of Algorithms for Path Planning Using Probabilistic  Inference on Factor Graphs",
    "abstract": "Even if path planning can be solved using standard techniques from dynamic\nprogramming and control, the problem can also be approached using probabilistic\ninference. The algorithms that emerge using the latter framework bear some\nappealing characteristics that qualify the probabilistic approach as a powerful\nalternative to the more traditional control formulations. The idea of using\nestimation on stochastic models to solve control problems is not new and the\ninference approach considered here falls under the rubric of Active Inference\n(AI) and Control as Inference (CAI). In this work, we look at the specific\nrecursions that arise from various cost functions that, although they may\nappear similar in scope, bear noticeable differences, at least when applied to\ntypical path planning problems. We start by posing the path planning problem on\na probabilistic factor graph, and show how the various algorithms translate\ninto specific message composition rules. We then show how this unified\napproach, presented both in probability space and in log space, provides a very\ngeneral framework that includes the Sum-product, the Max-product, Dynamic\nprogramming and mixed Reward/Entropy criteria-based algorithms. The framework\nalso expands algorithmic design options for smoother or sharper policy\ndistributions, including generalized Sum/Max-product algorithm, a Smooth\nDynamic programming algorithm and modified versions of the Reward/Entropy\nrecursions. We provide a comprehensive table of recursions and a comparison\nthrough simulations, first on a synthetic small grid with a single goal with\nobstacles, and then on a grid extrapolated from a real-world scene with\nmultiple goals and a semantic map.",
    "descriptor": "",
    "authors": [
      "Francesco A.N. Palmieri",
      "Krishna R. Pattipati",
      "Giovanni Di Gennaro",
      "Giovanni Fioretti",
      "Francesco Verolla",
      "Amedeo Buonanno"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10442"
  },
  {
    "id": "arXiv:2106.10444",
    "title": "On the Ergodic Capacity of Reconfigurable Intelligent Surface  (RIS)-Aided MIMO Channels",
    "abstract": "Reconfigurable intelligent surfaces (RISs) have emerged as a promising\ntechnique to enhance the system spectral efficiency. This letter investigates\nthe ergodic channel capacity (ECC) of an RIS-aided multiple-input\nmultiple-output channel under the assumption that the transmitter-RIS,\nRIS-receiver, and transmitter-receiver channels contain deterministic\nline-of-sight paths. Novel expressions are derived to characterize the upper\nand lower bounds of the ECC. To unveil more system insights, asymptotic\nanalyses are performed to the system ECC in the limit of large signal-to-noise\nratio (SNR) and number of reflecting elements (REs). Theoretical analyses\nsuggest that the RIS's deployment can shape the ECC curve by influencing its\nhigh-SNR power offset and the ECC can get improved by increasing the number of\nREs.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Chongjun Ouyang",
      "Sheng Wu",
      "Chunxiao Jiang",
      "Yuanwei Liu",
      "Hongwen Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10444"
  },
  {
    "id": "arXiv:2106.10446",
    "title": "Attend What You Need: Motion-Appearance Synergistic Networks for Video  Question Answering",
    "abstract": "Video Question Answering is a task which requires an AI agent to answer\nquestions grounded in video. This task entails three key challenges: (1)\nunderstand the intention of various questions, (2) capturing various elements\nof the input video (e.g., object, action, causality), and (3) cross-modal\ngrounding between language and vision information. We propose Motion-Appearance\nSynergistic Networks (MASN), which embed two cross-modal features grounded on\nmotion and appearance information and selectively utilize them depending on the\nquestion's intentions. MASN consists of a motion module, an appearance module,\nand a motion-appearance fusion module. The motion module computes the\naction-oriented cross-modal joint representations, while the appearance module\nfocuses on the appearance aspect of the input video. Finally, the\nmotion-appearance fusion module takes each output of the motion module and the\nappearance module as input, and performs question-guided fusion. As a result,\nMASN achieves new state-of-the-art performance on the TGIF-QA and MSVD-QA\ndatasets. We also conduct qualitative analysis by visualizing the inference\nresults of MASN. The code is available at\nhttps://github.com/ahjeongseo/MASN-pytorch.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Ahjeong Seo",
      "Gi-Cheon Kang",
      "Joonhan Park",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10446"
  },
  {
    "id": "arXiv:2106.10448",
    "title": "A Robust CACC Scheme Against Cyberattacks Via Multiple  Vehicle-to-Vehicle Networks",
    "abstract": "Cooperative Adaptive Cruise Control (CACC) is a vehicular technology that\nallows groups of vehicles on the highway to form in closely-coupled automated\nplatoons to increase highway capacity and safety, and decrease fuel consumption\nand CO2 emissions. The underlying mechanism behind CACC is the use of\nVehicle-to-Vehicle (V2V) wireless communication networks to transmit\nacceleration commands to adjacent vehicles in the platoon. However, the use of\nV2V networks leads to increased vulnerabilities against faults and cyberattacks\nat the communication channels. Communication networks serve as new access\npoints for malicious agents trying to deteriorate the platooning performance or\neven cause crashes. Here, we address the problem of increasing robustness of\nCACC schemes against cyberattacks by the use of multiple V2V networks and a\ndata fusion algorithm. The idea is to transmit acceleration commands multiple\ntimes through different communication networks (channels) to create redundancy\nat the receiver side. We exploit this redundancy to obtain attack-free\nestimates of acceleration commands. To accomplish this, we propose a\ndata-fusion algorithm that takes data from all channels, returns an estimate of\nthe true acceleration command, and isolates compromised channels. Note,\nhowever, that using estimated data for control introduces uncertainty into the\nloop and thus decreases performance. To minimize performance degradation, we\npropose a robust $H_{\\infty}$ controller that reduces the joint effect of\nestimation errors and sensor/channel noise in the platooning performance\n(tracking performance and string stability). We present simulation results to\nillustrate the performance of our approach.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.00883\n",
    "authors": [
      "Tianci Yang",
      "Carlos Murguia",
      "Dragan Ne\u0161i\u0107",
      "Chen Lv"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10448"
  },
  {
    "id": "arXiv:2106.10452",
    "title": "MSN: Efficient Online Mask Selection Network for Video Instance  Segmentation",
    "abstract": "In this work we present a novel solution for Video Instance\nSegmentation(VIS), that is automatically generating instance level segmentation\nmasks along with object class and tracking them in a video. Our method improves\nthe masks from segmentation and propagation branches in an online manner using\nthe Mask Selection Network (MSN) hence limiting the noise accumulation during\nmask tracking. We propose an effective design of MSN by using patch-based\nconvolutional neural network. The network is able to distinguish between very\nsubtle differences between the masks and choose the better masks out of the\nassociated masks accurately. Further, we make use of temporal consistency and\nprocess the video sequences in both forward and reverse manner as a post\nprocessing step to recover lost objects. The proposed method can be used to\nadapt any video object segmentation method for the task of VIS. Our method\nachieves a score of 49.1 mAP on 2021 YouTube-VIS Challenge and was ranked third\nplace among more than 30 global teams. Our code will be available at\nhttps://github.com/SHI-Labs/Mask-Selection-Networks.",
    "descriptor": "\nComments: 3rd Place Solution to the YouTube-VIS Challenge at CVPR 2021\n",
    "authors": [
      "Vidit Goel",
      "Jiachen Li",
      "Shubhika Garg",
      "Harsh Maheshwari",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10452"
  },
  {
    "id": "arXiv:2106.10453",
    "title": "Graph approximation and generalized Tikhonov regularization for signal  deblurring",
    "abstract": "Given a compact linear operator $\\K$, the (pseudo) inverse $\\K^\\dagger$ is\nusually substituted by a family of regularizing operators $\\R_\\alpha$ which\ndepends on $\\K$ itself. Naturally, in the actual computation we are forced to\napproximate the true continuous operator $\\K$ with a discrete operator\n$\\K^{(n)}$ characterized by a finesses discretization parameter $n$, and\nobtaining then a discretized family of regularizing operators\n$\\R_\\alpha^{(n)}$. In general, the numerical scheme applied to discretize $\\K$\ndoes not preserve, asymptotically, the full spectrum of $\\K$. In the context of\na generalized Tikhonov-type regularization, we show that a graph-based\napproximation scheme that guarantees, asymptotically, a zero maximum relative\nspectral error can significantly improve the approximated solutions given by\n$\\R_\\alpha^{(n)}$. This approach is combined with a graph based regularization\ntechnique with respect to the penalty term.",
    "descriptor": "",
    "authors": [
      "Davide Bianchi",
      "Marco Donatelli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10453"
  },
  {
    "id": "arXiv:2106.10454",
    "title": "Enhancing Question Generation with Commonsense Knowledge",
    "abstract": "Question generation (QG) is to generate natural and grammatical questions\nthat can be answered by a specific answer for a given context. Previous\nsequence-to-sequence models suffer from a problem that asking high-quality\nquestions requires commonsense knowledge as backgrounds, which in most cases\ncan not be learned directly from training data, resulting in unsatisfactory\nquestions deprived of knowledge. In this paper, we propose a multi-task\nlearning framework to introduce commonsense knowledge into question generation\nprocess. We first retrieve relevant commonsense knowledge triples from mature\ndatabases and select triples with the conversion information from source\ncontext to question. Based on these informative knowledge triples, we design\ntwo auxiliary tasks to incorporate commonsense knowledge into the main QG\nmodel, where one task is Concept Relation Classification and the other is Tail\nConcept Generation. Experimental results on SQuAD show that our proposed\nmethods are able to noticeably improve the QG performance on both automatic and\nhuman evaluation metrics, demonstrating that incorporating external commonsense\nknowledge with multi-task learning can help the model generate human-like and\nhigh-quality questions.",
    "descriptor": "\nComments: Accepted by CCL2021\n",
    "authors": [
      "Xin Jia",
      "Hao Wang",
      "Dawei Yin",
      "Yunfang Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10454"
  },
  {
    "id": "arXiv:2106.10456",
    "title": "Humble Teachers Teach Better Students for Semi-Supervised Object  Detection",
    "abstract": "We propose a semi-supervised approach for contemporary object detectors\nfollowing the teacher-student dual model framework. Our method is featured with\n1) the exponential moving averaging strategy to update the teacher from the\nstudent online, 2) using plenty of region proposals and soft pseudo-labels as\nthe student's training targets, and 3) a light-weighted detection-specific data\nensemble for the teacher to generate more reliable pseudo-labels. Compared to\nthe recent state-of-the-art -- STAC, which uses hard labels on sparsely\nselected hard pseudo samples, the teacher in our model exposes richer\ninformation to the student with soft-labels on many proposals. Our model\nachieves COCO-style AP of 53.04% on VOC07 val set, 8.4% better than STAC, when\nusing VOC12 as unlabeled data. On MS-COCO, it outperforms prior work when only\na small percentage of data is taken as labeled. It also reaches 53.8% AP on\nMS-COCO test-dev with 3.1% gain over the fully supervised ResNet-152 Cascaded\nR-CNN, by tapping into unlabeled data of a similar size to the labeled data.",
    "descriptor": "\nComments: CVPR 2021 camera-ready. Code: this https URL\n",
    "authors": [
      "Yihe Tang",
      "Weifeng Chen",
      "Yijun Luo",
      "Yuting Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10456"
  },
  {
    "id": "arXiv:2106.10458",
    "title": "Place recognition survey: An update on deep learning approaches",
    "abstract": "Autonomous Vehicles (AV) are becoming more capable of navigating in complex\nenvironments with dynamic and changing conditions. A key component that enables\nthese intelligent vehicles to overcome such conditions and become more\nautonomous is the sophistication of the perception and localization systems. As\npart of the localization system, place recognition has benefited from recent\ndevelopments in other perception tasks such as place categorization or object\nrecognition, namely with the emergence of deep learning (DL) frameworks. This\npaper surveys recent approaches and methods used in place recognition,\nparticularly those based on deep learning. The contributions of this work are\ntwofold: surveying recent sensors such as 3D LiDARs and RADARs, applied in\nplace recognition; and categorizing the various DL-based place recognition\nworks into supervised, unsupervised, semi-supervised, parallel, and\nhierarchical categories. First, this survey introduces key place recognition\nconcepts to contextualize the reader. Then, sensor characteristics are\naddressed. This survey proceeds by elaborating on the various DL-based works,\npresenting summaries for each framework. Some lessons learned from this survey\ninclude: the importance of NetVLAD for supervised end-to-end learning; the\nadvantages of unsupervised approaches in place recognition, namely for\ncross-domain applications; or the increasing tendency of recent works to seek,\nnot only for higher performance but also for higher efficiency.",
    "descriptor": "\nComments: Under review in IEEE Transactions on Intelligent Vehicles. This work has been submitted on the 13/01/2021 to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Upon acceptance of the article by IEEE, the preprint article will be replaced with the accepted version\n",
    "authors": [
      "Tiago Barros",
      "Ricardo Pereira",
      "Lu\u00eds Garrote",
      "Cristiano Premebida",
      "Urbano J. Nunes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10458"
  },
  {
    "id": "arXiv:2106.10460",
    "title": "XML Signature Wrapping Still Considered Harmful: A Case Study on the  Personal Health Record in Germany",
    "abstract": "XML Signature Wrapping (XSW) has been a relevant threat to web services for\n15 years until today. Using the Personal Health Record (PHR), which is\ncurrently under development in Germany, we investigate a current SOAP-based web\nservices system as a case study. In doing so, we highlight several deficiencies\nin defending against XSW. Using this real-world contemporary example as\nmotivation, we introduce a guideline for more secure XML signature processing\nthat provides practitioners with easier access to the effective countermeasures\nidentified in the current state of research.",
    "descriptor": "\nComments: Accepted for IFIP SEC 2021\n",
    "authors": [
      "Paul H\u00f6ller",
      "Alexander Krumeich",
      "Luigi Lo Iacono"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.10460"
  },
  {
    "id": "arXiv:2106.10464",
    "title": "Prediction of the facial growth direction with Machine Learning methods",
    "abstract": "First attempts of prediction of the facial growth (FG) direction were made\nover half of a century ago. Despite numerous attempts and elapsed time, a\nsatisfactory method has not been established yet and the problem still poses a\nchallenge for medical experts. To our knowledge, this paper is the first\nMachine Learning approach to the prediction of FG direction. Conducted data\nanalysis reveals the inherent complexity of the problem and explains the\nreasons of difficulty in FG direction prediction based on 2D X-ray images. To\nperform growth forecasting, we employ a wide range of algorithms, from logistic\nregression, through tree ensembles to neural networks and consider three,\nslightly different, problem formulations. The resulting classification accuracy\nvaries between 71% and 75%.",
    "descriptor": "",
    "authors": [
      "Stanis\u0142aw Ka\u017amierczak",
      "Zofia Juszka",
      "Piotr Fudalej",
      "Jacek Ma\u0144dziuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10464"
  },
  {
    "id": "arXiv:2106.10465",
    "title": "Interactive Object Segmentation with Dynamic Click Transform",
    "abstract": "In the interactive segmentation, users initially click on the target object\nto segment the main body and then provide corrections on mislabeled regions to\niteratively refine the segmentation masks. Most existing methods transform\nthese user-provided clicks into interaction maps and concatenate them with\nimage as the input tensor. Typically, the interaction maps are determined by\nmeasuring the distance of each pixel to the clicked points, ignoring the\nrelation between clicks and mislabeled regions. We propose a Dynamic Click\nTransform Network~(DCT-Net), consisting of Spatial-DCT and Feature-DCT, to\nbetter represent user interactions. Spatial-DCT transforms each user-provided\nclick with individual diffusion distance according to the target scale, and\nFeature-DCT normalizes the extracted feature map to a specific distribution\npredicted from the clicked points. We demonstrate the effectiveness of our\nproposed method and achieve favorable performance compared to the\nstate-of-the-art on three standard benchmark datasets.",
    "descriptor": "\nComments: This paper was accepted by IEEE International Conference on Image Processing (ICIP) 2021\n",
    "authors": [
      "Chun-Tse Lin",
      "Wei-Chih Tu",
      "Chih-Ting Liu",
      "Shao-Yi Chien"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10465"
  },
  {
    "id": "arXiv:2106.10466",
    "title": "Learning Timestamp-Level Representations for Time Series with  Hierarchical Contrastive Loss",
    "abstract": "This paper presents TS2Vec, a universal framework for learning\ntimestamp-level representations of time series. Unlike existing methods, TS2Vec\nperforms timestamp-wise discrimination, which learns a contextual\nrepresentation vector directly for each timestamp. We find that the learned\nrepresentations have superior predictive ability. A linear regression trained\non top of the learned representations outperforms previous SOTAs for supervised\ntime series forecasting. Also, the instance-level representations can be simply\nobtained by applying a max pooling layer on top of learned representations of\nall timestamps. We conduct extensive experiments on time series classification\ntasks to evaluate the quality of instance-level representations. As a result,\nTS2Vec achieves significant improvement compared with existing SOTAs of\nunsupervised time series representation on 125 UCR datasets and 29 UEA\ndatasets. The source code is publicly available at\nhttps://github.com/yuezhihan/ts2vec.",
    "descriptor": "\nComments: 20 pages, 6 figures\n",
    "authors": [
      "Zhihan Yue",
      "Yujing Wang",
      "Juanyong Duan",
      "Tianmeng Yang",
      "Congrui Huang",
      "Bixiong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10466"
  },
  {
    "id": "arXiv:2106.10468",
    "title": "A Condense-then-Select Strategy for Text Summarization",
    "abstract": "Select-then-compress is a popular hybrid, framework for text summarization\ndue to its high efficiency. This framework first selects salient sentences and\nthen independently condenses each of the selected sentences into a concise\nversion. However, compressing sentences separately ignores the context\ninformation of the document, and is therefore prone to delete salient\ninformation. To address this limitation, we propose a novel\ncondense-then-select framework for text summarization. Our framework first\nconcurrently condenses each document sentence. Original document sentences and\ntheir compressed versions then become the candidates for extraction. Finally,\nan extractor utilizes the context information of the document to select\ncandidates and assembles them into a summary. If salient information is deleted\nduring condensing, the extractor can select an original sentence to retain the\ninformation. Thus, our framework helps to avoid the loss of salient\ninformation, while preserving the high efficiency of sentence-level\ncompression. Experiment results on the CNN/DailyMail, DUC-2002, and Pubmed\ndatasets demonstrate that our framework outperforms the select-then-compress\nframework and other strong baselines.",
    "descriptor": "\nComments: Accepted by Knowledge-Based Systems (KBS) journal\n",
    "authors": [
      "Hou Pong Chan",
      "Irwin King"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10468"
  },
  {
    "id": "arXiv:2106.10470",
    "title": "Isogeometric de Rham complex discretization in solid toroidal domains",
    "abstract": "In this work we define a spline complex preserving the cohomological\nstructure of the continuous de Rham complex when the underlying physical domain\nis a toroidal solid. In the spirit of the isogeometric analysis, the spaces\ninvolved will be defined as pushforward of suitable spline spaces on a\nparametric domain. The singularity of the parametrization of the solid will\ndemand the imposition of smoothness constraints on the full tensor product\nspline spaces in the parametric domain to properly set up the discrete complex\non the physical domain.",
    "descriptor": "\nComments: 39 pages, 16 figures\n",
    "authors": [
      "Francesco Patrizi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10470"
  },
  {
    "id": "arXiv:2106.10471",
    "title": "Neural Network Classifier as Mutual Information Evaluator",
    "abstract": "Cross-entropy loss with softmax output is a standard choice to train neural\nnetwork classifiers. We give a new view of neural network classifiers with\nsoftmax and cross-entropy as mutual information evaluators. We show that when\nthe dataset is balanced, training a neural network with cross-entropy maximises\nthe mutual information between inputs and labels through a variational form of\nmutual information. Thereby, we develop a new form of softmax that also\nconverts a classifier to a mutual information evaluator when the dataset is\nimbalanced. Experimental results show that the new form leads to better\nclassification accuracy, in particular for imbalanced datasets.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1911.10688\n",
    "authors": [
      "Zhenyue Qin",
      "Dongwoo Kim",
      "Tom Gedeon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10471"
  },
  {
    "id": "arXiv:2106.10472",
    "title": "Informative Class Activation Maps",
    "abstract": "We study how to evaluate the quantitative information content of a region\nwithin an image for a particular label. To this end, we bridge class activation\nmaps with information theory. We develop an informative class activation map\n(infoCAM). Given a classification task, infoCAM depict how to accumulate\ninformation of partial regions to that of the entire image toward a label.\nThus, we can utilise infoCAM to locate the most informative features for a\nlabel. When applied to an image classification task, infoCAM performs better\nthan the traditional classification map in the weakly supervised object\nlocalisation task. We achieve state-of-the-art results on Tiny-ImageNet.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1911.10688\n",
    "authors": [
      "Zhenyue Qin",
      "Dongwoo Kim",
      "Tom Gedeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10472"
  },
  {
    "id": "arXiv:2106.10473",
    "title": "Pricing Social Visibility Service in Online Social Networks: Modeling  and Algorithms",
    "abstract": "Online social networks (OSNs) such as YoutTube, Instagram, Twitter, Facebook,\netc., serve as important platforms for users to share their information or\ncontent to friends or followers. Oftentimes, users want to enhance their social\nvisibility, as it can make their contents, i.e., opinions, videos, pictures,\netc., attract attention from more users, which in turn may bring higher\ncommercial benefit to them. Motivated by this, we propose a mechanism, where\nthe OSN operator provides a \"social visibility boosting service\" to incentivize\n\"transactions\" between requesters (users who seek to enhance their social\nvisibility via adding new \"neighbors\") and suppliers (users who are willing to\nbe added as a new \"neighbor\" of any requester when certain \"rewards\" is\nprovided). We design a posted pricing scheme for the OSN provider to charge the\nrequesters who use such boosting service, and reward the suppliers who\ncontribute to such boosting service. The OSN operator keeps a fraction of the\npayment from requesters and distributes the remaining part to participating\nsuppliers \"fairly\" via the Shapley value. The objective of the OSN provider is\nto select the price and supplier set to maximize the total amount of revenue\nunder the budget constraint of requesters. We first show that the revenue\nmaximization problem is not simpler than an NP-hard problem. We then decomposed\nit into two sub-routines, where one focuses on selecting the optimal set of\nsuppliers, and the other one focuses on selecting the optimal price. We prove\nthe hardness of each sub-routine, and eventually design a computationally\nefficient approximation algorithm to solve the revenue maximization problem\nwith provable theoretical guarantee on the revenue gap. We conduct extensive\nexperiments on four public datasets to validate the superior performance of our\nproposed algorithms.",
    "descriptor": "",
    "authors": [
      "Shiyuan Zheng",
      "Hong Xie",
      "John C.S. Lui"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.10473"
  },
  {
    "id": "arXiv:2106.10476",
    "title": "Neural network interpretability for forecasting of aggregated renewable  generation",
    "abstract": "With the rapid growth of renewable energy, lots of small photovoltaic (PV)\nprosumers emerge. Due to the uncertainty of solar power generation, there is a\nneed for aggregated prosumers to predict solar power generation and whether\nsolar power generation will be larger than load. This paper presents two\ninterpretable neural networks to solve the problem: one binary classification\nneural network and one regression neural network. The neural networks are built\nusing TensorFlow. The global feature importance and local feature contributions\nare examined by three gradient-based methods: Integrated Gradients, Expected\nGradients, and DeepLIFT. Moreover, we detect abnormal cases when predictions\nmight fail by estimating the prediction uncertainty using Bayesian neural\nnetworks. Neural networks, which are interpreted by gradient-based methods and\ncomplemented with uncertainty estimation, provide robust and explainable\nforecasting for decision-makers.",
    "descriptor": "",
    "authors": [
      "Yucun Lu",
      "Ilgiz Murzakhanov",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10476"
  },
  {
    "id": "arXiv:2106.10478",
    "title": "Vulnerability Detection with Fine-grained Interpretations",
    "abstract": "Despite the successes of machine learning (ML) and deep learning (DL) based\nvulnerability detectors (VD), they are limited to providing only the decision\non whether a given code is vulnerable or not, without details on what part of\nthe code is relevant to the detected vulnerability. We present IVDetect an\ninterpretable vulnerability detector with the philosophy of using Artificial\nIntelligence (AI) to detect vulnerabilities, while using Intelligence Assistant\n(IA) via providing VD interpretations in terms of vulnerable statements.\nFor vulnerability detection, we separately consider the vulnerable statements\nand their surrounding contexts via data and control dependencies. This allows\nour model better discriminate vulnerable statements than using the mixture of\nvulnerable code and~contextual code as in existing approaches. In addition to\nthe coarse-grained vulnerability detection result, we leverage interpretable AI\nto provide users with fine-grained interpretations that include the sub-graph\nin the Program Dependency Graph (PDG) with the crucial statements that are\nrelevant to the detected vulnerability. Our empirical evaluation on\nvulnerability databases shows that IVDetect outperforms the existing DL-based\napproaches by 43%--84% and 105%--255% in top-10 nDCG and MAP ranking scores.\nIVDetect correctly points out the vulnerable statements relevant to the\nvulnerability via its interpretation~in 67% of the cases with a top-5 ranked\nlist. It improves over baseline interpretation models by 12.3%--400% and\n9%--400% in accuracy.",
    "descriptor": "",
    "authors": [
      "Yi Li",
      "Shaohua Wang",
      "Tien N. Nguyen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.10478"
  },
  {
    "id": "arXiv:2106.10479",
    "title": "Practical Transferability Estimation for Image Classification Tasks",
    "abstract": "Transferability estimation is an essential problem in transfer learning to\npredict how good the performance is when transfer a source model (source task)\nto a target task. Recent analytical transferability metrics have been widely\nused for source model selection and multi-task learning. Earlier metrics does\nnot work sufficiently well under the challenging cross-domain cross-task\ntransfer settings, but recent OTCE score achieves a noteworthy performance\nusing auxiliary tasks. A simplified version named OT-based NCE score sacrifices\naccuracy to be more efficient, but it can be further improved. Consequently, we\npropose a practical transferability metric called JC-NCE score to further\nimprove the cross-domain cross-task transferability estimation performance,\nwhich is more efficient than the OTCE score and more accurate than the OT-based\nNCE score. Specifically, we build the joint correspondences between source and\ntarget data via solving an optimal transport problem with considering both the\nsample distance and label distance, and then compute the transferability score\nas the negative conditional entropy. Extensive validations under the\nintra-dataset and inter-dataset transfer settings demonstrate that our JC-NCE\nscore outperforms the OT-based NCE score with about 7% and 12% gains,\nrespectively.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Yang Tan",
      "Yang Li",
      "Shao-Lun Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10479"
  },
  {
    "id": "arXiv:2106.10481",
    "title": "Advances in Speech Vocoding for Text-to-Speech with Continuous  Parameters",
    "abstract": "Vocoders received renewed attention as main components in statistical\nparametric text-to-speech (TTS) synthesis and speech transformation systems.\nEven though there are vocoding techniques give almost accepted synthesized\nspeech, their high computational complexity and irregular structures are still\nconsidered challenging concerns, which yield a variety of voice quality\ndegradation. Therefore, this paper presents new techniques in a continuous\nvocoder, that is all features are continuous and presents a flexible speech\nsynthesis system. First, a new continuous noise masking based on the phase\ndistortion is proposed to eliminate the perceptual impact of the residual noise\nand letting an accurate reconstruction of noise characteristics. Second, we\naddressed the need of neural sequence to sequence modeling approach for the\ntask of TTS based on recurrent networks. Bidirectional long short-term memory\n(LSTM) and gated recurrent unit (GRU) are studied and applied to model\ncontinuous parameters for more natural-sounding like a human. The evaluation\nresults proved that the proposed model achieves the state-of-the-art\nperformance of the speech synthesis compared with the other traditional\nmethods.",
    "descriptor": "\nComments: 6 pages, 3 figures, International Conference on Artificial Intelligence and Speech Technology (AIST2020)\n",
    "authors": [
      "Mohammed Salah Al-Radhi",
      "Tam\u00e1s G\u00e1bor Csap\u00f3",
      "G\u00e9za N\u00e9meth"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.10481"
  },
  {
    "id": "arXiv:2106.10482",
    "title": "Unbalanced Feature Transport for Exemplar-based Image Translation",
    "abstract": "Despite the great success of GANs in images translation with different\nconditioned inputs such as semantic segmentation and edge maps, generating\nhigh-fidelity realistic images with reference styles remains a grand challenge\nin conditional image-to-image translation. This paper presents a general image\ntranslation framework that incorporates optimal transport for feature alignment\nbetween conditional inputs and style exemplars in image translation. The\nintroduction of optimal transport mitigates the constraint of many-to-one\nfeature matching significantly while building up accurate semantic\ncorrespondences between conditional inputs and exemplars. We design a novel\nunbalanced optimal transport to address the transport between features with\ndeviational distributions which exists widely between conditional inputs and\nexemplars. In addition, we design a semantic-activation normalization scheme\nthat injects style features of exemplars into the image translation process\nsuccessfully. Extensive experiments over multiple image translation tasks show\nthat our method achieves superior image translation qualitatively and\nquantitatively as compared with the state-of-the-art.",
    "descriptor": "\nComments: Accepted to CVPR 2021\n",
    "authors": [
      "Fangneng Zhan",
      "Yingchen Yu",
      "Kaiwen Cui",
      "Gongjie Zhang",
      "Shijian Lu",
      "Jianxiong Pan",
      "Changgong Zhang",
      "Feiying Ma",
      "Xuansong Xie",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10482"
  },
  {
    "id": "arXiv:2106.10485",
    "title": "Hybrid approach to detecting symptoms of depression in social media  entries",
    "abstract": "Sentiment and lexical analyses are widely used to detect depression or\nanxiety disorders. It has been documented that there are significant\ndifferences in the language used by a person with emotional disorders in\ncomparison to a healthy individual. Still, the effectiveness of these lexical\napproaches could be improved further because the current analysis focuses on\nwhat the social media entries are about, and not how they are written. In this\nstudy, we focus on aspects in which these short texts are similar to each\nother, and how they were created. We present an innovative approach to the\ndepression screening problem by applying Collgram analysis, which is a known\neffective method of obtaining linguistic information from texts. We compare\nthese results with sentiment analysis based on the BERT architecture. Finally,\nwe create a hybrid model achieving a diagnostic accuracy of 71%.",
    "descriptor": "\nComments: 11 pages, 4 figures, 2 tables, The Pacific Asia Conference on Information Systems (PACIS2021)\n",
    "authors": [
      "Agnieszka Wo\u0142k",
      "Karol Chlasta",
      "Pawe\u0142 Holas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10485"
  },
  {
    "id": "arXiv:2106.10486",
    "title": "CompConv: A Compact Convolution Module for Efficient Feature Learning",
    "abstract": "Convolutional Neural Networks (CNNs) have achieved remarkable success in\nvarious computer vision tasks but rely on tremendous computational cost. To\nsolve this problem, existing approaches either compress well-trained\nlarge-scale models or learn lightweight models with carefully designed network\nstructures. In this work, we make a close study of the convolution operator,\nwhich is the basic unit used in CNNs, to reduce its computing load. In\nparticular, we propose a compact convolution module, called CompConv, to\nfacilitate efficient feature learning. With the divide-and-conquer strategy,\nCompConv is able to save a great many computations as well as parameters to\nproduce a certain dimensional feature map. Furthermore, CompConv discreetly\nintegrates the input features into the outputs to efficiently inherit the input\ninformation. More importantly, the novel CompConv is a plug-and-play module\nthat can be directly applied to modern CNN structures to replace the vanilla\nconvolution layers without further effort. Extensive experimental results\nsuggest that CompConv can adequately compress the benchmark CNN structures yet\nbarely sacrifice the performance, surpassing other competitors.",
    "descriptor": "",
    "authors": [
      "Chen Zhang",
      "Yinghao Xu",
      "Yujun Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10486"
  },
  {
    "id": "arXiv:2106.10487",
    "title": "Transformers for Headline Selection for Russian News Clusters",
    "abstract": "In this paper, we explore various multilingual and Russian pre-trained\ntransformer-based models for the Dialogue Evaluation 2021 shared task on\nheadline selection. Our experiments show that the combined approach is superior\nto individual multilingual and monolingual models. We present an analysis of a\nnumber of ways to obtain sentence embeddings and learn a ranking model on top\nof them. We achieve the result of 87.28% and 86.60% accuracy for the public and\nprivate test sets respectively.",
    "descriptor": "\nComments: Accepted to Dialogue 2021 conference\n",
    "authors": [
      "Pavel Voropaev",
      "Olga Sopilnyak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10487"
  },
  {
    "id": "arXiv:2106.10492",
    "title": "Comparison Theorems for Splittings of M-matrices in (block) Hessenberg  Form",
    "abstract": "Some variants of the (block) Gauss-Seidel iteration for the solution of\nlinear systems with $M$-matrices in (block) Hessenberg form are discussed.\nComparison results for the asymptotic convergence rate of some regular\nsplittings are derived: in particular, we prove that for a lower-Hessenberg\nM-matrix $\\rho(P_{GS})\\geq \\rho(P_S)\\geq \\rho(P_{AGS})$, where $P_{GS}, P_S,\nP_{AGS}$ are the iteration matrices of the Gauss-Seidel, staircase, and\nanti-Gauss-Seidel method. This is a result that does not seem to follow from\nclassical comparison results, as these splittings are not directly comparable.\nIt is shown that the concept of stair partitioning provides a powerful tool for\nthe design of new variants that are suited for parallel computation.",
    "descriptor": "",
    "authors": [
      "Luca Gemignani",
      "Federico Poloni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10492"
  },
  {
    "id": "arXiv:2106.10493",
    "title": "CenterAtt: Fast 2-stage Center Attention Network",
    "abstract": "In this technical report, we introduce the methods of HIKVISION_LiDAR_Det in\nthe challenge of waymo open dataset real-time 3D detection. Our solution for\nthe competition are built upon Centerpoint 3D detection framework. Several\nvariants of CenterPoint are explored, including center attention head and\nfeature pyramid network neck. In order to achieve real time detection, methods\nlike batchnorm merge, half-precision floating point network and GPU-accelerated\nvoxelization process are adopted. By using these methods, our team ranks 6th\namong all the methods on real-time 3D detection challenge in the waymo open\ndataset.",
    "descriptor": "",
    "authors": [
      "Jianyun Xu",
      "Xin Tang",
      "Jian Dou",
      "Xu Shu",
      "Yushi Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10493"
  },
  {
    "id": "arXiv:2106.10494",
    "title": "Teacher's pet: understanding and mitigating biases in distillation",
    "abstract": "Knowledge distillation is widely used as a means of improving the performance\nof a relatively simple student model using the predictions from a complex\nteacher model. Several works have shown that distillation significantly boosts\nthe student's overall performance; however, are these gains uniform across all\ndata subgroups? In this paper, we show that distillation can harm performance\non certain subgroups, e.g., classes with few associated samples. We trace this\nbehaviour to errors made by the teacher distribution being transferred to and\namplified by the student model. To mitigate this problem, we present techniques\nwhich soften the teacher influence for subgroups where it is less reliable.\nExperiments on several image classification benchmarks show that these\nmodifications of distillation maintain boost in overall accuracy, while\nadditionally ensuring improvement in subgroup performance.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Michal Lukasik",
      "Srinadh Bhojanapalli",
      "Aditya Krishna Menon",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10494"
  },
  {
    "id": "arXiv:2106.10499",
    "title": "Evaluating Spatial Accelerator Architectures with Tiled Matrix-Matrix  Multiplication",
    "abstract": "There is a growing interest in custom spatial accelerators for machine\nlearning applications. These accelerators employ a spatial array of processing\nelements (PEs) interacting via custom buffer hierarchies and networks-on-chip.\nThe efficiency of these accelerators comes from employing optimized dataflow\n(i.e., spatial/temporal partitioning of data across the PEs and fine-grained\nscheduling) strategies to optimize data reuse. The focus of this work is to\nevaluate these accelerator architectures using a tiled general matrix-matrix\nmultiplication (GEMM) kernel. To do so, we develop a framework that finds\noptimized mappings (dataflow and tile sizes) for a tiled GEMM for a given\nspatial accelerator and workload combination, leveraging an analytical cost\nmodel for runtime and energy. Our evaluations over five spatial accelerators\ndemonstrate that the tiled GEMM mappings systematically generated by our\nframework achieve high performance on various GEMM workloads and accelerators.",
    "descriptor": "",
    "authors": [
      "Gordon E. Moon",
      "Hyoukjun Kwon",
      "Geonhwa Jeong",
      "Prasanth Chatarasi",
      "Sivasankaran Rajamanickam",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.10499"
  },
  {
    "id": "arXiv:2106.10502",
    "title": "JointGT: Graph-Text Joint Representation Learning for Text Generation  from Knowledge Graphs",
    "abstract": "Existing pre-trained models for knowledge-graph-to-text (KG-to-text)\ngeneration simply fine-tune text-to-text pre-trained models such as BART or T5\non KG-to-text datasets, which largely ignore the graph structure during\nencoding and lack elaborate pre-training tasks to explicitly model graph-text\nalignments. To tackle these problems, we propose a graph-text joint\nrepresentation learning model called JointGT. During encoding, we devise a\nstructure-aware semantic aggregation module which is plugged into each\nTransformer layer to preserve the graph structure. Furthermore, we propose\nthree new pre-training tasks to explicitly enhance the graph-text alignment\nincluding respective text / graph reconstruction, and graph-text alignment in\nthe embedding space via Optimal Transport. Experiments show that JointGT\nobtains new state-of-the-art performance on various KG-to-text datasets.",
    "descriptor": "\nComments: ACL 2021 (Findings)\n",
    "authors": [
      "Pei Ke",
      "Haozhe Ji",
      "Yu Ran",
      "Xin Cui",
      "Liwei Wang",
      "Linfeng Song",
      "Xiaoyan Zhu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10502"
  },
  {
    "id": "arXiv:2106.10506",
    "title": "Exploring Visual Context for Weakly Supervised Person Search",
    "abstract": "Person search has recently emerged as a challenging task that jointly\naddresses pedestrian detection and person re-identification. Existing\napproaches follow a fully supervised setting where both bounding box and\nidentity annotations are available. However, annotating identities is\nlabor-intensive, limiting the practicability and scalability of current\nframeworks. This paper inventively considers weakly supervised person search\nwith only bounding box annotations. We proposed the first framework to address\nthis novel task, namely Context-Guided Person Search (CGPS), by investigating\nthree levels of context clues (i.e., detection, memory and scene) in\nunconstrained natural images. The first two are employed to promote local and\nglobal discriminative capabilities, while the latter enhances clustering\naccuracy. Despite its simple design, our CGPS boosts the baseline model by 8.3%\nin mAP on CUHK-SYSU. Surprisingly, it even achieves comparable performance to\ntwo-step person search models, while displaying higher efficiency. Our code is\navailable at https://github.com/ljpadam/CGPS.",
    "descriptor": "",
    "authors": [
      "Yichao Yan",
      "Jinpeng Li",
      "Shengcai Liao",
      "Jie Qin",
      "Bingbing Ni",
      "Xiaokang Yang",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10506"
  },
  {
    "id": "arXiv:2106.10507",
    "title": "GLIB: Towards Automated Test Oracle for Graphically-Rich Applications",
    "abstract": "Graphically-rich applications such as games are ubiquitous with attractive\nvisual effects of Graphical User Interface (GUI) that offers a bridge between\nsoftware applications and end-users. However, various types of graphical\nglitches may arise from such GUI complexity and have become one of the main\ncomponent of software compatibility issues. Our study on bug reports from game\ndevelopment teams in NetEase Inc. indicates that graphical glitches frequently\noccur during the GUI rendering and severely degrade the quality of\ngraphically-rich applications such as video games. Existing automated testing\ntechniques for such applications focus mainly on generating various GUI test\nsequences and check whether the test sequences can cause crashes. These\ntechniques require constant human attention to captures non-crashing bugs such\nas bugs causing graphical glitches. In this paper, we present the first step in\nautomating the test oracle for detecting non-crashing bugs in graphically-rich\napplications. Specifically, we propose \\texttt{GLIB} based on a code-based data\naugmentation technique to detect game GUI glitches. We perform an evaluation of\n\\texttt{GLIB} on 20 real-world game apps (with bug reports available) and the\nresult shows that \\texttt{GLIB} can achieve 100\\% precision and 99.5\\% recall\nin detecting non-crashing bugs such as game GUI glitches. Practical application\nof \\texttt{GLIB} on another 14 real-world games (without bug reports) further\ndemonstrates that \\texttt{GLIB} can effectively uncover GUI glitches, with 48\nof 53 bugs reported by \\texttt{GLIB} having been confirmed and fixed so far.",
    "descriptor": "\nComments: Accepted by ESEC/FSE 2021\n",
    "authors": [
      "Ke Chen",
      "Yufei Li",
      "Yingfeng Chen",
      "Changjie Fan",
      "Zhipeng Hu",
      "Wei Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10507"
  },
  {
    "id": "arXiv:2106.10512",
    "title": "TweeNLP: A Twitter Exploration Portal for Natural Language Processing",
    "abstract": "We present TweeNLP, a one-stop portal that organizes Twitter's natural\nlanguage processing (NLP) data and builds a visualization and exploration\nplatform. It curates 19,395 tweets (as of April 2021) from various NLP\nconferences and general NLP discussions. It supports multiple features such as\nTweetExplorer to explore tweets by topics, visualize insights from Twitter\nactivity throughout the organization cycle of conferences, discover popular\nresearch papers and researchers. It also builds a timeline of conference and\nworkshop submission deadlines. We envision TweeNLP to function as a collective\nmemory unit for the NLP community by integrating the tweets pertaining to\nresearch papers with the NLPExplorer scientific literature search engine. The\ncurrent system is hosted at this http URL .",
    "descriptor": "\nComments: ACL-IJCNLP Demo Track 2021\n",
    "authors": [
      "Viraj Shah",
      "Shruti Singh",
      "Mayank Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.10512"
  },
  {
    "id": "arXiv:2106.10514",
    "title": "Cooperative Evasion by Translating Targets with Variable Speeds",
    "abstract": "We consider a problem of cooperative evasion between a single pursuer and\nmultiple evaders in which the evaders are constrained to move in the positive Y\ndirection. The evaders are slower than the vehicle and can choose their speeds\nfrom a bounded interval. The pursuer aims to intercept all evaders in a given\nsequence by executing a Manhattan pursuit strategy of moving parallel to the X\naxis, followed by moving parallel to the Y axis. The aim of the evaders is to\ncooperatively pick their individual speeds so that the total time to intercept\nall evaders is maximized. We first obtain conditions under which evaders should\ncooperate in order to maximize the total time to intercept as opposed to each\nmoving greedily to optimize its own intercept time. Then, we propose and\nanalyze an algorithm that assigns evasive strategies to the evaders in two\niterations as opposed to performing an exponential search over the choice of\nevader speeds. We also characterize a fundamental limit on the total time taken\nby the pursuer to capture all evaders when the number of evaders is large.\nFinally, we provide numerical comparisons against random sampling heuristics.",
    "descriptor": "",
    "authors": [
      "Shivam Bajaj",
      "Eloy Garcia",
      "Shaunak D. Bopardikar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10514"
  },
  {
    "id": "arXiv:2106.10515",
    "title": "A Generic Distributed Clustering Framework for Massive Data",
    "abstract": "In this paper, we introduce a novel Generic distributEd clustEring frameworK\n(GEEK) beyond $k$-means clustering to process massive amounts of data. To deal\nwith different data types, GEEK first converts data in the original feature\nspace into a unified format of buckets; then, we design a new Seeding method\nbased on simILar bucKets (SILK) to determine initial seeds. Compared with\nstate-of-the-art seeding methods such as $k$-means++ and its variants, SILK can\nautomatically identify the number of initial seeds based on the closeness of\nshared data objects in similar buckets instead of pre-specifying $k$. Thus, its\ntime complexity is independent of $k$. With these well-selected initial seeds,\nGEEK only needs a one-pass data assignment to get the final clusters. We\nimplement GEEK on a distributed CPU-GPU platform for large-scale clustering. We\nevaluate the performance of GEEK over five large-scale real-life datasets and\nshow that GEEK can deal with massive data of different types and is comparable\nto (or even better than) many state-of-the-art customized GPU-based methods,\nespecially in large $k$ values.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Pingyi Luo",
      "Qiang Huang",
      "Anthony K. H. Tung"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.10515"
  },
  {
    "id": "arXiv:2106.10516",
    "title": "DiffLoop: Tuning PID controllers by differentiating through the feedback  loop",
    "abstract": "Since most industrial control applications use PID controllers, PID tuning\nand anti-windup measures are significant problems. This paper investigates\ntuning the feedback gains of a PID controller via back-calculation and\nautomatic differentiation tools. In particular, we episodically use a cost\nfunction to generate gradients and perform gradient descent to improve\ncontroller performance. We provide a theoretical framework for analyzing this\nnon-convex optimization and establish a relationship between back-calculation\nand disturbance feedback policies. We include numerical experiments on linear\nsystems with actuator saturation to show the efficacy of this approach.",
    "descriptor": "\nComments: Extension of paper in 2021 55th Annual Conference on Information Sciences and Systems (CISS). IEEE, 2021\n",
    "authors": [
      "Athindran Ramesh Kumar",
      "Peter J. Ramadge"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10516"
  },
  {
    "id": "arXiv:2106.10517",
    "title": "A Max-Min Entropy Framework for Reinforcement Learning",
    "abstract": "In this paper, we propose a max-min entropy framework for reinforcement\nlearning (RL) to overcome the limitation of the maximum entropy RL framework in\nmodel-free sample-based learning. Whereas the maximum entropy RL framework\nguides learning for policies to reach states with high entropy in the future,\nthe proposed max-min entropy framework aims to learn to visit states with low\nentropy and maximize the entropy of these low-entropy states to promote\nexploration. For general Markov decision processes (MDPs), an efficient\nalgorithm is constructed under the proposed max-min entropy framework based on\ndisentanglement of exploration and exploitation. Numerical results show that\nthe proposed algorithm yields drastic performance improvement over the current\nstate-of-the-art RL algorithms.",
    "descriptor": "\nComments: Submitted to NIPS 2021\n",
    "authors": [
      "Seungyul Han",
      "Youngchul Sung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10517"
  },
  {
    "id": "arXiv:2106.10523",
    "title": "Learning Rays via Deep Neural Network in a Ray-based IPDG Method for  High-Frequency Helmholtz Equations in Inhomogeneous Media",
    "abstract": "We develop a deep learning approach to extract ray directions at discrete\nlocations by analyzing highly oscillatory wave fields. A deep neural network is\ntrained on a set of local plane-wave fields to predict ray directions at\ndiscrete locations. The resulting deep neural network is then applied to a\nreduced-frequency Helmholtz solution to extract the directions, which are\nfurther incorporated into a ray-based interior-penalty discontinuous Galerkin\n(IPDG) method to solve the Helmholtz equations at higher frequencies. In this\nway, we observe no apparent pollution effects in the resulting Helmholtz\nsolutions in inhomogeneous media. Our 2D and 3D numerical results show that the\nproposed scheme is very efficient and yields highly accurate solutions.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Tak Shing Au Yeung",
      "Ka Chun Cheung",
      "Eric T. Chung",
      "Shubin Fu",
      "Jianliang Qian"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10523"
  },
  {
    "id": "arXiv:2106.10524",
    "title": "Test case prioritization using test case diversification and  fault-proneness estimations",
    "abstract": "Context: Regression testing activities greatly reduce the risk of faulty\nsoftware release. However, the size of the test suites grows throughout the\ndevelopment process, resulting in time-consuming execution of the test suite\nand delayed feedback to the software development team. This has urged the need\nfor approaches such as test case prioritization (TCP) and test-suite reduction\nto reach better results in case of limited resources. In this regard, proposing\napproaches that use bug history can be interesting.\nObjective: Our aim is to propose an approach for TCP that takes into account\ntest case coverage data, bug history, and test case diversification. To\nevaluate this approach we study its performance on real-world open-source\nprojects.\nMethod: The bug history is used to estimate the fault-proneness of source\ncode areas. The diversification of test cases is preserved by incorporating\nfault-proneness on a clustering-based approach scheme.\nResults: The proposed methods are evaluated on datasets collected from the\ndevelopment history of five real-world projects including 357 versions in\ntotal. The experiments show that the proposed methods are superior to\ncoverage-based TCP methods.\nConclusion: The proposed approach shows that improvement of coverage-based\nand fault-proneness based methods is possible by using a combination of\ndiversification and fault-proneness incorporation.",
    "descriptor": "",
    "authors": [
      "Mostafa Mahdieh",
      "Seyed-Hassan Mirian-Hosseinabadi",
      "Mohsen Mahdieh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.10524"
  },
  {
    "id": "arXiv:2106.10526",
    "title": "Stability of Graph Convolutional Neural Networks to Stochastic  Perturbations",
    "abstract": "Graph convolutional neural networks (GCNNs) are nonlinear processing tools to\nlearn representations from network data. A key property of GCNNs is their\nstability to graph perturbations. Current analysis considers deterministic\nperturbations but fails to provide relevant insights when topological changes\nare random. This paper investigates the stability of GCNNs to stochastic graph\nperturbations induced by link losses. In particular, it proves the expected\noutput difference between the GCNN over random perturbed graphs and the GCNN\nover the nominal graph is upper bounded by a factor that is linear in the link\nloss probability. We perform the stability analysis in the graph spectral\ndomain such that the result holds uniformly for any graph. This result also\nshows the role of the nonlinearity and the architecture width and depth, and\nallows identifying handle to improve the GCNN robustness. Numerical simulations\non source localization and robot swarm control corroborate our theoretical\nfindings.",
    "descriptor": "",
    "authors": [
      "Zhan Gao",
      "Elvin Isufi",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10526"
  },
  {
    "id": "arXiv:2106.10528",
    "title": "Video Summarization through Reinforcement Learning with a 3D  Spatio-Temporal U-Net",
    "abstract": "Intelligent video summarization algorithms allow to quickly convey the most\nrelevant information in videos through the identification of the most essential\nand explanatory content while removing redundant video frames. In this paper,\nwe introduce the 3DST-UNet-RL framework for video summarization. A 3D\nspatio-temporal U-Net is used to efficiently encode spatio-temporal information\nof the input videos for downstream reinforcement learning (RL). An RL agent\nlearns from spatio-temporal latent scores and predicts actions for keeping or\nrejecting a video frame in a video summary. We investigate if real/inflated 3D\nspatio-temporal CNN features are better suited to learn representations from\nvideos than commonly used 2D image features. Our framework can operate in both,\na fully unsupervised mode and a supervised training mode. We analyse the impact\nof prescribed summary lengths and show experimental evidence for the\neffectiveness of 3DST-UNet-RL on two commonly used general video summarization\nbenchmarks. We also applied our method on a medical video summarization task.\nThe proposed video summarization method has the potential to save storage costs\nof ultrasound screening videos as well as to increase efficiency when browsing\npatient video data during retrospective analysis or audit without loosing\nessential information",
    "descriptor": "",
    "authors": [
      "Tianrui Liu",
      "Qingjie Meng",
      "Jun-Jie Huang",
      "Athanasios Vlontzos",
      "Daniel Rueckert",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10528"
  },
  {
    "id": "arXiv:2106.10529",
    "title": "Graph Neural Networks for Learning Real-Time Prices in Electricity  Market",
    "abstract": "Solving the optimal power flow (OPF) problem in real-time electricity market\nimproves the efficiency and reliability in the integration of low-carbon energy\nresources into the power grids. To address the scalability and adaptivity\nissues of existing end-to-end OPF learning solutions, we propose a new graph\nneural network (GNN) framework for predicting the electricity market prices\nfrom solving OPFs. The proposed GNN-for-OPF framework innovatively exploits the\nlocality property of prices and introduces physics-aware regularization, while\nattaining reduced model complexity and fast adaptivity to varying grid\ntopology. Numerical tests have validated the learning efficiency and adaptivity\nimprovements of our proposed method over existing approaches.",
    "descriptor": "",
    "authors": [
      "Shaohui Liu",
      "Chengyang Wu",
      "Hao Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10529"
  },
  {
    "id": "arXiv:2106.10532",
    "title": "QUBO transformation using Eigenvalue Decomposition",
    "abstract": "Quadratic Unconstrained Binary Optimization (QUBO) is a general-purpose\nmodeling framework for combinatorial optimization problems and is a requirement\nfor quantum annealers. This paper utilizes the eigenvalue decomposition of the\nunderlying Q matrix to alter and improve the search process by extracting the\ninformation from dominant eigenvalues and eigenvectors to implicitly guide the\nsearch towards promising areas of the solution landscape. Computational results\non benchmark datasets illustrate the efficacy of our routine demonstrating\nsignificant performance improvements on problems with dominant eigenvalues.",
    "descriptor": "\nComments: Preprint submitted to Springer\n",
    "authors": [
      "Amit Verma",
      "Mark Lewis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2106.10532"
  },
  {
    "id": "arXiv:2106.10533",
    "title": "Learning to Reach, Swim, Walk and Fly in One Trial: Data-Driven Control  with Scarce Data and Side Information",
    "abstract": "We develop a learning-based control algorithm for unknown dynamical systems\nunder very severe data limitations. Specifically, the algorithm has access to\nstreaming data only from a single and ongoing trial. Despite the scarcity of\ndata, we show -- through a series of examples -- that the algorithm can provide\nperformance comparable to reinforcement learning algorithms trained over\nmillions of environment interactions. It accomplishes such performance by\neffectively leveraging various forms of side information on the dynamics to\nreduce the sample complexity. Such side information typically comes from\nelementary laws of physics and qualitative properties of the system. More\nprecisely, the algorithm approximately solves an optimal control problem\nencoding the system's desired behavior. To this end, it constructs and refines\na differential inclusion that contains the unknown vector field of the\ndynamics. The differential inclusion, used in an interval Taylor-based method,\nenables to over-approximate the set of states the system may reach.\nTheoretically, we establish a bound on the suboptimality of the approximate\nsolution with respect to the case of known dynamics. We show that the longer\nthe trial or the more side information is available, the tighter the bound.\nEmpirically, experiments in a high-fidelity F-16 aircraft simulator and\nMuJoCo's environments such as the Reacher, Swimmer, and Cheetah illustrate the\nalgorithm's effectiveness.",
    "descriptor": "\nComments: Initial submission to CoRL 2021\n",
    "authors": [
      "Franck Djeumou",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10533"
  },
  {
    "id": "arXiv:2106.10534",
    "title": "The nonzero gain coefficients of Sobol's sequences are always powers of  two",
    "abstract": "When a plain Monte Carlo estimate on $n$ samples has variance $\\sigma^2/n$,\nthen scrambled digital nets attain a variance that is $o(1/n)$ as $n\\to\\infty$.\nFor finite $n$ and an adversarially selected integrand, the variance of a\nscrambled $(t,m,s)$-net can be at most $\\Gamma\\sigma^2/n$ for a maximal gain\ncoefficient $\\Gamma<\\infty$. The most widely used digital nets and sequences\nare those of Sobol'. It was previously known that $\\Gamma\\leqslant 2^t3^s$ for\nSobol' points as well as Niederreiter-Xing points. In this paper we study nets\nin base $2$. We show that $\\Gamma \\leqslant2^{t+s-1}$ for nets. This bound is a\nsimple, but apparently unnoticed, consequence of a microstructure analysis in\nNiederreiter and Pirsic (2001). We obtain a sharper bound that is smaller than\nthis for some digital nets. We also show that all nonzero gain coefficients\nmust be powers of two. A consequence of this latter fact is a simplified\nalgorithm for computing gain coefficients of nets in base $2$.",
    "descriptor": "",
    "authors": [
      "Zexin Pan",
      "Art B. Owen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.10534"
  },
  {
    "id": "arXiv:2106.10535",
    "title": "Learning and Generalization in Overparameterized Normalizing Flows",
    "abstract": "In supervised learning, it is known that overparameterized neural networks\nwith one hidden layer provably and efficiently learn and generalize, when\ntrained using stochastic gradient descent with sufficiently small learning rate\nand suitable initialization. In contrast, the benefit of overparameterization\nin unsupervised learning is not well understood. Normalizing flows (NFs)\nconstitute an important class of models in unsupervised learning for sampling\nand density estimation. In this paper, we theoretically and empirically analyze\nthese models when the underlying neural network is one-hidden-layer\noverparameterized network. Our main contributions are two-fold: (1) On the one\nhand, we provide theoretical and empirical evidence that for a class of NFs\ncontaining most of the existing NF models, overparametrization hurts training.\n(2) On the other hand, we prove that unconstrained NFs, a recently introduced\nmodel, can efficiently learn any reasonable data distribution under minimal\nassumptions when the underlying network is overparametrized.",
    "descriptor": "\nComments: 80 pages, 79 figures\n",
    "authors": [
      "Kulin Shah",
      "Amit Deshpande",
      "Navin Goyal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10535"
  },
  {
    "id": "arXiv:2106.10540",
    "title": "Simultaneous Suspension Control and Energy Harvesting through Novel  Design and Control of a New Nonlinear Energy Harvesting Shock Absorber",
    "abstract": "Simultaneous vibration control and energy harvesting of vehicle suspensions\nhave attracted significant research attention over the past decades. However,\nexisting energy harvesting shock absorbers (EHSAs) are mainly designed based on\nthe principle of linear resonance, thereby compromising suspension performance\nfor high-efficiency energy harvesting and being only responsive to narrow\nbandwidth vibrations. In this paper, we propose a new EHSA design -- inerter\npendulum vibration absorber (IPVA) -- that integrates an electromagnetic rotary\nEHSA with a nonlinear pendulum vibration absorber. We show that this design\nsimultaneously improves ride comfort and energy harvesting efficiency by\nexploiting the nonlinear effects of pendulum inertia. To further improve the\nperformance, we develop a novel stochastic linearization model predictive\ncontrol (SL-MPC) approach in which we employ stochastic linearization to\napproximate the nonlinear dynamics of EHSA that has superior accuracy compared\nto standard linearization. In particular, we develop a new stochastic\nlinearization method with guaranteed stabilizability, which is a prerequisite\nfor control designs. This leads to an MPC problem that is much more\ncomputationally efficient than the nonlinear MPC counterpart with no major\nperformance degradation. Extensive simulations are performed to show the\nsuperiority of the proposed new nonlinear EHSA and to demonstrate the efficacy\nof the proposed SL-MPC.",
    "descriptor": "",
    "authors": [
      "Mohammad R. Hajidavalloo",
      "Joel Cosner",
      "Zhaojian Li",
      "Wei-Che Tai",
      "Ziyou Song"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10540"
  },
  {
    "id": "arXiv:2106.10541",
    "title": "Checking whether a word is Hamming-isometric in linear time",
    "abstract": "A finite word $f$ is Hamming-isometric if for any two word $u$ and $v$ of\nsame length avoiding $f$, $u$ can be transformed into $v$ by changing one by\none all the letters on which $u$ differs from $v$, in such a way that all of\nthe new words obtained in this process also avoid~$f$. Words which are not\nHamming-isometric have been characterized as words having a border with two\nmismatches. We derive from this characterization a linear-time algorithm to\ncheck whether a word is Hamming-isometric. It is based on pattern matching\nalgorithms with $k$ mismatches. Lee-isometric words over a four-letter alphabet\nhave been characterized as words having a border with two Lee-errors. We derive\nfrom this characterization a linear-time algorithm to check whether a word over\nan alphabet of size four is Lee-isometric.",
    "descriptor": "",
    "authors": [
      "Marie-Pierre B\u00e9al",
      "Maxime Crochemore"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.10541"
  },
  {
    "id": "arXiv:2106.10544",
    "title": "Learning Space Partitions for Path Planning",
    "abstract": "Path planning, the problem of efficiently discovering high-reward\ntrajectories, often requires optimizing a high-dimensional and multimodal\nreward function. Popular approaches like CEM and CMA-ES greedily focus on\npromising regions of the search space and may get trapped in local maxima. DOO\nand VOOT balance exploration and exploitation, but use space partitioning\nstrategies independent of the reward function to be optimized. Recently, LaMCTS\nempirically learns to partition the search space in a reward-sensitive manner\nfor black-box optimization. In this paper, we develop a novel formal regret\nanalysis for when and why such an adaptive region partitioning scheme works. We\nalso propose a new path planning method PlaLaM which improves the function\nvalue estimation within each sub-region, and uses a latent representation of\nthe search space. Empirically, PlaLaM outperforms existing path planning\nmethods in 2D navigation tasks, especially in the presence of\ndifficult-to-escape local optima, and shows benefits when plugged into\nmodel-based RL with planning components such as PETS. These gains transfer to\nhighly multimodal real-world tasks, where we outperform strong baselines in\ncompiler phase ordering by up to 245% and in molecular design by up to 0.4 on\nproperties on a 0-1 scale.",
    "descriptor": "\nComments: Under submission to NeurIPS 2021\n",
    "authors": [
      "Kevin Yang",
      "Tianjun Zhang",
      "Chris Cummins",
      "Brandon Cui",
      "Benoit Steiner",
      "Linnan Wang",
      "Joseph E. Gonzalez",
      "Dan Klein",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10544"
  },
  {
    "id": "arXiv:2106.10547",
    "title": "Leveraging Multiple Online Sources for Accurate Income Verification",
    "abstract": "Income verification is the problem of validating a person's stated income\ngiven basic identity information such as name, location, job title and\nemployer. It is widely used in the context of mortgage lending, rental\napplications and other financial risk models. However, the current processes\nsurrounding verification involve significant human effort and document\ngathering which can be both time-consuming and expensive. In this paper, we\npropose a novel model for verifying an individual's income given very limited\nidentity information typically available in loan applications. Our model is a\ncombination of a deep neural network and hand-engineered features. The hand\nengineered features are based upon matching the input information against\nincome records extracted automatically from various publicly available online\nsources (e.g. payscale.com, H-1B filings, government employee salaries). We\nconduct experiments on two data sets, one simulated from H-1B records and the\nother from a real-world data set of peer-to-peer (P2P) loan applications\nobtained from one of the world's largest P2P lending platform. Our results show\na significant reduction in error of 3-6% relative to several strong baselines.\nWe also perform ablation studies to demonstrate that a combined model is indeed\nnecessary to achieve state-of-the-art performance on this task.",
    "descriptor": "",
    "authors": [
      "Chirag Mahapatra",
      "Kedar Bellare"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.10547"
  },
  {
    "id": "arXiv:2106.10548",
    "title": "VQA-Aid: Visual Question Answering for Post-Disaster Damage Assessment  and Analysis",
    "abstract": "Visual Question Answering system integrated with Unmanned Aerial Vehicle\n(UAV) has a lot of potentials to advance the post-disaster damage assessment\npurpose. Providing assistance to affected areas is highly dependent on\nreal-time data assessment and analysis. Scope of the Visual Question Answering\nis to understand the scene and provide query related answer which certainly\nfaster the recovery process after any disaster. In this work, we address the\nimportance of \\textit{visual question answering (VQA)} task for post-disaster\ndamage assessment by presenting our recently developed VQA dataset called\n\\textit{HurMic-VQA} collected during hurricane Michael, and comparing the\nperformances of baseline VQA models.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Argho Sarkar",
      "Maryam Rahnemoonfar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10548"
  },
  {
    "id": "arXiv:2106.10562",
    "title": "Score-Based Explanations in Data Management and Machine Learning: An  Answer-Set Programming Approach to Counterfactual Analysis",
    "abstract": "We describe some recent approaches to score-based explanations for query\nanswers in databases and outcomes from classification models in machine\nlearning. The focus is on work done by the author and collaborators. Special\nemphasis is placed on declarative approaches based on answer-set programming to\nthe use of counterfactual reasoning for score specification and computation.\nSeveral examples that illustrate the flexibility of these methods are shown.",
    "descriptor": "\nComments: Paper associated to forthcoming short course at Fall School. arXiv admin note: text overlap with arXiv:2007.12799\n",
    "authors": [
      "Leopoldo Bertossi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.10562"
  },
  {
    "id": "arXiv:2106.10563",
    "title": "gazel: Supporting Source Code Edits in Eye-Tracking Studies",
    "abstract": "Eye tracking tools are used in software engineering research to study various\nsoftware development activities. However, a major limitation of these tools is\ntheir inability to track gaze data for activities that involve source code\nediting. We present a novel solution to support eye tracking experiments for\ntasks involving source code edits as an extension of the iTrace community\ninfrastructure. We introduce the iTrace-Atom plugin and gazel -- a Python data\nprocessing pipeline that maps gaze information to changing source code elements\nand provides researchers with a way to query this dynamic data. iTrace-Atom is\nevaluated via a series of simulations and is over 99% accurate at high\neye-tracking speeds of over 1,000Hz. iTrace and gazel completely revolutionize\nthe way eye tracking studies are conducted in realistic settings with the\npresence of scrolling, context switching, and now editing. This opens the doors\nto support many day-to-day software engineering tasks such as bug fixing,\nadding new features, and refactoring.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Sarah Fakhoury",
      "Devjeet Roy",
      "Harry Pines",
      "Tyler Cleveland",
      "Cole Peterson",
      "Venera Arnaoudova",
      "Bonita Sharif",
      "Jonathan Maletic"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.10563"
  },
  {
    "id": "arXiv:2106.10566",
    "title": "Accelerated Policy Evaluation: Learning Adversarial Environments with  Adaptive Importance Sampling",
    "abstract": "The evaluation of rare but high-stakes events remains one of the main\ndifficulties in obtaining reliable policies from intelligent agents, especially\nin large or continuous state/action spaces where limited scalability enforces\nthe use of a prohibitively large number of testing iterations. On the other\nhand, a biased or inaccurate policy evaluation in a safety-critical system\ncould potentially cause unexpected catastrophic failures during deployment. In\nthis paper, we propose the Accelerated Policy Evaluation (APE) method, which\nsimultaneously uncovers rare events and estimates the rare event probability in\nMarkov decision processes. The APE method treats the environment nature as an\nadversarial agent and learns towards, through adaptive importance sampling, the\nzero-variance sampling distribution for the policy evaluation. Moreover, APE is\nscalable to large discrete or continuous spaces by incorporating function\napproximators. We investigate the convergence properties of proposed algorithms\nunder suitable regularity conditions. Our empirical studies show that APE\nestimates rare event probability with a smaller variance while only using\norders of magnitude fewer samples compared to baseline methods in both\nmulti-agent and single-agent environments.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Mengdi Xu",
      "Peide Huang",
      "Fengpei Li",
      "Jiacheng Zhu",
      "Xuewei Qi",
      "Kentaro Oguchi",
      "Zhiyuan Huang",
      "Henry Lam",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10566"
  },
  {
    "id": "arXiv:2106.10568",
    "title": "Stein particle filtering",
    "abstract": "We present a new particle filtering algorithm for nonlinear systems in the\ndiscrete-time setting. Our algorithm is based on the Stein variational gradient\ndescent (SVGD) framework, which is a general approach to sample from a target\ndistribution. We merge the standard two-step paradigm in particle filtering\ninto one step so that SVGD can be used. A distinguishing feature of the\nproposed algorithm is that, unlike most particle filtering methods, all the\nparticles at any time step are equally weighted and thus no update on the\nweights is needed. We further extended our algorithm to allow for updating\nprevious particles within a sliding window. This strategy may improve the\nreliability of the algorithm with respect to unexpected disturbance in the\ndynamics or outlier-measurements. The efficacy of the proposed algorithms is\nillustrated through several numerical examples in comparison with a standard\nparticle filtering method.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Jiaojiao Fan",
      "Amirhossein Taghvaei",
      "Yongxin Chen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.10568"
  },
  {
    "id": "arXiv:2106.10574",
    "title": "Coded Faster-than-Nyquist Signaling for Short Packet Communications",
    "abstract": "Ultra-reliable low-latency communication (URLLC) requires short packets of\ndata transmission. It is known that when the packet length becomes short, the\nachievable rate is subject to a penalty when compared to the channel capacity.\nIn this paper, we propose to use faster-than-Nyquist (FTN) signaling to\ncompensate for the achievable rate loss of short packet communications. We\ninvestigate the performance of a combination of a low complexity detector of\nFTN signaling used with nonbinary low-density parity-check (NB-LDPC) codes that\nis suitable for low-latency and short block length requirements of URLLC\nsystems. Our investigation shows that such combination of low-complexity FTN\nsignaling detection and NB-LDPC codes outperforms the use of close-to-optimal\nFTN signaling detectors with LDPC codes in terms of error rate performance and\nalso has a considerably lower computational complexity.",
    "descriptor": "\nComments: 6 pages, 5 figures, accepted for publication in IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (IEEE PIMRC 2021)\n",
    "authors": [
      "Emre Cerci",
      "Adem Cicek",
      "Enver Cavus",
      "Ebrahim Bedeer",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10574"
  },
  {
    "id": "arXiv:2106.10575",
    "title": "EvoGrad: Efficient Gradient-Based Meta-Learning and Hyperparameter  Optimization",
    "abstract": "Gradient-based meta-learning and hyperparameter optimization have seen\nsignificant progress recently, enabling practical end-to-end training of neural\nnetworks together with many hyperparameters. Nevertheless, existing approaches\nare relatively expensive as they need to compute second-order derivatives and\nstore a longer computational graph. This cost prevents scaling them to larger\nnetwork architectures. We present EvoGrad, a new approach to meta-learning that\ndraws upon evolutionary techniques to more efficiently compute hypergradients.\nEvoGrad estimates hypergradient with respect to hyperparameters without\ncalculating second-order gradients, or storing a longer computational graph,\nleading to significant improvements in efficiency. We evaluate EvoGrad on two\nsubstantial recent meta-learning applications, namely cross-domain few-shot\nlearning with feature-wise transformations and noisy label learning with\nMetaWeightNet. The results show that EvoGrad significantly improves efficiency\nand enables scaling meta-learning to bigger CNN architectures such as from\nResNet18 to ResNet34.",
    "descriptor": "",
    "authors": [
      "Ondrej Bohdal",
      "Yongxin Yang",
      "Timothy Hospedales"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10575"
  },
  {
    "id": "arXiv:2106.10578",
    "title": "Optimal adaptive control of a knee joint exoskeleton for lower limb  functional rehabilitation",
    "abstract": "Lower limb exoskeleton robots hold great potential for rehabilitation,\nmovement assistance, and strength augmentation. Design control to guarantee\noptimal needed assistance is still a challenge considering the pathological\nvariances between patients. In this paper, we proposed an optimal adaptive\ncontrol scheme based on Particle Swarm Optimization (PSO) Algorithm. The\nproposed controller is based on a well-known dynamic model of the knee joint\nexoskeleton, and the optimization algorithm is used to minimize a square error\nfitness function, which quantifies tracking performances. Control parameters\nare tuned respecting some nonlinear constraints for step response of the system\nand boundaries constraints. Numerical simulation results are presented to show\nthe validity and the high performances of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Maria-Sara-Nour Sadoun",
      "Fouad Yacef"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10578"
  },
  {
    "id": "arXiv:2106.10581",
    "title": "Supervised learning for crop/weed classification based on color and  texture features",
    "abstract": "Computer vision techniques have attracted a great interest in precision\nagriculture, recently. The common goal of all computer vision-based precision\nagriculture tasks is to detect the objects of interest (e.g., crop, weed) and\ndiscriminating them from the background. The Weeds are unwanted plants growing\namong crops competing for nutrients, water, and sunlight, causing losses to\ncrop yields. Weed detection and mapping is critical for site-specific weed\nmanagement to reduce the cost of labor and impact of herbicides. This paper\ninvestigates the use of color and texture features for discrimination of\nSoybean crops and weeds. Feature extraction methods including two color spaces\n(RGB, HSV), gray level Co-occurrence matrix (GLCM), and Local Binary Pattern\n(LBP) are used to train the Support Vector Machine (SVM) classifier. The\nexperiment was carried out on image dataset of soybean crop, obtained from an\nunmanned aerial vehicle (UAV), which is publicly available. The results from\nthe experiment showed that the highest accuracy (above 96%) was obtained from\nthe combination of color and LBP features.",
    "descriptor": "",
    "authors": [
      "Faiza Mekhalfa",
      "Fouad Yacef"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10581"
  },
  {
    "id": "arXiv:2106.10587",
    "title": "Exploring Vision Transformers for Fine-grained Classification",
    "abstract": "Existing computer vision research in categorization struggles with\nfine-grained attributes recognition due to the inherently high intra-class\nvariances and low inter-class variances. SOTA methods tackle this challenge by\nlocating the most informative image regions and rely on them to classify the\ncomplete image. The most recent work, Vision Transformer (ViT), shows its\nstrong performance in both traditional and fine-grained classification tasks.\nIn this work, we propose a multi-stage ViT framework for fine-grained image\nclassification tasks, which localizes the informative image regions without\nrequiring architectural changes using the inherent multi-head self-attention\nmechanism. We also introduce attention-guided augmentations for improving the\nmodel's capabilities. We demonstrate the value of our approach by experimenting\nwith four popular fine-grained benchmarks: CUB-200-2011, Stanford Cars,\nStanford Dogs, and FGVC7 Plant Pathology. We also prove our model's\ninterpretability via qualitative results.",
    "descriptor": "\nComments: 4 pages, 5 figures, 4 tables. Published in The Eighth Workshop on Fine-Grained Visual Categorization, for code see this https URL, for workshop papers see this https URL\n",
    "authors": [
      "Marcos V. Conde",
      "Kerem Turgutlu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10587"
  },
  {
    "id": "arXiv:2106.10588",
    "title": "Low-Power Multi-Camera Object Re-Identification using Hierarchical  Neural Networks",
    "abstract": "Low-power computer vision on embedded devices has many applications. This\npaper describes a low-power technique for the object re-identification (reID)\nproblem: matching a query image against a gallery of previously seen images.\nState-of-the-art techniques rely on large, computationally-intensive Deep\nNeural Networks (DNNs). We propose a novel hierarchical DNN architecture that\nuses attribute labels in the training dataset to perform efficient object reID.\nAt each node in the hierarchy, a small DNN identifies a different attribute of\nthe query image. The small DNN at each leaf node is specialized to re-identify\na subset of the gallery: only the images with the attributes identified along\nthe path from the root to a leaf. Thus, a query image is re-identified\naccurately after processing with a few small DNNs. We compare our method with\nstate-of-the-art object reID techniques. With a 4% loss in accuracy, our\napproach realizes significant resource savings: 74% less memory, 72% fewer\noperations, and 67% lower query latency, yielding 65% less energy consumption.",
    "descriptor": "\nComments: Accepted to ISLPED 2021\n",
    "authors": [
      "Abhinav Goel",
      "Caleb Tung",
      "Xiao Hu",
      "Haobo Wang",
      "James C. Davis",
      "George K. Thiruvathukal",
      "Yung-Hsiang Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.10588"
  },
  {
    "id": "arXiv:2106.10592",
    "title": "ExplorerTree: a focus+context exploration approach for 2D embedding",
    "abstract": "In exploratory tasks involving high-dimensional datasets, dimensionality\nreduction (DR) techniques help analysts to discover patterns and other useful\ninformation. Although scatter plot representations of DR results allow for\ncluster identification and similarity analysis, such a visual metaphor presents\nproblems when the number of instances of the dataset increases, resulting in\ncluttered visualizations. In this work, we propose a scatter plot-based\nmultilevel approach to display DR results and address clutter-related problems\nwhen visualizing large datasets, together with the definition of a methodology\nto use focus+context interaction on non-hierarchical embeddings. The proposed\ntechnique, called ExplorerTree, uses a sampling selection technique on scatter\nplots to reduce visual clutter and guide users through exploratory tasks. We\ndemonstrate ExplorerTree's effectiveness through a use case, where we visually\nexplore activation images of the convolutional layers of a neural network.\nFinally, we also conducted a user experiment to evaluate ExplorerTree's ability\nto convey embedding structures using different sampling strategies.",
    "descriptor": "",
    "authors": [
      "Wilson E. Marc\u00edlio-Jr",
      "Danilo M. Eler",
      "Fernando V. Paulovich",
      "Jos\u00e9 F. Rodrigues-Jr",
      "Almir O. Artero"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.10592"
  },
  {
    "id": "arXiv:2106.10595",
    "title": "Heterogeneous Multi-task Learning with Expert Diversity",
    "abstract": "Predicting multiple heterogeneous biological and medical targets is a\nchallenge for traditional deep learning models. In contrast to single-task\nlearning, in which a separate model is trained for each target, multi-task\nlearning (MTL) optimizes a single model to predict multiple related targets\nsimultaneously. To address this challenge, we propose the Multi-gate\nMixture-of-Experts with Exclusivity (MMoEEx). Our work aims to tackle the\nheterogeneous MTL setting, in which the same model optimizes multiple tasks\nwith different characteristics. Such a scenario can overwhelm current MTL\napproaches due to the challenges in balancing shared and task-specific\nrepresentations and the need to optimize tasks with competing optimization\npaths. Our method makes two key contributions: first, we introduce an approach\nto induce more diversity among experts, thus creating representations more\nsuitable for highly imbalanced and heterogenous MTL learning; second, we adopt\na two-step optimization [6, 11] approach to balancing the tasks at the gradient\nlevel. We validate our method on three MTL benchmark datasets, including\nMedical Information Mart for Intensive Care (MIMIC-III) and PubChem BioAssay\n(PCBA).",
    "descriptor": "\nComments: 10 pages, 7 figures, BIOKDD\n",
    "authors": [
      "Raquel Aoki",
      "Frederick Tung",
      "Gabriel L. Oliveira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10595"
  },
  {
    "id": "arXiv:2106.10598",
    "title": "TGRNet: A Table Graph Reconstruction Network for Table Structure  Recognition",
    "abstract": "A table arranging data in rows and columns is a very effective data\nstructure, which has been widely used in business and scientific research.\nConsidering large-scale tabular data in online and offline documents, automatic\ntable recognition has attracted increasing attention from the document analysis\ncommunity. Though human can easily understand the structure of tables, it\nremains a challenge for machines to understand that, especially due to a\nvariety of different table layouts and styles. Existing methods usually model a\ntable as either the markup sequence or the adjacency matrix between different\ntable cells, failing to address the importance of the logical location of table\ncells, e.g., a cell is located in the first row and the second column of the\ntable. In this paper, we reformulate the problem of table structure recognition\nas the table graph reconstruction, and propose an end-to-end trainable table\ngraph reconstruction network (TGRNet) for table structure recognition.\nSpecifically, the proposed method has two main branches, a cell detection\nbranch and a cell logical location branch, to jointly predict the spatial\nlocation and the logical location of different cells. Experimental results on\nthree popular table recognition datasets and a new dataset with table graph\nannotations (TableGraph-350K) demonstrate the effectiveness of the proposed\nTGRNet for table structure recognition. Code and annotations will be made\npublicly available.",
    "descriptor": "",
    "authors": [
      "Wenyuan Xue",
      "Baosheng Yu",
      "Wen Wang",
      "Dacheng Tao",
      "Qingyong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10598"
  },
  {
    "id": "arXiv:2106.10600",
    "title": "Improving Label Quality by Jointly Modeling Items and Annotators",
    "abstract": "We propose a fully Bayesian framework for learning ground truth labels from\nnoisy annotators.\nOur framework ensures scalability by factoring a generative, Bayesian soft\nclustering model over label distributions into the classic David and Skene\njoint annotator-data model. Earlier research along these lines has neither\nfully incorporated label distributions nor explored clustering by annotators\nonly or data only. Our framework incorporates all of these properties as:\n(1) a graphical model designed to provide better ground truth estimates of\nannotator responses as input to \\emph{any} black box supervised learning\nalgorithm, and\n(2) a standalone neural model whose internal structure captures many of the\nproperties of the graphical model.\nWe conduct supervised learning experiments using both models and compare them\nto the performance of one baseline and a state-of-the-art model.",
    "descriptor": "",
    "authors": [
      "Tharindu Cyril Weerasooriya",
      "Alexander G. Ororbia",
      "Christopher M. Homan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.10600"
  },
  {
    "id": "arXiv:2106.10601",
    "title": "ReGO: Reference-Guided Outpainting for Scenery Image",
    "abstract": "We aim to tackle the challenging yet practical scenery image outpainting task\nin this work. Recently, generative adversarial learning has significantly\nadvanced the image outpainting by producing semantic consistent content for the\ngiven image. However, the existing methods always suffer from the blurry\ntexture and the artifacts of the generative part, making the overall\noutpainting results lack authenticity. To overcome the weakness, this work\ninvestigates a principle way to synthesize texture-rich results by borrowing\npixels from its neighbors (\\ie, reference images), named\n\\textbf{Re}ference-\\textbf{G}uided \\textbf{O}utpainting (ReGO). Particularly,\nthe ReGO designs an Adaptive Content Selection (ACS) module to transfer the\npixel of reference images for texture compensating of the target one. To\nprevent the style of the generated part from being affected by the reference\nimages, a style ranking loss is further proposed to augment the ReGO to\nsynthesize style-consistent results. Extensive experiments on two popular\nbenchmarks, NS6K~\\cite{yangzx} and NS8K~\\cite{wang}, well demonstrate the\neffectiveness of our ReGO.",
    "descriptor": "\nComments: Image outpainting, 13 pages\n",
    "authors": [
      "Yaxiong Wang",
      "Yunchao Wei",
      "Xueming Qian",
      "Li Zhu",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10601"
  },
  {
    "id": "arXiv:2106.10604",
    "title": "Cloud-Assisted Nonlinear Model Predictive Control for Finite-Duration  Tasks",
    "abstract": "Cloud computing creates new possibilities for control applications by\noffering powerful computation and storage capabilities. In this paper, we\npropose a novel cloud-assisted model predictive control (MPC) framework in\nwhich we systematically fuse a cloud MPC that uses a high-fidelity nonlinear\nmodel but is subject to communication delays with a local MPC that exploits\nsimplified dynamics (due to limited computation) but has timely feedback.\nUnlike traditional cloud-based control that treats the cloud as powerful,\nremote, and sole controller in a networked-system control setting, the proposed\nframework aims at seamlessly integrating the two controllers for enhanced\nperformance. In particular, we formalize the fusion problem for finite-duration\ntasks by explicitly considering model mismatches and errors due to\nrequest-response communication delays. We analyze stability-like properties of\nthe proposed cloud-assisted MPC framework and establish approaches to robustly\nhandling constraints within this framework in spite of plant-model mismatch and\ndisturbances. A fusion scheme is then developed to enhance control performance\nwhile satisfying stability-like conditions, the efficacy of which is\ndemonstrated with multiple simulation examples, including an automotive control\nexample to show its industrial application potentials.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Nan Li",
      "Kaixiang Zhang",
      "Zhaojian Li",
      "Vaibhav Srivastava",
      "Xiang Yin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10604"
  },
  {
    "id": "arXiv:2106.10605",
    "title": "Remote Sensing Images Semantic Segmentation with General Remote Sensing  Vision Model via a Self-Supervised Contrastive Learning Method",
    "abstract": "A new learning paradigm, self-supervised learning (SSL), can be used to solve\nsuch problems by pre-training a general model with large unlabeled images and\nthen fine-tuning on a downstream task with very few labeled samples.\nContrastive learning is a typical method of SSL, which can learn general\ninvariant features. However, most of the existing contrastive learning is\ndesigned for classification tasks to obtain an image-level representation,\nwhich may be sub-optimal for semantic segmentation tasks requiring pixel-level\ndiscrimination. Therefore, we propose Global style and Local matching\nContrastive Learning Network (GLCNet) for remote sensing semantic segmentation.\nSpecifically, the global style contrastive module is used to learn an\nimage-level representation better, as we consider the style features can better\nrepresent the overall image features; The local features matching contrastive\nmodule is designed to learn representations of local regions which is\nbeneficial for semantic segmentation. We evaluate four remote sensing semantic\nsegmentation datasets, and the experimental results show that our method mostly\noutperforms state-of-the-art self-supervised methods and ImageNet pre-training.\nSpecifically, with 1\\% annotation from the original dataset, our approach\nimproves Kappa by 6\\% on the ISPRS Potsdam dataset and 3\\% on Deep Globe Land\nCover Classification dataset relative to the existing baseline. Moreover, our\nmethod outperforms supervised learning when there are some differences between\nthe datasets of upstream tasks and downstream tasks. Our study promotes the\ndevelopment of self-supervised learning in the field of remote sensing semantic\nsegmentation. The source code is available at\nhttps://github.com/GeoX-Lab/G-RSIM.",
    "descriptor": "\nComments: 13 pages, 10 figures, 4 tables\n",
    "authors": [
      "Haifeng Li",
      "Yi Li",
      "Guo Zhang",
      "Ruoyun Liu",
      "Haozhe Huang",
      "Qing Zhu",
      "Chao Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10605"
  },
  {
    "id": "arXiv:2106.10606",
    "title": "Attack to Fool and Explain Deep Networks",
    "abstract": "Deep visual models are susceptible to adversarial perturbations to inputs.\nAlthough these signals are carefully crafted, they still appear noise-like\npatterns to humans. This observation has led to the argument that deep visual\nrepresentation is misaligned with human perception. We counter-argue by\nproviding evidence of human-meaningful patterns in adversarial perturbations.\nWe first propose an attack that fools a network to confuse a whole category of\nobjects (source class) with a target label. Our attack also limits the\nunintended fooling by samples from non-sources classes, thereby circumscribing\nhuman-defined semantic notions for network fooling. We show that the proposed\nattack not only leads to the emergence of regular geometric patterns in the\nperturbations, but also reveals insightful information about the decision\nboundaries of deep models. Exploring this phenomenon further, we alter the\n`adversarial' objective of our attack to use it as a tool to `explain' deep\nvisual representation. We show that by careful channeling and projection of the\nperturbations computed by our method, we can visualize a model's understanding\nof human-defined semantic notions. Finally, we exploit the explanability\nproperties of our perturbations to perform image generation, inpainting and\ninteractive image manipulation by attacking adversarialy robust\n`classifiers'.In all, our major contribution is a novel pragmatic adversarial\nattack that is subsequently transformed into a tool to interpret the visual\nmodels. The article also makes secondary contributions in terms of establishing\nthe utility of our attack beyond the adversarial objective with multiple\ninteresting applications.",
    "descriptor": "\nComments: To appear in IEEE TPAMI. arXiv admin note: text overlap with arXiv:1905.11544\n",
    "authors": [
      "Naveed Akhtar",
      "Muhammad A. A. K. Jalwana",
      "Mohammed Bennamoun",
      "Ajmal Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10606"
  },
  {
    "id": "arXiv:2106.10608",
    "title": "Multi-Pair Text Style Transfer on Unbalanced Data",
    "abstract": "Text-style transfer aims to convert text given in one domain into another by\nparaphrasing the sentence or substituting the keywords without altering the\ncontent. By necessity, state-of-the-art methods have evolved to accommodate\nnonparallel training data, as it is frequently the case there are multiple data\nsources of unequal size, with a mixture of labeled and unlabeled sentences.\nMoreover, the inherent style defined within each source might be distinct. A\ngeneric bidirectional (e.g., formal $\\Leftrightarrow$ informal) style transfer\nregardless of different groups may not generalize well to different\napplications. In this work, we developed a task adaptive meta-learning\nframework that can simultaneously perform a multi-pair text-style transfer\nusing a single model. The proposed method can adaptively balance the difference\nof meta-knowledge across multiple tasks. Results show that our method leads to\nbetter quantitative performance as well as coherent style variations. Common\nchallenges of unbalanced data and mismatched domains are handled well by this\nmethod.",
    "descriptor": "\nComments: Meta Learning and Its Applications to Natural Language Processing, ACL 2021 Workshop\n",
    "authors": [
      "Xing Han",
      "Jessica Lundin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10608"
  },
  {
    "id": "arXiv:2106.10610",
    "title": "Discrepancies in Epidemiological Modeling of Aggregated Heterogeneous  Data",
    "abstract": "Within epidemiological modeling, the majority of analyses assume a single\nepidemic process for generating ground-truth data. However, this assumed data\ngeneration process can be unrealistic, since data sources for epidemics are\noften aggregated across geographic regions and communities. As a result,\nstate-of-the-art models for estimating epidemiological parameters,\ne.g.~transmission rates, can be inappropriate when faced with complex systems.\nOur work empirically demonstrates some limitations of applying epidemiological\nmodels to aggregated datasets. We generate three complex outbreak scenarios by\ncombining incidence curves from multiple epidemics that are independently\nsimulated via SEIR models with different sets of parameters. Using these\nscenarios, we assess the robustness of a state-of-the-art Bayesian inference\nmethod that estimates the epidemic trajectory from viral load surveillance\ndata. We evaluate two data-generating models within this Bayesian inference\nframework: a simple exponential growth model and a highly flexible Gaussian\nprocess prior model. Our results show that both models generate accurate\ntransmission rate estimates for the combined incidence curve at the cost of\ngenerating biased estimates for each underlying epidemic, reflecting highly\nheterogeneous underlying population dynamics. The exponential growth model,\nwhile interpretable, is unable to capture the complexity of the underlying\nepidemics. With sufficient surveillance data, the Gaussian process prior model\ncaptures the shape of complex trajectories, but is imprecise for periods of low\ndata coverage. Thus, our results highlight the potential pitfalls of neglecting\ncomplexity and heterogeneity in the data generation process, which can mask\nunderlying location- and population-specific epidemic dynamics.",
    "descriptor": "\nComments: Accepted to IJCAI 2021 Workshop on Artificial Intelligence for Social Good\n",
    "authors": [
      "Anna L. Trella",
      "Peniel N. Argaw",
      "Michelle M. Li",
      "James A. Hay"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Populations and Evolution (q-bio.PE)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.10610"
  },
  {
    "id": "arXiv:2106.10613",
    "title": "Differences in Jazz Project Leaders' Competencies and Behaviors: A  Preliminary Empirical Investigation",
    "abstract": "Studying the human factors that impact on software development, and assigning\nindividuals with specific competencies and qualities to particular software\nroles, have been shown to aid software project performance. For instance, prior\nevidence suggests that extroverted software project leaders are most\nsuccessful. Role assignment based on individuals' competencies and behaviors\nmay be especially relevant in distributed software development contexts where\nteams are often affected by distance, cultural, and personality issues. Project\nleaders in these environments need to possess high levels of inter-personal,\nintra-personal and organizational competencies if they are to appropriately\nmanage such issues and maintain positive project performance. With a view to\nunderstanding and explaining the specific competencies and behaviors that are\nrequired of project leaders in these settings, we used psycholinguistic and\ndirected content analysis to study the way six successful IBM Rational Jazz\nleaders operated while coordinating their three distributed projects. Contrary\nto previous evidence reported in personality studies, our results did not\nreveal universal competencies and behaviors among these Jazz leaders. Instead,\nJazz project leaders' competencies and behaviors varied with their project\nportfolio of tasks. Our findings suggest that a pragmatic approach that\nconsiders the nature of the software tasks being developed is likely to be a\nmore effective strategy for assigning leaders to distributed software teams, as\nagainst a strategy that promotes a specific personality type. We discuss these\nfindings and outline implications for distributed software project governance.",
    "descriptor": "\nComments: Conference paper, 9 pages, 7 tables, 1 table. arXiv admin note: text overlap with arXiv:2106.03309\n",
    "authors": [
      "Sherlock A. Licorish",
      "Stephen G. MacDonell"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.10613"
  },
  {
    "id": "arXiv:2106.10614",
    "title": "How do Globally Distributed Agile Teams Self-organise? Initial Insights  from a Case Study",
    "abstract": "Agile software developers are required to self-organize, occupying various\ninformal roles as needed in order to successfully deliver software features.\nHowever, previous research has reported conflicting evidence about the way\nteams actually undertake this activity. The ability to self-organize is\nparticularly necessary for software development in globally distributed\nenvironments, where distance has been shown to exacerbate human-centric issues.\nUnderstanding the way successful teams self-organise should inform distributed\nteam composition strategies and software project governance. We have used\npsycholinguistics to study the way IBM Rational Jazz practitioners enacted\nvarious roles, expressed attitudes and shared competencies to successfully\nself-organize in their global projects. Among our findings, we uncovered that\npractitioners enacted various roles depending on their teams' cohort of\nfeatures; and that team leaders were most critical to IBM Jazz teams'\nself-organisation. We discuss these findings and highlight their implications\nfor software project governance.",
    "descriptor": "\nComments: Conference paper, 7 pages, 4 tables\n",
    "authors": [
      "Sherlock A. Licorish",
      "Stephen G. MacDonell"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.10614"
  },
  {
    "id": "arXiv:2106.10616",
    "title": "The True Role of Active Communicators: An Empirical Study of Jazz Core  Developers",
    "abstract": "Context: Interest in software engineering (SE) methodologies and tools has\nbeen complemented in recent years by research efforts oriented towards\nunderstanding the human processes involved in software development. This shift\nhas been imperative given reports of inadequately performing teams and the\nconsequent growing emphasis on individuals and team relations in contemporary\nSE methods. Objective: While software repositories have frequently been studied\nwith a view to explaining such human processes, research has tended to use\nprimarily quantitative analysis approaches. There is concern, however, that\nsuch approaches can provide only a partial picture of the software process.\nGiven the way human behavior is nuanced within psychological and social\ncontexts, it has been asserted that a full understanding may only be achieved\nthrough deeper contextual enquiries. Method: We have followed such an approach\nand have applied data mining, SNA, psycholinguistic analysis and directed\ncontent analysis (CA) to study the way core developers at IBM Rational Jazz\ncontribute their social and intellectual capital, and have compared the\nattitudes, interactions and activities of these members to those of their less\nactive counterparts. Results: Among our results, we uncovered that Jazz's core\ndevelopers worked across multiple roles, and were crucial to their teams'\norganizational, intra-personal and inter-personal processes. Additionally,\nalthough these individuals were highly task- and achievement-focused, they were\nalso largely responsible for maintaining positive team atmosphere, and for\nproviding context awareness in support of their colleagues. Conclusion: Our\nresults suggest that high-performing distributed agile teams rely on both\nindividual and collective efforts, as well as organizational environments that\npromote informal and organic work structures.(Abridged)",
    "descriptor": "\nComments: Conference paper, 14 pages, 2 figures, 7 tables. arXiv admin note: text overlap with arXiv:2102.06317\n",
    "authors": [
      "Sherlock A. Licorish",
      "Stephen G. MacDonell"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.10616"
  },
  {
    "id": "arXiv:2106.10617",
    "title": "Cogradient Descent for Dependable Learning",
    "abstract": "Conventional gradient descent methods compute the gradients for multiple\nvariables through the partial derivative. Treating the coupled variables\nindependently while ignoring the interaction, however, leads to an insufficient\noptimization for bilinear models. In this paper, we propose a dependable\nlearning based on Cogradient Descent (CoGD) algorithm to address the bilinear\noptimization problem, providing a systematic way to coordinate the gradients of\ncoupling variables based on a kernelized projection function. CoGD is\nintroduced to solve bilinear problems when one variable is with sparsity\nconstraint, as often occurs in modern learning paradigms. CoGD can also be used\nto decompose the association of features and weights, which further generalizes\nour method to better train convolutional neural networks (CNNs) and improve the\nmodel capacity. CoGD is applied in representative bilinear problems, including\nimage reconstruction, image inpainting, network pruning and CNN training.\nExtensive experiments show that CoGD improves the state-of-the-arts by\nsignificant margins. Code is available at\n{https://github.com/bczhangbczhang/CoGD}.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2006.09142\n",
    "authors": [
      "Runqi Wang",
      "Baochang Zhang",
      "Li'an Zhuo",
      "Qixiang Ye",
      "David Doermann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10617"
  },
  {
    "id": "arXiv:2106.10619",
    "title": "A Brief Study on the Effects of Training Generative Dialogue Models with  a Semantic loss",
    "abstract": "Neural models trained for next utterance generation in dialogue task learn to\nmimic the n-gram sequences in the training set with training objectives like\nnegative log-likelihood (NLL) or cross-entropy. Such commonly used training\nobjectives do not foster generating alternate responses to a context. But, the\neffects of minimizing an alternate training objective that fosters a model to\ngenerate alternate response and score it on semantic similarity has not been\nwell studied. We hypothesize that a language generation model can improve on\nits diversity by learning to generate alternate text during training and\nminimizing a semantic loss as an auxiliary objective. We explore this idea on\ntwo different sized data sets on the task of next utterance generation in goal\noriented dialogues. We make two observations (1) minimizing a semantic\nobjective improved diversity in responses in the smaller data set (Frames) but\nonly as-good-as minimizing the NLL in the larger data set (MultiWoZ) (2) large\nlanguage model embeddings can be more useful as a semantic loss objective than\nas initialization for token embeddings.",
    "descriptor": "\nComments: Accepted at SIGDial 2021\n",
    "authors": [
      "Prasanna Parthasarathi",
      "Mohamed Abdelsalam",
      "Joelle Pineau",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10619"
  },
  {
    "id": "arXiv:2106.10620",
    "title": "Large-Scale Network Embedding in Apache Spark",
    "abstract": "Network embedding has been widely used in social recommendation and network\nanalysis, such as recommendation systems and anomaly detection with graphs.\nHowever, most of previous approaches cannot handle large graphs efficiently,\ndue to that (i) computation on graphs is often costly and (ii) the size of\ngraph or the intermediate results of vectors could be prohibitively large,\nrendering it difficult to be processed on a single machine. In this paper, we\npropose an efficient and effective distributed algorithm for network embedding\non large graphs using Apache Spark, which recursively partitions a graph into\nseveral small-sized subgraphs to capture the internal and external structural\ninformation of nodes, and then computes the network embedding for each subgraph\nin parallel. Finally, by aggregating the outputs on all subgraphs, we obtain\nthe embeddings of nodes in a linear cost. After that, we demonstrate in various\nexperiments that our proposed approach is able to handle graphs with billions\nof edges within a few hours and is at least 4 times faster than the\nstate-of-the-art approaches. Besides, it achieves up to $4.25\\%$ and $4.27\\%$\nimprovements on link prediction and node classification tasks respectively. In\nthe end, we deploy the proposed algorithms in two online games of Tencent with\nthe applications of friend recommendation and item recommendation, which\nimprove the competitors by up to $91.11\\%$ in running time and up to $12.80\\%$\nin the corresponding evaluation metrics.",
    "descriptor": "\nComments: Accepted in KDD 2021\n",
    "authors": [
      "Wenqing Lin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10620"
  },
  {
    "id": "arXiv:2106.10621",
    "title": "On Sampling Top-K Recommendation Evaluation",
    "abstract": "Recently, Rendle has warned that the use of sampling-based top-$k$ metrics\nmight not suffice. This throws a number of recent studies on deep\nlearning-based recommendation algorithms, and classic non-deep-learning\nalgorithms using such a metric, into jeopardy. In this work, we thoroughly\ninvestigate the relationship between the sampling and global top-$K$ Hit-Ratio\n(HR, or Recall), originally proposed by Koren[2] and extensively used by\nothers. By formulating the problem of aligning sampling top-$k$ ($SHR@k$) and\nglobal top-$K$ ($HR@K$) Hit-Ratios through a mapping function $f$, so that\n$SHR@k\\approx HR@f(k)$, we demonstrate both theoretically and experimentally\nthat the sampling top-$k$ Hit-Ratio provides an accurate approximation of its\nglobal (exact) counterpart, and can consistently predict the correct winners\n(the same as indicate by their corresponding global Hit-Ratios).",
    "descriptor": "",
    "authors": [
      "Dong Li",
      "Ruoming Jin",
      "Jing Gao",
      "Zhi Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.10621"
  },
  {
    "id": "arXiv:2106.10622",
    "title": "Do Encoder Representations of Generative Dialogue Models Encode  Sufficient Information about the Task ?",
    "abstract": "Predicting the next utterance in dialogue is contingent on encoding of users'\ninput text to generate appropriate and relevant response in data-driven\napproaches. Although the semantic and syntactic quality of the language\ngenerated is evaluated, more often than not, the encoded representation of\ninput is not evaluated. As the representation of the encoder is essential for\npredicting the appropriate response, evaluation of encoder representation is a\nchallenging yet important problem. In this work, we showcase evaluating the\ntext generated through human or automatic metrics is not sufficient to\nappropriately evaluate soundness of the language understanding of dialogue\nmodels and, to that end, propose a set of probe tasks to evaluate encoder\nrepresentation of different language encoders commonly used in dialogue models.\nFrom experiments, we observe that some of the probe tasks are easier and some\nare harder for even sophisticated model architectures to learn. And, through\nexperiments we observe that RNN based architectures have lower performance on\nautomatic metrics on text generation than transformer model but perform better\nthan the transformer model on the probe tasks indicating that RNNs might\npreserve task information better than the Transformers.",
    "descriptor": "\nComments: Accepted at SIGDial 2021. arXiv admin note: substantial text overlap with arXiv:2008.10427\n",
    "authors": [
      "Prasanna Parthasarathi",
      "Joelle Pineau",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10622"
  },
  {
    "id": "arXiv:2106.10634",
    "title": "Augmented 2D-TAN: A Two-stage Approach for Human-centric Spatio-Temporal  Video Grounding",
    "abstract": "We propose an effective two-stage approach to tackle the problem of\nlanguage-based Human-centric Spatio-Temporal Video Grounding (HC-STVG) task. In\nthe first stage, we propose an Augmented 2D Temporal Adjacent Network\n(Augmented 2D-TAN) to temporally ground the target moment corresponding to the\ngiven description. Primarily, we improve the original 2D-TAN from two aspects:\nFirst, a temporal context-aware Bi-LSTM Aggregation Module is developed to\naggregate clip-level representations, replacing the original max-pooling.\nSecond, we propose to employ Random Concatenation Augmentation (RCA) mechanism\nduring the training phase. In the second stage, we use pretrained MDETR model\nto generate per-frame bounding boxes via language query, and design a set of\nhand-crafted rules to select the best matching bounding box outputted by MDETR\nfor each frame within the grounded moment.",
    "descriptor": "\nComments: A technical report on our solution for Person in Context(PIC) Challenge HCVG track at CVPR 2021 workshop\n",
    "authors": [
      "Chaolei Tan",
      "Zihang Lin",
      "Jian-Fang Hu",
      "Xiang Li",
      "Wei-Shi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10634"
  },
  {
    "id": "arXiv:2106.10635",
    "title": "FloorPP-Net: Reconstructing Floor Plans using Point Pillars for  Scan-to-BIM",
    "abstract": "This paper presents a deep learning-based point cloud processing method named\nFloorPP-Net for the task of Scan-to-BIM (building information model).\nFloorPP-Net first converts the input point cloud of a building story into point\npillars (PP), then predicts the corners and edges to output the floor plan.\nAltogether, FloorPP-Net establishes an end-to-end supervised learning framework\nfor the Scan-to-Floor-Plan (Scan2FP) task. In the 1st International Scan-to-BIM\nChallenge held in conjunction with CVPR 2021, FloorPP-Net was ranked the second\nrunner-up in the floor plan reconstruction track. Future work includes general\nedge proposals, 2D plan regularization, and 3D BIM reconstruction.",
    "descriptor": "",
    "authors": [
      "Yijie Wu",
      "Fan Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10635"
  },
  {
    "id": "arXiv:2106.10637",
    "title": "More than Encoder: Introducing Transformer Decoder to Upsample",
    "abstract": "General segmentation models downsample images and then upsample to restore\nresolution for pixel level prediction. In such schema, upsample technique is\nvital in maintaining information for better performance. In this paper, we\npresent a new upsample approach, Attention Upsample (AU), that could serve as\ngeneral upsample method and be incorporated into any segmentation model that\npossesses lateral connections. AU leverages pixel-level attention to model long\nrange dependency and global information for better reconstruction. It consists\nof Attention Decoder (AD) and bilinear upsample as residual connection to\ncomplement the upsampled features. AD adopts the idea of decoder from\ntransformer which upsamples features conditioned on local and detailed\ninformation from contracting path. Moreover, considering the extensive memory\nand computation cost of pixel-level attention, we further propose to use window\nattention scheme to restrict attention computation in local windows instead of\nglobal range. Incorporating window attention, we denote our decoder as Window\nAttention Decoder (WAD) and our upsample method as Window Attention Upsample\n(WAU). We test our method on classic U-Net structure with lateral connection to\ndeliver information from contracting path and achieve state-of-the-arts\nperformance on Synapse (80.30 DSC and 23.12 HD) and MSD Brain (74.75 DSC)\ndatasets.",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Yijiang Li",
      "Wentian Cai",
      "Ying Gao",
      "Xiping Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.10637"
  },
  {
    "id": "arXiv:2106.10642",
    "title": "Task Attended Meta-Learning for Few-Shot Learning",
    "abstract": "Meta-learning (ML) has emerged as a promising direction in learning models\nunder constrained resource settings like few-shot learning. The popular\napproaches for ML either learn a generalizable initial model or a generic\nparametric optimizer through episodic training. The former approaches leverage\nthe knowledge from a batch of tasks to learn an optimal prior. In this work, we\nstudy the importance of a batch for ML. Specifically, we first incorporate a\nbatch episodic training regimen to improve the learning of the generic\nparametric optimizer. We also hypothesize that the common assumption in batch\nepisodic training that each task in a batch has an equal contribution to\nlearning an optimal meta-model need not be true. We propose to weight the tasks\nin a batch according to their \"importance\" in improving the meta-model's\nlearning. To this end, we introduce a training curriculum motivated by\nselective focus in humans, called task attended meta-training, to weight the\ntasks in a batch. Task attention is a standalone module that can be integrated\nwith any batch episodic training regimen. The comparisons of the models with\ntheir non-task-attended counterparts on complex datasets like miniImageNet and\ntieredImageNet validate its effectiveness.",
    "descriptor": "",
    "authors": [
      "Aroof Aimen",
      "Sahil Sidheekh",
      "Narayanan C. Krishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10642"
  },
  {
    "id": "arXiv:2106.10648",
    "title": "HapFIC: An Adaptive Force/Position Controller for Safe Environment  Interaction in Articulated Systems",
    "abstract": "Haptic interaction is essential for the dynamic dexterity of animals, which\nseamlessly switch from an impedance to an admittance behaviour using the force\nfeedback from their proprioception. However, this ability is extremely\nchallenging to reproduce in robots, especially when dealing with complex\ninteraction dynamics, distributed contacts, and contact switching. Current\nmodel-based controllers require accurate interaction modelling to account for\ncontacts and stabilise the interaction. In this manuscript, we propose an\nadaptive force/position controller that exploits the fractal impedance\ncontroller's passivity and non-linearity to execute a finite search algorithm\nusing the force feedback signal from the sensor at the end-effector. The method\nis computationally inexpensive, opening the possibility to deal with\ndistributed contacts in the future. We evaluated the architecture in physics\nsimulation and showed that the controller can robustly control the interaction\nwith objects of different dynamics without violating the maximum allowable\ntarget forces or causing numerical instability even for very rigid objects. The\nproposed controller can also autonomously deal with contact switching and may\nfind application in multiple fields such as legged locomotion, rehabilitation\nand assistive robotics.",
    "descriptor": "",
    "authors": [
      "Carlo Tiseo",
      "Wolfgang Merkt",
      "Keyhan Kouhkiloui Babarahmati",
      "Wouter Wolfslag",
      "Ioannis Havoutis",
      "Sethu Vijayakumar",
      "Michael Mistry"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10648"
  },
  {
    "id": "arXiv:2106.10649",
    "title": "CAMERAS: Enhanced Resolution And Sanity preserving Class Activation  Mapping for image saliency",
    "abstract": "Backpropagation image saliency aims at explaining model predictions by\nestimating model-centric importance of individual pixels in the input. However,\nclass-insensitivity of the earlier layers in a network only allows saliency\ncomputation with low resolution activation maps of the deeper layers, resulting\nin compromised image saliency. Remedifying this can lead to sanity failures. We\npropose CAMERAS, a technique to compute high-fidelity backpropagation saliency\nmaps without requiring any external priors and preserving the map sanity. Our\nmethod systematically performs multi-scale accumulation and fusion of the\nactivation maps and backpropagated gradients to compute precise saliency maps.\nFrom accurate image saliency to articulation of relative importance of input\nfeatures for different models, and precise discrimination between model\nperception of visually similar objects, our high-resolution mapping offers\nmultiple novel insights into the black-box deep visual models, which are\npresented in the paper. We also demonstrate the utility of our saliency maps in\nadversarial setup by drastically reducing the norm of attack signals by\nfocusing them on the precise regions identified by our maps. Our method also\ninspires new evaluation metrics and a sanity check for this developing research\ndirection. Code is available here https://github.com/VisMIL/CAMERAS",
    "descriptor": "\nComments: IEEE CVPR 2021 paper\n",
    "authors": [
      "Mohammad A. A. K. Jalwana",
      "Naveed Akhtar",
      "Mohammed Bennamoun",
      "Ajmal Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10649"
  },
  {
    "id": "arXiv:2106.10652",
    "title": "TinyML: Analysis of Xtensa LX6 microprocessor for Neural Network  Applications by ESP32 SoC",
    "abstract": "In recent decades, Machine Learning (ML) has become extremely important for\nmany computing applications. The pervasiveness of ultra-low-power embedded\ndevices such as ESP32 or ESP32 Cam with tiny Machine Learning (tinyML)\napplications will enable the mass proliferation of Artificial Intelligent\npowered Embedded IoT Devices. In the last few years, the microcontroller device\n(Espressif ESP32) became powerful enough to be used for small/tiny machine\nlearning (tinyML) tasks. The ease of use of platforms like Arduino IDE,\nMicroPython and TensorFlow Lite (TF) with tinyML application make it an\nindispensable topic of research for mobile robotics, modern computer science\nand electrical engineering. The goal of this paper is to analyze the speed of\nthe Xtensa dual core 32-bit LX6 microprocessor by running a neural network\napplication. The different number of inputs (9, 36, 144 and 576) inputted\nthrough the different number of neurons in neural networks with one and two\nhidden layers. Xtensa LX6 microprocessor has been analyzed because it comes\ninside with Espressif ESP32 and ESP32 Cam which are very easy to use, plug and\nplay IoT device. In this paper speed of the Xtensa LX6 microprocessor in\nfeed-forward mode has been analyzed.",
    "descriptor": "",
    "authors": [
      "Md Ziaul Haque Zim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.10652"
  },
  {
    "id": "arXiv:2106.10653",
    "title": "Practical Assessment of Generalization Performance Robustness for Deep  Networks via Contrastive Examples",
    "abstract": "Training images with data transformations have been suggested as contrastive\nexamples to complement the testing set for generalization performance\nevaluation of deep neural networks (DNNs). In this work, we propose a practical\nframework ContRE (The word \"contre\" means \"against\" or \"versus\" in French.)\nthat uses Contrastive examples for DNN geneRalization performance Estimation.\nSpecifically, ContRE follows the assumption in contrastive learning that robust\nDNN models with good generalization performance are capable of extracting a\nconsistent set of features and making consistent predictions from the same\nimage under varying data transformations. Incorporating with a set of\nrandomized strategies for well-designed data transformations over the training\nset, ContRE adopts classification errors and Fisher ratios on the generated\ncontrastive examples to assess and analyze the generalization performance of\ndeep models in complement with a testing set. To show the effectiveness and the\nefficiency of ContRE, extensive experiments have been done using various DNN\nmodels on three open source benchmark datasets with thorough ablation studies\nand applicability analyses. Our experiment results confirm that (1) behaviors\nof deep models on contrastive examples are strongly correlated to what on the\ntesting set, and (2) ContRE is a robust measure of generalization performance\ncomplementing to the testing set in various settings.",
    "descriptor": "",
    "authors": [
      "Xuanyu Wu",
      "Xuhong Li",
      "Haoyi Xiong",
      "Xiao Zhang",
      "Siyu Huang",
      "Dejing Dou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10653"
  },
  {
    "id": "arXiv:2106.10656",
    "title": "TD-GEN: Graph Generation With Tree Decomposition",
    "abstract": "We propose TD-GEN, a graph generation framework based on tree decomposition,\nand introduce a reduced upper bound on the maximum number of decisions needed\nfor graph generation. The framework includes a permutation invariant tree\ngeneration model which forms the backbone of graph generation. Tree nodes are\nsupernodes, each representing a cluster of nodes in the graph. Graph nodes and\nedges are incrementally generated inside the clusters by traversing the tree\nsupernodes, respecting the structure of the tree decomposition, and following\nnode sharing decisions between the clusters. Finally, we discuss the\nshortcomings of standard evaluation criteria based on statistical properties of\nthe generated graphs as performance measures. We propose to compare the\nperformance of models based on likelihood. Empirical results on a variety of\nstandard graph generation datasets demonstrate the superior performance of our\nmethod.",
    "descriptor": "",
    "authors": [
      "Hamed Shirzad",
      "Hossein Hajimirsadeghi",
      "Amir H. Abdi",
      "Greg Mori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10656"
  },
  {
    "id": "arXiv:2106.10657",
    "title": "New directions for contact integrators",
    "abstract": "Contact integrators are a family of geometric numerical schemes which\nguarantee the conservation of the contact structure. In this work we review the\nconstruction of both the variational and Hamiltonian versions of these methods.\nWe illustrate some of the advantages of geometric integration in the\ndissipative setting by focusing on models inspired by recent studies in\ncelestial mechanics and cosmology.",
    "descriptor": "\nComments: To appear as Chapter 24 in GSI 2021, Springer LNCS 12829\n",
    "authors": [
      "Alessandro Bravetti",
      "Marcello Seri",
      "Federico Zadra"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10657"
  },
  {
    "id": "arXiv:2106.10658",
    "title": "Exploring Semantic Relationships for Unpaired Image Captioning",
    "abstract": "Recently, image captioning has aroused great interest in both academic and\nindustrial worlds. Most existing systems are built upon large-scale datasets\nconsisting of image-sentence pairs, which, however, are time-consuming to\nconstruct. In addition, even for the most advanced image captioning systems, it\nis still difficult to realize deep image understanding. In this work, we\nachieve unpaired image captioning by bridging the vision and the language\ndomains with high-level semantic information. The motivation stems from the\nfact that the semantic concepts with the same modality can be extracted from\nboth images and descriptions. To further improve the quality of captions\ngenerated by the model, we propose the Semantic Relationship Explorer, which\nexplores the relationships between semantic concepts for better understanding\nof the image. Extensive experiments on MSCOCO dataset show that we can generate\ndesirable captions without paired datasets. Furthermore, the proposed approach\nboosts five strong baselines under the paired setting, where the most\nsignificant improvement in CIDEr score reaches 8%, demonstrating that it is\neffective and generalizes well to a wide range of models.",
    "descriptor": "",
    "authors": [
      "Fenglin Liu",
      "Meng Gao",
      "Tianhao Zhang",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10658"
  },
  {
    "id": "arXiv:2106.10659",
    "title": "Hole Detection and Healing in Hybrid Sensor Networks",
    "abstract": "Although monitoring and covering are fundamental goals of a wireless sensor\nnetwork (WSN), the accidental death of sensors or the running out of their\nenergy would result in holes in the WSN. Such holes have the potential to\ndisrupt the primary functions of WSNs. This paper investigates the hole\ndetection and healing problems in hybrid WSNs with non-identical sensor sensing\nranges. In particular, we aim to propose centralized algorithms for detecting\nholes in a given region and maximizing the area covered by a WSN in the\npresence of environmental obstacles. To precisely identify the boundary of the\nholes, we use an additively weighted Voronoi diagram and a polynomial-time\nalgorithm.Furthermore, since this problem is known to be computationally\ndifficult, we propose a centralized greedy 1/2-approximation algorithm to\nmaximize the area covered by sensors. Finally, we implement the algorithms and\nrun simulations to show that our approximation algorithm efficiently covers the\nholes by moving the mobile sensors.",
    "descriptor": "",
    "authors": [
      "Mansoor Davoodi",
      "Esmaeil Delfaraz",
      "Sajjad Ghobadi",
      "Mahtab Masoori"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10659"
  },
  {
    "id": "arXiv:2106.10662",
    "title": "FedXGBoost: Privacy-Preserving XGBoost for Federated Learning",
    "abstract": "Federated learning is the distributed machine learning framework that enables\ncollaborative training across multiple parties while ensuring data privacy.\nPractical adaptation of XGBoost, the state-of-the-art tree boosting framework,\nto federated learning remains limited due to high cost incurred by conventional\nprivacy-preserving methods. To address the problem, we propose two variants of\nfederated XGBoost with privacy guarantee: FedXGBoost-SMM and FedXGBoost-LDP.\nOur first protocol FedXGBoost-SMM deploys enhanced secure matrix multiplication\nmethod to preserve privacy with lossless accuracy and lower overhead than\nencryption-based techniques. Developed independently, the second protocol\nFedXGBoost-LDP is heuristically designed with noise perturbation for local\ndifferential privacy, and empirically evaluated on real-world and synthetic\ndatasets.",
    "descriptor": "",
    "authors": [
      "Nhan Khanh Le",
      "Yang Liu",
      "Quang Minh Nguyen",
      "Qingchen Liu",
      "Fangzhou Liu",
      "Quanwei Cai",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.10662"
  },
  {
    "id": "arXiv:2106.10663",
    "title": "PDE approach to centroidal tessellations of domains",
    "abstract": "We introduce a class of systems of Hamilton-Jacobi equations that\ncharacterize critical points of functionals associated to centroidal\ntessellations of domains, i.e. tessellations where generators and centroids\ncoincide,\nsuch as centroidal Voronoi tessellations and centroidal power diagrams. An\nappropriate version of the Lloyd algorithm, combined with a Fast Marching\nmethod on unstructured grids for the Hamilton-Jacobi equation, allows computing\nthe solution of the system. We propose various numerical examples to illustrate\nthe features of the technique.",
    "descriptor": "",
    "authors": [
      "Fabio Camilli",
      "Adriano Festa"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10663"
  },
  {
    "id": "arXiv:2106.10671",
    "title": "A compressive multi-kernel method for privacy-preserving machine  learning",
    "abstract": "As the analytic tools become more powerful, and more data are generated on a\ndaily basis, the issue of data privacy arises. This leads to the study of the\ndesign of privacy-preserving machine learning algorithms. Given two objectives,\nnamely, utility maximization and privacy-loss minimization, this work is based\non two previously non-intersecting regimes -- Compressive Privacy and\nmulti-kernel method. Compressive Privacy is a privacy framework that employs\nutility-preserving lossy-encoding scheme to protect the privacy of the data,\nwhile multi-kernel method is a kernel based machine learning regime that\nexplores the idea of using multiple kernels for building better predictors. The\ncompressive multi-kernel method proposed consists of two stages -- the\ncompression stage and the multi-kernel stage. The compression stage follows the\nCompressive Privacy paradigm to provide the desired privacy protection. Each\nkernel matrix is compressed with a lossy projection matrix derived from the\nDiscriminant Component Analysis (DCA). The multi-kernel stage uses the\nsignal-to-noise ratio (SNR) score of each kernel to non-uniformly combine\nmultiple compressive kernels. The proposed method is evaluated on two\nmobile-sensing datasets -- MHEALTH and HAR -- where activity recognition is\ndefined as utility and person identification is defined as privacy. The results\nshow that the compression regime is successful in privacy preservation as the\nprivacy classification accuracies are almost at the random-guess level in all\nexperiments. On the other hand, the novel SNR-based multi-kernel shows utility\nclassification accuracy improvement upon the state-of-the-art in both datasets.\nThese results indicate a promising direction for research in privacy-preserving\nmachine learning.",
    "descriptor": "\nComments: Published in 2017 International Joint Conference on Neural Networks (IJCNN). IEEE, 2017\n",
    "authors": [
      "Thee Chanyaswad",
      "J. Morris Chang",
      "S.Y. Kung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10671"
  },
  {
    "id": "arXiv:2106.10672",
    "title": "Image-guided Breast Biopsy of MRI-visible Lesions with a Hand-mounted  Motorised Needle Steering Tool",
    "abstract": "A biopsy is the only diagnostic procedure for accurate histological\nconfirmation of breast cancer. When sonographic placement is not feasible, a\nMagnetic Resonance Imaging(MRI)-guided biopsy is often preferred. The lack of\nreal-time imaging information and the deformations of the breast make it\nchallenging to bring the needle precisely towards the tumour detected in\npre-interventional Magnetic Resonance (MR) images. The current manual\nMRI-guided biopsy workflow is inaccurate and would benefit from a technique\nthat allows real-time tracking and localisation of the tumour lesion during\nneedle insertion. This paper proposes a robotic setup and software architecture\nto assist the radiologist in targeting MR-detected suspicious tumours. The\napproach benefits from image fusion of preoperative images with intraoperative\noptical tracking of markers attached to the patient's skin. A hand-mounted\nbiopsy device has been constructed with an actuated needle base to drive the\ntip toward the desired direction. The steering commands may be provided both by\nuser input and by computer guidance. The workflow is validated through phantom\nexperiments. On average, the suspicious breast lesion is targeted with a radius\ndown to 2.3 mm. The results suggest that robotic systems taking into account\nbreast deformations have the potentials to tackle this clinical challenge.",
    "descriptor": "\nComments: Submitted to 2021 International Symposium on Medical Robotics (ISMR)\n",
    "authors": [
      "Marta Lagomarsino",
      "Vincent Groenhuis",
      "Maura Casadio",
      "Marcel K. Welleweerd",
      "Francoise J. Siepel",
      "Stefano Stramigioli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10672"
  },
  {
    "id": "arXiv:2106.10673",
    "title": "Two-Faced Humans on Twitter and Facebook: Harvesting Social Multimedia  for Human Personality Profiling",
    "abstract": "Human personality traits are the key drivers behind our decision-making,\ninfluencing our life path on a daily basis. Inference of personality traits,\nsuch as Myers-Briggs Personality Type, as well as an understanding of\ndependencies between personality traits and users' behavior on various social\nmedia platforms is of crucial importance to modern research and industry\napplications. The emergence of diverse and cross-purpose social media avenues\nmakes it possible to perform user personality profiling automatically and\nefficiently based on data represented across multiple data modalities. However,\nthe research efforts on personality profiling from multi-source multi-modal\nsocial media data are relatively sparse, and the level of impact of different\nsocial network data on machine learning performance has yet to be\ncomprehensively evaluated. Furthermore, there is not such dataset in the\nresearch community to benchmark. This study is one of the first attempts\ntowards bridging such an important research gap. Specifically, in this work, we\ninfer the Myers-Briggs Personality Type indicators, by applying a novel\nmulti-view fusion framework, called \"PERS\" and comparing the performance\nresults not just across data modalities but also with respect to different\nsocial network data sources. Our experimental results demonstrate the PERS's\nability to learn from multi-view data for personality profiling by efficiently\nleveraging on the significantly different data arriving from diverse social\nmultimedia sources. We have also found that the selection of a machine learning\napproach is of crucial importance when choosing social network data sources and\nthat people tend to reveal multiple facets of their personality in different\nsocial media avenues. Our released social multimedia dataset facilitates future\nresearch on this direction.",
    "descriptor": "",
    "authors": [
      "Qi Yang",
      "Aleksandr Farseev",
      "Andrey Filchenkov"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.10673"
  },
  {
    "id": "arXiv:2106.10676",
    "title": "Overall Behavioural Index (OBI) For Measuring Segregation",
    "abstract": "Segregation, defined as the degree of separation between two or more\npopulation groups, helps to understand a complex social environment and\nsubsequently provides a basis for public policy intervention. To measure\nsegregation, past works often propose indexes that are criticized for being\nover-simplified and over-reduced. In other words, these indexes use the highly\naggregated information to measure segregation. In this paper, we propose three\nnovel indexes to measure segregation, namely: (i) Individual Segregation Index\n(ISI), (ii) Individual Inclination Index (III), and (iii) Overall Behavioural\nIndex (OBI). The ISI index measures individuals' segregation, and the III index\nreports the individuals' inclination towards other population groups. The OBI\nindex, calculated using both III and ISI index, is non-simplified and not only\nrecognizes individuals' connectivity behaviour but group's connectivity\nbehavioural distribution as well. By considering commonly used Freeman's\nsegregation and homophily index as baseline indexes, we compare the OBI index\non real call data records (CDR) dataset of Estonia to show the effectiveness of\nthe proposed indexes.",
    "descriptor": "",
    "authors": [
      "Rahul Goel",
      "Rajesh Sharma",
      "Anto Aasa"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.10676"
  },
  {
    "id": "arXiv:2106.10679",
    "title": "A Comprehensive Review on Non-Neural Networks Collaborative Filtering  Recommendation Systems",
    "abstract": "Over the past two decades, recommender systems have attracted a lot of\ninterest due to the explosion in the amount of data in online applications. A\nparticular attention has been paid to collaborative filtering, which is the\nmost widely used in applications that involve information recommendations.\nCollaborative filtering (CF) uses the known preference of a group of users to\nmake predictions and recommendations about the unknown preferences of other\nusers (recommendations are made based on the past behavior of users). First\nintroduced in the 1990s, a wide variety of increasingly successful models have\nbeen proposed. Due to the success of machine learning techniques in many areas,\nthere has been a growing emphasis on the application of such algorithms in\nrecommendation systems. In this article, we present an overview of the CF\napproaches for recommender systems, their two main categories, and their\nevaluation metrics. We focus on the application of classical Machine Learning\nalgorithms to CF recommender systems by presenting their evolution from their\nfirst use-cases to advanced Machine Learning models. We attempt to provide a\ncomprehensive and comparative overview of CF systems (with python\nimplementations) that can serve as a guideline for research and practice in\nthis area.",
    "descriptor": "\nComments: 29 pages, 7 tables and 2 figures\n",
    "authors": [
      "Carmel Wenga",
      "Majirus Fansi",
      "S\u00e9bastien Chabrier",
      "Jean-Martial Mari",
      "Alban Gabillon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10679"
  },
  {
    "id": "arXiv:2106.10680",
    "title": "Guiding vector fields in Paparazzi autopilot",
    "abstract": "This article is a technical report on the two different guidance systems\nbased on vector fields that can be found in Paparazzi, a free sw/hw autopilot.\nGuiding vector fields allow autonomous vehicles to track paths described by the\nuser mathematically. In particular, we allow two descriptions of the path with\nan implicit or a parametric function. Each description is associated with its\ncorresponding guiding vector field algorithm. The implementations of the two\nalgorithms are light enough to be run in a modern microcontroller. We will\ncover the basic theory on how they work, how a user can implement its own paths\nin Paparazzi, how to exploit them to coordinate multiple vehicles, and we\nfinish with some experimental results. Although the presented implementation is\nfocused on fixed-wing aircraft, the guidance is also applicable to other kinds\nof aerial vehicles such as rotorcraft.",
    "descriptor": "\nComments: Submitted to IMAV 2021, 5 pages\n",
    "authors": [
      "Hector Garcia de Marina",
      "Murat Bronz",
      "Gautier Hattenberger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.10680"
  },
  {
    "id": "arXiv:2106.10681",
    "title": "Tag, Copy or Predict: A Unified Weakly-Supervised Learning Framework for  Visual Information Extraction using Sequences",
    "abstract": "Visual information extraction (VIE) has attracted increasing attention in\nrecent years. The existing methods usually first organized optical character\nrecognition (OCR) results into plain texts and then utilized token-level entity\nannotations as supervision to train a sequence tagging model. However, it\nexpends great annotation costs and may be exposed to label confusion, and the\nOCR errors will also significantly affect the final performance. In this paper,\nwe propose a unified weakly-supervised learning framework called TCPN (Tag,\nCopy or Predict Network), which introduces 1) an efficient encoder to\nsimultaneously model the semantic and layout information in 2D OCR results; 2)\na weakly-supervised training strategy that utilizes only key information\nsequences as supervision; and 3) a flexible and switchable decoder which\ncontains two inference modes: one (Copy or Predict Mode) is to output key\ninformation sequences of different categories by copying a token from the input\nor predicting one in each time step, and the other (Tag Mode) is to directly\ntag the input sequence in a single forward pass. Our method shows new\nstate-of-the-art performance on several public benchmarks, which fully proves\nits effectiveness.",
    "descriptor": "\nComments: IJCAI2021\n",
    "authors": [
      "Jiapeng Wang",
      "Tianwei Wang",
      "Guozhi Tang",
      "Lianwen Jin",
      "Weihong Ma",
      "Kai Ding",
      "Yichao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.10681"
  },
  {
    "id": "arXiv:2106.10683",
    "title": "Solution for Large-scale Long-tailed Recognition with Noisy Labels",
    "abstract": "This is a technical report for CVPR 2021 AliProducts Challenge. AliProducts\nChallenge is a competition proposed for studying the large-scale and\nfine-grained commodity image recognition problem encountered by worldleading\necommerce companies. The large-scale product recognition simultaneously meets\nthe challenge of noisy annotations, imbalanced (long-tailed) data distribution\nand fine-grained classification. In our solution, we adopt stateof-the-art\nmodel architectures of both CNNs and Transformer, including ResNeSt,\nEfficientNetV2, and DeiT. We found that iterative data cleaning, classifier\nweight normalization, high-resolution finetuning, and test time augmentation\nare key components to improve the performance of training with the noisy and\nimbalanced dataset. Finally, we obtain 6.4365% mean class error rate in the\nleaderboard with our ensemble model.",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "Yuqiao Xian",
      "Jia-Xin Zhuang",
      "Fufu Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10683"
  },
  {
    "id": "arXiv:2106.10684",
    "title": "Optimal personalised treatment computation through in silico clinical  trials on patient digital twins",
    "abstract": "In Silico Clinical Trials (ISTC), i.e., clinical experimental campaigns\ncarried out by means of computer simulations, hold the promise to decrease time\nand cost for the safety and efficacy assessment of pharmacological treatments,\nreduce the need for animal and human testing, and enable precision medicine. In\nthis paper we present methods and an algorithm that, by means of extensive\ncomputer simulation--based experimental campaigns (ISTC) guided by intelligent\nsearch, optimise a pharmacological treatment for an individual patient\n(precision medicine). e show the effectiveness of our approach on a case study\ninvolving a real pharmacological treatment, namely the downregulation phase of\na complex clinical protocol for assisted reproduction in humans.",
    "descriptor": "\nComments: 31 pages, 9 figures\n",
    "authors": [
      "Stefano Sinisi",
      "Vadim Alimguzhin",
      "Toni Mancini",
      "Enrico Tronci",
      "Federico Mari",
      "Brigitte Leeners"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2106.10684"
  },
  {
    "id": "arXiv:2106.10685",
    "title": "MILP, pseudo-boolean, and OMT solvers for optimal fault-tolerant  placements of relay nodes in mission critical wireless networks",
    "abstract": "In critical infrastructures like airports, much care has to be devoted in\nprotecting radio communication networks from external electromagnetic\ninterference. Protection of such mission-critical radio communication networks\nis usually tackled by exploiting radiogoniometers: at least three suitably\ndeployed radiogoniometers, and a gateway gathering information from them,\npermit to monitor and localise sources of electromagnetic emissions that are\nnot supposed to be present in the monitored area. Typically, radiogoniometers\nare connected to the gateway through relay nodes. As a result, some degree of\nfault-tolerance for the network of relay nodes is essential in order to offer a\nreliable monitoring. On the other hand, deployment of relay nodes is typically\nquite expensive. As a result, we have two conflicting requirements: minimise\ncosts while guaranteeing a given fault-tolerance. In this paper, we address the\nproblem of computing a deployment for relay nodes that minimises the relay node\nnetwork cost while at the same time guaranteeing proper working of the network\neven when some of the relay nodes (up to a given maximum number) become faulty\n(fault-tolerance). We show that, by means of a computation-intensive\npre-processing on a HPC infrastructure, the above optimisation problem can be\nencoded as a 0/1 Linear Program, becoming suitable to be approached with\nstandard Artificial Intelligence reasoners like MILP, PB-SAT, and SMT/OMT\nsolvers. Our problem formulation enables us to present experimental results\ncomparing the performance of these three solving technologies on a real case\nstudy of a relay node network deployment in areas of the Leonardo da Vinci\nAirport in Rome, Italy.",
    "descriptor": "\nComments: 33 pages, 11 figures\n",
    "authors": [
      "Quian Matteo Chen",
      "Alberto Finzi",
      "Toni Mancini",
      "Igor Melatti",
      "Enrico Tronci"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Logic in Computer Science (cs.LO)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.10685"
  },
  {
    "id": "arXiv:2106.10686",
    "title": "Quality-Aware Memory Network for Interactive Volumetric Image  Segmentation",
    "abstract": "Despite recent progress of automatic medical image segmentation techniques,\nfully automatic results usually fail to meet the clinical use and typically\nrequire further refinement. In this work, we propose a quality-aware memory\nnetwork for interactive segmentation of 3D medical images. Provided by user\nguidance on an arbitrary slice, an interaction network is firstly employed to\nobtain an initial 2D segmentation. The quality-aware memory network\nsubsequently propagates the initial segmentation estimation bidirectionally\nover the entire volume. Subsequent refinement based on additional user guidance\non other slices can be incorporated in the same manner. To further facilitate\ninteractive segmentation, a quality assessment module is introduced to suggest\nthe next slice to segment based on the current segmentation quality of each\nslice. The proposed network has two appealing characteristics: 1) The\nmemory-augmented network offers the ability to quickly encode past segmentation\ninformation, which will be retrieved for the segmentation of other slices; 2)\nThe quality assessment module enables the model to directly estimate the\nqualities of segmentation predictions, which allows an active learning paradigm\nwhere users preferentially label the lowest-quality slice for multi-round\nrefinement. The proposed network leads to a robust interactive segmentation\nengine, which can generalize well to various types of user annotations (e.g.,\nscribbles, boxes). Experimental results on various medical datasets demonstrate\nthe superiority of our approach in comparison with existing techniques.",
    "descriptor": "\nComments: MICCAI 2021. Code: this https URL\n",
    "authors": [
      "Tianfei Zhou",
      "Liulei Li",
      "Gustav Bredell",
      "Jianwu Li",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10686"
  },
  {
    "id": "arXiv:2106.10689",
    "title": "NeuS: Learning Neural Implicit Surfaces by Volume Rendering for  Multi-view Reconstruction",
    "abstract": "We present a novel neural surface reconstruction method, called NeuS, for\nreconstructing objects and scenes with high fidelity from 2D image inputs.\nExisting neural surface reconstruction approaches, such as DVR and IDR, require\nforeground mask as supervision, easily get trapped in local minima, and\ntherefore struggle with the reconstruction of objects with severe\nself-occlusion or thin structures. Meanwhile, recent neural methods for novel\nview synthesis, such as NeRF and its variants, use volume rendering to produce\na neural scene representation with robustness of optimization, even for highly\ncomplex objects. However, extracting high-quality surfaces from this learned\nimplicit representation is difficult because there are not sufficient surface\nconstraints in the representation. In NeuS, we propose to represent a surface\nas the zero-level set of a signed distance function (SDF) and develop a new\nvolume rendering method to train a neural SDF representation. We observe that\nthe conventional volume rendering method causes inherent geometric errors (i.e.\nbias) for surface reconstruction, and therefore propose a new formulation that\nis free of bias in the first order of approximation, thus leading to more\naccurate surface reconstruction even without the mask supervision. Experiments\non the DTU dataset and the BlendedMVS dataset show that NeuS outperforms the\nstate-of-the-arts in high-quality surface reconstruction, especially for\nobjects and scenes with complex structures and self-occlusion.",
    "descriptor": "\nComments: 22 pages, 17 figures\n",
    "authors": [
      "Peng Wang",
      "Lingjie Liu",
      "Yuan Liu",
      "Christian Theobalt",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.10689"
  },
  {
    "id": "arXiv:2106.10692",
    "title": "Parallel Statistical Model Checking for Safety Verification in Smart  Grids",
    "abstract": "By using small computing devices deployed at user premises, Autonomous Demand\nResponse (ADR) adapts users electricity consumption to given time-dependent\nelectricity tariffs. This allows end-users to save on their electricity bill\nand Distribution System Operators to optimise (through suitable time-dependent\ntariffs) management of the electric grid by avoiding demand peaks.\nUnfortunately, even with ADR, users power consumption may deviate from the\nexpected (minimum cost) one, e.g., because ADR devices fail to correctly\nforecast energy needs at user premises. As a result, the aggregated power\ndemand may present undesirable peaks. In this paper we address such a problem\nby presenting methods and a software tool (APD-Analyser) implementing them,\nenabling Distribution System Operators to effectively verify that a given\ntime-dependent electricity tariff achieves the desired goals even when\nend-users deviate from their expected behaviour. We show feasibility of the\nproposed approach through a realistic scenario from a medium voltage Danish\ndistribution network.",
    "descriptor": "\nComments: 6 pages, 1 figure. In SmartGridComm 2018. IEEE, 2018\n",
    "authors": [
      "T. Mancini",
      "F. Mari",
      "I. Melatti",
      "I. Salvo",
      "E. Tronci",
      "J.K. Gruber",
      "B. Hayes",
      "M. Prodanovic",
      "L. Elmegaard"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.10692"
  },
  {
    "id": "arXiv:2106.10693",
    "title": "Fast PDN Impedance Prediction Using Deep Learning",
    "abstract": "Modeling and simulating a power distribution network (PDN) for printed\ncircuit boards (PCBs) with irregular board shapes and multi-layer stackup is\ncomputationally inefficient using full-wave simulations. This paper presents a\nnew concept of using deep learning for PDN impedance prediction. A boundary\nelement method (BEM) is applied to efficiently calculate the impedance for\narbitrary board shape and stackup. Then over one million boards with different\nshapes, stackup, IC location, and decap placement are randomly generated to\ntrain a deep neural network (DNN). The trained DNN can predict the impedance\naccurately for new board configurations that have not been used for training.\nThe consumed time using the trained DNN is only 0.1 seconds, which is over 100\ntimes faster than the BEM method and 5000 times faster than full-wave\nsimulations.",
    "descriptor": "",
    "authors": [
      "Ling Zhang",
      "Jack Juang",
      "Zurab Kiguradze",
      "Bo Pu",
      "Shuai Jin",
      "Songping Wu",
      "Zhiping Yang",
      "Chulsoon Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10693"
  },
  {
    "id": "arXiv:2106.10698",
    "title": "Plant Disease Detection Using Image Processing and Machine Learning",
    "abstract": "One of the important and tedious task in agricultural practices is the\ndetection of the disease on crops. It requires huge time as well as skilled\nlabor. This paper proposes a smart and efficient technique for detection of\ncrop disease which uses computer vision and machine learning techniques. The\nproposed system is able to detect 20 different diseases of 5 common plants with\n93% accuracy.",
    "descriptor": "",
    "authors": [
      "Pranesh Kulkarni",
      "Atharva Karwande",
      "Tejas Kolhe",
      "Soham Kamble",
      "Akshay Joshi",
      "Medha Wyawahare"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10698"
  },
  {
    "id": "arXiv:2106.10700",
    "title": "On predicting research grants productivity",
    "abstract": "Understanding the reasons associated with successful proposals is of\nparamount importance to improve evaluation processes. In this context, we\nanalyzed whether bibliometric features are able to predict the success of\nresearch grants. We extracted features aiming at characterizing the academic\nhistory of Brazilian researchers, including research topics, affiliations,\nnumber of publications and visibility. The extracted features were then used to\npredict grants productivity via machine learning in three major research areas,\nnamely Medicine, Dentistry and Veterinary Medicine. We found that research\nsubject and publication history play a role in predicting productivity. In\naddition, institution-based features turned out to be relevant when combined\nwith other features. While the best results outperformed text-based attributes,\nthe evaluated features were not highly discriminative. Our findings indicate\nthat predicting grants success, at least with the considered set of\nbibliometric features, is not a trivial task.",
    "descriptor": "",
    "authors": [
      "Jorge A. V. Tohalino",
      "Diego R. Amancio"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10700"
  },
  {
    "id": "arXiv:2106.10704",
    "title": "Better Training using Weight-Constrained Stochastic Dynamics",
    "abstract": "We employ constraints to control the parameter space of deep neural networks\nthroughout training. The use of customized, appropriately designed constraints\ncan reduce the vanishing/exploding gradients problem, improve smoothness of\nclassification boundaries, control weight magnitudes and stabilize deep neural\nnetworks, and thus enhance the robustness of training algorithms and the\ngeneralization capabilities of neural networks. We provide a general approach\nto efficiently incorporate constraints into a stochastic gradient Langevin\nframework, allowing enhanced exploration of the loss landscape. We also present\nspecific examples of constrained training methods motivated by orthogonality\npreservation for weight matrices and explicit weight normalizations.\nDiscretization schemes are provided both for the overdamped formulation of\nLangevin dynamics and the underdamped form, in which momenta further improve\nsampling efficiency. These optimization schemes can be used directly, without\nneeding to adapt neural network architecture design choices or to modify the\nobjective with regularization terms, and see performance improvements in\nclassification tasks.",
    "descriptor": "\nComments: ICML 2021 camera-ready. arXiv admin note: substantial text overlap with arXiv:2006.10114\n",
    "authors": [
      "Benedict Leimkuhler",
      "Tiffany Vlaar",
      "Timoth\u00e9e Pouchon",
      "Amos Storkey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10704"
  },
  {
    "id": "arXiv:2106.10705",
    "title": "Automated Deepfake Detection",
    "abstract": "In this paper, we propose to utilize Automated Machine Learning to\nautomatically search architecture for deepfake detection. Unlike previous\nworks, our method benefits from the superior capability of deep learning while\nrelieving us from the high labor cost in the manual network design process. It\nis experimentally proved that our proposed method not only outperforms previous\nnon-deep learning methods but achieves comparable or even better prediction\naccuracy compared to previous deep learning methods. To improve the generality\nof our method, especially when training data and testing data are manipulated\nby different methods, we propose a multi-task strategy in our network learning\nprocess, making it estimate potential manipulation regions in given samples as\nwell as predict whether the samples are real. Comparing to previous works using\nsimilar strategies, our method depends much less on prior knowledge, such as no\nneed to know which manipulation method is utilized and whether it is utilized\nalready. Extensive experimental results on two benchmark datasets demonstrate\nthe effectiveness of our proposed method on deepfake detection.",
    "descriptor": "",
    "authors": [
      "Ping Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10705"
  },
  {
    "id": "arXiv:2106.10707",
    "title": "Minimizing Delay in Network Function Visualization with Quantum  Computing",
    "abstract": "Network function virtualization (NFV) is a crucial technology for the 5G\nnetwork development because it can improve the flexibility of employing\nhardware and reduce the construction of base stations. There are vast service\nchains in NFV to meet users' requests, which are composed of a sequence of\nnetwork functions. These virtual network functions (VNFs) are implemented in\nvirtual machines by software and virtual environment. How to deploy VMs to\nprocess VNFs of the service chains as soon as possible when users' requests are\nreceived is very challenging to solve by traditional algorithms on a large\nscale. Compared with traditional algorithms, quantum computing has better\ncomputational performance because of quantum parallelism. We build an integer\nlinear programming model of the VNF scheduling problem with the objective of\nminimizing delays and transfer it into the quadratic unconstrained binary\noptimization (QUBO) model. Our proposed heuristic algorithm employs a quantum\nannealer to solve the model. Finally, we evaluate the computational results and\nexplore the feasibility of leveraging quantum computing to solve the VNFs\nscheduling problem.",
    "descriptor": "\nComments: Invited Paper by IEEE MASS 2021\n",
    "authors": [
      "Wenlu Xuan",
      "Zhongqi Zhao",
      "Lei Fan",
      "Zhu Han"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10707"
  },
  {
    "id": "arXiv:2106.10708",
    "title": "Memory Augmented Optimizers for Deep Learning",
    "abstract": "Popular approaches for minimizing loss in data-driven learning often involve\nan abstraction or an explicit retention of the history of gradients for\nefficient parameter updates. The aggregated history of gradients nudges the\nparameter updates in the right direction even when the gradients at any given\nstep are not informative. Although the history of gradients summarized in\nmeta-parameters or explicitly stored in memory has been shown effective in\ntheory and practice, the question of whether $all$ or only a subset of the\ngradients in the history are sufficient in deciding the parameter updates\nremains unanswered. In this paper, we propose a framework of memory-augmented\ngradient descent optimizers that retain a limited view of their gradient\nhistory in their internal memory. Such optimizers scale well to large real-life\ndatasets, and our experiments show that the memory augmented extensions of\nstandard optimizers enjoy accelerated convergence and improved performance on a\nmajority of computer vision and language tasks that we considered.\nAdditionally, we prove that the proposed class of optimizers with fixed-size\nmemory converge under assumptions of strong convexity, regardless of which\ngradients are selected or how they are linearly combined to form the update\nstep.",
    "descriptor": "\nComments: 24 Pages. Currently under review\n",
    "authors": [
      "Paul-Aymeric McRae",
      "Prasanna Parthasarathi",
      "Mahmoud Assran",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10708"
  },
  {
    "id": "arXiv:2106.10709",
    "title": "Spatial Covariance Matrix Reconstruction for DOA Estimation in Hybrid  Massive MIMO Systems with Multiple Radio Frequency Chains",
    "abstract": "Multiple signal classification (MUSIC) has been widely applied in\nmultiple-input multiple-output (MIMO) receivers for direction-of-arrival (DOA)\nestimation. To reduce the cost of radio frequency (RF) chains operating at\nmillimeter-wave bands, hybrid analog-digital structure has been adopted in\nmassive MIMO transceivers. In this situation, the received signals at the\nantennas are unavailable to the digital receiver, and as a consequence, the\nspatial covariance matrix (SCM), which is essential in MUSIC algorithm, cannot\nbe obtained using traditional sample average approach. Based on our previous\nwork, we propose a novel algorithm for SCM reconstruction in hybrid massive\nMIMO systems with multiple RF chains. By switching the analog beamformers to a\ngroup of predetermined DOAs, SCM can be reconstructed through the solutions of\na set of linear equations. In addition, based on insightful analysis on that\nlinear equations, a low-complexity algorithm, as well as a careful selection of\nthe predetermined DOAs, will be also presented in this paper. Simulation\nresults show that the proposed algorithms can reconstruct the SCM accurately so\nthat MUSIC algorithm can be well used for DOA estimation in hybrid massive MIMO\nsystems with multiple RF chains.",
    "descriptor": "",
    "authors": [
      "Yinsheng Liu",
      "Yiwei Yan",
      "Li You",
      "Wenji Wang",
      "Hongtao Duan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10709"
  },
  {
    "id": "arXiv:2106.10711",
    "title": "Transfer Bayesian Meta-learning via Weighted Free Energy Minimization",
    "abstract": "Meta-learning optimizes the hyperparameters of a training procedure, such as\nits initialization, kernel, or learning rate, based on data sampled from a\nnumber of auxiliary tasks. A key underlying assumption is that the auxiliary\ntasks, known as meta-training tasks, share the same generating distribution as\nthe tasks to be encountered at deployment time, known as meta-test tasks. This\nmay, however, not be the case when the test environment differ from the\nmeta-training conditions. To address shifts in task generating distribution\nbetween meta-training and meta-testing phases, this paper introduces weighted\nfree energy minimization (WFEM) for transfer meta-learning. We instantiate the\nproposed approach for non-parametric Bayesian regression and classification via\nGaussian Processes (GPs). The method is validated on a toy sinusoidal\nregression problem, as well as on classification using miniImagenet and CUB\ndata sets, through comparison with standard meta-learning of GP priors as\nimplemented by PACOH.",
    "descriptor": "\nComments: 9 pages, 5 figures, submitted to IEEE International Workshop on MACHINE LEARNING FOR SIGNAL PROCESSING 2021\n",
    "authors": [
      "Yunchuan Zhang",
      "Sharu Theresa Jose",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10711"
  },
  {
    "id": "arXiv:2106.10715",
    "title": "CPM-2: Large-scale Cost-effective Pre-trained Language Models",
    "abstract": "In recent years, the size of pre-trained language models (PLMs) has grown by\nleaps and bounds. However, efficiency issues of these large-scale PLMs limit\ntheir utilization in real-world scenarios. We present a suite of cost-effective\ntechniques for the use of PLMs to deal with the efficiency issues of\npre-training, fine-tuning, and inference. (1) We introduce knowledge\ninheritance to accelerate the pre-training process by exploiting existing PLMs\ninstead of training models from scratch. (2) We explore the best practice of\nprompt tuning with large-scale PLMs. Compared with conventional fine-tuning,\nprompt tuning significantly reduces the number of task-specific parameters. (3)\nWe implement a new inference toolkit, namely InfMoE, for using large-scale PLMs\nwith limited computational resources. Based on our cost-effective pipeline, we\npre-train two models: an encoder-decoder bilingual model with 11 billion\nparameters (CPM-2) and its corresponding MoE version with 198 billion\nparameters. In our experiments, we compare CPM-2 with mT5 on downstream tasks.\nExperimental results show that CPM-2 has excellent general language\nintelligence. Moreover, we validate the efficiency of InfMoE when conducting\ninference of large-scale models having tens of billions of parameters on a\nsingle GPU. All source code and model parameters are available at\nhttps://github.com/TsinghuaAI/CPM.",
    "descriptor": "",
    "authors": [
      "Zhengyan Zhang",
      "Yuxian Gu",
      "Xu Han",
      "Shengqi Chen",
      "Chaojun Xiao",
      "Zhenbo Sun",
      "Yuan Yao",
      "Fanchao Qi",
      "Jian Guan",
      "Pei Ke",
      "Yanzheng Cai",
      "Guoyang Zeng",
      "Zhixing Tan",
      "Zhiyuan Liu",
      "Minlie Huang",
      "Wentao Han",
      "Yang Liu",
      "Xiaoyan Zhu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10715"
  },
  {
    "id": "arXiv:2106.10716",
    "title": "Machine learning in the social and health sciences",
    "abstract": "The uptake of machine learning (ML) approaches in the social and health\nsciences has been rather slow, and research using ML for social and health\nresearch questions remains fragmented. This may be due to the separate\ndevelopment of research in the computational/data versus social and health\nsciences as well as a lack of accessible overviews and adequate training in ML\ntechniques for non data science researchers. This paper provides a meta-mapping\nof research questions in the social and health sciences to appropriate ML\napproaches, by incorporating the necessary requirements to statistical analysis\nin these disciplines. We map the established classification into description,\nprediction, and causal inference to common research goals, such as estimating\nprevalence of adverse health or social outcomes, predicting the risk of an\nevent, and identifying risk factors or causes of adverse outcomes. This\nmeta-mapping aims at overcoming disciplinary barriers and starting a fluid\ndialogue between researchers from the social and health sciences and\nmethodologically trained researchers. Such mapping may also help to fully\nexploit the benefits of ML while considering domain-specific aspects relevant\nto the social and health sciences, and hopefully contribute to the acceleration\nof the uptake of ML applications to advance both basic and applied social and\nhealth sciences research.",
    "descriptor": "",
    "authors": [
      "Anja K. Leist",
      "Matthias Klee",
      "Jung Hyun Kim",
      "David H. Rehkopf",
      "St\u00e9phane P. A. Bordas",
      "Graciela Muniz-Terrera",
      "Sara Wade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10716"
  },
  {
    "id": "arXiv:2106.10717",
    "title": "Optimal Strategies for Decision Theoretic Online Learning",
    "abstract": "We extend the drifting games analysis to continuous time and show that the\noptimal adversary, if the value function has strictly positive derivative up to\nfourth order is bronian motion.",
    "descriptor": "",
    "authors": [
      "Yoav Freund"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10717"
  },
  {
    "id": "arXiv:2106.10719",
    "title": "Challenges in Translation of Emotions in Multilingual User-Generated  Content: Twitter as a Case Study",
    "abstract": "Although emotions are universal concepts, transferring the different shades\nof emotion from one language to another may not always be straightforward for\nhuman translators, let alone for machine translation systems. Moreover, the\ncognitive states are established by verbal explanations of experience which is\nshaped by both the verbal and cultural contexts. There are a number of verbal\ncontexts where expression of emotions constitutes the pivotal component of the\nmessage. This is particularly true for User-Generated Content (UGC) which can\nbe in the form of a review of a product or a service, a tweet, or a social\nmedia post. Recently, it has become common practice for multilingual websites\nsuch as Twitter to provide an automatic translation of UGC to reach out to\ntheir linguistically diverse users. In such scenarios, the process of\ntranslating the user's emotion is entirely automatic with no human\nintervention, neither for post-editing nor for accuracy checking. In this\nresearch, we assess whether automatic translation tools can be a successful\nreal-life utility in transferring emotion in user-generated multilingual data\nsuch as tweets. We show that there are linguistic phenomena specific of Twitter\ndata that pose a challenge in translation of emotions in different languages.\nWe summarise these challenges in a list of linguistic features and show how\nfrequent these features are in different language pairs. We also assess the\ncapacity of commonly used methods for evaluating the performance of an MT\nsystem with respect to the preservation of emotion in the source text.",
    "descriptor": "",
    "authors": [
      "Hadeel Saadany",
      "Constantin Orasan",
      "Rocio Caro Quintana",
      "Felix do Carmo",
      "Leonardo Zilio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10719"
  },
  {
    "id": "arXiv:2106.10731",
    "title": "Neighborhood Contrastive Learning for Novel Class Discovery",
    "abstract": "In this paper, we address Novel Class Discovery (NCD), the task of unveiling\nnew classes in a set of unlabeled samples given a labeled dataset with known\nclasses. We exploit the peculiarities of NCD to build a new framework, named\nNeighborhood Contrastive Learning (NCL), to learn discriminative\nrepresentations that are important to clustering performance. Our contribution\nis twofold. First, we find that a feature extractor trained on the labeled set\ngenerates representations in which a generic query sample and its neighbors are\nlikely to share the same class. We exploit this observation to retrieve and\naggregate pseudo-positive pairs with contrastive learning, thus encouraging the\nmodel to learn more discriminative representations. Second, we notice that most\nof the instances are easily discriminated by the network, contributing less to\nthe contrastive loss. To overcome this issue, we propose to generate hard\nnegatives by mixing labeled and unlabeled samples in the feature space. We\nexperimentally demonstrate that these two ingredients significantly contribute\nto clustering performance and lead our model to outperform state-of-the-art\nmethods by a large margin (e.g., clustering accuracy +13% on CIFAR-100 and +8%\non ImageNet).",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Zhun Zhong",
      "Enrico Fini",
      "Subhankar Roy",
      "Zhiming Luo",
      "Elisa Ricci",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10731"
  },
  {
    "id": "arXiv:2106.10733",
    "title": "Mobile Sensing for Multipurpose Applications in Transportation",
    "abstract": "Routine and consistent data collection is required to address contemporary\ntransportation issues.The cost of data collection increases significantly when\nsophisticated machines are used to collect data. Due to this constraint, State\nDepartments of Transportation struggles to collect consistent data for\nanalyzing and resolving transportation problems in a timely manner. Recent\nadvancements in the sensors integrated into smartphones have resulted in a more\naffordable method of data collection.The primary objective of this study is to\ndevelop and implement a smartphone application for data collection.The\ncurrently designed app consists of three major modules: a frontend graphical\nuser interface (GUI), a sensor module, and a backend module. While the frontend\nuser interface enables interaction with the app, the sensor modules collect\nrelevant data such as video and accelerometer readings while the app is in use.\nThe backend, on the other hand, is made up of firebase storage, which is used\nto store the gathered data.In comparison to other developed apps for collecting\npavement information, this current app is not overly reliant on the internet\nenabling the app to be used in areas of restricted internet access.The\ndeveloped application was evaluated by collecting data on the i70W highway\nconnecting Columbia, Missouri, and Kansas City, Missouri.The data was analyzed\nfor a variety of purposes, including calculating the International Roughness\nIndex (IRI), identifying pavement distresses, and understanding driver's\nbehaviour and environment .The results of the application indicate that the\ndata collected by the app is of high quality.",
    "descriptor": "",
    "authors": [
      "Armstrong Aboah",
      "Michael Boeding",
      "Yaw Adu-Gyamfi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10733"
  },
  {
    "id": "arXiv:2106.10734",
    "title": "Is Shapley Value fair? Improving Client Selection for Mavericks in  Federated Learning",
    "abstract": "Shapley Value is commonly adopted to measure and incentivize client\nparticipation in federated learning. In this paper, we show -- theoretically\nand through simulations -- that Shapley Value underestimates the contribution\nof a common type of client: the Maverick. Mavericks are clients that differ\nboth in data distribution and data quantity and can be the sole owners of\ncertain types of data. Selecting the right clients at the right moment is\nimportant for federated learning to reduce convergence times and improve\naccuracy. We propose FedEMD, an adaptive client selection strategy based on the\nWasserstein distance between the local and global data distributions. As FedEMD\nadapts the selection probability such that Mavericks are preferably selected\nwhen the model benefits from improvement on rare classes, it consistently\nensures the fast convergence in the presence of different types of Mavericks.\nCompared to existing strategies, including Shapley Value-based ones, FedEMD\nimproves the convergence of neural network classifiers by at least 26.9% for\nFedAvg aggregation compared with the state of the art.",
    "descriptor": "",
    "authors": [
      "Jiyue Huang",
      "Chi Hong",
      "Lydia Y. Chen",
      "Stefanie Roos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.10734"
  },
  {
    "id": "arXiv:2106.10737",
    "title": "Windowing and random weighting based cubature RTS smoothing for target  tracking",
    "abstract": "This paper presents windowing and random weighting (WRW) based adaptive\ncubature Rauch Tung Striebel (CRTS) smoother (WRWACRTS). The Unscented KF\n(WRWUKF) has already existed as an alternative to nonlinear smoothing\nsolutions. In the proposed method, both windowing and random weighted\nestimation methods are combined together and used to estimate the noise\nstatistics. Subsequently, the weights of each window are adjusting randomly,\nand update the process and measurement noise covariances matrices at each\nepoch. The developed WRWACRTS algorithm overcomes the limitation of the\nconventional CKS. The Lyapunov function-based approach is used to investigate\nthe convergence proof of the WRWACRTS algorithm. A numerical example is shown\nto demonstrate the performance of the proposed algorithm.",
    "descriptor": "\nComments: 10 pages, 3 figures, 1 table\n",
    "authors": [
      "Mundla Narasimhappa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10737"
  },
  {
    "id": "arXiv:2106.10740",
    "title": "Flash Crash for Cash: Cyber Threats in Decentralized Finance",
    "abstract": "Decentralized Finance (DeFi) took shape in 2020. An unprecedented amount of\nover 14 billion USD moved into DeFi projects offering trading, loans and\ninsurance. But its growth has also drawn the attention of malicious actors.\nMany projects were exploited as quickly as they launched and millions of USD\nwere lost. While many developers understand integer overflows and reentrancy\nattacks, security threats to the DeFi ecosystem are more complex and still\npoorly understood. In this paper we provide the first overview of in-the-wild\nDeFi security incidents. We observe that many of these exploits are market\nattacks, weaponizing weakly implemented business logic in one protocol with\ncredit provided by another to inflate appropriations. Rather than misusing\nindividual protocols, attackers increasingly use DeFi's strength of\npermissionless composability against itself. By providing the first holistic\nanalysis of real-world security incidents within the nascent financial\necosystem DeFi is, we hope to inform threat modeling in decentralized\ncryptoeconomic initiatives in the years ahead.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Kris Oosthoek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.10740"
  },
  {
    "id": "arXiv:2106.10744",
    "title": "On the Cryptographic Hardness of Learning Single Periodic Neurons",
    "abstract": "We show a simple reduction which demonstrates the cryptographic hardness of\nlearning a single periodic neuron over isotropic Gaussian distributions in the\npresence of noise. More precisely, our reduction shows that any polynomial-time\nalgorithm (not necessarily gradient-based) for learning such functions under\nsmall noise implies a polynomial-time quantum algorithm for solving worst-case\nlattice problems, whose hardness form the foundation of lattice-based\ncryptography. Our core hard family of functions, which are well-approximated by\none-layer neural networks, take the general form of a univariate periodic\nfunction applied to an affine projection of the data. These functions have\nappeared in previous seminal works which demonstrate their hardness against\ngradient-based (Shamir'18), and Statistical Query (SQ) algorithms (Song et\nal.'17). We show that if (polynomially) small noise is added to the labels, the\nintractability of learning these functions applies to all polynomial-time\nalgorithms under the aforementioned cryptographic assumptions.\nMoreover, we demonstrate the necessity of noise in the hardness result by\ndesigning a polynomial-time algorithm for learning certain families of such\nfunctions under exponentially small adversarial noise. Our proposed algorithm\nis not a gradient-based or an SQ algorithm, but is rather based on the\ncelebrated Lenstra-Lenstra-Lov\\'asz (LLL) lattice basis reduction algorithm.\nFurthermore, in the absence of noise, this algorithm can be directly applied to\nsolve CLWE detection (Bruna et al.'21) and phase retrieval with an optimal\nsample complexity of $d+1$ samples. In the former case, this improves upon the\nquadratic-in-$d$ sample complexity required in (Bruna et al.'21). In the latter\ncase, this improves upon the state-of-the-art AMP-based algorithm, which\nrequires approximately $1.128d$ samples (Barbier et al.'19).",
    "descriptor": "\nComments: 54 pages\n",
    "authors": [
      "Min Jae Song",
      "Ilias Zadik",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10744"
  },
  {
    "id": "arXiv:2106.10745",
    "title": "Calliar: An Online Handwritten Dataset for Arabic Calligraphy",
    "abstract": "Calligraphy is an essential part of the Arabic heritage and culture. It has\nbeen used in the past for the decoration of houses and mosques. Usually, such\ncalligraphy is designed manually by experts with aesthetic insights. In the\npast few years, there has been a considerable effort to digitize such type of\nart by either taking a photo of decorated buildings or drawing them using\ndigital devices. The latter is considered an online form where the drawing is\ntracked by recording the apparatus movement, an electronic pen for instance, on\na screen. In the literature, there are many offline datasets collected with a\ndiversity of Arabic styles for calligraphy. However, there is no available\nonline dataset for Arabic calligraphy. In this paper, we illustrate our\napproach for the collection and annotation of an online dataset for Arabic\ncalligraphy called Calliar that consists of 2,500 sentences. Calliar is\nannotated for stroke, character, word and sentence level prediction.",
    "descriptor": "",
    "authors": [
      "Zaid Alyafeai",
      "Maged S. Al-shaibani",
      "Mustafa Ghaleb",
      "Yousif Ahmed Al-Wajih"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10745"
  },
  {
    "id": "arXiv:2106.10753",
    "title": "Opportunities and challenges in partitioning the graph measure space of  real-world networks",
    "abstract": "Based on a large dataset containing thousands of real-world networks ranging\nfrom genetic, protein interaction, and metabolic networks to brain, language,\necology, and social networks we search for defining structural measures of the\ndifferent complex network domains (CND). We calculate 208 measures for all\nnetworks and using a comprehensive and scrupulous workflow of statistical and\nmachine learning methods we investigated the limitations and possibilities of\nidentifying the key graph measures of CNDs. Our approach managed to identify\nwell distinguishable groups of network domains and confer their relevant\nfeatures. These features turn out to be CND specific and not unique even at the\nlevel of individual CNDs. The presented methodology may be applied to other\nsimilar scenarios involving highly unbalanced and skewed datasets.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "M\u00e1t\u00e9 J\u00f3zsa",
      "Alp\u00e1r S. L\u00e1z\u00e1r",
      "Zsolt I. L\u00e1z\u00e1r"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.10753"
  },
  {
    "id": "arXiv:2106.10755",
    "title": "Online Rank-Revealing Block-Term Tensor Decomposition",
    "abstract": "The so-called block-term decomposition (BTD) tensor model, especially in its\nrank-$(L_r,L_r,1)$ version, has been recently receiving increasing attention\ndue to its enhanced ability of representing systems and signals that are\ncomposed of \\emph{block} components of rank higher than one, a scenario\nencountered in numerous and diverse applications. Its uniqueness and\napproximation have thus been thoroughly studied. The challenging problem of\nestimating the BTD model structure, namely the number of block terms (rank) and\ntheir individual (block) ranks, is of crucial importance in practice and has\nonly recently started to attract significant attention. In data-streaming\nscenarios and/or big data applications, where the tensor dimension in one of\nits modes grows in time or can only be processed incrementally, it is essential\nto be able to perform model selection and computation in a recursive\n(incremental/online) manner. To date there is only one such work in the\nliterature concerning the (general rank-$(L,M,N)$) BTD model, which proposes an\nincremental method, however with the BTD rank and block ranks assumed to be\na-priori known and time invariant. In this preprint, a novel approach to\nrank-$(L_r,L_r,1)$ BTD model selection and tracking is proposed, based on the\nidea of imposing column sparsity jointly on the factors and estimating the\nranks as the numbers of factor columns of nonnegligible magnitude. An online\nmethod of the alternating iteratively reweighted least squares (IRLS) type is\ndeveloped and shown to be computationally efficient and fast converging, also\nallowing the model ranks to change in time. Its time and memory efficiency are\nevaluated and favorably compared with those of the batch approach. Simulation\nresults are reported that demonstrate the effectiveness of the proposed scheme\nin both selecting and tracking the correct BTD model.",
    "descriptor": "",
    "authors": [
      "Athanasios A. Rontogiannis",
      "Eleftherios Kofidis",
      "Paris V. Giampouras"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10755"
  },
  {
    "id": "arXiv:2106.10759",
    "title": "Robust Regression via Model Based Methods",
    "abstract": "The mean squared error loss is widely used in many applications, including\nauto-encoders, multi-target regression, and matrix factorization, to name a\nfew. Despite computational advantages due to its differentiability, it is not\nrobust to outliers. In contrast, l_p norms are known to be robust, but cannot\nbe optimized via, e.g., stochastic gradient descent, as they are\nnon-differentiable. We propose an algorithm inspired by so-called model-based\noptimization (MBO) [35, 36], which replaces a non-convex objective with a\nconvex model function and alternates between optimizing the model function and\nupdating the solution. We apply this to robust regression, proposing SADM, a\nstochastic variant of the Online Alternating Direction Method of Multipliers\n(OADM) [50] to solve the inner optimization in MBO. We show that SADM converges\nwith the rate O(log T/T). Finally, we demonstrate experimentally (a) the\nrobustness of l_p norms to outliers and (b) the efficiency of our proposed\nmodel-based algorithms in comparison with gradient methods on autoencoders and\nmulti-target regression.",
    "descriptor": "",
    "authors": [
      "Armin Moharrer",
      "Khashayar Kamran",
      "Edmund Ye",
      "Stratis Ioannidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10759"
  },
  {
    "id": "arXiv:2106.10760",
    "title": "On Stein Variational Neural Network Ensembles",
    "abstract": "Ensembles of deep neural networks have achieved great success recently, but\nthey do not offer a proper Bayesian justification. Moreover, while they allow\nfor averaging of predictions over several hypotheses, they do not provide any\nguarantees for their diversity, leading to redundant solutions in function\nspace. In contrast, particle-based inference methods, such as Stein variational\ngradient descent (SVGD), offer a Bayesian framework, but rely on the choice of\na kernel to measure the similarity between ensemble members. In this work, we\nstudy different SVGD methods operating in the weight space, function space, and\nin a hybrid setting. % Defining the kernel directly on the neural network\nfunctions seems promising to overcome the limitations of deep ensembles. %\nHowever, ensuring diversity in function space while maintaining SVGD's\ntheoretical guarantees is not trivial. % In this work, we provide an overview\nover different ensembling and SVGD methods in weight space and function space\nand propose new and assess their theoretical and empirical properties on\nsynthetic and real-world tasks. We compare the SVGD approaches to other\nensembling-based methods in terms of their theoretical properties and assess\ntheir empirical performance on synthetic and real-world tasks. We find that\nSVGD using functional and hybrid kernels can overcome the limitations of deep\nensembles. It improves on functional diversity and uncertainty estimation and\napproaches the true Bayesian posterior more closely. Moreover, we show that\nusing stochastic SVGD updates, as opposed to the standard deterministic ones,\ncan further improve the performance.",
    "descriptor": "",
    "authors": [
      "Francesco D'Angelo",
      "Vincent Fortuin",
      "Florian Wenzel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10760"
  },
  {
    "id": "arXiv:2106.10761",
    "title": "Generalization in the Face of Adaptivity: A Bayesian Perspective",
    "abstract": "Repeated use of a data sample via adaptively chosen queries can rapidly lead\nto overfitting, wherein the issued queries yield answers on the sample that\ndiffer wildly from the values of those queries on the underlying data\ndistribution. Differential privacy provides a tool to ensure generalization\ndespite adaptively-chosen queries, but its worst-case nature means that it\ncannot, for example, yield improved results for low-variance queries. In this\npaper, we give a simple new characterization that illuminates the core problem\nof adaptive data analysis. We show explicitly that the harms of adaptivity come\nfrom the covariance between the behavior of future queries and a Bayes\nfactor-based measure of how much information about the data sample was encoded\nin the responses given to past queries. We leverage this intuition to introduce\na new stability notion; we then use it to prove new generalization results for\nthe most basic noise-addition mechanisms (Laplace and Gaussian noise addition),\nwith guarantees that scale with the variance of the queries rather than the\nsquare of their range. Our characterization opens the door to new insights and\nnew algorithms for the fundamental problem of achieving generalization in\nadaptive data analysis.",
    "descriptor": "",
    "authors": [
      "Moshe Shenfeld",
      "Katrina Ligett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10761"
  },
  {
    "id": "arXiv:2106.10766",
    "title": "Learning to Track Object Position through Occlusion",
    "abstract": "Occlusion is one of the most significant challenges encountered by object\ndetectors and trackers. While both object detection and tracking has received a\nlot of attention in the past, most existing methods in this domain do not\ntarget detecting or tracking objects when they are occluded. However, being\nable to detect or track an object of interest through occlusion has been a long\nstanding challenge for different autonomous tasks. Traditional methods that\nemploy visual object trackers with explicit occlusion modeling experience drift\nand make several fundamental assumptions about the data. We propose to address\nthis with a `tracking-by-detection` approach that builds upon the success of\nregion based video object detectors. Our video level object detector uses a\nnovel recurrent computational unit at its core that enables long term\npropagation of object features even under occlusion. Finally, we compare our\napproach with existing state-of-the-art video object detectors and show that\nour approach achieves superior results on a dataset of furniture assembly\nvideos collected from the internet, where small objects like screws, nuts, and\nbolts often get occluded from the camera viewpoint.",
    "descriptor": "",
    "authors": [
      "Satyaki Chakraborty",
      "Martial Hebert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10766"
  },
  {
    "id": "arXiv:2106.10771",
    "title": "Multirate Training of Neural Networks",
    "abstract": "We propose multirate training of neural networks: partitioning neural network\nparameters into \"fast\" and \"slow\" parts which are trained simultaneously using\ndifferent learning rates. By choosing appropriate partitionings we can obtain\nlarge computational speed-ups for transfer learning tasks. We show that for\nvarious transfer learning applications in vision and NLP we can fine-tune deep\nneural networks in almost half the time, without reducing the generalization\nperformance of the resulting model. We also discuss other splitting choices for\nthe neural network parameters which are beneficial in enhancing generalization\nperformance in settings where neural networks are trained from scratch.\nFinally, we propose an additional multirate technique which can learn different\nfeatures present in the data by training the full network on different time\nscales simultaneously. The benefits of using this approach are illustrated for\nResNet architectures on image data. Our paper unlocks the potential of using\nmultirate techniques for neural network training and provides many starting\npoints for future work in this area.",
    "descriptor": "",
    "authors": [
      "Tiffany Vlaar",
      "Benedict Leimkuhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10771"
  },
  {
    "id": "arXiv:2106.10773",
    "title": "Neural Spectral Marked Point Processes",
    "abstract": "Self- and mutually-exciting point processes are popular models in machine\nlearning and statistics for dependent discrete event data. To date, most\nexisting models assume stationary kernels (including the classical Hawkes\nprocesses) and simple parametric models. Modern applications with complex event\ndata require more general point process models that can incorporate contextual\ninformation of the events, called marks, besides the temporal and location\ninformation. Moreover, such applications often require non-stationary models to\ncapture more complex spatio-temporal dependence. To tackle these challenges, a\nkey question is to devise a versatile influence kernel in the point process\nmodel. In this paper, we introduce a novel and general neural network-based\nnon-stationary influence kernel with high expressiveness for handling complex\ndiscrete events data while providing theoretical performance guarantees. We\ndemonstrate the superior performance of our proposed method compared with the\nstate-of-the-art on synthetic and real data.",
    "descriptor": "",
    "authors": [
      "Shixiang Zhu",
      "Haoyun Wang",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10773"
  },
  {
    "id": "arXiv:2106.10775",
    "title": "Covariance Matching based robust Adaptive Cubature Kalman Filter",
    "abstract": "This letter explores covariance matching-based adaptive robust cubature\nKalman filter (CMRACKF). In this method, the innovation sequence is used to\ndetermine the covariance matrix of measurement noise that can overcome the\nlimitation of conventional CKF. In the proposed algorithm, weights are\nadaptively adjusted and used for updating the measurement noise covariance\nmatrices online. It can also enhance the adaptive capability of the ACKF. The\nsimulation results are illustrated to evaluate the performance of the proposed\nalgorithm.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Mundla Narasimhappa",
      "Sesham Srinu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10775"
  },
  {
    "id": "arXiv:2106.10776",
    "title": "Context-Aware Legal Citation Recommendation using Deep Learning",
    "abstract": "Lawyers and judges spend a large amount of time researching the proper legal\nauthority to cite while drafting decisions. In this paper, we develop a\ncitation recommendation tool that can help improve efficiency in the process of\nopinion drafting. We train four types of machine learning models, including a\ncitation-list based method (collaborative filtering) and three context-based\nmethods (text similarity, BiLSTM and RoBERTa classifiers). Our experiments show\nthat leveraging local textual context improves recommendation, and that deep\nneural models achieve decent performance. We show that non-deep text-based\nmethods benefit from access to structured case metadata, but deep models only\nbenefit from such access when predicting from context of insufficient length.\nWe also find that, even after extensive training, RoBERTa does not outperform a\nrecurrent neural model, despite its benefits of pretraining. Our behavior\nanalysis of the RoBERTa model further shows that predictive performance is\nstable across time and citation classes.",
    "descriptor": "\nComments: 10 pages published in Proceedings of ICAIL 2021; link to data here: this https URL ; code available here: this https URL\n",
    "authors": [
      "Zihan Huang",
      "Charles Low",
      "Mengqiu Teng",
      "Hongyi Zhang",
      "Daniel E. Ho",
      "Mark S. Krass",
      "Matthias Grabmair"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10776"
  },
  {
    "id": "arXiv:2106.10777",
    "title": "Adversarial Manifold Matching via Deep Metric Learning for Generative  Modeling",
    "abstract": "We propose a manifold matching approach to generative models which includes a\ndistribution generator (or data generator) and a metric generator. In our\nframework, we view the real data set as some manifold embedded in a\nhigh-dimensional Euclidean space. The distribution generator aims at generating\nsamples that follow some distribution condensed around the real data manifold.\nIt is achieved by matching two sets of points using their geometric shape\ndescriptors, such as centroid and $p$-diameter, with learned distance metric;\nthe metric generator utilizes both real data and generated samples to learn a\ndistance metric which is close to some intrinsic geodesic distance on the real\ndata manifold. The produced distance metric is further used for manifold\nmatching. The two networks are learned simultaneously during the training\nprocess. We apply the approach on both unsupervised and supervised learning\ntasks: in unconditional image generation task, the proposed method obtains\ncompetitive results compared with existing generative models; in\nsuper-resolution task, we incorporate the framework in perception-based models\nand improve visual qualities by producing samples with more natural textures.\nBoth theoretical analysis and real data experiments guarantee the feasibility\nand effectiveness of the proposed framework.",
    "descriptor": "",
    "authors": [
      "Mengyu Dai",
      "Haibin Hang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10777"
  },
  {
    "id": "arXiv:2106.10782",
    "title": "Strong Singleton type upper bounds for linear insertion-deletion codes",
    "abstract": "The insertion-delation codes was motivated to correct the synchronization\nerrors. Several new Singleton type upper bounds for the insertion-deletion\ndistances were proved for linear codes over a general finite field ${\\bf F}_q$\nin 2021. It is a open problem if there exists a sequence of linear $[n_t,\nk_t]_q$ codes over ${\\bf F}_q$ with insdel distances $d_t$ and the lengths\n$n_t$ go to the infinity, such that $$\\lim_{t \\longrightarrow \\infty}\n\\frac{k_t}{n_t} \\geq \\frac{1}{2},$$ and $$\\lim_{t \\longrightarrow \\infty}\n\\frac{d_t}{2n_t}>0.$$ In this paper we give some new Singleton type upper\nbounds for the insertion-deletion distances for linear codes over ${\\bf F}_q$,\nwhich are much stronger than the previous bounds. Our result implies that\nasymptotically when the lengths goes to the infinity and the information rate\nis bigger than or equal to $\\frac{1}{2}$ then relative insdel distances go to\nthe zero. More accurately the insdel distances of such linear codes is smaller\nthan a fixed constant. Hence over an arbitrary fixed finite field ${\\bf F}_q$\nlinear codes of rate bigger than or equal to $\\frac{1}{2}$ have very small\ninsertion-delation error-correcting capabilities. This partially answers a\nquestion proposed by Cheng, Guruswami, Haeupler and Li about the sharp\nthreshold of the rate $\\frac{1}{2}$ for linear insertion-deletion codes.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.10782"
  },
  {
    "id": "arXiv:2106.10783",
    "title": "OptiDICE: Offline Policy Optimization via Stationary Distribution  Correction Estimation",
    "abstract": "We consider the offline reinforcement learning (RL) setting where the agent\naims to optimize the policy solely from the data without further environment\ninteractions. In offline RL, the distributional shift becomes the primary\nsource of difficulty, which arises from the deviation of the target policy\nbeing optimized from the behavior policy used for data collection. This\ntypically causes overestimation of action values, which poses severe problems\nfor model-free algorithms that use bootstrapping. To mitigate the problem,\nprior offline RL algorithms often used sophisticated techniques that encourage\nunderestimation of action values, which introduces an additional set of\nhyperparameters that need to be tuned properly. In this paper, we present an\noffline RL algorithm that prevents overestimation in a more principled way. Our\nalgorithm, OptiDICE, directly estimates the stationary distribution corrections\nof the optimal policy and does not rely on policy-gradients, unlike previous\noffline RL algorithms. Using an extensive set of benchmark datasets for offline\nRL, we show that OptiDICE performs competitively with the state-of-the-art\nmethods.",
    "descriptor": "\nComments: 26 pages, 11 figures, Accepted at ICML 2021\n",
    "authors": [
      "Jongmin Lee",
      "Wonseok Jeon",
      "Byung-Jun Lee",
      "Joelle Pineau",
      "Kee-Eung Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10783"
  },
  {
    "id": "arXiv:2106.10784",
    "title": "iDARTS: Differentiable Architecture Search with Stochastic Implicit  Gradients",
    "abstract": "\\textit{Differentiable ARchiTecture Search} (DARTS) has recently become the\nmainstream of neural architecture search (NAS) due to its efficiency and\nsimplicity. With a gradient-based bi-level optimization, DARTS alternately\noptimizes the inner model weights and the outer architecture parameter in a\nweight-sharing supernet. A key challenge to the scalability and quality of the\nlearned architectures is the need for differentiating through the inner-loop\noptimisation. While much has been discussed about several potentially fatal\nfactors in DARTS, the architecture gradient, a.k.a. hypergradient, has received\nless attention. In this paper, we tackle the hypergradient computation in DARTS\nbased on the implicit function theorem, making it only depends on the obtained\nsolution to the inner-loop optimization and agnostic to the optimization path.\nTo further reduce the computational requirements, we formulate a stochastic\nhypergradient approximation for differentiable NAS, and theoretically show that\nthe architecture optimization with the proposed method, named iDARTS, is\nexpected to converge to a stationary point. Comprehensive experiments on two\nNAS benchmark search spaces and the common NAS search space verify the\neffectiveness of our proposed method. It leads to architectures outperforming,\nwith large margins, those learned by the baseline methods.",
    "descriptor": "\nComments: ICML2021\n",
    "authors": [
      "Miao Zhang",
      "Steven Su",
      "Shirui Pan",
      "Xiaojun Chang",
      "Ehsan Abbasnejad",
      "Reza Haffari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10784"
  },
  {
    "id": "arXiv:2106.10785",
    "title": "Adversarial Attack on Graph Neural Networks as An Influence Maximization  Problem",
    "abstract": "Graph neural networks (GNNs) have attracted increasing interests. With broad\ndeployments of GNNs in real-world applications, there is an urgent need for\nunderstanding the robustness of GNNs under adversarial attacks, especially in\nrealistic setups. In this work, we study the problem of attacking GNNs in a\nrestricted and realistic setup, by perturbing the features of a small set of\nnodes, with no access to model parameters and model predictions. Our formal\nanalysis draws a connection between this type of attacks and an influence\nmaximization problem on the graph. This connection not only enhances our\nunderstanding on the problem of adversarial attack on GNNs, but also allows us\nto propose a group of effective and practical attack strategies. Our\nexperiments verify that the proposed attack strategies significantly degrade\nthe performance of three popular GNN models and outperform baseline adversarial\nattack strategies.",
    "descriptor": "",
    "authors": [
      "Jiaqi Ma",
      "Junwei Deng",
      "Qiaozhu Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10785"
  },
  {
    "id": "arXiv:2106.10786",
    "title": "ROPE: Reading Order Equivariant Positional Encoding for Graph-based  Document Information Extraction",
    "abstract": "Natural reading orders of words are crucial for information extraction from\nform-like documents. Despite recent advances in Graph Convolutional Networks\n(GCNs) on modeling spatial layout patterns of documents, they have limited\nability to capture reading orders of given word-level node representations in a\ngraph. We propose Reading Order Equivariant Positional Encoding (ROPE), a new\npositional encoding technique designed to apprehend the sequential presentation\nof words in documents. ROPE generates unique reading order codes for\nneighboring words relative to the target word given a word-level graph\nconnectivity. We study two fundamental document entity extraction tasks\nincluding word labeling and word grouping on the public FUNSD dataset and a\nlarge-scale payment dataset. We show that ROPE consistently improves existing\nGCNs with a margin up to 8.4% F1-score.",
    "descriptor": "\nComments: Accepted to ACL-IJCNLP 2021 (Oral)\n",
    "authors": [
      "Chen-Yu Lee",
      "Chun-Liang Li",
      "Chu Wang",
      "Renshen Wang",
      "Yasuhisa Fujii",
      "Siyang Qin",
      "Ashok Popat",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10786"
  },
  {
    "id": "arXiv:2106.10789",
    "title": "An empirical evaluation of the usefulness of Tree Kernels for  Commit-time Defect Detection in large software systems",
    "abstract": "Defect detection at commit check-in time prevents the introduction of defects\ninto software systems. Current defect detection approaches rely on metric-based\nmodels which are not very accurate and whose results are not directly useful\nfor developers. We propose a method to detect bug-inducing commits by comparing\nthe incoming changes with all past commits in the project, considering both\nthose that introduced defects and those that did not. Our method considers\nindividual changes in the commit separately, at the method-level granularity.\nDoing so helps developers as they are informed of specific methods that need\nfurther attention instead of being told that the entire commit is problematic.\nOur approach represents source code as abstract syntax trees and uses tree\nkernels to estimate the similarity of the code with previous commits. We\nexperiment with subtree kernels (STK), subset tree kernels (SSTK), or partial\ntree kernels (PTK). An incoming change is then classified using a K-NN\nclassifier on the past changes. We evaluate our approach on the BigCloneBench\nbenchmark and on the Technical Debt dataset, using the NiCad clone detector as\nthe baseline. Our experiments with the BigCloneBench benchmark show that the\ntree kernel approach can detect clones with a comparable MAP to that of NiCad.\nAlso, on defect detection with the Technical Debt dataset, tree kernels are\nleast as effective as NiCad with MRR, F-score, and Accuracy of 0.87, 0.80, and\n0.82 respectively.",
    "descriptor": "",
    "authors": [
      "Hareem Sahar",
      "Yuxin Liu",
      "Abram Hindle",
      "Denilson Barbosa"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.10789"
  },
  {
    "id": "arXiv:2106.10795",
    "title": "Large-scale image segmentation based on distributed clustering  algorithms",
    "abstract": "Many approaches to 3D image segmentation are based on hierarchical clustering\nof supervoxels into image regions. Here we describe a distributed algorithm\ncapable of handling a tremendous number of supervoxels. The algorithm works\nrecursively, the regions are divided into chunks that are processed\nindependently in parallel by multiple workers. At each round of the recursive\nprocedure, the chunk size in all dimensions are doubled until a single chunk\nencompasses the entire image. The final result is provably independent of the\nchunking scheme, and the same as if the entire image were processed without\ndivision into chunks. This is nontrivial because a pair of adjacent regions is\nscored by some statistical property (e.g. mean or median) of the affinities at\nthe interface, and the interface may extend over arbitrarily many chunks. The\ntrick is to delay merge decisions for regions that touch chunk boundaries, and\nonly complete them in a later round after the regions are fully contained\nwithin a chunk. We demonstrate the algorithm by clustering an affinity graph\nwith over 1.5 trillion edges between 135 billion supervoxels derived from a 3D\nelectron microscopic brain image.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Ran Lu",
      "Aleksandar Zlateski",
      "H. Sebastian Seung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10795"
  },
  {
    "id": "arXiv:2106.10796",
    "title": "CD-SGD: Distributed Stochastic Gradient Descent with Compression and  Delay Compensation",
    "abstract": "Communication overhead is the key challenge for distributed training.\nGradient compression is a widely used approach to reduce communication traffic.\nWhen combining with parallel communication mechanism method like pipeline,\ngradient compression technique can greatly alleviate the impact of\ncommunication overhead. However, there exists two problems of gradient\ncompression technique to be solved. Firstly, gradient compression brings in\nextra computation cost, which will delay the next training iteration. Secondly,\ngradient compression usually leads to the decrease of convergence accuracy.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Enda Yu",
      "Dezun Dong",
      "Yemao Xu",
      "Shuo Ouyang",
      "Xiangke Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.10796"
  },
  {
    "id": "arXiv:2106.10799",
    "title": "Performance Evaluation of Cooperative NOMA-based Improved Hybrid SWIPT  Protocol",
    "abstract": "This study proposes the integration of a cooperative non-orthogonal multiple\naccess (CNOMA) and improved hybrid simultaneous wireless information and power\ntransfer (IHS SWIPT) protocol (termed as CNOMA-IHS) to enhance the spectral\nefficiency (SE) of a downlink (DL) CNOMA communication system. CNOMA-IHS scheme\ncan enhance the ergodic sum capacity (ESC) and energy efficiency (EE) of DL\nCNOMA by transferring additional symbols towards the users and energize the\nrelay operation as well without any additional resources (e.g., time\nslot/frequency/code). The analytical and simulation results indicate that the\nproposed CNOMA-IHS scheme outperforms other existing SWIPT-based schemes (e.g.,\nCNOMA with hybrid SWIPT, CNOMA with power-splitting SWIPT, wireless-powered\nCNOMA, CNOMA with time switching SWIPT, and orthogonal multiple access with IHS\nSWIPT) in terms of the ESC. Moreover, the CNOMA-IHS scheme also enhances EE\ncompared with other conventional TS-SWIPT-based schemes, which is also\nillustrated by the simulation results. In addition, the proposed CNOMA-IHS\nscheme with the considered EE optimization technique outplayed the proposed\nCNOMA-IHS scheme without EE optimization and other existing TS-SWIPT-based\nschemes in terms of EE.",
    "descriptor": "",
    "authors": [
      "Ahmed Al Amin",
      "Soo Young Shin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10799"
  },
  {
    "id": "arXiv:2106.10800",
    "title": "Lossy Compression for Lossless Prediction",
    "abstract": "Most data is automatically collected and only ever \"seen\" by algorithms. Yet,\ndata compressors preserve perceptual fidelity rather than just the information\nneeded by algorithms performing downstream tasks. In this paper, we\ncharacterize the bit-rate required to ensure high performance on all predictive\ntasks that are invariant under a set of transformations, such as data\naugmentations. Based on our theory, we design unsupervised objectives for\ntraining neural compressors. Using these objectives, we train a generic image\ncompressor that achieves substantial rate savings (more than $1000\\times$ on\nImageNet) compared to JPEG on 8 datasets, without decreasing downstream\nclassification performance.",
    "descriptor": "",
    "authors": [
      "Yann Dubois",
      "Benjamin Bloem-Reddy",
      "Karen Ullrich",
      "Chris J. Maddison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10800"
  },
  {
    "id": "arXiv:2106.10807",
    "title": "Adversarial Examples Make Strong Poisons",
    "abstract": "The adversarial machine learning literature is largely partitioned into\nevasion attacks on testing data and poisoning attacks on training data. In this\nwork, we show that adversarial examples, originally intended for attacking\npre-trained models, are even more effective for data poisoning than recent\nmethods designed specifically for poisoning. Our findings indicate that\nadversarial examples, when assigned the original label of their natural base\nimage, cannot be used to train a classifier for natural images. Furthermore,\nwhen adversarial examples are assigned their adversarial class label, they are\nuseful for training. This suggests that adversarial examples contain useful\nsemantic content, just with the ``wrong'' labels (according to a network, but\nnot a human). Our method, adversarial poisoning, is substantially more\neffective than existing poisoning methods for secure dataset release, and we\nrelease a poisoned version of ImageNet, ImageNet-P, to encourage research into\nthe strength of this form of data obfuscation.",
    "descriptor": "",
    "authors": [
      "Liam Fowl",
      "Micah Goldblum",
      "Ping-yeh Chiang",
      "Jonas Geiping",
      "Wojtek Czaja",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.10807"
  },
  {
    "id": "arXiv:2106.10811",
    "title": "DiGS : Divergence guided shape implicit neural representation for  unoriented point clouds",
    "abstract": "Neural shape representations have recently shown to be effective in shape\nanalysis and reconstruction tasks. Existing neural network methods require\npoint coordinates and corresponding normal vectors to learn the implicit level\nsets of the shape. Normal vectors are often not provided as raw data,\ntherefore, approximation and reorientation are required as pre-processing\nstages, both of which can introduce noise. In this paper, we propose a\ndivergence guided shape representation learning approach that does not require\nnormal vectors as input. We show that incorporating a soft constraint on the\ndivergence of the distance function favours smooth solutions that reliably\norients gradients to match the unknown normal at each point, in some cases even\nbetter than approaches that use ground truth normal vectors directly.\nAdditionally, we introduce a novel geometric initialization method for\nsinusoidal shape representation networks that further improves convergence to\nthe desired solution. We evaluate the effectiveness of our approach on the task\nof surface reconstruction and show state-of-the-art performance compared to\nother unoriented methods and on-par performance compared to oriented methods.",
    "descriptor": "",
    "authors": [
      "Yizhak Ben-Shabat",
      "Chamin Hewa Koneputugodage",
      "Stephen Gould"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10811"
  },
  {
    "id": "arXiv:2106.10812",
    "title": "ToAlign: Task-oriented Alignment for Unsupervised Domain Adaptation",
    "abstract": "Unsupervised domain adaptive classification intends to improve\ntheclassification performance on unlabeled target domain. To alleviate the\nadverse effect of domain shift, many approaches align the source and target\ndomains in the feature space. However, a feature is usually taken as a whole\nfor alignment without explicitly making domain alignment proactively serve the\nclassification task, leading to sub-optimal solution. What sub-feature should\nbe aligned for better adaptation is under-explored. In this paper, we propose\nan effective Task-oriented Alignment (ToAlign) for unsupervised domain\nadaptation (UDA). We study what features should be aligned across domains and\npropose to make the domain alignment proactively serve classification by\nperforming feature decomposition and alignment under the guidance of the prior\nknowledge induced from the classification taskitself. Particularly, we\nexplicitly decompose a feature in the source domain intoa\ntask-related/discriminative feature that should be aligned, and a\ntask-irrelevant feature that should be avoided/ignored, based on the\nclassification meta-knowledge. Extensive experimental results on various\nbenchmarks (e.g., Office-Home, Visda-2017, and DomainNet) under different\ndomain adaptation settings demonstrate theeffectiveness of ToAlign which helps\nachieve the state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Guoqiang Wei",
      "Cuiling Lan",
      "Wenjun Zeng",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10812"
  },
  {
    "id": "arXiv:2106.10814",
    "title": "On Simple Mechanisms for Dependent Items",
    "abstract": "We study the problem of selling $n$ heterogeneous items to a single buyer,\nwhose values for different items are dependent. Under arbitrary dependence,\nHart and Nisan show that no simple mechanism can achieve a non-negligible\nfraction of the optimal revenue even with only two items. We consider the\nsetting where the buyer's type is drawn from a correlated distribution that can\nbe captured by a Markov Random Field, one of the most prominent frameworks for\nmodeling high-dimensional distributions with structure.\nIf the buyer's valuation is additive or unit-demand, we extend the result to\nall MRFs and show that max(SRev,BRev) can achieve an\n$\\Omega\\left(\\frac{1}{e^{O(\\Delta)}}\\right)$-fraction of the optimal revenue,\nwhere $\\Delta$ is a parameter of the MRF that is determined by how much the\nvalue of an item can be influenced by the values of the other items. We further\nshow that the exponential dependence on $\\Delta$ is unavoidable for our\napproach and a polynomial dependence on $\\Delta$ is unavoidable for any\napproach. When the buyer has a XOS valuation, we show that max(Srev,Brev)\nachieves at least an\n$\\Omega\\left(\\frac{1}{e^{O(\\Delta)}+\\frac{1}{\\sqrt{n\\gamma}}}\\right)$-fraction\nof the optimal revenue, where $\\gamma$ is the spectral gap of the Glauber\ndynamics of the MRF. Note that the values of $\\Delta$ and $\\frac{1}{n\\gamma}$\nincrease as the dependence between items strengthens. In the special case of\nindependently distributed items, $\\Delta=0$ and $\\frac{1}{n\\gamma}\\geq 1$, and\nour results recover the known constant factor approximations for a XOS buyer.\nWe further extend our parametric approximation to several other well-studied\ndependency measures such as the Dobrushin coefficient and the inverse\ntemperature. Our results are based on the Duality-Framework by Cai et al. and a\nnew concentration inequality for XOS functions over dependent random variables.",
    "descriptor": "",
    "authors": [
      "Yang Cai",
      "Argyris Oikonomou"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.10814"
  },
  {
    "id": "arXiv:2106.10815",
    "title": "Structured Sparse R-CNN for Direct Scene Graph Generation",
    "abstract": "Scene graph generation (SGG) is to detect entity pairs with their relations\nin an image. Existing SGG approaches often use multi-stage pipelines to\ndecompose this task into object detection, relation graph construction, and\ndense or dense-to-sparse relation prediction. Instead, from a perspective on\nSGG as a direct set prediction, this paper presents a simple, sparse, and\nunified framework for relation detection, termed as Structured Sparse R-CNN.\nThe key to our method is a set of learnable triplet queries and structured\ntriplet detectors which could be jointly optimized from the training set in an\nend-to-end manner. Specifically, the triplet queries encode the general prior\nfor entity pair locations, categories, and their relations, and provide an\ninitial guess of relation detection for subsequent refinement. The triplet\ndetector presents a cascaded dynamic head design to progressively refine the\nresults of relation detection. In addition, to relieve the training difficulty\nof Structured Sparse R-CNN, we propose a relaxed and enhanced training strategy\nbased on knowledge distillation from a Siamese Sparse R-CNN. We also propose\nadaptive focusing parameter and average logit approach for imbalance data\ndistribution. We perform experiments on two benchmarks: Visual Genome and Open\nImages, and the results demonstrate that our method achieves the\nstate-of-the-art performance. Meanwhile, we perform in-depth ablation studies\nto provide insights on our structured modeling in triplet detector design and\ntraining strategies.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Yao Teng",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10815"
  },
  {
    "id": "arXiv:2106.10816",
    "title": "Out of Context: A New Clue for Context Modeling of Aspect-based  Sentiment Analysis",
    "abstract": "Aspect-based sentiment analysis (ABSA) aims to predict the sentiment\nexpressed in a review with respect to a given aspect. The core of ABSA is to\nmodel the interaction between the context and given aspect to extract the\naspect-related information. In prior work, attention mechanisms and dependency\ngraph networks are commonly adopted to capture the relations between the\ncontext and given aspect. And the weighted sum of context hidden states is used\nas the final representation fed to the classifier. However, the information\nrelated to the given aspect may be already discarded and adverse information\nmay be retained in the context modeling processes of existing models. This\nproblem cannot be solved by subsequent modules and there are two reasons:\nfirst, their operations are conducted on the encoder-generated context hidden\nstates, whose value cannot change after the encoder; second, existing encoders\nonly consider the context while not the given aspect. To address this problem,\nwe argue the given aspect should be considered as a new clue out of context in\nthe context modeling process. As for solutions, we design several aspect-aware\ncontext encoders based on different backbones: an aspect-aware LSTM and three\naspect-aware BERTs. They are dedicated to generate aspect-aware hidden states\nwhich are tailored for ABSA task. In these aspect-aware context encoders, the\nsemantics of the given aspect is used to regulate the information flow.\nConsequently, the aspect-related information can be retained and\naspect-irrelevant information can be excluded in the generated hidden states.\nWe conduct extensive experiments on several benchmark datasets with empirical\nanalysis, demonstrating the efficacies and advantages of our proposed\naspect-aware context encoders.",
    "descriptor": "\nComments: Submitted to JAIR\n",
    "authors": [
      "Bowen Xing",
      "Ivor W. Tsang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10816"
  },
  {
    "id": "arXiv:2106.10820",
    "title": "Compressing Deep ODE-Nets using Basis Function Expansions",
    "abstract": "The recently-introduced class of ordinary differential equation networks\n(ODE-Nets) establishes a fruitful connection between deep learning and\ndynamical systems. In this work, we reconsider formulations of the weights as\ncontinuous-depth functions using linear combinations of basis functions. This\nperspective allows us to compress the weights through a change of basis,\nwithout retraining, while maintaining near state-of-the-art performance. In\nturn, both inference time and the memory footprint are reduced, enabling quick\nand rigorous adaptation between computational environments. Furthermore, our\nframework enables meaningful continuous-in-time batch normalization layers\nusing function projections. The performance of basis function compression is\ndemonstrated by applying continuous-depth models to (a) image classification\ntasks using convolutional units and (b) sentence-tagging tasks using\ntransformer encoder units.",
    "descriptor": "",
    "authors": [
      "Alejandro Queiruga",
      "N. Benjamin Erichson",
      "Liam Hodgkinson",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10820"
  },
  {
    "id": "arXiv:2106.10821",
    "title": "Demonstration of Panda: A Weakly Supervised Entity Matching System",
    "abstract": "Entity matching (EM) refers to the problem of identifying tuple pairs in one\nor more relations that refer to the same real world entities. Supervised\nmachine learning (ML) approaches, and deep learning based approaches in\nparticular, typically achieve state-of-the-art matching results. However, these\napproaches require many labeled examples, in the form of matching and\nnon-matching pairs, which are expensive and time-consuming to label. In this\npaper, we introduce Panda, a weakly supervised system specifically designed for\nEM. Panda uses the same labeling function abstraction as Snorkel, where\nlabeling functions (LF) are user-provided programs that can generate large\namounts of (somewhat noisy) labels quickly and cheaply, which can then be\ncombined via a labeling model to generate accurate final predictions. To\nsupport users developing LFs for EM, Panda provides an integrated development\nenvironment (IDE) that lives in a modern browser architecture. Panda's IDE\nfacilitates the development, debugging, and life-cycle management of LFs in the\ncontext of EM tasks, similar to how IDEs such as Visual Studio or Eclipse excel\nin general-purpose programming. Panda's IDE includes many novel features\npurpose-built for EM, such as smart data sampling, a builtin library of EM\nutility functions, automatically generated LFs, visual debugging of LFs, and\nfinally, an EM-specific labeling model. We show in this demo that Panda IDE can\ngreatly accelerate the development of high-quality EM solutions using weak\nsupervision.",
    "descriptor": "\nComments: video can be found at this https URL\n",
    "authors": [
      "Renzhi Wu",
      "Prem Sakala",
      "Peng Li",
      "Xu Chu",
      "Yeye He"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10821"
  },
  {
    "id": "arXiv:2106.10823",
    "title": "3D Object Detection for Autonomous Driving: A Survey",
    "abstract": "Autonomous driving is regarded as one of the most promising remedies to\nshield human beings from severe crashes. To this end, 3D object detection\nserves as the core basis of such perception system especially for the sake of\npath planning, motion prediction, collision avoidance, etc. Generally, stereo\nor monocular images with corresponding 3D point clouds are already standard\nlayout for 3D object detection, out of which point clouds are increasingly\nprevalent with accurate depth information being provided. Despite existing\nefforts, 3D object detection on point clouds is still in its infancy due to\nhigh sparseness and irregularity of point clouds by nature, misalignment view\nbetween camera view and LiDAR bird's eye of view for modality synergies,\nocclusions and scale variations at long distances, etc. Recently, profound\nprogress has been made in 3D object detection, with a large body of literature\nbeing investigated to address this vision task. As such, we present a\ncomprehensive review of the latest progress in this field covering all the main\ntopics including sensors, fundamentals, and the recent state-of-the-art\ndetection methods with their pros and cons. Furthermore, we introduce metrics\nand provide quantitative comparisons on popular public datasets. The avenues\nfor future work are going to be judiciously identified after an in-deep\nanalysis of the surveyed works. Finally, we conclude this paper.",
    "descriptor": "\nComments: 3D object detection, Autonomous driving, Point clouds\n",
    "authors": [
      "Rui Qian",
      "Xin Lai",
      "Xirong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10823"
  },
  {
    "id": "arXiv:2106.10826",
    "title": "Does Robustness Improve Fairness? Approaching Fairness with Word  Substitution Robustness Methods for Text Classification",
    "abstract": "Existing bias mitigation methods to reduce disparities in model outcomes\nacross cohorts have focused on data augmentation, debiasing model embeddings,\nor adding fairness-based optimization objectives during training. Separately,\ncertified word substitution robustness methods have been developed to decrease\nthe impact of spurious features and synonym substitutions on model predictions.\nWhile their end goals are different, they both aim to encourage models to make\nthe same prediction for certain changes in the input. In this paper, we\ninvestigate the utility of certified word substitution robustness methods to\nimprove equality of odds and equality of opportunity on multiple text\nclassification tasks. We observe that certified robustness methods improve\nfairness, and using both robustness and bias mitigation methods in training\nresults in an improvement in both fronts",
    "descriptor": "",
    "authors": [
      "Yada Pruksachatkun",
      "Satyapriya Krishna",
      "Jwala Dhamala",
      "Rahul Gupta",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.10826"
  },
  {
    "id": "arXiv:2106.10829",
    "title": "Two-Stream Consensus Network: Submission to HACS Challenge 2021  Weakly-Supervised Learning Track",
    "abstract": "This technical report presents our solution to the HACS Temporal Action\nLocalization Challenge 2021, Weakly-Supervised Learning Track. The goal of\nweakly-supervised temporal action localization is to temporally locate and\nclassify action of interest in untrimmed videos given only video-level labels.\nWe adopt the two-stream consensus network (TSCN) as the main framework in this\nchallenge. The TSCN consists of a two-stream base model training procedure and\na pseudo ground truth learning procedure. The base model training encourages\nthe model to predict reliable predictions based on single modality (i.e., RGB\nor optical flow), based on the fusion of which a pseudo ground truth is\ngenerated and in turn used as supervision to train the base models. On the HACS\nv1.1.1 dataset, without fine-tuning the feature-extraction I3D models, our\nmethod achieves 22.20% on the validation set and 21.68% on the testing set in\nterms of average mAP. Our solution ranked the 2rd in this challenge, and we\nhope our method can serve as a baseline for future academic research.",
    "descriptor": "\nComments: Second place solution to the HACS Weakly-Supervised Temporal Action Localization Challenge 2021. arXiv admin note: text overlap with arXiv:2010.11594\n",
    "authors": [
      "Yuanhao Zhai",
      "Le Wang",
      "David Doermann",
      "Junsong Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10829"
  },
  {
    "id": "arXiv:2106.10832",
    "title": "Online Handbook of Argumentation for AI: Volume 2",
    "abstract": "This volume contains revised versions of the papers selected for the second\nvolume of the Online Handbook of Argumentation for AI (OHAAI). Previously,\nformal theories of argument and argument interaction have been proposed and\nstudied, and this has led to the more recent study of computational models of\nargument. Argumentation, as a field within artificial intelligence (AI), is\nhighly relevant for researchers interested in symbolic representations of\nknowledge and defeasible reasoning. The purpose of this handbook is to provide\nan open access and curated anthology for the argumentation research community.\nOHAAI is designed to serve as a research hub to keep track of the latest and\nupcoming PhD-driven research on the theory and application of argumentation in\nall areas related to AI.",
    "descriptor": "",
    "authors": [
      "OHAAI Collaboration",
      "Andreas Brannstrom",
      "Federico Castagna",
      "Theo Duchatelle",
      "Matt Foulis",
      "Timotheus Kampik",
      "Isabelle Kuhlmann",
      "Lars Malmqvist",
      "Mariela Morveli-Espinoza",
      "Jack Mumford",
      "Stipe Pandzic",
      "Robin Schaefer",
      "Luke Thorburn",
      "Andreas Xydis",
      "Antonio Yuste-Ginel",
      "Heng Zheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10832"
  },
  {
    "id": "arXiv:2106.10834",
    "title": "Interpretable Face Manipulation Detection via Feature Whitening",
    "abstract": "Why should we trust the detections of deep neural networks for manipulated\nfaces? Understanding the reasons is important for users in improving the\nfairness, reliability, privacy and trust of the detection models. In this work,\nwe propose an interpretable face manipulation detection approach to achieve the\ntrustworthy and accurate inference. The approach could make the face\nmanipulation detection process transparent by embedding the feature whitening\nmodule. This module aims to whiten the internal working mechanism of deep\nnetworks through feature decorrelation and feature constraint. The experimental\nresults demonstrate that our proposed approach can strike a balance between the\ndetection accuracy and the model interpretability.",
    "descriptor": "",
    "authors": [
      "Yingying Hua",
      "Daichi Zhang",
      "Pengju Wang",
      "Shiming Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10834"
  },
  {
    "id": "arXiv:2106.10835",
    "title": "Empower Distantly Supervised Relation Extraction with Collaborative  Adversarial Training",
    "abstract": "With recent advances in distantly supervised (DS) relation extraction (RE),\nconsiderable attention is attracted to leverage multi-instance learning (MIL)\nto distill high-quality supervision from the noisy DS. Here, we go beyond label\nnoise and identify the key bottleneck of DS-MIL to be its low data utilization:\nas high-quality supervision being refined by MIL, MIL abandons a large amount\nof training instances, which leads to a low data utilization and hinders model\ntraining from having abundant supervision. In this paper, we propose\ncollaborative adversarial training to improve the data utilization, which\ncoordinates virtual adversarial training (VAT) and adversarial training (AT) at\ndifferent levels. Specifically, since VAT is label-free, we employ the\ninstance-level VAT to recycle instances abandoned by MIL. Besides, we deploy AT\nat the bag-level to unleash the full potential of the high-quality supervision\ngot by MIL. Our proposed method brings consistent improvements (~ 5 absolute\nAUC score) to the previous state of the art, which verifies the importance of\nthe data utilization issue and the effectiveness of our method.",
    "descriptor": "\nComments: Accepted by AAAI 2021\n",
    "authors": [
      "Tao Chen",
      "Haochen Shi",
      "Liyuan Liu",
      "Siliang Tang",
      "Jian Shao",
      "Zhigang Chen",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10835"
  },
  {
    "id": "arXiv:2106.10836",
    "title": "Active Learning for Deep Neural Networks on Edge Devices",
    "abstract": "When dealing with deep neural network (DNN) applications on edge devices,\ncontinuously updating the model is important. Although updating a model with\nreal incoming data is ideal, using all of them is not always feasible due to\nlimits, such as labeling and communication costs. Thus, it is necessary to\nfilter and select the data to use for training (i.e., active learning) on the\ndevice. In this paper, we formalize a practical active learning problem for\nDNNs on edge devices and propose a general task-agnostic framework to tackle\nthis problem, which reduces it to a stream submodular maximization. This\nframework is light enough to be run with low computational resources, yet\nprovides solutions whose quality is theoretically guaranteed thanks to the\nsubmodular property. Through this framework, we can configure data selection\ncriteria flexibly, including using methods proposed in previous active learning\nstudies. We evaluate our approach on both classification and object detection\ntasks in a practical setting to simulate a real-life scenario. The results of\nour study show that the proposed framework outperforms all other methods in\nboth tasks, while running at a practical speed on real devices.",
    "descriptor": "",
    "authors": [
      "Yuya Senzaki",
      "Christian Hamelain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.10836"
  },
  {
    "id": "arXiv:2106.10840",
    "title": "Pay Better Attention to Attention: Head Selection in Multilingual and  Multi-Domain Sequence Modeling",
    "abstract": "Multi-head attention has each of the attention heads collect salient\ninformation from different parts of an input sequence, making it a powerful\nmechanism for sequence modeling. Multilingual and multi-domain learning are\ncommon scenarios for sequence modeling, where the key challenge is to maximize\npositive transfer and mitigate negative transfer across languages and domains.\nIn this paper, we find that non-selective attention sharing is sub-optimal for\nachieving good generalization across all languages and domains. We further\npropose attention sharing strategies to facilitate parameter sharing and\nspecialization in multilingual and multi-domain sequence modeling. Our approach\nautomatically learns shared and specialized attention heads for different\nlanguages and domains to mitigate their interference. Evaluated in various\ntasks including speech recognition, text-to-text and speech-to-text\ntranslation, the proposed attention sharing strategies consistently bring gains\nto sequence models built upon multi-head attention. For speech-to-text\ntranslation, our approach yields an average of $+2.0$ BLEU over $13$ language\ndirections in multilingual setting and $+2.0$ BLEU over $3$ domains in\nmulti-domain setting.",
    "descriptor": "",
    "authors": [
      "Hongyu Gong",
      "Yun Tang",
      "Juan Pino",
      "Xian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10840"
  },
  {
    "id": "arXiv:2106.10846",
    "title": "Trainable Class Prototypes for Few-Shot Learning",
    "abstract": "Metric learning is a widely used method for few shot learning in which the\nquality of prototypes plays a key role in the algorithm. In this paper we\npropose the trainable prototypes for distance measure instead of the artificial\nones within the meta-training and task-training framework. Also to avoid the\ndisadvantages that the episodic meta-training brought, we adopt non-episodic\nmeta-training based on self-supervised learning. Overall we solve the few-shot\ntasks in two phases: meta-training a transferable feature extractor via\nself-supervised learning and training the prototypes for metric classification.\nIn addition, the simple attention mechanism is used in both meta-training and\ntask-training. Our method achieves state-of-the-art performance in a variety of\nestablished few-shot tasks on the standard few-shot visual classification\ndataset, with about 20% increase compared to the available unsupervised\nfew-shot learning methods.",
    "descriptor": "\nComments: 8 pages, 2 figures,and 3 Tables. arXiv admin note: substantial text overlap with arXiv:2008.09942\n",
    "authors": [
      "Jianyi Li",
      "Guizhong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10846"
  },
  {
    "id": "arXiv:2106.10850",
    "title": "Robust Pooling through the Data Mode",
    "abstract": "The task of learning from point cloud data is always challenging due to the\noften occurrence of noise and outliers in the data. Such data inaccuracies can\nsignificantly influence the performance of state-of-the-art deep learning\nnetworks and their ability to classify or segment objects. While there are some\nrobust deep learning approaches, they are computationally too expensive for\nreal-time applications. This paper proposes a deep learning solution that\nincludes a novel robust pooling layer which greatly enhances network robustness\nand performs significantly faster than state-of-the-art approaches. The\nproposed pooling layer looks for data a mode/cluster using two methods, RANSAC,\nand histogram, as clusters are indicative of models. We tested the pooling\nlayer into frameworks such as Point-based and graph-based neural networks, and\nthe tests showed enhanced robustness as compared to robust state-of-the-art\nmethods.",
    "descriptor": "\nComments: under consideration at Computer Vision and Image Understanding\n",
    "authors": [
      "Ayman Mukhaimar",
      "Ruwan Tennakoon",
      "Chow Yin Lai",
      "Reza Hoseinnezhad",
      "AlirezaBab-Hadiashar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10850"
  },
  {
    "id": "arXiv:2106.10852",
    "title": "CUDA-GR: Controllable Unsupervised Domain Adaptation for Gaze  Redirection",
    "abstract": "The aim of gaze redirection is to manipulate the gaze in an image to the\ndesired direction. However, existing methods are inadequate in generating\nperceptually reasonable images. Advancement in generative adversarial networks\nhas shown excellent results in generating photo-realistic images. Though, they\nstill lack the ability to provide finer control over different image\nattributes. To enable such fine-tuned control, one needs to obtain ground truth\nannotations for the training data which can be very expensive. In this paper,\nwe propose an unsupervised domain adaptation framework, called CUDA-GR, that\nlearns to disentangle gaze representations from the labeled source domain and\ntransfers them to an unlabeled target domain. Our method enables fine-grained\ncontrol over gaze directions while preserving the appearance information of the\nperson. We show that the generated image-labels pairs in the target domain are\neffective in knowledge transfer and can boost the performance of the downstream\ntasks. Extensive experiments on the benchmarking datasets show that the\nproposed method can outperform state-of-the-art techniques in both quantitative\nand qualitative evaluation.",
    "descriptor": "",
    "authors": [
      "Swati Jindal",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10852"
  },
  {
    "id": "arXiv:2106.10853",
    "title": "On the Importance of Environments in Human-Robot Coordination",
    "abstract": "When studying robots collaborating with humans, much of the focus has been on\nrobot policies that coordinate fluently with human teammates in collaborative\ntasks. However, less emphasis has been placed on the effect of the environment\non coordination behaviors. To thoroughly explore environments that result in\ndiverse behaviors, we propose a framework for procedural generation of\nenvironments that are (1) stylistically similar to human-authored environments,\n(2) guaranteed to be solvable by the human-robot team, and (3) diverse with\nrespect to coordination measures. We analyze the procedurally generated\nenvironments in the Overcooked benchmark domain via simulation and an online\nuser study. Results show that the environments result in qualitatively\ndifferent emerging behaviors and statistically significant differences in\ncollaborative fluency metrics, even when the robot runs the same planning\nalgorithm.",
    "descriptor": "\nComments: Accepted to Robotics: Science and Systems (RSS) 2021\n",
    "authors": [
      "Matthew C. Fontaine",
      "Ya-Chuan Hsu",
      "Yulun Zhang",
      "Bryon Tjakana",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10853"
  },
  {
    "id": "arXiv:2106.10855",
    "title": "CIL: Contrastive Instance Learning Framework for Distantly Supervised  Relation Extraction",
    "abstract": "The journey of reducing noise from distant supervision (DS) generated\ntraining data has been started since the DS was first introduced into the\nrelation extraction (RE) task. For the past decade, researchers apply the\nmulti-instance learning (MIL) framework to find the most reliable feature from\na bag of sentences. Although the pattern of MIL bags can greatly reduce DS\nnoise, it fails to represent many other useful sentence features in the\ndatasets. In many cases, these sentence features can only be acquired by extra\nsentence-level human annotation with heavy costs. Therefore, the performance of\ndistantly supervised RE models is bounded. In this paper, we go beyond typical\nMIL framework and propose a novel contrastive instance learning (CIL)\nframework. Specifically, we regard the initial MIL as the relational triple\nencoder and constraint positive pairs against negative pairs for each instance.\nExperiments demonstrate the effectiveness of our proposed framework, with\nsignificant improvements over the previous methods on NYT10, GDS and KBP.",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Tao Chen",
      "Haizhou Shi",
      "Siliang Tang",
      "Zhigang Chen",
      "Fei Wu",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10855"
  },
  {
    "id": "arXiv:2106.10859",
    "title": "Moving in a 360 World: Synthesizing Panoramic Parallaxes from a Single  Panorama",
    "abstract": "We present Omnidirectional Neural Radiance Fields (OmniNeRF), the first\nmethod to the application of parallax-enabled novel panoramic view synthesis.\nRecent works for novel view synthesis focus on perspective images with limited\nfield-of-view and require sufficient pictures captured in a specific condition.\nConversely, OmniNeRF can generate panorama images for unknown viewpoints given\na single equirectangular image as training data. To this end, we propose to\naugment the single RGB-D panorama by projecting back and forth between a 3D\nworld and different 2D panoramic coordinates at different virtual camera\npositions. By doing so, we are able to optimize an Omnidirectional Neural\nRadiance Field with visible pixels collecting from omnidirectional viewing\nangles at a fixed center for the estimation of new viewing angles from varying\ncamera positions. As a result, the proposed OmniNeRF achieves convincing\nrenderings of novel panoramic views that exhibit the parallax effect. We\nshowcase the effectiveness of each of our proposals on both synthetic and\nreal-world datasets.",
    "descriptor": "",
    "authors": [
      "Ching-Yu Hsu",
      "Cheng Sun",
      "Hwann-Tzong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10859"
  },
  {
    "id": "arXiv:2106.10860",
    "title": "Multiplying Matrices Without Multiplying",
    "abstract": "Multiplying matrices is among the most fundamental and compute-intensive\noperations in machine learning. Consequently, there has been significant work\non efficiently approximating matrix multiplies. We introduce a learning-based\nalgorithm for this task that greatly outperforms existing methods. Experiments\nusing hundreds of matrices from diverse domains show that it often runs\n$100\\times$ faster than exact matrix products and $10\\times$ faster than\ncurrent approximate methods. In the common case that one matrix is known ahead\nof time, our method also has the interesting property that it requires zero\nmultiply-adds. These results suggest that a mixture of hashing, averaging, and\nbyte shuffling$-$the core operations of our method$-$could be a more promising\nbuilding block for machine learning than the sparsified, factorized, and/or\nscalar quantized matrix products that have recently been the focus of\nsubstantial research and hardware investment.",
    "descriptor": "\nComments: To appear at ICML 2021\n",
    "authors": [
      "Davis Blalock",
      "John Guttag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10860"
  },
  {
    "id": "arXiv:2106.10862",
    "title": "ArgFuse: A Weakly-Supervised Framework for Document-Level Event Argument  Aggregation",
    "abstract": "Most of the existing information extraction frameworks (Wadden et al., 2019;\nVeysehet al., 2020) focus on sentence-level tasks and are hardly able to\ncapture the consolidated information from a given document. In our endeavour to\ngenerate precise document-level information frames from lengthy textual\nrecords, we introduce the task of Information Aggregation or Argument\nAggregation. More specifically, our aim is to filter irrelevant and redundant\nargument mentions that were extracted at a sentence level and render a document\nlevel information frame. Majority of the existing works have been observed to\nresolve related tasks of document-level event argument extraction (Yang et al.,\n2018a; Zheng et al., 2019a) and salient entity identification (Jain et\nal.,2020) using supervised techniques. To remove dependency from large amounts\nof labelled data, we explore the task of information aggregation using\nweakly-supervised techniques. In particular, we present an extractive algorithm\nwith multiple sieves which adopts active learning strategies to work\nefficiently in low-resource settings. For this task, we have annotated our own\ntest dataset comprising of 131 document information frames and have released\nthe code and dataset to further research prospects in this new domain. To the\nbest of our knowledge, we are the first to establish baseline results for this\ntask in English. Our data and code are publicly available at\nhttps://github.com/DebanjanaKar/ArgFuse.",
    "descriptor": "\nComments: 11 pages, 8 figures, Accepted in Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE) @ACL-IJCNLP 2021\n",
    "authors": [
      "Debanjana Kar",
      "Sudeshna Sarkar",
      "Pawan Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10862"
  },
  {
    "id": "arXiv:2106.10866",
    "title": "Graph Attention Networks with LSTM-based Path Reweighting",
    "abstract": "Graph Neural Networks (GNNs) have been extensively used for mining\ngraph-structured data with impressive performance. However, traditional GNNs\nsuffer from over-smoothing, non-robustness and over-fitting problems. To solve\nthese weaknesses, we design a novel GNN solution, namely Graph Attention\nNetwork with LSTM-based Path Reweighting (PR-GAT). PR-GAT can automatically\naggregate multi-hop information, highlight important paths and filter out\nnoises. In addition, we utilize random path sampling in PR-GAT for data\naugmentation. The augmented data is used for predicting the distribution of\ncorresponding labels. Finally, we demonstrate that PR-GAT can mitigate the\nissues of over-smoothing, non-robustness and overfitting. We achieve\nstate-of-the-art accuracy on 5 out of 7 datasets and competitive accuracy for\nother 2 datasets. The average accuracy of 7 datasets have been improved by\n0.5\\% than the best SOTA from literature.",
    "descriptor": "\nComments: 15 pages with 10 figures, submitted to NeurlPS 2021\n",
    "authors": [
      "Jianpeng Chen",
      "Yujing Wang",
      "Ming Zeng",
      "Zongyi Xiang",
      "Yazhou Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10866"
  },
  {
    "id": "arXiv:2106.10874",
    "title": "FedCM: Federated Learning with Client-level Momentum",
    "abstract": "Federated Learning is a distributed machine learning approach which enables\nmodel training without data sharing. In this paper, we propose a new federated\nlearning algorithm, Federated Averaging with Client-level Momentum (FedCM), to\ntackle problems of partial participation and client heterogeneity in real-world\nfederated learning applications. FedCM aggregates global gradient information\nin previous communication rounds and modifies client gradient descent with a\nmomentum-like term, which can effectively correct the bias and improve the\nstability of local SGD. We provide theoretical analysis to highlight the\nbenefits of FedCM. We also perform extensive empirical studies and demonstrate\nthat FedCM achieves superior performance in various tasks and is robust to\ndifferent levels of client numbers, participation rate and client\nheterogeneity.",
    "descriptor": "",
    "authors": [
      "Jing Xu",
      "Sen Wang",
      "Liwei Wang",
      "Andrew Chi-Chih Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10874"
  },
  {
    "id": "arXiv:2106.10875",
    "title": "An End-to-End Khmer Optical Character Recognition using  Sequence-to-Sequence with Attention",
    "abstract": "This paper presents an end-to-end deep convolutional recurrent neural network\nsolution for Khmer optical character recognition (OCR) task. The proposed\nsolution uses a sequence-to-sequence (Seq2Seq) architecture with attention\nmechanism. The encoder extracts visual features from an input text-line image\nvia layers of residual convolutional blocks and a layer of gated recurrent\nunits (GRU). The features are encoded in a single context vector and a sequence\nof hidden states which are fed to the decoder for decoding one character at a\ntime until a special end-of-sentence (EOS) token is reached. The attention\nmechanism allows the decoder network to adaptively select parts of the input\nimage while predicting a target character. The Seq2Seq Khmer OCR network was\ntrained on a large collection of computer-generated text-line images for seven\ncommon Khmer fonts. The proposed model's performance outperformed the\nstate-of-art Tesseract OCR engine for Khmer language on the 3000-images test\nset by achieving a character error rate (CER) of 1% vs 3%.",
    "descriptor": "\nComments: 16 pages, 18 figures\n",
    "authors": [
      "Rina Buoy",
      "Sokchea Kor",
      "Nguonly Taing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10875"
  },
  {
    "id": "arXiv:2106.10876",
    "title": "Total Generate: Cycle in Cycle Generative Adversarial Networks for  Generating Human Faces, Hands, Bodies, and Natural Scenes",
    "abstract": "We propose a novel and unified Cycle in Cycle Generative Adversarial Network\n(C2GAN) for generating human faces, hands, bodies, and natural scenes. Our\nproposed C2GAN is a cross-modal model exploring the joint exploitation of the\ninput image data and guidance data in an interactive manner. C2GAN contains two\ndifferent generators, i.e., an image-generation generator and a\nguidance-generation generator. Both generators are mutually connected and\ntrained in an end-to-end fashion and explicitly form three cycled subnets,\ni.e., one image generation cycle and two guidance generation cycles. Each cycle\naims at reconstructing the input domain and simultaneously produces a useful\noutput involved in the generation of another cycle. In this way, the cycles\nconstrain each other implicitly providing complementary information from both\nimage and guidance modalities and bringing an extra supervision gradient across\nthe cycles, facilitating a more robust optimization of the whole model.\nExtensive results on four guided image-to-image translation subtasks\ndemonstrate that the proposed C2GAN is effective in generating more realistic\nimages compared with state-of-the-art models. The code is available at\nhttps://github.com/Ha0Tang/C2GAN.",
    "descriptor": "\nComments: Accepted to TMM, an extended version of a paper published in ACM MM 2019. arXiv admin note: substantial text overlap with arXiv:1908.00999\n",
    "authors": [
      "Hao Tang",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.10876"
  },
  {
    "id": "arXiv:2106.10879",
    "title": "DisenHAN: Disentangled Heterogeneous Graph Attention Network for  Recommendation",
    "abstract": "Heterogeneous information network has been widely used to alleviate sparsity\nand cold start problems in recommender systems since it can model rich context\ninformation in user-item interactions. Graph neural network is able to encode\nthis rich context information through propagation on the graph. However,\nexisting heterogeneous graph neural networks neglect entanglement of the latent\nfactors stemming from different aspects. Moreover, meta paths in existing\napproaches are simplified as connecting paths or side information between node\npairs, overlooking the rich semantic information in the paths. In this paper,\nwe propose a novel disentangled heterogeneous graph attention network DisenHAN\nfor top-$N$ recommendation, which learns disentangled user/item representations\nfrom different aspects in a heterogeneous information network. In particular,\nwe use meta relations to decompose high-order connectivity between node pairs\nand propose a disentangled embedding propagation layer which can iteratively\nidentify the major aspect of meta relations. Our model aggregates corresponding\naspect features from each meta relation for the target user/item. With\ndifferent layers of embedding propagation, DisenHAN is able to explicitly\ncapture the collaborative filtering effect semantically. Extensive experiments\non three real-world datasets show that DisenHAN consistently outperforms\nstate-of-the-art approaches. We further demonstrate the effectiveness and\ninterpretability of the learned disentangled representations via insightful\ncase studies and visualization.",
    "descriptor": "\nComments: Accepted at CIKM2020\n",
    "authors": [
      "Yifan Wang",
      "Suyao Tang",
      "Yuntong Lei",
      "Weiping Song",
      "Sheng Wang",
      "Ming Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.10879"
  },
  {
    "id": "arXiv:2106.10882",
    "title": "Affect-driven Engagement Measurement from Videos",
    "abstract": "In education and intervention programs, person's engagement has been\nidentified as a major factor in successful program completion. Automatic\nmeasurement of person's engagement provides useful information for instructors\nto meet program objectives and individualize program delivery. In this paper,\nwe present a novel approach for video-based engagement measurement in virtual\nlearning programs. We propose to use affect states, continuous values of\nvalence and arousal extracted from consecutive video frames, along with a new\nlatent affective feature vector and behavioral features for engagement\nmeasurement. Deep learning-based temporal, and traditional\nmachine-learning-based non-temporal models are trained and validated on\nframe-level, and video-level features, respectively. In addition to the\nconventional centralized learning, we also implement the proposed method in a\ndecentralized federated learning setting and study the effect of model\npersonalization in engagement measurement. We evaluated the performance of the\nproposed method on the only two publicly available video engagement measurement\ndatasets, DAiSEE and EmotiW, containing videos of students in online learning\nprograms. Our experiments show a state-of-the-art engagement level\nclassification accuracy of 63.3% and correctly classifying disengagement videos\nin the DAiSEE dataset and a regression mean squared error of 0.0673 on the\nEmotiW dataset. Our ablation study shows the effectiveness of incorporating\naffect states in engagement measurement. We interpret the findings from the\nexperimental results based on psychology concepts in the field of engagement.",
    "descriptor": "\nComments: 13 pages, 8 figures, 7 tables\n",
    "authors": [
      "Ali Abedi",
      "Shehroz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.10882"
  },
  {
    "id": "arXiv:2106.10885",
    "title": "Knowledge Distillation via Instance-level Sequence Learning",
    "abstract": "Recently, distillation approaches are suggested to extract general knowledge\nfrom a teacher network to guide a student network. Most of the existing methods\ntransfer knowledge from the teacher network to the student via feeding the\nsequence of random mini-batches sampled uniformly from the data. Instead, we\nargue that the compact student network should be guided gradually using samples\nordered in a meaningful sequence. Thus, it can bridge the gap of feature\nrepresentation between the teacher and student network step by step. In this\nwork, we provide a curriculum learning knowledge distillation framework via\ninstance-level sequence learning. It employs the student network of the early\nepoch as a snapshot to create a curriculum for the student network's next\ntraining phase. We carry out extensive experiments on CIFAR-10, CIFAR-100, SVHN\nand CINIC-10 datasets. Compared with several state-of-the-art methods, our\nframework achieves the best performance with fewer iterations.",
    "descriptor": "",
    "authors": [
      "Haoran Zhao",
      "Xin Sun",
      "Junyu Dong",
      "Zihe Dong",
      "Qiong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10885"
  },
  {
    "id": "arXiv:2106.10886",
    "title": "Proceedings Eighteenth Conference on Theoretical Aspects of Rationality  and Knowledge",
    "abstract": "The TARK conference (Theoretical Aspects of Rationality and Knowledge) is a\nbiannual conference that aims to bring together researchers from a wide variety\nof fields, including computer science, artificial intelligence, game theory,\ndecision theory, philosophy, logic, linguistics, and cognitive science. Its\ngoal is to further our understanding of interdisciplinary issues involving\nreasoning about rationality and knowledge.\nTopics of interest include, but are not limited to, semantic models for\nknowledge, belief, awareness and uncertainty, bounded rationality and\nresource-bounded reasoning, commonsense epistemic reasoning, epistemic logic,\nepistemic game theory, knowledge and action, applications of reasoning about\nknowledge and other mental states, belief revision, and foundations of\nmulti-agent systems.\nThese proceedings contain the papers that have been accepted for presentation\nat the Eighteenth Conference on Theoretical Aspects of Rationality and\nKnowledge (TARK 2021), held between June 25 and June 27, 2021, at Tsinghua\nUniversity at Beijing, China.",
    "descriptor": "",
    "authors": [
      "Joseph Halpern",
      "Andr\u00e9s Perea"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.10886"
  },
  {
    "id": "arXiv:2106.10887",
    "title": "Confidence-Guided Radiology Report Generation",
    "abstract": "Medical imaging plays a pivotal role in diagnosis and treatment in clinical\npractice. Inspired by the significant progress in automatic image captioning,\nvarious deep learning (DL)-based architectures have been proposed for\ngenerating radiology reports for medical images. However, model uncertainty\n(i.e., model reliability/confidence on report generation) is still an\nunder-explored problem. In this paper, we propose a novel method to explicitly\nquantify both the visual uncertainty and the textual uncertainty for the task\nof radiology report generation. Such multi-modal uncertainties can sufficiently\ncapture the model confidence scores at both the report-level and the\nsentence-level, and thus they are further leveraged to weight the losses for\nachieving more comprehensive model optimization. Our experimental results have\ndemonstrated that our proposed method for model uncertainty characterization\nand estimation can provide more reliable confidence scores for radiology report\ngeneration, and our proposed uncertainty-weighted losses can achieve more\ncomprehensive model optimization and result in state-of-the-art performance on\na public radiology report dataset.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Yixin Wang",
      "Zihao Lin",
      "Jiang Tian",
      "zhongchao shi",
      "Yang Zhang",
      "Jianping Fan",
      "Zhiqiang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10887"
  },
  {
    "id": "arXiv:2106.10888",
    "title": "Basis transform in switched linear system state-space models from  input-output data",
    "abstract": "This paper tackles the basis selection issue in the context of state-space\nhybrid system identification from input-output data. It is often the case that\nan identification scheme responsible for state-space switched linear system\n(SLS) estimation from input-output data operates on local levels. Such\nindividually identified local estimates reside in distinct state bases, which\ncall for the need to perform some basis correction mechanism that facilitates\ntheir coherent patching for the ultimate goal of performing output predictions\nfor predefined input test signals. We derive necessary and sufficient\nconditions on the submodel set, the switching sequence, and the dwell times\nthat guarantee the presented approach's success. Such conditions turn out to be\nrelatively mild, which contributes to the application potential of the devised\nalgorithm. We also provide a linkage between this work and the existing\nliterature by providing several insightful remarks that highlight the discussed\nmethod's favorability. We supplement the theoretical findings by an elaborative\nnumerical simulation that puts our methodology into action.",
    "descriptor": "",
    "authors": [
      "Fethi Bencherki",
      "Semiha T\u00fcrkay",
      "H\u00fcseyin Ak\u00e7ay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10888"
  },
  {
    "id": "arXiv:2106.10891",
    "title": "Open-set Label Noise Can Improve Robustness Against Inherent Label Noise",
    "abstract": "Learning with noisy labels is a practically challenging problem in weakly\nsupervised learning. In the existing literature, open-set noises are always\nconsidered to be poisonous for generalization, similar to closed-set noises. In\nthis paper, we empirically show that open-set noisy labels can be non-toxic and\neven benefit the robustness against inherent noisy labels. Inspired by the\nobservations, we propose a simple yet effective regularization by introducing\nOpen-set samples with Dynamic Noisy Labels (ODNL) into training. With ODNL, the\nextra capacity of the neural network can be largely consumed in a way that does\nnot interfere with learning patterns from clean data. Through the lens of SGD\nnoise, we show that the noises induced by our method are random-direction,\nconflict-free and biased, which may help the model converge to a flat minimum\nwith superior stability and enforce the model to produce conservative\npredictions on Out-of-Distribution instances. Extensive experimental results on\nbenchmark datasets with various types of noisy labels demonstrate that the\nproposed method not only enhances the performance of many existing robust\nalgorithms but also achieves significant improvement on Out-of-Distribution\ndetection tasks even in the label noise setting.",
    "descriptor": "",
    "authors": [
      "Hongxin Wei",
      "Lue Tao",
      "Renchunzi Xie",
      "Bo An"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10891"
  },
  {
    "id": "arXiv:2106.10893",
    "title": "PIANO: A Parametric Hand Bone Model from Magnetic Resonance Imaging",
    "abstract": "Hand modeling is critical for immersive VR/AR, action understanding, or human\nhealthcare. Existing parametric models account only for hand shape, pose, or\ntexture, without modeling the anatomical attributes like bone, which is\nessential for realistic hand biomechanics analysis. In this paper, we present\nPIANO, the first parametric bone model of human hands from MRI data. Our PIANO\nmodel is biologically correct, simple to animate, and differentiable, achieving\nmore anatomically precise modeling of the inner hand kinematic structure in a\ndata-driven manner than the traditional hand models based on the outer surface\nonly. Furthermore, our PIANO model can be applied in neural network layers to\nenable training with a fine-grained semantic loss, which opens up the new task\nof data-driven fine-grained hand bone anatomic and semantic understanding from\nMRI or even RGB images. We make our model publicly available.",
    "descriptor": "\nComments: Accepted to IJCAI 2021\n",
    "authors": [
      "Yuwei Li",
      "Minye Wu",
      "Yuyao Zhang",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10893"
  },
  {
    "id": "arXiv:2106.10895",
    "title": "Posets with Interfaces for Concurrent Kleene Algebra",
    "abstract": "We introduce posets with interfaces (iposets) and generalise the serial\ncomposition of posets to a new gluing composition of iposets. In partial order\nsemantics of concurrency, this amounts to designate events that continue their\nexecution across components. Alternatively, in terms of decomposing concurrent\nsystems, it allows cutting through some events, whereas serial composition may\ncut through edges only.\nWe show that iposets under gluing composition form a category, extending the\nmonoid of posets under serial composition, and a 2-category when enriched with\na subsumption order and a suitable parallel composition as a lax tensor. This\ngeneralises the interchange monoids used in concurrent Kleene algebra.\nWe also consider gp-iposets, which are generated from singletons by finitary\ngluing and parallel compositions. We show that the class includes the\nseries-parallel posets as well as the interval orders, which are also well\nstudied in concurrency theory. Finally, we show that not all posets are\ngp-iposets, exposing several posets that cannot occur as induced substructures\nof gp-iposets.",
    "descriptor": "",
    "authors": [
      "Uli Fahrenberg",
      "Christian Johansen",
      "Georg Struth",
      "Krzysztof Ziemia\u0144ski"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.10895"
  },
  {
    "id": "arXiv:2106.10898",
    "title": "BanditMF: Multi-Armed Bandit Based Matrix Factorization Recommender  System",
    "abstract": "Multi-armed bandits (MAB) provide a principled online learning approach to\nattain the balance between exploration and exploitation.Due to the superior\nperformance and low feedback learning without the learning to act in multiple\nsituations, Multi-armed Bandits drawing widespread attention in applications\nranging such as recommender systems. Likewise, within the recommender system,\ncollaborative filtering (CF) is arguably the earliest and most influential\nmethod in the recommender system. Crucially, new users and an ever-changing\npool of recommended items are the challenges that recommender systems need to\naddress. For collaborative filtering, the classical method is training the\nmodel offline, then perform the online testing, but this approach can no longer\nhandle the dynamic changes in user preferences which is the so-called\n\\textit{cold start}. So how to effectively recommend items to users in the\nabsence of effective information? To address the aforementioned problems, a\nmulti-armed bandit based collaborative filtering recommender system has been\nproposed, named BanditMF. BanditMF is designed to address two challenges in the\nmulti-armed bandits algorithm and collaborative filtering: (1) how to solve the\ncold start problem for collaborative filtering under the condition of scarcity\nof valid information, (2) how to solve the sub-optimal problem of bandit\nalgorithms in strong social relations domains caused by independently\nestimating unknown parameters associated with each user and ignoring\ncorrelations between users.",
    "descriptor": "\nComments: MSc dissertation\n",
    "authors": [
      "Shenghao Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10898"
  },
  {
    "id": "arXiv:2106.10899",
    "title": "Ad Text Classification with Transformer-Based Natural Language  Processing Methods",
    "abstract": "In this study, a natural language processing-based (NLP-based) method is\nproposed for the sector-wise automatic classification of ad texts created on\nonline advertising platforms. Our data set consists of approximately 21,000\nlabeled advertising texts from 12 different sectors. In the study, the\nBidirectional Encoder Representations from Transformers (BERT) model, which is\na transformer-based language model that is recently used in fields such as text\nclassification in the natural language processing literature, was used. The\nclassification efficiencies obtained using a pre-trained BERT model for the\nTurkish language are shown in detail.",
    "descriptor": "\nComments: 6 pages, in Turkish language, 4 figures, 3 tables, 25. Pazarlama Konferans{\\i} (25th Marketing Conference)\n",
    "authors": [
      "Umut \u00d6zdil",
      "B\u00fc\u015fra Arslan",
      "D. Emre Ta\u015far",
      "G\u00f6k\u00e7e Polat",
      "\u015e\u00fckr\u00fc Ozan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10899"
  },
  {
    "id": "arXiv:2106.10900",
    "title": "Crop-Transform-Paste: Self-Supervised Learning for Visual Tracking",
    "abstract": "While deep-learning based methods for visual tracking have achieved\nsubstantial progress, these schemes entail large-scale and high-quality\nannotated data for sufficient training. To eliminate expensive and exhaustive\nannotation, we study self-supervised learning for visual tracking. In this\nwork, we develop the Crop-Transform-Paste operation, which is able to\nsynthesize sufficient training data by simulating various kinds of scene\nvariations during tracking, including appearance variations of objects and\nbackground changes. Since the object state is known in all synthesized data,\nexisting deep trackers can be trained in routine ways without human annotation.\nDifferent from typical self-supervised learning methods performing visual\nrepresentation learning as an individual step, the proposed self-supervised\nlearning mechanism can be seamlessly integrated into any existing tracking\nframework to perform training. Extensive experiments show that our method 1)\nachieves favorable performance than supervised learning in few-shot tracking\nscenarios; 2) can deal with various tracking challenges such as object\ndeformation, occlusion, or background clutter due to its design; 3) can be\ncombined with supervised learning to further boost the performance,\nparticularly effective in few-shot tracking scenarios.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Xin Li",
      "Wenjie Pei",
      "Zikun Zhou",
      "Zhenyu He",
      "Huchuan Lu",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10900"
  },
  {
    "id": "arXiv:2106.10901",
    "title": "Conversational Agents in Software Engineering: Survey, Taxonomy and  Challenges",
    "abstract": "The use of natural language interfaces in the field of human-computer\ninteraction is undergoing intense study through dedicated scientific and\nindustrial research. The latest contributions in the field, including deep\nlearning approaches like recurrent neural networks, the potential of\ncontext-aware strategies and user-centred design approaches, have brought back\nthe attention of the community to software-based dialogue systems, generally\nknown as conversational agents or chatbots. Nonetheless, and given the novelty\nof the field, a generic, context-independent overview on the current state of\nresearch of conversational agents covering all research perspectives involved\nis missing. Motivated by this context, this paper reports a survey of the\ncurrent state of research of conversational agents through a systematic\nliterature review of secondary studies. The conducted research is designed to\ndevelop an exhaustive perspective through a clear presentation of the\naggregated knowledge published by recent literature within a variety of\ndomains, research focuses and contexts. As a result, this research proposes a\nholistic taxonomy of the different dimensions involved in the conversational\nagents' field, which is expected to help researchers and to lay the groundwork\nfor future research in the field of natural language interfaces.",
    "descriptor": "\nComments: 37 pages, 15 figures, 2 tables, submitted to journal\n",
    "authors": [
      "Quim Motger",
      "Xavier Franch",
      "Jordi Marco"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.10901"
  },
  {
    "id": "arXiv:2106.10903",
    "title": "Infinite families of linear codes supporting more $t$-designs",
    "abstract": "Tang and Ding [IEEE IT 67 (2021) 244-254] studied the class of narrow-sense\nBCH codes $\\mathcal{C}_{(q,q+1,4,1)}$ and their dual codes with $q=2^m$ and\nestablished that the codewords of the minimum (or the second minimum) weight in\nthese codes support infinite families of 4-designs or 3-designs. Motivated by\nthis, we further investigate the codewords of the next adjacent weight in such\ncodes and discover more infinite classes of $t$-designs with $t=3,4$. In\nparticular, we prove that the codewords of weight $7$ in\n$\\mathcal{C}_{(q,q+1,4,1)}$ support $4$-designs when $m \\geqslant 5$ is odd and\n$3$-designs when $m \\geqslant 4$ is even, which provide infinite classes of\nsimple $t$-designs with new parameters. Another significant class of\n$t$-designs we produce in this paper has supplementary designs with parameters\n4-$(2^{2s+1}+ 1,5,5)$; these designs have the smallest index among all the\nknown simple 4-$(q+1,5,\\lambda)$ designs derived from codes for prime powers\n$q$; and they are further proved to be isomorphic to the 4-designs admitting\nthe projective general linear group PGL$(2,2^{2s+1})$ as automorphism group\nconstructed by Alltop in 1969.",
    "descriptor": "\nComments: 27 pages, 4 tables\n",
    "authors": [
      "Qianqian Yan",
      "Junling Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.10903"
  },
  {
    "id": "arXiv:2106.10904",
    "title": "Federated Learning with Positive and Unlabeled Data",
    "abstract": "We study the problem of learning from positive and unlabeled (PU) data in the\nfederated setting, where each client only labels a little part of their dataset\ndue to the limitation of resources and time. Different from the settings in\ntraditional PU learning where the negative class consists of a single class,\nthe negative samples which cannot be identified by a client in the federated\nsetting may come from multiple classes which are unknown to the client.\nTherefore, existing PU learning methods can be hardly applied in this\nsituation. To address this problem, we propose a novel framework, namely\nFederated learning with Positive and Unlabeled data (FedPU), to minimize the\nexpected risk of multiple negative classes by leveraging the labeled data in\nother clients. We theoretically prove that the proposed FedPU can achieve a\ngeneralization bound which is no worse than $C\\sqrt{C}$ times (where $C$\ndenotes the number of classes) of the fully-supervised model. Empirical\nexperiments show that the FedPU can achieve much better performance than\nconventional learning methods which can only use positive data.",
    "descriptor": "",
    "authors": [
      "Xinyang Lin",
      "Hanting Chen",
      "Yixing Xu",
      "Chao Xu",
      "Xiaolin Gui",
      "Yiping Deng",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10904"
  },
  {
    "id": "arXiv:2106.10905",
    "title": "Bayesian inference of ODEs with Gaussian processes",
    "abstract": "Recent machine learning advances have proposed black-box estimation of\nunknown continuous-time system dynamics directly from data. However, earlier\nworks are based on approximative ODE solutions or point estimates. We propose a\nnovel Bayesian nonparametric model that uses Gaussian processes to infer\nposteriors of unknown ODE systems directly from data. We derive sparse\nvariational inference with decoupled functional sampling to represent vector\nfield posteriors. We also introduce a probabilistic shooting augmentation to\nenable efficient inference from arbitrarily long trajectories. The method\ndemonstrates the benefit of computing vector field posteriors, with predictive\nuncertainty scores outperforming alternative methods on multiple ODE learning\ntasks.",
    "descriptor": "",
    "authors": [
      "Pashupati Hegde",
      "\u00c7a\u011fatay Y\u0131ld\u0131z",
      "Harri L\u00e4hdesm\u00e4ki",
      "Samuel Kaski",
      "Markus Heinonen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10905"
  },
  {
    "id": "arXiv:2106.10910",
    "title": "Fostering Student Engagement in a Mobile Formative Assessment System for  High-School Economics",
    "abstract": "In a mobile learning environment, students can learn via mobile devices\nwithout being limited by time and space. Therefore, it is vital to develop\ntools to assist students to learn and assess their knowledge in such\nenvironments. This paper presents a tool/application for formative\nself-assessment. The tool supports the selection of questions based on\nuser-defined criteria concerning (1) the difficulty level; (2) the associated\nconcepts; and (3) the purposes of the test taker. The main purpose of the\npresented tool is to better support the learning aims of the participants and\nto increase their engagement in the learning process. The focus of this study\nis to evaluate the tool using quizzes in Microeconomics to realize its\npotential in this specific domain. Teachers and students were involved in the\nexperiments conducted. The experiments demonstrated that the presented tool is\nusable; it motivates the students and improves their understanding",
    "descriptor": "\nComments: 10 pages, 3 images\n",
    "authors": [
      "Fotis Lazarinis",
      "Dimitris Kanellopoulos"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.10910"
  },
  {
    "id": "arXiv:2106.10911",
    "title": "Approximation capabilities of measure-preserving neural networks",
    "abstract": "Measure-preserving neural networks are well-developed invertible models,\nhowever, the approximation capabilities remain unexplored. This paper\nrigorously establishes the general sufficient conditions for approximating\nmeasure-preserving maps using measure-preserving neural networks. It is shown\nthat for compact $U \\subset \\R^D$ with $D\\geq 2$, every measure-preserving map\n$\\psi: U\\to \\R^D$ which is injective and bounded can be approximated in the\n$L^p$-norm by measure-preserving neural networks. Specifically, the\ndifferentiable maps with $\\pm 1$ determinants of Jacobians are\nmeasure-preserving, injective and bounded on $U$, thus hold the approximation\nproperty.",
    "descriptor": "",
    "authors": [
      "Aiqing Zhu",
      "Pengzhan Jin",
      "Yifa Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10911"
  },
  {
    "id": "arXiv:2106.10912",
    "title": "A probabilistic parallel modular algorithm for rational univariate  representation",
    "abstract": "This article does not introduce new mathematical ideas, it is more a state of\nthe art June 2021 picture about solving polynomial systems efficiently by\nreconstructing a rational univariate representation with a very high\nprobability of correctness using Groebner revlex computation, Berlekamp-Massey\nalgorithm and Hankel linear system solving modulo several primes in parallel.\nThis algorithm is implemented in Giac/Xcas since version 1.7.0-13, it has (June\n2021) leading performances on multiple CPU, at least for an open-source\nsoftware.",
    "descriptor": "",
    "authors": [
      "Bernard Parisse"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2106.10912"
  },
  {
    "id": "arXiv:2106.10913",
    "title": "Fully algebraic domain decomposition preconditioners with adaptive  spectral bounds",
    "abstract": "In this article a new family of preconditioners is introduced for symmetric\npositive definite linear systems. The new preconditioners, called the AWG\npreconditioners (for Algebraic-Woodbury-GenEO) are constructed algebraically.\nBy this, we mean that only the knowledge of the matrix A for which the linear\nsystem is being solved is required. Thanks to the GenEO spectral coarse space\ntechnique, the condition number of the preconditioned operator is bounded\ntheoretically from above. This upper bound can be made smaller by enriching the\ncoarse space with more spectral modes.The novelty is that, unlike in previous\nwork on the GenEO coarse spaces, no knowledge of a partially non-assembled form\nof A is required. Indeed, the spectral coarse space technique is not applied\ndirectly to A but to a low-rank modification of A of which a suitable\nnon-assembled form is known by construction. The extra cost is a second (and to\nthis day rather expensive) coarse solve in the preconditioner. One of the AWG\npreconditioners has already been presented in the short preprint [38]. This\narticle is the first full presentation of the larger family of AWG\npreconditioners. It includes proofs of the spectral bounds as well as numerical\nillustrations.",
    "descriptor": "",
    "authors": [
      "Lo\u00efc Gouarin",
      "Nicole Spillane"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10913"
  },
  {
    "id": "arXiv:2106.10916",
    "title": "Surgical data science for safe cholecystectomy: a protocol for  segmentation of hepatocystic anatomy and assessment of the critical view of  safety",
    "abstract": "Minimally invasive image-guided surgery heavily relies on vision. Deep\nlearning models for surgical video analysis could therefore support visual\ntasks such as assessing the critical view of safety (CVS) in laparoscopic\ncholecystectomy (LC), potentially contributing to surgical safety and\nefficiency. However, the performance, reliability and reproducibility of such\nmodels are deeply dependent on the quality of data and annotations used in\ntheir development. Here, we present a protocol, checklists, and visual examples\nto promote consistent annotation of hepatocystic anatomy and CVS criteria. We\nbelieve that sharing annotation guidelines can help build trustworthy\nmulticentric datasets for assessing generalizability of performance, thus\naccelerating the clinical translation of deep learning models for surgical\nvideo analysis.",
    "descriptor": "\nComments: 24 pages, 34 figures\n",
    "authors": [
      "Pietro Mascagni",
      "Deepak Alapatt",
      "Alain Garcia",
      "Nariaki Okamoto",
      "Armine Vardazaryan",
      "Guido Costamagna",
      "Bernard Dallemagne",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10916"
  },
  {
    "id": "arXiv:2106.10918",
    "title": "A Mocktail of Source Code Representations",
    "abstract": "Efficient representation of source code is essential for various software\nengineering tasks such as code search and code clone detection. One such\ntechnique for representing source code involves extracting paths from the AST\nand using a learning model to capture program properties. Code2vec is a\ncommonly used path-based approach that uses an attention-based neural network\nto learn code embeddings which can then be used for various software\nengineering tasks. However, this approach uses only ASTs and does not leverage\nother graph structures such as Control Flow Graphs (CFG) and Program Dependency\nGraphs (PDG). Similarly, most recent approaches for representing source code\nstill use AST and do not leverage semantic graph structures. Even though there\nexists an integrated graph approach (Code Property Graph) for representing\nsource code, it has only been explored in the domain of software security.\nMoreover, it does not leverage the paths from the individual graphs. In our\nwork, we extend the path-based approach code2vec to include semantic graphs,\nCFG, and PDG, along with AST, which is still largely unexplored in the domain\nof software engineering. We evaluate our approach on the task of MethodNaming\nusing a custom C dataset of 730K methods collected from 16 C projects from\nGitHub. In comparison to code2vec, our approach improves the F1 Score by 11% on\nthe full dataset and up to 100% with individual projects. We show that semantic\nfeatures from the CFG and PDG paths are indeed helpful. We envision that\nlooking at a mocktail of source code representations for various software\nengineering tasks can lay the foundation for a new line of research and a\nre-haul of existing research.",
    "descriptor": "",
    "authors": [
      "Dheeraj Vagavolu",
      "Karthik Chandra Swarna",
      "Sridhar Chimalakonda"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.10918"
  },
  {
    "id": "arXiv:2106.10920",
    "title": "Cross-layer Navigation Convolutional Neural Network for Fine-grained  Visual Classification",
    "abstract": "Fine-grained visual classification (FGVC) aims to classify sub-classes of\nobjects in the same super-class (e.g., species of birds, models of cars). For\nthe FGVC tasks, the essential solution is to find discriminative subtle\ninformation of the target from local regions. TraditionalFGVC models preferred\nto use the refined features,i.e., high-level semantic information for\nrecognition and rarely use low-level in-formation. However, it turns out that\nlow-level information which contains rich detail information also has effect on\nimproving performance. Therefore, in this paper, we propose cross-layer\nnavigation convolutional neural network for feature fusion. First, the feature\nmaps extracted by the backbone network are fed into a convolutional long\nshort-term memory model sequentially from high-level to low-level to perform\nfeature aggregation. Then, attention mechanisms are used after feature fusion\nto extract spatial and channel information while linking the high-level\nsemantic information and the low-level texture features, which can better\nlocate the discriminative regions for the FGVC. In the experiments, three\ncommonly used FGVC datasets, including CUB-200-2011, Stanford-Cars,\nandFGVC-Aircraft datasets, are used for evaluation and we demonstrate the\nsuperiority of the proposed method by comparing it with other referred FGVC\nmethods to show that this method achieves superior results.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Chenyu Guo",
      "Jiyang Xie",
      "Kongming Liang",
      "Xian Sun",
      "Zhanyu Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10920"
  },
  {
    "id": "arXiv:2106.10923",
    "title": "Unsupervised Deep Learning by Injecting Low-Rank and Sparse Priors",
    "abstract": "What if deep neural networks can learn from sparsity-inducing priors? When\nthe networks are designed by combining layer modules (CNN, RNN, etc), engineers\nless exploit the inductive bias, i.e., existing well-known rules or prior\nknowledge, other than annotated training data sets. We focus on employing\nsparsity-inducing priors in deep learning to encourage the network to concisely\ncapture the nature of high-dimensional data in an unsupervised way. In order to\nuse non-differentiable sparsity-inducing norms as loss functions, we plug their\nproximal mappings into the automatic differentiation framework. We demonstrate\nunsupervised learning of U-Net for background subtraction using low-rank and\nsparse priors. The U-Net can learn moving objects in a training sequence\nwithout any annotation, and successfully detect the foreground objects in test\nsequences.",
    "descriptor": "",
    "authors": [
      "Tomoya Sakai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.10923"
  },
  {
    "id": "arXiv:2106.10925",
    "title": "Investigating the role of educational robotics in formal mathematics  education: the case of geometry for 15-year-old students",
    "abstract": "Research has shown that Educational Robotics (ER) enhances student\nperformance, interest, engagement and collaboration. However, until now, the\nadoption of robotics in formal education has remained relatively scarce. Among\nother causes, this is due to the difficulty of determining the alignment of\neducational robotic learning activities with the learning outcomes envisioned\nby the curriculum, as well as their integration with traditional, non-robotics\nlearning activities that are well established in teachers' practices. This work\ninvestigates the integration of ER into formal mathematics education, through a\nquasi-experimental study employing the Thymio robot and Scratch programming to\nteach geometry to two classes of 15-year-old students, for a total of 26\nparticipants. Three research questions were addressed: (1) Should an ER-based\ntheoretical lecture precede, succeed or replace a traditional theoretical\nlecture? (2) What is the students' perception of and engagement in the ER-based\nlecture and exercises? (3) Do the findings differ according to students' prior\nappreciation of mathematics? The results suggest that ER activities are as\nvalid as traditional ones in helping students grasp the relevant theoretical\nconcepts. Robotics activities seem particularly beneficial during exercise\nsessions: students freely chose to do exercises that included the robot, rated\nthem as significantly more interesting and useful than their traditional\ncounterparts, and expressed their interest in introducing ER in other\nmathematics lectures. Finally, results were generally consistent between the\nstudents that like and did not like mathematics, suggesting the use of robotics\nas a means to broaden the number of students engaged in the discipline.",
    "descriptor": "\nComments: To appear in the proceedings of the Sixteenth European Conference on Technology Enhanced Learning (2021)\n",
    "authors": [
      "J\u00e9r\u00f4me Brender",
      "Laila El-Hamamsy",
      "Barbara Bruno",
      "Fr\u00e9d\u00e9rique Chessel-Lazzarotto",
      "Jessica Dehler Zufferey",
      "Francesco Mondada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.10925"
  },
  {
    "id": "arXiv:2106.10926",
    "title": "The weak convergence order of two Euler-type discretization schemes for  the log-Heston model",
    "abstract": "We study the weak convergence order of two Euler-type discretizations of the\nlog-Heston Model where we use symmetrization and absorption, respectively, to\nprevent the discretization of the underlying CIR process from becoming\nnegative. If the Feller index $\\nu$ of the CIR process satisfies $\\nu>1$, we\nestablish weak convergence order one, while for $\\nu \\leq 1$, we obtain weak\nconvergence order $\\nu-\\epsilon$ for $\\epsilon>0$ arbitrarily small. We\nillustrate our theoretical findings by several numerical examples.",
    "descriptor": "",
    "authors": [
      "Annalena Mickel",
      "Andreas Neuenkirch"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10926"
  },
  {
    "id": "arXiv:2106.10928",
    "title": "STEP-EZ: Syntax Tree guided semantic ExPlanation for Explainable  Zero-shot modeling of clinical depression symptoms from text",
    "abstract": "We focus on exploring various approaches of Zero-Shot Learning (ZSL) and\ntheir explainability for a challenging yet important supervised learning task\nnotorious for training data scarcity, i.e. Depression Symptoms Detection (DSD)\nfrom text. We start with a comprehensive synthesis of different components of\nour ZSL modeling and analysis of our ground truth samples and Depression\nsymptom clues curation process with the help of a practicing clinician. We next\nanalyze the accuracy of various state-of-the-art ZSL models and their potential\nenhancements for our task. Further, we sketch a framework for the use of ZSL\nfor hierarchical text-based explanation mechanism, which we call, Syntax\nTree-Guided Semantic Explanation (STEP). Finally, we summarize experiments from\nwhich we conclude that we can use ZSL models and achieve reasonable accuracy\nand explainability, measured by a proposed Explainability Index (EI). This work\nis, to our knowledge, the first work to exhaustively explore the efficacy of\nZSL models for DSD task, both in terms of accuracy and explainability.",
    "descriptor": "",
    "authors": [
      "Nawshad Farruque",
      "Randy Goebel",
      "Osmar Zaiane",
      "Sudhakar Sivapalan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10928"
  },
  {
    "id": "arXiv:2106.10932",
    "title": "Holographic Smart EM Skins for Advanced Beam Power Shaping in Next  Generation Wireless Environments",
    "abstract": "An innovative approach for the synthesis of inexpensive holographic smart\nelectromagnetic (EM) skins with advanced beamforming features is proposed. The\ncomplex multiscale smart skin design is formulated within the Generalized Sheet\nTransition Condition (GSTC) framework as a combination of a mask-constrained\nisophoric inverse source problem and a micro-scale susceptibility dyadic\noptimization. The solution strategy integrates a local search procedure based\non the iterative projection technique (IPT) and a System-by-Design (SbD)-based\noptimization loop for the identification of optimal metasurface descriptors\nmatching the desired surface currents. The performance and the efficiency of\nthe proposed approach are assessed in a set of representative test cases\nconcerned with different smart skin apertures and target pattern masks.",
    "descriptor": "",
    "authors": [
      "Giacomo Oliveri",
      "Paolo Rocca",
      "Marco Salucci",
      "Andrea Massa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10932"
  },
  {
    "id": "arXiv:2106.10934",
    "title": "GRAND: Graph Neural Diffusion",
    "abstract": "We present Graph Neural Diffusion (GRAND) that approaches deep learning on\ngraphs as a continuous diffusion process and treats Graph Neural Networks\n(GNNs) as discretisations of an underlying PDE. In our model, the layer\nstructure and topology correspond to the discretisation choices of temporal and\nspatial operators. Our approach allows a principled development of a broad new\nclass of GNNs that are able to address the common plights of graph learning\nmodels such as depth, oversmoothing, and bottlenecks. Key to the success of our\nmodels are stability with respect to perturbations in the data and this is\naddressed for both implicit and explicit discretisation schemes. We develop\nlinear and nonlinear versions of GRAND, which achieve competitive results on\nmany standard graph benchmarks.",
    "descriptor": "\nComments: 15 pages, 4 figures. Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021. Copyright 2021 by the author(s)\n",
    "authors": [
      "Benjamin Paul Chamberlain",
      "James Rowbottom",
      "Maria Gorinova",
      "Stefan Webb",
      "Emanuele Rossi",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10934"
  },
  {
    "id": "arXiv:2106.10935",
    "title": "On Limited-Memory Subsampling Strategies for Bandits",
    "abstract": "There has been a recent surge of interest in nonparametric bandit algorithms\nbased on subsampling. One drawback however of these approaches is the\nadditional complexity required by random subsampling and the storage of the\nfull history of rewards. Our first contribution is to show that a simple\ndeterministic subsampling rule, proposed in the recent work of Baudry et al.\n(2020) under the name of ''last-block subsampling'', is asymptotically optimal\nin one-parameter exponential families. In addition, we prove that these\nguarantees also hold when limiting the algorithm memory to a polylogarithmic\nfunction of the time horizon. These findings open up new perspectives, in\nparticular for non-stationary scenarios in which the arm distributions evolve\nover time. We propose a variant of the algorithm in which only the most recent\nobservations are used for subsampling, achieving optimal regret guarantees\nunder the assumption of a known number of abrupt changes. Extensive numerical\nsimulations highlight the merits of this approach, particularly when the\nchanges are not only affecting the means of the rewards.",
    "descriptor": "",
    "authors": [
      "Dorian Baudry",
      "Yoan Russac",
      "Olivier Capp\u00e9"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10935"
  },
  {
    "id": "arXiv:2106.10936",
    "title": "TCIC: Theme Concepts Learning Cross Language and Vision for Image  Captioning",
    "abstract": "Existing research for image captioning usually represents an image using a\nscene graph with low-level facts (objects and relations) and fails to capture\nthe high-level semantics. In this paper, we propose a Theme Concepts extended\nImage Captioning (TCIC) framework that incorporates theme concepts to represent\nhigh-level cross-modality semantics. In practice, we model theme concepts as\nmemory vectors and propose Transformer with Theme Nodes (TTN) to incorporate\nthose vectors for image captioning. Considering that theme concepts can be\nlearned from both images and captions, we propose two settings for their\nrepresentations learning based on TTN. On the vision side, TTN is configured to\ntake both scene graph based features and theme concepts as input for visual\nrepresentation learning. On the language side, TTN is configured to take both\ncaptions and theme concepts as input for text representation re-construction.\nBoth settings aim to generate target captions with the same transformer-based\ndecoder. During the training, we further align representations of theme\nconcepts learned from images and corresponding captions to enforce the\ncross-modality learning. Experimental results on MS COCO show the effectiveness\nof our approach compared to some state-of-the-art models.",
    "descriptor": "\nComments: IJCAI2021\n",
    "authors": [
      "Zhihao Fan",
      "Zhongyu Wei",
      "Siyuan Wang",
      "Ruize Wang",
      "Zejun Li",
      "Haijun Shan",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.10936"
  },
  {
    "id": "arXiv:2106.10938",
    "title": "A Game-Theoretic Taxonomy of Visual Concepts in DNNs",
    "abstract": "In this paper, we rethink how a DNN encodes visual concepts of different\ncomplexities from a new perspective, i.e. the game-theoretic multi-order\ninteractions between pixels in an image. Beyond the categorical taxonomy of\nobjects and the cognitive taxonomy of textures and shapes, we provide a new\ntaxonomy of visual concepts, which helps us interpret the encoding of shapes\nand textures, in terms of concept complexities. In this way, based on\nmulti-order interactions, we find three distinctive signal-processing behaviors\nof DNNs encoding textures. Besides, we also discover the flexibility for a DNN\nto encode shapes is lower than the flexibility of encoding textures.\nFurthermore, we analyze how DNNs encode outlier samples, and explore the\nimpacts of network architectures on interactions. Additionally, we clarify the\ncrucial role of the multi-order interactions in real-world applications. The\ncode will be released when the paper is accepted.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Xu Cheng",
      "Chuntung Chu",
      "Yi Zheng",
      "Jie Ren",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10938"
  },
  {
    "id": "arXiv:2106.10940",
    "title": "Deep Spatio-Temporal Forecasting of Electrical Vehicle Charging Demand",
    "abstract": "Electric vehicles can offer a low carbon emission solution to reverse rising\nemission trends. However, this requires that the energy used to meet the demand\nis green. To meet this requirement, accurate forecasting of the charging demand\nis vital. Short and long-term charging demand forecasting will allow for better\noptimisation of the power grid and future infrastructure expansions. In this\npaper, we propose to use publicly available data to forecast the electric\nvehicle charging demand. To model the complex spatial-temporal correlations\nbetween charging stations, we argue that Temporal Graph Convolution Models are\nthe most suitable to capture the correlations. The proposed Temporal Graph\nConvolutional Networks provide the most accurate forecasts for short and\nlong-term forecasting compared with other forecasting methods.",
    "descriptor": "",
    "authors": [
      "Frederik Boe H\u00fcttel",
      "Inon Peled",
      "Filipe Rodrigues",
      "Francisco C. Pereira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10940"
  },
  {
    "id": "arXiv:2106.10942",
    "title": "Realization of multi-input/multi-output switched linear systems from  Markov parameters",
    "abstract": "This paper presents a four-stage algorithm for the realization of\nmulti-input/multi-output (MIMO) switched linear systems (SLSs) from Markov\nparameters. In the first stage, a linear time-varying (LTV) realization that is\ntopologically equivalent to the true SLS is derived from the Markov parameters\nassuming that the submodels have a common MacMillan degree and a mild condition\non their dwell times holds. In the second stage, zero sets of LTV Hankel\nmatrices where the realized system has a linear time-invariant (LTI) pulse\nresponse matching that of the original SLS are exploited to extract the\nsubmodels, up to arbitrary similarity transformations, by a clustering\nalgorithm using a statistics that is invariant to similarity transformations.\nRecovery is shown to be complete if the dwell times are sufficiently long and\nsome mild identifiability conditions are met. In the third stage, the switching\nsequence is estimated by three schemes. The first scheme is based on\nforward/backward corrections and works on the short segments. The second scheme\nmatches Markov parameter estimates to the true parameters for LTV systems and\nworks on the medium-to-long segments. The third scheme also matches Markov\nparameters, but for LTI systems only and works on the very short segments. In\nthe fourth stage, the submodels estimated in Stage~2 are brought to a common\nbasis by applying a novel basis transformation method which is necessary before\nperforming output predictions to given inputs. A numerical example illustrates\nthe properties of the realization algorithm. A key role in this algorithm is\nplayed by time-dependent switching sequences that partition the state-space\naccording to time, unlike many other works in the literature in which\npartitioning is state and/or input dependent.",
    "descriptor": "",
    "authors": [
      "Fethi Bencherki",
      "Semiha T\u00fcrkay",
      "H\u00fcseyin Ak\u00e7ay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10942"
  },
  {
    "id": "arXiv:2106.10944",
    "title": "Hard hat wearing detection based on head keypoint localization",
    "abstract": "In recent years, a lot of attention is paid to deep learning methods in the\ncontext of vision-based construction site safety systems, especially regarding\npersonal protective equipment. However, despite all this attention, there is\nstill no reliable way to establish the relationship between workers and their\nhard hats. To answer this problem a combination of deep learning, object\ndetection and head keypoint localization, with simple rule-based reasoning is\nproposed in this article. In tests, this solution surpassed the previous\nmethods based on the relative bounding box position of different instances, as\nwell as direct detection of hard hat wearers and non-wearers. The results show\nthat the conjunction of novel deep learning methods with humanly-interpretable\nrule-based systems can result in a solution that is both reliable and can\nsuccessfully mimic manual, on-site supervision. This work is the next step in\nthe development of fully autonomous construction site safety systems and shows\nthat there is still room for improvement in this area.",
    "descriptor": "\nComments: 15 pages, 9 figures and 9 tables\n",
    "authors": [
      "Bartosz W\u00f3jcik",
      "Mateusz \u017barski",
      "Kamil Ksi\u0105\u017cek",
      "Jaros\u0142aw Adam Miszczak",
      "Miros\u0142aw Jan Skibniewski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.10944"
  },
  {
    "id": "arXiv:2106.10945",
    "title": "A posteriori goal-oriented bounds for the Poisson problem using  potential and equilibrated flux reconstructions: application to the  hybridizable discontinuous Galerkin method",
    "abstract": "We present a general framework to compute upper and lower bounds for\nlinear-functional outputs of the exact solutions of the Poisson equation based\non reconstructions of the field variable and flux for both the primal and\nadjoint problems. The method is devised from a generalization of the\ncomplementary energy principle and the duality theory. Using duality theory,\nthe computation of bounds is reduced to finding independent potential and\nequilibrated flux reconstructions. A generalization of this result is also\nintroduced, allowing to derive alternative guaranteed bounds from\nnearly-arbitrary H(div;{\\Omega}) flux reconstructions (only zero-order\nequilibration is required). This approach is applicable to any numerical method\nused to compute the solution. In this work, the proposed approach is applied to\nderive bounds for the hybridizable discontinuous Galerkin (HDG) method. An\nattractive feature of the proposed approach is that superconvergence on the\nbound gap is achieved, yielding accurate bounds even for very coarse meshes.\nNumerical experiments are presented to illustrate the performance and\nconvergence of the bounds for the HDG method in both uniform and adaptive mesh\nrefinements.",
    "descriptor": "",
    "authors": [
      "Nuria Pares",
      "Ngoc-Cuong Nguyen",
      "Pedro Diez",
      "Jaume Peraire"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10945"
  },
  {
    "id": "arXiv:2106.10946",
    "title": "Defeasible Reasoning via Datalog$^\\neg$",
    "abstract": "We address the problem of compiling defeasible theories to Datalog$^\\neg$\nprograms. We prove the correctness of this compilation, for the defeasible\nlogic $DL(\\partial_{||})$, but the techniques we use apply to many other\ndefeasible logics. Structural properties of $DL(\\partial_{||})$ are identified\nthat support efficient implementation and/or approximation of the conclusions\nof defeasible theories in the logic, compared with other defeasible logics. We\nalso use previously well-studied structural properties of logic programs to\nadapt to incomplete Datalog$^\\neg$ implementations.",
    "descriptor": "\nComments: Under consideration in Theory and Practice of Logic Programming (TPLP)\n",
    "authors": [
      "Michael J. Maher"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10946"
  },
  {
    "id": "arXiv:2106.10947",
    "title": "Leveraging Conditional Generative Models in a General Explanation  Framework of Classifier Decisions",
    "abstract": "Providing a human-understandable explanation of classifiers' decisions has\nbecome imperative to generate trust in their use for day-to-day tasks. Although\nmany works have addressed this problem by generating visual explanation maps,\nthey often provide noisy and inaccurate results forcing the use of heuristic\nregularization unrelated to the classifier in question. In this paper, we\npropose a new general perspective of the visual explanation problem overcoming\nthese limitations. We show that visual explanation can be produced as the\ndifference between two generated images obtained via two specific conditional\ngenerative models. Both generative models are trained using the classifier to\nexplain and a database to enforce the following properties: (i) All images\ngenerated by the first generator are classified similarly to the input image,\nwhereas the second generator's outputs are classified oppositely. (ii)\nGenerated images belong to the distribution of real images. (iii) The distances\nbetween the input image and the corresponding generated images are minimal so\nthat the difference between the generated elements only reveals relevant\ninformation for the studied classifier. Using symmetrical and cyclic\nconstraints, we present two different approximations and implementations of the\ngeneral formulation. Experimentally, we demonstrate significant improvements\nw.r.t the state-of-the-art on three different public data sets. In particular,\nthe localization of regions influencing the classifier is consistent with human\nannotations.",
    "descriptor": "",
    "authors": [
      "Martin Charachon",
      "Paul-Henry Courn\u00e8de",
      "C\u00e9line Hudelot",
      "Roberto Ardon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10947"
  },
  {
    "id": "arXiv:2106.10950",
    "title": "Multiple Object Tracking with Mixture Density Networks for Trajectory  Estimation",
    "abstract": "Multiple object tracking faces several challenges that may be alleviated with\ntrajectory information. Knowing the posterior locations of an object helps\ndisambiguating and solving situations such as occlusions, re-identification,\nand identity switching. In this work, we show that trajectory estimation can\nbecome a key factor for tracking, and present TrajE, a trajectory estimator\nbased on recurrent mixture density networks, as a generic module that can be\nadded to existing object trackers. To provide several trajectory hypotheses,\nour method uses beam search. Also, relying on the same estimated trajectory, we\npropose to reconstruct a track after an occlusion occurs. We integrate TrajE\ninto two state of the art tracking algorithms, CenterTrack [63] and Tracktor\n[3]. Their respective performances in the MOTChallenge 2017 test set are\nboosted 6.3 and 0.3 points in MOTA score, and 1.8 and 3.1 in IDF1, setting a\nnew state of the art for the CenterTrack+TrajE configuration",
    "descriptor": "\nComments: Best paper runner up on CVPR 2021 RVSU workshop\n",
    "authors": [
      "Andreu Girbau",
      "Xavier Gir\u00f3-i-Nieto",
      "Ignasi Rius",
      "Ferran Marqu\u00e9s"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10950"
  },
  {
    "id": "arXiv:2106.10955",
    "title": "Extractive approach for text summarisation using graphs",
    "abstract": "Natural language processing is an important discipline with the aim of\nunderstanding text by its digital representation, that due to the diverse way\nwe write and speak, is often not accurate enough. Our paper explores different\ngraph-related algorithms that can be used in solving the text summarization\nproblem using an extractive approach. We consider two metrics: sentence overlap\nand edit distance for measuring sentence similarity.",
    "descriptor": "\nComments: 4 pages, 2 figures, 5 tables\n",
    "authors": [
      "Kastriot Kadriu",
      "Milenko Obradovic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10955"
  },
  {
    "id": "arXiv:2106.10962",
    "title": "Segmentation of cell-level anomalies in electroluminescence images of  photovoltaic modules",
    "abstract": "In the operation & maintenance (O&M) of photovoltaic (PV) plants, the early\nidentification of failures has become crucial to maintain productivity and\nprolong components' life. Of all defects, cell-level anomalies can lead to\nserious failures and may affect surrounding PV modules in the long run. These\nfine defects are usually captured with high spatial resolution\nelectroluminescence (EL) imaging. The difficulty of acquiring such images has\nlimited the availability of data. For this work, multiple data resources and\naugmentation techniques have been used to surpass this limitation. Current\nstate-of-the-art detection methods extract barely low-level information from\nindividual PV cell images, and their performance is conditioned by the\navailable training data. In this article, we propose an end-to-end deep\nlearning pipeline that detects, locates and segments cell-level anomalies from\nentire photovoltaic modules via EL images. The proposed modular pipeline\ncombines three deep learning techniques: 1. object detection (modified\nFaster-RNN), 2. image classification (EfficientNet) and 3. weakly supervised\nsegmentation (autoencoder). The modular nature of the pipeline allows to\nupgrade the deep learning models to the further improvements in the\nstate-of-the-art and also extend the pipeline towards new functionalities.",
    "descriptor": "\nComments: 16 pages, 14 figures\n",
    "authors": [
      "Urtzi Otamendi",
      "I\u00f1igo Martinez",
      "Marco Quartulli",
      "Igor G. Olaizola",
      "Elisabeth Viles",
      "Werther Cambarau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10962"
  },
  {
    "id": "arXiv:2106.10963",
    "title": "Wireless Communication Aided by Intelligent Reflecting Surface: Active  or Passive?",
    "abstract": "In this letter, we consider an intelligent reflecting surface (IRS)-aided\nwireless communication system, where an active or passive IRS is employed to\nassist the communication between an access point and a user. First, we consider\nthe downlink/uplink communication separately and optimize the IRS placement for\nrate maximization with an active or passive IRS. We show that the active IRS\nshould be deployed closer to the receiver with the IRS's decreasing\namplification power; while in contrast, the passive IRS should be deployed near\neither the transmitter or receiver. Moreover, with optimized IRS placement, the\npassive IRS is shown to outperform its active counterpart when the number of\nreflecting elements is sufficiently large and/or the active-IRS amplification\npower is too small. Next, we optimize the IRS placement for both active and\npassive IRSs to maximize the weighted sum-rate of uplink and downlink\ncommunications. We show that in this case, the passive IRS is more likely to\nachieve superior rate performance. This is because the optimal active-IRS\nplacement needs to balance the rate performance in the uplink and downlink,\nwhile deploying the passive IRS near the transmitter or receiver is optimal\nregardless of the uplink or downlink.",
    "descriptor": "\nComments: We studied the comparison between active and passive IRS with optimized IRS deployment\n",
    "authors": [
      "Changsheng You",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.10963"
  },
  {
    "id": "arXiv:2106.10964",
    "title": "Detection Of Primary User Emulation Attack (PUEA) In Cognitive Radio  Networks Using One-Class Classification",
    "abstract": "Opportunistic usage of spectrum owned by licensed (or primary) users is the\ncornerstone on which the Cognitive Radio technology is built. Unlicensed (or\nsecondary) users that thus use the spectrum rely opportunistically on spectrum\nsensing to determine the presence of primary user signal. In such a context, an\nattacker may mimic the behavior of a primary user (PU) to deceive the secondary\nusers (SUs) into believing that a PU signal is present whereas it is not. Such\nan attack is known as the Primary User Emulation Attack (PUEA). A malicious\nuser may launch a PUEA with the intention of grabbing the vacant bands for its\nown transmission. Another reason may be to simply disrupt the functioning of\nthe Cognitive Radio Network (CRN). This work investigates the use of one-class\nclassification for detecting PUEA in an infrastructure-based CRN. We opine that\nsensing data collected at the fusion center mainly for Collaborative Spectrum\nSensing (CSS) can be exploited to characterize a PU signal. The PU signal\nfeatures thus learned can aid in distinguishing a PU signal from a PU signal\nemulation. In particular, we investigate the use of one-class classification\ntechniques, viz., Isolation Forest, Support Vector Machines (SVM), Minimum\nCovariance Determinant(MCD) and Local Outlier Factor(LOF) for detection of PUEA\nattacks. Simulation results support the validity of using one-class\nclassification for detection of PUEA.",
    "descriptor": "\nComments: 7 pages, 10 figures and 4 tables\n",
    "authors": [
      "Bishal Chhetry",
      "Ningrinla Marchang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10964"
  },
  {
    "id": "arXiv:2106.10969",
    "title": "Towards a Framework for Changing-Contact Robot Manipulation",
    "abstract": "Many robot manipulation tasks require the robot to make and break contact\nwith objects and surfaces. The dynamics of such changing-contact robot\nmanipulation tasks are discontinuous when contact is made or broken, and\ncontinuous elsewhere. These discontinuities make it difficult to construct and\nuse a single dynamics model or control strategy for any such task. We present a\nframework for smooth dynamics and control of such changing-contact manipulation\ntasks. For any given target motion trajectory, the framework incrementally\nimproves its prediction of when contacts will occur. This prediction and a\nmodel relating approach velocity to impact force modify the velocity profile of\nthe motion sequence such that it is $C^\\infty$ smooth, and help achieve a\ndesired force on impact. We implement this framework by building on our hybrid\nforce-motion variable impedance controller for continuous contact tasks. We\nexperimentally evaluate our framework in the illustrative context of sliding\ntasks involving multiple contact changes with transitions between surfaces of\ndifferent properties.",
    "descriptor": "\nComments: Submitted to \"Autonomous Robots and Multirobot Systems (ARMS) Workshop\" at 20th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2021\n",
    "authors": [
      "Saif Sidhik",
      "Mohan Sridharan",
      "Dirk Ruiken"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10969"
  },
  {
    "id": "arXiv:2106.10970",
    "title": "Anticipatory Detection of Compulsive Body-focused Repetitive Behaviors  with Wearables",
    "abstract": "Body-focused repetitive behaviors (BFRBs), like face-touching or\nskin-picking, are hand-driven behaviors which can damage one's appearance, if\nnot identified early and treated. Technology for automatic detection is still\nunder-explored, with few previous works being limited to wearables with single\nmodalities (e.g., motion). Here, we propose a multi-sensory approach combining\nmotion, orientation, and heart rate sensors to detect BFRBs. We conducted a\nfeasibility study in which participants (N=10) were exposed to BFRBs-inducing\ntasks, and analyzed 380 mins of signals under an extensive evaluation of\nsensing modalities, cross-validation methods, and observation windows. Our\nmodels achieved an AUC > 0.90 in distinguishing BFRBs, which were more evident\nin observation windows 5 mins prior to the behavior as opposed to 1-min ones.\nIn a follow-up qualitative survey, we found that not only the timing of\ndetection matters but also models need to be context-aware, when designing\njust-in-time interventions to prevent BFRBs.",
    "descriptor": "\nComments: Accepted to ACM MobileHCI 2021 (20 pages, dataset/code: this https URL)\n",
    "authors": [
      "Benjamin Lucas Searle",
      "Dimitris Spathis",
      "Marios Constantinides",
      "Daniele Quercia",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10970"
  },
  {
    "id": "arXiv:2106.10971",
    "title": "Near-Optimal Pool Testing under Urgency Constraints",
    "abstract": "Detection of rare traits or diseases in a large population is challenging.\nPool testing allows covering larger swathes of population at a reduced cost,\nwhile simplifying logistics. However, testing precision decreases as it becomes\nunclear which member of a pool made the global test positive.\nIn this paper we discuss testing strategies that provably approach\nbest-possible strategy - optimal in the sense that no other strategy can give\nexact results with fewer tests. Our algorithms guarantee that they provide a\ncomplete and exact result for every individual, without exceeding $1/0.99$\ntimes the number of tests the optimal strategy would require.\nThis threshold is arbitrary: algorithms closer to the optimal bound can be\ndescribed, however their complexity increases, making them less practical.\nMoreover, the way the algorithms process input samples leads to some\nindividuals' status to be known sooner, thus allowing to take urgency into\naccount when assigning individuals to tests.",
    "descriptor": "",
    "authors": [
      "\u00c9ric Brier",
      "Megi Dervishi",
      "R\u00e9mi G\u00e9raud-Stewart",
      "David Naccache",
      "Ofer Yifrach-Stav"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.10971"
  },
  {
    "id": "arXiv:2106.10972",
    "title": "Improving security for users of decentralized exchanges through  multiparty computation",
    "abstract": "Decentralized cryptocurrency exchanges offer compelling security benefits\nover centralized exchanges: users control their funds and avoid the risk of an\nexchange hack or malicious operator. However, because user assets are fully\naccessible by a secret key, decentralized exchanges pose significant internal\nsecurity risks for trading firms and automated trading systems, where a\ncompromised system can result in total loss of funds. Centralized exchanges\nmitigate this risk through API key based security policies that allow\nprofessional users to give individual traders or automated systems specific and\ncustomizable access rights such as trading or withdrawal limits. Such policies,\nhowever, are not compatible with decentralized exchanges, where all exchange\noperations require a signature generated by the owner's secret key. This paper\nintroduces a protocol based upon multiparty computation that allows for the\ncreation of API keys and security policies that can be applied to any existing\ndecentralized exchange. Our protocol works with both ECDSA and EdDSA signature\nschemes and prioritizes efficient computation and communication. We have\ndeployed this protocol on Nash exchange, as well as around several\nEthereum-based automated market maker smart contracts, where it secures the\ntrading accounts and wallets of thousands of users.",
    "descriptor": "",
    "authors": [
      "Robert Annessi",
      "Ethan Fast"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.10972"
  },
  {
    "id": "arXiv:2106.10974",
    "title": "Friendly Training: Neural Networks Can Adapt Data To Make Learning  Easier",
    "abstract": "In the last decade, motivated by the success of Deep Learning, the scientific\ncommunity proposed several approaches to make the learning procedure of Neural\nNetworks more effective. When focussing on the way in which the training data\nare provided to the learning machine, we can distinguish between the classic\nrandom selection of stochastic gradient-based optimization and more involved\ntechniques that devise curricula to organize data, and progressively increase\nthe complexity of the training set. In this paper, we propose a novel training\nprocedure named Friendly Training that, differently from the aforementioned\napproaches, involves altering the training examples in order to help the model\nto better fulfil its learning criterion. The model is allowed to simplify those\nexamples that are too hard to be classified at a certain stage of the training\nprocedure. The data transformation is controlled by a developmental plan that\nprogressively reduces its impact during training, until it completely vanishes.\nIn a sense, this is the opposite of what is commonly done in order to increase\nrobustness against adversarial examples, i.e., Adversarial Training.\nExperiments on multiple datasets are provided, showing that Friendly Training\nyields improvements with respect to informed data sub-selection routines and\nrandom selection, especially in deep convolutional architectures. Results\nsuggest that adapting the input data is a feasible way to stabilize learning\nand improve the generalization skills of the network.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Simone Marullo",
      "Matteo Tiezzi",
      "Marco Gori",
      "Stefano Melacci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10974"
  },
  {
    "id": "arXiv:2106.10977",
    "title": "Computational Pronunciation Analysis in Sung Utterances",
    "abstract": "Recent automatic lyrics transcription (ALT) approaches focus on building\nstronger acoustic models or in-domain language models, while the pronunciation\naspect is seldom touched upon. This paper applies a novel computational\nanalysis on the pronunciation variances in sung utterances and further proposes\na new pronunciation model adapted for singing. The singing-adapted model is\ntested on multiple public datasets via word recognition experiments. It\nperforms better than the standard speech dictionary in all settings reporting\nthe best results on ALT in a capella recordings using n-gram language models.\nFor reproducibility, we share the sentence-level annotations used in testing,\nproviding a new benchmark evaluation set for ALT.",
    "descriptor": "",
    "authors": [
      "Emir Demirel",
      "Sven Ahlback",
      "Simon Dixon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.10977"
  },
  {
    "id": "arXiv:2106.10978",
    "title": "Attribute Selection using Contranominal Scales",
    "abstract": "Formal Concept Analysis (FCA) allows to analyze binary data by deriving\nconcepts and ordering them in lattices. One of the main goals of FCA is to\nenable humans to comprehend the information that is encapsulated in the data;\nhowever, the large size of concept lattices is a limiting factor for the\nfeasibility of understanding the underlying structural properties. The size of\nsuch a lattice depends on the number of subcontexts in the corresponding formal\ncontext that are isomorphic to a contranominal scale of high dimension. In this\nwork, we propose the algorithm ContraFinder that enables the computation of all\ncontranominal scales of a given formal context. Leveraging this algorithm, we\nintroduce delta-adjusting, a novel approach in order to decrease the number of\ncontranominal scales in a formal context by the selection of an appropriate\nattribute subset. We demonstrate that delta-adjusting a context reduces the\nsize of the hereby emerging sub-semilattice and that the implication set is\nrestricted to meaningful implications. This is evaluated with respect to its\nassociated knowledge by means of a classification task. Hence, our proposed\ntechnique strongly improves understandability while preserving important\nconceptual structures.",
    "descriptor": "\nComments: 17 pages, 2 figures, 3 tables, 1 algorithm, 26th International Conference on Conceptual Structures\n",
    "authors": [
      "Dominik D\u00fcrrschnabel",
      "Maren Koyda",
      "Gerd Stumme"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10978"
  },
  {
    "id": "arXiv:2106.10980",
    "title": "SHREC 2021: Track on Skeleton-based Hand Gesture Recognition in the Wild",
    "abstract": "Gesture recognition is a fundamental tool to enable novel interaction\nparadigms in a variety of application scenarios like Mixed Reality\nenvironments, touchless public kiosks, entertainment systems, and more.\nRecognition of hand gestures can be nowadays performed directly from the stream\nof hand skeletons estimated by software provided by low-cost trackers\n(Ultraleap) and MR headsets (Hololens, Oculus Quest) or by video processing\nsoftware modules (e.g. Google Mediapipe). Despite the recent advancements in\ngesture and action recognition from skeletons, it is unclear how well the\ncurrent state-of-the-art techniques can perform in a real-world scenario for\nthe recognition of a wide set of heterogeneous gestures, as many benchmarks do\nnot test online recognition and use limited dictionaries. This motivated the\nproposal of the SHREC 2021: Track on Skeleton-based Hand Gesture Recognition in\nthe Wild. For this contest, we created a novel dataset with heterogeneous\ngestures featuring different types and duration. These gestures have to be\nfound inside sequences in an online recognition scenario. This paper presents\nthe result of the contest, showing the performances of the techniques proposed\nby four research groups on the challenging task compared with a simple baseline\nmethod.",
    "descriptor": "\nComments: 12 pages, to be published on Computers & Graphics\n",
    "authors": [
      "Ariel Caputo",
      "Andrea Giachetti",
      "Simone Soso",
      "Deborah Pintani",
      "Andrea D'Eusanio",
      "Stefano Pini",
      "Guido Borghi",
      "Alessandro Simoni",
      "Roberto Vezzani",
      "Rita Cucchiara",
      "Andrea Ranieri",
      "Franca Giannini",
      "Katia Lupinetti",
      "Marina Monti",
      "Mehran Maghoumi",
      "Joseph J. LaViola Jr",
      "Minh-Quan Le",
      "Hai-Dang Nguyen",
      "Minh-Triet Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10980"
  },
  {
    "id": "arXiv:2106.10989",
    "title": "Pre-training also Transfers Non-Robustness",
    "abstract": "Pre-training has enabled many state-of-the-art results on many tasks. In\nspite of its recognized contribution to generalization, we observed in this\nstudy that pre-training also transfers the non-robustness from pre-trained\nmodel into the fine-tuned model. Using image classification as an example, we\nfirst conducted experiments on various datasets and network backbones to\nexplore the factors influencing robustness. Further analysis is conducted on\nexamining the difference between the fine-tuned model and standard model to\nuncover the reason leading to the non-robustness transfer. Finally, we\nintroduce a simple robust pre-training solution by regularizing the difference\nbetween target and source tasks. Results validate the effectiveness in\nalleviating non-robustness and preserving generalization.",
    "descriptor": "",
    "authors": [
      "Jiaming Zhang",
      "Jitao Sang",
      "Qi Yi",
      "Huiwen Dong",
      "Jian Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10989"
  },
  {
    "id": "arXiv:2106.10994",
    "title": "BernNet: Learning Arbitrary Graph Spectral Filters via Bernstein  Approximation",
    "abstract": "Many representative graph neural networks, $e.g.$, GPR-GNN and ChebyNet,\napproximate graph convolutions with graph spectral filters. However, existing\nwork either applies predefined filter weights or learns them without necessary\nconstraints, which may lead to oversimplified or ill-posed filters. To overcome\nthese issues, we propose $\\textit{BernNet}$, a novel graph neural network with\ntheoretical support that provides a simple but effective scheme for designing\nand learning arbitrary graph spectral filters. In particular, for any filter\nover the normalized Laplacian spectrum of a graph, our BernNet estimates it by\nan order-$K$ Bernstein polynomial approximation and designs its spectral\nproperty by setting the coefficients of the Bernstein basis. Moreover, we can\nlearn the coefficients (and the corresponding filter weights) based on observed\ngraphs and their associated signals and thus achieve the BernNet specialized\nfor the data. Our experiments demonstrate that BernNet can learn arbitrary\nspectral filters, including complicated band-rejection and comb filters, and it\nachieves superior performance in real-world graph modeling tasks.",
    "descriptor": "\nComments: 14 pages, 31 figures\n",
    "authors": [
      "Mingguo He",
      "Zhewei Wei",
      "Zengfeng Huang",
      "Hongteng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10994"
  },
  {
    "id": "arXiv:2106.10996",
    "title": "Delving into the pixels of adversarial samples",
    "abstract": "Despite extensive research into adversarial attacks, we do not know how\nadversarial attacks affect image pixels. Knowing how image pixels are affected\nby adversarial attacks has the potential to lead us to better adversarial\ndefenses. Motivated by instances that we find where strong attacks do not\ntransfer, we delve into adversarial examples at pixel level to scrutinize how\nadversarial attacks affect image pixel values. We consider several ImageNet\narchitectures, InceptionV3, VGG19 and ResNet50, as well as several strong\nattacks. We find that attacks can have different effects at pixel level\ndepending on classifier architecture. In particular, input pre-processing plays\na previously overlooked role in the effect that attacks have on pixels. Based\non the insights of pixel-level examination, we find new ways to detect some of\nthe strongest current attacks.",
    "descriptor": "",
    "authors": [
      "Blerta Lindqvist"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10996"
  },
  {
    "id": "arXiv:2106.11000",
    "title": "A Comparative Study of Online Disinformation and Offline Protests",
    "abstract": "In early 2021 the United States Capitol in Washington was stormed during a\nriot and violent attack. Although the storming was merely an instance in a long\nsequence of events, it provided a testimony for many observers who had claimed\nthat online actions, including the propagation of disinformation, have offline\nconsequences. Soon after, a number of papers have been published about the\nrelation between online disinformation and offline violence, among other\nrelated relations. Hitherto, the effects upon political protests have been\nunexplored. This paper thus evaluates such effects with a time series\ncross-sectional sample of 125 countries in a period between 2000 and 2019. The\nresults are mixed. Based on Bayesian multi-level regression modeling, (i) there\nindeed is an effect between online disinformation and offline protests, but the\neffect is partially meditated by political polarization. The results are\nclearer in a sample of countries belonging to the European Economic Area. With\nthis sample, (ii) offline protest counts increase from online disinformation\ndisseminated by domestic governments, political parties, and politicians as\nwell as by foreign governments. Furthermore, (iii) Internet shutdowns and\ngovernmental monitoring of social media tend to decrease the counts. With these\nresults, the paper contributes to the blossoming disinformation research by\nmodeling the impact of disinformation upon offline phenomenon. The contribution\nis important due to the various policy measures planned or already enacted.",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Jukka Ruohonen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11000"
  },
  {
    "id": "arXiv:2106.11003",
    "title": "Stochastic Model for Sunk Cost Bias",
    "abstract": "We present a novel model for capturing the behavior of an agent exhibiting\nsunk-cost bias in a stochastic environment. Agents exhibiting sunk-cost bias\ntake into account the effort they have already spent on an endeavor when they\nevaluate whether to continue or abandon it. We model planning tasks in which an\nagent with this type of bias tries to reach a designated goal. Our model\nstructures this problem as a type of Markov decision process: loosely speaking,\nthe agent traverses a directed acyclic graph with probabilistic transitions,\npaying costs for its actions as it tries to reach a target node containing a\nspecified reward. The agent's sunk cost bias is modeled by a cost that it\nincurs for abandoning the traversal: if the agent decides to stop traversing\nthe graph, it incurs a cost of $\\lambda \\cdot C_{sunk}$, where ${\\lambda \\geq\n0}$ is a parameter that captures the extent of the bias and $C_{sunk}$ is the\nsum of costs already invested.\nWe analyze the behavior of two types of agents: naive agents that are unaware\nof their bias, and sophisticated agents that are aware of it. Since optimal\n(bias-free) behavior in this problem can involve abandoning the traversal\nbefore reaching the goal, the bias exhibited by these types of agents can\nresult in sub-optimal behavior by shifting their decisions about abandonment.\nWe show that in contrast to optimal agents, it is computationally hard to\ncompute the optimal policy for a sophisticated agent. Our main results quantify\nthe loss exhibited by these two types of agents with respect to an optimal\nagent. We present both general and topology-specific bounds.",
    "descriptor": "\nComments: To appear in the 2021 Conference on Uncertainty in Artificial Intelligence (UAI'21)\n",
    "authors": [
      "Jon Kleinberg",
      "Sigal Oren",
      "Manish Raghavan",
      "Nadav Sklar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.11003"
  },
  {
    "id": "arXiv:2106.11007",
    "title": "On the Capacity-Achieving Input of Channels with Phase Quantization",
    "abstract": "Several information-theoretic studies on channels with output quantization\nhave identified the capacity-achieving input distributions for different fading\nchannels with 1-bit in-phase and quadrature (I/Q) output quantization. But can\nanalytical results on the capacity-achieving input also be obtained for\nmulti-bit quantization? We answer the question in the affirmative by\nconsidering multi-bit phase quantization. We first consider a complex Gaussian\nchannel with $b$-bit phase-quantized output and prove that the\ncapacity-achieving distribution is a rotated $2^b$-phase shift keying (PSK).\nThe analysis is then extended to multiple fading scenarios. We show that the\noptimality of rotated $2^b$-PSK continues to hold under noncoherent fast fading\nRician channels with $b$-bit phase quantization when line-of-sight (LoS) is\npresent. When channel state information (CSI) is available at the receiver, we\nidentify $\\frac{2\\pi}{2^b}$-symmetry and constant amplitude as the necessary\nand sufficient conditions for the ergodic capacity-achieving input\ndistribution; which a $2^b$-PSK satisfies. Finally, an optimum power control\nscheme is presented which achieves ergodic capacity when CSI is also available\nat the transmitter.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Information Theory\n",
    "authors": [
      "Neil Irwin Bernardo",
      "Jingge Zhu",
      "Jamie Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11007"
  },
  {
    "id": "arXiv:2106.11008",
    "title": "Wheelchair automation by a hybrid BCI system using SSVEP and eye blinks",
    "abstract": "This work proposes a hybrid Brain Computer Interface system for the\nautomation of a wheelchair for the disabled. Herein a working prototype of a\nBCI-based wheelchair is detailed that can navigate inside a typical home\nenvironment with minimum structural modification and without any visual\nobstruction and discomfort to the user. The prototype is based on a combined\nmechanism of steady-state visually evoked potential and eye blinks. To elicit\nSSVEP, LEDs flickering at 13Hz and 15Hz were used to select the left and right\ndirection, respectively, and EEG data was recorded. In addition, the occurrence\nof three continuous blinks was used as an indicator for stopping an ongoing\naction. The wavelet packet denoising method was applied, followed by feature\nextraction methods such as Wavelet Packet Decomposition and Canonical\nCorrelation Analysis over narrowband reconstructed EEG signals. Bayesian\noptimization was used to obtain 5 fold cross-validations to optimize the\nhyperparameters of the Support Vector Machine. The resulting new model was\ntested and the average cross-validation accuracy 89.65% + 6.6% (SD) and testing\naccuracy 83.53% + 8.59% (SD) were obtained. The wheelchair was controlled by\nRaspberryPi through WiFi. The developed prototype demonstrated an average of\n86.97% success rate for all trials with 4.015s for each command execution. The\nprototype can be used efficiently in a home environment without causing any\ndiscomfort to the user.",
    "descriptor": "",
    "authors": [
      "Lizy Kanungo",
      "Nikhil Garg",
      "Anish Bhobe",
      "Smit Rajguru",
      "Veeky Baths"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11008"
  },
  {
    "id": "arXiv:2106.11010",
    "title": "Three-body problem -- from Newton to supercomputer plus machine learning",
    "abstract": "The famous three-body problem can be traced back to Newton in 1687, but quite\nfew families of periodic orbits were found in 300 years thereafter. As proved\nby Poincar\\`{e}, the first integral does not exist for three-body systems,\nwhich implies that numerical approach had to be used in general. In this paper,\nwe propose an effective approach and roadmap to numerically gain planar\nperiodic orbits of three-body systems with arbitrary masses by means of machine\nlearning based on an artificial neural network (ANN) model. Given any a known\nperiodic orbit as a starting point, this approach can provide more and more\nperiodic orbits (of the same family name) with variable masses, while the mass\ndomain having periodic orbits becomes larger and larger, and the ANN model\nbecomes wiser and wiser. Finally we have an ANN model trained by means of all\nobtained periodic orbits of the same family, which provides a convenient way to\ngive accurate enough predictions of periodic orbits with arbitrary masses for\nphysicists and astronomers. It suggests that the high-performance computer and\nartificial intelligence (including machine learning) should be the key to gain\nperiodic orbits of the famous three-body problem.",
    "descriptor": "\nComments: 31 pages, 6 figures, 2 tables, this https URL\n",
    "authors": [
      "Shijun Liao",
      "Xiaoming Li",
      "Yu Yang"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.11010"
  },
  {
    "id": "arXiv:2106.11013",
    "title": "Interventional Video Grounding with Dual Contrastive Learning",
    "abstract": "Video grounding aims to localize a moment from an untrimmed video for a given\ntextual query. Existing approaches focus more on the alignment of visual and\nlanguage stimuli with various likelihood-based matching or regression\nstrategies, i.e., P(Y|X). Consequently, these models may suffer from spurious\ncorrelations between the language and video features due to the selection bias\nof the dataset. 1) To uncover the causality behind the model and data, we first\npropose a novel paradigm from the perspective of the causal inference, i.e.,\ninterventional video grounding (IVG) that leverages backdoor adjustment to\ndeconfound the selection bias based on structured causal model (SCM) and\ndo-calculus P(Y|do(X)). Then, we present a simple yet effective method to\napproximate the unobserved confounder as it cannot be directly sampled from the\ndataset. 2) Meanwhile, we introduce a dual contrastive learning approach (DCL)\nto better align the text and video by maximizing the mutual information (MI)\nbetween query and video clips, and the MI between start/end frames of a target\nmoment and the others within a video to learn more informative visual\nrepresentations. Experiments on three standard benchmarks show the\neffectiveness of our approaches.",
    "descriptor": "\nComments: Accepted in CVPR 2021\n",
    "authors": [
      "Guoshun Nan",
      "Rui Qiao",
      "Yao Xiao",
      "Jun Liu",
      "Sicong Leng",
      "Hao Zhang",
      "Wei Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11013"
  },
  {
    "id": "arXiv:2106.11018",
    "title": "Large deviations principles of sample paths and invariant measures of  numerical methods for parabolic SPDEs",
    "abstract": "For parabolic stochastic partial differential equations (SPDEs), we show that\nthe numerical methods, including the spatial spectral Galerkin method and\nfurther the full discretization via the temporal accelerated exponential Euler\nmethod, satisfy the uniform sample path large deviations. Combining the\nexponential tail estimate of invariant measures, we establish the large\ndeviations principles (LDPs) of invariant measures of these numerical methods.\nBased on the error estimate between the rate function of the considered\nnumerical methods and that of the original equation, we prove that these\nnumerical methods can weakly asymptotically preserve the LDPs of sample paths\nand invariant measures of the original equation. This work provides an approach\nto proving the weakly asymptotical preservation for the above two LDPs for\nSPDEs with small noise via numerical methods, by means of the minimization\nsequences.",
    "descriptor": "",
    "authors": [
      "Chuchu Chen",
      "Ziheng Chen",
      "Jialin Hong",
      "Diancong Jin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11018"
  },
  {
    "id": "arXiv:2106.11021",
    "title": "Defending IEEE Software Standards in Federal Criminal Court",
    "abstract": "IEEE's 1012 Standard for independent software and hardware verification and\nvalidation (IV&V) is under attack in U.S. federal criminal court. As software\nspreads through the criminal legal system, scientists, engineers, and IEEE have\nan essential role in ensuring courts understand and respect IEEE 1012 and IV&V.\nIf scientists, engineers, and IEEE do not engage, courts will continue to allow\nunreliable scientific evidence to deprive people of their life and liberty.",
    "descriptor": "\nComments: 13 pages, 0 figures, 1 table\n",
    "authors": [
      "Marc Canellas"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11021"
  },
  {
    "id": "arXiv:2106.11022",
    "title": "Hard Choices in Artificial Intelligence",
    "abstract": "As AI systems are integrated into high stakes social domains, researchers now\nexamine how to design and operate them in a safe and ethical manner. However,\nthe criteria for identifying and diagnosing safety risks in complex social\ncontexts remain unclear and contested. In this paper, we examine the vagueness\nin debates about the safety and ethical behavior of AI systems. We show how\nthis vagueness cannot be resolved through mathematical formalism alone, instead\nrequiring deliberation about the politics of development as well as the context\nof deployment. Drawing from a new sociotechnical lexicon, we redefine vagueness\nin terms of distinct design challenges at key stages in AI system development.\nThe resulting framework of Hard Choices in Artificial Intelligence (HCAI)\nempowers developers by 1) identifying points of overlap between design\ndecisions and major sociotechnical challenges; 2) motivating the creation of\nstakeholder feedback channels so that safety issues can be exhaustively\naddressed. As such, HCAI contributes to a timely debate about the status of AI\ndevelopment in democratic societies, arguing that deliberation should be the\ngoal of AI Safety, not just the procedure by which it is ensured.",
    "descriptor": "\nComments: Pre-print. Shorter versions published at Neurips 2019 Workshop on AI for Social Good and Conference on AI, Ethics and Society 2020\n",
    "authors": [
      "Roel Dobbe",
      "Thomas Krendl Gilbert",
      "Yonatan Mintz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.11022"
  },
  {
    "id": "arXiv:2106.11023",
    "title": "A Contribution to COVID-19 Prevention through Crowd Collaboration using  Conversational AI & Social Platforms",
    "abstract": "COVID-19 Prevention, which combines the soft approaches and best practices\nfor public health safety, is the only recommended solution from the health\nscience and management society side considering the pandemic era. In an attempt\nto evaluate the validity of such claims in a conflict and COVID-19-affected\ncountry like Afghanistan, we conducted a large-scale digital social experiment\nusing conversational AI and social platforms from an info-epidemiology and an\ninfoveillance perspective. This served as a means to uncover an underling\ntruth, give large-scale facilitation support, extend the soft impact of\ndiscussion to multiple sites, collect, diverge, converge and evaluate a large\namount of opinions and concerns from health experts, patients and local people,\ndeliberate on the data collected and explore collective prevention approaches\nof COVID-19. Finally, this paper shows that deciding a prevention measure that\nmaximizes the probability of finding the ground truth is intrinsically\ndifficult without utilizing the support of an AI-enabled discussion systems.",
    "descriptor": "\nComments: To appear as a workshop paper at AI4SG 2020. 6 pages, 4 figures, 1 table\n",
    "authors": [
      "Jawad Haqbeen",
      "Takayuki Ito",
      "Sofia Sahab",
      "Rafik Hadfi",
      "Shun Okuhara",
      "Nasim Saba",
      "Murataza Hofaini",
      "Umar Baregzai"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.11023"
  },
  {
    "id": "arXiv:2106.11025",
    "title": "Come back when you are charged! Self-Organized Charging for Electric  Vehicles",
    "abstract": "Dwindling nonrenewable fuel reserves, progressing severe environmental\npollution, and accelerating climate change require society to reevaluate\nexisting transportation concepts. While electric vehicles (EVs) have become\nmore popular and slowly gain widespread adoption, the corresponding battery\ncharging infrastructures still limits EVs' use in our everyday life. This is\nespecially true for EV owners that do not have the option to operate charging\nhardware, such as wall boxes, at their premises. Charging an EV without an\nat-home wall box is time-consuming since the owner has to drive to the charger,\ncharge the vehicle while waiting nearby, and finally drive back home. Thus, a\nconvenient and easy-to-use solution is required to overcome the issue and\nincentivize EVs for daily commuters. Therefore, we propose an ecosystem and a\nservice platform for (semi-)autonomous electric vehicles that allow them to\nutilize their \"free\"-time, e.g., at night, to access public and private\ncharging infrastructure, charge their batteries, and get back home before the\nowner needs the car again. To do so, we utilize the concept of the\nMachine-to-Everything Economy (M2X Economy) and outline a decentralized\necosystem for smart machines that transact, interact and collaborate via\nblockchain-based smart contracts to enable a convenient battery charging\nmarketplace for (semi-)autonomous EVs.",
    "descriptor": "",
    "authors": [
      "Benjamin Leiding"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11025"
  },
  {
    "id": "arXiv:2106.11026",
    "title": "An interpretable prediction model for longitudinal dispersion  coefficient in natural streams based on evolutionary symbolic regression  network",
    "abstract": "A better understanding of dispersion in natural streams requires knowledge of\nlongitudinal dispersion coefficient(LDC). Various methods have been proposed\nfor predictions of LDC. Those studies can be grouped into three types:\nanalytical, statistical and ML-driven researches(Implicit and explicit).\nHowever, a comprehensive evaluation of them is still lacking. In this paper, we\nfirst present an in-depth analysis of those methods and find out their defects.\nThis is carried out on an extensive database composed of 660 samples of\nhydraulic and channel properties worldwide. The reliability and\nrepresentativeness of utilized data are enhanced through the deployment of the\nSubset Selection of Maximum Dissimilarity(SSMD) for testing set selection and\nthe Inter Quartile Range(IQR) for removal of the outlier. The evaluation\nreveals the rank of those methods as: ML-driven method > the statistical method\n> the analytical method. Whereas implicit ML-driven methods are black-boxes in\nnature, explicit ML-driven methods have more potential in prediction of LDC.\nBesides, overfitting is a universal problem in existing models. Those models\nalso suffer from a fixed parameter combination. To establish an interpretable\nmodel for LDC prediction with higher performance, we then design a novel\nsymbolic regression method called evolutionary symbolic regression\nnetwork(ESRN). It is a combination of genetic algorithms and neural networks.\nStrategies are introduced to avoid overfitting and explore more parameter\ncombinations. Results show that the ESRN model has superiorities over other\nexisting symbolic models in performance. The proposed model is suitable for\npractical engineering problems due to its advantage in low requirement of\nparameters (only w and U* are required). It can provide convincing solutions\nfor situations where the field test cannot be carried out or limited field\ninformation can be obtained.",
    "descriptor": "\nComments: Due to the limitation \"The abstract field cannot be longer than 1,920 characters\", the abstract here is shorter than that in the PDF file Subjects\n",
    "authors": [
      "Yifeng Zhao",
      "Zicheng Liu",
      "Pei Zhang",
      "Stan Z. Li",
      "S.A. Galindo-Torres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.11026"
  },
  {
    "id": "arXiv:2106.11027",
    "title": "Simulation-based Algorithm for Determining Best Package Delivery  Alternatives under Three Criteria: Time, Cost and Sustainability",
    "abstract": "With the significant rise in demand for same-day instant deliveries, several\ncourier services are exploring alternatives to transport packages in a cost-\nand time-effective, as well as, sustainable manner. Motivated by a real-life\ncase study, this paper focuses on developing a simulation algorithm that\nassists same-day package delivery companies to serve customers instantly. The\nproposed recommender system provides the best solution with respect to three\ncriteria: cost, time, and sustainability, considering the variation in travel\ntime and cost parameters. The decision support tool provides recommendations on\nthe best alternative for transporting products based on factors, such as source\nand destination locations, time of the day, package weight, and volume. Besides\nconsidering existing new technologies like electric-assisted cargo bikes, we\nalso analyze the impact of emerging methods of deliveries, such as robots and\nair taxis. Finally, this paper also considers the best delivery alternative\nduring the presence of a pandemic, such as COVID-19. For the purpose of\nillustrating our approach, we consider the delivery options in New York City.\nWe believe that the proposed tool is the first to provide solutions to courier\ncompanies considering evolving modes of transportation and under logistics\ndisruptions due to pandemic.\nKeywords: Instant package delivery; Courier services; Simulation algorithm;\nRecommender system; Emerging technologies; COVID-19 pandemic.",
    "descriptor": "",
    "authors": [
      "Suchithra Rajendran",
      "Aidan Harper"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.11027"
  },
  {
    "id": "arXiv:2106.11028",
    "title": "Neural Controlled Differential Equations for Online Prediction Tasks",
    "abstract": "Neural controlled differential equations (Neural CDEs) are a continuous-time\nextension of recurrent neural networks (RNNs), achieving state-of-the-art\n(SOTA) performance at modelling functions of irregular time series. In order to\ninterpret discrete data in continuous time, current implementations rely on\nnon-causal interpolations of the data. This is fine when the whole time series\nis observed in advance, but means that Neural CDEs are not suitable for use in\n\\textit{online prediction tasks}, where predictions need to be made in\nreal-time: a major use case for recurrent networks. Here, we show how this\nlimitation may be rectified. First, we identify several theoretical conditions\nthat interpolation schemes for Neural CDEs should satisfy, such as boundedness\nand uniqueness. Second, we use these to motivate the introduction of new\nschemes that address these conditions, offering in particular measurability\n(for online prediction), and smoothness (for speed). Third, we empirically\nbenchmark our online Neural CDE model on three continuous monitoring tasks from\nthe MIMIC-IV medical database: we demonstrate improved performance on all tasks\nagainst ODE benchmarks, and on two of the three tasks against SOTA non-ODE\nbenchmarks.",
    "descriptor": "",
    "authors": [
      "James Morrill",
      "Patrick Kidger",
      "Lingyi Yang",
      "Terry Lyons"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11028"
  },
  {
    "id": "arXiv:2106.11029",
    "title": "Understanding the Dynamics between Vaping and Cannabis Legalization  Using Twitter Opinions",
    "abstract": "Cannabis legalization has been welcomed by many U.S. states but its role in\nescalation from tobacco e-cigarette use to cannabis vaping is unclear.\nMeanwhile, cannabis vaping has been associated with new lung diseases and\nrising adolescent use. To understand the impact of cannabis legalization on\nescalation, we design an observational study to estimate the causal effect of\nrecreational cannabis legalization on the development of pro-cannabis attitude\nfor e-cigarette users. We collect and analyze Twitter data which contains\nopinions about cannabis and JUUL, a very popular e-cigarette brand. We use\nweakly supervised learning for personal tweet filtering and classification for\nstance detection. We discover that recreational cannabis legalization policy\nhas an effect on increased development of pro-cannabis attitudes for users\nalready in favor of e-cigarettes.",
    "descriptor": "\nComments: Published at ICWSM 2021\n",
    "authors": [
      "Shishir Adhikari",
      "Akshay Uppal",
      "Robin Mermelstein",
      "Tanya Berger-Wolf",
      "Elena Zheleva"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.11029"
  },
  {
    "id": "arXiv:2106.11030",
    "title": "BIM, Digital Twin and Cyber-Physical Systems: crossing and blurring  boundaries",
    "abstract": "Digital Twin in construction and the built environment have started to\nattract the attention of researchers and practitioners in recent times. Its\nanticipated value proposition is focussed on its capability of generating new\nunderstanding and insights into an asset at all stages of its life cycle,\nexploiting diverse data sets from a multitude of sources and professions, in\nreal or near real-time. However, there is still a significant debate about the\ndelineation (i.e. communalities and differences) between digital twin and other\nrelated concepts, particularly Building Information Modelling (BIM) and\nCyber-Physical Systems (CPS). To date, this debate has been confined to social\nmedia discussions, insights blogs and position papers. This paper addresses\nthis challenge using a systematic review. The aim is to investigate\ncommunalities and differences between the three concepts, Digital Twin, BIM and\nCPS. The results of this paper are expected to foster the discussion around\nthis theme within construction and the built environment.",
    "descriptor": "",
    "authors": [
      "Dean Douglas",
      "Graham Kelly",
      "Mohamad Kassem"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11030"
  },
  {
    "id": "arXiv:2106.11031",
    "title": "A Graduate Course on E-commerce Information Systems Engineering",
    "abstract": "Interest in developing and deploying E-commerce systems has grown greatly\nover the past few years, leading to a major shortage of qualified developers.\nThis paper describes the development of a graduate course in E-commerce\neducation that has been implemented as part of an Honours degree programme and\na first year Masters offering for a traditional Information Systems programme.\nThe aim of this course is to give graduate students a broad grounding and\nholistic set of skills to enable them to begin successful E-commerce systems\ndevelopment. This paper provides a background and context for this course, an\noverview and discussion of the course content, delivery methods and practical\nfocus, and discusses experience in running and evolving the course over the\npast two years. We hope that our experiences and approaches will be useful for\nothers who are planning similar courses focusing on E-commerce systems\nengineering.",
    "descriptor": "\nComments: Preprint to appear in\n",
    "authors": [
      "John C. Grundy"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2106.11031"
  },
  {
    "id": "arXiv:2106.11032",
    "title": "Proof Blocks: Autogradeable Scaffolding Activities for Learning to Write  Proofs",
    "abstract": "Proof Blocks is a software tool which enables students to write proofs by\ndragging and dropping prewritten proof lines into the correct order. These\nproofs can be graded completely automatically, enabling students to receive\nrapid feedback on how they are doing with their proofs. When constructing a\nproblem, the instructor specifies the dependency graph of the lines of the\nproof, so that any correct arrangement of the lines can receive full credit.\nThis innovation can improve assessment tools by increasing the types of\nquestions we can ask students about proofs, and can give greater access to\nproof knowledge by increasing the amount that students can learn on their own\nwith the help of a computer.",
    "descriptor": "",
    "authors": [
      "Seth Poulsen",
      "Mahesh Viswanathan",
      "Geoffrey L. Herman",
      "Matthew West"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.11032"
  },
  {
    "id": "arXiv:2106.11033",
    "title": "Gr\u00f6\u00dfe als Erfolgsgarant? Zur Bedeutung der Organisationstruktur  f\u00fcr die Einwerbung von Drittmitteln der Deutschen Forschungsgemeinschaft",
    "abstract": "Research funding through third-party financing is of considerable importance\nfor the German science system. The funds of the German Research Foundation\n(DFG) serve as the central focus due to the high reputation of the foundation.\nHowever, it has not been clarified yet to what extent the chances of\nsuccessfully acquiring these funds depend on the structure of the university as\nan institution. The present study analyses DFG funding in the context of\nuniversity research and examines the role of organisational conditions in the\nacquisition of funding. Several factors, such as size of the institution,\nequipment, and teaching activities, are analysed. The empirical study focuses\non four subjects and investigates the correlation between funding success and\nconditional factors using a Bayesian approach. Results reveal the considerable\nrelevance of the factors size as well as provision of academic and non-academic\npersonnel. This implies that the organisational conditions are to be taken into\naccount while evaluating third-party financing success.",
    "descriptor": "\nComments: in German\n",
    "authors": [
      "Axel Oberschelp",
      "Stephan Stahlschmidt"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.11033"
  },
  {
    "id": "arXiv:2106.11034",
    "title": "Teaching Machine Learning in K-12 Computing Education: Potential and  Pitfalls",
    "abstract": "Over the past decades, numerous practical applications of machine learning\ntechniques have shown the potential of data-driven approaches in a large number\nof computing fields. Machine learning is increasingly included in computing\ncurricula in higher education, and a quickly growing number of initiatives are\nexpanding it in K-12 computing education, too. As machine learning enters K-12\ncomputing education, understanding how intuition and agency in the context of\nsuch systems is developed becomes a key research area. But as schools and\nteachers are already struggling with integrating traditional computational\nthinking and traditional artificial intelligence into school curricula,\nunderstanding the challenges behind teaching machine learning in K-12 is an\neven more daunting challenge for computing education research. Despite the\ncentral position of machine learning in the field of modern computing, the\ncomputing education research body of literature contains remarkably few studies\nof how people learn to train, test, improve, and deploy machine learning\nsystems. This is especially true of the K-12 curriculum space. This article\ncharts the emerging trajectories in educational practice, theory, and\ntechnology related to teaching machine learning in K-12 education. The article\nsituates the existing work in the context of computing education in general,\nand describes some differences that K-12 computing educators should take into\naccount when facing this challenge. The article focuses on key aspects of the\nparadigm shift that will be required in order to successfully integrate machine\nlearning into the broader K-12 computing curricula. A crucial step is\nabandoning the belief that rule-based \"traditional\" programming is a central\naspect and building block in developing next generation computational thinking.",
    "descriptor": "",
    "authors": [
      "Matti Tedre",
      "Tapani Toivonen",
      "Juho Kaihila",
      "Henriikka Vartiainen",
      "Teemu Valtonen",
      "Ilkka Jormanainen",
      "Arnold Pears"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11034"
  },
  {
    "id": "arXiv:2106.11035",
    "title": "A Meta-model for Process Failure Mode and Effects Analysis (PFMEA)",
    "abstract": "Short product lifecycles and a high variety of products force industrial\nmanufacturing processes to change frequently. Due to the manual approach of\nmany quality analysis techniques, they can significantly slow down adaption\nprocesses of production systems or make production unprofitable. Therefore,\nautomating them can be a key technology for keeping pace with market demand of\nthe future. The methodology presented here aims at a meta-model supporting\nautomation for PFMEA. The method differentiates product requirements,\nproduction steps and quality measures in such a way, that complex quality\nrequirements can be addressed in any instance of a factory using a common\nmeta-modeling language.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.14817\n",
    "authors": [
      "Kai Hoefig",
      "Cornel Klein",
      "Stefan Rothbauer",
      "Marc Zeller",
      "Marian Vorderer",
      "Chee Hung Koo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11035"
  },
  {
    "id": "arXiv:2106.11036",
    "title": "Know Your Model (KYM): Increasing Trust in AI and Machine Learning",
    "abstract": "The widespread utilization of AI systems has drawn attention to the potential\nimpacts of such systems on society. Of particular concern are the consequences\nthat prediction errors may have on real-world scenarios, and the trust humanity\nplaces in AI systems. It is necessary to understand how we can evaluate\ntrustworthiness in AI and how individuals and entities alike can develop\ntrustworthy AI systems. In this paper, we analyze each element of\ntrustworthiness and provide a set of 20 guidelines that can be leveraged to\nensure optimal AI functionality while taking into account the greater ethical,\ntechnical, and practical impacts to humanity. Moreover, the guidelines help\nensure that trustworthiness is provable and can be demonstrated, they are\nimplementation agnostic, and they can be applied to any AI system in any\nsector.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Mary Roszel",
      "Robert Norvill",
      "Jean Hilger",
      "Radu State"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11036"
  },
  {
    "id": "arXiv:2106.11037",
    "title": "One Million Scenes for Autonomous Driving: ONCE Dataset",
    "abstract": "Current perception models in autonomous driving have become notorious for\ngreatly relying on a mass of annotated data to cover unseen cases and address\nthe long-tail problem. On the other hand, learning from unlabeled large-scale\ncollected data and incrementally self-training powerful recognition models have\nreceived increasing attention and may become the solutions of next-generation\nindustry-level powerful and robust perception models in autonomous driving.\nHowever, the research community generally suffered from data inadequacy of\nthose essential real-world scene data, which hampers the future exploration of\nfully/semi/self-supervised methods for 3D perception. In this paper, we\nintroduce the ONCE (One millioN sCenEs) dataset for 3D object detection in the\nautonomous driving scenario. The ONCE dataset consists of 1 million LiDAR\nscenes and 7 million corresponding camera images. The data is selected from 144\ndriving hours, which is 20x longer than the largest 3D autonomous driving\ndataset available (e.g. nuScenes and Waymo), and it is collected across a range\nof different areas, periods and weather conditions. To facilitate future\nresearch on exploiting unlabeled data for 3D detection, we additionally provide\na benchmark in which we reproduce and evaluate a variety of self-supervised and\nsemi-supervised methods on the ONCE dataset. We conduct extensive analyses on\nthose methods and provide valuable observations on their performance related to\nthe scale of used data. Data, code, and more information are available at\nhttps://once-for-auto-driving.github.io/index.html.",
    "descriptor": "",
    "authors": [
      "Jiageng Mao",
      "Minzhe Niu",
      "Chenhan Jiang",
      "Hanxue Liang",
      "Xiaodan Liang",
      "Yamin Li",
      "Chaoqiang Ye",
      "Wei Zhang",
      "Zhenguo Li",
      "Jie Yu",
      "Hang Xu",
      "Chunjing Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11037"
  },
  {
    "id": "arXiv:2106.11039",
    "title": "Institutionalising Ethics in AI through Broader Impact Requirements",
    "abstract": "Turning principles into practice is one of the most pressing challenges of\nartificial intelligence (AI) governance. In this article, we reflect on a novel\ngovernance initiative by one of the world's largest AI conferences. In 2020,\nthe Conference on Neural Information Processing Systems (NeurIPS) introduced a\nrequirement for submitting authors to include a statement on the broader\nsocietal impacts of their research. Drawing insights from similar governance\ninitiatives, including institutional review boards (IRBs) and impact\nrequirements for funding applications, we investigate the risks, challenges and\npotential benefits of such an initiative. Among the challenges, we list a lack\nof recognised best practice and procedural transparency, researcher opportunity\ncosts, institutional and social pressures, cognitive biases, and the inherently\ndifficult nature of the task. The potential benefits, on the other hand,\ninclude improved anticipation and identification of impacts, better\ncommunication with policy and governance experts, and a general strengthening\nof the norms around responsible research. To maximise the chance of success, we\nrecommend measures to increase transparency, improve guidance, create\nincentives to engage earnestly with the process, and facilitate public\ndeliberation on the requirement's merits and future. Perhaps the most important\ncontribution from this analysis are the insights we can gain regarding\neffective community-based governance and the role and responsibility of the AI\nresearch community more broadly.",
    "descriptor": "",
    "authors": [
      "Carina Prunkl",
      "Carolyn Ashurst",
      "Markus Anderljung",
      "Helena Webb",
      "Jan Leike",
      "Allan Dafoe"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11039"
  },
  {
    "id": "arXiv:2106.11040",
    "title": "An exploratory study of skill requirements for social media positions: A  content analysis of job advertisements",
    "abstract": "There has been considerable debate about the comparative advantages of\nmarketing education emphasizing theoretical knowledge and applied skills. The\ncurrent study investigated the skills necessary for entry-level marketing\npositions, specifically that of Social Media Manager (SMMgr) and Social Media\nMarketer (SMMkt). Data was collected from Indeed.com using a web crawler to\nextract job postings for SMMgr and SMMkt. A total of 766 and 654 entry-level\njobs for SMMgr and SMMkt, respectively, across the entire United States, was\ncollected. Independent raters separately analyzed the data for keywords and\ncategories. Findings suggest that the most desired skills are occupational\ndigital marketing skills. Other relevant skill categories included\ncommunication, employee attributes, problem-solving, and information technology\nskills. This study extends the current literature by highlighting the desired\nskills prevalent across the social media industry. The findings also have\nrelevance in designing the marketing education curriculum, specifically in\nisolating core skills that could be integrated into the marketing courses.",
    "descriptor": "\nComments: This is the authors original manuscript (preprint) of an article that has been accepted for publication in a future issue of The Journal of Social Media in Society. Content may change prior to final publication\n",
    "authors": [
      "Amit Verma",
      "Phillip Frank",
      "Kamal Lamsal"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11040"
  },
  {
    "id": "arXiv:2106.11041",
    "title": "Sampling of Shape Expressions",
    "abstract": "Cyber-physical systems (CPS) are increasingly becoming driven by data, using\nmultiple types of sensors to capture huge amounts of data. Extraction and\ncharacterization of useful information from big streams of data is a\nchallenging problem. Shape expressions facilitate formal specification of rich\ntemporal patterns encountered in time series as well as in behaviors of CPS. In\nthis paper, we introduce a method for systematically sampling shape\nexpressions. The proposed approach combines methods for uniform sampling of\nautomata (for exploring qualitative shapes) with hit-and-run Monte Carlo\nsampling procedures (for exploring multi-dimensional parameter spaces defined\nby sets of possibly non-linear constraints). We study and implement several\npossible solutions and evaluate them in the context of visualization and\ntesting applications.",
    "descriptor": "",
    "authors": [
      "Nicolas Basset",
      "Thao Dang",
      "Felix Gigler",
      "Cristinel Mateis",
      "Dejan Nickovic"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.11041"
  },
  {
    "id": "arXiv:2106.11042",
    "title": "A Taxonomy to Unify Fault Tolerance Regimes for Automotive Systems:  Defining Fail-Operational, Fail-Degraded, and Fail-Safe",
    "abstract": "This paper presents a taxonomy that allows to define the fault tolerance\nregimes \"fail-operational\", \"fail-degraded\", and \"fail-safe\" in the context of\nautomotive systems. Fault tolerance regimes such as these are widely used in\nrecent publications related to automated driving, yet without definitions,\nwhich largely holds true for automotive safety standards, too. Moreover, we\nshow that fault tolerance regimes defined in scientific publications related to\nthe automotive domain are partially ambiguous as well as taxonomically\nunrelated. The presented taxonomy is based on terminology stemming from ISO\n26262 as well as from systems engineering and uses four criteria to distinguish\nfault tolerance regimes. In addition to \"fail-operational\", \"fail-degraded\",\nand \"fail-safe\", the core terminology consists of \"operational\" and\n\"fail-unsafe\". These terms are supported by definitions of \"available\nperformance\", \"nominal performance\", and a novel definition of the \"safe\nstate\". For verification, we show by means of two examples from the automotive\ndomain that the taxonomy can be applied to hierarchical systems of different\ncomplexity. Finally, we relate the definitions to the recently published\ntechnical report ISO/TR 4804, which also presents definitions of fault\ntolerance regimes.",
    "descriptor": "\nComments: 12 pages, 3 figures, 1 table, submitted to IEEE Transactions on Intelligent Vehicles\n",
    "authors": [
      "Torben Stolte",
      "Stefan Ackermann",
      "Robert Graubohm",
      "Inga Jatzkowski",
      "Hermann Winner",
      "Markus Maurer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.11042"
  },
  {
    "id": "arXiv:2106.11048",
    "title": "CataNet: Predicting remaining cataract surgery duration",
    "abstract": "Cataract surgery is a sight saving surgery that is performed over 10 million\ntimes each year around the world. With such a large demand, the ability to\norganize surgical wards and operating rooms efficiently is critical to delivery\nthis therapy in routine clinical care. In this context, estimating the\nremaining surgical duration (RSD) during procedures is one way to help\nstreamline patient throughput and workflows. To this end, we propose CataNet, a\nmethod for cataract surgeries that predicts in real time the RSD jointly with\ntwo influential elements: the surgeon's experience, and the current phase of\nthe surgery. We compare CataNet to state-of-the-art RSD estimation methods,\nshowing that it outperforms them even when phase and experience are not\nconsidered. We investigate this improvement and show that a significant\ncontributor is the way we integrate the elapsed time into CataNet's feature\nextractor.",
    "descriptor": "\nComments: Accepted at MICCAI 2021\n",
    "authors": [
      "Andr\u00e9s Marafioti",
      "Michel Hayoz",
      "Mathias Gallardo",
      "Pablo M\u00e1rquez Neila",
      "Sebastian Wolf",
      "Martin Zinkernagel",
      "Raphael Sznitman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11048"
  },
  {
    "id": "arXiv:2106.11050",
    "title": "A photonic complex perceptron for ultrafast data processing",
    "abstract": "In photonic neural network a key building block is the perceptron. Here, we\ndescribe and demonstrate a complex-valued photonic perceptron that combines\ntime and space multiplexing in a fully passive silicon photonics integrated\ncircuit. An input time dependent bit sequence is broadcasted into a few delay\nlines where the relative phases are trained by particle swarm algorithms toward\nthe given task. Since only the phases of the propagating optical modes are\ntrained, signal attenuation in the perceptron due to amplitude modulation is\navoided. The perceptron performs binary pattern recognition and few bit delayed\nXOR operations up to 16 Gbps (limited by the used electronics) with Bit Error\nRates as low as $10^{-6}$. The perceptron is fully integrated, silicon based,\nscalable, and can be used as a building block in large neural networks.",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Mattia Mancinelli",
      "Davide Bazzanella",
      "Paolo Bettotti",
      "Lorenzo Pavesi"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2106.11050"
  },
  {
    "id": "arXiv:2106.11051",
    "title": "Towards Better Shale Gas Production Forecasting Using Transfer Learning",
    "abstract": "Deep neural networks can generate more accurate shale gas production\nforecasts in counties with a limited number of sample wells by utilizing\ntransfer learning. This paper provides a way of transferring the knowledge\ngained from other deep neural network models trained on adjacent counties into\nthe county of interest. The paper uses data from more than 6000 shale gas wells\nacross 17 counties from Texas Barnett and Pennsylvania Marcellus shale\nformations to test the capabilities of transfer learning. The results reduce\nthe forecasting error between 11% and 47% compared to the widely used Arps\ndecline curve model.",
    "descriptor": "",
    "authors": [
      "Omar S. Alolayan",
      "Samuel J. Raymond",
      "Justin B. Montgomery",
      "John R. Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11051"
  },
  {
    "id": "arXiv:2106.11053",
    "title": "Leveraging Language to Learn Program Abstractions and Search Heuristics",
    "abstract": "Inductive program synthesis, or inferring programs from examples of desired\nbehavior, offers a general paradigm for building interpretable, robust, and\ngeneralizable machine learning systems. Effective program synthesis depends on\ntwo key ingredients: a strong library of functions from which to build\nprograms, and an efficient search strategy for finding programs that solve a\ngiven task. We introduce LAPS (Language for Abstraction and Program Search), a\ntechnique for using natural language annotations to guide joint learning of\nlibraries and neurally-guided search models for synthesis. When integrated into\na state-of-the-art library learning system (DreamCoder), LAPS produces\nhigher-quality libraries and improves search efficiency and generalization on\nthree domains -- string editing, image composition, and abstract reasoning\nabout scenes -- even when no natural language hints are available at test time.",
    "descriptor": "\nComments: appeared in Thirty-eighth International Conference on Machine Learning (ICML 2021)\n",
    "authors": [
      "Catherine Wong",
      "Kevin Ellis",
      "Joshua B. Tenenbaum",
      "Jacob Andreas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11053"
  },
  {
    "id": "arXiv:2106.11054",
    "title": "Visual Probing: Cognitive Framework for Explaining Self-Supervised Image  Representations",
    "abstract": "Recently introduced self-supervised methods for image representation learning\nprovide on par or superior results to their fully supervised competitors, yet\nthe corresponding efforts to explain the self-supervised approaches lag behind.\nMotivated by this observation, we introduce a novel visual probing framework\nfor explaining the self-supervised models by leveraging probing tasks employed\npreviously in natural language processing. The probing tasks require knowledge\nabout semantic relationships between image parts. Hence, we propose a\nsystematic approach to obtain analogs of natural language in vision, such as\nvisual words, context, and taxonomy. Our proposal is grounded in Marr's\ncomputational theory of vision and concerns features like textures, shapes, and\nlines. We show the effectiveness and applicability of those analogs in the\ncontext of explaining self-supervised representations. Our key findings\nemphasize that relations between language and vision can serve as an effective\nyet intuitive tool for discovering how machine learning models work,\nindependently of data modality. Our work opens a plethora of research pathways\ntowards more explainable and transparent AI.",
    "descriptor": "",
    "authors": [
      "Witold Oleszkiewicz",
      "Dominika Basaj",
      "Igor Sieradzki",
      "Micha\u0142 G\u00f3rszczak",
      "Barbara Rychalska",
      "Koryna Lewandowska",
      "Tomasz Trzci\u0144ski",
      "Bartosz Zieli\u0144ski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11054"
  },
  {
    "id": "arXiv:2106.11055",
    "title": "Performance Evaluation of Classification Models for Household Income,  Consumption and Expenditure Data Set",
    "abstract": "Food security is more prominent on the policy agenda today than it has been\nin the past, thanks to recent food shortages at both the regional and global\nlevels as well as renewed promises from major donor countries to combat chronic\nhunger. One field where machine learning can be used is in the classification\nof household food insecurity. In this study, we establish a robust methodology\nto categorize whether or not a household is being food secure and food insecure\nby machine learning algorithms. In this study, we have used ten machine\nlearning algorithms to classify the food security status of the Household.\nGradient Boosting (GB), Random Forest (RF), Extra Tree (ET), Bagging, K-Nearest\nNeighbor (KNN), Decision Tree (DT), Support Vector Machine (SVM), Logistic\nRegression (LR), Ada Boost (AB) and Naive Bayes were the classification\nalgorithms used throughout this study (NB). Then, we perform classification\ntasks from developing data set for household food security status by gathering\ndata from HICE survey data and validating it by Domain Experts. The performance\nof all classifiers has better results for all performance metrics. The\nperformance of the Random Forest and Gradient Boosting models are outstanding\nwith a testing accuracy of 0.9997 and the other classifier such as Bagging,\nDecision tree, Ada Boost, Extra tree, K-nearest neighbor, Logistic Regression,\nSVM and Naive Bayes are scored 0.9996, 0.09996, 0.9994, 0.95675, 0.9415,\n0.8915, 0.7853 and 0.7595, respectively.",
    "descriptor": "",
    "authors": [
      "Mersha Nigus",
      "Dorsewamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11055"
  },
  {
    "id": "arXiv:2106.11056",
    "title": "Paradigm selection for Data Fusion of SAR and Multispectral Sentinel  data applied to Land-Cover Classification",
    "abstract": "Data fusion is a well-known technique, becoming more and more popular in the\nArtificial Intelligence for Earth Observation (AI4EO) domain mainly due to its\nability of reinforcing AI4EO applications by combining multiple data sources\nand thus bringing better results. On the other hand, like other methods for\nsatellite data analysis, data fusion itself is also benefiting and evolving\nthanks to the integration of Artificial Intelligence (AI). In this letter, four\ndata fusion paradigms, based on Convolutional Neural Networks (CNNs), are\nanalyzed and implemented. The goals are to provide a systematic procedure for\nchoosing the best data fusion framework, resulting in the best classification\nresults, once the basic structure for the CNN has been defined, and to help\ninterested researchers in their work when data fusion applied to remote sensing\nis involved. The procedure has been validated for land-cover classification but\nit can be transferred to other cases.",
    "descriptor": "\nComments: This work has been submitted to the IEEE Geoscience and Remote Sensing Letters for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Alessandro Sebastianelli",
      "Maria Pia Del Rosso",
      "Pierre Philippe Mathieu",
      "Silvia Liberata Ullo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.11056"
  },
  {
    "id": "arXiv:2106.11057",
    "title": "QuaPy: A Python-Based Framework for Quantification",
    "abstract": "QuaPy is an open-source framework for performing quantification (a.k.a.\nsupervised prevalence estimation), written in Python. Quantification is the\ntask of training quantifiers via supervised learning, where a quantifier is a\npredictor that estimates the relative frequencies (a.k.a. prevalence values) of\nthe classes of interest in a sample of unlabelled data. While quantification\ncan be trivially performed by applying a standard classifier to each unlabelled\ndata item and counting how many data items have been assigned to each class, it\nhas been shown that this \"classify and count\" method is outperformed by methods\nspecifically designed for quantification. QuaPy provides implementations of a\nnumber of baseline methods and advanced quantification methods, of routines for\nquantification-oriented model selection, of several broadly accepted evaluation\nmeasures, and of robust evaluation protocols routinely used in the field. QuaPy\nalso makes available datasets commonly used for testing quantifiers, and offers\nvisualization tools for facilitating the analysis and interpretation of the\nresults. The software is open-source and publicly available under a BSD-3\nlicence via https://github.com/HLT-ISTI/QuaPy, and can be installed via pip\n(https://pypi.org/project/QuaPy/)",
    "descriptor": "",
    "authors": [
      "Alejandro Moreo",
      "Andrea Esuli",
      "Fabrizio Sebastiani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11057"
  },
  {
    "id": "arXiv:2106.11059",
    "title": "Improving Multi-Modal Learning with Uni-Modal Teachers",
    "abstract": "Learning multi-modal representations is an essential step towards real-world\nrobotic applications, and various multi-modal fusion models have been developed\nfor this purpose. However, we observe that existing models, whose objectives\nare mostly based on joint training, often suffer from learning inferior\nrepresentations of each modality. We name this problem Modality Failure, and\nhypothesize that the imbalance of modalities and the implicit bias of common\nobjectives in fusion method prevent encoders of each modality from sufficient\nfeature learning. To this end, we propose a new multi-modal learning method,\nUni-Modal Teacher, which combines the fusion objective and uni-modal\ndistillation to tackle the modality failure problem. We show that our method\nnot only drastically improves the representation of each modality, but also\nimproves the overall multi-modal task performance. Our method can be\neffectively generalized to most multi-modal fusion approaches. We achieve more\nthan 3% improvement on the VGGSound audio-visual classification task, as well\nas improving performance on the NYU depth V2 RGB-D image segmentation task.",
    "descriptor": "",
    "authors": [
      "Chenzhuang Du",
      "Tingle Li",
      "Yichen Liu",
      "Zixin Wen",
      "Tianyu Hua",
      "Yue Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11059"
  },
  {
    "id": "arXiv:2106.11067",
    "title": "An Urban Population Health Observatory System to Support COVID-19  Pandemic Preparedness, Response, and Management: Design and Development Study",
    "abstract": "Background: COVID-19 is impacting people worldwide and is currently a leading\ncause of death in many countries. This study sought to redefine the Healthy\nPeople 2030 SDoH taxonomy to accommodate the COVID-19 pandemic. Furthermore, we\naim to provide a blueprint and implement a prototype for the Urban Population\nHealth Observatory (UPHO), a web-based platform that integrates classified\ngroup-level SDoH indicators to individual- and aggregate-level population\nhealth data. The process of building the UPHO involves collecting and\nintegrating data from several sources, classifying the collected data into\ndrivers and outcomes, incorporating data science techniques for calculating\nmeasurable indicators from the raw variables, and studying the extent to which\ninterventions are identified or developed to mitigate drivers that lead to the\nundesired outcomes. We generated and classified the indicators of social\ndeterminants of health, which are linked to COVID-19. To display the\nfunctionalities of the UPHO platform, we presented a prototype design to\ndemonstrate its features. We provided a use case scenario for 4 different\nusers. UPHO serves as an apparatus for implementing effective interventions and\ncan be adopted as a global platform for chronic and infectious diseases. The\nUPHO surveillance platform provides a novel approach and novel insights into\nimmediate and long-term health policy responses to the COVID-19 pandemic and\nother future public health crises. The UPHO assists public health organizations\nand policymakers in their efforts in reducing health disparities, achieving\nhealth equity, and improving urban population health.",
    "descriptor": "\nComments: 16 Pages, 7 Figures, 1 Table\n",
    "authors": [
      "Whitney S. Brakefield",
      "Nariman Ammar",
      "Olufunto A. Olusanya",
      "Arash Shaban-Nejad"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11067"
  },
  {
    "id": "arXiv:2106.11071",
    "title": "Making Sense of Learning Log Data",
    "abstract": "Research is constantly engaged in finding more productive and powerful ways\nto support quality learning and teaching. However, although researchers and\ndata scientists try to analyse educational data most transparently and\nresponsibly, the risk of training machine learning algorithms on biased\ndatasets is always around the corner and may lead to misinterpretations of\nstudent behaviour. This may happen in case of partial understanding of how\nlearning log data is generated. Moreover, the pursuit of an ever friendlier\nuser experience moves more and more Learning Management Systems functionality\nfrom the server to the client, but it tends to reduce significant logs as a\nside effect. This paper tries to focus on these issues showing some examples of\nlearning log data extracted from Moodle and some possible misinterpretations\nthat they hide with the aim to open the debate on data understanding and data\nknowledge loss.",
    "descriptor": "\nComments: 14 pages, 2 figures, 7 tables\n",
    "authors": [
      "Daniela Rotelli",
      "Giuseppe Fiorentino",
      "Anna Monreale"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11071"
  },
  {
    "id": "arXiv:2106.11072",
    "title": "Techniques for Symbol Grounding with SATNet",
    "abstract": "Many experts argue that the future of artificial intelligence is limited by\nthe field's ability to integrate symbolic logical reasoning into deep learning\narchitectures. The recently proposed differentiable MAXSAT solver, SATNet, was\na breakthrough in its capacity to integrate with a traditional neural network\nand solve visual reasoning problems. For instance, it can learn the rules of\nSudoku purely from image examples. Despite its success, SATNet was shown to\nsuccumb to a key challenge in neurosymbolic systems known as the Symbol\nGrounding Problem: the inability to map visual inputs to symbolic variables\nwithout explicit supervision (\"label leakage\"). In this work, we present a\nself-supervised pre-training pipeline that enables SATNet to overcome this\nlimitation, thus broadening the class of problems that SATNet architectures can\nsolve to include datasets where no intermediary labels are available at all. We\ndemonstrate that our method allows SATNet to attain full accuracy even with a\nharder problem setup that prevents any label leakage. We additionally introduce\na proofreading method that further improves the performance of SATNet\narchitectures, beating the state-of-the-art on Visual Sudoku.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Sever Topan",
      "David Rolnick",
      "Xujie Si"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11072"
  },
  {
    "id": "arXiv:2106.11075",
    "title": "EML Online Speech Activity Detection for the Fearless Steps Challenge  Phase-III",
    "abstract": "Speech Activity Detection (SAD), locating speech segments within an audio\nrecording, is a main part of most speech technology applications. Robust SAD is\nusually more difficult in noisy conditions with varying signal-to-noise ratios\n(SNR). The Fearless Steps challenge has recently provided such data from the\nNASA Apollo-11 mission for different speech processing tasks including SAD.\nMost audio recordings are degraded by different kinds and levels of noise\nvarying within and between channels. This paper describes the EML online\nalgorithm for the most recent phase of this challenge. The proposed algorithm\ncan be trained both in a supervised and unsupervised manner and assigns speech\nand non-speech labels at runtime approximately every 0.1 sec. The experimental\nresults show a competitive accuracy on both development and evaluation datasets\nwith a real-time factor of about 0.002 using a single CPU machine.",
    "descriptor": "",
    "authors": [
      "Omid Ghahabi",
      "Volker Fischer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.11075"
  },
  {
    "id": "arXiv:2106.11076",
    "title": "Flipping Stance: Social Influence on Bot's and Non Bot's COVID Vaccine  Stance",
    "abstract": "Social influence characterizes the change of opinions in a complex social\nenvironment, incorporating an individual's past stances and the impact of\ninterpersonal influence through the social network influence. In this work, we\nobserve stance changes towards the coronavirus vaccine on Twitter from April\n2020 to May 2021, where 1\\% of the agents exhibit the stance flipping behavior,\nof which 53.7\\% are identified bots. We then propose a novel social influence\nmodel to characterize the change in stance of agents. This model considers an\nagent's and his neighbor's past tweets and the overall network structure\ntowards a stance score. In our experiments, the model achieves 86\\% accuracy.\nIn our analysis, bot agents require lesser social influence to flip stances and\na larger proportion of bots flip.",
    "descriptor": "\nComments: To appear in The Second International MIS2 Workshop: Misinformation and Misbehavior Mining on the Web\n",
    "authors": [
      "Lynnette Hui Xian Ng",
      "Kathleen Carley"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.11076"
  },
  {
    "id": "arXiv:2106.11077",
    "title": "Toward Knowledge Discovery Framework for Data Science Job Market in the  United States",
    "abstract": "The growth of the data science field requires better tools to understand such\na fast-paced growing domain. Moreover, individuals from different backgrounds\nbecame interested in following a career as data scientists. Therefore,\nproviding a quantitative guide for individuals and organizations to understand\nthe skills required in the job market would be crucial. This paper introduces a\nframework to analyze the job market for data science-related jobs within the US\nwhile providing an interface to access insights in this market. The proposed\nframework includes three sub-modules allowing continuous data collection,\ninformation extraction, and a web-based dashboard visualization to investigate\nthe spatial and temporal distribution of data science-related jobs and skills.\nThe result of this work shows important skills for the main branches of data\nscience jobs and attempts to provide a skill-based definition of these data\nscience branches. The current version of this application is deployed on the\nweb and allows individuals and institutes to investigate skills required for\ndata science positions through the industry lens.",
    "descriptor": "",
    "authors": [
      "Mojtaba Heidarysafa",
      "Kamran Kowsari",
      "Masoud Bashiri",
      "Donald E. Brown"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11077"
  },
  {
    "id": "arXiv:2106.11080",
    "title": "Linear Codes Associated to Symmetric Determinantal Varieties: Even Rank  Case",
    "abstract": "We consider linear codes over a finite field $\\mathbb{F}_q$, for odd $q$,\nderived from determinantal varieties, obtained from symmetric matrices of\nbounded ranks. A formula for the weight of a codeword is derived. Using this\nformula, we have computed the minimum distance for the codes corresponding to\nmatrices upperbounded by any fixed, even rank. A conjecture is proposed for the\ncases where the upper bound is odd. At the end of the article, tables for the\nweights of these codes, for spaces of symmetric matrices up to order $5$, are\ngiven.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Peter Beelen",
      "Trygve Johnsen",
      "Prasant Singh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2106.11080"
  },
  {
    "id": "arXiv:2106.11083",
    "title": "Conditional Neural Relational Inference for Interacting Systems",
    "abstract": "In this work, we want to learn to model the dynamics of similar yet distinct\ngroups of interacting objects. These groups follow some common physical laws\nthat exhibit specificities that are captured through some vectorial\ndescription. We develop a model that allows us to do conditional generation\nfrom any such group given its vectorial description. Unlike previous work on\nlearning dynamical systems that can only do trajectory completion and require a\npart of the trajectory dynamics to be provided as input in generation time, we\ndo generation using only the conditioning vector with no access to generation\ntime's trajectories. We evaluate our model in the setting of modeling human\ngait and, in particular pathological human gait.",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Joao A. Candido Ramos",
      "Lionel Blond\u00e9",
      "St\u00e9phane Armand",
      "Alexandros Kalousis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11083"
  },
  {
    "id": "arXiv:2106.11086",
    "title": "Analytically Tractable Bayesian Deep Q-Learning",
    "abstract": "Reinforcement learning (RL) has gained increasing interest since the\ndemonstration it was able to reach human performance on video game benchmarks\nusing deep Q-learning (DQN). The current consensus for training neural networks\non such complex environments is to rely on gradient-based optimization.\nAlthough alternative Bayesian deep learning methods exist, most of them still\nrely on gradient-based optimization, and they typically do not scale on\nbenchmarks such as the Atari game environment. Moreover none of these\napproaches allow performing the analytical inference for the weights and biases\ndefining the neural network. In this paper, we present how we can adapt the\ntemporal difference Q-learning framework to make it compatible with the\ntractable approximate Gaussian inference (TAGI), which allows learning the\nparameters of a neural network using a closed-form analytical method.\nThroughout the experiments with on- and off-policy reinforcement learning\napproaches, we demonstrate that TAGI can reach a performance comparable to\nbackpropagation-trained networks while using fewer hyperparameters, and without\nrelying on gradient-based optimization.",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Luong Ha",
      "Nguyen",
      "James-A. Goulet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11086"
  },
  {
    "id": "arXiv:2106.11092",
    "title": "A PTAS for $k$-hop MST on the Euclidean plane: Improving Dependency on  $k$",
    "abstract": "For any $\\epsilon>0$, Laue and Matijevi\\'{c} [CCCG'07, IPL'08] give a PTAS\nfor finding a $(1+\\epsilon)$-approximate solution to the $k$-hop MST problem in\nthe Euclidean plane that runs in time $(n/\\epsilon)^{O(k/\\epsilon)}$. In this\npaper, we present an algorithm that runs in time $(n/\\epsilon)^{O(\\log k\n\\cdot(1/\\epsilon)^2\\cdot\\log^2(1/\\epsilon))}$. This gives an improvement on the\ndependency on $k$ on the exponent, while having a worse dependency on\n$\\epsilon$. As in Laue and Matijevi\\'{c}, we follow the framework introduced by\nArora for Euclidean TSP. Our key ingredients include exponential distance\nscaling and compression of dynamic programming state tables.",
    "descriptor": "",
    "authors": [
      "Jittat Fakcharoenphol",
      "Nonthaphat Wongwattanakij"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.11092"
  },
  {
    "id": "arXiv:2106.11096",
    "title": "Learning to Rank Question Answer Pairs with Bilateral Contrastive Data  Augmentation",
    "abstract": "In this work, we propose a novel and easy-to-apply data augmentation\nstrategy, namely Bilateral Generation (BiG), with a contrastive training\nobjective for improving the performance of ranking question answer pairs with\nexisting labeled data. In specific, we synthesize pseudo-positive QA pairs in\ncontrast to the original negative QA pairs with two pre-trained generation\nmodels, one for question generation, the other for answer generation, which are\nfine-tuned on the limited positive QA pairs from the original dataset. With the\naugmented dataset, we design a contrastive training objective for learning to\nrank question answer pairs. Experimental results on three benchmark datasets,\nnamely TREC-QA, WikiQA, and ANTIQUE, show that our method significantly\nimproves the performance of ranking models by making full use of existing\nlabeled data and can be easily applied to different ranking models.",
    "descriptor": "",
    "authors": [
      "Yang Deng",
      "Wenxuan Zhang",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.11096"
  },
  {
    "id": "arXiv:2106.11097",
    "title": "CLIP2Video: Mastering Video-Text Retrieval via Image CLIP",
    "abstract": "We present CLIP2Video network to transfer the image-language pre-training\nmodel to video-text retrieval in an end-to-end manner. Leading approaches in\nthe domain of video-and-language learning try to distill the spatio-temporal\nvideo features and multi-modal interaction between videos and languages from a\nlarge-scale video-text dataset. Different from them, we leverage pretrained\nimage-language model, simplify it as a two-stage framework with co-learning of\nimage-text and enhancing temporal relations between video frames and video-text\nrespectively, make it able to train on comparatively small datasets.\nSpecifically, based on the spatial semantics captured by Contrastive\nLanguage-Image Pretraining (CLIP) model, our model involves a Temporal\nDifference Block to capture motions at fine temporal video frames, and a\nTemporal Alignment Block to re-align the tokens of video clips and phrases and\nenhance the multi-modal correlation. We conduct thorough ablation studies, and\nachieve state-of-the-art performance on major text-to-video and video-to-text\nretrieval benchmarks, including new records of retrieval accuracy on MSR-VTT,\nMSVD and VATEX.",
    "descriptor": "",
    "authors": [
      "Han Fang",
      "Pengfei Xiong",
      "Luhui Xu",
      "Yu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11097"
  },
  {
    "id": "arXiv:2106.11098",
    "title": "Obstacle Detection for BVLOS Drones",
    "abstract": "With the introduction of new regulations in the European Union, the future of\nBeyond Visual Line Of Sight (BVLOS) drones is set to bloom. This led to the\ncreation of the theBEAST project, which aims to create an autonomous security\ndrone, with focus on those regulations and on safety. This technical paper\ndescribes the first steps of a module within this project, which revolves\naround detecting obstacles so they can be avoided in a fail-safe landing. A\ndeep learning powered object detection method is the subject of our research,\nand various experiments are held to maximize its performance, such as comparing\nvarious data augmentation techniques or YOLOv3 and YOLOv5. According to the\nresults of the experiments, we conclude that although object detection is a\npromising approach to resolve this problem, more volume of data is required for\npotential usage in a real-life application.",
    "descriptor": "\nComments: 7 pages, 7 figures, Supervisors: Maya Aghaei Gavari and Jaap van de Loosdrecht\n",
    "authors": [
      "Jan Moros Esteban"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11098"
  },
  {
    "id": "arXiv:2106.11099",
    "title": "Distilling effective supervision for robust medical image segmentation  with noisy labels",
    "abstract": "Despite the success of deep learning methods in medical image segmentation\ntasks, the human-level performance relies on massive training data with\nhigh-quality annotations, which are expensive and time-consuming to collect.\nThe fact is that there exist low-quality annotations with label noise, which\nleads to suboptimal performance of learned models. Two prominent directions for\nsegmentation learning with noisy labels include pixel-wise noise robust\ntraining and image-level noise robust training. In this work, we propose a\nnovel framework to address segmenting with noisy labels by distilling effective\nsupervision information from both pixel and image levels. In particular, we\nexplicitly estimate the uncertainty of every pixel as pixel-wise noise\nestimation, and propose pixel-wise robust learning by using both the original\nlabels and pseudo labels. Furthermore, we present an image-level robust\nlearning method to accommodate more information as the complements to\npixel-level learning. We conduct extensive experiments on both simulated and\nreal-world noisy datasets. The results demonstrate the advantageous performance\nof our method compared to state-of-the-art baselines for medical image\nsegmentation with noisy labels.",
    "descriptor": "\nComments: Accepted to MICCAI 2021\n",
    "authors": [
      "Jialin Shi",
      "Ji Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11099"
  },
  {
    "id": "arXiv:2106.11102",
    "title": "Low-rank Dictionary Learning for Unsupervised Feature Selection",
    "abstract": "There exist many high-dimensional data in real-world applications such as\nbiology, computer vision, and social networks. Feature selection approaches are\ndevised to confront with high-dimensional data challenges with the aim of\nefficient learning technologies as well as reduction of models complexity. Due\nto the hardship of labeling on these datasets, there are a variety of\napproaches on feature selection process in an unsupervised setting by\nconsidering some important characteristics of data. In this paper, we introduce\na novel unsupervised feature selection approach by applying dictionary learning\nideas in a low-rank representation. Dictionary learning in a low-rank\nrepresentation not only enables us to provide a new representation, but it also\nmaintains feature correlation. Then, spectral analysis is employed to preserve\nsample similarities. Finally, a unified objective function for unsupervised\nfeature selection is proposed in a sparse way by an $\\ell_{2,1}$-norm\nregularization. Furthermore, an efficient numerical algorithm is designed to\nsolve the corresponding optimization problem. We demonstrate the performance of\nthe proposed method based on a variety of standard datasets from different\napplied domains. Our experimental findings reveal that the proposed method\noutperforms the state-of-the-art algorithm.",
    "descriptor": "",
    "authors": [
      "Mohsen Ghassemi Parsa",
      "Hadi Zare",
      "Mehdi Ghatee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11102"
  },
  {
    "id": "arXiv:2106.11111",
    "title": "Decadal Forecasts with ResDMD: a Residual DMD Neural Network",
    "abstract": "Operational forecasting centers are investing in decadal (1-10 year) forecast\nsystems to support long-term decision making for a more climate-resilient\nsociety. One method that has previously been employed is the Dynamic Mode\nDecomposition (DMD) algorithm - also known as the Linear Inverse Model - which\nfits linear dynamical models to data. While the DMD usually approximates\nnon-linear terms in the true dynamics as a linear system with random noise, we\ninvestigate an extension to the DMD that explicitly represents the non-linear\nterms as a neural network. Our weight initialization allows the network to\nproduce sensible results before training and then improve the prediction after\ntraining as data becomes available. In this short paper, we evaluate the\nproposed architecture for simulating global sea surface temperatures and\ncompare the results with the standard DMD and seasonal forecasts produced by\nthe state-of-the-art dynamical model, CFSv2.",
    "descriptor": "\nComments: Accepted to ICML 2021 Workshop Tackling Climate Change with Machine Learning\n",
    "authors": [
      "Eduardo Rodrigues",
      "Bianca Zadrozny",
      "Campbell Watson",
      "David Gold"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11111"
  },
  {
    "id": "arXiv:2106.11112",
    "title": "Multivariate Data Explanation by Jumping Emerging Patterns Visualization",
    "abstract": "Visual Analytics (VA) tools and techniques have shown to be instrumental in\nsupporting users to build better classification models, interpret model\ndecisions and audit results. In a different direction, VA has recently been\napplied to transform classification models into descriptive mechanisms instead\nof predictive. The idea is to use such models as surrogates for data patterns,\nvisualizing the model to understand the phenomenon represented by the data.\nAlthough very useful and inspiring, the few proposed approaches have opted to\nuse low complex classification models to promote straightforward\ninterpretation, presenting limitations to capture intricate data patterns. In\nthis paper, we present VAX (multiVariate dAta eXplanation), a new VA method to\nsupport the identification and visual interpretation of patterns in\nmultivariate data sets. Unlike the existing similar approaches, VAX uses the\nconcept of Jumping Emerging Patterns to identify and aggregate several\ndiversified patterns, producing explanations through logic combinations of data\nvariables. The potential of VAX to interpret complex multivariate datasets is\ndemonstrated through study-cases using two real-world data sets covering\ndifferent scenarios.",
    "descriptor": "",
    "authors": [
      "M\u00e1rio Popolin Neto",
      "Fernando V. Paulovich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11112"
  },
  {
    "id": "arXiv:2106.11113",
    "title": "Matrix Encoding Networks for Neural Combinatorial Optimization",
    "abstract": "Machine Learning (ML) can help solve combinatorial optimization (CO) problems\nbetter. A popular approach is to use a neural net to compute on the parameters\nof a given CO problem and extract useful information that guides the search for\ngood solutions. Many CO problems of practical importance can be specified in a\nmatrix form of parameters quantifying the relationship between two groups of\nitems. There is currently no neural net model, however, that takes in such\nmatrix-style relationship data as an input. Consequently, these types of CO\nproblems have been out of reach for ML engineers. In this paper, we introduce\nMatrix Encoding Network (MatNet) and show how conveniently it takes in and\nprocesses parameters of such complex CO problems. Using an end-to-end model\nbased on MatNet, we solve asymmetric traveling salesman (ATSP) and flexible\nflow shop (FFSP) problems as the earliest neural approach. In particular, for a\nclass of FFSP we have tested MatNet on, we demonstrate a far superior empirical\nperformance to any methods (neural or not) known to date.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Yeong-Dae Kwon",
      "Jinho Choo",
      "Iljoo Yoon",
      "Minah Park",
      "Duwon Park",
      "Youngjune Gwon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11113"
  },
  {
    "id": "arXiv:2106.11117",
    "title": "Uncertainty Quantification by MLMC and Local Time-stepping For Wave  Propagation",
    "abstract": "Because of their robustness, efficiency and non-intrusiveness, Monte Carlo\nmethods are probably the most popular approach in uncertainty quantification to\ncomputing expected values of quantities of interest (QoIs). Multilevel Monte\nCarlo (MLMC) methods significantly reduce the computational cost by\ndistributing the sampling across a hierarchy of discretizations and allocating\nmost samples to the coarser grids. For time dependent problems, spatial\ncoarsening typically entails an increased time-step. Geometric constraints,\nhowever, may impede uniform coarsening thereby forcing some elements to remain\nsmall across all levels. If explicit time-stepping is used, the time-step will\nthen be dictated by the smallest element on each level for numerical stability.\nHence, the increasingly stringent CFL condition on the time-step on coarser\nlevels significantly reduces the advantages of the multilevel approach. By\nadapting the time-step to the locally refined elements on each level, local\ntime-stepping (LTS) methods permit to restore the efficiency of MLMC methods\neven in the presence of complex geometry without sacrificing the explicitness\nand inherent parallelism.",
    "descriptor": "",
    "authors": [
      "Marcus J. Grote",
      "Simon Michel",
      "Fabio Nobile"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11117"
  },
  {
    "id": "arXiv:2106.11118",
    "title": "SODA10M: Towards Large-Scale Object Detection Benchmark for Autonomous  Driving",
    "abstract": "Aiming at facilitating a real-world, ever-evolving and scalable autonomous\ndriving system, we present a large-scale benchmark for standardizing the\nevaluation of different self-supervised and semi-supervised approaches by\nlearning from raw data, which is the first and largest benchmark to date.\nExisting autonomous driving systems heavily rely on `perfect' visual perception\nmodels (e.g., detection) trained using extensive annotated data to ensure the\nsafety. However, it is unrealistic to elaborately label instances of all\nscenarios and circumstances (e.g., night, extreme weather, cities) when\ndeploying a robust autonomous driving system. Motivated by recent powerful\nadvances of self-supervised and semi-supervised learning, a promising direction\nis to learn a robust detection model by collaboratively exploiting large-scale\nunlabeled data and few labeled data. Existing dataset (e.g., KITTI, Waymo)\neither provides only a small amount of data or covers limited domains with full\nannotation, hindering the exploration of large-scale pre-trained models. Here,\nwe release a Large-Scale Object Detection benchmark for Autonomous driving,\nnamed as SODA10M, containing 10 million unlabeled images and 20K images labeled\nwith 6 representative object categories. To improve diversity, the images are\ncollected every ten seconds per frame within 32 different cities under\ndifferent weather conditions, periods and location scenes. We provide extensive\nexperiments and deep analyses of existing supervised state-of-the-art detection\nmodels, popular self-supervised and semi-supervised approaches, and some\ninsights about how to develop future models. The data and more up-to-date\ninformation have been released at https://soda-2d.github.io.",
    "descriptor": "",
    "authors": [
      "Jianhua Han",
      "Xiwen Liang",
      "Hang Xu",
      "Kai Chen",
      "Lanqing Hong",
      "Chaoqiang Ye",
      "Wei Zhang",
      "Zhenguo Li",
      "Chunjing Xu",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11118"
  },
  {
    "id": "arXiv:2106.11119",
    "title": "Graceful Degradation and Related Fields",
    "abstract": "When machine learning models encounter data which is out of the distribution\non which they were trained they have a tendency to behave poorly, most\nprominently over-confidence in erroneous predictions. Such behaviours will have\ndisastrous effects on real-world machine learning systems. In this field\ngraceful degradation refers to the optimisation of model performance as it\nencounters this out-of-distribution data. This work presents a definition and\ndiscussion of graceful degradation and where it can be applied in deployed\nvisual systems. Following this a survey of relevant areas is undertaken,\nnovelly splitting the graceful degradation problem into active and passive\napproaches. In passive approaches, graceful degradation is handled and achieved\nby the model in a self-contained manner, in active approaches the model is\nupdated upon encountering epistemic uncertainties. This work communicates the\nimportance of the problem and aims to prompt the development of machine\nlearning strategies that are aware of graceful degradation.",
    "descriptor": "",
    "authors": [
      "Jack Dymond"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11119"
  },
  {
    "id": "arXiv:2106.11125",
    "title": "Classification of Documents Extracted from Images with Optical Character  Recognition Methods",
    "abstract": "Over the past decade, machine learning methods have given us driverless cars,\nvoice recognition, effective web search, and a much better understanding of the\nhuman genome. Machine learning is so common today that it is used dozens of\ntimes a day, possibly unknowingly. Trying to teach a machine some processes or\nsome situations can make them predict some results that are difficult to\npredict by the human brain. These methods also help us do some operations that\nare often impossible or difficult to do with human activities in a short time.\nFor these reasons, machine learning is so important today. In this study, two\ndifferent machine learning methods were combined. In order to solve a\nreal-world problem, the manuscript documents were first transferred to the\ncomputer and then classified. We used three basic methods to realize the whole\nprocess. Handwriting or printed documents have been digitalized by a scanner or\ndigital camera. These documents have been processed with two different Optical\nCharacter Recognition (OCR) operation. After that generated texts are\nclassified by using Naive Bayes algorithm. All project was programmed in\nMicrosoft Visual Studio 12 platform on Windows operating system. C# programming\nlanguage was used for all parts of the study. Also, some prepared codes and\nDLLs were used.",
    "descriptor": "",
    "authors": [
      "Omer Aydin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.11125"
  },
  {
    "id": "arXiv:2106.11133",
    "title": "GraphMixup: Improving Class-Imbalanced Node Classification on Graphs by  Self-supervised Context Prediction",
    "abstract": "Recent years have witnessed great success in handling node classification\ntasks with Graph Neural Networks (GNNs). However, most existing GNNs are based\non the assumption that node samples for different classes are balanced, while\nfor many real-world graphs, there exists the problem of class imbalance, i.e.,\nsome classes may have much fewer samples than others. In this case, directly\ntraining a GNN classifier with raw data would under-represent samples from\nthose minority classes and result in sub-optimal performance. This paper\npresents GraphMixup, a novel mixup-based framework for improving\nclass-imbalanced node classification on graphs. However, directly performing\nmixup in the input space or embedding space may produce out-of-domain samples\ndue to the extreme sparsity of minority classes; hence we construct semantic\nrelation spaces that allows the Feature Mixup to be performed at the semantic\nlevel. Moreover, we apply two context-based self-supervised techniques to\ncapture both local and global information in the graph structure and then\npropose Edge Mixup specifically for graph data. Finally, we develop a\n\\emph{Reinforcement Mixup} mechanism to adaptively determine how many samples\nare to be generated by mixup for those minority classes. Extensive experiments\non three real-world datasets show that GraphMixup yields truly encouraging\nresults for class-imbalanced node classification tasks.",
    "descriptor": "",
    "authors": [
      "Lirong Wu",
      "Haitao Lin",
      "Zhangyang Gao",
      "Cheng Tan",
      "Stan.Z.Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11133"
  },
  {
    "id": "arXiv:2106.11135",
    "title": "Brushless Motor Performance Optimization by Eagle Strategy with Firefly  and PSO",
    "abstract": "Brushless motors has special place though different motors are available\nbecause of its special features like absence in commutation, reduced noise and\nlonger lifetime etc., The experimental parameter tracking of BLDC Motor can be\nachieved by developing a Reference system and their stability is guaranteed by\nadopting Lyapunov Stability theorems. But the stability is guaranteed only if\nthe adaptive system is incorporated with the powerful and efficient\noptimization techniques. In this paper the powerful eagle strategy with\nParticle Swarm optimization and Firefly algorithms are applied to evaluate the\nperformance of brushless motor Where, Eagle Strategy(ES) with the use of Levys\nwalk distribution function performs diversified global search and the Particle\nSwarm Optimization (PSO) and Firefly Algorithm(FFA) performs the efficient\nintensive local search. The combined operation makes the overall optimization\ntechnique as much convenient The simulation results are obtained by using\nMATLAB Simulink software",
    "descriptor": "\nComments: International Journal of Engineering Trends and Technology (IJETT) Journal Volume-68 Issue-9,Year of Publication 2020 8Pages,5 Figures\n",
    "authors": [
      "Appalabathula Venkatesh",
      "Pradeepa H",
      "Chidanandappa R",
      "Shankar Nalinakshan",
      "Jayasankar V N"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.11135"
  },
  {
    "id": "arXiv:2106.11140",
    "title": "An Exploratory Study on Architectural Knowledge in Issue Tracking  Systems",
    "abstract": "Software developers use issue trackers (e.g. Jira) to manage defects, bugs,\ntasks, change requests, etc. In this paper we explore (a) how architectural\nknowledge concepts (e.g. architectural component behavior, contextual\nconstraints) are textually represented in issues (e.g. as adjectives), (b)\nwhich architectural knowledge concepts commonly occur in issues, and (c) which\narchitectural knowledge concepts appear together. We analyzed issues in the\nJira issue trackers of three large Apache projects. To identify\n``architecturally relevant'' issues, we linked issues to architecturally\nrelevant source code changes in the studied systems. We then developed a code\nbook by manually labeling a subset of issues. After reaching conceptual\nsaturation, we coded remaining issues. Our findings support\nempirically-grounded search tools to identify architectural knowledge concepts\nin issues for future reuse.",
    "descriptor": "",
    "authors": [
      "Mohamed Soliman",
      "Matthias Galster",
      "Paris Avgeriou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.11140"
  },
  {
    "id": "arXiv:2106.11145",
    "title": "FP-Age: Leveraging Face Parsing Attention for Facial Age Estimation in  the Wild",
    "abstract": "Image-based age estimation aims to predict a person's age from facial images.\nIt is used in a variety of real-world applications. Although end-to-end deep\nmodels have achieved impressive results for age estimation on benchmark\ndatasets, their performance in-the-wild still leaves much room for improvement\ndue to the challenges caused by large variations in head pose, facial\nexpressions, and occlusions. To address this issue, we propose a simple yet\neffective method to explicitly incorporate facial semantics into age\nestimation, so that the model would learn to correctly focus on the most\ninformative facial components from unaligned facial images regardless of head\npose and non-rigid deformation. To this end, we design a face parsing-based\nnetwork to learn semantic information at different scales and a novel face\nparsing attention module to leverage these semantic features for age\nestimation. To evaluate our method on in-the-wild data, we also introduce a new\nchallenging large-scale benchmark called IMDB-Clean. This dataset is created by\nsemi-automatically cleaning the noisy IMDB-WIKI dataset using a constrained\nclustering method. Through comprehensive experiment on IMDB-Clean and other\nbenchmark datasets, under both intra-dataset and cross-dataset evaluation\nprotocols, we show that our method consistently outperforms all existing age\nestimation methods and achieves a new state-of-the-art performance. To the best\nof our knowledge, our work presents the first attempt of leveraging face\nparsing attention to achieve semantic-aware age estimation, which may be\ninspiring to other high level facial analysis tasks.",
    "descriptor": "\nComments: Code and data will be available on this https URL\n",
    "authors": [
      "Yiming Lin",
      "Jie Shen",
      "Yujiang Wang",
      "Maja Pantic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11145"
  },
  {
    "id": "arXiv:2106.11146",
    "title": "On decoding of a specific type of self-dual codes",
    "abstract": "This work introduces a decoding strategy for binary self-dual codes\npossessing an automorphism of a specific type. The proposed algorithm is a hard\ndecision iterative decoding scheme. The enclosed experiments show that the new\ndecoding concept performs error correction beyond the upper bound for the code\ncorrection capability. Moreover, we prove that the requirements for the new\nalgorithm hold for any binary self-dual code having an automorphism of the\nspecific type, which makes decoding of this large group of codes possible.",
    "descriptor": "",
    "authors": [
      "Radinka Yorgova"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11146"
  },
  {
    "id": "arXiv:2106.11148",
    "title": "Explicit Interaction Network for Aspect Sentiment Triplet Extraction",
    "abstract": "Aspect Sentiment Triplet Extraction (ASTE) aims to recognize targets, their\nsentiment polarities and opinions explaining the sentiment from a sentence.\nASTE could be naturally divided into 3 atom subtasks, namely target detection,\nopinion detection and sentiment classification. We argue that the proper\nsubtask combination, compositional feature extraction for target-opinion pairs,\nand interaction between subtasks would be the key to success. Prior work,\nhowever, may fail on `one-to-many' or `many-to-one' situations, or derive\nnon-existent sentiment triplets due to defective subtask formulation,\nsub-optimal feature representation or the lack of subtask interaction. In this\npaper, we divide ASTE into target-opinion joint detection and sentiment\nclassification subtasks, which is in line with human cognition, and\ncorrespondingly propose sequence encoder and table encoder. Table encoder\nextracts sentiment at token-pair level, so that the compositional feature\nbetween targets and opinions can be easily captured. To establish explicit\ninteraction between subtasks, we utilize the table representation to guide the\nsequence encoding, and inject the sequence features back into the table\nencoder. Experiments show that our model outperforms state-of-the-art methods\non six popular ASTE datasets.",
    "descriptor": "",
    "authors": [
      "Peiyi Wang",
      "Lianzhe Huang",
      "Tianyu Liu",
      "Damai Dai",
      "Runxin Xu",
      "Houfeng Wang",
      "Baobao Chang",
      "Zhifang Sui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11148"
  },
  {
    "id": "arXiv:2106.11149",
    "title": "OadTR: Online Action Detection with Transformers",
    "abstract": "Most recent approaches for online action detection tend to apply Recurrent\nNeural Network (RNN) to capture long-range temporal structure. However, RNN\nsuffers from non-parallelism and gradient vanishing, hence it is hard to be\noptimized. In this paper, we propose a new encoder-decoder framework based on\nTransformers, named OadTR, to tackle these problems. The encoder attached with\na task token aims to capture the relationships and global interactions between\nhistorical observations. The decoder extracts auxiliary information by\naggregating anticipated future clip representations. Therefore, OadTR can\nrecognize current actions by encoding historical information and predicting\nfuture context simultaneously. We extensively evaluate the proposed OadTR on\nthree challenging datasets: HDD, TVSeries, and THUMOS14. The experimental\nresults show that OadTR achieves higher training and inference speeds than\ncurrent RNN based approaches, and significantly outperforms the\nstate-of-the-art methods in terms of both mAP and mcAP. Code is available at\nhttps://github.com/wangxiang1230/OadTR.",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Xiang Wang",
      "Shiwei Zhang",
      "Zhiwu Qing",
      "Yuanjie Shao",
      "Zhengrong Zuo",
      "Changxin Gao",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11149"
  },
  {
    "id": "arXiv:2106.11151",
    "title": "The Role of Evolution in Machine Intelligence",
    "abstract": "Machine intelligence can develop either directly from experience or by\ninheriting experience through evolution. The bulk of current research efforts\nfocus on algorithms which learn directly from experience. I argue that the\nalternative, evolution, is important to the development of machine intelligence\nand underinvested in terms of research allocation. The primary aim of this work\nis to assess where along the spectrum of evolutionary algorithms to invest in\nresearch. My first-order suggestion is to diversify research across a broader\nspectrum of evolutionary approaches. I also define meta-evolutionary algorithms\nand argue that they may yield an optimal trade-off between the many factors\ninfluencing the development of machine intelligence.",
    "descriptor": "",
    "authors": [
      "Awni Hannun"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.11151"
  },
  {
    "id": "arXiv:2106.11154",
    "title": "Automatic Plant Cover Estimation with CNNs Automatic Plant Cover  Estimation with Convolutional Neural Networks",
    "abstract": "Monitoring the responses of plants to environmental changes is essential for\nplant biodiversity research. This, however, is currently still being done\nmanually by botanists in the field. This work is very laborious, and the data\nobtained is, though following a standardized method to estimate plant coverage,\nusually subjective and has a coarse temporal resolution. To remedy these\ncaveats, we investigate approaches using convolutional neural networks (CNNs)\nto automatically extract the relevant data from images, focusing on plant\ncommunity composition and species coverages of 9 herbaceous plant species. To\nthis end, we investigate several standard CNN architectures and different\npretraining methods. We find that we outperform our previous approach at higher\nimage resolutions using a custom CNN with a mean absolute error of 5.16%. In\naddition to these investigations, we also conduct an error analysis based on\nthe temporal aspect of the plant cover images. This analysis gives insight into\nwhere problems for automatic approaches lie, like occlusion and likely\nmisclassifications caused by temporal changes.",
    "descriptor": "",
    "authors": [
      "Matthias K\u00f6rschens",
      "Paul Bodesheim",
      "Christine R\u00f6mermann",
      "Solveig Franziska Bucher",
      "Mirco Migliavacca",
      "Josephine Ulrich",
      "Joachim Denzler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11154"
  },
  {
    "id": "arXiv:2106.11156",
    "title": "Curriculum-Driven Multi-Agent Learning and the Role of Implicit  Communication in Teamwork",
    "abstract": "We propose a curriculum-driven learning strategy for solving difficult\nmulti-agent coordination tasks. Our method is inspired by a study of animal\ncommunication, which shows that two straightforward design features (mutual\nreward and decentralization) support a vast spectrum of communication protocols\nin nature. We highlight the importance of similarly interpreting emergent\ncommunication as a spectrum. We introduce a toroidal, continuous-space\npursuit-evasion environment and show that naive decentralized learning does not\nperform well. We then propose a novel curriculum-driven strategy for\nmulti-agent learning. Experiments with pursuit-evasion show that our approach\nenables decentralized pursuers to learn to coordinate and capture a superior\nevader, significantly outperforming sophisticated analytical policies. We argue\nthrough additional quantitative analysis -- including influence-based measures\nsuch as Instantaneous Coordination -- that emergent implicit communication\nplays a large role in enabling superior levels of coordination.",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "Niko A. Grupen",
      "Daniel D. Lee",
      "Bart Selman"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11156"
  },
  {
    "id": "arXiv:2106.11159",
    "title": "Towards a corpus for credibility assessment in software practitioner  blog articles",
    "abstract": "Blogs are a source of grey literature which are widely adopted by software\npractitioners for disseminating opinion and experience. Analysing such articles\ncan provide useful insights into the state-of-practice for software engineering\nresearch. However, there are challenges in identifying higher quality content\nfrom the large quantity of articles available. Credibility assessment can help\nin identifying quality content, though there is a lack of existing corpora.\nCredibility is typically measured through a series of conceptual criteria, with\n'argumentation' and 'evidence' being two important criteria.\nWe create a corpus labelled for argumentation and evidence that can aid the\ncredibility community. The corpus consists of articles from the blog of a\nsingle software practitioner and is publicly available.\nThree annotators label the corpus with a series of conceptual credibility\ncriteria, reaching an agreement of 0.82 (Fleiss' Kappa). We present preliminary\nanalysis of the corpus by using it to investigate the identification of claim\nsentences (one of our ten labels).\nWe train four systems (Bert, KNN, Decision Tree and SVM) using three feature\nsets (Bag of Words, Topic Modelling and InferSent), achieving an F1 score of\n0.64 using InferSent and a Linear SVM.\nOur preliminary results are promising, indicating that the corpus can help\nfuture studies in detecting the credibility of grey literature. Future research\nwill investigate the degree to which the sentence level annotations can infer\nthe credibility of the overall document.",
    "descriptor": "",
    "authors": [
      "Ashley Williams",
      "Matthew Shardlow",
      "Austen Rainer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.11159"
  },
  {
    "id": "arXiv:2106.11160",
    "title": "Effects of boundary conditions in fully convolutional networks for  learning spatio-temporal dynamics",
    "abstract": "Accurate modeling of boundary conditions is crucial in computational physics.\nThe ever increasing use of neural networks as surrogates for physics-related\nproblems calls for an improved understanding of boundary condition treatment,\nand its influence on the network accuracy. In this paper, several strategies to\nimpose boundary conditions (namely padding, improved spatial context, and\nexplicit encoding of physical boundaries) are investigated in the context of\nfully convolutional networks applied to recurrent tasks. These strategies are\nevaluated on two spatio-temporal evolving problems modeled by partial\ndifferential equations: the 2D propagation of acoustic waves (hyperbolic PDE)\nand the heat equation (parabolic PDE). Results reveal a high sensitivity of\nboth accuracy and stability on the boundary implementation in such recurrent\ntasks. It is then demonstrated that the choice of the optimal padding strategy\nis directly linked to the data semantics. Furthermore, the inclusion of\nadditional input spatial context or explicit physics-based rules allows a\nbetter handling of boundaries in particular for large number of recurrences,\nresulting in more robust and stable neural networks, while facilitating the\ndesign and versatility of such networks.",
    "descriptor": "\nComments: 17 pages, 8 figures, submitted to ECML PKDD 2021 Conference\n",
    "authors": [
      "Antonio Alguacil andr Gon\u00e7alves Pinto",
      "Michael Bauerheim",
      "Marc C. Jacob",
      "St\u00e9phane Moreau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2106.11160"
  },
  {
    "id": "arXiv:2106.11164",
    "title": "Design criteria of flexible capacitive pressure sensors using  DIY-techniques and household materials",
    "abstract": "The flexible capacitive pressure sensors are one of the most essential and\nfamous devices with vast applications in automobile, aerospace, marine,\nhealthcare, wearables, consumer, and portable electronics. The fabrication of\npressure sensors in a cleanroom is expensive and time-consuming; however, the\nsensitivity, linearity, and other performance factors of those pressure sensors\nare exceptional. Moreover, sometimes we require sensors that are not expensive\nand can be fabricated rapidly where the other performance factors do not need\nto be highly remarkable. In this modern era, household materials and DIY\n(Do-it-yourself) techniques are quite helpful, highly utilized. They are\nrecommended to fabricate low-cost sensors and healthcare devices for\npersonalized medicine and low-cost consumer electronics. Different flexible\ncapacitive pressure sensors are presented and experimentally characterized for\nacoustic and air-pressure monitoring in this thesis. The design criteria of a\ncantilever-based capacitive pressure sensor are discussed. The three different\ndesigns are analysed with aspect ratios of 1.5, 1.0, and 0.67. The sensor with\nan aspect ratio of 0.67 shows maximum sensitivity (mechanical and electrical),\nbetter response time, and the 1st and 2nd mode of resonant frequencies is\ncomparatively less than the other two. The cantilever designs are susceptible\nto slight pressure; therefore, the diaphragm-based normal mode capacitive\npressure sensor is introduced in the second chapter, which defines the design\ncriteria of diaphragm shapes. The five different diaphragms analysed are\ncircular, elliptical, pentagon, square, and rectangular shapes. The circular\ncapacitive pressure sensor shows maximum sensitivity, however, maximum\nnon-linear response.....",
    "descriptor": "",
    "authors": [
      "Rishabh Bhooshan Mishra"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.11164"
  },
  {
    "id": "arXiv:2106.11166",
    "title": "3D Shape Registration Using Spectral Graph Embedding and Probabilistic  Matching",
    "abstract": "We address the problem of 3D shape registration and we propose a novel\ntechnique based on spectral graph theory and probabilistic matching. The task\nof 3D shape analysis involves tracking, recognition, registration, etc.\nAnalyzing 3D data in a single framework is still a challenging task considering\nthe large variability of the data gathered with different acquisition devices.\n3D shape registration is one such challenging shape analysis task. The main\ncontribution of this chapter is to extend the spectral graph matching methods\nto very large graphs by combining spectral graph matching with Laplacian\nembedding. Since the embedded representation of a graph is obtained by\ndimensionality reduction we claim that the existing spectral-based methods are\nnot easily applicable. We discuss solutions for the exact and inexact graph\nisomorphism problems and recall the main spectral properties of the\ncombinatorial graph Laplacian; We provide a novel analysis of the commute-time\nembedding that allows us to interpret the latter in terms of the PCA of a\ngraph, and to select the appropriate dimension of the associated embedded\nmetric space; We derive a unit hyper-sphere normalization for the commute-time\nembedding that allows us to register two shapes with different samplings; We\npropose a novel method to find the eigenvalue-eigenvector ordering and the\neigenvector signs using the eigensignature (histogram) which is invariant to\nthe isometric shape deformations and fits well in the spectral graph matching\nframework, and we present a probabilistic shape matching formulation using an\nexpectation maximization point registration algorithm which alternates between\naligning the eigenbases and finding a vertex-to-vertex assignment.",
    "descriptor": "",
    "authors": [
      "Avinash Sharma",
      "Radu Horaud",
      "Diana Mateus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11166"
  },
  {
    "id": "arXiv:2106.11173",
    "title": "TNT: Text-Conditioned Network with Transductive Inference for Few-Shot  Video Classification",
    "abstract": "Recently, few-shot learning has received increasing interest. Existing\nefforts have been focused on image classification, with very few attempts\ndedicated to the more challenging few-shot video classification problem. These\nfew attempts aim to effectively exploit the temporal dimension in videos for\nbetter learning in low data regimes. However, they have largely ignored a key\ncharacteristic of video which could be vital for few-shot recognition, that is,\nvideos are often accompanied by rich text descriptions. In this paper, for the\nfirst time, we propose to leverage these human-provided textual descriptions as\nprivileged information when training a few-shot video classification model.\nSpecifically, we formulate a text-based task conditioner to adapt video\nfeatures to the few-shot learning task. Our model follows a transductive\nsetting where query samples and support textual descriptions can be used to\nupdate the support set class prototype to further improve the task-adaptation\nability of the model. Our model obtains state-of-the-art performance on four\nchallenging benchmarks in few-shot video action classification.",
    "descriptor": "\nComments: 10 pages including references, 7 figures, and 4 tables\n",
    "authors": [
      "Andr\u00e9s Villa",
      "Juan-Manuel Perez-Rua",
      "Vladimir Araujo",
      "Juan Carlos Niebles",
      "Victor Escorcia",
      "Alvaro Soto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11173"
  },
  {
    "id": "arXiv:2106.11174",
    "title": "Does Optimal Source Task Performance Imply Optimal Pre-training for a  Target Task?",
    "abstract": "Pre-trained deep nets are commonly used to improve accuracies and training\ntimes for neural nets. It is generally assumed that pre-training a net for\noptimal source task performance best prepares it to learn an arbitrary target\ntask. This is generally not true. Stopping source task training, prior to\noptimal performance, can create a pre-trained net better suited for learning a\nnew task.\nWe performed several experiments demonstrating this effect, as well as the\ninfluence of amount of training and of learning rate. Additionally, we show\nthat this reflects a general loss of learning ability that even extends to\nrelearning the source task",
    "descriptor": "",
    "authors": [
      "Steven Gutstein",
      "Brent Lance",
      "Sanjay Shakkottai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11174"
  },
  {
    "id": "arXiv:2106.11175",
    "title": "Vehicle Trajectory Prediction in City-scale Road Networks using a  Direction-based Sequence-to-Sequence Model with Spatiotemporal Attention  Mechanisms",
    "abstract": "Trajectory prediction of vehicles at the city scale is of great importance to\nvarious location-based applications such as vehicle navigation, traffic\nmanagement, and location-based recommendations. Existing methods typically\nrepresent a trajectory as a sequence of grid cells, road segments or intention\nsets. None of them is ideal, as the cell-based representation ignores the road\nnetwork structures and the other two are less efficient in analyzing city-scale\nroad networks. In addition, most models focus on predicting the immediate next\nposition, and are difficult to generalize for longer sequences. To address\nthese problems, we propose a novel sequence-to-sequence model named D-LSTM\n(Direction-based Long Short-Term Memory), which represents each trajectory as a\nsequence of intersections and associated movement directions, and then feeds\nthem into a LSTM encoder-decoder network for future trajectory generation.\nFurthermore, we introduce a spatial attention mechanism to capture dynamic\nspatial dependencies in road networks, and a temporal attention mechanism with\na sliding context window to capture both short- and long-term temporal\ndependencies in trajectory data. Extensive experiments based on two real-world\nlarge-scale taxi trajectory datasets show that D-LSTM outperforms the existing\nstate-of-the-art methods for vehicle trajectory prediction, validating the\neffectiveness of the proposed trajectory representation method and\nspatiotemporal attention mechanisms.",
    "descriptor": "",
    "authors": [
      "Yuebing Liang",
      "Zhan Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11175"
  },
  {
    "id": "arXiv:2106.11176",
    "title": "Abstract Geometrical Computation 11: Slanted Firing Squad  Synchronisation on Signal Machines",
    "abstract": "Firing Squad Synchronisation on Cellular Automata is the dynamical\nsynchronisation of finitely many cells without any prior knowledge of their\nrange. This can be conceived as a signal with an infinite speed. Most of the\nproposed constructions naturally translate to the continuous setting of signal\nmachines and generate fractal figures with an accumulation on a horizontal\nline, i.e. synchronously, in the space-time diagram. Signal machines are\nstudied in a series of articles named Abstract Geometrical Computation.\nIn the present article, we design a signal machine that is able to\nsynchronise/accumulate on any non-infinite slope. The slope is encoded in the\ninitial configuration. This is done by constructing an infinite tree such that\neach node computes the way the tree expands.\nThe interest of Abstract Geometrical computation is to do away with the\nconstraint of discrete space, while tackling new difficulties from continuous\nspace. The interest of this paper in particular is to provide basic tools for\nfurther study of computable accumulation lines in the signal machine model.",
    "descriptor": "\nComments: 21 pages,29 figures\n",
    "authors": [
      "J\u00e9r\u00f4me Durand-Lose",
      "Aur\u00e9lien Emmanuel"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computation and Language (cs.CL)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.11176"
  },
  {
    "id": "arXiv:2106.11177",
    "title": "MetaDetector: Meta Event Knowledge Transfer for Fake News Detection",
    "abstract": "The blooming of fake news on social networks has devastating impacts on\nsociety, economy, and public security. Although numerous studies are conducted\nfor the automatic detection of fake news, the majority tend to utilize deep\nneural networks to learn event-specific features for superior detection\nperformance on specific datasets. However, the trained models heavily rely on\nthe training datasets and are infeasible to apply to upcoming events due to the\ndiscrepancy between event distributions. Inspired by domain adaptation\ntheories, we propose an end-to-end adversarial adaptation network, dubbed as\nMetaDetector, to transfer meta knowledge (event-shared features) between\ndifferent events. Specifically, MetaDetector pushes the feature extractor and\nevent discriminator to eliminate event-specific features and preserve required\nevent-shared features by adversarial training. Furthermore, the pseudo-event\ndiscriminator is utilized to evaluate the importance of historical event posts\nto obtain partial shared features that are discriminative for detecting fake\nnews. Under the coordinated optimization among the four submodules,\nMetaDetector accurately transfers the meta-knowledge of historical events to\nthe upcoming event for fact checking. We conduct extensive experiments on two\nlarge-scale datasets collected from Weibo and Twitter. The experimental results\ndemonstrate that MetaDetector outperforms the state-of-the-art methods,\nespecially when the distribution shift between events is significant.\nFurthermore, we find that MetaDetector is able to learn the event-shared\nfeatures, and alleviate the negative transfer caused by the large distribution\nshift between events.",
    "descriptor": "",
    "authors": [
      "Yasan Ding",
      "Bin Guo",
      "Yan Liu",
      "Yunji Liang",
      "Haocheng Shen",
      "Zhiwen Yu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.11177"
  },
  {
    "id": "arXiv:2106.11178",
    "title": "Thou Shalt Covet The Average Of Thy Neighbors' Cakes",
    "abstract": "We prove an $\\Omega(n^2)$ lower bound on the query complexity of local\nproportionality in the Robertson-Webb cake-cutting model. Local proportionality\nrequires that each agent prefer their allocation to the average of their\nneighbors' allocations in some undirected social network. It is a weaker\nfairness notion than envy-freeness, which also has query complexity\n$\\Omega(n^2)$, and generally incomparable to proportionality, which has query\ncomplexity $\\Theta(n \\log n)$. This result separates the complexity of local\nproportionality from that of ordinary proportionality, confirming the intuition\nthat finding a locally proportional allocation is a more difficult\ncomputational problem.",
    "descriptor": "",
    "authors": [
      "Jamie Tucker-Foltz"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.11178"
  },
  {
    "id": "arXiv:2106.11181",
    "title": "A Query-based Routing Table Update Mechanism for Content-Centric Network",
    "abstract": "Due to the popularity of network applications, such as multimedia, online\nshopping, Internet of Things (IoT), and 5G, the contents cached in the routers\nare frequently replaced in Content-Centric Networking (CCN). Generally, cache\nmiss causes numerous propagated packets to get the required content that\ndeteriorates network congestion and delay the response time of consumers. Many\ncaching strategies and routing policies were proposed to solve the problem.\nThis paper presents an alternative solution by designing a query-based routing\ntable update mechanism to increase the accuracy of routing tables. By adding an\nadditional query content in interest packets, our approach real-time explores\nthe cached content in routers and updated the routing table accordingly. This\npaper uses a general network simulator, ndnSIM, to compare basic CCN and our\napproach. The results show that our approach improves the response time of\nconsumers and network congestion and is compatible with general forwarding\nstrategies.",
    "descriptor": "\nComments: 6 pages, 14 figures, conference. ISBN:978-1-7281-9256-7\n",
    "authors": [
      "Pei-Hsuan Tsai",
      "Yu-Lin Tseng",
      "Jun-Bin Zhang",
      "Meng-Hsun Tsai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.11181"
  },
  {
    "id": "arXiv:2106.11182",
    "title": "On fine-tuning of Autoencoders for Fuzzy rule classifiers",
    "abstract": "Recent discoveries in Deep Neural Networks are allowing researchers to tackle\nsome very complex problems such as image classification and audio\nclassification, with improved theoretical and empirical justifications. This\npaper presents a novel scheme to incorporate the use of autoencoders in Fuzzy\nrule classifiers (FRC). Autoencoders when stacked can learn the complex\nnon-linear relationships amongst data, and the proposed framework built towards\nFRC can allow users to input expert knowledge to the system. This paper further\nintroduces four novel fine-tuning strategies for autoencoders to improve the\nFRC's classification and rule reduction performance. The proposed framework has\nbeen tested across five real-world benchmark datasets. Elaborate comparisons\nwith over 15 previous studies, and across 10-fold cross validation performance,\nsuggest that the proposed methods are capable of building FRCs which can\nprovide state of the art accuracies.",
    "descriptor": "",
    "authors": [
      "Rahul Kumar Sevakula",
      "Nishchal Kumar Verma",
      "Hisao Ishibuchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11182"
  },
  {
    "id": "arXiv:2106.11187",
    "title": "Agile Islands in a Waterfall Environment: Requirements Engineering  Challenges and Strategies in Automotive",
    "abstract": "[Context & motivation] Driven by the need for faster time-to-market and\nreduced development lead-time, large-scale systems engineering companies are\nadopting agile methods in their organizations. This agile transformation is\nchallenging and it is common that adoption starts bottom-up with agile software\nteams within the context of traditional company structures.\n[Question/Problem] This creates the challenge of agile teams working within a\ndocument-centric and plan-driven (or waterfall) environment. While it may be\ndesirable to take the best of both worlds, it is not clear how that can be\nachieved especially with respect to managing requirements in large-scale\nsystems.\n[Principal ideas/Results] This paper presents an exploratory case study at an\nautomotive company, focusing on two departments of a large-scale systems\ncompany that is in the process of company-wide agile adoption.\n[Contribution] We present challenges related to requirements engineering that\nagile teams face while working within a larger plan-driven context and propose\npotential strategies to mitigate the challenges. Challenges relate to, e.g.,\ndevelopment teams not being aware of the high-level requirement and dealing\nwith flexibility of writing user stories. We found that strategies for\novercoming most of these challenges are still lacking and thus call for more\nresearch.",
    "descriptor": "\nComments: Peer-reviewed and accepted at EASE2020\n",
    "authors": [
      "Rashidah Kasauli",
      "Eric Knauss",
      "Joyce Nakatumba-Nabende",
      "Benjamin Kanagwa"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.11187"
  },
  {
    "id": "arXiv:2106.11189",
    "title": "Regularization is all you Need: Simple Neural Nets can Excel on Tabular  Data",
    "abstract": "Tabular datasets are the last \"unconquered castle\" for deep learning, with\ntraditional ML methods like Gradient-Boosted Decision Trees still performing\nstrongly even against recent specialized neural architectures. In this paper,\nwe hypothesize that the key to boosting the performance of neural networks lies\nin rethinking the joint and simultaneous application of a large set of modern\nregularization techniques. As a result, we propose regularizing plain\nMultilayer Perceptron (MLP) networks by searching for the optimal\ncombination/cocktail of 13 regularization techniques for each dataset using a\njoint optimization over the decision on which regularizers to apply and their\nsubsidiary hyperparameters. We empirically assess the impact of these\nregularization cocktails for MLPs on a large-scale empirical study comprising\n40 tabular datasets and demonstrate that (i) well-regularized plain MLPs\nsignificantly outperform recent state-of-the-art specialized neural network\narchitectures, and (ii) they even outperform strong traditional ML methods,\nsuch as XGBoost.",
    "descriptor": "",
    "authors": [
      "Arlind Kadra",
      "Marius Lindauer",
      "Frank Hutter",
      "Josif Grabocka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11189"
  },
  {
    "id": "arXiv:2106.11190",
    "title": "Competitive MA-DRL for Transmit Power Pool Design in Semi-Grant-Free  NOMA Systems",
    "abstract": "In this paper, we exploit the capability of multi-agent deep reinforcement\nlearning (MA-DRL) technique to generate a transmit power pool (PP) for Internet\nof things (IoT) networks with semi-grant-free non-orthogonal multiple access\n(SGF-NOMA). The PP is mapped with each resource block (RB) to achieve\ndistributed transmit power control (DPC). We first formulate the resource\n(sub-channel and transmit power) selection problem as stochastic Markov game,\nand then solve it using two competitive MA-DRL algorithms, namely double deep Q\nnetwork (DDQN) and Dueling DDQN. Each GF user as an agent tries to find out the\noptimal transmit power level and RB to form the desired PP. With the aid of\ndueling processes, the learning process can be enhanced by evaluating the\nvaluable state without considering the effect of each action at each state.\nTherefore, DDQN is designed for communication scenarios with a small-size\naction-state space, while Dueling DDQN is for a large-size case. Our results\nshow that the proposed MA-Dueling DDQN based SGF-NOMA with DPC outperforms the\nSGF-NOMA system with the fixed-power-control mechanism and networks with pure\nGF protocols with 17.5% and 22.2% gain in terms of the system throughput,\nrespectively. Moreover, to decrease the training time, we eliminate invalid\nactions (high transmit power levels) to reduce the action space. We show that\nour proposed algorithm is computationally scalable to massive IoT networks.\nFinally, to control the interference and guarantee the quality-of-service\nrequirements of grant-based users, we find the optimal number of GF users for\neach sub-channel.",
    "descriptor": "",
    "authors": [
      "Muhammad Fayaz",
      "Wenqiang Yi",
      "Yuanwei Liu",
      "Arumugam Nallanathan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11190"
  },
  {
    "id": "arXiv:2106.11191",
    "title": "Computing the original eBWT faster, simpler, and with less memory",
    "abstract": "Mantaci et al. [TCS 2007] defined the eBWT to extend the definition of the\nBWT to a collection of strings, however, since this introduction, it has been\nused more generally to describe any BWT of a collection of strings and the\nfundamental property of the original definition (i.e., the independence from\nthe input order) is frequently disregarded. In this paper, we propose a simple\nlinear-time algorithm for the construction of the original eBWT, which does not\nrequire the preprocessing of Bannai et al. [CPM 2021]. As a byproduct, we\nobtain the first linear-time algorithm for computing the BWT of a single string\nthat uses neither an end-of-string symbol nor Lyndon rotations. We combine our\nnew eBWT construction with a variation of prefix-free parsing to allow for\nscalable construction of the eBWT. We evaluate our algorithm (pfpebwt) on sets\nof human chromosomes 19, Salmonella, and SARS-CoV2 genomes, and demonstrate\nthat it is the fastest method for all collections, with a maximum speedup of\n7.6x on the second best method. The peak memory is at most 2x larger than the\nsecond best method. Comparing with methods that are also, as our algorithm,\nable to report suffix array samples, we obtain a 57.1x improvement in peak\nmemory. The source code is publicly available at\nhttps://github.com/davidecenzato/PFP-eBWT.",
    "descriptor": "\nComments: 20 pages, 5 figures, 1 table\n",
    "authors": [
      "Christina Boucher",
      "Davide Cenzato",
      "Zsuzsanna Lipt\u00e1k",
      "Massimiliano Rossi",
      "Marinella Sciortino"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.11191"
  },
  {
    "id": "arXiv:2106.11193",
    "title": "Contrastive Multi-Modal Clustering",
    "abstract": "Multi-modal clustering, which explores complementary information from\nmultiple modalities or views, has attracted people's increasing attentions.\nHowever, existing works rarely focus on extracting high-level semantic\ninformation of multiple modalities for clustering. In this paper, we propose\nContrastive Multi-Modal Clustering (CMMC) which can mine high-level semantic\ninformation via contrastive learning. Concretely, our framework consists of\nthree parts. (1) Multiple autoencoders are optimized to maintain each\nmodality's diversity to learn complementary information. (2) A feature\ncontrastive module is proposed to learn common high-level semantic features\nfrom different modalities. (3) A label contrastive module aims to learn\nconsistent cluster assignments for all modalities. By the proposed multi-modal\ncontrastive learning, the mutual information of high-level features is\nmaximized, while the diversity of the low-level latent features is maintained.\nIn addition, to utilize the learned high-level semantic features, we further\ngenerate pseudo labels by solving a maximum matching problem to fine-tune the\ncluster assignments. Extensive experiments demonstrate that CMMC has good\nscalability and outperforms state-of-the-art multi-modal clustering methods.",
    "descriptor": "",
    "authors": [
      "Jie Xu",
      "Huayi Tang",
      "Yazhou Ren",
      "Xiaofeng Zhu",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11193"
  },
  {
    "id": "arXiv:2106.11196",
    "title": "Self-Calibrating Neural-Probabilistic Model for Authorship Verification  Under Covariate Shift",
    "abstract": "We are addressing two fundamental problems in authorship verification (AV):\nTopic variability and miscalibration. Variations in the topic of two disputed\ntexts are a major cause of error for most AV systems. In addition, it is\nobserved that the underlying probability estimates produced by deep learning AV\nmechanisms oftentimes do not match the actual case counts in the respective\ntraining data. As such, probability estimates are poorly calibrated. We are\nexpanding our framework from PAN 2020 to include Bayes factor scoring (BFS) and\nan uncertainty adaptation layer (UAL) to address both problems. Experiments\nwith the 2020/21 PAN AV shared task data show that the proposed method\nsignificantly reduces sensitivities to topical variations and significantly\nimproves the system's calibration.",
    "descriptor": "\nComments: 12th International Conference of the CLEF Association, 2021\n",
    "authors": [
      "Benedikt Boenninghoff",
      "Dorothea Kolossa",
      "Robert M. Nickel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11196"
  },
  {
    "id": "arXiv:2106.11197",
    "title": "Iterative Network Pruning with Uncertainty Regularization for Lifelong  Sentiment Classification",
    "abstract": "Lifelong learning capabilities are crucial for sentiment classifiers to\nprocess continuous streams of opinioned information on the Web. However,\nperforming lifelong learning is non-trivial for deep neural networks as\ncontinually training of incrementally available information inevitably results\nin catastrophic forgetting or interference. In this paper, we propose a novel\niterative network pruning with uncertainty regularization method for lifelong\nsentiment classification (IPRLS), which leverages the principles of network\npruning and weight regularization. By performing network pruning with\nuncertainty regularization in an iterative manner, IPRLS can adapta single BERT\nmodel to work with continuously arriving data from multiple domains while\navoiding catastrophic forgetting and interference. Specifically, we leverage an\niterative pruning method to remove redundant parameters in large deep networks\nso that the freed-up space can then be employed to learn new tasks, tackling\nthe catastrophic forgetting problem. Instead of keeping the old-tasks fixed\nwhen learning new tasks, we also use an uncertainty regularization based on the\nBayesian online learning framework to constrain the update of old tasks weights\nin BERT, which enables positive backward transfer, i.e. learning new tasks\nimproves performance on past tasks while protecting old knowledge from being\nlost. In addition, we propose a task-specific low-dimensional residual function\nin parallel to each layer of BERT, which makes IPRLS less prone to losing the\nknowledge saved in the base BERT network when learning a new task. Extensive\nexperiments on 16 popular review corpora demonstrate that the proposed IPRLS\nmethod sig-nificantly outperforms the strong baselines for lifelong sentiment\nclassification. For reproducibility, we submit the code and data\nat:https://github.com/siat-nlp/IPRLS.",
    "descriptor": "\nComments: Accepted by the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), 2021\n",
    "authors": [
      "Binzong Geng",
      "Min Yang",
      "Fajie Yuan",
      "Shupeng Wang",
      "Xiang Ao",
      "Ruifeng Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11197"
  },
  {
    "id": "arXiv:2106.11198",
    "title": "Deep Learning-Based Active User Detection for Grant-free SCMA Systems",
    "abstract": "Grant-free random access and uplink non-orthogonal multiple access (NOMA)\nhave been introduced to reduce transmission latency and signaling overhead in\nmassive machine-type communication (mMTC). In this paper, we propose two novel\ngroup-based deep neural network active user detection (AUD) schemes for the\ngrant-free sparse code multiple access (SCMA) system in mMTC uplink framework.\nThe proposed AUD schemes learn the nonlinear mapping, i.e., multi-dimensional\ncodebook structure and the channel characteristic. This is accomplished through\nthe received signal which incorporates the sparse structure of device activity\nwith the training dataset. Moreover, the offline pre-trained model is able to\ndetect the active devices without any channel state information and prior\nknowledge of the device sparsity level. Simulation results show that with\nseveral active devices, the proposed schemes obtain more than twice the\nprobability of detection compared to the conventional AUD schemes over the\nsignal to noise ratio range of interest.",
    "descriptor": "\nComments: Accepted for 2021 IEEE 32nd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)\n",
    "authors": [
      "Thushan Sivalingam",
      "Samad Ali",
      "Nurul Huda Mahmood",
      "Nandana Rajatheva",
      "Matti Latva-Aho"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11198"
  },
  {
    "id": "arXiv:2106.11204",
    "title": "Deep Neural Network-Based Blind Multiple User Detection for Grant-free  Multi-User Shared Access",
    "abstract": "Multi-user shared access (MUSA) is introduced as advanced code domain\nnon-orthogonal complex spreading sequences to support a massive number of\nmachine-type communications (MTC) devices. In this paper, we propose a novel\ndeep neural network (DNN)-based multiple user detection (MUD) for grant-free\nMUSA systems. The DNN-based MUD model determines the structure of the sensing\nmatrix, randomly distributed noise, and inter-device interference during the\ntraining phase of the model by several hidden nodes, neuron activation units,\nand a fit loss function. The thoroughly learned DNN model is capable of\ndistinguishing the active devices of the received signal without any a priori\nknowledge of the device sparsity level and the channel state information. Our\nnumerical evaluation shows that with a higher percentage of active devices, the\nDNN-MUD achieves a significantly increased probability of detection compared to\nthe conventional approaches.",
    "descriptor": "\nComments: Accepted for 2021 IEEE 32nd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)-Workshop\n",
    "authors": [
      "Thushan Sivalingam",
      "Samad Ali",
      "Nurul Huda Mahmood",
      "Nandana Rajatheva",
      "Matti Latva-Aho"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.11204"
  },
  {
    "id": "arXiv:2106.11208",
    "title": "Temporal Early Exits for Efficient Video Object Detection",
    "abstract": "Transferring image-based object detectors to the domain of video remains\nchallenging under resource constraints. Previous efforts utilised optical flow\nto allow unchanged features to be propagated, however, the overhead is\nconsiderable when working with very slowly changing scenes from applications\nsuch as surveillance. In this paper, we propose temporal early exits to reduce\nthe computational complexity of per-frame video object detection. Multiple\ntemporal early exit modules with low computational overhead are inserted at\nearly layers of the backbone network to identify the semantic differences\nbetween consecutive frames. Full computation is only required if the frame is\nidentified as having a semantic change to previous frames; otherwise, detection\nresults from previous frames are reused. Experiments on CDnet show that our\nmethod significantly reduces the computational complexity and execution of\nper-frame video object detection up to $34 \\times$ compared to existing methods\nwith an acceptable reduction of 2.2\\% in mAP.",
    "descriptor": "",
    "authors": [
      "Amin Sabet",
      "Jonathon Hare",
      "Bashir Al-Hashimi",
      "Geoff V. Merrett"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11208"
  },
  {
    "id": "arXiv:2106.11210",
    "title": "HFContractFuzzer: Fuzzing Hyperledger Fabric Smart Contracts for  Vulnerability Detection",
    "abstract": "With its unique advantages such as decentralization and immutability,\nblockchain technology has been widely used in various fields in recent years.\nThe smart contract running on the blockchain is also playing an increasingly\nimportant role in decentralized application scenarios. Therefore, the automatic\ndetection of security vulnerabilities in smart contracts has become an urgent\nproblem in the application of blockchain technology. Hyperledger Fabric is a\nsmart contract platform based on enterprise-level licensed distributed ledger\ntechnology. However, the research on the vulnerability detection technology of\nHyperledger Fabric smart contracts is still in its infancy. In this paper, we\npropose HFContractFuzzer, a method based on Fuzzing technology to detect\nHyperledger Fabric smart contracts, which combines a Fuzzing tool for golang\nnamed go-fuzz and smart contracts written by golang. We use HFContractFuzzer to\ndetect vulnerabilities in five contracts from typical sources and discover that\nfour of them have security vulnerabilities, proving the effectiveness of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Mengjie Ding",
      "Peiru Li",
      "Shanshan Li",
      "He Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.11210"
  },
  {
    "id": "arXiv:2106.11214",
    "title": "Improved Private and Secure Distributed (Batch) Matrix Multiplication",
    "abstract": "In this paper, we study the problem of distributed matrix multiplication\nunder various scenarios. Specifically, we focus on a scenario where a user has\ntwo matrices A and B and wishes to compute their product with the assistance of\nseveral distributed colluding servers, which is referred to as secure\ndistributed matrix multiplication (SDMM). Meanwhile, we also consider its\ngeneralization by assuming that the user has two matrix batches, which is\nreferred to as secure distributed batch matrix multiplication (SDBMM) or\ndistributed batch matrix multiplication (DBMM) if the distributed servers are\nincurious. In a variant of this problem, we consider the problem of private and\nsecure distributed matrix multiplication (PSDMM), where a user having a private\nmatrix A and N non-colluding servers sharing a library of L (L>1) matrices\n$B^{(0)}, B^{(1)},...,B^{(L-1)}$, for which the user wishes to compute\n$AB^{(\\theta)}$ for some $\\theta\\in [0, L)$ without revealing any information\nof the matrix A to the servers, and keeping the index $\\theta$ private to the\nservers. Distributed matrix multiplication under these scenarios is supposed to\nhave wide application potentials, such as machine learning and cloud computing.\nHowever, studies of distributed matrix multiplication are still scarce in the\nliterature and there is much room for improvement. In this paper, we propose\nseveral new coding schemes for the various distributed matrix multiplication\nmodels, including two classes of SDMM codes, a DBMM code, an SDBMM code, and\nfinally a PSDMM code. The proposed codes have a better performance than\nstate-of-the-art schemes in that they can achieve a smaller recovery threshold\nand download cost as well as providing a more flexible tradeoff between the\nupload and download costs.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Jie Li",
      "Camilla Hollanti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11214"
  },
  {
    "id": "arXiv:2106.11218",
    "title": "Data Optimisation for a Deep Learning Recommender System",
    "abstract": "This paper advocates privacy preserving requirements on collection of user\ndata for recommender systems. The purpose of our study is twofold. First, we\nask if restrictions on data collection will hurt test quality of RNN-based\nrecommendations. We study how validation performance depends on the available\namount of training data. We use a combination of top-K accuracy, catalog\ncoverage and novelty for this purpose, since good recommendations for the user\nis not necessarily captured by a traditional accuracy metric. Second, we ask if\nwe can improve the quality under minimal data by using secondary data sources.\nWe propose knowledge transfer for this purpose and construct a representation\nto measure similarities between purchase behaviour in data. This to make\nqualified judgements of which source domain will contribute the most. Our\nresults show that (i) there is a saturation in test performance when training\nsize is increased above a critical point. We also discuss the interplay between\ndifferent performance metrics, and properties of data. Moreover, we demonstrate\nthat (ii) our representation is meaningful for measuring purchase behaviour. In\nparticular, results show that we can leverage secondary data to improve\nvalidation performance if we select a relevant source domain according to our\nsimilarly measure.",
    "descriptor": "",
    "authors": [
      "Gustav Hertz",
      "Sandhya Sachidanandan",
      "Bal\u00e1zs T\u00f3th",
      "Emil S. J\u00f8rgensen",
      "Martin Tegn\u00e9r"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11218"
  },
  {
    "id": "arXiv:2106.11220",
    "title": "Corruption Robust Active Learning",
    "abstract": "We conduct theoretical studies on streaming-based active learning for binary\nclassification under unknown adversarial label corruptions. In this setting,\nevery time before the learner observes a sample, the adversary decides whether\nto corrupt the label or not. First, we show that, in a benign corruption\nsetting (which includes the misspecification setting as a special case), with a\nslight enlargement on the hypothesis elimination threshold, the classical\nRobustCAL framework can (surprisingly) achieve nearly the same label complexity\nguarantee as in the non-corrupted setting. However, this algorithm can fail in\nthe general corruption setting. To resolve this drawback, we propose a new\nalgorithm which is provably correct without any assumptions on the presence of\ncorruptions. Furthermore, this algorithm enjoys the minimax label complexity in\nthe non-corrupted setting (which is achieved by RobustCAL) and only requires\n$\\tilde{\\mathcal{O}}(C_{\\mathrm{total}})$ additional labels in the corrupted\nsetting to achieve $\\mathcal{O}(\\varepsilon + \\frac{C_{\\mathrm{total}}}{n})$,\nwhere $\\varepsilon$ is the target accuracy, $C_{\\mathrm{total}}$ is the total\nnumber of corruptions and $n$ is the total number of unlabeled samples.",
    "descriptor": "",
    "authors": [
      "Yifang Chen",
      "Simon S. Du",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11220"
  },
  {
    "id": "arXiv:2106.11227",
    "title": "FauxWard: A Graph Neural Network Approach to Fauxtography Detection  Using Social Media Comments",
    "abstract": "Online social media has been a popular source for people to consume and share\nnews content. More recently, the spread of misinformation online has caused\nwidespread concerns. In this work, we focus on a critical task of detecting\nfauxtography on social media where the image and associated text together\nconvey misleading information. Many efforts have been made to mitigate\nmisinformation online, but we found that the fauxtography problem has not been\nfully addressed by existing work. Solutions focusing on detecting fake images\nor misinformed texts alone on social media often fail to identify the\nmisinformation delivered together by the image and the associated text of a\nfauxtography post. In this paper, we develop FauxWard, a novel graph\nconvolutional neural network framework that explicitly explores the complex\ninformation extracted from a user comment network of a social media post to\neffectively identify fauxtography. FauxWard is content-free in the sense that\nit does not analyze the visual or textual contents of the post itself, which\nmakes it robust against sophisticated fauxtography uploaders who intentionally\ncraft image-centric posts by editing either the text or image content. We\nevaluate FauxWard on two real-world datasets collected from mainstream social\nmedia platforms (i.e., Reddit and Twitter). The results show that FauxWard is\nboth effective and efficient in identifying fauxtography posts on social media.",
    "descriptor": "",
    "authors": [
      "Lanyu Shang",
      "Yang Zhang",
      "Daniel Zhang",
      "Dong Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.11227"
  },
  {
    "id": "arXiv:2106.11229",
    "title": "AOMD: An Analogy-aware Approach to Offensive Meme Detection on Social  Media",
    "abstract": "This paper focuses on an important problem of detecting offensive analogy\nmeme on online social media where the visual content and the texts/captions of\nthe meme together make an analogy to convey the offensive information. Existing\noffensive meme detection solutions often ignore the implicit relation between\nthe visual and textual contents of the meme and are insufficient to identify\nthe offensive analogy memes. Two important challenges exist in accurately\ndetecting the offensive analogy memes: i) it is not trivial to capture the\nanalogy that is often implicitly conveyed by a meme; ii) it is also challenging\nto effectively align the complex analogy across different data modalities in a\nmeme. To address the above challenges, we develop a deep learning based\nAnalogy-aware Offensive Meme Detection (AOMD) framework to learn the implicit\nanalogy from the multi-modal contents of the meme and effectively detect\noffensive analogy memes. We evaluate AOMD on two real-world datasets from\nonline social media. Evaluation results show that AOMD achieves significant\nperformance gains compared to state-of-the-art baselines by detecting offensive\nanalogy memes more accurately.",
    "descriptor": "",
    "authors": [
      "Lanyu Shang",
      "Yang Zhang",
      "Yuheng Zha",
      "Yingxi Chen",
      "Christina Youn",
      "Dong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11229"
  },
  {
    "id": "arXiv:2106.11230",
    "title": "Can contrastive learning avoid shortcut solutions?",
    "abstract": "The generalization of representations learned via contrastive learning\ndepends crucially on what features of the data are extracted. However, we\nobserve that the contrastive loss does not always sufficiently guide which\nfeatures are extracted, a behavior that can negatively impact the performance\non downstream tasks via \"shortcuts\", i.e., by inadvertently suppressing\nimportant predictive features. We find that feature extraction is influenced by\nthe difficulty of the so-called instance discrimination task (i.e., the task of\ndiscriminating pairs of similar points from pairs of dissimilar ones). Although\nharder pairs improve the representation of some features, the improvement comes\nat the cost of suppressing previously well represented features. In response,\nwe propose implicit feature modification (IFM), a method for altering positive\nand negative samples in order to guide contrastive models towards capturing a\nwider variety of predictive features. Empirically, we observe that IFM reduces\nfeature suppression, and as a result improves performance on vision and medical\nimaging tasks. The code is available at: \\url{https://github.com/joshr17/IFM}.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Joshua Robinson",
      "Li Sun",
      "Ke Yu",
      "Kayhan Batmanghelich",
      "Stefanie Jegelka",
      "Suvrit Sra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11230"
  },
  {
    "id": "arXiv:2106.11232",
    "title": "Multi-VAE: Learning Disentangled View-common and View-peculiar Visual  Representations for Multi-view Clustering",
    "abstract": "Multi-view clustering, a long-standing and important research problem,\nfocuses on mining complementary information from diverse views. However,\nexisting works often fuse multiple views' representations or handle clustering\nin a common feature space, which may result in their entanglement especially\nfor visual representations. To address this issue, we present a novel VAE-based\nmulti-view clustering framework (Multi-VAE) by learning disentangled visual\nrepresentations. Concretely, we define a view-common variable and multiple\nview-peculiar variables in the generative model. The prior of view-common\nvariable obeys approximately discrete Gumbel Softmax distribution, which is\nintroduced to extract the common cluster factor of multiple views. Meanwhile,\nthe prior of view-peculiar variable follows continuous Gaussian distribution,\nwhich is used to represent each view's peculiar visual factors. By controlling\nthe mutual information capacity to disentangle the view-common and\nview-peculiar representations, continuous visual information of multiple views\ncan be separated so that their common discrete cluster information can be\neffectively mined. Experimental results demonstrate that Multi-VAE enjoys the\ndisentangled and explainable visual representations, while obtaining superior\nclustering performance compared with state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Jie Xu",
      "Yazhou Ren",
      "Huayi Tang",
      "Xiaorong Pu",
      "Xiaofeng Zhu",
      "Ming Zeng",
      "Lifang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11232"
  },
  {
    "id": "arXiv:2106.11233",
    "title": "Affinity Mixup for Weakly Supervised Sound Event Detection",
    "abstract": "The weakly supervised sound event detection problem is the task of predicting\nthe presence of sound events and their corresponding starting and ending points\nin a weakly labeled dataset. A weak dataset associates each training sample (a\nshort recording) to one or more present sources. Networks that solely rely on\nconvolutional and recurrent layers cannot directly relate multiple frames in a\nrecording. Motivated by attention and graph neural networks, we introduce the\nconcept of an affinity mixup to incorporate time-level similarities and make a\nconnection between frames. This regularization technique mixes up features in\ndifferent layers using an adaptive affinity matrix. Our proposed affinity mixup\nnetwork improves over state-of-the-art techniques event-F1 scores by $8.2\\%$.",
    "descriptor": "",
    "authors": [
      "Mohammad Rasool Izadi",
      "Robert Stevenson",
      "Laura N. Kloepper"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.11233"
  },
  {
    "id": "arXiv:2106.11234",
    "title": "A causal view on compositional data",
    "abstract": "Many scientific datasets are compositional in nature. Important examples\ninclude species abundances in ecology, rock compositions in geology, topic\ncompositions in large-scale text corpora, and sequencing count data in\nmolecular biology. Here, we provide a causal view on compositional data in an\ninstrumental variable setting where the composition acts as the cause.\nThroughout, we pay particular attention to the interpretation of compositional\ncauses from the viewpoint of interventions and crisply articulate potential\npitfalls for practitioners. Focusing on modern high-dimensional microbiome\nsequencing data as a timely illustrative use case, our analysis first reveals\nthat popular one-dimensional information-theoretic summary statistics, such as\ndiversity and richness, may be insufficient for drawing causal conclusions from\necological data. Instead, we advocate for multivariate alternatives using\nstatistical data transformations and regression techniques that take the\nspecial structure of the compositional sample space into account. In a\ncomparative analysis on synthetic and semi-synthetic data we show the\nadvantages and limitations of our proposal. We posit that our framework may\nprovide a useful starting point for cause-effect estimation in the context of\ncompositional data.",
    "descriptor": "\nComments: Code available on this https URL\n",
    "authors": [
      "Elisabeth Ailer",
      "Christian L. M\u00fcller",
      "Niki Kilbertus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11234"
  },
  {
    "id": "arXiv:2106.11236",
    "title": "Can poachers find animals from public camera trap images?",
    "abstract": "To protect the location of camera trap data containing sensitive, high-target\nspecies, many ecologists randomly obfuscate the latitude and longitude of the\ncamera when publishing their data. For example, they may publish a random\nlocation within a 1km radius of the true camera location for each camera in\ntheir network. In this paper, we investigate the robustness of geo-obfuscation\nfor maintaining camera trap location privacy, and show via a case study that a\nfew simple, intuitive heuristics and publicly available satellite rasters can\nbe used to reduce the area likely to contain the camera by 87% (assuming random\nobfuscation within 1km), demonstrating that geo-obfuscation may be less\neffective than previously believed.",
    "descriptor": "\nComments: CV4Animals Workshop at CVPR 2021\n",
    "authors": [
      "Sara Beery",
      "Elizabeth Bondi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2106.11236"
  },
  {
    "id": "arXiv:2106.11239",
    "title": "Domain and Modality Gaps for LiDAR-based Person Detection on Mobile  Robots",
    "abstract": "Person detection is a crucial task for mobile robots navigating in\nhuman-populated environments and LiDAR sensors are promising for this task,\ngiven their accurate depth measurements and large field of view. This paper\nstudies existing LiDAR-based person detectors with a particular focus on mobile\nrobot scenarios (e.g. service robot or social robot), where persons are\nobserved more frequently and in much closer ranges, compared to the driving\nscenarios. We conduct a series of experiments, using the recently released\nJackRabbot dataset and the state-of-the-art detectors based on 3D or 2D LiDAR\nsensors (CenterPoint and DR-SPAAM respectively). These experiments revolve\naround the domain gap between driving and mobile robot scenarios, as well as\nthe modality gap between 3D and 2D LiDAR sensors. For the domain gap, we aim to\nunderstand if detectors pretrained on driving datasets can achieve good\nperformance on the mobile robot scenarios, for which there are currently no\ntrained models readily available. For the modality gap, we compare detectors\nthat use 3D or 2D LiDAR, from various aspects, including performance, runtime,\nlocalization accuracy, robustness to range and crowdedness. The results from\nour experiments provide practical insights into LiDAR-based person detection\nand facilitate informed decisions for relevant mobile robot designs and\napplications.",
    "descriptor": "",
    "authors": [
      "Dan Jia",
      "Alexander Hermans",
      "Bastian Leibe"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11239"
  },
  {
    "id": "arXiv:2106.11240",
    "title": "Reliability and Validity of Image-Based and Self-Reported Skin Phenotype  Metrics",
    "abstract": "With increasing adoption of face recognition systems, it is important to\nensure adequate performance of these technologies across demographic groups.\nRecently, phenotypes such as skin-tone, have been proposed as superior\nalternatives to traditional race categories when exploring performance\ndifferentials. However, there is little consensus regarding how to\nappropriately measure skin-tone in evaluations of biometric performance or in\nAI more broadly. In this study, we explore the relationship between\nface-area-lightness-measures (FALMs) estimated from images and ground-truth\nskin readings collected using a device designed to measure human skin. FALMs\nestimated from different images of the same individual varied significantly\nrelative to ground-truth FALM. This variation was only reduced by greater\ncontrol of acquisition (camera, background, and environment). Next, we compare\nground-truth FALM to Fitzpatrick Skin Types (FST) categories obtained using the\nstandard, in-person, medical survey and show FST is poorly predictive of\nskin-tone. Finally, we show how noisy estimation of FALM leads to errors\nselecting explanatory factors for demographic differentials. These results\ndemonstrate that measures of skin-tone for biometric performance evaluations\nmust come from objective, characterized, and controlled sources. Further,\ndespite this being a currently practiced approach, estimating FST categories\nand FALMs from uncontrolled imagery does not provide an appropriate measure of\nskin-tone.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "John J. Howard",
      "Yevgeniy B. Sirotin",
      "Jerry L. Tipton",
      "Arun R. Vemury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.11240"
  },
  {
    "id": "arXiv:2106.11248",
    "title": "Alignment Problems With Current Forecasting Platforms",
    "abstract": "We present alignment problems in current forecasting platforms, such as Good\nJudgment Open, CSET-Foretell or Metaculus. We classify those problems as either\nreward specification problems or principal-agent problems, and we propose\nsolutions. For instance, the scoring rule used by Good Judgment Open is not\nproper, and Metaculus tournaments disincentivize sharing information and\nincentivize distorting one's true probabilities to maximize the chances of\nplacing in the top few positions which earn a monetary reward. We also point\nout some partial similarities between the problem of aligning forecasters and\nthe problem of aligning artificial intelligence systems.",
    "descriptor": "\nComments: 39 pages, 13 figures\n",
    "authors": [
      "Nu\u00f1o Sempere",
      "Alex Lawsen"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.11248"
  },
  {
    "id": "arXiv:2106.11250",
    "title": "VIMPAC: Video Pre-Training via Masked Token Prediction and Contrastive  Learning",
    "abstract": "Video understanding relies on perceiving the global content and modeling its\ninternal connections (e.g., causality, movement, and spatio-temporal\ncorrespondence). To learn these interactions, we apply a mask-then-predict\npre-training task on discretized video tokens generated via VQ-VAE. Unlike\nlanguage, where the text tokens are more independent, neighboring video tokens\ntypically have strong correlations (e.g., consecutive video frames usually look\nvery similar), and hence uniformly masking individual tokens will make the task\ntoo trivial to learn useful representations. To deal with this issue, we\npropose a block-wise masking strategy where we mask neighboring video tokens in\nboth spatial and temporal domains. We also add an augmentation-free contrastive\nlearning method to further capture the global content by predicting whether the\nvideo clips are sampled from the same video. We pre-train our model on\nuncurated videos and show that our pre-trained model can reach state-of-the-art\nresults on several video understanding datasets (e.g., SSV2, Diving48). Lastly,\nwe provide detailed analyses on model scalability and pre-training method\ndesign. Code is released at https://github.com/airsplay/vimpac.",
    "descriptor": "\nComments: Under review, 23 Pages\n",
    "authors": [
      "Hao Tan",
      "Jie Lei",
      "Thomas Wolf",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11250"
  },
  {
    "id": "arXiv:2106.11251",
    "title": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
    "abstract": "Pseudo-relevance feedback mechanisms, from Rocchio to the relevance models,\nhave shown the usefulness of expanding and reweighting the users' initial\nqueries using information occurring in an initial set of retrieved documents,\nknown as the pseudo-relevant set. Recently, dense retrieval -- through the use\nof neural contextual language models such as BERT for analysing the documents'\nand queries' contents and computing their relevance scores -- has shown a\npromising performance on several information retrieval tasks still relying on\nthe traditional inverted index for identifying documents relevant to a query.\nTwo different dense retrieval families have emerged: the use of single embedded\nrepresentations for each passage and query (e.g. using BERT's [CLS] token), or\nvia multiple representations (e.g. using an embedding for each token of the\nquery and document). In this work, we conduct the first study into the\npotential for multiple representation dense retrieval to be enhanced using\npseudo-relevance feedback. In particular, based on the pseudo-relevant set of\ndocuments identified using a first-pass dense retrieval, we extract\nrepresentative feedback embeddings - while ensuring that these embeddings\ndiscriminate among passages -- which are then added to the query\nrepresentation. These additional feedback embeddings are shown to both enhance\nthe effectiveness of a reranking as well as an additional dense retrieval\noperation. Indeed, experiments on the MSMARCO passage ranking dataset show that\nMAP can be improved by upto 26% on the TREC 2019 query set and 10% on the TREC\n2020 query set by the application of our proposed ColBERT-PRF method on a\nColBERT dense retrieval approach.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Xiao Wang",
      "Craig Macdonald",
      "Nicola Tonellotto",
      "Iadh Ounis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.11251"
  },
  {
    "id": "arXiv:2106.11253",
    "title": "Applying VertexShuffle Toward 360-Degree Video Super-Resolution on  Focused-Icosahedral-Mesh",
    "abstract": "With the emerging of 360-degree image/video, augmented reality (AR) and\nvirtual reality (VR), the demand for analysing and processing spherical signals\nget tremendous increase. However, plenty of effort paid on planar signals that\nprojected from spherical signals, which leading to some problems, e.g. waste of\npixels, distortion. Recent advances in spherical CNN have opened up the\npossibility of directly analysing spherical signals. However, they pay\nattention to the full mesh which makes it infeasible to deal with situations in\nreal-world application due to the extremely large bandwidth requirement. To\naddress the bandwidth waste problem associated with 360-degree video streaming\nand save computation, we exploit Focused Icosahedral Mesh to represent a small\narea and construct matrices to rotate spherical content to the focused mesh\narea. We also proposed a novel VertexShuffle operation that can significantly\nimprove both the performance and the efficiency compared to the original\nMeshConv Transpose operation introduced in UGSCNN. We further apply our\nproposed methods on super resolution model, which is the first to propose a\nspherical super-resolution model that directly operates on a mesh\nrepresentation of spherical pixels of 360-degree data. To evaluate our model,\nwe also collect a set of high-resolution 360-degree videos to generate a\nspherical image dataset. Our experiments indicate that our proposed spherical\nsuper-resolution model achieves significant benefits in terms of both\nperformance and inference time compared to the baseline spherical\nsuper-resolution model that uses the simple MeshConv Transpose operation. In\nsummary, our model achieves great super-resolution performance on 360-degree\ninputs, achieving 32.79 dB PSNR on average when super-resoluting 16x vertices\non the mesh.",
    "descriptor": "\nComments: This paper introduce a new mesh representation and a new upsampling method on a mesh\n",
    "authors": [
      "Na Li",
      "Yao Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.11253"
  },
  {
    "id": "arXiv:2106.11256",
    "title": "A Well Balanced Reconstruction with Bounded Velocities and  Low-Oscillation Slow Shocks for the Shallow Water Equations",
    "abstract": "Many numerical schemes for hyperbolic systems require a piecewise polynomial\nreconstruction of the cell averaged values, and to simulate perturbed steady\nstates accurately we require a so called 'well balanced' reconstruction scheme.\nFor the shallow water system this involves reconstructing in surface elevation,\nto which modifications must be made as the fluid depth becomes small to ensure\npositivity.\nWe investigate the scheme proposed in Skevington (2021) though numerical\nexperiments, demonstrating its ability to resolve steady and near steady states\nat high accuracy. We also present a modification to the scheme which enables\nthe resolution of slowly moving shocks and dam break problems without\ncompromising the well balanced property.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Edward W. G. Skevington"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11256"
  },
  {
    "id": "arXiv:2106.11257",
    "title": "Secure Distributed Training at Scale",
    "abstract": "Some of the hardest problems in deep learning can be solved with the combined\neffort of many independent parties, as is the case for volunteer computing and\nfederated learning. These setups rely on high numbers of peers to provide\ncomputational resources or train on decentralized datasets. Unfortunately,\nparticipants in such systems are not always reliable. Any single participant\ncan jeopardize the entire training run by sending incorrect updates, whether\ndeliberately or by mistake. Training in presence of such peers requires\nspecialized distributed training algorithms with Byzantine tolerance. These\nalgorithms often sacrifice efficiency by introducing redundant communication or\npassing all updates through a trusted server. As a result, it can be infeasible\nto apply such algorithms to large-scale distributed deep learning, where models\ncan have billions of parameters. In this work, we propose a novel protocol for\nsecure (Byzantine-tolerant) decentralized training that emphasizes\ncommunication efficiency. We rigorously analyze this protocol: in particular,\nwe provide theoretical bounds for its resistance against Byzantine and Sybil\nattacks and show that it has a marginal communication overhead. To demonstrate\nits practical effectiveness, we conduct large-scale experiments on image\nclassification and language modeling in presence of Byzantine attackers.",
    "descriptor": "\nComments: 55 pages, 6 figures. Code: this https URL\n",
    "authors": [
      "Eduard Gorbunov",
      "Alexander Borzunov",
      "Michael Diskin",
      "Max Ryabinin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.11257"
  },
  {
    "id": "arXiv:2106.11258",
    "title": "A comparative study of model approximation methods applied to economic  MPC",
    "abstract": "Economic model predictive control (EMPC) has attracted significant attention\nin recent years and is recognized as a promising advanced process control\nmethod for the next generation smart manufacturing. It can lead to improving\neconomic performance but at the same time increases the computational\ncomplexity significantly. Model approximation has been a standard approach for\nreducing computational complexity in process control. In this work, we perform\na study on three types of representative model approximation methods applied to\nEMPC, including model reduction based on available first-principle models\n(e.g., proper orthogonal decomposition), system identification based on\ninput-output data (e.g., subspace identification) that results in an explicitly\nexpressed mathematical model, and neural networks based on input-output data. A\nrepresentative algorithm from each model approximation method is considered.\nTwo processes that are very different in dynamic nature and complexity were\nselected as benchmark processes for computational complexity and economic\nperformance comparison, namely an alkylation process and a wastewater treatment\nplant (WWTP). The strengths and drawbacks of each method are summarized\naccording to the simulation results, with future research direction regarding\ncontrol oriented model approximation proposed at the end.",
    "descriptor": "",
    "authors": [
      "Zhiyinan Huang",
      "Qinyao Liu",
      "Jinfeng Liu",
      "Biao Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.11258"
  },
  {
    "id": "arXiv:2106.11262",
    "title": "The implementation of a broad class of boundary conditions for  non-linear hyperbolic systems",
    "abstract": "We propose methods that augment existing numerical schemes for the simulation\nof hyperbolic balance laws with Dirichlet boundary conditions to allow for the\nsimulation of a broad class of differential algebraic conditions. Our approach\nis similar to that of Thompson (1987), where the boundary values were simulated\nby combining characteristic equations with the time derivative of the algebraic\nconditions, but differs in two important regards. Firstly, when the boundary is\na characteristic of one of the fields Thompson's method can fail to produce\nreasonable values. We propose a method of combining the characteristic\nequations with extrapolation which ensures convergence. Secondly, the\napplication of algebraic conditions can suffer from $O(1)$ drift-off error, and\nwe discuss projective time-stepping algorithms designed to converge for this\ntype of system. Test problems for the shallow water equations are presented to\ndemonstrate the result of simulating with and without the modifications\ndiscussed, illustrating their necessity for certain problems.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Edward W. G. Skevington"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11262"
  },
  {
    "id": "arXiv:2106.11264",
    "title": "Compositional Federated Learning: Applications in Distributionally  Robust Averaging and Meta Learning",
    "abstract": "In the paper, we propose an effective and efficient Compositional Federated\nLearning (ComFedL) algorithm for solving a new compositional Federated Learning\n(FL) framework, which frequently appears in many machine learning problems with\na hierarchical structure such as distributionally robust federated learning and\nmodel-agnostic meta learning (MAML). Moreover, we study the convergence\nanalysis of our ComFedL algorithm under some mild conditions, and prove that it\nachieves a fast convergence rate of $O(\\frac{1}{\\sqrt{T}})$, where $T$ denotes\nthe number of iteration. To the best of our knowledge, our algorithm is the\nfirst work to bridge federated learning with composition stochastic\noptimization. In particular, we first transform the distributionally robust FL\n(i.e., a minimax optimization problem) into a simple composition optimization\nproblem by using KL divergence regularization. At the same time, we also first\ntransform the distribution-agnostic MAML problem (i.e., a minimax optimization\nproblem) into a simple composition optimization problem. Finally, we apply two\npopular machine learning tasks, i.e., distributionally robust FL and MAML to\ndemonstrate the effectiveness of our algorithm.",
    "descriptor": "\nComments: 21 pages, 8 figures\n",
    "authors": [
      "Feihu Huang",
      "Junyi Li",
      "Heng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.11264"
  },
  {
    "id": "arXiv:2106.11266",
    "title": "PHYSFRAME: Type Checking Physical Frames of Reference for Robotic  Systems",
    "abstract": "A robotic system continuously measures its own motions and the external world\nduring operation. Such measurements are with respect to some frame of\nreference, i.e., a coordinate system. A nontrivial robotic system has a large\nnumber of different frames and data have to be translated back-and-forth from a\nframe to another. The onus is on the developers to get such translation right.\nHowever, this is very challenging and error-prone, evidenced by the large\nnumber of questions and issues related to frame uses on developers' forum.\nSince any state variable can be associated with some frame, reference frames\ncan be naturally modeled as variable types. We hence develop a novel type\nsystem that can automatically infer variables' frame types and in turn detect\nany type inconsistencies and violations of frame conventions. The evaluation on\na set of 180 publicly available ROS projects shows that our system can detect\n190 inconsistencies with 154 true positives. We reported 52 to developers and\nreceived 18 responses so far, with 15 fixed/acknowledged. Our technique also\nfinds 45 violations of common practices.",
    "descriptor": "",
    "authors": [
      "Sayali Kate",
      "Michael Chinn",
      "Hongjun Choi",
      "Xiangyu Zhang",
      "Sebastian Elbaum"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.11266"
  },
  {
    "id": "arXiv:2106.11272",
    "title": "Neural Marching Cubes",
    "abstract": "We introduce Neural Marching Cubes (NMC), a data-driven approach for\nextracting a triangle mesh from a discretized implicit field. Classical MC is\ndefined by coarse tessellation templates isolated to individual cubes. While\nmore refined tessellations have been proposed, they all make heuristic\nassumptions, such as trilinearity, when determining the vertex positions and\nlocal mesh topologies in each cube. In principle, none of these approaches can\nreconstruct geometric features that reveal coherence or dependencies between\nnearby cubes (e.g., a sharp edge), as such information is unaccounted for,\nresulting in poor estimates of the true underlying implicit field. To tackle\nthese challenges, we re-cast MC from a deep learning perspective, by designing\ntessellation templates more apt at preserving geometric features, and learning\nthe vertex positions and mesh topologies from training meshes, to account for\ncontextual information from nearby cubes. We develop a compact per-cube\nparameterization to represent the output triangle mesh, while being compatible\nwith neural processing, so that a simple 3D convolutional network can be\nemployed for the training. We show that all topological cases in each cube that\nare applicable to our design can be easily derived using our representation,\nand the resulting tessellations can also be obtained naturally and efficiently\nby following a few design guidelines. In addition, our network learns local\nfeatures with limited receptive fields, hence it generalizes well to new shapes\nand new datasets. We evaluate our neural MC approach by quantitative and\nqualitative comparisons to all well-known MC variants. In particular, we\ndemonstrate the ability of our network to recover sharp features such as edges\nand corners, a long-standing issue of MC and its variants. Our network also\nreconstructs local mesh topologies more accurately than previous approaches.",
    "descriptor": "",
    "authors": [
      "Zhiqin Chen",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11272"
  },
  {
    "id": "arXiv:2106.11273",
    "title": "A well-balanced reconstruction with bounded velocities for the shallow  water equations by convex combination",
    "abstract": "Finite volume schemes for hyperbolic balance laws require a piecewise\npolynomial reconstruction of the cell averaged values, and a reconstruction is\ntermed `well-balanced' if it is able to simulate steady states at higher order\nthan time evolving states. For the shallow water system this involves\nreconstructing in surface elevation, to which modifications must be made as the\nfluid depth becomes small to ensure positivity, and for many reconstruction\nschemes a modification of the inertial field is also required to ensure the\nvelocities are bounded.\nWe propose here a reconstruction based on a convex combination of surface and\ndepth reconstructions which ensures that the depth increases with the cell\naverage depth. We also discuss how, for cells that are much shallower than\ntheir neighbours, reducing the variation in the reconstructed flux yields\nbounds on the velocities. This approach is generalisable to high order schemes,\nproblems in multiple spacial dimensions, and to more complicated systems of\nequations. We present reconstructions and associated technical results for\nthree systems, the standard shallow water equations, shallow water in a channel\nof varying width, and a shallow water model of a particle driven current.\nPositivity preserving time stepping is also discussed.",
    "descriptor": "\nComments: 16 page main text, 11 page supplemental information\n",
    "authors": [
      "Edward W. G. Skevington"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11273"
  },
  {
    "id": "arXiv:2106.11277",
    "title": "Attention-based Neural Network for Driving Environment Complexity  Perception",
    "abstract": "Environment perception is crucial for autonomous vehicle (AV) safety. Most\nexisting AV perception algorithms have not studied the surrounding environment\ncomplexity and failed to include the environment complexity parameter. This\npaper proposes a novel attention-based neural network model to predict the\ncomplexity level of the surrounding driving environment. The proposed model\ntakes naturalistic driving videos and corresponding vehicle dynamics parameters\nas input. It consists of a Yolo-v3 object detection algorithm, a heat map\ngeneration algorithm, CNN-based feature extractors, and attention-based feature\nextractors for both video and time-series vehicle dynamics data inputs to\nextract features. The output from the proposed algorithm is a surrounding\nenvironment complexity parameter. The Berkeley DeepDrive dataset (BDD Dataset)\nand subjectively labeled surrounding environment complexity levels are used for\nmodel training and validation to evaluate the algorithm. The proposed\nattention-based network achieves 91.22% average classification accuracy to\nclassify the surrounding environment complexity. It proves that the environment\ncomplexity level can be accurately predicted and applied for future AVs'\nenvironment perception studies.",
    "descriptor": "\nComments: Accepted by 2021 IEEE Intelligent Transportation Systems Conference\n",
    "authors": [
      "Ce Zhang",
      "Azim Eskandarian",
      "Xuelai Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.11277"
  },
  {
    "id": "arXiv:2106.11280",
    "title": "The Arm-Swing Is Discriminative in Video Gait Recognition for Athlete  Re-Identification",
    "abstract": "In this paper we evaluate running gait as an attribute for video person\nre-identification in a long-distance running event. We show that running gait\nrecognition achieves competitive performance compared to appearance-based\napproaches in the cross-camera retrieval task and that gait and appearance\nfeatures are complementary to each other. For gait, the arm swing during\nrunning is less distinguishable when using binary gait silhouettes, due to\nambiguity in the torso region. We propose to use human semantic parsing to\ncreate partial gait silhouettes where the torso is left out. Leaving out the\ntorso improves recognition results by allowing the arm swing to be more visible\nin the frontal and oblique viewing angles, which offers hints that arm swings\nare somewhat personal. Experiments show an increase of 3.2% mAP on the\nCampusRun and increased accuracy with 4.8% in the frontal and rear view on\nCASIA-B, compared to using the full body silhouettes.",
    "descriptor": "\nComments: ICIP 2021\n",
    "authors": [
      "Yapkan Choi",
      "Yeshwanth Napolean",
      "Jan C. van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11280"
  },
  {
    "id": "arXiv:2106.11292",
    "title": "A Discriminative Entity-Aware Language Model for Virtual Assistants",
    "abstract": "High-quality automatic speech recognition (ASR) is essential for virtual\nassistants (VAs) to work well. However, ASR often performs poorly on VA\nrequests containing named entities. In this work, we start from the observation\nthat many ASR errors on named entities are inconsistent with real-world\nknowledge. We extend previous discriminative n-gram language modeling\napproaches to incorporate real-world knowledge from a Knowledge Graph (KG),\nusing features that capture entity type-entity and entity-entity relationships.\nWe apply our model through an efficient lattice rescoring process, achieving\nrelative sentence error rate reductions of more than 25% on some synthesized\ntest sets covering less popular entities, with minimal degradation on a\nuniformly sampled VA test set.",
    "descriptor": "\nComments: To appear in Interspeech 2021\n",
    "authors": [
      "Mandana Saebi",
      "Ernest Pusateri",
      "Aaksha Meghawat",
      "Christophe Van Gysel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11292"
  },
  {
    "id": "arXiv:2106.11294",
    "title": "Smooth Sequential Optimisation with Delayed Feedback",
    "abstract": "Stochastic delays in feedback lead to unstable sequential learning using\nmulti-armed bandits. Recently, empirical Bayesian shrinkage has been shown to\nimprove reward estimation in bandit learning. Here, we propose a novel\nadaptation to shrinkage that estimates smoothed reward estimates from windowed\ncumulative inputs, to deal with incomplete knowledge from delayed feedback and\nnon-stationary rewards. Using numerical simulations, we show that this\nadaptation retains the benefits of shrinkage, and improves the stability of\nreward estimation by more than 50%. Our proposal reduces variability in\ntreatment allocations to the best arm by up to 3.8x, and improves statistical\naccuracy - with up to 8% improvement in true positive rates and 37% reduction\nin false positive rates. Together, these advantages enable control of the\ntrade-off between speed and stability of adaptation, and facilitate\nhuman-in-the-loop sequential optimisation.",
    "descriptor": "\nComments: Workshop on Bayesian causal inference for real world interactive systems, 27th SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2021)\n",
    "authors": [
      "Srivas Chennu",
      "Jamie Martin",
      "Puli Liyanagama",
      "Phil Mohr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11294"
  },
  {
    "id": "arXiv:2106.11297",
    "title": "TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?",
    "abstract": "In this paper, we introduce a novel visual representation learning which\nrelies on a handful of adaptively learned tokens, and which is applicable to\nboth image and video understanding tasks. Instead of relying on hand-designed\nsplitting strategies to obtain visual tokens and processing a large number of\ndensely sampled patches for attention, our approach learns to mine important\ntokens in visual data. This results in efficiently and effectively finding a\nfew important visual tokens and enables modeling of pairwise attention between\nsuch tokens, over a longer temporal horizon for videos, or the spatial content\nin images. Our experiments demonstrate strong performance on several\nchallenging benchmarks for both image and video recognition tasks. Importantly,\ndue to our tokens being adaptive, we accomplish competitive results at\nsignificantly reduced compute amount.",
    "descriptor": "",
    "authors": [
      "Michael S. Ryoo",
      "AJ Piergiovanni",
      "Anurag Arnab",
      "Mostafa Dehghani",
      "Anelia Angelova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11297"
  },
  {
    "id": "arXiv:2106.11299",
    "title": "Boundary Graph Neural Networks for 3D Simulations",
    "abstract": "The abundance of data has given machine learning huge momentum in natural\nsciences and engineering. However, the modeling of simulated physical processes\nremains difficult. A key problem in doing so is the correct handling of\ngeometric boundaries. While triangularized geometric boundaries are very common\nin engineering applications, they are notoriously difficult to model by machine\nlearning approaches due to their heterogeneity with respect to size and\norientation. In this work, we introduce Boundary Graph Neural Networks (BGNNs),\nwhich dynamically modify graph structures to address boundary conditions.\nBoundary graph structures are constructed via modifying edges, augmenting node\nfeatures, and dynamically inserting virtual nodes. The new BGNNs are tested on\ncomplex 3D granular flow processes of hoppers and rotating drums which are\nstandard parts of industrial machinery. Using precise simulations that are\nobtained by an expensive and complex discrete element method, BGNNs are\nevaluated in terms of computational efficiency as well as prediction accuracy\nof particle flows and mixing entropies. Even if complex boundaries are present,\nBGNNs are able to accurately reproduce 3D granular flows within simulation\nuncertainties over hundreds of thousands of simulation timesteps, and most\nnotably particles completely stay within the geometric objects without using\nhandcrafted conditions or restrictions.",
    "descriptor": "",
    "authors": [
      "Andreas Mayr",
      "Sebastian Lehner",
      "Arno Mayrhofer",
      "Christoph Kloss",
      "Sepp Hochreiter",
      "Johannes Brandstetter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11299"
  },
  {
    "id": "arXiv:2106.11303",
    "title": "Understanding Object Dynamics for Interactive Image-to-Video Synthesis",
    "abstract": "What would be the effect of locally poking a static scene? We present an\napproach that learns naturally-looking global articulations caused by a local\nmanipulation at a pixel level. Training requires only videos of moving objects\nbut no information of the underlying manipulation of the physical scene. Our\ngenerative model learns to infer natural object dynamics as a response to user\ninteraction and learns about the interrelations between different object body\nregions. Given a static image of an object and a local poking of a pixel, the\napproach then predicts how the object would deform over time. In contrast to\nexisting work on video prediction, we do not synthesize arbitrary realistic\nvideos but enable local interactive control of the deformation. Our model is\nnot restricted to particular object categories and can transfer dynamics onto\nnovel unseen object instances. Extensive experiments on diverse objects\ndemonstrate the effectiveness of our approach compared to common video\nprediction frameworks. Project page is available at https://bit.ly/3cxfA2L .",
    "descriptor": "\nComments: CVPR 2021, project page available at this https URL\n",
    "authors": [
      "Andreas Blattmann",
      "Timo Milbich",
      "Michael Dorkenwald",
      "Bj\u00f6rn Ommer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11303"
  },
  {
    "id": "arXiv:2106.11304",
    "title": "Simple Distillation Baselines for Improving Small Self-supervised Models",
    "abstract": "While large self-supervised models have rivalled the performance of their\nsupervised counterparts, small models still struggle. In this report, we\nexplore simple baselines for improving small self-supervised models via\ndistillation, called SimDis. Specifically, we present an offline-distillation\nbaseline, which establishes a new state-of-the-art, and an online-distillation\nbaseline, which achieves similar performance with minimal computational\noverhead. We hope these baselines will provide useful experience for relevant\nfuture research. Code is available at: https://github.com/JindongGu/SimDis/",
    "descriptor": "",
    "authors": [
      "Jindong Gu",
      "Wei Liu",
      "Yonglong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11304"
  },
  {
    "id": "arXiv:2106.11308",
    "title": "Fast Simultaneous Gravitational Alignment of Multiple Point Sets",
    "abstract": "The problem of simultaneous rigid alignment of multiple unordered point sets\nwhich is unbiased towards any of the inputs has recently attracted increasing\ninterest, and several reliable methods have been newly proposed. While being\nremarkably robust towards noise and clustered outliers, current approaches\nrequire sophisticated initialisation schemes and do not scale well to large\npoint sets. This paper proposes a new resilient technique for simultaneous\nregistration of multiple point sets by interpreting the latter as particle\nswarms rigidly moving in the mutually induced force fields. Thanks to the\nimproved simulation with altered physical laws and acceleration of globally\nmultiply-linked point interactions with a 2^D-tree (D is the space\ndimensionality), our Multi-Body Gravitational Approach (MBGA) is robust to\nnoise and missing data while supporting more massive point sets than previous\nmethods (with 10^5 points and more). In various experimental settings, MBGA is\nshown to outperform several baseline point set alignment approaches in terms of\naccuracy and runtime. We make our source code available for the community to\nfacilitate the reproducibility of the results.",
    "descriptor": "\nComments: Project webpage: this http URL\n",
    "authors": [
      "Vladislav Golyanik",
      "Soshi Shimada",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11308"
  },
  {
    "id": "arXiv:2106.11309",
    "title": "How Do Adam and Training Strategies Help BNNs Optimization?",
    "abstract": "The best performing Binary Neural Networks (BNNs) are usually attained using\nAdam optimization and its multi-step training variants. However, to the best of\nour knowledge, few studies explore the fundamental reasons why Adam is superior\nto other optimizers like SGD for BNN optimization or provide analytical\nexplanations that support specific training strategies. To address this, in\nthis paper we first investigate the trajectories of gradients and weights in\nBNNs during the training process. We show the regularization effect of\nsecond-order momentum in Adam is crucial to revitalize the weights that are\ndead due to the activation saturation in BNNs. We find that Adam, through its\nadaptive learning rate strategy, is better equipped to handle the rugged loss\nsurface of BNNs and reaches a better optimum with higher generalization\nability. Furthermore, we inspect the intriguing role of the real-valued weights\nin binary networks, and reveal the effect of weight decay on the stability and\nsluggishness of BNN optimization. Through extensive experiments and analysis,\nwe derive a simple training scheme, building on existing Adam-based\noptimization, which achieves 70.5% top-1 accuracy on the ImageNet dataset using\nthe same architecture as the state-of-the-art ReActNet while achieving 1.1%\nhigher accuracy. Code and models are available at\nhttps://github.com/liuzechun/AdamBNN.",
    "descriptor": "\nComments: ICML 2021. Code and models are available at this https URL\n",
    "authors": [
      "Zechun Liu",
      "Zhiqiang Shen",
      "Shichao Li",
      "Koen Helwegen",
      "Dong Huang",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11309"
  },
  {
    "id": "arXiv:2106.11310",
    "title": "Towards Long-Form Video Understanding",
    "abstract": "Our world offers a never-ending stream of visual stimuli, yet today's vision\nsystems only accurately recognize patterns within a few seconds. These systems\nunderstand the present, but fail to contextualize it in past or future events.\nIn this paper, we study long-form video understanding. We introduce a framework\nfor modeling long-form videos and develop evaluation protocols on large-scale\ndatasets. We show that existing state-of-the-art short-term models are limited\nfor long-form tasks. A novel object-centric transformer-based video recognition\narchitecture performs significantly better on 7 diverse tasks. It also\noutperforms comparable state-of-the-art on the AVA dataset.",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Chao-Yuan Wu",
      "Philipp Kr\u00e4henb\u00fchl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11310"
  },
  {
    "id": "arXiv:2007.10894",
    "title": "Optimizing Quantum Search with a Binomial Version of Grover's Algorithm",
    "abstract": "Amplitude Amplification -- a key component of Grover's Search algorithm --\nuses an iterative approach to systematically increase the probability of one or\nmultiple target states. We present novel strategies to enhance the\namplification procedure by partitioning the states into classes, whose\nprobabilities are increased at different levels before or during amplification.\nThe partitioning process is based on the binomial distribution. If the classes\nto which the search target states belong are known in advance, the number of\niterations in the Amplitude Amplification algorithm can be drastically reduced\ncompared to the standard version. In the more likely case in which the relevant\nclasses are not known in advance, their selection can be configured at run\ntime, or a random approach can be employed, similar to classical algorithms\nsuch as binary search. In particular, we apply this method in the context of\nour previously introduced Quantum Dictionary pattern, where keys and values are\nencoded in two separate registers, and the value-encoding method is independent\nof the type of superposition used in the key register. We consider this type of\nstructure to be the natural setup for search. We confirm the validity of our\nnew approach through experimental results obtained on real quantum hardware,\nthe Honeywell System Model H0 trapped-ion quantum computer.",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Austin Gilliam",
      "Marco Pistoia",
      "Constantin Gonciulea"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2007.10894"
  },
  {
    "id": "arXiv:2106.08609",
    "title": "Reinforcement learning for pursuit and evasion of microswimmers at low  Reynolds number",
    "abstract": "Aquatic organisms can use hydrodynamic cues to navigate, find their preys and\nescape from predators. We consider a model of two competing microswimmers\nengaged in a pursue-evasion task while immersed in a low-Reynolds-number\nenvironment. The players have limited abilities: they can only sense\nhydrodynamic disturbances, which provide some cue about the opponent's\nposition, and perform simple manoeuvres. The goal of the pursuer is to\ncapturethe evader in the shortest possible time. Conversely the evader aims at\ndeferring capture as much as possible. We show that by means of Reinforcement\nLearning the players find efficient and physically explainable strategies which\nnon-trivially exploit the hydrodynamic environment. This Letter offers a\nproof-of-concept for the use of Reinforcement Learning to discover\nprey-predator strategies in aquatic environments, with potential applications\nto underwater robotics.",
    "descriptor": "\nComments: 6 pages, 3 figures (Supplementary Material in ancillary directory)\n",
    "authors": [
      "Francesco Borra",
      "Luca Biferale",
      "Massimo Cencini",
      "Antonio Celani"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2106.08609"
  },
  {
    "id": "arXiv:2106.09897",
    "title": "LEO Satellite Constellations for 5G and Beyond: How Will They Reshape  Vertical Domains?",
    "abstract": "The rapid development of communication technologies in the past decades has\nprovided immense vertical opportunities for individuals and enterprises.\nHowever, conventional terrestrial cellular networks have unfortunately\nneglected the huge geographical digital divide, since high bandwidth wireless\ncoverage is concentrated to urban areas. To meet the goal of ``connecting the\nunconnected'', integrating low Earth orbit (LEO) satellites with the\nterrestrial cellular networks has been widely considered as a promising\nsolution. In this article, we first introduce the development roadmap of LEO\nsatellite constellations (SatCons), including early attempts in LEO satellites\nwith the emerging LEO constellations. Further, we discuss the unique\nopportunities of employing LEO SatCons for the delivery of integrating 5G\nnetworks. Specifically, we present their key performance indicators, which\noffer important guidelines for the design of associated enabling techniques,\nand then discuss the potential impact of integrating LEO SatCons with typical\n5G use cases, where we engrave our vision of various vertical domains reshaped\nby LEO SatCons. Technical challenges are finally provided to specify future\nresearch directions.",
    "descriptor": "\nComments: 4 figures, 1 table, accepted by Communications Magazine\n",
    "authors": [
      "Shicong Liu",
      "Zhen Gao",
      "Yongpeng Wu",
      "Derrick Wing Kwan Ng",
      "Xiqi Gao",
      "Kai-Kit Wong",
      "Symeon Chatzinotas",
      "Bjorn Ottersten"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.09897"
  },
  {
    "id": "arXiv:2106.10277",
    "title": "GPLA-12: An Acoustic Signal Dataset of Gas Pipeline Leakage",
    "abstract": "In this paper, we introduce a new acoustic leakage dataset of gas pipelines,\ncalled as GPLA-12, which has 12 categories over 684 training/testing acoustic\nsignals. Unlike massive image and voice datasets, there have relatively few\nacoustic signal datasets, especially for engineering fault detection. In order\nto enhance the development of fault diagnosis, we collect acoustic leakage\nsignals on the basis of an intact gas pipe system with external artificial\nleakages, and then preprocess the collected data with structured tailoring\nwhich are turned into GPLA-12. GPLA-12 dedicates to serve as a feature learning\ndataset for time-series tasks and classifications. To further understand the\ndataset, we train both shadow and deep learning algorithms to observe the\nperformance. The dataset as well as the pretrained models have been released at\nboth www.daip.club and github.com/Deep-AI-Application-DAIP",
    "descriptor": "",
    "authors": [
      "Jie Li",
      "Lizhong Yao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.10277"
  },
  {
    "id": "arXiv:2106.10314",
    "title": "Differentiable Particle Filtering without Modifying the Forward Pass",
    "abstract": "In recent years particle filters have being used as components in systems\noptimized end-to-end with gradient descent. However, the resampling step in a\nparticle filter is not differentiable, which biases gradients and interferes\nwith optimization. To remedy this problem, several differentiable variants of\nresampling have been proposed, all of which modify the behavior of the particle\nfilter in significant and potentially undesirable ways. In this paper, we show\nhow to obtain unbiased estimators of the gradient of the marginal likelihood by\nonly modifying messages used in backpropagation, leaving the standard forward\npass of a particle filter unchanged. Our method is simple to implement, has a\nlow computational overhead, does not introduce additional hyperparameters, and\nextends to derivatives of higher orders. We call it stop-gradient resampling,\nsince it can easily be implemented with automatic differentiation libraries\nusing the stop-gradient operator instead of explicitly modifying the backward\nmessages.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Adam \u015acibior",
      "Vaden Masrani",
      "Frank Wood"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10314"
  },
  {
    "id": "arXiv:2106.10329",
    "title": "Binary Optimal Control Of Single-Flux-Quantum Pulse Sequences",
    "abstract": "We introduce a binary, relaxed gradient, trust-region method for optimizing\npulse sequences for single flux quanta (SFQ) control of a quantum computer. The\npulse sequences are optimized with the goal of realizing unitary gate\ntransformations. Each pulse has a fixed amplitude and duration. We model this\nprocess as an binary optimal control problem, constrained by Schr\\\"{o}dinger's\nequation, where the binary variables indicate whether each pulse is on or off.\nWe introduce a first-order trust-region method, which takes advantage of a\nrelaxed gradient to determine an optimal pulse sequence that minimizes the gate\ninfidelity, while also suppressing leakage to higher energy levels. The\nproposed algorithm has a computational complexity of ${\\cal O}(p\\log(p)$, where\n$p$ is the number of pulses in the sequence. We present numerical results for\nthe H and X gates, where the optimized pulse sequences give gate fidelity's\nbetter than $99.9\\%$, in $\\approx 25$ trust-region iterations.",
    "descriptor": "",
    "authors": [
      "Ryan H. Vogt",
      "Anders Petersson"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10329"
  },
  {
    "id": "arXiv:2106.10338",
    "title": "Intersectional synergies: untangling irreducible effects of intersecting  identities via information decomposition",
    "abstract": "The idea of intersectionality has become a frequent topic of discussion both\nin academic sociology, as well as among popular movements for social justice\nsuch as Black Lives Matter, intersectional feminism, and LGBT rights.\nIntersectionality proposes that an individual's experience of society has\naspects that are irreducible to the sum of one's various identities considered\nindividually, but are \"greater than the sum of their parts.\" In this work, we\nshow that the effects of intersectional identities can be statistically\nobserved in empirical data using information theory. We show that, when\nconsidering the predictive relationship between various identities categories\nsuch as race, sex, and income (as a proxy for class) on outcomes such as health\nand wellness, robust statistical synergies appear. These synergies show that\nthere are joint-effects of identities on outcomes that are irreducible to any\nidentity considered individually and only appear when specific categories are\nconsidered together (for example, there is a large, synergistic effect of race\nand sex considered jointly on income irreducible to either race or sex). We\nthen show using synthetic data that the current gold-standard method of\nassessing intersectionalities in data (linear regression with multiplicative\ninteraction coefficients) fails to disambiguate between truly synergistic,\ngreater-than-the-sum-of-their-parts interactions, and redundant interactions.\nWe explore the significance of these two distinct types of interactions in the\ncontext of making inferences about intersectional relationships in data and the\nimportance of being able to reliably differentiate the two. Finally, we\nconclude that information theory, as a model-free framework sensitive to\nnonlinearities and synergies in data, is a natural method by which to explore\nthe space of higher-order social dynamics.",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Thomas F. Varley"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.10338"
  },
  {
    "id": "arXiv:2106.10345",
    "title": "High Relative Degree Control Barrier Functions Under Input Constraints",
    "abstract": "This paper presents methodologies for ensuring forward invariance of sublevel\nsets of constraint functions with high-relative-degree with respect to the\nsystem dynamics and in the presence of input constraints. We show that such\nconstraint functions can be converted into special Zeroing Control Barrier\nFunctions (ZCBFs), which, by construction, generate sufficient conditions for\nrendering the state always inside a sublevel set of the constraint function in\nthe presence of input constraints. We present a general form for one such ZCBF,\nas well as a special case applicable to a specific class of systems. We\nconclude with a comparison of system trajectories under the two ZCBFs developed\nand prior literature, and a case study for an asteroid observation problem\nusing quadratic-program based controllers to enforce the ZCBF condition.",
    "descriptor": "\nComments: Submitted to 2021 Conference on Decision and Control, under review\n",
    "authors": [
      "Joseph Breeden",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10345"
  },
  {
    "id": "arXiv:2106.10356",
    "title": "Liquid Sensing Using WiFi Signals",
    "abstract": "The popularity of Internet-of-Things (IoT) has provided us with unprecedented\nopportunities to enable a variety of emerging services in a smart home\nenvironment. Among those services, sensing the liquid level in a container is\ncritical to building many smart home and mobile healthcare applications that\nimprove the quality of life. This paper presents LiquidSense, a liquid-level\nsensing system that is low-cost, high accuracy, widely applicable to different\ndaily liquids and containers, and can be easily integrated with existing smart\nhome networks. LiquidSense uses an existing home WiFi network and a low-cost\ntransducer that attached to the container to sense the resonance of the\ncontainer for liquid level detection. In particular, our system mounts a\nlow-cost transducer on the surface of the container and emits a well-designed\nchirp signal to make the container resonant, which introduces subtle changes to\nthe home WiFi signals. By analyzing the subtle phase changes of the WiFi\nsignals, LiquidSense extracts the resonance frequency as a feature for liquid\nlevel detection. Our system constructs prediction models for both continuous\nand discrete predictions using curve fitting and SVM respectively. We evaluate\nLiquidSense in home environments with containers of three different materials\nand six types of liquids. Results show that LiquidSense achieves an overall\naccuracy of 97% for continuous prediction and an overall F-score of 0.968 for\ndiscrete prediction. Results also show that our system has a large coverage in\na home environment and works well under non-line-of-sight (NLOS) scenarios.",
    "descriptor": "",
    "authors": [
      "Yili Ren",
      "Jie Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10356"
  },
  {
    "id": "arXiv:2106.10359",
    "title": "Direct Reconstruction of Linear Parametric Images from Dynamic PET Using  Nonlocal Deep Image Prior",
    "abstract": "Direct reconstruction methods have been developed to estimate parametric\nimages directly from the measured PET sinograms by combining the PET imaging\nmodel and tracer kinetics in an integrated framework. Due to limited counts\nreceived, signal-to-noise-ratio (SNR) and resolution of parametric images\nproduced by direct reconstruction frameworks are still limited. Recently\nsupervised deep learning methods have been successfully applied to medical\nimaging denoising/reconstruction when large number of high-quality training\nlabels are available. For static PET imaging, high-quality training labels can\nbe acquired by extending the scanning time. However, this is not feasible for\ndynamic PET imaging, where the scanning time is already long enough. In this\nwork, we proposed an unsupervised deep learning framework for direct parametric\nreconstruction from dynamic PET, which was tested on the Patlak model and the\nrelative equilibrium Logan model. The patient's anatomical prior image, which\nis readily available from PET/CT or PET/MR scans, was supplied as the network\ninput to provide a manifold constraint, and also utilized to construct a kernel\nlayer to perform non-local feature denoising. The linear kinetic model was\nembedded in the network structure as a 1x1 convolution layer. The training\nobjective function was based on the PET statistical model. Evaluations based on\ndynamic datasets of 18F-FDG and 11C-PiB tracers show that the proposed\nframework can outperform the traditional and the kernel method-based direct\nreconstruction methods.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Kuang Gong",
      "Ciprian Catana",
      "Jinyi Qi",
      "Quanzheng Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10359"
  },
  {
    "id": "arXiv:2106.10370",
    "title": "On the benefits of maximum likelihood estimation for Regression and  Forecasting",
    "abstract": "We advocate for a practical Maximum Likelihood Estimation (MLE) approach for\nregression and forecasting, as an alternative to the typical approach of\nEmpirical Risk Minimization (ERM) for a specific target metric. This approach\nis better suited to capture inductive biases such as prior domain knowledge in\ndatasets, and can output post-hoc estimators at inference time that can\noptimize different types of target metrics. We present theoretical results to\ndemonstrate that our approach is always competitive with any estimator for the\ntarget metric under some general conditions, and in many practical settings\n(such as Poisson Regression) can actually be much superior to ERM. We\ndemonstrate empirically that our method instantiated with a well-designed\ngeneral purpose mixture likelihood family can obtain superior performance over\nERM for a variety of tasks across time-series forecasting and regression\ndatasets with different data distributions.",
    "descriptor": "",
    "authors": [
      "Pranjal Awasthi",
      "Abhimanyu Das",
      "Rajat Sen",
      "Ananda Theertha Suresh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10370"
  },
  {
    "id": "arXiv:2106.10394",
    "title": "Learning the Preferences of Uncertain Humans with Inverse Decision  Theory",
    "abstract": "Existing observational approaches for learning human preferences, such as\ninverse reinforcement learning, usually make strong assumptions about the\nobservability of the human's environment. However, in reality, people make many\nimportant decisions under uncertainty. To better understand preference learning\nin these cases, we study the setting of inverse decision theory (IDT), a\npreviously proposed framework where a human is observed making non-sequential\nbinary decisions under uncertainty. In IDT, the human's preferences are\nconveyed through their loss function, which expresses a tradeoff between\ndifferent types of mistakes. We give the first statistical analysis of IDT,\nproviding conditions necessary to identify these preferences and characterizing\nthe sample complexity -- the number of decisions that must be observed to learn\nthe tradeoff the human is making to a desired precision. Interestingly, we show\nthat it is actually easier to identify preferences when the decision problem is\nmore uncertain. Furthermore, uncertain decision problems allow us to relax the\nunrealistic assumption that the human is an optimal decision maker but still\nidentify their exact preferences; we give sample complexities in this\nsuboptimal case as well. Our analysis contradicts the intuition that partial\nobservability should make preference learning more difficult. It also provides\na first step towards understanding and improving preference learning methods\nfor uncertain and suboptimal humans.",
    "descriptor": "",
    "authors": [
      "Cassidy Laidlaw",
      "Stuart Russell"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10394"
  },
  {
    "id": "arXiv:2106.10401",
    "title": "Parallel frequency function-deep neural network for efficient complex  broadband signal approximation",
    "abstract": "A neural network is essentially a high-dimensional complex mapping model by\nadjusting network weights for feature fitting. However, the spectral bias in\nnetwork training leads to unbearable training epochs for fitting the\nhigh-frequency components in broadband signals. To improve the fitting\nefficiency of high-frequency components, the PhaseDNN was proposed recently by\ncombining complex frequency band extraction and frequency shift techniques [Cai\net al. SIAM J. SCI. COMPUT. 42, A3285 (2020)]. Our paper is devoted to an\nalternative candidate for fitting complex signals with high-frequency\ncomponents. Here, a parallel frequency function-deep neural network (PFF-DNN)\nis proposed to suppress computational overhead while ensuring fitting accuracy\nby utilizing fast Fourier analysis of broadband signals and the spectral bias\nnature of neural networks. The effectiveness and efficiency of the proposed\nPFF-DNN method are verified based on detailed numerical experiments for six\ntypical broadband signals.",
    "descriptor": "",
    "authors": [
      "Zhi Zeng",
      "Pengpeng Shi",
      "Fulei Ma",
      "Peihan Qi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10401"
  },
  {
    "id": "arXiv:2106.10414",
    "title": "Deep Learning for Functional Data Analysis with Adaptive Basis Layers",
    "abstract": "Despite their widespread success, the application of deep neural networks to\nfunctional data remains scarce today. The infinite dimensionality of functional\ndata means standard learning algorithms can be applied only after appropriate\ndimension reduction, typically achieved via basis expansions. Currently, these\nbases are chosen a priori without the information for the task at hand and thus\nmay not be effective for the designated task. We instead propose to adaptively\nlearn these bases in an end-to-end fashion. We introduce neural networks that\nemploy a new Basis Layer whose hidden units are each basis functions themselves\nimplemented as a micro neural network. Our architecture learns to apply\nparsimonious dimension reduction to functional inputs that focuses only on\ninformation relevant to the target rather than irrelevant variation in the\ninput function. Across numerous classification/regression tasks with functional\ndata, our method empirically outperforms other types of neural networks, and we\nprove that our approach is statistically consistent with low generalization\nerror. Code is available at: \\url{https://github.com/jwyyy/AdaFNN}.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Junwen Yao",
      "Jonas Mueller",
      "Jane-Ling Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10414"
  },
  {
    "id": "arXiv:2106.10415",
    "title": "R\u00e9nyi divergence inequalities via interpolation, with applications to  generalised entropic uncertainty relations",
    "abstract": "We investigate quantum R\\'enyi entropic quantities, specifically those\nderived from 'sandwiched' divergence. This divergence is one of several\nproposed R\\'enyi generalisations of the quantum relative entropy. We may define\nR\\'enyi generalisations of the quantum conditional entropy and mutual\ninformation in terms of this divergence, from which they inherit many desirable\nproperties. However, these quantities lack some of the convenient structure of\ntheir Shannon and von Neumann counterparts. We attempt to bridge this gap by\nestablishing divergence inequalities for valid combinations of R\\'enyi order\nwhich replicate the chain and decomposition rules of Shannon and von Neumann\nentropies. Although weaker in general, these inequalities recover equivalence\nwhen the R\\'enyi parameters tend to one.\nTo this end we present R\\'enyi mutual information decomposition rules, a new\napproach to the R\\'enyi conditional entropy tripartite chain rules and a more\ngeneral bipartite comparison. The derivation of these results relies on a novel\ncomplex interpolation approach for general spaces of linear operators.\nThese new comparisons allow us to employ techniques that until now were only\navailable for Shannon and von Neumann entropies. We can therefore directly\napply them to the derivation of R\\'enyi entropic uncertainty relations.\nAccordingly, we establish a family of R\\'enyi information exclusion relations\nand provide further generalisations and improvements to this and other known\nrelations, including the R\\'enyi bipartite uncertainty relations.",
    "descriptor": "",
    "authors": [
      "Alexander McKinlay"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.10415"
  },
  {
    "id": "arXiv:2106.10421",
    "title": "QFCNN: Quantum Fourier Convolutional Neural Network",
    "abstract": "The neural network and quantum computing are both significant and appealing\nfields, with their interactive disciplines promising for large-scale computing\ntasks that are untackled by conventional computers. However, both developments\nare restricted by the scope of the hardware development. Nevertheless, many\nneural network algorithms had been proposed before GPUs become powerful enough\nfor running very deep models. Similarly, quantum algorithms can also be\nproposed as knowledge reserves before real quantum computers are easily\naccessible. Specifically, taking advantage of both the neural networks and\nquantum computation and designing quantum deep neural networks (QDNNs) for\nacceleration on Noisy Intermediate-Scale Quantum (NISQ) processors is also an\nimportant research problem. As one of the most widely used neural network\narchitectures, convolutional neural network (CNN) remains to be accelerated by\nquantum mechanisms, with only a few attempts have been demonstrated. In this\npaper, we propose a new hybrid quantum-classical circuit, namely Quantum\nFourier Convolutional Network (QFCN). Our model achieves exponential speed-up\ncompared with classical CNN theoretically and improves over the existing best\nresult of quantum CNN. We demonstrate the potential of this architecture by\napplying it to different deep learning tasks, including traffic prediction and\nimage classification.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Feihong Shen",
      "Jun Liu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10421"
  },
  {
    "id": "arXiv:2106.10433",
    "title": "Sharp-interface limits of the diffuse interface model for two-phase  inductionless magnetohydrodynamic fluids",
    "abstract": "In this paper, we propose and analyze a diffuse interface model for\ninductionless magnetohydrodynamic fluids. The model couples a convective\nCahn-Hilliard equation for the evolution of the interface, the Navier-Stokes\nsystem for fluid flow and the possion quation for electrostatics. The model is\nderived from Onsager's variational principle and conservation laws\nsystematically. We perform formally matched asymptotic expansions and develop\nseveral sharp interface models in the limit when the interfacial thickness\ntends to zero. It is shown that the sharp interface limit of the models are the\nstandard incompressible inductionless magnetohydrodynamic equations coupled\nwith several different interface conditions for different choice of the\nmobilities. Numerical results verify the convergence of the diffuse interface\nmodel with different mobilitiess.",
    "descriptor": "",
    "authors": [
      "Xiaodi Zhang"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10433"
  },
  {
    "id": "arXiv:2106.10437",
    "title": "One-to-many Approach for Improving Super-Resolution",
    "abstract": "Super-resolution (SR) is a one-to-many task with multiple possible solutions.\nHowever, previous works were not concerned about this characteristic. For a\none-to-many pipeline, the generator should be able to generate multiple\nestimates of the reconstruction, and not be penalized for generating similar\nand equally realistic images. To achieve this, we propose adding weighted\npixel-wise noise after every Residual-in-Residual Dense Block (RRDB) to enable\nthe generator to generate various images. We modify the strict content loss to\nnot penalize the stochastic variation in reconstructed images as long as it has\nconsistent content. Additionally, we observe that there are out-of-focus\nregions in the DIV2K, DIV8K datasets that provide unhelpful guidelines. We\nfilter blurry regions in the training data using the method of [10]. Finally,\nwe modify the discriminator to receive the low-resolution image as a reference\nimage along with the target image to provide better feedback to the generator.\nUsing our proposed methods, we were able to improve the performance of ESRGAN\nin x4 perceptual SR and achieve the state-of-the-art LPIPS score in x16\nperceptual extreme SR.",
    "descriptor": "",
    "authors": [
      "Sieun Park",
      "Eunho Lee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10437"
  },
  {
    "id": "arXiv:2106.10480",
    "title": "Cumulative structure and path length in networks of knowledge",
    "abstract": "An important knowledge dimension of science and technology is the extent to\nwhich their development is cumulative, that is, the extent to which later\nfindings build on earlier ones. Cumulative knowledge structures can be studied\nusing a network approach, in which nodes represent findings and links represent\nknowledge flows. Of particular interest to those studies is the notion of\nnetwork paths and path length. Starting from the Price model of network growth,\nwe derive an exact solution for the path length distribution of all unique\npaths from a given initial node to each node in the network. We study the\nrelative importance of the average in-degree and cumulative advantage effect\nand implement a generalization where the in-degree depends on the number of\nnodes. The cumulative advantage effect is found to fundamentally slow down path\nlength growth. As the collection of all unique paths may contain many\nredundancies, we additionally consider the subset of the longest paths to each\nnode in the network. As this case is more complicated, we only approximate the\nlongest path length distribution in a simple context. Where the number of all\nunique paths of a given length grows unbounded, the number of longest paths of\na given length converges to a finite limit, which depends exponentially on the\ngiven path length. Fundamental network properties and dynamics therefore\ncharacteristically shape cumulative structures in those networks, and should\ntherefore be taken into account when studying those structures.",
    "descriptor": "",
    "authors": [
      "P.G.J. Persoon"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.10480"
  },
  {
    "id": "arXiv:2106.10497",
    "title": "Perturbation-based Regret Analysis of Predictive Control in Linear Time  Varying Systems",
    "abstract": "We study predictive control in a setting where the dynamics are time-varying\nand linear, and the costs are time-varying and well-conditioned. At each time\nstep, the controller receives the exact predictions of costs, dynamics, and\ndisturbances for the future $k$ time steps. We show that when the prediction\nwindow $k$ is sufficiently large, predictive control is input-to-state stable\nand achieves a dynamic regret of $O(\\lambda^k T)$, where $\\lambda < 1$ is a\npositive constant. This is the first dynamic regret bound on the predictive\ncontrol of linear time-varying systems. Under more assumptions on the terminal\ncosts, we also show that predictive control obtains the first competitive bound\nfor the control of linear time-varying systems: $1 + O(\\lambda^k)$. Our results\nare derived using a novel proof framework based on a perturbation bound that\ncharacterizes how a small change to the system parameters impacts the optimal\ntrajectory.",
    "descriptor": "",
    "authors": [
      "Yiheng Lin",
      "Yang Hu",
      "Haoyuan Sun",
      "Guanya Shi",
      "Guannan Qu",
      "Adam Wierman"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10497"
  },
  {
    "id": "arXiv:2106.10520",
    "title": "SAN: Stochastic Average Newton Algorithm for Minimizing Finite Sums",
    "abstract": "We present a principled approach for designing stochastic Newton methods for\nsolving finite sum optimization problems. Our approach has two steps. First, we\nrewrite the stationarity conditions as a system of nonlinear equations that\nassociates each data point to a new row. Second, we apply a subsampled Newton\nRaphson method to solve this system of nonlinear equations. By design, methods\ndeveloped using our approach are incremental, in that they require only a\nsingle data point per iteration. Using our approach, we develop a new\nStochastic Average Newton (SAN) method, which is incremental and cheap to\nimplement when solving regularized generalized linear models. We show through\nextensive numerical experiments that SAN requires no knowledge about the\nproblem, neither parameter tuning, while remaining competitive as compared to\nclassical variance reduced gradient methods, such as SAG and SVRG.",
    "descriptor": "\nComments: 38 pages, 6 figures, 6 tables\n",
    "authors": [
      "Jiabin Chen",
      "Rui Yuan",
      "Guillaume Garrigos",
      "Robert M. Gower"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10520"
  },
  {
    "id": "arXiv:2106.10542",
    "title": "Reversible Colour Density Compression of Images using cGANs",
    "abstract": "Image compression using colour densities is historically impractical to\ndecompress losslessly. We examine the use of conditional generative adversarial\nnetworks in making this transformation more feasible, through learning a\nmapping between the images and a loss function to train on. We show that this\nmethod is effective at producing visually lossless generations, indicating that\nefficient colour compression is viable.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Arun Jose",
      "Abraham Francis"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10542"
  },
  {
    "id": "arXiv:2106.10543",
    "title": "Signal Processing Based Deep Learning for Blind Symbol Decoding and  Modulation Classification",
    "abstract": "Blindly decoding a signal requires estimating its unknown transmit\nparameters, compensating for the wireless channel impairments, and identifying\nthe modulation type. While deep learning can solve complex problems, digital\nsignal processing (DSP) is interpretable and can be more computationally\nefficient. To combine both, we propose the dual path network (DPN). It consists\nof a signal path of DSP operations that recover the signal, and a feature path\nof neural networks that estimate the unknown transmit parameters. By\ninterconnecting the paths over several recovery stages, later stages benefit\nfrom the recovered signals and reuse all the previously extracted features. The\nproposed design is demonstrated to provide 5% improvement in modulation\nclassification compared to alternative designs lacking either feature sharing\nor access to recovered signals. The estimation results of DPN along with its\nblind decoding performance are shown to outperform a blind signal processing\nalgorithm for BPSK and QPSK on a simulated dataset. An over-the-air\nsoftware-defined-radio capture was used to verify DPN results at high SNRs. DPN\ndesign can process variable length inputs and is shown to outperform relying on\nfixed length inputs with prediction averaging on longer signals by up to 15% in\nmodulation classification.",
    "descriptor": "",
    "authors": [
      "Samer Hanna",
      "Chris Dick",
      "Danijela Cabric"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10543"
  },
  {
    "id": "arXiv:2106.10558",
    "title": "Rayleigh-Gauss-Newton optimization with enhanced sampling for  variational Monte Carlo",
    "abstract": "Variational Monte Carlo (VMC) is an approach for computing ground-state\nwavefunctions that has recently become more powerful due to the introduction of\nneural network-based wavefunction parametrizations. However, efficiently\ntraining neural wavefunctions to converge to an energy minimum remains a\ndifficult problem. In this work, we analyze optimization and sampling methods\nused in VMC and introduce alterations to improve their performance. First,\nbased on theoretical convergence analysis in a noiseless setting, we motivate a\nnew optimizer that we call the Rayleigh-Gauss-Newton method, which can improve\nupon gradient descent and natural gradient descent to achieve superlinear\nconvergence. Second, in order to realize this favorable comparison in the\npresence of stochastic noise, we analyze the effect of sampling error on VMC\nparameter updates and experimentally demonstrate that it can be reduced by the\nparallel tempering method. In particular, we demonstrate that RGN can be made\nrobust to energy spikes that occur when new regions of configuration space\nbecome available to the sampler over the course of optimization. Finally,\nputting theory into practice, we apply our enhanced optimization and sampling\nmethods to the transverse-field Ising and XXZ models on large lattices,\nyielding ground-state energy estimates with remarkably high accuracy after just\n200-500 parameter updates.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Robert J. Webber",
      "Michael Lindsey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10558"
  },
  {
    "id": "arXiv:2106.10561",
    "title": "EMG Signal Classification Using Reflection Coefficients and Extreme  Value Machine",
    "abstract": "Electromyography is a promising approach to the gesture recognition of humans\nif an efficient classifier with high accuracy is available. In this paper, we\npropose to utilize Extreme Value Machine (EVM) as a high-performance algorithm\nfor the classification of EMG signals. We employ reflection coefficients\nobtained from an Autoregressive (AR) model to train a set of classifiers. Our\nexperimental results indicate that EVM has better accuracy in comparison to the\nconventional classifiers approved in the literature based on K-Nearest\nNeighbors (KNN) and Support Vector Machine (SVM).",
    "descriptor": "",
    "authors": [
      "Reza Bagherian Azhiri",
      "Mohammad Esmaeili",
      "Mohsen Jafarzadeh",
      "Mehrdad Nourani"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10561"
  },
  {
    "id": "arXiv:2106.10591",
    "title": "Low-rank Characteristic Tensor Density Estimation Part II: Compression  and Latent Density Estimation",
    "abstract": "Learning generative probabilistic models is a core problem in machine\nlearning, which presents significant challenges due to the curse of\ndimensionality. This paper proposes a joint dimensionality reduction and\nnon-parametric density estimation framework, using a novel estimator that can\nexplicitly capture the underlying distribution of appropriate reduced-dimension\nrepresentations of the input data. The idea is to jointly design a nonlinear\ndimensionality reducing auto-encoder to model the training data in terms of a\nparsimonious set of latent random variables, and learn a canonical low-rank\ntensor model of the joint distribution of the latent variables in the Fourier\ndomain. The proposed latent density model is non-parametric and universal, as\nopposed to the predefined prior that is assumed in variational auto-encoders.\nJoint optimization of the auto-encoder and the latent density estimator is\npursued via a formulation which learns both by minimizing a combination of the\nnegative log-likelihood in the latent domain and the auto-encoder\nreconstruction loss. We demonstrate that the proposed model achieves very\npromising results on toy, tabular, and image datasets on regression tasks,\nsampling, and anomaly detection.",
    "descriptor": "",
    "authors": [
      "Magda Amiridi",
      "Nikos Kargas",
      "Nicholas D. Sidiropoulos"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10591"
  },
  {
    "id": "arXiv:2106.10633",
    "title": "Learning Signal Representations for EEG Cross-Subject Channel Selection  and Trial Classification",
    "abstract": "EEG technology finds applications in several domains. Currently, most EEG\nsystems require subjects to wear several electrodes on the scalp to be\neffective. However, several channels might include noisy information, redundant\nsignals, induce longer preparation times and increase computational times of\nany automated system for EEG decoding. One way to reduce the signal-to-noise\nratio and improve classification accuracy is to combine channel selection with\nfeature extraction, but EEG signals are known to present high inter-subject\nvariability. In this work we introduce a novel algorithm for\nsubject-independent channel selection of EEG recordings. Considering\nmulti-channel trial recordings as statistical units and the EEG decoding task\nas the class of reference, the algorithm (i) exploits channel-specific\n1D-Convolutional Neural Networks (1D-CNNs) as feature extractors in a\nsupervised fashion to maximize class separability; (ii) it reduces a high\ndimensional multi-channel trial representation into a unique trial vector by\nconcatenating the channels' embeddings and (iii) recovers the complex\ninter-channel relationships during channel selection, by exploiting an ensemble\nof AutoEncoders (AE) to identify from these vectors the most relevant channels\nto perform classification. After training, the algorithm can be exploited by\ntransferring only the parametrized subgroup of selected channel-specific\n1D-CNNs to new signals from new subjects and obtain low-dimensional and highly\ninformative trial vectors to be fed to any classifier.",
    "descriptor": "",
    "authors": [
      "Michela C. Massi",
      "Francesca Ieva"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10633"
  },
  {
    "id": "arXiv:2106.10641",
    "title": "Nuclei Grading of Clear Cell Renal Cell Carcinoma in Histopathological  Image by Composite High-Resolution Network",
    "abstract": "The grade of clear cell renal cell carcinoma (ccRCC) is a critical prognostic\nfactor, making ccRCC nuclei grading a crucial task in RCC pathology analysis.\nComputer-aided nuclei grading aims to improve pathologists' work efficiency\nwhile reducing their misdiagnosis rate by automatically identifying the grades\nof tumor nuclei within histopathological images. Such a task requires precisely\nsegment and accurately classify the nuclei. However, most of the existing\nnuclei segmentation and classification methods can not handle the inter-class\nsimilarity property of nuclei grading, thus can not be directly applied to the\nccRCC grading task. In this paper, we propose a Composite High-Resolution\nNetwork for ccRCC nuclei grading. Specifically, we propose a segmentation\nnetwork called W-Net that can separate the clustered nuclei. Then, we recast\nthe fine-grained classification of nuclei to two cross-category classification\ntasks, based on two high-resolution feature extractors (HRFEs) which are\nproposed for learning these two tasks. The two HRFEs share the same backbone\nencoder with W-Net by a composite connection so that meaningful features for\nthe segmentation task can be inherited for the classification task. Last, a\nhead-fusion block is applied to generate the predicted label of each nucleus.\nFurthermore, we introduce a dataset for ccRCC nuclei grading, containing 1000\nimage patches with 70945 annotated nuclei. We demonstrate that our proposed\nmethod achieves state-of-the-art performance compared to existing methods on\nthis large ccRCC grading dataset.",
    "descriptor": "\nComments: Accepted by MICCAI 2021\n",
    "authors": [
      "Zeyu Gao",
      "Jiangbo Shi",
      "Xianli Zhang",
      "Yang Li",
      "Haichuan Zhang",
      "Jialun Wu",
      "Chunbao Wang",
      "Deyu Meng",
      "Chen Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10641"
  },
  {
    "id": "arXiv:2106.10651",
    "title": "Implementing a Detection System for COVID-19 based on Lung Ultrasound  Imaging and Deep Learning",
    "abstract": "The COVID-19 pandemic started in China in December 2019 and quickly spread to\nseveral countries. The consequences of this pandemic are incalculable, causing\nthe death of millions of people and damaging the global economy. To achieve\nlarge-scale control of this pandemic, fast tools for detection and treatment of\npatients are needed. Thus, the demand for alternative tools for the diagnosis\nof COVID-19 has increased dramatically since accurated and automated tools are\nnot available. In this paper we present the ongoing work on a system for\nCOVID-19 detection using ultrasound imaging and using Deep Learning techniques.\nFurthermore, such a system is implemented on a Raspberry Pi to make it portable\nand easy to use in remote regions without an Internet connection.",
    "descriptor": "\nComments: Beyond Fairness Workshop at CVPR 2021\n",
    "authors": [
      "Carlos Rojas-Azabache",
      "Karen Vilca-Janampa",
      "Renzo Guerrero-Huayta",
      "Dennis N\u00fa\u00f1ez-Fern\u00e1ndez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10651"
  },
  {
    "id": "arXiv:2106.10654",
    "title": "Encoder-Decoder Based Attractor Calculation for End-to-End Neural  Diarization",
    "abstract": "This paper investigates an end-to-end neural diarization (EEND) method for an\nunknown number of speakers. In contrast to the conventional pipeline approach\nto speaker diarization, EEND methods are better in terms of speaker overlap\nhandling. However, EEND still has a disadvantage in that it cannot deal with a\nflexible number of speakers. To remedy this problem, we introduce\nencoder-decoder-based attractor calculation module (EDA) to EEND. Once\nframe-wise embeddings are obtained, EDA sequentially generates speaker-wise\nattractors on the basis of a sequence-to-sequence method using an LSTM\nencoder-decoder. The attractor generation continues until a stopping condition\nis satisfied; thus, the number of attractors can be flexible. Diarization\nresults are then estimated as dot products of the attractors and embeddings.\nThe embeddings from speaker overlaps result in larger dot product values with\nmultiple attractors; thus, this method can deal with speaker overlaps. Because\nthe maximum number of output speakers is still limited by the training set, we\nalso propose an iterative inference method to remove this restriction. Further,\nwe propose a method that aligns the estimated diarization results with the\nresults of an external speech activity detector, which enables fair comparison\nagainst pipeline approaches. Extensive evaluations on simulated and real\ndatasets show that EEND-EDA outperforms the conventional pipeline approach.",
    "descriptor": "\nComments: Submitted to IEEE TASLP. This article is based on our previous conference paper arxiv:2005.09921\n",
    "authors": [
      "Shota Horiguchi",
      "Yusuke Fujita",
      "Shinji Watanabe",
      "Yawen Xue",
      "Paola Garcia"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.10654"
  },
  {
    "id": "arXiv:2106.10665",
    "title": "Distributed Picard Iteration: Application to Distributed EM and  Distributed PCA",
    "abstract": "In recent work, we proposed a distributed Picard iteration (DPI) that allows\na set of agents, linked by a communication network, to find a fixed point of a\nlocally contractive (LC) map that is the average of individual maps held by\nsaid agents. In this work, we build upon the DPI and its local linear\nconvergence (LLC) guarantees to make several contributions. We show that\nSanger's algorithm for principal component analysis (PCA) corresponds to the\niteration of an LC map that can be written as the average of local maps, each\nmap known to each agent holding a subset of the data. Similarly, we show that a\nvariant of the expectation-maximization (EM) algorithm for parameter estimation\nfrom noisy and faulty measurements in a sensor network can be written as the\niteration of an LC map that is the average of local maps, each available at\njust one node. Consequently, via the DPI, we derive two distributed algorithms\n- distributed EM and distributed PCA - whose LLC guarantees follow from those\nthat we proved for the DPI. The verification of the LC condition for EM is\nchallenging, as the underlying operator depends on random samples, thus the LC\ncondition is of probabilistic nature.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Francisco L. Andrade",
      "M\u00e1rio A. T. Figueiredo",
      "Jo\u00e3o Xavier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.10665"
  },
  {
    "id": "arXiv:2106.10669",
    "title": "Outlier Detection and Spatial Analysis Algorithms",
    "abstract": "Outlier detection is a significant area in data mining. It can be either used\nto pre-process the data prior to an analysis or post the processing phase\n(before visualization) depending on the effectiveness of the outlier and its\nimportance. Outlier detection extends to several fields such as detection of\ncredit card fraud, network intrusions, machine failure prediction, potential\nterrorist attacks, and so on. Outliers are those data points with\ncharacteristics considerably different. They deviate from the data set causing\ninconsistencies, noise and anomalies during analysis and result in modification\nof the original points However, a common misconception is that outliers have to\nbe immediately eliminated or replaced from the data set. Such points could be\nconsidered useful if analyzed separately as they could be obtained from a\nseparate mechanism entirely making it important to the research question. This\nstudy surveys the different methods of outlier detection for spatial analysis.\nSpatial data or geospatial data are those that exhibit geographic properties or\nattributes such as position or areas. An example would be weather data such as\nprecipitation, temperature, wind velocity, and so on collected for a defined\nregion.",
    "descriptor": "\nComments: 7 pages, 14 figures\n",
    "authors": [
      "Jacob John"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10669"
  },
  {
    "id": "arXiv:2106.10696",
    "title": "Generative Model Adversarial Training for Deep Compressed Sensing",
    "abstract": "Deep compressed sensing assumes the data has sparse representation in a\nlatent space, i.e., it is intrinsically of low-dimension. The original data is\nassumed to be mapped from a low-dimensional space through a\nlow-to-high-dimensional generator. In this work, we propound how to design such\na low-to-high dimensional deep learning-based generator suiting for compressed\nsensing, while satisfying robustness to universal adversarial perturbations in\nthe latent domain. We also justify why the noise is considered in the latent\nspace. The work is also buttressed with theoretical analysis on the robustness\nof the trained generator to adversarial perturbations. Experiments on\nreal-world datasets are provided to substantiate the efficacy of the proposed\n\\emph{generative model adversarial training for deep compressed sensing.}",
    "descriptor": "",
    "authors": [
      "Ashkan Esmaeili"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10696"
  },
  {
    "id": "arXiv:2106.10706",
    "title": "Feedback Nash Equilibria in Differential Games with Impulse Control",
    "abstract": "We study a class of deterministic finite-horizon two-player nonzero-sum\ndifferential games where players are endowed with different kinds of controls.\nWe assume that Player 1 uses piecewise-continuous controls, while Player 2 uses\nimpulse controls. For this class of games, we seek to derive conditions for the\nexistence of feedback Nash equilibrium strategies for the players. More\nspecifically, we provide a verification theorem for identifying such\nequilibrium strategies, using the Hamilton-Jacobi-Bellman (HJB) equations for\nPlayer 1 and the quasi-variational inequalities (QVIs) for Player 2. Further,\nwe show that the equilibrium number of interventions by Player 2 is upper\nbounded. Furthermore, we specialize the obtained results to a scalar two-player\nlinear-quadratic differential game. In this game, Player 1's objective is to\ndrive the state variable towards a specific target value, and Player 2 has a\nsimilar objective with a different target value. We provide, for the first\ntime, an analytical characterization of the feedback Nash equilibrium in a\nlinear-quadratic differential game with impulse control. We illustrate our\nresults using numerical experiments.",
    "descriptor": "",
    "authors": [
      "Utsav Sadana",
      "Puduru Viswanadha Reddy",
      "Georges Zaccour"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10706"
  },
  {
    "id": "arXiv:2106.10712",
    "title": "Solving the linear approximation problem",
    "abstract": "We will provide algorithms that recover best inhomogeneous linear\napproximates",
    "descriptor": "",
    "authors": [
      "Avraham Bourla"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.10712"
  },
  {
    "id": "arXiv:2106.10714",
    "title": "Quantum Machine Learning: Fad or Future?",
    "abstract": "For the last few decades, classical machine learning has allowed us to\nimprove the lives of many through automation, natural language processing,\npredictive analytics and much more. However, a major concern is the fact that\nwe're fast approach the threshold of the maximum possible computational\ncapacity available to us by the means of classical computing devices including\nCPUs, GPUs and Application Specific Integrated Circuits (ASICs). This is due to\nthe exponential increase in model sizes which now have parameters in the\nmagnitude of billions and trillions, requiring a significant amount of\ncomputing resources across a significant amount of time, just to converge one\nsingle model. To observe the efficacy of using quantum computing for certain\nmachine learning tasks and explore the improved potential of convergence, error\nreduction and robustness to noisy data, this paper will look forth to test and\nverify the aspects in which quantum machine learning can help improve over\nclassical machine learning approaches while also shedding light on the likely\nlimitations that have prevented quantum approaches to become the mainstream. A\nmajor focus will be to recreate the work by Farhi et al and conduct experiments\nusing their theory of performing machine learning in a quantum context, with\nassistance from the Tensorflow Quantum documentation.",
    "descriptor": "",
    "authors": [
      "Arhum Ishtiaq",
      "Sara Mahmood"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10714"
  },
  {
    "id": "arXiv:2106.10718",
    "title": "Underwater Image Restoration via Contrastive Learning and a Real-world  Dataset",
    "abstract": "Underwater image restoration is of significant importance in unveiling the\nunderwater world. Numerous techniques and algorithms have been developed in the\npast decades. However, due to fundamental difficulties associated with\nimaging/sensing, lighting, and refractive geometric distortions, in capturing\nclear underwater images, no comprehensive evaluations have been conducted of\nunderwater image restoration. To address this gap, we have constructed a\nlarge-scale real underwater image dataset, dubbed `HICRD' (Heron Island Coral\nReef Dataset), for the purpose of benchmarking existing methods and supporting\nthe development of new deep-learning based methods. We employ accurate water\nparameter (diffuse attenuation coefficient) in generating reference images.\nThere are 2000 reference restored images and 6003 original underwater images in\nthe unpaired training set. Further, we present a novel method for underwater\nimage restoration based on unsupervised image-to-image translation framework.\nOur proposed method leveraged contrastive learning and generative adversarial\nnetworks to maximize the mutual information between raw and restored images.\nExtensive experiments with comparisons to recent approaches further demonstrate\nthe superiority of our proposed method. Our code and dataset are publicly\navailable at GitHub.",
    "descriptor": "\nComments: In submission, code/dataset are at this https URL arXiv admin note: text overlap with arXiv:2103.09697\n",
    "authors": [
      "Junlin Han",
      "Mehrdad Shoeiby",
      "Tim Malthus",
      "Elizabeth Botha",
      "Janet Anstee",
      "Saeed Anwar",
      "Ran Wei",
      "Mohammad Ali Armin",
      "Hongdong Li",
      "Lars Petersson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10718"
  },
  {
    "id": "arXiv:2106.10751",
    "title": "Routing by matching on convex pieces of grid graphs",
    "abstract": "The routing number is a graph invariant introduced by Alon, Chung, and Graham\nin 1994, and it has been studied for trees and other classes of graphs such as\nhypercubes. It gives the minimum number of routing steps needed to sort a set\nof distinct tokens, placed one on each vertex, where each routing step swaps a\nset of disjoint pairs of adjacent tokens. Our main theorem generalizes the\nknown estimate that a rectangular grid graph R with width w(R) and height h(R)\nhas routing number rt(R) in O(w(R)+h(R)). We show that for the subgraph P of\nthe infinite square lattice enclosed by any convex polygon, its routing number\nrt(P) is in O(w(P)+h(P)).",
    "descriptor": "\nComments: 32 pages, 16 figures\n",
    "authors": [
      "H. Alpert",
      "R. Barnes",
      "S. Bell",
      "A. Mauro",
      "N. Nevo",
      "N. Tucker",
      "H. Yang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.10751"
  },
  {
    "id": "arXiv:2106.10768",
    "title": "Representations and Strategies for Transferable Machine Learning Models  in Chemical Discovery",
    "abstract": "Strategies for machine-learning(ML)-accelerated discovery that are general\nacross materials composition spaces are essential, but demonstrations of ML\nhave been primarily limited to narrow composition variations. By addressing the\nscarcity of data in promising regions of chemical space for challenging targets\nlike open-shell transition-metal complexes, general representations and\ntransferable ML models that leverage known relationships in existing data will\naccelerate discovery. Over a large set (ca. 1000) of isovalent transition-metal\ncomplexes, we quantify evident relationships for different properties (i.e.,\nspin-splitting and ligand dissociation) between rows of the periodic table\n(i.e., 3d/4d metals and 2p/3p ligands). We demonstrate an extension to\ngraph-based revised autocorrelation (RAC) representation (i.e., eRAC) that\nincorporates the effective nuclear charge alongside the nuclear charge\nheuristic that otherwise overestimates dissimilarity of isovalent complexes. To\naddress the common challenge of discovery in a new space where data is limited,\nwe introduce a transfer learning approach in which we seed models trained on a\nlarge amount of data from one row of the periodic table with a small number of\ndata points from the additional row. We demonstrate the synergistic value of\nthe eRACs alongside this transfer learning strategy to consistently improve\nmodel performance. Analysis of these models highlights how the approach\nsucceeds by reordering the distances between complexes to be more consistent\nwith the periodic table, a property we expect to be broadly useful for other\nmaterials domains.",
    "descriptor": "",
    "authors": [
      "Daniel R. Harper",
      "Aditya Nandy",
      "Naveen Arunachalam",
      "Chenru Duan",
      "Jon Paul Janet",
      "Heather J. Kulik"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10768"
  },
  {
    "id": "arXiv:2106.10801",
    "title": "MeshRIR: A Dataset of Room Impulse Responses on Meshed Grid Points For  Evaluating Sound Field Analysis and Synthesis Methods",
    "abstract": "A new impulse response (IR) dataset called \"MeshRIR\" is introduced. Currently\navailable datasets usually include IRs at an array of microphones from several\nsource positions under various room conditions, which are basically designed\nfor evaluating speech enhancement and distant speech recognition methods. On\nthe other hand, methods of estimating or controlling spatial sound fields have\nbeen extensively investigated in recent years; however, the current IR datasets\nare not applicable to validating and comparing these methods because of the low\nspatial resolution of measurement points. MeshRIR consists of IRs measured at\npositions obtained by finely discretizing a spatial region. Two subdatasets are\ncurrently available: one consists of IRs in a three-dimensional cuboidal region\nfrom a single source, and the other consists of IRs in a two-dimensional square\nregion from an array of 32 sources. Therefore, MeshRIR is suitable for\nevaluating sound field analysis and synthesis methods. This dataset is freely\navailable at \\url{https://sh01k.github.io/MeshRIR/} with some codes of sample\napplications.",
    "descriptor": "",
    "authors": [
      "Shoichi Koyama",
      "Tomoya Nishida",
      "Keisuke Kimura",
      "Takumi Abe",
      "Natsuki Ueno",
      "Jesper Brunnstr\u00f6m"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.10801"
  },
  {
    "id": "arXiv:2106.10806",
    "title": "Ensemble of ACCDOA- and EINV2-based Systems with D3Nets and Impulse  Response Simulation for Sound Event Localization and Detection",
    "abstract": "This report describes our systems submitted to the DCASE2021 challenge task\n3: sound event localization and detection (SELD) with directional interference.\nOur previous system based on activity-coupled Cartesian direction of arrival\n(ACCDOA) representation enables us to solve a SELD task with a single target.\nThis ACCDOA-based system with efficient network architecture called RD3Net and\ndata augmentation techniques outperformed state-of-the-art SELD systems in\nterms of localization and location-dependent detection. Using the ACCDOA-based\nsystem as a base, we perform model ensembles by averaging outputs of several\nsystems trained with different conditions such as input features, training\nfolds, and model architectures. We also use the event independent network v2\n(EINV2)-based system to increase the diversity of the model ensembles. To\ngeneralize the models, we further propose impulse response simulation (IRS),\nwhich generates simulated multi-channel signals by convolving simulated room\nimpulse responses (RIRs) with source signals extracted from the original\ndataset. Our systems significantly improved over the baseline system on the\ndevelopment dataset.",
    "descriptor": "\nComments: 5 pages, 3 figures, submitted to DCASE2021 task3\n",
    "authors": [
      "Kazuki Shimada",
      "Naoya Takahashi",
      "Yuichiro Koyama",
      "Shusuke Takahashi",
      "Emiru Tsunoo",
      "Masafumi Takahashi",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.10806"
  },
  {
    "id": "arXiv:2106.10828",
    "title": "Controllable Context-aware Conversational Speech Synthesis",
    "abstract": "In spoken conversations, spontaneous behaviors like filled pause and\nprolongations always happen. Conversational partner tends to align features of\ntheir speech with their interlocutor which is known as entrainment. To produce\nhuman-like conversations, we propose a unified controllable spontaneous\nconversational speech synthesis framework to model the above two phenomena.\nSpecifically, we use explicit labels to represent two typical spontaneous\nbehaviors filled-pause and prolongation in the acoustic model and develop a\nneural network based predictor to predict the occurrences of the two behaviors\nfrom text. We subsequently develop an algorithm based on the predictor to\ncontrol the occurrence frequency of the behaviors, making the synthesized\nspeech vary from less disfluent to more disfluent. To model the speech\nentrainment at acoustic level, we utilize a context acoustic encoder to extract\na global style embedding from the previous speech conditioning on the\nsynthesizing of current speech. Furthermore, since the current and previous\nutterances belong to the different speakers in a conversation, we add a domain\nadversarial training module to eliminate the speaker-related information in the\nacoustic encoder while maintaining the style-related information. Experiments\nshow that our proposed approach can synthesize realistic conversations and\ncontrol the occurrences of the spontaneous behaviors naturally.",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2021\n",
    "authors": [
      "Jian Cong",
      "Shan Yang",
      "Na Hu",
      "Guangzhi Li",
      "Lei Xie",
      "Dan Su"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.10828"
  },
  {
    "id": "arXiv:2106.10831",
    "title": "Glow-WaveGAN: Learning Speech Representations from GAN-based Variational  Auto-Encoder For High Fidelity Flow-based Speech Synthesis",
    "abstract": "Current two-stage TTS framework typically integrates an acoustic model with a\nvocoder -- the acoustic model predicts a low resolution intermediate\nrepresentation such as Mel-spectrum while the vocoder generates waveform from\nthe intermediate representation. Although the intermediate representation is\nserved as a bridge, there still exists critical mismatch between the acoustic\nmodel and the vocoder as they are commonly separately learned and work on\ndifferent distributions of representation, leading to inevitable artifacts in\nthe synthesized speech. In this work, different from using pre-designed\nintermediate representation in most previous studies, we propose to use VAE\ncombining with GAN to learn a latent representation directly from speech and\nthen utilize a flow-based acoustic model to model the distribution of the\nlatent representation from text. In this way, the mismatch problem is migrated\nas the two stages work on the same distribution. Results demonstrate that the\nflow-based acoustic model can exactly model the distribution of our learned\nspeech representation and the proposed TTS framework, namely Glow-WaveGAN, can\nproduce high fidelity speech outperforming the state-of-the-art GAN-based\nmodel.",
    "descriptor": "",
    "authors": [
      "Jian Cong",
      "Shan Yang",
      "Lei Xie",
      "Dan Su"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.10831"
  },
  {
    "id": "arXiv:2106.10865",
    "title": "Benign Overfitting in Multiclass Classification: All Roads Lead to  Interpolation",
    "abstract": "The growing literature on \"benign overfitting\" in overparameterized models\nhas been mostly restricted to regression or binary classification settings;\nhowever, most success stories of modern machine learning have been recorded in\nmulticlass settings. Motivated by this discrepancy, we study benign overfitting\nin multiclass linear classification. Specifically, we consider the following\npopular training algorithms on separable data: (i) empirical risk minimization\n(ERM) with cross-entropy loss, which converges to the multiclass support vector\nmachine (SVM) solution; (ii) ERM with least-squares loss, which converges to\nthe min-norm interpolating (MNI) solution; and, (iii) the one-vs-all SVM\nclassifier. First, we provide a simple sufficient condition under which all\nthree algorithms lead to classifiers that interpolate the training data and\nhave equal accuracy. When the data is generated from Gaussian mixtures or a\nmultinomial logistic model, this condition holds under high enough effective\noverparameterization. Second, we derive novel error bounds on the accuracy of\nthe MNI classifier, thereby showing that all three training algorithms lead to\nbenign overfitting under sufficient overparameterization. Ultimately, our\nanalysis shows that good generalization is possible for SVM solutions beyond\nthe realm in which typical margin-based bounds apply.",
    "descriptor": "",
    "authors": [
      "Ke Wang",
      "Vidya Muthukumar",
      "Christos Thrampoulidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10865"
  },
  {
    "id": "arXiv:2106.10870",
    "title": "Non-native English lexicon creation for bilingual speech synthesis",
    "abstract": "Bilingual English speakers speak English as one of their languages. Their\nEnglish is of a non-native kind, and their conversations are of a code-mixed\nfashion. The intelligibility of a bilingual text-to-speech (TTS) system for\nsuch non-native English speakers depends on a lexicon that captures the phoneme\nsequence used by non-native speakers. However, due to the lack of non-native\nEnglish lexicon, existing bilingual TTS systems employ native English lexicons\nthat are widely available, in addition to their native language lexicon. Due to\nthe inconsistency between the non-native English pronunciation in the audio and\nnative English lexicon in the text, the intelligibility of synthesized speech\nin such TTS systems is significantly reduced.\nThis paper is motivated by the knowledge that the native language of the\nspeaker highly influences non-native English pronunciation. We propose a\ngeneric approach to obtain rules based on letter to phoneme alignment to map\nnative English lexicon to their non-native version. The effectiveness of such\nmapping is studied by comparing bilingual (Indian English and Hindi) TTS\nsystems trained with and without the proposed rules. The subjective evaluation\nshows that the bilingual TTS system trained with the proposed non-native\nEnglish lexicon rules obtains a 6% absolute improvement in preference.",
    "descriptor": "\nComments: Accepted for Presentation at Speech Synthesis Workshop (SSW), 2021 (August 2021)\n",
    "authors": [
      "Arun Baby",
      "Pranav Jawale",
      "Saranya Vinnaitherthan",
      "Sumukh Badam",
      "Nagaraj Adiga",
      "Sharath Adavanne"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.10870"
  },
  {
    "id": "arXiv:2106.10889",
    "title": "Brain tumor grade classification Using LSTM Neural Networks with Domain  Pre-Transforms",
    "abstract": "The performance of image classification methodsheavily relies on the\nhigh-quality annotations, which are noteasily affordable, particularly for\nmedical data. To alleviate thislimitation, in this study, we propose a weakly\nsupervised imageclassification method based on combination of\nhand-craftedfeatures. We hypothesize that integration of these\nhand-craftedfeatures alongside Long short-term memory (LSTM) classifiercan\nreduce the adverse effects of weak labels in classificationaccuracy. Our\nproposed algorithm is based on selecting theappropriate domain representations\nof the data in Wavelet andDiscrete Cosine Transform (DCT) domains. This\ninformationis then fed into LSTM network to account for the sequentialnature of\nthe data. The proposed efficient, low dimensionalfeatures exploit the power of\nshallow deep learning modelsto achieve higher performance with lower\ncomputational cost.In order to show efficacy of the proposed strategy, we\nhaveexperimented classification of brain tumor grades and achievedthe state of\nthe art performance with the resolution of 256 x 256. We also conducted a\ncomprehensive set of experiments toanalyze the effect of each component on the\nperformance.",
    "descriptor": "\nComments: 4 pages, 5 figures, MWSCAS2021\n",
    "authors": [
      "Maedeh Sadat Fasihi",
      "Wasfy B. Mikhael"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10889"
  },
  {
    "id": "arXiv:2106.10906",
    "title": "Energy stability analysis of turbulent incompressible flow based on the  triple decomposition of the velocity gradient tensor",
    "abstract": "In the context of flow visualization a triple decomposition of the velocity\ngradient was proposed by Kolat in 2007 who demonstrated the technique in 2D,\nwhich was later realized in 3D by Nagata et al. in 2020. The triple\ndecomposition opens for a refined energy stability analysis of the\nNavier-Stokes equations, with implications for the mathematical analysis of the\nstructure, computability and regularity of turbulent flow. We here perform an\nenergy stability analysis of turbulent incompressible flow, which suggests a\nscenario where any exponentially unstable irrotational flow structures rapidly\nevolve towards linearly unstable shear flow and stable rigid body rotational\nflow, which dissipates to heat. In contrast to worst case energy stability\nestimates, this refined stability analysis reflects the existence of stable\nflow structures in turbulence over extended time, and the robustness of average\nquantities.",
    "descriptor": "\nComments: 4 pages. The following article has been submitted to Physics of Fluids\n",
    "authors": [
      "Johan Hoffman"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10906"
  },
  {
    "id": "arXiv:2106.10915",
    "title": "Speech prosody and remote experiments: a technical report",
    "abstract": "The aim of this paper is twofold. First, we present a review of different\nrecording options for gathering prosodic data in the event that fieldwork is\nimpracticable (e.g. due to pandemics). Under this light, we mimic a\nlong-distance reading task experiment using different software and hardware\nsynchronously. In order to evaluate the employed methodologies, we extract\nnoise levels and frequency manipulation of the recordings. Subsequently, we\nexamine the impact of the different recordings onto linguistic variables, such\nas the pitch curves and values. We also include a discussion on experimental\npracticalities. After balancing these factors, we decree an online platform,\nZencastr, as the most affordable and practical for acoustic data collection.\nSecondly, we want to open up a debate on the most optimal remote methodology\nthat researchers on speech prosody can deploy.",
    "descriptor": "",
    "authors": [
      "Giuseppe Magistro"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.10915"
  },
  {
    "id": "arXiv:2106.10933",
    "title": "Polynomial Input-to-state Stability of Infinite-dimensional Linear  Systems",
    "abstract": "We introduce a notion of polynomial input-to-state stability for\ninfinite-dimensional linear systems. This notion comes from polynomial\nstability of $C_0$-semigroups. We obtain sufficient conditions for polynomial\ninput-to-state stability, by restricting the range of an input operator.\nNecessary conditions for polynomial input-to-state stability and an\nattractivity property related to polynomial input-to-state stability are also\ninvestigated.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Masashi Wakaiki"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10933"
  },
  {
    "id": "arXiv:2106.10952",
    "title": "Spliced Binned-Pareto Distribution for Robust Modeling of Heavy-tailed  Time Series",
    "abstract": "This work proposes a novel method to robustly and accurately model time\nseries with heavy-tailed noise, in non-stationary scenarios. In many practical\napplication time series have heavy-tailed noise that significantly impacts the\nperformance of classical forecasting models; in particular, accurately modeling\na distribution over extreme events is crucial to performing accurate time\nseries anomaly detection. We propose a Spliced Binned-Pareto distribution which\nis both robust to extreme observations and allows accurate modeling of the full\ndistribution. Our method allows the capture of time dependencies in the higher\norder moments of the distribution such as the tail heaviness. We compare the\nrobustness and the accuracy of the tail estimation of our method to other state\nof the art methods on Twitter mentions count time series.",
    "descriptor": "\nComments: Accepted at RobustWorkshop@ICLR2021: &lt;this https URL&gt;\n",
    "authors": [
      "Elena Ehrlich",
      "Laurent Callot",
      "Fran\u00e7ois-Xavier Aubet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.10952"
  },
  {
    "id": "arXiv:2106.10985",
    "title": "Equivalence between a time-fractional and an integer-order gradient  flow: The memory effect reflected in the energy",
    "abstract": "Time-fractional partial differential equations are nonlocal in time and show\nan innate memory effect. In this work, we propose an augmented energy\nfunctional which includes the history of the solution. Further, we prove the\nequivalence of a time-fractional gradient flow problem to an integer-order one\nbased on our new energy. This equivalence guarantees the dissipating character\nof the augmented energy. The state function of the integer-order gradient flow\nacts on an extended domain similar to the Caffarelli-Silvestre extension for\nthe fractional Laplacian. Additionally, we apply a numerical scheme for solving\ntime-fractional gradient flows, which is based on kernel compressing methods.\nWe illustrate the behavior of the original and augmented energy in the case of\nthe Ginzburg-Landau energy functional.",
    "descriptor": "",
    "authors": [
      "Marvin Fritz",
      "Ustim Khristenko",
      "Barbara Wohlmuth"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10985"
  },
  {
    "id": "arXiv:2106.10992",
    "title": "Estimating MRI Image Quality via Image Reconstruction Uncertainty",
    "abstract": "Quality control (QC) in medical image analysis is time-consuming and\nlaborious, leading to increased interest in automated methods. However, what is\ndeemed suitable quality for algorithmic processing may be different from\nhuman-perceived measures of visual quality. In this work, we pose MR image\nquality assessment from an image reconstruction perspective. We train Bayesian\nCNNs using a heteroscedastic uncertainty model to recover clean images from\nnoisy data, providing measures of uncertainty over the predictions. This\nframework enables us to divide data corruption into learnable and non-learnable\ncomponents and leads us to interpret the predictive uncertainty as an\nestimation of the achievable recovery of an image. Thus, we argue that quality\ncontrol for visual assessment cannot be equated to quality control for\nalgorithmic processing. We validate this statement in a multi-task experiment\ncombining artefact recovery with uncertainty prediction and grey matter\nsegmentation. Recognising this distinction between visual and algorithmic\nquality has the impact that, depending on the downstream task, less data can be\nexcluded based on ``visual quality\" reasons alone.",
    "descriptor": "",
    "authors": [
      "Richard Shaw",
      "Carole H. Sudre",
      "Sebastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10992"
  },
  {
    "id": "arXiv:2106.10997",
    "title": "Towards sound based testing of COVID-19 -- Summary of the first  Diagnostics of COVID-19 using Acoustics (DiCOVA) Challenge",
    "abstract": "The technology development for point-of-care tests (POCTs) targeting\nrespiratory diseases has witnessed a growing demand in the recent past.\nInvestigating the presence of acoustic biomarkers in modalities such as cough,\nbreathing and speech sounds, and using them for building POCTs can offer fast,\ncontactless and inexpensive testing. In view of this, over the past year, we\nlaunched the ``Coswara'' project to collect cough, breathing and speech sound\nrecordings via worldwide crowdsourcing. With this data, a call for development\nof diagnostic tools was announced in the Interspeech 2021 as a special session\ntitled ``Diagnostics of COVID-19 using Acoustics (DiCOVA) Challenge''. The goal\nwas to bring together researchers and practitioners interested in developing\nacoustics-based COVID-19 POCTs by enabling them to work on the same set of\ndevelopment and test datasets. As part of the challenge, datasets with\nbreathing, cough, and speech sound samples from COVID-19 and non-COVID-19\nindividuals were released to the participants. The challenge consisted of two\ntracks. The Track-1 focused only on cough sounds, and participants competed in\na leaderboard setting. In Track-2, breathing and speech samples were provided\nfor the participants, without a competitive leaderboard. The challenge\nattracted 85 plus registrations with 29 final submissions for Track-1. This\npaper describes the challenge (datasets, tasks, baseline system), and presents\na focused summary of the various systems submitted by the participating teams.\nAn analysis of the results from the top four teams showed that a fusion of the\nscores from these teams yields an area-under-the-curve of 95.1% on the blind\ntest data. By summarizing the lessons learned, we foresee the challenge\noverview in this paper to help accelerate technology for acoustic-based POCTs.",
    "descriptor": "\nComments: Manuscript in review in the Elsevier Computer Speech and Language journal\n",
    "authors": [
      "Neeraj Kumar Sharma",
      "Ananya Muguli",
      "Prashant Krishnan",
      "Rohit Kumar",
      "Srikanth Raj Chetupalli",
      "Sriram Ganapathy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.10997"
  },
  {
    "id": "arXiv:2106.11064",
    "title": "$\u03b1$-Stable convergence of heavy-tailed infinitely-wide neural  networks",
    "abstract": "We consider infinitely-wide multi-layer perceptrons (MLPs) which are limits\nof standard deep feed-forward neural networks. We assume that, for each layer,\nthe weights of an MLP are initialized with i.i.d. samples from either a\nlight-tailed (finite variance) or heavy-tailed distribution in the domain of\nattraction of a symmetric $\\alpha$-stable distribution, where $\\alpha\\in(0,2]$\nmay depend on the layer. For the bias terms of the layer, we assume i.i.d.\ninitializations with a symmetric $\\alpha$-stable distribution having the same\n$\\alpha$ parameter of that layer. We then extend a recent result of Favaro,\nFortini, and Peluchetti (2020), to show that the vector of pre-activation\nvalues at all nodes of a given hidden layer converges in the limit, under a\nsuitable scaling, to a vector of i.i.d. random variables with symmetric\n$\\alpha$-stable distributions.",
    "descriptor": "",
    "authors": [
      "Paul Jung",
      "Hoil Lee",
      "Jiho Lee",
      "Hongseok Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.11064"
  },
  {
    "id": "arXiv:2106.11068",
    "title": "Affine-Invariant Integrated Rank-Weighted Depth: Definition, Properties  and Finite Sample Analysis",
    "abstract": "Because it determines a center-outward ordering of observations in\n$\\mathbb{R}^d$ with $d\\geq 2$, the concept of statistical depth permits to\ndefine quantiles and ranks for multivariate data and use them for various\nstatistical tasks (\\textit{e.g.} inference, hypothesis testing). Whereas many\ndepth functions have been proposed \\textit{ad-hoc} in the literature since the\nseminal contribution of \\cite{Tukey75}, not all of them possess the properties\ndesirable to emulate the notion of quantile function for univariate probability\ndistributions. In this paper, we propose an extension of the \\textit{integrated\nrank-weighted} statistical depth (IRW depth in abbreviated form) originally\nintroduced in \\cite{IRW}, modified in order to satisfy the property of\n\\textit{affine-invariance}, fulfilling thus all the four key axioms listed in\nthe nomenclature elaborated by \\cite{ZuoS00a}. The variant we propose, referred\nto as the Affine-Invariant IRW depth (AI-IRW in short), involves the\ncovariance/precision matrices of the (supposedly square integrable)\n$d$-dimensional random vector $X$ under study, in order to take into account\nthe directions along which $X$ is most variable to assign a depth value to any\npoint $x\\in \\mathbb{R}^d$. The accuracy of the sampling version of the AI-IRW\ndepth is investigated from a nonasymptotic perspective. Namely, a concentration\nresult for the statistical counterpart of the AI-IRW depth is proved. Beyond\nthe theoretical analysis carried out, applications to anomaly detection are\nconsidered and numerical results are displayed, providing strong empirical\nevidence of the relevance of the depth function we propose here.",
    "descriptor": "",
    "authors": [
      "Guillaume Staerman",
      "Pavlo Mozharovskyi",
      "St\u00e9phan Cl\u00e9men\u00e7on"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11068"
  },
  {
    "id": "arXiv:2106.11087",
    "title": "Recolouring co-bipartite and weakly chordal graphs",
    "abstract": "For a graph $G$, the $k$-recolouring graph $\\mathcal{R}_k(G)$ is the graph\nwhose vertices are the $k$-colourings of $G$ and two colourings are joined by\nan edge if they differ in colour on exactly one vertex. We prove that for all\n$n \\ge 1$, there exists a $k$-colourable weakly chordal $G$ graph where\n$\\mathcal{R}_{k+n}(G)$ is disconnected, answering an open question of Feghali\nand Fiala. We also show that for every $k$-colourable co-bipartite graph $G$,\n$\\mathcal{R}_{k+1}(G)$ is connected with diameter at most $4|V(G)|$.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Owen Merkel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.11087"
  },
  {
    "id": "arXiv:2106.11101",
    "title": "Data completion algorithms and their applications in inverse acoustic  scattering with limited-aperture backscattering data",
    "abstract": "We introduce two data completion algorithms for the limited-aperture problems\nin inverse acoustic scattering. Both completion algorithms are independent of\nthe topological and physical properties of the unknown scatterers. The main\nidea is to relate the limited-aperture data to the full-aperture data via the\nprolate matrix. The data completion algorithms are simple and fast since only\nthe approximate inversion of the prolate matrix is involved. We then combine\nthe data completion algorithms with imaging methods such as factorization\nmethod and direct sampling method for the object reconstructions. A variety of\nnumerical examples are presented to illustrate the effectiveness and robustness\nof the proposed algorithms.",
    "descriptor": "",
    "authors": [
      "Fangfang Dou",
      "Xiaodong Liu",
      "Shixu Meng",
      "Bo Zhang"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11101"
  },
  {
    "id": "arXiv:2106.11107",
    "title": "Electromagnetic Interference in RIS-Aided Communications",
    "abstract": "The prospects of using a reconfigurable intelligent surface (RIS) to aid\nwireless communication systems have recently received much attention. Among the\ndifferent use cases, the most popular one is where each element of the RIS\nscatters the incoming signal with a controllable phase-shift, without\nincreasing its power. In prior literature, this setup has been analyzed by\nneglecting the electromagnetic interference, consisting of the inevitable\nincoming waves from external sources. In this letter, we provide a physically\nmeaningful model for the electromagnetic interference that can be used as a\nbaseline when evaluating RIS-aided communications. The model is used to show\nthat electromagnetic interference has a non-negligible impact on communication\nperformance, especially when the size of the RIS grows large. When the direct\nlink is present (though with a relatively weak gain), the RIS can even reduce\nthe communication performance. Importantly, it turns out that the SNR grows\nquadratically with the number of RIS elements only when the spatial correlation\nmatrix of the electromagnetic interference is asymptotically orthogonal to that\nof the channel vector towards the intended receiver. Otherwise, the SNR only\nincreases linearly.",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to IEEE Wireless Communication Letters\n",
    "authors": [
      "Andrea De Jesus Torres",
      "Luca Sanguinetti",
      "Emil Bj\u00f6rnson"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11107"
  },
  {
    "id": "arXiv:2106.11144",
    "title": "Scientific multi-agent reinforcement learning for wall-models of  turbulent flows",
    "abstract": "The predictive capabilities of turbulent flow simulations, critical for\naerodynamic design and weather prediction, hinge on the choice of turbulence\nmodels. The abundance of data from experiments and simulations and the advent\nof machine learning have provided a boost to these modeling efforts. However,\nsimulations of turbulent flows remain hindered by the inability of heuristics\nand supervised learning to model the near-wall dynamics. We address this\nchallenge by introducing scientific multi-agent reinforcement learning\n(SciMARL) for the discovery of wall models for large-eddy simulations (LES). In\nSciMARL, discretization points act also as cooperating agents that learn to\nsupply the LES closure model. The agents self-learn using limited data and\ngeneralize to extreme Reynolds numbers and previously unseen geometries. The\npresent simulations reduce by several orders of magnitude the computational\ncost over fully-resolved simulations while reproducing key flow quantities. We\nbelieve that SciMARL creates new capabilities for the simulation of turbulent\nflows.",
    "descriptor": "",
    "authors": [
      "H. Jane Bae",
      "Petros Koumoutsakos"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.11144"
  },
  {
    "id": "arXiv:2106.11163",
    "title": "Energy-dissipation for time-fractional phase-field equations",
    "abstract": "We consider a class of time-fractional phase field models including the\nAllen-Cahn and Cahn-Hilliard equations. We establish several weighted\npositivity results for functionals driven by the Caputo time-fractional\nderivative. Several novel criterions are examined for showing the\npositive-definiteness of the associated kernel functions. We deduce strict\nenergy-dissipation for a number of non-local energy functionals, thereby\nproving fractional energy dissipation laws.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Dong Li",
      "Chaoyu Quan",
      "Jiao Xu"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11163"
  },
  {
    "id": "arXiv:2106.11169",
    "title": "Signals to Spikes for Neuromorphic Regulated Reservoir Computing and EMG  Hand Gesture Recognition",
    "abstract": "We propose a simple yet novel approach for optimizing the spike encoding\nalgorithm's hyper-parameters inspired by the readout layer concept in reservoir\ncomputing. Using a simple machine learning algorithm after spike encoding, we\nreport performance higher than the state-of-the-art spiking neural networks on\ntwo open-source datasets for hand gesture recognition. Surface electromyogram\n(sEMG) signals result from muscle movement and hence they are an ideal\ncandidate for benchmarking event-driven sensing and computing. The spike\nencoded data is processed through a spiking reservoir with a biologically\ninspired topology and neuron model. When trained with the unsupervised activity\nregulation CRITICAL algorithm to operate at the edge of chaos, the reservoir\nyields better performance than state-of-the-art convolutional neural networks.\nThe reservoir performance with regulated activity was found to be 89.72% for\nthe Roshambo EMG dataset and 70.6% for the EMG subset of sensor fusion dataset.\nTherefore, the biologically-inspired computing paradigm, which is known for\nbeing power efficient, also proves to have a great potential when compared with\nconventional AI algorithms.",
    "descriptor": "",
    "authors": [
      "Nikhil Garg",
      "Ismael Balafrej",
      "Yann Beilliard",
      "Dominique Drouin",
      "Fabien Alibart",
      "Jean Rouat"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2106.11169"
  },
  {
    "id": "arXiv:2106.11170",
    "title": "Transformer-based Spatial-Temporal Feature Learning for EEG Decoding",
    "abstract": "At present, people usually use some methods based on convolutional neural\nnetworks (CNNs) for Electroencephalograph (EEG) decoding. However, CNNs have\nlimitations in perceiving global dependencies, which is not adequate for common\nEEG paradigms with a strong overall relationship. Regarding this issue, we\npropose a novel EEG decoding method that mainly relies on the attention\nmechanism. The EEG data is firstly preprocessed and spatially filtered. And\nthen, we apply attention transforming on the feature-channel dimension so that\nthe model can enhance more relevant spatial features. The most crucial step is\nto slice the data in the time dimension for attention transforming, and finally\nobtain a highly distinguishable representation. At this time, global averaging\npooling and a simple fully-connected layer are used to classify different\ncategories of EEG data. Experiments on two public datasets indicate that the\nstrategy of attention transforming effectively utilizes spatial and temporal\nfeatures. And we have reached the level of the state-of-the-art in\nmulti-classification of EEG, with fewer parameters. As far as we know, it is\nthe first time that a detailed and complete method based on the transformer\nidea has been proposed in this field. It has good potential to promote the\npracticality of brain-computer interface (BCI). The source code can be found\nat: \\textit{https://github.com/anranknight/EEG-Transformer}.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Yonghao Song",
      "Xueyu Jia",
      "Lie Yang",
      "Longhan Xie"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11170"
  },
  {
    "id": "arXiv:2106.11171",
    "title": "UniTTS: Residual Learning of Unified Embedding Space for Speech Style  Control",
    "abstract": "We propose a novel high-fidelity expressive speech synthesis model, UniTTS,\nthat learns and controls overlapping style attributes avoiding interference.\nUniTTS represents multiple style attributes in a single unified embedding space\nby the residuals between the phoneme embeddings before and after applying the\nattributes. The proposed method is especially effective in controlling multiple\nattributes that are difficult to separate cleanly, such as speaker ID and\nemotion, because it minimizes redundancy when adding variance in speaker ID and\nemotion, and additionally, predicts duration, pitch, and energy based on the\nspeaker ID and emotion. In experiments, the visualization results exhibit that\nthe proposed methods learned multiple attributes harmoniously in a manner that\ncan be easily separated again. As well, UniTTS synthesized high-fidelity speech\nsignals controlling multiple style attributes. The synthesized speech samples\nare presented at https://jackson-kang.github.io/paper_works/UniTTS/demos.",
    "descriptor": "",
    "authors": [
      "Minsu Kang",
      "Sungjae Kim",
      "Injung Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.11171"
  },
  {
    "id": "arXiv:2106.11180",
    "title": "Complexity-Free Generalization via Distributionally Robust Optimization",
    "abstract": "Established approaches to obtain generalization bounds in data-driven\noptimization and machine learning mostly build on solutions from empirical risk\nminimization (ERM), which depend crucially on the functional complexity of the\nhypothesis class. In this paper, we present an alternate route to obtain these\nbounds on the solution from distributionally robust optimization (DRO), a\nrecent data-driven optimization framework based on worst-case analysis and the\nnotion of ambiguity set to capture statistical uncertainty. In contrast to the\nhypothesis class complexity in ERM, our DRO bounds depend on the ambiguity set\ngeometry and its compatibility with the true loss function. Notably, when using\nmaximum mean discrepancy as a DRO distance metric, our analysis implies, to the\nbest of our knowledge, the first generalization bound in the literature that\ndepends solely on the true loss function, entirely free of any complexity\nmeasures or bounds on the hypothesis class.",
    "descriptor": "",
    "authors": [
      "Henry Lam",
      "Yibo Zeng"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11180"
  },
  {
    "id": "arXiv:2106.11184",
    "title": "Dynamics of Disruption in Science and Technology",
    "abstract": "Although the number of new scientific discoveries and technological\ninventions has increased dramatically over the past century, there have also\nbeen concerns of a slowdown in the progress of science and technology. We\nanalyze 25 million papers and 4 million patents across 6 decades and find that\nscience and technology are becoming less disruptive of existing knowledge, a\npattern that holds nearly universally across fields. We link this decline in\ndisruptiveness to a narrowing in the utilization of existing knowledge.\nDiminishing quality of published science and changes in citation practices are\nunlikely to be responsible for this trend, suggesting that this pattern\nrepresents a fundamental shift in science and technology.",
    "descriptor": "",
    "authors": [
      "Michael Park",
      "Erin Leahey",
      "Russell Funk"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.11184"
  },
  {
    "id": "arXiv:2106.11186",
    "title": "Variations on Hammersley's interacting particle process",
    "abstract": "The longest increasing subsequence problem for permutations has been studied\nextensively in the last fifty years. The interpretation of the longest\nincreasing subsequence as the longest 21-avoiding subsequence in the context of\npermutation patterns leads to many interesting research directions. We\nintroduce and study the statistical properties of Hammersleytype interacting\nparticle processes related to these generalizations and explore the finer\nstructures of their distributions. We also propose three different interacting\nparticle systems in the plane analogous to the Hammersley process in one\ndimension and obtain estimates for the asymptotic orders of the mean and\nvariance of the number of particles in the systems.",
    "descriptor": "\nComments: 6 pages, 6 figures, accepted for publication in Discrete Mathematics Letters\n",
    "authors": [
      "Arda Atalik",
      "H. S. Melihcan Erol",
      "G\u00f6khan Y\u0131ld\u0131r\u0131m",
      "Mustafa Yilmaz"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.11186"
  },
  {
    "id": "arXiv:2106.11211",
    "title": "Stratified Learning: a general-purpose statistical method for improved  learning under Covariate Shift",
    "abstract": "Covariate shift arises when the labelled training (source) data is not\nrepresentative of the unlabelled (target) data due to systematic differences in\nthe covariate distributions. A supervised model trained on the source data\nsubject to covariate shift may suffer from poor generalization on the target\ndata. We propose a novel, statistically principled and theoretically justified\nmethod to improve learning under covariate shift conditions, based on\npropensity score stratification, a well-established methodology in causal\ninference. We show that the effects of covariate shift can be reduced or\naltogether eliminated by conditioning on propensity scores. In practice, this\nis achieved by fitting learners on subgroups (\"strata\") constructed by\npartitioning the data based on the estimated propensity scores, leading to\nbalanced covariates and much-improved target prediction. We demonstrate the\neffectiveness of our general-purpose method on contemporary research questions\nin observational cosmology, and on additional benchmark examples, matching or\noutperforming state-of-the-art importance weighting methods, widely studied in\nthe covariate shift literature. We obtain the best reported AUC (0.958) on the\nupdated \"Supernovae photometric classification challenge\" and improve upon\nexisting conditional density estimation of galaxy redshift from Sloan Data Sky\nSurvey (SDSS) data.",
    "descriptor": "",
    "authors": [
      "Maximilian Autenrieth",
      "David A. van Dyk",
      "Roberto Trotta",
      "David C. Stenning"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11211"
  },
  {
    "id": "arXiv:2106.11215",
    "title": "Machine Learning based optimization for interval uncertainty propagation  with application to vibro-acoustic models",
    "abstract": "Two non-intrusive uncertainty propagation approaches are proposed for the\nperformance analysis of engineering systems described by expensive-to-evaluate\ndeterministic computer models with parameters defined as interval variables.\nThese approaches employ a machine learning based optimization strategy, the\nso-called Bayesian optimization, for evaluating the upper and lower bounds of a\ngeneric response variable over the set of possible responses obtained when each\ninterval variable varies independently over its range. The lack of knowledge\ncaused by not evaluating the response function for all the possible\ncombinations of the interval variables is accounted for by developing a\nprobabilistic description of the response variable itself by using a Gaussian\nProcess regression model. An iterative procedure is developed for selecting a\nsmall number of simulations to be evaluated for updating this statistical model\nby using well-established acquisition functions and to assess the response\nbounds. In both approaches, an initial training dataset is defined. While one\napproach builds iteratively two distinct training datasets for evaluating\nseparately the upper and lower bounds of the response variable, the other\nbuilds iteratively a single training dataset. Consequently, the two approaches\nwill produce different bound estimates at each iteration. The upper and lower\nbound responses are expressed as point estimates obtained from the mean\nfunction of the posterior distribution. Moreover, a confidence interval on each\nestimate is provided for effectively communicating to engineers when these\nestimates are obtained for a combination of the interval variables for which no\ndeterministic simulation has been run. Finally, two metrics are proposed to\ndefine conditions for assessing if the predicted bound estimates can be\nconsidered satisfactory.",
    "descriptor": "\nComments: Preprint submitted to Mechanical Systems and Signal Processing\n",
    "authors": [
      "Alice Cicirello",
      "Filippo Giunta"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.11215"
  },
  {
    "id": "arXiv:2106.11246",
    "title": "LEAP: Scaling Numerical Optimization Based Synthesis Using an  Incremental Approach",
    "abstract": "While showing great promise, circuit synthesis techniques that combine\nnumerical optimization with search over circuit structures face scalability\nchallenges due to large number of parameters, exponential search spaces, and\ncomplex objective functions. The LEAP algorithm improves scaling across these\ndimensions using iterative circuit synthesis, incremental reoptimization,\ndimensionality reduction, and improved numerical optimization. LEAP draws on\nthe design of the optimal synthesis algorithm QSearch by extending it with an\nincremental approach to determine constant prefix solutions for a circuit. By\nnarrowing the search space, LEAP improves scalability from four to six qubit\ncircuits. LEAP was evaluated with known quantum circuits such as QFT and\nphysical simulation circuits like the VQE, TFIM and QITE. LEAP is able to\ncompile four qubit unitaries up to $59\\times$ faster than QSearch and five and\nsix qubit unitaries with up to $1.2\\times$ fewer CNOTs compared to the advanced\nQFAST package. LEAP is able to reduce the CNOT count by up to $48\\times$, or\n$11\\times$ on average, compared to the IBM Qiskit compiler. Although employing\nheuristics, LEAP has generated optimal depth circuits for all test cases where\na solution is known a priori. The techniques introduced by LEAP are applicable\nto other numerical optimization based synthesis approaches.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Ethan Smith",
      "Marc G. Davis",
      "Jeffrey M. Larson",
      "Ed Younis",
      "Costin Iancu",
      "Wim Lavrijsen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2106.11246"
  },
  {
    "id": "arXiv:2106.11267",
    "title": "Minimal Rank Completions for Overlapping Blocks",
    "abstract": "We consider the multi-objective optimization problem of choosing the bottom\nleft block-entry of a block lower triangular matrix to minimize the ranks of\nall block sub-matrices. We provide a proof that there exists a simultaneous\nrank-minimizer by constructing the complete set of all minimizers.",
    "descriptor": "\nComments: 11 pages, 1 figure, accepted in Linear Algebra and its Applications\n",
    "authors": [
      "Ethan N. Epperly",
      "Nithin Govindarajan",
      "Shivkumar Chandrasekaran"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11267"
  },
  {
    "id": "arXiv:2106.11281",
    "title": "Active and Dynamic Beam Tracking UnderStochastic Mobility",
    "abstract": "We consider the problem of active and sequential beam tracking at mmWave\nfrequencies and above. We focus on the dynamic scenario of a UAV to UAV\ncommunications where we formulate the problem to be equivalent to tracking an\noptimal beamforming vector along the line-of-sight path. In this setting, the\nresulting beam ideally points in the direction of the angle of arrival with\nsufficiently high resolution. Existing solutions account for predictable\nmovements or small random movements using filtering strategies or by accounting\nfor predictable mobility but must resort to re-estimation protocols when\ntracking fails due to unpredictable movements. We propose an algorithm for\nactive learning of the AoA through evolving a Bayesian posterior probability\nbelief which is utilized for a sequential selection of beamforming vectors. We\npropose an adaptive pilot allocation strategy based on a trade-off of mutual\ninformation versus spectral efficiency. Numerically, we analyze the performance\nof our proposed algorithm and demonstrate significant improvements over\nexisting strategies.",
    "descriptor": "\nComments: This paper has been submitted for publication\n",
    "authors": [
      "Nancy Ronquillo",
      "Tara Javidi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.11281"
  },
  {
    "id": "arXiv:2106.11284",
    "title": "Fully automated quantification of in vivo viscoelasticity of prostate  zones using magnetic resonance elastography with Dense U-net segmentation",
    "abstract": "Magnetic resonance elastography (MRE) for measuring viscoelasticity heavily\ndepends on proper tissue segmentation, especially in heterogeneous organs such\nas the prostate. Using trained network-based image segmentation, we\ninvestigated if MRE data suffice to extract anatomical and viscoelastic\ninformation for automatic tabulation of zonal mechanical properties of the\nprostate. Overall, 40 patients with benign prostatic hyperplasia (BPH) or\nprostate cancer (PCa) were examined with three magnetic resonance imaging (MRI)\nsequences: T2-weighted MRI (T2w), diffusion-weighted imaging (DWI), and\nMRE-based tomoelastography yielding six independent sets of imaging data per\npatient (T2w, DWI, apparent diffusion coefficient (ADC), MRE magnitude, shear\nwave speed, and loss angle maps). Combinations of these data were used to train\nDense U-nets with manually segmented masks of the entire prostate gland (PG),\ncentral zone (CZ), and peripheral zone (PZ) in 30 patients and to validate them\nin 10 patients. Dice score (DS), sensitivity, specificity, and Hausdorff\ndistance were determined. We found that segmentation based on MRE magnitude\nmaps alone (DS, PG: 0.93$\\pm$0.04, CZ: 0.95$\\pm$0.03, PZ: 0.77$\\pm$0.05) was\nmore accurate than magnitude maps combined with T2w and DWI_b (DS, PG:\n0.91$\\pm$0.04, CZ: 0.91$\\pm$0.06, PZ: 0.63$\\pm$0.16) or T2w alone (DS, PG:\n0.92$\\pm$0.03, CZ: 0.91$\\pm$0.04, PZ: 0.65$\\pm$0.08). Automatically tabulated\nMRE values were not different from ground-truth values (P>0.05). In conclusion:\nMRE combined with Dense U-net segmentation allows tabulation of quantitative\nimaging markers without manual analysis and independent of other MRI sequences\nand can thus contribute to PCa detection and classification.",
    "descriptor": "",
    "authors": [
      "Nader Aldoj",
      "Federico Biavati",
      "Marc Dewey",
      "Anja Hennemuth",
      "Patrick Asbach",
      "Ingolf Sack"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11284"
  },
  {
    "id": "arXiv:2106.11302",
    "title": "Nested Variational Inference",
    "abstract": "We develop nested variational inference (NVI), a family of methods that learn\nproposals for nested importance samplers by minimizing an forward or reverse KL\ndivergence at each level of nesting. NVI is applicable to many commonly-used\nimportance sampling strategies and provides a mechanism for learning\nintermediate densities, which can serve as heuristics to guide the sampler. Our\nexperiments apply NVI to (a) sample from a multimodal distribution using a\nlearned annealing path (b) learn heuristics that approximate the likelihood of\nfuture observations in a hidden Markov model and (c) to perform amortized\ninference in hierarchical deep generative models. We observe that optimizing\nnested objectives leads to improved sample quality in terms of log average\nweight and effective sample size.",
    "descriptor": "",
    "authors": [
      "Heiko Zimmermann",
      "Hao Wu",
      "Babak Esmaeili",
      "Jan-Willem van de Meent"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11302"
  },
  {
    "id": "arXiv:1707.08729",
    "title": "Learning audio sequence representations for acoustic event  classification",
    "abstract": "Learning audio sequence representations for acoustic event  classification",
    "descriptor": "",
    "authors": [
      "Zixing Zhang",
      "Ding Liu",
      "Jing Han",
      "Kun Qian",
      "Bj\u00f6rn Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1707.08729"
  },
  {
    "id": "arXiv:1809.02517",
    "title": "Streaming dictionary matching with mismatches",
    "abstract": "Streaming dictionary matching with mismatches",
    "descriptor": "",
    "authors": [
      "Pawe\u0142 Gawrychowski",
      "Tatiana Starikovskaya"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1809.02517"
  },
  {
    "id": "arXiv:1809.03626",
    "title": "Smoothed Analysis for the Condition Number of Structured Real Polynomial  Systems",
    "abstract": "Comments: Title changed due to an interesting journal policy, to appear in Mathematics of Computation",
    "descriptor": "\nComments: Title changed due to an interesting journal policy, to appear in Mathematics of Computation\n",
    "authors": [
      "Alperen A. Erg\u00fcr",
      "Grigoris Paouris",
      "J. Maurice Rojas"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Symbolic Computation (cs.SC)",
      "Metric Geometry (math.MG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1809.03626"
  },
  {
    "id": "arXiv:1810.13196",
    "title": "Hamilton-Green solver for the forward and adjoint problems in  photoacoustic tomography",
    "abstract": "Comments: 35 pages, 15 figures",
    "descriptor": "\nComments: 35 pages, 15 figures\n",
    "authors": [
      "Francesc Rullan",
      "Marta M. Betcke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1810.13196"
  },
  {
    "id": "arXiv:1811.05436",
    "title": "Robust H-infinity kinematic control of manipulator robots using dual  quaternion algebra",
    "abstract": "Comments: 8 pages, 4 figures, version accepted in Automatica",
    "descriptor": "\nComments: 8 pages, 4 figures, version accepted in Automatica\n",
    "authors": [
      "Luis Felipe Cruz Figueredo",
      "Bruno Vilhena Adorno",
      "Jo\u00e3o Yoshiyuki Ishihara"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1811.05436"
  },
  {
    "id": "arXiv:1901.09723",
    "title": "Edge, Ridge, and Blob Detection with Symmetric Molecules",
    "abstract": "Comments: Accepted version. Supplemental materials available at www.math.uni-bremen.de/cda/publications.html",
    "descriptor": "\nComments: Accepted version. Supplemental materials available at www.math.uni-bremen.de/cda/publications.html\n",
    "authors": [
      "Rafael Reisenhofer",
      "Emily J. King"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1901.09723"
  },
  {
    "id": "arXiv:1902.01810",
    "title": "Exact Markov Chain-based Runtime Analysis of a Discrete Particle Swarm  Optimization Algorithm on Sorting and OneMax",
    "abstract": "Exact Markov Chain-based Runtime Analysis of a Discrete Particle Swarm  Optimization Algorithm on Sorting and OneMax",
    "descriptor": "",
    "authors": [
      "Moritz M\u00fchlenthaler",
      "Alexander Ra\u00df",
      "Manuel Schmitt",
      "Rolf Wanka"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1902.01810"
  },
  {
    "id": "arXiv:1902.07247",
    "title": "Fast Neural Network Verification via Shadow Prices",
    "abstract": "Fast Neural Network Verification via Shadow Prices",
    "descriptor": "",
    "authors": [
      "Vicenc Rubies-Royo",
      "Roberto Calandra",
      "Dusan M. Stipanovic",
      "Claire Tomlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1902.07247"
  },
  {
    "id": "arXiv:1903.10143",
    "title": "Unconstrained Facial Action Unit Detection via Latent Feature Domain",
    "abstract": "Comments: This paper has been accepted by IEEE Transactions on Affective Computing",
    "descriptor": "\nComments: This paper has been accepted by IEEE Transactions on Affective Computing\n",
    "authors": [
      "Zhiwen Shao",
      "Jianfei Cai",
      "Tat-Jen Cham",
      "Xuequan Lu",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1903.10143"
  },
  {
    "id": "arXiv:1904.12144",
    "title": "IsMo-GAN: Adversarial Learning for Monocular Non-Rigid 3D Reconstruction",
    "abstract": "Comments: 13 pages, 11 figures, 4 tables, 6 sections, 73 references",
    "descriptor": "\nComments: 13 pages, 11 figures, 4 tables, 6 sections, 73 references\n",
    "authors": [
      "Soshi Shimada",
      "Vladislav Golyanik",
      "Christian Theobalt",
      "Didier Stricker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1904.12144"
  },
  {
    "id": "arXiv:1906.03365",
    "title": "Global Semantic Description of Objects based on Prototype Theory",
    "abstract": "Comments: Content: 24 pages (22 + 2 reference) with 15 Figures and 3 Tables. In the future, a new version will be updated with other experiments and results (and a journal reference if applicable)",
    "descriptor": "\nComments: Content: 24 pages (22 + 2 reference) with 15 Figures and 3 Tables. In the future, a new version will be updated with other experiments and results (and a journal reference if applicable)\n",
    "authors": [
      "Omar Vidal Pino",
      "Erickson Rangel Nascimento",
      "Mario Fernando Montenegro Campos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1906.03365"
  },
  {
    "id": "arXiv:1907.03452",
    "title": "Deep splitting method for parabolic PDEs",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Christian Beck",
      "Sebastian Becker",
      "Patrick Cheridito",
      "Arnulf Jentzen",
      "Ariel Neufeld"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1907.03452"
  },
  {
    "id": "arXiv:1907.04505",
    "title": "An Algorithmic Framework for Approximating Maximin Share Allocation of  Chores",
    "abstract": "Comments: In Proceedings of the 22nd ACM Conference on Economics and Computation (EC '21)",
    "descriptor": "\nComments: In Proceedings of the 22nd ACM Conference on Economics and Computation (EC '21)\n",
    "authors": [
      "Xin Huang",
      "Pinyan Lu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1907.04505"
  },
  {
    "id": "arXiv:1909.05694",
    "title": "Repeat-Free Codes",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Ohad Elishco",
      "Ryan Gabrys",
      "Eitan Yaakobi",
      "Muriel M\u00e9dard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1909.05694"
  },
  {
    "id": "arXiv:1909.06865",
    "title": "I-MAD: Interpretable Malware Detector Using Galaxy Transformer",
    "abstract": "Comments: Published by Elsevier Computers & Security",
    "descriptor": "\nComments: Published by Elsevier Computers & Security\n",
    "authors": [
      "Miles Q. Li",
      "Benjamin C. M. Fung",
      "Philippe Charland",
      "Steven H.H. Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.06865"
  },
  {
    "id": "arXiv:1909.11564",
    "title": "Analytical confidence intervals for the number of different objects in  data streams",
    "abstract": "Comments: accepted version",
    "descriptor": "\nComments: accepted version\n",
    "authors": [
      "Giacomo Aletti"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.11564"
  },
  {
    "id": "arXiv:1910.03384",
    "title": "Experimental Validation of Feedback Optimization in Power Distribution  Grids",
    "abstract": "Experimental Validation of Feedback Optimization in Power Distribution  Grids",
    "descriptor": "",
    "authors": [
      "Lukas Ortmann",
      "Adrian Hauswirth",
      "Ivo Caduff",
      "Florian D\u00f6rfler",
      "Saverio Bolognani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1910.03384"
  },
  {
    "id": "arXiv:1910.06552",
    "title": "Improved Generalization Bounds of Group Invariant / Equivariant Deep  Networks via Quotient Feature Spaces",
    "abstract": "Comments: Old title: \"Improved Generalization Bound of Permutation Invariant Deep Neural Networks\"",
    "descriptor": "\nComments: Old title: \"Improved Generalization Bound of Permutation Invariant Deep Neural Networks\"\n",
    "authors": [
      "Akiyoshi Sannai",
      "Masaaki Imaizumi",
      "Makoto Kawano"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.06552"
  },
  {
    "id": "arXiv:1910.09796",
    "title": "Fine-grained Fact Verification with Kernel Graph Attention Network",
    "abstract": "Comments: Accepted to ACL 2020, 10 pages, 6 figures",
    "descriptor": "\nComments: Accepted to ACL 2020, 10 pages, 6 figures\n",
    "authors": [
      "Zhenghao Liu",
      "Chenyan Xiong",
      "Maosong Sun",
      "Zhiyuan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1910.09796"
  },
  {
    "id": "arXiv:1910.10174",
    "title": "Leveraging directed causal discovery to detect latent common causes",
    "abstract": "Comments: Presented at Frontiers of AI-Assisted Care 2019 (Scientific Symposium, Stanford Medicine). 13 pages, 5 figures, 4 tables. Comments welcome",
    "descriptor": "\nComments: Presented at Frontiers of AI-Assisted Care 2019 (Scientific Symposium, Stanford Medicine). 13 pages, 5 figures, 4 tables. Comments welcome\n",
    "authors": [
      "Ciar\u00e1n M. Lee",
      "Christopher Hart",
      "Jonathan G. Richens",
      "Saurabh Johri"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.10174"
  },
  {
    "id": "arXiv:1911.13136",
    "title": "A Multilayered Block Network Model to Forecast Large Dynamic  Transportation Graphs: an Application to US Air Transport",
    "abstract": "A Multilayered Block Network Model to Forecast Large Dynamic  Transportation Graphs: an Application to US Air Transport",
    "descriptor": "",
    "authors": [
      "Hector Rodriguez-Deniz",
      "Mattias Villani",
      "Augusto Voltes-Dorta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/1911.13136"
  },
  {
    "id": "arXiv:1912.01238",
    "title": "Overcoming Catastrophic Forgetting by Generative Regularization",
    "abstract": "Overcoming Catastrophic Forgetting by Generative Regularization",
    "descriptor": "",
    "authors": [
      "Patrick H. Chen",
      "Wei Wei",
      "Cho-jui Hsieh",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.01238"
  },
  {
    "id": "arXiv:2001.00562",
    "title": "Optimal Entropy Compression and Purification in Quantum Bits",
    "abstract": "Comments: 26 pages, 12 + 1 (external) figures; v3: revised manuscript",
    "descriptor": "\nComments: 26 pages, 12 + 1 (external) figures; v3: revised manuscript\n",
    "authors": [
      "Varad R. Pande"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2001.00562"
  },
  {
    "id": "arXiv:2001.04515",
    "title": "Statistical Inference of the Value Function for Reinforcement Learning  in Infinite Horizon Settings",
    "abstract": "Statistical Inference of the Value Function for Reinforcement Learning  in Infinite Horizon Settings",
    "descriptor": "",
    "authors": [
      "C. Shi",
      "S. Zhang",
      "W. Lu",
      "R. Song"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.04515"
  },
  {
    "id": "arXiv:2001.04787",
    "title": "What's Live? Understanding Distributed Consensus",
    "abstract": "What's Live? Understanding Distributed Consensus",
    "descriptor": "",
    "authors": [
      "Saksham Chand",
      "Yanhong A Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2001.04787"
  },
  {
    "id": "arXiv:2001.09590",
    "title": "Energy conserving SUPG methods for compatible finite element schemes in  numerical weather prediction",
    "abstract": "Comments: 32 pages, 12 figures; main differences to first version: simplified formulation for auxiliary SUPG operator, improved numerical results section",
    "descriptor": "\nComments: 32 pages, 12 figures; main differences to first version: simplified formulation for auxiliary SUPG operator, improved numerical results section\n",
    "authors": [
      "Golo A. Wimmer",
      "Colin J. Cotter",
      "Werner Bauer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2001.09590"
  },
  {
    "id": "arXiv:2001.11593",
    "title": "Authorship Attribution of Source Code: A Language-Agnostic Approach and  Applicability in Software Engineering",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Egor Bogomolov",
      "Vladimir Kovalenko",
      "Yurii Rebryk",
      "Alberto Bacchelli",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2001.11593"
  },
  {
    "id": "arXiv:2002.03580",
    "title": "Combinatorial Semi-Bandit in the Non-Stationary Environment",
    "abstract": "Comments: Accepted to UAI 2021",
    "descriptor": "\nComments: Accepted to UAI 2021\n",
    "authors": [
      "Wei Chen",
      "Liwei Wang",
      "Haoyu Zhao",
      "Kai Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.03580"
  },
  {
    "id": "arXiv:2002.11213",
    "title": "Speech2Phone: A Novel and Efficient Method for Training Speaker  Recognition Models",
    "abstract": "Comments: Submitted to BRACIS",
    "descriptor": "\nComments: Submitted to BRACIS\n",
    "authors": [
      "Edresson Casanova",
      "Arnaldo Candido Junior",
      "Christopher Shulby",
      "Frederico Santos de Oliveira",
      "Lucas Rafael Stefanel Gris",
      "Hamilton Pereira da Silva",
      "Sandra Maria Aluisio",
      "Moacir Antonelli Ponti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2002.11213"
  },
  {
    "id": "arXiv:2002.12162",
    "title": "Defending against Backdoor Attack on Deep Neural Networks",
    "abstract": "Comments: This workshop manuscript is not a publication and will not be published anywhere",
    "descriptor": "\nComments: This workshop manuscript is not a publication and will not be published anywhere\n",
    "authors": [
      "Kaidi Xu",
      "Sijia Liu",
      "Pin-Yu Chen",
      "Pu Zhao",
      "Xue Lin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.12162"
  },
  {
    "id": "arXiv:2003.05738",
    "title": "IG-RL: Inductive Graph Reinforcement Learning for Massive-Scale Traffic  Signal Control",
    "abstract": "Comments: 11 pages, 10 figures, 1 table. IEEE Transactions on Intelligent Transportation Systems (2021)",
    "descriptor": "\nComments: 11 pages, 10 figures, 1 table. IEEE Transactions on Intelligent Transportation Systems (2021)\n",
    "authors": [
      "Fran\u00e7ois-Xavier Devailly",
      "Denis Larocque",
      "Laurent Charlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.05738"
  },
  {
    "id": "arXiv:2003.07584",
    "title": "SiamSNN: Siamese Spiking Neural Networks for Energy-Efficient Object  Tracking",
    "abstract": "Comments: Accepted by ICANN2021, 12 pages, 5figures",
    "descriptor": "\nComments: Accepted by ICANN2021, 12 pages, 5figures\n",
    "authors": [
      "Yihao Luo",
      "Min Xu",
      "Caihong Yuan",
      "Xiang Cao",
      "Liangqi Zhang",
      "Yan Xu",
      "Tianjiang Wang",
      "Qi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2003.07584"
  },
  {
    "id": "arXiv:2003.10392",
    "title": "Steepest Descent Neural Architecture Optimization: Escaping Local  Optimum with Signed Neural Splitting",
    "abstract": "Steepest Descent Neural Architecture Optimization: Escaping Local  Optimum with Signed Neural Splitting",
    "descriptor": "",
    "authors": [
      "Lemeng Wu",
      "Mao Ye",
      "Qi Lei",
      "Jason D. Lee",
      "Qiang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.10392"
  },
  {
    "id": "arXiv:2003.12665",
    "title": "Distributed and time-varying primal-dual dynamics via contraction  analysis",
    "abstract": "Distributed and time-varying primal-dual dynamics via contraction  analysis",
    "descriptor": "",
    "authors": [
      "Pedro Cisneros-Velarde",
      "Saber Jafarpour",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2003.12665"
  },
  {
    "id": "arXiv:2004.03924",
    "title": "Densities of Almost Surely Terminating Probabilistic Programs are  Differentiable Almost Everywhere",
    "abstract": "Densities of Almost Surely Terminating Probabilistic Programs are  Differentiable Almost Everywhere",
    "descriptor": "",
    "authors": [
      "Carol Mak",
      "C.-H. Luke Ong",
      "Hugo Paquet",
      "Dominik Wagner"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2004.03924"
  },
  {
    "id": "arXiv:2004.07574",
    "title": "A polynomial time algorithm for solving the closest vector problem in  zonotopal lattices",
    "abstract": "Comments: 12 pages, v3: Comments of referees incorporated, to appear in SIAM Journal on Discrete Mathematics (SIDMA)",
    "descriptor": "\nComments: 12 pages, v3: Comments of referees incorporated, to appear in SIAM Journal on Discrete Mathematics (SIDMA)\n",
    "authors": [
      "S. Thomas McCormick",
      "Britta Peis",
      "Robert Scheidweiler",
      "Frank Vallentin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Metric Geometry (math.MG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2004.07574"
  },
  {
    "id": "arXiv:2004.09508",
    "title": "Adversarial Distortion for Learned Video Compression",
    "abstract": "Comments: CVPR Workshops, 2020",
    "descriptor": "\nComments: CVPR Workshops, 2020\n",
    "authors": [
      "Vijay Veerabadran",
      "Reza Pourreza",
      "Amirhossein Habibian",
      "Taco Cohen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.09508"
  },
  {
    "id": "arXiv:2004.09928",
    "title": "Principled approach to the selection of the embedding dimension of  networks",
    "abstract": "Comments: 13 pages, 5 figures, Supplementary Information available this this http URL",
    "descriptor": "\nComments: 13 pages, 5 figures, Supplementary Information available this this http URL\n",
    "authors": [
      "Weiwei Gu",
      "Aditya Tandon",
      "Yong-Yeol Ahn",
      "Filippo Radicchi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2004.09928"
  },
  {
    "id": "arXiv:2005.00146",
    "title": "Addressing Catastrophic Forgetting in Few-Shot Problems",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Pauching Yap",
      "Hippolyt Ritter",
      "David Barber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.00146"
  },
  {
    "id": "arXiv:2005.05719",
    "title": "Smooth Exploration for Robotic Reinforcement Learning",
    "abstract": "Comments: Code: this https URL Training scripts: this https URL",
    "descriptor": "\nComments: Code: this https URL Training scripts: this https URL\n",
    "authors": [
      "Antonin Raffin",
      "Jens Kober",
      "Freek Stulp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.05719"
  },
  {
    "id": "arXiv:2005.08090",
    "title": "FiberStars: Visual Comparison of Diffusion Tractography Data between  Multiple Subjects",
    "abstract": "Comments: 10 pages, 9 figures",
    "descriptor": "\nComments: 10 pages, 9 figures\n",
    "authors": [
      "Loraine Franke",
      "Daniel Karl I. Weidele",
      "Fan Zhang",
      "Suheyla Cetin-Karayumak",
      "Steve Pieper",
      "Lauren J. O'Donnell",
      "Yogesh Rathi",
      "Daniel Haehn"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2005.08090"
  },
  {
    "id": "arXiv:2005.09532",
    "title": "Scalable Privacy-Preserving Distributed Learning",
    "abstract": "Comments: Accepted for publication at the 21st Privacy Enhancing Technologies Symposium (PETS 2021)",
    "descriptor": "\nComments: Accepted for publication at the 21st Privacy Enhancing Technologies Symposium (PETS 2021)\n",
    "authors": [
      "David Froelicher",
      "Juan R. Troncoso-Pastoriza",
      "Apostolos Pyrgelis",
      "Sinem Sav",
      "Joao Sa Sousa",
      "Jean-Philippe Bossuat",
      "Jean-Pierre Hubaux"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2005.09532"
  },
  {
    "id": "arXiv:2005.09547",
    "title": "Throughput and Age of Information in a Cellular-based IoT Network",
    "abstract": "Throughput and Age of Information in a Cellular-based IoT Network",
    "descriptor": "",
    "authors": [
      "Praful D. Mankar",
      "Zheng Chen",
      "Mohamed A. Abd-Elmagid",
      "Nikolaos Pappas",
      "Harpreet S. Dhillon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2005.09547"
  },
  {
    "id": "arXiv:2005.11949",
    "title": "Approximation in shift-invariant spaces with deep ReLU neural networks",
    "abstract": "Approximation in shift-invariant spaces with deep ReLU neural networks",
    "descriptor": "",
    "authors": [
      "Yunfei Yang",
      "Zhen Li",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.11949"
  },
  {
    "id": "arXiv:2006.02684",
    "title": "Stochastic Graph Neural Networks",
    "abstract": "Stochastic Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Zhan Gao",
      "Elvin Isufi",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.02684"
  },
  {
    "id": "arXiv:2006.03258",
    "title": "Learned Factor Graphs for Inference from Stationary Time Sequences",
    "abstract": "Learned Factor Graphs for Inference from Stationary Time Sequences",
    "descriptor": "",
    "authors": [
      "Nir Shlezinger",
      "Nariman Farsad",
      "Yonina C. Eldar",
      "Andrea J. Goldsmith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.03258"
  },
  {
    "id": "arXiv:2006.04628",
    "title": "Model-agnostic Feature Importance and Effects with Dependent Features --  A Conditional Subgroup Approach",
    "abstract": "Model-agnostic Feature Importance and Effects with Dependent Features --  A Conditional Subgroup Approach",
    "descriptor": "",
    "authors": [
      "Christoph Molnar",
      "Gunnar K\u00f6nig",
      "Bernd Bischl",
      "Giuseppe Casalicchio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.04628"
  },
  {
    "id": "arXiv:2006.05109",
    "title": "Fair Bayesian Optimization",
    "abstract": "Fair Bayesian Optimization",
    "descriptor": "",
    "authors": [
      "Valerio Perrone",
      "Michele Donini",
      "Muhammad Bilal Zafar",
      "Robin Schmucker",
      "Krishnaram Kenthapadi",
      "C\u00e9dric Archambeau"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.05109"
  },
  {
    "id": "arXiv:2006.05139",
    "title": "PIVEN: A Deep Neural Network for Prediction Intervals with Specific  Value Prediction",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Eli Simhayev",
      "Gilad Katz",
      "Lior Rokach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05139"
  },
  {
    "id": "arXiv:2006.06608",
    "title": "GNNAdvisor: An Adaptive and Efficient Runtime System for GNN  Acceleration on GPUs",
    "abstract": "GNNAdvisor: An Adaptive and Efficient Runtime System for GNN  Acceleration on GPUs",
    "descriptor": "",
    "authors": [
      "Yuke Wang",
      "Boyuan Feng",
      "Gushu Li",
      "Shuangchen Li",
      "Lei Deng",
      "Yuan Xie",
      "Yufei Ding"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2006.06608"
  },
  {
    "id": "arXiv:2006.07134",
    "title": "Tight Differential Privacy for Discrete-Valued Mechanisms and for the  Subsampled Gaussian Mechanism Using FFT",
    "abstract": "Comments: 41 pages, 5 figures",
    "descriptor": "\nComments: 41 pages, 5 figures\n",
    "authors": [
      "Antti Koskela",
      "Joonas J\u00e4lk\u00f6",
      "Lukas Prediger",
      "Antti Honkela"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.07134"
  },
  {
    "id": "arXiv:2006.10102",
    "title": "Capturing Label Characteristics in VAEs",
    "abstract": "Comments: Accepted to ICLR 2021",
    "descriptor": "\nComments: Accepted to ICLR 2021\n",
    "authors": [
      "Tom Joy",
      "Sebastian M. Schmon",
      "Philip H. S. Torr",
      "N. Siddharth",
      "Tom Rainforth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10102"
  },
  {
    "id": "arXiv:2006.10114",
    "title": "Constraint-Based Regularization of Neural Networks",
    "abstract": "Comments: T. Vlaar won best student paper award at OPT2020",
    "descriptor": "\nComments: T. Vlaar won best student paper award at OPT2020\n",
    "authors": [
      "Benedict Leimkuhler",
      "Timoth\u00e9e Pouchon",
      "Tiffany Vlaar",
      "Amos Storkey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10114"
  },
  {
    "id": "arXiv:2006.10159",
    "title": "Automatic heterogeneous quantization of deep neural networks for  low-latency inference on the edge for particle detectors",
    "abstract": "Automatic heterogeneous quantization of deep neural networks for  low-latency inference on the edge for particle detectors",
    "descriptor": "",
    "authors": [
      "Claudionor N. Coelho Jr.",
      "Aki Kuusela",
      "Shan Li",
      "Hao Zhuang",
      "Thea Aarrestad",
      "Vladimir Loncar",
      "Jennifer Ngadiuba",
      "Maurizio Pierini",
      "Adrian Alan Pol",
      "Sioni Summers"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2006.10159"
  },
  {
    "id": "arXiv:2006.12135",
    "title": "Learning to Generate Noise for Multi-Attack Robustness",
    "abstract": "Comments: Accepted to ICML 2021. Code available at this https URL",
    "descriptor": "\nComments: Accepted to ICML 2021. Code available at this https URL\n",
    "authors": [
      "Divyam Madaan",
      "Jinwoo Shin",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.12135"
  },
  {
    "id": "arXiv:2006.13135",
    "title": "Estimation of Causal Effects in the Presence of Unobserved Confounding  in the Alzheimer's Continuum",
    "abstract": "Comments: Accepted as oral presentation at 2021 International Conference on Information Processing in Medical Imaging (IPMI)",
    "descriptor": "\nComments: Accepted as oral presentation at 2021 International Conference on Information Processing in Medical Imaging (IPMI)\n",
    "authors": [
      "Sebastian P\u00f6lsterl",
      "Christian Wachinger"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2006.13135"
  },
  {
    "id": "arXiv:2006.14969",
    "title": "Fully Abstract and Robust Compilation and How to Reconcile the Two,  Abstractly",
    "abstract": "Fully Abstract and Robust Compilation and How to Reconcile the Two,  Abstractly",
    "descriptor": "",
    "authors": [
      "Carmine Abate",
      "Matteo Busi",
      "Stelios Tsampas"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2006.14969"
  },
  {
    "id": "arXiv:2006.15007",
    "title": "Database Reconstruction from Noisy Volumes: A Cache Side-Channel Attack  on SQLite",
    "abstract": "Comments: Source code : this https URL",
    "descriptor": "\nComments: Source code : this https URL\n",
    "authors": [
      "Aria Shahverdi",
      "Mahammad Shirinov",
      "Dana Dachman-Soled"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2006.15007"
  },
  {
    "id": "arXiv:2007.00113",
    "title": "Long-term Pedestrian Trajectory Prediction using Mutable Intention  Filter and Warp LSTM",
    "abstract": "Comments: Accepted by RA-L Special Issue on Long-Term Human Motion Prediction",
    "descriptor": "\nComments: Accepted by RA-L Special Issue on Long-Term Human Motion Prediction\n",
    "authors": [
      "Zhe Huang",
      "Aamir Hasan",
      "Kazuki Shin",
      "Ruohua Li",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.00113"
  },
  {
    "id": "arXiv:2007.00189",
    "title": "A Posteriori Error Estimates for Solving Graph Laplacians",
    "abstract": "A Posteriori Error Estimates for Solving Graph Laplacians",
    "descriptor": "",
    "authors": [
      "Xiaozhe Hu",
      "Kaiyi Wu",
      "Ludmil T. Zikatanov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2007.00189"
  },
  {
    "id": "arXiv:2007.04626",
    "title": "DISCO PAL: Diachronic Spanish Sonnet Corpus with Psychological and  Affective Labels",
    "abstract": "Comments: 24 pages, 3 figures, 17 tables",
    "descriptor": "\nComments: 24 pages, 3 figures, 17 tables\n",
    "authors": [
      "Alberto Barbado",
      "V\u00edctor Fresno",
      "\u00c1ngeles Manjarr\u00e9s Riesco",
      "Salvador Ros"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2007.04626"
  },
  {
    "id": "arXiv:2007.05674",
    "title": "Illuminating Mario Scenes in the Latent Space of a Generative  Adversarial Network",
    "abstract": "Comments: Accepted to AAAI 2021",
    "descriptor": "\nComments: Accepted to AAAI 2021\n",
    "authors": [
      "Matthew C. Fontaine",
      "Ruilin Liu",
      "Ahmed Khalifa",
      "Jignesh Modi",
      "Julian Togelius",
      "Amy K. Hoover",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2007.05674"
  },
  {
    "id": "arXiv:2007.06934",
    "title": "CoreGen: Contextualized Code Representation Learning for Commit Message  Generation",
    "abstract": "Comments: [J]. Neurocomputing, 2021",
    "descriptor": "\nComments: [J]. Neurocomputing, 2021\n",
    "authors": [
      "Lun Yiu Nie",
      "Cuiyun Gao",
      "Zhicong Zhong",
      "Wai Lam",
      "Yang Liu",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2007.06934"
  },
  {
    "id": "arXiv:2007.12247",
    "title": "On Solving Word Equations via Program Transformation",
    "abstract": "Comments: Another version of this work will be uploaded on arXiv by eptcs",
    "descriptor": "\nComments: Another version of this work will be uploaded on arXiv by eptcs\n",
    "authors": [
      "Antonina Nepeivoda"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2007.12247"
  },
  {
    "id": "arXiv:2007.12391",
    "title": "Artificial Intelligence in the Creative Industries: A Review",
    "abstract": "Comments: Accepted for publication in Artificial Intelligence Review (AIRE)",
    "descriptor": "\nComments: Accepted for publication in Artificial Intelligence Review (AIRE)\n",
    "authors": [
      "Nantheera Anantrasirichai",
      "David Bull"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.12391"
  },
  {
    "id": "arXiv:2007.16041",
    "title": "Whole MILC: generalizing learned dynamics across tasks, datasets, and  populations",
    "abstract": "Comments: Accepted at MICCAI 2020. arXiv admin note: substantial text overlap with arXiv:1912.03130",
    "descriptor": "\nComments: Accepted at MICCAI 2020. arXiv admin note: substantial text overlap with arXiv:1912.03130\n",
    "authors": [
      "Usman Mahmood",
      "Md Mahfuzur Rahman",
      "Alex Fedorov",
      "Noah Lewis",
      "Zening Fu",
      "Vince D. Calhoun",
      "Sergey M. Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.16041"
  },
  {
    "id": "arXiv:2007.16192",
    "title": "Contiguous Graph Partitioning For Optimal Total Or Bottleneck  Communication",
    "abstract": "Comments: 20 pages; added total partitioning algorithm, added total costs, added experimental results, added lazy near-linear bisection algorithm, simplified presentation. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 20 pages; added total partitioning algorithm, added total costs, added experimental results, added lazy near-linear bisection algorithm, simplified presentation. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Peter Ahrens"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2007.16192"
  },
  {
    "id": "arXiv:2008.01663",
    "title": "Efficient Urdu Caption Generation using Attention based LSTM",
    "abstract": "Comments: This a project report of Deep Learning subject taught at Information Technology University, Lahore, Pakistan by Dr. Mohsen Ali",
    "descriptor": "\nComments: This a project report of Deep Learning subject taught at Information Technology University, Lahore, Pakistan by Dr. Mohsen Ali\n",
    "authors": [
      "Inaam Ilahi",
      "Hafiz Muhammad Abdullah Zia",
      "Muhammad Ahtazaz Ahsan",
      "Rauf Tabassam",
      "Armaghan Ahmed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.01663"
  },
  {
    "id": "arXiv:2008.04847",
    "title": "IGANI: Iterative Generative Adversarial Networks for Imputation with  Application to Traffic Data",
    "abstract": "IGANI: Iterative Generative Adversarial Networks for Imputation with  Application to Traffic Data",
    "descriptor": "",
    "authors": [
      "Amir Kazemi",
      "Hadi Meidani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2008.04847"
  },
  {
    "id": "arXiv:2008.05816",
    "title": "Guaranteed upper bounds for the velocity error of pressure-robust Stokes  discretisations",
    "abstract": "Guaranteed upper bounds for the velocity error of pressure-robust Stokes  discretisations",
    "descriptor": "",
    "authors": [
      "Philip L. Lederer",
      "Christian Merdon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.05816"
  },
  {
    "id": "arXiv:2008.08652",
    "title": "The Organization of Software Teams in the Quest for Continuous Delivery:  A Grounded Theory Approach",
    "abstract": "Comments: Version accepted for publication in the Information and Software Technology journal (Jun, 2021)",
    "descriptor": "\nComments: Version accepted for publication in the Information and Software Technology journal (Jun, 2021)\n",
    "authors": [
      "Leonardo Leite",
      "Gustavo Pinto",
      "Fabio Kon",
      "Paulo Meirelles"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2008.08652"
  },
  {
    "id": "arXiv:2008.08930",
    "title": "A Systematic Survey of Regularization and Normalization in GANs",
    "abstract": "A Systematic Survey of Regularization and Normalization in GANs",
    "descriptor": "",
    "authors": [
      "Ziqiang Li",
      "Xintian Wu",
      "Muhammad Usman",
      "Rentuo Tao",
      "Pengfei Xia",
      "Huanhuan Chen",
      "Bin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2008.08930"
  },
  {
    "id": "arXiv:2008.08937",
    "title": "Institutional Grammar 2.0 Codebook",
    "abstract": "Comments: 120 pages, 16 figures, 14 tables",
    "descriptor": "\nComments: 120 pages, 16 figures, 14 tables\n",
    "authors": [
      "Christopher K. Frantz",
      "Saba N. Siddiki"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.08937"
  },
  {
    "id": "arXiv:2008.09112",
    "title": "Inducing Language-Agnostic Multilingual Representations",
    "abstract": "Comments: *SEM2021 Camera Ready",
    "descriptor": "\nComments: *SEM2021 Camera Ready\n",
    "authors": [
      "Wei Zhao",
      "Steffen Eger",
      "Johannes Bjerva",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2008.09112"
  },
  {
    "id": "arXiv:2008.09376",
    "title": "Optimal SNR Analysis for Single-user RIS Systems",
    "abstract": "Comments: 6 pages, 4 figures. Keywords: Reconfigurable Intelligent Surface (RIS), Intelligent Reflecting Surface (IRS)",
    "descriptor": "\nComments: 6 pages, 4 figures. Keywords: Reconfigurable Intelligent Surface (RIS), Intelligent Reflecting Surface (IRS)\n",
    "authors": [
      "Ikram Singh",
      "Peter J. Smith",
      "Pawel A. Dmochowski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2008.09376"
  },
  {
    "id": "arXiv:2008.12671",
    "title": "Data-driven control on encrypted data",
    "abstract": "Data-driven control on encrypted data",
    "descriptor": "",
    "authors": [
      "Andreea B. Alexandru",
      "Anastasios Tsiamis",
      "George J. Pappas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.12671"
  },
  {
    "id": "arXiv:2009.02030",
    "title": "Evaluating the Security and Economic Effects of Moving Target Defense  Techniques on the Cloud",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Hooman Alavizadeh",
      "Samin Aref",
      "Dong Seong Kim",
      "Julian Jang-Jaccard"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2009.02030"
  },
  {
    "id": "arXiv:2009.05092",
    "title": "Dialogue Relation Extraction with Document-level Heterogeneous Graph  Attention Networks",
    "abstract": "Dialogue Relation Extraction with Document-level Heterogeneous Graph  Attention Networks",
    "descriptor": "",
    "authors": [
      "Hui Chen",
      "Pengfei Hong",
      "Wei Han",
      "Navonil Majumder",
      "Soujanya Poria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.05092"
  },
  {
    "id": "arXiv:2009.05839",
    "title": "On topology optimization of design-dependent pressure-loaded  three-dimensional structures and compliant mechanisms",
    "abstract": "Comments: 25 pages, 17 figures",
    "descriptor": "\nComments: 25 pages, 17 figures\n",
    "authors": [
      "Prabhat Kumar",
      "Matthijs Langelaar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2009.05839"
  },
  {
    "id": "arXiv:2009.06861",
    "title": "Privacy in Targeted Advertising: A Survey",
    "abstract": "Privacy in Targeted Advertising: A Survey",
    "descriptor": "",
    "authors": [
      "Imdad Ullah",
      "Roksana Boreli",
      "Salil S. Kanhere"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2009.06861"
  },
  {
    "id": "arXiv:2009.08102",
    "title": "Time series forecasting with Gaussian Processes needs priors",
    "abstract": "Time series forecasting with Gaussian Processes needs priors",
    "descriptor": "",
    "authors": [
      "Giorgio Corani",
      "Alessio Benavoli",
      "Marco Zaffalon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.08102"
  },
  {
    "id": "arXiv:2009.08295",
    "title": "Neural Rough Differential Equations for Long Time Series",
    "abstract": "Comments: Published at ICML 2021",
    "descriptor": "\nComments: Published at ICML 2021\n",
    "authors": [
      "James Morrill",
      "Cristopher Salvi",
      "Patrick Kidger",
      "James Foster",
      "Terry Lyons"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.08295"
  },
  {
    "id": "arXiv:2009.11435",
    "title": "Fully Dynamic Approximate Maximum Independent Set on Massive Graphs",
    "abstract": "Fully Dynamic Approximate Maximum Independent Set on Massive Graphs",
    "descriptor": "",
    "authors": [
      "Xiangyu Gao",
      "Jianzhong Li",
      "Dongjing Miao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2009.11435"
  },
  {
    "id": "arXiv:2009.14388",
    "title": "Secure Aggregation with Heterogeneous Quantization in Federated Learning",
    "abstract": "Secure Aggregation with Heterogeneous Quantization in Federated Learning",
    "descriptor": "",
    "authors": [
      "Ahmed Roushdy Elkordy",
      "A. Salman Avestimehr"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.14388"
  },
  {
    "id": "arXiv:2010.01464",
    "title": "LEGAN: Disentangled Manipulation of Directional Lighting and Facial  Expressions by Leveraging Human Perceptual Judgements",
    "abstract": "Comments: AMFG Workshop at CVPR 2021 (CVPRW 2021). Get our synthetic face images & their perceptual labels here: this https URL",
    "descriptor": "\nComments: AMFG Workshop at CVPR 2021 (CVPRW 2021). Get our synthetic face images & their perceptual labels here: this https URL\n",
    "authors": [
      "Sandipan Banerjee",
      "Ajjen Joshi",
      "Prashant Mahajan",
      "Sneha Bhattacharya",
      "Survi Kyal",
      "Taniya Mishra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.01464"
  },
  {
    "id": "arXiv:2010.01875",
    "title": "Pointwise Binary Classification with Pairwise Confidence Comparisons",
    "abstract": "Comments: Accepted to ICML 2021",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Lei Feng",
      "Senlin Shu",
      "Nan Lu",
      "Bo Han",
      "Miao Xu",
      "Gang Niu",
      "Bo An",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.01875"
  },
  {
    "id": "arXiv:2010.03250",
    "title": "DiffMG: Differentiable Meta Graph Search for Heterogeneous Graph Neural  Networks",
    "abstract": "Comments: KDD 2021, Research Track",
    "descriptor": "\nComments: KDD 2021, Research Track\n",
    "authors": [
      "Yuhui Ding",
      "Quanming Yao",
      "Huan Zhao",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2010.03250"
  },
  {
    "id": "arXiv:2010.03792",
    "title": "The Adaptive Doubly Robust Estimator for Policy Evaluation in Adaptive  Experiments and a Paradox Concerning Logging Policy",
    "abstract": "The Adaptive Doubly Robust Estimator for Policy Evaluation in Adaptive  Experiments and a Paradox Concerning Logging Policy",
    "descriptor": "",
    "authors": [
      "Masahiro Kato",
      "Shota Yasui",
      "Kenichiro McAlinn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.03792"
  },
  {
    "id": "arXiv:2010.07488",
    "title": "RetiNerveNet: Using Recursive Deep Learning to Estimate Pointwise 24-2  Visual Field Data based on Retinal Structure",
    "abstract": "RetiNerveNet: Using Recursive Deep Learning to Estimate Pointwise 24-2  Visual Field Data based on Retinal Structure",
    "descriptor": "",
    "authors": [
      "Shounak Datta",
      "Eduardo B. Mariottoni",
      "David Dov",
      "Alessandro A. Jammal",
      "Lawrence Carin",
      "Felipe A. Medeiros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2010.07488"
  },
  {
    "id": "arXiv:2010.09391",
    "title": "Measuring breathing induced oesophageal motion and its dosimetric impact",
    "abstract": "Comments: The paper got accepted for publication in Physica Medica",
    "descriptor": "\nComments: The paper got accepted for publication in Physica Medica\n",
    "authors": [
      "Tobias Fechter",
      "Sonja Adebahr",
      "Anca-Ligia Grosu",
      "Dimos Baltas"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.09391"
  },
  {
    "id": "arXiv:2010.09954",
    "title": "Improving Dialog Systems for Negotiation with Personality Modeling",
    "abstract": "Comments: ACL 2021. 12 pages, 3 figures",
    "descriptor": "\nComments: ACL 2021. 12 pages, 3 figures\n",
    "authors": [
      "Runzhe Yang",
      "Jingxiao Chen",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.09954"
  },
  {
    "id": "arXiv:2010.11384",
    "title": "A Disentangled Adversarial Neural Topic Model for Separating Opinions  from Plots in User Reviews",
    "abstract": "Comments: Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2021",
    "descriptor": "\nComments: Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2021\n",
    "authors": [
      "Gabriele Pergola",
      "Lin Gui",
      "Yulan He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.11384"
  },
  {
    "id": "arXiv:2010.12773",
    "title": "Structure-Grounded Pretraining for Text-to-SQL",
    "abstract": "Comments: Accepted to NAACL 2021. Please contact the first author for questions regarding the spider-realistic dataset",
    "descriptor": "\nComments: Accepted to NAACL 2021. Please contact the first author for questions regarding the spider-realistic dataset\n",
    "authors": [
      "Xiang Deng",
      "Ahmed Hassan Awadallah",
      "Christopher Meek",
      "Oleksandr Polozov",
      "Huan Sun",
      "Matthew Richardson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.12773"
  },
  {
    "id": "arXiv:2010.12973",
    "title": "Unsupervised Learning of Disentangled Speech Content and Style  Representation",
    "abstract": "Comments: Submitted to Interspeech 2021",
    "descriptor": "\nComments: Submitted to Interspeech 2021\n",
    "authors": [
      "Andros Tjandra",
      "Ruoming Pang",
      "Yu Zhang",
      "Shigeki Karita"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2010.12973"
  },
  {
    "id": "arXiv:2010.13570",
    "title": "On the intrinsic robustness to noise of some leading classifiers and  symmetric loss function -- an empirical evaluation",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Hugo Le Baher",
      "Vincent Lemaire",
      "Romain Trinquart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.13570"
  },
  {
    "id": "arXiv:2010.14680",
    "title": "Learning to Represent Action Values as a Hypergraph on the Action  Vertices",
    "abstract": "Comments: ICLR 2021, code: this https URL",
    "descriptor": "\nComments: ICLR 2021, code: this https URL\n",
    "authors": [
      "Arash Tavakoli",
      "Mehdi Fatemi",
      "Petar Kormushev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.14680"
  },
  {
    "id": "arXiv:2010.14785",
    "title": "Designing Interpretable Approximations to Deep Reinforcement Learning",
    "abstract": "Designing Interpretable Approximations to Deep Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Nathan Dahlin",
      "Krishna Chaitanya Kalagarla",
      "Nikhil Naik",
      "Rahul Jain",
      "Pierluigi Nuzzo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.14785"
  },
  {
    "id": "arXiv:2010.15658",
    "title": "Compressive Sensing and Neural Networks from a Statistical Learning  Perspective",
    "abstract": "Comments: 29 pages, 4 figures",
    "descriptor": "\nComments: 29 pages, 4 figures\n",
    "authors": [
      "Arash Behboodi",
      "Holger Rauhut",
      "Ekkehard Schnoor"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.15658"
  },
  {
    "id": "arXiv:2011.00639",
    "title": "Model-Agnostic Explanations using Minimal Forcing Subsets",
    "abstract": "Comments: International Joint Conference on Neural Networks (IJCNN), 2021",
    "descriptor": "\nComments: International Joint Conference on Neural Networks (IJCNN), 2021\n",
    "authors": [
      "Xing Han",
      "Joydeep Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.00639"
  },
  {
    "id": "arXiv:2011.01051",
    "title": "Differential Dynamic Programming with Nonlinear Safety Constraints Under  System Uncertainties",
    "abstract": "Comments: 8 pages, 6 figures, submitted to IEEE Robotics and Automation Letters",
    "descriptor": "\nComments: 8 pages, 6 figures, submitted to IEEE Robotics and Automation Letters\n",
    "authors": [
      "Gokhan Alcan",
      "Ville Kyrki"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.01051"
  },
  {
    "id": "arXiv:2011.01295",
    "title": "Dirac Assisted Tree Method for 1D Heterogeneous Helmholtz Equations with  Arbitrary Variable Wave Numbers",
    "abstract": "Dirac Assisted Tree Method for 1D Heterogeneous Helmholtz Equations with  Arbitrary Variable Wave Numbers",
    "descriptor": "",
    "authors": [
      "Bin Han",
      "Michelle Michelle",
      "Yau Shu Wong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.01295"
  },
  {
    "id": "arXiv:2011.02803",
    "title": "Intriguing Properties of Contrastive Losses",
    "abstract": "Comments: Technical report. Code at this https URL",
    "descriptor": "\nComments: Technical report. Code at this https URL\n",
    "authors": [
      "Ting Chen",
      "Calvin Luo",
      "Lala Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.02803"
  },
  {
    "id": "arXiv:2011.03688",
    "title": "A fast time-stepping strategy for dynamical systems equipped with a  surrogate model",
    "abstract": "A fast time-stepping strategy for dynamical systems equipped with a  surrogate model",
    "descriptor": "",
    "authors": [
      "Steven Roberts",
      "Andrey A Popov",
      "Arash Sarshar",
      "Adrian Sandu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.03688"
  },
  {
    "id": "arXiv:2011.03891",
    "title": "Channel Pruning Guided by Spatial and Channel Attention for DNNs in  Intelligent Edge Computing",
    "abstract": "Channel Pruning Guided by Spatial and Channel Attention for DNNs in  Intelligent Edge Computing",
    "descriptor": "",
    "authors": [
      "Mengran Liu",
      "Weiwei Fang",
      "Xiaodong Ma",
      "Wenyuan Xu",
      "Naixue Xiong",
      "Yi Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.03891"
  },
  {
    "id": "arXiv:2011.04539",
    "title": "Learning to Localize in New Environments from Synthetic Training Data",
    "abstract": "Comments: 7 pages, 3 figures; in Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2021",
    "descriptor": "\nComments: 7 pages, 3 figures; in Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2021\n",
    "authors": [
      "Dominik Winkelbauer",
      "Maximilian Denninger",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.04539"
  },
  {
    "id": "arXiv:2011.05601",
    "title": "A Nonconvex Framework for Structured Dynamic Covariance Recovery",
    "abstract": "A Nonconvex Framework for Structured Dynamic Covariance Recovery",
    "descriptor": "",
    "authors": [
      "Katherine Tsai",
      "Mladen Kolar",
      "Oluwasanmi Koyejo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2011.05601"
  },
  {
    "id": "arXiv:2011.06158",
    "title": "Mostly Harmless Machine Learning: Learning Optimal Instruments in Linear  IV Models",
    "abstract": "Comments: NeurIPS 2020 Workshop on Machine Learning for Economic Policy",
    "descriptor": "\nComments: NeurIPS 2020 Workshop on Machine Learning for Economic Policy\n",
    "authors": [
      "Jiafeng Chen",
      "Daniel L. Chen",
      "Greg Lewis"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2011.06158"
  },
  {
    "id": "arXiv:2011.07954",
    "title": "Using a Supervised Method without supervision for foreground  segmentation",
    "abstract": "Using a Supervised Method without supervision for foreground  segmentation",
    "descriptor": "",
    "authors": [
      "Levi Kassel",
      "Michael Werman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.07954"
  },
  {
    "id": "arXiv:2011.09735",
    "title": "Decentralized Design and Plug-and-Play Distributed Control for Linear  Multi-Channel Systems",
    "abstract": "Comments: Submitted to IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Taekyoo Kim",
      "Donggil Lee",
      "Hyungbo Shim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.09735"
  },
  {
    "id": "arXiv:2011.12099",
    "title": "Model Order Reduction for Gas and Energy Networks",
    "abstract": "Model Order Reduction for Gas and Energy Networks",
    "descriptor": "",
    "authors": [
      "Christian Himpe",
      "Sara Grundel",
      "Peter Benner"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.12099"
  },
  {
    "id": "arXiv:2011.12950",
    "title": "Space-time Neural Irradiance Fields for Free-Viewpoint Video",
    "abstract": "Comments: Project website: this https URL",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Wenqi Xian",
      "Jia-Bin Huang",
      "Johannes Kopf",
      "Changil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.12950"
  },
  {
    "id": "arXiv:2012.00308",
    "title": "A Stitching Algorithm for Automated Surface Inspection of Rotationally  Symmetric Components",
    "abstract": "Comments: 9 pages, 13 figures",
    "descriptor": "\nComments: 9 pages, 13 figures\n",
    "authors": [
      "Tobias Schlagenhauf",
      "Tim Brander",
      "Juergen Fleischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.00308"
  },
  {
    "id": "arXiv:2012.01198",
    "title": "Production Monitoring to Improve Test Suites",
    "abstract": "Production Monitoring to Improve Test Suites",
    "descriptor": "",
    "authors": [
      "Deepika Tiwari",
      "Long Zhang",
      "Martin Monperrus",
      "Benoit Baudry"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2012.01198"
  },
  {
    "id": "arXiv:2012.02532",
    "title": "DeepSym: Deep Symbol Generation and Rule Learning from Unsupervised  Continuous Robot Interaction for Planning",
    "abstract": "DeepSym: Deep Symbol Generation and Rule Learning from Unsupervised  Continuous Robot Interaction for Planning",
    "descriptor": "",
    "authors": [
      "Alper Ahmetoglu",
      "M. Yunus Seker",
      "Justus Piater",
      "Erhan Oztop",
      "Emre Ugur"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.02532"
  },
  {
    "id": "arXiv:2012.03403",
    "title": "How to Deploy Intelligent Reflecting Surfaces in Wireless Network:  BS-side, User-side, or Both Sides?",
    "abstract": "Comments: This article addresses the important issue of how to deploy IRSs in a wireless network to achieve its optimum performance",
    "descriptor": "\nComments: This article addresses the important issue of how to deploy IRSs in a wireless network to achieve its optimum performance\n",
    "authors": [
      "Changsheng You",
      "Beixiong Zheng",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2012.03403"
  },
  {
    "id": "arXiv:2012.04025",
    "title": "Specification and Verification of Timing Properties in Interoperable  Medical Systems",
    "abstract": "Specification and Verification of Timing Properties in Interoperable  Medical Systems",
    "descriptor": "",
    "authors": [
      "Mahsa Zarneshan",
      "Fatemeh Ghassemi",
      "Ehsan Khamespanah",
      "Marjan Sirjani",
      "John Hatcliff"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2012.04025"
  },
  {
    "id": "arXiv:2012.04283",
    "title": "A Quality Diversity Approach to Automatically Generating Human-Robot  Interaction Scenarios in Shared Autonomy",
    "abstract": "Comments: Accepted to Robotics: Science and Systems (RSS) 2021",
    "descriptor": "\nComments: Accepted to Robotics: Science and Systems (RSS) 2021\n",
    "authors": [
      "Matthew Fontaine",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.04283"
  },
  {
    "id": "arXiv:2012.04378",
    "title": "Forecasting the Olympic medal distribution during a pandemic: a  socio-economic machine learning model",
    "abstract": "Forecasting the Olympic medal distribution during a pandemic: a  socio-economic machine learning model",
    "descriptor": "",
    "authors": [
      "Christoph Schlembach",
      "Sascha L. Schmidt",
      "Dominik Schreyer",
      "Linus Wunderlich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.04378"
  },
  {
    "id": "arXiv:2012.05390",
    "title": "Ensemble Squared: A Meta AutoML System",
    "abstract": "Ensemble Squared: A Meta AutoML System",
    "descriptor": "",
    "authors": [
      "Jason Yoo",
      "Tony Joseph",
      "Dylan Yung",
      "S. Ali Nasseri",
      "Frank Wood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.05390"
  },
  {
    "id": "arXiv:2012.06981",
    "title": "Fine-Grained Lineage for Safer Notebook Interactions",
    "abstract": "Fine-Grained Lineage for Safer Notebook Interactions",
    "descriptor": "",
    "authors": [
      "Stephen Macke",
      "Hongpu Gong",
      "Doris Jung-Lin Lee",
      "Andrew Head",
      "Doris Xin",
      "Aditya Parameswaran"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Databases (cs.DB)",
      "Human-Computer Interaction (cs.HC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2012.06981"
  },
  {
    "id": "arXiv:2012.08005",
    "title": "Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can  be Exponentially Harder than Online RL",
    "abstract": "Comments: Accepted to ICML 2021 as long talk",
    "descriptor": "\nComments: Accepted to ICML 2021 as long talk\n",
    "authors": [
      "Andrea Zanette"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.08005"
  },
  {
    "id": "arXiv:2012.08489",
    "title": "Amazon SageMaker Automatic Model Tuning: Scalable Gradient-Free  Optimization",
    "abstract": "Amazon SageMaker Automatic Model Tuning: Scalable Gradient-Free  Optimization",
    "descriptor": "",
    "authors": [
      "Valerio Perrone",
      "Huibin Shen",
      "Aida Zolic",
      "Iaroslav Shcherbatyi",
      "Amr Ahmed",
      "Tanya Bansal",
      "Michele Donini",
      "Fela Winkelmolen",
      "Rodolphe Jenatton",
      "Jean Baptiste Faddoul",
      "Barbara Pogorzelska",
      "Miroslav Miladinovic",
      "Krishnaram Kenthapadi",
      "Matthias Seeger",
      "C\u00e9dric Archambeau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.08489"
  },
  {
    "id": "arXiv:2012.10042",
    "title": "3D Object Classification on Partial Point Clouds: A Practical  Perspective",
    "abstract": "3D Object Classification on Partial Point Clouds: A Practical  Perspective",
    "descriptor": "",
    "authors": [
      "Zelin Xu",
      "Ke Chen",
      "Changxing Ding",
      "Yaowei Wang",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.10042"
  },
  {
    "id": "arXiv:2012.11409",
    "title": "3D Object Detection with Pointformer",
    "abstract": "Comments: Accepted by IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2021. Code is available at this https URL",
    "descriptor": "\nComments: Accepted by IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2021. Code is available at this https URL\n",
    "authors": [
      "Xuran Pan",
      "Zhuofan Xia",
      "Shiji Song",
      "Li Erran Li",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.11409"
  },
  {
    "id": "arXiv:2012.11556",
    "title": "A scalable control design for grid-forming inverters in microgrids",
    "abstract": "Comments: 14 pages, 10 figures",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Jeremy Watson",
      "Yemi Ojo",
      "Khaled Laib",
      "Ioannis Lestas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.11556"
  },
  {
    "id": "arXiv:2012.11696",
    "title": "Image Captioning as an Assistive Technology: Lessons Learned from VizWiz  2020 Challenge",
    "abstract": "Comments: In submission to JAIR. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: In submission to JAIR. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Pierre Dognin",
      "Igor Melnyk",
      "Youssef Mroueh",
      "Inkit Padhi",
      "Mattia Rigotti",
      "Jarret Ross",
      "Yair Schiff",
      "Richard A. Young",
      "Brian Belgodere"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.11696"
  },
  {
    "id": "arXiv:2012.13138",
    "title": "A non-alternating graph hashing algorithm for large scale image search",
    "abstract": "Comments: The paper is under consideration at Computer Vision and Image Understanding journal",
    "descriptor": "\nComments: The paper is under consideration at Computer Vision and Image Understanding journal\n",
    "authors": [
      "Sobhan Hemati",
      "Mohammad Hadi Mehdizavareh",
      "Shojaeddin Chenouri",
      "Hamid R Tizhoosh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.13138"
  },
  {
    "id": "arXiv:2012.13431",
    "title": "Mixed-Privacy Forgetting in Deep Networks",
    "abstract": "Comments: CVPR 2021",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Aditya Golatkar",
      "Alessandro Achille",
      "Avinash Ravichandran",
      "Marzia Polito",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.13431"
  },
  {
    "id": "arXiv:2012.13831",
    "title": "Spatial Contrastive Learning for Few-Shot Classification",
    "abstract": "Comments: ECML/PKDD 2021",
    "descriptor": "\nComments: ECML/PKDD 2021\n",
    "authors": [
      "Yassine Ouali",
      "C\u00e9line Hudelot",
      "Myriam Tami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.13831"
  },
  {
    "id": "arXiv:2012.14635",
    "title": "Sensifi: A Wireless Sensing System for Ultra-High-Rate Applications",
    "abstract": "Sensifi: A Wireless Sensing System for Ultra-High-Rate Applications",
    "descriptor": "",
    "authors": [
      "Chia-Chi Li",
      "Vikram K. Ramanna",
      "Daniel Webber",
      "Cole Hunter",
      "Tyler Hack",
      "Behnam Dezfouli"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Operating Systems (cs.OS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2012.14635"
  },
  {
    "id": "arXiv:2012.15484",
    "title": "Seeing is Knowing! Fact-based Visual Question Answering using Knowledge  Graph Embeddings",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Kiran Ramnath",
      "Mark Hasegawa-Johnson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.15484"
  },
  {
    "id": "arXiv:2012.15800",
    "title": "A stable majority population protocol using logarithmic time and states",
    "abstract": "Comments: We combined this paper with arXiv:2011.07392 and have a new updated version at arXiv:2106.10201",
    "descriptor": "\nComments: We combined this paper with arXiv:2011.07392 and have a new updated version at arXiv:2106.10201\n",
    "authors": [
      "David Doty",
      "Mahsa Eftekhari",
      "Eric Severson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2012.15800"
  },
  {
    "id": "arXiv:2101.01167",
    "title": "Scale-free networks may not necessarily witness cooperation",
    "abstract": "Comments: Accepted to Europhysics Letters (EPL)",
    "descriptor": "\nComments: Accepted to Europhysics Letters (EPL)\n",
    "authors": [
      "Deep Nath",
      "Saptarshi Sinha",
      "Soumen Roy"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2101.01167"
  },
  {
    "id": "arXiv:2101.02405",
    "title": "Adaptive Group Testing on Networks with Community Structure",
    "abstract": "Comments: 26 pages, 5 figures, to be presented in part at the 2021 IEEE International Symposium on Information Theory (ISIT)",
    "descriptor": "\nComments: 26 pages, 5 figures, to be presented in part at the 2021 IEEE International Symposium on Information Theory (ISIT)\n",
    "authors": [
      "Surin Ahn",
      "Wei-Ning Chen",
      "Ayfer Ozgur"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2101.02405"
  },
  {
    "id": "arXiv:2101.04738",
    "title": "Stability and performance in MPC using a finite-tail cost",
    "abstract": "Comments: Final version, accepted for presentation at the 7th IFAC Conference on Nonlinear Model Predictive Control 2021",
    "descriptor": "\nComments: Final version, accepted for presentation at the 7th IFAC Conference on Nonlinear Model Predictive Control 2021\n",
    "authors": [
      "Johannes K\u00f6hler",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2101.04738"
  },
  {
    "id": "arXiv:2101.04884",
    "title": "Piano Skills Assessment",
    "abstract": "Comments: Dataset is available from: this https URL",
    "descriptor": "\nComments: Dataset is available from: this https URL\n",
    "authors": [
      "Paritosh Parmar",
      "Jaiden Reddy",
      "Brendan Morris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2101.04884"
  },
  {
    "id": "arXiv:2101.05278",
    "title": "GAN Inversion: A Survey",
    "abstract": "Comments: papers on generative modeling: this https URL awesome gan-inversion papers: this https URL",
    "descriptor": "\nComments: papers on generative modeling: this https URL awesome gan-inversion papers: this https URL\n",
    "authors": [
      "Weihao Xia",
      "Yulun Zhang",
      "Yujiu Yang",
      "Jing-Hao Xue",
      "Bolei Zhou",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.05278"
  },
  {
    "id": "arXiv:2101.05592",
    "title": "Dynamic network analysis of a target defense differential game with  limited observations",
    "abstract": "Comments: 8 figures",
    "descriptor": "\nComments: 8 figures\n",
    "authors": [
      "Sharad Kumar Singh",
      "Puduru Viswanadha Reddy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.05592"
  },
  {
    "id": "arXiv:2101.07296",
    "title": "Using Shape to Categorize: Low-Shot Learning with an Explicit Shape Bias",
    "abstract": "Comments: Accepted at CVPR2021. Project page, code and data available at this https URL",
    "descriptor": "\nComments: Accepted at CVPR2021. Project page, code and data available at this https URL\n",
    "authors": [
      "Stefan Stojanov",
      "Anh Thai",
      "James M. Rehg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.07296"
  },
  {
    "id": "arXiv:2101.07312",
    "title": "Benchmarking Perturbation-based Saliency Maps for Explaining Atari  Agents",
    "abstract": "Benchmarking Perturbation-based Saliency Maps for Explaining Atari  Agents",
    "descriptor": "",
    "authors": [
      "Tobias Huber",
      "Benedikt Limmer",
      "Elisabeth Andr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2101.07312"
  },
  {
    "id": "arXiv:2101.07937",
    "title": "Noise Learning Based Denoising Autoencoder",
    "abstract": "Noise Learning Based Denoising Autoencoder",
    "descriptor": "",
    "authors": [
      "Woong-Hee Lee",
      "Mustafa Ozger",
      "Ursula Challita",
      "Ki Won Sung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2101.07937"
  },
  {
    "id": "arXiv:2101.08106",
    "title": "Learning to Augment for Data-Scarce Domain BERT Knowledge Distillation",
    "abstract": "Comments: AAAI2021",
    "descriptor": "\nComments: AAAI2021\n",
    "authors": [
      "Lingyun Feng",
      "Minghui Qiu",
      "Yaliang Li",
      "Hai-Tao Zheng",
      "Ying Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.08106"
  },
  {
    "id": "arXiv:2101.08398",
    "title": "TDA-Net: Fusion of Persistent Homology and Deep Learning Features for  COVID-19 Detection in Chest X-Ray Images",
    "abstract": "TDA-Net: Fusion of Persistent Homology and Deep Learning Features for  COVID-19 Detection in Chest X-Ray Images",
    "descriptor": "",
    "authors": [
      "Mustafa Hajij",
      "Ghada Zamzmi",
      "Fawwaz Batayneh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2101.08398"
  },
  {
    "id": "arXiv:2101.08600",
    "title": "On Separation between the Degree of a Boolean Function and the Block  Sensitivity",
    "abstract": "Comments: 16 pages in total (12 for article + 4 for references and appendix)",
    "descriptor": "\nComments: 16 pages in total (12 for article + 4 for references and appendix)\n",
    "authors": [
      "Nikolay V. Proskurin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2101.08600"
  },
  {
    "id": "arXiv:2101.08886",
    "title": "A co-Design approach to develop a smart cooking appliance. Applying a  Domain Specific Language for a community supported appliance",
    "abstract": "Comments: 9 pages, 7 figures",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Matteo Zallio",
      "Paula Kelly",
      "Barry Cryan",
      "Damon Berry"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.08886"
  },
  {
    "id": "arXiv:2101.09624",
    "title": "A Review of Speaker Diarization: Recent Advances with Deep Learning",
    "abstract": "A Review of Speaker Diarization: Recent Advances with Deep Learning",
    "descriptor": "",
    "authors": [
      "Tae Jin Park",
      "Naoyuki Kanda",
      "Dimitrios Dimitriadis",
      "Kyu J. Han",
      "Shinji Watanabe",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2101.09624"
  },
  {
    "id": "arXiv:2101.09999",
    "title": "Democratizing information visualization. A study to map the value of  graphic design to easier knowledge transfer of scientific research",
    "abstract": "Comments: 13 pages, 2 images",
    "descriptor": "\nComments: 13 pages, 2 images\n",
    "authors": [
      "Matteo Zallio"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2101.09999"
  },
  {
    "id": "arXiv:2101.10266",
    "title": "COVID-19 Outbreak Prediction and Analysis using Self Reported Symptoms",
    "abstract": "Comments: 15 pages, 16 Figures - Latest version on the Journal of Behavioural Data Science - this https URL",
    "descriptor": "\nComments: 15 pages, 16 Figures - Latest version on the Journal of Behavioural Data Science - this https URL\n",
    "authors": [
      "Rohan Sukumaran",
      "Parth Patwa",
      "T V Sethuraman",
      "Sheshank Shankar",
      "Rishank Kanaparti",
      "Joseph Bae",
      "Yash Mathur",
      "Abhishek Singh",
      "Ayush Chopra",
      "Myungsun Kang",
      "Priya Ramaswamy",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2101.10266"
  },
  {
    "id": "arXiv:2101.10696",
    "title": "AINet: Association Implantation for Superpixel Segmentation",
    "abstract": "Comments: Superpixel Segmentation, Computer Version, 10 pages",
    "descriptor": "\nComments: Superpixel Segmentation, Computer Version, 10 pages\n",
    "authors": [
      "Yaxiong Wang",
      "Yunchao Wei",
      "Xueming Qian",
      "Li Zhu",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.10696"
  },
  {
    "id": "arXiv:2101.12164",
    "title": "Two-level Nystr\u00f6m--Schur preconditioner for sparse symmetric positive  definite matrices",
    "abstract": "Two-level Nystr\u00f6m--Schur preconditioner for sparse symmetric positive  definite matrices",
    "descriptor": "",
    "authors": [
      "Hussam Al Daas",
      "Tyrone Rees",
      "Jennifer Scott"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.12164"
  },
  {
    "id": "arXiv:2101.12463",
    "title": "Robust Representation Learning with Feedback for Single Image Deraining",
    "abstract": "Robust Representation Learning with Feedback for Single Image Deraining",
    "descriptor": "",
    "authors": [
      "Chenghao Chen",
      "Hao Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.12463"
  },
  {
    "id": "arXiv:2102.02167",
    "title": "Algorithmic Instabilities of Accelerated Gradient Descent",
    "abstract": "Comments: 37 pages",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Amit Attia",
      "Tomer Koren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.02167"
  },
  {
    "id": "arXiv:2102.02831",
    "title": "Decoding of (Interleaved) Generalized Goppa Codes",
    "abstract": "Decoding of (Interleaved) Generalized Goppa Codes",
    "descriptor": "",
    "authors": [
      "Hedongliang Liu",
      "Sabine Pircher",
      "Alexander Zeh",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.02831"
  },
  {
    "id": "arXiv:2102.04351",
    "title": "Generating Fake Cyber Threat Intelligence Using Transformer-Based Models",
    "abstract": "Comments: In Proceedings of International Joint Conference on Neural Networks 2021 (IJCNN 2021), July 2021",
    "descriptor": "\nComments: In Proceedings of International Joint Conference on Neural Networks 2021 (IJCNN 2021), July 2021\n",
    "authors": [
      "Priyanka Ranade",
      "Aritran Piplai",
      "Sudip Mittal",
      "Anupam Joshi",
      "Tim Finin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.04351"
  },
  {
    "id": "arXiv:2102.04353",
    "title": "Unlocking Pixels for Reinforcement Learning via Implicit Attention",
    "abstract": "Unlocking Pixels for Reinforcement Learning via Implicit Attention",
    "descriptor": "",
    "authors": [
      "Krzysztof Choromanski",
      "Deepali Jain",
      "Jack Parker-Holder",
      "Xingyou Song",
      "Valerii Likhosherstov",
      "Anirban Santara",
      "Aldo Pacchiano",
      "Yunhao Tang",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.04353"
  },
  {
    "id": "arXiv:2102.05308",
    "title": "Explaining Inference Queries with Bayesian Optimization",
    "abstract": "Explaining Inference Queries with Bayesian Optimization",
    "descriptor": "",
    "authors": [
      "Brandon Lockhart",
      "Jinglin Peng",
      "Weiyuan Wu",
      "Jiannan Wang",
      "Eugene Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05308"
  },
  {
    "id": "arXiv:2102.05776",
    "title": "Defense Against Reward Poisoning Attacks in Reinforcement Learning",
    "abstract": "Defense Against Reward Poisoning Attacks in Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Kiarash Banihashem",
      "Adish Singla",
      "Goran Radanovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.05776"
  },
  {
    "id": "arXiv:2102.06619",
    "title": "Differences in the spatial landscape of urban mobility: gender and  socioeconomic perspectives",
    "abstract": "Comments: main + supplementary material. Submitted for publication. Comments are welcome",
    "descriptor": "\nComments: main + supplementary material. Submitted for publication. Comments are welcome\n",
    "authors": [
      "Mariana Macedo",
      "Laura Lotero",
      "Alessio Cardillo",
      "Ronaldo Menezes",
      "Hugo Barbosa"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2102.06619"
  },
  {
    "id": "arXiv:2102.06725",
    "title": "Neural Network Libraries: A Deep Learning Framework Designed from  Engineers' Perspectives",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Takuya Narihira",
      "Javier Alonsogarcia",
      "Fabien Cardinaux",
      "Akio Hayakawa",
      "Masato Ishii",
      "Kazunori Iwaki",
      "Thomas Kemp",
      "Yoshiyuki Kobayashi",
      "Lukas Mauch",
      "Akira Nakamura",
      "Yukio Obuchi",
      "Andrew Shin",
      "Kenji Suzuki",
      "Stephen Tiedmann",
      "Stefan Uhlich",
      "Takuya Yashima",
      "Kazuki Yoshiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.06725"
  },
  {
    "id": "arXiv:2102.06950",
    "title": "Sequential Recommendation in Online Games with Multiple Sequences, Tasks  and User Levels",
    "abstract": "Comments: Accepted in SSTD'21",
    "descriptor": "\nComments: Accepted in SSTD'21\n",
    "authors": [
      "Si Chen",
      "Yuqiu Qian",
      "Hui Li",
      "Chen Lin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2102.06950"
  },
  {
    "id": "arXiv:2102.06986",
    "title": "How Framelets Enhance Graph Neural Networks",
    "abstract": "Comments: 24 pages, 17 figures, 8 tables, ICML2021 (fix typos)",
    "descriptor": "\nComments: 24 pages, 17 figures, 8 tables, ICML2021 (fix typos)\n",
    "authors": [
      "Xuebin Zheng",
      "Bingxin Zhou",
      "Junbin Gao",
      "Yu Guang Wang",
      "Pietro Lio",
      "Ming Li",
      "Guido Montufar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.06986"
  },
  {
    "id": "arXiv:2102.07030",
    "title": "Diffusion Approximations for a Class of Sequential Testing Problems",
    "abstract": "Diffusion Approximations for a Class of Sequential Testing Problems",
    "descriptor": "",
    "authors": [
      "Victor F. Araman",
      "Rene Caldentey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07030"
  },
  {
    "id": "arXiv:2102.07949",
    "title": "Optimal Distributed Frequency and Voltage Control for Zonal Electricity  Markets",
    "abstract": "Optimal Distributed Frequency and Voltage Control for Zonal Electricity  Markets",
    "descriptor": "",
    "authors": [
      "Lukas K\u00f6lsch",
      "Lena Zellmann",
      "Rishabh Vyas",
      "Martin Pfeifer",
      "S\u00f6ren Hohmann"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.07949"
  },
  {
    "id": "arXiv:2102.08086",
    "title": "Supportive 5G Infrastructure Policies are Essential for Universal 6G:  Assessment using an Open-source Techno-economic Simulation Model utilizing  Remote Sensing",
    "abstract": "Supportive 5G Infrastructure Policies are Essential for Universal 6G:  Assessment using an Open-source Techno-economic Simulation Model utilizing  Remote Sensing",
    "descriptor": "",
    "authors": [
      "Edward J. Oughton",
      "Ashutosh Jha"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2102.08086"
  },
  {
    "id": "arXiv:2102.08574",
    "title": "Firefly Neural Architecture Descent: a General Approach for Growing  Neural Networks",
    "abstract": "Firefly Neural Architecture Descent: a General Approach for Growing  Neural Networks",
    "descriptor": "",
    "authors": [
      "Lemeng Wu",
      "Bo Liu",
      "Peter Stone",
      "Qiang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.08574"
  },
  {
    "id": "arXiv:2102.08850",
    "title": "Contrastive Learning Inverts the Data Generating Process",
    "abstract": "Comments: Presented at ICML 2021. The first three authors, as well as the last two authors, contributed equally. Code is available at this https URL",
    "descriptor": "\nComments: Presented at ICML 2021. The first three authors, as well as the last two authors, contributed equally. Code is available at this https URL\n",
    "authors": [
      "Roland S. Zimmermann",
      "Yash Sharma",
      "Steffen Schneider",
      "Matthias Bethge",
      "Wieland Brendel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.08850"
  },
  {
    "id": "arXiv:2102.08946",
    "title": "S2-BNN: Bridging the Gap Between Self-Supervised Real and 1-bit Neural  Networks via Guided Distribution Calibration",
    "abstract": "Comments: CVPR 2021 camera-ready version. Self-supervised binary neural networks using distillation loss (5.5~15% improvement over contrastive baseline). Code is available at this https URL",
    "descriptor": "\nComments: CVPR 2021 camera-ready version. Self-supervised binary neural networks using distillation loss (5.5~15% improvement over contrastive baseline). Code is available at this https URL\n",
    "authors": [
      "Zhiqiang Shen",
      "Zechun Liu",
      "Jie Qin",
      "Lei Huang",
      "Kwang-Ting Cheng",
      "Marios Savvides"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.08946"
  },
  {
    "id": "arXiv:2102.09430",
    "title": "State Entropy Maximization with Random Encoders for Efficient  Exploration",
    "abstract": "Comments: ICML 2021. First two authors contributed equally. Website: this https URL Code: this https URL",
    "descriptor": "\nComments: ICML 2021. First two authors contributed equally. Website: this https URL Code: this https URL\n",
    "authors": [
      "Younggyo Seo",
      "Lili Chen",
      "Jinwoo Shin",
      "Honglak Lee",
      "Pieter Abbeel",
      "Kimin Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09430"
  },
  {
    "id": "arXiv:2102.09507",
    "title": "Regular Expressions for Fast-response COVID-19 Text Classification",
    "abstract": "Comments: 10 pages, 7 tables",
    "descriptor": "\nComments: 10 pages, 7 tables\n",
    "authors": [
      "Igor L. Markov",
      "Jacqueline Liu",
      "Adam Vagner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2102.09507"
  },
  {
    "id": "arXiv:2102.09847",
    "title": "Key Technologies for Networked Virtual Environments",
    "abstract": "Comments: Submitted to Springer Multimedia Systems",
    "descriptor": "\nComments: Submitted to Springer Multimedia Systems\n",
    "authors": [
      "Juan Gonz\u00e1lez",
      "Fernando Boronat",
      "Almanzor Sapena",
      "Javier Pastor"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2102.09847"
  },
  {
    "id": "arXiv:2102.11893",
    "title": "Honey, I Shrunk The Actor: A Case Study on Preserving Performance with  Smaller Actors in Actor-Critic RL",
    "abstract": "Comments: Accepted to the IEEE Conference on Games 2021",
    "descriptor": "\nComments: Accepted to the IEEE Conference on Games 2021\n",
    "authors": [
      "Siddharth Mysore",
      "Bassel Mabsout",
      "Renato Mancuso",
      "Kate Saenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.11893"
  },
  {
    "id": "arXiv:2102.12192",
    "title": "Multiplicative Reweighting for Robust Neural Network Optimization",
    "abstract": "Comments: Our code is publicly available in this https URL",
    "descriptor": "\nComments: Our code is publicly available in this https URL\n",
    "authors": [
      "Noga Bar",
      "Tomer Koren",
      "Raja Giryes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.12192"
  },
  {
    "id": "arXiv:2102.12412",
    "title": "Computing Differential Privacy Guarantees for Heterogeneous Compositions  Using FFT",
    "abstract": "Comments: 44 pages, 10 figures",
    "descriptor": "\nComments: 44 pages, 10 figures\n",
    "authors": [
      "Antti Koskela",
      "Antti Honkela"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.12412"
  },
  {
    "id": "arXiv:2102.12610",
    "title": "Approximate Privacy-Preserving Neighbourhood Estimations",
    "abstract": "Approximate Privacy-Preserving Neighbourhood Estimations",
    "descriptor": "",
    "authors": [
      "Alvaro Garcia-Recuero"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2102.12610"
  },
  {
    "id": "arXiv:2102.12781",
    "title": "Do Input Gradients Highlight Discriminative Features?",
    "abstract": "Comments: Code: this https URL",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Harshay Shah",
      "Prateek Jain",
      "Praneeth Netrapalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.12781"
  },
  {
    "id": "arXiv:2102.13544",
    "title": "Robust Adaptive Model Predictive Control of Quadrotors",
    "abstract": "Comments: Accepted at ECC'21",
    "descriptor": "\nComments: Accepted at ECC'21\n",
    "authors": [
      "Alexandre Didier",
      "Anilkumar Parsi",
      "Jeremy Coulson",
      "Roy S. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.13544"
  },
  {
    "id": "arXiv:2103.00065",
    "title": "Gradient Descent on Neural Networks Typically Occurs at the Edge of  Stability",
    "abstract": "Comments: ICLR 2021",
    "descriptor": "\nComments: ICLR 2021\n",
    "authors": [
      "Jeremy M. Cohen",
      "Simran Kaur",
      "Yuanzhi Li",
      "J. Zico Kolter",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.00065"
  },
  {
    "id": "arXiv:2103.01496",
    "title": "DPlis: Boosting Utility of Differentially Private Deep Learning via  Randomized Smoothing",
    "abstract": "Comments: The 21st Privacy Enhancing Technologies Symposium (PETS), 2021",
    "descriptor": "\nComments: The 21st Privacy Enhancing Technologies Symposium (PETS), 2021\n",
    "authors": [
      "Wenxiao Wang",
      "Tianhao Wang",
      "Lun Wang",
      "Nanqing Luo",
      "Pan Zhou",
      "Dawn Song",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.01496"
  },
  {
    "id": "arXiv:2103.01750",
    "title": "Nonparametric estimation of the preferential attachment function from  one network snapshot",
    "abstract": "Comments: 26 pages, 11 figures",
    "descriptor": "\nComments: 26 pages, 11 figures\n",
    "authors": [
      "Thong Pham",
      "Paul Sheridan",
      "Hidetoshi Shimodaira"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2103.01750"
  },
  {
    "id": "arXiv:2103.01907",
    "title": "Fairness in Credit Scoring: Assessment, Implementation and Profit  Implications",
    "abstract": "Comments: Accepted to European Journal of Operational Research",
    "descriptor": "\nComments: Accepted to European Journal of Operational Research\n",
    "authors": [
      "Nikita Kozodoi",
      "Johannes Jacob",
      "Stefan Lessmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2103.01907"
  },
  {
    "id": "arXiv:2103.03285",
    "title": "A vertex scheme for two-phase flow in heterogeneous media",
    "abstract": "Comments: 25 pages, 17 figures; added reference",
    "descriptor": "\nComments: 25 pages, 17 figures; added reference\n",
    "authors": [
      "M. S. Joshaghani",
      "V. Girault",
      "B. Riviere"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.03285"
  },
  {
    "id": "arXiv:2103.03854",
    "title": "A Pilot Study on Visually Stimulated Cognitive Tasks for EEG-Based  Dementia Recognition",
    "abstract": "A Pilot Study on Visually Stimulated Cognitive Tasks for EEG-Based  Dementia Recognition",
    "descriptor": "",
    "authors": [
      "Supavit Kongwudhikunakorn",
      "Suktipol Kiatthaveephong",
      "Kamonwan Thanontip",
      "Pitshaporn Leelaarporn",
      "Maytus Piriyajitakonkij",
      "Thananya Charoenpattarawut",
      "Phairot Autthasan",
      "Rattanaphon Chaisaen",
      "Pathitta Dujada",
      "Thapanun Sudhawiyangkul",
      "Cuntai Guan",
      "Vorapun Senanarong",
      "Theerawit Wilaiprasitporn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2103.03854"
  },
  {
    "id": "arXiv:2103.04174",
    "title": "Greedy Hierarchical Variational Autoencoders for Large-Scale Video  Prediction",
    "abstract": "Comments: Equal advising and contribution for last two authors",
    "descriptor": "\nComments: Equal advising and contribution for last two authors\n",
    "authors": [
      "Bohan Wu",
      "Suraj Nair",
      "Roberto Martin-Martin",
      "Li Fei-Fei",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.04174"
  },
  {
    "id": "arXiv:2103.04490",
    "title": "Adaptive-Control-Oriented Meta-Learning for Nonlinear Systems",
    "abstract": "Comments: Robotics: Science and Systems, Virtual, 2021",
    "descriptor": "\nComments: Robotics: Science and Systems, Virtual, 2021\n",
    "authors": [
      "Spencer M. Richards",
      "Navid Azizan",
      "Jean-Jacques Slotine",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.04490"
  },
  {
    "id": "arXiv:2103.04955",
    "title": "Threshold-based Network Structural Dynamics",
    "abstract": "Comments: 18 pages, Post-print, to appear in SIROCCO 2021",
    "descriptor": "\nComments: 18 pages, Post-print, to appear in SIROCCO 2021\n",
    "authors": [
      "Evangelos Kipouridis",
      "Paul G. Spirakis",
      "Kostas Tsichlas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2103.04955"
  },
  {
    "id": "arXiv:2103.05354",
    "title": "Revisiting Model's Uncertainty and Confidences for Adversarial Example  Detection",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Ahmed Aldahdooh",
      "Wassim Hamidouche",
      "Olivier D\u00e9forges"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.05354"
  },
  {
    "id": "arXiv:2103.06219",
    "title": "Why flatness does and does not correlate with generalization for deep  neural networks",
    "abstract": "Why flatness does and does not correlate with generalization for deep  neural networks",
    "descriptor": "",
    "authors": [
      "Shuofeng Zhang",
      "Isaac Reid",
      "Guillermo Valle P\u00e9rez",
      "Ard Louis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.06219"
  },
  {
    "id": "arXiv:2103.08143",
    "title": "Constrained plasticity reserve as a natural way to control frequency and  weights in spiking neural networks",
    "abstract": "Comments: 24 pages, 10 figures",
    "descriptor": "\nComments: 24 pages, 10 figures\n",
    "authors": [
      "Oleg Nikitin",
      "Olga Lukyanova",
      "Alex Kunin"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2103.08143"
  },
  {
    "id": "arXiv:2103.10153",
    "title": "A Probabilistic State Space Model for Joint Inference from Differential  Equations and Data",
    "abstract": "Comments: 12 pages (+ 5 pages appendix), 7 figures",
    "descriptor": "\nComments: 12 pages (+ 5 pages appendix), 7 figures\n",
    "authors": [
      "Jonathan Schmidt",
      "Nicholas Kr\u00e4mer",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2103.10153"
  },
  {
    "id": "arXiv:2103.11907",
    "title": "MEC-Empowered Non-Terrestrial Network for 6G Wide-Area Time-Sensitive  Internet of Things",
    "abstract": "Comments: 29 pages, 11 figures, one column",
    "descriptor": "\nComments: 29 pages, 11 figures, one column\n",
    "authors": [
      "Chengxiao Liu",
      "Wei Feng",
      "Xiaoming Tao",
      "Ning Ge"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.11907"
  },
  {
    "id": "arXiv:2103.13598",
    "title": "Recent Advances in Large Margin Learning",
    "abstract": "Comments: Accepted by TPAMI, 8 pages, 3 figures",
    "descriptor": "\nComments: Accepted by TPAMI, 8 pages, 3 figures\n",
    "authors": [
      "Yiwen Guo",
      "Changshui Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2103.13598"
  },
  {
    "id": "arXiv:2103.13859",
    "title": "Group-CAM: Group Score-Weighted Visual Explanations for Deep  Convolutional Networks",
    "abstract": "Comments: Group-CAM is an efficient region-based saliency method, which can be used as an effective data augmentation trick",
    "descriptor": "\nComments: Group-CAM is an efficient region-based saliency method, which can be used as an effective data augmentation trick\n",
    "authors": [
      "Qinglong Zhang",
      "Lu Rao",
      "Yubin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.13859"
  },
  {
    "id": "arXiv:2103.14120",
    "title": "Vertex-centric Parallel Computation of SQL Queries",
    "abstract": "Comments: 50 pages, LaTeX; added examples in Section 6.4; corrected figure in Section 8.6",
    "descriptor": "\nComments: 50 pages, LaTeX; added examples in Section 6.4; corrected figure in Section 8.6\n",
    "authors": [
      "Ainur Smagulova",
      "Alin Deutsch"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2103.14120"
  },
  {
    "id": "arXiv:2103.14216",
    "title": "Which Parts Determine the Impression of the Font?",
    "abstract": "Comments: Accepted at ICDAR 2021",
    "descriptor": "\nComments: Accepted at ICDAR 2021\n",
    "authors": [
      "Masaya Ueda",
      "Akisato Kimura",
      "Seiichi Uchida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14216"
  },
  {
    "id": "arXiv:2103.14862",
    "title": "TS-CAM: Token Semantic Coupled Attention Map for Weakly Supervised  Object Localization",
    "abstract": "Comments: 10 pages, 9 figures. For appendix, 8 pages, 6 figures. arXiv admin note: text overlap with arXiv:2103.04523",
    "descriptor": "\nComments: 10 pages, 9 figures. For appendix, 8 pages, 6 figures. arXiv admin note: text overlap with arXiv:2103.04523\n",
    "authors": [
      "Wei Gao",
      "Fang Wan",
      "Xingjia Pan",
      "Zhiliang Peng",
      "Qi Tian",
      "Zhenjun Han",
      "Bolei Zhou",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14862"
  },
  {
    "id": "arXiv:2103.15074",
    "title": "Attention to Warp: Deep Metric Learning for Multivariate Time Series",
    "abstract": "Comments: Accepted at ICDAR2021",
    "descriptor": "\nComments: Accepted at ICDAR2021\n",
    "authors": [
      "Shinnosuke Matsuo",
      "Xiaomeng Wu",
      "Gantugs Atarsaikhan",
      "Akisato Kimura",
      "Kunio Kashino",
      "Brian Kenji Iwana",
      "Seiichi Uchida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15074"
  },
  {
    "id": "arXiv:2103.15348",
    "title": "LayoutParser: A Unified Toolkit for Deep Learning Based Document Image  Analysis",
    "abstract": "Comments: Accepted at ICDAR 2021, 16 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: Accepted at ICDAR 2021, 16 pages, 6 figures, 2 tables\n",
    "authors": [
      "Zejiang Shen",
      "Ruochen Zhang",
      "Melissa Dell",
      "Benjamin Charles Germain Lee",
      "Jacob Carlson",
      "Weining Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.15348"
  },
  {
    "id": "arXiv:2103.15408",
    "title": "A simpler encoding of indexed types",
    "abstract": "Comments: 14 pages, 8 figures, ICFP 2021 TyDe workshop",
    "descriptor": "\nComments: 14 pages, 8 figures, ICFP 2021 TyDe workshop\n",
    "authors": [
      "Tesla Zhang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2103.15408"
  },
  {
    "id": "arXiv:2103.17228",
    "title": "OLIVAW: Mastering Othello with neither Humans nor a Penny",
    "abstract": "Comments: Presented at AAAI-21 Reinforcement Learning in Games Workshop, 7 pages, 6 figures",
    "descriptor": "\nComments: Presented at AAAI-21 Reinforcement Learning in Games Workshop, 7 pages, 6 figures\n",
    "authors": [
      "Antonio Norelli",
      "Alessandro Panconesi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.17228"
  },
  {
    "id": "arXiv:2104.00322",
    "title": "Domain Invariant Adversarial Learning",
    "abstract": "Domain Invariant Adversarial Learning",
    "descriptor": "",
    "authors": [
      "Matan Levi",
      "Idan Attias",
      "Aryeh Kontorovich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.00322"
  },
  {
    "id": "arXiv:2104.01939",
    "title": "NQMIX: Non-monotonic Value Function Factorization for Deep Multi-Agent  Reinforcement Learning",
    "abstract": "NQMIX: Non-monotonic Value Function Factorization for Deep Multi-Agent  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Quanlin Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2104.01939"
  },
  {
    "id": "arXiv:2104.02005",
    "title": "Uncertainty-Aware COVID-19 Detection from Imbalanced Sound Data",
    "abstract": "Comments: Accepted by INTERSPEECH 2021",
    "descriptor": "\nComments: Accepted by INTERSPEECH 2021\n",
    "authors": [
      "Tong Xia",
      "Jing Han",
      "Lorena Qendro",
      "Ting Dang",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.02005"
  },
  {
    "id": "arXiv:2104.02532",
    "title": "End-To-End Bias Mitigation: Removing Gender Bias in Deep Learning",
    "abstract": "Comments: 9 pages, 1 figure",
    "descriptor": "\nComments: 9 pages, 1 figure\n",
    "authors": [
      "Tal Feldman",
      "Ashley Peake"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2104.02532"
  },
  {
    "id": "arXiv:2104.02864",
    "title": "Self-Supervised Learning for Gastritis Detection with Gastric X-ray  Images",
    "abstract": "Self-Supervised Learning for Gastritis Detection with Gastric X-ray  Images",
    "descriptor": "",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.02864"
  },
  {
    "id": "arXiv:2104.03068",
    "title": "Analysis Towards Classification of Infection and Ischaemia of Diabetic  Foot Ulcers",
    "abstract": "Comments: 4 pages, 6 figures and 3 tables",
    "descriptor": "\nComments: 4 pages, 6 figures and 3 tables\n",
    "authors": [
      "Moi Hoon Yap",
      "Bill Cassidy",
      "Joseph M. Pappachan",
      "Claire O'Shea",
      "David Gillespie",
      "Neil Reeves"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03068"
  },
  {
    "id": "arXiv:2104.04598",
    "title": "Cross-Modal learning for Audio-Visual Video Parsing",
    "abstract": "Comments: Work accepted at Interspeech 2021",
    "descriptor": "\nComments: Work accepted at Interspeech 2021\n",
    "authors": [
      "Jatin Lamba",
      "Abhishek",
      "Jayaprakash Akula",
      "Rishabh Dabral",
      "Preethi Jyothi",
      "Ganesh Ramakrishnan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.04598"
  },
  {
    "id": "arXiv:2104.04616",
    "title": "Automatically Enforcing Fresh and Consistent Inputs in Intermittent  Systems",
    "abstract": "Comments: Updates for camera-ready, add DOI",
    "descriptor": "\nComments: Updates for camera-ready, add DOI\n",
    "authors": [
      "Milijana Surbatovich",
      "Limin Jia",
      "Brandon Lucia"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2104.04616"
  },
  {
    "id": "arXiv:2104.05391",
    "title": "Energy-Efficient Coverage Enhancement of Indoor THz-MISO Systems: An  FD-NOMA Approach",
    "abstract": "Comments: Accepted for publication in proceedings of 2021 IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC 2021)",
    "descriptor": "\nComments: Accepted for publication in proceedings of 2021 IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC 2021)\n",
    "authors": [
      "Omar Maraqa",
      "Aditya S. Rajasekaran",
      "Hamza U. Sokun",
      "Saad Al-Ahmadi",
      "Halim Yanikomeroglu",
      "Sadiq M. Sait"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.05391"
  },
  {
    "id": "arXiv:2104.05947",
    "title": "\"Subverting the Jewtocracy\": Online Antisemitism Detection Using  Multimodal Deep Learning",
    "abstract": "\"Subverting the Jewtocracy\": Online Antisemitism Detection Using  Multimodal Deep Learning",
    "descriptor": "",
    "authors": [
      "Mohit Chandra",
      "Dheeraj Pailla",
      "Himanshu Bhatia",
      "Aadilmehdi Sanchawala",
      "Manish Gupta",
      "Manish Shrivastava",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.05947"
  },
  {
    "id": "arXiv:2104.06772",
    "title": "Deep Evaluation Metric: Learning to Evaluate Simulated Radar Point  Clouds for Virtual Testing of Autonomous Driving",
    "abstract": "Comments: 2021 IEEE Radar Conference (IEEE RadarConf 2021)",
    "descriptor": "\nComments: 2021 IEEE Radar Conference (IEEE RadarConf 2021)\n",
    "authors": [
      "Anthony Ngo",
      "Max Paul Bauer",
      "Michael Resch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.06772"
  },
  {
    "id": "arXiv:2104.07511",
    "title": "Ensemble of MRR and NDCG models for Visual Dialog",
    "abstract": "Comments: Accepted to NAACL2021",
    "descriptor": "\nComments: Accepted to NAACL2021\n",
    "authors": [
      "Idan Schwartz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07511"
  },
  {
    "id": "arXiv:2104.07719",
    "title": "Meta Faster R-CNN: Towards Accurate Few-Shot Object Detection with  Attentive Feature Alignment",
    "abstract": "Comments: 14 pages; Typos corrected and references added",
    "descriptor": "\nComments: 14 pages; Typos corrected and references added\n",
    "authors": [
      "Guangxing Han",
      "Shiyuan Huang",
      "Jiawei Ma",
      "Yicheng He",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2104.07719"
  },
  {
    "id": "arXiv:2104.08440",
    "title": "Learning on a Budget via Teacher Imitation",
    "abstract": "Learning on a Budget via Teacher Imitation",
    "descriptor": "",
    "authors": [
      "Ercument Ilhan",
      "Jeremy Gow",
      "Diego Perez-Liebana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.08440"
  },
  {
    "id": "arXiv:2104.09882",
    "title": "A monolithic and a partitioned Reduced Basis Method for Fluid-Structure  Interaction problems",
    "abstract": "A monolithic and a partitioned Reduced Basis Method for Fluid-Structure  Interaction problems",
    "descriptor": "",
    "authors": [
      "Monica Nonino",
      "Francesco Ballarin",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.09882"
  },
  {
    "id": "arXiv:2104.09946",
    "title": "A cappella: Audio-visual Singing Voice Separation",
    "abstract": "Comments: Extended version of Estimating Individual A Cappella Voices in Music Videos with Singing Faces from Sight and Sound workshop, CVPR21",
    "descriptor": "\nComments: Extended version of Estimating Individual A Cappella Voices in Music Videos with Singing Faces from Sight and Sound workshop, CVPR21\n",
    "authors": [
      "Juan F. Montesinos",
      "Venkatesh S. Kadandale",
      "Gloria Haro"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.09946"
  },
  {
    "id": "arXiv:2104.09971",
    "title": "GDPR-Compliant Use of Blockchain for Secure Usage Logs",
    "abstract": "Comments: Peer-reviewed version accepted for publication in the proceedings of the 2021 International Conference on Evaluation and Assessment in Software Engineering (EASE'21)",
    "descriptor": "\nComments: Peer-reviewed version accepted for publication in the proceedings of the 2021 International Conference on Evaluation and Assessment in Software Engineering (EASE'21)\n",
    "authors": [
      "Valentin Zieglmeier",
      "Gabriel Loyola Daiqui"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.09971"
  },
  {
    "id": "arXiv:2104.10586",
    "title": "Mixture of Robust Experts (MoRE)",
    "abstract": "Comments: This paper is an under review workshop and seminar paper, which will not be published and printed anywhere. And it will be keep updating",
    "descriptor": "\nComments: This paper is an under review workshop and seminar paper, which will not be published and printed anywhere. And it will be keep updating\n",
    "authors": [
      "Kaidi Xu",
      "Chenan Wang",
      "Hao Cheng",
      "Bhavya Kailkhura",
      "Xue Lin",
      "Ryan Goldhahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.10586"
  },
  {
    "id": "arXiv:2104.13281",
    "title": "Complete Deterministic Dynamics and Spectral Decomposition of the  Ensemble Kalman Inversion",
    "abstract": "Comments: Extended the analysis to mean field and averaged stochastic EKI",
    "descriptor": "\nComments: Extended the analysis to mean field and averaged stochastic EKI\n",
    "authors": [
      "Leon Bungert",
      "Philipp Wacker"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2104.13281"
  },
  {
    "id": "arXiv:2104.13514",
    "title": "A Perceptual Model for Eccentricity-dependent Spatio-temporal Flicker  Fusion and its Applications to Foveated Graphics",
    "abstract": "A Perceptual Model for Eccentricity-dependent Spatio-temporal Flicker  Fusion and its Applications to Foveated Graphics",
    "descriptor": "",
    "authors": [
      "Brooke Krajancich",
      "Petr Kellnhofer",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.13514"
  },
  {
    "id": "arXiv:2104.13881",
    "title": "Universal Consistency of Decision Trees in High Dimensions",
    "abstract": "Universal Consistency of Decision Trees in High Dimensions",
    "descriptor": "",
    "authors": [
      "Jason M. Klusowski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2104.13881"
  },
  {
    "id": "arXiv:2104.14267",
    "title": "Source Seeking Control of Unicycle Robots with 3D-printed Flexible  Piezoresistive Sensors",
    "abstract": "Comments: Published in IEEE Transactions on Robotics",
    "descriptor": "\nComments: Published in IEEE Transactions on Robotics\n",
    "authors": [
      "Tinghua Li",
      "Bayu Jayawardhana",
      "Amar Kamat",
      "Ajay Giri Prakash Kottapalli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.14267"
  },
  {
    "id": "arXiv:2105.00351",
    "title": "Lattice Paths for Persistent Diagrams with Application to COVID-19 Virus  Spike Proteins",
    "abstract": "Lattice Paths for Persistent Diagrams with Application to COVID-19 Virus  Spike Proteins",
    "descriptor": "",
    "authors": [
      "Moo K. Chung",
      "Hernando Ombao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2105.00351"
  },
  {
    "id": "arXiv:2105.00648",
    "title": "A novel hybrid methodology of measuring sentence similarity",
    "abstract": "A novel hybrid methodology of measuring sentence similarity",
    "descriptor": "",
    "authors": [
      "Yongmin Yoo",
      "Tak-Sung Heo",
      "Yeongjoon Park",
      "Kyungsun Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.00648"
  },
  {
    "id": "arXiv:2105.01051",
    "title": "SUPERB: Speech processing Universal PERformance Benchmark",
    "abstract": "Comments: To appear in Interspeech 2021",
    "descriptor": "\nComments: To appear in Interspeech 2021\n",
    "authors": [
      "Shu-wen Yang",
      "Po-Han Chi",
      "Yung-Sung Chuang",
      "Cheng-I Jeff Lai",
      "Kushal Lakhotia",
      "Yist Y. Lin",
      "Andy T. Liu",
      "Jiatong Shi",
      "Xuankai Chang",
      "Guan-Ting Lin",
      "Tzu-Hsien Huang",
      "Wei-Cheng Tseng",
      "Ko-tik Lee",
      "Da-Rong Liu",
      "Zili Huang",
      "Shuyan Dong",
      "Shang-Wen Li",
      "Shinji Watanabe",
      "Abdelrahman Mohamed",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.01051"
  },
  {
    "id": "arXiv:2105.02968",
    "title": "This Looks Like That... Does it? Shortcomings of Latent Space Prototype  Interpretability in Deep Networks",
    "abstract": "This Looks Like That... Does it? Shortcomings of Latent Space Prototype  Interpretability in Deep Networks",
    "descriptor": "",
    "authors": [
      "Adrian Hoffmann",
      "Claudio Fanconi",
      "Rahul Rade",
      "Jonas Kohler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.02968"
  },
  {
    "id": "arXiv:2105.03287",
    "title": "Order in the Court: Explainable AI Methods Prone to Disagreement",
    "abstract": "Comments: Accepted for presentation at the ICML Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI",
    "descriptor": "\nComments: Accepted for presentation at the ICML Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI\n",
    "authors": [
      "Michael Neely",
      "Stefan F. Schouten",
      "Maurits J. R. Bleeker",
      "Ana Lucic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03287"
  },
  {
    "id": "arXiv:2105.03361",
    "title": "What Kinds of Functions do Deep Neural Networks Learn? Insights from  Variational Spline Theory",
    "abstract": "What Kinds of Functions do Deep Neural Networks Learn? Insights from  Variational Spline Theory",
    "descriptor": "",
    "authors": [
      "Rahul Parhi",
      "Robert D. Nowak"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03361"
  },
  {
    "id": "arXiv:2105.03824",
    "title": "FNet: Mixing Tokens with Fourier Transforms",
    "abstract": "FNet: Mixing Tokens with Fourier Transforms",
    "descriptor": "",
    "authors": [
      "James Lee-Thorp",
      "Joshua Ainslie",
      "Ilya Eckstein",
      "Santiago Ontanon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03824"
  },
  {
    "id": "arXiv:2105.04027",
    "title": "Improving Multi-agent Coordination by Learning to Estimate Contention",
    "abstract": "Comments: Accepted to the 30th International Joint Conference on Artificial Intelligence (IJCAI-21)",
    "descriptor": "\nComments: Accepted to the 30th International Joint Conference on Artificial Intelligence (IJCAI-21)\n",
    "authors": [
      "Panayiotis Danassis",
      "Florian Wiedemair",
      "Boi Faltings"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04027"
  },
  {
    "id": "arXiv:2105.04783",
    "title": "Towards building the OP-Mapped WENO schemes: A general methodology",
    "abstract": "Comments: 31 pages. arXiv admin note: text overlap with arXiv:2104.04467",
    "descriptor": "\nComments: 31 pages. arXiv admin note: text overlap with arXiv:2104.04467\n",
    "authors": [
      "Ruo Li",
      "Wei Zhong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.04783"
  },
  {
    "id": "arXiv:2105.04801",
    "title": "On Characterizing GAN Convergence Through Proximal Duality Gap",
    "abstract": "On Characterizing GAN Convergence Through Proximal Duality Gap",
    "descriptor": "",
    "authors": [
      "Sahil Sidheekh",
      "Aroof Aimen",
      "Narayanan C. Krishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04801"
  },
  {
    "id": "arXiv:2105.05911",
    "title": "The Power of the Weisfeiler-Leman Algorithm for Machine Learning with  Graphs",
    "abstract": "Comments: Accepted at IJCAI 2021 (survey track)",
    "descriptor": "\nComments: Accepted at IJCAI 2021 (survey track)\n",
    "authors": [
      "Christopher Morris",
      "Matthias Fey",
      "Nils M. Kriege"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.05911"
  },
  {
    "id": "arXiv:2105.06145",
    "title": "Efficient Stepping Algorithms and Implementations for Parallel Shortest  Paths",
    "abstract": "Efficient Stepping Algorithms and Implementations for Parallel Shortest  Paths",
    "descriptor": "",
    "authors": [
      "Xiaojun Dong",
      "Yan Gu",
      "Yihan Sun",
      "Yunming Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.06145"
  },
  {
    "id": "arXiv:2105.06285",
    "title": "Memory compression and thermal efficiency of quantum implementations of  non-deterministic hidden Markov models",
    "abstract": "Comments: 10 pages, 1 figure, 1 table",
    "descriptor": "\nComments: 10 pages, 1 figure, 1 table\n",
    "authors": [
      "Thomas J. Elliott"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2105.06285"
  },
  {
    "id": "arXiv:2105.06831",
    "title": "Quantum coarse-graining for extreme dimension reduction in modelling  stochastic temporal dynamics",
    "abstract": "Comments: 14 pages, 9 figures",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Thomas J. Elliott"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.06831"
  },
  {
    "id": "arXiv:2105.07029",
    "title": "Learning a Universal Template for Few-shot Dataset Generalization",
    "abstract": "Learning a Universal Template for Few-shot Dataset Generalization",
    "descriptor": "",
    "authors": [
      "Eleni Triantafillou",
      "Hugo Larochelle",
      "Richard Zemel",
      "Vincent Dumoulin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07029"
  },
  {
    "id": "arXiv:2105.07342",
    "title": "Self-supervised on Graphs: Contrastive, Generative,or Predictive",
    "abstract": "Self-supervised on Graphs: Contrastive, Generative,or Predictive",
    "descriptor": "",
    "authors": [
      "Lirong Wu",
      "Haitao Lin",
      "Zhangyang Gao",
      "Cheng Tan",
      "Stan.Z.Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.07342"
  },
  {
    "id": "arXiv:2105.07464",
    "title": "Few-NERD: A Few-Shot Named Entity Recognition Dataset",
    "abstract": "Comments: Accepted by ACL-IJCNLP 2021 (long paper), update",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021 (long paper), update\n",
    "authors": [
      "Ning Ding",
      "Guangwei Xu",
      "Yulin Chen",
      "Xiaobin Wang",
      "Xu Han",
      "Pengjun Xie",
      "Hai-Tao Zheng",
      "Zhiyuan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.07464"
  },
  {
    "id": "arXiv:2105.08280",
    "title": "Peer-to-Peer Energy Cooperation in Building Community over A Lossy  Network",
    "abstract": "Comments: 5 pages, 6 figures, accepted to IEEE PESGM 2021, Best Paper Award",
    "descriptor": "\nComments: 5 pages, 6 figures, accepted to IEEE PESGM 2021, Best Paper Award\n",
    "authors": [
      "Cheng Lyu",
      "Youwei Jia",
      "Zhao Xu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.08280"
  },
  {
    "id": "arXiv:2105.08321",
    "title": "Can Self Reported Symptoms Predict Daily COVID-19 Cases?",
    "abstract": "Comments: Accepted as a full-length oral presentation at the International Workshop on Artificial Intelligence for Social Good (AI4SG), IJCAI-21",
    "descriptor": "\nComments: Accepted as a full-length oral presentation at the International Workshop on Artificial Intelligence for Social Good (AI4SG), IJCAI-21\n",
    "authors": [
      "Parth Patwa",
      "Viswanatha Reddy",
      "Rohan Sukumaran",
      "Sethuraman TV",
      "Eptehal Nashnoush",
      "Sheshank Shankar",
      "Rishemjit Kaur",
      "Abhishek Singh",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.08321"
  },
  {
    "id": "arXiv:2105.08442",
    "title": "Explainable Graph-based Search for Lessons-Learned Documents in the  Semiconductor Industry",
    "abstract": "Comments: Accepted in the \"Computing2021\" conference, 15-16 July 2021, London, UK",
    "descriptor": "\nComments: Accepted in the \"Computing2021\" conference, 15-16 July 2021, London, UK\n",
    "authors": [
      "Hasan Abu-Rasheed",
      "Christian Weber",
      "Johannes Zenkert",
      "Roland Krumm",
      "Madjid Fathi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.08442"
  },
  {
    "id": "arXiv:2105.08645",
    "title": "CoTexT: Multi-task Learning with Code-Text Transformer",
    "abstract": "CoTexT: Multi-task Learning with Code-Text Transformer",
    "descriptor": "",
    "authors": [
      "Long Phan",
      "Hieu Tran",
      "Daniel Le",
      "Hieu Nguyen",
      "James Anibal",
      "Alec Peltekian",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.08645"
  },
  {
    "id": "arXiv:2105.08901",
    "title": "A Sequence-to-Set Network for Nested Named Entity Recognition",
    "abstract": "Comments: Accepted to IJCAI 2021, submission version",
    "descriptor": "\nComments: Accepted to IJCAI 2021, submission version\n",
    "authors": [
      "Zeqi Tan",
      "Yongliang Shen",
      "Shuai Zhang",
      "Weiming Lu",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.08901"
  },
  {
    "id": "arXiv:2105.09446",
    "title": "A Review of Autonomous Road Vehicle Integrated Approaches to an  Emergency Obstacle Avoidance Maneuver",
    "abstract": "Comments: (Bookmarks for section headings included) 59 pages of text, 14 pages of references, 60 figures, 3 tables",
    "descriptor": "\nComments: (Bookmarks for section headings included) 59 pages of text, 14 pages of references, 60 figures, 3 tables\n",
    "authors": [
      "Evan Lowe",
      "Levent Guven\u00e7"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.09446"
  },
  {
    "id": "arXiv:2105.10127",
    "title": "A Need-finding Study for Understanding Text Entry in Smartphone App  Usage",
    "abstract": "A Need-finding Study for Understanding Text Entry in Smartphone App  Usage",
    "descriptor": "",
    "authors": [
      "Toby Jia-Jun Li",
      "Brad A. Myers"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.10127"
  },
  {
    "id": "arXiv:2105.10134",
    "title": "Certification of Iterative Predictions in Bayesian Neural Networks",
    "abstract": "Comments: Accepted, UAI 2021. 17 pages",
    "descriptor": "\nComments: Accepted, UAI 2021. 17 pages\n",
    "authors": [
      "Matthew Wicker",
      "Luca Laurenti",
      "Andrea Patane",
      "Nicola Paoletti",
      "Alessandro Abate",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10134"
  },
  {
    "id": "arXiv:2105.10869",
    "title": "Insect-Computer Hybrid System for Autonomous Search and Rescue Mission",
    "abstract": "Comments: Videos are available at this https URL",
    "descriptor": "\nComments: Videos are available at this https URL\n",
    "authors": [
      "P. Thanh Tran-Ngoc",
      "D. Long Le",
      "Bing Sheng Chong",
      "H. Duoc Nguyen",
      "V. Than Dung",
      "Feng Cao",
      "Yao Li",
      "Kazuki Kai",
      "Jia Hui Gan",
      "T. Thang Vo-Doan",
      "T. Luan Nguyen",
      "Hirotaka Sato"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.10869"
  },
  {
    "id": "arXiv:2105.10919",
    "title": "Continual World: A Robotic Benchmark For Continual Reinforcement  Learning",
    "abstract": "Continual World: A Robotic Benchmark For Continual Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "Maciej Wo\u0142czyk",
      "Micha\u0142 Zaj\u0105c",
      "Razvan Pascanu",
      "\u0141ukasz Kuci\u0144ski",
      "Piotr Mi\u0142o\u015b"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.10919"
  },
  {
    "id": "arXiv:2105.12026",
    "title": "Providing Meaningful Data Summarizations Using Exemplar-based Clustering  in Industry 4.0",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2101.08763",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2101.08763\n",
    "authors": [
      "Philipp-Jan Honysz",
      "Alexander Schulze-Struchtrup",
      "Sebastian Buschj\u00e4ger",
      "Katharina Morik"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.12026"
  },
  {
    "id": "arXiv:2105.12364",
    "title": "Basic and Depression Specific Emotion Identification in Tweets:  Multi-label Classification Experiments",
    "abstract": "Comments: Accepted at CICLing, 2019",
    "descriptor": "\nComments: Accepted at CICLing, 2019\n",
    "authors": [
      "Nawshad Farruque",
      "Chenyang Huang",
      "Osmar Zaiane",
      "Randy Goebel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.12364"
  },
  {
    "id": "arXiv:2105.12723",
    "title": "Aggregating Nested Transformers",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Zizhao Zhang",
      "Han Zhang",
      "Long Zhao",
      "Ting Chen",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.12723"
  },
  {
    "id": "arXiv:2105.13084",
    "title": "HDRUNet: Single Image HDR Reconstruction with Denoising and  Dequantization",
    "abstract": "HDRUNet: Single Image HDR Reconstruction with Denoising and  Dequantization",
    "descriptor": "",
    "authors": [
      "Xiangyu Chen",
      "Yihao Liu",
      "Zhengwen Zhang",
      "Yu Qiao",
      "Chao Dong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13084"
  },
  {
    "id": "arXiv:2105.13218",
    "title": "Pattern Transfer Learning for Reinforcement Learning in Order  Dispatching",
    "abstract": "Comments: Spotlight paper, RL4ITS, IJCAI-21",
    "descriptor": "\nComments: Spotlight paper, RL4ITS, IJCAI-21\n",
    "authors": [
      "Runzhe Wan",
      "Sheng Zhang",
      "Chengchun Shi",
      "Shikai Luo",
      "Rui Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13218"
  },
  {
    "id": "arXiv:2105.13801",
    "title": "A Probabilistic Forecast-Driven Strategy for a Risk-Aware Participation  in the Capacity Firming Market",
    "abstract": "A Probabilistic Forecast-Driven Strategy for a Risk-Aware Participation  in the Capacity Firming Market",
    "descriptor": "",
    "authors": [
      "Jonathan Dumas",
      "Colin Cointe",
      "Antoine Wehenkel",
      "Antonio Sutera",
      "Xavier Fettweis",
      "Bertrand Corn\u00e9lusse"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13801"
  },
  {
    "id": "arXiv:2105.13863",
    "title": "On plane algebraic curves passing through $n$-independent nodes",
    "abstract": "Comments: 22 pages. arXiv admin note: substantial text overlap with arXiv:1903.10874",
    "descriptor": "\nComments: 22 pages. arXiv admin note: substantial text overlap with arXiv:1903.10874\n",
    "authors": [
      "Hakop Hakopian",
      "Harutyun Kloyan",
      "Davit Voskanyan"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13863"
  },
  {
    "id": "arXiv:2105.14162",
    "title": "EDDA: Explanation-driven Data Augmentation to Improve Model and  Explanation Alignment",
    "abstract": "EDDA: Explanation-driven Data Augmentation to Improve Model and  Explanation Alignment",
    "descriptor": "",
    "authors": [
      "Ruiwen Li",
      "Zhibo Zhang",
      "Jiani Li",
      "Scott Sanner",
      "Jongseong Jang",
      "Yeonjeong Jeong",
      "Dongsub Shim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14162"
  },
  {
    "id": "arXiv:2105.14708",
    "title": "On Dynamic Resource Allocation for Blockchain Assisted Federated  Learning over Wireless Channels",
    "abstract": "On Dynamic Resource Allocation for Blockchain Assisted Federated  Learning over Wireless Channels",
    "descriptor": "",
    "authors": [
      "Xiumei Deng",
      "Jun Li",
      "Chuan Ma",
      "Kang Wei",
      "Long Shi",
      "Ming Ding",
      "Wen Chen",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.14708"
  },
  {
    "id": "arXiv:2105.14840",
    "title": "Elegant elaboration with function invocation",
    "abstract": "Comments: 6 pages, 3 figures",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Tesla Zhang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.14840"
  },
  {
    "id": "arXiv:2106.00093",
    "title": "Approximate polymorphisms",
    "abstract": "Comments: 43 pages",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "Gilad Chase",
      "Yuval Filmus",
      "Dor Minzer",
      "Elchanan Mossel",
      "Nitin Saurabh"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.00093"
  },
  {
    "id": "arXiv:2106.00666",
    "title": "You Only Look at One Sequence: Rethinking Transformer in Vision through  Object Detection",
    "abstract": "Comments: 18 pages, 7 tables, 5 figures. Add Appendix & some missing references",
    "descriptor": "\nComments: 18 pages, 7 tables, 5 figures. Add Appendix & some missing references\n",
    "authors": [
      "Yuxin Fang",
      "Bencheng Liao",
      "Xinggang Wang",
      "Jiemin Fang",
      "Jiyang Qi",
      "Rui Wu",
      "Jianwei Niu",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00666"
  },
  {
    "id": "arXiv:2106.00676",
    "title": "Incorporating Visual Layout Structures for Scientific Text  Classification",
    "abstract": "Comments: 13 pages, 4 figures, 6 tables",
    "descriptor": "\nComments: 13 pages, 4 figures, 6 tables\n",
    "authors": [
      "Zejiang Shen",
      "Kyle Lo",
      "Lucy Lu Wang",
      "Bailey Kuehl",
      "Daniel S. Weld",
      "Doug Downey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00676"
  },
  {
    "id": "arXiv:2106.00898",
    "title": "Trajectory Optimization for Manipulation of Deformable Objects: Assembly  of Belt Drive Units",
    "abstract": "Trajectory Optimization for Manipulation of Deformable Objects: Assembly  of Belt Drive Units",
    "descriptor": "",
    "authors": [
      "Shiyu Jin",
      "Diego Romeres",
      "Arvind Ragunathan",
      "Devesh K. Jha",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.00898"
  },
  {
    "id": "arXiv:2106.01065",
    "title": "Towards Robustness of Text-to-SQL Models against Synonym Substitution",
    "abstract": "Comments: To appear in ACL 2021",
    "descriptor": "\nComments: To appear in ACL 2021\n",
    "authors": [
      "Yujian Gan",
      "Xinyun Chen",
      "Qiuping Huang",
      "Matthew Purver",
      "John R. Woodward",
      "Jinxia Xie",
      "Pengsheng Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01065"
  },
  {
    "id": "arXiv:2106.01416",
    "title": "Ebola Optimization Search Algorithm (EOSA): A new metaheuristic  algorithm based on the propagation model of Ebola virus disease",
    "abstract": "Ebola Optimization Search Algorithm (EOSA): A new metaheuristic  algorithm based on the propagation model of Ebola virus disease",
    "descriptor": "",
    "authors": [
      "Olaide N. Oyelade",
      "Absalom E. Ezugwu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01416"
  },
  {
    "id": "arXiv:2106.01450",
    "title": "Inferring Black Hole Properties from Astronomical Multivariate Time  Series with Bayesian Attentive Neural Processes",
    "abstract": "Comments: 6 pages, 4 figures, 1 table, written for non-astronomers, submitted to the ICML 2021 Time Series and Uncertainty and Robustness in Deep Learning Workshops. Comments welcome! Added affiliations and references for Fig 1",
    "descriptor": "\nComments: 6 pages, 4 figures, 1 table, written for non-astronomers, submitted to the ICML 2021 Time Series and Uncertainty and Robustness in Deep Learning Workshops. Comments welcome! Added affiliations and references for Fig 1\n",
    "authors": [
      "Ji Won Park",
      "Ashley Villar",
      "Yin Li",
      "Yan-Fei Jiang",
      "Shirley Ho",
      "Joshua Yao-Yu Lin",
      "Philip J. Marshall",
      "Aaron Roodman"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01450"
  },
  {
    "id": "arXiv:2106.01609",
    "title": "Tail-to-Tail Non-Autoregressive Sequence Prediction for Chinese  Grammatical Error Correction",
    "abstract": "Comments: Accepted in the main conference of ACL 2021. Code: this https URL",
    "descriptor": "\nComments: Accepted in the main conference of ACL 2021. Code: this https URL\n",
    "authors": [
      "Piji Li",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01609"
  },
  {
    "id": "arXiv:2106.01930",
    "title": "Tropical linear regression and mean payoff games: or, how to measure the  distance to equilibria",
    "abstract": "Tropical linear regression and mean payoff games: or, how to measure the  distance to equilibria",
    "descriptor": "",
    "authors": [
      "Marianne Akian",
      "St\u00e9phane Gaubert",
      "Yang Qi",
      "Omar Saadi"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.01930"
  },
  {
    "id": "arXiv:2106.01933",
    "title": "An Improved Model for Voicing Silent Speech",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "David Gaddy",
      "Dan Klein"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.01933"
  },
  {
    "id": "arXiv:2106.01946",
    "title": "Convex optimization",
    "abstract": "Comments: 364 pages, in Russian",
    "descriptor": "\nComments: 364 pages, in Russian\n",
    "authors": [
      "Evgeniya Vorontsova",
      "Roland Hildebrand",
      "Alexander Gasnikov",
      "Fedor Stonyakin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01946"
  },
  {
    "id": "arXiv:2106.02190",
    "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug  Discovery",
    "abstract": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug  Discovery",
    "descriptor": "",
    "authors": [
      "Yulun Wu",
      "Nicholas Choma",
      "Andrew Chen",
      "Mikaela Cashman",
      "\u00c9rica T. Prates",
      "Manesh Shah",
      "Ver\u00f3nica G. Melesse Vergara",
      "Austin Clyde",
      "Thomas S. Brettin",
      "Wibe A. de Jong",
      "Neeraj Kumar",
      "Martha S. Head",
      "Rick L. Stevens",
      "Peter Nugent",
      "Daniel A. Jacobson",
      "James B. Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2106.02190"
  },
  {
    "id": "arXiv:2106.02221",
    "title": "Specular reflections removal in colposcopic images based on neural  networks: Supervised training with no ground truth previous knowledge",
    "abstract": "Comments: This new version corrects typos and adds references",
    "descriptor": "\nComments: This new version corrects typos and adds references\n",
    "authors": [
      "Lauren Jimenez-Martin",
      "Daniel A. Vald\u00e9s P\u00e9rez",
      "Ana M. Solares Asteasuainzarra",
      "Ludwig Leonard",
      "Marta L. Baguer D\u00edaz-Roma\u00f1ach"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02221"
  },
  {
    "id": "arXiv:2106.02792",
    "title": "Weakly-Supervised Methods for Suicide Risk Assessment: Role of Related  Domains",
    "abstract": "Comments: ACL 2021 short paper. Code is available at this https URL (under construction)",
    "descriptor": "\nComments: ACL 2021 short paper. Code is available at this https URL (under construction)\n",
    "authors": [
      "Chenghao Yang",
      "Yudong Zhang",
      "Smaranda Muresan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02792"
  },
  {
    "id": "arXiv:2106.03156",
    "title": "Fast and Robust Online Inference with Stochastic Gradient Descent via  Random Scaling",
    "abstract": "Comments: 16 pages, 5 figures, 5 tables",
    "descriptor": "\nComments: 16 pages, 5 figures, 5 tables\n",
    "authors": [
      "Sokbae Lee",
      "Yuan Liao",
      "Myung Hwan Seo",
      "Youngki Shin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.03156"
  },
  {
    "id": "arXiv:2106.03346",
    "title": "QFuzz: Quantitative Fuzzing for Side Channels",
    "abstract": "QFuzz: Quantitative Fuzzing for Side Channels",
    "descriptor": "",
    "authors": [
      "Yannic Noller",
      "Saeid Tizpaz-Niari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.03346"
  },
  {
    "id": "arXiv:2106.03548",
    "title": "Auction-based and Distributed Optimization Approaches for Scheduling  Observations in Satellite Constellations with Exclusive Orbit Portions",
    "abstract": "Auction-based and Distributed Optimization Approaches for Scheduling  Observations in Satellite Constellations with Exclusive Orbit Portions",
    "descriptor": "",
    "authors": [
      "Gauthier Picard"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.03548"
  },
  {
    "id": "arXiv:2106.03626",
    "title": "Towards Formal Verification of Password Generation Algorithms used in  Password Managers",
    "abstract": "Comments: shortpaper",
    "descriptor": "\nComments: shortpaper\n",
    "authors": [
      "Miguel Grilo",
      "Jo\u00e3o F. Ferreira",
      "Jos\u00e9 Bacelar Almeida"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.03626"
  },
  {
    "id": "arXiv:2106.03953",
    "title": "Neural Abstractive Unsupervised Summarization of Online News Discussions",
    "abstract": "Neural Abstractive Unsupervised Summarization of Online News Discussions",
    "descriptor": "",
    "authors": [
      "Ignacio Tampe Palma",
      "Marcelo Mendoza",
      "Evangelos Milios"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03953"
  },
  {
    "id": "arXiv:2106.04419",
    "title": "Asymmetrical Bi-RNN for pedestrian trajectory encoding",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Rapha\u00ebl Rozenberg",
      "Joseph Gesnouin",
      "Fabien Moutarde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.04419"
  },
  {
    "id": "arXiv:2106.04494",
    "title": "Optimization of Service Addition in Multilevel Index Model for Edge  Computing",
    "abstract": "Optimization of Service Addition in Multilevel Index Model for Edge  Computing",
    "descriptor": "",
    "authors": [
      "Jiayan Gu",
      "Yan Wu",
      "Ashiq Anjum",
      "John Panneerselvam",
      "Yao Lu",
      "Bo Yuan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.04494"
  },
  {
    "id": "arXiv:2106.06171",
    "title": "Inter-domain Multi-relational Link Prediction",
    "abstract": "Comments: 16 pages, 2 figures, 5 tables, Accepted for ECML-PKDD 2021",
    "descriptor": "\nComments: 16 pages, 2 figures, 5 tables, Accepted for ECML-PKDD 2021\n",
    "authors": [
      "Luu Huu Phuc",
      "Koh Takeuchi",
      "Seiji Okajima",
      "Arseny Tolmachev",
      "Tomoyoshi Takebayashi",
      "Koji Maruhashi",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06171"
  },
  {
    "id": "arXiv:2106.06439",
    "title": "An Image Forensic Technique Based on JPEG Ghosts",
    "abstract": "Comments: 8 pages, 10 figures, 2 tables",
    "descriptor": "\nComments: 8 pages, 10 figures, 2 tables\n",
    "authors": [
      "Divakar Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.06439"
  },
  {
    "id": "arXiv:2106.06482",
    "title": "Neural Network Modeling of Probabilities for Coding the Octree  Representation of Point Clouds",
    "abstract": "Comments: 6 pages, 3 figures, Submitted to MMSP 2021, typos fixed",
    "descriptor": "\nComments: 6 pages, 3 figures, Submitted to MMSP 2021, typos fixed\n",
    "authors": [
      "Emre Can Kaya",
      "Ioan Tabus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.06482"
  },
  {
    "id": "arXiv:2106.06807",
    "title": "Redirected Walking in Static and Dynamic Scenes Using Visibility  Polygons",
    "abstract": "Redirected Walking in Static and Dynamic Scenes Using Visibility  Polygons",
    "descriptor": "",
    "authors": [
      "Niall L. Williams",
      "Aniket Bera",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.06807"
  },
  {
    "id": "arXiv:2106.07135",
    "title": "MTC: Multiresolution Tensor Completion from Partial and Coarse  Observations",
    "abstract": "Comments: Accepted in SIGKDD 2021. Code in this https URL",
    "descriptor": "\nComments: Accepted in SIGKDD 2021. Code in this https URL\n",
    "authors": [
      "Chaoqi Yang",
      "Navjot Singh",
      "Cao Xiao",
      "Cheng Qian",
      "Edgar Solomonik",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07135"
  },
  {
    "id": "arXiv:2106.07400",
    "title": "Determinantal Beam Search",
    "abstract": "Determinantal Beam Search",
    "descriptor": "",
    "authors": [
      "Clara Meister",
      "Martina Forster",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07400"
  },
  {
    "id": "arXiv:2106.07524",
    "title": "MIA-COV19D: COVID-19 Detection through 3-D Chest CT Image Analysis",
    "abstract": "MIA-COV19D: COVID-19 Detection through 3-D Chest CT Image Analysis",
    "descriptor": "",
    "authors": [
      "Dimitrios Kollias",
      "Anastasios Arsenos",
      "Levon Soukissian",
      "Stefanos Kollias"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07524"
  },
  {
    "id": "arXiv:2106.07929",
    "title": "Image Feature Information Extraction for Interest Point Detection: A  Comprehensive Review",
    "abstract": "Image Feature Information Extraction for Interest Point Detection: A  Comprehensive Review",
    "descriptor": "",
    "authors": [
      "Junfeng Jing",
      "Tian Gao",
      "Weichuan Zhang",
      "Yongsheng Gao",
      "Changming Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07929"
  },
  {
    "id": "arXiv:2106.08253",
    "title": "Code Generation Based on Deep Learning: a Brief Review",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Qihao Zhu",
      "Wenjie Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08253"
  },
  {
    "id": "arXiv:2106.08279",
    "title": "First Place Solution of KDD Cup 2021 & OGB Large-Scale Challenge Graph  Prediction Track",
    "abstract": "First Place Solution of KDD Cup 2021 & OGB Large-Scale Challenge Graph  Prediction Track",
    "descriptor": "",
    "authors": [
      "Chengxuan Ying",
      "Mingqi Yang",
      "Shuxin Zheng",
      "Guolin Ke",
      "Shengjie Luo",
      "Tianle Cai",
      "Chenglin Wu",
      "Yuxin Wang",
      "Yanming Shen",
      "Di He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08279"
  },
  {
    "id": "arXiv:2106.08370",
    "title": "Unraveling the Temporal Importance of Community-scale Human Activity  Features for Rapid Assessment of Flood Impacts",
    "abstract": "Comments: 26 pages and 15 figures",
    "descriptor": "\nComments: 26 pages and 15 figures\n",
    "authors": [
      "Faxi Yuan",
      "Yang Yang",
      "Qingchun Li",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.08370"
  },
  {
    "id": "arXiv:2106.08372",
    "title": "A Multi-Layered Approach for Measuring the Simulation-to-Reality Gap of  Radar Perception for Autonomous Driving",
    "abstract": "Comments: Accepted at the 24th IEEE International Conference on Intelligent Transportation Systems (ITSC 2021)",
    "descriptor": "\nComments: Accepted at the 24th IEEE International Conference on Intelligent Transportation Systems (ITSC 2021)\n",
    "authors": [
      "Anthony Ngo",
      "Max Paul Bauer",
      "Michael Resch"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.08372"
  },
  {
    "id": "arXiv:2106.08482",
    "title": "Minimizing Communication while Maximizing Performance in Multi-Agent  Reinforcement Learning",
    "abstract": "Minimizing Communication while Maximizing Performance in Multi-Agent  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Varun Kumar Vijay",
      "Hassam Sheikh",
      "Somdeb Majumdar",
      "Mariano Phielipp"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08482"
  },
  {
    "id": "arXiv:2106.08525",
    "title": "A Feynman-Kac Type Theorem for ODEs: Solutions of Second Order ODEs as  Modes of Diffusions",
    "abstract": "Comments: Comments welcome!",
    "descriptor": "\nComments: Comments welcome!\n",
    "authors": [
      "Zachary Selk",
      "Harsha Honnappa"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.08525"
  },
  {
    "id": "arXiv:2106.08720",
    "title": "Predicting crop yields with little ground truth: A simple statistical  model for in-season forecasting",
    "abstract": "Predicting crop yields with little ground truth: A simple statistical  model for in-season forecasting",
    "descriptor": "",
    "authors": [
      "Nemo Semret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08720"
  },
  {
    "id": "arXiv:2106.08853",
    "title": "Strategic Behavior is Bliss: Iterative Voting Improves Social Welfare",
    "abstract": "Comments: 21 pages, 4 figures",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Joshua Kavner",
      "Lirong Xia"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.08853"
  },
  {
    "id": "arXiv:2106.08962",
    "title": "Efficient Deep Learning: A Survey on Making Deep Learning Models  Smaller, Faster, and Better",
    "abstract": "Efficient Deep Learning: A Survey on Making Deep Learning Models  Smaller, Faster, and Better",
    "descriptor": "",
    "authors": [
      "Gaurav Menghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08962"
  },
  {
    "id": "arXiv:2106.09166",
    "title": "Improving DNN Fault Tolerance using Weight Pruning and Differential  Crossbar Mapping for ReRAM-based Edge AI",
    "abstract": "Comments: In Proceedings of the 22nd International Symposium on Quality Electronic Design (ISQED), 2021",
    "descriptor": "\nComments: In Proceedings of the 22nd International Symposium on Quality Electronic Design (ISQED), 2021\n",
    "authors": [
      "Geng Yuan",
      "Zhiheng Liao",
      "Xiaolong Ma",
      "Yuxuan Cai",
      "Zhenglun Kong",
      "Xuan Shen",
      "Jingyan Fu",
      "Zhengang Li",
      "Chengming Zhang",
      "Hongwu Peng",
      "Ning Liu",
      "Ao Ren",
      "Jinhui Wang",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2106.09166"
  },
  {
    "id": "arXiv:2106.09303",
    "title": "A Multi-task convolutional neural network for blind stereoscopic image  quality assessment using naturalness analysis",
    "abstract": "A Multi-task convolutional neural network for blind stereoscopic image  quality assessment using naturalness analysis",
    "descriptor": "",
    "authors": [
      "Salima Bourbia",
      "Ayoub Karine",
      "Aladine Chetouani",
      "Mohammed El Hassouni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09303"
  },
  {
    "id": "arXiv:2106.09473",
    "title": "Importance measures derived from random forests: characterisation and  extension",
    "abstract": "Comments: PhD thesis, Li\\`ege, Belgium, June 2019. Permalink : this http URL",
    "descriptor": "\nComments: PhD thesis, Li\\`ege, Belgium, June 2019. Permalink : this http URL\n",
    "authors": [
      "Antonio Sutera"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09473"
  },
  {
    "id": "arXiv:2106.09584",
    "title": "SIFT Matching by Context Exposed",
    "abstract": "Comments: Early pre-release",
    "descriptor": "\nComments: Early pre-release\n",
    "authors": [
      "Fabio Bellavia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09584"
  },
  {
    "id": "arXiv:2106.09660",
    "title": "WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis",
    "abstract": "Comments: Proceedings of INTERSPEECH",
    "descriptor": "\nComments: Proceedings of INTERSPEECH\n",
    "authors": [
      "Nanxin Chen",
      "Yu Zhang",
      "Heiga Zen",
      "Ron J. Weiss",
      "Mohammad Norouzi",
      "Najim Dehak",
      "William Chan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09660"
  },
  {
    "id": "arXiv:2106.09694",
    "title": "Simulation study on the fleet performance of shared autonomous bicycles",
    "abstract": "Simulation study on the fleet performance of shared autonomous bicycles",
    "descriptor": "",
    "authors": [
      "Naroa Coretti S\u00e1nchez",
      "I\u00f1igo Martinez",
      "Luis Alonso Pastor",
      "Kent Larson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.09694"
  },
  {
    "id": "arXiv:2106.09775",
    "title": "An Information Retrieval Approach to Building Datasets for Hate Speech  Detection",
    "abstract": "Comments: 10 pages (Under review in CIKM 2021)",
    "descriptor": "\nComments: 10 pages (Under review in CIKM 2021)\n",
    "authors": [
      "Md Mustafizur Rahman",
      "Dinesh Balakrishnan",
      "Dhiraj Murthy",
      "Mucahid Kutlu",
      "Matthew Lease"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.09775"
  },
  {
    "id": "arXiv:2106.09881",
    "title": "Identifying intracity freight trip ends from heavy truck GPS  trajectories",
    "abstract": "Identifying intracity freight trip ends from heavy truck GPS  trajectories",
    "descriptor": "",
    "authors": [
      "Yitao Yang",
      "Bin Jia",
      "Xiao-Yong Yan",
      "Rui Jiang",
      "Hao Ji",
      "Ziyou Gao"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2106.09881"
  },
  {
    "id": "arXiv:2106.09989",
    "title": "BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly  Detection",
    "abstract": "BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly  Detection",
    "descriptor": "",
    "authors": [
      "Yulin Zhu",
      "Yuni Lai",
      "Kaifa Zhao",
      "Xiapu Luo",
      "Mingquan Yuan",
      "Jian Ren",
      "Kai Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.09989"
  },
  {
    "id": "arXiv:2106.10013",
    "title": "Shape Prior Non-Uniform Sampling Guided Real-time Stereo 3D Object  Detection",
    "abstract": "Comments: 9 pages, 7 figures",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Aqi. Gao",
      "Jiale. Cao",
      "Yanwei. Pang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10013"
  },
  {
    "id": "arXiv:2106.10080",
    "title": "Debiased Subjective Assessment of Real-World Image Enhancement",
    "abstract": "Debiased Subjective Assessment of Real-World Image Enhancement",
    "descriptor": "",
    "authors": [
      "Cao Peibei",
      "Wang Zhangyang",
      "Ma Kede"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10080"
  },
  {
    "id": "arXiv:2106.10137",
    "title": "Self-supervised Video Representation Learning with Cross-Stream  Prototypical Contrasting",
    "abstract": "Self-supervised Video Representation Learning with Cross-Stream  Prototypical Contrasting",
    "descriptor": "",
    "authors": [
      "Martine Toering",
      "Ioannis Gatopoulos",
      "Maarten Stol",
      "Vincent Tao Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10137"
  }
]
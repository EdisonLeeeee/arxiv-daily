[
  {
    "id": "arXiv:2106.08361",
    "title": "Adversarial Attacks on Deep Models for Financial Transaction Records",
    "abstract": "Machine learning models using transaction records as inputs are popular among\nfinancial institutions. The most efficient models use deep-learning\narchitectures similar to those in the NLP community, posing a challenge due to\ntheir tremendous number of parameters and limited robustness. In particular,\ndeep-learning models are vulnerable to adversarial attacks: a little change in\nthe input harms the model's output.\nIn this work, we examine adversarial attacks on transaction records data and\ndefences from these attacks. The transaction records data have a different\nstructure than the canonical NLP or time series data, as neighbouring records\nare less connected than words in sentences, and each record consists of both\ndiscrete merchant code and continuous transaction amount. We consider a\nblack-box attack scenario, where the attack doesn't know the true decision\nmodel, and pay special attention to adding transaction tokens to the end of a\nsequence. These limitations provide more realistic scenario, previously\nunexplored in NLP world.\nThe proposed adversarial attacks and the respective defences demonstrate\nremarkable performance using relevant datasets from the financial industry. Our\nresults show that a couple of generated transactions are sufficient to fool a\ndeep-learning model. Further, we improve model robustness via adversarial\ntraining or separate adversarial examples detection. This work shows that\nembedding protection from adversarial attacks improves model robustness,\nallowing a wider adoption of deep models for transaction records in banking and\nfinance.",
    "descriptor": "",
    "authors": [
      "Ivan Fursov",
      "Matvey Morozov",
      "Nina Kaploukhaya",
      "Elizaveta Kovtun",
      "Rodrigo Rivera-Castro",
      "Gleb Gusev",
      "Dmitry Babaev",
      "Ivan Kireev",
      "Alexey Zaytsev",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08361"
  },
  {
    "id": "arXiv:2106.08363",
    "title": "Convergence of a Lagrangian-Eulerian scheme via the weak asymptotic  method",
    "abstract": "This work presents a suitable mathematical analysis to understand the\nproperties of convergence and bounded variation of a new { fully discrete\nlocally conservative} Lagrangian--Eulerian {explicit} numerical scheme to the\nentropy solution in the sense of Kruzhkov via weak asymptotic method. We also\nmake use of the weak asymptotic method to connect the theoretical developments\nwith the computational approach within the practical framework of a solid\nnumerical analysis. This method also serves to address the issue of notions of\nsolutions, and its resulting algorithms have been proven to be effective to\nstudy nonlinear wave formations and rarefaction interactions in intricate\napplications. The weak asymptotic solutions we compute in this study with our\nnovel Lagrangian--Eulerian framework are shown to coincide with classical\nsolutions and Kruzhkov entropy solutions in the scalar case. Moreover, we\npresent and discuss significant computational aspects by means of numerical\nexperiments related to nontrivial problems: a nonlocal traffic model, the $2\n\\times 2$ symmetric Keyfitz--Kranzer system, and numerical studies via\nWasserstein distance to explain shock interaction with the fundamental inviscid\nBurgers' model for fluids. Therefore, the proposed weak asymptotic analysis,\nwhen applied to the Lagrangian--Eulerian framework, fits in properly with the\nclassical theory while optimizing the mathematical computations for the\nconstruction of new accurate numerical schemes.",
    "descriptor": "",
    "authors": [
      "Eduardo Abreu",
      "Arthur Esp\u00edrito Santo",
      "Wanderson Lambert",
      "John P\u00e9rez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08363"
  },
  {
    "id": "arXiv:2106.08364",
    "title": "Unsupervised Enrichment of Persona-grounded Dialog with Background  Stories",
    "abstract": "Humans often refer to personal narratives, life experiences, and events to\nmake a conversation more engaging and rich. While persona-grounded dialog\nmodels are able to generate responses that follow a given persona, they often\nmiss out on stating detailed experiences or events related to a persona, often\nleaving conversations shallow and dull. In this work, we equip dialog models\nwith 'background stories' related to a persona by leveraging fictional\nnarratives from existing story datasets (e.g. ROCStories). Since current dialog\ndatasets do not contain such narratives as responses, we perform an\nunsupervised adaptation of a retrieved story for generating a dialog response\nusing a gradient-based rewriting technique. Our proposed method encourages the\ngenerated response to be fluent (i.e., highly likely) with the dialog history,\nminimally different from the retrieved story to preserve event ordering and\nconsistent with the original persona. We demonstrate that our method can\ngenerate responses that are more diverse, and are rated more engaging and\nhuman-like by human evaluators, compared to outputs from existing dialog\nmodels.",
    "descriptor": "\nComments: Accepted at ACL 2021 for oral presentation\n",
    "authors": [
      "Bodhisattwa Prasad Majumder",
      "Taylor Berg-Kirkpatrick",
      "Julian McAuley",
      "Harsh Jhamtani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08364"
  },
  {
    "id": "arXiv:2106.08365",
    "title": "Predicting Unreliable Predictions by Shattering a Neural Network",
    "abstract": "Piecewise linear neural networks can be split into subfunctions, each with\nits own activation pattern, domain, and empirical error. Empirical error for\nthe full network can be written as an expectation over empirical error of\nsubfunctions. Constructing a generalization bound on subfunction empirical\nerror indicates that the more densely a subfunction is surrounded by training\nsamples in representation space, the more reliable its predictions are.\nFurther, it suggests that models with fewer activation regions generalize\nbetter, and models that abstract knowledge to a greater degree generalize\nbetter, all else equal. We propose not only a theoretical framework to reason\nabout subfunction error bounds but also a pragmatic way of approximately\nevaluating it, which we apply to predicting which samples the network will not\nsuccessfully generalize to. We test our method on detection of\nmisclassification and out-of-distribution samples, finding that it performs\ncompetitively in both cases. In short, some network activation patterns are\nassociated with higher reliability than others, and these can be identified\nusing subfunction error bounds.",
    "descriptor": "",
    "authors": [
      "Xu Ji",
      "Razvan Pascanu",
      "Devon Hjelm",
      "Andrea Vedaldi",
      "Balaji Lakshminarayanan",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08365"
  },
  {
    "id": "arXiv:2106.08366",
    "title": "Explaining decision of model from its prediction",
    "abstract": "This document summarizes different visual explanations methods such as CAM,\nGrad-CAM, Localization using Multiple Instance Learning - Saliency-based\nmethods, Saliency-driven Class-Impressions, Muting pixels in input image -\nAdversarial methods and Activation visualization, Convolution filter\nvisualization - Feature-based methods. We have also shown the results produced\nby different methods and a comparison between CAM, GradCAM, and Guided\nBackpropagation.",
    "descriptor": "\nComments: Literature review\n",
    "authors": [
      "Dipesh Tamboli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08366"
  },
  {
    "id": "arXiv:2106.08367",
    "title": "What Context Features Can Transformer Language Models Use?",
    "abstract": "Transformer-based language models benefit from conditioning on contexts of\nhundreds to thousands of previous tokens. What aspects of these contexts\ncontribute to accurate model prediction? We describe a series of experiments\nthat measure usable information by selectively ablating lexical and structural\ninformation in transformer language models trained on English Wikipedia. In\nboth mid- and long-range contexts, we find that several extremely destructive\ncontext manipulations -- including shuffling word order within sentences and\ndeleting all words other than nouns -- remove less than 15% of the usable\ninformation. Our results suggest that long contexts, but not their detailed\nsyntactic and propositional content, are important for the low perplexity of\ncurrent transformer language models.",
    "descriptor": "\nComments: 14 pages, 7 figures, to be published at ACL 2021\n",
    "authors": [
      "Joe O'Connor",
      "Jacob Andreas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08367"
  },
  {
    "id": "arXiv:2106.08370",
    "title": "Unraveling the Temporal Importance of Community-scale Human Activity  Features for Rapid Assessment of Flood Impacts",
    "abstract": "The objective of this research is to explore the temporal importance of\ncommunity-scale human activity features for rapid assessment of flood impacts.\nUltimate flood impact data, such as flood inundation maps and insurance claims,\nbecomes available only weeks and months after the floods have receded. Crisis\nresponse managers, however, need near-real-time data to prioritize emergency\nresponse. This time lag creates a need for rapid flood impact assessment. Some\nrecent studies have shown promising results for using human activity\nfluctuations as indicators of flood impacts. Existing studies, however, used\nmainly a single community-scale activity feature for the estimation of flood\nimpacts and have not investigated their temporal importance for indicating\nflood impacts. Hence, in this study, we examined the importance of\nheterogeneous human activity features in different flood event stages. Using\nfour community-scale big data categories we derived ten features related to the\nvariations in human activity and evaluated their temporal importance for rapid\nassessment of flood impacts. Using multiple random forest models, we examined\nthe temporal importance of each feature in indicating the extent of flood\nimpacts in the context of the 2017 Hurricane Harvey in Harris County, Texas.\nOur findings reveal that 1) fluctuations in human activity index and percentage\nof congested roads are the most important indicators for rapid flood impact\nassessment during response and recovery stages; 2) variations in credit card\ntransactions assumed a middle ranking; and 3) patterns of geolocated social\nmedia posts (Twitter) were of low importance across flood stages. The results\nof this research could rapidly forge a multi-tool enabling crisis managers to\nidentify hotspots with severe flood impacts at various stages then to plan and\nprioritize effective response strategies.",
    "descriptor": "\nComments: 26 pages and 15 figures\n",
    "authors": [
      "Fax Yuan",
      "Yang Yang",
      "Qingchun Li",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.08370"
  },
  {
    "id": "arXiv:2106.08371",
    "title": "Rinascimento: searching the behaviour space of Splendor",
    "abstract": "The use of Artificial Intelligence (AI) for play-testing is still on the\nsidelines of main applications of AI in games compared to performance-oriented\ngame-playing. One of the main purposes of play-testing a game is gathering data\non the gameplay, highlighting good and bad features of the design of the game,\nproviding useful insight to the game designers for improving the design. Using\nAI agents has the potential of speeding the process dramatically. The purpose\nof this research is to map the behavioural space (BSpace) of a game by using a\ngeneral method. Using the MAP-Elites algorithm we search the hyperparameter\nspace Rinascimento AI agents and map it to the BSpace defined by several\nbehavioural metrics. This methodology was able to highlight both exemplary and\ndegenerated behaviours in the original game design of Splendor and two\nvariations. In particular, the use of event-value functions has generally shown\na remarkable improvement in the coverage of the BSpace compared to agents based\non classic score-based reward signals.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Ivan Bravi",
      "Simon Lucas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08371"
  },
  {
    "id": "arXiv:2106.08372",
    "title": "A Multi-Layered Approach for Measuring the Simulation-to-Reality Gap of  Radar Perception for Autonomous Driving",
    "abstract": "With the increasing safety validation requirements for the release of a\nself-driving car, alternative approaches, such as simulation-based testing, are\nemerging in addition to conventional real-world testing. In order to rely on\nvirtual tests the employed sensor models have to be validated. For this reason,\nit is necessary to quantify the discrepancy between simulation and reality in\norder to determine whether a certain fidelity is sufficient for a desired\nintended use. There exists no sound method to measure this\nsimulation-to-reality gap of radar perception for autonomous driving. We\naddress this problem by introducing a multi-layered evaluation approach, which\nconsists of a combination of an explicit and an implicit sensor model\nevaluation. The former directly evaluates the realism of the synthetically\ngenerated sensor data, while the latter refers to an evaluation of a downstream\ntarget application. In order to demonstrate the method, we evaluated the\nfidelity of three typical radar model types (ideal, data-driven, ray\ntracing-based) and their applicability for virtually testing radar-based\nmulti-object tracking. We have shown the effectiveness of the proposed approach\nin terms of providing an in-depth sensor model assessment that renders existing\ndisparities visible and enables a realistic estimation of the overall model\nfidelity across different scenarios.",
    "descriptor": "\nComments: Accepted at the 24th IEEE International Conference on Intelligent Transportation Systems (ITSC 2021)\n",
    "authors": [
      "Anthony Ngo",
      "Max Paul Bauer",
      "Michael Resch"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.08372"
  },
  {
    "id": "arXiv:2106.08376",
    "title": "On the Objective Evaluation of Post Hoc Explainers",
    "abstract": "Many applications of data-driven models demand transparency of decisions,\nespecially in health care, criminal justice, and other high-stakes\nenvironments. Modern trends in machine learning research have led to algorithms\nthat are increasingly intricate to the degree that they are considered to be\nblack boxes. In an effort to reduce the opacity of decisions, methods have been\nproposed to construe the inner workings of such models in a\nhuman-comprehensible manner. These post hoc techniques are described as being\nuniversal explainers - capable of faithfully augmenting decisions with\nalgorithmic insight. Unfortunately, there is little agreement about what\nconstitutes a \"good\" explanation. Moreover, current methods of explanation\nevaluation are derived from either subjective or proxy means. In this work, we\npropose a framework for the evaluation of post hoc explainers on ground truth\nthat is directly derived from the additive structure of a model. We demonstrate\nthe efficacy of the framework in understanding explainers by evaluating popular\nexplainers on thousands of synthetic and several real-world tasks. The\nframework unveils that explanations may be accurate but misattribute the\nimportance of individual features.",
    "descriptor": "\nComments: 14 pages, 4 figures. Under review\n",
    "authors": [
      "Zachariah Carmichael",
      "Walter J. Scheirer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08376"
  },
  {
    "id": "arXiv:2106.08377",
    "title": "Implicit Finite-Horizon Approximation and Efficient Optimal Algorithms  for Stochastic Shortest Path",
    "abstract": "We introduce a generic template for developing regret minimization algorithms\nin the Stochastic Shortest Path (SSP) model, which achieves minimax optimal\nregret as long as certain properties are ensured. The key of our analysis is a\nnew technique called implicit finite-horizon approximation, which approximates\nthe SSP model by a finite-horizon counterpart only in the analysis without\nexplicit implementation. Using this template, we develop two new algorithms:\nthe first one is model-free (the first in the literature to our knowledge) and\nminimax optimal under strictly positive costs; the second one is model-based\nand minimax optimal even with zero-cost state-action pairs, matching the best\nexisting result from [Tarbouriech et al., 2021b]. Importantly, both algorithms\nadmit highly sparse updates, making them computationally more efficient than\nall existing algorithms. Moreover, both can be made completely parameter-free.",
    "descriptor": "",
    "authors": [
      "Liyu Chen",
      "Mehdi Jafarnia-Jahromi",
      "Rahul Jain",
      "Haipeng Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08377"
  },
  {
    "id": "arXiv:2106.08382",
    "title": "DMSANet: Dual Multi Scale Attention Network",
    "abstract": "Attention mechanism of late has been quite popular in the computer vision\ncommunity. A lot of work has been done to improve the performance of the\nnetwork, although almost always it results in increased computational\ncomplexity. In this paper, we propose a new attention module that not only\nachieves the best performance but also has lesser parameters compared to most\nexisting models. Our attention module can easily be integrated with other\nconvolutional neural networks because of its lightweight nature. The proposed\nnetwork named Dual Multi Scale Attention Network (DMSANet) is comprised of two\nparts: the first part is used to extract features at various scales and\naggregate them, the second part uses spatial and channel attention modules in\nparallel to adaptively integrate local features with their global dependencies.\nWe benchmark our network performance for Image Classification on ImageNet\ndataset, Object Detection and Instance Segmentation both on MS COCO dataset.",
    "descriptor": "\nComments: 11 pages, 3 figures, 8 tables, Submitted to Neurips 2021\n",
    "authors": [
      "Abhinav Sagar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08382"
  },
  {
    "id": "arXiv:2106.08385",
    "title": "TextStyleBrush: Transfer of Text Aesthetics from a Single Example",
    "abstract": "We present a novel approach for disentangling the content of a text image\nfrom all aspects of its appearance. The appearance representation we derive can\nthen be applied to new content, for one-shot transfer of the source style to\nnew content. We learn this disentanglement in a self-supervised manner. Our\nmethod processes entire word boxes, without requiring segmentation of text from\nbackground, per-character processing, or making assumptions on string lengths.\nWe show results in different text domains which were previously handled by\nspecialized methods, e.g., scene text, handwritten text. To these ends, we make\na number of technical contributions: (1) We disentangle the style and content\nof a textual image into a non-parametric, fixed-dimensional vector. (2) We\npropose a novel approach inspired by StyleGAN but conditioned over the example\nstyle at different resolution and content. (3) We present novel self-supervised\ntraining criteria which preserve both source style and target content using a\npre-trained font classifier and text recognizer. Finally, (4) we also introduce\nImgur5K, a new challenging dataset for handwritten word images. We offer\nnumerous qualitative photo-realistic results of our method. We further show\nthat our method surpasses previous work in quantitative tests on scene text and\nhandwriting datasets, as well as in a user study.",
    "descriptor": "\nComments: 18 pages, 13 figures\n",
    "authors": [
      "Praveen Krishnan",
      "Rama Kovvuri",
      "Guan Pang",
      "Boris Vassilev",
      "Tal Hassner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08385"
  },
  {
    "id": "arXiv:2106.08387",
    "title": "Towards Adversarial Robustness via Transductive Learning",
    "abstract": "There has been emerging interest to use transductive learning for adversarial\nrobustness (Goldwasser et al., NeurIPS 2020; Wu et al., ICML 2020). Compared to\ntraditional \"test-time\" defenses, these defense mechanisms \"dynamically\nretrain\" the model based on test time input via transductive learning; and\ntheoretically, attacking these defenses boils down to bilevel optimization,\nwhich seems to raise the difficulty for adaptive attacks. In this paper, we\nfirst formalize and analyze modeling aspects of transductive robustness. Then,\nwe propose the principle of attacking model space for solving bilevel attack\nobjectives, and present an instantiation of the principle which breaks previous\ntransductive defenses. These attacks thus point to significant difficulties in\nthe use of transductive learning to improve adversarial robustness. To this\nend, we present new theoretical and empirical evidence in support of the\nutility of transductive learning.",
    "descriptor": "",
    "authors": [
      "Jiefeng Chen",
      "Yang Guo",
      "Xi Wu",
      "Tianqi Li",
      "Qicheng Lao",
      "Yingyu Liang",
      "Somesh Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08387"
  },
  {
    "id": "arXiv:2106.08389",
    "title": "Plane and Sample: Maximizing Information about Autonomous Vehicle  Performance using Submodular Optimization",
    "abstract": "As autonomous vehicles (AVs) take on growing Operational Design Domains\n(ODDs), they need to go through a systematic, transparent, and scalable\nevaluation process to demonstrate their benefits to society. Current scenario\nsampling techniques for AV performance evaluation usually focus on a specific\nfunctionality, such as lane changing, and do not accommodate a transfer of\ninformation about an AV system from one ODD to the next. In this paper, we\nreformulate the scenario sampling problem across ODDs and functionalities as a\nsubmodular optimization problem. To do so, we abstract AV performance as a\nBayesian Hierarchical Model, which we use to infer information gained by\nrevealing performance in new scenarios. We propose the information gain as a\nmeasure of scenario relevance and evaluation progress. Furthermore, we leverage\nthe submodularity, or diminishing returns, property of the information gain not\nonly to find a near-optimal scenario set, but also to propose a stopping\ncriterion for an AV performance evaluation campaign. We find that we only need\nto explore about 7.5% of the scenario space to meet this criterion, a 23%\nimprovement over Latin Hypercube Sampling.",
    "descriptor": "\nComments: 8 pages, 8 figures. Accepted for publication at the 2021 IEEE International Intelligent Transportation Systems Conference (ITSC)\n",
    "authors": [
      "Anne Collin",
      "Amitai Y. Bin-Nun",
      "Radboud Duintjer Tebbens"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08389"
  },
  {
    "id": "arXiv:2106.08392",
    "title": "Channel Responses for the Molecule Release from Spherical Homogeneous  Matrix Carriers",
    "abstract": "Molecular communications is a promising framework for the design of\ncontrolled-release drug delivery systems. Under this framework, drug carriers,\ndiseased cells, and the channel are modeled as transmitters, absorbing\nreceivers, and diffusive channel, respectively. In this paper, we investigate\ndiffusion-based spherical matrix-type drug carriers, which are employed in\nmedical applications. In a matrix carrier, the drug molecules are dispersed in\nthe matrix core and diffuse from the inner to the outer layers of the carrier\nonce immersed in a dissolution medium. We derive the channel response of the\nmatrix carrier transmitter for an absorbing receiver and compare our results\nwith commonly used point and transparent spherical transmitters to highlight\nthe necessity of considering practical models. Furthermore, we derive a\ncriterion for evaluating whether the release process or the channel dynamics\nare more important for the characteristics of the channel response of a drug\ndelivery system. For the limiting regimes, where only the release process or\nthe channel determine the behavior of the end-to-end system, we propose\nclosed-form approximations for the channel response. Finally, we investigate\nthe channel responses for the release of common therapeutic drugs, e.g.,\ndoxorubicin, from a diblock copolymer micelle acting as drug carrier.",
    "descriptor": "\nComments: 30 pages, 8 figures, 2 tables, Submitted for possible journal publication in IEEE Transactions on Molecular, Biological and Multi-Scale Communications. arXiv admin note: text overlap with arXiv:2104.05332\n",
    "authors": [
      "Maximilian Sch\u00e4fer",
      "Yolanda Salinas",
      "Alexander Ruderer",
      "Franz Enzenhofer",
      "Oliver Br\u00fcggemann",
      "Ram\u00f3n Mart\u00ednez-M\u00e1\u00f1ez",
      "Rudolf Rabenstein",
      "Robert Schober",
      "Werner Haselmayr"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2106.08392"
  },
  {
    "id": "arXiv:2106.08393",
    "title": "Spoofing Generalization: When Can't You Trust Proprietary Models?",
    "abstract": "In this work, we study the computational complexity of determining whether a\nmachine learning model that perfectly fits the training data will generalizes\nto unseen data. In particular, we study the power of a malicious agent whose\ngoal is to construct a model g that fits its training data and nothing else,\nbut is indistinguishable from an accurate model f. We say that g strongly\nspoofs f if no polynomial-time algorithm can tell them apart. If instead we\nrestrict to algorithms that run in $n^c$ time for some fixed $c$, we say that g\nc-weakly spoofs f. Our main results are\n1. Under cryptographic assumptions, strong spoofing is possible and 2. For\nany c> 0, c-weak spoofing is possible unconditionally\nWhile the assumption of a malicious agent is an extreme scenario (hopefully\ncompanies training large models are not malicious), we believe that it sheds\nlight on the inherent difficulties of blindly trusting large proprietary models\nor data.",
    "descriptor": "",
    "authors": [
      "Ankur Moitra",
      "Elchanan Mossel",
      "Colin Sandon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.08393"
  },
  {
    "id": "arXiv:2106.08396",
    "title": "Learning-based Support Estimation in Sublinear Time",
    "abstract": "We consider the problem of estimating the number of distinct elements in a\nlarge data set (or, equivalently, the support size of the distribution induced\nby the data set) from a random sample of its elements. The problem occurs in\nmany applications, including biology, genomics, computer systems and\nlinguistics. A line of research spanning the last decade resulted in algorithms\nthat estimate the support up to $ \\pm \\varepsilon n$ from a sample of size\n$O(\\log^2(1/\\varepsilon) \\cdot n/\\log n)$, where $n$ is the data set size.\nUnfortunately, this bound is known to be tight, limiting further improvements\nto the complexity of this problem. In this paper we consider estimation\nalgorithms augmented with a machine-learning-based predictor that, given any\nelement, returns an estimation of its frequency. We show that if the predictor\nis correct up to a constant approximation factor, then the sample complexity\ncan be reduced significantly, to \\[ \\ \\log (1/\\varepsilon) \\cdot\nn^{1-\\Theta(1/\\log(1/\\varepsilon))}. \\] We evaluate the proposed algorithms on\na collection of data sets, using the neural-network based estimators from {Hsu\net al, ICLR'19} as predictors. Our experiments demonstrate substantial (up to\n3x) improvements in the estimation accuracy compared to the state of the art\nalgorithm.",
    "descriptor": "\nComments: 17 pages. Published as a conference paper in ICLR 2021\n",
    "authors": [
      "Talya Eden",
      "Piotr Indyk",
      "Shyam Narayanan",
      "Ronitt Rubinfeld",
      "Sandeep Silwal",
      "Tal Wagner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.08396"
  },
  {
    "id": "arXiv:2106.08402",
    "title": "Exploring the Feasibility of Using 3D XPoint as an In-Memory Computing  Accelerator",
    "abstract": "This paper describes how 3D XPoint memory arrays can be used as in-memory\ncomputing accelerators. We first show that thresholded matrix-vector\nmultiplication (TMVM), the fundamental computational kernel in many\napplications including machine learning, can be implemented within a 3D XPoint\narray without requiring data to leave the array for processing. Using the\nimplementation of TMVM, we then discuss the implementation of a binary neural\ninference engine. We discuss the application of the core concept to address\nissues such as system scalability, where we connect multiple 3D XPoint arrays,\nand power integrity, where we analyze the parasitic effects of metal lines on\nnoise margins. To assure power integrity within the 3D XPoint array during this\nimplementation, we carefully analyze the parasitic effects of metal lines on\nthe accuracy of the implementations. We quantify the impact of parasitics on\nlimiting the size and configuration of a 3D XPoint array, and estimate the\nmaximum acceptable size of a 3D XPoint subarray.",
    "descriptor": "",
    "authors": [
      "Masoud Zabihi",
      "Salonik Resch",
      "Husrev C\u0131lasun",
      "Zamshed I. Chowdhury",
      "Zhengyang Zhao",
      "Ulya R. Karpuzcu",
      "Jian-Ping Wang",
      "Sachin S. Sapatnekar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.08402"
  },
  {
    "id": "arXiv:2106.08403",
    "title": "AndroR2: A Dataset of Manually Reproduced Bug Reports for Android  Applications",
    "abstract": "Software maintenance constitutes a large portion of the software development\nlifecycle. To carry out maintenance tasks, developers often need to understand\nand reproduce bug reports. As such, there has been increasing research activity\ncoalescing around the notion of automating various activities related to bug\nreporting. A sizable portion of this research interest has focused on the\ndomain of mobile apps. However, as research around mobile app bug reporting\nprogresses, there is a clear need for a manually vetted and reproducible set of\nreal-world bug reports that can serve as a benchmark for future work. This\npaper presents ANDROR2: a dataset of 90 manually reproduced bug reports for\nAndroid apps listed on Google Play and hosted on GitHub, systematically\ncollected via an in-depth analysis of 459 reports extracted from the GitHub\nissue tracker. For each reproduced report, ANDROR2 includes the original bug\nreport, an apk file for the buggy version of the app, an executable\nreproduction script, and metadata regarding the quality of the reproduction\nsteps associated with the original report. We believe that the ANDROR2 dataset\ncan be used to facilitate research in automatically analyzing, understanding,\nreproducing, localizing, and fixing bugs for mobile applications as well as\nother software maintenance activities more broadly.",
    "descriptor": "\nComments: 5 pages, Accepted to the 2021 International Conference on Mining Software Repositories, Data Showcase Track; Links to Datasets: this https URL; this https URL\n",
    "authors": [
      "Tyler Wendland",
      "Jingyang Sun",
      "Junayed Mahmud",
      "S. M. Hasan Mansur",
      "Steven Huang",
      "Kevin Moran",
      "Julia Rubin",
      "Mattia Fazzini"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.08403"
  },
  {
    "id": "arXiv:2106.08408",
    "title": "Seeing Through Clouds in Satellite Images",
    "abstract": "This paper presents a neural-network-based solution to recover pixels\noccluded by clouds in satellite images. We leverage radio frequency (RF)\nsignals in the ultra/super-high frequency band that penetrate clouds to help\nreconstruct the occluded regions in multispectral images. We introduce the\nfirst multi-modal multi-temporal cloud removal model. Our model uses publicly\navailable satellite observations and produces daily cloud-free images.\nExperimental results show that our system significantly outperforms baselines\nby 8dB in PSNR. We also demonstrate use cases of our system in digital\nagriculture, flood monitoring, and wildfire detection. We will release the\nprocessed dataset to facilitate future research.",
    "descriptor": "",
    "authors": [
      "Mingmin Zhao",
      "Peder A. Olsen",
      "Ranveer Chandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08408"
  },
  {
    "id": "arXiv:2106.08409",
    "title": "Benchmark dataset of memes with text transcriptions for automatic  detection of multi-modal misogynistic content",
    "abstract": "In this paper we present a benchmark dataset generated as part of a project\nfor automatic identification of misogyny within online content, which focuses\nin particular on memes. The benchmark here described is composed of 800 memes\ncollected from the most popular social media platforms, such as Facebook,\nTwitter, Instagram and Reddit, and consulting websites dedicated to collection\nand creation of memes. To gather misogynistic memes, specific keywords that\nrefer to misogynistic content have been considered as search criterion,\nconsidering different manifestations of hatred against women, such as body\nshaming, stereotyping, objectification and violence. In parallel, memes with no\nmisogynist content have been manually downloaded from the same web sources.\nAmong all the collected memes, three domain experts have selected a dataset of\n800 memes equally balanced between misogynistic and non-misogynistic ones. This\ndataset has been validated through a crowdsourcing platform, involving 60\nsubjects for the labelling process, in order to collect three evaluations for\neach instance. Two further binary labels have been collected from both the\nexperts and the crowdsourcing platform, for memes evaluated as misogynistic,\nconcerning aggressiveness and irony. Finally for each meme, the text has been\nmanually transcribed. The dataset provided is thus composed of the 800 memes,\nthe labels given by the experts and those obtained by the crowdsourcing\nvalidation, and the transcribed texts. This data can be used to approach the\nproblem of automatic detection of misogynistic content on the Web relying on\nboth textual and visual cues, facing phenomenons that are growing every day\nsuch as cybersexism and technology-facilitated violence.",
    "descriptor": "",
    "authors": [
      "Francesca Gasparini",
      "Giulia Rizzi",
      "Aurora Saibene",
      "Elisabetta Fersini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08409"
  },
  {
    "id": "arXiv:2106.08413",
    "title": "Robust Reinforcement Learning Under Minimax Regret for Green Security",
    "abstract": "Green security domains feature defenders who plan patrols in the face of\nuncertainty about the adversarial behavior of poachers, illegal loggers, and\nillegal fishers. Importantly, the deterrence effect of patrols on adversaries'\nfuture behavior makes patrol planning a sequential decision-making problem.\nTherefore, we focus on robust sequential patrol planning for green security\nfollowing the minimax regret criterion, which has not been considered in the\nliterature. We formulate the problem as a game between the defender and nature\nwho controls the parameter values of the adversarial behavior and design an\nalgorithm MIRROR to find a robust policy. MIRROR uses two reinforcement\nlearning-based oracles and solves a restricted game considering limited\ndefender strategies and parameter values. We evaluate MIRROR on real-world\npoaching data.",
    "descriptor": "\nComments: Accepted at the Conference on Uncertainty in Artificial Intelligence (UAI) 2021. 11 pages, 5 figures\n",
    "authors": [
      "Lily Xu",
      "Andrew Perrault",
      "Fei Fang",
      "Haipeng Chen",
      "Milind Tambe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.08413"
  },
  {
    "id": "arXiv:2106.08414",
    "title": "On the Sample Complexity and Metastability of Heavy-tailed Policy Search  in Continuous Control",
    "abstract": "Reinforcement learning is a framework for interactive decision-making with\nincentives sequentially revealed across time without a system dynamics model.\nDue to its scaling to continuous spaces, we focus on policy search where one\niteratively improves a parameterized policy with stochastic policy gradient\n(PG) updates. In tabular Markov Decision Problems (MDPs), under persistent\nexploration and suitable parameterization, global optimality may be obtained.\nBy contrast, in continuous space, the non-convexity poses a pathological\nchallenge as evidenced by existing convergence results being mostly limited to\nstationarity or arbitrary local extrema. To close this gap, we step towards\npersistent exploration in continuous space through policy parameterizations\ndefined by distributions of heavier tails defined by tail-index parameter\nalpha, which increases the likelihood of jumping in state space. Doing so\ninvalidates smoothness conditions of the score function common to PG. Thus, we\nestablish how the convergence rate to stationarity depends on the policy's tail\nindex alpha, a Holder continuity parameter, integrability conditions, and an\nexploration tolerance parameter introduced here for the first time. Further, we\ncharacterize the dependence of the set of local maxima on the tail index\nthrough an exit and transition time analysis of a suitably defined Markov\nchain, identifying that policies associated with Levy Processes of a heavier\ntail converge to wider peaks. This phenomenon yields improved stability to\nperturbations in supervised learning, which we corroborate also manifests in\nimproved performance of policy search, especially when myopic and farsighted\nincentives are misaligned.",
    "descriptor": "",
    "authors": [
      "Amrit Singh Bedi",
      "Anjaly Parayil",
      "Junyu Zhang",
      "Mengdi Wang",
      "Alec Koppel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08414"
  },
  {
    "id": "arXiv:2106.08415",
    "title": "Code to Comment Translation: A Comparative Study on Model Effectiveness  & Errors",
    "abstract": "Automated source code summarization is a popular software engineering\nresearch topic wherein machine translation models are employed to \"translate\"\ncode snippets into relevant natural language descriptions. Most evaluations of\nsuch models are conducted using automatic reference-based metrics. However,\ngiven the relatively large semantic gap between programming languages and\nnatural language, we argue that this line of research would benefit from a\nqualitative investigation into the various error modes of current\nstate-of-the-art models. Therefore, in this work, we perform both a\nquantitative and qualitative comparison of three recently proposed source code\nsummarization models. In our quantitative evaluation, we compare the models\nbased on the smoothed BLEU-4, METEOR, and ROUGE-L machine translation metrics,\nand in our qualitative evaluation, we perform a manual open-coding of the most\ncommon errors committed by the models when compared to ground truth captions.\nOur investigation reveals new insights into the relationship between\nmetric-based performance and model prediction errors grounded in an empirically\nderived error taxonomy that can be used to drive future research efforts",
    "descriptor": "\nComments: Accepted to the 2021 NLP4Prog Workshop co-located with The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)\n",
    "authors": [
      "Junayed Mahmud",
      "Fahim Faisal",
      "Raihan Islam Arnob",
      "Antonios Anastasopoulos",
      "Kevin Moran"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08415"
  },
  {
    "id": "arXiv:2106.08417",
    "title": "Scene Transformer: A unified multi-task model for behavior prediction  and planning",
    "abstract": "Predicting the future motion of multiple agents is necessary for planning in\ndynamic environments. This task is challenging for autonomous driving since\nagents (e.g., vehicles and pedestrians) and their associated behaviors may be\ndiverse and influence each other. Most prior work has focused on first\npredicting independent futures for each agent based on all past motion, and\nthen planning against these independent predictions. However, planning against\nfixed predictions can suffer from the inability to represent the future\ninteraction possibilities between different agents, leading to sub-optimal\nplanning. In this work, we formulate a model for predicting the behavior of all\nagents jointly in real-world driving environments in a unified manner. Inspired\nby recent language modeling approaches, we use a masking strategy as the query\nto our model, enabling one to invoke a single model to predict agent behavior\nin many ways, such as potentially conditioned on the goal or full future\ntrajectory of the autonomous vehicle or the behavior of other agents in the\nenvironment. Our model architecture fuses heterogeneous world state in a\nunified Transformer architecture by employing attention across road elements,\nagent interactions and time steps. We evaluate our approach on autonomous\ndriving datasets for behavior prediction, and achieve state-of-the-art\nperformance. Our work demonstrates that formulating the problem of behavior\nprediction in a unified architecture with a masking strategy may allow us to\nhave a single model that can perform multiple motion prediction and planning\nrelated tasks effectively.",
    "descriptor": "",
    "authors": [
      "Jiquan Ngiam",
      "Benjamin Caine",
      "Vijay Vasudevan",
      "Zhengdong Zhang",
      "Hao-Tien Lewis Chiang",
      "Jeffrey Ling",
      "Rebecca Roelofs",
      "Alex Bewley",
      "Chenxi Liu",
      "Ashish Venugopal",
      "David Weiss",
      "Ben Sapp",
      "Zhifeng Chen",
      "Jonathon Shlens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.08417"
  },
  {
    "id": "arXiv:2106.08418",
    "title": "Probabilistic Metric Temporal Graph Logic",
    "abstract": "Cyber-physical systems often encompass complex concurrent behavior with\ntiming constraints and probabilistic failures on demand. The analysis whether\nsuch systems with probabilistic timed behavior ad-here to a given specification\nis essential. When the states of the system can be represented by graphs, the\nrule-based formalism of Probabilistic Timed Graph Transformation Systems\n(PTGTSs) can be used to suitably capture structure dynamics as well as\nprobabilistic and timed behavior of the system. The model checking support for\nPTGTSs w.r.t. properties specified using Probabilistic Timed Computation Tree\nLogic (PTCTL) has been already presented. Moreover, for timed graph-based\nruntime monitoring, Metric Temporal Graph Logic (MTGL) has been developed for\nstating metric temporal properties on identified subgraphs and their structural\nchanges over time. In this paper, we (a) extend MTGL to the Probabilistic\nMetric Temporal Graph Logic (PMTGL) by allowing for the specification of\nprobabilistic properties, (b) adapt our MTGL satisfaction checking approach to\nPTGTSs, and (c) combine the approaches for PTCTL model checking and MTGL\nsatisfaction checking to obtain a Bounded Model Checking (BMC) approach for\nPMTGL. In our evaluation, we apply an implementation of our BMC approach in\nAutoGraph to a running example.",
    "descriptor": "",
    "authors": [
      "Sven Schneider",
      "Maria Maximova",
      "Holger Giese"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.08418"
  },
  {
    "id": "arXiv:2106.08422",
    "title": "Imitation and Mirror Systems in Robots through Deep Modality Blending  Networks",
    "abstract": "Learning to interact with the environment not only empowers the agent with\nmanipulation capability but also generates information to facilitate building\nof action understanding and imitation capabilities. This seems to be a strategy\nadopted by biological systems, in particular primates, as evidenced by the\nexistence of mirror neurons that seem to be involved in multi-modal action\nunderstanding. How to benefit from the interaction experience of the robots to\nenable understanding actions and goals of other agents is still a challenging\nquestion. In this study, we propose a novel method, deep modality blending\nnetworks (DMBN), that creates a common latent space from multi-modal experience\nof a robot by blending multi-modal signals with a stochastic weighting\nmechanism. We show for the first time that deep learning, when combined with a\nnovel modality blending scheme, can facilitate action recognition and produce\nstructures to sustain anatomical and effect-based imitation capabilities. Our\nproposed system, can be conditioned on any desired sensory/motor value at any\ntime-step, and can generate a complete multi-modal trajectory consistent with\nthe desired conditioning in parallel avoiding accumulation of prediction\nerrors. We further showed that given desired images from different\nperspectives, i.e. images generated by the observation of other robots placed\non different sides of the table, our system could generate image and joint\nangle sequences that correspond to either anatomical or effect based imitation\nbehavior. Overall, the proposed DMBN architecture not only serves as a\ncomputational model for sustaining mirror neuron-like capabilities, but also\nstands as a powerful machine learning architecture for high-dimensional\nmulti-modal temporal data with robust retrieval capabilities operating with\npartial information in one or multiple modalities.",
    "descriptor": "",
    "authors": [
      "M. Y. Seker",
      "A. Ahmetoglu",
      "Y. Nagai",
      "M. Asada",
      "E. Oztop",
      "E. Ugur"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.08422"
  },
  {
    "id": "arXiv:2106.08423",
    "title": "COVID-19 Vaccines: Characterizing Misinformation Campaigns and Vaccine  Hesitancy on Twitter",
    "abstract": "Vaccine hesitancy and misinformation on social media has increased concerns\nabout COVID-19 vaccine uptake required to achieve herd immunity and overcome\nthe pandemic. However anti-science and political misinformation and\nconspiracies have been rampant throughout the pandemic. For COVID-19 vaccines,\nwe investigate misinformation and conspiracy campaigns and their characteristic\nbehaviours. We identify whether coordinated efforts are used to promote\nmisinformation in vaccine related discussions, and find accounts coordinately\npromoting a `Great Reset' conspiracy group promoting vaccine related\nmisinformation and strong anti-vaccine and anti-social messages such as boycott\nvaccine passports, no lock-downs and masks. We characterize other\nmisinformation communities from the information diffusion structure, and study\nthe large anti-vaccine misinformation community and smaller anti-vaccine\ncommunities, including a far-right anti-vaccine conspiracy group. In comparison\nwith the mainstream and health news, left-leaning group, which are more\npro-vaccine, the right-leaning group is influenced more by the anti-vaccine and\nfar-right misinformation/conspiracy communities. The misinformation communities\nare more vocal either specific to the vaccine discussion or political\ndiscussion, and we find other differences in the characteristic behaviours of\ndifferent communities. Lastly, we investigate misinformation narratives and\ntactics of information distortion that can increase vaccine hesitancy, using\ntopic modeling and comparison with reported vaccine side-effects (VAERS)\nfinding rarer side-effects are more frequently discussed on social media.",
    "descriptor": "",
    "authors": [
      "Karishma Sharma",
      "Yizhou Zhang",
      "Yan Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.08423"
  },
  {
    "id": "arXiv:2106.08424",
    "title": "Design and analysis of deployable clustered tensegrity cable domes",
    "abstract": "This study presents the design and analysis of deployable cable domes based\non the clustered tensegrity structures (CTS). In this paper, the statics and\ndynamics equations of the CTS are first given. Using a traditional Levy cable\ndome as an example, we show the approach to modify the Levy dome to a\ndeployable CTS one. The strings to be clustered are determined by the\nrequirement of prestress mode and global stability. The deployment trajectory\nis proposed by changing the deployment ratio (the ratio between the radius of\nthe inner and outer rings of the cable dome). Then, the quasi-static and\ndynamic deployment of clustered tensegrity dome is studied. Results show that\nthe proposed CTS cable dome always has one prestress mode and is globally\nstable in its deployment trajectory. In the deployment process analysis, the\ndynamics show that the system's dynamic response differs from the quasi-static\nsimulation as the actuation speed increases. That is, for a fast deployment\nprocess, quasi-static simulation is not accurate enough. The dynamics effects\nof the deployment must be considered. The developed approaches can also be used\nfor the design and analysis of various kinds of CTS.",
    "descriptor": "\nComments: 13 pages, 14 figures\n",
    "authors": [
      "Shuo Ma",
      "Muhao Chen",
      "Xingfei Yuan",
      "Robert E. Skelton"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.08424"
  },
  {
    "id": "arXiv:2106.08427",
    "title": "Pathological voice adaptation with autoencoder-based voice conversion",
    "abstract": "In this paper, we propose a new approach to pathological speech synthesis.\nInstead of using healthy speech as a source, we customise an existing\npathological speech sample to a new speaker's voice characteristics. This\napproach alleviates the evaluation problem one normally has when converting\ntypical speech to pathological speech, as in our approach, the voice conversion\n(VC) model does not need to be optimised for speech degradation but only for\nthe speaker change. This change in the optimisation ensures that any\ndegradation found in naturalness is due to the conversion process and not due\nto the model exaggerating characteristics of a speech pathology. To show a\nproof of concept of this method, we convert dysarthric speech using the\nUASpeech database and an autoencoder-based VC technique. Subjective evaluation\nresults show reasonable naturalness for high intelligibility dysarthric\nspeakers, though lower intelligibility seems to introduce a marginal\ndegradation in naturalness scores for mid and low intelligibility speakers\ncompared to ground truth. Conversion of speaker characteristics for low and\nhigh intelligibility speakers is successful, but not for mid. Whether the\ndifferences in the results for the different intelligibility levels is due to\nthe intelligibility levels or due to the speakers needs to be further\ninvestigated.",
    "descriptor": "\nComments: 6 pages, 3 figures. Accepted to the 11th ISCA Speech Synthesis Workshop (2021)\n",
    "authors": [
      "Marc Illa",
      "Bence Mark Halpern",
      "Rob van Son",
      "Laureano Moro-Velazquez",
      "Odette Scharenborg"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.08427"
  },
  {
    "id": "arXiv:2106.08433",
    "title": "Analysing Dense Passage Retrieval for Multi-hop Question Answering",
    "abstract": "We analyse the performance of passage retrieval models in the presence of\ncomplex (multi-hop) questions to provide a better understanding of how\nretrieval systems behave when multiple hops of reasoning are needed. In simple\nopen-domain question answering (QA), dense passage retrieval has become one of\nthe standard approaches for retrieving the relevant passages to infer an\nanswer. Recently, dense passage retrieval also achieved state-of-the-art\nresults in multi-hop QA, where aggregating information from multiple documents\nand reasoning over them is required. However, so far, the dense retrieval\nmodels are not evaluated properly concerning the multi-hop nature of the\nproblem: models are typically evaluated by the end result of the retrieval\npipeline, which leaves unclear where their success lies. In this work, we\nprovide an in-depth evaluation of such models not only unveiling the reasons\nbehind their success but also their limitations. Moreover, we introduce a\nhybrid (lexical and dense) retrieval approach that is highly competitive with\nthe state-of-the-art dense retrieval model, while requiring substantially less\ncomputational resources. Furthermore, we also perform qualitative analysis to\nbetter understand the challenges behind passage retrieval for multi-hop QA.",
    "descriptor": "",
    "authors": [
      "Georgios Sidiropoulos",
      "Nikos Voskarides",
      "Svitlana Vakulenko",
      "Evangelos Kanoulas"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.08433"
  },
  {
    "id": "arXiv:2106.08441",
    "title": "Online Learning with Uncertain Feedback Graphs",
    "abstract": "Online learning with expert advice is widely used in various machine learning\ntasks. It considers the problem where a learner chooses one from a set of\nexperts to take advice and make a decision. In many learning problems, experts\nmay be related, henceforth the learner can observe the losses associated with a\nsubset of experts that are related to the chosen one. In this context, the\nrelationship among experts can be captured by a feedback graph, which can be\nused to assist the learner's decision making. However, in practice, the nominal\nfeedback graph often entails uncertainties, which renders it impossible to\nreveal the actual relationship among experts. To cope with this challenge, the\npresent work studies various cases of potential uncertainties, and develops\nnovel online learning algorithms to deal with uncertainties while making use of\nthe uncertain feedback graph. The proposed algorithms are proved to enjoy\nsublinear regret under mild conditions. Experiments on real datasets are\npresented to demonstrate the effectiveness of the novel algorithms.",
    "descriptor": "",
    "authors": [
      "Pouya M Ghari",
      "Yanning Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08441"
  },
  {
    "id": "arXiv:2106.08444",
    "title": "CODA: Constructivism Learning for Instance-Dependent Dropout  Architecture Construction",
    "abstract": "Dropout is attracting intensive research interest in deep learning as an\nefficient approach to prevent overfitting. Recently incorporating structural\ninformation when deciding which units to drop out produced promising results\ncomparing to methods that ignore the structural information. However, a major\nissue of the existing work is that it failed to differentiate among instances\nwhen constructing the dropout architecture. This can be a significant\ndeficiency for many applications. To solve this issue, we propose\nConstructivism learning for instance-dependent Dropout Architecture (CODA),\nwhich is inspired from a philosophical theory, constructivism learning.\nSpecially, based on the theory we have designed a better drop out technique,\nUniform Process Mixture Models, using a Bayesian nonparametric method Uniform\nprocess. We have evaluated our proposed method on 5 real-world datasets and\ncompared the performance with other state-of-the-art dropout techniques. The\nexperimental results demonstrated the effectiveness of CODA.",
    "descriptor": "",
    "authors": [
      "Xiaoli Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08444"
  },
  {
    "id": "arXiv:2106.08445",
    "title": "Machine learning-based analysis of hyperspectral images for automated  sepsis diagnosis",
    "abstract": "Sepsis is a leading cause of mortality and critical illness worldwide. While\nrobust biomarkers for early diagnosis are still missing, recent work indicates\nthat hyperspectral imaging (HSI) has the potential to overcome this bottleneck\nby monitoring microcirculatory alterations. Automated machine learning-based\ndiagnosis of sepsis based on HSI data, however, has not been explored to date.\nGiven this gap in the literature, we leveraged an existing data set to (1)\ninvestigate whether HSI-based automated diagnosis of sepsis is possible and (2)\nput forth a list of possible confounders relevant for HSI-based tissue\nclassification. While we were able to classify sepsis with an accuracy of over\n$98\\,\\%$ using the existing data, our research also revealed several subject-,\ntherapy- and imaging-related confounders that may lead to an overestimation of\nalgorithm performance when not balanced across the patient groups. We conclude\nthat further prospective studies, carefully designed with respect to these\nconfounders, are necessary to confirm the preliminary results obtained in this\nstudy.",
    "descriptor": "\nComments: Maximilian Dietrich and Silvia Seidlitz contributed equally. Markus A. Weigand and Lena Maier-Hein contributed equally\n",
    "authors": [
      "Maximilian Dietrich",
      "Silvia Seidlitz",
      "Nicholas Schreck",
      "Manuel Wiesenfarth",
      "Patrick Godau",
      "Minu Tizabi",
      "Jan Sellner",
      "Sebastian Marx",
      "Samuel Kn\u00f6dler",
      "Michael M. Allers",
      "Leonardo Ayala",
      "Karsten Schmidt",
      "Thorsten Brenner",
      "Alexander Studier-Fischer",
      "Felix Nickel",
      "Beat P. M\u00fcller-Stich",
      "Annette Kopp-Schneider",
      "Markus A. Weigand",
      "Lena Maier-Hein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08445"
  },
  {
    "id": "arXiv:2106.08446",
    "title": "Bridge Networks",
    "abstract": "Despite rapid progress, current deep learning methods face a number of\ncritical challenges. These include high energy consumption, catastrophic\nforgetting, dependance on global losses, and an inability to reason\nsymbolically. By combining concepts from information bottleneck theory and\nvector-symbolic architectures, we propose and implement a novel information\nprocessing architecture, the 'Bridge network.' We show this architecture\nprovides unique advantages which can address the problem of global losses and\ncatastrophic forgetting. Furthermore, we argue that it provides a further basis\nfor increasing energy efficiency of execution and the ability to reason\nsymbolically.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Wilkie Olin-Ammentorp",
      "Maxim Bazhenov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08446"
  },
  {
    "id": "arXiv:2106.08448",
    "title": "Correlation Clustering in Constant Many Parallel Rounds",
    "abstract": "Correlation clustering is a central topic in unsupervised learning, with many\napplications in ML and data mining. In correlation clustering, one receives as\ninput a signed graph and the goal is to partition it to minimize the number of\ndisagreements. In this work we propose a massively parallel computation (MPC)\nalgorithm for this problem that is considerably faster than prior work. In\nparticular, our algorithm uses machines with memory sublinear in the number of\nnodes in the graph and returns a constant approximation while running only for\na constant number of rounds. To the best of our knowledge, our algorithm is the\nfirst that can provably approximate a clustering problem on graphs using only a\nconstant number of MPC rounds in the sublinear memory regime. We complement our\nanalysis with an experimental analysis of our techniques.",
    "descriptor": "\nComments: ICML 2021 (long talk)\n",
    "authors": [
      "Vincent Cohen-Addad",
      "Silvio Lattanzi",
      "Slobodan Mitrovi\u0107",
      "Ashkan Norouzi-Fard",
      "Nikos Parotsidis",
      "Jakub Tarnawski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08448"
  },
  {
    "id": "arXiv:2106.08452",
    "title": "Deep Neural Networks for Approximating Stream Reasoning with C-SPARQL",
    "abstract": "The amount of information produced, whether by newspapers, blogs and social\nnetworks, or by monitoring systems, is increasing rapidly. Processing all this\ndata in real-time, while taking into consideration advanced knowledge about the\nproblem domain, is challenging, but required in scenarios where assessing\npotential risks in a timely fashion is critical. C-SPARQL, a language for\ncontinuous queries over streams of RDF data, is one of the more prominent\napproaches in stream reasoning that provides such continuous inference\ncapabilities over dynamic data that go beyond mere stream processing. However,\nit has been shown that, in the presence of huge amounts of data, C-SPARQL may\nnot be able to answer queries in time, in particular when the frequency of\nincoming data is higher than the time required for reasoning with that data. In\nthis paper, we investigate whether reasoning with C-SPARQL can be approximated\nusing Recurrent Neural Networks and Convolutional Neural Networks, two neural\nnetwork architectures that have been shown to be well-suited for time series\nforecasting and time series classification, to leverage on their higher\nprocessing speed once the network has been trained. We consider a variety of\ndifferent kinds of queries and obtain overall positive results with high\naccuracies while improving processing time often by several orders of\nmagnitude.",
    "descriptor": "\nComments: Accepted at the 20th EPIA Conference on Artificial Intelligence, EPIA 2021\n",
    "authors": [
      "Ricardo Ferreira",
      "Carolina Lopes",
      "Ricardo Gon\u00e7alves",
      "Matthias Knorr",
      "Ludwig Krippahl",
      "Jo\u00e3o Leite"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08452"
  },
  {
    "id": "arXiv:2106.08453",
    "title": "Gradient-trained Weights in Wide Neural Networks Align Layerwise to  Error-scaled Input Correlations",
    "abstract": "Recent works have examined how deep neural networks, which can solve a\nvariety of difficult problems, incorporate the statistics of training data to\nachieve their success. However, existing results have been established only in\nlimited settings. In this work, we derive the layerwise weight dynamics of\ninfinite-width neural networks with nonlinear activations trained by gradient\ndescent. We show theoretically that weight updates are aligned with input\ncorrelations from intermediate layers weighted by error, and demonstrate\nempirically that the result also holds in finite-width wide networks. The\nalignment result allows us to formulate backpropagation-free learning rules,\nnamed Align-zero and Align-ada, that theoretically achieve the same alignment\nas backpropagation. Finally, we test these learning rules on benchmark problems\nin feedforward and recurrent neural networks and demonstrate, in wide networks,\ncomparable performance to backpropagation.",
    "descriptor": "\nComments: 22 pages, 11 figures\n",
    "authors": [
      "Akhilan Boopathy",
      "Ila Fiete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08453"
  },
  {
    "id": "arXiv:2106.08455",
    "title": "Machamp: A Generalized Entity Matching Benchmark",
    "abstract": "Entity Matching (EM) refers to the problem of determining whether two\ndifferent data representations refer to the same real-world entity. It has been\na long-standing interest of the data management community and many efforts have\nbeen paid in creating benchmark tasks as well as in developing advanced\nmatching techniques. However, existing benchmark tasks for EM are limited to\nthe case where the two data collections of entities are structured tables with\nthe same schema. Meanwhile, the data collections for matching could be\nstructured, semi-structured, or unstructured in real-world scenarios of data\nscience. In this paper, we come up with a new research problem -- Generalized\nEntity Matching to satisfy this requirement and create a benchmark Machamp for\nit. Machamp consists of seven tasks having diverse characteristics and thus\nprovides good coverage of use cases in real applications. We summarize existing\nEM benchmark tasks for structured tables and conduct a series of processing and\ncleaning efforts to transform them into matching tasks between tables with\ndifferent structures. Based on that, we further conduct comprehensive profiling\nof the proposed benchmark tasks and evaluate popular entity matching approaches\non them. With the help of Machamp, it is the first time that researchers can\nevaluate EM techniques between data collections with different structures.",
    "descriptor": "",
    "authors": [
      "Jin Wang",
      "Yuliang Li",
      "Wataru Hirota"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.08455"
  },
  {
    "id": "arXiv:2106.08457",
    "title": "Faster than LASER -- Towards Stream Reasoning with Deep Neural Networks",
    "abstract": "With the constant increase of available data in various domains, such as the\nInternet of Things, Social Networks or Smart Cities, it has become fundamental\nthat agents are able to process and reason with such data in real time. Whereas\nreasoning over time-annotated data with background knowledge may be\nchallenging, due to the volume and velocity in which such data is being\nproduced, such complex reasoning is necessary in scenarios where agents need to\ndiscover potential problems and this cannot be done with simple stream\nprocessing techniques. Stream Reasoners aim at bridging this gap between\nreasoning and stream processing and LASER is such a stream reasoner designed to\nanalyse and perform complex reasoning over streams of data. It is based on\nLARS, a rule-based logical language extending Answer Set Programming, and it\nhas shown better runtime results than other state-of-the-art stream reasoning\nsystems. Nevertheless, for high levels of data throughput even LASER may be\nunable to compute answers in a timely fashion. In this paper, we study whether\nConvolutional and Recurrent Neural Networks, which have shown to be\nparticularly well-suited for time series forecasting and classification, can be\ntrained to approximate reasoning with LASER, so that agents can benefit from\ntheir high processing speed.",
    "descriptor": "\nComments: Extended version of EPIA 21 paper\n",
    "authors": [
      "Jo\u00e3o Ferreira",
      "Diogo Lavado",
      "Ricardo Gon\u00e7alves",
      "Matthias Knorr",
      "Ludwig Krippahl",
      "Jo\u00e3o Leite"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08457"
  },
  {
    "id": "arXiv:2106.08458",
    "title": "Enabling AI and Robotic Coaches for Physical Rehabilitation Therapy:  Iterative Design and Evaluation with Therapists and Post-Stroke Survivors",
    "abstract": "Artificial intelligence (AI) and robotic coaches promise the improved\nengagement of patients on rehabilitation exercises through social interaction.\nWhile previous work explored the potential of automatically monitoring\nexercises for AI and robotic coaches, the deployment of these systems remains a\nchallenge. Previous work described the lack of involving stakeholders to design\nsuch functionalities as one of the major causes. In this paper, we present our\nefforts on eliciting the detailed design specifications on how AI and robotic\ncoaches could interact with and guide patient's exercises in an effective and\nacceptable way with four therapists and five post-stroke survivors. Through\niterative questionnaires and interviews, we found that both post-stroke\nsurvivors and therapists appreciated the potential benefits of AI and robotic\ncoaches to achieve more systematic management and improve their self-efficacy\nand motivation on rehabilitation therapy. In addition, our evaluation sheds\nlight on several practical concerns (e.g. a possible difficulty with the\ninteraction for people with cognitive impairment, system failures, etc.). We\ndiscuss the value of early involvement of stakeholders and interactive\ntechniques that complement system failures, but also support a personalized\ntherapy session for the better deployment of AI and robotic exercise coaches.",
    "descriptor": "",
    "authors": [
      "Min Hun Lee",
      "Daniel P. Siewiorek",
      "Asim Smailagic",
      "Alexandre Bernardino",
      "Sergi Berm\u00fadez i Badia"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.08458"
  },
  {
    "id": "arXiv:2106.08462",
    "title": "Multi-Resolution Continuous Normalizing Flows",
    "abstract": "Recent work has shown that Neural Ordinary Differential Equations (ODEs) can\nserve as generative models of images using the perspective of Continuous\nNormalizing Flows (CNFs). Such models offer exact likelihood calculation, and\ninvertible generation/density estimation. In this work we introduce a\nMulti-Resolution variant of such models (MRCNF), by characterizing the\nconditional distribution over the additional information required to generate a\nfine image that is consistent with the coarse image. We introduce a\ntransformation between resolutions that allows for no change in the log\nlikelihood. We show that this approach yields comparable likelihood values for\nvarious image datasets, with improved performance at higher resolutions, with\nfewer parameters, using only 1 GPU.",
    "descriptor": "\nComments: 9 pages, 5 figures, 3 tables, 17 equations\n",
    "authors": [
      "Vikram Voleti",
      "Chris Finlay",
      "Adam Oberman",
      "Christopher Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.08462"
  },
  {
    "id": "arXiv:2106.08463",
    "title": "Collision Avoidance with Stochastic Model Predictive Control for Systems  with a Twofold Uncertainty Structure",
    "abstract": "Model Predictive Control (MPC) has shown to be a successful method for many\napplications that require control. Especially in the presence of prediction\nuncertainty, various types of MPC offer robust or efficient control system\nbehavior. For modeling, uncertainty is most often approximated in such a way\nthat established MPC approaches are applicable for specific uncertainty types.\nHowever, for a number of applications, especially automated vehicles,\nuncertainty in predicting the future behavior of other agents is more suitably\nmodeled by a twofold description: a high-level task uncertainty and a low-level\nexecution uncertainty of individual tasks. In this work, we present an MPC\nframework that is capable of dealing with this twofold uncertainty. A scenario\nMPC approach considers the possibility of other agents performing one of\nmultiple tasks, with an arbitrary probability distribution, while an analytic\nstochastic MPC method handles execution uncertainty within a specific task,\nbased on a Gaussian distribution. Combining both approaches allows to\nefficiently handle the twofold uncertainty structure of many applications.\nApplication of the proposed MPC method is demonstrated in an automated vehicle\nsimulation study.",
    "descriptor": "\nComments: This work has been accepted to the IEEE 2021 International Conference on Intelligent Transportation Systems\n",
    "authors": [
      "Tim Br\u00fcdigam",
      "Jie Zhan",
      "Dirk Wollherr",
      "Marion Leibold"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08463"
  },
  {
    "id": "arXiv:2106.08468",
    "title": "RyanSpeech: A Corpus for Conversational Text-to-Speech Synthesis",
    "abstract": "This paper introduces RyanSpeech, a new speech corpus for research on\nautomated text-to-speech (TTS) systems. Publicly available TTS corpora are\noften noisy, recorded with multiple speakers, or lack quality male speech data.\nIn order to meet the need for a high quality, publicly available male speech\ncorpus within the field of speech recognition, we have designed and created\nRyanSpeech which contains textual materials from real-world conversational\nsettings. These materials contain over 10 hours of a professional male voice\nactor's speech recorded at 44.1 kHz. This corpus's design and pipeline make\nRyanSpeech ideal for developing TTS systems in real-world applications. To\nprovide a baseline for future research, protocols, and benchmarks, we trained 4\nstate-of-the-art speech models and a vocoder on RyanSpeech. The results show\n3.36 in mean opinion scores (MOS) in our best model. We have made both the\ncorpus and trained models for public use.",
    "descriptor": "",
    "authors": [
      "Rohola Zandie",
      "Mohammad H. Mahoor",
      "Julia Madsen",
      "Eshrat S. Emamian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08468"
  },
  {
    "id": "arXiv:2106.08470",
    "title": "Introducing Type Properties",
    "abstract": "In type theory, we can express many practical ideas by attributing some\nadditional data to expressions we operate on during compilation. For instance,\nsome substructural type theories augment variables' typing judgments with the\ninformation of their usage. That is, they allow one to explicitly state how\nmany times - 0, 1, or many - a variable can be used. This solves the problem of\nresource usage control and allows us to treat variables as resources.\nWhat's more, it often happens that this attributed information is interpreted\n(used) during the same compilation and erased before we run a program. A case\nin the point is that in the same substructural type theories, their type\ncheckers use these 0, 1, or many, to ensure that all variables are used as many\ntimes as these attributions say them to be.\nYet, there wasn't any programming language concept whose concern would be to\nallow a programmer to express these attributions in the language itself. That\nis, to let the programmer express which data the one wants to attribute to what\nexpressions and, most importantly, the meaning of the attributed data in their\nprogram.\nAs it turned out, the presence of such a concept allows us to express many\npractical ideas in the language itself. For instance, with appropriate means\nfor assigning the meaning of these attributions, this concept would allow one\nto express linear types as functionality in a separate program module, without\nthe need to refine the whole type system to add them.\nIn this paper, we present such a concept - we propose type properties. It\nallows a programmer to express these attributions while fulfilling the\nrequirement of being fully on the static level. That is, it allows one to\nexpress how to interpret these attributions during compilation and erases them\nbefore a program is passed to the runtime.",
    "descriptor": "",
    "authors": [
      "Aziz Akhmedkhodjaev"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.08470"
  },
  {
    "id": "arXiv:2106.08473",
    "title": "Age of Information for Small Buffer Systems",
    "abstract": "Consider a message processing system whose objective is to produce the most\ncurrent information as measured by the quantity known as \"age of information\".\nWe have argued in previous papers that if we are allowed to design the message\nprocessing policy ad libitum, we should keep a small buffer and operate\naccording to a LIFO policy. In this small note we provide an analysis for the\nAoI of the P_m system which uses a buffer of size m, a single server, operating\nwithout service preemption and in a LIFO manner for stored messages. Analytical\nexpressions for the mean (or even distribution) of the AoI in steady-state are\npossible but with the aid computer algebra. We explain the the analysis for\nm=3.",
    "descriptor": "",
    "authors": [
      "George Kesidis",
      "Takis Konstantopoulos",
      "Michael Zazanis"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.08473"
  },
  {
    "id": "arXiv:2106.08475",
    "title": "Circa: Stochastic ReLUs for Private Deep Learning",
    "abstract": "The simultaneous rise of machine learning as a service and concerns over user\nprivacy have increasingly motivated the need for private inference (PI). While\nrecent work demonstrates PI is possible using cryptographic primitives, the\ncomputational overheads render it impractical. The community is largely\nunprepared to address these overheads, as the source of slowdown in PI stems\nfrom the ReLU operator whereas optimizations for plaintext inference focus on\noptimizing FLOPs. In this paper we re-think the ReLU computation and propose\noptimizations for PI tailored to properties of neural networks. Specifically,\nwe reformulate ReLU as an approximate sign test and introduce a novel\ntruncation method for the sign test that significantly reduces the cost per\nReLU. These optimizations result in a specific type of stochastic ReLU. The key\nobservation is that the stochastic fault behavior is well suited for the\nfault-tolerant properties of neural network inference. Thus, we provide\nsignificant savings without impacting accuracy. We collectively call the\noptimizations Circa and demonstrate improvements of up to 4.7x storage and 3x\nruntime over baseline implementations; we further show that Circa can be used\non top of recent PI optimizations to obtain 1.8x additional speedup.",
    "descriptor": "",
    "authors": [
      "Zahra Ghodsi",
      "Nandan Kumar Jha",
      "Brandon Reagen",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08475"
  },
  {
    "id": "arXiv:2106.08477",
    "title": "Fundamental Limits of Reinforcement Learning in Environment with  Endogeneous and Exogeneous Uncertainty",
    "abstract": "Online reinforcement learning (RL) has been widely applied in information\nprocessing scenarios, which usually exhibit much uncertainty due to the\nintrinsic randomness of channels and service demands. In this paper, we\nconsider an un-discounted RL in general Markov decision processes (MDPs) with\nboth endogeneous and exogeneous uncertainty, where both the rewards and state\ntransition probability are unknown to the RL agent and evolve with the time as\nlong as their respective variations do not exceed certain dynamic budget (i.e.,\nupper bound). We first develop a variation-aware Bernstein-based upper\nconfidence reinforcement learning (VB-UCRL), which we allow to restart\naccording to a schedule dependent on the variations. We successfully overcome\nthe challenges due to the exogeneous uncertainty and establish a regret bound\nof saving at most $\\sqrt{S}$ or $S^{\\frac{1}{6}}T^{\\frac{1}{12}}$ compared with\nthe latest results in the literature, where $S$ denotes the state size of the\nMDP and $T$ indicates the iteration index of learning steps.",
    "descriptor": "\nComments: Manuscript has been submitted to an IEEE journal. Copyright may be transferred without further notice\n",
    "authors": [
      "Rongpeng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08477"
  },
  {
    "id": "arXiv:2106.08479",
    "title": "Tonal Frequencies, Consonance, Dissonance: A Math-Bio Intersection",
    "abstract": "To date, calculating the frequencies of musical notes requires one to know\nthe frequency of some reference note. In this study, first-order ordinary\ndifferential equations are used to arrive at a mathematical model to determine\ntonal frequencies using their respective note indices. In the next part of the\nstudy, an analysis that is based on the fundamental musical frequencies is\nconducted to theoretically and neurobiologically explain the consonance and\ndissonance caused by the different musical notes in the chromatic scale which\nis based on the fact that systematic patterns of sound invoke pleasure. The\nreason behind the richness of harmony and the sonic interference and degree of\nconsonance in musical chords are discussed. Since a human mind analyses\neverything relatively, anything other than the most consonant notes sounds\ndissonant. In conclusion, the study explains clearly why musical notes and in\ntoto, music sounds the way it does.",
    "descriptor": "\nComments: 9 pages, 1 figure, 1 table\n",
    "authors": [
      "Steve Mathew"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.08479"
  },
  {
    "id": "arXiv:2106.08482",
    "title": "Minimizing Communication while Maximizing Performance in Multi-Agent  Reinforcement Learning",
    "abstract": "Inter-agent communication can significantly increase performance in\nmulti-agent tasks that require co-ordination to achieve a shared goal. Prior\nwork has shown that it is possible to learn inter-agent communication protocols\nusing multi-agent reinforcement learning and message-passing network\narchitectures. However, these models use an unconstrained broadcast\ncommunication model, in which an agent communicates with all other agents at\nevery step, even when the task does not require it. In real-world applications,\nwhere communication may be limited by system constraints like bandwidth, power\nand network capacity, one might need to reduce the number of messages that are\nsent. In this work, we explore a simple method of minimizing communication\nwhile maximizing performance in multi-task learning: simultaneously optimizing\na task-specific objective and a communication penalty. We show that the\nobjectives can be optimized using Reinforce and the Gumbel-Softmax\nreparameterization. We introduce two techniques to stabilize training: 50%\ntraining and message forwarding. Training with the communication penalty on\nonly 50% of the episodes prevents our models from turning off their outgoing\nmessages. Second, repeating messages received previously helps models retain\ninformation, and further improves performance. With these techniques, we show\nthat we can reduce communication by 75% with no loss of performance.",
    "descriptor": "",
    "authors": [
      "Varun Kumar Vijay",
      "Hassam Sheikh",
      "Somdeb Majumdar",
      "Mariano Phielipp"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08482"
  },
  {
    "id": "arXiv:2106.08484",
    "title": "Generative Conversational Networks",
    "abstract": "Inspired by recent work in meta-learning and generative teaching networks, we\npropose a framework called Generative Conversational Networks, in which\nconversational agents learn to generate their own labelled training data (given\nsome seed data) and then train themselves from that data to perform a given\ntask. We use reinforcement learning to optimize the data generation process\nwhere the reward signal is the agent's performance on the task. The task can be\nany language-related task, from intent detection to full task-oriented\nconversations. In this work, we show that our approach is able to generalise\nfrom seed data and performs well in limited data and limited computation\nsettings, with significant gains for intent detection and slot tagging across\nmultiple datasets: ATIS, TOD, SNIPS, and Restaurants8k. We show an average\nimprovement of 35% in intent detection and 21% in slot tagging over a baseline\nmodel trained from the seed data. We also conduct an analysis of the novelty of\nthe generated data and provide generated examples for intent detection, slot\ntagging, and non-goal oriented conversations.",
    "descriptor": "\nComments: SIGDial 2021\n",
    "authors": [
      "Alexandros Papangelis",
      "Karthik Gopalakrishnan",
      "Aishwarya Padmakumar",
      "Seokhwan Kim",
      "Gokhan Tur",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.08484"
  },
  {
    "id": "arXiv:2106.08486",
    "title": "Achieving Domain Robustness in Stereo Matching Networks by Removing  Shortcut Learning",
    "abstract": "Learning-based stereo matching and depth estimation networks currently excel\non public benchmarks with impressive results. However, state-of-the-art\nnetworks often fail to generalize from synthetic imagery to more challenging\nreal data domains. This paper is an attempt to uncover hidden secrets of\nachieving domain robustness and in particular, discovering the important\ningredients of generalization success of stereo matching networks by analyzing\nthe effect of synthetic image learning on real data performance. We provide\nevidence that demonstrates that learning of features in the synthetic domain by\na stereo matching network is heavily influenced by two \"shortcuts\" presented in\nthe synthetic data: (1) identical local statistics (RGB colour features)\nbetween matching pixels in the synthetic stereo images and (2) lack of realism\nin synthetic textures on 3D objects simulated in game engines. We will show\nthat by removing such shortcuts, we can achieve domain robustness in the\nstate-of-the-art stereo matching frameworks and produce a remarkable\nperformance on multiple realistic datasets, despite the fact that the networks\nwere trained on synthetic data, only. Our experimental results point to the\nfact that eliminating shortcuts from the synthetic data is key to achieve\ndomain-invariant generalization between synthetic and real data domains.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "WeiQin Chuah",
      "Ruwan Tennakoon",
      "Alireza Bab-Hadiashar",
      "David Suter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08486"
  },
  {
    "id": "arXiv:2106.08488",
    "title": "Predictive Modeling of Hospital Readmission: Challenges and Solutions",
    "abstract": "Hospital readmission prediction is a study to learn models from historical\nmedical data to predict probability of a patient returning to hospital in a\ncertain period, 30 or 90 days, after the discharge. The motivation is to help\nhealth providers deliver better treatment and post-discharge strategies, lower\nthe hospital readmission rate, and eventually reduce the medical costs. Due to\ninherent complexity of diseases and healthcare ecosystems, modeling hospital\nreadmission is facing many challenges. By now, a variety of methods have been\ndeveloped, but existing literature fails to deliver a complete picture to\nanswer some fundamental questions, such as what are the main challenges and\nsolutions in modeling hospital readmission; what are typical features/models\nused for readmission prediction; how to achieve meaningful and transparent\npredictions for decision making; and what are possible conflicts when deploying\npredictive approaches for real-world usages. In this paper, we systematically\nreview computational models for hospital readmission prediction, and propose a\ntaxonomy of challenges featuring four main categories: (1) data variety and\ncomplexity; (2) data imbalance, locality and privacy; (3) model\ninterpretability; and (4) model implementation. The review summarizes methods\nin each category, and highlights technical solutions proposed to address the\nchallenges. In addition, a review of datasets and resources available for\nhospital readmission modeling also provides firsthand materials to support\nresearchers and practitioners to design new approaches for effective and\nefficient hospital readmission prediction.",
    "descriptor": "",
    "authors": [
      "Shuwen Wang",
      "Xingquan Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08488"
  },
  {
    "id": "arXiv:2106.08492",
    "title": "Developing a Fidelity Evaluation Approach for Interpretable Machine  Learning",
    "abstract": "Although modern machine learning and deep learning methods allow for complex\nand in-depth data analytics, the predictive models generated by these methods\nare often highly complex, and lack transparency. Explainable AI (XAI) methods\nare used to improve the interpretability of these complex models, and in doing\nso improve transparency. However, the inherent fitness of these explainable\nmethods can be hard to evaluate. In particular, methods to evaluate the\nfidelity of the explanation to the underlying black box require further\ndevelopment, especially for tabular data. In this paper, we (a) propose a three\nphase approach to developing an evaluation method; (b) adapt an existing\nevaluation method primarily for image and text data to evaluate models trained\non tabular data; and (c) evaluate two popular explainable methods using this\nevaluation method. Our evaluations suggest that the internal mechanism of the\nunderlying predictive model, the internal mechanism of the explainable method\nused and model and data complexity all affect explanation fidelity. Given that\nexplanation fidelity is so sensitive to context and tools and data used, we\ncould not clearly identify any specific explainable method as being superior to\nanother.",
    "descriptor": "",
    "authors": [
      "Mythreyi Velmurugan",
      "Chun Ouyang",
      "Catarina Moreira",
      "Renuka Sindhgatta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08492"
  },
  {
    "id": "arXiv:2106.08493",
    "title": "Multi-scale Neural ODEs for 3D Medical Image Registration",
    "abstract": "Image registration plays an important role in medical image analysis.\nConventional optimization based methods provide an accurate estimation due to\nthe iterative process at the cost of expensive computation. Deep learning\nmethods such as learn-to-map are much faster but either iterative or\ncoarse-to-fine approach is required to improve accuracy for handling large\nmotions. In this work, we proposed to learn a registration optimizer via a\nmulti-scale neural ODE model. The inference consists of iterative gradient\nupdates similar to a conventional gradient descent optimizer but in a much\nfaster way, because the neural ODE learns from the training data to adapt the\ngradient efficiently at each iteration. Furthermore, we proposed to learn a\nmodal-independent similarity metric to address image appearance variations\nacross different image contrasts. We performed evaluations through extensive\nexperiments in the context of multi-contrast 3D MR images from both public and\nprivate data sources and demonstrate the superior performance of our proposed\nmethods.",
    "descriptor": "",
    "authors": [
      "Junshen Xu",
      "Eric Z. Chen",
      "Xiao Chen",
      "Terrence Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08493"
  },
  {
    "id": "arXiv:2106.08495",
    "title": "Improving Entity Linking through Semantic Reinforced Entity Embeddings",
    "abstract": "Entity embeddings, which represent different aspects of each entity with a\nsingle vector like word embeddings, are a key component of neural entity\nlinking models. Existing entity embeddings are learned from canonical Wikipedia\narticles and local contexts surrounding target entities. Such entity embeddings\nare effective, but too distinctive for linking models to learn contextual\ncommonality. We propose a simple yet effective method, FGS2EE, to inject\nfine-grained semantic information into entity embeddings to reduce the\ndistinctiveness and facilitate the learning of contextual commonality. FGS2EE\nfirst uses the embeddings of semantic type words to generate semantic\nembeddings, and then combines them with existing entity embeddings through\nlinear aggregation. Extensive experiments show the effectiveness of such\nembeddings. Based on our entity embeddings, we achieved new sate-of-the-art\nperformance on entity linking.",
    "descriptor": "\nComments: 6 pages, 3 figures, ACL 2020\n",
    "authors": [
      "Feng Hou",
      "Ruili Wang",
      "Jun He",
      "Yi Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08495"
  },
  {
    "id": "arXiv:2106.08497",
    "title": "GKNet: grasp keypoint network for grasp candidates detection",
    "abstract": "Contemporary grasp detection approaches employ deep learning to achieve\nrobustness to sensor and object model uncertainty. The two dominant approaches\ndesign either grasp-quality scoring or anchor-based grasp recognition networks.\nThis paper presents a different approach to grasp detection by treating it as\nkeypoint detection. The deep network detects each grasp candidate as a pair of\nkeypoints, convertible to the grasp representation g = {x, y, w, {\\theta}}^T,\nrather than a triplet or quartet of corner points. Decreasing the detection\ndifficulty by grouping keypoints into pairs boosts performance. To further\npromote dependencies between keypoints, the general non-local module is\nincorporated into the proposed learning framework. A final filtering strategy\nbased on discrete and continuous orientation prediction removes false\ncorrespondences and further improves grasp detection performance. GKNet, the\napproach presented here, achieves the best balance of accuracy and speed on the\nCornell and the abridged Jacquard dataset (96.9% and 98.39% at 41.67 and 23.26\nfps). Follow-up experiments on a manipulator evaluate GKNet using 4 types of\ngrasping experiments reflecting different nuisance sources: static grasping,\ndynamic grasping, grasping at varied camera angles, and bin picking. GKNet\noutperforms reference baselines in static and dynamic grasping experiments\nwhile showing robustness to varied camera viewpoints and bin picking\nexperiments. The results confirm the hypothesis that grasp keypoints are an\neffective output representation for deep grasp networks that provide robustness\nto expected nuisance factors.",
    "descriptor": "\nComments: 24 pages, 12 figures, 13 tables\n",
    "authors": [
      "Ruinian Xu",
      "Fu-Jen Chu",
      "Patricio A. Vela"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08497"
  },
  {
    "id": "arXiv:2106.08499",
    "title": "ICDAR 2021 Competition on Components Segmentation Task of Document  Photos",
    "abstract": "This paper describes the short-term competition on Components Segmentation\nTask of Document Photos that was prepared in the context of the 16th\nInternational Conference on Document Analysis and Recognition (ICDAR 2021).\nThis competition aims to bring together researchers working on the filed of\nidentification document image processing and provides them a suitable benchmark\nto compare their techniques on the component segmentation task of document\nimages. Three challenge tasks were proposed entailing different segmentation\nassignments to be performed on a provided dataset. The collected data are from\nseveral types of Brazilian ID documents, whose personal information was\nconveniently replaced. There were 16 participants whose results obtained for\nsome or all the three tasks show different rates for the adopted metrics, like\nDice Similarity Coefficient ranging from 0.06 to 0.99. Different Deep Learning\nmodels were applied by the entrants with diverse strategies to achieve the best\nresults in each of the tasks. Obtained results show that the current applied\nmethods for solving one of the proposed tasks (document boundary detection) are\nalready well stablished. However, for the other two challenge tasks (text zone\nand handwritten sign detection) research and development of more robust\napproaches are still required to achieve acceptable results.",
    "descriptor": "\nComments: This paper was accepted for ICDAR 2021 Conference\n",
    "authors": [
      "Celso A. M. Lopes Junior",
      "Ricardo B. das Neves Junior",
      "Byron L. D. Bezerra",
      "Alejandro H. Toselli",
      "Donato Impedovo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08499"
  },
  {
    "id": "arXiv:2106.08500",
    "title": "Optimizing Graph Transformer Networks with Graph-based Techniques",
    "abstract": "Graph transformer networks (GTN) are a variant of graph convolutional\nnetworks (GCN) that are targeted to heterogeneous graphs in which nodes and\nedges have associated type information that can be exploited to improve\ninference accuracy. GTNs learn important metapaths in the graph, create\nweighted edges for these metapaths, and use the resulting graph in a GCN.\nCurrently, the only available implementation of GTNs uses dense matrix\nmultiplication to find metapaths. Unfortunately, the space overhead of this\napproach can be large, so in practice it is used only for small graphs. In\naddition, the matrix-based implementation is not fine-grained enough to use\nrandom-walk based methods to optimize metapath finding. In this paper, we\npresent a graph-based formulation and implementation of the GTN metapath\nfinding problem. This graph-based formulation has two advantages over the\nmatrix-based approach. First, it is more space efficient than the original GTN\nimplementation and more compute-efficient for metapath sizes of practical\ninterest. Second, it permits us to implement a sampling method that reduces the\nnumber of metapaths that must be enumerated, allowing the implementation to be\nused for larger graphs and larger metapath sizes. Experimental results show\nthat our implementation is $6.5\\times$ faster than the original GTN\nimplementation on average for a metapath length of 4, and our sampling\nimplementation is $155\\times$ faster on average than this implementation\nwithout compromising on the accuracy of the GTN.",
    "descriptor": "",
    "authors": [
      "Loc Hoang",
      "Udit Agarwal",
      "Gurbinder Gill",
      "Roshan Dathathri",
      "Abhik Seal",
      "Brian Martin",
      "Keshav Pingali"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08500"
  },
  {
    "id": "arXiv:2106.08503",
    "title": "Understanding and Evaluating Racial Biases in Image Captioning",
    "abstract": "Image captioning is an important task for benchmarking visual reasoning and\nfor enabling accessibility for people with vision impairments. However, as in\nmany machine learning settings, social biases can influence image captioning in\nundesirable ways. In this work, we study bias propagation pathways within image\ncaptioning, focusing specifically on the COCO dataset. Prior work has analyzed\ngender bias in captions using automatically-derived gender labels; here we\nexamine racial and intersectional biases using manual annotations. Our first\ncontribution is in annotating the perceived gender and skin color of 28,315 of\nthe depicted people after obtaining IRB approval. Using these annotations, we\ncompare racial biases present in both manual and automatically-generated image\ncaptions. We demonstrate differences in caption performance, sentiment, and\nword choice between images of lighter versus darker-skinned people. Further, we\nfind the magnitude of these differences to be greater in modern captioning\nsystems compared to older ones, thus leading to concerns that without proper\nconsideration and mitigation these differences will only become increasingly\nprevalent. Code and data is available at\nhttps://princetonvisualai.github.io/imagecaptioning-bias .",
    "descriptor": "",
    "authors": [
      "Dora Zhao",
      "Angelina Wang",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08503"
  },
  {
    "id": "arXiv:2106.08504",
    "title": "A study on CFL conditions for the DG solution of conservation laws on  adaptive moving meshes",
    "abstract": "The selection of time step plays a crucial role in improving stability and\nefficiency in the Discontinuous Galerkin (DG) solution of hyperbolic\nconservation laws on adaptive moving meshes that typically employs explicit\nstepping. A commonly used selection of time step has been based on CFL\nconditions established for fixed and uniform meshes. This work provides a\nmathematical justification for those time step selection strategies used in\npractical adaptive DG computations. A stability analysis is presented for a\nmoving mesh DG method for linear scalar conservation laws. Based on the\nanalysis, a new selection strategy of the time step is proposed, which takes\ninto consideration the coupling of the $\\alpha$-function (that is related to\nthe eigenvalues of the Jacobian matrix of the flux and the mesh movement\nvelocity) and the heights of the mesh elements. The analysis also suggests\nseveral stable combinations of the choices of the $\\alpha$-function in the\nnumerical scheme and in the time step selection. Numerical results obtained\nwith a moving mesh DG method for Burgers' and Euler equations are presented.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Min Zhang",
      "Weizhang Huang",
      "Jianxian Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08504"
  },
  {
    "id": "arXiv:2106.08505",
    "title": "Dynamically Grown Generative Adversarial Networks",
    "abstract": "Recent work introduced progressive network growing as a promising way to ease\nthe training for large GANs, but the model design and architecture-growing\nstrategy still remain under-explored and needs manual design for different\nimage data. In this paper, we propose a method to dynamically grow a GAN during\ntraining, optimizing the network architecture and its parameters together with\nautomation. The method embeds architecture search techniques as an interleaving\nstep with gradient-based training to periodically seek the optimal\narchitecture-growing strategy for the generator and discriminator. It enjoys\nthe benefits of both eased training because of progressive growing and improved\nperformance because of broader architecture design space. Experimental results\ndemonstrate new state-of-the-art of image generation. Observations in the\nsearch procedure also provide constructive insights into the GAN model design\nsuch as generator-discriminator balance and convolutional layer choices.",
    "descriptor": "\nComments: Accepted to AAAI 2021\n",
    "authors": [
      "Lanlan Liu",
      "Yuting Zhang",
      "Jia Deng",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08505"
  },
  {
    "id": "arXiv:2106.08507",
    "title": "WSRGlow: A Glow-based Waveform Generative Model for Audio  Super-Resolution",
    "abstract": "Audio super-resolution is the task of constructing a high-resolution (HR)\naudio from a low-resolution (LR) audio by adding the missing band. Previous\nmethods based on convolutional neural networks and mean squared error training\nobjective have relatively low performance, while adversarial generative models\nare difficult to train and tune. Recently, normalizing flow has attracted a lot\nof attention for its high performance, simple training and fast inference. In\nthis paper, we propose WSRGlow, a Glow-based waveform generative model to\nperform audio super-resolution. Specifically, 1) we integrate WaveNet and Glow\nto directly maximize the exact likelihood of the target HR audio conditioned on\nLR information; and 2) to exploit the audio information from low-resolution\naudio, we propose an LR audio encoder and an STFT encoder, which encode the LR\ninformation from the time domain and frequency domain respectively. The\nexperimental results show that the proposed model is easier to train and\noutperforms the previous works in terms of both objective and perceptual\nquality. WSRGlow is also the first model to produce 48kHz waveforms from 12kHz\nLR audio.",
    "descriptor": "\nComments: Accepted by INTERSPEECH 2021\n",
    "authors": [
      "Kexun Zhang",
      "Yi Ren",
      "Changliang Xu",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.08507"
  },
  {
    "id": "arXiv:2106.08512",
    "title": "Revisit Visual Representation in Analytics Taxonomy: A Compression  Perspective",
    "abstract": "Visual analytics have played an increasingly critical role in the Internet of\nThings, where massive visual signals have to be compressed and fed into\nmachines. But facing such big data and constrained bandwidth capacity, existing\nimage/video compression methods lead to very low-quality representations, while\nexisting feature compression techniques fail to support diversified visual\nanalytics applications/tasks with low-bit-rate representations. In this paper,\nwe raise and study the novel problem of supporting multiple machine vision\nanalytics tasks with the compressed visual representation, namely, the\ninformation compression problem in analytics taxonomy. By utilizing the\nintrinsic transferability among different tasks, our framework successfully\nconstructs compact and expressive representations at low bit-rates to support a\ndiversified set of machine vision tasks, including both high-level\nsemantic-related tasks and mid-level geometry analytic tasks. In order to\nimpose compactness in the representations, we propose a codebook-based\nhyperprior, which helps map the representation into a low-dimensional manifold.\nAs it well fits the signal structure of the deep visual feature, it facilitates\nmore accurate entropy estimation, and results in higher compression efficiency.\nWith the proposed framework and the codebook-based hyperprior, we further\ninvestigate the relationship of different task features owning different levels\nof abstraction granularity. Experimental results demonstrate that with the\nproposed scheme, a set of diversified tasks can be supported at a significantly\nlower bit-rate, compared with existing compression schemes.",
    "descriptor": "",
    "authors": [
      "Yueyu Hu",
      "Wenhan Yang",
      "Haofeng Huang",
      "Jiaying Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08512"
  },
  {
    "id": "arXiv:2106.08513",
    "title": "Watching Too Much Television is Good: Self-Supervised Audio-Visual  Representation Learning from Movies and TV Shows",
    "abstract": "The abundance and ease of utilizing sound, along with the fact that auditory\nclues reveal so much about what happens in the scene, make the audio-visual\nspace a perfectly intuitive choice for self-supervised representation learning.\nHowever, the current literature suggests that training on \\textit{uncurated}\ndata yields considerably poorer representations compared to the\n\\textit{curated} alternatives collected in supervised manner, and the gap only\nnarrows when the volume of data significantly increases. Furthermore, the\nquality of learned representations is known to be heavily influenced by the\nsize and taxonomy of the curated datasets used for self-supervised training.\nThis begs the question of whether we are celebrating too early on catching up\nwith supervised learning when our self-supervised efforts still rely almost\nexclusively on curated data. In this paper, we study the efficacy of learning\nfrom Movies and TV Shows as forms of uncurated data for audio-visual\nself-supervised learning. We demonstrate that a simple model based on\ncontrastive learning, trained on a collection of movies and TV shows, not only\ndramatically outperforms more complex methods which are trained on orders of\nmagnitude larger uncurated datasets, but also performs very competitively with\nthe state-of-the-art that learns from large-scale curated data. We identify\nthat audiovisual patterns like the appearance of the main character or\nprominent scenes and mise-en-sc\\`ene which frequently occur through the whole\nduration of a movie, lead to an overabundance of easy negative instances in the\ncontrastive learning formulation. Capitalizing on such observation, we propose\na hierarchical sampling policy, which despite its simplicity, effectively\nimproves the performance, particularly when learning from TV shows which\nnaturally face less semantic diversity.",
    "descriptor": "",
    "authors": [
      "Mahdi M. Kalayeh",
      "Nagendra Kamath",
      "Lingyi Liu",
      "Ashok Chandrashekar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08513"
  },
  {
    "id": "arXiv:2106.08523",
    "title": "ECKPN: Explicit Class Knowledge Propagation Network for Transductive  Few-shot Learning",
    "abstract": "Recently, the transductive graph-based methods have achieved great success in\nthe few-shot classification task. However, most existing methods ignore\nexploring the class-level knowledge that can be easily learned by humans from\njust a handful of samples. In this paper, we propose an Explicit Class\nKnowledge Propagation Network (ECKPN), which is composed of the comparison,\nsqueeze and calibration modules, to address this problem. Specifically, we\nfirst employ the comparison module to explore the pairwise sample relations to\nlearn rich sample representations in the instance-level graph. Then, we squeeze\nthe instance-level graph to generate the class-level graph, which can help\nobtain the class-level visual knowledge and facilitate modeling the relations\nof different classes. Next, the calibration module is adopted to characterize\nthe relations of the classes explicitly to obtain the more discriminative\nclass-level knowledge representations. Finally, we combine the class-level\nknowledge with the instance-level sample representations to guide the inference\nof the query samples. We conduct extensive experiments on four few-shot\nclassification benchmarks, and the experimental results show that the proposed\nECKPN significantly outperforms the state-of-the-art methods.",
    "descriptor": "\nComments: Accepted by CVPR2021\n",
    "authors": [
      "Chaofan Chen",
      "Xiaoshan Yang",
      "Changsheng Xu",
      "Xuhui Huang",
      "Zhe Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08523"
  },
  {
    "id": "arXiv:2106.08527",
    "title": "FAIR: Fairness-Aware Information Retrieval Evaluation",
    "abstract": "With the emerging needs of creating fairness-aware solutions for search and\nrecommendation systems, a daunting challenge exists of evaluating such\nsolutions. While many of the traditional information retrieval (IR) metrics can\ncapture the relevance, diversity and novelty for the utility with respect to\nusers, they are not suitable for inferring whether the presented results are\nfair from the perspective of responsible information exposure. On the other\nhand, various fairness metrics have been proposed but they do not account for\nthe user utility or do not measure it adequately. To address this problem, we\npropose a new metric called Fairness-Aware IR (FAIR). By unifying standard IR\nmetrics and fairness measures into an integrated metric, this metric offers a\nnew perspective for evaluating fairness-aware ranking results. Based on this\nmetric, we developed an effective ranking algorithm that jointly optimized user\nutility and fairness. The experimental results showed that our FAIR metric\ncould highlight results with good user utility and fair information exposure.\nWe showed how FAIR related to existing metrics and demonstrated the\neffectiveness of our FAIR-based algorithm. We believe our work opens up a new\ndirection of pursuing a computationally feasible metric for evaluating and\nimplementing the fairness-aware IR systems.",
    "descriptor": "\nComments: submitted to The Journal of the Association for Information Science and Technology\n",
    "authors": [
      "Ruoyuan Gao",
      "Yingqiang Ge",
      "Chirag Shah"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.08527"
  },
  {
    "id": "arXiv:2106.08531",
    "title": "Latent Representation in Human-Robot Interaction with Explicit  Consideration of Periodic Dynamics",
    "abstract": "This paper presents a new data-driven framework for analyzing periodic\nphysical human-robot interaction (pHRI) in latent state space. To elaborate\nhuman understanding and/or robot control during pHRI, the model representing\npHRI is critical. Recent developments of deep learning technologies would\nenable us to learn such a model from a dataset collected from the actual pHRI.\nOur framework is developed based on variational recurrent neural network\n(VRNN), which can inherently handle time-series data like one pHRI generates.\nThis paper modifies VRNN in order to include the latent dynamics from robot to\nhuman explicitly. In addition, to analyze periodic motions like walking, we\nintegrate a new recurrent network based on reservoir computing (RC), which has\nrandom and fixed connections between numerous neurons, with VRNN. By augmenting\nRC into complex domain, periodic behavior can be represented as the phase\nrotation in complex domain without decaying the amplitude. For verification of\nthe proposed framework, a rope-rotation/swinging experiment was analyzed. The\nproposed framework, trained on the dataset collected from the experiment,\nachieved the latent state space where the differences in periodic motions can\nbe distinguished. Such a well-distinguished space yielded the best prediction\naccuracy of the human observations and the robot actions. The attached video\ncan be seen in youtube: https://youtu.be/umn0MVcIpsY",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Taisuke Kobayashi",
      "Shingo Murata",
      "Tetsunari Inamura"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.08531"
  },
  {
    "id": "arXiv:2106.08532",
    "title": "SEEN: Sharpening Explanations for Graph Neural Networks using  Explanations from Neighborhoods",
    "abstract": "Explaining the foundations for predictions obtained from graph neural\nnetworks (GNNs) is critical for credible use of GNN models for real-world\nproblems. Owing to the rapid growth of GNN applications, recent progress in\nexplaining predictions from GNNs, such as sensitivity analysis, perturbation\nmethods, and attribution methods, showed great opportunities and possibilities\nfor explaining GNN predictions. In this study, we propose a method to improve\nthe explanation quality of node classification tasks that can be applied in a\npost hoc manner through aggregation of auxiliary explanations from important\nneighboring nodes, named SEEN. Applying SEEN does not require modification of a\ngraph and can be used with diverse explainability techniques due to its\nindependent mechanism. Experiments on matching motif-participating nodes from a\ngiven graph show great improvement in explanation accuracy of up to 12.71% and\ndemonstrate the correlation between the auxiliary explanations and the enhanced\nexplanation accuracy through leveraging their contributions. SEEN provides a\nsimple but effective method to enhance the explanation quality of GNN model\noutputs, and this method is applicable in combination with most explainability\ntechniques.",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Hyeoncheol Cho",
      "Youngrock Oh",
      "Eunjoo Jeon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08532"
  },
  {
    "id": "arXiv:2106.08535",
    "title": "Application of a High Order Accurate Meshless Method to Solution of Heat  Conduction in Complex Geometries",
    "abstract": "In recent years, a variety of meshless methods have been developed to solve\npartial differential equations in complex domains. Meshless methods discretize\nthe partial differential equations over scattered points instead of grids.\nRadial basis functions (RBFs) have been popularly used as high accuracy\ninterpolants of function values at scattered locations. In this paper, we apply\nthe polyharmonic splines (PHS) as the RBF together with appended polynomial and\nsolve the heat conduction equation in several geometries using a collocation\nprocedure. We demonstrate the expected exponential convergence of the numerical\nsolution as the degree of the appended polynomial is increased. The method\nholds promise to solve several different governing equations in thermal\nsciences.",
    "descriptor": "",
    "authors": [
      "Naman Bartwal",
      "Shantanu Shahane",
      "Somnath Roy",
      "Surya Pratap Vanka"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.08535"
  },
  {
    "id": "arXiv:2106.08537",
    "title": "Clustering Mixture Models in Almost-Linear Time via List-Decodable Mean  Estimation",
    "abstract": "We study the problem of list-decodable mean estimation, where an adversary\ncan corrupt a majority of the dataset. Specifically, we are given a set $T$ of\n$n$ points in $\\mathbb{R}^d$ and a parameter $0< \\alpha <\\frac 1 2$ such that\nan $\\alpha$-fraction of the points in $T$ are i.i.d. samples from a\nwell-behaved distribution $\\mathcal{D}$ and the remaining $(1-\\alpha)$-fraction\nof the points are arbitrary. The goal is to output a small list of vectors at\nleast one of which is close to the mean of $\\mathcal{D}$. As our main\ncontribution, we develop new algorithms for list-decodable mean estimation,\nachieving nearly-optimal statistical guarantees, with running time $n^{1 +\no(1)} d$. All prior algorithms for this problem had additional polynomial\nfactors in $\\frac 1 \\alpha$. As a corollary, we obtain the first almost-linear\ntime algorithms for clustering mixtures of $k$ separated well-behaved\ndistributions, nearly-matching the statistical guarantees of spectral methods.\nPrior clustering algorithms inherently relied on an application of $k$-PCA,\nthereby incurring runtimes of $\\Omega(n d k)$. This marks the first runtime\nimprovement for this basic statistical problem in nearly two decades.\nThe starting point of our approach is a novel and simpler near-linear time\nrobust mean estimation algorithm in the $\\alpha \\to 1$ regime, based on a\none-shot matrix multiplicative weights-inspired potential decrease. We\ncrucially leverage this new algorithmic framework in the context of the\niterative multi-filtering technique of Diakonikolas et. al. '18, '20, providing\na method to simultaneously cluster and downsample points using one-dimensional\nprojections --- thus, bypassing the $k$-PCA subroutines required by prior\nalgorithms.",
    "descriptor": "\nComments: 64 pages, 1 figure\n",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane",
      "Daniel Kongsgaard",
      "Jerry Li",
      "Kevin Tian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08537"
  },
  {
    "id": "arXiv:2106.08541",
    "title": "Distilling Self-Knowledge From Contrastive Links to Classify Graph Nodes  Without Passing Messages",
    "abstract": "Nowadays, Graph Neural Networks (GNNs) following the Message Passing paradigm\nbecome the dominant way to learn on graphic data. Models in this paradigm have\nto spend extra space to look up adjacent nodes with adjacency matrices and\nextra time to aggregate multiple messages from adjacent nodes. To address this\nissue, we develop a method called LinkDist that distils self-knowledge from\nconnected node pairs into a Multi-Layer Perceptron (MLP) without the need to\naggregate messages. Experiment with 8 real-world datasets shows the MLP derived\nfrom LinkDist can predict the label of a node without knowing its adjacencies\nbut achieve comparable accuracy against GNNs in the contexts of semi- and\nfull-supervised node classification. Moreover, LinkDist benefits from its\nNon-Message Passing paradigm that we can also distil self-knowledge from\narbitrarily sampled node pairs in a contrastive way to further boost the\nperformance of LinkDist.",
    "descriptor": "\nComments: 9 pages, 2 figures, 4 tables\n",
    "authors": [
      "Yi Luo",
      "Aiguo Chen",
      "Ke Yan",
      "Ling Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08541"
  },
  {
    "id": "arXiv:2106.08543",
    "title": "Tackling the Challenges in Scene Graph Generation with Local-to-Global  Interactions",
    "abstract": "In this work, we seek new insights into the underlying challenges of the\nScene Graph Generation (SGG) task. Quantitative and qualitative analysis of the\nVisual Genome dataset implies -- 1) Ambiguity: even if inter-object\nrelationship contains the same object (or predicate), they may not be visually\nor semantically similar, 2) Asymmetry: despite the nature of the relationship\nthat embodied the direction, it was not well addressed in previous studies, and\n3) Higher-order contexts: leveraging the identities of certain graph elements\ncan help to generate accurate scene graphs. Motivated by the analysis, we\ndesign a novel SGG framework, Local-to-Global Interaction Networks (LOGIN).\nLocally, interactions extract the essence between three instances - subject,\nobject, and background - while baking direction awareness into the network by\nconstraining the input order. Globally, interactions encode the contexts\nbetween every graph components -- nodes and edges. Also we introduce Attract &\nRepel loss which finely adjusts predicate embeddings. Our framework enables\npredicting the scene graph in a local-to-global manner by design, leveraging\nthe possible complementariness. To quantify how much LOGIN is aware of\nrelational direction, we propose a new diagnostic task called Bidirectional\nRelationship Classification (BRC). We see that LOGIN can successfully\ndistinguish relational direction than existing methods (in BRC task) while\nshowing state-of-the-art results on the Visual Genome benchmark (in SGG task).",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sangmin Woo",
      "Junhyug Noh",
      "Kangil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08543"
  },
  {
    "id": "arXiv:2106.08544",
    "title": "Non-PSD Matrix Sketching with Applications to Regression and  Optimization",
    "abstract": "A variety of dimensionality reduction techniques have been applied for\ncomputations involving large matrices. The underlying matrix is randomly\ncompressed into a smaller one, while approximately retaining many of its\noriginal properties. As a result, much of the expensive computation can be\nperformed on the small matrix. The sketching of positive semidefinite (PSD)\nmatrices is well understood, but there are many applications where the related\nmatrices are not PSD, including Hessian matrices in non-convex optimization and\ncovariance matrices in regression applications involving complex numbers. In\nthis paper, we present novel dimensionality reduction methods for non-PSD\nmatrices, as well as their ``square-roots\", which involve matrices with complex\nentries. We show how these techniques can be used for multiple downstream\ntasks. In particular, we show how to use the proposed matrix sketching\ntechniques for both convex and non-convex optimization, $\\ell_p$-regression for\nevery $1 \\leq p \\leq \\infty$, and vector-matrix-vector queries.",
    "descriptor": "",
    "authors": [
      "Zhili Feng",
      "Fred Roosta",
      "David P. Woodruff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08544"
  },
  {
    "id": "arXiv:2106.08545",
    "title": "A Survey on Fault-tolerance in Distributed Optimization and Machine  Learning",
    "abstract": "The robustness of distributed optimization is an emerging field of study,\nmotivated by various applications of distributed optimization including\ndistributed machine learning, distributed sensing, and swarm robotics. With the\nrapid expansion of the scale of distributed systems, resilient distributed\nalgorithms for optimization are needed, in order to mitigate system failures,\ncommunication issues, or even malicious attacks. This survey investigates the\ncurrent state of fault-tolerance research in distributed optimization, and aims\nto provide an overview of the existing studies on both fault-tolerant\ndistributed optimization theories and applicable algorithms.",
    "descriptor": "\nComments: 35 pages, 1 figure, and 2 tables\n",
    "authors": [
      "Shuo Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.08545"
  },
  {
    "id": "arXiv:2106.08548",
    "title": "Mining Interpretable Spatio-temporal Logic Properties for Spatially  Distributed Systems",
    "abstract": "The Internet-of-Things, complex sensor networks, multi-agent cyber-physical\nsystems are all examples of spatially distributed systems that continuously\nevolve in time. Such systems generate huge amounts of spatio-temporal data, and\nsystem designers are often interested in analyzing and discovering structure\nwithin the data. There has been considerable interest in learning causal and\nlogical properties of temporal data using logics such as Signal Temporal Logic\n(STL); however, there is limited work on discovering such relations on\nspatio-temporal data. We propose the first set of algorithms for unsupervised\nlearning for spatio-temporal data. Our method does automatic feature extraction\nfrom the spatio-temporal data by projecting it onto the parameter space of a\nparametric spatio-temporal reach and escape logic (PSTREL). We propose an\nagglomerative hierarchical clustering technique that guarantees that each\ncluster satisfies a distinct STREL formula. We show that our method generates\nSTREL formulas of bounded description complexity using a novel decision-tree\napproach which generalizes previous unsupervised learning techniques for Signal\nTemporal Logic. We demonstrate the effectiveness of our approach on case\nstudies from diverse domains such as urban transportation, epidemiology, green\ninfrastructure, and air quality monitoring.",
    "descriptor": "",
    "authors": [
      "Sara Mohammadinejad",
      "Jyotirmy V. Deshmukh",
      "Laura Nenzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08548"
  },
  {
    "id": "arXiv:2106.08551",
    "title": "Fast Quantum Property Prediction via Deeper 2D and 3D Graph Networks",
    "abstract": "Molecular property prediction is gaining increasing attention due to its\ndiverse applications. One task of particular interests and importance is to\npredict quantum chemical properties without 3D equilibrium structures. This is\npractically favorable since obtaining 3D equilibrium structures requires\nextremely expensive calculations. In this work, we design a deep graph neural\nnetwork to predict quantum properties by directly learning from 2D molecular\ngraphs. In addition, we propose a 3D graph neural network to learn from\nlow-cost conformer sets, which can be obtained with open-source tools using an\naffordable budget. We employ our methods to participate in the 2021 KDD Cup on\nOGB Large-Scale Challenge (OGB-LSC), which aims to predict the HOMO-LUMO energy\ngap of molecules. Final evaluation results reveal that we are one of the\nwinners with a mean absolute error of 0.1235 on the holdout test set. Our\nimplementation is available as part of the MoleculeX package\n(https://github.com/divelab/MoleculeX).",
    "descriptor": "\nComments: One of the winners of 2021 KDD Cup on OGB Large-Scale Challenge\n",
    "authors": [
      "Meng Liu",
      "Cong Fu",
      "Xuan Zhang",
      "Limei Wang",
      "Yaochen Xie",
      "Hao Yuan",
      "Youzhi Luo",
      "Zhao Xu",
      "Shenglong Xu",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08551"
  },
  {
    "id": "arXiv:2106.08554",
    "title": "iBatch: Saving Ethereum Fees via Secure and Cost-Effective Batching of  Smart-Contract Invocations",
    "abstract": "This paper presents iBatch, a middleware system running on top of an\noperational Ethereum network to enable secure batching of smart-contract\ninvocations against an untrusted relay server off-chain. iBatch does so at a\nlow overhead by validating the server's batched invocations in smart contracts\nwithout additional states. The iBatch mechanism supports a variety of policies,\nranging from conservative to aggressive batching, and can be configured\nadaptively to the current workloads. iBatch automatically rewrites smart\ncontracts to integrate with legacy applications and support large-scale\ndeployment.\nWe built an evaluation platform for fast and cost-accurate transaction\nreplaying and constructed real transaction benchmarks on popular Ethereum\napplications. With a functional prototype of iBatch, we conduct extensive cost\nevaluations, which shows iBatch saves $14.6\\%\\sim{}59.1\\%$ Gas cost per\ninvocation with a moderate 2-minute delay and $19.06\\%\\sim{}31.52\\%$ Ether cost\nper invocation with a delay of $0.26\\sim{}1.66$ blocks.",
    "descriptor": "\nComments: ESEC/FSE 2021\n",
    "authors": [
      "Yibo Wang",
      "Qi Zhang",
      "Kai Li",
      "Yuzhe Tang",
      "Xiapu Luo",
      "Ting Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08554"
  },
  {
    "id": "arXiv:2106.08556",
    "title": "Coreference-Aware Dialogue Summarization",
    "abstract": "Summarizing conversations via neural approaches has been gaining research\ntraction lately, yet it is still challenging to obtain practical solutions.\nExamples of such challenges include unstructured information exchange in\ndialogues, informal interactions between speakers, and dynamic role changes of\nspeakers as the dialogue evolves. Many of such challenges result in complex\ncoreference links. Therefore, in this work, we investigate different approaches\nto explicitly incorporate coreference information in neural abstractive\ndialogue summarization models to tackle the aforementioned challenges.\nExperimental results show that the proposed approaches achieve state-of-the-art\nperformance, implying it is useful to utilize coreference information in\ndialogue summarization. Evaluation results on factual correctness suggest such\ncoreference-aware models are better at tracing the information flow among\ninterlocutors and associating accurate status/actions with the corresponding\ninterlocutors and person mentions.",
    "descriptor": "\nComments: accepted for presentation at SIGDIAL-2021\n",
    "authors": [
      "Zhengyuan Liu",
      "Ke Shi",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08556"
  },
  {
    "id": "arXiv:2106.08557",
    "title": "Unsupervised-learning-based method for chest MRI-CT transformation using  structure constrained unsupervised generative attention networks",
    "abstract": "The integrated positron emission tomography/magnetic resonance imaging\n(PET/MRI) scanner facilitates the simultaneous acquisition of metabolic\ninformation via PET and morphological information with high soft-tissue\ncontrast using MRI. Although PET/MRI facilitates the capture of high-accuracy\nfusion images, its major drawback can be attributed to the difficulty\nencountered when performing attenuation correction, which is necessary for\nquantitative PET evaluation. The combined PET/MRI scanning requires the\ngeneration of attenuation-correction maps from MRI owing to no direct\nrelationship between the gamma-ray attenuation information and MRIs. While\nMRI-based bone-tissue segmentation can be readily performed for the head and\npelvis regions, the realization of accurate bone segmentation via chest CT\ngeneration remains a challenging task. This can be attributed to the\nrespiratory and cardiac motions occurring in the chest as well as its\nanatomically complicated structure and relatively thin bone cortex. This paper\npresents a means to minimise the anatomical structural changes without human\nannotation by adding structural constraints using a modality-independent\nneighbourhood descriptor (MIND) to a generative adversarial network (GAN) that\ncan transform unpaired images. The results obtained in this study revealed the\nproposed U-GAT-IT + MIND approach to outperform all other competing approaches.\nThe findings of this study hint towards possibility of synthesising clinically\nacceptable CT images from chest MRI without human annotation, thereby\nminimising the changes in the anatomical structure.",
    "descriptor": "\nComments: 27 pages, 12 figures\n",
    "authors": [
      "Hidetoshi Matsuo",
      "Mizuho Nishio",
      "Munenobu Nogami",
      "Feibi Zeng",
      "Takako Kurimoto",
      "Sandeep Kaushik",
      "Florian Wiesinger",
      "Atsushi K Kono",
      "Takamichi Murakami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08557"
  },
  {
    "id": "arXiv:2106.08564",
    "title": "Adaptive Visibility Graph Neural Network and It's Application in  Modulation Classification",
    "abstract": "Our digital world is full of time series and graphs which capture the various\naspects of many complex systems. Traditionally, there are respective methods in\nprocessing these two different types of data, e.g., Recurrent Neural Network\n(RNN) and Graph Neural Network (GNN), while in recent years, time series could\nbe mapped to graphs by using the techniques such as Visibility Graph (VG), so\nthat researchers can use graph algorithms to mine the knowledge in time series.\nSuch mapping methods establish a bridge between time series and graphs, and\nhave high potential to facilitate the analysis of various real-world time\nseries. However, the VG method and its variants are just based on fixed rules\nand thus lack of flexibility, largely limiting their application in reality. In\nthis paper, we propose an Adaptive Visibility Graph (AVG) algorithm that can\nadaptively map time series into graphs, based on which we further establish an\nend-to-end classification framework AVGNet, by utilizing GNN model DiffPool as\nthe classifier. We then adopt AVGNet for radio signal modulation classification\nwhich is an important task in the field of wireless communication. The\nsimulations validate that AVGNet outperforms a series of advanced deep learning\nmethods, achieving the state-of-the-art performance in this task.",
    "descriptor": "",
    "authors": [
      "Qi Xuan",
      "Kunfeng Qiu",
      "Jinchao Zhou",
      "Zhuangzhi Chen",
      "Dongwei Xu",
      "Shilian Zheng",
      "Xiaoniu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08564"
  },
  {
    "id": "arXiv:2106.08565",
    "title": "Detection of Morphed Face Images Using Discriminative Wavelet Sub-bands",
    "abstract": "This work investigates the well-known problem of morphing attacks, which has\ndrawn considerable attention in the biometrics community. Morphed images have\nexposed face recognition systems' susceptibility to false acceptance, resulting\nin dire consequences, especially for national security applications. To detect\nmorphing attacks, we propose a method which is based on a discriminative 2D\nDiscrete Wavelet Transform (2D-DWT). A discriminative wavelet sub-band can\nhighlight inconsistencies between a real and a morphed image. We observe that\nthere is a salient discrepancy between the entropy of a given sub-band in a\nbona fide image, and the same sub-band's entropy in a morphed sample.\nConsidering this dissimilarity between these two entropy values, we find the\nKullback-Leibler divergence between the two distributions, namely the entropy\nof the bona fide and the corresponding morphed images. The most discriminative\nwavelet sub-bands are those with the highest corresponding KL-divergence\nvalues. Accordingly, 22 sub-bands are selected as the most discriminative ones\nin terms of morph detection. We show that a Deep Neural Network (DNN) trained\non the 22 discriminative sub-bands can detect morphed samples precisely. Most\nimportantly, the effectiveness of our algorithm is validated through\nexperiments on three datasets: VISAPP17, LMA, and MorGAN. We also performed an\nablation study on the sub-band selection.",
    "descriptor": "",
    "authors": [
      "Poorya Aghdaie",
      "Baaria Chaudhary",
      "Sobhan Soleymani",
      "Jeremy Dawson",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08565"
  },
  {
    "id": "arXiv:2106.08567",
    "title": "Optimal Accounting of Differential Privacy via Characteristic Function",
    "abstract": "Characterizing the privacy degradation over compositions, i.e., privacy\naccounting, is a fundamental topic in differential privacy (DP) with many\napplications to differentially private machine learning and federated learning.\nWe propose a unification of recent advances (Renyi DP, privacy profiles,\n$f$-DP and the PLD formalism) via the characteristic function ($\\phi$-function)\nof a certain ``worst-case'' privacy loss random variable.\nWe show that our approach allows natural adaptive composition like Renyi DP,\nprovides exactly tight privacy accounting like PLD, and can be (often\nlosslessly) converted to privacy profile and $f$-DP, thus providing\n$(\\epsilon,\\delta)$-DP guarantees and interpretable tradeoff functions.\nAlgorithmically, we propose an analytical Fourier accountant that represents\nthe complex logarithm of $\\phi$-functions symbolically and uses Gaussian\nquadrature for numerical computation. On several popular DP mechanisms and\ntheir subsampled counterparts, we demonstrate the flexibility and tightness of\nour approach in theory and experiments.",
    "descriptor": "",
    "authors": [
      "Yuqing Zhu",
      "Jinshuo Dong",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08567"
  },
  {
    "id": "arXiv:2106.08568",
    "title": "Towards Automated Attack Simulations of BPMN-based Processes",
    "abstract": "Process digitization and integration is an increasing need for enterprises,\nwhile cyber-attacks denote a growing threat. Using the Business Process\nManagement Notation (BPMN) is common to handle the digital and integration\nfocus within and across organizations. In other parts of the same companies,\nthreat modeling and attack graphs are used for analyzing the security posture\nand resilience.\nIn this paper, we propose a novel approach to use attack graph simulations on\nprocesses represented in BPMN. Our contributions are the identification of\nBPMN's attack surface, a mapping of BPMN elements to concepts in a Meta Attack\nLanguage (MAL)-based Domain-Specific Language (DSL), called coreLang, and a\nprototype to demonstrate our approach in a case study using a real-world\ninvoice integration process. The study shows that non-invasively enriching BPMN\ninstances with cybersecurity analysis through attack graphs is possible without\nmuch human expert input. The resulting insights into potential vulnerabilities\ncould be beneficial for the process modelers.",
    "descriptor": "\nComments: Submitted for review to EDOC 2021\n",
    "authors": [
      "Simon Hacks",
      "Robert Lagerstr\u00f6m",
      "Daniel Ritter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08568"
  },
  {
    "id": "arXiv:2106.08569",
    "title": "TSO: Curriculum Generation using continuous optimization",
    "abstract": "The training of deep learning models poses vast challenges of including\nparameter tuning and ordering of training data. Significant research has been\ndone in Curriculum learning for optimizing the sequence of training data.\nRecent works have focused on using complex reinforcement learning techniques to\nfind the optimal data ordering strategy to maximize learning for a given\nnetwork. In this paper, we present a simple and efficient technique based on\ncontinuous optimization. We call this new approach Training Sequence\nOptimization (TSO). There are three critical components in our proposed\napproach: (a) An encoder network maps/embeds training sequence into continuous\nspace. (b) A predictor network uses the continuous representation of a strategy\nas input and predicts the accuracy for fixed network architecture. (c) A\ndecoder further maps a continuous representation of a strategy to the ordered\ntraining dataset. The performance predictor and encoder enable us to perform\ngradient-based optimization in the continuous space to find the embedding of\noptimal training data ordering with potentially better accuracy. Experiments\nshow that we can gain 2AP with our generated optimal curriculum strategy over\nthe random strategy using the CIFAR-100 dataset and have better boosts than the\nstate of the art CL algorithms. We do an ablation study varying the\narchitecture, dataset and sample sizes showcasing our approach's robustness.",
    "descriptor": "\nComments: 10 pages, along with all experiment details\n",
    "authors": [
      "Dipankar Sarkar",
      "Mukur Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08569"
  },
  {
    "id": "arXiv:2106.08570",
    "title": "Anomaly Detection in Video Sequences: A Benchmark and Computational  Model",
    "abstract": "Anomaly detection has attracted considerable search attention. However,\nexisting anomaly detection databases encounter two major problems. Firstly,\nthey are limited in scale. Secondly, training sets contain only video-level\nlabels indicating the existence of an abnormal event during the full video\nwhile lacking annotations of precise time durations. To tackle these problems,\nwe contribute a new Large-scale Anomaly Detection (LAD) database as the\nbenchmark for anomaly detection in video sequences, which is featured in two\naspects. 1) It contains 2000 video sequences including normal and abnormal\nvideo clips with 14 anomaly categories including crash, fire, violence, etc.\nwith large scene varieties, making it the largest anomaly analysis database to\ndate. 2) It provides the annotation data, including video-level labels\n(abnormal/normal video, anomaly type) and frame-level labels (abnormal/normal\nvideo frame) to facilitate anomaly detection. Leveraging the above benefits\nfrom the LAD database, we further formulate anomaly detection as a\nfully-supervised learning problem and propose a multi-task deep neural network\nto solve it. We first obtain the local spatiotemporal contextual feature by\nusing an Inflated 3D convolutional (I3D) network. Then we construct a recurrent\nconvolutional neural network fed the local spatiotemporal contextual feature to\nextract the spatiotemporal contextual feature. With the global spatiotemporal\ncontextual feature, the anomaly type and score can be computed simultaneously\nby a multi-task neural network. Experimental results show that the proposed\nmethod outperforms the state-of-the-art anomaly detection methods on our\ndatabase and other public databases of anomaly detection. Codes are available\nat https://github.com/wanboyang/anomaly_detection_LAD2000.",
    "descriptor": "\nComments: Publication in IET Image Processing\n",
    "authors": [
      "Boyang Wan",
      "Wenhui Jiang",
      "Yuming Fang",
      "Zhiyuan Luo",
      "Guanqun Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08570"
  },
  {
    "id": "arXiv:2106.08571",
    "title": "Discrete Auto-regressive Variational Attention Models for Text Modeling",
    "abstract": "Variational autoencoders (VAEs) have been widely applied for text modeling.\nIn practice, however, they are troubled by two challenges: information\nunderrepresentation and posterior collapse. The former arises as only the last\nhidden state of LSTM encoder is transformed into the latent space, which is\ngenerally insufficient to summarize the data. The latter is a long-standing\nproblem during the training of VAEs as the optimization is trapped to a\ndisastrous local optimum. In this paper, we propose Discrete Auto-regressive\nVariational Attention Model (DAVAM) to address the challenges. Specifically, we\nintroduce an auto-regressive variational attention approach to enrich the\nlatent space by effectively capturing the semantic dependency from the input.\nWe further design discrete latent space for the variational attention and\nmathematically show that our model is free from posterior collapse. Extensive\nexperiments on language modeling tasks demonstrate the superiority of DAVAM\nagainst several VAE counterparts.",
    "descriptor": "\nComments: IJCNN 2021\n",
    "authors": [
      "Xianghong Fang",
      "Haoli Bai",
      "Jian Li",
      "Zenglin Xu",
      "Michael Lyu",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08571"
  },
  {
    "id": "arXiv:2106.08573",
    "title": "Learning Implicit Glyph Shape Representation",
    "abstract": "In this paper, we present a novel implicit glyph shape representation, which\nmodels glyphs as shape primitives enclosed by quadratic curves, and naturally\nenables generating glyph images at arbitrary high resolutions. Experiments on\nfont reconstruction and interpolation tasks verified that this structured\nimplicit representation is suitable for describing both structure and style\nfeatures of glyphs. Furthermore, based on the proposed representation, we\ndesign a simple yet effective disentangled network for the challenging one-shot\nfont style transfer problem, and achieve the best results comparing to\nstate-of-the-art alternatives in both quantitative and qualitative comparisons.\nBenefit from this representation, our generated glyphs have the potential to be\nconverted to vector fonts through post-processing, reducing the gap between\nrasterized images and vector graphics. We hope this work can provide a powerful\ntool for 2D shape analysis and synthesis, and inspire further exploitation in\nimplicit representations for 2D shape modeling.",
    "descriptor": "",
    "authors": [
      "Ying-Tian Liu",
      "Yuan-Chen Guo",
      "Yi-Xiao Li",
      "Chen Wang",
      "Song-Hai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08573"
  },
  {
    "id": "arXiv:2106.08574",
    "title": "Unsupervised Lexical Acquisition of Relative Spatial Concepts Using  Spoken User Utterances",
    "abstract": "This paper proposes methods for unsupervised lexical acquisition for relative\nspatial concepts using spoken user utterances. A robot with a flexible spoken\ndialog system must be able to acquire linguistic representation and its meaning\nspecific to an environment through interactions with humans as children do.\nSpecifically, relative spatial concepts (e.g., front and right) are widely used\nin our daily lives, however, it is not obvious which object is a reference\nobject when a robot learns relative spatial concepts. Therefore, we propose\nmethods by which a robot without prior knowledge of words can learn relative\nspatial concepts. The methods are formulated using a probabilistic model to\nestimate the proper reference objects and distributions representing concepts\nsimultaneously. The experimental results show that relative spatial concepts\nand a phoneme sequence representing each concept can be learned under the\ncondition that the robot does not know which located object is the reference\nobject. Additionally, we show that two processes in the proposed method improve\nthe estimation accuracy of the concepts: generating candidate word sequences by\nclass n-gram and selecting word sequences using location information.\nFurthermore, we show that clues to reference objects improve accuracy even\nthough the number of candidate reference objects increases.",
    "descriptor": "\nComments: 27 pages, 12 figures, submitted to Advanced Robotics\n",
    "authors": [
      "Rikunari Sagara",
      "Ryo Taguchi",
      "Akira Taniguchi",
      "Tadahiro Taniguchi",
      "Koosuke Hattori",
      "Masahiro Hoguro",
      "Taizo Umezaki"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.08574"
  },
  {
    "id": "arXiv:2106.08575",
    "title": "Compound Frechet Inception Distance for Quality Assessment of GAN  Created Images",
    "abstract": "Generative adversarial networks or GANs are a type of generative modeling\nframework. GANs involve a pair of neural networks engaged in a competition in\niteratively creating fake data, indistinguishable from the real data. One\nnotable application of GANs is developing fake human faces, also known as \"deep\nfakes,\" due to the deep learning algorithms at the core of the GAN framework.\nMeasuring the quality of the generated images is inherently subjective but\nattempts to objectify quality using standardized metrics have been made. One\nexample of objective metrics is the Frechet Inception Distance (FID), which\nmeasures the difference between distributions of feature vectors for two\nseparate datasets of images. There are situations that images with low\nperceptual qualities are not assigned appropriate FID scores. We propose to\nimprove the robustness of the evaluation process by integrating lower-level\nfeatures to cover a wider array of visual defects. Our proposed method\nintegrates three levels of feature abstractions to evaluate the quality of\ngenerated images. Experimental evaluations show better performance of the\nproposed method for distorted images.",
    "descriptor": "\nComments: 11 pages, 10 figures\n",
    "authors": [
      "Eric J. Nunn",
      "Pejman Khadivi",
      "Shadrokh Samavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08575"
  },
  {
    "id": "arXiv:2106.08582",
    "title": "Alternated Training with Synthetic and Authentic Data for Neural Machine  Translation",
    "abstract": "While synthetic bilingual corpora have demonstrated their effectiveness in\nlow-resource neural machine translation (NMT), adding more synthetic data often\ndeteriorates translation performance. In this work, we propose alternated\ntraining with synthetic and authentic data for NMT. The basic idea is to\nalternate synthetic and authentic corpora iteratively during training. Compared\nwith previous work, we introduce authentic data as guidance to prevent the\ntraining of NMT models from being disturbed by noisy synthetic data.\nExperiments on Chinese-English and German-English translation tasks show that\nour approach improves the performance over several strong baselines. We\nvisualize the BLEU landscape to further investigate the role of authentic and\nsynthetic data during alternated training. From the visualization, we find that\nauthentic data helps to direct the NMT model parameters towards points with\nhigher BLEU scores and leads to consistent translation performance improvement.",
    "descriptor": "\nComments: ACL 2021, Short Findings\n",
    "authors": [
      "Rui Jiao",
      "Zonghan Yang",
      "Maosong Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08582"
  },
  {
    "id": "arXiv:2106.08590",
    "title": "Domain Consistency Regularization for Unsupervised Multi-source Domain  Adaptive Classification",
    "abstract": "Deep learning-based multi-source unsupervised domain adaptation (MUDA) has\nbeen actively studied in recent years. Compared with single-source unsupervised\ndomain adaptation (SUDA), domain shift in MUDA exists not only between the\nsource and target domains but also among multiple source domains. Most existing\nMUDA algorithms focus on extracting domain-invariant representations among all\ndomains whereas the task-specific decision boundaries among classes are largely\nneglected. In this paper, we propose an end-to-end trainable network that\nexploits domain Consistency Regularization for unsupervised Multi-source domain\nAdaptive classification (CRMA). CRMA aligns not only the distributions of each\npair of source and target domains but also that of all domains. For each pair\nof source and target domains, we employ an intra-domain consistency to\nregularize a pair of domain-specific classifiers to achieve intra-domain\nalignment. In addition, we design an inter-domain consistency that targets\njoint inter-domain alignment among all domains. To address different\nsimilarities between multiple source domains and the target domain, we design\nan authorization strategy that assigns different authorities to domain-specific\nclassifiers adaptively for optimal pseudo label prediction and self-training.\nExtensive experiments show that CRMA tackles unsupervised domain adaptation\neffectively under a multi-source setup and achieves superior adaptation\nconsistently across multiple MUDA datasets.",
    "descriptor": "",
    "authors": [
      "Zhipeng Luo",
      "Xiaobing Zhang",
      "Shijian Lu",
      "Shuai Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08590"
  },
  {
    "id": "arXiv:2106.08591",
    "title": "Quality-Quantity Trade-offs in Tests for Management of COVID-19-like  Epidemics",
    "abstract": "There are multiple testing methods to ascertain an infection in an individual\nand they vary in their performances, cost and delay. Unfortunately, better\nperforming tests are sometimes costlier and time consuming and can only be done\nfor a small fraction of the population. On the other hand, greater number of\nindividuals can be tested using a cheaper, rapid test, but may only provide\nless reliable results. In this work, we studied the interplay between cost and\ndelay of the tests as well the additional advantages offered by partial and\ncomplete lockdowns. To understand the influence of different test strategies,\nwe implemented them on realistic random social networks with a COVID-19-like\nepidemic in progression. Specifically, we compared the performance of two tests\nmimicking the characteristics of popular tests implemented for COVID-19\ndetection. We present procedures and intuitive understanding to ascertain the\noptimum combination of the tests to minimize the peak infection as well as\ntotal quarantine days when the number of tests is constrained by a fixed total\nbudget.",
    "descriptor": "\nComments: The contents are prepared as a report with figures and graphs at their appropriate positions. All the figures are captioned properly and are explained in the main text. The references are all in IEEE format. Section from pages 21 to 31 forms the appendix\n",
    "authors": [
      "Harish Sasikumar",
      "Manoj Varma"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2106.08591"
  },
  {
    "id": "arXiv:2106.08592",
    "title": "STAR-RIS Enabled Heterogeneous Networks: Ubiquitous NOMA Communication  and Pervasive Federated Learning",
    "abstract": "This paper integrates non-orthogonal multiple access (NOMA) and over-the-air\nfederated learning (AirFL) into a unified framework using a simultaneous\ntransmitting and reflecting reconfigurable intelligent surface (STAR-RIS). The\nSTAR-RIS plays an important role in adjusting the decoding order of hybrid\nusers for efficient interference mitigation and omni-directional coverage\nextension. To capture the impact of non-ideal wireless channels on AirFL, a\nclosed-form expression for the optimality gap (a.k.a. convergence upper bound)\nbetween the actual loss and the optimal loss is derived. This analysis reveals\nthat the learning performance is significantly affected by active and passive\nbeamforming schemes as well as wireless noise. Furthermore, when the learning\nrate diminishes as the training proceeds, the optimality gap is explicitly\ncharacterized to converge with a linear rate. To accelerate convergence while\nsatisfying QoS requirements, a mixed-integer non-linear programming (MINLP)\nproblem is formulated by jointly designing the transmit power at users and the\nconfiguration mode of STAR-RIS. Next, a trust region-based successive convex\napproximation method and a penalty-based semidefinite relaxation approach is\nproposed to handle the decoupled non-convex subproblems iteratively. An\nalternating optimization algorithm is then developed to find a suboptimal\nsolution for the original MINLP problem. Extensive simulation results show that\ni) the proposed framework can efficiently support NOMA and AirFL users via\nconcurrent uplink communications, ii) our algorithms can achieve a faster\nconvergence rate on the IID and non-IID settings as compared to baselines, and\niii) both the spectrum efficiency and learning performance can be significantly\nimproved with the aid of the well-tuned STAR-RIS.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Wanli Ni",
      "Yuanwei Liu",
      "Yonina C. Eldar",
      "Zhaohui Yang",
      "Hui Tian"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.08592"
  },
  {
    "id": "arXiv:2106.08596",
    "title": "Temporal Convolution Networks with Positional Encoding for Evoked  Expression Estimation",
    "abstract": "This paper presents an approach for Evoked Expressions from Videos (EEV)\nchallenge, which aims to predict evoked facial expressions from video. We take\nadvantage of pre-trained models on large-scale datasets in computer vision and\naudio signals to extract the deep representation of timestamps in the video. A\ntemporal convolution network, rather than an RNN like architecture, is used to\nexplore temporal relationships due to its advantage in memory consumption and\nparallelism. Furthermore, to address the missing annotations of some\ntimestamps, positional encoding is employed to ensure continuity of input data\nwhen discarding these timestamps during training. We achieved state-of-the-art\nresults on the EEV challenge with a Pearson correlation coefficient of 0.05477,\nthe first ranked performance in the EEV 2021 challenge.",
    "descriptor": "\nComments: Oral presentation at AUVi Workshop - CVPR 2021 (this https URL). Source code available at this https URL\n",
    "authors": [
      "VanThong Huynh",
      "Guee-Sang Lee",
      "Hyung-Jeong Yang",
      "Soo-Huyng Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.08596"
  },
  {
    "id": "arXiv:2106.08598",
    "title": "Ada-BKB: Scalable Gaussian Process Optimization on Continuous Domain by  Adaptive Discretization",
    "abstract": "Gaussian process optimization is a successful class of algorithms (e.g.\nGP-UCB) to optimize a black-box function through sequential evaluations.\nHowever, when the domain of the function is continuous, Gaussian process\noptimization has to either rely on a fixed discretization of the space, or\nsolve a non-convex optimization subproblem at each evaluation. The first\napproach can negatively affect performance, while the second one puts a heavy\ncomputational burden on the algorithm. A third option, that only recently has\nbeen theoretically studied, is to adaptively discretize the function domain.\nEven though this approach avoids the extra non-convex optimization costs, the\noverall computational complexity is still prohibitive. An algorithm such as\nGP-UCB has a runtime of $O(T^4)$, where $T$ is the number of iterations. In\nthis paper, we introduce Ada-BKB (Adaptive Budgeted Kernelized Bandit), a\nno-regret Gaussian process optimization algorithm for functions on continuous\ndomains, that provably runs in $O(T^2 d_\\text{eff}^2)$, where $d_\\text{eff}$ is\nthe effective dimension of the explored space, and which is typically much\nsmaller than $T$. We corroborate our findings with experiments on synthetic\nnon-convex functions and on the real-world problem of hyper-parameter\noptimization.",
    "descriptor": "",
    "authors": [
      "Marco Rando",
      "Luigi Carratino",
      "Silvia Villa",
      "Lorenzo Rosasco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08598"
  },
  {
    "id": "arXiv:2106.08599",
    "title": "PatchNet: Unsupervised Object Discovery based on Patch Embedding",
    "abstract": "We demonstrate that frequently appearing objects can be discovered by\ntraining randomly sampled patches from a small number of images (100 to 200) by\nself-supervision. Key to this approach is the pattern space, a latent space of\npatterns that represents all possible sub-images of the given image data. The\ndistance structure in the pattern space captures the co-occurrence of patterns\ndue to the frequent objects. The pattern space embedding is learned by\nminimizing the contrastive loss between randomly generated adjacent patches. To\nprevent the embedding from learning the background, we modulate the contrastive\nloss by color-based object saliency and background dissimilarity. The learned\ndistance structure serves as object memory, and the frequent objects are simply\ndiscovered by clustering the pattern vectors from the random patches sampled\nfor inference. Our image representation based on image patches naturally\nhandles the position and scale invariance property that is crucial to\nmulti-object discovery. The method has been proven surprisingly effective, and\nsuccessfully applied to finding multiple human faces and bodies from natural\nimages.",
    "descriptor": "",
    "authors": [
      "Hankyu Moon",
      "Heng Hao",
      "Sima Didari",
      "Jae Oh Woo",
      "Patrick Bangert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08599"
  },
  {
    "id": "arXiv:2106.08600",
    "title": "Federated Semi-supervised Medical Image Classification via Inter-client  Relation Matching",
    "abstract": "Federated learning (FL) has emerged with increasing popularity to collaborate\ndistributed medical institutions for training deep networks. However, despite\nexisting FL algorithms only allow the supervised training setting, most\nhospitals in realistic usually cannot afford the intricate data labeling due to\nabsence of budget or expertise. This paper studies a practical yet challenging\nFL problem, named \\textit{Federated Semi-supervised Learning} (FSSL), which\naims to learn a federated model by jointly utilizing the data from both labeled\nand unlabeled clients (i.e., hospitals). We present a novel approach for this\nproblem, which improves over traditional consistency regularization mechanism\nwith a new inter-client relation matching scheme. The proposed learning scheme\nexplicitly connects the learning across labeled and unlabeled clients by\naligning their extracted disease relationships, thereby mitigating the\ndeficiency of task knowledge at unlabeled clients and promoting discriminative\ninformation from unlabeled samples. We validate our method on two large-scale\nmedical image classification datasets. The effectiveness of our method has been\ndemonstrated with the clear improvements over state-of-the-arts as well as the\nthorough ablation analysis on both tasks\\footnote{Code will be made available\nat \\url{https://github.com/liuquande/FedIRM}}.",
    "descriptor": "\nComments: Accepted to MICCAI 2021\n",
    "authors": [
      "Quande Liu",
      "Hongzheng Yang",
      "Qi Dou",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08600"
  },
  {
    "id": "arXiv:2106.08601",
    "title": "Self-supervised GANs with Label Augmentation",
    "abstract": "Recently, transformation-based self-supervised learning has been applied to\ngenerative adversarial networks (GANs) to mitigate the catastrophic forgetting\nproblem of discriminator by learning stable representations. However, the\nseparate self-supervised tasks in existing self-supervised GANs cause an\ninconsistent goal with generative modeling due to the learning of the generator\nfrom their generator distribution-agnostic classifiers. To address this issue,\nwe propose a novel self-supervised GANs framework with label augmentation,\ni.e., augmenting the GAN labels (real or fake) with the self-supervised\npseudo-labels. In particular, the discriminator and the self-supervised\nclassifier are unified to learn a single task that predicts the augmented label\nsuch that the discriminator/classifier is aware of the generator distribution,\nwhile the generator tries to confuse the discriminator/classifier by optimizing\nthe discrepancy between the transformed real and generated distributions.\nTheoretically, we prove that the generator, at the equilibrium point, converges\nto replicate the data distribution. Empirically, we demonstrate that the\nproposed method significantly outperforms competitive baselines on both\ngenerative modeling and representation learning across benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Liang Hou",
      "Huawei Shen",
      "Qi Cao",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08601"
  },
  {
    "id": "arXiv:2106.08605",
    "title": "Disentangling Semantic-to-visual Confusion for Zero-shot Learning",
    "abstract": "Using generative models to synthesize visual features from semantic\ndistribution is one of the most popular solutions to ZSL image classification\nin recent years. The triplet loss (TL) is popularly used to generate realistic\nvisual distributions from semantics by automatically searching discriminative\nrepresentations. However, the traditional TL cannot search reliable unseen\ndisentangled representations due to the unavailability of unseen classes in\nZSL. To alleviate this drawback, we propose in this work a multi-modal triplet\nloss (MMTL) which utilizes multimodal information to search a disentangled\nrepresentation space. As such, all classes can interplay which can benefit\nlearning disentangled class representations in the searched space. Furthermore,\nwe develop a novel model called Disentangling Class Representation Generative\nAdversarial Network (DCR-GAN) focusing on exploiting the disentangled\nrepresentations in training, feature synthesis, and final recognition stages.\nBenefiting from the disentangled representations, DCR-GAN could fit a more\nrealistic distribution over both seen and unseen features. Extensive\nexperiments show that our proposed model can lead to superior performance to\nthe state-of-the-arts on four benchmark datasets. Our code is available at\nhttps://github.com/FouriYe/DCRGAN-TMM.",
    "descriptor": "\nComments: Accepted by IEEE TRANSACTIONS ON MULTIMEDIA (TMM) in 2021\n",
    "authors": [
      "Zihan Ye",
      "Fuyuan Hu",
      "Fan Lyu",
      "Linyan Li",
      "Kaizhu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08605"
  },
  {
    "id": "arXiv:2106.08607",
    "title": "OESense: Employing Occlusion Effect for In-ear Human Sensing",
    "abstract": "Smart earbuds are recognized as a new wearable platform for personal-scale\nhuman motion sensing. However, due to the interference from head movement or\nbackground noise, commonly-used modalities (e.g. accelerometer and microphone)\nfail to reliably detect both intense and light motions. To obviate this, we\npropose OESense, an acoustic-based in-ear system for general human motion\nsensing. The core idea behind OESense is the joint use of the occlusion effect\n(i.e., the enhancement of low-frequency components of bone-conducted sounds in\nan occluded ear canal) and inward-facing microphone, which naturally boosts the\nsensing signal and suppresses external interference. We prototype OESense as an\nearbud and evaluate its performance on three representative applications, i.e.,\nstep counting, activity recognition, and hand-to-face gesture interaction. With\ndata collected from 31 subjects, we show that OESense achieves 99.3% step\ncounting recall, 98.3% recognition recall for 5 activities, and 97.0% recall\nfor five tapping gestures on human face, respectively. We also demonstrate that\nOESense is compatible with earbuds' fundamental functionalities (e.g. music\nplayback and phone calls). In terms of energy, OESense consumes 746 mW during\ndata recording and recognition and it has a response latency of 40.85 ms for\ngesture recognition. Our analysis indicates such overhead is acceptable and\nOESense is potential to be integrated into future earbuds.",
    "descriptor": "",
    "authors": [
      "Dong Ma",
      "Andrea Ferlini",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.08607"
  },
  {
    "id": "arXiv:2106.08610",
    "title": "On the Fragile Rates of Linear Feedback Coding Schemes of Gaussian  Channels with Memory",
    "abstract": "In \\cite{butman1976} the linear coding scheme is applied, $X_t\n=g_t\\Big(\\Theta - {\\bf E}\\Big\\{\\Theta\\Big|Y^{t-1}, V_0=v_0\\Big\\}\\Big)$,\n$t=2,\\ldots,n$, $X_1=g_1\\Theta$, with $\\Theta: \\Omega \\to {\\mathbb R}$, a\nGaussian random variable, to derive a lower bound on the feedback rate, for\nadditive Gaussian noise (AGN) channels, $Y_t=X_t+V_t, t=1, \\ldots, n$, where\n$V_t$ is a Gaussian autoregressive (AR) noise, and $\\kappa \\in [0,\\infty)$ is\nthe total transmitter power. For the unit memory AR noise, with parameters $(c,\nK_W)$, where $c\\in [-1,1]$ is the pole and $K_W$ is the variance of the\nGaussian noise, the lower bound is $C^{L,B} =\\frac{1}{2} \\log \\chi^2$, where\n$\\chi =\\lim_{n\\longrightarrow \\infty} \\chi_n$ is the positive root of\n$\\chi^2=1+\\Big(1+ \\frac{|c|}{\\chi}\\Big)^2 \\frac{\\kappa}{K_W}$, and the sequence\n$\\chi_n \\triangleq \\Big|\\frac{g_n}{g_{n-1}}\\Big|, n=2, 3, \\ldots,$ satisfies a\ncertain recursion, and conjectured that $C^{L,B}$ is the feedback capacity.\nIn this correspondence, it is observed that the nontrivial lower bound\n$C^{L,B}=\\frac{1}{2} \\log \\chi^2$ such that $\\chi >1$, necessarily implies the\nscaling coefficients of the feedback code, $g_n$, $n=1,2, \\ldots$, grow\nunbounded, in the sense that, $\\lim_{n\\longrightarrow\\infty}|g_n| =+\\infty$.\nThe unbounded behaviour of $g_n$ follows from the ratio limit theorem of a\nsequence of real numbers, and it is verified by simulations. It is then\nconcluded that such linear codes are not practical, and fragile with respect to\na mismatch between the statistics of the mathematical model of the channel and\nthe real statistics of the channel. In particular, if the error is perturbed by\n$\\epsilon_n>0$ no matter how small, then $X_n =g_t\\Big(\\Theta - {\\bf\nE}\\Big\\{\\Theta\\Big|Y^{t-1}, V_0=v_0\\Big\\}\\Big)+g_n \\epsilon_n$, and\n$|g_n|\\epsilon_n \\longrightarrow \\infty$, as $n \\longrightarrow \\infty$.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Charalambos D. Charalambous",
      "Christos Kourtellaris",
      "Themistoklis Charalambous"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.08610"
  },
  {
    "id": "arXiv:2106.08613",
    "title": "FastAno: Fast Anomaly Detection via Spatio-temporal Patch Transformation",
    "abstract": "Video anomaly detection has gained significant attention due to the\nincreasing requirements of automatic monitoring for surveillance videos.\nEspecially, the prediction based approach is one of the most studied methods to\ndetect anomalies by predicting frames that include abnormal events in the test\nset after learning with the normal frames of the training set. However, a lot\nof prediction networks are computationally expensive owing to the use of\npre-trained optical flow networks, or fail to detect abnormal situations\nbecause of their strong generative ability to predict even the anomalies. To\naddress these shortcomings, we propose spatial rotation transformation (SRT)\nand temporal mixing transformation (TMT) to generate irregular patch cuboids\nwithin normal frame cuboids in order to enhance the learning of normal\nfeatures. Additionally, the proposed patch transformation is used only during\nthe training phase, allowing our model to detect abnormal frames at fast speed\nduring inference. Our model is evaluated on three anomaly detection benchmarks,\nachieving competitive accuracy and surpassing all the previous works in terms\nof speed.",
    "descriptor": "\nComments: 2022WACV\n",
    "authors": [
      "Chaewon Park",
      "MyeongAh Cho",
      "Minhyeok Lee",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08613"
  },
  {
    "id": "arXiv:2106.08615",
    "title": "EdgeConv with Attention Module for Monocular Depth Estimation",
    "abstract": "Monocular depth estimation is an especially important task in robotics and\nautonomous driving, where 3D structural information is essential. However,\nextreme lighting conditions and complex surface objects make it difficult to\npredict depth in a single image. Therefore, to generate accurate depth maps, it\nis important for the model to learn structural information about the scene. We\npropose a novel Patch-Wise EdgeConv Module (PEM) and EdgeConv Attention Module\n(EAM) to solve the difficulty of monocular depth estimation. The proposed\nmodules extract structural information by learning the relationship between\nimage patches close to each other in space using edge convolution. Our method\nis evaluated on two popular datasets, the NYU Depth V2 and the KITTI Eigen\nsplit, achieving state-of-the-art performance. We prove that the proposed model\npredicts depth robustly in challenging scenes through various comparative\nexperiments.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Minhyeok Lee",
      "Sangwon Hwang",
      "Chaewon Park",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08615"
  },
  {
    "id": "arXiv:2106.08616",
    "title": "Out-of-Scope Intent Detection with Self-Supervision and Discriminative  Training",
    "abstract": "Out-of-scope intent detection is of practical importance in task-oriented\ndialogue systems. Since the distribution of outlier utterances is arbitrary and\nunknown in the training stage, existing methods commonly rely on strong\nassumptions on data distribution such as mixture of Gaussians to make\ninference, resulting in either complex multi-step training procedures or\nhand-crafted rules such as confidence threshold selection for outlier\ndetection. In this paper, we propose a simple yet effective method to train an\nout-of-scope intent classifier in a fully end-to-end manner by simulating the\ntest scenario in training, which requires no assumption on data distribution\nand no additional post-processing or threshold setting. Specifically, we\nconstruct a set of pseudo outliers in the training stage, by generating\nsynthetic outliers using inliner features via self-supervision and sampling\nout-of-scope sentences from easily available open-domain datasets. The pseudo\noutliers are used to train a discriminative classifier that can be directly\napplied to and generalize well on the test task. We evaluate our method\nextensively on four benchmark dialogue datasets and observe significant\nimprovements over state-of-the-art approaches. Our code has been released at\nhttps://github.com/liam0949/DCLOOS.",
    "descriptor": "\nComments: ACL2021\n",
    "authors": [
      "Li-Ming Zhan",
      "Haowen Liang",
      "Bo Liu",
      "Lu Fan",
      "Xiao-Ming Wu",
      "Albert Y.S. Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08616"
  },
  {
    "id": "arXiv:2106.08617",
    "title": "CMF: Cascaded Multi-model Fusion for Referring Image Segmentation",
    "abstract": "In this work, we address the task of referring image segmentation (RIS),\nwhich aims at predicting a segmentation mask for the object described by a\nnatural language expression. Most existing methods focus on establishing\nunidirectional or directional relationships between visual and linguistic\nfeatures to associate two modalities together, while the multi-scale context is\nignored or insufficiently modeled. Multi-scale context is crucial to localize\nand segment those objects that have large scale variations during the\nmulti-modal fusion process. To solve this problem, we propose a simple yet\neffective Cascaded Multi-modal Fusion (CMF) module, which stacks multiple\natrous convolutional layers in parallel and further introduces a cascaded\nbranch to fuse visual and linguistic features. The cascaded branch can\nprogressively integrate multi-scale contextual information and facilitate the\nalignment of two modalities during the multi-modal fusion process. Experimental\nresults on four benchmark datasets demonstrate that our method outperforms most\nstate-of-the-art methods. Code is available at\nhttps://github.com/jianhua2022/CMF-Refseg.",
    "descriptor": "\nComments: Accepted by ICIP 2021\n",
    "authors": [
      "Jianhua Yang",
      "Yan Huang",
      "Zhanyu Ma",
      "Liang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08617"
  },
  {
    "id": "arXiv:2106.08620",
    "title": "Accurate and efficient hydrodynamic analysis of structures with sharp  edges by the Extended Finite Element Method (XFEM): 2D studies",
    "abstract": "Achieving accurate numerical results of hydrodynamic loads based on the\npotential-flow theory is very challenging for structures with sharp edges, due\nto the singular behavior of the local-flow velocities. In this paper, we\nintroduce the Extended Finite Element Method (XFEM) to solve fluid-structure\ninteraction problems involving sharp edges on structures. Four different FEM\nsolvers, including conventional linear and quadratic FEMs as well as their\ncorresponding XFEM versions with local enrichment by singular basis functions\nat sharp edges, are implemented and compared. To demonstrate the accuracy and\nefficiency of the XFEMs, a thin flat plate in an infinite fluid domain and a\nforced heaving rectangle at the free surface, both in two dimensions, will be\nstudied. For the flat plate, the mesh convergence studies are carried out for\nboth the velocity potential in the fluid domain and the added mass, and the\nXFEMs show apparent advantages thanks to their local enhancement at the sharp\nedges. Three different enrichment strategies are also compared, and suggestions\nwill be made for the practical implementation of the XFEM. For the forced\nheaving rectangle, the linear and 2nd order mean wave loads are studied. Our\nresults confirm the previous conclusion in the literature that it is not\ndifficult for a conventional numerical model to obtain convergent results for\nadded mass and damping coefficients. However, when the 2nd order mean wave\nloads requiring the computation of velocity components are calculated via\ndirect pressure integration, it takes a tremendously large number of elements\nfor the conventional FEMs to get convergent results. On the contrary, the\nnumerical results of XFEMs converge rapidly even with very coarse meshes,\nespecially for the quadratic XFEM.",
    "descriptor": "",
    "authors": [
      "Ying Wang",
      "Yanlin Shao",
      "Jikang Chen",
      "Hui Liang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2106.08620"
  },
  {
    "id": "arXiv:2106.08624",
    "title": "Structured DropConnect for Uncertainty Inference in Image Classification",
    "abstract": "With the complexity of the network structure, uncertainty inference has\nbecome an important task to improve the classification accuracy for artificial\nintelligence systems. For image classification tasks, we propose a structured\nDropConnect (SDC) framework to model the output of a deep neural network by a\nDirichlet distribution. We introduce a DropConnect strategy on weights in the\nfully connected layers during training. In test, we split the network into\nseveral sub-networks, and then model the Dirichlet distribution by match its\nmoments with the mean and variance of the outputs of these sub-networks. The\nentropy of the estimated Dirichlet distribution is finally utilized for\nuncertainty inference. In this paper, this framework is implemented on LeNet$5$\nand VGG$16$ models for misclassification detection and out-of-distribution\ndetection on MNIST and CIFAR-$10$ datasets. Experimental results show that the\nperformance of the proposed SDC can be comparable to other uncertainty\ninference methods. Furthermore, the SDC is adapted well to different network\nstructures with certain generalization capabilities and research prospects.",
    "descriptor": "\nComments: 5 pages,1 figures\n",
    "authors": [
      "Wenqing Zheng",
      "Jiyang Xie",
      "Weidong Liu",
      "Zhanyu Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08624"
  },
  {
    "id": "arXiv:2106.08629",
    "title": "From Discourse to Narrative: Knowledge Projection for Event Relation  Extraction",
    "abstract": "Current event-centric knowledge graphs highly rely on explicit connectives to\nmine relations between events. Unfortunately, due to the sparsity of\nconnectives, these methods severely undermine the coverage of EventKGs. The\nlack of high-quality labelled corpora further exacerbates that problem. In this\npaper, we propose a knowledge projection paradigm for event relation\nextraction: projecting discourse knowledge to narratives by exploiting the\ncommonalities between them. Specifically, we propose Multi-tier Knowledge\nProjection Network (MKPNet), which can leverage multi-tier discourse knowledge\neffectively for event relation extraction. In this way, the labelled data\nrequirement is significantly reduced, and implicit event relations can be\neffectively extracted. Intrinsic experimental results show that MKPNet achieves\nthe new state-of-the-art performance, and extrinsic experimental results verify\nthe value of the extracted event relations.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Jialong Tang",
      "Hongyu Lin",
      "Meng Liao",
      "Yaojie Lu",
      "Xianpei Han",
      "Le Sun",
      "Weijian Xie",
      "Jin Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08629"
  },
  {
    "id": "arXiv:2106.08630",
    "title": "HELP: Hardware-Adaptive Efficient Latency Predictor for NAS via  Meta-Learning",
    "abstract": "For deployment, neural architecture search should be hardware-aware, in order\nto satisfy the device-specific constraints (e.g., memory usage, latency and\nenergy consumption) and enhance the model efficiency. Existing methods on\nhardware-aware NAS collect a large number of samples (e.g., accuracy and\nlatency) from a target device, either builds a lookup table or a latency\nestimator. However, such approach is impractical in real-world scenarios as\nthere exist numerous devices with different hardware specifications, and\ncollecting samples from such a large number of devices will require prohibitive\ncomputational and monetary cost. To overcome such limitations, we propose\nHardware-adaptive Efficient Latency Predictor (HELP), which formulates the\ndevice-specific latency estimation problem as a meta-learning problem, such\nthat we can estimate the latency of a model's performance for a given task on\nan unseen device with a few samples. To this end, we introduce novel hardware\nembeddings to embed any devices considering them as black-box functions that\noutput latencies, and meta-learn the hardware-adaptive latency predictor in a\ndevice-dependent manner, using the hardware embeddings. We validate the\nproposed HELP for its latency estimation performance on unseen platforms, on\nwhich it achieves high estimation performance with as few as 10 measurement\nsamples, outperforming all relevant baselines. We also validate end-to-end NAS\nframeworks using HELP against ones without it, and show that it largely reduces\nthe total time cost of the base NAS method, in latency-constrained settings.",
    "descriptor": "",
    "authors": [
      "Hayeon Lee",
      "Sewoong Lee",
      "Song Chong",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08630"
  },
  {
    "id": "arXiv:2106.08634",
    "title": "MPC-based Reinforcement Learning for a Simplified Freight Mission of  Autonomous Surface Vehicles",
    "abstract": "In this work, we propose a Model Predictive Control (MPC)-based Reinforcement\nLearning (RL) method for Autonomous Surface Vehicles (ASVs). The objective is\nto find an optimal policy that minimizes the closed-loop performance of a\nsimplified freight mission, including collision-free path following, autonomous\ndocking, and a skillful transition between them. We use a parametrized\nMPC-scheme to approximate the optimal policy, which considers\npath-following/docking costs and states (position, velocity)/inputs (thruster\nforce, angle) constraints. The Least Squares Temporal Difference (LSTD)-based\nDeterministic Policy Gradient (DPG) method is then applied to update the policy\nparameters. Our simulation results demonstrate that the proposed MPC-LSTD-based\nDPG method could improve the closed-loop performance during learning for the\nfreight mission problem of ASV.",
    "descriptor": "\nComments: 6 pages, 7 figures, submitted to CDC2021 60th Conference on Decision and Control\n",
    "authors": [
      "Wenqi Cai",
      "Arash B. Kordabad",
      "Hossein N. Esfahani",
      "Anastasios M. Lekkas",
      "Sebastien Gros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08634"
  },
  {
    "id": "arXiv:2106.08636",
    "title": "Optimal Water-Filling Algorithm in Downlink Multi-Cluster NOMA Systems",
    "abstract": "The key idea of power-domain non-orthogonal multiple access (NOMA) is to\nexploit the superposition coding (SC) combined with successive interference\ncancellation (SIC) technique (called SC-SIC) while reducing the receivers'\ncomplexity as well as error propagation. Actually, NOMA suggests a\nlow-complexity scheme, where users are grouped into multiple clusters operating\nin isolated resource blocks, and SC-SIC is performed among users within each\ncluster. In this paper, we propose a globally optimal joint intra- and\ninter-cluster power allocation for any arbitrary user grouping to maximize\nusers' sum-rate. In this algorithm, we exploit the closed-form of optimal\nintra-cluster power allocation obtained in our previous work. Then, by\ntransforming network-NOMA to an equivalent virtual network-OMA, we show that\nthe optimal power allocation can be obtained based on the very fast\nwater-filling algorithm. Interestingly, we observe that each NOMA cluster acts\nas a virtual OMA user whose effective channel gain is obtained in closed form.\nAlso, each virtual OMA user requires a minimum power to satisfy the minimum\nrate demand of its real multiplexed user. In simulation results, we evaluate\nthe performance gap between fully SC-SIC, NOMA, and OMA, in terms of users\nsum-rate, and outage probability.",
    "descriptor": "\nComments: 6 pages, 7 figures, submitted to IEEE Wireless Communications and Networking Conference (WCNC) 2022\n",
    "authors": [
      "Sepehr Rezvani",
      "Eduard A. Jorswieck"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.08636"
  },
  {
    "id": "arXiv:2106.08637",
    "title": "Topic Classification on Spoken Documents Using Deep Acoustic and  Linguistic Features",
    "abstract": "Topic classification systems on spoken documents usually consist of two\nmodules: an automatic speech recognition (ASR) module to convert speech into\ntext and a text topic classification (TTC) module to predict the topic class\nfrom the decoded text. In this paper, instead of using the ASR transcripts, the\nfusion of deep acoustic and linguistic features is used for topic\nclassification on spoken documents. More specifically, a conventional CTC-based\nacoustic model (AM) using phonemes as output units is first trained, and the\noutputs of the layer before the linear phoneme classifier in the trained AM are\nused as the deep acoustic features of spoken documents. Furthermore, these deep\nacoustic features are fed to a phoneme-to-word (P2W) module to obtain deep\nlinguistic features. Finally, a local multi-head attention module is proposed\nto fuse these two types of deep features for topic classification. Experiments\nconducted on a subset selected from Switchboard corpus show that our proposed\nframework outperforms the conventional ASR+TTC systems and achieves a 3.13%\nimprovement in ACC.",
    "descriptor": "",
    "authors": [
      "Tan Liu",
      "Wu Guo",
      "Bin Gu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08637"
  },
  {
    "id": "arXiv:2106.08640",
    "title": "Counterfactual Graphs for Explainable Classification of Brain Networks",
    "abstract": "Training graph classifiers able to distinguish between healthy brains and\ndysfunctional ones, can help identifying substructures associated to specific\ncognitive phenotypes. However, the mere predictive power of the graph\nclassifier is of limited interest to the neuroscientists, which have plenty of\ntools for the diagnosis of specific mental disorders. What matters is the\ninterpretation of the model, as it can provide novel insights and new\nhypotheses.\nIn this paper we propose \\emph{counterfactual graphs} as a way to produce\nlocal post-hoc explanations of any black-box graph classifier. Given a graph\nand a black-box, a counterfactual is a graph which, while having high\nstructural similarity with the original graph, is classified by the black-box\nin a different class. We propose and empirically compare several strategies for\ncounterfactual graph search. Our experiments against a white-box classifier\nwith known optimal counterfactual, show that our methods, although heuristic,\ncan produce counterfactuals very close to the optimal one. Finally, we show how\nto use counterfactual graphs to build global explanations correctly capturing\nthe behaviour of different black-box classifiers and providing interesting\ninsights for the neuroscientists.",
    "descriptor": "\nComments: In proceedings of KDD 2021\n",
    "authors": [
      "Carlo Abrate",
      "Francesco Bonchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08640"
  },
  {
    "id": "arXiv:2106.08641",
    "title": "Best of both worlds: local and global explanations with  human-understandable concepts",
    "abstract": "Interpretability techniques aim to provide the rationale behind a model's\ndecision, typically by explaining either an individual prediction (local\nexplanation, e.g. `why is this patient diagnosed with this condition') or a\nclass of predictions (global explanation, e.g. `why are patients diagnosed with\nthis condition in general'). While there are many methods focused on either\none, few frameworks can provide both local and global explanations in a\nconsistent manner. In this work, we combine two powerful existing techniques,\none local (Integrated Gradients, IG) and one global (Testing with Concept\nActivation Vectors), to provide local, and global concept-based explanations.\nWe first validate our idea using two synthetic datasets with a known ground\ntruth, and further demonstrate with a benchmark natural image dataset. We test\nour method with various concepts, target classes, model architectures and IG\nbaselines. We show that our method improves global explanations over TCAV when\ncompared to ground truth, and provides useful insights. We hope our work\nprovides a step towards building bridges between many existing local and global\nmethods to get the best of both worlds.",
    "descriptor": "",
    "authors": [
      "Jessica Schrouff",
      "Sebastien Baur",
      "Shaobo Hou",
      "Diana Mincu",
      "Eric Loreaux",
      "Ralph Blanes",
      "James Wexler",
      "Alan Karthikesalingam",
      "Been Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08641"
  },
  {
    "id": "arXiv:2106.08644",
    "title": "RASAECO: Requirements Analysis of Software for the AECO Industry",
    "abstract": "Digitalization is forging its path in the architecture, construction,\nengineering, operation (AECO) industry. This trend demands not only solutions\nfor data governance but also sophisticated cyber-physical systems with a high\nvariety of stakeholder background and very complex requirements. Existing\napproaches to general requirements engineering ignore the context of the AECO\nindustry. This makes it harder for the software engineers usually lacking the\nknowledge of the industry context to elicit, analyze and structure the\nrequirements and to effectively communicate with AECO professionals. To live up\nto that task, we present an approach and a tool for collecting AECO-specific\nsoftware requirements with the aim to foster reuse and leverage domain\nknowledge. We introduce a common scenario space, propose a novel choice of an\nubiquitous language well-suited for this particular industry and develop a\nsystematic way to refine the scenario ontologies based on the exploration of\nthe scenario space. The viability of our approach is demonstrated on an\nontology of 20 practical scenarios from a large project aiming to develop a\ndigital twin of a construction site.",
    "descriptor": "\nComments: Pre-print of our submission to 29th IEEE International Requirements Engineering Conference\n",
    "authors": [
      "Marko Ristin",
      "Dag Fjeld Edvardsen",
      "Hans Wernher van de Venn"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.08644"
  },
  {
    "id": "arXiv:2106.08647",
    "title": "Exponential Approximation of Band-limited Signals from Nonuniform  Sampling",
    "abstract": "Reconstructing a band-limited function from its finite sample data is a\nfundamental task in signal analysis. A simple Gaussian or hyper-Gaussian\nregularized Shannon sampling series has been proved to be able to achieve\nexponential convergence for uniform sampling. In this paper, we prove that\nexponential approximation can also be attained for general nonuniform sampling.\nThe analysis is based on the the residue theorem to represent the truncated\nerror by a contour integral. Several concrete examples of nonuniform sampling\nwith exponential convergence will be presented.",
    "descriptor": "",
    "authors": [
      "Yunfei Yang",
      "Haizhang Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.08647"
  },
  {
    "id": "arXiv:2106.08648",
    "title": "Semantic sentence similarity: size does not always matter",
    "abstract": "This study addresses the question whether visually grounded speech\nrecognition (VGS) models learn to capture sentence semantics without access to\nany prior linguistic knowledge. We produce synthetic and natural spoken\nversions of a well known semantic textual similarity database and show that our\nVGS model produces embeddings that correlate well with human semantic\nsimilarity judgements. Our results show that a model trained on a small\nimage-caption database outperforms two models trained on much larger databases,\nindicating that database size is not all that matters. We also investigate the\nimportance of having multiple captions per image and find that this is indeed\nhelpful even if the total number of images is lower, suggesting that\nparaphrasing is a valuable learning signal. While the general trend in the\nfield is to create ever larger datasets to train models on, our findings\nindicate other characteristics of the database can just as important important.",
    "descriptor": "\nComments: This paper has been accepted at Interspeech 2021 where it will be presented and appear in the conference proceedings in September 2021\n",
    "authors": [
      "Danny Merkx",
      "Stefan L. Frank",
      "Mirjam Ernestus"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08648"
  },
  {
    "id": "arXiv:2106.08650",
    "title": "Shuffle Transformer with Feature Alignment for Video Face Parsing",
    "abstract": "This is a short technical report introducing the solution of the Team\nTCParser for Short-video Face Parsing Track of The 3rd Person in Context (PIC)\nWorkshop and Challenge at CVPR 2021. In this paper, we introduce a strong\nbackbone which is cross-window based Shuffle Transformer for presenting\naccurate face parsing representation. To further obtain the finer segmentation\nresults, especially on the edges, we introduce a Feature Alignment Aggregation\n(FAA) module. It can effectively relieve the feature misalignment issue caused\nby multi-resolution feature aggregation. Benefiting from the stronger backbone\nand better feature aggregation, the proposed method achieves 86.9519% score in\nthe Short-video Face Parsing track of the 3rd Person in Context (PIC) Workshop\nand Challenge, ranked the first place.",
    "descriptor": "\nComments: technical report\n",
    "authors": [
      "Rui Zhang",
      "Yang Han",
      "Zilong Huang",
      "Pei Cheng",
      "Guozhong Luo",
      "Gang Yu",
      "Bin Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08650"
  },
  {
    "id": "arXiv:2106.08652",
    "title": "Maxmin-Fair Ranking: Individual Fairness under Group-Fairness  Constraints",
    "abstract": "We study a novel problem of fairness in ranking aimed at minimizing the\namount of individual unfairness introduced when enforcing group-fairness\nconstraints. Our proposal is rooted in the distributional maxmin fairness\ntheory, which uses randomization to maximize the expected satisfaction of the\nworst-off individuals. We devise an exact polynomial-time algorithm to find\nmaxmin-fair distributions of general search problems (including, but not\nlimited to, ranking), and show that our algorithm can produce rankings which,\nwhile satisfying the given group-fairness constraints, ensure that the maximum\npossible value is brought to individuals.",
    "descriptor": "\nComments: In proceedings of KDD 2021\n",
    "authors": [
      "David Garcia-Soriano",
      "Francesco Bonchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.08652"
  },
  {
    "id": "arXiv:2106.08654",
    "title": "A Revised Taxonomy of Steganography Embedding Patterns",
    "abstract": "Steganography embraces several hiding techniques which spawn across multiple\ndomains. However, the related terminology is not unified among the different\ndomains, such as digital media steganography, text steganography,\ncyber-physical systems steganography, network steganography (network covert\nchannels), local covert channels, and out-of-band covert channels. To cope with\nthis, a prime attempt has been done in 2015, with the introduction of the\nso-called hiding patterns, which allow to describe hiding techniques in a more\nabstract manner. Despite significant enhancements, the main limitation of such\na taxonomy is that it only considers the case of network steganography.\nTherefore, this paper reviews both the terminology and the taxonomy of hiding\npatterns as to make them more general. Specifically, hiding patterns are split\ninto those that describe the embedding and the representation of hidden data\nwithin the cover object.\nAs a first research action, we focus on embedding hiding patterns and we show\nhow they can be applied to multiple domains of steganography instead of being\nlimited to the network scenario. Additionally, we exemplify representation\npatterns using network steganography. Our pattern collection is available under\nhttps://patterns.ztt.hs-worms.de.",
    "descriptor": "",
    "authors": [
      "Steffen Wendzel",
      "Luca Caviglione",
      "Wojciech Mazurczyk",
      "Aleksandra Mileva",
      "Jana Dittmann",
      "Christian Kr\u00e4tzer",
      "Kevin Lamsh\u00f6ft",
      "Claus Vielhauer",
      "Laura Hartmann",
      "J\u00f6rg Keller",
      "Tom Neubert"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.08654"
  },
  {
    "id": "arXiv:2106.08657",
    "title": "Eider: Evidence-enhanced Document-level Relation Extraction",
    "abstract": "Document-level relation extraction (DocRE) aims at extracting the semantic\nrelations among entity pairs in a document. In DocRE, a subset of the sentences\nin a document, called the evidence sentences, might be sufficient for\npredicting the relation between a specific entity pair. To make better use of\nthe evidence sentences, in this paper, we propose a three-stage\nevidence-enhanced DocRE framework consisting of joint relation and evidence\nextraction, evidence-centered relation extraction (RE), and fusion of\nextraction results. We first jointly train an RE model with a simple and\nmemory-efficient evidence extraction model. Then, we construct pseudo documents\nbased on the extracted evidence sentences and run the RE model again. Finally,\nwe fuse the extraction results of the first two stages using a blending layer\nand make a final prediction. Extensive experiments show that our proposed\nframework achieves state-of-the-art performance on the DocRED dataset,\noutperforming the second-best method by 0.76/0.82 Ign F1/F1. In particular, our\nmethod significantly improves the performance on inter-sentence relations by\n1.23 Inter F1.",
    "descriptor": "",
    "authors": [
      "Yiqing Xie",
      "Jiaming Shen",
      "Sha Li",
      "Yuning Mao",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08657"
  },
  {
    "id": "arXiv:2106.08658",
    "title": "A Dataset-Level Geometric Framework for Ensemble Classifiers",
    "abstract": "Ensemble classifiers have been investigated by many in the artificial\nintelligence and machine learning community. Majority voting and weighted\nmajority voting are two commonly used combination schemes in ensemble learning.\nHowever, understanding of them is incomplete at best, with some properties even\nmisunderstood. In this paper, we present a group of properties of these two\nschemes formally under a dataset-level geometric framework. Two key factors,\nevery component base classifier's performance and dissimilarity between each\npair of component classifiers are evaluated by the same metric - the Euclidean\ndistance. Consequently, ensembling becomes a deterministic problem and the\nperformance of an ensemble can be calculated directly by a formula. We prove\nseveral theorems of interest and explain their implications for ensembles. In\nparticular, we compare and contrast the effect of the number of component\nclassifiers on these two types of ensemble schemes. Empirical investigation is\nalso conducted to verify the theoretical results when other metrics such as\naccuracy are used. We believe that the results from this paper are very useful\nfor us to understand the fundamental properties of these two combination\nschemes and the principles of ensemble classifiers in general. The results are\nalso helpful for us to investigate some issues in ensemble classifiers, such as\nensemble performance prediction, selecting a small number of base classifiers\nto obtain efficient and effective ensembles.",
    "descriptor": "\nComments: number of pages: 32 number of figures: 2\n",
    "authors": [
      "Shengli Wu",
      "Weimin Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08658"
  },
  {
    "id": "arXiv:2106.08670",
    "title": "The Difficulty of Novelty Detection in Open-World Physical Domains: An  Application to Angry Birds",
    "abstract": "Detecting and responding to novel situations in open-world environments is a\nkey capability of human cognition. Current artificial intelligence (AI)\nresearchers strive to develop systems that can perform in open-world\nenvironments. Novelty detection is an important ability of such AI systems. In\nan open-world, novelties appear in various forms and the difficulty to detect\nthem varies. Therefore, to accurately evaluate the detection capability of AI\nsystems, it is necessary to investigate the difficulty to detect novelties. In\nthis paper, we propose a qualitative physics-based method to quantify the\ndifficulty of novelty detection focusing on open-world physical domains. We\napply our method in a popular physics simulation game, Angry Birds. We conduct\nan experiment with human players with different novelties in Angry Birds to\nvalidate our method. Results indicate that the calculated difficulty values are\nin line with the detection difficulty of the human players.",
    "descriptor": "",
    "authors": [
      "Vimukthini Pinto",
      "Cheng Xue",
      "Chathura Nagoda Gamage",
      "Jochen Renz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08670"
  },
  {
    "id": "arXiv:2106.08671",
    "title": "Comparison of Automated Machine Learning Tools for SMS Spam Message  Filtering",
    "abstract": "Short Message Service (SMS) is a very popular service used for communication\nby mobile users. However, this popular service can be abused by executing\nillegal activities and influencing security risks. Nowadays, many automatic\nmachine learning (AutoML) tools exist which can help domain experts and lay\nusers to build high-quality ML models with little or no machine learning\nknowledge. In this work, a classification performance comparison was conducted\nbetween three automatic ML tools for SMS spam message filtering. These tools\nare mljar-supervised AutoML, H2O AutoML, and Tree-based Pipeline Optimization\nTool (TPOT) AutoML. Experimental results showed that ensemble models achieved\nthe best classification performance. The Stacked Ensemble model, which was\nbuilt using H2O AutoML, achieved the best performance in terms of Log Loss\n(0.8370), true positive (1088/1116), and true negative (281/287) metrics. There\nis a 19.05\\% improvement in Log Loss with respect to TPOT AutoML and 10.53\\%\nimprovement with respect to mljar-supervised AutoML. The satisfactory filtering\nperformance achieved with AutoML tools provides a potential application for\nAutoML tools to automatically determine the best ML model that can perform best\nfor SMS spam message filtering.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Waddah Saeed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08671"
  },
  {
    "id": "arXiv:2106.08676",
    "title": "Velos: One-sided Paxos for RDMA applications",
    "abstract": "Modern data centers are becoming increasingly equipped with RDMA-capable\nNICs. These devices enable distributed systems to rely on algorithms designed\nfor shared memory. RDMA allows consensus to terminate within a few microsecond\nin failure-free scenarios, yet, RDMA-optimized algorithms still use expensive\ntwo-sided operations in case of failure. In this work, we present a new\nleader-based consensus algorithm that relies solely on one-sided RDMA verbs.\nOur algorithm is based on Paxos, it decides in a single one-sided RDMA\noperation in the common case, and changes leader also in a single one-sided\nRDMA operation in case of failure. We implement our algorithm in the form of an\nSMR system named Velos, and we evaluated our system against the\nstate-of-the-art competitor Mu. Compared to Mu, our solution adds a small\noverhead of approximately 0.6 microseconds in failure-free executions and\nshines during failover periods during which it is 13 times faster in changing\nleader.",
    "descriptor": "",
    "authors": [
      "Rachid Guerraoui",
      "Antoine Murat",
      "Athanasios Xygkis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.08676"
  },
  {
    "id": "arXiv:2106.08680",
    "title": "Evaluating Gender Bias in Hindi-English Machine Translation",
    "abstract": "With language models being deployed increasingly in the real world, it is\nessential to address the issue of the fairness of their outputs. The word\nembedding representations of these language models often implicitly draw\nunwanted associations that form a social bias within the model. The nature of\ngendered languages like Hindi, poses an additional problem to the\nquantification and mitigation of bias, owing to the change in the form of the\nwords in the sentence, based on the gender of the subject. Additionally, there\nis sparse work done in the realm of measuring and debiasing systems for Indic\nlanguages. In our work, we attempt to evaluate and quantify the gender bias\nwithin a Hindi-English machine translation system. We implement a modified\nversion of the existing TGBI metric based on the grammatical considerations for\nHindi. We also compare and contrast the resulting bias measurements across\nmultiple metrics for pre-trained embeddings and the ones learned by our machine\ntranslation model.",
    "descriptor": "",
    "authors": [
      "Gauri Gupta",
      "Krithika Ramesh",
      "Sanjay Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08680"
  },
  {
    "id": "arXiv:2106.08684",
    "title": "Infodemics on Youtube: Reliability of Content and Echo Chambers on  COVID-19",
    "abstract": "Social media radically changed how information is consumed and reported.\nMoreover, social networks elicited a disintermediated access to an\nunprecedented amount of content. The world health organization (WHO) coined the\nterm infodemics to identify the information overabundance during an epidemic.\nIndeed, the spread of inaccurate and misleading information may alter behaviors\nand complicate crisis management and health responses. This paper addresses\ninformation diffusion during the COVID-19 pandemic period with a massive data\nanalysis on YouTube. First, we analyze more than 2M users' engagement in 13000\nvideos released by 68 different YouTube channels, with different political bias\nand fact-checking indexes. We then investigate the relationship between each\nuser's political preference and her/his consumption of questionable/reliable\ninformation. Our results, quantified using information theory measures, provide\nevidence for the existence of echo chambers across two dimensions represented\nby the political bias and by the trustworthiness of information channels.\nFinally, we observe that the echo chamber structure cannot be reproduced after\nproperly randomizing the users' interaction patterns.",
    "descriptor": "",
    "authors": [
      "Niccol\u00f2 Di Marco",
      "Matteo Cinelli",
      "Walter Quattrociocchi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.08684"
  },
  {
    "id": "arXiv:2106.08685",
    "title": "Drum-Aware Ensemble Architecture for Improved Joint Musical Beat and  Downbeat Tracking",
    "abstract": "This paper presents a novel system architecture that integrates blind source\nseparation with joint beat and downbeat tracking in musical audio signals. The\nsource separation module segregates the percussive and non-percussive\ncomponents of the input signal, over which beat and downbeat tracking are\nperformed separately and then the results are aggregated with a learnable\nfusion mechanism. This way, the system can adaptively determine how much the\ntracking result for an input signal should depend on the input's percussive or\nnon-percussive components. Evaluation on four testing sets that feature\ndifferent levels of presence of drum sounds shows that the new architecture\nconsistently outperforms the widely-adopted baseline architecture that does not\nemploy source separation.",
    "descriptor": "\nComments: Accepted to IEEE Signal Processing Letters (May 2021)\n",
    "authors": [
      "Ching-Yu Chiu",
      "Alvin Wen-Yu Su",
      "Yi-Hsuan Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.08685"
  },
  {
    "id": "arXiv:2106.08686",
    "title": "Do Acoustic Word Embeddings Capture Phonological Similarity? An  Empirical Study",
    "abstract": "Several variants of deep neural networks have been successfully employed for\nbuilding parametric models that project variable-duration spoken word segments\nonto fixed-size vector representations, or acoustic word embeddings (AWEs).\nHowever, it remains unclear to what degree we can rely on the distance in the\nemerging AWE space as an estimate of word-form similarity. In this paper, we\nask: does the distance in the acoustic embedding space correlate with\nphonological dissimilarity? To answer this question, we empirically investigate\nthe performance of supervised approaches for AWEs with different neural\narchitectures and learning objectives. We train AWE models in controlled\nsettings for two languages (German and Czech) and evaluate the embeddings on\ntwo tasks: word discrimination and phonological similarity. Our experiments\nshow that (1) the distance in the embedding space in the best cases only\nmoderately correlates with phonological distance, and (2) improving the\nperformance on the word discrimination task does not necessarily yield models\nthat better reflect word phonological similarity. Our findings highlight the\nnecessity to rethink the current intrinsic evaluations for AWEs.",
    "descriptor": "\nComments: Accepted in Interspeech 2021\n",
    "authors": [
      "Badr M. Abdullah",
      "Marius Mosbach",
      "Iuliia Zaitova",
      "Bernd M\u00f6bius",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.08686"
  },
  {
    "id": "arXiv:2106.08687",
    "title": "Leveraging Probabilistic Circuits for Nonparametric Multi-Output  Regression",
    "abstract": "Inspired by recent advances in the field of expert-based approximations of\nGaussian processes (GPs), we present an expert-based approach to large-scale\nmulti-output regression using single-output GP experts. Employing a deeply\nstructured mixture of single-output GPs encoded via a probabilistic circuit\nallows us to capture correlations between multiple output dimensions\naccurately. By recursively partitioning the covariate space and the output\nspace, posterior inference in our model reduces to inference on single-output\nGP experts, which only need to be conditioned on a small subset of the\nobservations. We show that inference can be performed exactly and efficiently\nin our model, that it can capture correlations between output dimensions and,\nhence, often outperforms approaches that do not incorporate inter-output\ncorrelations, as demonstrated on several data sets in terms of the negative log\npredictive density.",
    "descriptor": "\nComments: Accepted for the 37th Conference on Uncertainty in Artificial Intelligence (UAI 2021)\n",
    "authors": [
      "Zhongjie Yu",
      "Mingye Zhu",
      "Martin Trapp",
      "Arseny Skryagin",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08687"
  },
  {
    "id": "arXiv:2106.08689",
    "title": "Alzheimer's Disease Detection from Spontaneous Speech through Combining  Linguistic Complexity and (Dis)Fluency Features with Pretrained Language  Models",
    "abstract": "In this paper, we combined linguistic complexity and (dis)fluency features\nwith pretrained language models for the task of Alzheimer's disease detection\nof the 2021 ADReSSo (Alzheimer's Dementia Recognition through Spontaneous\nSpeech) challenge. An accuracy of 83.1% was achieved on the test set, which\namounts to an improvement of 4.23% over the baseline model. Our best-performing\nmodel that integrated component models using a stacking ensemble technique\nperformed equally well on cross-validation and test data, indicating that it is\nrobust against overfitting.",
    "descriptor": "\nComments: accepted at Interspeech2021\n",
    "authors": [
      "Yu Qiao",
      "Xuefeng Yin",
      "Daniel Wiechmann",
      "Elma Kerz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08689"
  },
  {
    "id": "arXiv:2106.08692",
    "title": "Detecting message modification attacks on the CAN bus with Temporal  Convolutional Networks",
    "abstract": "Multiple attacks have shown that in-vehicle networks have vulnerabilities\nwhich can be exploited. Securing the Controller Area Network (CAN) for modern\nvehicles has become a necessary task for car manufacturers. Some attacks inject\npotentially large amount of fake messages into the CAN network; however, such\nattacks are relatively easy to detect. In more sophisticated attacks, the\noriginal messages are modified, making the de- tection a more complex problem.\nIn this paper, we present a novel machine learning based intrusion detection\nmethod for CAN networks. We focus on detecting message modification attacks,\nwhich do not change the timing patterns of communications. Our proposed\ntemporal convolutional network-based solution can learn the normal behavior of\nCAN signals and differentiate them from malicious ones. The method is evaluated\non multiple CAN-bus message IDs from two public datasets including different\ntypes of attacks. Performance results show that our lightweight approach\ncompares favorably to the state-of-the-art unsupervised learning approach,\nachieving similar or better accuracy for a wide range of scenarios with a\nsignificantly lower false positive rate.",
    "descriptor": "",
    "authors": [
      "Irina Chiscop",
      "Andr\u00e1s Gazdag",
      "Joost Bosman",
      "Gergely Bicz\u00f3k"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08692"
  },
  {
    "id": "arXiv:2106.08693",
    "title": "ParticleAugment: Sampling-Based Data Augmentation",
    "abstract": "We present an automated data augmentation approach for image classification.\nWe formulate the problem as Monte Carlo sampling where our goal is to\napproximate the optimal augmentation policies. We propose a particle filtering\nformulation to find optimal augmentation policies and their schedules during\nmodel training. Our performance measurement procedure relies on a validation\nsubset of our training set, while the policy transition model depends on a\nGaussian prior and an optional augmentation velocity parameter. In our\nexperiments, we show that our formulation for automated augmentation reaches\npromising results on CIFAR-10, CIFAR-100, and ImageNet datasets using the\nstandard network architectures for this problem. By comparing with the related\nwork, we also show that our method reaches a balance between the computational\ncost of policy search and the model performance.",
    "descriptor": "\nComments: 11 pages. Submitted to NeurIPS 2021\n",
    "authors": [
      "Alexander Tsaregorodtsev",
      "Vasileios Belagiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08693"
  },
  {
    "id": "arXiv:2106.08694",
    "title": "On the proper role of linguistically-oriented deep net analysis in  linguistic theorizing",
    "abstract": "A lively research field has recently emerged that uses experimental methods\nto probe the linguistic behavior of modern deep networks. While work in this\ntradition often reports intriguing results about the grammatical skills of deep\nnets, it is not clear what their implications for linguistic theorizing should\nbe. As a consequence, linguistically-oriented deep net analysis has had very\nlittle impact on linguistics at large. In this chapter, I suggest that deep\nnetworks should be treated as theories making explicit predictions about the\nacceptability of linguistic utterances. I argue that, if we overcome some\nobstacles standing in the way of seriously pursuing this idea, we will gain a\npowerful new theoretical tool, complementary to mainstream algebraic\napproaches.",
    "descriptor": "\nComments: Submitted to collective volume on Algebraic Systems and the Representation of Linguistic Knowledge\n",
    "authors": [
      "Marco Baroni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08694"
  },
  {
    "id": "arXiv:2106.08696",
    "title": "High-Quality Hypergraph Partitioning",
    "abstract": "This paper considers the balanced hypergraph partitioning problem, which asks\nfor partitioning the vertices into $k$ disjoint blocks of bounded size while\nminimizing an objective function over the hyperedges. Here, we consider the\nmost commonly used connectivity metric.\nWe describe our open source hypergraph partitioner KaHyPar which is based on\nthe successful multi-level approach -- driving it to the extreme of one level\nfor (almost) every vertex. Using carefully designed data structures and dynamic\nupdate techniques, this approach offers a very good time--quality tradeoff. We\npresent two preprocessing techniques -- pin sparsification using locality\nsensitive hashing and community detection based on the Louvain algorithm. The\ncommunity structure is used to guide the coarsening process that incrementally\ncontracts vertices. Portfolio-based partitioning of the contracted hypergraph\nalready achieves good initial solutions. While reversing the contractions, a\ncombination of highly-localized direct $k$-way local search and flow-based\ntechniques that take a more global view, refine the partition to achieve high\nquality. Optionally, a memetic algorithm evolves a pool of solution candidates\nto obtain even higher quality.\nWe evaluate KaHyPar on a large set of instances from a wide range of\napplication domains. With respect to quality, KaHyPar outperforms all\npreviously considered systems that can handle large hypergraphs such as hMETIS,\nPaToH, Mondriaan, or Zoltan. KaHyPar is also faster than most of these systems\nexcept for PaToH which represents a different speed--quality tradeoff. The\nresults even extend to the special case of graph partitioning, where\nspecialized systems such as KaHIP should have an advantage.",
    "descriptor": "",
    "authors": [
      "Sebastian Schlag",
      "Tobias Heuer",
      "Lars Gottesb\u00fcren",
      "Yaroslav Akhremtsev",
      "Christian Schulz",
      "Peter Sanders"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.08696"
  },
  {
    "id": "arXiv:2106.08700",
    "title": "Topology Distillation for Recommender System",
    "abstract": "Recommender Systems (RS) have employed knowledge distillation which is a\nmodel compression technique training a compact student model with the knowledge\ntransferred from a pre-trained large teacher model. Recent work has shown that\ntransferring knowledge from the teacher's intermediate layer significantly\nimproves the recommendation quality of the student. However, they transfer the\nknowledge of individual representation point-wise and thus have a limitation in\nthat primary information of RS lies in the relations in the representation\nspace. This paper proposes a new topology distillation approach that guides the\nstudent by transferring the topological structure built upon the relations in\nthe teacher space. We first observe that simply making the student learn the\nwhole topological structure is not always effective and even degrades the\nstudent's performance. We demonstrate that because the capacity of the student\nis highly limited compared to that of the teacher, learning the whole\ntopological structure is daunting for the student. To address this issue, we\npropose a novel method named Hierarchical Topology Distillation (HTD) which\ndistills the topology hierarchically to cope with the large capacity gap. Our\nextensive experiments on real-world datasets show that the proposed method\nsignificantly outperforms the state-of-the-art competitors. We also provide\nin-depth analyses to ascertain the benefit of distilling the topology for RS.",
    "descriptor": "\nComments: KDD 2021. 9 pages + appendix (2 pages). 8 figures\n",
    "authors": [
      "SeongKu Kang",
      "Junyoung Hwang",
      "Wonbin Kweon",
      "Hwanjo Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.08700"
  },
  {
    "id": "arXiv:2106.08701",
    "title": "Universal and specific features of Ukrainian economic research:  publication analysis based on Crossref data",
    "abstract": "Our study is one of the first examples of multidimensional and longitudinal\ndisciplinary analysis at the national level based on Crossref data. We present\na large-scale quantitative analysis of Ukrainian economics. This study is not\nyet another example of research aimed at ranking of local journals, authors or\ninstitutions, but rather exploring general tendencies that can be compared to\nother countries or regions. We study different aspects of Ukrainian economics\noutput. In particular, the collaborative nature, geographic landscape and some\npeculiarities of citation statistics are investigated. We have found that\nUkrainian economics is characterized by a comparably small share of co-authored\npublications, however, it demonstrates the tendency towards more collaborative\noutput. Based on our analysis, we discuss specific and universal features of\nUkrainian economic research. The importance of supporting various initiatives\naimed at enriching open scholarly metadata is considered. A comprehensive and\nhigh-quality meta description of publications is probably the shortest path to\na better understanding of national trends, especially for non-English speaking\ncountries. The results of our analysis can be used to better understand\nUkrainian economic research and support research policy decisions.",
    "descriptor": "\nComments: This is the version of the Article before peer-review has taken place. The paper is submitted to \\textit{Scientometrics} journal, Manuscript Number: SCIM-D-21-00282R1\n",
    "authors": [
      "O. Mryglod",
      "S. Nazarovets",
      "S. Kozmenko"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.08701"
  },
  {
    "id": "arXiv:2106.08702",
    "title": "A Review of Lithium-Ion Battery Models in Techno-economic Analyses of  Power Systems",
    "abstract": "The penetration of the lithium-ion battery energy storage system (BESS) into\nthe power system environment occurs at a colossal rate worldwide. This is\nmainly because it is considered as one of the major tools to decarbonize,\ndigitalize, and democratize the electricity grid. The economic viability and\ntechnical reliability of projects with batteries require appropriate assessment\nbecause of high capital expenditures, deterioration in charging/discharging\nperformance and uncertainty with regulatory policies. Most of the power system\neconomic studies employ a simple power-energy representation coupled with an\nempirical description of degradation to model the lithium-ion battery. This\napproach to modelling may result in violations of the safe operation and\nmisleading estimates of the economic benefits. Recently, the number of\npublications on techno-economic analysis of BESS with more details on the\nlithium-ion battery performance has increased. The aim of this review paper is\nto explore these publications focused on the grid-scale BESS applications and\nto discuss the impacts of using more sophisticated modelling approaches. First,\nan overview of the three most popular battery models is given, followed by a\nreview of the applications of such models. The possible directions of future\nresearch of employing detailed battery models in power systems' techno-economic\nstudies are then explored.",
    "descriptor": "",
    "authors": [
      "Anton V. Vykhodtsev",
      "Darren Jang",
      "Qianpu Wang",
      "Hamidreza Zareipour",
      "William D. Rosehart"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08702"
  },
  {
    "id": "arXiv:2106.08703",
    "title": "Source Separation-based Data Augmentation for Improved Joint Beat and  Downbeat Tracking",
    "abstract": "Due to advances in deep learning, the performance of automatic beat and\ndownbeat tracking in musical audio signals has seen great improvement in recent\nyears. In training such deep learning based models, data augmentation has been\nfound an important technique. However, existing data augmentation methods for\nthis task mainly target at balancing the distribution of the training data with\nrespect to their tempo. In this paper, we investigate another approach for data\naugmentation, to account for the composition of the training data in terms of\nthe percussive and non-percussive sound sources. Specifically, we propose to\nemploy a blind drum separation model to segregate the drum and non-drum sounds\nfrom each training audio signal, filtering out training signals that are\ndrumless, and then use the obtained drum and non-drum stems to augment the\ntraining data. We report experiments on four completely unseen test sets,\nvalidating the effectiveness of the proposed method, and accordingly the\nimportance of drum sound composition in the training data for beat and downbeat\ntracking.",
    "descriptor": "\nComments: Accepted to European Signal Processing Conference (EUSIPCO 2021)\n",
    "authors": [
      "Ching-Yu Chiu",
      "Joann Ching",
      "Wen-Yi Hsiao",
      "Yu-Hua Chen",
      "Alvin Wen-Yu Su",
      "Yi-Hsuan Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.08703"
  },
  {
    "id": "arXiv:2106.08704",
    "title": "Memorization and Generalization in Neural Code Intelligence Models",
    "abstract": "Deep Neural Networks (DNN) are increasingly commonly used in software\nengineering and code intelligence tasks. These are powerful tools that are\ncapable of learning highly generalizable patterns from large datasets through\nmillions of parameters. At the same time, training DNNs means walking a knife's\nedges, because their large capacity also renders them prone to memorizing data\npoints. While traditionally thought of as an aspect of over-training, recent\nwork suggests that the memorization risk manifests especially strongly when the\ntraining datasets are noisy and memorization is the only recourse.\nUnfortunately, most code intelligence tasks rely on rather noise-prone and\nrepetitive data sources, such as GitHub, which, due to their sheer size, cannot\nbe manually inspected and evaluated. We evaluate the memorization and\ngeneralization tendencies in neural code intelligence models through a case\nstudy across several benchmarks and model families by leveraging established\napproaches from other fields that use DNNs, such as introducing targeted noise\ninto the training dataset. In addition to reinforcing prior general findings\nabout the extent of memorization in DNNs, our results shed light on the impact\nof noisy dataset in training.",
    "descriptor": "\nComments: manuscript in preparation\n",
    "authors": [
      "Md Rafiqul Islam Rabin",
      "Aftab Hussain",
      "Vincent J. Hellendoorn",
      "Mohammad Amin Alipour"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.08704"
  },
  {
    "id": "arXiv:2106.08708",
    "title": "The association between topic growth and citation impact of research  publications",
    "abstract": "Citations are used for research evaluation, and it is therefore important to\nknow which factors influence or associate with citation impact of articles.\nSeveral citation factors have been studied in the literature. In this study we\npropose a new factor, topic growth, that no previous study has taken into\nconsideration. The growth rate of topics may influence future citation counts,\nbecause a high growth in a topic means there are more publications citing\nprevious publications in that topic. We construct topics using community\ndetection in a citation network and use a two-part regression model is used to\nstudy the association between topic growth and citation counts in eight broad\ndisciplines. The first part of the model uses quantile regression to estimate\nthe effect of growth ratio on citation counts for publications with more than\nthree citations. The second part of the model uses logistic regression to model\nthe influence of the independent variables on the probability of being lowly\ncited versus being modestly or highly cited. Both models control for three\nvariables that may distort the association between the topic growth and\ncitations: journal impact, number of references, and number of authors. The\nregression model clearly shows that publications in fast-growing topics have a\ncitation advantage compared to publications in slow-growing or declining topics\nin all of the eight disciplines. Using citation indicators for research\nevaluation may give incentives for researchers to publish in fast-growing\ntopics, but they may cause research to be less diversified. The results have\nalso some implications for citation normalization.",
    "descriptor": "",
    "authors": [
      "Peter Sj\u00f6g\u00e5rde",
      "Fereshteh Didegah"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.08708"
  },
  {
    "id": "arXiv:2106.08710",
    "title": "Mobile Augmented Reality: User Interfaces, Frameworks, and Intelligence",
    "abstract": "Mobile Augmented Reality (MAR) integrates computer-generated virtual objects\nwith physical environments for mobile devices. MAR systems enable users to\ninteract with MAR devices, such as smartphones and head-worn wearables, and\nperforms seamless transitions from the physical world to a mixed world with\ndigital entities. These MAR systems support user experiences by using MAR\ndevices to provide universal accessibility to digital contents. Over the past\n20 years, a number of MAR systems have been developed, however, the studies and\ndesign of MAR frameworks have not yet been systematically reviewed from the\nperspective of user-centric design. This article presents the first effort of\nsurveying existing MAR frameworks (count: 37) and further discusses the latest\nstudies on MAR through a top-down approach: 1) MAR applications; 2) MAR\nvisualisation techniques adaptive to user mobility and contexts; 3) systematic\nevaluation of MAR frameworks including supported platforms and corresponding\nfeatures such as tracking, feature extraction plus sensing capabilities; and 4)\nunderlying machine learning approaches supporting intelligent operations within\nMAR systems. Finally, we summarise the development of emerging research fields,\ncurrent state-of-the-art, and discuss the important open challenges and\npossible theoretical and technical directions. This survey aims to benefit both\nresearchers and MAR system developers alike.",
    "descriptor": "\nComments: This work is currently under review in an international journal\n",
    "authors": [
      "Jacky Cao",
      "Kit-Yung Lam",
      "Lik-Hang Lee",
      "Xiaoli Liu",
      "Pan Hui",
      "Xiang Su"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08710"
  },
  {
    "id": "arXiv:2106.08712",
    "title": "Low-Rank Parity-Check Codes Over Finite Commutative Rings and  Application to Cryptography",
    "abstract": "Low-Rank Parity-Check (LRPC) codes are a class of rank metric codes that have\nmany applications specifically in cryptography. Recently, LRPC codes have been\nextended to Galois rings which are a specific case of finite rings. In this\npaper, we first define LRPC codes over finite commutative local rings, which\nare bricks of finite rings, with an efficient decoder and derive an upper bound\nof the failure probability together with the complexity of the decoder. We then\nextend the definition to arbitrary finite commutative rings and also provide a\ndecoder in this case. We end-up by introducing an application of the\ncorresponding LRPC codes to cryptography, together with the new corresponding\nmathematical problems.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Information Theory\n",
    "authors": [
      "Hermann Tchatchiem Kamche",
      "Herve Tale Kalachi",
      "Franck Rivel Kamwa Djomou",
      "Emmanuel Fouotsa"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.08712"
  },
  {
    "id": "arXiv:2106.08713",
    "title": "2nd Place Solution for Waymo Open Dataset Challenge - Real-time 2D  Object Detection",
    "abstract": "In an autonomous driving system, it is essential to recognize vehicles,\npedestrians and cyclists from images. Besides the high accuracy of the\nprediction, the requirement of real-time running brings new challenges for\nconvolutional network models. In this report, we introduce a real-time method\nto detect the 2D objects from images. We aggregate several popular one-stage\nobject detectors and train the models of variety input strategies\nindependently, to yield better performance for accurate multi-scale detection\nof each category, especially for small objects. For model acceleration, we\nleverage TensorRT to optimize the inference time of our detection pipeline. As\nshown in the leaderboard, our proposed detection framework ranks the 2nd place\nwith 75.00% L1 mAP and 69.72% L2 mAP in the real-time 2D detection track of the\nWaymo Open Dataset Challenges, while our framework achieves the latency of\n45.8ms/frame on an Nvidia Tesla V100 GPU.",
    "descriptor": "",
    "authors": [
      "Yueming Zhang",
      "Xiaolin Song",
      "Bing Bai",
      "Tengfei Xing",
      "Chao Liu",
      "Xin Gao",
      "Zhihui Wang",
      "Yawei Wen",
      "Haojin Liao",
      "Guoshan Zhang",
      "Pengfei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08713"
  },
  {
    "id": "arXiv:2106.08714",
    "title": "Numerical Stability of Tangents and Adjoints of Implicit Functions",
    "abstract": "We investigate errors in tangents and adjoints of implicit functions\nresulting from errors in the primal solution due to approximations computed by\na numerical solver.\nAdjoints of systems of linear equations turn out to be unconditionally\nnumerically stable. Tangents of systems of linear equations can become instable\nas well as both tangents and adjoints of systems of nonlinear equations, which\nextends to optima of convex unconstrained objectives. Sufficient conditions for\nnumerical stability are derived.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Uwe Naumann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08714"
  },
  {
    "id": "arXiv:2106.08717",
    "title": "Probabilistic DAG Search",
    "abstract": "Exciting contemporary machine learning problems have recently been phrased in\nthe classic formalism of tree search -- most famously, the game of Go.\nInterestingly, the state-space underlying these sequential decision-making\nproblems often posses a more general latent structure than can be captured by a\ntree. In this work, we develop a probabilistic framework to exploit a search\nspace's latent structure and thereby share information across the search tree.\nThe method is based on a combination of approximate inference in jointly\nGaussian models for the explored part of the problem, and an abstraction for\nthe unexplored part that imposes a reduction of complexity ad hoc. We\nempirically find our algorithm to compare favorably to existing\nnon-probabilistic alternatives in Tic-Tac-Toe and a feature selection\napplication.",
    "descriptor": "\nComments: 10 pages, 8 figures, to be published at the Conference on Uncertainty in Artificial Intelligence (UAI) 2021\n",
    "authors": [
      "Julia Grosse",
      "Cheng Zhang",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08717"
  },
  {
    "id": "arXiv:2106.08720",
    "title": "Predicting crop yields with little ground truth: A simple statistical  model for in-season forecasting",
    "abstract": "We present a fully automated model for in-season crop yield prediction,\ndesigned to work where there is a dearth of sub-national \"ground truth\"\ninformation. Our approach relies primarily on satellite data and is\ncharacterized by careful feature engineering combined with a simple regression\nmodel. As such, it can work almost anywhere in the world. Applying it to 10\ndifferent crop-country pairs (5 cereals -- corn, wheat, sorghum, barley and\nmillet, in 2 countries -- Ethiopia and Kenya), we achieve RMSEs of 5\\%-10\\% for\npredictions 9 months into the year, and 7\\%-14\\% for predictions 3 months into\nthe year. The model outputs daily forecasts for the final yield of the current\nyear. It is trained using approximately 4 million data points for each\ncrop-country pair. These consist of: historical country-level annual yields,\ncrop calendars, crop cover, NDVI, temperature, rainfall, and\nevapotransporation.",
    "descriptor": "",
    "authors": [
      "Nemo Semret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08720"
  },
  {
    "id": "arXiv:2106.08723",
    "title": "Coreference Augmentation for Multi-Domain Task-Oriented Dialogue State  Tracking",
    "abstract": "Dialogue State Tracking (DST), which is the process of inferring user goals\nby estimating belief states given the dialogue history, plays a critical role\nin task-oriented dialogue systems. A coreference phenomenon observed in\nmulti-turn conversations is not addressed by existing DST models, leading to\nsub-optimal performances. In this paper, we propose Coreference Dialogue State\nTracker (CDST) that explicitly models the coreference feature. In particular,\nat each turn, the proposed model jointly predicts the coreferred domain-slot\npair and extracts the coreference values from the dialogue context.\nExperimental results on MultiWOZ 2.1 dataset show that the proposed model\nachieves the state-of-the-art joint goal accuracy of 56.47%.",
    "descriptor": "\nComments: Accepted by Interspeech2021\n",
    "authors": [
      "Ting Han",
      "Chongxuan Huang",
      "Wei Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08723"
  },
  {
    "id": "arXiv:2106.08727",
    "title": "AtrialGeneral: Domain Generalization for Left Atrial Segmentation of  Multi-Center LGE MRIs",
    "abstract": "Left atrial (LA) segmentation from late gadolinium enhanced magnetic\nresonance imaging (LGE MRI) is a crucial step needed for planning the treatment\nof atrial fibrillation. However, automatic LA segmentation from LGE MRI is\nstill challenging, due to the poor image quality, high variability in LA\nshapes, and unclear LA boundary. Though deep learning-based methods can provide\npromising LA segmentation results, they often generalize poorly to unseen\ndomains, such as data from different scanners and/or sites. In this work, we\ncollect 210 LGE MRIs from different centers with different levels of image\nquality. To evaluate the domain generalization ability of models on the LA\nsegmentation task, we employ four commonly used semantic segmentation networks\nfor the LA segmentation from multi-center LGE MRIs. Besides, we investigate\nthree domain generalization strategies, i.e., histogram matching, mutual\ninformation based disentangled representation, and random style transfer, where\na simple histogram matching is proved to be most effective.",
    "descriptor": "\nComments: 10 pages, 4 figures, MICCAI2021\n",
    "authors": [
      "Lei Li",
      "Veronika A. Zimmer",
      "Julia A. Schnabel",
      "Xiahai Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08727"
  },
  {
    "id": "arXiv:2106.08729",
    "title": "Modeling and Accomplishing the BEREC Network Neutrality Policy",
    "abstract": "Network neutrality (NN) is a principle of equal treatment of data in network\ninfrastructures with fairness and universality being the primary outcomes of\nthe NN management practice. For networks, the accomplishment of NN management\npractice is essential to deal with heterogeneous user requirements and the\never-increasing data traffic. Current tools and methods address the NN problem\nby detecting network neutrality violations and detecting traffic\ndifferentiation. This paper proposes the NN-PCM (Network Neutrality Policy\nConformance Module) that deploys the BEREC network neutrality policy using a\nbandwidth allocation model (BAM). The NN-PCM new approach allocates bandwidth\nto network users and accomplishes the BEREC NN policy concomitantly. Network\nneutrality is achieved by grouping users with similar traffic requirements in\nclasses and leveraging the bandwidth allocation model's characteristics. The\nconceptual analysis and simulation results indicate that NN-PCM allocates\nbandwidth to users and accomplishes BEREC network neutrality conformance by\ndesign with transparent, non-discriminatory, exceptional, and proportional\nmanagement practices.",
    "descriptor": "\nComments: 17 pages, 8 figures, IJNM preprint\n",
    "authors": [
      "David S. Barreto",
      "Rafael F. Reale",
      "Joberto S. B. Martins"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computers and Society (cs.CY)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2106.08729"
  },
  {
    "id": "arXiv:2106.08732",
    "title": "AMA-GCN: Adaptive Multi-layer Aggregation Graph Convolutional Network  for Disease Prediction",
    "abstract": "Recently, Graph Convolutional Networks (GCNs) have proven to be a powerful\nmean for Computer Aided Diagnosis (CADx). This approach requires building a\npopulation graph to aggregate structural information, where the graph adjacency\nmatrix represents the relationship between nodes. Until now, this adjacency\nmatrix is usually defined manually based on phenotypic information. In this\npaper, we propose an encoder that automatically selects the appropriate\nphenotypic measures according to their spatial distribution, and uses the text\nsimilarity awareness mechanism to calculate the edge weights between nodes. The\nencoder can automatically construct the population graph using phenotypic\nmeasures which have a positive impact on the final results, and further\nrealizes the fusion of multimodal information. In addition, a novel graph\nconvolution network architecture using multi-layer aggregation mechanism is\nproposed. The structure can obtain deep structure information while suppressing\nover-smooth, and increase the similarity between the same type of nodes.\nExperimental results on two databases show that our method can significantly\nimprove the diagnostic accuracy for Autism spectrum disorder and breast cancer,\nindicating its universality in leveraging multimodal data for disease\nprediction.",
    "descriptor": "",
    "authors": [
      "Hao Chen",
      "Fuzhen Zhuang",
      "Li Xiao",
      "Ling Ma",
      "Haiyan Liu",
      "Ruifang Zhang",
      "Huiqin Jiang",
      "Qing He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08732"
  },
  {
    "id": "arXiv:2106.08737",
    "title": "Benefits, Challenges and Contributors to Success for National eHealth  Systems Implementation: A Scoping Review",
    "abstract": "Our scoping review aims to assess what legal, ethical, and socio-technical\nfactors contribute or inhibit the success of national eHealth system\nimplementations. In addition, our review seeks to describe the characteristics\nand benefits of eHealth systems. We conducted a scoping review of literature\npublished in English between January 2000 and 2020 using a keyword search on\nfive databases; PubMed, Scopus, Web of Science, IEEEXplore, and ProQuest. After\nremoval of duplicates, abstract screening and full-text filtering, 86 articles\nwere included from 8276 search results. We identified 17 stakeholder groups, 6\neHealth Systems areas, and 15 types of legal regimes and standards. In-depth\ntextual analysis revealed challenges mainly in implementation, followed by\nethico-legal and data related aspects. Key factors influencing success include\npromoting trust of the system, ensuring wider acceptance amongst users,\nreconciling the system with legal requirements and ensuring an adaptable\ntechnical platform. Results revealed support for decentralised implementations\nbecause they carry less implementation and engagement challenges than\ncentralised ones. Simultaneously, due to decentralised systems interoperability\nissues, federated implementations (with a set of national standards) might be\npreferable. This study identifies the primary socio-technical, legal and\nethical factors that challenge and contribute to the success of eHealth system\nimplementations. This study also describes the complexities and characteristics\nof existing eHealth implementation programs, and surmises suggested guidance\nfor resolving the identified challenges.",
    "descriptor": "\nComments: 28 pages, 4 figures, 2 tables\n",
    "authors": [
      "James Scheibner",
      "Marcello Ienca",
      "Joanna Sleigh",
      "Effy Vayena"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.08737"
  },
  {
    "id": "arXiv:2106.08740",
    "title": "The DEWCAD Project: Pushing Back the Doubly Exponential Wall of  Cylindrical Algebraic Decomposition",
    "abstract": "This abstract seeks to introduce the ISSAC community to the DEWCAD project,\nwhich is based at Coventry University and the University of Bath, in the United\nKingdom. The project seeks to push back the Doubly Exponential Wall of\nCylindrical Algebraic Decomposition, through the integration of SAT/SMT\ntechnology, the extension of Lazard projection theory, and the development of\nnew algorithms based on CAD technology but without producing CADs themselves.\nThe project also seeks to develop applications of CAD and will focus on\napplications in the domains of economics and bio-network analysis.",
    "descriptor": "\nComments: 5 pages. Accepted as short communication at ISSAC 2021\n",
    "authors": [
      "R. Bradford",
      "J.H. Davenport",
      "M. England",
      "A. Sadeghimanesh",
      "A.Uncu"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2106.08740"
  },
  {
    "id": "arXiv:2106.08746",
    "title": "Real-time Attacks Against Deep Reinforcement Learning Policies",
    "abstract": "Recent work has discovered that deep reinforcement learning (DRL) policies\nare vulnerable to adversarial examples. These attacks mislead the policy of DRL\nagents by perturbing the state of the environment observed by agents. They are\nfeasible in principle but too slow to fool DRL policies in real time. We\npropose a new attack to fool DRL policies that is both effective and efficient\nenough to be mounted in real time. We utilize the Universal Adversarial\nPerturbation (UAP) method to compute effective perturbations independent of the\nindividual inputs to which they are applied. Via an extensive evaluation using\nAtari 2600 games, we show that our technique is effective, as it fully degrades\nthe performance of both deterministic and stochastic policies (up to 100%, even\nwhen the $l_\\infty$ bound on the perturbation is as small as 0.005). We also\nshow that our attack is efficient, incurring an online computational cost of\n0.027ms on average. It is faster compared to the response time (0.6ms on\naverage) of agents with different DRL policies, and considerably faster than\nprior attacks (2.7ms on average). Furthermore, we demonstrate that known\ndefenses are ineffective against universal perturbations. We propose an\neffective detection technique which can form the basis for robust defenses\nagainst attacks based on universal perturbations.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Buse G.A. Tekgul",
      "Shelly Wang",
      "Samuel Marchal",
      "N. Asokan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08746"
  },
  {
    "id": "arXiv:2106.08747",
    "title": "Towards Optimally Weighted Physics-Informed Neural Networks in Ocean  Modelling",
    "abstract": "The carbon pump of the world's ocean plays a vital role in the biosphere and\nclimate of the earth, urging improved understanding of the functions and\ninfluences of the ocean for climate change analyses. State-of-the-art\ntechniques are required to develop models that can capture the complexity of\nocean currents and temperature flows. This work explores the benefits of using\nphysics-informed neural networks (PINNs) for solving partial differential\nequations related to ocean modeling; such as the Burgers, wave, and\nadvection-diffusion equations. We explore the trade-offs of using data vs.\nphysical models in PINNs for solving partial differential equations. PINNs\naccount for the deviation from physical laws in order to improve learning and\ngeneralization. We observed how the relative weight between the data and\nphysical model in the loss function influence training results, where small\ndata sets benefit more from the added physics information.",
    "descriptor": "",
    "authors": [
      "Taco de Wolff",
      "Hugo Carrillo",
      "Luis Mart{\u00ed}",
      "Nayat Sanchez-Pi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08747"
  },
  {
    "id": "arXiv:2106.08748",
    "title": "Input Invex Neural Network",
    "abstract": "In this paper, we present a novel method to constrain invexity on Neural\nNetworks (NN). Invex functions ensure every stationary point is global minima.\nHence, gradient descent commenced from any point will lead to the global\nminima. Another advantage of invexity on NN is to divide data space locally\ninto two connected sets with a highly non-linear decision boundary by simply\nthresholding the output. To this end, we formulate a universal invex function\napproximator and employ it to enforce invexity in NN. We call it Input Invex\nNeural Networks (II-NN). We first fit data with a known invex function,\nfollowed by modification with a NN, compare the direction of the gradient and\npenalize the direction of gradient on NN if it contradicts with the direction\nof reference invex function. In order to penalize the direction of the gradient\nwe perform Gradient Clipped Gradient Penalty (GC-GP). We applied our method to\nthe existing NNs for both image classification and regression tasks. From the\nextensive empirical and qualitative experiments, we observe that our method\ngives the performance similar to ordinary NN yet having invexity. Our method\noutperforms linear NN and Input Convex Neural Network (ICNN) with a large\nmargin. We publish our code and implementation details at github.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Suman Sapkota",
      "Binod Bhattarai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08748"
  },
  {
    "id": "arXiv:2106.08749",
    "title": "Learning to Disentangle GAN Fingerprint for Fake Image Attribution",
    "abstract": "Rapid pace of generative models has brought about new threats to visual\nforensics such as malicious personation and digital copyright infringement,\nwhich promotes works on fake image attribution. Existing works on fake image\nattribution mainly rely on a direct classification framework. Without\nadditional supervision, the extracted features could include many\ncontent-relevant components and generalize poorly. Meanwhile, how to obtain an\ninterpretable GAN fingerprint to explain the decision remains an open question.\nAdopting a multi-task framework, we propose a GAN Fingerprint Disentangling\nNetwork (GFD-Net) to simultaneously disentangle the fingerprint from\nGAN-generated images and produce a content-irrelevant representation for fake\nimage attribution. A series of constraints are provided to guarantee the\nstability and discriminability of the fingerprint, which in turn helps\ncontent-irrelevant feature extraction. Further, we perform comprehensive\nanalysis on GAN fingerprint, providing some clues about the properties of GAN\nfingerprint and which factors dominate the fingerprint in GAN architecture.\nExperiments show that our GFD-Net achieves superior fake image attribution\nperformance in both closed-world and open-world testing. We also apply our\nmethod in binary fake image detection and exhibit a significant generalization\nability on unseen generators.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Tianyun Yang",
      "Juan Cao",
      "Qiang Sheng",
      "Lei Li",
      "Jiaqi Ji",
      "Xirong Li",
      "Sheng Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08749"
  },
  {
    "id": "arXiv:2106.08752",
    "title": "Unsupervised Domain Adaptation with Variational Approximation for  Cardiac Segmentation",
    "abstract": "Unsupervised domain adaptation is useful in medical image segmentation.\nParticularly, when ground truths of the target images are not available, domain\nadaptation can train a target-specific model by utilizing the existing labeled\nimages from other modalities. Most of the reported works mapped images of both\nthe source and target domains into a common latent feature space, and then\nreduced their discrepancy either implicitly with adversarial training or\nexplicitly by directly minimizing a discrepancy metric. In this work, we\npropose a new framework, where the latent features of both domains are driven\ntowards a common and parameterized variational form, whose conditional\ndistribution given the image is Gaussian. This is achieved by two networks\nbased on variational auto-encoders (VAEs) and a regularization for this\nvariational approximation. Both of the VAEs, each for one domain, contain a\nsegmentation module, where the source segmentation is trained in a supervised\nmanner, while the target one is trained unsupervisedly. We validated the\nproposed domain adaptation method using two cardiac segmentation tasks, i.e.,\nthe cross-modality (CT and MR) whole heart segmentation and the cross-sequence\ncardiac MR segmentation. Results show that the proposed method achieved better\naccuracies compared to two state-of-the-art approaches and demonstrated good\npotential for cardiac segmentation. Furthermore, the proposed explicit\nregularization was shown to be effective and efficient in narrowing down the\ndistribution gap between domains, which is useful for unsupervised domain\nadaptation. Our code and data has been released via\nhttps://zmiclab.github.io/projects.html.",
    "descriptor": "\nComments: accepted by IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Fuping Wu",
      "Xiahai Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08752"
  },
  {
    "id": "arXiv:2106.08756",
    "title": "Automating Augmentation Through Random Unidimensional Search",
    "abstract": "It is no secret amongst deep learning researchers that finding the right data\naugmentation strategy during training can mean the difference between a\nstate-of-the-art result and a run-of-the-mill ranking. To that end, the\ncommunity has seen many efforts to automate the process of finding the perfect\naugmentation procedure for any task at hand. Unfortunately, even recent\ncutting-edge methods bring massive computational overhead, requiring as many as\n100 full model trainings to settle on an ideal configuration. We show how to\nachieve even better performance in just 7: with Random Unidimensional\nAugmentation. Source code is available at https://github.com/fastestimator/RUA",
    "descriptor": "",
    "authors": [
      "Xiaomeng Dong",
      "Michael Potter",
      "Gaurav Kumar",
      "Yun-Chan Tsai",
      "V. Ratna Saripalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08756"
  },
  {
    "id": "arXiv:2106.08759",
    "title": "OpenSSLNTRU: Faster post-quantum TLS key exchange",
    "abstract": "Google's CECPQ1 experiment in 2016 integrated a post-quantum key-exchange\nalgorithm, newhope1024, into TLS 1.2. The Google-Cloudflare CECPQ2 experiment\nin 2019 integrated a more efficient key-exchange algorithm, ntruhrss701, into\nTLS 1.3.\nThis paper revisits the choices made in CECPQ2, and shows how to achieve\nhigher performance for post-quantum key exchange in TLS 1.3 using a\nhigher-security algorithm, sntrup761. Previous work had indicated that\nntruhrss701 key generation was much faster than sntrup761 key generation, but\nthis paper makes sntrup761 key generation much faster by generating a batch of\nkeys at once.\nBatch key generation is invisible at the TLS protocol layer, but raises\nsoftware-engineering questions regarding the difficulty of integrating batch\nkey exchange into existing TLS libraries and applications. This paper shows\nthat careful choices of software layers make it easy to integrate fast\npost-quantum software, including batch key exchange, into TLS with minor\nchanges to TLS libraries and no changes to applications.\nAs a demonstration of feasibility, this paper reports successful integration\nof its fast sntrup761 library, via a lightly patched OpenSSL, into an\nunmodified web browser and an unmodified TLS terminator. This paper also\nreports TLS 1.3 handshake benchmarks, achieving more TLS 1.3 handshakes per\nsecond than any software included in OpenSSL.",
    "descriptor": "",
    "authors": [
      "Daniel J. Bernstein",
      "Billy Bob Brumley",
      "Ming-Shing Chen",
      "Nicola Tuveri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08759"
  },
  {
    "id": "arXiv:2106.08761",
    "title": "Toward Affective XAI: Facial Affect Analysis for Understanding  Explainable Human-AI Interactions",
    "abstract": "As machine learning approaches are increasingly used to augment human\ndecision-making, eXplainable Artificial Intelligence (XAI) research has\nexplored methods for communicating system behavior to humans. However, these\napproaches often fail to account for the emotional responses of humans as they\ninteract with explanations. Facial affect analysis, which examines human facial\nexpressions of emotions, is one promising lens for understanding how users\nengage with explanations. Therefore, in this work, we aim to (1) identify which\nfacial affect features are pronounced when people interact with XAI interfaces,\nand (2) develop a multitask feature embedding for linking facial affect signals\nwith participants' use of explanations. Our analyses and results show that the\noccurrence and values of facial AU1 and AU4, and Arousal are heightened when\nparticipants fail to use explanations effectively. This suggests that facial\naffect analysis should be incorporated into XAI to personalize explanations to\nindividuals' interaction styles and to adapt explanations based on the\ndifficulty of the task performed.",
    "descriptor": "",
    "authors": [
      "Luke Guerdan",
      "Alex Raymond",
      "Hatice Gunes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.08761"
  },
  {
    "id": "arXiv:2106.08762",
    "title": "Shape from Blur: Recovering Textured 3D Shape and Motion of Fast Moving  Objects",
    "abstract": "We address the novel task of jointly reconstructing the 3D shape, texture,\nand motion of an object from a single motion-blurred image. While previous\napproaches address the deblurring problem only in the 2D image domain, our\nproposed rigorous modeling of all object properties in the 3D domain enables\nthe correct description of arbitrary object motion. This leads to significantly\nbetter image decomposition and sharper deblurring results. We model the\nobserved appearance of a motion-blurred object as a combination of the\nbackground and a 3D object with constant translation and rotation. Our method\nminimizes a loss on reconstructing the input image via differentiable rendering\nwith suitable regularizers. This enables estimating the textured 3D mesh of the\nblurred object with high fidelity. Our method substantially outperforms\ncompeting approaches on several benchmarks for fast moving objects deblurring.\nQualitative results show that the reconstructed 3D mesh generates high-quality\ntemporal super-resolution and novel views of the deblurred object.",
    "descriptor": "\nComments: 15 pages, 8 figures, 2 tables\n",
    "authors": [
      "Denys Rozumnyi",
      "Martin R. Oswald",
      "Vittorio Ferrari",
      "Marc Pollefeys"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08762"
  },
  {
    "id": "arXiv:2106.08767",
    "title": "To Raise or Not To Raise: The Autonomous Learning Rate Question",
    "abstract": "There is a parameter ubiquitous throughout the deep learning world: learning\nrate. There is likewise a ubiquitous question: what should that learning rate\nbe? The true answer to this question is often tedious and time consuming to\nobtain, and a great deal of arcane knowledge has accumulated in recent years\nover how to pick and modify learning rates to achieve optimal training\nperformance. Moreover, the long hours spent carefully crafting the perfect\nlearning rate can come to nothing the moment your network architecture,\noptimizer, dataset, or initial conditions change ever so slightly. But it need\nnot be this way. We propose a new answer to the great learning rate question:\nthe Autonomous Learning Rate Controller. Find it at\nhttps://github.com/fastestimator/ARC",
    "descriptor": "",
    "authors": [
      "Xiaomeng Dong",
      "Tao Tan",
      "Michael Potter",
      "Yun-Chan Tsai",
      "Gaurav Kumar",
      "V. Ratna Saripalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08767"
  },
  {
    "id": "arXiv:2106.08769",
    "title": "Knowledge-Adaptation Priors",
    "abstract": "Humans and animals have a natural ability to quickly adapt to their\nsurroundings, but machine-learning models, when subjected to changes, often\nrequire a complete retraining from scratch. We present Knowledge-adaptation\npriors (K-priors) to reduce the cost of retraining by enabling quick and\naccurate adaptation for a wide-variety of tasks and models. This is made\npossible by a combination of weight and function-space priors to reconstruct\nthe gradients of the past, which recovers and generalizes many existing, but\nseemingly-unrelated, adaptation strategies. Training with simple first-order\ngradient methods can often recover the exact retrained model to an arbitrary\naccuracy by choosing a sufficiently large memory of the past data. Empirical\nresults confirm that the adaptation can be cheap and accurate, and a promising\nalternative to retraining.",
    "descriptor": "",
    "authors": [
      "Mohammad Emtiyaz Khan",
      "Siddharth Swaroop"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08769"
  },
  {
    "id": "arXiv:2106.08770",
    "title": "TSSuBERT: Tweet Stream Summarization Using BERT",
    "abstract": "The development of deep neural networks and the emergence of pre-trained\nlanguage models such as BERT allow to increase performance on many NLP tasks.\nHowever, these models do not meet the same popularity for tweet summarization,\nwhich can probably be explained by the lack of existing collections for\ntraining and evaluation. Our contribution in this paper is twofold : (1) we\nintroduce a large dataset for Twitter event summarization, and (2) we propose a\nneural model to automatically summarize huge tweet streams. This extractive\nmodel combines in an original way pre-trained language models and vocabulary\nfrequency-based representations to predict tweet salience. An additional\nadvantage of the model is that it automatically adapts the size of the output\nsummary according to the input tweet stream. We conducted experiments using two\ndifferent Twitter collections, and promising results are observed in comparison\nwith state-of-the-art baselines.",
    "descriptor": "\nComments: UNDER SUBMISSION\n",
    "authors": [
      "Alexis Dusart",
      "Karen Pinel-Sauvagnat",
      "Gilles Hubert"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.08770"
  },
  {
    "id": "arXiv:2106.08771",
    "title": "Reinforcement Learning for Markovian Bandits: Is Posterior Sampling more  Scalable than Optimism?",
    "abstract": "We study learning algorithms for the classical Markovian bandit problem with\ndiscount. We explain how to adapt PSRL [24] and UCRL2 [2] to exploit the\nproblem structure. These variants are called MB-PSRL and MB-UCRL2. While the\nregret bound and runtime of vanilla implementations of PSRL and UCRL2 are\nexponential in the number of bandits, we show that the episodic regret of\nMB-PSRL and MB-UCRL2 is\u00d5(S $\\sqrt$ nK) where K is the number of episodes, n is\nthe number of bandits and S is the number of states of each bandit (the exact\nbound in S, n and K is given in the paper). Up to a factor $\\sqrt$ S, this\nmatches the lower bound of $\\Omega$($\\sqrt$ SnK) that we also derive in the\npaper. MB-PSRL is also computationally efficient: its runtime is linear in the\nnumber of bandits. We further show that this linear runtime cannot be achieved\nby adapting classical non-Bayesian algorithms such as UCRL2 or UCBVI to\nMarkovian bandit problems. Finally, we perform numerical experiments that\nconfirm that MB-PSRL outperforms other existing algorithms in practice, both in\nterms of regret and of computation time.",
    "descriptor": "",
    "authors": [
      "Nicolas Gast",
      "Bruno Gaujal",
      "Kimang Khun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08771"
  },
  {
    "id": "arXiv:2106.08773",
    "title": "Persistent Excitation is Unnecessary for On-line Exponential Parameter  Estimation: A New Algorithm that Overcomes this Obstacle",
    "abstract": "In this paper, we prove that it is possible to estimate online the parameters\nof a classical vector linear regression equation $ Y=\\Omega \\theta$, where $ Y\n\\in \\mathbb{R}^n,\\;\\Omega \\in \\mathbb{R}^{n \\times q}$ are bounded, measurable\nsignals and $\\theta \\in \\mathbb{R}^q$ is a constant vector of unknown\nparameters, even when the regressor $\\Omega$ is not persistently exciting.\nMoreover, the convergence of the new parameter estimator is global and\nexponential and is given for both continuous-time and discrete-time\nimplementations. As an illustration example, we consider the problem of\nparameter estimation of a linear time-invariant system, when the input signal\nis not sufficiently exciting, which is known to be a necessary and sufficient\ncondition for the solution of the problem with the standard gradient or\nleast-squares adaptation algorithms.",
    "descriptor": "\nComments: submitted to System and Control Letters\n",
    "authors": [
      "Marina Korotina",
      "Jose Guadalupe Romero",
      "Stanislav Aranovskiy",
      "Alexey Bobtsov",
      "Romeo Ortega"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08773"
  },
  {
    "id": "arXiv:2106.08774",
    "title": "Analysis and Optimisation of Bellman Residual Errors with Neural  Function Approximation",
    "abstract": "Recent development of Deep Reinforcement Learning has demonstrated superior\nperformance of neural networks in solving challenging problems with large or\neven continuous state spaces. One specific approach is to deploy neural\nnetworks to approximate value functions by minimising the Mean Squared Bellman\nError function. Despite great successes of Deep Reinforcement Learning,\ndevelopment of reliable and efficient numerical algorithms to minimise the\nBellman Error is still of great scientific interest and practical demand. Such\na challenge is partially due to the underlying optimisation problem being\nhighly non-convex or using incorrect gradient information as done in\nSemi-Gradient algorithms. In this work, we analyse the Mean Squared Bellman\nError from a smooth optimisation perspective combined with a Residual Gradient\nformulation. Our contribution is two-fold.\nFirst, we analyse critical points of the error function and provide technical\ninsights on the optimisation procure and design choices for neural networks.\nWhen the existence of global minima is assumed and the objective fulfils\ncertain conditions we can eliminate suboptimal local minima when using\nover-parametrised neural networks. We can construct an efficient Approximate\nNewton's algorithm based on our analysis and confirm theoretical properties of\nthis algorithm such as being locally quadratically convergent to a global\nminimum numerically.\nSecond, we demonstrate feasibility and generalisation capabilities of the\nproposed algorithm empirically using continuous control problems and provide a\nnumerical verification of our critical point analysis. We outline the short\ncoming of Semi-Gradients. To benefit from an approximate Newton's algorithm\ncomplete derivatives of the Mean Squared Bellman error must be considered\nduring training.",
    "descriptor": "\nComments: 29 pages, 8 figures\n",
    "authors": [
      "Martin Gottwald",
      "Sven Gronauer",
      "Hao Shen",
      "Klaus Diepold"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08774"
  },
  {
    "id": "arXiv:2106.08777",
    "title": "Manifolds.jl: An Extensible Julia Framework for Data Analysis on  Manifolds",
    "abstract": "For data given on a nonlinear space, like angles, symmetric positive\nmatrices, the sphere, or the hyperbolic space, there is often enough structure\nto form a Riemannian manifold. We present the Julia package Manifolds.jl,\nproviding a fast and easy to use library of Riemannian manifolds and Lie\ngroups. We introduce a common interface, available in ManifoldsBase.jl, with\nwhich new manifolds, applications, and algorithms can be implemented. We\ndemonstrate the utility of Manifolds.jl using B\\'ezier splines, an optimization\ntask on manifolds, and a principal component analysis on nonlinear data. In a\nbenchmark, Manifolds.jl outperforms existing packages in Matlab or Python by\nseveral orders of magnitude and is about twice as fast as a comparable package\nimplemented in C++.",
    "descriptor": "",
    "authors": [
      "Seth D. Axen",
      "Mateusz Baran",
      "Ronny Bergmann",
      "Krzysztof Rzecki"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2106.08777"
  },
  {
    "id": "arXiv:2106.08779",
    "title": "Comparison of Outlier Detection Techniques for Structured Data",
    "abstract": "An outlier is an observation or a data point that is far from rest of the\ndata points in a given dataset or we can be said that an outlier is away from\nthe center of mass of observations. Presence of outliers can skew statistical\nmeasures and data distributions which can lead to misleading representation of\nthe underlying data and relationships. It is seen that the removal of outliers\nfrom the training dataset before modeling can give better predictions. With the\nadvancement of machine learning, the outlier detection models are also\nadvancing at a good pace. The goal of this work is to highlight and compare\nsome of the existing outlier detection techniques for the data scientists to\nuse that information for outlier algorithm selection while building a machine\nlearning model.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Amulya Agarwal",
      "Nitin Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08779"
  },
  {
    "id": "arXiv:2106.08785",
    "title": "SEOVER: Sentence-level Emotion Orientation Vector based Conversation  Emotion Recognition Model",
    "abstract": "For the task of conversation emotion recognition, recent works focus on\nspeaker relationship modeling but ignore the role of utterance's emotional\ntendency.In this paper, we propose a new expression paradigm of sentence-level\nemotion orientation vector to model the potential correlation of emotions\nbetween sentence vectors. Based on it, we design an emotion recognition model,\nwhich extracts the sentence-level emotion orientation vectors from the language\nmodel and jointly learns from the dialogue sentiment analysis model and\nextracted sentence-level emotion orientation vectors to identify the speaker's\nemotional orientation during the conversation. We conduct experiments on two\nbenchmark datasets and compare them with the five baseline models.The\nexperimental results show that our model has better performance on all data\nsets.",
    "descriptor": "",
    "authors": [
      "Zaijing Li",
      "Fengxiao Tang",
      "Tieyu Sun",
      "Yusen Zhu",
      "Ming Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08785"
  },
  {
    "id": "arXiv:2106.08792",
    "title": "Reflector Antennas Characterization and Diagnostics using a Single Set  of Far Field Phaseless Data and Crosswords-like Processing",
    "abstract": "We introduce and discuss a new approach to the phase retrieval of fields\nradiated by continuous aperture sources having a circular support, which is of\ninterest in many applications including the detection of shape deformations on\nreflector antennas. The approach is based on a decomposition of the actual 2-D\nproblem into a number of 1-D phase retrieval problems along diameters and\nconcentric rings of the visible part of the spectrum. In particular, the 1-D\nproblems are effectively solved by using the spectral factorization method,\nwhile discrimination arguments at the crossing points allows to complete the\nretrieval of the 2-D complex field. The proposed procedure, which just requires\na single set of far field amplitudes, takes advantage from up to now unexplored\nfield properties and it is assessed in terms of reflector aperture fields.",
    "descriptor": "",
    "authors": [
      "R. Palmeri",
      "G. M. Battaglia",
      "A. F. Morabito",
      "T. Isernia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.08792"
  },
  {
    "id": "arXiv:2106.08795",
    "title": "Robustness of Object Detectors in Degrading Weather Conditions",
    "abstract": "State-of-the-art object detection systems for autonomous driving achieve\npromising results in clear weather conditions. However, such autonomous safety\ncritical systems also need to work in degrading weather conditions, such as\nrain, fog and snow. Unfortunately, most approaches evaluate only on the KITTI\ndataset, which consists only of clear weather scenes. In this paper we address\nthis issue and perform one of the most detailed evaluation on single and dual\nmodality architectures on data captured in real weather conditions. We analyse\nthe performance degradation of these architectures in degrading weather\nconditions. We demonstrate that an object detection architecture performing\ngood in clear weather might not be able to handle degrading weather conditions.\nWe also perform ablation studies on the dual modality architectures and show\ntheir limitations.",
    "descriptor": "\nComments: Accepted for publication at ITSC 2021\n",
    "authors": [
      "Muhammad Jehanzeb Mirza",
      "Cornelius Buerkle",
      "Julio Jarquin",
      "Michael Opitz",
      "Fabian Oboril",
      "Kay-Ulrich Scholl",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08795"
  },
  {
    "id": "arXiv:2106.08796",
    "title": "Optical Tactile Sim-to-Real Policy Transfer via Real-to-Sim Tactile  Image Translation",
    "abstract": "Simulation has recently become key for deep reinforcement learning to safely\nand efficiently acquire general and complex control policies from visual and\nproprioceptive inputs. Tactile information is not usually considered despite\nits direct relation to environment interaction. In this work, we present a\nsuite of simulated environments tailored towards tactile robotics and\nreinforcement learning. A simple and fast method of simulating optical tactile\nsensors is provided, where high-resolution contact geometry is represented as\ndepth images. Proximal Policy Optimisation (PPO) is used to learn successful\npolicies across all considered tasks. A data-driven approach enables\ntranslation of the current state of a real tactile sensor to corresponding\nsimulated depth images. This policy is implemented within a real-time control\nloop on a physical robot to demonstrate zero-shot sim-to-real policy transfer\non several physically-interactive tasks requiring a sense of touch.",
    "descriptor": "",
    "authors": [
      "Alex Church",
      "John Lloyd",
      "Raia Hadsell",
      "Nathan F. Lepora"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08796"
  },
  {
    "id": "arXiv:2106.08798",
    "title": "Unsupervised Person Re-identification via Multi-Label Prediction and  Classification based on Graph-Structural Insight",
    "abstract": "This paper addresses unsupervised person re-identification (Re-ID) using\nmulti-label prediction and classification based on graph-structural insight.\nOur method extracts features from person images and produces a graph that\nconsists of the features and a pairwise similarity of them as nodes and edges,\nrespectively. Based on the graph, the proposed graph structure based\nmulti-label prediction (GSMLP) method predicts multi-labels by considering the\npairwise similarity and the adjacency node distribution of each node. The\nmulti-labels created by GSMLP are applied to the proposed selective multi-label\nclassification (SMLC) loss. SMLC integrates a hard-sample mining scheme and a\nmulti-label classification. The proposed GSMLP and SMLC boost the performance\nof unsupervised person Re-ID without any pre-labelled dataset. Experimental\nresults justify the superiority of the proposed method in unsupervised person\nRe-ID by producing state-of-the-art performance. The source code for this paper\nis publicly available on 'https://github.com/uknownpioneer/GSMLP-SMLC.git'.",
    "descriptor": "\nComments: submitted to ICCV\n",
    "authors": [
      "Jongmin Yu",
      "Hyeontaek Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08798"
  },
  {
    "id": "arXiv:2106.08799",
    "title": "Regularization-Induced Bias and Consistency in Recursive Least Squares",
    "abstract": "Within the context of recursive least squares (RLS) parameter estimation, the\ngoal of the present paper is to study the effect of regularization-induced bias\non the transient and asymptotic accuracy of the parameter estimates. We\nconsider this question in three stages. First, we consider regression with\nrandom data, in which case persistency is guaranteed. Next, we apply RLS to\nfinite-impulse-response (FIR) system identification and, finally, to\ninfinite-impulse-response (IIR) system identification. For each case, we relate\nthe condition number of the regressor matrix to the transient response and rate\nof convergence of the parameter estimates.",
    "descriptor": "",
    "authors": [
      "Brian Lai",
      "Syed Aseem Ul Islam",
      "Dennis S. Bernstein"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08799"
  },
  {
    "id": "arXiv:2106.08800",
    "title": "High Performance and Optimal Configuration of Accurate Heterogeneous  Block-Based Approximate Adder",
    "abstract": "Approximate computing is an emerging paradigm to improve power and\nperformance efficiency for error-resilient application. Recent approximate\nadders have significantly extended the design space of accuracy-power\nconfigurable approximate adders, and find optimal designs by exploring the\ndesign space. In this paper, a new energy-efficient heterogeneous block-based\napproximate adder (HBBA) is proposed; which is a generic/configurable model\nthat can be transformed to a particular adder by defining some configurations.\nAn HBBA, in general, is composed of heterogeneous sub-adders, where each\nsub-adder can have a different configuration. A set of configurations of all\nthe sub-adders in an HBBA defines its configuration. The block-based adders are\napproximated through inexact logic configuration and truncated carry chains.\nHBBA increases design space providing additional design points that fall on the\nPareto-front and offer better power-accuracy trade-off compared to other\nconfigurations. Furthermore, to avoid Mont-Carlo simulations, we propose an\nanalytical modelling technique to evaluate the probability of error and\nProbability Mass Function (PMF) of error value. Moreover, the estimation method\nestimates delay, area and power of heterogeneous block-based approximate\nadders. Thus, based on the analytical model and estimation method, the optimal\nconfiguration under a given error constraint can be selected from the whole\ndesign space of the proposed adder model by exhaustive search. The simulation\nresults show that our HBBA provides improved accuracy in terms of error metrics\ncompared to some state-of-the-art approximate adders. HBBA with 32 bits length\nserves about 15% reduction in area and up to 17% reduction in energy compared\nto state-of-the-art approximate adders.",
    "descriptor": "\nComments: Submitted to the IEEE-TCAD journal, 16 pages, 16 figures\n",
    "authors": [
      "Ebrahim Farahmand",
      "Ali Mahani",
      "Muhammad Abdullah Hanif",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.08800"
  },
  {
    "id": "arXiv:2106.08801",
    "title": "PRASEMap: A Probabilistic Reasoning and Semantic Embedding based  Knowledge Graph Alignment System",
    "abstract": "Knowledge Graph (KG) alignment aims at finding equivalent entities and\nrelations (i.e., mappings) between two KGs. The existing approaches utilize\neither reasoning-based or semantic embedding-based techniques, but few studies\nexplore their combination. In this demonstration, we present PRASEMap, an\nunsupervised KG alignment system that iteratively computes the Mappings with\nboth Probabilistic Reasoning (PR) And Semantic Embedding (SE) techniques.\nPRASEMap can support various embedding-based KG alignment approaches as the SE\nmodule, and enables easy human computer interaction that additionally provides\nan option for users to feed the mapping annotations back to the system for\nbetter results. The demonstration showcases these features via a stand-alone\nWeb application with user friendly interfaces.",
    "descriptor": "",
    "authors": [
      "Zhiyuan Qi",
      "Ziheng Zhang",
      "Jiaoyan Chen",
      "Xi Chen",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08801"
  },
  {
    "id": "arXiv:2106.08808",
    "title": "Contrastive Learning with Continuous Proxy Meta-Data for 3D MRI  Classification",
    "abstract": "Traditional supervised learning with deep neural networks requires a\ntremendous amount of labelled data to converge to a good solution. For 3D\nmedical images, it is often impractical to build a large homogeneous annotated\ndataset for a specific pathology. Self-supervised methods offer a new way to\nlearn a representation of the images in an unsupervised manner with a neural\nnetwork. In particular, contrastive learning has shown great promises by\n(almost) matching the performance of fully-supervised CNN on vision tasks.\nNonetheless, this method does not take advantage of available meta-data, such\nas participant's age, viewed as prior knowledge. Here, we propose to leverage\ncontinuous proxy metadata, in the contrastive learning framework, by\nintroducing a new loss called y-Aware InfoNCE loss. Specifically, we improve\nthe positive sampling during pre-training by adding more positive examples with\nsimilar proxy meta-data with the anchor, assuming they share similar\ndiscriminative semantic features.With our method, a 3D CNN model pre-trained on\n$10^4$ multi-site healthy brain MRI scans can extract relevant features for\nthree classification tasks: schizophrenia, bipolar diagnosis and Alzheimer's\ndetection. When fine-tuned, it also outperforms 3D CNN trained from scratch on\nthese tasks, as well as state-of-the-art self-supervised methods. Our code is\nmade publicly available here.",
    "descriptor": "\nComments: MICCAI 2021\n",
    "authors": [
      "Benoit Dufumier",
      "Pietro Gori",
      "Julie Victor",
      "Antoine Grigis",
      "Michel Wessa",
      "Paolo Brambilla",
      "Pauline Favre",
      "Mircea Polosan",
      "Colm McDonald",
      "Camille Marie Piguet",
      "Edouard Duchesnay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08808"
  },
  {
    "id": "arXiv:2106.08809",
    "title": "Federated Learning over Energy Harvesting Wireless Networks",
    "abstract": "In this paper, the deployment of federated learning (FL) is investigated in\nan energy harvesting wireless network in which the base station (BS) employs\nmassive multiple-input multiple-output (MIMO) to serve a set of users powered\nby independent energy harvesting sources. Since a certain number of users may\nnot be able to participate in FL due to the interference and energy\nconstraints, a joint energy management and user scheduling problem in FL over\nwireless systems is formulated. This problem is formulated as an optimization\nproblem whose goal is to minimize the FL training loss via optimizing user\nscheduling. To find how the factors such as transmit power and number of\nscheduled users affect the training loss, the convergence rate of the FL\nalgorithm is first analyzed. Given this analytical result, the user scheduling\nand energy management optimization problem can be decomposed, simplified, and\nsolved. Further, the system model is extended by considering multiple BSs.\nHence, a joint user association and scheduling problem in FL over wireless\nsystems is studied. The optimal user association problem is solved using the\nbranch-and-bound technique. Simulation results show that the proposed user\nscheduling and user association algorithm can reduce training loss compared to\na standard FL algorithm.",
    "descriptor": "\nComments: To appear in IEEE Internet of Things Journal\n",
    "authors": [
      "Rami Hamdi",
      "Mingzhe Chen",
      "Ahmed Ben Said",
      "Marwa Qaraqe",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.08809"
  },
  {
    "id": "arXiv:2106.08810",
    "title": "Opportunistic Relaying in Multicasting over Generalized Shadowed Fading  Channels: A PHY Security Analysis",
    "abstract": "The secrecy of wireless multicast networks is greatly hampered due to the\nsimultaneous presence of fading and shadowing, which can be enhanced using\nrandom attributes of the propagation medium. This work focuses on utilizing\nthose attributes to enhance the physical layer security (PHY security)\nperformance of a dual-hop wireless multicast network over kappa-mu shadowed\nfading channel under the wiretapping attempts of multiple eavesdroppers. In\norder to raise the secrecy level, we employ multiple relays with the best relay\nselection strategy. Performance analysis has been carried out based on the\nmathematical modeling in terms of closed-form expressions of the probability of\nnon-zero secrecy multicast capacity, secure outage probability for\nmulticasting, and ergodic secrecy multicast capacity. Capitalizing on those\nexpressions, we analyze how the system parameters (i.e. fading, shadowing, the\nnumber of antennas, destination receivers, eavesdroppers, and relays) affect\nthe secrecy performance. Our numerical results show that the detrimental\nimpacts due to fading and shadowing can be remarkably mitigated using the\nwell-known opportunistic relaying technique. Moreover, the proposed model\nunifies secrecy analysis of several classical models, thereby exhibits enormous\nversatility than the existing works. Finally, all the numerical results are\nauthenticated utilizing Monte-Carlo simulations.",
    "descriptor": "",
    "authors": [
      "S. M. S. Shahriyer",
      "A. S. M. Badrudduza",
      "S. Shabab",
      "M. K. Kundu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.08810"
  },
  {
    "id": "arXiv:2106.08811",
    "title": "Projective and Telescopic Projective Integration for Non-Linear Kinetic  Mixtures",
    "abstract": "We propose fully explicit projective integration and telescopic projective\nintegration schemes for the multispecies Boltzmann and \\acf{BGK} equations. The\nmethods employ a sequence of small forward-Euler steps, intercalated with large\nextrapolation steps. The telescopic approach repeats said extrapolations as the\nbasis for an even larger step. This hierarchy renders the computational\ncomplexity of the method essentially independent of the stiffness of the\nproblem, which permits the efficient solution of equations in the hyperbolic\nscaling with very small Knudsen numbers. We validate the schemes on a range of\nscenarios, demonstrating its prowess in dealing with extreme mass ratios, fluid\ninstabilities, and other complex phenomena.",
    "descriptor": "",
    "authors": [
      "Rafael Bailo",
      "Thomas Rey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08811"
  },
  {
    "id": "arXiv:2106.08812",
    "title": "Costs and Benefits of Wasserstein Fair Regression",
    "abstract": "Real-world applications of machine learning tools in high-stakes domains are\noften regulated to be fair, in the sense that the predicted target should\nsatisfy some quantitative notion of parity with respect to a protected\nattribute. However, the exact tradeoff between fairness and accuracy with a\nreal-valued target is not clear. In this paper, we characterize the inherent\ntradeoff between statistical parity and accuracy in the regression setting by\nproviding a lower bound on the error of any fair regressor. Our lower bound is\nsharp, algorithm-independent, and admits a simple interpretation: when the\nmoments of the target differ between groups, any fair algorithm has to make a\nlarge error on at least one of the groups. We further extend this result to\ngive a lower bound on the joint error of any (approximately) fair algorithm,\nusing the Wasserstein distance to measure the quality of the approximation. On\nthe upside, we establish the first connection between individual fairness,\naccuracy parity, and the Wasserstein distance by showing that if a regressor is\nindividually fair, it also approximately verifies the accuracy parity, where\nthe gap is given by the Wasserstein distance between the two groups. Inspired\nby our theoretical results, we develop a practical algorithm for fair\nregression through the lens of representation learning, and conduct experiments\non a real-world dataset to corroborate our findings.",
    "descriptor": "",
    "authors": [
      "Han Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08812"
  },
  {
    "id": "arXiv:2106.08813",
    "title": "\"It's Viral!\" - A study of the behaviors, practices, and motivations of  TikTok Social Activists",
    "abstract": "Social media platforms such as Facebook and Twitter are used for social\nactivism purposes, and TikTok is no different. We conducted 9 qualitative\nsemi-structured interviews with social activists who recently posted their\nvideos on TikTok to understand. This study presents an initial look into why\nTikTok is used by social activists, and what processes they use to carry out\nthis work. The interviews revealed the following main patterns: (1) content\ncreation practices are typical and expected, (2) motivation and inspiration for\nposting social activist content comes from a wide range of personal sources,\n(3) social activism has communities on TikTok that provides encouragement and\ndiscussion, (4) engagement and interaction with other activists and viewers is\na crucial part of content creation as well as social activism, and (5) the main\ndriving force behind picking TikTok over other platforms is the ability to\nspread messages much farther with less effort. These findings provide insight\ninto the unique factors that TikTok brings for social activists and\ncorroborates previous findings in understanding how social activists use social\nmedia for their purposes.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Daniel Le Compte",
      "Daniel Klug"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.08813"
  },
  {
    "id": "arXiv:2106.08816",
    "title": "SiamAPN++: Siamese Attentional Aggregation Network for Real-Time UAV  Tracking",
    "abstract": "Recently, the Siamese-based method has stood out from multitudinous tracking\nmethods owing to its state-of-the-art (SOTA) performance. Nevertheless, due to\nvarious special challenges in UAV tracking, \\textit{e.g.}, severe occlusion,\nand fast motion, most existing Siamese-based trackers hardly combine superior\nperformance with high efficiency. To this concern, in this paper, a novel\nattentional Siamese tracker (SiamAPN++) is proposed for real-time UAV tracking.\nBy virtue of the attention mechanism, the attentional aggregation network (AAN)\nis conducted with self-AAN and cross-AAN, raising the expression ability of\nfeatures eventually. The former AAN aggregates and models the self-semantic\ninterdependencies of the single feature map via spatial and channel dimensions.\nThe latter aims to aggregate the cross-interdependencies of different semantic\nfeatures including the location information of anchors. In addition, the dual\nfeatures version of the anchor proposal network is proposed to raise the\nrobustness of proposing anchors, increasing the perception ability to objects\nwith various scales. Experiments on two well-known authoritative benchmarks are\nconducted, where SiamAPN++ outperforms its baseline SiamAPN and other SOTA\ntrackers. Besides, real-world tests onboard a typical embedded platform\ndemonstrate that SiamAPN++ achieves promising tracking results with real-time\nspeed.",
    "descriptor": "",
    "authors": [
      "Ziang Cao",
      "Changhong Fu",
      "Junjie Ye",
      "Bowen Li",
      "Yiming Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08816"
  },
  {
    "id": "arXiv:2106.08817",
    "title": "Metamorphic image registration using a semi-Lagrangian scheme",
    "abstract": "In this paper, we propose an implementation of both Large Deformation\nDiffeomorphic Metric Mapping (LDDMM) and Metamorphosis image registration using\na semi-Lagrangian scheme for geodesic shooting. We propose to solve both\nproblems as an inexact matching providing a single and unifying cost function.\nWe demonstrate that for image registration the use of a semi-Lagrangian scheme\nis more stable than a standard Eulerian scheme. Our GPU implementation is based\non PyTorch, which greatly simplifies and accelerates the computations thanks to\nits powerful automatic differentiation engine. It will be freely available at\nhttps://github.com/antonfrancois/Demeter_metamorphosis.",
    "descriptor": "\nComments: SEE GSI 2021\n",
    "authors": [
      "Anton Fran\u00e7ois",
      "Pietro Gori",
      "Joan Glaun\u00e8s"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08817"
  },
  {
    "id": "arXiv:2106.08822",
    "title": "Concatenated Reed-Solomon and Polarization-Adjusted Convolutional (PAC)  Codes",
    "abstract": "Two concatenated coding schemes incorporating algebraic Reed-Solomon (RS)\ncodes and polarization-adjusted convolutional (PAC) codes are proposed.\nSimulation results show that at a bit error rate of $10^{-5}$, a concatenated\nscheme using RS and PAC codes has more than $0.25$ dB coding gain over the NASA\nstandard concatenation scheme, which uses RS and convolutional codes.",
    "descriptor": "",
    "authors": [
      "Mohsen Moradi",
      "Amir Mozammel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.08822"
  },
  {
    "id": "arXiv:2106.08823",
    "title": "Eigen Analysis of Self-Attention and its Reconstruction from Partial  Computation",
    "abstract": "State-of-the-art transformer models use pairwise dot-product based\nself-attention, which comes at a computational cost quadratic in the input\nsequence length. In this paper, we investigate the global structure of\nattention scores computed using this dot product mechanism on a typical\ndistribution of inputs, and study the principal components of their variation.\nThrough eigen analysis of full attention score matrices, as well as of their\nindividual rows, we find that most of the variation among attention scores lie\nin a low-dimensional eigenspace. Moreover, we find significant overlap between\nthese eigenspaces for different layers and even different transformer models.\nBased on this, we propose to compute scores only for a partial subset of token\npairs, and use them to estimate scores for the remaining pairs. Beyond\ninvestigating the accuracy of reconstructing attention scores themselves, we\ninvestigate training transformer models that employ these approximations, and\nanalyze the effect on overall accuracy. Our analysis and the proposed method\nprovide insights into how to balance the benefits of exact pair-wise attention\nand its significant computational expense.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Srinadh Bhojanapalli",
      "Ayan Chakrabarti",
      "Himanshu Jain",
      "Sanjiv Kumar",
      "Michal Lukasik",
      "Andreas Veit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08823"
  },
  {
    "id": "arXiv:2106.08827",
    "title": "JRDB-Act: A Large-scale Multi-modal Dataset for Spatio-temporal Action,  Social Group and Activity Detection",
    "abstract": "The availability of large-scale video action understanding datasets has\nfacilitated advances in the interpretation of visual scenes containing people.\nHowever, learning to recognize human activities in an unconstrained real-world\nenvironment, with potentially highly unbalanced and long-tailed distributed\ndata remains a significant challenge, not least owing to the lack of a\nreflective large-scale dataset. Most existing large-scale datasets are either\ncollected from a specific or constrained environment, e.g. kitchens or rooms,\nor video sharing platforms such as YouTube. In this paper, we introduce\nJRDB-Act, a multi-modal dataset, as an extension of the existing JRDB, which is\ncaptured by asocial mobile manipulator and reflects a real distribution of\nhuman daily life actions in a university campus environment. JRDB-Act has been\ndensely annotated with atomic actions, comprises over 2.8M action labels,\nconstituting a large-scale spatio-temporal action detection dataset. Each human\nbounding box is labelled with one pose-based action label and multiple\n(optional) interaction-based action labels. Moreover JRDB-Act comes with social\ngroup identification annotations conducive to the task of grouping individuals\nbased on their interactions in the scene to infer their social activities\n(common activities in each social group).",
    "descriptor": "",
    "authors": [
      "Mahsa Ehsanpour",
      "Fatemeh Saleh",
      "Silvio Savarese",
      "Ian Reid",
      "Hamid Rezatofighi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08827"
  },
  {
    "id": "arXiv:2106.08829",
    "title": "A Fair and Comprehensive Comparison of Multimodal Tweet Sentiment  Analysis Methods",
    "abstract": "Opinion and sentiment analysis is a vital task to characterize subjective\ninformation in social media posts. In this paper, we present a comprehensive\nexperimental evaluation and comparison with six state-of-the-art methods, from\nwhich we have re-implemented one of them. In addition, we investigate different\ntextual and visual feature embeddings that cover different aspects of the\ncontent, as well as the recently introduced multimodal CLIP embeddings.\nExperimental results are presented for two different publicly available\nbenchmark datasets of tweets and corresponding images. In contrast to the\nevaluation methodology of previous work, we introduce a reproducible and fair\nevaluation scheme to make results comparable. Finally, we conduct an error\nanalysis to outline the limitations of the methods and possibilities for the\nfuture work.",
    "descriptor": "\nComments: Accepted in Workshop on Multi-ModalPre-Training for Multimedia Understanding (MMPT 2021), co-located with ICMR 2021\n",
    "authors": [
      "Gullal S. Cheema",
      "Sherzod Hakimov",
      "Eric M\u00fcller-Budack",
      "Ralph Ewerth"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08829"
  },
  {
    "id": "arXiv:2106.08832",
    "title": "Solving Continuous Control with Episodic Memory",
    "abstract": "Episodic memory lets reinforcement learning algorithms remember and exploit\npromising experience from the past to improve agent performance. Previous works\non memory mechanisms show benefits of using episodic-based data structures for\ndiscrete action problems in terms of sample-efficiency. The application of\nepisodic memory for continuous control with a large action space is not\ntrivial. Our study aims to answer the question: can episodic memory be used to\nimprove agent's performance in continuous control? Our proposed algorithm\ncombines episodic memory with Actor-Critic architecture by modifying critic's\nobjective. We further improve performance by introducing episodic-based replay\nbuffer prioritization. We evaluate our algorithm on OpenAI gym domains and show\ngreater sample-efficiency compared with the state-of-the art model-free\noff-policy algorithms.",
    "descriptor": "\nComments: To appear in the 30th International Joint Conference on Artificial Intelligence (IJCAI 2021)\n",
    "authors": [
      "Igor Kuznetsov",
      "Andrey Filchenkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08832"
  },
  {
    "id": "arXiv:2106.08833",
    "title": "Dynamic Recompilation of Software Network Services with Morpheus",
    "abstract": "State-of-the-art approaches to design, develop and optimize software\npacket-processing programs are based on static compilation: the compiler's\ninput is a description of the forwarding plane semantics and the output is a\nbinary that can accommodate any control plane configuration or input traffic.\nIn this paper, we demonstrate that tracking control plane actions and\npacket-level traffic dynamics at run time opens up new opportunities for code\nspecialization. We present Morpheus, a system working alongside static\ncompilers that continuously optimizes the targeted networking code. We\nintroduce a number of new techniques, from static code analysis to adaptive\ncode instrumentation, and we implement a toolbox of domain specific\noptimizations that are not restricted to a specific data plane framework or\nprogramming language. We apply Morpheus to several eBPF and DPDK programs\nincluding Katran, Facebook's production-grade load balancer. We compare\nMorpheus against state-of-the-art optimization frameworks and show that it can\nbring up to 2x throughput improvement, while halving the 99th percentile\nlatency.",
    "descriptor": "",
    "authors": [
      "Sebastiano Miano",
      "Alireza Sanaee",
      "Fulvio Risso",
      "G\u00e1bor R\u00e9tv\u00e1ri",
      "Gianni Antichi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.08833"
  },
  {
    "id": "arXiv:2106.08834",
    "title": "A Low Rank Tensor Representation of Linear Transport and Nonlinear  Vlasov Solutions and Their Associated Flow Maps",
    "abstract": "We propose a low-rank tensor approach to approximate linear transport and\nnonlinear Vlasov solutions and their associated flow maps. The approach takes\nadvantage of the fact that the differential operators in the Vlasov equation is\ntensor friendly, based on which we propose a novel way to dynamically and\nadaptively build up low-rank solution basis by adding new basis functions from\ndiscretization of the PDE, and removing basis from an SVD-type truncation\nprocedure. For the discretization, we adopt a high order finite difference\nspatial discretization and a second order strong stability preserving\nmulti-step time discretization. We apply the same procedure to evolve the\ndynamics of the flow map in a low-rank fashion, which proves to be advantageous\nwhen the flow map enjoys the low rank structure, while the solution suffers\nfrom high rank or displays filamentation structures. Hierarchical Tucker\ndecomposition is adopted for high dimensional problems. An extensive set of\nlinear and nonlinear Vlasov test examples are performed to show the high order\nspatial and temporal convergence of the algorithm with mesh refinement up to\nSVD-type truncation, the significant computational savings of the proposed\nlow-rank approach especially for high dimensional problems, the improved\nperformance of the flow map approach for solutions with filamentations.",
    "descriptor": "",
    "authors": [
      "Wei Guo",
      "Jing-Mei Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08834"
  },
  {
    "id": "arXiv:2106.08838",
    "title": "Domain-independent User Simulation with Transformers for Task-oriented  Dialogue Systems",
    "abstract": "Dialogue policy optimisation via reinforcement learning requires a large\nnumber of training interactions, which makes learning with real users time\nconsuming and expensive. Many set-ups therefore rely on a user simulator\ninstead of humans. These user simulators have their own problems. While\nhand-coded, rule-based user simulators have been shown to be sufficient in\nsmall, simple domains, for complex domains the number of rules quickly becomes\nintractable. State-of-the-art data-driven user simulators, on the other hand,\nare still domain-dependent. This means that adaptation to each new domain\nrequires redesigning and retraining. In this work, we propose a\ndomain-independent transformer-based user simulator (TUS). The structure of our\nTUS is not tied to a specific domain, enabling domain generalisation and\nlearning of cross-domain user behaviour from data. We compare TUS with the\nstate of the art using automatic as well as human evaluations. TUS can compete\nwith rule-based user simulators on pre-defined domains and is able to\ngeneralise to unseen domains in a zero-shot fashion.",
    "descriptor": "",
    "authors": [
      "Hsien-chin Lin",
      "Nurul Lubis",
      "Songbo Hu",
      "Carel van Niekerk",
      "Christian Geishauser",
      "Michael Heck",
      "Shutong Feng",
      "Milica Ga\u0161i\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08838"
  },
  {
    "id": "arXiv:2106.08843",
    "title": "Visualizing Evolving Trees",
    "abstract": "Evolving trees arise in many real-life scenarios from computer file systems\nand dynamic call graphs, to fake news propagation and disease spread. Most\nlayout algorithms for static trees, however, do not work well in an evolving\nsetting (e.g., they are not designed to be stable between time steps). Dynamic\ngraph layout algorithms are better suited to this task, although they often\nintroduce unnecessary edge crossings. With this in mind we propose two methods\nfor visualizing evolving trees that guarantee no edge crossings, while\noptimizing (1) desired edge length realization, (2) layout compactness, and (3)\nstability. We evaluate the two new methods, along with four prior approaches\n(two static and two dynamic), on real-world datasets using quantitative\nmetrics: stress, desired edge length realization, layout compactness,\nstability, and running time. The new methods are fully functional and available\non github.",
    "descriptor": "",
    "authors": [
      "Kathryn Gray",
      "Mingwei Li",
      "Reyan Ahmed",
      "Stephen Kobourov"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.08843"
  },
  {
    "id": "arXiv:2106.08846",
    "title": "Algorithm to Compilation Codesign: An Integrated View of Neural Network  Sparsity",
    "abstract": "Reducing computation cost, inference latency, and memory footprint of neural\nnetworks are frequently cited as research motivations for pruning and sparsity.\nHowever, operationalizing those benefits and understanding the end-to-end\neffect of algorithm design and regularization on the runtime execution is not\noften examined in depth.\nHere we apply structured and unstructured pruning to attention weights of\ntransformer blocks of the BERT language model, while also expanding block\nsparse representation (BSR) operations in the TVM compiler. Integration of BSR\noperations enables the TVM runtime execution to leverage structured pattern\nsparsity induced by model regularization.\nThis integrated view of pruning algorithms enables us to study relationships\nbetween modeling decisions and their direct impact on sparsity-enhanced\nexecution. Our main findings are: 1) we validate that performance benefits of\nstructured sparsity block regularization must be enabled by the BSR\naugmentations to TVM, with 4x speedup relative to vanilla PyTorch and 2.2x\nspeedup relative to standard TVM compilation (without expanded BSR support). 2)\nfor BERT attention weights, the end-to-end optimal block sparsity shape in this\nCPU inference context is not a square block (as in \\cite{gray2017gpu}) but\nrather a linear 32x1 block 3) the relationship between performance and block\nsize / shape is is suggestive of how model regularization parameters interact\nwith task scheduler optimizations resulting in the observed end-to-end\nperformance.",
    "descriptor": "",
    "authors": [
      "Fu-Ming Guo",
      "Austin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08846"
  },
  {
    "id": "arXiv:2106.08847",
    "title": "Power Minimization of Downlink Spectrum Slicing for eMBB and URLLC Users",
    "abstract": "A critical task in 5G networks with heterogeneous services is spectrum\nslicing of the shared radio resources, through which each service gets\nperformance guarantees. In this paper, we consider a setup in which a Base\nStation (BS) should serve two types of traffic in the downlink, enhanced mobile\nbroadband (eMBB) and ultra-reliable low-latency communication (URLLC),\nrespectively. Two resource allocation strategies are considered, non-orthogonal\nmultiple access (NOMA) and orthogonal multiple access (OMA). A framework for\npower minimization is presented, in which the BS knows the channel state\ninformation (CSI) of the eMBB users only. Nevertheless, due to the resource\nsharing, it is shown that this knowledge can be used also to the benefit of the\nURLLC users. The numerical results show that NOMA leads to a lower power\nconsumption compared to OMA for every simulation parameter under test.",
    "descriptor": "\nComments: This work has been submitted to the IEEE GLOBECOM for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Fabio Saggese",
      "Marco Moretti",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.08847"
  },
  {
    "id": "arXiv:2106.08848",
    "title": "Data Augmentation for Graph Convolutional Network on Semi-Supervised  Classification",
    "abstract": "Data augmentation aims to generate new and synthetic features from the\noriginal data, which can identify a better representation of data and improve\nthe performance and generalizability of downstream tasks. However, data\naugmentation for graph-based models remains a challenging problem, as graph\ndata is more complex than traditional data, which consists of two features with\ndifferent properties: graph topology and node attributes. In this paper, we\nstudy the problem of graph data augmentation for Graph Convolutional Network\n(GCN) in the context of improving the node embeddings for semi-supervised node\nclassification. Specifically, we conduct cosine similarity based cross\noperation on the original features to create new graph features, including new\nnode attributes and new graph topologies, and we combine them as new pairwise\ninputs for specific GCNs. Then, we propose an attentional integrating model to\nweighted sum the hidden node embeddings encoded by these GCNs into the final\nnode embeddings. We also conduct a disparity constraint on these hidden node\nembeddings when training to ensure that non-redundant information is captured\nfrom different features. Experimental results on five real-world datasets show\nthat our method improves the classification accuracy with a clear margin (+2.5%\n- +84.2%) than the original GCN model.",
    "descriptor": "\nComments: 16 pages, 6 figures,APWeb-WAIM 2021: The 5th APWeb-WAIM International Joint Conference on Web and Big Data\n",
    "authors": [
      "Zhengzheng Tang",
      "Ziyue Qiao",
      "Xuehai Hong",
      "Yang Wang",
      "Fayaz Ali Dharejo",
      "Yuanchun Zhou",
      "Yi Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.08848"
  },
  {
    "id": "arXiv:2106.08849",
    "title": "How memory architecture affects performance and learning in simple  POMDPs",
    "abstract": "Reinforcement learning is made much more complex when the agent's observation\nis partial or noisy. This case corresponds to a partially observable Markov\ndecision process (POMDP). One strategy to seek good performance in POMDPs is to\nendow the agent with a finite memory, whose update is governed by the policy.\nHowever, policy optimization is non-convex in that case and can lead to poor\ntraining performance for random initialization. The performance can be\nempirically improved by constraining the memory architecture, then sacrificing\noptimality to facilitate training. Here we study this trade-off in the two-arm\nbandit problem, and compare two extreme cases: (i) the random access memory\nwhere any transitions between $M$ memory states are allowed and (ii) a fixed\nmemory where the agent can access its last $m$ actions and rewards. For (i),\nthe probability $q$ to play the worst arm is known to be exponentially small in\n$M$ for the optimal policy. Our main result is to show that similar performance\ncan be reached for (ii) as well, despite the simplicity of the memory\narchitecture: using a conjecture on Gray-ordered binary necklaces, we find\npolicies for which $q$ is exponentially small in $2^m$ i.e. $q\\sim\\alpha^{2^m}$\nfor some $\\alpha < 1$. Interestingly, we observe empirically that training from\nrandom initialization leads to very poor results for (i), and significantly\nbetter results for (ii).",
    "descriptor": "",
    "authors": [
      "Mario Geiger",
      "Christophe Eloy",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08849"
  },
  {
    "id": "arXiv:2106.08850",
    "title": "Nonlinear Trajectory-Based Region of Attraction Estimation for Aircraft  Dynamics Analysis",
    "abstract": "Current flight control validation is heavily based on linear analysis and\nhigh fidelity, nonlinear simulations. Continuing developments of nonlinear\nanalysis tools for flight control has greatly enhanced the validation process.\nMany analysis tools are reliant on assuming the analytical flight dynamics but\nthis paper proposes an approach using only simulation data. First, this paper\npresents improvements to a method for estimating the region of attraction (ROA)\nof nonlinear systems governed by ordinary differential equations (ODEs) based\nonly on trajectory measurements. Faster and more accurate convergence to the\ntrue ROA results. These improvements make the proposed algorithm feasible in\nhigher-dimensional and more complex systems. Next, these tools are used to\nanalyze the four-state longitudinal dynamics of NASA's Generic Transport Model\n(GTM) aircraft. A piecewise polynomial model of the GTM is used to simulate\ntrajectories and the developed analysis tools are used to estimate the ROA\naround a trim condition based only on this trajectory data. Finally, the\nalgorithm presented is extended to estimate the ROA of finitely many\nequilibrium point systems and of general equilibrium set (arbitrary equilibrium\npoints and limit cycles) systems.",
    "descriptor": "",
    "authors": [
      "Brian Lai",
      "Torbj\u00f8rn Cunis",
      "Laurent Burlion"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08850"
  },
  {
    "id": "arXiv:2106.08851",
    "title": "GelSight Wedge: Measuring High-Resolution 3D Contact Geometry with a  Compact Robot Finger",
    "abstract": "Vision-based tactile sensors have the potential to provide important contact\ngeometry to localize the objective with visual occlusion. However, it is\nchallenging to measure high-resolution 3D contact geometry for a compact robot\nfinger, to simultaneously meet optical and mechanical constraints. In this\nwork, we present the GelSight Wedge sensor, which is optimized to have a\ncompact shape for robot fingers, while achieving high-resolution 3D\nreconstruction. We evaluate the 3D reconstruction under different lighting\nconfigurations, and extend the method from 3 lights to 1 or 2 lights. We\ndemonstrate the flexibility of the design by shrinking the sensor to the size\nof a human finger for fine manipulation tasks. We also show the effectiveness\nand potential of the reconstructed 3D geometry for pose tracking in the 3D\nspace.",
    "descriptor": "\nComments: ICRA 2021\n",
    "authors": [
      "Shaoxiong Wang",
      "Yu She",
      "Branden Romero",
      "Edward Adelson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08851"
  },
  {
    "id": "arXiv:2106.08852",
    "title": "Multilinear Dirichlet Processes",
    "abstract": "Dependent Dirichlet processes (DDP) have been widely applied to model data\nfrom distributions over collections of measures which are correlated in some\nway. On the other hand, in recent years, increasing research efforts in machine\nlearning and data mining have been dedicated to dealing with data involving\ninteractions from two or more factors. However, few researchers have addressed\nthe heterogeneous relationship in data brought by modulation of multiple\nfactors using techniques of DDP. In this paper, we propose a novel technique,\nMultiLinear Dirichlet Processes (MLDP), to constructing DDPs by combining DP\nwith a state-of-the-art factor analysis technique, multilinear factor analyzers\n(MLFA). We have evaluated MLDP on real-word data sets for different\napplications and have achieved state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Xiaoli Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08852"
  },
  {
    "id": "arXiv:2106.08853",
    "title": "Strategic Behavior is Bliss: Iterative Voting Improves Social Welfare",
    "abstract": "Recent work in iterative voting has defined the difference in social welfare\nbetween the truthful winner and worst-case equilibrium winner, due to repeated\nstrategic manipulations, known as the additive dynamic price of anarchy\n(ADPoA). While all iterative plurality winners have been shown to differ from\ntruth by at most one initial vote, it is less understood how agents' welfare\nchanges in equilibrium. To this end, we differentiate agents' utility from\ntheir iteration mechanism and determine iterative plurality's ADPoA in the\nworst- and average-case. We first negatively demonstrate that the worst-case\nADPoA is linear in the number of agents. In expectation, rather, equilibrium\nwinners have a constant order welfare advantage over the truthful winner. Our\npositive results illustrate the prospect for social welfare to increase due to\nstrategic manipulation.",
    "descriptor": "\nComments: 21 pages, 4 figures, in submission to NeurIPS'21\n",
    "authors": [
      "Joshua Kavner",
      "Lirong Xia"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.08853"
  },
  {
    "id": "arXiv:2106.08855",
    "title": "Beyond Tikhonov: Faster Learning with Self-Concordant Losses via  Iterative Regularization",
    "abstract": "The theory of spectral filtering is a remarkable tool to understand the\nstatistical properties of learning with kernels. For least squares, it allows\nto derive various regularization schemes that yield faster convergence rates of\nthe excess risk than with Tikhonov regularization. This is typically achieved\nby leveraging classical assumptions called source and capacity conditions,\nwhich characterize the difficulty of the learning task. In order to understand\nestimators derived from other loss functions, Marteau-Ferey et al. have\nextended the theory of Tikhonov regularization to generalized self concordant\nloss functions (GSC), which contain, e.g., the logistic loss. In this paper, we\ngo a step further and show that fast and optimal rates can be achieved for GSC\nby using the iterated Tikhonov regularization scheme, which is intrinsically\nrelated to the proximal point method in optimization, and overcomes the\nlimitation of the classical Tikhonov regularization.",
    "descriptor": "",
    "authors": [
      "Gaspard Beugnot",
      "Julien Mairal",
      "Alessandro Rudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.08855"
  },
  {
    "id": "arXiv:2106.08856",
    "title": "X-MAN: Explaining multiple sources of anomalies in video",
    "abstract": "Our objective is to detect anomalies in video while also automatically\nexplaining the reason behind the detector's response. In a practical sense,\nexplainability is crucial for this task as the required response to an anomaly\ndepends on its nature and severity. However, most leading methods (based on\ndeep neural networks) are not interpretable and hide the decision making\nprocess in uninterpretable feature representations. In an effort to tackle this\nproblem we make the following contributions: (1) we show how to build\ninterpretable feature representations suitable for detecting anomalies with\nstate of the art performance, (2) we propose an interpretable probabilistic\nanomaly detector which can describe the reason behind it's response using high\nlevel concepts, (3) we are the first to directly consider object interactions\nfor anomaly detection and (4) we propose a new task of explaining anomalies and\nrelease a large dataset for evaluating methods on this task. Our method\ncompetes well with the state of the art on public datasets while also providing\nanomaly explanation based on objects and their interactions.",
    "descriptor": "\nComments: In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, June 2021\n",
    "authors": [
      "Stanislaw Szymanowicz",
      "James Charles",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08856"
  },
  {
    "id": "arXiv:2106.08858",
    "title": "Grounding Spatio-Temporal Language with Transformers",
    "abstract": "Language is an interface to the outside world. In order for embodied agents\nto use it, language must be grounded in other, sensorimotor modalities. While\nthere is an extended literature studying how machines can learn grounded\nlanguage, the topic of how to learn spatio-temporal linguistic concepts is\nstill largely uncharted. To make progress in this direction, we here introduce\na novel spatio-temporal language grounding task where the goal is to learn the\nmeaning of spatio-temporal descriptions of behavioral traces of an embodied\nagent. This is achieved by training a truth function that predicts if a\ndescription matches a given history of observations. The descriptions involve\ntime-extended predicates in past and present tense as well as spatio-temporal\nreferences to objects in the scene. To study the role of architectural biases\nin this task, we train several models including multimodal Transformer\narchitectures; the latter implement different attention computations between\nwords and objects across space and time. We test models on two classes of\ngeneralization: 1) generalization to randomly held-out sentences; 2)\ngeneralization to grammar primitives. We observe that maintaining object\nidentity in the attention computation of our Transformers is instrumental to\nachieving good performance on generalization overall, and that summarizing\nobject traces in a single token has little influence on performance. We then\ndiscuss how this opens new perspectives for language-guided autonomous embodied\nagents. We also release our code under open-source license as well as\npretrained models and datasets to encourage the wider community to build upon\nand extend our work in the future.",
    "descriptor": "\nComments: Contains main article and supplementaries\n",
    "authors": [
      "Tristan Karch",
      "Laetitia Teodorescu",
      "Katja Hofmann",
      "Cl\u00e9ment Moulin-Frier",
      "Pierre-Yves Oudeyer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08858"
  },
  {
    "id": "arXiv:2106.08859",
    "title": "Attention-Based Keyword Localisation in Speech using Visual Grounding",
    "abstract": "Visually grounded speech models learn from images paired with spoken\ncaptions. By tagging images with soft text labels using a trained visual\nclassifier with a fixed vocabulary, previous work has shown that it is possible\nto train a model that can detect whether a particular text keyword occurs in\nspeech utterances or not. Here we investigate whether visually grounded speech\nmodels can also do keyword localisation: predicting where, within an utterance,\na given textual keyword occurs without any explicit text-based or alignment\nsupervision. We specifically consider whether incorporating attention into a\nconvolutional model is beneficial for localisation. Although absolute\nlocalisation performance with visually supervised models is still modest\n(compared to using unordered bag-of-word text labels for supervision), we show\nthat attention provides a large gain in performance over previous visually\ngrounded models. As in many other speech-image studies, we find that many of\nthe incorrect localisations are due to semantic confusions, e.g. locating the\nword 'backstroke' for the query keyword 'swimming'.",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Kayode Olaleye",
      "Herman Kamper"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.08859"
  },
  {
    "id": "arXiv:2106.08863",
    "title": "Unbiased Methods for Multi-Goal Reinforcement Learning",
    "abstract": "In multi-goal reinforcement learning (RL) settings, the reward for each goal\nis sparse, and located in a small neighborhood of the goal. In large dimension,\nthe probability of reaching a reward vanishes and the agent receives little\nlearning signal. Methods such as Hindsight Experience Replay (HER) tackle this\nissue by also learning from realized but unplanned-for goals. But HER is known\nto introduce bias, and can converge to low-return policies by overestimating\nchancy outcomes. First, we vindicate HER by proving that it is actually\nunbiased in deterministic environments, such as many optimal control settings.\nNext, for stochastic environments in continuous spaces, we tackle sparse\nrewards by directly taking the infinitely sparse reward limit. We fully\nformalize the problem of multi-goal RL with infinitely sparse Dirac rewards at\neach goal. We introduce unbiased deep Q-learning and actor-critic algorithms\nthat can handle such infinitely sparse rewards, and test them in toy\nenvironments.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "L\u00e9onard Blier",
      "Yann Ollivier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08863"
  },
  {
    "id": "arXiv:2106.08864",
    "title": "Multi-Class Classification from Single-Class Data with Confidences",
    "abstract": "Can we learn a multi-class classifier from only data of a single class? We\nshow that without any assumptions on the loss functions, models, and\noptimizers, we can successfully learn a multi-class classifier from only data\nof a single class with a rigorous consistency guarantee when confidences (i.e.,\nthe class-posterior probabilities for all the classes) are available.\nSpecifically, we propose an empirical risk minimization framework that is\nloss-/model-/optimizer-independent. Instead of constructing a boundary between\nthe given class and other classes, our method can conduct discriminative\nclassification between all the classes even if no data from the other classes\nare provided. We further theoretically and experimentally show that our method\ncan be Bayes-consistent with a simple modification even if the provided\nconfidences are highly noisy. Then, we provide an extension of our method for\nthe case where data from a subset of all the classes are available.\nExperimental results demonstrate the effectiveness of our methods.",
    "descriptor": "\nComments: 23 pages, 1 figure\n",
    "authors": [
      "Yuzhou Cao",
      "Lei Feng",
      "Senlin Shu",
      "Yitian Xu",
      "Bo An",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08864"
  },
  {
    "id": "arXiv:2106.08867",
    "title": "Latent Mappings: Generating Open-Ended Expressive Mappings Using  Variational Autoencoders",
    "abstract": "In many contexts, creating mappings for gestural interactions can form part\nof an artistic process. Creators seeking a mapping that is expressive, novel,\nand affords them a sense of authorship may not know how to program it up in a\nsignal processing patch. Tools like Wekinator and MIMIC allow creators to use\nsupervised machine learning to learn mappings from example input/output\npairings. However, a creator may know a good mapping when they encounter it yet\nstart with little sense of what the inputs or outputs should be. We call this\nan open-ended mapping process. Addressing this need, we introduce the latent\nmapping, which leverages the latent space of an unsupervised machine learning\nalgorithm such as a Variational Autoencoder trained on a corpus of unlabelled\ngestural data from the creator. We illustrate it with Sonified Body, a system\nmapping full-body movement to sound which we explore in a residency with three\ndancers.",
    "descriptor": "\nComments: Published at the International Conference on New Interfaces for Musical Expression, June 2021. 3000 word short paper. 5 figures plus video which may be seen at this https URL\n",
    "authors": [
      "Tim Murray-Browne",
      "Panagiotis Tigas"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.08867"
  },
  {
    "id": "arXiv:2106.08872",
    "title": "Enabling Sustainable Clouds: The Case for Virtualizing the Energy System",
    "abstract": "Cloud platforms' growing energy demand and carbon emissions are raising\nconcern about their environmental sustainability. The current approach to\nenabling sustainable clouds focuses on improving energy-efficiency and\npurchasing carbon offsets. These approaches have limits: many cloud data\ncenters already operate near peak efficiency, and carbon offsets cannot scale\nto near zero carbon where there is little carbon left to offset. Instead,\nenabling sustainable clouds will require applications to adapt to when and\nwhere unreliable low-carbon energy is available. Applications cannot do this\ntoday because their energy use and carbon emissions are not visible to them, as\nthe energy system provides the rigid abstraction of a continuous, reliable\nenergy supply. This vision paper instead advocates for a ``carbon first''\napproach to cloud design that elevates carbon-efficiency to a first-class\nmetric. To do so, we argue that cloud platforms should virtualize the energy\nsystem by exposing visibility into, and software-defined control of, it to\napplications, enabling them to define their own abstractions for managing\nenergy and carbon emissions based on their own requirements.",
    "descriptor": "",
    "authors": [
      "Noman Bashir",
      "Tian Guo",
      "Mohammad Hajiesmaili",
      "David Irwin",
      "Prashant Shenoy",
      "Ramesh Sitaraman",
      "Abel Souza",
      "Adam Wierman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.08872"
  },
  {
    "id": "arXiv:2106.08873",
    "title": "Voicy: Zero-Shot Non-Parallel Voice Conversion in Noisy Reverberant  Environments",
    "abstract": "Voice Conversion (VC) is a technique that aims to transform the\nnon-linguistic information of a source utterance to change the perceived\nidentity of the speaker. While there is a rich literature on VC, most proposed\nmethods are trained and evaluated on clean speech recordings. However, many\nacoustic environments are noisy and reverberant, severely restricting the\napplicability of popular VC methods to such scenarios. To address this\nlimitation, we propose Voicy, a new VC framework particularly tailored for\nnoisy speech. Our method, which is inspired by the de-noising auto-encoders\nframework, is comprised of four encoders (speaker, content, phonetic and\nacoustic-ASR) and one decoder. Importantly, Voicy is capable of performing\nnon-parallel zero-shot VC, an important requirement for any VC system that\nneeds to work on speakers not seen during training. We have validated our\napproach using a noisy reverberant version of the LibriSpeech dataset.\nExperimental results show that Voicy outperforms other tested VC techniques in\nterms of naturalness and target speaker similarity in noisy reverberant\nenvironments.",
    "descriptor": "\nComments: Presented at the Speech Synthesis Workshops 2021 (SSW11)\n",
    "authors": [
      "Alejandro Mottini",
      "Jaime Lorenzo-Trueba",
      "Sri Vishnu Kumar Karlapati",
      "Thomas Drugman"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.08873"
  },
  {
    "id": "arXiv:2106.08877",
    "title": "Side-Channel Attacks on RISC-V Processors: Current Progress, Challenges,  and Opportunities",
    "abstract": "Side-channel attacks on microprocessors, like the RISC-V, exhibit security\nvulnerabilities that lead to several design challenges. Hence, it is imperative\nto study and analyze these security vulnerabilities comprehensively. In this\npaper, we present a brief yet comprehensive study of the security\nvulnerabilities in modern microprocessors with respect to side-channel attacks\nand their respective mitigation techniques. The focus of this paper is to\nanalyze the hardware-exploitable side-channel attack using power consumption\nand software-exploitable side-channel attacks to manipulate cache. Towards\nthis, we perform an in-depth analysis of the applicability and practical\nimplications of cache attacks on RISC-V microprocessors and their associated\nchallenges. Finally, based on the comparative study and our analysis, we\nhighlight some key research directions to develop robust RISC-V microprocessors\nthat are resilient to side-channel attacks.",
    "descriptor": "\nComments: CYBER 2020, The Fifth International Conference on Cyber-Technologies and Cyber-Systems\n",
    "authors": [
      "Mahya Morid Ahmadi",
      "Faiq Khalid",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.08877"
  },
  {
    "id": "arXiv:2106.08878",
    "title": "Autonomous Navigation System for a Delivery Drone",
    "abstract": "The use of delivery services is an increasing trend worldwide, further\nenhanced by the COVID pandemic. In this context, drone delivery systems are of\ngreat interest as they may allow for faster and cheaper deliveries. This paper\npresents a navigation system that makes feasible the delivery of parcels with\nautonomous drones. The system generates a path between a start and a final\npoint and controls the drone to follow this path based on its localization\nobtained through GPS, 9DoF IMU, and barometer. In the landing phase,\ninformation of poses estimated by a marker (ArUco) detection technique using a\ncamera, ultra-wideband (UWB) devices, and the drone's software estimation are\nmerged by utilizing an Extended Kalman Filter algorithm to improve the landing\nprecision. A vector field-based method controls the drone to follow the desired\npath smoothly, reducing vibrations or harsh movements that could harm the\ntransported parcel. Real experiments validate the delivery strategy and allow\nto evaluate the performance of the adopted techniques. Preliminary results\nstate the viability of our proposal for autonomous drone delivery.",
    "descriptor": "\nComments: 12 pages, 15 figures, extended version of an paper published at the XXIII Brazilian Congress of Automatica, entitled \"Desenvolvimento de um drone aut\\^onomo para tarefas de entrega de carga\"\n",
    "authors": [
      "Victor R. F. Miranda",
      "Adriano M. C. Rezende",
      "Thiago L. Rocha",
      "H\u00e9ctor Azp\u00farua",
      "Luciano C. A. Pimenta",
      "Gustavo M. Freitas"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08878"
  },
  {
    "id": "arXiv:2106.08881",
    "title": "Nonparametric Empirical Bayes Estimation and Testing for Sparse and  Heteroscedastic Signals",
    "abstract": "Large-scale modern data often involves estimation and testing for\nhigh-dimensional unknown parameters. It is desirable to identify the sparse\nsignals, ``the needles in the haystack'', with accuracy and false discovery\ncontrol. However, the unprecedented complexity and heterogeneity in modern data\nstructure require new machine learning tools to effectively exploit\ncommonalities and to robustly adjust for both sparsity and heterogeneity. In\naddition, estimates for high-dimensional parameters often lack uncertainty\nquantification. In this paper, we propose a novel Spike-and-Nonparametric\nmixture prior (SNP) -- a spike to promote the sparsity and a nonparametric\nstructure to capture signals. In contrast to the state-of-the-art methods, the\nproposed methods solve the estimation and testing problem at once with several\nmerits: 1) an accurate sparsity estimation; 2) point estimates with\nshrinkage/soft-thresholding property; 3) credible intervals for uncertainty\nquantification; 4) an optimal multiple testing procedure that controls false\ndiscovery rate. Our method exhibits promising empirical performance on both\nsimulated data and a gene expression case study.",
    "descriptor": "",
    "authors": [
      "Junhui Cai",
      "Xu Han",
      "Ya'acov Ritov",
      "Linda Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.08881"
  },
  {
    "id": "arXiv:2106.08882",
    "title": "Robust Training in High Dimensions via Block Coordinate Geometric Median  Descent",
    "abstract": "Geometric median (\\textsc{Gm}) is a classical method in statistics for\nachieving a robust estimation of the uncorrupted data; under gross corruption,\nit achieves the optimal breakdown point of 0.5. However, its computational\ncomplexity makes it infeasible for robustifying stochastic gradient descent\n(SGD) for high-dimensional optimization problems. In this paper, we show that\nby applying \\textsc{Gm} to only a judiciously chosen block of coordinates at a\ntime and using a memory mechanism, one can retain the breakdown point of 0.5\nfor smooth non-convex problems, with non-asymptotic convergence rates\ncomparable to the SGD with \\textsc{Gm}.",
    "descriptor": "",
    "authors": [
      "Anish Acharya",
      "Abolfazl Hashemi",
      "Prateek Jain",
      "Sujay Sanghavi",
      "Inderjit S. Dhillon",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08882"
  },
  {
    "id": "arXiv:2106.08886",
    "title": "Over-and-Under Complete Convolutional RNN for MRI Reconstruction",
    "abstract": "Reconstructing magnetic resonance (MR) images from undersampled data is a\nchallenging problem due to various artifacts introduced by the under-sampling\noperation. Recent deep learning-based methods for MR image reconstruction\nusually leverage a generic auto-encoder architecture which captures low-level\nfeatures at the initial layers and high?level features at the deeper layers.\nSuch networks focus much on global features which may not be optimal to\nreconstruct the fully-sampled image. In this paper, we propose an\nOver-and-Under Complete Convolu?tional Recurrent Neural Network (OUCR), which\nconsists of an overcomplete and an undercomplete Convolutional Recurrent Neural\nNetwork(CRNN). The overcomplete branch gives special attention in learning\nlocal structures by restraining the receptive field of the network. Combining\nit with the undercomplete branch leads to a network which focuses more on\nlow-level features without losing out on the global structures. Extensive\nexperiments on two datasets demonstrate that the proposed method achieves\nsignificant improvements over the compressed sensing and popular deep\nlearning-based methods with less number of trainable parameters. Our code is\navailable at https://github.com/guopengf/OUCR.",
    "descriptor": "\nComments: Accepted to MICCAI 2021\n",
    "authors": [
      "Pengfei Guo",
      "Jeya Maria Jose Valanarasu",
      "Puyang Wang",
      "Jinyuan Zhou",
      "Shanshan Jiang",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08886"
  },
  {
    "id": "arXiv:2106.08887",
    "title": "WaveNet-Based Deep Neural Networks for the Characterization of Anomalous  Diffusion (WADNet)",
    "abstract": "Anomalous diffusion, which shows a deviation of transport dynamics from the\nframework of standard Brownian motion, is involved in the evolution of various\nphysical, chemical, biological, and economic systems. The study of such random\nprocesses is of fundamental importance in unveiling the physical properties of\nrandom walkers and complex systems. However, classical methods to characterize\nanomalous diffusion are often disqualified for individual short trajectories,\nleading to the launch of the Anomalous Diffusion (AnDi) Challenge. This\nchallenge aims at objectively assessing and comparing new approaches for single\ntrajectory characterization, with respect to three different aspects: the\ninference of the anomalous diffusion exponent; the classification of the\ndiffusion model; and the segmentation of trajectories. In this article, to\naddress the inference and classification tasks in the challenge, we develop a\nWaveNet-based deep neural network (WADNet) by combining a modified WaveNet\nencoder with long short-term memory networks, without any prior knowledge of\nanomalous diffusion. As the performance of our model has surpassed the current\n1st places in the challenge leaderboard on both two tasks for all dimensions (6\nsubtasks), WADNet could be the part of state-of-the-art techniques to decode\nthe AnDi database. Our method presents a benchmark for future research, and\ncould accelerate the development of a versatile tool for the characterization\nof anomalous diffusion.",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Dezhong Li",
      "Qiujin Yao",
      "Zihan Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.08887"
  },
  {
    "id": "arXiv:2106.08888",
    "title": "Bandit Modeling of Map Selection in Counter-Strike: Global Offensive",
    "abstract": "Many esports use a pick and ban process to define the parameters of a match\nbefore it starts. In Counter-Strike: Global Offensive (CSGO) matches, two teams\nfirst pick and ban maps, or virtual worlds, to play. Teams typically ban and\npick maps based on a variety of factors, such as banning maps which they do not\npractice, or choosing maps based on the team's recent performance. We introduce\na contextual bandit framework to tackle the problem of map selection in CSGO\nand to investigate teams' pick and ban decision-making. Using a data set of\nover 3,500 CSGO matches and over 25,000 map selection decisions, we consider\ndifferent framings for the problem, different contexts, and different reward\nmetrics. We find that teams have suboptimal map choice policies with respect to\nboth picking and banning. We also define an approach for rewarding bans, which\nhas not been explored in the bandit setting, and find that incorporating ban\nrewards improves model performance. Finally, we determine that usage of our\nmodel could improve teams' predicted map win probability by up to 11% and raise\noverall match win probabilities by 19.8% for evenly-matched teams.",
    "descriptor": "\nComments: 6 pages, 3 figures, IJCAI-AISA 2021\n",
    "authors": [
      "Guido Petri",
      "Michael H. Stanley",
      "Alec B. Hon",
      "Alexander Dong",
      "Peter Xenopoulos",
      "Cl\u00e1udio Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08888"
  },
  {
    "id": "arXiv:2106.08889",
    "title": "Cardiovascular Disease Prediction using Recursive Feature Elimination  and Gradient Boosting Classification Techniques",
    "abstract": "Cardiovascular diseases (CVDs) are one of the most common chronic illnesses\nthat affect peoples health. Early detection of CVDs can reduce mortality rates\nby preventing or reducing the severity of the disease. Machine learning\nalgorithms are a promising method for identifying risk factors. This paper\nproposes a proposed recursive feature elimination-based gradient boosting\n(RFE-GB) algorithm in order to obtain accurate heart disease prediction. The\npatients health record with important CVD features has been analyzed for the\nevaluation of the results. Several other machine learning methods were also\nused to build the prediction model, and the results were compared with the\nproposed model. The results of this proposed model infer that the combined\nrecursive feature elimination and gradient boosting algorithm achieves the\nhighest accuracy (89.7 %). Further, with an area under the curve of 0.84, the\nproposed RFE-GB algorithm was found superior and had obtained a substantial\ngain over other techniques. Thus, the proposed RFE-GB algorithm will serve as a\nprominent model for CVD estimation and treatment.",
    "descriptor": "\nComments: 20 pages, 9 figures\n",
    "authors": [
      "Prasannavenkatesan Theerthagiri",
      "Vidya J"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08889"
  },
  {
    "id": "arXiv:2106.08890",
    "title": "ModelDiff: Testing-Based DNN Similarity Comparison for Model Reuse  Detection",
    "abstract": "The knowledge of a deep learning model may be transferred to a student model,\nleading to intellectual property infringement or vulnerability propagation.\nDetecting such knowledge reuse is nontrivial because the suspect models may not\nbe white-box accessible and/or may serve different tasks. In this paper, we\npropose ModelDiff, a testing-based approach to deep learning model similarity\ncomparison. Instead of directly comparing the weights, activations, or outputs\nof two models, we compare their behavioral patterns on the same set of test\ninputs. Specifically, the behavioral pattern of a model is represented as a\ndecision distance vector (DDV), in which each element is the distance between\nthe model's reactions to a pair of inputs. The knowledge similarity between two\nmodels is measured with the cosine similarity between their DDVs. To evaluate\nModelDiff, we created a benchmark that contains 144 pairs of models that cover\nmost popular model reuse methods, including transfer learning, model\ncompression, and model stealing. Our method achieved 91.7% correctness on the\nbenchmark, which demonstrates the effectiveness of using ModelDiff for model\nreuse detection. A study on mobile deep learning apps has shown the feasibility\nof ModelDiff on real-world models.",
    "descriptor": "\nComments: ISSTA 2021\n",
    "authors": [
      "Yuanchun Li",
      "Ziqi Zhang",
      "Bingyan Liu",
      "Ziyue Yang",
      "Yunxin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.08890"
  },
  {
    "id": "arXiv:2106.08892",
    "title": "Development of Quantized DNN Library for Exact Hardware Emulation",
    "abstract": "Quantization is used to speed up execution time and save power when runnning\nDeep neural networks (DNNs) on edge devices like AI chips. To investigate the\neffect of quantization, we need performing inference after quantizing the\nweights of DNN with 32-bit floating-point precision by a some bit width, and\nthen quantizing them back to 32-bit floating-point precision. This is because\nthe DNN library can only handle floating-point numbers. However, the accuracy\nof the emulation does not provide accurate precision. We need accurate\nprecision to detect overflow in MAC operations or to verify the operation on\nedge de vices. We have developed PyParch, a DNN library that executes quantized\nDNNs (QNNs) with exactly the same be havior as hardware. In this paper, we\ndescribe a new proposal and implementation of PyParch. As a result of the\nevaluation, the accuracy of QNNs with arbitrary bit widths can be estimated for\nla rge and complex DNNs such as YOLOv5, and the overflow can be detected. We\nevaluated the overhead of the emulation time and found that it was 5.6 times\nslower for QNN and 42\ntimes slower for QNN with overflow detection compared to the normal DNN\nexecution time.",
    "descriptor": "",
    "authors": [
      "Masato Kiyama",
      "Motoki Amagasaki",
      "Masahiro Iida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08892"
  },
  {
    "id": "arXiv:2106.08895",
    "title": "Simultaneous Training of Partially Masked Neural Networks",
    "abstract": "For deploying deep learning models to lower end devices, it is necessary to\ntrain less resource-demanding variants of state-of-the-art architectures. This\ndoes not eliminate the need for more expensive models as they have a higher\nperformance. In order to avoid training two separate models, we show that it is\npossible to train neural networks in such a way that a predefined 'core'\nsubnetwork can be split-off from the trained full network with remarkable good\nperformance. We extend on prior methods that focused only on core networks of\nsmaller width, while we focus on supporting arbitrary core network\narchitectures. Our proposed training scheme switches consecutively between\noptimizing only the core part of the network and the full one. The accuracy of\nthe full model remains comparable, while the core network achieves better\nperformance than when it is trained in isolation. In particular, we show that\ntraining a Transformer with a low-rank core gives a low-rank model with\nsuperior performance than when training the low-rank model alone. We analyze\nour training scheme theoretically, and show its convergence under assumptions\nthat are either standard or practically justified. Moreover, we show that the\ndeveloped theoretical framework allows analyzing many other partial training\nschemes for neural networks.",
    "descriptor": "",
    "authors": [
      "Amirkeivan Mohtashami",
      "Martin Jaggi",
      "Sebastian U. Stich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08895"
  },
  {
    "id": "arXiv:2106.08897",
    "title": "Toward Robotic Weed Control: Detection of Nutsedge Weed in Bermudagrass  Turf Using Inaccurate and Insufficient Training Data",
    "abstract": "To enable robotic weed control, we develop algorithms to detect nutsedge weed\nfrom bermudagrass turf. Due to the similarity between the weed and the\nbackground turf, manual data labeling is expensive and error-prone.\nConsequently, directly applying deep learning methods for object detection\ncannot generate satisfactory results. Building on an instance detection\napproach (i.e. Mask R-CNN), we combine synthetic data with raw data to train\nthe network. We propose an algorithm to generate high fidelity synthetic data,\nadopting different levels of annotations to reduce labeling cost. Moreover, we\nconstruct a nutsedge skeleton-based probabilistic map (NSPM) as the neural\nnetwork input to reduce the reliance on pixel-wise precise labeling. We also\nmodify loss function from cross entropy to Kullback-Leibler divergence which\naccommodates uncertainty in the labeling process. We implement the proposed\nalgorithm and compare it with both Faster R-CNN and Mask R-CNN. The results\nshow that our design can effectively overcome the impact of imprecise and\ninsufficient training sample issues and significantly outperform the Faster\nR-CNN counterpart with a false negative rate of only 0.4%. In particular, our\napproach also reduces labeling time by 95% while achieving better performance\nif comparing with the original Mask R-CNN approach.",
    "descriptor": "",
    "authors": [
      "Shuangyu Xie",
      "Chengsong Hu",
      "Muthukumar Bagavathiannan",
      "Dezhen Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08897"
  },
  {
    "id": "arXiv:2106.08898",
    "title": "RefBERT: Compressing BERT by Referencing to Pre-computed Representations",
    "abstract": "Recently developed large pre-trained language models, e.g., BERT, have\nachieved remarkable performance in many downstream natural language processing\napplications. These pre-trained language models often contain hundreds of\nmillions of parameters and suffer from high computation and latency in\nreal-world applications. It is desirable to reduce the computation overhead of\nthe models for fast training and inference while keeping the model performance\nin downstream applications. Several lines of work utilize knowledge\ndistillation to compress the teacher model to a smaller student model. However,\nthey usually discard the teacher's knowledge when in inference. Differently, in\nthis paper, we propose RefBERT to leverage the knowledge learned from the\nteacher, i.e., facilitating the pre-computed BERT representation on the\nreference sample and compressing BERT into a smaller student model. To\nguarantee our proposal, we provide theoretical justification on the loss\nfunction and the usage of reference samples. Significantly, the theoretical\nresult shows that including the pre-computed teacher's representations on the\nreference samples indeed increases the mutual information in learning the\nstudent model. Finally, we conduct the empirical evaluation and show that our\nRefBERT can beat the vanilla TinyBERT over 8.1\\% and achieves more than 94\\% of\nthe performance of $\\BERTBASE$ on the GLUE benchmark. Meanwhile, RefBERT is\n7.4x smaller and 9.5x faster on inference than BERT$_{\\rm BASE}$.",
    "descriptor": "\nComments: 8 pages, 1 figure, 3 tables, in IJCNN'21\n",
    "authors": [
      "Xinyi Wang",
      "Haiqin Yang",
      "Liang Zhao",
      "Yang Mo",
      "Jianping Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08898"
  },
  {
    "id": "arXiv:2106.08900",
    "title": "Random feature neural networks learn Black-Scholes type PDEs without  curse of dimensionality",
    "abstract": "This article investigates the use of random feature neural networks for\nlearning Kolmogorov partial (integro-)differential equations associated to\nBlack-Scholes and more general exponential L\\'evy models. Random feature neural\nnetworks are single-hidden-layer feedforward neural networks in which only the\noutput weights are trainable. This makes training particularly simple, but (a\npriori) reduces expressivity. Interestingly, this is not the case for\nBlack-Scholes type PDEs, as we show here. We derive bounds for the prediction\nerror of random neural networks for learning sufficiently non-degenerate\nBlack-Scholes type models. A full error analysis is provided and it is shown\nthat the derived bounds do not suffer from the curse of dimensionality. We also\ninvestigate an application of these results to basket options and validate the\nbounds numerically.\nThese results prove that neural networks are able to \\textit{learn} solutions\nto Black-Scholes type PDEs without the curse of dimensionality. In addition,\nthis provides an example of a relevant learning problem in which random feature\nneural networks are provably efficient.",
    "descriptor": "",
    "authors": [
      "Lukas Gonon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Mathematical Finance (q-fin.MF)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08900"
  },
  {
    "id": "arXiv:2106.08905",
    "title": "Structure First Detail Next: Image Inpainting with Pyramid Generator",
    "abstract": "Recent deep generative models have achieved promising performance in image\ninpainting. However, it is still very challenging for a neural network to\ngenerate realistic image details and textures, due to its inherent spectral\nbias. By our understanding of how artists work, we suggest to adopt a\n`structure first detail next' workflow for image inpainting. To this end, we\npropose to build a Pyramid Generator by stacking several sub-generators, where\nlower-layer sub-generators focus on restoring image structures while the\nhigher-layer sub-generators emphasize image details. Given an input image, it\nwill be gradually restored by going through the entire pyramid in a bottom-up\nfashion. Particularly, our approach has a learning scheme of progressively\nincreasing hole size, which allows it to restore large-hole images. In\naddition, our method could fully exploit the benefits of learning with\nhigh-resolution images, and hence is suitable for high-resolution image\ninpainting. Extensive experimental results on benchmark datasets have validated\nthe effectiveness of our approach compared with state-of-the-art methods.",
    "descriptor": "\nComments: ICCV'21 under review\n",
    "authors": [
      "Shuyi Qu",
      "Zhenxing Niu",
      "Kaizhu Huang",
      "Jianke Zhu",
      "Matan Protter",
      "Gadi Zimerman",
      "Yinghui Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08905"
  },
  {
    "id": "arXiv:2106.08908",
    "title": "A Neural Model for Joint Document and Snippet Ranking in Question  Answering for Large Document Collections",
    "abstract": "Question answering (QA) systems for large document collections typically use\npipelines that (i) retrieve possibly relevant documents, (ii) re-rank them,\n(iii) rank paragraphs or other snippets of the top-ranked documents, and (iv)\nselect spans of the top-ranked snippets as exact answers. Pipelines are\nconceptually simple, but errors propagate from one component to the next,\nwithout later components being able to revise earlier decisions. We present an\narchitecture for joint document and snippet ranking, the two middle stages,\nwhich leverages the intuition that relevant documents have good snippets and\ngood snippets come from relevant documents. The architecture is general and can\nbe used with any neural text relevance ranker. We experiment with two main\ninstantiations of the architecture, based on POSIT-DRMM (PDRMM) and a\nBERT-based ranker. Experiments on biomedical data from BIOASQ show that our\njoint models vastly outperform the pipelines in snippet retrieval, the main\ngoal for QA, with fewer trainable parameters, also remaining competitive in\ndocument retrieval. Furthermore, our joint PDRMM-based model is competitive\nwith BERT-based models, despite using orders of magnitude fewer parameters.\nThese claims are also supported by human evaluation on two test batches of\nBIOASQ. To test our key findings on another dataset, we modified the Natural\nQuestions dataset so that it can also be used for document and snippet\nretrieval. Our joint PDRMM-based model again outperforms the corresponding\npipeline in snippet retrieval on the modified Natural Questions dataset, even\nthough it performs worse than the pipeline in document retrieval. We make our\ncode and the modified Natural Questions dataset publicly available.",
    "descriptor": "\nComments: 12 pages, 3 figures, 4 tables, ACL-IJCNLP 2021\n",
    "authors": [
      "Dimitris Pappas",
      "Ion Androutsopoulos"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08908"
  },
  {
    "id": "arXiv:2106.08909",
    "title": "Offline RL Without Off-Policy Evaluation",
    "abstract": "Most prior approaches to offline reinforcement learning (RL) have taken an\niterative actor-critic approach involving off-policy evaluation. In this paper\nwe show that simply doing one step of constrained/regularized policy\nimprovement using an on-policy Q estimate of the behavior policy performs\nsurprisingly well. This one-step algorithm beats the previously reported\nresults of iterative algorithms on a large portion of the D4RL benchmark. The\nsimple one-step baseline achieves this strong performance without many of the\ntricks used by previously proposed iterative algorithms and is more robust to\nhyperparameters. We argue that the relatively poor performance of iterative\napproaches is a result of the high variance inherent in doing off-policy\nevaluation and magnified by the repeated optimization of policies against those\nhigh-variance estimates. In addition, we hypothesize that the strong\nperformance of the one-step algorithm is due to a combination of favorable\nstructure in the environment and behavior policy.",
    "descriptor": "",
    "authors": [
      "David Brandfonbrener",
      "William F. Whitney",
      "Rajesh Ranganath",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08909"
  },
  {
    "id": "arXiv:2106.08913",
    "title": "Loki: Hardening Code Obfuscation Against Automated Attacks",
    "abstract": "Software obfuscation is a crucial technology to protect intellectual\nproperty. Despite its importance, commercial and academic state-of-the-art\nobfuscation approaches are vulnerable to a plethora of automated deobfuscation\nattacks, such as symbolic execution, taint analysis, or program synthesis.\nWhile several enhanced techniques were proposed to thwart taint analysis or\nsymbolic execution, they either impose a prohibitive runtime overhead or can be\nremoved by compiler optimizations. In general, they suffer from focusing on a\nsingle attack vector, allowing an attacker to switch to other more effective\ntechniques, such as program synthesis. In this work, we present Loki, an\napproach for code obfuscation that is resilient against all known automated\ndeobfuscation attacks. To this end, we deploy multiple techniques, including a\ngeneric approach to synthesize formally verified expressions of arbitrary\ncomplexity. Contrary to state-of-the-art approaches that rely on a few\nhardcoded generation rules, our expressions are more diverse and harder to\npattern match against. Moreover, Loki protects against previously unaccounted\nattack vectors such as program synthesis, for which it reduces the success rate\nto merely 19%. Overall, our design incurs significantly less overhead while\nproviding a much stronger protection level.",
    "descriptor": "",
    "authors": [
      "Moritz Schloegel",
      "Tim Blazytko",
      "Moritz Contag",
      "Cornelius Aschermann",
      "Julius Basler",
      "Thorsten Holz",
      "Ali Abbasi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08913"
  },
  {
    "id": "arXiv:2106.08914",
    "title": "$C^3$: Compositional Counterfactual Constrastive Learning for  Video-grounded Dialogues",
    "abstract": "Video-grounded dialogue systems aim to integrate video understanding and\ndialogue understanding to generate responses that are relevant to both the\ndialogue and video context. Most existing approaches employ deep learning\nmodels and have achieved remarkable performance, given the relatively small\ndatasets available. However, the results are partly accomplished by exploiting\nbiases in the datasets rather than developing multimodal reasoning, resulting\nin limited generalization. In this paper, we propose a novel approach of\nCompositional Counterfactual Contrastive Learning ($C^3$) to develop\ncontrastive training between factual and counterfactual samples in\nvideo-grounded dialogues. Specifically, we design factual/counterfactual\nsampling based on the temporal steps in videos and tokens in dialogues and\npropose contrastive loss functions that exploit object-level or action-level\nvariance. Different from prior approaches, we focus on contrastive hidden state\nrepresentations among compositional output tokens to optimize the\nrepresentation space in a generation setting. We achieved promising performance\ngains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the\nbenefits of our approach in grounding video and dialogue context.",
    "descriptor": "\nComments: 22 pages, 11 figures, 7 tables\n",
    "authors": [
      "Hung Le",
      "Nancy F. Chen",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08914"
  },
  {
    "id": "arXiv:2106.08917",
    "title": "Differentiable Diffusion for Dense Depth Estimation from Multi-view  Images",
    "abstract": "We present a method to estimate dense depth by optimizing a sparse set of\npoints such that their diffusion into a depth map minimizes a multi-view\nreprojection error from RGB supervision. We optimize point positions, depths,\nand weights with respect to the loss by differential splatting that models\npoints as Gaussians with analytic transmittance. Further, we develop an\nefficient optimization routine that can simultaneously optimize the 50k+ points\nrequired for complex scene reconstruction. We validate our routine using ground\ntruth data and show high reconstruction quality. Then, we apply this to light\nfield and wider baseline images via self supervision, and show improvements in\nboth average and outlier error for depth maps diffused from inaccurate sparse\npoints. Finally, we compare qualitative and quantitative results to image\nprocessing and deep learning methods.",
    "descriptor": "",
    "authors": [
      "Numair Khan",
      "Min H. Kim",
      "James Tompkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08917"
  },
  {
    "id": "arXiv:2106.08918",
    "title": "Towards Automatic Actor-Critic Solutions to Continuous Control",
    "abstract": "Model-free off-policy actor-critic methods are an efficient solution to\ncomplex continuous control tasks. However, these algorithms rely on a number of\ndesign tricks and many hyperparameters, making their applications to new\ndomains difficult and computationally expensive. This paper creates an\nevolutionary approach that automatically tunes these design decisions and\neliminates the RL-specific hyperparameters from the Soft Actor-Critic\nalgorithm. Our design is sample efficient and provides practical advantages\nover baseline approaches, including improved exploration, generalization over\nmultiple control frequencies, and a robust ensemble of high-performance\npolicies. Empirically, we show that our agent outperforms well-tuned\nhyperparameter settings in popular benchmarks from the DeepMind Control Suite.\nWe then apply it to new control tasks to find high-performance solutions with\nminimal compute and research effort.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Jake Grigsby",
      "Jin Yong Yoo",
      "Yanjun Qi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08918"
  },
  {
    "id": "arXiv:2106.08921",
    "title": "A Spiking Neural Network for Image Segmentation",
    "abstract": "We seek to investigate the scalability of neuromorphic computing for computer\nvision, with the objective of replicating non-neuromorphic performance on\ncomputer vision tasks while reducing power consumption. We convert the deep\nArtificial Neural Network (ANN) architecture U-Net to a Spiking Neural Network\n(SNN) architecture using the Nengo framework. Both rate-based and spike-based\nmodels are trained and optimized for benchmarking performance and power, using\na modified version of the ISBI 2D EM Segmentation dataset consisting of\nmicroscope images of cells. We propose a partitioning method to optimize\ninter-chip communication to improve speed and energy efficiency when deploying\nmulti-chip networks on the Loihi neuromorphic chip. We explore the advantages\nof regularizing firing rates of Loihi neurons for converting ANN to SNN with\nminimum accuracy loss and optimized energy consumption. We propose a percentile\nbased regularization loss function to limit the spiking rate of the neuron\nbetween a desired range. The SNN is converted directly from the corresponding\nANN, and demonstrates similar semantic segmentation as the ANN using the same\nnumber of neurons and weights. However, the neuromorphic implementation on the\nIntel Loihi neuromorphic chip is over 2x more energy-efficient than\nconventional hardware (CPU, GPU) when running online (one image at a time).\nThese power improvements are achieved without sacrificing the task performance\naccuracy of the network, and when all weights (Loihi, CPU, and GPU networks)\nare quantized to 8 bits.",
    "descriptor": "",
    "authors": [
      "Kinjal Patel",
      "Eric Hunsberger",
      "Sean Batir",
      "Chris Eliasmith"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08921"
  },
  {
    "id": "arXiv:2106.08927",
    "title": "On the long-term learning ability of LSTM LMs",
    "abstract": "We inspect the long-term learning ability of Long Short-Term Memory language\nmodels (LSTM LMs) by evaluating a contextual extension based on the Continuous\nBag-of-Words (CBOW) model for both sentence- and discourse-level LSTM LMs and\nby analyzing its performance. We evaluate on text and speech. Sentence-level\nmodels using the long-term contextual module perform comparably to vanilla\ndiscourse-level LSTM LMs. On the other hand, the extension does not provide\ngains for discourse-level models. These findings indicate that discourse-level\nLSTM LMs already rely on contextual information to perform long-term learning.",
    "descriptor": "",
    "authors": [
      "Wim Boes",
      "Robbe Van Rompaey",
      "Lyan Verwimp",
      "Joris Pelemans",
      "Hugo Van hamme",
      "Patrick Wambacq"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08927"
  },
  {
    "id": "arXiv:2106.08928",
    "title": "Recursive Construction of Stable Assemblies of Recurrent Neural Networks",
    "abstract": "Advanced applications of modern machine learning will likely involve\ncombinations of trained networks, as are already used in spectacular systems\nsuch as DeepMind's AlphaGo. Recursively building such combinations in an\neffective and stable fashion while also allowing for continual refinement of\nthe individual networks - as nature does for biological networks - will require\nnew analysis tools. This paper takes a step in this direction by establishing\ncontraction properties of broad classes of nonlinear recurrent networks and\nneural ODEs, and showing how these quantified properties allow in turn to\nrecursively construct stable networks of networks in a systematic fashion. The\nresults can also be used to stably combine recurrent networks and physical\nsystems with quantified contraction properties. Similarly, they may be applied\nto modular computational models of cognition.",
    "descriptor": "\nComments: 23 pages, 3 figures\n",
    "authors": [
      "Michaela Ennis",
      "Leo Kozachkov",
      "Jean-Jacques Slotine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.08928"
  },
  {
    "id": "arXiv:2106.08934",
    "title": "Personalized News Recommendation: A Survey",
    "abstract": "Personalized news recommendation is an important technique to help users find\ntheir interested news information and alleviate their information overload. It\nhas been extensively studied over decades and has achieved notable success in\nimproving users' news reading experience. However, there are still many\nunsolved problems and challenges that need to be further studied. To help\nresearchers master the advances in personalized news recommendation over the\npast years, in this paper we present a comprehensive overview of personalized\nnews recommendation. Instead of following the conventional taxonomy of news\nrecommendation methods, in this paper we propose a novel perspective to\nunderstand personalized news recommendation based on its core problems and the\nassociated techniques and challenges. We first review the techniques for\ntackling each core problem in a personalized news recommender system and the\nchallenges they face. Next, we introduce the public datasets and evaluation\nmetrics used for personalized news recommendation. We then discuss the key\npoints on improving the responsibility of personalized news recommender\nsystems. Finally, we raise several research directions that are worth\ninvestigating in future. This paper can provide up-to-date and comprehensive\nviews to help readers understand the personalized news recommendation field. We\nhope this paper can facilitate research on personalized news recommendation and\nas well as related fields in natural language processing and data mining.",
    "descriptor": "",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.08934"
  },
  {
    "id": "arXiv:2106.08937",
    "title": "A Predictive Coding Account for Chaotic Itinerancy",
    "abstract": "As a phenomenon in dynamical systems allowing autonomous switching between\nstable behaviors, chaotic itinerancy has gained interest in neurorobotics\nresearch. In this study, we draw a connection between this phenomenon and the\npredictive coding theory by showing how a recurrent neural network implementing\npredictive coding can generate neural trajectories similar to chaotic\nitinerancy in the presence of input noise. We propose two scenarios generating\nrandom and past-independent attractor switching trajectories using our model.",
    "descriptor": "",
    "authors": [
      "Louis Annabi",
      "Alexandre Pitti",
      "Mathias Quoy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08937"
  },
  {
    "id": "arXiv:2106.08938",
    "title": "Memory Leak Detection Algorithms in the Cloud-based Infrastructure",
    "abstract": "A memory leak in an application deployed on the cloud can affect the\navailability and reliability of the application. Therefore, identifying and\nultimately resolve it quickly is highly important. However, in the production\nenvironment running on the cloud, memory leak detection is a challenge without\nthe knowledge of the application or its internal object allocation details.\nThis paper addresses this challenge of detection of memory leaks in\ncloud-based infrastructure without having any internal knowledge by introducing\ntwo novel machine learning-based algorithms: Linear Backward Regression (LBR)\nand Precog and, their two variants: Linear Backward Regression with Change\nPoints Detection (LBRCPD) and Precog with Maximum Filteration (PrecogMF). These\nalgorithms only use one metric i.e the system's memory utilization on which the\napplication is deployed for detection of a memory leak. The developed\nalgorithm's accuracy was tested on 60 virtual machines manually labeled memory\nutilization data and it was found that the proposed PrecogMF algorithm achieves\nthe highest accuracy score of 85%. The same algorithm also achieves this by\ndecreasing the overall compute time by 80% when compared to LBR's compute time.\nThe paper also presents the different memory leak patterns found in the\nvarious memory leak applications and are further classified into different\nclasses based on their visual representation.",
    "descriptor": "\nComments: 10. pages. arXiv admin note: substantial text overlap with arXiv:2101.09799\n",
    "authors": [
      "Anshul Jindal",
      "Paul Staab",
      "Pooja Kulkarni",
      "Jorge Cardoso",
      "Michael Gerndt",
      "Vladimir Podolskiy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.08938"
  },
  {
    "id": "arXiv:2106.08941",
    "title": "Mean-value exergy modeling of internal combustion engines:  characterization of feasible operating regions",
    "abstract": "In this paper, a novel mean-value exergy-based modeling framework for\ninternal combustion engines is developed. Starting from a detailed description\nof the in-cylinder dynamics, the exergy balance is solved for each engine\noperating point and, for the first time, static maps describing the\navailability transfer and destruction phenomena as a function of speed and load\nare derived. The application of the proposed modeling strategy, from the\nconstruction of the static maps to their usage, is shown for a military series\nhybrid electric vehicle. Ultimately, these static maps, while providing\ninsightful information about inefficiencies over the whole operating field of\nthe engine, are the enabling step for the development of exergy-based control\nstrategies aiming at minimizing the overall operational losses of ground\nvehicles.",
    "descriptor": "",
    "authors": [
      "Gabriele Pozzato",
      "Denise Rizze",
      "Simona Onori"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08941"
  },
  {
    "id": "arXiv:2106.08942",
    "title": "Revisiting the Weaknesses of Reinforcement Learning for Neural Machine  Translation",
    "abstract": "Policy gradient algorithms have found wide adoption in NLP, but have recently\nbecome subject to criticism, doubting their suitability for NMT. Choshen et al.\n(2020) identify multiple weaknesses and suspect that their success is\ndetermined by the shape of output distributions rather than the reward. In this\npaper, we revisit these claims and study them under a wider range of\nconfigurations. Our experiments on in-domain and cross-domain adaptation reveal\nthe importance of exploration and reward scaling, and provide empirical\ncounter-evidence to these claims.",
    "descriptor": "",
    "authors": [
      "Samuel Kiegeland",
      "Julia Kreutzer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08942"
  },
  {
    "id": "arXiv:2106.08943",
    "title": "Banker Online Mirror Descent",
    "abstract": "We propose Banker-OMD, a novel framework generalizing the classical Online\nMirror Descent (OMD) technique in online learning algorithm design. Banker-OMD\nallows algorithms to robustly handle delayed feedback, and offers a general\nmethodology for achieving $\\tilde{O}(\\sqrt{T} + \\sqrt{D})$-style regret bounds\nin various delayed-feedback online learning tasks, where $T$ is the time\nhorizon length and $D$ is the total feedback delay. We demonstrate the power of\nBanker-OMD with applications to three important bandit scenarios with delayed\nfeedback, including delayed adversarial Multi-armed bandits (MAB), delayed\nadversarial linear bandits, and a novel delayed best-of-both-worlds MAB\nsetting. Banker-OMD achieves nearly-optimal performance in all the three\nsettings. In particular, it leads to the first delayed adversarial linear\nbandit algorithm achieving $\\tilde{O}(\\text{poly}(n)(\\sqrt{T} + \\sqrt{D}))$\nregret.",
    "descriptor": "",
    "authors": [
      "Jiatai Huang",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08943"
  },
  {
    "id": "arXiv:2106.08946",
    "title": "FGLP: A Federated Fine-Grained Location Prediction System for Mobile  Users",
    "abstract": "Fine-grained location prediction on smart phones can be used to improve\napp/system performance. Application scenarios include video quality adaptation\nas a function of the 5G network quality at predicted user locations, and\naugmented reality apps that speed up content rendering based on predicted user\nlocations. Such use cases require prediction error in the same range as the GPS\nerror, and no existing works on location prediction can achieve this level of\naccuracy. We present a system for fine-grained location prediction (FGLP) of\nmobile users, based on GPS traces collected on the phones. FGLP has two\ncomponents: a federated learning framework and a prediction model. The\nframework runs on the phones of the users and also on a server that coordinates\nlearning from all users in the system. FGLP represents the user location data\nas relative points in an abstract 2D space, which enables learning across\ndifferent physical spaces. The model merges Bidirectional Long Short-Term\nMemory (BiLSTM) and Convolutional Neural Networks (CNN), where BiLSTM learns\nthe speed and direction of the mobile users, and CNN learns information such as\nuser movement preferences. FGLP uses federated learning to protect user privacy\nand reduce bandwidth consumption. Our experimental results, using a dataset\nwith over 600,000 users, demonstrate that FGLP outperforms baseline models in\nterms of prediction accuracy. We also demonstrate that FGLP works well in\nconjunction with transfer learning, which enables model reusability. Finally,\nbenchmark results on several types of Android phones demonstrate FGLP's\nfeasibility in real life.",
    "descriptor": "",
    "authors": [
      "Xiaopeng Jiang",
      "Shuai Zhao",
      "Guy Jacobson",
      "Rittwik Jana",
      "Wen-Ling Hsu",
      "Manoop Talasila",
      "Syed Anwar Aftab",
      "Yi Chen",
      "Cristian Borcea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08946"
  },
  {
    "id": "arXiv:2106.08948",
    "title": "Muzeel: A Dynamic JavaScript Analyzer for Dead Code Elimination in  Today's Web",
    "abstract": "JavaScript contributes to the increasing complexity of today's web. To\nsupport user interactivity and accelerate the development cycle, web developers\nheavily rely on large general-purpose third-party JavaScript libraries. This\npractice increases the size and the processing complexity of a web page by\nbringing additional functions that are not used by the page but unnecessarily\ndownloaded and processed by the browser. In this paper, an analysis of around\n40,000 web pages shows that 70% of JavaScript functions on the median page are\nunused, and the elimination of these functions would contribute to the\nreduction of the page size by 60%. Motivated by these findings, we propose\nMuzeel (which means eliminator in Arabic); a solution for eliminating\nJavaScript functions that are not used in a given web page (commonly referred\nto as dead code). Muzeel extracts all of the page event listeners upon page\nload, and emulates user interactions using a bot that triggers each of these\nevents, in order to eliminate the dead code of functions that are not called by\nany of these events. Our evaluation results spanning several Android mobile\nphones and browsers show that Muzeel speeds up the page load by around 30% on\nlow-end phones, and by 25% on high-end phones under 3G network. It also reduces\nthe speed index (which is an important user experience metric) by 23% and 21%\nunder the same network on low-end, and high-end phones, respectively.\nAdditionally, Muzeel reduces the overall download size while maintaining the\nvisual content and interactive functionality of the pages.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Tofunmi Kupoluyi",
      "Moumena Chaqfeh",
      "Matteo Varvello",
      "Waleed Hashmi",
      "Lakshmi Subramanian",
      "Yasir Zaki"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.08948"
  },
  {
    "id": "arXiv:2106.08956",
    "title": "Detecting chaos in lineage-trees: A deep learning approach",
    "abstract": "Many complex phenomena, from weather systems to heartbeat rhythm patterns,\nare effectively modeled as low-dimensional dynamical systems. Such systems may\nbehave chaotically under certain conditions, and so the ability to detect chaos\nbased on empirical measurement is an important step in characterizing and\npredicting these processes. Classifying a system as chaotic usually requires\nestimating its largest Lyapunov exponent, which quantifies the average rate of\nconvergence or divergence of initially close trajectories in state space, and\nfor which a positive value is generally accepted as an operational definition\nof chaos. Estimating the largest Lyapunov exponent from observations of a\nprocess is especially challenging in systems affected by dynamical noise, which\nis the case for many models of real-world processes, in particular models of\nbiological systems. We describe a novel method for estimating the largest\nLyapunov exponent from data, based on training Deep Learning models on\nsynthetically generated trajectories, and demonstrate that this method yields\naccurate and noise-robust predictions given relatively short inputs and across\na range of different dynamical systems. Our method is unique in that it can\nanalyze tree-shaped data, a ubiquitous topology in biological settings, and\nspecifically in dynamics over lineages of cells or organisms. We also\ncharacterize the types of input information extracted by our models for their\npredictions, allowing for a deeper understanding into the different ways by\nwhich chaos can be analyzed in different topologies.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Hagai Rappeport",
      "Irit Levin Reisman",
      "Naftali Tishby",
      "Nathalie Q. Balaban"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08956"
  },
  {
    "id": "arXiv:2106.08957",
    "title": "Early fault detection with multi-target neural networks",
    "abstract": "Wind power is seeing a strong growth around the world. At the same time,\nshrinking profit margins in the energy markets let wind farm managers explore\noptions for cost reductions in the turbine operation and maintenance.\nSensor-based condition monitoring facilitates remote diagnostics of turbine\nsubsystems, enabling faster responses when unforeseen maintenance is required.\nCondition monitoring with data from the turbines' supervisory control and data\nacquisition (SCADA) systems was proposed and SCADA-based fault detection and\ndiagnosis approaches introduced based on single-task normal operation models of\nturbine state variables. As the number of SCADA channels has grown strongly,\nthousands of independent single-target models are in place today for monitoring\na single turbine. Multi-target learning was recently proposed to limit the\nnumber of models. This study applied multi-target neural networks to the task\nof early fault detection in drive-train components. The accuracy and delay of\ndetecting gear bearing faults were compared to state-of-the-art single-target\napproaches. We found that multi-target multi-layer perceptrons (MLPs) detected\nfaults at least as early and in many cases earlier than single-target MLPs. The\nmulti-target MLPs could detect faults up to several days earlier than the\nsingle-target models. This can deliver a significant advantage in the planning\nand performance of maintenance work. At the same time, the multi-target MLPs\nachieved the same level of prediction stability.",
    "descriptor": "",
    "authors": [
      "Angela Meyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08957"
  },
  {
    "id": "arXiv:2106.08960",
    "title": "Collaborative Training of Acoustic Encoders for Speech Recognition",
    "abstract": "On-device speech recognition requires training models of different sizes for\ndeploying on devices with various computational budgets. When building such\ndifferent models, we can benefit from training them jointly to take advantage\nof the knowledge shared between them. Joint training is also efficient since it\nreduces the redundancy in the training procedure's data handling operations. We\npropose a method for collaboratively training acoustic encoders of different\nsizes for speech recognition. We use a sequence transducer setup where\ndifferent acoustic encoders share a common predictor and joiner modules. The\nacoustic encoders are also trained using co-distillation through an auxiliary\ntask for frame level chenone prediction, along with the transducer loss. We\nperform experiments using the LibriSpeech corpus and demonstrate that the\ncollaboratively trained acoustic encoders can provide up to a 11% relative\nimprovement in the word error rate on both the test partitions.",
    "descriptor": "\nComments: INTERSPEECH 2021\n",
    "authors": [
      "Varun Nagaraja",
      "Yangyang Shi",
      "Ganesh Venkatesh",
      "Ozlem Kalinli",
      "Michael L. Seltzer",
      "Vikas Chandra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.08960"
  },
  {
    "id": "arXiv:2106.08961",
    "title": "Intelligent Tire-Based Slip Ratio Estimation Using Different Machine  Learning Algorithms",
    "abstract": "Estimation of the longitudinal slip ratio of tires is important in boosting\nthe control performance of the vehicle under driving and braking conditions. In\nthis paper, the slip ratio is estimated using four machine learning algorithms\n(Neural Network, Gradient Boosting Machine, Random Forest and Support Vector\nMachine) based on the acceleration signals from the tri-axial MEMS\naccelerometers utilized in the intelligent tire system. The experimental data\nare collected through the MTS experimental platform. The corresponding\nacceleration signals within the tire contact patch are extracted after\nfiltering to be used for the training the aforesaid machine learning\nalgorithms. A comparison is provided between the implemented ML algorithms\nusing a 10-fold CV. NRMS errors in the CV results indicate that NN has the\nhighest accuracy in comparison with other techniques. The NRSM errors of NN,\nGBM, RF, and SVM are 2.59\\%, 3.30\\%, 4.21\\%, and 5.34\\%, respectively. Among\nthese techniques, GBM has a more stable results as it has the smallest output\nvariance. The present study with the fusion of intelligent tire system and\nmachine learning algorithms paves the way for the accurate estimation of tire\nslip ratio, which is critical for the development of reliable vehicle control\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Nan Xu",
      "Zepeng Tang",
      "Jianfeng Zhou",
      "Hassan Askari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08961"
  },
  {
    "id": "arXiv:2106.08962",
    "title": "Efficient Deep Learning: A Survey on Making Deep Learning Models  Smaller, Faster, and Better",
    "abstract": "Deep Learning has revolutionized the fields of computer vision, natural\nlanguage understanding, speech recognition, information retrieval and more.\nHowever, with the progressive improvements in deep learning models, their\nnumber of parameters, latency, resources required to train, etc. have all have\nincreased significantly. Consequently, it has become important to pay attention\nto these footprint metrics of a model as well, not just its quality. We present\nand motivate the problem of efficiency in deep learning, followed by a thorough\nsurvey of the five core areas of model efficiency (spanning modeling\ntechniques, infrastructure, and hardware) and the seminal work there. We also\npresent an experiment-based guide along with code, for practitioners to\noptimize their model training and deployment. We believe this is the first\ncomprehensive survey in the efficient deep learning space that covers the\nlandscape of model efficiency from modeling techniques to hardware support. Our\nhope is that this survey would provide the reader with the mental model and the\nnecessary understanding of the field to apply generic efficiency techniques to\nimmediately get significant improvements, and also equip them with ideas for\nfurther research and experimentation to achieve additional gains.",
    "descriptor": "",
    "authors": [
      "Gaurav Menghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08962"
  },
  {
    "id": "arXiv:2106.08963",
    "title": "Deep-learning based Tools for Automated Protocol Definition of Advanced  Diagnostic Imaging Exams",
    "abstract": "Purpose: This study evaluates the effectiveness and impact of automated\norder-based protocol assignment for magnetic resonance imaging (MRI) exams\nusing natural language processing (NLP) and deep learning (DL).\nMethods: NLP tools were applied to retrospectively process orders from over\n116,000 MRI exams with 200 unique sub-specialized protocols (\"Local\" protocol\nclass). Separate DL models were trained on 70\\% of the processed data for\n\"Local\" protocols as well as 93 American College of Radiology (\"ACR\") protocols\nand 48 \"General\" protocols. The DL Models were assessed in an \"auto-protocoling\n(AP)\" inference mode which returns the top recommendation and in a \"clinical\ndecision support (CDS)\" inference mode which returns up to 10 protocols for\nradiologist review. The accuracy of each protocol recommendation was computed\nand analyzed based on the difference between the normalized output score of the\ncorresponding neural net for the top two recommendations.\nResults: The top predicted protocol in AP mode was correct for 82.8%, 73.8%,\nand 69.3% of the test cases for \"General\", \"ACR\", and \"Local\" protocol classes,\nrespectively. Higher levels of accuracy over 96% were obtained for all protocol\nclasses in CDS mode. However, at current validation performance levels, the\nproposed models offer modest, positive, financial impact on large-scale imaging\nnetworks.\nConclusions: DL-based protocol automation is feasible and can be tuned to\nroute substantial fractions of exams for auto-protocoling, with higher accuracy\nwith more general protocols. Economic analyses of the tested algorithms\nindicate that improved algorithm performance is required to yield a practical\nexam auto-protocoling tool for sub-specialized imaging exams.",
    "descriptor": "",
    "authors": [
      "Andrew S. Nencka",
      "Mohammad Sherafati",
      "Timothy Goebel",
      "Parag Tolat",
      "Kevin M. Koch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.08963"
  },
  {
    "id": "arXiv:2106.08967",
    "title": "Estimating the Robustness of Public Transport Systems Using Machine  Learning",
    "abstract": "The planning of attractive and cost efficient public transport systems is a\nhighly complex optimization process involving many steps. Integrating\nrobustness from a passenger's point of view makes the task even more\nchallenging. With numerous different definitions of robustness in literature, a\nreal-world acceptable evaluation of the robustness of a public transport system\nis to simulate its performance under a large number of possible scenarios.\nUnfortunately, this is computationally very expensive. In this paper, we\ntherefore explore a new way of such a scenario-based robustness approximation\nby using methods from machine learning. We achieve a fast approach with a very\nhigh accuracy by gathering a subset of key features of a public transport\nsystem and its passenger demand and training an artificial neural network to\nlearn the outcome of a given set of robustness tests. The network is then able\nto predict the robustness of untrained instances with high accuracy using only\nits key features, allowing for a robustness oracle for transport planners that\napproximates the robustness in constant time. Such an oracle can be used as\nblack box to increase the robustness within a local search framework for\nintegrated public transportation planning. In computational experiments with\ndifferent benchmark instances we demonstrate an excellent quality of our\npredictions.",
    "descriptor": "",
    "authors": [
      "Matthias M\u00fcller-Hannemann",
      "Ralf R\u00fcckert",
      "Alexander Schiewe",
      "Anita Sch\u00f6bel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08967"
  },
  {
    "id": "arXiv:2106.08968",
    "title": "Optimized ensemble deep learning framework for scalable forecasting of  dynamics containing extreme events",
    "abstract": "The remarkable flexibility and adaptability of both deep learning models and\nensemble methods have led to the proliferation for their application in\nunderstanding many physical phenomena. Traditionally, these two techniques have\nlargely been treated as independent methodologies in practical applications.\nThis study develops an optimized ensemble deep learning (OEDL) framework\nwherein these two machine learning techniques are jointly used to achieve\nsynergistic improvements in model accuracy, stability, scalability, and\nreproducibility prompting a new wave of applications in the forecasting of\ndynamics. Unpredictability is considered as one of the key features of chaotic\ndynamics, so forecasting such dynamics of nonlinear systems is a relevant issue\nin the scientific community. It becomes more challenging when the prediction of\nextreme events is the focus issue for us. In this circumstance, the proposed\nOEDL model based on a best convex combination of feed-forward neural networks,\nreservoir computing, and long short-term memory can play a key role in\nadvancing predictions of dynamics consisting of extreme events. The combined\nframework can generate the best out-of-sample performance than the individual\ndeep learners and standard ensemble framework for both numerically simulated\nand real world data sets. We exhibit the outstanding performance of the OEDL\nframework for forecasting extreme events generated from Lienard-type system,\nprediction of COVID-19 cases in Brazil, dengue cases in San Juan, and sea\nsurface temperature in Nino 3.4 region.",
    "descriptor": "\nComments: 14 pages, 8 figures, any comments are welcome\n",
    "authors": [
      "Arnob Ray",
      "Tanujit Chakraborty",
      "Dibakar Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08968"
  },
  {
    "id": "arXiv:2106.08970",
    "title": "Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks  Trained from Scratch",
    "abstract": "As the curation of data for machine learning becomes increasingly automated,\ndataset tampering is a mounting threat. Backdoor attackers tamper with training\ndata to embed a vulnerability in models that are trained on that data. This\nvulnerability is then activated at inference time by placing a \"trigger\" into\nthe model's input. Typical backdoor attacks insert the trigger directly into\nthe training data, although the presence of such an attack may be visible upon\ninspection. In contrast, the Hidden Trigger Backdoor Attack achieves poisoning\nwithout placing a trigger into the training data at all. However, this hidden\ntrigger attack is ineffective at poisoning neural networks trained from\nscratch. We develop a new hidden trigger attack, Sleeper Agent, which employs\ngradient matching, data selection, and target model re-training during the\ncrafting process. Sleeper Agent is the first hidden trigger backdoor attack to\nbe effective against neural networks trained from scratch. We demonstrate its\neffectiveness on ImageNet and in black-box settings. Our implementation code\ncan be found at https://github.com/hsouri/Sleeper-Agent.",
    "descriptor": "",
    "authors": [
      "Hossein Souri",
      "Micah Goldblum",
      "Liam Fowl",
      "Rama Chellappa",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08970"
  },
  {
    "id": "arXiv:2106.08971",
    "title": "Model-Based Counterfactual Synthesizer for Interpretation",
    "abstract": "Counterfactuals, serving as one of the emerging type of model\ninterpretations, have recently received attention from both researchers and\npractitioners. Counterfactual explanations formalize the exploration of\n``what-if'' scenarios, and are an instance of example-based reasoning using a\nset of hypothetical data samples. Counterfactuals essentially show how the\nmodel decision alters with input perturbations. Existing methods for generating\ncounterfactuals are mainly algorithm-based, which are time-inefficient and\nassume the same counterfactual universe for different queries. To address these\nlimitations, we propose a Model-based Counterfactual Synthesizer (MCS)\nframework for interpreting machine learning models. We first analyze the\nmodel-based counterfactual process and construct a base synthesizer using a\nconditional generative adversarial net (CGAN). To better approximate the\ncounterfactual universe for those rare queries, we novelly employ the umbrella\nsampling technique to conduct the MCS framework training. Besides, we also\nenhance the MCS framework by incorporating the causal dependence among\nattributes with model inductive bias, and validate its design correctness from\nthe causality identification perspective. Experimental results on several\ndatasets demonstrate the effectiveness as well as efficiency of our proposed\nMCS framework, and verify the advantages compared with other alternatives.",
    "descriptor": "\nComments: 11 pages in total; To appear in KDD'21;\n",
    "authors": [
      "Fan Yang",
      "Sahan Suresh Alva",
      "Jiahao Chen",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08971"
  },
  {
    "id": "arXiv:2106.08972",
    "title": "Redefining Neural Architecture Search of Heterogeneous Multi-Network  Models by Characterizing Variation Operators and Model Components",
    "abstract": "With neural architecture search methods gaining ground on manually designed\ndeep neural networks -even more rapidly as model sophistication escalates-, the\nresearch trend shifts towards arranging different and often increasingly\ncomplex neural architecture search spaces. In this conjuncture, delineating\nalgorithms which can efficiently explore these search spaces can result in a\nsignificant improvement over currently used methods, which, in general,\nrandomly select the structural variation operator, hoping for a performance\ngain. In this paper, we investigate the effect of different variation operators\nin a complex domain, that of multi-network heterogeneous neural models. These\nmodels have an extensive and complex search space of structures as they require\nmultiple sub-networks within the general model in order to answer to different\noutput types. From that investigation, we extract a set of general guidelines,\nwhose application is not limited to that particular type of model, and are\nuseful to determine the direction in which an architecture optimization method\ncould find the largest improvement. To deduce the set of guidelines, we\ncharacterize both the variation operators, according to their effect on the\ncomplexity and performance of the model; and the models, relying on diverse\nmetrics which estimate the quality of the different parts composing it.",
    "descriptor": "",
    "authors": [
      "Unai Garciarena",
      "Roberto Santana",
      "Alexander Mendiburu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.08972"
  },
  {
    "id": "arXiv:2106.08973",
    "title": "Data-driven, structure-preserving approximations to entropy-based moment  closures for kinetic equations",
    "abstract": "We present a data-driven approach to construct entropy-based closures for the\nmoment system from kinetic equations. The proposed closure learns the entropy\nfunction by fitting the map between the moments and the entropy of the moment\nsystem, and thus does not depend on the space-time discretization of the moment\nsystem and specific problem configurations such as initial and boundary\nconditions. With convex and $C^2$ approximations, this data-driven closure\ninherits several structural properties from entropy-based closures, such as\nentropy dissipation, hyperbolicity, and H-Theorem. We construct convex\napproximations to the Maxwell-Boltzmann entropy using convex splines and neural\nnetworks, test them on the plane source benchmark problem for linear transport\nin slab geometry, and compare the results to the standard, optimization-based\nM$_N$ closures. Numerical results indicate that these data-driven closures\nprovide accurate solutions in much less computation time than the M$_N$\nclosures.",
    "descriptor": "",
    "authors": [
      "William A. Porteous",
      "M. Paul Laiu",
      "Cory D. Hauck"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.08973"
  },
  {
    "id": "arXiv:2106.08977",
    "title": "Named Entity Recognition with Small Strongly Labeled and Large Weakly  Labeled Data",
    "abstract": "Weak supervision has shown promising results in many natural language\nprocessing tasks, such as Named Entity Recognition (NER). Existing work mainly\nfocuses on learning deep NER models only with weak supervision, i.e., without\nany human annotation, and shows that by merely using weakly labeled data, one\ncan achieve good performance, though still underperforms fully supervised NER\nwith manually/strongly labeled data. In this paper, we consider a more\npractical scenario, where we have both a small amount of strongly labeled data\nand a large amount of weakly labeled data. Unfortunately, we observe that\nweakly labeled data does not necessarily improve, or even deteriorate the model\nperformance (due to the extensive noise in the weak labels) when we train deep\nNER models over a simple or weighted combination of the strongly labeled and\nweakly labeled data. To address this issue, we propose a new multi-stage\ncomputational framework -- NEEDLE with three essential ingredients: (1) weak\nlabel completion, (2) noise-aware loss function, and (3) final fine-tuning over\nthe strongly labeled data. Through experiments on E-commerce query NER and\nBiomedical NER, we demonstrate that NEEDLE can effectively suppress the noise\nof the weak labels and outperforms existing methods. In particular, we achieve\nnew SOTA F1-scores on 3 Biomedical NER datasets: BC5CDR-chem 93.74,\nBC5CDR-disease 90.69, NCBI-disease 92.28.",
    "descriptor": "\nComments: The 59th Annual Meeting of the Association for Computational Linguistics (ACL 2021)\n",
    "authors": [
      "Haoming Jiang",
      "Danqing Zhang",
      "Tianyu Cao",
      "Bing Yin",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08977"
  },
  {
    "id": "arXiv:2106.08983",
    "title": "The Oxford Road Boundaries Dataset",
    "abstract": "In this paper we present the Oxford Road Boundaries Dataset, designed for\ntraining and testing machine-learning-based road-boundary detection and\ninference approaches. We have hand-annotated two of the 10 km-long forays from\nthe Oxford Robotcar Dataset and generated from other forays several thousand\nfurther examples with semi-annotated road-boundary masks. To boost the number\nof training samples in this way, we used a vision-based localiser to project\nlabels from the annotated datasets to other traversals at different times and\nweather conditions. As a result, we release 62605 labelled samples, of which\n47639 samples are curated. Each of these samples contains both raw and\nclassified masks for left and right lenses. Our data contains images from a\ndiverse set of scenarios such as straight roads, parked cars, junctions, etc.\nFiles for download and tools for manipulating the labelled data are available\nat: oxford-robotics-institute.github.io/road-boundaries-dataset",
    "descriptor": "\nComments: Accepted for publication at the workshop \"3D-DLAD: 3D-Deep Learning for Autonomous Driving\" (WS15), Intelligent Vehicles Symposium (IV 2021)\n",
    "authors": [
      "Tarlan Suleymanov",
      "Matthew Gadd",
      "Daniele De Martini",
      "Paul Newman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.08983"
  },
  {
    "id": "arXiv:2106.08987",
    "title": "Ookami: Deployment and Initial Experiences",
    "abstract": "Ookami is a computer technology testbed supported by the United States\nNational Science Foundation. It provides researchers with access to the A64FX\nprocessor developed by Fujitsu in collaboration with RIK{\\Xi}N for the Japanese\npath to exascale computing, as deployed in Fugaku, the fastest computer in the\nworld. By focusing on crucial architectural details, the ARM-based, multi-core,\n512-bit SIMD-vector processor with ultrahigh-bandwidth memory promises to\nretain familiar and successful programming models while achieving very high\nperformance for a wide range of applications. We review relevant technology and\nsystem details, and the main body of the paper focuses on initial experiences\nwith the hardware and software ecosystem for micro-benchmarks, mini-apps, and\nfull applications, and starts to answer questions about where such technologies\nfit into the NSF ecosystem.",
    "descriptor": "\nComments: 14 pages, 7 figures, PEARC '21: Practice and Experience in Advanced Research Computing, July 18--22, 2021, Boston, MA, USA\n",
    "authors": [
      "Andrew Burford",
      "Alan C. Calder",
      "David Carlson",
      "Barbara Chapman",
      "Firat Co\u015eKun",
      "Tony Curtis",
      "Catherine Feldman",
      "Robert J. Harrison",
      "Yan Kang",
      "Benjamin Michalow-Icz",
      "Eric Raut",
      "Eva Siegmann",
      "Daniel G. Wood",
      "Robert L. Deleon",
      "Mathew Jones",
      "Nikolay A. Simakov",
      "Joseph P. White",
      "Dossay Oryspayev"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.08987"
  },
  {
    "id": "arXiv:2106.08992",
    "title": "An unifying point of view on expressive power of GNNs",
    "abstract": "Graph Neural Networks (GNNs) are a wide class of connectionist models for\ngraph processing. They perform an iterative message passing operation on each\nnode and its neighbors, to solve classification/ clustering tasks --- on some\nnodes or on the whole graph --- collecting all such messages, regardless of\ntheir order. Despite the differences among the various models belonging to this\nclass, most of them adopt the same computation scheme, based on a local\naggregation mechanism and, intuitively, the local computation framework is\nmainly responsible for the expressive power of GNNs. In this paper, we prove\nthat the Weisfeiler--Lehman test induces an equivalence relationship on the\ngraph nodes that exactly corresponds to the unfolding equivalence, defined on\nthe original GNN model. Therefore, the results on the expressive power of the\noriginal GNNs can be extended to general GNNs which, under mild conditions, can\nbe proved capable of approximating, in probability and up to any precision, any\nfunction on graphs that respects the unfolding equivalence.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Giuseppe Alessio D'Inverno",
      "Monica Bianchini",
      "Maria Lucia Sampoli",
      "Franco Scarselli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08992"
  },
  {
    "id": "arXiv:2106.08998",
    "title": "Herd Behaviors in Epidemics: A Dynamics-Coupled Evolutionary Games  Approach",
    "abstract": "The recent COVID-19 pandemic has led to an increasing interest in the\nmodeling and analysis of infectious diseases. The pandemic has made a\nsignificant impact on the way we behave and interact in our daily life. The\npast year has witnessed a strong interplay between human behaviors and epidemic\nspreading. In this paper, we propose an evolutionary game-theoretic framework\nto study the coupled evolutions of herd behaviors and epidemics. Our framework\nextends the classical degree-based mean-field epidemic model over complex\nnetworks by coupling it with the evolutionary game dynamics. The statistically\nequivalent individuals in a population choose their social activity intensities\nbased on the fitness or the payoffs that depend on the state of the epidemics.\nMeanwhile, the spreading of the infectious disease over the complex network is\nreciprocally influenced by the players' social activities. We analyze the\ncoupled dynamics by studying the stationary properties of the epidemic for a\ngiven herd behavior and the structural properties of the game for a given\nepidemic process. The decisions of the herd turn out to be strategic\nsubstitutes. We formulate an equivalent finite-player game and an equivalent\nnetwork to represent the interactions among the finite populations. We develop\nstructure-preserving approximation techniques to study time-dependent\nproperties of the joint evolution of the behavioral and epidemic dynamics. The\nresemblance between the simulated coupled dynamics and the real COVID-19\nstatistics in the numerical experiments indicates the predictive power of our\nframework.",
    "descriptor": "\nComments: 32 pages, 12 figures\n",
    "authors": [
      "Shutian Liu",
      "Yuhan Zhao",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.08998"
  },
  {
    "id": "arXiv:2106.09003",
    "title": "Invertible Attention",
    "abstract": "Attention has been proved to be an efficient mechanism to capture long-range\ndependencies. However, so far it has not been deployed in invertible networks.\nThis is due to the fact that in order to make a network invertible, every\ncomponent within the network needs to be a bijective transformation, but a\nnormal attention block is not. In this paper, we propose invertible attention\nthat can be plugged into existing invertible models. We mathematically and\nexperimentally prove that the invertibility of an attention model can be\nachieved by carefully constraining its Lipschitz constant. We validate the\ninvertibility of our invertible attention on image reconstruction task with 3\npopular datasets: CIFAR-10, SVHN, and CelebA. We also show that our invertible\nattention achieves similar performance in comparison with normal non-invertible\nattention on dense prediction tasks.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Jiajun Zha",
      "Yiran Zhong",
      "Jing Zhang",
      "Liang Zheng",
      "Richard Hartley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09003"
  },
  {
    "id": "arXiv:2106.09006",
    "title": "\"I have no idea what they're trying to accomplish:\" Enthusiastic and  Casual Signal Users' Understanding of Signal PINs",
    "abstract": "We conducted an online study with $n = 235$ Signal users on their\nunderstanding and usage of PINs in Signal. In our study, we observe a split in\nPIN management and composition strategies between users who can explain the\npurpose of the Signal PINs (56%; enthusiasts) and users who cannot (44%; casual\nusers). Encouraging adoption of PINs by Signal appears quite successful: only\n14% opted-out of setting a PIN entirely. Among those who did set a PIN, most\nenthusiasts had long, complex alphanumeric PINs generated by and saved in a\npassword manager. Meanwhile more casual Signal users mostly relied on short\nnumeric-only PINs. Our results suggest that better communication about the\npurpose of the Signal PIN could help more casual users understand the features\nPINs enable (such as that it is not simply a personal identification number).\nThis communication could encourage a stronger security posture.",
    "descriptor": "\nComments: To appear at Symposium on Usable Privacy and Security (SOUPS) 2021\n",
    "authors": [
      "Daniel V. Bailey",
      "Philipp Markert",
      "Adam J. Aviv"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.09006"
  },
  {
    "id": "arXiv:2106.09009",
    "title": "End-to-End Spoken Language Understanding for Generalized Voice  Assistants",
    "abstract": "End-to-end (E2E) spoken language understanding (SLU) systems predict\nutterance semantics directly from speech using a single model. Previous work in\nthis area has focused on targeted tasks in fixed domains, where the output\nsemantic structure is assumed a priori and the input speech is of limited\ncomplexity. In this work we present our approach to developing an E2E model for\ngeneralized SLU in commercial voice assistants (VAs). We propose a fully\ndifferentiable, transformer-based, hierarchical system that can be pretrained\nat both the ASR and NLU levels. This is then fine-tuned on both transcription\nand semantic classification losses to handle a diverse set of intent and\nargument combinations. This leads to an SLU system that achieves significant\nimprovements over baselines on a complex internal generalized VA dataset with a\n43% improvement in accuracy, while still meeting the 99% accuracy benchmark on\nthe popular Fluent Speech Commands dataset. We further evaluate our model on a\nhard test set, exclusively containing slot arguments unseen in training, and\ndemonstrate a nearly 20% improvement, showing the efficacy of our approach in\ntruly demanding VA scenarios.",
    "descriptor": "\nComments: Accepted to Interspeech 2021; 5 pages, 2 tables, 1 figure\n",
    "authors": [
      "Michael Saxon",
      "Samridhi Choudhary",
      "Joseph P. McKenna",
      "Athanasios Mouchtaris"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.09009"
  },
  {
    "id": "arXiv:2106.09011",
    "title": "Evolving Image Compositions for Feature Representation Learning",
    "abstract": "Convolutional neural networks for visual recognition require large amounts of\ntraining samples and usually benefit from data augmentation. This paper\nproposes PatchMix, a data augmentation method that creates new samples by\ncomposing patches from pairs of images in a grid-like pattern. These new\nsamples' ground truth labels are set as proportional to the number of patches\nfrom each image. We then add a set of additional losses at the patch-level to\nregularize and to encourage good representations at both the patch and image\nlevels. A ResNet-50 model trained on ImageNet using PatchMix exhibits superior\ntransfer learning capabilities across a wide array of benchmarks. Although\nPatchMix can rely on random pairings and random grid-like patterns for mixing,\nwe explore evolutionary search as a guiding strategy to discover optimal\ngrid-like patterns and image pairing jointly. For this purpose, we conceive a\nfitness function that bypasses the need to re-train a model to evaluate each\nchoice. In this way, PatchMix outperforms a base model on CIFAR-10 (+1.91),\nCIFAR-100 (+5.31), Tiny Imagenet (+3.52), and ImageNet (+1.16) by significant\nmargins, also outperforming previous state-of-the-art pairwise augmentation\nstrategies.",
    "descriptor": "",
    "authors": [
      "Paola Cascante-Bonilla",
      "Arshdeep Sekhon",
      "Yanjun Qi",
      "Vicente Ordonez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.09011"
  },
  {
    "id": "arXiv:2106.09012",
    "title": "A learning agent that acquires social norms from public sanctions in  decentralized multi-agent settings",
    "abstract": "Society is characterized by the presence of a variety of social norms:\ncollective patterns of sanctioning that can prevent miscoordination and\nfree-riding. Inspired by this, we aim to construct learning dynamics where\npotentially beneficial social norms can emerge. Since social norms are\nunderpinned by sanctioning, we introduce a training regime where agents can\naccess all sanctioning events but learning is otherwise decentralized. This\nsetting is technologically interesting because sanctioning events may be the\nonly available public signal in decentralized multi-agent systems where reward\nor policy-sharing is infeasible or undesirable. To achieve collective action in\nthis setting we construct an agent architecture containing a classifier module\nthat categorizes observed behaviors as approved or disapproved, and a\nmotivation to punish in accord with the group. We show that social norms emerge\nin multi-agent systems containing this agent and investigate the conditions\nunder which this helps them achieve socially beneficial outcomes.",
    "descriptor": "",
    "authors": [
      "Eugene Vinitsky",
      "Raphael K\u00f6ster",
      "John P. Agapiou",
      "Edgar Du\u00e9\u00f1ez-Guzm\u00e1n",
      "Alexander Sasha Vezhnevets",
      "Joel Z. Leibo"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.09012"
  },
  {
    "id": "arXiv:2106.09013",
    "title": "An Intelligent Question Answering System based on Power Knowledge Graph",
    "abstract": "The intelligent question answering (IQA) system can accurately capture users'\nsearch intention by understanding the natural language questions, searching\nrelevant content efficiently from a massive knowledge-base, and returning the\nanswer directly to the user. Since the IQA system can save inestimable time and\nworkforce in data search and reasoning, it has received more and more attention\nin data science and artificial intelligence. This article introduced a domain\nknowledge graph using the graph database and graph computing technologies from\nmassive heterogeneous data in electric power. It then proposed an IQA system\nbased on the electrical power knowledge graph to extract the intent and\nconstraints of natural interrogation based on the natural language processing\n(NLP) method, to construct graph data query statements via knowledge reasoning,\nand to complete the accurate knowledge search and analysis to provide users\nwith an intuitive visualization. This method thoroughly combined knowledge\ngraph and graph computing characteristics, realized high-speed multi-hop\nknowledge correlation reasoning analysis in tremendous knowledge. The proposed\nwork can also provide a basis for the context-aware intelligent question and\nanswer.",
    "descriptor": "\nComments: 5 pages,6 figures, IEEE General Meeting 2020\n",
    "authors": [
      "Yachen Tang",
      "Haiyun Han",
      "Xianmao Yu",
      "Jing Zhao",
      "Guangyi Liu",
      "Longfei Wei"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09013"
  },
  {
    "id": "arXiv:2106.09015",
    "title": "Cascading Modular Network (CAM-Net) for Multimodal Image Synthesis",
    "abstract": "Deep generative models such as GANs have driven impressive advances in\nconditional image synthesis in recent years. A persistent challenge has been to\ngenerate diverse versions of output images from the same input image, due to\nthe problem of mode collapse: because only one ground truth output image is\ngiven per input image, only one mode of the conditional distribution is\nmodelled. In this paper, we focus on this problem of multimodal conditional\nimage synthesis and build on the recently proposed technique of Implicit\nMaximum Likelihood Estimation (IMLE). Prior IMLE-based methods required\ndifferent architectures for different tasks, which limit their applicability,\nand were lacking in fine details in the generated images. We propose CAM-Net, a\nunified architecture that can be applied to a broad range of tasks.\nAdditionally, it is capable of generating convincing high frequency details,\nachieving a reduction of the Frechet Inception Distance (FID) by up to 45.3%\ncompared to the baseline.",
    "descriptor": "\nComments: Videos available as ancillary files\n",
    "authors": [
      "Shichong Peng",
      "Alireza Moazeni",
      "Ke Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09015"
  },
  {
    "id": "arXiv:2106.09016",
    "title": "Smoothing the Disentangled Latent Style Space for Unsupervised  Image-to-Image Translation",
    "abstract": "Image-to-Image (I2I) multi-domain translation models are usually evaluated\nalso using the quality of their semantic interpolation results. However,\nstate-of-the-art models frequently show abrupt changes in the image appearance\nduring interpolation, and usually perform poorly in interpolations across\ndomains. In this paper, we propose a new training protocol based on three\nspecific losses which help a translation network to learn a smooth and\ndisentangled latent style space in which: 1) Both intra- and inter-domain\ninterpolations correspond to gradual changes in the generated images and 2) The\ncontent of the source image is better preserved during the translation.\nMoreover, we propose a novel evaluation metric to properly measure the\nsmoothness of latent style space of I2I translation models. The proposed method\ncan be plugged into existing translation approaches, and our extensive\nexperiments on different datasets show that it can significantly boost the\nquality of the generated images and the graduality of the interpolations.",
    "descriptor": "\nComments: Accepted to CVPR 2021\n",
    "authors": [
      "Yahui Liu",
      "Enver Sangineto",
      "Yajing Chen",
      "Linchao Bao",
      "Haoxian Zhang",
      "Nicu Sebe",
      "Bruno Lepri",
      "Wei Wang",
      "Marco De Nadai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09016"
  },
  {
    "id": "arXiv:2106.09017",
    "title": "Bridging Multi-Task Learning and Meta-Learning: Towards Efficient  Training and Effective Adaptation",
    "abstract": "Multi-task learning (MTL) aims to improve the generalization of several\nrelated tasks by learning them jointly. As a comparison, in addition to the\njoint training scheme, modern meta-learning allows unseen tasks with limited\nlabels during the test phase, in the hope of fast adaptation over them. Despite\nthe subtle difference between MTL and meta-learning in the problem formulation,\nboth learning paradigms share the same insight that the shared structure\nbetween existing training tasks could lead to better generalization and\nadaptation. In this paper, we take one important step further to understand the\nclose connection between these two learning paradigms, through both theoretical\nanalysis and empirical investigation. Theoretically, we first demonstrate that\nMTL shares the same optimization formulation with a class of gradient-based\nmeta-learning (GBML) algorithms. We then prove that for over-parameterized\nneural networks with sufficient depth, the learned predictive functions of MTL\nand GBML are close. In particular, this result implies that the predictions\ngiven by these two models are similar over the same unseen task. Empirically,\nwe corroborate our theoretical findings by showing that, with proper\nimplementation, MTL is competitive against state-of-the-art GBML algorithms on\na set of few-shot image classification benchmarks. Since existing GBML\nalgorithms often involve costly second-order bi-level optimization, our\nfirst-order MTL method is an order of magnitude faster on large-scale datasets\nsuch as mini-ImageNet. We believe this work could help bridge the gap between\nthese two learning paradigms, and provide a computationally efficient\nalternative to GBML that also supports fast task adaptation.",
    "descriptor": "\nComments: ICML 2021 camera-ready version. Code is released at this https URL\n",
    "authors": [
      "Haoxiang Wang",
      "Han Zhao",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09017"
  },
  {
    "id": "arXiv:2106.09018",
    "title": "End-to-End Semi-Supervised Object Detection with Soft Teacher",
    "abstract": "This paper presents an end-to-end semi-supervised object detection approach,\nin contrast to previous more complex multi-stage methods. The end-to-end\ntraining gradually improves pseudo label qualities during the curriculum, and\nthe more and more accurate pseudo labels in turn benefit object detection\ntraining. We also propose two simple yet effective techniques within this\nframework: a soft teacher mechanism where the classification loss of each\nunlabeled bounding box is weighed by the classification score produced by the\nteacher network; a box jittering approach to select reliable pseudo boxes for\nthe learning of box regression. On COCO benchmark, the proposed approach\noutperforms previous methods by a large margin under various labeling ratios,\ni.e. 1\\%, 5\\% and 10\\%. Moreover, our approach proves to perform also well when\nthe amount of labeled data is relatively large. For example, it can improve a\n40.9 mAP baseline detector trained using the full COCO training set by +3.6\nmAP, reaching 44.5 mAP, by leveraging the 123K unlabeled images of COCO. On the\nstate-of-the-art Swin Transformer-based object detector (58.9 mAP on test-dev),\nit can still significantly improve the detection accuracy by +1.5 mAP, reaching\n60.4 mAP, and improve the instance segmentation accuracy by +1.2 mAP, reaching\n52.4 mAP, pushing the new state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Mengde Xu",
      "Zheng Zhang",
      "Han Hu",
      "Jianfeng Wang",
      "Lijuan Wang",
      "Fangyun Wei",
      "Xiang Bai",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09018"
  },
  {
    "id": "arXiv:2106.09019",
    "title": "Amortized Synthesis of Constrained Configurations Using a Differentiable  Surrogate",
    "abstract": "In design, fabrication, and control problems, we are often faced with the\ntask of synthesis, in which we must generate an object or configuration that\nsatisfies a set of constraints while maximizing one or more objective\nfunctions. The synthesis problem is typically characterized by a physical\nprocess in which many different realizations may achieve the goal. This\nmany-to-one map presents challenges to the supervised learning of feed-forward\nsynthesis, as the set of viable designs may have a complex structure. In\naddition, the non-differentiable nature of many physical simulations prevents\ndirect optimization. We address both of these problems with a two-stage neural\nnetwork architecture that we may consider to be an autoencoder. We first learn\nthe decoder: a differentiable surrogate that approximates the many-to-one\nphysical realization process. We then learn the encoder, which maps from goal\nto design, while using the fixed decoder to evaluate the quality of the\nrealization. We evaluate the approach on two case studies: extruder path\nplanning in additive manufacturing and constrained soft robot inverse\nkinematics. We compare our approach to direct optimization of design using the\nlearned surrogate, and to supervised learning of the synthesis problem. We find\nthat our approach produces higher quality solutions than supervised learning,\nwhile being competitive in quality with direct optimization, at a greatly\nreduced computational cost.",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Xingyuan Sun",
      "Tianju Xue",
      "Szymon M. Rusinkiewicz",
      "Ryan P. Adams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09019"
  },
  {
    "id": "arXiv:2011.14193",
    "title": "Model Predictive Control with and without Terminal Weight: Stability and  Algorithms",
    "abstract": "This paper presents stability analysis tools for model predictive control\n(MPC) with and without terminal weight. Stability analysis of MPC with a\nlimited horizon but without terminal weight is a long-standing open problem. By\nusing a modified value function as an Lyapunov function candidate and the\nprinciple of optimality, this paper establishes stability conditions for this\ntype of widely spread MPC algorithms. A new stability guaranteed MPC algorithm\nwithout terminal weight (MPCS) is presented. With the help of designing a new\nsublevel set defined by the value function of one-step ahead stage cost,\nconditions for checking its recursive feasibility and stability of the proposed\nMPC algorithm are presented. The new stability condition and the derived MPCS\novercome the difficulties arising in the existing terminal weight based MPC\nframework, including the need of searching a suitable terminal weight and\npossible poor performance caused by an inappropriate terminal weight. This work\nis further extended to MPC with a terminal weight for the completeness.\nNumerical examples are presented to demonstrate the effectiveness of the\nproposed tool, whereas the existing stability analysis tools are either not\napplicable or lead to quite conservative results. It shows that the proposed\ntools offer a number of mechanisms to achieve stability: adjusting state and/or\ncontrol weights, extending the length of horizon, and adding a simple extra\nconstraint on the first or second state in the optimisation.",
    "descriptor": "",
    "authors": [
      "Wen-Hua Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.14193"
  },
  {
    "id": "arXiv:2106.07996",
    "title": "Over-the-Air Equalization with Reconfigurable Intelligent Surfaces",
    "abstract": "Reconfigurable intelligent surface (RIS)-empowered communications is on the\nrise and is a promising technology envisioned to aid in 6G and beyond wireless\ncommunication networks. RISs can manipulate impinging waves through their\nelectromagnetic elements enabling some sort of a control over the wireless\nchannel. In this paper, the potential of RIS technology is explored to perform\nequalization over-the-air for frequency-selective channels whereas,\nequalization is generally conducted at either the transmitter or receiver in\nconventional communication systems. Specifically, with the aid of an RIS, the\nfrequency-selective channel from the transmitter to the RIS is transformed to a\nfrequency-flat channel through elimination of inter-symbol interference (ISI)\ncomponents at the receiver. ISI is eliminated by adjusting the phases of\nimpinging signals particularly to maximize the incoming signal of the strongest\ntap. First, a general end-to-end system model is provided and a continuous to\ndiscrete-time signal model is presented. Subsequently, a probabilistic analysis\nfor the elimination of ISI terms is conducted and reinforced with computer\nsimulations. Furthermore, a theoretical error probability analysis is performed\nalong with computer simulations. It is demonstrated that with the proposed\nmethod, ISI can successfully be eliminated and the RIS-aided communication\nchannel can be converted from frequency-selective to frequency-flat.",
    "descriptor": "",
    "authors": [
      "Emre Arslan",
      "Ibrahim Yildirim",
      "Fatih Kilinc",
      "Ertugrul Basar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.07996"
  },
  {
    "id": "arXiv:2106.08334",
    "title": "Quantum-inspired event reconstruction with Tensor Networks: Matrix  Product States",
    "abstract": "Tensor Networks are non-trivial representations of high-dimensional tensors,\noriginally designed to describe quantum many-body systems. We show that Tensor\nNetworks are ideal vehicles to connect quantum mechanical concepts to machine\nlearning techniques, thereby facilitating an improved interpretability of\nneural networks. This study presents the discrimination of top quark signal\nover QCD background processes using a Matrix Product State classifier. We show\nthat entanglement entropy can be used to interpret what a network learns, which\ncan be used to reduce the complexity of the network and feature space without\nloss of generality or performance. For the optimisation of the network, we\ncompare the Density Matrix Renormalization Group (DMRG) algorithm to stochastic\ngradient descent (SGD) and propose a joined training algorithm to harness the\nexplainability of DMRG with the efficiency of SGD.",
    "descriptor": "\nComments: 25 pages, 23 figures\n",
    "authors": [
      "Jack Y. Araz",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.08334"
  },
  {
    "id": "arXiv:2106.08352",
    "title": "Ctrl-P: Temporal Control of Prosodic Variation for Speech Synthesis",
    "abstract": "Text does not fully specify the spoken form, so text-to-speech models must be\nable to learn from speech data that vary in ways not explained by the\ncorresponding text. One way to reduce the amount of unexplained variation in\ntraining data is to provide acoustic information as an additional learning\nsignal. When generating speech, modifying this acoustic information enables\nmultiple distinct renditions of a text to be produced.\nSince much of the unexplained variation is in the prosody, we propose a model\nthat generates speech explicitly conditioned on the three primary acoustic\ncorrelates of prosody: $F_{0}$, energy and duration. The model is flexible\nabout how the values of these features are specified: they can be externally\nprovided, or predicted from text, or predicted then subsequently modified.\nCompared to a model that employs a variational auto-encoder to learn\nunsupervised latent features, our model provides more interpretable,\ntemporally-precise, and disentangled control. When automatically predicting the\nacoustic features from text, it generates speech that is more natural than that\nfrom a Tacotron 2 model with reference encoder. Subsequent human-in-the-loop\nmodification of the predicted acoustic features can significantly further\nincrease naturalness.",
    "descriptor": "\nComments: To be published in Interspeech 2021. 5 pages, 4 figures\n",
    "authors": [
      "Devang S Ram Mohan",
      "Vivian Hu",
      "Tian Huey Teh",
      "Alexandra Torresquintero",
      "Christopher G. R. Wallis",
      "Marlene Staib",
      "Lorenzo Foglianti",
      "Jiameng Gao",
      "Simon King"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.08352"
  },
  {
    "id": "arXiv:2106.08374",
    "title": "Warning Signs for Non-Markovian Bifurcations: Color Blindness and  Scaling Laws",
    "abstract": "Warning signs for tipping points (or critical transitions) have been very\nactively studied. Although the theory has been applied successfully in models\nand in experiments, for many complex systems, e.g., for tipping in climate\nsystems, there are ongoing debates, when warning signs can be extracted from\ndata. In this work, we provide an explanation, why these difficulties occur,\nand we significantly advance the general theory of warning signs for nonlinear\nstochastic dynamics. A key scenario deals with stochastic systems approaching a\nbifurcation point dynamically upon slow parameter variation. The stochastic\nfluctuations are generically able to probe the dynamics near a deterministic\nattractor to detect critical slowing down. Using scaling laws, one can then\nanticipate the distance to a bifurcation. Previous warning signs results assume\nthat the noise is Markovian, most often even white. Here we study warning signs\nfor non-Markovian systems including colored noise and $\\alpha$-regular Volterra\nprocesses (of which fractional Brownian motion and the Rosenblatt process are\nspecial cases). We prove that early-warning scaling laws can disappear\ncompletely or drastically change their exponent based upon the parameters\ncontrolling the noise process. This provides a clear explanation, why applying\nstandard warning signs results to reduced models of complex systems may not\nagree with data-driven studies. We demonstrate our results numerically in the\ncontext of a box model of the Atlantic Meridional Overturning Circulation\n(AMOC).",
    "descriptor": "",
    "authors": [
      "Christian Kuehn",
      "Kerstin Lux",
      "Alexandra Neamtu"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2106.08374"
  },
  {
    "id": "arXiv:2106.08419",
    "title": "A Framework for Discovering Optimal Solutions in Photonic Inverse Design",
    "abstract": "Photonic inverse design has emerged as an indispensable engineering tool for\ncomplex optical systems. In many instances it is important to optimize for both\nmaterial and geometry configurations, which results in complex non-smooth\nsearch spaces with multiple local minima. Finding solutions approaching global\noptimum may present a computationally intractable task. Here, we develop a\nframework that allows expediting the search of solutions close to global\noptimum on complex optimization spaces. We study the way representative black\nbox optimization algorithms work, including genetic algorithm (GA), particle\nswarm optimization (PSO), simulated annealing (SA), and mesh adaptive direct\nsearch (NOMAD). We then propose and utilize a two-step approach that identifies\nbest performance algorithms on arbitrarily complex search spaces. We reveal a\nconnection between the search space complexity and algorithm performance and\nfind that PSO and NOMAD consistently deliver better performance for mixed\ninteger problems encountered in photonic inverse design, particularly with the\naccount of material combinations. Our results differ from a commonly\nanticipated advantage of GA. Our findings will foster more efficient design of\nphotonic systems with optimal performance.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Jagrit Digani",
      "Phillip Hon",
      "Artur R. Davoyan"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.08419"
  },
  {
    "id": "arXiv:2106.08429",
    "title": "Optimal control of a 2D diffusion-advection process with a team of  mobile actuators under jointly optimal guidance",
    "abstract": "This paper describes an optimization framework to control a distributed\nparameter system (DPS) using a team of mobile actuators. The framework\nsimultaneously seeks optimal control of the DPS and optimal guidance of the\nmobile actuators such that a cost function associated with both the DPS and the\nmobile actuators is minimized subject to the dynamics of each. The cost\nincurred from controlling the DPS is linear-quadratic, which is transformed\ninto an equivalent form as a quadratic term associated with an operator-valued\nRiccati equation. This equivalent form reduces the problem to seeking for\nguidance only because the optimal control can be recovered once the optimal\nguidance is obtained. We establish conditions for the existence of a solution\nto the proposed problem. Since computing an optimal solution requires\napproximation, we also establish the conditions for convergence to the exact\noptimal solution of the approximate optimal solution. That is, when evaluating\nthese two solutions by the original cost function, the difference becomes\narbitrarily small as the approximation gets finer. Two numerical examples\ndemonstrate the performance of the optimal control and guidance obtained from\nthe proposed approach.",
    "descriptor": "\nComments: to appear in Automatica\n",
    "authors": [
      "Sheng Cheng",
      "Derek A. Paley"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.08429"
  },
  {
    "id": "arXiv:2106.08443",
    "title": "Reproducing Kernel Hilbert Space, Mercer's Theorem, Eigenfunctions,  Nystr\u00f6m Method, and Use of Kernels in Machine Learning: Tutorial and Survey",
    "abstract": "This is a tutorial and survey paper on kernels, kernel methods, and related\nfields. We start with reviewing the history of kernels in functional analysis\nand machine learning. Then, Mercer kernel, Hilbert and Banach spaces,\nReproducing Kernel Hilbert Space (RKHS), Mercer's theorem and its proof,\nfrequently used kernels, kernel construction from distance metric, important\nclasses of kernels (including bounded, integrally positive definite, universal,\nstationary, and characteristic kernels), kernel centering and normalization,\nand eigenfunctions are explained in detail. Then, we introduce types of use of\nkernels in machine learning including kernel methods (such as kernel support\nvector machines), kernel learning by semi-definite programming, Hilbert-Schmidt\nindependence criterion, maximum mean discrepancy, kernel mean embedding, and\nkernel dimensionality reduction. We also cover rank and factorization of kernel\nmatrix as well as the approximation of eigenfunctions and kernels using the\nNystr{\\\"o}m method. This paper can be useful for various fields of science\nincluding machine learning, dimensionality reduction, functional analysis in\nmathematics, and mathematical physics in quantum mechanics.",
    "descriptor": "\nComments: To appear as a part of an upcoming textbook on dimensionality reduction and manifold learning\n",
    "authors": [
      "Benyamin Ghojogh",
      "Ali Ghodsi",
      "Fakhri Karray",
      "Mark Crowley"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2106.08443"
  },
  {
    "id": "arXiv:2106.08489",
    "title": "Lorenz System State Stability Identification using Neural Networks",
    "abstract": "Nonlinear dynamical systems such as Lorenz63 equations are known to be\nchaotic in nature and sensitive to initial conditions. As a result, a small\nperturbation in the initial conditions results in deviation in state trajectory\nafter a few time steps. The algorithms and computational resources needed to\naccurately identify the system states vary depending on whether the solution is\nin transition region or not. We refer to the transition and non-transition\nregions as unstable and stable regions respectively. We label a system state to\nbe stable if it's immediate past and future states reside in the same regime.\nHowever, at a given time step we don't have the prior knowledge about whether\nsystem is in stable or unstable region. In this paper, we develop and train a\nfeed forward (multi-layer perceptron) Neural Network to classify the system\nstates of a Lorenz system as stable and unstable. We pose this task as a\nsupervised learning problem where we train the neural network on Lorenz system\nwhich have states labeled as stable or unstable. We then test the ability of\nthe neural network models to identify the stable and unstable states on a\ndifferent Lorenz system that is generated using different initial conditions.\nWe also evaluate the classification performance in the mismatched case i.e.,\nwhen the initial conditions for training and validation data are sampled from\ndifferent intervals. We show that certain normalization schemes can greatly\nimprove the performance of neural networks in especially these mismatched\nscenarios. The classification framework developed in the paper can be a\npreprocessor for a larger context of sequential decision making framework where\nthe decision making is performed based on observed stable or unstable states.",
    "descriptor": "",
    "authors": [
      "Megha Subramanian",
      "Ramakrishna Tipireddy",
      "Samrat Chatterjee"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08489"
  },
  {
    "id": "arXiv:2106.08502",
    "title": "Averaging on the Bures-Wasserstein manifold: dimension-free convergence  of gradient descent",
    "abstract": "We study first-order optimization algorithms for computing the barycenter of\nGaussian distributions with respect to the optimal transport metric. Although\nthe objective is geodesically non-convex, Riemannian GD empirically converges\nrapidly, in fact faster than off-the-shelf methods such as Euclidean GD and SDP\nsolvers. This stands in stark contrast to the best-known theoretical results\nfor Riemannian GD, which depend exponentially on the dimension. In this work,\nwe prove new geodesic convexity results which provide stronger control of the\niterates, yielding a dimension-free convergence rate. Our techniques also\nenable the analysis of two related notions of averaging, the\nentropically-regularized barycenter and the geometric median, providing the\nfirst convergence guarantees for Riemannian GD for these problems.",
    "descriptor": "\nComments: 48 pages, 8 figures\n",
    "authors": [
      "Jason M. Altschuler",
      "Sinho Chewi",
      "Patrik Gerber",
      "Austin J. Stromme"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08502"
  },
  {
    "id": "arXiv:2106.08519",
    "title": "Global Rhythm Style Transfer Without Text Transcriptions",
    "abstract": "Prosody plays an important role in characterizing the style of a speaker or\nan emotion, but most non-parallel voice or emotion style transfer algorithms do\nnot convert any prosody information. Two major components of prosody are pitch\nand rhythm. Disentangling the prosody information, particularly the rhythm\ncomponent, from the speech is challenging because it involves breaking the\nsynchrony between the input speech and the disentangled speech representation.\nAs a result, most existing prosody style transfer algorithms would need to rely\non some form of text transcriptions to identify the content information, which\nconfines their application to high-resource languages only. Recently,\nSpeechSplit has made sizeable progress towards unsupervised prosody style\ntransfer, but it is unable to extract high-level global prosody style in an\nunsupervised manner. In this paper, we propose AutoPST, which can disentangle\nglobal prosody style from speech without relying on any text transcriptions.\nAutoPST is an Autoencoder-based Prosody Style Transfer framework with a\nthorough rhythm removal module guided by the self-expressive representation\nlearning. Experiments on different style transfer tasks show that AutoPST can\neffectively convert prosody that correctly reflects the styles of the target\ndomains.",
    "descriptor": "",
    "authors": [
      "Kaizhi Qian",
      "Yang Zhang",
      "Shiyu Chang",
      "Jinjun Xiong",
      "Chuang Gan",
      "David Cox",
      "Mark Hasegawa-Johnson"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.08519"
  },
  {
    "id": "arXiv:2106.08525",
    "title": "A Feynman-Kac Type Theorem for ODEs: Solutions of Second Order ODEs as  Modes of Diffusions",
    "abstract": "In this article, we prove a Feynman-Kac type result for a broad class of\nsecond order ordinary differential equations. The classical Feynman-Kac theorem\nsays that the solution to a broad class of second order parabolic equation is\nthe mean of a particular diffusion. In our situation, we show that the solution\nto a system of second order ordinary differential equations is the mode of a\ndiffusion, defined through the Onsager-Machlup formalism. One potential utility\nof our result is to use Monte Carlo type methods to estimate the solutions of\nordinary differential equations. We conclude with examples of our result\nillustrating its utility in numerically solving linear second order ODEs.",
    "descriptor": "\nComments: Comments welcome!\n",
    "authors": [
      "Zachary Selk",
      "Harsha Honnappa"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.08525"
  },
  {
    "id": "arXiv:2106.08534",
    "title": "Sharp convergence to steady states of Allen-Cahn",
    "abstract": "In our recent work we found a surprising breakdown of symmetry conservation:\nusing standard numerical discretization with very high precision the computed\nnumerical solutions corresponding to very nice initial data may converge to\ncompletely incorrect steady states due to the gradual accumulation of machine\nround-off error. We solved this issue by introducing a new Fourier filter\ntechnique for solutions with certain band gap properties. To further\ninvestigate the attracting basin of steady states we classify in this work all\npossible bounded nontrivial steady states for the Allen-Cahn equation. We\ncharacterize sharp dependence of nontrivial steady states on the diffusion\ncoefficient and prove strict monotonicity of the associated energy. In\nparticular, we establish a certain self-replicating property amongst the\nhierarchy of steady states and give a full classification of their energies and\nprofiles. We develop a new modulation theory and prove sharp convergence to the\nsteady state with explicit rates and profiles.",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Dong Li",
      "Chaoyu Quan",
      "Tao Tang",
      "Wen Yang"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08534"
  },
  {
    "id": "arXiv:2106.08536",
    "title": "Detection of Consonant Errors in Disordered Speech Based on  Consonant-vowel Segment Embedding",
    "abstract": "Speech sound disorder (SSD) refers to a type of developmental disorder in\nyoung children who encounter persistent difficulties in producing certain\nspeech sounds at the expected age. Consonant errors are the major indicator of\nSSD in clinical assessment. Previous studies on automatic assessment of SSD\nrevealed that detection of speech errors concerning short and transitory\nconsonants is less satisfactory. This paper investigates a neural network based\napproach to detecting consonant errors in disordered speech using\nconsonant-vowel (CV) diphone segment in comparison to using consonant monophone\nsegment. The underlying assumption is that the vowel part of a CV segment\ncarries important information of co-articulation from the consonant. Speech\nembeddings are extracted from CV segments by a recurrent neural network model.\nThe similarity scores between the embeddings of the test segment and the\nreference segments are computed to determine if the test segment is the\nexpected consonant or not. Experimental results show that using CV segments\nachieves improved performance on detecting speech errors concerning those\n\"difficult\" consonants reported in the previous studies.",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2021\n",
    "authors": [
      "Si-Ioi Ng",
      "Cymie Wing-Yee Ng",
      "Jingyu Li",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.08536"
  },
  {
    "id": "arXiv:2106.08562",
    "title": "Multi-resolution intra-predictive coding of 3D point cloud attributes",
    "abstract": "We propose an intra frame predictive strategy for compression of 3D point\ncloud attributes. Our approach is integrated with the region adaptive graph\nFourier transform (RAGFT), a multi-resolution transform formed by a composition\nof localized block transforms, which produces a set of low pass (approximation)\nand high pass (detail) coefficients at multiple resolutions. Since the\ntransform operations are spatially localized, RAGFT coefficients at a given\nresolution may still be correlated. To exploit this phenomenon, we propose an\nintra-prediction strategy, in which decoded approximation coefficients are used\nto predict uncoded detail coefficients. The prediction residuals are then\nquantized and entropy coded. For the 8i dataset, we obtain gains up to 0.5db as\ncompared to intra predicted point cloud compresion based on the region adaptive\nHaar transform (RAHT).",
    "descriptor": "\nComments: 5 pages, 5 figures, Accepted at 2021 IEEE International Conference on Image Processing (ICIP)\n",
    "authors": [
      "Eduardo Pavez",
      "Andre L. Souto",
      "Ricardo L. De Queiroz",
      "Antonio Ortega"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Graphics (cs.GR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.08562"
  },
  {
    "id": "arXiv:2106.08595",
    "title": "Multi-Speaker ASR Combining Non-Autoregressive Conformer CTC and  Conditional Speaker Chain",
    "abstract": "Non-autoregressive (NAR) models have achieved a large inference computation\nreduction and comparable results with autoregressive (AR) models on various\nsequence to sequence tasks. However, there has been limited research aiming to\nexplore the NAR approaches on sequence to multi-sequence problems, like\nmulti-speaker automatic speech recognition (ASR). In this study, we extend our\nproposed conditional chain model to NAR multi-speaker ASR. Specifically, the\noutput of each speaker is inferred one-by-one using both the input mixture\nspeech and previously-estimated conditional speaker features. In each step, a\nNAR connectionist temporal classification (CTC) encoder is used to perform\nparallel computation. With this design, the total inference steps will be\nrestricted to the number of mixed speakers. Besides, we also adopt the\nConformer and incorporate an intermediate CTC loss to improve the performance.\nExperiments on WSJ0-Mix and LibriMix corpora show that our model outperforms\nother NAR models with only a slight increase of latency, achieving WERs of\n22.3% and 24.9%, respectively. Moreover, by including the data of variable\nnumbers of speakers, our model can even better than the PIT-Conformer AR model\nwith only 1/7 latency, obtaining WERs of 19.9% and 34.3% on WSJ0-2mix and\nWSJ0-3mix sets. All of our codes are publicly available at\nhttps://github.com/pengchengguo/espnet/tree/conditional-multispk.",
    "descriptor": "\nComments: Accepted by Interspeech 2021\n",
    "authors": [
      "Pengcheng Guo",
      "Xuankai Chang",
      "Shinji Watanabe",
      "Lei Xie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.08595"
  },
  {
    "id": "arXiv:2106.08597",
    "title": "Breaking The Dimension Dependence in Sparse Distribution Estimation  under Communication Constraints",
    "abstract": "We consider the problem of estimating a $d$-dimensional $s$-sparse discrete\ndistribution from its samples observed under a $b$-bit communication\nconstraint. The best-known previous result on $\\ell_2$ estimation error for\nthis problem is $O\\left( \\frac{s\\log\\left( {d}/{s}\\right)}{n2^b}\\right)$.\nSurprisingly, we show that when sample size $n$ exceeds a minimum threshold\n$n^*(s, d, b)$, we can achieve an $\\ell_2$ estimation error of $O\\left(\n\\frac{s}{n2^b}\\right)$. This implies that when $n>n^*(s, d, b)$ the convergence\nrate does not depend on the ambient dimension $d$ and is the same as knowing\nthe support of the distribution beforehand.\nWe next ask the question: ``what is the minimum $n^*(s, d, b)$ that allows\ndimension-free convergence?''. To upper bound $n^*(s, d, b)$, we develop novel\nlocalization schemes to accurately and efficiently localize the unknown\nsupport. For the non-interactive setting, we show that $n^*(s, d, b) = O\\left(\n\\min \\left( {d^2\\log^2 d}/{2^b}, {s^4\\log^2 d}/{2^b}\\right) \\right)$. Moreover,\nwe connect the problem with non-adaptive group testing and obtain a\npolynomial-time estimation scheme when $n = \\tilde{\\Omega}\\left({s^4\\log^4\nd}/{2^b}\\right)$. This group testing based scheme is adaptive to the sparsity\nparameter $s$, and hence can be applied without knowing it. For the interactive\nsetting, we propose a novel tree-based estimation scheme and show that the\nminimum sample-size needed to achieve dimension-free convergence can be further\nreduced to $n^*(s, d, b) = \\tilde{O}\\left( {s^2\\log^2 d}/{2^b} \\right)$.",
    "descriptor": "",
    "authors": [
      "Wei-Ning Chen",
      "Peter Kairouz",
      "Ayfer \u00d6zg\u00fcr"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08597"
  },
  {
    "id": "arXiv:2106.08602",
    "title": "Colouring graphs with no induced six-vertex path or diamond",
    "abstract": "The diamond is the graph obtained by removing an edge from the complete graph\non 4 vertices. A graph is ($P_6$, diamond)-free if it contains no induced\nsubgraph isomorphic to a six-vertex path or a diamond. In this paper we show\nthat the chromatic number of a ($P_6$, diamond)-free graph $G$ is no larger\nthan the maximum of 6 and the clique number of $G$. We do this by reducing the\nproblem to imperfect ($P_6$, diamond)-free graphs via the Strong Perfect Graph\nTheorem, dividing the imperfect graphs into several cases, and giving a proper\ncolouring for each case. We also show that there is exactly one\n6-vertex-critical ($P_6$, diamond, $K_6$)-free graph. Together with the\nLov\\'asz theta function, this gives a polynomial time algorithm to compute the\nchromatic number of ($P_6$, diamond)-free graphs.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Jan Goedgebeur",
      "Shenwei Huang",
      "Yiao Ju",
      "Owen Merkel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.08602"
  },
  {
    "id": "arXiv:2106.08619",
    "title": "Locality defeats the curse of dimensionality in convolutional  teacher-student scenarios",
    "abstract": "Convolutional neural networks perform a local and translationally-invariant\ntreatment of the data: quantifying which of these two aspects is central to\ntheir success remains a challenge. We study this problem within a\nteacher-student framework for kernel regression, using `convolutional' kernels\ninspired by the neural tangent kernel of simple convolutional architectures of\ngiven filter size. Using heuristic methods from physics, we find in the\nridgeless case that locality is key in determining the learning curve exponent\n$\\beta$ (that relates the test error $\\epsilon_t\\sim P^{-\\beta}$ to the size of\nthe training set $P$), whereas translational invariance is not. In particular,\nif the filter size of the teacher $t$ is smaller than that of the student $s$,\n$\\beta$ is a function of $s$ only and does not depend on the input dimension.\nWe confirm our predictions on $\\beta$ empirically. Theoretically, in some cases\n(including when teacher and student are equal) it can be shown that this\nprediction is an upper bound on performance. We conclude by proving, using a\nnatural universality assumption, that performing kernel regression with a ridge\nthat decreases with the size of the training set leads to similar learning\ncurve exponents to those we obtain in the ridgeless case.",
    "descriptor": "\nComments: 27 pages, 3 figures\n",
    "authors": [
      "Alessandro Favero",
      "Francesco Cagnetta",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08619"
  },
  {
    "id": "arXiv:2106.08627",
    "title": "A complete and consistent second-order hydrodynamic model for floating  structures with large horizontal motions",
    "abstract": "Floating offshore structures often exhibit low-frequency oscillatory motions\nin the horizontal plane, with amplitudes in the same order as their\ncharacteristic dimensions and larger than the corresponding wave-frequency\nresponses, making the traditional formulations in an inertial coordinate system\ninconsistent and less applicable. To address this issue, we explore an\nalternative formulation completely based on a non-inertial body-fixed\ncoordinate system. Unlike the traditional seakeeping models, this formulation\nconsistently allows for large-amplitude horizontal motions. A numerical model\nbased on a higher-order boundary element is applied to solve the resulting\nboundary-value problems in the time domain. A new set of explicit\ntime-integration methods, which do not necessitate the use of upwind schemes\nfor spatial derivatives, are designed to deal with the convective-type\nfree-surface conditions. To suppress the weak saw-tooth instabilities on the\nfree surface in time marching, we also present novel low-pass filters based on\noptimized weighted-least-squares, which are in principle applicable for both\nstructured and unstructured meshes. For ship seakeeping and added resistance\nanalyses, we show that the present computational model does not need to use\nsoft-springs for surge and sway, in contrast to the traditional models. For a\nspar floating offshore wind turbine (FOWT), the importance of consistently\ntaking into account the effects of large horizontal motions is demonstrated\nconsidering the bi-chromatic incident waves. The present model is also referred\nto as a complete 2nd order wave-load model, as all the 2nd order wave loads,\nincluding the sum-frequency and difference-frequency components, are solved\nsimultaneously.",
    "descriptor": "",
    "authors": [
      "Yanlin Shao",
      "Zhiping Zheng",
      "Hui Liang",
      "Jikang Chen"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08627"
  },
  {
    "id": "arXiv:2106.08649",
    "title": "Improving the expressiveness of neural vocoding with non-affine  Normalizing Flows",
    "abstract": "This paper proposes a general enhancement to the Normalizing Flows (NF) used\nin neural vocoding. As a case study, we improve expressive speech vocoding with\na revamped Parallel Wavenet (PW). Specifically, we propose to extend the affine\ntransformation of PW to the more expressive invertible non-affine function. The\ngreater expressiveness of the improved PW leads to better-perceived signal\nquality and naturalness in the waveform reconstruction and text-to-speech (TTS)\ntasks. We evaluate the model across different speaking styles on a\nmulti-speaker, multi-lingual dataset. In the waveform reconstruction task, the\nproposed model closes the naturalness and signal quality gap from the original\nPW to recordings by $10\\%$, and from other state-of-the-art neural vocoding\nsystems by more than $60\\%$. We also demonstrate improvements in objective\nmetrics on the evaluation test set with L2 Spectral Distance and Cross-Entropy\nreduced by $3\\%$ and $6\\unicode{x2030}$ comparing to the affine PW.\nFurthermore, we extend the probability density distillation procedure proposed\nby the original PW paper, so that it works with any non-affine invertible and\ndifferentiable function.",
    "descriptor": "\nComments: Accepted to Interspeech 2021, 5 pages,3 figures\n",
    "authors": [
      "Adam Gabry\u015b",
      "Yunlong Jiao",
      "Viacheslav Klimkov",
      "Daniel Korzekwa",
      "Roberto Barra-Chicote"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.08649"
  },
  {
    "id": "arXiv:2106.08672",
    "title": "DCCRN+: Channel-wise Subband DCCRN with SNR Estimation for Speech  Enhancement",
    "abstract": "Deep complex convolution recurrent network (DCCRN), which extends CRN with\ncomplex structure, has achieved superior performance in MOS evaluation in\nInterspeech 2020 deep noise suppression challenge (DNS2020). This paper further\nextends DCCRN with the following significant revisions. We first extend the\nmodel to sub-band processing where the bands are split and merged by learnable\nneural network filters instead of engineered FIR filters, leading to a faster\nnoise suppressor trained in an end-to-end manner. Then the LSTM is further\nsubstituted with a complex TF-LSTM to better model temporal dependencies along\nboth time and frequency axes. Moreover, instead of simply concatenating the\noutput of each encoder layer to the input of the corresponding decoder layer,\nwe use convolution blocks to first aggregate essential information from the\nencoder output before feeding it to the decoder layers. We specifically\nformulate the decoder with an extra a priori SNR estimation module to maintain\ngood speech quality while removing noise. Finally a post-processing module is\nadopted to further suppress the unnatural residual noise. The new model, named\nDCCRN+, has surpassed the original DCCRN as well as several competitive models\nin terms of PESQ and DNSMOS, and has achieved superior performance in the new\nInterspeech 2021 DNS challenge",
    "descriptor": "",
    "authors": [
      "Shubo Lv",
      "Yanxin Hu",
      "Shimin Zhang",
      "Lei Xie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.08672"
  },
  {
    "id": "arXiv:2106.08678",
    "title": "Directed Graph Embeddings in Pseudo-Riemannian Manifolds",
    "abstract": "The inductive biases of graph representation learning algorithms are often\nencoded in the background geometry of their embedding space. In this paper, we\nshow that general directed graphs can be effectively represented by an\nembedding model that combines three components: a pseudo-Riemannian metric\nstructure, a non-trivial global topology, and a unique likelihood function that\nexplicitly incorporates a preferred direction in embedding space. We\ndemonstrate the representational capabilities of this method by applying it to\nthe task of link prediction on a series of synthetic and real directed graphs\nfrom natural language applications and biology. In particular, we show that\nlow-dimensional cylindrical Minkowski and anti-de Sitter spacetimes can produce\nequal or better graph representations than curved Riemannian manifolds of\nhigher dimensions.",
    "descriptor": "\nComments: Accepted at ICML 2021\n",
    "authors": [
      "Aaron Sim",
      "Maciej Wiatrak",
      "Angus Brayne",
      "P\u00e1id\u00ed Creed",
      "Saee Paliwal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08678"
  },
  {
    "id": "arXiv:2106.08706",
    "title": "Silent Speech and Emotion Recognition from Vocal Tract Shape Dynamics in  Real-Time MRI",
    "abstract": "Speech sounds of spoken language are obtained by varying configuration of the\narticulators surrounding the vocal tract. They contain abundant information\nthat can be utilized to better understand the underlying mechanism of human\nspeech production. We propose a novel deep neural network-based learning\nframework that understands acoustic information in the variable-length sequence\nof vocal tract shaping during speech production, captured by real-time magnetic\nresonance imaging (rtMRI), and translate it into text. The proposed framework\ncomprises of spatiotemporal convolutions, a recurrent network, and the\nconnectionist temporal classification loss, trained entirely end-to-end. On the\nUSC-TIMIT corpus, the model achieved a 40.6% PER at sentence-level, much better\ncompared to the existing models. To the best of our knowledge, this is the\nfirst study that demonstrates the recognition of entire spoken sentence based\non an individual's articulatory motions captured by rtMRI video. We also\nperformed an analysis of variations in the geometry of articulation in each\nsub-regions of the vocal tract (i.e., pharyngeal, velar and dorsal, hard\npalate, labial constriction region) with respect to different emotions and\ngenders. Results suggest that each sub-regions distortion is affected by both\nemotion and gender.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Laxmi Pandey",
      "Ahmed Sabbir Arif"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.08706"
  },
  {
    "id": "arXiv:2106.08741",
    "title": "Enriching Source Style Transfer in Recognition-Synthesis based  Non-Parallel Voice Conversion",
    "abstract": "Current voice conversion (VC) methods can successfully convert timbre of the\naudio. As modeling source audio's prosody effectively is a challenging task,\nthere are still limitations of transferring source style to the converted\nspeech. This study proposes a source style transfer method based on\nrecognition-synthesis framework. Previously in speech generation task, prosody\ncan be modeled explicitly with prosodic features or implicitly with a latent\nprosody extractor. In this paper, taking advantages of both, we model the\nprosody in a hybrid manner, which effectively combines explicit and implicit\nmethods in a proposed prosody module. Specifically, prosodic features are used\nto explicit model prosody, while VAE and reference encoder are used to\nimplicitly model prosody, which take Mel spectrum and bottleneck feature as\ninput respectively. Furthermore, adversarial training is introduced to remove\nspeaker-related information from the VAE outputs, avoiding leaking source\nspeaker information while transferring style. Finally, we use a modified\nself-attention based encoder to extract sentential context from bottleneck\nfeatures, which also implicitly aggregates the prosodic aspects of source\nspeech from the layered representations. Experiments show that our approach is\nsuperior to the baseline and a competitive system in terms of style transfer;\nmeanwhile, the speech quality and speaker similarity are well maintained.",
    "descriptor": "\nComments: Accepted by Interspeech 2021\n",
    "authors": [
      "Zhichao Wang",
      "Xinyong Zhou",
      "Fengyu Yang",
      "Tao Li",
      "Hongqiang Du",
      "Lei Xie",
      "Wendong Gan",
      "Haitao Chen",
      "Hai Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.08741"
  },
  {
    "id": "arXiv:2106.08750",
    "title": "Scalable Quasi-Bayesian Inference for Instrumental Variable Regression",
    "abstract": "Recent years have witnessed an upsurge of interest in employing flexible\nmachine learning models for instrumental variable (IV) regression, but the\ndevelopment of uncertainty quantification methodology is still lacking. In this\nwork we present a scalable quasi-Bayesian procedure for IV regression, building\nupon the recently developed kernelized IV models. Contrary to Bayesian modeling\nfor IV, our approach does not require additional assumptions on the data\ngenerating process, and leads to a scalable approximate inference algorithm\nwith time cost comparable to the corresponding point estimation methods. Our\nalgorithm can be further extended to work with neural network models. We\nanalyze the theoretical properties of the proposed quasi-posterior, and\ndemonstrate through empirical evaluation the competitive performance of our\nmethod.",
    "descriptor": "\nComments: ZW and YZ contribute equally\n",
    "authors": [
      "Ziyu Wang",
      "Yuhao Zhou",
      "Tongzheng Ren",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08750"
  },
  {
    "id": "arXiv:2106.08775",
    "title": "Momentum-inspired Low-Rank Coordinate Descent for Diagonally Constrained  SDPs",
    "abstract": "We present a novel, practical, and provable approach for solving diagonally\nconstrained semi-definite programming (SDP) problems at scale using accelerated\nnon-convex programming. Our algorithm non-trivially combines acceleration\nmotions from convex optimization with coordinate power iteration and matrix\nfactorization techniques. The algorithm is extremely simple to implement, and\nadds only a single extra hyperparameter -- momentum. We prove that our method\nadmits local linear convergence in the neighborhood of the optimum and always\nconverges to a first-order critical point. Experimentally, we showcase the\nmerits of our method on three major application domains: MaxCut, MaxSAT, and\nMIMO signal detection. In all cases, our methodology provides significant\nspeedups over non-convex and convex SDP solvers -- 5X faster than\nstate-of-the-art non-convex solvers, and 9 to 10^3 X faster than convex SDP\nsolvers -- with comparable or improved solution quality.",
    "descriptor": "\nComments: 10 pages, 8 figures, preprint under review\n",
    "authors": [
      "Junhyung Lyle Kim",
      "Jose Antonio Lara Benitez",
      "Mohammad Taha Toghani",
      "Cameron Wolfe",
      "Zhiwei Zhang",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2106.08775"
  },
  {
    "id": "arXiv:2106.08814",
    "title": "Silhouettes and quasi residual plots for neural nets and tree-based  classifiers",
    "abstract": "Classification by neural nets and by tree-based methods are powerful tools of\nmachine learning. There exist interesting visualizations of the inner workings\nof these and other classifiers. Here we pursue a different goal, which is to\nvisualize the cases being classified, either in training data or in test data.\nAn important aspect is whether a case has been classified to its given class\n(label) or whether the classifier wants to assign it to different class. This\nis reflected in the (conditional and posterior) probability of the alternative\nclass (PAC). A high PAC indicates label bias, i.e. the possibility that the\ncase was mislabeled. The PAC is used to construct a silhouette plot which is\nsimilar in spirit to the silhouette plot for cluster analysis (Rousseeuw,\n1987). The average silhouette width can be used to compare different\nclassifications of the same dataset. We will also draw quasi residual plots of\nthe PAC versus a data feature, which may lead to more insight in the data. One\nof these data features is how far each case lies from its given class. The\ngraphical displays are illustrated and interpreted on benchmark data sets\ncontaining images, mixed features, and tweets.",
    "descriptor": "",
    "authors": [
      "Jakob Raymaekers",
      "Peter J. Rousseeuw"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08814"
  },
  {
    "id": "arXiv:2106.08870",
    "title": "Covariance-based smoothed particle hydrodynamics. A machine-learning  application to simulating disc fragmentation",
    "abstract": "A PCA-based, machine learning version of the SPH method is proposed. In the\npresent scheme, the smoothing tensor is computed to have their eigenvalues\nproportional to the covariance's principal components, using a modified octree\ndata structure, which allows the fast estimation of the anisotropic\nself-regulating kNN. Each SPH particle is the center of such an optimal kNN\ncluster, i.e., the one whose covariance tensor allows the find of the kNN\ncluster itself according to the Mahalanobis metric. Such machine learning\nconstitutes a fixed point problem. The definitive (self-regulating) kNN cluster\ndefines the smoothing volume, or properly saying, the smoothing ellipsoid,\nrequired to perform the anisotropic interpolation. Thus, the smoothing kernel\nhas an ellipsoidal profile, which changes how the kernel gradients are\ncomputed. As an application, it was performed the simulation of collapse and\nfragmentation of a non-magnetic, rotating gaseous sphere. An interesting\noutcome was the formation of protostars in the disc fragmentation, shown to be\nmuch more persistent and much more abundant in the anisotropic simulation than\nin the isotropic case.",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Eraldo Pereira Marinho"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08870"
  },
  {
    "id": "arXiv:2106.08884",
    "title": "On cyclic algebraic-geometry codes",
    "abstract": "In this paper we initiate the study of cyclic algebraic geometry codes. We\ngive conditions to construct cyclic algebraic geometry codes in the context of\nalgebraic function fields over a finite field by using their group of\nautomorphisms. We prove that cyclic algebraic geometry codes constructed in\nthis way are closely related to cyclic extensions. We also give a detailed\nstudy of the monomial equivalence of cyclic algebraic geometry codes\nconstructed with our method in the case of a rational function field.",
    "descriptor": "\nComments: 25 pages, 1 figure\n",
    "authors": [
      "Gustavo Caba\u00f1a",
      "Mar\u00eda Chara",
      "Ricardo A. Podest\u00e1",
      "Ricardo Toledano"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2106.08884"
  },
  {
    "id": "arXiv:2106.08891",
    "title": "Using Machine Learning to Select High-Quality Measurements",
    "abstract": "We describe the use of machine learning algorithms to select high-quality\nmeasurements for the Mu2e experiment. This technique is important for\nexperiments with backgrounds that arise due to measurement errors. The\nalgorithms use multiple pieces of ancillary information that are sensitive to\nmeasurement quality to separate high-quality and low-quality measurements.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Andrew Edmonds",
      "David Brown",
      "Luciano Vinas",
      "Samantha Pagan"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2106.08891"
  },
  {
    "id": "arXiv:2106.08893",
    "title": "Variational principles and finite element Bloch analysis in couple  stress elastodynamics",
    "abstract": "We address the numerical simulation of periodic solids (phononic crystals)\nwithin the framework of couple stress elasticity. The additional terms in the\nelastic potential energy lead to dispersive behavior in shear waves, even in\nthe absence of material periodicity. To study the bulk waves in these\nmaterials, we establish an action principle in the frequency domain and present\na finite element formulation for the wave propagation problem related to couple\nstress theory subject to an extended set of Bloch-periodic boundary conditions.\nA major difference from the traditional finite element formulation for phononic\ncrystals is the appearance of higher-order derivatives. We solve this problem\nwith the use of a Lagrange-multiplier approach. After presenting the\nvariational principle and general finite element treatment, we particularize it\nto the problem of finding dispersion relations in elastic bodies with periodic\nmaterial properties. The resulting implementation is used to determine the\ndispersion curves for homogeneous and porous couple stress solids, in which the\nlatter is found to exhibit an interesting bandgap structure.",
    "descriptor": "\nComments: 29 pages, 8 figures\n",
    "authors": [
      "Nicol\u00e1s Guar\u00edn-Zapata",
      "Juan Gomez",
      "Ali Reza Hadjesfandiari",
      "Gary F. Dargush"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08893"
  },
  {
    "id": "arXiv:2106.08901",
    "title": "Economic Nowcasting with Long Short-Term Memory Artificial Neural  Networks (LSTM)",
    "abstract": "Artificial neural networks (ANNs) have been the catalyst to numerous advances\nin a variety of fields and disciplines in recent years. Their impact on\neconomics, however, has been comparatively muted. One type of ANN, the long\nshort-term memory network (LSTM), is particularly wellsuited to deal with\neconomic time-series. Here, the architecture's performance and characteristics\nare evaluated in comparison with the dynamic factor model (DFM), currently a\npopular choice in the field of economic nowcasting. LSTMs are found to produce\nsuperior results to DFMs in the nowcasting of three separate variables; global\nmerchandise export values and volumes, and global services exports. Further\nadvantages include their ability to handle large numbers of input features in a\nvariety of time frequencies. A disadvantage is the inability to ascribe\ncontributions of input features to model outputs, common to all ANNs. In order\nto facilitate continued applied research of the methodology by avoiding the\nneed for any knowledge of deep-learning libraries, an accompanying Python\nlibrary was developed using PyTorch, https://pypi.org/project/nowcast-lstm/.",
    "descriptor": "\nComments: 21 pages, 3 figures\n",
    "authors": [
      "Daniel Hopp"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08901"
  },
  {
    "id": "arXiv:2106.08902",
    "title": "Collaborative Learning and Personalization in Multi-Agent Stochastic  Linear Bandits",
    "abstract": "We consider the problem of minimizing regret in an $N$ agent heterogeneous\nstochastic linear bandits framework, where the agents (users) are similar but\nnot all identical. We model user heterogeneity using two popularly used ideas\nin practice; (i) A clustering framework where users are partitioned into groups\nwith users in the same group being identical to each other, but different\nacross groups, and (ii) a personalization framework where no two users are\nnecessarily identical, but a user's parameters are close to that of the\npopulation average. In the clustered users' setup, we propose a novel\nalgorithm, based on successive refinement of cluster identities and regret\nminimization. We show that, for any agent, the regret scales as\n$\\mathcal{O}(\\sqrt{T/N})$, if the agent is in a `well separated' cluster, or\nscales as $\\mathcal{O}(T^{\\frac{1}{2} + \\varepsilon}/(N)^{\\frac{1}{2}\n-\\varepsilon})$ if its cluster is not well separated, where $\\varepsilon$ is\npositive and arbitrarily close to $0$. Our algorithm is adaptive to the cluster\nseparation, and is parameter free -- it does not need to know the number of\nclusters, separation and cluster size, yet the regret guarantee adapts to the\ninherent complexity. In the personalization framework, we introduce a natural\nalgorithm where, the personal bandit instances are initialized with the\nestimates of the global average model. We show that, an agent $i$ whose\nparameter deviates from the population average by $\\epsilon_i$, attains a\nregret scaling of $\\widetilde{O}(\\epsilon_i\\sqrt{T})$. This demonstrates that\nif the user representations are close (small $\\epsilon_i)$, the resulting\nregret is low, and vice-versa. The results are empirically validated and we\nobserve superior performance of our adaptive algorithms over non-adaptive\nbaselines.",
    "descriptor": "\nComments: 25 pages, 8 figures\n",
    "authors": [
      "Avishek Ghosh",
      "Abishek Sankararaman",
      "Kannan Ramchandran"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08902"
  },
  {
    "id": "arXiv:2106.08903",
    "title": "GemNet: Universal Directional Graph Neural Networks for Molecules",
    "abstract": "Effectively predicting molecular interactions has the potential to accelerate\nmolecular dynamics by multiple orders of magnitude and thus revolutionize\nchemical simulations. Graph neural networks (GNNs) have recently shown great\nsuccesses for this task, overtaking classical methods based on fixed molecular\nkernels. However, they still appear very limited from a theoretical\nperspective, since regular GNNs cannot distinguish certain types of graphs. In\nthis work we close this gap between theory and practice. We show that GNNs with\ndirected edge embeddings and two-hop message passing are indeed universal\napproximators for predictions that are invariant to global rotation and\ntranslation, and equivariant to permutation. We then leverage these insights\nand multiple structural improvements to propose the geometric message passing\nneural network (GemNet). We demonstrate the benefits of the proposed changes in\nmultiple ablation studies. GemNet outperforms previous models on the COLL and\nMD17 molecular dynamics datasets by 36%, performing especially well on the most\nchallenging molecules.",
    "descriptor": "",
    "authors": [
      "Johannes Klicpera",
      "Florian Becker",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08903"
  },
  {
    "id": "arXiv:2106.08922",
    "title": "Momentum Pseudo-Labeling for Semi-Supervised Speech Recognition",
    "abstract": "Pseudo-labeling (PL) has been shown to be effective in semi-supervised\nautomatic speech recognition (ASR), where a base model is self-trained with\npseudo-labels generated from unlabeled data. While PL can be further improved\nby iteratively updating pseudo-labels as the model evolves, most of the\nprevious approaches involve inefficient retraining of the model or intricate\ncontrol of the label update. We present momentum pseudo-labeling (MPL), a\nsimple yet effective strategy for semi-supervised ASR. MPL consists of a pair\nof online and offline models that interact and learn from each other, inspired\nby the mean teacher method. The online model is trained to predict\npseudo-labels generated on the fly by the offline model. The offline model\nmaintains a momentum-based moving average of the online model. MPL is performed\nin a single training process and the interaction between the two models\neffectively helps them reinforce each other to improve the ASR performance. We\napply MPL to an end-to-end ASR model based on the connectionist temporal\nclassification. The experimental results demonstrate that MPL effectively\nimproves over the base model and is scalable to different semi-supervised\nscenarios with varying amounts of data or domain mismatch.",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Yosuke Higuchi",
      "Niko Moritz",
      "Jonathan Le Roux",
      "Takaaki Hori"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.08922"
  },
  {
    "id": "arXiv:2106.08929",
    "title": "KALE Flow: A Relaxed KL Gradient Flow for Probabilities with Disjoint  Support",
    "abstract": "We study the gradient flow for a relaxed approximation to the\nKullback-Leibler (KL) divergence between a moving source and a fixed target\ndistribution. This approximation, termed the KALE (KL approximate lower-bound\nestimator), solves a regularized version of the Fenchel dual problem defining\nthe KL over a restricted class of functions. When using a Reproducing Kernel\nHilbert Space (RKHS) to define the function class, we show that the KALE\ncontinuously interpolates between the KL and the Maximum Mean Discrepancy\n(MMD). Like the MMD and other Integral Probability Metrics, the KALE remains\nwell defined for mutually singular distributions. Nonetheless, the KALE\ninherits from the limiting KL a greater sensitivity to mismatch in the support\nof the distributions, compared with the MMD. These two properties make the KALE\ngradient flow particularly well suited when the target distribution is\nsupported on a low-dimensional manifold. Under an assumption of sufficient\nsmoothness of the trajectories, we show the global convergence of the KALE\nflow. We propose a particle implementation of the flow given initial samples\nfrom the source and the target distribution, which we use to empirically\nconfirm the KALE's properties.",
    "descriptor": "",
    "authors": [
      "Pierre Glaser",
      "Michael Arbel",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08929"
  },
  {
    "id": "arXiv:2106.08936",
    "title": "Improved CNN-based Learning of Interpolation Filters for Low-Complexity  Inter Prediction in Video Coding",
    "abstract": "The versatility of recent machine learning approaches makes them ideal for\nimprovement of next generation video compression solutions. Unfortunately,\nthese approaches typically bring significant increases in computational\ncomplexity and are difficult to interpret into explainable models, affecting\ntheir potential for implementation within practical video coding applications.\nThis paper introduces a novel explainable neural network-based inter-prediction\nscheme, to improve the interpolation of reference samples needed for fractional\nprecision motion compensation. The approach requires a single neural network to\nbe trained from which a full quarter-pixel interpolation filter set is derived,\nas the network is easily interpretable due to its linear structure. A novel\ntraining framework enables each network branch to resemble a specific\nfractional shift. This practical solution makes it very efficient to use\nalongside conventional video coding schemes. When implemented in the context of\nthe state-of-the-art Versatile Video Coding (VVC) test model, 0.77%, 1.27% and\n2.25% BD-rate savings can be achieved on average for lower resolution sequences\nunder the random access, low-delay B and low-delay P configurations,\nrespectively, while the complexity of the learned interpolation schemes is\nsignificantly reduced compared to the interpolation with full CNNs.",
    "descriptor": "\nComments: IEEE Open Journal of Signal Processing Special Issue on Applied AI and Machine Learning for Video Coding and Streaming, June 2021\n",
    "authors": [
      "Luka Murn",
      "Saverio Blasi",
      "Alan F. Smeaton",
      "Marta Mrak"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.08936"
  },
  {
    "id": "arXiv:2106.08981",
    "title": "Nonequilibrium thermodynamics of self-supervised learning",
    "abstract": "Self-supervised learning (SSL) of energy based models has an intuitive\nrelation to equilibrium thermodynamics because the softmax layer, mapping\nenergies to probabilities, is a Gibbs distribution. However, in what way SSL is\na thermodynamic process? We show that some SSL paradigms behave as a\nthermodynamic composite system formed by representations and self-labels in\ncontact with a nonequilibrium reservoir. Moreover, this system is subjected to\nusual thermodynamic cycles, such as adiabatic expansion and isochoric heating,\nresulting in a generalized Gibbs ensemble (GGE). In this picture, we show that\nlearning is seen as a demon that operates in cycles using feedback measurements\nto extract negative work from the system. As applications, we examine some SSL\nalgorithms using this idea.",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "Domingos S. P. Salazar"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08981"
  },
  {
    "id": "arXiv:2106.08990",
    "title": "mSHAP: SHAP Values for Two-Part Models",
    "abstract": "Two-part models are important to and used throughout insurance and actuarial\nscience. Since insurance is required for registering a car, obtaining a\nmortgage, and participating in certain businesses, it is especially important\nthat the models which price insurance policies are fair and non-discriminatory.\nBlack box models can make it very difficult to know which covariates are\ninfluencing the results. SHAP values enable interpretation of various black box\nmodels, but little progress has been made in two-part models. In this paper, we\npropose mSHAP (or multiplicative SHAP), a method for computing SHAP values of\ntwo-part models using the SHAP values of the individual models. This method\nwill allow for the predictions of two-part models to be explained at an\nindividual observation level. After developing mSHAP, we perform an in-depth\nsimulation study. Although the kernelSHAP algorithm is also capable of\ncomputing approximate SHAP values for a two-part model, a comparison with our\nmethod demonstrates that mSHAP is exponentially faster. Ultimately, we apply\nmSHAP to a two-part ratemaking model for personal auto property damage\ninsurance coverage. Additionally, an R package (mshap) is available to easily\nimplement the method in a wide variety of applications.",
    "descriptor": "",
    "authors": [
      "Spencer Matthews",
      "Brian Hartman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08990"
  },
  {
    "id": "arXiv:2106.08995",
    "title": "Surgical task expertise detected by a self-organizing neural network map",
    "abstract": "Individual grip force profiling of bimanual simulator task performance of\nexperts and novices using a robotic control device designed for endoscopic\nsurgery permits defining benchmark criteria that tell true expert task skills\nfrom the skills of novices or trainee surgeons. Grip force variability in a\ntrue expert and a complete novice executing a robot assisted surgical simulator\ntask reveal statistically significant differences as a function of task\nexpertise. Here we show that the skill specific differences in local grip\nforces are predicted by the output metric of a Self Organizing neural network\nMap (SOM) with a bio inspired functional architecture that maps the functional\nconnectivity of somatosensory neural networks in the primate brain.",
    "descriptor": "\nComments: Conference on Automation in Medical Engineering AUTOMED21, University Hospital Basel, Switzerland, 2021, June 8-9\n",
    "authors": [
      "Birgitta Dresp-Langley",
      "Rongrong Liu",
      "John M. Wandeto"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.08995"
  },
  {
    "id": "arXiv:2106.09000",
    "title": "Deriving Autism Spectrum Disorder Functional Networks from RS-FMRI Data  using Group ICA and Dictionary Learning",
    "abstract": "The objective of this study is to derive functional networks for the autism\nspectrum disorder (ASD) population using the group ICA and dictionary learning\nmodel together and to classify ASD and typically developing (TD) participants\nusing the functional connectivity calculated from the derived functional\nnetworks. In our experiments, the ASD functional networks were derived from\nresting-state functional magnetic resonance imaging (rs-fMRI) data. We\ndownloaded a total of 120 training samples, including 58 ASD and 62 TD\nparticipants, which were obtained from the public repository: Autism Brain\nImaging Data Exchange I (ABIDE I). Our methodology and results have five main\nparts. First, we utilize a group ICA model to extract functional networks from\nthe ASD group and rank the top 20 regions of interest (ROIs). Second, we\nutilize a dictionary learning model to extract functional networks from the ASD\ngroup and rank the top 20 ROIs. Third, we merged the 40 selected ROIs from the\ntwo models together as the ASD functional networks. Fourth, we generate three\ncorresponding masks based on the 20 selected ROIs from group ICA, the 20 ROIs\nselected from dictionary learning, and the 40 combined ROIs selected from both.\nFinally, we extract ROIs for all training samples using the above three masks,\nand the calculated functional connectivity was used as features for ASD and TD\nclassification. The classification results showed that the functional networks\nderived from ICA and dictionary learning together outperform those derived from\na single ICA model or a single dictionary learning model.",
    "descriptor": "\nComments: Conference\n",
    "authors": [
      "Xin Yang",
      "Ning Zhang",
      "Donglin Wang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.09000"
  },
  {
    "id": "arXiv:2106.09004",
    "title": "Learning effective stochastic differential equations from microscopic  simulations: combining stochastic numerics and deep learning",
    "abstract": "We identify effective stochastic differential equations (SDE) for coarse\nobservables of fine-grained particle- or agent-based simulations; these SDE\nthen provide coarse surrogate models of the fine scale dynamics. We approximate\nthe drift and diffusivity functions in these effective SDE through neural\nnetworks, which can be thought of as effective stochastic ResNets. The loss\nfunction is inspired by, and embodies, the structure of established stochastic\nnumerical integrators (here, Euler-Maruyama and Milstein); our approximations\ncan thus benefit from error analysis of these underlying numerical schemes.\nThey also lend themselves naturally to \"physics-informed\" gray-box\nidentification when approximate coarse models, such as mean field equations,\nare available. Our approach does not require long trajectories, works on\nscattered snapshot data, and is designed to naturally handle different time\nsteps per snapshot. We consider both the case where the coarse collective\nobservables are known in advance, as well as the case where they must be found\nin a data-driven manner.",
    "descriptor": "\nComments: 19 pages, includes supplemental material\n",
    "authors": [
      "Felix Dietrich",
      "Alexei Makeev",
      "George Kevrekidis",
      "Nikolaos Evangelou",
      "Tom Bertalan",
      "Sebastian Reich",
      "Ioannis G. Kevrekidis"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09004"
  },
  {
    "id": "arXiv:2106.09007",
    "title": "Fungi anaesthesia",
    "abstract": "Electrical activity of fungus \\emph{Pleurotus ostreatus} is characterised by\nslow (hours) irregular waves of baseline potential drift and fast (minutes)\naction potential likes spikes of the electrical potential. An exposure of the\nmycelium colonised substrate to a chloroform vapour lead to several fold\ndecrease of the baseline potential waves and increase of their duration. The\nchloroform vapour also causes either complete cessation of spiking activity or\nsubstantial reduction of the spiking frequency. Removal of the chloroform\nvapour from the growth containers leads to a gradual restoration of the\nmycelium electrical activity.",
    "descriptor": "",
    "authors": [
      "Andrew Adamatzky",
      "Antoni Gandia"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Emerging Technologies (cs.ET)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.09007"
  },
  {
    "id": "arXiv:2106.09008",
    "title": "A Flow-Based Neural Network for Time Domain Speech Enhancement",
    "abstract": "Speech enhancement involves the distinction of a target speech signal from an\nintrusive background. Although generative approaches using Variational\nAutoencoders or Generative Adversarial Networks (GANs) have increasingly been\nused in recent years, normalizing flow (NF) based systems are still scarse,\ndespite their success in related fields. Thus, in this paper we propose a NF\nframework to directly model the enhancement process by density estimation of\nclean speech utterances conditioned on their noisy counterpart. The WaveGlow\nmodel from speech synthesis is adapted to enable direct enhancement of noisy\nutterances in time domain. In addition, we demonstrate that nonlinear input\ncompanding benefits the model performance by equalizing the distribution of\ninput samples. Experimental evaluation on a publicly available dataset shows\ncomparable results to current state-of-the-art GAN-based approaches, while\nsurpassing the chosen baselines using objective evaluation metrics.",
    "descriptor": "\nComments: Accepted to ICASSP 2021\n",
    "authors": [
      "Martin Strauss",
      "Bernd Edler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.09008"
  },
  {
    "id": "arXiv:1803.03407",
    "title": "Institutional Metaphors for Designing Large-Scale Distributed AI versus  AI Techniques for Running Institutions",
    "abstract": "Comments: invited chapter, before proofread",
    "descriptor": "\nComments: invited chapter, before proofread\n",
    "authors": [
      "Alexander Boer",
      "Giovanni Sileno"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1803.03407"
  },
  {
    "id": "arXiv:1810.12941",
    "title": "Joint detection and matching of feature points in multimodal images",
    "abstract": "Joint detection and matching of feature points in multimodal images",
    "descriptor": "",
    "authors": [
      "Elad Ben Baruch",
      "Yosi Keller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1810.12941"
  },
  {
    "id": "arXiv:1902.04251",
    "title": "Thompson Sampling with Information Relaxation Penalties",
    "abstract": "Thompson Sampling with Information Relaxation Penalties",
    "descriptor": "",
    "authors": [
      "Seungki Min",
      "Costis Maglaras",
      "Ciamac C. Moallemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1902.04251"
  },
  {
    "id": "arXiv:1908.05978",
    "title": "The Partial Response Network: a neural network nomogram",
    "abstract": "Comments: 23 pages, 8 figures",
    "descriptor": "\nComments: 23 pages, 8 figures\n",
    "authors": [
      "Paulo J. G. Lisboa",
      "Sandra Ortega-Martorell",
      "Sadie Cashman",
      "Ivan Olier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1908.05978"
  },
  {
    "id": "arXiv:1909.05350",
    "title": "The Error-Feedback Framework: Better Rates for SGD with Delayed  Gradients and Compressed Communication",
    "abstract": "Comments: Submitted 9/19, Published 9/20",
    "descriptor": "\nComments: Submitted 9/19, Published 9/20\n",
    "authors": [
      "Sebastian U. Stich",
      "Sai Praneeth Karimireddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.05350"
  },
  {
    "id": "arXiv:1910.04284",
    "title": "Improved Sample Complexities for Deep Networks and Robust Classification  via an All-Layer Margin",
    "abstract": "Comments: Code for all-layer margin optimization is available at the following link: this https URL Version 4: Re-organized proofs for more clarity",
    "descriptor": "\nComments: Code for all-layer margin optimization is available at the following link: this https URL Version 4: Re-organized proofs for more clarity\n",
    "authors": [
      "Colin Wei",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.04284"
  },
  {
    "id": "arXiv:1910.09991",
    "title": "Towards Automated Website Classification by Deep Learning",
    "abstract": "Towards Automated Website Classification by Deep Learning",
    "descriptor": "",
    "authors": [
      "Fabrizio De Fausti",
      "Francesco Pugliese",
      "Diego Zardetto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.09991"
  },
  {
    "id": "arXiv:2001.07063",
    "title": "Modular coinduction up-to for higher-order languages via first-order  transition systems",
    "abstract": "Comments: This paper is an improved and extended version of a paper appeared in Proc. CONCUR 2014",
    "descriptor": "\nComments: This paper is an improved and extended version of a paper appeared in Proc. CONCUR 2014\n",
    "authors": [
      "Jean-Marie Madiot",
      "Damien Pous",
      "Davide Sangiorgi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2001.07063"
  },
  {
    "id": "arXiv:2001.09528",
    "title": "Imperfect ImaGANation: Implications of GANs Exacerbating Biases on  Facial Data Augmentation and Snapchat Selfie Lenses",
    "abstract": "Imperfect ImaGANation: Implications of GANs Exacerbating Biases on  Facial Data Augmentation and Snapchat Selfie Lenses",
    "descriptor": "",
    "authors": [
      "Niharika Jain",
      "Alberto Olmo",
      "Sailik Sengupta",
      "Lydia Manikonda",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.09528"
  },
  {
    "id": "arXiv:2002.09664",
    "title": "Book-Ahead & Supply Management for Ridesourcing Platforms",
    "abstract": "Book-Ahead & Supply Management for Ridesourcing Platforms",
    "descriptor": "",
    "authors": [
      "Cesar N. Yahia",
      "Gustavo de Veciana",
      "Stephen D. Boyles",
      "Jean Abou Rahal",
      "Michael Stecklein"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2002.09664"
  },
  {
    "id": "arXiv:2003.04868",
    "title": "This PIN Can Be Easily Guessed: Analyzing the Security of Smartphone  Unlock PINs",
    "abstract": "Comments: 15+3 pages, 9 figures, 8+5 tables",
    "descriptor": "\nComments: 15+3 pages, 9 figures, 8+5 tables\n",
    "authors": [
      "Philipp Markert",
      "Daniel V. Bailey",
      "Maximilian Golla",
      "Markus D\u00fcrmuth",
      "Adam J. Aviv"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2003.04868"
  },
  {
    "id": "arXiv:2004.07119",
    "title": "Generating Tertiary Protein Structures via an Interpretative Variational  Autoencoder",
    "abstract": "Generating Tertiary Protein Structures via an Interpretative Variational  Autoencoder",
    "descriptor": "",
    "authors": [
      "Xiaojie Guo",
      "Yuanqi Du",
      "Sivani Tadepalli",
      "Liang Zhao",
      "Amarda Shehu"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.07119"
  },
  {
    "id": "arXiv:2004.09764",
    "title": "Discrete Variational Attention Models for Language Generation",
    "abstract": "Comments: 7 pages, 3 figures",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Xianghong Fang",
      "Haoli Bai",
      "Zenglin Xu",
      "Michael Lyu",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.09764"
  },
  {
    "id": "arXiv:2005.00356",
    "title": "A Naturalness Evaluation Database for Video Prediction Models",
    "abstract": "Comments: Project website: this https URL",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Nagabhushan Somraj",
      "Manoj Surya Kashi",
      "S. P. Arun",
      "Rajiv Soundararajan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.00356"
  },
  {
    "id": "arXiv:2005.02960",
    "title": "Exploring the Loss Landscape in Neural Architecture Search",
    "abstract": "Exploring the Loss Landscape in Neural Architecture Search",
    "descriptor": "",
    "authors": [
      "Colin White",
      "Sam Nolen",
      "Yash Savani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.02960"
  },
  {
    "id": "arXiv:2005.07662",
    "title": "Guided interactive image segmentation using machine learning and color  based data set clustering",
    "abstract": "Guided interactive image segmentation using machine learning and color  based data set clustering",
    "descriptor": "",
    "authors": [
      "Adrian Friebel",
      "Tim Johann",
      "Dirk Drasdo",
      "Stefan Hoehme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2005.07662"
  },
  {
    "id": "arXiv:2005.09327",
    "title": "Griefing-Penalty: Countermeasure for Griefing Attack in Lightning  Network",
    "abstract": "Comments: 29 pages, 20 figures, 2 table, A preliminary version of the paper was accepted in the proceedings of The 19th IEEE International Conference on Trust, Security and Privacy in Computing and Communications (IEEE TrustCom 2020), DOI Bookmark: 10.1109/TrustCom50675.2020.00138",
    "descriptor": "\nComments: 29 pages, 20 figures, 2 table, A preliminary version of the paper was accepted in the proceedings of The 19th IEEE International Conference on Trust, Security and Privacy in Computing and Communications (IEEE TrustCom 2020), DOI Bookmark: 10.1109/TrustCom50675.2020.00138\n",
    "authors": [
      "Subhra Mazumdar",
      "Prabal Banerjee",
      "Sushmita Ruj"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2005.09327"
  },
  {
    "id": "arXiv:2005.11583",
    "title": "What do class comments tell us? An investigation of comment evolution  and practices in Pharo Smalltalk",
    "abstract": "Comments: 35 pages, 26 figures, 10 tables, Journal format, five authors, three research questions",
    "descriptor": "\nComments: 35 pages, 26 figures, 10 tables, Journal format, five authors, three research questions\n",
    "authors": [
      "Pooja Rani",
      "Sebastiano Panichella",
      "Manuel Leuenberger",
      "Mohammad Ghafari",
      "Oscar Nierstrasz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2005.11583"
  },
  {
    "id": "arXiv:2006.02337",
    "title": "Minimization of Constraint Violation Probability in Model Predictive  Control",
    "abstract": "Comments: This is the pre-peer reviewed version of an article published by the International Journal of Robust and Nonlinear Control. The published version is available at this https URL This article may be used for non-commercial purposes in accordance with Wiley Terms and Conditions for Use of Self-Archived Versions",
    "descriptor": "\nComments: This is the pre-peer reviewed version of an article published by the International Journal of Robust and Nonlinear Control. The published version is available at this https URL This article may be used for non-commercial purposes in accordance with Wiley Terms and Conditions for Use of Self-Archived Versions\n",
    "authors": [
      "Tim Br\u00fcdigam",
      "Victor Ga\u00dfmann",
      "Dirk Wollherr",
      "Marion Leibold"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.02337"
  },
  {
    "id": "arXiv:2006.02482",
    "title": "Explaining the Behavior of Black-Box Prediction Algorithms with Causal  Learning",
    "abstract": "Explaining the Behavior of Black-Box Prediction Algorithms with Causal  Learning",
    "descriptor": "",
    "authors": [
      "Numair Sani",
      "Daniel Malinsky",
      "Ilya Shpitser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.02482"
  },
  {
    "id": "arXiv:2006.09373",
    "title": "The shape and simplicity biases of adversarially robust ImageNet-trained  CNNs",
    "abstract": "The shape and simplicity biases of adversarially robust ImageNet-trained  CNNs",
    "descriptor": "",
    "authors": [
      "Peijie Chen",
      "Chirag Agarwal",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.09373"
  },
  {
    "id": "arXiv:2006.09858",
    "title": "Geometry of Similarity Comparisons",
    "abstract": "Geometry of Similarity Comparisons",
    "descriptor": "",
    "authors": [
      "Puoya Tabaghi",
      "Jianhao Peng",
      "Olgica Milenkovic",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.09858"
  },
  {
    "id": "arXiv:2006.15337",
    "title": "On Dualization over Distributive Lattices",
    "abstract": "On Dualization over Distributive Lattices",
    "descriptor": "",
    "authors": [
      "Khaled Elbassioni"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2006.15337"
  },
  {
    "id": "arXiv:2006.15368",
    "title": "Offline Contextual Bandits with Overparameterized Models",
    "abstract": "Offline Contextual Bandits with Overparameterized Models",
    "descriptor": "",
    "authors": [
      "David Brandfonbrener",
      "William F. Whitney",
      "Rajesh Ranganath",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.15368"
  },
  {
    "id": "arXiv:2007.00107",
    "title": "Ideal formulations for constrained convex optimization problems with  indicator variables",
    "abstract": "Ideal formulations for constrained convex optimization problems with  indicator variables",
    "descriptor": "",
    "authors": [
      "Linchuan Wei",
      "Andres Gomez",
      "Simge Kucukyavuz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.00107"
  },
  {
    "id": "arXiv:2007.07978",
    "title": "CloudCast: A Satellite-Based Dataset and Baseline for Forecasting Clouds",
    "abstract": "Comments: For the novel dataset, see this https URL",
    "descriptor": "\nComments: For the novel dataset, see this https URL\n",
    "authors": [
      "A. H. Nielsen",
      "A. Iosifidis",
      "H. Karstoft"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.07978"
  },
  {
    "id": "arXiv:2007.08319",
    "title": "Less is More: A privacy-respecting Android malware classifier using  Federated Learning",
    "abstract": "Comments: 21 pages, 8 figures, accepted in PoPETS 2021.4",
    "descriptor": "\nComments: 21 pages, 8 figures, accepted in PoPETS 2021.4\n",
    "authors": [
      "Rafa G\u00e1lvez",
      "Veelasha Moonsamy",
      "Claudia Diaz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.08319"
  },
  {
    "id": "arXiv:2007.10817",
    "title": "Split and Expand: An inference-time improvement for Weakly Supervised  Cell Instance Segmentation",
    "abstract": "Split and Expand: An inference-time improvement for Weakly Supervised  Cell Instance Segmentation",
    "descriptor": "",
    "authors": [
      "Lin Geng Foo",
      "Jiamei Sun",
      "Alexander Binder"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2007.10817"
  },
  {
    "id": "arXiv:2008.06148",
    "title": "Complexity aspects of local minima and related notions",
    "abstract": "Comments: 41 pages, 10 figures",
    "descriptor": "\nComments: 41 pages, 10 figures\n",
    "authors": [
      "Amir Ali Ahmadi",
      "Jeffrey Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.06148"
  },
  {
    "id": "arXiv:2008.07186",
    "title": "On the convergence of adaptive stochastic collocation for elliptic  partial differential equations with affine diffusion",
    "abstract": "Comments: 24 pages, 1 figure",
    "descriptor": "\nComments: 24 pages, 1 figure\n",
    "authors": [
      "Martin Eigel",
      "Oliver Ernst",
      "Bj\u00f6rn Sprungk",
      "Lorenzo Tamellini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.07186"
  },
  {
    "id": "arXiv:2009.00154",
    "title": "Multilevel decompositions and norms for negative order Sobolev spaces",
    "abstract": "Comments: updated version includes numerical examples",
    "descriptor": "\nComments: updated version includes numerical examples\n",
    "authors": [
      "Thomas F\u00fchrer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2009.00154"
  },
  {
    "id": "arXiv:2009.01942",
    "title": "On system-wide safety staffing of large-scale parallel server networks",
    "abstract": "Comments: 36 pages",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Hassan Hmedi",
      "Ari Arapostathis",
      "Guodong Pang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.01942"
  },
  {
    "id": "arXiv:2009.04709",
    "title": "Quantifying the Preferential Direction of the Model Gradient in  Adversarial Training With Projected Gradient Descent",
    "abstract": "Comments: v3: new counting of Tables and Figures in the SM; fixed typo in eq. of Lemma 1; new evaluation of linearity of models; new evaluation of correlation of alignment metrics and robustness for a fixed training method; new citations to python libraries; changed range of some graphs to simplify the axes' digits; new comment about the difference of input gradient in proposed and baseline metric; editing",
    "descriptor": "\nComments: v3: new counting of Tables and Figures in the SM; fixed typo in eq. of Lemma 1; new evaluation of linearity of models; new evaluation of correlation of alignment metrics and robustness for a fixed training method; new citations to python libraries; changed range of some graphs to simplify the axes' digits; new comment about the difference of input gradient in proposed and baseline metric; editing\n",
    "authors": [
      "Ricardo Bigolin Lanfredi",
      "Joyce D. Schroeder",
      "Tolga Tasdizen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.04709"
  },
  {
    "id": "arXiv:2009.05685",
    "title": "Linear Shannon Capacity of Cayley Graphs",
    "abstract": "Linear Shannon Capacity of Cayley Graphs",
    "descriptor": "",
    "authors": [
      "Venkatesan Guruswami",
      "Andrii Riazanov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2009.05685"
  },
  {
    "id": "arXiv:2009.06808",
    "title": "Optimality of short-term synaptic plasticity in modelling certain  dynamic environments",
    "abstract": "Comments: Main paper: 12 pages, 4 figures. Supplementary Information: 13 pages, 4 figures",
    "descriptor": "\nComments: Main paper: 12 pages, 4 figures. Supplementary Information: 13 pages, 4 figures\n",
    "authors": [
      "Timoleon Moraitis",
      "Abu Sebastian",
      "Evangelos Eleftheriou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2009.06808"
  },
  {
    "id": "arXiv:2009.08452",
    "title": "Real-Time Anomaly Detection in Edge Streams",
    "abstract": "Comments: Extended Journal Version of arXiv:1911.04464",
    "descriptor": "\nComments: Extended Journal Version of arXiv:1911.04464\n",
    "authors": [
      "Siddharth Bhatia",
      "Rui Liu",
      "Bryan Hooi",
      "Minji Yoon",
      "Kijung Shin",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.08452"
  },
  {
    "id": "arXiv:2009.08541",
    "title": "Variational Disentanglement for Rare Event Modeling",
    "abstract": "Comments: Accepted to AAAI2021",
    "descriptor": "\nComments: Accepted to AAAI2021\n",
    "authors": [
      "Zidi Xiu",
      "Chenyang Tao",
      "Michael Gao",
      "Connor Davis",
      "Benjamin A. Goldstein",
      "Ricardo Henao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.08541"
  },
  {
    "id": "arXiv:2009.12029",
    "title": "Privacy-Preserving Push-sum Average Consensus via State Decomposition",
    "abstract": "Privacy-Preserving Push-sum Average Consensus via State Decomposition",
    "descriptor": "",
    "authors": [
      "Xiaomeng Chen",
      "Lingying Huang",
      "Kemi Ding",
      "Subhrakanti Dey",
      "Ling Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.12029"
  },
  {
    "id": "arXiv:2009.13342",
    "title": "Learning Category- and Instance-Aware Pixel Embedding for Fast Panoptic  Segmentation",
    "abstract": "Learning Category- and Instance-Aware Pixel Embedding for Fast Panoptic  Segmentation",
    "descriptor": "",
    "authors": [
      "Naiyu Gao",
      "Yanhu Shan",
      "Xin Zhao",
      "Kaiqi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.13342"
  },
  {
    "id": "arXiv:2010.03622",
    "title": "Theoretical Analysis of Self-Training with Deep Networks on Unlabeled  Data",
    "abstract": "Comments: Published at ICLR 2021",
    "descriptor": "\nComments: Published at ICLR 2021\n",
    "authors": [
      "Colin Wei",
      "Kendrick Shen",
      "Yining Chen",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.03622"
  },
  {
    "id": "arXiv:2010.04261",
    "title": "Dissecting Hessian: Understanding Common Structure of Hessian in Neural  Networks",
    "abstract": "Comments: 60 pages, 30 figures. Main text: 10 pages, 7 figures. First two authors have equal contribution and are in alphabetical order",
    "descriptor": "\nComments: 60 pages, 30 figures. Main text: 10 pages, 7 figures. First two authors have equal contribution and are in alphabetical order\n",
    "authors": [
      "Yikai Wu",
      "Xingyu Zhu",
      "Chenwei Wu",
      "Annie Wang",
      "Rong Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.04261"
  },
  {
    "id": "arXiv:2010.08262",
    "title": "Local plasticity rules can learn deep representations using  self-supervised contrastive predictions",
    "abstract": "Local plasticity rules can learn deep representations using  self-supervised contrastive predictions",
    "descriptor": "",
    "authors": [
      "Bernd Illing",
      "Jean Ventura",
      "Guillaume Bellec",
      "Wulfram Gerstner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.08262"
  },
  {
    "id": "arXiv:2010.08566",
    "title": "Reflective Decoding: Beyond Unidirectional Generation with Off-the-Shelf  Language Models",
    "abstract": "Reflective Decoding: Beyond Unidirectional Generation with Off-the-Shelf  Language Models",
    "descriptor": "",
    "authors": [
      "Peter West",
      "Ximing Lu",
      "Ari Holtzman",
      "Chandra Bhagavatula",
      "Jena Hwang",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.08566"
  },
  {
    "id": "arXiv:2010.11970",
    "title": "Two-sample Test using Projected Wasserstein Distance: Breaking the Curse  of Dimensionality",
    "abstract": "Comments: 10 pages, 3 figures. Accepted in ISIT-21",
    "descriptor": "\nComments: 10 pages, 3 figures. Accepted in ISIT-21\n",
    "authors": [
      "Jie Wang",
      "Rui Gao",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.11970"
  },
  {
    "id": "arXiv:2010.12537",
    "title": "TUTA: Tree-based Transformers for Generally Structured Table  Pre-training",
    "abstract": "TUTA: Tree-based Transformers for Generally Structured Table  Pre-training",
    "descriptor": "",
    "authors": [
      "Zhiruo Wang",
      "Haoyu Dong",
      "Ran Jia",
      "Jia Li",
      "Zhiyi Fu",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2010.12537"
  },
  {
    "id": "arXiv:2010.12760",
    "title": "Dataset Dynamics via Gradient Flows in Probability Space",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "David Alvarez-Melis",
      "Nicol\u00f2 Fusi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.12760"
  },
  {
    "id": "arXiv:2010.14889",
    "title": "Object shape error modelling and simulation during early design stage by  morphing Gaussian Random Fields",
    "abstract": "Object shape error modelling and simulation during early design stage by  morphing Gaussian Random Fields",
    "descriptor": "",
    "authors": [
      "Manoj Babu",
      "Pasquale Franciosa",
      "Prashanth Shekar",
      "Darek Ceglarek"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2010.14889"
  },
  {
    "id": "arXiv:2010.15153",
    "title": "On the Optimality and Convergence Properties of the Iterative Learning  Model Predictive Controller",
    "abstract": "Comments: technical note",
    "descriptor": "\nComments: technical note\n",
    "authors": [
      "Ugo Rosolia",
      "Yingzhao Lian",
      "Emilio T. Maddalena",
      "Giancarlo Ferrari-Trecate",
      "Colin N. Jones"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.15153"
  },
  {
    "id": "arXiv:2011.01681",
    "title": "Learning Causal Semantic Representation for Out-of-Distribution  Prediction",
    "abstract": "Comments: Figures for CSG-ind/DA; model selection highlighted; condition and intuition of identifiability; new version of OOD error bound supporting CSG-ind; improved experiment implementation, with shifted-MNIST and ImageCLEF-DA results updated; MDD and BNM baselines added; results on PACS and VLCS datasets added",
    "descriptor": "\nComments: Figures for CSG-ind/DA; model selection highlighted; condition and intuition of identifiability; new version of OOD error bound supporting CSG-ind; improved experiment implementation, with shifted-MNIST and ImageCLEF-DA results updated; MDD and BNM baselines added; results on PACS and VLCS datasets added\n",
    "authors": [
      "Chang Liu",
      "Xinwei Sun",
      "Jindong Wang",
      "Haoyue Tang",
      "Tao Li",
      "Tao Qin",
      "Wei Chen",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.01681"
  },
  {
    "id": "arXiv:2011.09899",
    "title": "MixMix: All You Need for Data-Free Compression Are Feature and Data  Mixing",
    "abstract": "MixMix: All You Need for Data-Free Compression Are Feature and Data  Mixing",
    "descriptor": "",
    "authors": [
      "Yuhang Li",
      "Feng Zhu",
      "Ruihao Gong",
      "Mingzhu Shen",
      "Xin Dong",
      "Fengwei Yu",
      "Shaoqing Lu",
      "Shi Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.09899"
  },
  {
    "id": "arXiv:2011.12077",
    "title": "CLAWS: Clustering Assisted Weakly Supervised Learning with Normalcy  Suppression for Anomalous Event Detection",
    "abstract": "Comments: Presented in the European Conference on Computer Vision ECCV 2020. (Changes from actual paper: 1) Recently published methods have been added in ShanghaiTech and UCF Crime comparison tabs. 2) Due to some error in arxiv compilation, few references are exceeding the paragraph. Also, word 'normalcy' in the title is misspelling despite being correct in the code. (Contents are intact)",
    "descriptor": "\nComments: Presented in the European Conference on Computer Vision ECCV 2020. (Changes from actual paper: 1) Recently published methods have been added in ShanghaiTech and UCF Crime comparison tabs. 2) Due to some error in arxiv compilation, few references are exceeding the paragraph. Also, word 'normalcy' in the title is misspelling despite being correct in the code. (Contents are intact)\n",
    "authors": [
      "Muhammad Zaigham Zaheer",
      "Arif Mahmood",
      "Marcella Astrid",
      "Seung-Ik Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.12077"
  },
  {
    "id": "arXiv:2011.13681",
    "title": "Point and Ask: Incorporating Pointing into Visual Question Answering",
    "abstract": "Point and Ask: Incorporating Pointing into Visual Question Answering",
    "descriptor": "",
    "authors": [
      "Arjun Mani",
      "Will Hinthorn",
      "Nobline Yoo",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.13681"
  },
  {
    "id": "arXiv:2011.14303",
    "title": "A Probabilistic Higher-order Fixpoint Logic",
    "abstract": "A Probabilistic Higher-order Fixpoint Logic",
    "descriptor": "",
    "authors": [
      "Yo Mitani",
      "Naoki Kobayashi",
      "Takeshi Tsukada"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2011.14303"
  },
  {
    "id": "arXiv:2012.00517",
    "title": "One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer",
    "abstract": "One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer",
    "descriptor": "",
    "authors": [
      "Joni Korpihalkola",
      "Tuomo Sipola",
      "Samir Puuska",
      "Tero Kokkonen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.00517"
  },
  {
    "id": "arXiv:2012.03548",
    "title": "Reset-Free Lifelong Learning with Skill-Space Planning",
    "abstract": "Comments: In the proceedings of the 7th International Conference on Learning Representations (ICLR), Virtual, April 2021",
    "descriptor": "\nComments: In the proceedings of the 7th International Conference on Learning Representations (ICLR), Virtual, April 2021\n",
    "authors": [
      "Kevin Lu",
      "Aditya Grover",
      "Pieter Abbeel",
      "Igor Mordatch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.03548"
  },
  {
    "id": "arXiv:2012.04221",
    "title": "Ditto: Fair and Robust Federated Learning Through Personalization",
    "abstract": "Comments: Accepted by ICML 2021",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Tian Li",
      "Shengyuan Hu",
      "Ahmad Beirami",
      "Virginia Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.04221"
  },
  {
    "id": "arXiv:2012.04293",
    "title": "CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions",
    "abstract": "Comments: Submitted to the 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks",
    "descriptor": "\nComments: Submitted to the 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks\n",
    "authors": [
      "Tayfun Ates",
      "Muhammed Samil Atesoglu",
      "Cagatay Yigit",
      "Ilker Kesen",
      "Mert Kobas",
      "Erkut Erdem",
      "Aykut Erdem",
      "Tilbe Goksun",
      "Deniz Yuret"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04293"
  },
  {
    "id": "arXiv:2012.04454",
    "title": "Adversarial Disentanglement of Speaker Representation for  Attribute-Driven Privacy Preservation",
    "abstract": "Comments: Accepted to Interspeech 2021",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Paul-Gauthier No\u00e9",
      "Mohammad Mohammadamini",
      "Driss Matrouf",
      "Titouan Parcollet",
      "Andreas Nautsch",
      "Jean-Fran\u00e7ois Bonastre"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2012.04454"
  },
  {
    "id": "arXiv:2012.05072",
    "title": "Variational System Identification for Nonlinear State-Space Models",
    "abstract": "Variational System Identification for Nonlinear State-Space Models",
    "descriptor": "",
    "authors": [
      "Jarrad Courts",
      "Adrian Wills",
      "Thomas Sch\u00f6n",
      "Brett Ninness"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2012.05072"
  },
  {
    "id": "arXiv:2012.05867",
    "title": "Virtual Classrooms and Real Harms: Remote Learning at U.S. Universities",
    "abstract": "Virtual Classrooms and Real Harms: Remote Learning at U.S. Universities",
    "descriptor": "",
    "authors": [
      "Shaanan Cohney",
      "Ross Teixeira",
      "Anne Kohlbrenner",
      "Arvind Narayanan",
      "Mihir Kshirsagar",
      "Yan Shvartzshnaider",
      "Madelyn Sanfilippo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2012.05867"
  },
  {
    "id": "arXiv:2012.06274",
    "title": "A Topic Coverage Approach to Evaluation of Topic Models",
    "abstract": "Comments: Results and contributions unchanged; Added new references; Improved the contextualization and the description of the work (abstr, intro, 7.1 concl, rw, concl); Moved technical details of data and model building to appendices; Improved layout;",
    "descriptor": "\nComments: Results and contributions unchanged; Added new references; Improved the contextualization and the description of the work (abstr, intro, 7.1 concl, rw, concl); Moved technical details of data and model building to appendices; Improved layout;\n",
    "authors": [
      "Damir Koren\u010di\u0107",
      "Strahil Ristov",
      "Jelena Repar",
      "Jan \u0160najder"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.06274"
  },
  {
    "id": "arXiv:2012.06706",
    "title": "Communication-Efficient Federated Learning with Compensated  Overlap-FedAvg",
    "abstract": "Comments: 15 pages, 9 figures",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Yuhao Zhou",
      "Ye Qing",
      "Jiancheng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2012.06706"
  },
  {
    "id": "arXiv:2012.09054",
    "title": "PGMAN: An Unsupervised Generative Multi-adversarial Network for  Pan-sharpening",
    "abstract": "Comments: Code is available &lt;this https URL&gt;",
    "descriptor": "\nComments: Code is available &lt;this https URL&gt;\n",
    "authors": [
      "Huanyu Zhou",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.09054"
  },
  {
    "id": "arXiv:2012.09421",
    "title": "Learning Fair Policies in Decentralized Cooperative Multi-Agent  Reinforcement Learning",
    "abstract": "Comments: International Conference on Machine Learning",
    "descriptor": "\nComments: International Conference on Machine Learning\n",
    "authors": [
      "Matthieu Zimmer",
      "Claire Glanois",
      "Umer Siddique",
      "Paul Weng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2012.09421"
  },
  {
    "id": "arXiv:2012.10430",
    "title": "Order-of-magnitude differences in computational performance of analog  Ising machines induced by the choice of nonlinearity",
    "abstract": "Order-of-magnitude differences in computational performance of analog  Ising machines induced by the choice of nonlinearity",
    "descriptor": "",
    "authors": [
      "Fabian B\u00f6hm",
      "Thomas Van Vaerenbergh",
      "Guy Verschaffelt",
      "Guy Van der Sande"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Emerging Technologies (cs.ET)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.10430"
  },
  {
    "id": "arXiv:2012.10885",
    "title": "LieTransformer: Equivariant self-attention for Lie Groups",
    "abstract": "LieTransformer: Equivariant self-attention for Lie Groups",
    "descriptor": "",
    "authors": [
      "Michael Hutchinson",
      "Charline Le Lan",
      "Sheheryar Zaidi",
      "Emilien Dupont",
      "Yee Whye Teh",
      "Hyunjik Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.10885"
  },
  {
    "id": "arXiv:2012.11657",
    "title": "Subword Sampling for Low Resource Word Alignment",
    "abstract": "Subword Sampling for Low Resource Word Alignment",
    "descriptor": "",
    "authors": [
      "Ehsaneddin Asgari",
      "Masoud Jalili Sabet",
      "Philipp Dufter",
      "Christopher Ringlstetter",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.11657"
  },
  {
    "id": "arXiv:2012.11662",
    "title": "Explicitly Encouraging Low Fractional Dimensional Trajectories Via  Reinforcement Learning",
    "abstract": "Comments: Presented at CORL 2020",
    "descriptor": "\nComments: Presented at CORL 2020\n",
    "authors": [
      "Sean Gillen",
      "Katie Byl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.11662"
  },
  {
    "id": "arXiv:2012.15412",
    "title": "WiForce: Wireless Sensing and Localization of Contact Forces on a Space  Continuum",
    "abstract": "Comments: 18 Pages, 19 Figures",
    "descriptor": "\nComments: 18 Pages, 19 Figures\n",
    "authors": [
      "Agrim Gupta",
      "Cedric Girerd",
      "Manideep Dunna",
      "Qiming Zhang",
      "Raghav Subbaraman",
      "Tania Morimoto",
      "Dinesh Bharadia"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.15412"
  },
  {
    "id": "arXiv:2012.15492",
    "title": "Super-k: A Piecewise Linear Classifier Based on Voronoi Tessellations",
    "abstract": "Comments: 11 pages, 15 figures, \"for the source code, see this https URL\"",
    "descriptor": "\nComments: 11 pages, 15 figures, \"for the source code, see this https URL\"\n",
    "authors": [
      "Rahman Salim Zengin",
      "Volkan Sezer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.15492"
  },
  {
    "id": "arXiv:2012.15525",
    "title": "BANG: Bridging Autoregressive and Non-autoregressive Generation with  Large Scale Pretraining",
    "abstract": "Comments: Accepted by ICML 2021",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Weizhen Qi",
      "Yeyun Gong",
      "Jian Jiao",
      "Yu Yan",
      "Weizhu Chen",
      "Dayiheng Liu",
      "Kewen Tang",
      "Houqiang Li",
      "Jiusheng Chen",
      "Ruofei Zhang",
      "Ming Zhou",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15525"
  },
  {
    "id": "arXiv:2012.15788",
    "title": "Evidence-based Factual Error Correction",
    "abstract": "Comments: Accepted at ACL2021",
    "descriptor": "\nComments: Accepted at ACL2021\n",
    "authors": [
      "James Thorne",
      "Andreas Vlachos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.15788"
  },
  {
    "id": "arXiv:2101.03735",
    "title": "Optimizing Biomanufacturing Harvesting Decisions under Limited  Historical Data",
    "abstract": "Comments: 37 pages, 6 figures",
    "descriptor": "\nComments: 37 pages, 6 figures\n",
    "authors": [
      "Bo Wang",
      "Wei Xie",
      "Tugce Martagan",
      "Alp Akcay",
      "Bram van Ravenstein"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.03735"
  },
  {
    "id": "arXiv:2101.10249",
    "title": "Assessing the Impact: Does an Improvement to a Revenue Management System  Lead to an Improved Revenue?",
    "abstract": "Assessing the Impact: Does an Improvement to a Revenue Management System  Lead to an Improved Revenue?",
    "descriptor": "",
    "authors": [
      "Greta Laage",
      "Emma Frejinger",
      "Andrea Lodi",
      "Guillaume Rabusseau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2101.10249"
  },
  {
    "id": "arXiv:2101.12158",
    "title": "Beyond Equi-joins: Ranking, Enumeration and Factorization",
    "abstract": "Comments: 18 pages, 15 figures",
    "descriptor": "\nComments: 18 pages, 15 figures\n",
    "authors": [
      "Nikolaos Tziavelis",
      "Wolfgang Gatterbauer",
      "Mirek Riedewald"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2101.12158"
  },
  {
    "id": "arXiv:2101.12616",
    "title": "Polynomial Trajectory Predictions for Improved Learning Performance",
    "abstract": "Comments: To appear in IEEE ICIP 2021",
    "descriptor": "\nComments: To appear in IEEE ICIP 2021\n",
    "authors": [
      "Ido Freeman",
      "Kun Zhao",
      "Anton Kummert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.12616"
  },
  {
    "id": "arXiv:2102.00804",
    "title": "Phoneme-BERT: Joint Language Modelling of Phoneme Sequence and ASR  Transcript",
    "abstract": "Comments: Accepted to Interspeech 2021 conference",
    "descriptor": "\nComments: Accepted to Interspeech 2021 conference\n",
    "authors": [
      "Mukuntha Narayanan Sundararaman",
      "Ayush Kumar",
      "Jithendra Vepa"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.00804"
  },
  {
    "id": "arXiv:2102.01232",
    "title": "Joint Active and Passive Beamforming Design for IRS-Assisted Multi-User  MIMO Systems: A VAMP-Based Approach",
    "abstract": "Joint Active and Passive Beamforming Design for IRS-Assisted Multi-User  MIMO Systems: A VAMP-Based Approach",
    "descriptor": "",
    "authors": [
      "Haseeb Ur Rehman",
      "Faouzi Bellili",
      "Amine Mezghani",
      "and Ekram Hossain"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2102.01232"
  },
  {
    "id": "arXiv:2102.01454",
    "title": "An Information Divergence Measure Between Neural Text and Human Text",
    "abstract": "An Information Divergence Measure Between Neural Text and Human Text",
    "descriptor": "",
    "authors": [
      "Krishna Pillutla",
      "Swabha Swayamdipta",
      "Rowan Zellers",
      "John Thickstun",
      "Sean Welleck",
      "Yejin Choi",
      "Zaid Harchaoui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.01454"
  },
  {
    "id": "arXiv:2102.01670",
    "title": "Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network  Optimization",
    "abstract": "Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network  Optimization",
    "descriptor": "",
    "authors": [
      "Kale-ab Tessera",
      "Sara Hooker",
      "Benjamin Rosman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.01670"
  },
  {
    "id": "arXiv:2102.01955",
    "title": "Predictive coding feedback results in perceived illusory contours in a  recurrent neural network",
    "abstract": "Comments: Manuscript under review",
    "descriptor": "\nComments: Manuscript under review\n",
    "authors": [
      "Zhaoyang Pang",
      "Callum Biggs O'May",
      "Bhavin Choksi",
      "Rufin VanRullen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2102.01955"
  },
  {
    "id": "arXiv:2102.02400",
    "title": "Provably End-to-end Label-Noise Learning without Anchor Points",
    "abstract": "Provably End-to-end Label-Noise Learning without Anchor Points",
    "descriptor": "",
    "authors": [
      "Xuefeng Li",
      "Tongliang Liu",
      "Bo Han",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02400"
  },
  {
    "id": "arXiv:2102.04057",
    "title": "Improving filling level classification with adversarial training",
    "abstract": "Comments: Accepted to the 28th IEEE International Conference on Image Processing (ICIP) 2021",
    "descriptor": "\nComments: Accepted to the 28th IEEE International Conference on Image Processing (ICIP) 2021\n",
    "authors": [
      "Apostolos Modas",
      "Alessio Xompero",
      "Ricardo Sanchez-Matilla",
      "Pascal Frossard",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.04057"
  },
  {
    "id": "arXiv:2102.04229",
    "title": "Learning the exchange-correlation functional from nature with fully  differentiable density functional theory",
    "abstract": "Learning the exchange-correlation functional from nature with fully  differentiable density functional theory",
    "descriptor": "",
    "authors": [
      "Muhammad F. Kasim",
      "Sam M. Vinko"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.04229"
  },
  {
    "id": "arXiv:2102.06806",
    "title": "Parameter-free Locally Accelerated Conditional Gradients",
    "abstract": "Parameter-free Locally Accelerated Conditional Gradients",
    "descriptor": "",
    "authors": [
      "Alejandro Carderera",
      "Jelena Diakonikolas",
      "Cheuk Yin Lin",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06806"
  },
  {
    "id": "arXiv:2102.07655",
    "title": "Dense for the Price of Sparse: Improved Performance of Sparsely  Initialized Networks via a Subspace Offset",
    "abstract": "Comments: 18 pages, 15 figures",
    "descriptor": "\nComments: 18 pages, 15 figures\n",
    "authors": [
      "Ilan Price",
      "Jared Tanner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07655"
  },
  {
    "id": "arXiv:2102.08332",
    "title": "Domain Name Encryption Is Not Enough: Privacy Leakage via IP-based  Website Fingerprinting",
    "abstract": "Comments: To appear in Proceedings of the 21st Privacy Enhancing Technologies Symposium (PETS 2021)",
    "descriptor": "\nComments: To appear in Proceedings of the 21st Privacy Enhancing Technologies Symposium (PETS 2021)\n",
    "authors": [
      "Nguyen Phong Hoang",
      "Arian Akhavan Niaki",
      "Phillipa Gill",
      "Michalis Polychronakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2102.08332"
  },
  {
    "id": "arXiv:2102.08570",
    "title": "Outside the Echo Chamber: Optimizing the Performative Risk",
    "abstract": "Outside the Echo Chamber: Optimizing the Performative Risk",
    "descriptor": "",
    "authors": [
      "John Miller",
      "Juan C. Perdomo",
      "Tijana Zrnic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.08570"
  },
  {
    "id": "arXiv:2102.09188",
    "title": "Edge Sparse Basis Network: A Deep Learning Framework for EEG Source  Localization",
    "abstract": "Edge Sparse Basis Network: A Deep Learning Framework for EEG Source  Localization",
    "descriptor": "",
    "authors": [
      "Chen Wei",
      "Kexin Lou",
      "Zhengyang Wang",
      "Mingqi Zhao",
      "Dante Mantini",
      "Quanying Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2102.09188"
  },
  {
    "id": "arXiv:2102.09242",
    "title": "DSRN: an Efficient Deep Network for Image Relighting",
    "abstract": "Comments: Accepted at ICIP 2021. $\\copyright$ IEEE",
    "descriptor": "\nComments: Accepted at ICIP 2021. $\\copyright$ IEEE\n",
    "authors": [
      "Sourya Dipta Das",
      "Nisarg A. Shah",
      "Saikat Dutta",
      "Himanshu Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.09242"
  },
  {
    "id": "arXiv:2102.10204",
    "title": "Linear Classifiers in Product Space Forms",
    "abstract": "Linear Classifiers in Product Space Forms",
    "descriptor": "",
    "authors": [
      "Puoya Tabaghi",
      "Eli Chien",
      "Chao Pan",
      "Jianhao Peng",
      "Olgica Milenkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.10204"
  },
  {
    "id": "arXiv:2102.10951",
    "title": "Explainers in the Wild: Making Surrogate Explainers Robust to  Distortions through Perception",
    "abstract": "Explainers in the Wild: Making Surrogate Explainers Robust to  Distortions through Perception",
    "descriptor": "",
    "authors": [
      "Alexander Hepburn",
      "Raul Santos-Rodriguez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.10951"
  },
  {
    "id": "arXiv:2102.12136",
    "title": "Augmenting Part-of-speech Tagging with Syntactic Information for  Vietnamese and Chinese",
    "abstract": "Comments: The comparison with existing methods in this paper is unfair because the hyper-parameters of Bi-LSTM are different compared with previous research. Importantly, there is a data leakage issue w.r.t this paper's experimental setup",
    "descriptor": "\nComments: The comparison with existing methods in this paper is unfair because the hyper-parameters of Bi-LSTM are different compared with previous research. Importantly, there is a data leakage issue w.r.t this paper's experimental setup\n",
    "authors": [
      "Duc-Vu Nguyen",
      "Kiet Van Nguyen",
      "Ngan Luu-Thuy Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.12136"
  },
  {
    "id": "arXiv:2103.00039",
    "title": "Practical and Private (Deep) Learning without Sampling or Shuffling",
    "abstract": "Practical and Private (Deep) Learning without Sampling or Shuffling",
    "descriptor": "",
    "authors": [
      "Peter Kairouz",
      "Brendan McMahan",
      "Shuang Song",
      "Om Thakkar",
      "Abhradeep Thakurta",
      "Zheng Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00039"
  },
  {
    "id": "arXiv:2103.00430",
    "title": "Training Generative Adversarial Networks in One Stage",
    "abstract": "Comments: Accepted to CVPR 2021",
    "descriptor": "\nComments: Accepted to CVPR 2021\n",
    "authors": [
      "Chengchao Shen",
      "Youtan Yin",
      "Xinchao Wang",
      "Xubin Li",
      "Jie Song",
      "Mingli Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.00430"
  },
  {
    "id": "arXiv:2103.01345",
    "title": "Emotion Dynamics in Movie Dialogues",
    "abstract": "Comments: 18 pages, 7 figures",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Will E. Hipson",
      "Saif M. Mohammad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.01345"
  },
  {
    "id": "arXiv:2103.02854",
    "title": "Morphset:Augmenting categorical emotion datasets with dimensional affect  labels using face morphing",
    "abstract": "Comments: in Proc IEEE International Conference on Image Processing (ICIP), Anchorage, Sep.2021",
    "descriptor": "\nComments: in Proc IEEE International Conference on Image Processing (ICIP), Anchorage, Sep.2021\n",
    "authors": [
      "Vassilios Vonikakis",
      "Dexter Neo",
      "Stefan Winkler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.02854"
  },
  {
    "id": "arXiv:2103.03677",
    "title": "Control Barrier Functions in Sampled-Data Systems",
    "abstract": "Comments: Published in IEEE Control Systems Letters, 6 pages. See prior version for additional theorem not included in final version",
    "descriptor": "\nComments: Published in IEEE Control Systems Letters, 6 pages. See prior version for additional theorem not included in final version\n",
    "authors": [
      "Joseph Breeden",
      "Kunal Garg",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.03677"
  },
  {
    "id": "arXiv:2103.04000",
    "title": "Off-Belief Learning",
    "abstract": "Off-Belief Learning",
    "descriptor": "",
    "authors": [
      "Hengyuan Hu",
      "Adam Lerer",
      "Brandon Cui",
      "David Wu",
      "Luis Pineda",
      "Noam Brown",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.04000"
  },
  {
    "id": "arXiv:2103.04247",
    "title": "Adaptive Coding for Matrix Multiplication at Edge Networks",
    "abstract": "Adaptive Coding for Matrix Multiplication at Edge Networks",
    "descriptor": "",
    "authors": [
      "Elahe Vedadi",
      "Hulya Seferoglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2103.04247"
  },
  {
    "id": "arXiv:2103.05056",
    "title": "LCDNet: Deep Loop Closure Detection and Point Cloud Registration for  LiDAR SLAM",
    "abstract": "LCDNet: Deep Loop Closure Detection and Point Cloud Registration for  LiDAR SLAM",
    "descriptor": "",
    "authors": [
      "Daniele Cattaneo",
      "Matteo Vaghi",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.05056"
  },
  {
    "id": "arXiv:2103.05690",
    "title": "Multitask 3D CBCT-to-CT Translation and Organs-at-Risk Segmentation  Using Physics-Based Data Augmentation",
    "abstract": "Comments: Medical Physics 2021",
    "descriptor": "\nComments: Medical Physics 2021\n",
    "authors": [
      "Navdeep Dahiya",
      "Sadegh R Alam",
      "Pengpeng Zhang",
      "Si-Yuan Zhang",
      "Anthony Yezzi",
      "Saad Nadeem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.05690"
  },
  {
    "id": "arXiv:2103.06064",
    "title": "Graph Neural Networks Inspired by Classical Iterative Algorithms",
    "abstract": "Comments: accepted as long oral for ICML 2021",
    "descriptor": "\nComments: accepted as long oral for ICML 2021\n",
    "authors": [
      "Yongyi Yang",
      "Tang Liu",
      "Yangkun Wang",
      "Jinjing Zhou",
      "Quan Gan",
      "Zhewei Wei",
      "Zheng Zhang",
      "Zengfeng Huang",
      "David Wipf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06064"
  },
  {
    "id": "arXiv:2103.06271",
    "title": "Learning-Based Vulnerability Analysis of Cyber-Physical Systems",
    "abstract": "Learning-Based Vulnerability Analysis of Cyber-Physical Systems",
    "descriptor": "",
    "authors": [
      "Amir Khazraei",
      "Spencer Hallyburton",
      "Qitong Gao",
      "Yu Wang",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.06271"
  },
  {
    "id": "arXiv:2103.06759",
    "title": "Automatic Social Distance Estimation From Images: Performance  Evaluation, Test Benchmark, and Algorithm",
    "abstract": "Comments: 12 pages, 10 figures, 5 tables",
    "descriptor": "\nComments: 12 pages, 10 figures, 5 tables\n",
    "authors": [
      "Mert Seker",
      "Anssi M\u00e4nnist\u00f6",
      "Alexandros Iosifidis",
      "Jenni Raitoharju"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06759"
  },
  {
    "id": "arXiv:2103.08147",
    "title": "LARNet: Lie Algebra Residual Network for Face Recognition",
    "abstract": "Comments: Accepted by ICML 2021",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Xiaolong Yang",
      "Xiaohong Jia",
      "Dihong Gong",
      "Dong-Ming Yan",
      "Zhifeng Li",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.08147"
  },
  {
    "id": "arXiv:2103.10415",
    "title": "Refining Language Models with Compositional Explanations",
    "abstract": "Comments: Code: this https URL",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Huihan Yao",
      "Ying Chen",
      "Qinyuan Ye",
      "Xisen Jin",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10415"
  },
  {
    "id": "arXiv:2103.12040",
    "title": "LaneAF: Robust Multi-Lane Detection with Affinity Fields",
    "abstract": "LaneAF: Robust Multi-Lane Detection with Affinity Fields",
    "descriptor": "",
    "authors": [
      "Hala Abualsaud",
      "Sean Liu",
      "David Lu",
      "Kenny Situ",
      "Akshay Rangesh",
      "Mohan M. Trivedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.12040"
  },
  {
    "id": "arXiv:2103.16223",
    "title": "LemgoRL: An open-source Benchmark Tool to Train Reinforcement Learning  Agents for Traffic Signal Control in a real-world simulation scenario",
    "abstract": "LemgoRL: An open-source Benchmark Tool to Train Reinforcement Learning  Agents for Traffic Signal Control in a real-world simulation scenario",
    "descriptor": "",
    "authors": [
      "Arthur M\u00fcller",
      "Vishal Rangras",
      "Georg Schnittker",
      "Michael Waldmann",
      "Maxim Friesen",
      "Tobias Ferfers",
      "Lukas Schreckenberg",
      "Florian Hufen",
      "J\u00fcrgen Jasperneite",
      "Marco Wiering"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.16223"
  },
  {
    "id": "arXiv:2104.00447",
    "title": "Towards Evaluating and Training Verifiably Robust Neural Networks",
    "abstract": "Comments: Accepted to CVPR 2021 (Oral)",
    "descriptor": "\nComments: Accepted to CVPR 2021 (Oral)\n",
    "authors": [
      "Zhaoyang Lyu",
      "Minghao Guo",
      "Tong Wu",
      "Guodong Xu",
      "Kehuan Zhang",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.00447"
  },
  {
    "id": "arXiv:2104.02125",
    "title": "SpeakerStew: Scaling to Many Languages with a Triaged Multilingual  Text-Dependent and Text-Independent Speaker Verification System",
    "abstract": "SpeakerStew: Scaling to Many Languages with a Triaged Multilingual  Text-Dependent and Text-Independent Speaker Verification System",
    "descriptor": "",
    "authors": [
      "Roza Chojnacka",
      "Jason Pelecanos",
      "Quan Wang",
      "Ignacio Lopez Moreno"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.02125"
  },
  {
    "id": "arXiv:2104.02410",
    "title": "Using Voice and Biofeedback to Predict User Engagement during  Requirements Interviews",
    "abstract": "Comments: We discovered issues in the code used for the experiments, and we need to run them again. While the method reported in the paper is correct, the results are not",
    "descriptor": "\nComments: We discovered issues in the code used for the experiments, and we need to run them again. While the method reported in the paper is correct, the results are not\n",
    "authors": [
      "Alessio Ferrari",
      "Thaide Huichapa",
      "Paola Spoletini",
      "Nicole Novielli",
      "Davide Fucci",
      "Daniela Girardi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.02410"
  },
  {
    "id": "arXiv:2104.02748",
    "title": "Communication-Efficient Agnostic Federated Averaging",
    "abstract": "Communication-Efficient Agnostic Federated Averaging",
    "descriptor": "",
    "authors": [
      "Jae Ro",
      "Mingqing Chen",
      "Rajiv Mathews",
      "Mehryar Mohri",
      "Ananda Theertha Suresh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.02748"
  },
  {
    "id": "arXiv:2104.05557",
    "title": "SC-GlowTTS: an Efficient Zero-Shot Multi-Speaker Text-To-Speech Model",
    "abstract": "Comments: Accepted on Interspeech 2021",
    "descriptor": "\nComments: Accepted on Interspeech 2021\n",
    "authors": [
      "Edresson Casanova",
      "Christopher Shulby",
      "Eren G\u00f6lge",
      "Nicolas Michael M\u00fcller",
      "Frederico Santos de Oliveira",
      "Arnaldo Candido Junior",
      "Anderson da Silva Soares",
      "Sandra Maria Aluisio",
      "Moacir Antonelli Ponti"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2104.05557"
  },
  {
    "id": "arXiv:2104.05654",
    "title": "Dynamic Matching Markets in Power Grid: Concepts and Solution using Deep  Reinforcement Learning",
    "abstract": "Dynamic Matching Markets in Power Grid: Concepts and Solution using Deep  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Majid Majidi",
      "Deepan Muthirayan",
      "Masood Parvania",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.05654"
  },
  {
    "id": "arXiv:2104.06624",
    "title": "Device-Cloud Collaborative Learning for Recommendation",
    "abstract": "Comments: A new version will be updated soon",
    "descriptor": "\nComments: A new version will be updated soon\n",
    "authors": [
      "Jiangchao Yao",
      "Feng Wang",
      "KunYang Jia",
      "Bo Han",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.06624"
  },
  {
    "id": "arXiv:2104.07932",
    "title": "Interval-censored Hawkes processes",
    "abstract": "Interval-censored Hawkes processes",
    "descriptor": "",
    "authors": [
      "Marian-Andrei Rizoiu",
      "Alexander Soen",
      "Shidi Li",
      "Leanne Dong",
      "Pio Calderon",
      "Aditya Krishna Menon",
      "Lexing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.07932"
  },
  {
    "id": "arXiv:2104.08459",
    "title": "KazakhTTS: An Open-Source Kazakh Text-to-Speech Synthesis Dataset",
    "abstract": "Comments: 5 pages, 4 tables, 2 figures, accepted to INTERSPEECH 2021",
    "descriptor": "\nComments: 5 pages, 4 tables, 2 figures, accepted to INTERSPEECH 2021\n",
    "authors": [
      "Saida Mussakhojayeva",
      "Aigerim Janaliyeva",
      "Almas Mirzakhmetov",
      "Yerbolat Khassanov",
      "Huseyin Atakan Varol"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2104.08459"
  },
  {
    "id": "arXiv:2104.08529",
    "title": "The Impact of ASR on the Automatic Analysis of Linguistic Complexity and  Sophistication in Spontaneous L2 Speech",
    "abstract": "Comments: accepted at Interspeech2021",
    "descriptor": "\nComments: accepted at Interspeech2021\n",
    "authors": [
      "Yu Qiao",
      "Wei Zhou",
      "Elma Kerz",
      "Ralf Schl\u00fcter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08529"
  },
  {
    "id": "arXiv:2104.09413",
    "title": "Linear-time uniform generation of random sparse contingency tables with  specified marginals",
    "abstract": "Comments: 27 pages, 1 figure",
    "descriptor": "\nComments: 27 pages, 1 figure\n",
    "authors": [
      "Andrii Arman",
      "Pu Gao",
      "Nicholas Wormald"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2104.09413"
  },
  {
    "id": "arXiv:2104.09748",
    "title": "Waveform Phasicity Prediction from Arterial Sounds through Spectrogram  Analysis using Convolutional Neural Networks for Limb Perfusion Assessment",
    "abstract": "Comments: 5 pages, 8 figures",
    "descriptor": "\nComments: 5 pages, 8 figures\n",
    "authors": [
      "Adrit Rao",
      "Kevin Battenfield",
      "Oliver Aalami"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.09748"
  },
  {
    "id": "arXiv:2104.10796",
    "title": "Efficient Non-Sampling Knowledge Graph Embedding",
    "abstract": "Comments: 10 pages, 3 figures. The first two authors contributed equally to the work. Accepted to WWW 2021",
    "descriptor": "\nComments: 10 pages, 3 figures. The first two authors contributed equally to the work. Accepted to WWW 2021\n",
    "authors": [
      "Zelong Li",
      "Jianchao Ji",
      "Zuohui Fu",
      "Yingqiang Ge",
      "Shuyuan Xu",
      "Chong Chen",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.10796"
  },
  {
    "id": "arXiv:2104.11014",
    "title": "Network Space Search for Pareto-Efficient Spaces",
    "abstract": "Comments: CVPR2021 Workshop (Efficient Deep Learning for Computer Vision). Website: this https URL",
    "descriptor": "\nComments: CVPR2021 Workshop (Efficient Deep Learning for Computer Vision). Website: this https URL\n",
    "authors": [
      "Min-Fong Hong",
      "Hao-Yun Chen",
      "Min-Hung Chen",
      "Yu-Syuan Xu",
      "Hsien-Kai Kuo",
      "Yi-Min Tsai",
      "Hung-Jen Chen",
      "Kevin Jou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.11014"
  },
  {
    "id": "arXiv:2104.11348",
    "title": "Earnings-21: A Practical Benchmark for ASR in the Wild",
    "abstract": "Comments: Accepted to INTERSPEECH 2021. June 15 2021: Addressing the comments of reviewers and updating the results of our internal ESPNet model. The results do not change our conclusions. April 28th, 2021: We found and resolved an issue in our experimental evaluation that scored the LibriSpeech model at ~20% worse relative WER than the actual WER. The updated results do not affect our conclusions",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2021. June 15 2021: Addressing the comments of reviewers and updating the results of our internal ESPNet model. The results do not change our conclusions. April 28th, 2021: We found and resolved an issue in our experimental evaluation that scored the LibriSpeech model at ~20% worse relative WER than the actual WER. The updated results do not affect our conclusions\n",
    "authors": [
      "Miguel Del Rio",
      "Natalie Delworth",
      "Ryan Westerman",
      "Michelle Huang",
      "Nishchal Bhandari",
      "Joseph Palakapilly",
      "Quinten McNamara",
      "Joshua Dong",
      "Piotr Zelasko",
      "Miguel Jette"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.11348"
  },
  {
    "id": "arXiv:2104.14937",
    "title": "Federated Learning with Fair Averaging",
    "abstract": "Comments: Accepted by IJCAI2021",
    "descriptor": "\nComments: Accepted by IJCAI2021\n",
    "authors": [
      "Zheng Wang",
      "Xiaoliang Fan",
      "Jianzhong Qi",
      "Chenglu Wen",
      "Cheng Wang",
      "Rongshan Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14937"
  },
  {
    "id": "arXiv:2105.00106",
    "title": "Directional TGV-based image restoration under Poisson noise",
    "abstract": "Comments: 20 pages, 1 table, 13 figures",
    "descriptor": "\nComments: 20 pages, 1 table, 13 figures\n",
    "authors": [
      "Daniela di Serafino",
      "Germana Landi",
      "Marco Viola"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.00106"
  },
  {
    "id": "arXiv:2105.00623",
    "title": "Black-Box Dissector: Towards Erasing-based Hard-Label Model Stealing  Attack",
    "abstract": "Black-Box Dissector: Towards Erasing-based Hard-Label Model Stealing  Attack",
    "descriptor": "",
    "authors": [
      "Yixu Wang",
      "Jie Li",
      "Hong Liu",
      "Yan Wang",
      "Yongjian Wu",
      "Feiyue Huang",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.00623"
  },
  {
    "id": "arXiv:2105.00648",
    "title": "A novel hybrid methodology of measuring sentence similarity",
    "abstract": "A novel hybrid methodology of measuring sentence similarity",
    "descriptor": "",
    "authors": [
      "Yongmin Yoo",
      "Tak-Sung Heo",
      "Yeongjoon Park"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.00648"
  },
  {
    "id": "arXiv:2105.01370",
    "title": "Small-Sample Inferred Adaptive Recoding for Batched Network Coding",
    "abstract": "Comments: 7 pages, 2 figures, accepted in ISIT-21, appendix added",
    "descriptor": "\nComments: 7 pages, 2 figures, accepted in ISIT-21, appendix added\n",
    "authors": [
      "Jie Wang",
      "Zhiyuan Jia",
      "Hoover H. F. Yin",
      "Shenghao Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.01370"
  },
  {
    "id": "arXiv:2105.01933",
    "title": "Automated scoring of pre-REM sleep in mice with deep learning",
    "abstract": "Comments: 14 pages, 5 figures",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Niklas Grieger",
      "Justus T. C. Schwabedal",
      "Stefanie Wendel",
      "Yvonne Ritze",
      "Stephan Bialonski"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.01933"
  },
  {
    "id": "arXiv:2105.04655",
    "title": "Causal Inference in medicine and in health policy, a summary",
    "abstract": "Comments: 31 pages, 17 figures, to appear in the second edition of the handbook of computational intelligence",
    "descriptor": "\nComments: 31 pages, 17 figures, to appear in the second edition of the handbook of computational intelligence\n",
    "authors": [
      "Wenhao Zhang",
      "Ramin Ramezani",
      "Arash Naeim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04655"
  },
  {
    "id": "arXiv:2105.06762",
    "title": "DialogSum: A Real-Life Scenario Dialogue Summarization Dataset",
    "abstract": "Comments: ACL findings",
    "descriptor": "\nComments: ACL findings\n",
    "authors": [
      "Yulong Chen",
      "Yang Liu",
      "Liang Chen",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.06762"
  },
  {
    "id": "arXiv:2105.08353",
    "title": "Quantitative and Approximate Monitoring",
    "abstract": "Comments: To appear in LICS 2021; corrected a reference",
    "descriptor": "\nComments: To appear in LICS 2021; corrected a reference\n",
    "authors": [
      "Thomas A. Henzinger",
      "N. Ege Sara\u00e7"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.08353"
  },
  {
    "id": "arXiv:2105.08743",
    "title": "Coverage Path Planning for Spraying Drones",
    "abstract": "Comments: In preparation for submission",
    "descriptor": "\nComments: In preparation for submission\n",
    "authors": [
      "E. Viridiana Vazquez-Carmona",
      "J. Irving Vasquez-Gomez",
      "Juan Carlos Herrera Lozada",
      "Mayra Antonio-Cruz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.08743"
  },
  {
    "id": "arXiv:2105.08866",
    "title": "Localization, Convexity, and Star Aggregation",
    "abstract": "Localization, Convexity, and Star Aggregation",
    "descriptor": "",
    "authors": [
      "Suhas Vijaykumar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08866"
  },
  {
    "id": "arXiv:2105.09002",
    "title": "QuatDE: Dynamic Quaternion Embedding for Knowledge Graph Completion",
    "abstract": "QuatDE: Dynamic Quaternion Embedding for Knowledge Graph Completion",
    "descriptor": "",
    "authors": [
      "Haipeng Gao",
      "Kun Yang",
      "Yuxue Yang",
      "Rufai Yusuf Zakari",
      "Jim Wilson Owusu",
      "Ke Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.09002"
  },
  {
    "id": "arXiv:2105.12937",
    "title": "Towards a Better Understanding of Linear Models for Recommendation",
    "abstract": "Towards a Better Understanding of Linear Models for Recommendation",
    "descriptor": "",
    "authors": [
      "Ruoming Jin",
      "Dong Li",
      "Jing Gao",
      "Zhi Liu",
      "Li Chen",
      "Yang Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.12937"
  },
  {
    "id": "arXiv:2105.15157",
    "title": "Adaptive Feature Alignment for Adversarial Training",
    "abstract": "Adaptive Feature Alignment for Adversarial Training",
    "descriptor": "",
    "authors": [
      "Tao Wang",
      "Ruixin Zhang",
      "Xingyu Chen",
      "Kai Zhao",
      "Xiaolin Huang",
      "Yuge Huang",
      "Shaoxin Li",
      "Jilin Li",
      "Feiyue Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.15157"
  },
  {
    "id": "arXiv:2106.00083",
    "title": "Composing Networks of Automated Market Makers",
    "abstract": "Composing Networks of Automated Market Makers",
    "descriptor": "",
    "authors": [
      "Daniel Engel",
      "Maurice Herlihy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.00083"
  },
  {
    "id": "arXiv:2106.01357",
    "title": "Diffusion Schr\u00f6dinger Bridge with Applications to Score-Based  Generative Modeling",
    "abstract": "Comments: 57 pages, 17 figures",
    "descriptor": "\nComments: 57 pages, 17 figures\n",
    "authors": [
      "Valentin De Bortoli",
      "James Thornton",
      "Jeremy Heng",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.01357"
  },
  {
    "id": "arXiv:2106.02283",
    "title": "Privacy Preference Signals: Past, Present and Future",
    "abstract": "Comments: To appear in Proceedings on Privacy Enhancing Technologies (PETS) 2021 Issue 4",
    "descriptor": "\nComments: To appear in Proceedings on Privacy Enhancing Technologies (PETS) 2021 Issue 4\n",
    "authors": [
      "Maximilian Hils",
      "Daniel W. Woods",
      "Rainer B\u00f6hme"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.02283"
  },
  {
    "id": "arXiv:2106.02331",
    "title": "Manifold-Aware Deep Clustering: Maximizing Angles between Embedding  Vectors Based on Regular Simplex",
    "abstract": "Comments: Accepted by Interspeech 2021",
    "descriptor": "\nComments: Accepted by Interspeech 2021\n",
    "authors": [
      "Keitaro Tanaka",
      "Ryosuke Sawata",
      "Shusuke Takahashi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02331"
  },
  {
    "id": "arXiv:2106.02391",
    "title": "Data-Driven Control Design with LMIs and Dynamic Programming",
    "abstract": "Data-Driven Control Design with LMIs and Dynamic Programming",
    "descriptor": "",
    "authors": [
      "Donghwan Lee",
      "Do Wan Kim"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02391"
  },
  {
    "id": "arXiv:2106.02472",
    "title": "A Database for Research on Detection and Enhancement of Speech  Transmitted over HF links",
    "abstract": "Comments: Submitted to ITG 2021",
    "descriptor": "\nComments: Submitted to ITG 2021\n",
    "authors": [
      "Jens Heitkaemper",
      "Joerg Schmalenstroeer",
      "Joerg Ullmann",
      "Valentin Ion",
      "Reinhold Haeb-Umbach"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.02472"
  },
  {
    "id": "arXiv:2106.03096",
    "title": "TabularNet: A Neural Network Architecture for Understanding Semantic  Structures of Tabular Data",
    "abstract": "Comments: 10 pages, 7 figures, to be published in the proceedings of KDD 2021",
    "descriptor": "\nComments: 10 pages, 7 figures, to be published in the proceedings of KDD 2021\n",
    "authors": [
      "Lun Du",
      "Fei Gao",
      "Xu Chen",
      "Ran Jia",
      "Junshan Wang",
      "Jiang Zhang",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03096"
  },
  {
    "id": "arXiv:2106.03153",
    "title": "Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation",
    "abstract": "Comments: Accepted by ICML 2021",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Dongchan Min",
      "Dong Bok Lee",
      "Eunho Yang",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.03153"
  },
  {
    "id": "arXiv:2106.03569",
    "title": "Socially-Aware Self-Supervised Tri-Training for Recommendation",
    "abstract": "Comments: 9 pages, accepted by KDD'21",
    "descriptor": "\nComments: 9 pages, accepted by KDD'21\n",
    "authors": [
      "Junliang Yu",
      "Hongzhi Yin",
      "Min Gao",
      "Xin Xia",
      "Xiangliang Zhang",
      "Nguyen Quoc Viet Hung"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.03569"
  },
  {
    "id": "arXiv:2106.03609",
    "title": "High-Dimensional Bayesian Optimisation with Variational Autoencoders and  Deep Metric Learning",
    "abstract": "High-Dimensional Bayesian Optimisation with Variational Autoencoders and  Deep Metric Learning",
    "descriptor": "",
    "authors": [
      "Antoine Grosnit",
      "Rasul Tutunov",
      "Alexandre Max Maraval",
      "Ryan-Rhys Griffiths",
      "Alexander I. Cowen-Rivers",
      "Lin Yang",
      "Lin Zhu",
      "Wenlong Lyu",
      "Zhitang Chen",
      "Jun Wang",
      "Jan Peters",
      "Haitham Bou-Ammar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03609"
  },
  {
    "id": "arXiv:2106.03969",
    "title": "Chow-Liu++: Optimal Prediction-Centric Learning of Tree Ising Models",
    "abstract": "Comments: 49 pages, 3 figures",
    "descriptor": "\nComments: 49 pages, 3 figures\n",
    "authors": [
      "Enric Boix-Adsera",
      "Guy Bresler",
      "Frederic Koehler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.03969"
  },
  {
    "id": "arXiv:2106.04274",
    "title": "A Synchronized Reprojection-based Model for 3D Human Pose Estimation",
    "abstract": "A Synchronized Reprojection-based Model for 3D Human Pose Estimation",
    "descriptor": "",
    "authors": [
      "Yicheng Deng",
      "Cheng Sun",
      "Yongqi Sun",
      "Jiahui Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04274"
  },
  {
    "id": "arXiv:2106.04426",
    "title": "Hash Layers For Large Sparse Models",
    "abstract": "Hash Layers For Large Sparse Models",
    "descriptor": "",
    "authors": [
      "Stephen Roller",
      "Sainbayar Sukhbaatar",
      "Arthur Szlam",
      "Jason Weston"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.04426"
  },
  {
    "id": "arXiv:2106.04871",
    "title": "Congestion Control in the Cellular-V2X Sidelink",
    "abstract": "Comments: 8 Pages, 7 Figures, 6 Tables",
    "descriptor": "\nComments: 8 Pages, 7 Figures, 6 Tables\n",
    "authors": [
      "Brian McCarthy",
      "Aisling O'Driscoll"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.04871"
  },
  {
    "id": "arXiv:2106.05012",
    "title": "Bayesian Bellman Operators",
    "abstract": "Bayesian Bellman Operators",
    "descriptor": "",
    "authors": [
      "Matthew Fellows",
      "Kristian Hartikainen",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05012"
  },
  {
    "id": "arXiv:2106.05218",
    "title": "Convergence of parallel overlapping domain decomposition methods for the  Helmholtz equation",
    "abstract": "Convergence of parallel overlapping domain decomposition methods for the  Helmholtz equation",
    "descriptor": "",
    "authors": [
      "Shihua Gong",
      "Martin J.Gander",
      "Ivan G. Graham",
      "David Lafontaine",
      "Euan A. Spence"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.05218"
  },
  {
    "id": "arXiv:2106.05426",
    "title": "Low-Dimensional Structure in the Space of Language Representations is  Reflected in Brain Responses",
    "abstract": "Comments: Preprint, submitted for review",
    "descriptor": "\nComments: Preprint, submitted for review\n",
    "authors": [
      "Richard Antonello",
      "Javier Turek",
      "Vy Vo",
      "Alexander Huth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05426"
  },
  {
    "id": "arXiv:2106.05616",
    "title": "SVMA: A GAN-based model for Monocular 3D Human Pose Estimation",
    "abstract": "SVMA: A GAN-based model for Monocular 3D Human Pose Estimation",
    "descriptor": "",
    "authors": [
      "Yicheng Deng",
      "Yongqi Sun",
      "Jiahui Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05616"
  },
  {
    "id": "arXiv:2106.05739",
    "title": "Separation Results between Fixed-Kernel and Feature-Learning Probability  Metrics",
    "abstract": "Comments: 32 pages, 3 figures",
    "descriptor": "\nComments: 32 pages, 3 figures\n",
    "authors": [
      "Carles Domingo-Enrich",
      "Youssef Mroueh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.05739"
  },
  {
    "id": "arXiv:2106.05923",
    "title": "FetReg: Placental Vessel Segmentation and Registration in Fetoscopy  Challenge Dataset",
    "abstract": "FetReg: Placental Vessel Segmentation and Registration in Fetoscopy  Challenge Dataset",
    "descriptor": "",
    "authors": [
      "Sophia Bano",
      "Alessandro Casella",
      "Francisco Vasconcelos",
      "Sara Moccia",
      "George Attilakos",
      "Ruwan Wimalasundera",
      "Anna L. David",
      "Dario Paladini",
      "Jan Deprest",
      "Elena De Momi",
      "Leonardo S. Mattos",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.05923"
  },
  {
    "id": "arXiv:2106.06087",
    "title": "Causal Analysis of Syntactic Agreement Mechanisms in Neural Language  Models",
    "abstract": "Comments: Accepted to ACL-IJCNLP 2021. Code can be found at this https URL",
    "descriptor": "\nComments: Accepted to ACL-IJCNLP 2021. Code can be found at this https URL\n",
    "authors": [
      "Matthew Finlayson",
      "Aaron Mueller",
      "Stuart Shieber",
      "Sebastian Gehrmann",
      "Tal Linzen",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06087"
  },
  {
    "id": "arXiv:2106.06183",
    "title": "Improving RNN-T ASR Performance with Date-Time and Location Awareness",
    "abstract": "Comments: To appear in TSD 2021",
    "descriptor": "\nComments: To appear in TSD 2021\n",
    "authors": [
      "Swayambhu Nath Ray",
      "Soumyajit Mitra",
      "Raghavendra Bilgi",
      "Sri Garimella"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06183"
  },
  {
    "id": "arXiv:2106.06440",
    "title": "Learning Compositional Shape Priors for Few-Shot 3D Reconstruction",
    "abstract": "Comments: 13 pages, 12 figures. arXiv admin note: substantial text overlap with arXiv:2004.06302",
    "descriptor": "\nComments: 13 pages, 12 figures. arXiv admin note: substantial text overlap with arXiv:2004.06302\n",
    "authors": [
      "Mateusz Michalkiewicz",
      "Stavros Tsogkas",
      "Sarah Parisot",
      "Mahsa Baktashmotlagh",
      "Anders Eriksson",
      "Eugene Belilovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06440"
  },
  {
    "id": "arXiv:2106.06743",
    "title": "Hippocampus segmentation in magnetic resonance images of Alzheimer's  patients using Deep machine learning",
    "abstract": "Hippocampus segmentation in magnetic resonance images of Alzheimer's  patients using Deep machine learning",
    "descriptor": "",
    "authors": [
      "Hossein Yousefi-Banaem",
      "Saber Malekzadeh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.06743"
  },
  {
    "id": "arXiv:2106.06822",
    "title": "A Pseudo Label-wise Attention Network for Automatic ICD Coding",
    "abstract": "A Pseudo Label-wise Attention Network for Automatic ICD Coding",
    "descriptor": "",
    "authors": [
      "Yifan Wu",
      "Min Zeng",
      "Ying Yu",
      "Min Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06822"
  },
  {
    "id": "arXiv:2106.06881",
    "title": "A public transit network optimization model for equitable access to  social services",
    "abstract": "Comments: 38 pages, 6 figures; replaced missing ancillary files",
    "descriptor": "\nComments: 38 pages, 6 figures; replaced missing ancillary files\n",
    "authors": [
      "Adam Rumpf",
      "Hemanshu Kaul"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.06881"
  },
  {
    "id": "arXiv:2106.06935",
    "title": "Neural Bellman-Ford Networks: A General Graph Neural Network Framework  for Link Prediction",
    "abstract": "Neural Bellman-Ford Networks: A General Graph Neural Network Framework  for Link Prediction",
    "descriptor": "",
    "authors": [
      "Zhaocheng Zhu",
      "Zuobai Zhang",
      "Louis-Pascal Xhonneux",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06935"
  },
  {
    "id": "arXiv:2106.06998",
    "title": "Low-memory stochastic backpropagation with multi-channel randomized  trace estimation",
    "abstract": "Low-memory stochastic backpropagation with multi-channel randomized  trace estimation",
    "descriptor": "",
    "authors": [
      "Mathias Louboutin",
      "Ali Siahkoohi",
      "Rongrong Wang",
      "Felix J. Herrmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.06998"
  },
  {
    "id": "arXiv:2106.07084",
    "title": "Security Analysis of the Silver Bullet Technique for RowHammer  Prevention",
    "abstract": "Comments: 40 pages",
    "descriptor": "\nComments: 40 pages\n",
    "authors": [
      "Abdullah Giray Ya\u011fl\u0131k\u00e7\u0131",
      "Jeremie S. Kim",
      "Fabrice Devaux",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.07084"
  },
  {
    "id": "arXiv:2106.07141",
    "title": "Selection of Source Images Heavily Influences the Effectiveness of  Adversarial Attacks",
    "abstract": "Selection of Source Images Heavily Influences the Effectiveness of  Adversarial Attacks",
    "descriptor": "",
    "authors": [
      "Utku Ozbulak",
      "Esla Timothy Anzaku",
      "Wesley De Neve",
      "Arnout Van Messem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07141"
  },
  {
    "id": "arXiv:2106.07537",
    "title": "A Wasserstein Minimax Framework for Mixed Linear Regression",
    "abstract": "Comments: To appear in 38th International Conference on Machine Learning (ICML 2021)",
    "descriptor": "\nComments: To appear in 38th International Conference on Machine Learning (ICML 2021)\n",
    "authors": [
      "Theo Diamandis",
      "Yonina C. Eldar",
      "Alireza Fallah",
      "Farzan Farnia",
      "Asuman Ozdaglar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07537"
  },
  {
    "id": "arXiv:2106.07577",
    "title": "F-T-LSTM based Complex Network for Joint Acoustic Echo Cancellation and  Speech Enhancement",
    "abstract": "Comments: Accepted by Interspeech 2021",
    "descriptor": "\nComments: Accepted by Interspeech 2021\n",
    "authors": [
      "Shimin Zhang",
      "Yuxiang Kong",
      "Shubo Lv",
      "Yanxin Hu",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.07577"
  },
  {
    "id": "arXiv:2106.07728",
    "title": "Targeted Data Acquisition for Evolving Negotiation Agents",
    "abstract": "Comments: The Thirty-eighth International Conference on Machine Learning",
    "descriptor": "\nComments: The Thirty-eighth International Conference on Machine Learning\n",
    "authors": [
      "Minae Kwon",
      "Siddharth Karamcheti",
      "Mariano-Florentino Cuellar",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.07728"
  },
  {
    "id": "arXiv:2106.07770",
    "title": "Potato Crop Stress Identification in Aerial Images using Deep  Learning-based Object Detection",
    "abstract": "Comments: 15 pages, 4 figures",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Sujata Butte",
      "Aleksandar Vakanski",
      "Kasia Duellman",
      "Haotian Wang",
      "Amin Mirkouei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07770"
  },
  {
    "id": "arXiv:2106.07785",
    "title": "Multivariate Public Key Cryptosystem from Sidon Spaces",
    "abstract": "Comments: Appeared in Public-Key Cryptography - PKC 2021, 24th IACR International Conference on Practice and Theory of Public Key Cryptography",
    "descriptor": "\nComments: Appeared in Public-Key Cryptography - PKC 2021, 24th IACR International Conference on Practice and Theory of Public Key Cryptography\n",
    "authors": [
      "Netanel Raviv",
      "Ben Langton",
      "Itzhak Tamo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.07785"
  },
  {
    "id": "arXiv:2106.07787",
    "title": "Tracing Back Music Emotion Predictions to Sound Sources and Intuitive  Perceptual Qualities",
    "abstract": "Comments: In Proceedings of the 18th Sound and Music Computing Conference (SMC 2021)",
    "descriptor": "\nComments: In Proceedings of the 18th Sound and Music Computing Conference (SMC 2021)\n",
    "authors": [
      "Shreyan Chowdhury",
      "Verena Praher",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.07787"
  },
  {
    "id": "arXiv:2106.07843",
    "title": "Teacher-Student MixIT for Unsupervised and Semi-supervised Speech  Separation",
    "abstract": "Comments: Accepted to Interspeech 2021",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Jisi Zhang",
      "Catalin Zorila",
      "Rama Doddipatla",
      "Jon Barker"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.07843"
  },
  {
    "id": "arXiv:2106.08008",
    "title": "Towards Long-term Non-invasive Monitoring for Epilepsy via Wearable EEG  Devices",
    "abstract": "Comments: 4 pages, 3 figures, 2 tables, preprint",
    "descriptor": "\nComments: 4 pages, 3 figures, 2 tables, preprint\n",
    "authors": [
      "Thorir Mar Ingolfsson",
      "Andrea Cossettini",
      "Xiaying Wang",
      "Enrico Tabanelli",
      "Giuseppe Tagliavini",
      "Philippe Ryvlin",
      "Luca Benini"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08008"
  },
  {
    "id": "arXiv:2106.08017",
    "title": "Color2Style: Real-Time Exemplar-Based Image Colorization with  Self-Reference Learning and Deep Feature Modulation",
    "abstract": "Comments: 16 pages, 21 figures",
    "descriptor": "\nComments: 16 pages, 21 figures\n",
    "authors": [
      "Hengyuan Zhao",
      "Wenhao Wu",
      "Yihao Liu",
      "Dongliang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.08017"
  },
  {
    "id": "arXiv:2106.08048",
    "title": "Epidemic modelling of multiple virus strains: a case study of SARS-CoV-2  B.1.1.7 in Moscow",
    "abstract": "Epidemic modelling of multiple virus strains: a case study of SARS-CoV-2  B.1.1.7 in Moscow",
    "descriptor": "",
    "authors": [
      "Boris Tseytlin",
      "Ilya Makarov"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.08048"
  },
  {
    "id": "arXiv:2106.08049",
    "title": "Demographic Fairness in Face Identification: The Watchlist Imbalance  Effect",
    "abstract": "Comments: 5 pages, 6 figures",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Pawel Drozdowski",
      "Christian Rathgeb",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.08049"
  },
  {
    "id": "arXiv:2106.08061",
    "title": "Relation Modeling in Spatio-Temporal Action Localization",
    "abstract": "Comments: CVPR 2021 ActivityNet Workshop Report",
    "descriptor": "\nComments: CVPR 2021 ActivityNet Workshop Report\n",
    "authors": [
      "Yutong Feng",
      "Jianwen Jiang",
      "Ziyuan Huang",
      "Zhiwu Qing",
      "Xiang Wang",
      "Shiwei Zhang",
      "Mingqian Tang",
      "Yue Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08061"
  },
  {
    "id": "arXiv:2106.08078",
    "title": "Time-free solution to independent set problem using P systems with  active membranes",
    "abstract": "Time-free solution to independent set problem using P systems with  active membranes",
    "descriptor": "",
    "authors": [
      "Yu Jin",
      "Bosheng Song",
      "Yanyan Li",
      "Ying Zhu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.08078"
  },
  {
    "id": "arXiv:2106.08114",
    "title": "Don't Count on One to Carry the Ball: Scaling BFT without Sacrifing  Efficiency",
    "abstract": "Don't Count on One to Carry the Ball: Scaling BFT without Sacrifing  Efficiency",
    "descriptor": "",
    "authors": [
      "Kexin Hu",
      "Kaiwen Guo",
      "Qiang Tang",
      "Zhenfeng Zhang",
      "Hao Cheng",
      "Zhiyang Zhao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08114"
  },
  {
    "id": "arXiv:2106.08157",
    "title": "CeFi vs. DeFi -- Comparing Centralized to Decentralized Finance",
    "abstract": "CeFi vs. DeFi -- Comparing Centralized to Decentralized Finance",
    "descriptor": "",
    "authors": [
      "Kaihua Qin",
      "Liyi Zhou",
      "Yaroslav Afonin",
      "Ludovico Lazzaretti",
      "Arthur Gervais"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08157"
  },
  {
    "id": "arXiv:2106.08167",
    "title": "ShortcutFusion: From Tensorflow to FPGA-based accelerator with  reuse-aware memory allocation for shortcut data",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Duy Thanh Nguyen",
      "Hyeonseung Je",
      "Tuan Nghia Nguyen",
      "Soojung Ryu",
      "Kyujung Lee",
      "Hyuk-Jae Lee"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.08167"
  },
  {
    "id": "arXiv:2106.08187",
    "title": "Thompson Sampling for Unimodal Bandits",
    "abstract": "Comments: There are some technical parts need to be improved. We will fix these places and provide an updated version",
    "descriptor": "\nComments: There are some technical parts need to be improved. We will fix these places and provide an updated version\n",
    "authors": [
      "Long Yang",
      "Zhao Li",
      "Zehong Hu",
      "Shasha Ruan",
      "Shijian Li",
      "Gang Pan",
      "Hongyang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08187"
  },
  {
    "id": "arXiv:2106.08274",
    "title": "Elasticity Based Demand Forecasting and Price Optimization for Online  Retail",
    "abstract": "Elasticity Based Demand Forecasting and Price Optimization for Online  Retail",
    "descriptor": "",
    "authors": [
      "Chengcheng Liu",
      "M\u00e1ty\u00e1s A. Sustik"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.08274"
  },
  {
    "id": "arXiv:2106.08301",
    "title": "Efficient Micro-Structured Weight Unification and Pruning for Neural  Network Compression",
    "abstract": "Comments: 10 pages, 3 figures and 5 tables",
    "descriptor": "\nComments: 10 pages, 3 figures and 5 tables\n",
    "authors": [
      "Sheng Lin",
      "Wei Jiang",
      "Wei Wang",
      "Kaidi Xu",
      "Yanzhi Wang",
      "Shan Liu",
      "Songnan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08301"
  }
]
[
  {
    "id": "arXiv:2106.00001",
    "title": "Privately Learning Subspaces",
    "abstract": "Private data analysis suffers a costly curse of dimensionality. However, the\ndata often has an underlying low-dimensional structure. For example, when\noptimizing via gradient descent, the gradients often lie in or near a\nlow-dimensional subspace. If that low-dimensional structure can be identified,\nthen we can avoid paying (in terms of privacy or accuracy) for the high ambient\ndimension.\nWe present differentially private algorithms that take input data sampled\nfrom a low-dimensional linear subspace (possibly with a small amount of error)\nand output that subspace (or an approximation to it). These algorithms can\nserve as a pre-processing step for other procedures.",
    "descriptor": "",
    "authors": [
      "Vikrant Singhal",
      "Thomas Steinke"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.00001"
  },
  {
    "id": "arXiv:2106.00002",
    "title": "Analysis and classification of main risk factors causing stroke in  Shanxi Province",
    "abstract": "In China, stroke is the first leading cause of death in recent years. It is a\nmajor cause of long-term physical and cognitive impairment, which bring great\npressure on the National Public Health System. Evaluation of the risk of\ngetting stroke is important for the prevention and treatment of stroke in\nChina. A data set with 2000 hospitalized stroke patients in 2018 and 27583\nresidents during the year 2017 to 2020 is analyzed in this study. Due to data\nincompleteness, inconsistency, and non-structured formats, missing values in\nthe raw data are filled with -1 as an abnormal class. With the cleaned\nfeatures, three models on risk levels of getting stroke are built by using\nmachine learning methods. The importance of \"8+2\" factors from China National\nStroke Prevention Project (CSPP) is evaluated via decision tree and random\nforest models. Except for \"8+2\" factors the importance of features and SHAP1\nvalues for lifestyle information, demographic information, and medical\nmeasurement are evaluated and ranked via a random forest model. Furthermore, a\nlogistic regression model is applied to evaluate the probability of getting\nstroke for different risk levels. Based on the census data in both communities\nand hospitals from Shanxi Province, we investigate different risk factors of\ngetting stroke and their ranking with interpretable machine learning models.\nThe results show that Hypertension (Systolic blood pressure, Diastolic blood\npressure), Physical Inactivity (Lack of sports), and Overweight (BMI) are\nranked as the top three high-risk factors of getting stroke in Shanxi province.\nThe probability of getting stroke for a person can also be predicted via our\nmachine learning model.",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Junjie Liu",
      "Yiyang Sun",
      "Jing Ma",
      "Jiachen Tu",
      "Yuhui Deng",
      "Ping He",
      "Huaxiong Huang",
      "Xiaoshuang Zhou",
      "Shixin Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00002"
  },
  {
    "id": "arXiv:2106.00003",
    "title": "Parallelized Computation and Backpropagation Under Angle-Parametrized  Orthogonal Matrices",
    "abstract": "We present a methodology for parallel acceleration of learning in the\npresence of matrix orthogonality and unitarity constraints of interest in\nseveral branches of machine learning. We show how an apparently sequential\nelementary rotation parametrization can be restructured into blocks of\ncommutative operations using a well-known tool for coloring the edges of\ncomplete graphs, in turn widely applied to schedule round-robin\n(all-against-all) sports tournaments. The resulting decomposition admits an\nalgorithm to compute a fully-parametrized orthogonal matrix from its rotation\nparameters in $O(n)$ sequential steps and one to compute the gradient of a\ntraining loss with respect to its parameters in $O(n\\log n)$ steps. We discuss\nparametric restrictions of interest to generative modeling and present\npromising performance results with a prototype GPU implementation.",
    "descriptor": "",
    "authors": [
      "Firas Hamze"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.00003"
  },
  {
    "id": "arXiv:2106.00007",
    "title": "DikpolaSat Mission: Improvement of Space Flight Performance and Optimal  Control Using Trained Deep Neural Network -- Trajectory Controller for Space  Objects Collision Avoidance",
    "abstract": "This paper introduced the space mission DikpolaSat Mission, how this research\nfits into the mission, and the importance of having a trained DNN model instead\nof the usual GN&C functionality. This paper shows how the controller\ndemonstration is carried out by having the spacecraft follow a desired path,\nspecified in the referenced model. Increases can be made by examining the route\nused to construct a DNN and understanding the effects of various activating\nfunctions on system efficiency. The obstacle avoidance algorithm is built into\nthe control features to respond spontaneously using inputs from the neural\nnetwork for collision avoidance while optimizing the modified trajectory. The\naction of a neural network to control the adaptive nature of the nonlinear\nmechanisms in the controller will make the control system capable of handling\nmultiple nonlinear events and also uncertainties that have not been induced in\nthe control algorithm. Multiple algorithms for optimizing flight controls and\nfuel consumption can be implemented using knowledge of flight dynamics in\ntrajectory and also in the event of obstacle avoidance. This paper also\nexplains how a DNN can learn to control the flight path and make the system\nmore reliable with each launch, thereby improving the chances of predicting\ncollisions of space objects. The data released from this research is used to\ndesign more advanced DNN model capable of predicting other orbital events as\nwell.",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Manuel Ntumba",
      "Saurabh Gore",
      "Jean Baptiste Awanyo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00007"
  },
  {
    "id": "arXiv:2106.00008",
    "title": "Robust discovery of partial differential equations in complex situations",
    "abstract": "Data-driven discovery of partial differential equations (PDEs) has achieved\nconsiderable development in recent years. Several aspects of problems have been\nresolved by sparse regression-based and neural network-based methods. However,\nthe performances of existing methods lack stability when dealing with complex\nsituations, including sparse data with high noise, high-order derivatives and\nshock waves, which bring obstacles to calculating derivatives accurately.\nTherefore, a robust PDE discovery framework, called the robust deep\nlearning-genetic algorithm (R-DLGA), that incorporates the physics-informed\nneural network (PINN), is proposed in this work. In the framework, a\npreliminary result of potential terms provided by the deep learning-genetic\nalgorithm is added into the loss function of the PINN as physical constraints\nto improve the accuracy of derivative calculation. It assists to optimize the\npreliminary result and obtain the ultimately discovered PDE by eliminating the\nerror compensation terms. The stability and accuracy of the proposed R-DLGA in\nseveral complex situations are examined for proof-and-concept, and the results\nprove that the proposed framework is able to calculate derivatives accurately\nwith the optimization of PINN and possesses surprising robustness to complex\nsituations, including sparse data with high noise, high-order derivatives, and\nshock waves.",
    "descriptor": "\nComments: 20 pages, 8 figures\n",
    "authors": [
      "Hao Xu",
      "Dongxiao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00008"
  },
  {
    "id": "arXiv:2106.00010",
    "title": "Multi-Scale Attention Neural Network for Acoustic Echo Cancellation",
    "abstract": "Acoustic Echo Cancellation (AEC) plays a key role in speech interaction by\nsuppressing the echo received at microphone introduced by acoustic\nreverberations from loudspeakers. Since the performance of linear adaptive\nfilter (AF) would degrade severely due to nonlinear distortions, background\nnoises, and microphone clipping in real scenarios, deep learning has been\nemployed for AEC for its good nonlinear modelling ability. In this paper, we\nconstructed an end-to-end multi-scale attention neural network for AEC.\nTemporal convolution is first used to transform waveform into spectrogram. The\nspectrograms of the far-end reference and the near-end mixture are\nconcatenated, and fed to a temporal convolution network (TCN) with stacked\ndilated convolution layers. Attention mechanism is performed among these\nrepresentations from different layers to adaptively extract relevant features\nby referring to the previous hidden state in the encoder long short-term memory\n(LSTM) unit. The representations are weighted averaged and fed to the encoder\nLSTM for the near-end speech estimation. Experiments show the superiority of\nour method in terms of the echo return loss enhancement (ERLE) for single-talk\nperiods and the perceptual evaluation of speech quality (PESQ) score for\ndouble-talk periods in background noise and nonlinear distortion scenarios.",
    "descriptor": "\nComments: 5 pages, 3 figures, 4 tables. arXiv admin note: substantial text overlap with arXiv:2105.14666\n",
    "authors": [
      "Lu Ma",
      "Song Yang",
      "Yaguang Gong",
      "Zhongqin Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00010"
  },
  {
    "id": "arXiv:2106.00011",
    "title": "Constrained Deep Reinforcement Based Functional Split Optimization in  Virtualized RANs",
    "abstract": "Virtualized Radio Access Network (vRAN) brings agility to Next-Generation RAN\nthrough functional split. It allows decomposing the base station (BS) functions\ninto virtualized components and hosts it either at the distributed-unit (DU) or\ncentral-unit (CU). However, deciding which functions to deploy at DU or CU to\nminimize the total network cost is challenging. In this paper, a constrained\ndeep reinforcement based functional split optimization (CDRS) is proposed to\noptimize the locations of functions in vRAN. Our formulation results in a\ncombinatorial and NP-hard problem for which finding the exact solution is\ncomputationally expensive. Hence, in our proposed approach, a policy gradient\nmethod with Lagrangian relaxation is applied that uses a penalty signal to lead\nthe policy toward constraint satisfaction. It utilizes a neural network\narchitecture formed by an encoder-decoder sequence-to-sequence model based on\nstacked Long Short-term Memory (LSTM) networks to approximate the policy.\nGreedy decoding and temperature sampling methods are also leveraged for a\nsearch strategy to infer the best solution among candidates from multiple\ntrained models that help to avoid a severe suboptimality. Simulations are\nperformed to evaluate the performance of the proposed solution in both\nsynthetic and real network datasets. Our findings reveal that CDRS successfully\nlearns the optimal decision, solves the problem with the accuracy of 0.05\\%\noptimality gap and becomes the most cost-effective compared to the available\nRAN setups. Moreover, altering the routing cost and traffic load does not\nsignificantly degrade the optimality. The results also show that all of our\nCDRS settings have faster computational time than the optimal baseline solver.\nOur proposed method fills the gap of optimizing the functional split offering a\nnear-optimal solution, faster computational time and minimal hand-engineering.",
    "descriptor": "\nComments: Submitted to IEEE for possible publication. arXiv admin note: text overlap with arXiv:2105.14731\n",
    "authors": [
      "Fahri Wisnu Murti",
      "Samad Ali",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00011"
  },
  {
    "id": "arXiv:2106.00012",
    "title": "Persistent Homology Captures the Generalization of Neural Networks  Without A Validation Set",
    "abstract": "The training of neural networks is usually monitored with a validation\n(holdout) set to estimate the generalization of the model. This is done instead\nof measuring intrinsic properties of the model to determine whether it is\nlearning appropriately. In this work, we suggest studying the training of\nneural networks with Algebraic Topology, specifically Persistent Homology (PH).\nUsing simplicial complex representations of neural networks, we study the PH\ndiagram distance evolution on the neural network learning process with\ndifferent architectures and several datasets. Results show that the PH diagram\ndistance between consecutive neural network states correlates with the\nvalidation accuracy, implying that the generalization error of a neural network\ncould be intrinsically estimated without any holdout set.",
    "descriptor": "",
    "authors": [
      "Asier Guti\u00e9rrez-Fandi\u00f1o",
      "David P\u00e9rez-Fern\u00e1ndez",
      "Jordi Armengol-Estap\u00e9",
      "Marta Villegas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2106.00012"
  },
  {
    "id": "arXiv:2106.00014",
    "title": "Diffusion Self-Organizing Map on the Hypersphere",
    "abstract": "We discuss a diffusion based implementation of the self-organizing map on the\nunit hypersphere. We show that this approach can be efficiently implemented\nusing just linear algebra methods, we give a python numpy implementation, and\nwe illustrate the approach using the well known MNIST dataset.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "M. Andrecut"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00014"
  },
  {
    "id": "arXiv:2106.00026",
    "title": "Machine-Learning Non-Conservative Dynamics for New-Physics Detection",
    "abstract": "Energy conservation is a basic physics principle, the breakdown of which\noften implies new physics. This paper presents a method for data-driven \"new\nphysics\" discovery. Specifically, given a trajectory governed by unknown\nforces, our Neural New-Physics Detector (NNPhD) aims to detect new physics by\ndecomposing the force field into conservative and non-conservative components,\nwhich are represented by a Lagrangian Neural Network (LNN) and a universal\napproximator network (UAN), respectively, trained to minimize the force\nrecovery error plus a constant $\\lambda$ times the magnitude of the predicted\nnon-conservative force. We show that a phase transition occurs at $\\lambda$=1,\nuniversally for arbitrary forces. We demonstrate that NNPhD successfully\ndiscovers new physics in toy numerical experiments, rediscovering friction\n(1493) from a damped double pendulum, Neptune from Uranus' orbit (1846) and\ngravitational waves (2017) from an inspiraling orbit. We also show how NNPhD\ncoupled with an integrator outperforms previous methods for predicting the\nfuture of a damped double pendulum.",
    "descriptor": "\nComments: 17 pages, 7 figs, 2 tables\n",
    "authors": [
      "Ziming Li",
      "Bohan Wang",
      "Qi Meng",
      "Wei Chen",
      "Max Tegmark",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00026"
  },
  {
    "id": "arXiv:2106.00038",
    "title": "HEMET: A Homomorphic-Encryption-Friendly Privacy-Preserving Mobile  Neural Network Architecture",
    "abstract": "Recently Homomorphic Encryption (HE) is used to implement Privacy-Preserving\nNeural Networks (PPNNs) that perform inferences directly on encrypted data\nwithout decryption. Prior PPNNs adopt mobile network architectures such as\nSqueezeNet for smaller computing overhead, but we find na\\\"ively using mobile\nnetwork architectures for a PPNN does not necessarily achieve shorter inference\nlatency. Despite having less parameters, a mobile network architecture\ntypically introduces more layers and increases the HE multiplicative depth of a\nPPNN, thereby prolonging its inference latency. In this paper, we propose a\n\\textbf{HE}-friendly privacy-preserving \\textbf{M}obile neural n\\textbf{ET}work\narchitecture, \\textbf{HEMET}. Experimental results show that, compared to\nstate-of-the-art (SOTA) PPNNs, HEMET reduces the inference latency by\n$59.3\\%\\sim 61.2\\%$, and improves the inference accuracy by $0.4 \\% \\sim\n0.5\\%$.",
    "descriptor": "",
    "authors": [
      "Qian Lou",
      "Lei Jiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00038"
  },
  {
    "id": "arXiv:2106.00041",
    "title": "A Grammatical Approach for Distributed Business Process Management using  Structured and Cooperatively Edited Mobile Artifacts",
    "abstract": "In this thesis, we focus on the proposal of distributed workflow systems\ndedicated to the automation of administrative business processes. We propose an\napproach to build such systems by relying on the concepts of multiagent\nsystems, Peer to Peer (P2P) architecture, Service-Oriented Architecture (SOA)\nand structured documents (artifacts) cooperative edition. Indeed, we develop\nmathematical tools that allow any workflow systems designer, to express each\nadministrative process in the form of an attributed grammar whose symbols\nrepresent tasks to be executed, productions specify a scheduling of these\ntasks, and instances (the derivation trees that conform to it) represent the\ndifferent execution scenarios leading to business goal states. The obtained\ngrammatical model is then introduced into a proposed P2P system which is in\ncharge of carrying out the completely decentralised execution of the underlying\nprocess's instances. The said system orchestrates a process's instance\nexecution as a choreography during which, various software agents driven by\nhuman agents (actors), coordinate themselves through artifacts that they\ncollectively edit. The exchanged artifacts represent the system's memory: they\nprovide information on already executed tasks, on those ready to be executed\nand on their executors. The software agents are autonomous and identical: they\nexecute the same unique protocol each time they receive an artifact. This\nprotocol allows them to identify the tasks they must immediately execute, to\nexecute them, to update the artifact and to disseminate it if necessary, for\nthe continuation of the execution. Moreover, actors potentially have only a\npartial perception of processes in which they are involved. In practice, this\nmeans that certain tasks can be carried out confidentially.",
    "descriptor": "",
    "authors": [
      "Milliam Maxime Zekeng Ndadji"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.00041"
  },
  {
    "id": "arXiv:2106.00042",
    "title": "A study on the plasticity of neural networks",
    "abstract": "One aim shared by multiple settings, such as continual learning or transfer\nlearning, is to leverage previously acquired knowledge to converge faster on\nthe current task. Usually this is done through fine-tuning, where an implicit\nassumption is that the network maintains its plasticity, meaning that the\nperformance it can reach on any given task is not affected negatively by\npreviously seen tasks. It has been observed recently that a pretrained model on\ndata from the same distribution as the one it is fine-tuned on might not reach\nthe same generalisation as a freshly initialised one. We build and extend this\nobservation, providing a hypothesis for the mechanics behind it. We discuss the\nimplication of losing plasticity for continual learning which heavily relies on\noptimising pretrained models.",
    "descriptor": "",
    "authors": [
      "Tudor Berariu",
      "Wojciech Czarnecki",
      "Soham De",
      "Jorg Bornschein",
      "Samuel Smith",
      "Razvan Pascanu",
      "Claudia Clopath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00042"
  },
  {
    "id": "arXiv:2106.00047",
    "title": "Learning and Generalization in RNNs",
    "abstract": "Simple recurrent neural networks (RNNs) and their more advanced cousins LSTMs\netc. have been very successful in sequence modeling. Their theoretical\nunderstanding, however, is lacking and has not kept pace with the progress for\nfeedforward networks, where a reasonably complete understanding in the special\ncase of highly overparametrized one-hidden-layer networks has emerged. In this\npaper, we make progress towards remedying this situation by proving that RNNs\ncan learn functions of sequences. In contrast to the previous work that could\nonly deal with functions of sequences that are sums of functions of individual\ntokens in the sequence, we allow general functions. Conceptually and\ntechnically, we introduce new ideas which enable us to extract information from\nthe hidden state of the RNN in our proofs -- addressing a crucial weakness in\nprevious work. We illustrate our results on some regular language recognition\nproblems.",
    "descriptor": "",
    "authors": [
      "Abhishek Panigrahi",
      "Navin Goyal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00047"
  },
  {
    "id": "arXiv:2106.00050",
    "title": "Continual 3D Convolutional Neural Networks for Real-time Processing of  Videos",
    "abstract": "This paper introduces Continual 3D Convolutional Neural Networks (Co3D CNNs),\na new computational formulation of spatio-temporal 3D CNNs, in which videos are\nprocessed frame-by-frame rather than by clip. In online processing tasks\ndemanding frame-wise predictions, Co3D CNNs dispense with the computational\nredundancies of regular 3D CNNs, namely the repeated convolutions over frames,\nwhich appear in multiple clips. While yielding an order of magnitude in\ncomputational savings, Co3D CNNs have memory requirements comparable with that\nof corresponding regular 3D CNNs and are less affected by changes in the size\nof the temporal receptive field. We show that Continual 3D CNNs initialised on\nthe weights from preexisting state-of-the-art video recognition models reduce\nthe floating point operations for frame-wise computations by 10.0-12.4x while\nimproving accuracy on Kinetics-400 by 2.3-3.8. Moreover, we investigate the\ntransient start-up response of Co3D CNNs and perform an extensive benchmark of\nonline processing speed as well as accuracy for publicly available\nstate-of-the-art 3D CNNs on modern hardware.",
    "descriptor": "\nComments: 12 pages, 6 figures, 5 tables\n",
    "authors": [
      "Lukas Hedegaard",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00050"
  },
  {
    "id": "arXiv:2106.00055",
    "title": "More than just Frequency? Demasking Unsupervised Hypernymy Prediction  Methods",
    "abstract": "This paper presents a comparison of unsupervised methods of hypernymy\nprediction (i.e., to predict which word in a pair of words such as fish-cod is\nthe hypernym and which the hyponym). Most importantly, we demonstrate across\ndatasets for English and for German that the predictions of three methods\n(WeedsPrec, invCL, SLQS Row) strongly overlap and are highly correlated with\nfrequency-based predictions. In contrast, the second-order method SLQS shows an\noverall lower accuracy but makes correct predictions where the others go wrong.\nOur study once more confirms the general need to check the frequency bias of a\ncomputational method in order to identify frequency-(un)related effects.",
    "descriptor": "\nComments: ACL Findings, 5 pages\n",
    "authors": [
      "Thomas Bott",
      "Dominik Schlechtweg",
      "Sabine Schulte im Walde"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00055"
  },
  {
    "id": "arXiv:2106.00058",
    "title": "PUDLE: Implicit Acceleration of Dictionary Learning by Backpropagation",
    "abstract": "The dictionary learning problem, representing data as a combination of few\natoms, has long stood as a popular method for learning representations in\nstatistics and signal processing. The most popular dictionary learning\nalgorithm alternates between sparse coding and dictionary update steps, and a\nrich literature has studied its theoretical convergence. The growing popularity\nof neurally plausible unfolded sparse coding networks has led to the empirical\nfinding that backpropagation through such networks performs dictionary\nlearning. This paper offers the first theoretical proof for these empirical\nresults through PUDLE, a Provable Unfolded Dictionary LEarning method. We\nhighlight the impact of loss, unfolding, and backpropagation on convergence. We\ndiscover an implicit acceleration: as a function of unfolding, the\nbackpropagated gradient converges faster and is more accurate than the gradient\nfrom alternating minimization. We complement our findings through synthetic and\nimage denoising experiments. The findings support the use of accelerated deep\nlearning optimizers and unfolded networks for dictionary learning.",
    "descriptor": "",
    "authors": [
      "Bahareh Tolooshams",
      "Demba Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00058"
  },
  {
    "id": "arXiv:2106.00062",
    "title": "Controllable Gradient Item Retrieval",
    "abstract": "In this paper, we identify and study an important problem of gradient item\nretrieval. We define the problem as retrieving a sequence of items with a\ngradual change on a certain attribute, given a reference item and a\nmodification text. For example, after a customer saw a white dress, she/he\nwants to buy a similar one but more floral on it. The extent of \"more floral\"\nis subjective, thus prompting one floral dress is hard to satisfy the\ncustomer's needs. A better way is to present a sequence of products with\nincreasingly floral attributes based on the white dress, and allow the customer\nto select the most satisfactory one from the sequence. Existing item retrieval\nmethods mainly focus on whether the target items appear at the top of the\nretrieved sequence, but ignore the demand for retrieving a sequence of products\nwith gradual change on a certain attribute. To deal with this problem, we\npropose a weakly-supervised method that can learn a disentangled item\nrepresentation from user-item interaction data and ground the semantic meaning\nof attributes to dimensions of the item representation. Our method takes a\nreference item and a modification as a query. During inference, we start from\nthe reference item and \"walk\" along the direction of the modification in the\nitem representation space to retrieve a sequence of items in a gradient manner.\nWe demonstrate our proposed method can achieve disentanglement through weak\nsupervision. Besides, we empirically show that an item sequence retrieved by\nour method is gradually changed on an indicated attribute and, in the item\nretrieval task, our method outperforms existing approaches on three different\ndatasets.",
    "descriptor": "\nComments: Accepted by The International World Wide Web Conference (WWW), 2021\n",
    "authors": [
      "Haonan Wang",
      "Chang Zhou",
      "Carl Yang",
      "Hongxia Yang",
      "Jingrui He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.00062"
  },
  {
    "id": "arXiv:2106.00063",
    "title": "Living mycelium composites discern weights",
    "abstract": "Fungal construction materials -- substrates colonised by mycelium -- are\ngetting increased recognition as viable ecologically friendly alternatives to\nconventional building materials. A functionality of the constructions made from\nfungal materials would be enriched if blocks with living mycelium, known for\ntheir ability to respond to chemical, optical and tactile stimuli, were\ninserted. We investigate how large blocks of substrates colonised with mycelium\nof \\emph{Ganoderma resinaceum} respond to stimulation with heavy weights. We\nanalyse details of the electrical responses to the stimulation with weights and\nshow that ON and OFF stimuli can be discriminated by the living mycelium\ncomposites and that a habituation to the stimulation occurs.",
    "descriptor": "",
    "authors": [
      "Andrew Adamatzky",
      "Antoni Gandia"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2106.00063"
  },
  {
    "id": "arXiv:2106.00066",
    "title": "Energy and Network Aware Workload Management for Geographically  Distributed Data Centers",
    "abstract": "Cloud service providers are distributing data centers geographically to\nminimize energy costs through intelligent workload distribution. With\nincreasing data volumes in emerging cloud workloads, it is critical to factor\nin the network costs for transferring workloads across data centers. For\ngeo-distributed data centers, many researchers have been exploring strategies\nfor energy cost minimization and intelligent inter-data-center workload\ndistribution separately. However, prior work does not comprehensively and\nsimultaneously consider data center energy costs, data transfer costs, and data\ncenter queueing delay. In this paper, we propose a novel game theory-based\nworkload management framework that takes a holistic approach to the cloud\noperating cost minimization problem by making intelligent scheduling decisions\naware of data transfer costs and the data center queueing delay. Our framework\nperforms intelligent workload management that considers heterogeneity in data\ncenter compute capability, cooling power, interference effects from task\nco-location in servers, time-of-use electricity pricing, renewable energy, net\nmetering, peak demand pricing distribution, and network pricing. Our\nsimulations show that the proposed game-theoretic technique can minimize the\ncloud operating cost more effectively than existing approaches.",
    "descriptor": "",
    "authors": [
      "Ninad Hogade",
      "Sudeep Pasricha",
      "Howard Jay Siegel"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.00066"
  },
  {
    "id": "arXiv:2106.00073",
    "title": "GRAVITAS: Graphical Reticulated Attack Vectors for Internet-of-Things  Aggregate Security",
    "abstract": "Internet-of-Things (IoT) and cyber-physical systems (CPSs) may consist of\nthousands of devices connected in a complex network topology. The diversity and\ncomplexity of these components present an enormous attack surface, allowing an\nadversary to exploit security vulnerabilities of different devices to execute a\npotent attack. Though significant efforts have been made to improve the\nsecurity of individual devices in these systems, little attention has been paid\nto security at the aggregate level. In this article, we describe a\ncomprehensive risk management system, called GRAVITAS, for IoT/CPS that can\nidentify undiscovered attack vectors and optimize the placement of defenses\nwithin the system for optimal performance and cost. While existing risk\nmanagement systems consider only known attacks, our model employs a machine\nlearning approach to extrapolate undiscovered exploits, enabling us to identify\nattacks overlooked by manual penetration testing (pen-testing). The model is\nflexible enough to analyze practically any IoT/CPS and provide the system\nadministrator with a concrete list of suggested defenses that can reduce system\nvulnerability at optimal cost. GRAVITAS can be employed by governments,\ncompanies, and system administrators to design secure IoT/CPS at scale,\nproviding a quantitative measure of security and efficiency in a world where\nIoT/CPS devices will soon be ubiquitous.",
    "descriptor": "\nComments: This article has been published in IEEE Transactions on Emerging Topics in Computing, 2021\n",
    "authors": [
      "Jacob Brown",
      "Tanujay Saha",
      "Niraj K. Jha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.00073"
  },
  {
    "id": "arXiv:2106.00076",
    "title": "Closer Look at the Uncertainty Estimation in Semantic Segmentation under  Distributional Shift",
    "abstract": "While recent computer vision algorithms achieve impressive performance on\nmany benchmarks, they lack robustness - presented with an image from a\ndifferent distribution, (e.g. weather or lighting conditions not considered\nduring training), they may produce an erroneous prediction. Therefore, it is\ndesired that such a model will be able to reliably predict its confidence\nmeasure. In this work, uncertainty estimation for the task of semantic\nsegmentation is evaluated under a varying level of domain shift: in a\ncross-dataset setting and when adapting a model trained on data from the\nsimulation. It was shown that simple color transformations already provide a\nstrong baseline, comparable to using more sophisticated style-transfer data\naugmentation. Further, by constructing an ensemble consisting of models using\ndifferent backbones and/or augmentation methods, it was possible to improve\nsignificantly model performance in terms of overall accuracy and uncertainty\nestimation under the domain shift setting. The Expected Calibration Error (ECE)\non challenging GTA to Cityscapes adaptation was reduced from 4.05 to the\ncompetitive value of 1.1. Further, an ensemble of models was utilized in the\nself-training setting to improve the pseudo-labels generation, which resulted\nin a significant gain in the final model accuracy, compared to the standard\nfine-tuning (without ensemble).",
    "descriptor": "\nComments: International Joint Conference on Neural Networks 2021\n",
    "authors": [
      "Sebastian Cygert",
      "Bart\u0142omiej Wr\u00f3blewski",
      "Karol Wo\u017aniak",
      "Rados\u0142aw S\u0142owi\u0144ski",
      "Andrzej Czy\u017cewski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00076"
  },
  {
    "id": "arXiv:2106.00077",
    "title": "Automating Visualization Quality Assessment: a Case Study in Higher  Education",
    "abstract": "We present a case study in the use of machine+human mixed intelligence for\nvisualization quality assessment, applying automated visualization quality\nmetrics to support the human assessment of data visualizations produced as\ncoursework by students taking higher education courses. A set of image\ninformatics algorithms including edge congestion, visual saliency and colour\nanalysis generate machine analysis of student visualizations. The insight from\nthe image informatics outputs has proved helpful for the marker in assessing\nthe work and is also provided to the students as part of a written report on\ntheir work. Student and external reviewer comments suggest that the addition of\nthe image informatics outputs to the standard feedback document was a positive\nstep. We review the ethical challenges of working with assessment data and of\nautomating assessment processes.",
    "descriptor": "",
    "authors": [
      "Nicolas Steven Holliman"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00077"
  },
  {
    "id": "arXiv:2106.00083",
    "title": "Composing Networks of Automated Market Makers",
    "abstract": "Automated market makers (AMMs) are automata that trade electronic assets at\nrates set by mathematical formulas. AMMs are usually implemented by smart\ncontracts on blockchains. In practice, AMMs are often composed: and outputs\nfrom AMMs can be directed into other compatible AMMs. This paper proposes a\nmathematical model for AMM composition. We define sequential and parallel\ncomposition operators for AMMs in a way that ensures that AMMs are closed under\ncomposition, in a way that works for \"higher-dimensional\" AMMs that manage more\nthan two asset classes, and so the composition of AMMs in \"stable\" states\nremains stable.",
    "descriptor": "",
    "authors": [
      "Daniel Engel",
      "Maurice Herlihy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.00083"
  },
  {
    "id": "arXiv:2106.00085",
    "title": "Language Model Evaluation Beyond Perplexity",
    "abstract": "We propose an alternate approach to quantifying how well language models\nlearn natural language: we ask how well they match the statistical tendencies\nof natural language. To answer this question, we analyze whether text generated\nfrom language models exhibits the statistical tendencies present in the\nhuman-generated text on which they were trained. We provide a framework--paired\nwith significance tests--for evaluating the fit of language models to certain\nstatistical tendencies of natural language. We find that neural language models\nappear to learn only a subset of the statistical tendencies considered, but\nalign much more closely with empirical trends than theoretical laws (when\npresent). Further, the fit to different distributions is dependent on both\nmodel architecture and generation strategy. As concrete examples, text\ngenerated under the nucleus sampling scheme adheres more closely to the\ntype--token relationship of natural language than text produced using standard\nancestral sampling; text from LSTMs reflects the natural language distributions\nover length, stopwords, and symbols suprisingly well.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Clara Meister",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00085"
  },
  {
    "id": "arXiv:2106.00089",
    "title": "Node-Variant Graph Filters in Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) have been successfully employed in a myriad of\napplications involving graph-structured data. Theoretical findings establish\nthat GNNs use nonlinear activation functions to create low-eigenvalue frequency\ncontent that can be processed in a stable manner by subsequent graph\nconvolutional filters. However, the exact shape of the frequency content\ncreated by nonlinear functions is not known, and thus, it cannot be learned nor\ncontrolled. In this work, node-variant graph filters (NVGFs) are shown to be\ncapable of creating frequency content and are thus used in lieu of nonlinear\nactivation functions. This results in a novel GNN architecture that, although\nlinear, is capable of creating frequency content as well. Furthermore, this new\nfrequency content can be either designed or learned from data. In this way, the\nrole of frequency creation is separated from the nonlinear nature of\ntraditional GNNs. Extensive simulations are carried out to differentiate the\ncontributions of frequency creation from those of the nonlinearity.",
    "descriptor": "",
    "authors": [
      "Fernando Gama",
      "Brendon G. Anderson",
      "Somayeh Sojoudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00089"
  },
  {
    "id": "arXiv:2106.00090",
    "title": "Deep learning for prediction of hepatocellular carcinoma recurrence  after resection or liver transplantation: a discovery and validation study",
    "abstract": "This study aimed to develop a classifier of prognosis after resection or\nliver transplantation (LT) for HCC by directly analysing the ubiquitously\navailable histological images using deep learning based neural networks.\nNucleus map set was used to train U-net to capture the nuclear architectural\ninformation. Train set included the patients with HCC treated by resection and\nhas a distinct outcome. LT set contained patients with HCC treated by LT. Train\nset and its nuclear architectural information extracted by U-net were used to\ntrain MobileNet V2 based classifier (MobileNetV2_HCC_Class), purpose-built for\nclassifying supersized heterogeneous images. The MobileNetV2_HCC_Class\nmaintained relative higher discriminatory power than the other factors after\nHCC resection or LT in the independent validation set. Pathological review\nshowed that the tumoral areas most predictive of recurrence were characterized\nby presence of stroma, high degree of cytological atypia, nuclear\nhyperchomasia, and a lack of immune infiltration. A clinically useful\nprognostic classifier was developed using deep learning allied to histological\nslides. The classifier has been extensively evaluated in independent patient\npopulations with different treatment, and gives consistent excellent results\nacross the classical clinical, biological and pathological features. The\nclassifier assists in refining the prognostic prediction of HCC patients and\nidentifying patients who would benefit from more intensive management.",
    "descriptor": "",
    "authors": [
      "Zhikun Liu",
      "Yuanpeng Liu",
      "Yuan Hong",
      "Jinwen Meng",
      "Jianguo Wang",
      "Shusen Zheng",
      "Xiao Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00090"
  },
  {
    "id": "arXiv:2106.00091",
    "title": "Optimal Algorithms for Multiwinner Elections and the Chamberlin-Courant  Rule",
    "abstract": "We consider the algorithmic question of choosing a subset of candidates of a\ngiven size $k$ from a set of $m$ candidates, with knowledge of voters' ordinal\nrankings over all candidates. We consider the well-known and classic scoring\nrule for achieving diverse representation: the Chamberlin-Courant (CC) or\n$1$-Borda rule, where the score of a committee is the average over the voters,\nof the rank of the best candidate in the committee for that voter; and its\ngeneralization to the average of the top $s$ best candidates, called the\n$s$-Borda rule.\nOur first result is an improved analysis of the natural and well-studied\ngreedy heuristic. We show that greedy achieves a $\\left(1 -\n\\frac{2}{k+1}\\right)$-approximation to the maximization (or satisfaction)\nversion of CC rule, and a $\\left(1 - \\frac{2s}{k+1}\\right)$-approximation to\nthe $s$-Borda score. Our result improves on the best known approximation\nalgorithm for this problem. We show that these bounds are almost tight.\nFor the dissatisfaction (or minimization) version of the problem, we show\nthat the score of $\\frac{m+1}{k+1}$ can be viewed as an optimal benchmark for\nthe CC rule, as it is essentially the best achievable score of any\npolynomial-time algorithm even when the optimal score is a polynomial factor\nsmaller (under standard computational complexity assumptions). We show that\nanother well-studied algorithm for this problem, called the Banzhaf rule,\nattains this benchmark.\nWe finally show that for the $s$-Borda rule, when the optimal value is small,\nthese algorithms can be improved by a factor of $\\tilde \\Omega(\\sqrt{s})$ via\nLP rounding. Our upper and lower bounds are a significant improvement over\nprevious results, and taken together, not only enable us to perform a finer\ncomparison of greedy algorithms for these problems, but also provide analytic\njustification for using such algorithms in practice.",
    "descriptor": "\nComments: Accepted by the Twenty-Second ACM Conference on Economics and Computation (EC 2021)\n",
    "authors": [
      "Kamesh Munagala",
      "Zeyu Shen",
      "Kangning Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2106.00091"
  },
  {
    "id": "arXiv:2106.00092",
    "title": "Generalized AdaGrad (G-AdaGrad) and Adam: A State-Space Perspective",
    "abstract": "Accelerated gradient-based methods are being extensively used for solving\nnon-convex machine learning problems, especially when the data points are\nabundant or the available data is distributed across several agents. Two of the\nprominent accelerated gradient algorithms are AdaGrad and Adam. AdaGrad is the\nsimplest accelerated gradient method, which is particularly effective for\nsparse data. Adam has been shown to perform favorably in deep learning problems\ncompared to other methods. In this paper, we propose a new fast optimizer,\nGeneralized AdaGrad (G-AdaGrad), for accelerating the solution of potentially\nnon-convex machine learning problems. Specifically, we adopt a state-space\nperspective for analyzing the convergence of gradient acceleration algorithms,\nnamely G-AdaGrad and Adam, in machine learning. Our proposed state-space models\nare governed by ordinary differential equations. We present simple convergence\nproofs of these two algorithms in the deterministic settings with minimal\nassumptions. Our analysis also provides intuition behind improving upon\nAdaGrad's convergence rate. We provide empirical results on MNIST dataset to\nreinforce our claims on the convergence and performance of G-AdaGrad and Adam.",
    "descriptor": "",
    "authors": [
      "Kushal Chakrabarti",
      "Nikhil Chopra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00092"
  },
  {
    "id": "arXiv:2106.00093",
    "title": "Approximate polymorphisms",
    "abstract": "For a function $g\\colon\\{0,1\\}^m\\to\\{0,1\\}$, a function $f\\colon\n\\{0,1\\}^n\\to\\{0,1\\}$ is called a $g$-polymorphism if their actions commute:\n$f(g(\\mathsf{row}_1(Z)),\\ldots,g(\\mathsf{row}_n(Z))) =\ng(f(\\mathsf{col}_1(Z)),\\ldots,f(\\mathsf{col}_m(Z)))$ for all\n$Z\\in\\{0,1\\}^{n\\times m}$. The function $f$ is called an approximate\npolymorphism if this equality holds with probability close to $1$, when $Z$ is\nsampled uniformly.\nWe study the structure of exact polymorphisms as well as approximate\npolymorphisms. Our results include:\n- We prove that an approximate polymorphism $f$ must be close to an exact\npolymorphism;\n- We give a characterization of exact polymorphisms, showing that besides\ntrivial cases, only the functions $g = \\mathsf{AND}, \\mathsf{XOR}, \\mathsf{OR},\n\\mathsf{NXOR}$ admit non-trivial exact polymorphisms.\nWe also study the approximate polymorphism problem in the list-decoding\nregime (i.e., when the probability equality holds is not close to $1$, but is\nbounded away from some value) and obtain partial results.\nOur result generalize the classical linearity testing result of Blum, Luby\nand Rubinfeld, that in this language showed that the approximate polymorphisms\nof $g = \\mathsf{XOR}$ are close to XOR's, as well as a recent result of Filmus,\nLifshitz, Minzer and Mossel, showing that the approximate polymorphisms of AND\ncan only be close to AND functions.",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "Gilad Chase",
      "Yuval Filmus",
      "Dor Minzer",
      "Nitin Saurabh"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.00093"
  },
  {
    "id": "arXiv:2106.00099",
    "title": "Multi-Objective SPIBB: Seldonian Offline Policy Improvement with Safety  Constraints in Finite MDPs",
    "abstract": "We study the problem of Safe Policy Improvement (SPI) under constraints in\nthe offline Reinforcement Learning (RL) setting. We consider the scenario\nwhere: (i) we have a dataset collected under a known baseline policy, (ii)\nmultiple reward signals are received from the environment inducing as many\nobjectives to optimize. We present an SPI formulation for this RL setting that\ntakes into account the preferences of the algorithm's user for handling the\ntrade-offs for different reward signals while ensuring that the new policy\nperforms at least as well as the baseline policy along each individual\nobjective. We build on traditional SPI algorithms and propose a novel method\nbased on Safe Policy Iteration with Baseline Bootstrapping (SPIBB, Laroche et\nal., 2019) that provides high probability guarantees on the performance of the\nagent in the true environment. We show the effectiveness of our method on a\nsynthetic grid-world safety task as well as in a real-world critical care\ncontext to learn a policy for the administration of IV fluids and vasopressors\nto treat sepsis.",
    "descriptor": "",
    "authors": [
      "Harsh Satija",
      "Philip S. Thomas",
      "Joelle Pineau",
      "Romain Laroche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00099"
  },
  {
    "id": "arXiv:2106.00102",
    "title": "The Cold-start Problem: Minimal Users' Activity Estimation",
    "abstract": "Cold-start problem, which arises upon the new users arrival, is one of the\nfundamental problems in today's recommender approaches. Moreover, in some\ndomains as TV or multime-dia-items take long time to experience by users, thus\nusers usually do not provide rich preference information. In this paper we\nanalyze the minimal amount of ratings needs to be done by a user over a set of\nitems, in order to solve or reduce the cold-start problem. In our analysis we\napplied clustering data mining technique in order to identify minimal amount of\nitem's ratings required from recommender system's users, in order to be\nassigned to a correct cluster. In this context, cluster quality is being\nmonitored and in case of reaching certain cluster quality threshold, the\nrec-ommender system could start to generate recommendations for given user, as\nin this point cold-start problem is considered as resolved. Our proposed\napproach is applicable to any domain in which user preferences are received\nbased on explicit items rating. Our experiments are performed within the movie\nand jokes recommendation domain using the MovieLens and Jester dataset.",
    "descriptor": "\nComments: 1st Workshop on Recommender Systems for Television and online Video (RecSysTV) in conjunction with 8th ACM Conference on Recommender Systems, 2014\n",
    "authors": [
      "Juraj Visnovsky",
      "Ondrej Kassak",
      "Michal Kompan",
      "Maria Bielikova"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.00102"
  },
  {
    "id": "arXiv:2106.00104",
    "title": "Text Summarization with Latent Queries",
    "abstract": "The availability of large-scale datasets has driven the development of neural\nmodels that create summaries from single documents, for generic purposes. When\nusing a summarization system, users often have specific intents with various\nlanguage realizations, which, depending on the information need, can range from\na single keyword to a long narrative composed of multiple questions. Existing\nsummarization systems, however, often either fail to support or act robustly on\nthis query focused summarization task. We introduce LaQSum, the first unified\ntext summarization system that learns Latent Queries from documents for\nabstractive summarization with any existing query forms. Under a deep\ngenerative framework, our system jointly optimizes a latent query model and a\nconditional language model, allowing users to plug-and-play queries of any type\nat test time. Despite learning from only generic summarization data and\nrequiring no further optimization for downstream summarization tasks, our\nsystem robustly outperforms strong comparison systems across summarization\nbenchmarks with different query types, document settings, and target domains.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Yumo Xu",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00104"
  },
  {
    "id": "arXiv:2106.00107",
    "title": "3D map creation using crowdsourced GNSS data",
    "abstract": "3D maps are increasingly useful for many applications such as drone\nnavigation, emergency services, and urban planning. However, creating 3D maps\nand keeping them up-to-date using existing technologies, such as laser\nscanners, is expensive. This paper proposes and implements a novel approach to\ngenerate 2.5D (otherwise known as 3D level-of-detail (LOD) 1) maps for free\nusing Global Navigation Satellite Systems (GNSS) signals, which are globally\navailable and are blocked only by obstacles between the satellites and the\nreceivers. This enables us to find the patterns of GNSS signal availability and\ncreate 3D maps. The paper applies algorithms to GNSS signal strength patterns\nbased on a boot-strapped technique that iteratively trains the signal\nclassifiers while generating the map. Results of the proposed technique\ndemonstrate the ability to create 3D maps using automatically processed GNSS\ndata. The results show that the third dimension, i.e. height of the buildings,\ncan be estimated with below 5 metre accuracy, which is the benchmark\nrecommended by the CityGML standard.",
    "descriptor": "\nComments: 25 pages with 11 figures\n",
    "authors": [
      "Terence Lines",
      "Ana Basiri"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00107"
  },
  {
    "id": "arXiv:2106.00109",
    "title": "Equilibrium Computation of Generalized Nash Games: A New  Lagrangian-Based Approach",
    "abstract": "This paper presents a new primal-dual method for computing an equilibrium of\ngeneralized (continuous) Nash game (referred to as generalized Nash equilibrium\nproblem (GNEP)) where each player's feasible strategy set depends on the other\nplayers' strategies. The method is based on a new form of Lagrangian function\nwith a quadratic approximation. First, we reformulate a GNEP as a saddle point\ncomputation using the new Lagrangian and establish equivalence between a saddle\npoint of the Lagrangian and an equilibrium of the GNEP. We then propose a\nsimple algorithm that is convergent to the saddle point. Furthermore, we\nestablish global convergence by assuming that the Lagrangian function satisfies\nthe Kurdyka-{\\L}ojasiewicz property. A distinctive feature of our analysis is\nto make use of the new Lagrangian as a potential function to guide the iterate\nconvergence, which is based on the idea of turning a descent method into a\nmultiplier method. Our method has two novel features over existing approaches:\n(i) it requires neither boundedness assumptions on the strategy set and the set\nof multipliers of each player, nor any boundedness assumptions on the iterates\ngenerated by the algorithm; (ii) it leads to a Jacobi-type decomposition\nscheme, which, to the best of our knowledge, is the first development of a\ndistributed algorithm to solve a general class of GNEPs. Numerical experiments\nare performed on benchmark test problems and the results demonstrate the\neffectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Jong Gwang Kim"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00109"
  },
  {
    "id": "arXiv:2106.00110",
    "title": "Towards Explainable Convolutional Features for Music Audio Modeling",
    "abstract": "Audio signals are often represented as spectrograms and treated as 2D images.\nIn this light, deep convolutional architectures are widely used for music audio\ntasks even though these two data types have very different structures. In this\nwork, we attempt to \"open the black-box\" on deep convolutional models to inform\nfuture architectures for music audio tasks, and explain the excellent\nperformance of deep convolutions that model spectrograms as 2D images. To this\nend, we expand recent explainability discussions in deep learning for natural\nimage data to music audio data through systematic experiments using the deep\nfeatures learned by various convolutional architectures. We demonstrate that\ndeep convolutional features perform well across various target tasks, whether\nor not they are extracted from deep architectures originally trained on that\ntask. Additionally, deep features exhibit high similarity to hand-crafted\nwavelet features, whether the deep features are extracted from a trained or\nuntrained model.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Anna K. Yanchenko",
      "Mohammadreza Soltani",
      "Robert J. Ravier",
      "Sayan Mukherjee",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00110"
  },
  {
    "id": "arXiv:2106.00115",
    "title": "Fine-grained Generalization Analysis of Structured Output Prediction",
    "abstract": "In machine learning we often encounter structured output prediction problems\n(SOPPs), i.e. problems where the output space admits a rich internal structure.\nApplication domains where SOPPs naturally occur include natural language\nprocessing, speech recognition, and computer vision. Typical SOPPs have an\nextremely large label set, which grows exponentially as a function of the size\nof the output. Existing generalization analysis implies generalization bounds\nwith at least a square-root dependency on the cardinality $d$ of the label set,\nwhich can be vacuous in practice. In this paper, we significantly improve the\nstate of the art by developing novel high-probability bounds with a logarithmic\ndependency on $d$. Moreover, we leverage the lens of algorithmic stability to\ndevelop generalization bounds in expectation without any dependency on $d$. Our\nresults therefore build a solid theoretical foundation for learning in\nlarge-scale SOPPs. Furthermore, we extend our results to learning with weakly\ndependent data.",
    "descriptor": "\nComments: To appearn in IJCAI 2021\n",
    "authors": [
      "Waleed Mustafa",
      "Yunwen Lei",
      "Antoine Ledent",
      "Marius Kloft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00115"
  },
  {
    "id": "arXiv:2106.00116",
    "title": "Effect of large-scale pre-training on full and few-shot transfer  learning for natural and medical images",
    "abstract": "Transfer learning aims to exploit pre-trained models for more efficient\nfollow-up training on wide range of downstream tasks and datasets, enabling\nsuccessful training also on small data. Recent line of work posits strong\nbenefits for model generalization and transfer when model size, data size, and\ncompute budget are increased for the pre-training. It remains however still\nlargely unclear whether the observed transfer improvement due to increase in\nscale also holds when source and target data distributions are far apart from\neach other. In this work we conduct large-scale pre-training on large source\ndatasets of either natural (ImageNet-21k/1k) or medical chest X-Ray images and\ncompare full and few-shot transfer using different target datasets from both\nnatural and medical imaging domains. Our observations provide evidence that\nwhile pre-training and transfer on closely related datasets do show clear\nbenefit of increasing model and data size during pre-training, such benefits\nare not clearly visible when source and target datasets are further apart.\nThese observations hold across both full and few-shot transfer and indicate\nthat scaling laws hinting improvement of generalization and transfer with\nincreasing model and data size are incomplete and should also take into account\nthe degree of how distinct the source and target data distributions are, to\ncorrectly predict effect of model size and data size variation during\npre-training on transfer. (Repository for reproducing the experiments will be\nmade available.)",
    "descriptor": "\nComments: Preprint. Under review\n",
    "authors": [
      "Mehdi Cherti",
      "Jenia Jitsev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00116"
  },
  {
    "id": "arXiv:2106.00120",
    "title": "Probabilistic Deep Learning with Probabilistic Neural Networks and Deep  Probabilistic Models",
    "abstract": "Probabilistic deep learning is deep learning that accounts for uncertainty,\nboth model uncertainty and data uncertainty. It is based on the use of\nprobabilistic models and deep neural networks. We distinguish two approaches to\nprobabilistic deep learning: probabilistic neural networks and deep\nprobabilistic models. The former employs deep neural networks that utilize\nprobabilistic layers which can represent and process uncertainty; the latter\nuses probabilistic models that incorporate deep neural network components which\ncapture complex non-linear stochastic relationships between the random\nvariables. We discuss some major examples of each approach including Bayesian\nneural networks and mixed density networks (for probabilistic neural networks),\nand variational autoencoders, deep Gaussian processes and deep mixed effects\nmodels (for deep probabilistic models). TensorFlow Probability is a library for\nprobabilistic modeling and inference which can be used for both approaches of\nprobabilistic deep learning. We include its code examples for illustration.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1811.06622\n",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00120"
  },
  {
    "id": "arXiv:2106.00122",
    "title": "Suppressing the endemic equilibrium in SIS epidemics: A state dependent  approach",
    "abstract": "This paper considers the susceptible-infected-susceptible (SIS) epidemic\nmodel with an underlying network structure among subpopulations and focuses on\nthe effect of social distancing to regulate the epidemic level. We demonstrate\nthat if each subpopulation is informed of its infection rate and reduces\ninteractions accordingly, the fraction of the subpopulation infected can remain\nbelow half for all time instants. To this end, we first modify the basic SIS\nmodel by introducing a state dependent parameter representing the frequency of\ninteractions between subpopulations. Thereafter, we show that for this modified\nSIS model, the spectral radius of a suitably-defined matrix being not greater\nthan one causes all the agents, regardless of their initial sickness levels, to\nconverge to the healthy state; assuming non-trivial disease spread, the\nspectral radius being greater than one leads to the existence of a unique\nendemic equilibrium, which is also asymptotically stable. Finally, by\nleveraging the aforementioned results, we show that the fraction of\n(sub)populations infected never exceeds half.",
    "descriptor": "",
    "authors": [
      "Yuan Wang",
      "Sebin Gracy",
      "Hideaki Ishii",
      "Karl Henrik Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00122"
  },
  {
    "id": "arXiv:2106.00123",
    "title": "Deep Reinforcement Learning in Quantitative Algorithmic Trading: A  Review",
    "abstract": "Algorithmic stock trading has become a staple in today's financial market,\nthe majority of trades being now fully automated. Deep Reinforcement Learning\n(DRL) agents proved to be to a force to be reckon with in many complex games\nlike Chess and Go. We can look at the stock market historical price series and\nmovements as a complex imperfect information environment in which we try to\nmaximize return - profit and minimize risk. This paper reviews the progress\nmade so far with deep reinforcement learning in the subdomain of AI in finance,\nmore precisely, automated low-frequency quantitative stock trading. Many of the\nreviewed studies had only proof-of-concept ideals with experiments conducted in\nunrealistic settings and no real-time trading applications. For the majority of\nthe works, despite all showing statistically significant improvements in\nperformance compared to established baseline strategies, no decent\nprofitability level was obtained. Furthermore, there is a lack of experimental\ntesting in real-time, online trading platforms and a lack of meaningful\ncomparisons between agents built on different types of DRL or human traders. We\nconclude that DRL in stock trading has showed huge applicability potential\nrivalling professional traders under strong assumptions, but the research is\nstill in the very early stages of development.",
    "descriptor": "",
    "authors": [
      "Tidor-Vlad Pricope"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2106.00123"
  },
  {
    "id": "arXiv:2106.00124",
    "title": "Multidimensional Included and Excluded Sums",
    "abstract": "This paper presents algorithms for the included-sums and excluded-sums\nproblems used by scientific computing applications such as the fast multipole\nmethod. These problems are defined in terms of a $d$-dimensional array of $N$\nelements and a binary associative operator~$\\oplus$ on the elements. The\nincluded-sum problem requires that the elements within overlapping boxes\ncornered at each element within the array be reduced using $\\oplus$. The\nexcluded-sum problem reduces the elements outside each box. The weak versions\nof these problems assume that the operator $\\oplus$ has an inverse $\\ominus$,\nwhereas the strong versions do not require this assumption. In addition to\nstudying existing algorithms to solve these problems, we introduce three new\nalgorithms.\nThe bidirectional box-sum (BDBS) algorithm solves the strong included-sums\nproblem in $\\Theta(d N)$ time, asymptotically beating the classical summed-area\ntable (SAT) algorithm, which runs in $\\Theta(2^d N)$ and which only solves the\nweak version of the problem. Empirically, the BDBS algorithm outperforms the\nSAT algorithm in higher dimensions by up to $17.1\\times$.\nThe \\defn{box-complement} algorithm can solve the strong excluded-sums\nproblem in $\\Theta(d N)$ time, asymptotically beating the state-of-the-art\ncorners algorithm by Demaine et al., which runs in $\\Omega(2^d N)$ time. In 3\ndimensions the box-complement algorithm empirically outperforms the corners\nalgorithm by about $1.4\\times$ given similar amounts of space.\nThe weak excluded-sums problem can be solved in $\\Theta(d N)$ time by the\nbidirectional box-sum complement (BDBSC) algorithm, which is a trivial\nextension of the BDBS algorithm. Given an operator inverse $\\ominus$, BDBSC can\nbeat box-complement by up to a factor of $4$.",
    "descriptor": "\nComments: 18 pages, short version to appear in ACDA 2021\n",
    "authors": [
      "Helen Xu",
      "Sean Fraser",
      "Charles E. Leiserson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00124"
  },
  {
    "id": "arXiv:2106.00127",
    "title": "Integer-Only Neural Network Quantization Scheme Based on  Shift-Batch-Normalization",
    "abstract": "Neural networks are very popular in many areas, but great computing\ncomplexity makes it hard to run neural networks on devices with limited\nresources. To address this problem, quantization methods are used to reduce\nmodel size and computation cost, making it possible to use neural networks on\nembedded platforms or mobile devices.\nIn this paper, an integer-only-quantization scheme is introduced. This scheme\nuses one layer that combines shift-based batch normalization and uniform\nquantization to implement 4-bit integer-only inference. Without big integer\nmultiplication(which is used in previous integer-only-quantization methods),\nthis scheme can achieve good power and latency efficiency, and is especially\nsuitable to be deployed on co-designed hardware platforms. Tests have proved\nthat this scheme works very well for easy tasks. And for tough tasks,\nperformance loss can be tolerated for its inference efficiency. Our work is\navailable on github: https://github.com/hguq/IntegerNet.",
    "descriptor": "",
    "authors": [
      "Qingyu Guo",
      "Yuan Wang",
      "Xiaoxin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00127"
  },
  {
    "id": "arXiv:2106.00130",
    "title": "Bringing Structure into Summaries: a Faceted Summarization Dataset for  Long Scientific Documents",
    "abstract": "Faceted summarization provides briefings of a document from different\nperspectives. Readers can quickly comprehend the main points of a long document\nwith the help of a structured outline. However, little research has been\nconducted on this subject, partially due to the lack of large-scale faceted\nsummarization datasets. In this study, we present FacetSum, a faceted\nsummarization benchmark built on Emerald journal articles, covering a diverse\nrange of domains. Different from traditional document-summary pairs, FacetSum\nprovides multiple summaries, each targeted at specific sections of a long\ndocument, including the purpose, method, findings, and value. Analyses and\nempirical results on our dataset reveal the importance of bringing structure\ninto summaries. We believe FacetSum will spur further advances in summarization\nresearch and foster the development of NLP systems that can leverage the\nstructured information in both long texts and summaries.",
    "descriptor": "\nComments: Accepted at ACL2021\n",
    "authors": [
      "Rui Meng",
      "Khushboo Thaker",
      "Lei Zhang",
      "Yue Dong",
      "Xingdi Yuan",
      "Tong Wang",
      "Daqing He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00130"
  },
  {
    "id": "arXiv:2106.00131",
    "title": "Clustering-friendly Representation Learning via Instance Discrimination  and Feature Decorrelation",
    "abstract": "Clustering is one of the most fundamental tasks in machine learning.\nRecently, deep clustering has become a major trend in clustering techniques.\nRepresentation learning often plays an important role in the effectiveness of\ndeep clustering, and thus can be a principal cause of performance degradation.\nIn this paper, we propose a clustering-friendly representation learning method\nusing instance discrimination and feature decorrelation. Our\ndeep-learning-based representation learning method is motivated by the\nproperties of classical spectral clustering. Instance discrimination learns\nsimilarities among data and feature decorrelation removes redundant correlation\namong features. We utilize an instance discrimination method in which learning\nindividual instance classes leads to learning similarity among instances.\nThrough detailed experiments and examination, we show that the approach can be\nadapted to learning a latent space for clustering. We design novel\nsoftmax-formulated decorrelation constraints for learning. In evaluations of\nimage clustering using CIFAR-10 and ImageNet-10, our method achieves accuracy\nof 81.5% and 95.4%, respectively. We also show that the softmax-formulated\nconstraints are compatible with various neural networks.",
    "descriptor": "\nComments: 15 pages, ICLR2021\n",
    "authors": [
      "Yaling Tao",
      "Kentaro Takagi",
      "Kouta Nakata"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00131"
  },
  {
    "id": "arXiv:2106.00132",
    "title": "On Fast Sampling of Diffusion Probabilistic Models",
    "abstract": "In this work, we propose FastDPM, a unified framework for fast sampling in\ndiffusion probabilistic models. FastDPM generalizes previous methods and gives\nrise to new algorithms with improved sample quality. We systematically\ninvestigate the fast sampling methods under this framework across different\ndomains, on different datasets, and with different amount of conditional\ninformation provided for generation. We find the performance of a particular\nmethod depends on data domains (e.g., image or audio), the trade-off between\nsampling speed and sample quality, and the amount of conditional information.\nWe further provide insights and recipes on the choice of methods for\npractitioners.",
    "descriptor": "",
    "authors": [
      "Zhifeng Kong",
      "Wei Ping"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00132"
  },
  {
    "id": "arXiv:2106.00133",
    "title": "AppBuddy: Learning to Accomplish Tasks in Mobile Apps via Reinforcement  Learning",
    "abstract": "Human beings, even small children, quickly become adept at figuring out how\nto use applications on their mobile devices. Learning to use a new app is often\nachieved via trial-and-error, accelerated by transfer of knowledge from past\nexperiences with like apps. The prospect of building a smarter smartphone - one\nthat can learn how to achieve tasks using mobile apps - is tantalizing. In this\npaper we explore the use of Reinforcement Learning (RL) with the goal of\nadvancing this aspiration. We introduce an RL-based framework for learning to\naccomplish tasks in mobile apps. RL agents are provided with states derived\nfrom the underlying representation of on-screen elements, and rewards that are\nbased on progress made in the task. Agents can interact with screen elements by\ntapping or typing. Our experimental results, over a number of mobile apps, show\nthat RL agents can learn to accomplish multi-step tasks, as well as achieve\nmodest generalization across different apps. More generally, we develop a\nplatform which addresses several engineering challenges to enable an effective\nRL training environment. Our AppBuddy platform is compatible with OpenAI Gym\nand includes a suite of mobile apps and benchmark tasks that supports a\ndiversity of RL research in the mobile app setting.",
    "descriptor": "",
    "authors": [
      "Maayan Shvo",
      "Zhiming Hu",
      "Rodrigo Toro Icarte",
      "Iqbal Mohomed",
      "Allan Jepson",
      "Sheila A. McIlraith"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00133"
  },
  {
    "id": "arXiv:2106.00134",
    "title": "GANs Can Play Lottery Tickets Too",
    "abstract": "Deep generative adversarial networks (GANs) have gained growing popularity in\nnumerous scenarios, while usually suffer from high parameter complexities for\nresource-constrained real-world applications. However, the compression of GANs\nhas less been explored. A few works show that heuristically applying\ncompression techniques normally leads to unsatisfactory results, due to the\nnotorious training instability of GANs. In parallel, the lottery ticket\nhypothesis shows prevailing success on discriminative models, in locating\nsparse matching subnetworks capable of training in isolation to full model\nperformance. In this work, we for the first time study the existence of such\ntrainable matching subnetworks in deep GANs. For a range of GANs, we certainly\nfind matching subnetworks at 67%-74% sparsity. We observe that with or without\npruning discriminator has a minor effect on the existence and quality of\nmatching subnetworks, while the initialization weights used in the\ndiscriminator play a significant role. We then show the powerful\ntransferability of these subnetworks to unseen tasks. Furthermore, extensive\nexperimental results demonstrate that our found subnetworks substantially\noutperform previous state-of-the-art GAN compression approaches in both image\ngeneration (e.g. SNGAN) and image-to-image translation GANs (e.g. CycleGAN).\nCodes available at https://github.com/VITA-Group/GAN-LTH.",
    "descriptor": "",
    "authors": [
      "Xuxi Chen",
      "Zhenyu Zhang",
      "Yongduo Sui",
      "Tianlong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00134"
  },
  {
    "id": "arXiv:2106.00135",
    "title": "Evaluating the Performance of Distributed Optimal Power Flow Algorithms  with Nonideal Communication",
    "abstract": "Power system operators are increasingly looking toward distributed\noptimization to address various challenges facing electric power systems. To\nassess their capabilities in environments with nonideal communications, this\npaper investigates the impacts of data quality on the performance of\ndistributed optimization algorithms. Specifically, this paper compares the\nperformance of the Alternating Direction Method of Multipliers (ADMM), Analytic\nTarget Cascading (ATC), and Auxiliary Principal Problem (APP) algorithms in the\ncontext of DC Optimal Power Flow (DC OPF) problems. Using several test cases,\nthis paper characterizes the performance of these algorithms in terms of their\nconvergence rates and solution quality under three data quality nonidealities:\n(1) additive Gaussian noise, (2) false data, and (3) intermittent communication\nfailure.",
    "descriptor": "\nComments: 10 pages with 16 figures, the paper is submitted to IEEE Transactions on Smart Grid\n",
    "authors": [
      "Mohannad Alkhraijah",
      "Carlos Menendez",
      "Daniel K. Molzahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00135"
  },
  {
    "id": "arXiv:2106.00136",
    "title": "Tesseract: Tensorised Actors for Multi-Agent Reinforcement Learning",
    "abstract": "Reinforcement Learning in large action spaces is a challenging problem.\nCooperative multi-agent reinforcement learning (MARL) exacerbates matters by\nimposing various constraints on communication and observability. In this work,\nwe consider the fundamental hurdle affecting both value-based and\npolicy-gradient approaches: an exponential blowup of the action space with the\nnumber of agents. For value-based methods, it poses challenges in accurately\nrepresenting the optimal value function. For policy gradient methods, it makes\ntraining the critic difficult and exacerbates the problem of the lagging\ncritic. We show that from a learning theory perspective, both problems can be\naddressed by accurately representing the associated action-value function with\na low-complexity hypothesis class. This requires accurately modelling the agent\ninteractions in a sample efficient way. To this end, we propose a novel\ntensorised formulation of the Bellman equation. This gives rise to our method\nTesseract, which views the Q-function as a tensor whose modes correspond to the\naction spaces of different agents. Algorithms derived from Tesseract decompose\nthe Q-tensor across agents and utilise low-rank tensor approximations to model\nagent interactions relevant to the task. We provide PAC analysis for\nTesseract-based algorithms and highlight their relevance to the class of rich\nobservation MDPs. Empirical results in different domains confirm Tesseract's\ngains in sample efficiency predicted by the theory.",
    "descriptor": "\nComments: 38th International Conference on Machine Learning, PMLR 139, 2021\n",
    "authors": [
      "Anuj Mahajan",
      "Mikayel Samvelyan",
      "Lei Mao",
      "Viktor Makoviychuk",
      "Animesh Garg",
      "Jean Kossaifi",
      "Shimon Whiteson",
      "Yuke Zhu",
      "Animashree Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00136"
  },
  {
    "id": "arXiv:2106.00139",
    "title": "Training ELECTRA Augmented with Multi-word Selection",
    "abstract": "Pre-trained text encoders such as BERT and its variants have recently\nachieved state-of-the-art performances on many NLP tasks. While being\neffective, these pre-training methods typically demand massive computation\nresources. To accelerate pre-training, ELECTRA trains a discriminator that\npredicts whether each input token is replaced by a generator. However, this new\ntask, as a binary classification, is less semantically informative. In this\nstudy, we present a new text encoder pre-training method that improves ELECTRA\nbased on multi-task learning. Specifically, we train the discriminator to\nsimultaneously detect replaced tokens and select original tokens from candidate\nsets. We further develop two techniques to effectively combine all pre-training\ntasks: (1) using attention-based networks for task-specific heads, and (2)\nsharing bottom layers of the generator and the discriminator. Extensive\nexperiments on GLUE and SQuAD datasets demonstrate both the effectiveness and\nthe efficiency of our proposed method.",
    "descriptor": "\nComments: Accepted in Findings of ACL 2021\n",
    "authors": [
      "Jiaming Shen",
      "Jialu Liu",
      "Tianqi Liu",
      "Cong Yu",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00139"
  },
  {
    "id": "arXiv:2106.00141",
    "title": "Proactive Provenance Policies for Automatic Cryptographic Data Centric  Security",
    "abstract": "Data provenance analysis has been used as an assistive measure for ensuring\nsystem integrity. However, such techniques are typically reactive approaches to\nidentify the root cause of an attack in its aftermath. This is in part due to\nfact that the collection of provenance metadata often results in a deluge of\ninformation that cannot easily be queried and analyzed in real time. This paper\npresents an approach for proactively reasoning about provenance metadata within\nthe Automatic Cryptographic Data Centric (ACDC) security architecture, a new\nsecurity infrastructure in which all data interactions are considered at a\ncoarse granularity, similar to the Function as a Service model. At this scale,\nwe have found that data interactions are manageable for the proactive\nspecification and evaluation of provenance policies -- constraints placed on\nprovenance metadata to prevent the consumption of untrusted data. This paper\nprovides a model for proactively evaluating provenance metadata in the ACDC\nparadigm as well as a case study of an electronic voting scheme to demonstrate\nthe applicability of ACDC and the provenance policies needed to ensure data\nintegrity.",
    "descriptor": "",
    "authors": [
      "Shamaria Engram",
      "Tyler Kaczmarek",
      "Alice Lee",
      "David Bigelow"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.00141"
  },
  {
    "id": "arXiv:2106.00142",
    "title": "FBAdTracker: An Interactive Data Collection and Analysis Tool for  Facebook Advertisements",
    "abstract": "The growing use of social media has led to drastic changes in our\ndecision-making. Especially, Facebook offers marketing API which promotes\nbusiness to target potential groups who are likely to consume their items.\nHowever, this service can be abused by malicious advertisers who attempt to\ndeceive people by disinformation such as propaganda and divisive opinion. To\ncounter this problem, we introduce a new application named FBAdTracker. The\npurpose of this application is to provide an integrated data collection and\nanalysis system for current research on fact-checking related to Facebook\nadvertisements. Our system is capable of monitoring up-to-date Facebook ads and\nanalyzing ads retrieved from Facebook Ads Library.",
    "descriptor": "\nComments: 3 pages, 1 figure, 2021 International Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction and Behavior Representation in Modeling and Simulation, demo track\n",
    "authors": [
      "Ujun Jeong",
      "Kaize Ding",
      "Huan Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.00142"
  },
  {
    "id": "arXiv:2106.00143",
    "title": "An Exploratory Analysis of Multilingual Word-Level Quality Estimation  with Cross-Lingual Transformers",
    "abstract": "Most studies on word-level Quality Estimation (QE) of machine translation\nfocus on language-specific models. The obvious disadvantages of these\napproaches are the need for labelled data for each language pair and the high\ncost required to maintain several language-specific models. To overcome these\nproblems, we explore different approaches to multilingual, word-level QE. We\nshow that these QE models perform on par with the current language-specific\nmodels. In the cases of zero-shot and few-shot QE, we demonstrate that it is\npossible to accurately predict word-level quality for any given new language\npair from models trained on other language pairs. Our findings suggest that the\nword-level QE models based on powerful pre-trained transformers that we propose\nin this paper generalise well across languages, making them more useful in\nreal-world scenarios.",
    "descriptor": "\nComments: Accepted to appear at the ACL-IJCNLP 2021 Main conference\n",
    "authors": [
      "Tharindu Ranasinghe",
      "Constantin Orasan",
      "Ruslan Mitkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00143"
  },
  {
    "id": "arXiv:2106.00144",
    "title": "Risk-Aware Dimensioning and Procurement of Contingency Reserve",
    "abstract": "Current contingency reserve criteria ignore the likelihood of individual\ncontingencies and, thus, their impact on system reliability and risk. This\npaper develops an iterative approach, inspired by the current\nsecurity-constrained unit commitment (SCUC) practice, enabling system operators\nto determine risk-cognizant contingency reserve requirements and their\nallocation with minimal alterations to the current SCUC practice. The proposed\napproach uses generator and transmission system reliability models, including\nfailure-to synchronize and adverse conditions, to compute contingency\nprobabilities, which inform a risk-based system reliability assessment, and\nensures reserve deliverability by learning the response of generators to\npost-contingency states within the SCUC. The effectiveness of the proposed\napproach is demonstrated using the Grid Modernization Lab Consortium update of\nthe Reliability Test System.",
    "descriptor": "",
    "authors": [
      "Robert Mieth",
      "Yury Dvorkin",
      "Miguel A. Ortega-Vazquez"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00144"
  },
  {
    "id": "arXiv:2106.00145",
    "title": "Corpus-Based Paraphrase Detection Experiments and Review",
    "abstract": "Paraphrase detection is important for a number of applications, including\nplagiarism detection, authorship attribution, question answering, text\nsummarization, text mining in general, etc. In this paper, we give a\nperformance overview of various types of corpus-based models, especially deep\nlearning (DL) models, with the task of paraphrase detection. We report the\nresults of eight models (LSI, TF-IDF, Word2Vec, Doc2Vec, GloVe, FastText, ELMO,\nand USE) evaluated on three different public available corpora: Microsoft\nResearch Paraphrase Corpus, Clough and Stevenson and Webis Crowd Paraphrase\nCorpus 2011. Through a great number of experiments, we decided on the most\nappropriate approaches for text pre-processing: hyper-parameters, sub-model\nselection-where they exist (e.g., Skipgram vs. CBOW), distance measures, and\nsemantic similarity/paraphrase detection threshold. Our findings and those of\nother researchers who have used deep learning models show that DL models are\nvery competitive with traditional state-of-the-art approaches and have\npotential that should be further developed.",
    "descriptor": "\nComments: 25 pages, 7 figures, 4 tables\n",
    "authors": [
      "Tedo Vrbanec",
      "Ana Mestrovic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00145"
  },
  {
    "id": "arXiv:2106.00149",
    "title": "HiddenCut: Simple Data Augmentation for Natural Language Understanding  with Better Generalization",
    "abstract": "Fine-tuning large pre-trained models with task-specific data has achieved\ngreat success in NLP. However, it has been demonstrated that the majority of\ninformation within the self-attention networks is redundant and not utilized\neffectively during the fine-tuning stage. This leads to inferior results when\ngeneralizing the obtained models to out-of-domain distributions. To this end,\nwe propose a simple yet effective data augmentation technique, HiddenCut, to\nbetter regularize the model and encourage it to learn more generalizable\nfeatures. Specifically, contiguous spans within the hidden space are\ndynamically and strategically dropped during training. Experiments show that\nour HiddenCut method outperforms the state-of-the-art augmentation methods on\nthe GLUE benchmark, and consistently exhibits superior generalization\nperformances on out-of-distribution and challenging counterexamples. We have\npublicly released our code at https://github.com/GT-SALT/HiddenCut.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Jiaao Chen",
      "Dinghan Shen",
      "Weizhu Chen",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00149"
  },
  {
    "id": "arXiv:2106.00150",
    "title": "Single-query Path Planning Using Sample-efficient Probability Informed  Trees",
    "abstract": "In this work, we present a novel sampling-based path planning method, called\nSPRINT. The method finds solutions for high dimensional path planning problems\nquickly and robustly. Its efficiency comes from minimizing the number of\ncollision check samples. This reduction in sampling relies on heuristics that\npredict the likelihood that samples will be useful in the search process.\nSpecifically, heuristics (1) prioritize more promising search regions; (2) cull\nsamples from local minima regions; and (3) steer the search away from\npreviously observed collision states. Empirical evaluations show that our\nmethod finds shorter or comparable-length solution paths in significantly less\ntime than commonly used methods. We demonstrate that these performance gains\ncan be largely attributed to our approach to achieve sample efficiency.",
    "descriptor": "",
    "authors": [
      "Daniel Rakita",
      "Bilge Mutlu",
      "Michael Gleicher"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.00150"
  },
  {
    "id": "arXiv:2106.00153",
    "title": "Strobe: An Acceleration Meta-algorithm for Optimizing Robot Paths using  Concurrent Interleaved Sub-Epoch Pods",
    "abstract": "In this paper, we present a meta-algorithm intended to accelerate many\nexisting path optimization algorithms. The central idea of our work is to\nstrategically break up a waypoint path into consecutive groupings called\n\"pods,\" then optimize over various pods concurrently using parallel processing.\nEach pod is assigned a color, either blue or red, and the path is divided in\nsuch a way that adjacent pods of the same color have an appropriate buffer of\nthe opposite color between them, reducing the risk of interference between\nconcurrent computations. We present a path splitting algorithm to create blue\nand red pod groupings and detail steps for a meta-algorithm that optimizes over\nthese pods in parallel. We assessed how our method works on a testbed of\nsimulated path optimization scenarios using various optimization tasks and\ncharacterize how it scales with additional threads. We also compared our\nmeta-algorithm on these tasks to other parallelization schemes. Our results\nshow that our method more effectively utilizes concurrency compared to the\nalternatives, both in terms of speed and optimization quality.",
    "descriptor": "",
    "authors": [
      "Daniel Rakita",
      "Bilge Mutlu",
      "Michael Gleicher"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.00153"
  },
  {
    "id": "arXiv:2106.00154",
    "title": "Explanations for Monotonic Classifiers",
    "abstract": "In many classification tasks there is a requirement of monotonicity.\nConcretely, if all else remains constant, increasing (resp. decreasing) the\nvalue of one or more features must not decrease (resp. increase) the value of\nthe prediction. Despite comprehensive efforts on learning monotonic\nclassifiers, dedicated approaches for explaining monotonic classifiers are\nscarce and classifier-specific. This paper describes novel algorithms for the\ncomputation of one formal explanation of a (black-box) monotonic classifier.\nThese novel algorithms are polynomial in the run time complexity of the\nclassifier and the number of features. Furthermore, the paper presents a\npractically efficient model-agnostic algorithm for enumerating formal\nexplanations.",
    "descriptor": "",
    "authors": [
      "Joao Marques-Silva",
      "Thomas Gerspacher",
      "Martin Cooper",
      "Alexey Ignatiev",
      "Nina Narodytska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00154"
  },
  {
    "id": "arXiv:2106.00156",
    "title": "Detecting a single fault in a deterministic finite automaton",
    "abstract": "Given a deterministic finite automaton and its implementation with at most\none single fault, that we can test on a set of inputs, we provide an algorithm\nto find a test set that guarantees finding whether the fault exists.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Artur Pola\u0144ski",
      "Eryk Lipka"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.00156"
  },
  {
    "id": "arXiv:2106.00157",
    "title": "Scalar Field Comparison with Topological Descriptors: Properties and  Applications for Scientific Visualization",
    "abstract": "In topological data analysis and visualization, topological descriptors such\nas persistence diagrams, merge trees, contour trees, Reeb graphs, and\nMorse-Smale complexes play an essential role in capturing the shape of scalar\nfield data. We present a state-of-the-art report on scalar field comparison\nusing topological descriptors. We provide a taxonomy of existing approaches\nbased on visualization tasks associated with three categories of data: single\nfields, time-varying fields, and ensembles. These tasks include symmetry\ndetection, periodicity detection, key event/feature detection, feature\ntracking, clustering, and structure statistics. Our main contributions include\nthe formulation of a set of desirable mathematical and computational properties\nof comparative measures, and the classification of visualization tasks and\napplications that are enabled by these measures.",
    "descriptor": "",
    "authors": [
      "Lin Yan",
      "Talha Bin Masood",
      "Raghavendra Sridharamurthy",
      "Farhan Rasheed",
      "Vijay Natarajan",
      "Ingrid Hotz",
      "Bei Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.00157"
  },
  {
    "id": "arXiv:2106.00158",
    "title": "A Road-map to Robot Task Execution with the Functional Object-Oriented  Network",
    "abstract": "Following work on joint object-action representations, the functional\nobject-oriented network (FOON) was introduced as a knowledge graph\nrepresentation for robots. Taking the form of a bipartite graph, a FOON\ncontains symbolic or high-level information that would be pertinent to a\nrobot's understanding of its environment and tasks in a way that mirrors human\nunderstanding of actions. In this work, we outline a road-map for future\ndevelopment of FOON and its application in robotic systems for task planning as\nwell as knowledge acquisition from demonstration. We propose preliminary ideas\nto show how a FOON can be created in a real-world scenario with a robot and\nhuman teacher in a way that can jointly augment existing knowledge in a FOON\nand teach a robot the skills it needs to replicate the demonstrated actions and\nsolve a given manipulation problem.",
    "descriptor": "\nComments: Ubiquitous Robots 2021 Submission -- 4 pages\n",
    "authors": [
      "David Paulius",
      "Alejandro Agostini",
      "Yu Sun",
      "Dongheui Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00158"
  },
  {
    "id": "arXiv:2106.00161",
    "title": "Integrative Use of Computer Vision and Unmanned Aircraft Technologies in  Public Inspection: Foreign Object Debris Image Collection",
    "abstract": "Unmanned Aircraft Systems (UAS) have become an important resource for public\nservice providers and smart cities. The purpose of this study is to expand this\nresearch area by integrating computer vision and UAS technology to automate\npublic inspection. As an initial case study for this work, a dataset of common\nforeign object debris (FOD) is developed to assess the potential of\nlight-weight automated detection. This paper presents the rationale and\ncreation of this dataset. Future iterations of our work will include further\ntechnical details analyzing experimental implementation. At a local airport,\nUAS and portable cameras are used to collect the data contained in the initial\nversion of this dataset. After collecting these videos of FOD, they were split\ninto individual frames and stored as several thousand images. These frames are\nthen annotated following standard computer vision format and stored in a\nfolder-structure that reflects our creation method. The dataset annotations are\nvalidated using a custom tool that could be abstracted to fit future\napplications. Initial detection models were successfully created using the\nfamous You Only Look Once algorithm, which indicates the practicality of the\nproposed data. Finally, several potential scenarios that could utilize either\nthis dataset or similar methods for other public service are presented.",
    "descriptor": "\nComments: This paper has been accepted for publication by the 22nd Annual International Conference on Digital Government Research. 7 pages, 1 figure, 1 table\n",
    "authors": [
      "Travis J. E. Munyer",
      "Daniel Brinkman",
      "Chenyu Huang",
      "Xin Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00161"
  },
  {
    "id": "arXiv:2106.00162",
    "title": "HERALD: An Annotation Efficient Method to Detect User Disengagement in  Social Conversations",
    "abstract": "Open-domain dialog systems have a user-centric goal: to provide humans with\nan engaging conversation experience. User engagement is one of the most\nimportant metrics for evaluating open-domain dialog systems, and could also be\nused as real-time feedback to benefit dialog policy learning. Existing work on\ndetecting user disengagement typically requires hand-labeling many dialog\nsamples. We propose HERALD, an annotation efficient framework that reframes the\ntraining data annotation process as a denoising problem. Specifically, instead\nof manual labeling training samples, we first use a set of labeling heuristics\nto automatically label training samples. We then denoise the weakly labeled\ndata using Shapley algorithm. Finally, we use the denoised data to train a user\nengagement detector. Our experiments show that HERALD improves annotation\nefficiency significantly and achieves 86% user disengagement detection accuracy\nin two dialog corpora.",
    "descriptor": "\nComments: ACL 2021. Code & data available at this https URL\n",
    "authors": [
      "Weixin Liang",
      "Kai-Hui Liang",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00162"
  },
  {
    "id": "arXiv:2106.00163",
    "title": "Parlermonium: A Data-Driven UX Design Evaluation of the Parler Platform",
    "abstract": "This paper evaluates Parler, the controversial social media platform, from\ntwo seemingly orthogonal perspectives: UX design perspective and data science.\nUX design researchers explore how users react to the interface/content of their\nsocial media feeds; Data science researchers analyze the misinformation flow in\nthese feeds to detect alternative narratives and state-sponsored disinformation\ncampaigns. We took a critical look into the intersection of these approaches to\nunderstand how Parler's interface itself is conductive to the flow of\nmisinformation and the perception of \"free speech\" among its audience. Parler\ndrew widespread attention leading up to and after the 2020 U.S. elections as\nthe \"alternative\" place for free speech, as a reaction to other mainstream\nsocial media platform which actively engaged in labeling misinformation with\ncontent warnings. Because platforms like Parler are disruptive to the social\nmedia landscape, we believe the evaluation uniquely uncovers the platform's\nconductivity to the spread of misinformation.",
    "descriptor": "",
    "authors": [
      "Emma Pieroni",
      "Peter Jachim",
      "Nathaniel Jachim",
      "Filipo Sharevski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00163"
  },
  {
    "id": "arXiv:2106.00168",
    "title": "Rethinking Pseudo Labels for Semi-Supervised Object Detection",
    "abstract": "Recent advances in semi-supervised object detection (SSOD) are largely driven\nby consistency-based pseudo-labeling methods for image classification tasks,\nproducing pseudo labels as supervisory signals. However, when using pseudo\nlabels, there is a lack of consideration in localization precision and\namplified class imbalance, both of which are critical for detection tasks. In\nthis paper, we introduce certainty-aware pseudo labels tailored for object\ndetection, which can effectively estimate the classification and localization\nquality of derived pseudo labels. This is achieved by converting conventional\nlocalization as a classification task followed by refinement. Conditioned on\nclassification and localization quality scores, we dynamically adjust the\nthresholds used to generate pseudo labels and reweight loss functions for each\ncategory to alleviate the class imbalance problem. Extensive experiments\ndemonstrate that our method improves state-of-the-art SSOD performance by 1-2%\nand 4-6% AP on COCO and PASCAL VOC, respectively. In the limited-annotation\nregime, our approach improves supervised baselines by up to 10% AP using only\n1-10% labeled data from COCO.",
    "descriptor": "",
    "authors": [
      "Hengduo Li",
      "Zuxuan Wu",
      "Abhinav Shrivastava",
      "Larry S. Davis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00168"
  },
  {
    "id": "arXiv:2106.00169",
    "title": "Gender Bias Amplification During Speed-Quality Optimization in Neural  Machine Translation",
    "abstract": "Is bias amplified when neural machine translation (NMT) models are optimized\nfor speed and evaluated on generic test sets using BLEU? We investigate\narchitectures and techniques commonly used to speed up decoding in\nTransformer-based models, such as greedy search, quantization, average\nattention networks (AANs) and shallow decoder models and show their effect on\ngendered noun translation. We construct a new gender bias test set, SimpleGEN,\nbased on gendered noun phrases in which there is a single, unambiguous, correct\nanswer. While we find minimal overall BLEU degradation as we apply speed\noptimizations, we observe that gendered noun translation performance degrades\nat a much faster rate.",
    "descriptor": "\nComments: Accepted at ACL 2021\n",
    "authors": [
      "Adithya Renduchintala",
      "Denise Diaz",
      "Kenneth Heafield",
      "Xian Li",
      "Mona Diab"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00169"
  },
  {
    "id": "arXiv:2106.00173",
    "title": "Enhancing Trajectory Prediction using Sparse Outputs: Application to  Team Sports",
    "abstract": "Sophisticated trajectory prediction models that effectively mimic team\ndynamics have many potential uses for sports coaches, broadcasters and\nspectators. However, through experiments on soccer data we found that it can be\nsurprisingly challenging to train a deep learning model for player trajectory\nprediction which outperforms linear extrapolation on average distance between\npredicted and true future trajectories. We propose and test a novel method for\nimproving training by predicting a sparse trajectory and interpolating using\nconstant acceleration, which improves performance for several models. This\ninterpolation can also be used on models that aren't trained with sparse\noutputs, and we find that this consistently improves performance for all tested\nmodels. Additionally, we find that the accuracy of predicted trajectories for a\nsubset of players can be improved by conditioning on the full trajectories of\nthe other players, and that this is further improved when combined with sparse\npredictions. We also propose a novel architecture using graph networks and\nmulti-head attention (GraN-MA) which achieves better performance than other\ntested state-of-the-art models on our dataset and is trivially adapted for both\nsparse trajectories and full-trajectory conditioned trajectory prediction.",
    "descriptor": "\nComments: 10 pages (not including references), 7 figures. Published in Neural Computing and Applications on 20 March 2021\n",
    "authors": [
      "Brandon Victor",
      "Aiden Nibali",
      "Zhen He",
      "David L. Carey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00173"
  },
  {
    "id": "arXiv:2106.00175",
    "title": "Duckworth-Lewis-Stern Method Comparison with Machine Learning Approach",
    "abstract": "This work presents an analysis of the Duckworth-Lewis-Stern (DLS) method for\nOne Day International (ODI) cricket matches. The accuracy of the DLS method is\ncompared against various supervised learning algorithms for result prediction.\nThe result of a cricket match is predicted during the second inning. The paper\nalso optimized DLS resource table which is used in the Duckworth-Lewis (D/L)\nformula to increase its predictive power. Finally, an Unpredictability Index is\ndeveloped that ranks different cricket playing nations according to how\nunpredictable they are while playing an ODI match.",
    "descriptor": "\nComments: The paper has been published in the conference of Frontiers of Information Technology 2019\n",
    "authors": [
      "Kumail Abbas",
      "Sajjad Haider"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00175"
  },
  {
    "id": "arXiv:2106.00178",
    "title": "Language-Driven Image Style Transfer",
    "abstract": "Despite having promising results, style transfer, which requires preparing\nstyle images in advance, may result in lack of creativity and accessibility.\nFollowing human instruction, on the other hand, is the most natural way to\nperform artistic style transfer that can significantly improve controllability\nfor visual effect applications. We introduce a new task -- language-driven\nimage style transfer (\\texttt{LDIST}) -- to manipulate the style of a content\nimage, guided by a text. We propose contrastive language visual artist (CLVA)\nthat learns to extract visual semantics from style instructions and accomplish\n\\texttt{LDIST} by the patch-wise style discriminator. The discriminator\nconsiders the correlation between language and patches of style images or\ntransferred results to jointly embed style instructions. CLVA further compares\ncontrastive pairs of content image and style instruction to improve the mutual\nrelativeness between transfer results. The transferred results from the same\ncontent image can preserve consistent content structures. Besides, they should\npresent analogous style patterns from style instructions that contain similar\nvisual semantics. The experiments show that our CLVA is effective and achieves\nsuperb transferred results on \\texttt{LDIST}.",
    "descriptor": "",
    "authors": [
      "Tsu-Jui Fu",
      "Xin Eric Wang",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00178"
  },
  {
    "id": "arXiv:2106.00180",
    "title": "Dual Normalization Multitasking for Audio-Visual Sounding Object  Localization",
    "abstract": "Although several research works have been reported on audio-visual sound\nsource localization in unconstrained videos, no datasets and metrics have been\nproposed in the literature to quantitatively evaluate its performance. Defining\nthe ground truth for sound source localization is difficult, because the\nlocation where the sound is produced is not limited to the range of the source\nobject, but the vibrations propagate and spread through the surrounding\nobjects. Therefore we propose a new concept, Sounding Object, to reduce the\nambiguity of the visual location of sound, making it possible to annotate the\nlocation of the wide range of sound sources. With newly proposed metrics for\nquantitative evaluation, we formulate the problem of Audio-Visual Sounding\nObject Localization (AVSOL). We also created the evaluation dataset (AVSOL-E\ndataset) by manually annotating the test set of well-known Audio-Visual Event\n(AVE) dataset. To tackle this new AVSOL problem, we propose a novel multitask\ntraining strategy and architecture called Dual Normalization Multitasking\n(DNM), which aggregates the Audio-Visual Correspondence (AVC) task and the\nclassification task for video events into a single audio-visual similarity map.\nBy efficiently utilize both supervisions by DNM, our proposed architecture\nsignificantly outperforms the baseline methods.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Tokuhiro Nishikawa",
      "Daiki Shimada",
      "Jerry Jun Yokono"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00180"
  },
  {
    "id": "arXiv:2106.00181",
    "title": "Gender Bias Hidden Behind Chinese Word Embeddings: The Case of Chinese  Adjectives",
    "abstract": "Gender bias in word embeddings gradually becomes a vivid research field in\nrecent years. Most studies in this field aim at measurement and debiasing\nmethods with English as the target language. This paper investigates gender\nbias in static word embeddings from a unique perspective, Chinese adjectives.\nBy training word representations with different models, the gender bias behind\nthe vectors of adjectives is assessed. Through a comparison between the\nproduced results and a human-scored data set, we demonstrate how gender bias\nencoded in word embeddings differentiates from people's attitudes.",
    "descriptor": "\nComments: Accepted at the 3rd Workshop on Gender Bias in Natural Language Processing\n",
    "authors": [
      "Meichun Jiao",
      "Ziyang Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00181"
  },
  {
    "id": "arXiv:2106.00182",
    "title": "Quantification of Carbon Sequestration in Urban Forests",
    "abstract": "Vegetation, trees in particular, sequester carbon by absorbing carbon dioxide\nfrom the atmosphere, however, the lack of efficient quantification methods of\ncarbon stored in trees renders it difficult to track the process. Here we\npresent an approach to estimate the carbon storage in trees based on fusing\nmultispectral aerial imagery and LiDAR data to identify tree coverage,\ngeometric shape, and tree species, which are crucial attributes in carbon\nstorage quantification. We demonstrate that tree species information and their\nthree-dimensional geometric shapes can be estimated from remote imagery in\norder to calculate the tree's biomass. Specifically, for Manhattan, New York\nCity, we estimate a total of $52,000$ tons of carbon sequestered in trees.",
    "descriptor": "",
    "authors": [
      "Levente Klein",
      "Wang Zhou",
      "Conrad Albrecht"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.00182"
  },
  {
    "id": "arXiv:2106.00184",
    "title": "Anti-aliasing Semantic Reconstruction for Few-Shot Semantic Segmentation",
    "abstract": "Encouraging progress in few-shot semantic segmentation has been made by\nleveraging features learned upon base classes with sufficient training data to\nrepresent novel classes with few-shot examples. However, this feature sharing\nmechanism inevitably causes semantic aliasing between novel classes when they\nhave similar compositions of semantic concepts. In this paper, we reformulate\nfew-shot segmentation as a semantic reconstruction problem, and convert base\nclass features into a series of basis vectors which span a class-level semantic\nspace for novel class reconstruction. By introducing contrastive loss, we\nmaximize the orthogonality of basis vectors while minimizing semantic aliasing\nbetween classes. Within the reconstructed representation space, we further\nsuppress interference from other classes by projecting query features to the\nsupport vector for precise semantic activation. Our proposed approach, referred\nto as anti-aliasing semantic reconstruction (ASR), provides a systematic yet\ninterpretable solution for few-shot learning problems. Extensive experiments on\nPASCAL VOC and MS COCO datasets show that ASR achieves strong results compared\nwith the prior works.",
    "descriptor": "",
    "authors": [
      "Binghao Liu",
      "Yao Ding",
      "Jianbin Jiao",
      "Xiangyang Ji",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00184"
  },
  {
    "id": "arXiv:2106.00185",
    "title": "Construction of Simplicial Complexes with Prescribed Degree-Size  Sequences",
    "abstract": "We study the realizability of simplicial complexes with a given pair of\ninteger sequences, representing the node degree distribution and facet size\ndistribution, respectively. While the $s$-uniform variant of the problem is\n$\\mathsf{NP}$-complete when $s \\geq 3$, we identify two populations of input\nsequences, most of which can be solved in polynomial time using a recursive\nalgorithm that we contribute. Combining with a sampler for the simplicial\nconfiguration model [Young $\\textit{et al.}$, Phys. Rev. E $\\textbf{96}$,\n032312 (2017)], we facilitate efficient sampling of simplicial ensembles from\narbitrary degree and size distributions. We find that, contrary to expectations\nbased on dyadic networks, increasing nodes' degrees reduces the number of loops\nin simplicial complexes. Our work unveils a fundamental constraint on the\ndegree-size sequences and sheds light on further analysis of higher-order\nphenomena based on local structures.",
    "descriptor": "\nComments: 6 pages, 4 figures. Code implementing our methods is available at this https URL (Python, pip installable). Read the Docs at this https URL\n",
    "authors": [
      "Tzu-Chi Yen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Algebraic Topology (math.AT)",
      "Combinatorics (math.CO)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00185"
  },
  {
    "id": "arXiv:2106.00186",
    "title": "Towards Real-time and Light-weight Line Segment Detection",
    "abstract": "Previous deep learning-based line segment detection (LSD) suffer from the\nimmense model size and high computational cost for line prediction. This\nconstrains them from real-time inference on computationally restricted\nenvironments. In this paper, we propose a real-time and light-weight line\nsegment detector for resource-constrained environments named Mobile LSD\n(M-LSD). We design an extremely efficient LSD architecture by minimizing the\nbackbone network and removing the typical multi-module process for line\nprediction in previous methods. To maintain competitive performance with such a\nlight-weight network, we present novel training schemes: Segments of Line\nsegment (SoL) augmentation and geometric learning scheme. SoL augmentation\nsplits a line segment into multiple subparts, which are used to provide\nauxiliary line data during the training process. Moreover, the geometric\nlearning scheme allows a model to capture additional geometry cues from\nmatching loss, junction and line segmentation, length and degree regression.\nCompared with TP-LSD-Lite, previously the best real-time LSD method, our model\n(M-LSD-tiny) achieves competitive performance with 2.5% of model size and an\nincrease of 130.5% in inference speed on GPU when evaluated with Wireframe and\nYorkUrban datasets. Furthermore, our model runs at 56.8 FPS and 48.6 FPS on\nAndroid and iPhone mobile devices, respectively. To the best of our knowledge,\nthis is the first real-time deep LSD method available on mobile devices.",
    "descriptor": "",
    "authors": [
      "Geonmo Gu",
      "Byungsoo Ko",
      "SeoungHyun Go",
      "Sung-Hyun Lee",
      "Jingeun Lee",
      "Minchul Shin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00186"
  },
  {
    "id": "arXiv:2106.00188",
    "title": "PIGLeT: Language Grounding Through Neuro-Symbolic Interaction in a 3D  World",
    "abstract": "We propose PIGLeT: a model that learns physical commonsense knowledge through\ninteraction, and then uses this knowledge to ground language. We factorize\nPIGLeT into a physical dynamics model, and a separate language model. Our\ndynamics model learns not just what objects are but also what they do: glass\ncups break when thrown, plastic ones don't. We then use it as the interface to\nour language model, giving us a unified model of linguistic form and grounded\nmeaning. PIGLeT can read a sentence, simulate neurally what might happen next,\nand then communicate that result through a literal symbolic representation, or\nnatural language.\nExperimental results show that our model effectively learns world dynamics,\nalong with how to communicate them. It is able to correctly forecast \"what\nhappens next\" given an English sentence over 80% of the time, outperforming a\n100x larger, text-to-text approach by over 10%. Likewise, its natural language\nsummaries of physical interactions are also judged by humans as more accurate\nthan LM alternatives. We present comprehensive analysis showing room for future\nwork.",
    "descriptor": "\nComments: ACL 2021 camera ready, project page at this https URL\n",
    "authors": [
      "Rowan Zellers",
      "Ari Holtzman",
      "Matthew Peters",
      "Roozbeh Mottaghi",
      "Aniruddha Kembhavi",
      "Ali Farhadi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00188"
  },
  {
    "id": "arXiv:2106.00192",
    "title": "Responses to COVID-19 with Probabilistic Programming",
    "abstract": "The COVID-19 pandemic left its unique mark on the 21st century as one of the\nmost significant disasters in history, triggering governments all over the\nworld to respond with a wide range of interventions. However, these\nrestrictions come with a substantial price tag. It is crucial for governments\nto form anti-virus strategies that balance the trade-off between protecting\npublic health and minimizing the economic cost. This work proposes a\nprobabilistic programming method to quantify the efficiency of major\nnon-pharmaceutical interventions. We present a generative simulation model that\naccounts for the economic and human capital cost of adopting such strategies,\nand provide an end-to-end pipeline to simulate the virus spread and the\nincurred loss of various policy combinations. By investigating the national\nresponse in 10 countries covering four continents, we found that social\ndistancing coupled with contact tracing is the most successful policy, reducing\nthe virus transmission rate by 96\\% along with a 98\\% reduction in economic and\nhuman capital loss. Together with experimental results, we open-sourced a\nframework to test the efficacy of each policy combination.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Assem Zhunis",
      "Tung-Duong Mai",
      "Sundong Kim"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.00192"
  },
  {
    "id": "arXiv:2106.00196",
    "title": "All-Hex Meshing Strategies For Densely Packed Spheres",
    "abstract": "We develop an all-hex meshing strategy for the interstitial space in beds of\ndensely packed spheres that is tailored to turbulent flow simulations based on\nthe spectral element method (SEM). The SEM achieves resolution through elevated\npolynomial order N and requires two to three orders of magnitude fewer elements\nthan standard finite element approaches do. These reduced element counts place\nstringent requirements on mesh quality and conformity. Our meshing algorithm is\nbased on a Voronoi decomposition of the sphere centers. Facets of the Voronoi\ncells are tessellated into quads that are swept to the sphere surface to\ngenerate a high-quality base mesh. Refinements to the algorithm include edge\ncollapse to remove slivers, node insertion to balance resolution, localized\nrefinement in the radial direction about each sphere, and mesh optimization. We\ndemonstrate geometries with 10^2-10^5 spheres using approximately 300 elements\nper sphere (for three radial layers), along with mesh quality metrics, timings,\nflow simulations, and solver performance.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Yu-Hsiang Lan",
      "Paul Fischer",
      "Elia Merzari",
      "Misun Min"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.00196"
  },
  {
    "id": "arXiv:2106.00197",
    "title": "Multilingual Speech Translation with Unified Transformer: Huawei Noah's  Ark Lab at IWSLT 2021",
    "abstract": "This paper describes the system submitted to the IWSLT 2021 Multilingual\nSpeech Translation (MultiST) task from Huawei Noah's Ark Lab. We use a unified\ntransformer architecture for our MultiST model, so that the data from different\nmodalities (i.e., speech and text) and different tasks (i.e., Speech\nRecognition, Machine Translation, and Speech Translation) can be exploited to\nenhance the model's ability. Specifically, speech and text inputs are firstly\nfed to different feature extractors to extract acoustic and textual features,\nrespectively. Then, these features are processed by a shared encoder--decoder\narchitecture. We apply several training techniques to improve the performance,\nincluding multi-task learning, task-level curriculum learning, data\naugmentation, etc. Our final system achieves significantly better results than\nbilingual baselines on supervised language pairs and yields reasonable results\non zero-shot language pairs.",
    "descriptor": "\nComments: IWSLT 2021\n",
    "authors": [
      "Xingshan Zeng",
      "Liangyou Li",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00197"
  },
  {
    "id": "arXiv:2106.00198",
    "title": "Gradient Play in Multi-Agent Markov Stochastic Games: Stationary Points  and Convergence",
    "abstract": "We study the performance of the gradient play algorithm for multi-agent\ntabular Markov decision processes (MDPs), which are also known as stochastic\ngames (SGs), where each agent tries to maximize its own total discounted reward\nby making decisions independently based on current state information which is\nshared between agents. Policies are directly parameterized by the probability\nof choosing a certain action at a given state. We show that Nash equilibria\n(NEs) and first order stationary policies are equivalent in this setting, and\ngive a non-asymptotic global convergence rate analysis to an $\\epsilon$-NE for\na subclass of multi-agent MDPs called Markov potential games, which includes\nthe cooperative setting with identical rewards among agents as an important\nspecial case. Our result shows that the number of iterations to reach an\n$\\epsilon$-NE scales linearly, instead of exponentially, with the number of\nagents. Local geometry and local stability are also considered. For Markov\npotential games, we prove that strict NEs are local maxima of the total\npotential function and fully-mixed NEs are saddle points. We also give a local\nconvergence rate around strict NEs for more general settings.",
    "descriptor": "",
    "authors": [
      "Runyu Zhang",
      "Zhaolin Ren",
      "Na Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00198"
  },
  {
    "id": "arXiv:2106.00200",
    "title": "End-to-End Multihop Retrieval for Compositional Question Answering over  Long Documents",
    "abstract": "Answering complex questions from long documents requires aggregating multiple\npieces of evidence and then predicting the answers. In this paper, we propose a\nmulti-hop retrieval method, DocHopper, to answer compositional questions over\nlong documents. At each step, DocHopper retrieves a paragraph or sentence\nembedding from the document, mixes the retrieved result with the query, and\nupdates the query for the next step. In contrast to many other retrieval-based\nmethods (e.g., RAG or REALM) the query is not augmented with a token sequence:\ninstead, it is augmented by \"numerically\" combining it with another neural\nrepresentation. This means that model is end-to-end differentiable. We\ndemonstrate that utilizing document structure in this was can largely improve\nquestion-answering and retrieval performance on long documents. We experimented\nwith DocHopper on three different QA tasks that require reading long documents\nto answer compositional questions: discourse entailment reasoning, factual QA\nwith table and text, and information seeking QA from academic papers. DocHopper\noutperforms all baseline models and achieves state-of-the-art results on all\ndatasets. Additionally, DocHopper is efficient at inference time, being 3~10\ntimes faster than the baselines.",
    "descriptor": "",
    "authors": [
      "Haitian Sun",
      "William W. Cohen",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00200"
  },
  {
    "id": "arXiv:2106.00202",
    "title": "Comoving mesh method for certain classes of moving boundary problems",
    "abstract": "A Lagrangian-type numerical scheme called the \"comoving mesh method\" or CMM\nis developed for numerically solving certain classes of moving boundary\nproblems which include, for example, the classical Hele-Shaw flow problem and\nthe well-known mean curvature flow problem. This finite element scheme exploits\nthe idea that the normal velocity field of the moving boundary can be extended\nthroughout the entire domain of definition of the problem using, for instance,\nthe Laplace operator. Then, the boundary as well as the finite element mesh of\nthe domain are easily updated at every time step by moving the nodal points\nalong this velocity field. The feasibility of the method, highlighting its\npracticality, is illustrated through various numerical experiments. Also, in\norder to examine the accuracy of the proposed scheme, the experimental order of\nconvergences between the numerical and manufactured solutions for these\nexamples are also calculated.",
    "descriptor": "\nComments: 28 pages, 37 figures\n",
    "authors": [
      "Yosuke Sunayama",
      "Masato Kimura",
      "Julius Fergy Rabago"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00202"
  },
  {
    "id": "arXiv:2106.00203",
    "title": "Hybrid Generative Models for Two-Dimensional Datasets",
    "abstract": "Two-dimensional array-based datasets are pervasive in a variety of domains.\nCurrent approaches for generative modeling have typically been limited to\nconventional image datasets and performed in the pixel domain which do not\nexplicitly capture the correlation between pixels. Additionally, these\napproaches do not extend to scientific and other applications where each\nelement value is continuous and is not limited to a fixed range. In this paper,\nwe propose a novel approach for generating two-dimensional datasets by moving\nthe computations to the space of representation bases and show its usefulness\nfor two different datasets, one from imaging and another from scientific\ncomputing. The proposed approach is general and can be applied to any dataset,\nrepresentation basis, or generative model. We provide a comprehensive\nperformance comparison of various combinations of generative models and\nrepresentation basis spaces. We also propose a new evaluation metric which\ncaptures the deficiency of generating images in pixel space.",
    "descriptor": "",
    "authors": [
      "Hoda Shajari",
      "Jaemoon Lee",
      "Sanjay Ranka",
      "Anand Rangarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00203"
  },
  {
    "id": "arXiv:2106.00209",
    "title": "Rethinking Re-Sampling in Imbalanced Semi-Supervised Learning",
    "abstract": "Semi-Supervised Learning (SSL) has shown its strong ability in utilizing\nunlabeled data when labeled data is scarce. However, most SSL algorithms work\nunder the assumption that the class distributions are balanced in both training\nand test sets. In this work, we consider the problem of SSL on class-imbalanced\ndata, which better reflects real-world situations but has only received limited\nattention so far. In particular, we decouple the training of the representation\nand the classifier, and systematically investigate the effects of different\ndata re-sampling techniques when training the whole network including a\nclassifier as well as fine-tuning the feature extractor only. We find that data\nre-sampling is of critical importance to learn a good classifier as it\nincreases the accuracy of the pseudo-labels, in particular for the minority\nclasses in the unlabeled data. Interestingly, we find that accurate\npseudo-labels do not help when training the feature extractor, rather\ncontrariwise, data re-sampling harms the training of the feature extractor.\nThis finding is against the general intuition that wrong pseudo-labels always\nharm the model performance in SSL. Based on these findings, we suggest to\nre-think the current paradigm of having a single data re-sampling strategy and\ndevelop a simple yet highly effective Bi-Sampling (BiS) strategy for SSL on\nclass-imbalanced data. BiS implements two different re-sampling strategies for\ntraining the feature extractor and the classifier and integrates this decoupled\ntraining into an end-to-end framework... Code will be released at\nhttps://github.com/TACJu/Bi-Sampling.",
    "descriptor": "",
    "authors": [
      "Ju He",
      "Adam Kortylewski",
      "Shaokang Yang",
      "Shuai Liu",
      "Cheng Yang",
      "Changhu Wang",
      "Alan Yuille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00209"
  },
  {
    "id": "arXiv:2106.00210",
    "title": "Improving Formality Style Transfer with Context-Aware Rule Injection",
    "abstract": "Models pre-trained on large-scale regular text corpora often do not work well\nfor user-generated data where the language styles differ significantly from the\nmainstream text. Here we present Context-Aware Rule Injection (CARI), an\ninnovative method for formality style transfer (FST). CARI injects multiple\nrules into an end-to-end BERT-based encoder and decoder model. It learns to\nselect optimal rules based on context. The intrinsic evaluation showed that\nCARI achieved the new highest performance on the FST benchmark dataset. Our\nextrinsic evaluation showed that CARI can greatly improve the regular\npre-trained models' performance on several tweet sentiment analysis tasks.",
    "descriptor": "\nComments: ACL2021\n",
    "authors": [
      "Zonghai Yao",
      "Hong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00210"
  },
  {
    "id": "arXiv:2106.00214",
    "title": "Game-Theoretic Frameworks for Epidemic Spreading and Human Decision  Making: A Review",
    "abstract": "This review presents and reviews various solved and open problems in\ndeveloping, analyzing, and mitigating epidemic spreading processes under human\ndecision-making. We provide a review of a range of epidemic models and explain\nthe pros and cons of different epidemic models. We exhibit the art of coupling\nepidemic models and decision models in the existing literature. More\nspecifically, fundamental questions in human decision-making amid epidemics\nsuch as what interventions are taken to combat the disease, who are\ndecision-makers, when interventions are taken, and how interventions are\nmodeled. Among many decision models, game-theoretic models have become\nincreasingly crucial in modeling human responses/behavior amid epidemics in the\nlast decade.\nIn this review, we motivate the game-theoretic approach to human\ndecision-making amid epidemics. This review provides an overview of the\nexisting literature by developing a multi-dimensional taxonomy, which\ncategorizes existing works based on multiple dimensions, including 1) types of\ngames, such as differential games, stochastic games, evolutionary games, and\nstatic games; 2) types of interventions, such as social distancing,\nvaccination, quarantine, taking antidotes, etc.; 3) the types of\ndecision-makers, such as individuals, adversaries, and central authorities at\ndifferent hierarchical levels. A fine-grained dynamic game framework is\nproposed to capture the essence of game-theoretic decision-making amid\nepidemics. From a vast body of works, we showcase three representative works\nwith unique ways of integrating game-theoretic decision-making into the\nepidemic models. The uniqueness of each of these three works distinguishes\nthemselves from each other regarding their models, analytical approaches, and\nresults. In the end, we identify several main open problems and research gaps\nleft to be addressed and filled.",
    "descriptor": "",
    "authors": [
      "Yunhan Huang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.00214"
  },
  {
    "id": "arXiv:2106.00216",
    "title": "EV-VGCNN: A Voxel Graph CNN for Event-based Object Classification",
    "abstract": "Event cameras report sparse intensity changes and hold noticeable advantages\nof low power consumption, high dynamic range, and high response speed for\nvisual perception and understanding on portable devices. Event-based learning\nmethods have recently achieved massive success on object recognition by\nintegrating events into dense frame-based representations to apply traditional\n2D learning algorithms. However, these approaches introduce much redundant\ninformation during the sparse-to-dense conversion and necessitate models with\nheavy-weight and large capacities, limiting the potential of event cameras on\nreal-life applications. To address the core problem of balancing accuracy and\nmodel complexity for event-based classification models, we (1) construct graph\nrepresentations for event data to utilize their sparsity nature better and\ndesign a lightweight end-to-end graph neural network (EV-VGCNN) for\nclassification; (2) use voxel-wise vertices rather than traditional point-wise\nmethods to incorporate the information from more points; (3) introduce a\nmulti-scale feature relational layer (MFRL) to extract semantic and motion cues\nfrom each vertex adaptively concerning its distances to neighbors.\nComprehensive experiments show that our approach advances state-of-the-art\nclassification accuracy while achieving nearly 20 times parameter reduction\n(merely 0.84M parameters).",
    "descriptor": "\nComments: 10 pages, 5 Figures\n",
    "authors": [
      "Yongjian Deng",
      "Hao Chen",
      "Huiying Chen",
      "Youfu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00216"
  },
  {
    "id": "arXiv:2106.00217",
    "title": "Toward a Secure Crowdsourced Location Tracking System",
    "abstract": "Low-energy Bluetooth devices have become ubiquitous and widely used for\ndifferent applications. Among these, Bluetooth trackers are becoming popular as\nthey allow users to track the location of their physical objects. To do so,\nBluetooth trackers are often built-in within other commercial products\nconnected to a larger crowdsourced tracking system. Such a system, however, can\npose a threat to the security and privacy of the users, for instance, by\nrevealing the location of a user's valuable object. In this paper, we introduce\na set of security properties and investigate the state of commercial\ncrowdsourced tracking systems, which present common design flaws that make them\ninsecure. Leveraging the results of our investigation, we propose a new design\nfor a secure crowdsourced tracking system (SECrow), which allows devices to\nleverage the benefits of the crowdsourced model without sacrificing security\nand privacy. Our preliminary evaluation shows that SECrow is a practical,\nsecure, and effective crowdsourced tracking solution",
    "descriptor": "\nComments: 10 pages - ACM WiSec 2021 - Preprint\n",
    "authors": [
      "Chinmay Garg",
      "Aravind Machiry",
      "Andrea Continella",
      "Christopher Kruegel",
      "Giovanni Vigna"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.00217"
  },
  {
    "id": "arXiv:2106.00218",
    "title": "Discontinuous Named Entity Recognition as Maximal Clique Discovery",
    "abstract": "Named entity recognition (NER) remains challenging when entity mentions can\nbe discontinuous. Existing methods break the recognition process into several\nsequential steps. In training, they predict conditioned on the golden\nintermediate results, while at inference relying on the model output of the\nprevious steps, which introduces exposure bias. To solve this problem, we first\nconstruct a segment graph for each sentence, in which each node denotes a\nsegment (a continuous entity on its own, or a part of discontinuous entities),\nand an edge links two nodes that belong to the same entity. The nodes and edges\ncan be generated respectively in one stage with a grid tagging scheme and\nlearned jointly using a novel architecture named Mac. Then discontinuous NER\ncan be reformulated as a non-parametric process of discovering maximal cliques\nin the graph and concatenating the spans in each clique. Experiments on three\nbenchmarks show that our method outperforms the state-of-the-art (SOTA)\nresults, with up to 3.5 percentage points improvement on F1, and achieves 5x\nspeedup over the SOTA model.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Yucheng Wang",
      "Bowen Yu",
      "Hongsong Zhu",
      "Tingwen Liu",
      "Nan Yu",
      "Limin Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00218"
  },
  {
    "id": "arXiv:2106.00219",
    "title": "Question-aware Transformer Models for Consumer Health Question  Summarization",
    "abstract": "Searching for health information online is becoming customary for more and\nmore consumers every day, which makes the need for efficient and reliable\nquestion answering systems more pressing. An important contributor to the\nsuccess rates of these systems is their ability to fully understand the\nconsumers' questions. However, these questions are frequently longer than\nneeded and mention peripheral information that is not useful in finding\nrelevant answers. Question summarization is one of the potential solutions to\nsimplifying long and complex consumer questions before attempting to find an\nanswer. In this paper, we study the task of abstractive summarization for\nreal-world consumer health questions. We develop an abstractive question\nsummarization model that leverages the semantic interpretation of a question\nvia recognition of medical entities, which enables the generation of\ninformative summaries. Towards this, we propose multiple Cloze tasks (i.e. the\ntask of filing missing words in a given context) to identify the key medical\nentities that enforce the model to have better coverage in question-focus\nrecognition. Additionally, we infuse the decoder inputs with question-type\ninformation to generate question-type driven summaries. When evaluated on the\nMeQSum benchmark corpus, our framework outperformed the state-of-the-art method\nby 10.2 ROUGE-L points. We also conducted a manual evaluation to assess the\ncorrectness of the generated summaries.",
    "descriptor": "",
    "authors": [
      "Shweta Yadav",
      "Deepak Gupta",
      "Asma Ben Abacha",
      "Dina Demner-Fushman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00219"
  },
  {
    "id": "arXiv:2106.00220",
    "title": "Integer Coordinates for Intrinsic Geometry Processing",
    "abstract": "In this work, we present a general, efficient, and provably robust\nrepresentation for intrinsic triangulations. These triangulations have emerged\nas a powerful tool for robust geometry processing of surface meshes, taking a\nlow-quality mesh and retriangulating it with high-quality intrinsic triangles.\nHowever, existing representations either support only edge flips, or do not\noffer a robust procedure to recover the common subdivision, that is, how the\nintrinsic triangulation sits along the original surface. To build a\ngeneral-purpose robust structure, we extend the framework of normal\ncoordinates, which have been deeply studied in topology, as well as the more\nrecent idea of roundabouts from geometry processing, to support a variety of\nmesh processing operations like vertex insertions, edge splits, etc. The basic\nidea is to store an integer per mesh edge counting the number of times a curve\ncrosses that edge. We show that this paradigm offers a highly effective\nrepresentation for intrinsic triangulations with strong robustness guarantees.\nThe resulting data structure is general and efficient, while offering a\nguarantee of always encoding a valid subdivision. Among other things, this\nallows us to generate a high-quality intrinsic Delaunay refinement of all\nmanifold meshes in the challenging Thingi10k dataset for the first time. This\nenables a broad class of existing surface geometry algorithms to be applied\nout-of-the-box to low-quality triangulations.",
    "descriptor": "",
    "authors": [
      "Mark Gillespie",
      "Nicholas Sharp",
      "Keenan Crane"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.00220"
  },
  {
    "id": "arXiv:2106.00221",
    "title": "Concurrent Adversarial Learning for Large-Batch Training",
    "abstract": "Large-batch training has become a commonly used technique when training\nneural networks with a large number of GPU/TPU processors. As batch size\nincreases, stochastic optimizers tend to converge to sharp local minima,\nleading to degraded test performance. Current methods usually use extensive\ndata augmentation to increase the batch size, but we found the performance gain\nwith data augmentation decreases as batch size increases, and data augmentation\nwill become insufficient after certain point. In this paper, we propose to use\nadversarial learning to increase the batch size in large-batch training.\nDespite being a natural choice for smoothing the decision surface and biasing\ntowards a flat region, adversarial learning has not been successfully applied\nin large-batch training since it requires at least two sequential gradient\ncomputations at each step, which will at least double the running time compared\nwith vanilla training even with a large number of processors. To overcome this\nissue, we propose a novel Concurrent Adversarial Learning (ConAdv) method that\ndecouple the sequential gradient computations in adversarial learning by\nutilizing staled parameters. Experimental results demonstrate that ConAdv can\nsuccessfully increase the batch size on both ResNet-50 and EfficientNet\ntraining on ImageNet while maintaining high accuracy. In particular, we show\nConAdv along can achieve 75.3\\% top-1 accuracy on ImageNet ResNet-50 training\nwith 96K batch size, and the accuracy can be further improved to 76.2\\% when\ncombining ConAdv with data augmentation. This is the first work successfully\nscales ResNet-50 training batch size to 96K.",
    "descriptor": "",
    "authors": [
      "Yong Liu",
      "Xiangning Chen",
      "Minhao Cheng",
      "Cho-Jui Hsieh",
      "Yang You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00221"
  },
  {
    "id": "arXiv:2106.00225",
    "title": "Locally Valid and Discriminative Confidence Intervals for Deep Learning  Models",
    "abstract": "Crucial for building trust in deep learning models for critical real-world\napplications is efficient and theoretically sound uncertainty quantification, a\ntask that continues to be challenging. Useful uncertainty information is\nexpected to have two key properties: It should be valid (guaranteeing coverage)\nand discriminative (more uncertain when the expected risk is high). Moreover,\nwhen combined with deep learning (DL) methods, it should be scalable and affect\nthe DL model performance minimally. Most existing Bayesian methods lack\nfrequentist coverage guarantees and usually affect model performance. The few\navailable frequentist methods are rarely discriminative and/or violate coverage\nguarantees due to unrealistic assumptions. Moreover, many methods are expensive\nor require substantial modifications to the base neural network. Building upon\nrecent advances in conformal prediction and leveraging the classical idea of\nkernel regression, we propose Locally Valid and Discriminative confidence\nintervals (LVD), a simple, efficient and lightweight method to construct\ndiscriminative confidence intervals (CIs) for almost any DL model. With no\nassumptions on the data distribution, such CIs also offer finite-sample local\ncoverage guarantees (contrasted to the simpler marginal coverage). Using a\ndiverse set of datasets, we empirically verify that besides being the only\nlocally valid method, LVD also exceeds or matches the performance (including\ncoverage rate and prediction accuracy) of existing uncertainty quantification\nmethods, while offering additional benefits in scalability and flexibility.",
    "descriptor": "",
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00225"
  },
  {
    "id": "arXiv:2106.00226",
    "title": "Families of hybridizable interior penalty discontinuous Galerkin methods  for degenerate advection-diffusion-reaction problems",
    "abstract": "We analyze families of primal high-order hybridizable discontinuous Galerkin\n(HDG) methods for solving degenerate (second-order) elliptic problems. One\nmajor trouble regarding this class of PDEs concerns its mathematical nature,\nwhich may be nonuniform over the domain. Due to the local degeneracy of the\ndiffusion term, it can be purely hyperbolic in a subregion and elliptic in the\nrest. This problem is thus quite delicate to solve since the exact solution is\ndiscontinuous at interfaces separating both elliptic and hyperbolic parts. The\nproposed HDG method is developed in a unified and compact fashion. It can\nefficiently handle pure diffusive or advective regimes and intermediate regimes\nthat combine the above mechanisms for a wide range of P\\'eclet numbers,\nincluding the delicate situation of local evanescent diffusion. To this end, an\nadaptive stabilization strategy based on the addition of jump-penalty terms is\nthen considered. A $\\theta$-upwind-based scheme is favored for the hyperbolic\nregion, and an inspired Scharfetter--Gummel-based technique is preferred for\nthe elliptic region. The well-posedness of the HDG method is also discussed by\nanalyzing the consistency and discrete coercivity properties. Extensive\nnumerical experiments are finally considered to verify the model's robustness\nfor all the abovementioned regimes.",
    "descriptor": "\nComments: 22 pages, 5 figures\n",
    "authors": [
      "G. Etangsale",
      "M. Fahs",
      "V. Fontaine",
      "A.R. Isa-Abadi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.00226"
  },
  {
    "id": "arXiv:2106.00227",
    "title": "VA-GCN: A Vector Attention Graph Convolution Network for learning on  Point Clouds",
    "abstract": "Owing to the development of research on local aggregation operators, dramatic\nbreakthrough has been made in point cloud analysis models. However, existing\nlocal aggregation operators in the current literature fail to attach decent\nimportance to the local information of the point cloud, which limits the power\nof the models. To fit this gap, we propose an efficient Vector Attention\nConvolution module (VAConv), which utilizes K-Nearest Neighbor (KNN) to extract\nthe neighbor points of each input point, and then uses the elevation and\nazimuth relationship of the vectors between the center point and its neighbors\nto construct an attention weight matrix for edge features. Afterwards, the\nVAConv adopts a dual-channel structure to fuse weighted edge features and\nglobal features. To verify the efficiency of the VAConv, we connect the VAConvs\nwith different receptive fields in parallel to obtain a Multi-scale graph\nconvolutional network, VA-GCN. The proposed VA-GCN achieves state-of-the-art\nperformance on standard benchmarks including ModelNet40, S3DIS and ShapeNet.\nRemarkably, on the ModelNet40 dataset for 3D classification, VA-GCN increased\nby 2.4% compared to the baseline.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Haotian Hu",
      "Fanyi Wang",
      "Huixiao Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00227"
  },
  {
    "id": "arXiv:2106.00232",
    "title": "Multimodal Transportation with Ridesharing of Personal Vehicles",
    "abstract": "The current public transportation system is unable to keep up with the\ngrowing passenger demand as the population grows in urban areas. The slow or\nlack of improvements for public transportation pushes people to use private\ntransportation modes, such as carpooling and ridesharing. However, the\noccupancy rate of personal vehicles has been dropping in many cities. In this\npaper, we propose a centralized transit system that integrates public transit\nand ridesharing, which is capable of matching drivers and public transit riders\nsuch that the riders would result in shorter travel time. The optimization goal\nof the system is to assign as many riders to drivers as possible for\nridesharing. We describe an exact approach and approximation algorithms to\nachieve the optimization goal. We conduct an extensive computational study to\nshow the effectiveness of the transit system for different approximation\nalgorithms. Our experiments are based on the real-world traffic data in Chicago\nCity; the data sets include both public transit and ridesharing trip\ninformation. The experiment results show that our system is able to assign more\nthan 60% of riders to drivers, leading to a substantial increase in occupancy\nrate of personal vehicles and reducing riders' travel time.",
    "descriptor": "\nComments: 31 pages, 11 figures\n",
    "authors": [
      "Qian-Ping Gu",
      "Jiajian Leo Liang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00232"
  },
  {
    "id": "arXiv:2106.00236",
    "title": "\"Why wouldn't someone think of democracy as a target?\": Security  practices & challenges of people involved with U.S. political campaigns",
    "abstract": "People who are involved with political campaigns face increased digital\nsecurity threats from well-funded, sophisticated attackers, especially\nnation-states. Improving political campaign security is a vital part of\nprotecting democracy. To identify campaign security issues, we conducted\nqualitative research with 28 participants across the U.S. political spectrum to\nunderstand the digital security practices, challenges, and perceptions of\npeople involved in campaigns. A main, overarching finding is that a unique\ncombination of threats, constraints, and work culture lead people involved with\npolitical campaigns to use technologies from across platforms and domains in\nways that leave them--and democracy--vulnerable to security attacks. Sensitive\ndata was kept in a plethora of personal and work accounts, with ad hoc adoption\nof strong passwords, two-factor authentication, encryption, and access\ncontrols. No individual company, committee, organization, campaign, or academic\ninstitution can solve the identified problems on their own. To this end, we\nprovide an initial understanding of this complex problem space and\nrecommendations for how a diverse group of experts can begin working together\nto improve security for political campaigns.",
    "descriptor": "\nComments: 18 pages, 2 tables, one ancillary file with 4 appendices\n",
    "authors": [
      "Sunny Consolvo",
      "Patrick Gage Kelley",
      "Tara Matthews",
      "Kurt Thomas",
      "Lee Dunn",
      "Elie Bursztein"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.00236"
  },
  {
    "id": "arXiv:2106.00237",
    "title": "Improving Automatic Hate Speech Detection with Multiword Expression  Features",
    "abstract": "The task of automatically detecting hate speech in social media is gaining\nmore and more attention. Given the enormous volume of content posted daily,\nhuman monitoring of hate speech is unfeasible. In this work, we propose new\nword-level features for automatic hate speech detection (HSD): multiword\nexpressions (MWEs). MWEs are lexical units greater than a word that have\nidiomatic and compositional meanings. We propose to integrate MWE features in a\ndeep neural network-based HSD framework. Our baseline HSD system relies on\nUniversal Sentence Encoder (USE). To incorporate MWE features, we create a\nthree-branch deep neural network: one branch for USE, one for MWE categories,\nand one for MWE embeddings. We conduct experiments on two hate speech tweet\ncorpora with different MWE categories and with two types of MWE embeddings,\nword2vec and BERT. Our experiments demonstrate that the proposed HSD system\nwith MWE features significantly outperforms the baseline system in terms of\nmacro-F1.",
    "descriptor": "\nComments: In Proceedings of NLDB 2021\n",
    "authors": [
      "Nicolas Zampieri",
      "Irina Illina",
      "Dominique Fohr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00237"
  },
  {
    "id": "arXiv:2106.00239",
    "title": "Watching Smartly from the Bottom: Intrusion Detection revamped through  Programmable Networks and Artificial Intelligence",
    "abstract": "The advent of Programmable Data Planes represents an outstanding evolution\nand complete revolution of the Software- Defined Networking paradigm. The\ncapacity to define the entire behavior of forwarding devices by controlling the\npacket parsing procedures and executing custom operations enables offloading\nfunctionalities traditionally performed at the control plane. A recent research\nline has explored the possibility of even offloading to the data plane part of\nArtificial Intelligence algorithms, and more specifically, Machine Learning\nones, to increase their accuracy and responsiveness (by having more detailed\nvisibility of the traffic). This introduces a significant opportunity for\nevolution in the critical field of Intrusion Detection. However, offloading\nfunctionalities to the data plane is not a straightforward task. In this paper,\nwe discuss how Programmable Data Planes might complement different stages of an\nIntrusion Detection System based on Machine Learning. We present two use cases\nthat make evident the feasibility of this approach and highlight aspects that\nmust be considered when addressing the challenge of deploying solutions\nleveraging data-plane functionalities.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Sergio Armando Guti\u00e9rrez",
      "John Willian Branch",
      "Luciano Paschoal Gaspary",
      "Juan Felipe Botero"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.00239"
  },
  {
    "id": "arXiv:2106.00240",
    "title": "Volta at SemEval-2021 Task 6: Towards Detecting Persuasive Texts and  Images using Textual and Multimodal Ensemble",
    "abstract": "Memes are one of the most popular types of content used to spread information\nonline. They can influence a large number of people through rhetorical and\npsychological techniques. The task, Detection of Persuasion Techniques in Texts\nand Images, is to detect these persuasive techniques in memes. It consists of\nthree subtasks: (A) Multi-label classification using textual content, (B)\nMulti-label classification and span identification using textual content, and\n(C) Multi-label classification using visual and textual content. In this paper,\nwe propose a transfer learning approach to fine-tune BERT-based models in\ndifferent modalities. We also explore the effectiveness of ensembles of models\ntrained in different modalities. We achieve an F1-score of 57.0, 48.2, and 52.1\nin the corresponding subtasks.",
    "descriptor": "\nComments: 7 pages, accepted at SemEval-2021 co-located with ACL-IJCNLP 2021\n",
    "authors": [
      "Kshitij Gupta",
      "Devansh Gautam",
      "Radhika Mamidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00240"
  },
  {
    "id": "arXiv:2106.00241",
    "title": "Reinforced Iterative Knowledge Distillation for Cross-Lingual Named  Entity Recognition",
    "abstract": "Named entity recognition (NER) is a fundamental component in many\napplications, such as Web Search and Voice Assistants. Although deep neural\nnetworks greatly improve the performance of NER, due to the requirement of\nlarge amounts of training data, deep neural networks can hardly scale out to\nmany languages in an industry setting. To tackle this challenge, cross-lingual\nNER transfers knowledge from a rich-resource language to languages with low\nresources through pre-trained multilingual language models. Instead of using\ntraining data in target languages, cross-lingual NER has to rely on only\ntraining data in source languages, and optionally adds the translated training\ndata derived from source languages. However, the existing cross-lingual NER\nmethods do not make good use of rich unlabeled data in target languages, which\nis relatively easy to collect in industry applications. To address the\nopportunities and challenges, in this paper we describe our novel practice in\nMicrosoft to leverage such large amounts of unlabeled data in target languages\nin real production settings. To effectively extract weak supervision signals\nfrom the unlabeled data, we develop a novel approach based on the ideas of\nsemi-supervised learning and reinforcement learning. The empirical study on\nthree benchmark data sets verifies that our approach establishes the new\nstate-of-the-art performance with clear edges. Now, the NER techniques reported\nin this paper are on their way to become a fundamental component for Web\nranking, Entity Pane, Answers Triggering, and Question Answering in the\nMicrosoft Bing search engine. Moreover, our techniques will also serve as part\nof the Spoken Language Understanding module for a commercial voice assistant.\nWe plan to open source the code of the prototype framework after deployment.",
    "descriptor": "\nComments: KDD 2021\n",
    "authors": [
      "Shining Liang",
      "Ming Gong",
      "Jian Pei",
      "Linjun Shou",
      "Wanli Zuo",
      "Xianglin Zuo",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00241"
  },
  {
    "id": "arXiv:2106.00243",
    "title": "Comprehensive Nonlinear Optimal Energy Management Scheme for Electrified  Powertrains: Application and Implementation",
    "abstract": "In this paper we present a benchmark solution with higher number of\ncontinuous and discrete states and control levers using validated powertrain\ncomponent models, where DP fails due to exponential rise in the computation\ntime. The problem involves 13 states and 4 control levers, with complex\ninteractions between multiple subsystems. Some of these variables are discrete\nwhile some are continuous. Some have slow dynamics while some have fast\ndynamics. A novel three step PS3 algorithm which is presented in our prequel\npaper is used to obtain a near-optimal solution. PS3 algorithm makes use of\npseudo spectral method for accurate state estimations. We present three\nscenarios where only fuel is minimized, only emissions are minimized and,\nlastly a combination of both fuel and emissions are minimized. All three cases\nare analyzed for their performance and computation time. The optimal compromise\nbetween fuel consumption and emissions are analyzed using a Pareto-front study.\nThis large-scale powertrain optimization problem is solved for a P2 parallel\nhybrid architecture on a class 6 pick-up & delivery truck.",
    "descriptor": "",
    "authors": [
      "Aashrith Vishwanath",
      "Hamza Anwar",
      "Apurva Chunodkar",
      "Qadeer Ahmed"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00243"
  },
  {
    "id": "arXiv:2106.00245",
    "title": "Adversarial VQA: A New Benchmark for Evaluating the Robustness of VQA  Models",
    "abstract": "With large-scale pre-training, the past two years have witnessed significant\nperformance boost on the Visual Question Answering (VQA) task. Though rapid\nprogresses have been made, it remains unclear whether these state-of-the-art\n(SOTA) VQA models are robust when encountering test examples in the wild. To\nstudy this, we introduce Adversarial VQA, a new large-scale VQA benchmark,\ncollected iteratively via an adversarial human-and-model-in-the-loop procedure.\nThrough this new benchmark, we present several interesting findings. (i)\nSurprisingly, during dataset collection, we find that non-expert annotators can\nsuccessfully attack SOTA VQA models with relative ease. (ii) We test a variety\nof SOTA VQA models on our new dataset to highlight their fragility, and find\nthat both large-scale pre-trained models and adversarial training methods can\nonly achieve far lower performance than what they can achieve on the standard\nVQA v2 dataset. (iii) When considered as data augmentation, our dataset can be\nused to improve the performance on other robust VQA benchmarks. (iv) We present\na detailed analysis of the dataset, providing valuable insights on the\nchallenges it brings to the community. We hope Adversarial VQA can serve as a\nvaluable benchmark that will be used by future work to test the robustness of\nits developed VQA models. Our dataset is publicly available at\nhttps://adversarialvqa. github.io/.",
    "descriptor": "",
    "authors": [
      "Linjie Li",
      "Jie Lei",
      "Zhe Gan",
      "Jingjing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00245"
  },
  {
    "id": "arXiv:2106.00247",
    "title": "Combination of component fault trees and Markov chains to analyze  complex, software-controlled systems",
    "abstract": "Fault Tree analysis is a widely used failure analysis methodology to assess a\nsystem in terms of safety or reliability in many industrial application\ndomains. However, with Fault Tree methodology there is no possibility to\nexpress a temporal sequence of events or state-dependent behavior of\nsoftware-controlled systems. In contrast to this, Markov Chains are a\nstate-based analysis technique based on a stochastic model. But the use of\nMarkov Chains for failure analysis of complex safety-critical systems is\nlimited due to exponential explosion of the size of the model. In this paper,\nwe present a concept to integrate Markov Chains in Component Fault Tree models.\nBased on a component concept for Markov Chains, which enables the association\nof Markov Chains to system development elements such as components, complex or\nsoftware-controlled systems can be analyzed w.r.t. safety or reliability in a\nmodular and compositional way. We illustrate this approach using a case study\nfrom the automotive domain.",
    "descriptor": "",
    "authors": [
      "Marc Zeller",
      "Francesco Montrone"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.00247"
  },
  {
    "id": "arXiv:2106.00248",
    "title": "Volta at SemEval-2021 Task 9: Statement Verification and Evidence  Finding with Tables using TAPAS and Transfer Learning",
    "abstract": "Tables are widely used in various kinds of documents to present information\nconcisely. Understanding tables is a challenging problem that requires an\nunderstanding of language and table structure, along with numerical and logical\nreasoning. In this paper, we present our systems to solve Task 9 of\nSemEval-2021: Statement Verification and Evidence Finding with Tables\n(SEM-TAB-FACTS). The task consists of two subtasks: (A) Given a table and a\nstatement, predicting whether the table supports the statement and (B)\nPredicting which cells in the table provide evidence for/against the statement.\nWe fine-tune TAPAS (a model which extends BERT's architecture to capture\ntabular structure) for both the subtasks as it has shown state-of-the-art\nperformance in various table understanding tasks. In subtask A, we evaluate how\ntransfer learning and standardizing tables to have a single header row improves\nTAPAS' performance. In subtask B, we evaluate how different fine-tuning\nstrategies can improve TAPAS' performance. Our systems achieve an F1 score of\n67.34 in subtask A three-way classification, 72.89 in subtask A two-way\nclassification, and 62.95 in subtask B.",
    "descriptor": "\nComments: 9 pages, accepted at SemEval-2021 co-located with ACL-IJCNLP 2021\n",
    "authors": [
      "Devansh Gautam",
      "Kshitij Gupta",
      "Manish Shrivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00248"
  },
  {
    "id": "arXiv:2106.00250",
    "title": "ViTA: Visual-Linguistic Translation by Aligning Object Tags",
    "abstract": "Multimodal Machine Translation (MMT) enriches the source text with visual\ninformation for translation. It has gained popularity in recent years, and\nseveral pipelines have been proposed in the same direction. Yet, the task lacks\nquality datasets to illustrate the contribution of visual modality in the\ntranslation systems. In this paper, we propose our system for the Multimodal\nTranslation Task of WAT 2021 from English to Hindi. We propose to use mBART, a\npretrained multilingual sequence-to-sequence model, for the textual-only\ntranslations. Further, we bring the visual information to a textual domain by\nextracting object tags from the image and enhance the input for the multimodal\ntask. We also explore the robustness of our system by systematically degrading\nthe source text. Finally, we achieve a BLEU score of 44.6 and 51.6 on the test\nset and challenge set of the task.",
    "descriptor": "\nComments: 7 pages, accepted at WAT-2021 co-located with ACL-IJCNLP 2021\n",
    "authors": [
      "Kshitij Gupta",
      "Devansh Gautam",
      "Radhika Mamidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00250"
  },
  {
    "id": "arXiv:2106.00252",
    "title": "Information-Theoretic Analysis of Epistemic Uncertainty in Bayesian  Meta-learning",
    "abstract": "The overall predictive uncertainty of a trained predictor can be decomposed\ninto separate contributions due to epistemic and aleatoric uncertainty. Under a\nBayesian formulation, assuming a well-specified model, the two contributions\ncan be exactly expressed (for the log-loss) or bounded (for more general\nlosses) in terms of information-theoretic quantities (Xu and Raginsky, 2020).\nThis paper addresses the study of epistemic uncertainty within an\ninformation-theoretic framework in the broader setting of Bayesian\nmeta-learning. A general hierarchical Bayesian model is assumed in which\nhyperparameters determine the per-task priors of the model parameters. Exact\ncharacterizations (for the log-loss) and bounds (for more general losses) are\nderived for the epistemic uncertainty - quantified by the minimum excess\nmeta-risk (MEMR)- of optimal meta-learning rules. This characterization is\nleveraged to bring insights into the dependence of the epistemic uncertainty on\nthe number of tasks and on the amount of per-task training data. Experiments\nare presented that compare the proposed information-theoretic bounds, evaluated\nvia neural mutual information estimators, with the performance of a novel\napproximate fully Bayesian meta-learning strategy termed Langevin-Stein\nBayesian Meta-Learning (LS-BML).",
    "descriptor": "\nComments: Under review, 21 pages\n",
    "authors": [
      "Sharu Theresa Jose",
      "Sangwoo Park",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00252"
  },
  {
    "id": "arXiv:2106.00253",
    "title": "Proactive Scheduling of Hydrogen Systems for Resilience Enhancement of  Distribution Networks",
    "abstract": "Recent advances in smart grid technologies bring opportunities to better\ncontrol the modern and complex power grids with renewable integration. The\noperation of power systems, especially distribution network (DN), is facing\nwith preeminent challenges from cyber-physical-human (CPH) threats and natural\ndisasters. In order to provide better response against threats and improve the\nresilience of power grid, proactive plans and operational schemes are required\nby system operators to minimize the damages caused by CPH threats. To that end,\nthis paper proposes a proactive plan for DN operation by using hydrogen (H2)\nsystems to enhance the resilience through cost-effective long-term energy\nstorage. Unlike batteries, H2 energy can be stored in the storage tanks days\nbefore the extreme event, and transformed into power by fuel cell units in the\npost-event time to reduce load curtailment caused by CPH threats. The proposed\nframework is validated by testing on 33-node test feeder. Simulation results\ndemonstrate that H2 systems can improve the resilience of DN during $N-m$\noutages lasting for more than 10 hours.",
    "descriptor": "",
    "authors": [
      "Hamed Haggi",
      "Wei Sun",
      "James M. Fenton",
      "Paul Brooker"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00253"
  },
  {
    "id": "arXiv:2106.00256",
    "title": "Reconciliation of Statistical and Spatial Sparsity For Robust Image and  Image-Set Classification",
    "abstract": "Recent image classification algorithms, by learning deep features from\nlarge-scale datasets, have achieved significantly better results comparing to\nthe classic feature-based approaches. However, there are still various\nchallenges of image classifications in practice, such as classifying noisy\nimage or image-set queries and training deep image classification models over\nthe limited-scale dataset. Instead of applying generic deep features, the\nmodel-based approaches can be more effective and data-efficient for robust\nimage and image-set classification tasks, as various image priors are exploited\nfor modeling the inter- and intra-set data variations while preventing\nover-fitting. In this work, we propose a novel Joint Statistical and Spatial\nSparse representation, dubbed \\textit{J3S}, to model the image or image-set\ndata for classification, by reconciling both their local patch structures and\nglobal Gaussian distribution mapped into Riemannian manifold. To the best of\nour knowledge, no work to date utilized both global statistics and local patch\nstructures jointly via joint sparse representation. We propose to solve the\njoint sparse coding problem based on the J3S model, by coupling the local and\nglobal image representations using joint sparsity. The learned J3S models are\nused for robust image and image-set classification. Experiments show that the\nproposed J3S-based image classification scheme outperforms the popular or\nstate-of-the-art competing methods over FMD, UIUC, ETH-80 and YTC databases.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Multimedia\n",
    "authors": [
      "Hao Cheng",
      "Kim-Hui Yap",
      "Bihan Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00256"
  },
  {
    "id": "arXiv:2106.00257",
    "title": "A Coarse to Fine Question Answering System based on Reinforcement  Learning",
    "abstract": "In this paper, we present a coarse to fine question answering (CFQA) system\nbased on reinforcement learning which can efficiently processes documents with\ndifferent lengths by choosing appropriate actions. The system is designed using\nan actor-critic based deep reinforcement learning model to achieve multi-step\nquestion answering. Compared to previous QA models targeting on datasets mainly\ncontaining either short or long documents, our multi-step coarse to fine model\ntakes the merits from multiple system modules, which can handle both short and\nlong documents. The system hence obtains a much better accuracy and faster\ntrainings speed compared to the current state-of-the-art models. We test our\nmodel on four QA datasets, WIKEREADING, WIKIREADING LONG, CNN and SQuAD, and\ndemonstrate 1.3$\\%$-1.7$\\%$ accuracy improvements with 1.5x-3.4x training\nspeed-ups in comparison to the baselines using state-of-the-art models.",
    "descriptor": "\nComments: 9 pages, original work published in AAAI 2019\n",
    "authors": [
      "Yu Wang",
      "Hongxia Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00257"
  },
  {
    "id": "arXiv:2106.00258",
    "title": "Divide and Rule: Recurrent Partitioned Network for Dynamic Processes",
    "abstract": "In general, many dynamic processes are involved with interacting variables,\nfrom physical systems to sociological analysis. The interplay of components in\nthe system can give rise to confounding dynamic behavior. Many approaches model\ntemporal sequences holistically ignoring the internal interaction which are\nimpotent in capturing the protogenic actuation. Differently, our goal is to\nrepresent a system with a part-whole hierarchy and discover the implied\ndependencies among intra-system variables: inferring the interactions that\npossess causal effects on the sub-system behavior with REcurrent partItioned\nNetwork (REIN). The proposed architecture consists of (i) a perceptive module\nthat extracts a hierarchical and temporally consistent representation of the\nobservation at multiple levels, (ii) a deductive module for determining the\nrelational connection between neurons at each level, and (iii) a statistical\nmodule that can predict the future by conditioning on the temporal\ndistributional estimation. Our model is demonstrated to be effective in\nidentifying the componential interactions with limited observation and stable\nin long-term future predictions experimented with diverse physical systems.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2007.15240, arXiv:2007.00631 by other authors\n",
    "authors": [
      "Qianyu Feng",
      "Bang Zhang",
      "Yi Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00258"
  },
  {
    "id": "arXiv:2106.00261",
    "title": "Exploring Dynamic Selection of Branch Expansion Orders for Code  Generation",
    "abstract": "Due to the great potential in facilitating software development, code\ngeneration has attracted increasing attention recently. Generally, dominant\nmodels are Seq2Tree models, which convert the input natural language\ndescription into a sequence of tree-construction actions corresponding to the\npre-order traversal of an Abstract Syntax Tree (AST). However, such a traversal\norder may not be suitable for handling all multi-branch nodes. In this paper,\nwe propose to equip the Seq2Tree model with a context-based Branch Selector,\nwhich is able to dynamically determine optimal expansion orders of branches for\nmulti-branch nodes. Particularly, since the selection of expansion orders is a\nnon-differentiable multi-step operation, we optimize the selector through\nreinforcement learning, and formulate the reward function as the difference of\nmodel losses obtained through different expansion orders. Experimental results\nand in-depth analysis on several commonly-used datasets demonstrate the\neffectiveness and generality of our approach. We have released our code at\nhttps://github.com/DeepLearnXMU/CG-RL.",
    "descriptor": "\nComments: Accepted by ACL 2021 main conference\n",
    "authors": [
      "Hui Jiang",
      "Chulun Zhou",
      "Fandong Meng",
      "Biao Zhang",
      "Jie Zhou",
      "Degen Huang",
      "Qingqiang Wu",
      "Jinsong Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00261"
  },
  {
    "id": "arXiv:2106.00263",
    "title": "Graph-based Exercise- and Knowledge-Aware Learning Network for Student  Performance Prediction",
    "abstract": "Predicting student performance is a fundamental task in Intelligent Tutoring\nSystems (ITSs), by which we can learn about students' knowledge level and\nprovide personalized teaching strategies for them. Researchers have made plenty\nof efforts on this task. They either leverage educational psychology methods to\npredict students' scores according to the learned knowledge proficiency, or\nmake full use of Collaborative Filtering (CF) models to represent latent\nfactors of students and exercises. However, most of these methods either\nneglect the exercise-specific characteristics (e.g., exercise materials), or\ncannot fully explore the high-order interactions between students, exercises,\nas well as knowledge concepts. To this end, we propose a Graph-based Exercise-\nand Knowledge-Aware Learning Network for accurate student score prediction.\nSpecifically, we learn students' mastery of exercises and knowledge concepts\nrespectively to model the two-fold effects of exercises and knowledge concepts.\nThen, to model the high-order interactions, we apply graph convolution\ntechniques in the prediction process. Extensive experiments on two real-world\ndatasets prove the effectiveness of our proposed Graph-EKLN.",
    "descriptor": "",
    "authors": [
      "Mengfan Liu",
      "Pengyang Shao",
      "Kun Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00263"
  },
  {
    "id": "arXiv:2106.00264",
    "title": "Hardness Sampling for Self-Training Based Transductive Zero-Shot  Learning",
    "abstract": "Transductive zero-shot learning (T-ZSL) which could alleviate the domain\nshift problem in existing ZSL works, has received much attention recently.\nHowever, an open problem in T-ZSL: how to effectively make use of unseen-class\nsamples for training, still remains. Addressing this problem, we first\nempirically analyze the roles of unseen-class samples with different degrees of\nhardness in the training process based on the uneven prediction phenomenon\nfound in many ZSL methods, resulting in three observations. Then, we propose\ntwo hardness sampling approaches for selecting a subset of diverse and hard\nsamples from a given unseen-class dataset according to these observations. The\nfirst one identifies the samples based on the class-level frequency of the\nmodel predictions while the second enhances the former by normalizing the class\nfrequency via an approximate class prior estimated by an explored prior\nestimation algorithm. Finally, we design a new Self-Training framework with\nHardness Sampling for T-ZSL, called STHS, where an arbitrary inductive ZSL\nmethod could be seamlessly embedded and it is iteratively trained with\nunseen-class samples selected by the hardness sampling approach. We introduce\ntwo typical ZSL methods into the STHS framework and extensive experiments\ndemonstrate that the derived T-ZSL methods outperform many state-of-the-art\nmethods on three public benchmarks. Besides, we note that the unseen-class\ndataset is separately used for training in some existing transductive\ngeneralized ZSL (T-GZSL) methods, which is not strict for a GZSL task. Hence,\nwe suggest a more strict T-GZSL data setting and establish a competitive\nbaseline on this setting by introducing the proposed STHS framework to T-GZSL.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Liu Bo",
      "Qiulei Dong",
      "Zhanyi Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00264"
  },
  {
    "id": "arXiv:2106.00265",
    "title": "A unified PAC-Bayesian framework for machine unlearning via information  risk minimization",
    "abstract": "Machine unlearning refers to mechanisms that can remove the influence of a\nsubset of training data upon request from a trained model without incurring the\ncost of re-training from scratch. This paper develops a unified PAC-Bayesian\nframework for machine unlearning that recovers the two recent design principles\n- variational unlearning (Nguyen et.al., 2020) and forgetting Lagrangian\n(Golatkar et.al., 2020) - as information risk minimization problems\n(Zhang,2006). Accordingly, both criteria can be interpreted as PAC-Bayesian\nupper bounds on the test loss of the unlearned model that take the form of free\nenergy metrics.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Sharu Theresa Jose",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00265"
  },
  {
    "id": "arXiv:2106.00266",
    "title": "Did I do that? Blame as a means to identify controlled effects in  reinforcement learning",
    "abstract": "Modeling controllable aspects of the environment enable better prioritization\nof interventions and has become a popular exploration strategy in reinforcement\nlearning methods. Despite repeatedly achieving State-of-the-Art results, this\napproach has only been studied as a proxy to a reward-based task and has not\nyet been evaluated on its own. We show that solutions relying on action\nprediction fail to model important events. Humans, on the other hand, assign\nblame to their actions to decide what they controlled. Here we propose\nControlled Effect Network (CEN), an unsupervised method based on counterfactual\nmeasures of blame. CEN is evaluated in a wide range of environments showing\nthat it can identify controlled effects better than popular models based on\naction prediction.",
    "descriptor": "",
    "authors": [
      "Oriol Corcoll",
      "Raul Vicente"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00266"
  },
  {
    "id": "arXiv:2106.00267",
    "title": "Classes in Object-Oriented Modeling (UML): Further Understanding and  Abstraction",
    "abstract": "Object orientation has become the predominant paradigm for conceptual\nmodeling (e.g., UML), where the notions of class and object form the primitive\nbuilding blocks of thought. Classes act as templates for objects that have\nattributes and methods (actions). The modeled systems are not even necessarily\nsoftware systems: They can be human and artificial systems of many different\nkinds (e.g., teaching and learning systems). The UML class diagram is described\nas a central component of model-driven software development. It is the most\ncommon diagram in object-oriented models and used to model the static design\nview of a system. Objects both carry data and execute actions. According to\nsome authorities in modeling, a certain degree of difficulty exists in\nunderstanding the semantics of these notions in UML class diagrams. Some\nresearchers claim class diagrams have limited use for conceptual analysis and\nthat they are best used for logical design. Performing conceptual analysis\nshould not concern the ways facts are grouped into structures. Whether a fact\nwill end up in the design as an attribute is not a conceptual issue. UML leads\nto drilling down into physical design details (e.g., private/public attributes,\nencapsulated operations, and navigating direction of an association). This\npaper is a venture to further the understanding of object-orientated concepts\nas exemplified in UML with the aim of developing a broad comprehension of\nconceptual modeling fundamentals. Thinging machine (TM) modeling is a new\nmodeling language employed in such an undertaking. TM modeling interlaces\nstructure (components) and actionality where actions infiltrate the attributes\nas much as the classes. Although space limitations affect some aspects of the\nclass diagram, the concluding assessment of this study reveals the class\ndescription is a kind of shorthand for a richer sematic TM construct.",
    "descriptor": "\nComments: 12 pages, 22 figures\n",
    "authors": [
      "Sabah Al-Fedaghi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.00267"
  },
  {
    "id": "arXiv:2106.00273",
    "title": "Adversarial Defense for Automatic Speaker Verification by  Self-Supervised Learning",
    "abstract": "Previous works have shown that automatic speaker verification (ASV) is\nseriously vulnerable to malicious spoofing attacks, such as replay, synthetic\nspeech, and recently emerged adversarial attacks. Great efforts have been\ndedicated to defending ASV against replay and synthetic speech; however, only a\nfew approaches have been explored to deal with adversarial attacks. All the\nexisting approaches to tackle adversarial attacks for ASV require the knowledge\nfor adversarial samples generation, but it is impractical for defenders to know\nthe exact attack algorithms that are applied by the in-the-wild attackers. This\nwork is among the first to perform adversarial defense for ASV without knowing\nthe specific attack algorithms. Inspired by self-supervised learning models\n(SSLMs) that possess the merits of alleviating the superficial noise in the\ninputs and reconstructing clean samples from the interrupted ones, this work\nregards adversarial perturbations as one kind of noise and conducts adversarial\ndefense for ASV by SSLMs. Specifically, we propose to perform adversarial\ndefense from two perspectives: 1) adversarial perturbation purification and 2)\nadversarial perturbation detection. Experimental results show that our\ndetection module effectively shields the ASV by detecting adversarial samples\nwith an accuracy of around 80%. Moreover, since there is no common metric for\nevaluating the adversarial defense performance for ASV, this work also\nformalizes evaluation metrics for adversarial defense considering both\npurification and detection based approaches into account. We sincerely\nencourage future works to benchmark their approaches based on the proposed\nevaluation framework.",
    "descriptor": "\nComments: Submitted to TASLP on 03 May 2021\n",
    "authors": [
      "Haibin Wu",
      "Xu Li",
      "Andy T. Liu",
      "Zhiyong Wu",
      "Helen Meng",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00273"
  },
  {
    "id": "arXiv:2106.00274",
    "title": "Analysis of classifiers robust to noisy labels",
    "abstract": "We explore contemporary robust classification algorithms for overcoming\nclass-dependant labelling noise: Forward, Importance Re-weighting and\nT-revision. The classifiers are trained and evaluated on class-conditional\nrandom label noise data while the final test data is clean. We demonstrate\nmethods for estimating the transition matrix in order to obtain better\nclassifier performance when working with noisy data. We apply deep learning to\nthree data-sets and derive an end-to-end analysis with unknown noise on the\nCIFAR data-set from scratch. The effectiveness and robustness of the\nclassifiers are analysed, and we compare and contrast the results of each\nexperiment are using top-1 accuracy as our criterion.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Alex D\u00edaz",
      "Damian Steele"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00274"
  },
  {
    "id": "arXiv:2106.00275",
    "title": "H-FL: A Hierarchical Communication-Efficient and Privacy-Protected  Architecture for Federated Learning",
    "abstract": "The longstanding goals of federated learning (FL) require rigorous privacy\nguarantees and low communication overhead while holding a relatively high model\naccuracy. However, simultaneously achieving all the goals is extremely\nchallenging. In this paper, we propose a novel framework called hierarchical\nfederated learning (H-FL) to tackle this challenge. Considering the degradation\nof the model performance due to the statistic heterogeneity of the training\ndata, we devise a runtime distribution reconstruction strategy, which\nreallocates the clients appropriately and utilizes mediators to rearrange the\nlocal training of the clients. In addition, we design a compression-correction\nmechanism incorporated into H-FL to reduce the communication overhead while not\nsacrificing the model performance. To further provide privacy guarantees, we\nintroduce differential privacy while performing local training, which injects\nmoderate amount of noise into only part of the complete model. Experimental\nresults show that our H-FL framework achieves the state-of-art performance on\ndifferent datasets for the real-world image recognition tasks.",
    "descriptor": "\nComments: Accepted by IJCAI 2021, 7pages, 10 figures\n",
    "authors": [
      "He Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.00275"
  },
  {
    "id": "arXiv:2106.00278",
    "title": "Approximate and exact results for the harmonious chromatic number",
    "abstract": "Graph colorings is a fundamental topic in graph theory that require an\nassignment of labels (or colors) to vertices or edges subject to various\nconstraints. We focus on the harmonious coloring of a graph, which is a proper\nvertex coloring such that for every two distinct colors i, j at most one pair\nof adjacent vertices are colored with i and j. This type of coloring is\nedge-distinguishing and has potential applications in transportation network,\ncomputer network, airway network system.\nThe results presented in this paper fall into two categories: in the first\npart of the paper we are concerned with the computational aspects of finding a\nminimum harmonious coloring and in the second part we determine the exact value\nof the harmonious chromatic number for some particular graphs and classes of\ngraphs. More precisely, in the first part we show that finding a minimum\nharmonious coloring for arbitrary graphs is APX-hard, the natural greedy\nalgorithm is a $\\Omega(\\sqrt{n})$-approximation, and, moreover, we show a\nrelationship between the vertex cover and the harmonious chromatic number. In\nthe second part we determine the exact value of the harmonious chromatic number\nfor all 3-regular planar graphs of diameter 3, some non-planar regular graphs\nand cycle-related graphs.",
    "descriptor": "\nComments: 15 pages, 27 figures, under submission\n",
    "authors": [
      "Ruxandra Marinescu-Ghemeci",
      "Camelia Obreja",
      "Alexandru Popa"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.00278"
  },
  {
    "id": "arXiv:2106.00279",
    "title": "$L_0$ Isotonic Regression With Secondary Objectives",
    "abstract": "We provide algorithms for isotonic regression minimizing $L_0$ error (Hamming\ndistance). This is also known as monotonic relabeling, and is applicable when\nlabels have a linear ordering but not necessarily a metric. There may be\nexponentially many optimal relabelings, so we look at secondary criteria to\ndetermine which are best. For arbitrary ordinal labels the criterion is\nmaximizing the number of labels which are only changed to an adjacent label\n(and recursively apply this). For real-valued labels we minimize the $L_p$\nerror. For linearly ordered sets we also give algorithms which minimize the sum\nof the $L_p$ and weighted $L_0$ errors, a form of penalized (regularized)\nregression. We also examine $L_0$ isotonic regression on multidimensional\ncoordinate-wise orderings. Previous algorithms took $\\Theta(n^3)$ time, but we\nreduce this to $o(n^{3/2})$.",
    "descriptor": "",
    "authors": [
      "Quentin F. Stout"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00279"
  },
  {
    "id": "arXiv:2106.00280",
    "title": "AAPM DL-Sparse-View CT Challenge Submission Report: Designing an  Iterative Network for Fanbeam-CT with Unknown Geometry",
    "abstract": "This report is dedicated to a short motivation and description of our\ncontribution to the AAPM DL-Sparse-View CT Challenge (team name:\n\"robust-and-stable\"). The task is to recover breast model phantom images from\nlimited view fanbeam measurements using data-driven reconstruction techniques.\nThe challenge is distinctive in the sense that participants are provided with a\ncollection of ground truth images and their noiseless, subsampled sinograms (as\nwell as the associated limited view filtered backprojection images), but not\nwith the actual forward model. Therefore, our approach first estimates the\nfanbeam geometry in a data-driven geometric calibration step. In a subsequent\ntwo-step procedure, we design an iterative end-to-end network that enables the\ncomputation of near-exact solutions.",
    "descriptor": "\nComments: This is a technical report of a method participating in a not yet finished challenge. Therefore, it does not contain any final results. In particular, the reported reconstruction errors are only with respect to our own validation split of the provided training data. Once the official challenge report is released, these values will be updated with the results from the actual test set\n",
    "authors": [
      "Martin Genzel",
      "Jan Macdonald",
      "Maximilian M\u00e4rz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Numerical Analysis (math.NA)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00280"
  },
  {
    "id": "arXiv:2106.00282",
    "title": "Diffuse interface relaxation model for two-phase compressible flows with  diffusion processes",
    "abstract": "The paper addresses a two-temperature model for simulating compressible\ntwo-phase flow taking into account diffusion processes related to the heat\nconduction and viscosity of the phases. This model is reduced from the\ntwo-phase Baer-Nunziato model in the limit of complete velocity relaxation and\nconsists of the phase mass and energy balance equations, the mixture momentum\nequation, and a transport equation for the volume fraction.Terms describing\neffects of mechanical relaxation, temperature relaxation, and thermal\nconduction on volume fraction evolution are derived and demonstrated to be\nsignificant for heat conduction problems. The thermal conduction leads to\ninstantaneous thermal relaxation so that the temperature equilibrium is always\nmaintained in the interface region with meeting the entropy relations. A\nnumerical method is developed to solve the model governing equations that\nensures the pressure-velocity-temperature (PVT) equilibrium condition in its\nhigh-order extension. We solve the hyperbolic part of the governing equations\nwith the Godunov method with the HLLC approximate Riemann solver. The\nnon-linear parabolic part is solved with an efficient Chebyshev explicit\niterative method without dealing with large sparse matrices. To verify the\nmodel and numerical methods proposed,we demonstrate numerical results of\nseveral numerical tests such as the multiphase shock tube problem, the\nmultiphase impact problem, and the planar ablative Rayleigh-Taylor instability\nproblem.",
    "descriptor": "\nComments: 37 pages, 16 figures\n",
    "authors": [
      "Chao Zhang",
      "Igor Menshov",
      "Lifeng Wang",
      "Zhijun Shen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.00282"
  },
  {
    "id": "arXiv:2106.00284",
    "title": "Cross-interactive residual smoothing for global and block Lanczos-type  solvers for linear systems with multiple right-hand sides",
    "abstract": "Global and block Krylov subspace methods are efficient iterative solvers for\nlarge sparse linear systems with multiple right-hand sides. However, global or\nblock Lanczos-type solvers often exhibit large oscillations in the residual\nnorms and may have a large residual gap relating to the loss of attainable\naccuracy of the approximations. Conventional residual smoothing schemes\nsuppress the oscillations but do not aid in improving the attainable accuracy,\nwhereas a novel residual smoothing scheme enables the attainable accuracy for\nsingle right-hand side Lanczos-type solvers to be improved. The underlying\nconcept of this scheme is that the primary and smoothed sequences of the\napproximations and residuals influence one another, thereby avoiding the severe\npropagation of rounding errors. In the present study, we extend this\ncross-interactive residual smoothing to the case of solving linear systems with\nmultiple right-hand sides. The resulting smoothed methods can reduce the\nresidual gap with few additional costs compared to their original counterparts.\nWe demonstrate the effectiveness of the proposed approach through rounding\nerror analysis and numerical experiments.",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Kensuke Aihara",
      "Akira Imakura",
      "Keiichi Morikuni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00284"
  },
  {
    "id": "arXiv:2106.00285",
    "title": "Shapley Counterfactual Credits for Multi-Agent Reinforcement Learning",
    "abstract": "Centralized Training with Decentralized Execution (CTDE) has been a popular\nparadigm in cooperative Multi-Agent Reinforcement Learning (MARL) settings and\nis widely used in many real applications. One of the major challenges in the\ntraining process is credit assignment, which aims to deduce the contributions\nof each agent according to the global rewards. Existing credit assignment\nmethods focus on either decomposing the joint value function into individual\nvalue functions or measuring the impact of local observations and actions on\nthe global value function. These approaches lack a thorough consideration of\nthe complicated interactions among multiple agents, leading to an unsuitable\nassignment of credit and subsequently mediocre results on MARL. We propose\nShapley Counterfactual Credit Assignment, a novel method for explicit credit\nassignment which accounts for the coalition of agents. Specifically, Shapley\nValue and its desired properties are leveraged in deep MARL to credit any\ncombinations of agents, which grants us the capability to estimate the\nindividual credit for each agent. Despite this capability, the main technical\ndifficulty lies in the computational complexity of Shapley Value who grows\nfactorially as the number of agents. We instead utilize an approximation method\nvia Monte Carlo sampling, which reduces the sample complexity while maintaining\nits effectiveness. We evaluate our method on StarCraft II benchmarks across\ndifferent scenarios. Our method outperforms existing cooperative MARL\nalgorithms significantly and achieves the state-of-the-art, with especially\nlarge margins on tasks with more severe difficulties.",
    "descriptor": "",
    "authors": [
      "Jiahui Li",
      "Kun Kuang",
      "Baoxiang Wang",
      "Furui Liu",
      "Long Chen",
      "Fei Wu",
      "Jun Xiao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.00285"
  },
  {
    "id": "arXiv:2106.00287",
    "title": "Junta Distance Approximation with Sub-Exponential Queries",
    "abstract": "Leveraging tools of De, Mossel, and Neeman [FOCS, 2019], we show two\ndifferent results pertaining to the \\emph{tolerant testing} of juntas. Given\nblack-box access to a Boolean function $f:\\{\\pm1\\}^{n} \\to \\{\\pm1\\}$, we give a\n$poly(k, \\frac{1}{\\varepsilon})$ query algorithm that distinguishes between\nfunctions that are $\\gamma$-close to $k$-juntas and $(\\gamma+\\varepsilon)$-far\nfrom $k'$-juntas, where $k' = O(\\frac{k}{\\varepsilon^2})$.\nIn the non-relaxed setting, we extend our ideas to give a\n$2^{\\tilde{O}(\\sqrt{k/\\varepsilon})}$ (adaptive) query algorithm that\ndistinguishes between functions that are $\\gamma$-close to $k$-juntas and\n$(\\gamma+\\varepsilon)$-far from $k$-juntas. To the best of our knowledge, this\nis the first subexponential-in-$k$ query algorithm for approximating the\ndistance of $f$ to being a $k$-junta (previous results of Blais, Canonne, Eden,\nLevi, and Ron [SODA, 2018] and De, Mossel, and Neeman [FOCS, 2019] required\nexponentially many queries in $k$).\nOur techniques are Fourier analytical and make use of the notion of\n\"normalized influences\" that was introduced by Talagrand [AoP, 1994].",
    "descriptor": "\nComments: To appear in CCC 2021\n",
    "authors": [
      "Vishnu Iyer",
      "Avishay Tal",
      "Michael Whitmeyer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.00287"
  },
  {
    "id": "arXiv:2106.00289",
    "title": "Resource-aware Online Parameter Adaptation for  Computationally-constrained Visual-Inertial Navigation Systems",
    "abstract": "In this paper, a computational resources-aware parameter adaptation method\nfor visual-inertial navigation systems is proposed with the goal of enabling\nthe improved deployment of such algorithms on computationally constrained\nsystems. Such a capacity can prove critical when employed on ultra-lightweight\nsystems or alongside mission critical computationally expensive processes. To\nachieve this objective, the algorithm proposes selected changes in the vision\nfront-end and optimization back-end of visual-inertial odometry algorithms,\nboth prior to execution and in real-time based on an online profiling of\navailable resources. The method also utilizes information from the motion\ndynamics experienced by the system to manipulate parameters online. The general\npolicy is demonstrated on three established algorithms, namely S-MSCKF,\nVINS-Mono and OKVIS and has been verified experimentally on the EuRoC dataset.\nThe proposed approach achieved comparable performance at a fraction of the\noriginal computational cost.",
    "descriptor": "\nComments: 6+1 pages, 8 figures\n",
    "authors": [
      "Pranay Mathur",
      "Nikhil Khedekar",
      "Kostas Alexis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.00289"
  },
  {
    "id": "arXiv:2106.00291",
    "title": "Preview, Attend and Review: Schema-Aware Curriculum Learning for  Multi-Domain Dialog State Tracking",
    "abstract": "Existing dialog state tracking (DST) models are trained with dialog data in a\nrandom order, neglecting rich structural information in a dataset. In this\npaper, we propose to use curriculum learning (CL) to better leverage both the\ncurriculum structure and schema structure for task-oriented dialogs.\nSpecifically, we propose a model-agnostic framework called Schema-aware\nCurriculum Learning for Dialog State Tracking (SaCLog), which consists of a\npreview module that pre-trains a DST model with schema information, a\ncurriculum module that optimizes the model with CL, and a review module that\naugments mispredicted data to reinforce the CL training. We show that our\nproposed approach improves DST performance over both a transformer-based and\nRNN-based DST model (TripPy and TRADE) and achieves new state-of-the-art\nresults on WOZ2.0 and MultiWOZ2.1.",
    "descriptor": "\nComments: 7 pages, 2 figures, accepted to ACL21\n",
    "authors": [
      "Yinpei Dai",
      "Hangyu Li",
      "Yongbin Li",
      "Jian Sun",
      "Fei Huang",
      "Luo Si",
      "Xiaodan Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00291"
  },
  {
    "id": "arXiv:2106.00297",
    "title": "More Behind Your Electricity Bill: a Dual-DNN Approach to Non-Intrusive  Load Monitoring",
    "abstract": "Non-intrusive load monitoring (NILM) is a well-known single-channel blind\nsource separation problem that aims to decompose the household energy\nconsumption into itemised energy usage of individual appliances. In this way,\nconsiderable energy savings could be achieved by enhancing household's\nawareness of energy usage. Recent investigations have shown that deep neural\nnetworks (DNNs) based approaches are promising for the NILM task. Nevertheless,\nthey normally ignore the inherent properties of appliance operations in the\nnetwork design, potentially leading to implausible results. We are thus\nmotivated to develop the dual Deep Neural Networks (dual-DNN), which aims to i)\ntake advantage of DNNs' learning capability of latent features and ii) empower\nthe DNN architecture with identification ability of universal properties.\nSpecifically in the design of dual-DNN, we adopt one subnetwork to measure\npower ratings of different appliances' operation states, and the other\nsubnetwork to identify the running states of target appliances. The final\nresult is then obtained by multiplying these two network outputs and meanwhile\nconsidering the multi-state property of household appliances. To enforce the\nsparsity property in appliance's state operating, we employ median filtering\nand hard gating mechanisms to the subnetwork for state identification. Compared\nwith the state-of-the-art NILM methods, our dual-DNN approach demonstrates a\n21.67% performance improvement in average on two public benchmark datasets.",
    "descriptor": "\nComments: 9 pages, 6 figures, 3 tables\n",
    "authors": [
      "Yu Zhang",
      "Guoming Tang",
      "Qianyi Huang",
      "Yi Wang",
      "Hong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00297"
  },
  {
    "id": "arXiv:2106.00300",
    "title": "Throughput-Outage Scaling Behaviors for Wireless Single-Hop D2D Caching  Networks with Physical Model -- Analysis and Derivations",
    "abstract": "Throughput-Outage scaling laws for single-hop cache-aided device-to-device\n(D2D) communications have been extensively investigated under the assumption of\nthe protocol model. However, the corresponding performance under physical\nmodels has not been explored; in particular it remains unclear whether\nlink-level power control and scheduling can improve the asymptotic performance.\nThis paper thus investigates the throughput-outage scaling laws of cache-aided\nsingle-hop D2D networks considering a general physical channel model. By\nconsidering the networks with and without the equal-throughput assumption, we\nanalyze the corresponding outer bounds and provide the achievable performance\nanalysis. Results show that when the equal-throughput assumption is considered,\nusing link-level power control and scheduling cannot improve the scaling laws.\nOn the other hand, when the equal-throughput assumption is not considered, we\nshow that the proposed double time-slot framework with appropriate link-level\npower control and scheduling can significantly improve the throughput-outage\nscaling laws, where the fundamental concept is to first distinguish links\naccording to their communication distances, and then enhance the throughput for\nlinks with small communication distances.",
    "descriptor": "",
    "authors": [
      "Ming-Chun Lee",
      "Andreas F. Molisch",
      "Mingyue Ji"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.00300"
  },
  {
    "id": "arXiv:2106.00302",
    "title": "Harvesting the Public MeSH Note field",
    "abstract": "In this document, we report an analysis of the Public MeSH Note field of the\nnew descriptors introduced in the MeSH thesaurus between 2006 and 2020. The aim\nof this analysis was to extract information about the previous status of these\nnew descriptors as Supplementary Concept Records. The Public MeSH Note field\ncontains information in semi-structured text, meant to be read by humans.\nTherefore, we adopted a semi-automated approach, based on regular expressions,\nto extract information from it. In the large majority of cases, we managed to\nminimize the required manual effort for extracting the previous state of a new\ndescriptor as a Supplementary Concept Record. The source code for this analysis\nis openly available on GitHub.",
    "descriptor": "\nComments: 3 pages, 1 figure, 1 table. Technical report\n",
    "authors": [
      "Anastasios Nentidis",
      "Anastasia Krithara",
      "Grigorios Tsoumakas",
      "Georgios Paliouras"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.00302"
  },
  {
    "id": "arXiv:2106.00305",
    "title": "Independent Prototype Propagation for Zero-Shot Compositionality",
    "abstract": "Humans are good at compositional zero-shot reasoning; someone who has never\nseen a zebra before could nevertheless recognize one when we tell them it looks\nlike a horse with black and white stripes. Machine learning systems, on the\nother hand, usually leverage spurious correlations in the training data, and\nwhile such correlations can help recognize objects in context, they hurt\ngeneralization. To be able to deal with underspecified datasets while still\nleveraging contextual clues during classification, we propose ProtoProp, a\nnovel prototype propagation graph method. First we learn prototypical\nrepresentations of objects (e.g., zebra) that are conditionally independent\nw.r.t. their attribute labels (e.g., stripes) and vice versa. Next we propagate\nthe independent prototypes through a compositional graph, to learn\ncompositional prototypes of novel attribute-object combinations that reflect\nthe dependencies of the target distribution. The method does not rely on any\nexternal data, such as class hierarchy graphs or pretrained word embeddings. We\nevaluate our approach on AO-Clever, a synthetic and strongly visual dataset\nwith clean labels, and UT-Zappos, a noisy real-world dataset of fine-grained\nshoe types. We show that in the generalized compositional zero-shot setting we\noutperform state-of-the-art results, and through ablations we show the\nimportance of each part of the method and their contribution to the final\nresults.",
    "descriptor": "",
    "authors": [
      "Frank Ruis",
      "Gertjan Burghours",
      "Doina Bucur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00305"
  },
  {
    "id": "arXiv:2106.00306",
    "title": "Understanding peacefulness through the world news",
    "abstract": "Peacefulness is a principal dimension of well-being for all humankind and is\nthe way out of inequity and every single form of violence. Thus, its\nmeasurement has lately drawn the attention of researchers and policy-makers.\nDuring the last years, novel digital data streams have drastically changed the\nresearch in this field. In the current study, we exploit information extracted\nfrom Global Data on Events, Location, and Tone (GDELT) digital news database,\nto capture peacefulness through the Global Peace Index (GPI). Applying\npredictive machine learning models, we demonstrate that news media attention\nfrom GDELT can be used as a proxy for measuring GPI at a monthly level.\nAdditionally, we use the SHAP methodology to obtain the most important\nvariables that drive the predictions. This analysis highlights each country's\nprofile and provides explanations for the predictions overall, and particularly\nfor the errors and the events that drive these errors. We believe that digital\ndata exploited by Social Good researchers, policy-makers, and peace-builders,\nwith data science tools as powerful as machine learning, could contribute to\nmaximize the societal benefits and minimize the risks to peacefulness.",
    "descriptor": "\nComments: 19 pages, 19 figures\n",
    "authors": [
      "Vasiliki Voukelatou",
      "Ioanna Miliou",
      "Fosca Giannotti",
      "Luca Pappalardo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00306"
  },
  {
    "id": "arXiv:2106.00308",
    "title": "Fast Splitting Algorithms for Sparsity-Constrained and Noisy Group  Testing",
    "abstract": "In group testing, the goal is to identify a subset of defective items within\na larger set of items based on tests whose outcomes indicate whether at least\none defective item is present. This problem is relevant in areas such as\nmedical testing, DNA sequencing, communication protocols, and many more. In\nthis paper, we study (i) a sparsity-constrained version of the problem, in\nwhich the testing procedure is subjected to one of the following two\nconstraints: items are finitely divisible and thus may participate in at most\n$\\gamma$ tests; or tests are size-constrained to pool no more than $\\rho$ items\nper test; and (ii) a noisy version of the problem, where each test outcome is\nindependently flipped with some constant probability. Under each of these\nsettings, considering the for-each recovery guarantee with asymptotically\nvanishing error probability, we introduce a fast splitting algorithm and\nestablish its near-optimality not only in terms of the number of tests, but\nalso in terms of the decoding time. While the most basic formulations of our\nalgorithms require $\\Omega(n)$ storage for each algorithm, we also provide\nlow-storage variants based on hashing, with similar recovery guarantees.",
    "descriptor": "",
    "authors": [
      "Eric Price",
      "Jonathan Scarlett",
      "Nelvin Tan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00308"
  },
  {
    "id": "arXiv:2106.00309",
    "title": "Innovation in Large-scale agile -- Benefits and Challenges of Hackathons  when Hacking from Home",
    "abstract": "Hackathons are events in which diverse teams work together to explore, and\ndevelop solutions, software or even ideas. Hackathons have been recognized not\nonly as public events for hacking, but also as a corporate mechanism for\ninnovation. Hackathons are a way for established companies to achieve increased\nemployee wellbeing as well as being a curator for innovation and developing new\nproducts. Sudden transition to the work-from-home mode caused by the COVID-19\npandemic first put many corporate events requiring collocation, such as\nhackathons, temporarily on hold and then motivated companies to find ways to\nhold these events virtually. In this paper, we report our findings from\ninvestigating hackathons in the context of a large agile company by first\nexploring the general benefits and challenges of hackathons and then trying to\nunderstand how they were affected by the virtual setup. We conducted nine\ninterviews, surveyed 23 employees and analyzed a hackathon demo. We found that\nhackathons provide both individual and organizational benefits of innovation,\npersonal interests, and acquiring new skills and competences. Several\nchallenges such as added stress due to stopping the regular work, employees\nfearing not having enough contribution to deliver and potential mismatch\nbetween individual and organizational goals were also found. With respect to\nthe virtual setup, we found that virtual hackathons are not diminishing the\ninnovation benefits, however, some negative effect surfaced on the social and\nnetworking side.",
    "descriptor": "",
    "authors": [
      "Rasmus Ulfsnes",
      "Viktoria Stray",
      "Nils Brede Moe",
      "Darja \u0160mite"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.00309"
  },
  {
    "id": "arXiv:2106.00313",
    "title": "On the Stability of Mixed Finite-Element Formulations for  High-Temperature Superconductors",
    "abstract": "In this work, we present and analyze the numerical stability of two coupled\nfinite element formulations. The first one is the h-a-formulation and is well\nsuited for modeling systems with superconductors and ferromagnetic materials.\nThe second one, the so-called t-a-formulation with thin-shell approximation,\napplies for systems with thin superconducting domains. Both formulations\ninvolve two coupled unknown fields and are mixed on the coupling interfaces.\nFunction spaces in mixed formulations must satisfy compatibility conditions to\nensure stability of the problem and reliability of the numerical solution. We\npropose stable choices of function spaces using hierarchical basis functions\nand demonstrate the effectiveness of the approach on simple 2D examples.",
    "descriptor": "",
    "authors": [
      "Julien Dular",
      "Mane Harutyunyan",
      "Lorenzo Bortot",
      "Sebastian Schoeps",
      "Benoit Vanderheyden",
      "Christophe Geuzaine"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Accelerator Physics (physics.acc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00313"
  },
  {
    "id": "arXiv:2106.00314",
    "title": "Dual Graph enhanced Embedding Neural Network for CTRPrediction",
    "abstract": "CTR prediction, which aims to estimate the probability that a user will click\nan item, plays a crucial role in online advertising and recommender system.\nFeature interaction modeling based and user interest mining based methods are\nthe two kinds of most popular techniques that have been extensively explored\nfor many years and have made great progress for CTR prediction. However, (1)\nfeature interaction based methods which rely heavily on the co-occurrence of\ndifferent features, may suffer from the feature sparsity problem (i.e., many\nfeatures appear few times); (2) user interest mining based methods which need\nrich user behaviors to obtain user's diverse interests, are easy to encounter\nthe behavior sparsity problem (i.e., many users have very short behavior\nsequences). To solve these problems, we propose a novel module named Dual Graph\nenhanced Embedding, which is compatible with various CTR prediction models to\nalleviate these two problems. We further propose a Dual Graph enhanced\nEmbedding Neural Network (DG-ENN) for CTR prediction. Dual Graph enhanced\nEmbedding exploits the strengths of graph representation with two carefully\ndesigned learning strategies (divide-and-conquer, curriculum-learning-inspired\norganized learning) to refine the embedding. We conduct comprehensive\nexperiments on three real-world industrial datasets. The experimental results\nshow that our proposed DG-ENN significantly outperforms state-of-the-art CTR\nprediction models. Moreover, when applying to state-of-the-art CTR prediction\nmodels, Dual graph enhanced embedding always obtains better performance.\nFurther case studies prove that our proposed dual graph enhanced embedding\ncould alleviate the feature sparsity and behavior sparsity problems. Our\nframework will be open-source based on MindSpore in the near future.",
    "descriptor": "\nComments: KDD 2021\n",
    "authors": [
      "Wei Guo",
      "Rong Su",
      "Renhao Tan",
      "Huifeng Guo",
      "Yingxue Zhang",
      "Zhirong Liu",
      "Ruiming Tang",
      "Xiuqiang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.00314"
  },
  {
    "id": "arXiv:2106.00315",
    "title": "Ordering regular languages: a danger zone",
    "abstract": "Ordering the collection of states of a given automaton starting from an order\nof the underlying alphabet is a natural move towards a computational treatment\nof the language accepted by the automaton. Along this path, Wheeler\n\\emph{graphs} have been recently introduced as an extension/adaptation of the\nBurrows-Wheeler Transform (the now famous BWT, originally defined on strings)\nto graphs. These graphs constitute an important data-structure for languages,\nsince they allow a very efficient storage mechanism for the transition function\nof an automaton, while providing a fast support to all sorts of substring\nqueries. This is possible as a consequence of a property -- the so-called\n\\emph{path coherence} -- valid on Wheeler graphs and consisting in an ordering\non nodes that \"propagates\" to (collections of) strings. By looking at a Wheeler\ngraph as an automaton, the ordering on strings corresponds to the\nco-lexicographic order of the words entering each state. This leads naturally\nto consider the class of regular languages accepted by Wheeler automata, i.e.\nthe Wheeler languages.\nIt has been shown that, as opposed to the general case, the classic\ndeterminization by powerset construction is polynomial on Wheeler languages. As\na consequence, most of the classical problems turn out to be \"easy\" -- that is,\nsolvable in polynomial time -- on Wheeler languages. Moreover, deciding whether\na DFA is Wheeler and deciding whether a DFA accepts a Wheeler language is\npolynomial.\nOur contribution here is to put an upper bound to easy problems. For\ninstance, whenever we generalize by switching to general NFAs or by not fixing\nan order of the underlying alphabet, the above mentioned problems become \"hard\"\n-- that is NP-complete or even PSPACE-complete.",
    "descriptor": "\nComments: 23 pages, 6 figures\n",
    "authors": [
      "Giovanna D'Agostino",
      "Davide Martincigh",
      "Alberto Policriti"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.00315"
  },
  {
    "id": "arXiv:2106.00316",
    "title": "LenAtten: An Effective Length Controlling Unit For Text Summarization",
    "abstract": "Fixed length summarization aims at generating summaries with a preset number\nof words or characters. Most recent researches incorporate length information\nwith word embeddings as the input to the recurrent decoding unit, causing a\ncompromise between length controllability and summary quality. In this work, we\npresent an effective length controlling unit Length Attention (LenAtten) to\nbreak this trade-off. Experimental results show that LenAtten not only brings\nimprovements in length controllability and ROGUE scores but also has great\ngeneralization ability. In the task of generating a summary with the target\nlength, our model is 732 times better than the best-performing length\ncontrollable summarizer in length controllability on the CNN/Daily Mail\ndataset.",
    "descriptor": "\nComments: 8 pages, accepted at Findings of ACL 2021 (short)\n",
    "authors": [
      "Zhongyi Yu",
      "Zhenghao Wu",
      "Hao Zheng",
      "Zhe XuanYuan",
      "Jefferson Fong",
      "Weifeng Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00316"
  },
  {
    "id": "arXiv:2106.00317",
    "title": "Data-Driven Shadowgraph Simulation of a 3D Object",
    "abstract": "In this work we propose a deep neural network based surrogate model for a\nplasma shadowgraph - a technique for visualization of perturbations in a\ntransparent medium. We are substituting the numerical code by a computationally\ncheaper projection based surrogate model that is able to approximate the\nelectric fields at a given time without computing all preceding electric fields\nas required by numerical methods. This means that the projection based\nsurrogate model allows to recover the solution of the governing 3D partial\ndifferential equation, 3D wave equation, at any point of a given compute domain\nand configuration without the need to run a full simulation. This model has\nshown a good quality of reconstruction in a problem of interpolation of data\nwithin a narrow range of simulation parameters and can be used for input data\nof large size.",
    "descriptor": "\nComments: 9 pages, 9 figures. Published as a workshop paper at ICLR 2021 SimDL Workshop\n",
    "authors": [
      "Anna Willmann",
      "Patrick Stiller",
      "Alexander Debus",
      "Arie Irman",
      "Richard Pausch",
      "Yen-Yu Chang",
      "Michael Bussmann",
      "Nico Hoffmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00317"
  },
  {
    "id": "arXiv:2106.00318",
    "title": "Semi-Supervised Disparity Estimation with Deep Feature Reconstruction",
    "abstract": "Despite the success of deep learning in disparity estimation, the domain\ngeneralization gap remains an issue. We propose a semi-supervised pipeline that\nsuccessfully adapts DispNet to a real-world domain by joint supervised training\non labeled synthetic data and self-supervised training on unlabeled real data.\nFurthermore, accounting for the limitations of the widely-used photometric\nloss, we analyze the impact of deep feature reconstruction as a promising\nsupervisory signal for disparity estimation.",
    "descriptor": "\nComments: Women in Computer Vision workshop CVPR 2021\n",
    "authors": [
      "Julia Guerrero-Viu",
      "Sergio Izquierdo",
      "Philipp Schr\u00f6ppel",
      "Thomas Brox"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00318"
  },
  {
    "id": "arXiv:2106.00319",
    "title": "Bayesian Agency: Linear versus Tractable Contracts",
    "abstract": "We study principal-agent problems in which a principal commits to an\noutcome-dependent payment scheme (a.k.a. contract) so as to induce an agent to\ntake a costly, unobservable action. We relax the assumption that the principal\nperfectly knows the agent by considering a Bayesian setting where the agent's\ntype is unknown and randomly selected according to a given probability\ndistribution, which is known to the principal. Each agent's type is\ncharacterized by her own action costs and action-outcome distributions. In the\nliterature on non-Bayesian principal-agent problems, considerable attention has\nbeen devoted to linear contracts, which are simple, pure-commission payment\nschemes that still provide nice approximation guarantees with respect to\nprincipal-optimal (possibly non-linear) contracts. While in non-Bayesian\nsettings an optimal contract can be computed efficiently, this is no longer the\ncase for our Bayesian principal-agent problems. This further motivates our\nfocus on linear contracts, which can be optimized efficiently given their\nsingle-parameter nature. Our goal is to analyze the properties of linear\ncontracts in Bayesian settings, in terms of approximation guarantees with\nrespect to optimal contracts and general tractable contracts (i.e.,\nefficiently-computable ones). First, we study the approximation guarantees of\nlinear contracts with respect to optimal ones, showing that the former suffer\nfrom a multiplicative loss linear in the number of agent's types. Nevertheless,\nwe prove that linear contracts can still provide a constant multiplicative\napproximation $\\rho$ of the optimal principal's expected utility, though at the\nexpense of an exponentially-small additive loss $2^{-\\Omega(\\rho)}$. Then, we\nswitch to tractable contracts, showing that, surprisingly, linear contracts\nperform well among them.",
    "descriptor": "",
    "authors": [
      "Matteo Castiglioni",
      "Alberto Marchesi",
      "Nicola Gatti"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.00319"
  },
  {
    "id": "arXiv:2106.00320",
    "title": "Distribution Matching for Rationalization",
    "abstract": "The task of rationalization aims to extract pieces of input text as\nrationales to justify neural network predictions on text classification tasks.\nBy definition, rationales represent key text pieces used for prediction and\nthus should have similar classification feature distribution compared to the\noriginal input text. However, previous methods mainly focused on maximizing the\nmutual information between rationales and labels while neglecting the\nrelationship between rationales and input text. To address this issue, we\npropose a novel rationalization method that matches the distributions of\nrationales and input text in both the feature space and output space.\nEmpirically, the proposed distribution matching approach consistently\noutperforms previous methods by a large margin. Our data and code are\navailable.",
    "descriptor": "\nComments: Accepted by AAAI2021\n",
    "authors": [
      "Yongfeng Huang",
      "Yujun Chen",
      "Yulun Du",
      "Zhilin Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00320"
  },
  {
    "id": "arXiv:2106.00321",
    "title": "A Way to a Universal VR Accessibility Toolkit",
    "abstract": "Virtual Reality (VR) has become more and more popular with dropping prices\nfor systems and a growing number of users. However, the issue of accessibility\nin VR has been hardly addressed so far and no uniform approach or standard\nexists at this time. In this position paper, we propose a customisable toolkit\nimplemented at the system-level and discuss the potential benefits of this\napproach and challenges that will need to be overcome for a successful\nimplementation.",
    "descriptor": "\nComments: This work was presented at the ACM CHI 2021 Workshop on Design and Creation of Inclusive User Interactions Through Immersive Media. this https URL\n",
    "authors": [
      "Felix J. Thiel",
      "Anthony Steed"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.00321"
  },
  {
    "id": "arXiv:2106.00322",
    "title": "Sequential Domain Adaptation by Synthesizing Distributionally Robust  Experts",
    "abstract": "Least squares estimators, when trained on a few target domain samples, may\npredict poorly. Supervised domain adaptation aims to improve the predictive\naccuracy by exploiting additional labeled training samples from a source\ndistribution that is close to the target distribution. Given available data, we\ninvestigate novel strategies to synthesize a family of least squares estimator\nexperts that are robust with regard to moment conditions. When these moment\nconditions are specified using Kullback-Leibler or Wasserstein-type\ndivergences, we can find the robust estimators efficiently using convex\noptimization. We use the Bernstein online aggregation algorithm on the proposed\nfamily of robust experts to generate predictions for the sequential stream of\ntarget test samples. Numerical experiments on real data show that the robust\nstrategies may outperform non-robust interpolations of the empirical least\nsquares estimators.",
    "descriptor": "",
    "authors": [
      "Bahar Taskesen",
      "Man-Chung Yue",
      "Jose Blanchet",
      "Daniel Kuhn",
      "Viet Anh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00322"
  },
  {
    "id": "arXiv:2106.00323",
    "title": "Boosting the Search Performance of B+-tree for Non-volatile Memory with  Sentinels",
    "abstract": "The next-generation non-volatile memory (NVM) is striding into computer\nsystems as a new tier as it incorporates both DRAM's byte-addressability and\ndisk's persistency. Researchers and practitioners have considered building\npersistent memory by placing NVM on the memory bus for CPU to directly load and\nstore data. As a result, cache-friendly data structures have been developed for\nNVM. One of them is the prevalent B+-tree. State-of-the-art in-NVM B+-trees\nmainly focus on the optimization of write operations (insertion and deletion).\nHowever, search is of vital importance for B+-tree. Not only search-intensive\nworkloads benefit from an optimized search, but insertion and deletion also\nrely on a preceding search operation to proceed. In this paper, we attentively\nstudy a sorted B+-tree node that spans over contiguous cache lines. Such cache\nlines exhibit a monotonically increasing trend and searching a target key\nacross them can be accelerated by estimating a range the key falls into. To do\nso, we construct a probing Sentinel Array in which a sentinel stands for each\ncache line of B+-tree node. Checking the Sentinel Array avoids scanning\nunnecessary cache lines and hence significantly reduces cache misses for a\nsearch. A quantitative evaluation shows that using Sentinel Arrays boosts the\nsearch performance of state-of-the-art in-NVM B+-trees by up to 48.4% while the\ncost of maintaining of Sentinel Array is low.",
    "descriptor": "\nComments: Accepted and Presented at MSC 2020 (@ESWeek 2020)\n",
    "authors": [
      "Chongnan Ye",
      "Chundong Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00323"
  },
  {
    "id": "arXiv:2106.00326",
    "title": "AI-Ethics by Design. Evaluating Public Perception on the Importance of  Ethical Design Principles of AI",
    "abstract": "Despite the immense societal importance of ethically designing artificial\nintelligence (AI), little research on the public perceptions of ethical AI\nprinciples exists. This becomes even more striking when considering that\nethical AI development has the aim to be human-centric and of benefit for the\nwhole society. In this study, we investigate how ethical principles\n(explainability, fairness, security, accountability, accuracy, privacy, machine\nautonomy) are weighted in comparison to each other. This is especially\nimportant, since simultaneously considering ethical principles is not only\ncostly, but sometimes even impossible, as developers must make specific\ntrade-off decisions. In this paper, we give first answers on the relative\nimportance of ethical principles given a specific use case - the use of AI in\ntax fraud detection. The results of a large conjoint survey (n=1099) suggest\nthat, by and large, German respondents found the ethical principles equally\nimportant. However, subsequent cluster analysis shows that different preference\nmodels for ethically designed systems exist among the German population. These\nclusters substantially differ not only in the preferred attributes, but also in\nthe importance level of the attributes themselves. We further describe how\nthese groups are constituted in terms of sociodemographics as well as opinions\non AI. Societal implications as well as design challenges are discussed.",
    "descriptor": "",
    "authors": [
      "Kimon Kieslich",
      "Birte Keller",
      "Christopher Starke"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00326"
  },
  {
    "id": "arXiv:2106.00327",
    "title": "Search from History and Reason for Future: Two-stage Reasoning on  Temporal Knowledge Graphs",
    "abstract": "Temporal Knowledge Graphs (TKGs) have been developed and used in many\ndifferent areas. Reasoning on TKGs that predicts potential facts (events) in\nthe future brings great challenges to existing models. When facing a prediction\ntask, human beings usually search useful historical information (i.e., clues)\nin their memories and then reason for future meticulously. Inspired by this\nmechanism, we propose CluSTeR to predict future facts in a two-stage manner,\nClue Searching and Temporal Reasoning, accordingly. Specifically, at the clue\nsearching stage, CluSTeR learns a beam search policy via reinforcement learning\n(RL) to induce multiple clues from historical facts. At the temporal reasoning\nstage, it adopts a graph convolution network based sequence method to deduce\nanswers from clues. Experiments on four datasets demonstrate the substantial\nadvantages of CluSTeR compared with the state-of-the-art methods. Moreover, the\nclues found by CluSTeR further provide interpretability for the results.",
    "descriptor": "\nComments: ACL 2021 long paper (main conference)\n",
    "authors": [
      "Zixuan Li",
      "Xiaolong Jin",
      "Saiping Guan",
      "Wei Li",
      "Jiafeng Guo",
      "Yuanzhuo Wang",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00327"
  },
  {
    "id": "arXiv:2106.00328",
    "title": "Optimizing travel routes using temporal networks constructed from GPS  data",
    "abstract": "Because of the complexity of urban transportation networks and the temporal\nchanges in traffic conditions, it is difficult to assess real-time traffic\nsituations. However, the development of information terminals has made it\neasier to obtain personal mobility information. In this study, we propose\nmethods for evaluating the mobility of people in a city using global\npositioning system data. There are two main methods for evaluating movement.\nOne is to create a temporal network from real data and check the change in\ntravel time according to time zones or seasons. Temporal networks are difficult\nto evaluate because of their time complexity, and in this study, we proposed an\nevaluation method using the probability density function of travel time. The\nother method is to define a time-dependent traveling salesman problem and find\nan efficient traveling route by finding the shortest path. By creating a\ntime-dependent traveling salesman problem in an existing city and solving it, a\ntraveler can choose an efficient route by considering traffic conditions at\ndifferent times of the day. We used 2 months of data from Kyoto City to conduct\na traffic evaluation as a case study.",
    "descriptor": "\nComments: 10 pages, 7 figures, 6 tables\n",
    "authors": [
      "Tatsuro Mukai",
      "Yuichi Ikeda"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00328"
  },
  {
    "id": "arXiv:2106.00329",
    "title": "Consistent Two-Flow Network for Tele-Registration of Point Clouds",
    "abstract": "Rigid registration of partial observations is a fundamental problem in\nvarious applied fields. In computer graphics, special attention has been given\nto the registration between two partial point clouds generated by scanning\ndevices. State-of-the-art registration techniques still struggle when the\noverlap region between the two point clouds is small, and completely fail if\nthere is no overlap between the scan pairs. In this paper, we present a\nlearning-based technique that alleviates this problem, and allows registration\nbetween point clouds, presented in arbitrary poses, and having little or even\nno overlap, a setting that has been referred to as tele-registration. Our\ntechnique is based on a novel neural network design that learns a prior of a\nclass of shapes and can complete a partial shape. The key idea is combining the\nregistration and completion tasks in a way that reinforces each other. In\nparticular, we simultaneously train the registration network and completion\nnetwork using two coupled flows, one that register-and-complete, and one that\ncomplete-and-register, and encourage the two flows to produce a consistent\nresult. We show that, compared with each separate flow, this two-flow training\nleads to robust and reliable tele-registration, and hence to a better point\ncloud prediction that completes the registered scans. It is also worth\nmentioning that each of the components in our neural network outperforms\nstate-of-the-art methods in both completion and registration. We further\nanalyze our network with several ablation studies and demonstrate its\nperformance on a large number of partial point clouds, both synthetic and\nreal-world, that have only small or no overlap.",
    "descriptor": "\nComments: Accepted to TVCG 2021, project page at this https URL\n",
    "authors": [
      "Zihao Yan",
      "Zimu Yi",
      "Ruizhen Hu",
      "Niloy J. Mitra",
      "Daniel Cohen-Or",
      "Hui Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00329"
  },
  {
    "id": "arXiv:2106.00334",
    "title": "An In-depth Study on Internal Structure of Chinese Words",
    "abstract": "Unlike English letters, Chinese characters have rich and specific meanings.\nUsually, the meaning of a word can be derived from its constituent characters\nin some way. Several previous works on syntactic parsing propose to annotate\nshallow word-internal structures for better utilizing character-level\ninformation. This work proposes to model the deep internal structures of\nChinese words as dependency trees with 11 labels for distinguishing syntactic\nrelationships. First, based on newly compiled annotation guidelines, we\nmanually annotate a word-internal structure treebank (WIST) consisting of over\n30K multi-char words from Chinese Penn Treebank. To guarantee quality, each\nword is independently annotated by two annotators and inconsistencies are\nhandled by a third senior annotator. Second, we present detailed and\ninteresting analysis on WIST to reveal insights on Chinese word formation.\nThird, we propose word-internal structure parsing as a new task, and conduct\nbenchmark experiments using a competitive dependency parser. Finally, we\npresent two simple ways to encode word-internal structures, leading to\npromising gains on the sentence-level syntactic parsing task.",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021 (long paper)\n",
    "authors": [
      "Chen Gong",
      "Saihao Huang",
      "Houquan Zhou",
      "Zhenghua Li",
      "Min Zhang",
      "Zhefeng Wang",
      "Baoxing Huai",
      "Nicholas Jing Yuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00334"
  },
  {
    "id": "arXiv:2106.00339",
    "title": "Studying Duplicate Logging Statements and Their Relationships with Code  Clones",
    "abstract": "In this paper, we focus on studying duplicate logging statements, which are\nlogging statements that have the same static text message. We manually studied\nover 4K duplicate logging statements and their surrounding code in five\nlarge-scale open source systems. We uncovered five patterns of duplicate\nlogging code smells. For each instance of the duplicate logging code smell, we\nfurther manually identify the potentially problematic and justifiable cases.\nThen, we contact developers to verify our manual study result. We integrated\nour manual study result and the feedback of developers into our automated\nstatic analysis tool, DLFinder, which automatically detects problematic\nduplicate logging code smells. We evaluated DLFinder on the five manually\nstudied systems and three additional systems. In total, combining the results\nof DLFinder and our manual analysis, we reported 91 problematic duplicate\nlogging code smell instances to developers and all of them have been fixed. We\nfurther study the relationship between duplicate logging statements, including\nthe problematic instances of duplicate logging code smells, and code clones. We\nfind that 83% of the duplicate logging code smell instances reside in cloned\ncode, but 17% of them reside in micro-clones that are difficult to detect using\nautomated clone detection tools. We also find that more than half of the\nduplicate logging statements reside in cloned code snippets, and a large\nportion of them reside in very short code blocks which may not be effectively\ndetected by existing code clone detection tools. Our study shows that, in\naddition to general source code that implements the business logic, code clones\nmay also result in bad logging practices that could increase maintenance\ndifficulties.",
    "descriptor": "\nComments: Accepted at IEEE Transactions on Software Engineering\n",
    "authors": [
      "Zhenhao Li",
      "Tse-Hsun",
      "Chen",
      "Jinqiu Yang",
      "Weiyi Shang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.00339"
  },
  {
    "id": "arXiv:2106.00343",
    "title": "Reinforce Security: A Model-Free Approach Towards Secure Wiretap Coding",
    "abstract": "The use of deep learning-based techniques for approximating secure encoding\nfunctions has attracted considerable interest in wireless communications due to\nimpressive results obtained for general coding and decoding tasks for wireless\ncommunication systems. Of particular importance is the development of\nmodel-free techniques that work without knowledge about the underlying channel.\nSuch techniques utilize for example generative adversarial networks to estimate\nand model the conditional channel distribution, mutual information estimation\nas a reward function, or reinforcement learning. In this paper, the approach of\nreinforcement learning is studied and, in particular, the policy gradient\nmethod for a model-free approach of neural network-based secure encoding is\ninvestigated. Previously developed techniques for enforcing a certain co-set\nstructure on the encoding process can be combined with recent reinforcement\nlearning approaches. This new approach is evaluated by extensive simulations,\nand it is demonstrated that the resulting decoding performance of an\neavesdropper is capped at a certain error level.",
    "descriptor": "\nComments: Accepted for ICC 2021, 6 pages\n",
    "authors": [
      "Rick Fritschek",
      "Rafael F. Schaefer",
      "Gerhard Wunder"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00343"
  },
  {
    "id": "arXiv:2106.00344",
    "title": "UniStore: A fault-tolerant marriage of causal and strong consistency  (extended version)",
    "abstract": "Modern online services rely on data stores that replicate their data across\ngeographically distributed data centers. Providing strong consistency in such\ndata stores results in high latencies and makes the system vulnerable to\nnetwork partitions. The alternative of relaxing consistency violates crucial\ncorrectness properties. A compromise is to allow multiple consistency levels to\ncoexist in the data store. In this paper we present UniStore, the first\nfault-tolerant and scalable data store that combines causal and strong\nconsistency. The key challenge we address in UniStore is to maintain liveness\ndespite data center failures: this could be compromised if a strong transaction\ntakes a dependency on a causal transaction that is later lost because of a\nfailure. UniStore ensures that such situations do not arise while paying the\ncost of durability for causal transactions only when necessary. We evaluate\nUniStore on Amazon EC2 using both microbenchmarks and a sample application. Our\nresults show that UniStore effectively and scalably combines causal and strong\nconsistency.",
    "descriptor": "\nComments: Extended version of a paper from USENIX ATC'21: Annual Technical Conference\n",
    "authors": [
      "Manuel Bravo",
      "Alexey Gotsman",
      "Borja de R\u00e9gil",
      "Hengfeng Wei"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.00344"
  },
  {
    "id": "arXiv:2106.00352",
    "title": "Replicating and Extending \"\\textit{Because Their Treebanks Leak}\": Graph  Isomorphism, Covariants, and Parser Performance",
    "abstract": "S{\\o}gaard (2020) obtained results suggesting the fraction of trees occurring\nin the test data isomorphic to trees in the training set accounts for a\nnon-trivial variation in parser performance. Similar to other statistical\nanalyses in NLP, the results were based on evaluating linear regressions.\nHowever, the study had methodological issues and was undertaken using a small\nsample size leading to unreliable results. We present a replication study in\nwhich we also bin sentences by length and find that only a small subset of\nsentences vary in performance with respect to graph isomorphism. Further, the\ncorrelation observed between parser performance and graph isomorphism in the\nwild disappears when controlling for covariants. However, in a controlled\nexperiment, where covariants are kept fixed, we do observe a strong\ncorrelation. We suggest that conclusions drawn from statistical analyses like\nthis need to be tempered and that controlled experiments can complement them by\nmore readily teasing factors apart.",
    "descriptor": "\nComments: To appear in the Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics\n",
    "authors": [
      "Mark Anderson",
      "Anders S\u00f8gaard",
      "Carlos G\u00f3mez Rodr\u00edguez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00352"
  },
  {
    "id": "arXiv:2106.00355",
    "title": "Refined Transformation Approach for Stabilization of MIMO System by Pole  Placement",
    "abstract": "The paper presents a distinctive and straightforward technique for\nstabilization of multi-variable systems. The idea is to decouple the system\nstate matrix depending on different inputs and outputs. Refined special\ncanonical transformations are described for the design of controller and\nobserver for a single-input and single-output (SISO) case and are extended to\nmulti-input multi-output (MIMO) systems. These transformations help in the\nstabilization of the error dynamics of the observer and in placing the closed\nloop poles of the system. The idea is not only in the transformations taken but\nalso how the gain matrices are selected which simplifies the computation.",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Justin Jacob",
      "Sreya Das",
      "Navin Khaneja"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00355"
  },
  {
    "id": "arXiv:2106.00357",
    "title": "Experiments with graph convolutional networks for solving the vertex  $p$-center problem",
    "abstract": "In the last few years, graph convolutional networks (GCN) have become a\npopular research direction in the machine learning community to tackle NP-hard\ncombinatorial optimization problems (COPs) defined on graphs. While the\nobtained results are usually still not competitive with problem-specific\nsolution approaches from the operations research community, GCNs often lead to\nimprovements compared to previous machine learning approaches for classical\nCOPs such as the traveling salesperson problem (TSP).\nIn this work we present a preliminary study on using GCNs for solving the\nvertex p-center problem (PCP), which is another classic COP on graphs. In\nparticular, we investigate whether a successful model based on end-to-end\ntraining for the TSP can be adapted to a PCP, which is defined on a similar 2D\nEuclidean graph input as the usually used version of the TSP. However, the\nobjective of the PCP has a min-max structure which could lead to many symmetric\noptimal, i.e., ground-truth solutions and other potential difficulties for\nlearning. Our obtained preliminary results show that indeed a direct transfer\nof network architecture ideas does not seem to work too well. Thus we think\nthat the PCP could be an interesting benchmark problem for new ideas and\ndevelopments in the area of GCNs.",
    "descriptor": "",
    "authors": [
      "Elisabeth Gaar",
      "Markus Sinnl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00357"
  },
  {
    "id": "arXiv:2106.00358",
    "title": "Towards Efficient Cross-Modal Visual Textual Retrieval using  Transformer-Encoder Deep Features",
    "abstract": "Cross-modal retrieval is an important functionality in modern search engines,\nas it increases the user experience by allowing queries and retrieved objects\nto pertain to different modalities. In this paper, we focus on the\nimage-sentence retrieval task, where the objective is to efficiently find\nrelevant images for a given sentence (image-retrieval) or the relevant\nsentences for a given image (sentence-retrieval). Computer vision literature\nreports the best results on the image-sentence matching task using deep neural\nnetworks equipped with attention and self-attention mechanisms. They evaluate\nthe matching performance on the retrieval task by performing sequential scans\nof the whole dataset. This method does not scale well with an increasing amount\nof images or captions. In this work, we explore different preprocessing\ntechniques to produce sparsified deep multi-modal features extracting them from\nstate-of-the-art deep-learning architectures for image-text matching. Our main\nobjective is to lay down the paths for efficient indexing of complex\nmulti-modal descriptions. We use the recently introduced TERN architecture as\nan image-sentence features extractor. It is designed for producing fixed-size\n1024-d vectors describing whole images and sentences, as well as\nvariable-length sets of 1024-d vectors describing the various building\ncomponents of the two modalities (image regions and sentence words\nrespectively). All these vectors are enforced by the TERN design to lie into\nthe same common space. Our experiments show interesting preliminary results on\nthe explored methods and suggest further experimentation in this important\nresearch direction.",
    "descriptor": "\nComments: Accepted at CBMI 2021\n",
    "authors": [
      "Nicola Messina",
      "Giuseppe Amato",
      "Fabrizio Falchi",
      "Claudio Gennaro",
      "St\u00e9phane Marchand-Maillet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00358"
  },
  {
    "id": "arXiv:2106.00359",
    "title": "Learning Football Body-Orientation as a Matter of Classification",
    "abstract": "Orientation is a crucial skill for football players that becomes a\ndifferential factor in a large set of events, especially the ones involving\npasses. However, existing orientation estimation methods, which are based on\ncomputer-vision techniques, still have a lot of room for improvement. To the\nbest of our knowledge, this article presents the first deep learning model for\nestimating orientation directly from video footage. By approaching this\nchallenge as a classification problem where classes correspond to orientation\nbins, and by introducing a cyclic loss function, a well-known convolutional\nnetwork is refined to provide player orientation data. The model is trained by\nusing ground-truth orientation data obtained from wearable EPTS devices, which\nare individually compensated with respect to the perceived orientation in the\ncurrent frame. The obtained results outperform previous methods; in particular,\nthe absolute median error is less than 12 degrees per player. An ablation study\nis included in order to show the potential generalization to any kind of\nfootball video footage.",
    "descriptor": "\nComments: Accepted in the AI for Sports Analytics Workshop at ICJAI 2021\n",
    "authors": [
      "Adri\u00e0 Arbu\u00e9s-Sang\u00fcesa",
      "Adri\u00e1n Mart\u00edn",
      "Paulino Granero",
      "Coloma Ballester",
      "Gloria Haro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.00359"
  },
  {
    "id": "arXiv:2106.00365",
    "title": "Scientific Computing in the Cavendish Laboratory and the pioneering  women Computors",
    "abstract": "The use of computers and the role of women in radio astronomy and X-ray\ncrystallography research at the Cavendish Laboratory between 1949 and 1975 have\nbeen investigated. We recorded examples of when computers were used, what they\nwere used for and who used them from hundreds of papers published during these\nyears. The use of the EDSAC, EDSAC 2 and TITAN computers was found to increase\nconsiderably over this time-scale and they were used for a diverse range of\napplications. The majority of references to computer operators and programmers\nreferred to women, 57% for astronomy and 62% for crystallography, in contrast\nto a very small proportion, 4% and 13% respectively, of female authors of\npapers.",
    "descriptor": "\nComments: 11 pages, 8 figures, submitted to IEEE Annals in the History of Computing, (C) IEEE 2021\n",
    "authors": [
      "Verity Allan",
      "Caitriona Leedham"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2106.00365"
  },
  {
    "id": "arXiv:2106.00368",
    "title": "Natural Statistics of Network Activations and Implications for Knowledge  Distillation",
    "abstract": "In a matter that is analog to the study of natural image statistics, we study\nthe natural statistics of the deep neural network activations at various\nlayers. As we show, these statistics, similar to image statistics, follow a\npower law. We also show, both analytically and empirically, that with depth the\nexponent of this power law increases at a linear rate.\nAs a direct implication of our discoveries, we present a method for\nperforming Knowledge Distillation (KD). While classical KD methods consider the\nlogits of the teacher network, more recent methods obtain a leap in performance\nby considering the activation maps. This, however, uses metrics that are\nsuitable for comparing images. We propose to employ two additional loss terms\nthat are based on the spectral properties of the intermediate activation maps.\nThe proposed method obtains state of the art results on multiple image\nrecognition KD benchmarks.",
    "descriptor": "\nComments: Accepted to ICIP 2021\n",
    "authors": [
      "Michael Rotman",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00368"
  },
  {
    "id": "arXiv:2106.00369",
    "title": "Rate-Splitting Multiple Access in Cache-Aided Cloud-Radio Access  Networks",
    "abstract": "Rate-splitting multiple access (RSMA) has been recognized as a promising\nphysical layer strategy for 6G. Motivated by ever increasing popularity of\ncache-enabled content delivery in wireless communications, this paper proposes\nan innovative multigroup multicast transmission scheme based on RSMA for\ncache-aided cloud-radio access networks (C-RAN). Our proposed scheme not only\nexploits the properties of content-centric communications and local caching at\nthe base stations (BSs), but also incorporates RSMA to better manage\ninterference in multigroup multicast transmission with statistical channel\nstate information (CSI) known at the central processor (CP) and the BSs. At the\nRSMA-enabled cloud CP, the message of each multicast group is split into a\nprivate and a common part with the former private part being decoded by all\nusers in the respective group and the latter common part being decoded by\nmultiple users from other multicast groups. Common message decoding is done for\nthe purpose of mitigating the interference. In this work, we jointly optimize\nthe clustering of BSs and the precoding with the aim of maximizing the minimum\nrate among all multicast groups to guarantee fairness serving all groups. The\nproblem is a mixed-integer non-linear stochastic program (MINLSP), which is\nsolved by a practical algorithm we proposed including a heuristic clustering\nalgorithm for assigning a set of BSs to serve each user followed by an\nefficient iterative algorithm that combines the sample average approximation\n(SAA) and weighted minimum mean square error (WMMSE) to solve the stochastic\nnon-convex sub-problem of precoder design. Numerical results show the explicit\nmax-min rate gain of our proposed transmission scheme compared to the\nstate-of-the-art trivial interference processing methods. Therefore, we\nconclude that RSMA is a promising technique for cache-aided C-RAN.",
    "descriptor": "\nComments: 38 pages, 9 figures, 2 tables\n",
    "authors": [
      "Robert-Jeron Reifert",
      "Alaa Alameer Ahmad",
      "Yijie Mao",
      "Aydin Sezgin",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00369"
  },
  {
    "id": "arXiv:2106.00371",
    "title": "Markov Localisation using Heatmap Regression and Deep Convolutional  Odometry",
    "abstract": "In the context of self-driving vehicles there is strong competition between\napproaches based on visual localisation and LiDAR. While LiDAR provides\nimportant depth information, it is sparse in resolution and expensive. On the\nother hand, cameras are low-cost and recent developments in deep learning mean\nthey can provide high localisation performance. However, several fundamental\nproblems remain, particularly in the domain of uncertainty, where learning\nbased approaches can be notoriously over-confident.\nMarkov, or grid-based, localisation was an early solution to the localisation\nproblem but fell out of favour due to its computational complexity.\nRepresenting the likelihood field as a grid (or volume) means there is a trade\noff between accuracy and memory size. Furthermore, it is necessary to perform\nexpensive convolutions across the entire likelihood volume. Despite the benefit\nof simultaneously maintaining a likelihood for all possible locations, grid\nbased approaches were superseded by more efficient particle filters and Monte\nCarlo Localisation (MCL). However, MCL introduces its own problems e.g.\nparticle deprivation.\nRecent advances in deep learning hardware allow large likelihood volumes to\nbe stored directly on the GPU, along with the hardware necessary to efficiently\nperform GPU-bound 3D convolutions and this obviates many of the disadvantages\nof grid based methods. In this work, we present a novel CNN-based localisation\napproach that can leverage modern deep learning hardware. By implementing a\ngrid-based Markov localisation approach directly on the GPU, we create a hybrid\nCNN that can perform image-based localisation and odometry-based likelihood\npropagation within a single neural network. The resulting approach is capable\nof outperforming direct pose regression methods as well as state-of-the-art\nlocalisation systems.",
    "descriptor": "\nComments: IEEE International Conference on Robotics and Automation (ICRA) 2021\n",
    "authors": [
      "Oscar Mendez",
      "Simon Hadfield",
      "Richard Bowden"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00371"
  },
  {
    "id": "arXiv:2106.00374",
    "title": "Fault-Tolerant Labeling and Compact Routing Schemes",
    "abstract": "The paper presents fault-tolerant (FT) labeling schemes for general graphs,\nas well as, improved FT routing schemes. For a given $n$-vertex graph $G$ and a\nbound $f$ on the number of faults, an $f$-FT connectivity labeling scheme is a\ndistributed data structure that assigns each of the graph edges and vertices a\nshort label, such that given the labels of the vertices $s$ and $t$, and at\nmost $f$ failing edges $F$, one can determine if $s$ and $t$ are connected in\n$G \\setminus F$. The primary complexity measure is the length of the individual\nlabels. Since their introduction by [Courcelle, Twigg, STACS '07], compact FT\nlabeling schemes have been devised only for a limited collection of graph\nfamilies. In this work, we fill in this gap by proposing two (independent) FT\nconnectivity labeling schemes for general graphs, with a nearly optimal label\nlength. This serves the basis for providing also FT approximate distance\nlabeling schemes, and ultimately also routing schemes. Our main results for an\n$n$-vertex graph and a fault bound $f$ are:\n-- There is a randomized FT connectivity labeling scheme with a label length\nof $O(f+\\log n)$ bits, hence optimal for $f=O(\\log n)$. This scheme is based on\nthe notion of cycle space sampling [Pritchard, Thurimella, TALG '11].\n-- There is a randomized FT connectivity labeling scheme with a label length\nof $O(\\log^3 n)$ bits (independent of the number of faults $f$). This scheme is\nbased on the notion of linear sketches of [Ahn et al., SODA '12].\n-- For $k\\geq 1$, there is a randomized routing scheme that routes a message\nfrom $s$ to $t$ in the presence of a set $F$ of faulty edges, with stretch\n$O(|F|^2 k)$ and routing tables of size $\\tilde{O}(f^3 n^{1/k})$.\nThis significantly improves over the state-of-the-art bounds by [Chechik,\nICALP '11], providing the first scheme with sub-linear FT labeling and routing\nschemes for general graphs.",
    "descriptor": "\nComments: PODC 2021\n",
    "authors": [
      "Michal Dory",
      "Merav Parter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.00374"
  },
  {
    "id": "arXiv:2106.00376",
    "title": "DLA-Net: Learning Dual Local Attention Features for Semantic  Segmentation of Large-Scale Building Facade Point Clouds",
    "abstract": "Semantic segmentation of building facade is significant in various\napplications, such as urban building reconstruction and damage assessment. As\nthere is a lack of 3D point clouds datasets related to the fine-grained\nbuilding facade, we construct the first large-scale building facade point\nclouds benchmark dataset for semantic segmentation. The existing methods of\nsemantic segmentation cannot fully mine the local neighborhood information of\npoint clouds. Addressing this problem, we propose a learnable attention module\nthat learns Dual Local Attention features, called DLA in this paper. The\nproposed DLA module consists of two blocks, including the self-attention block\nand attentive pooling block, which both embed an enhanced position encoding\nblock. The DLA module could be easily embedded into various network\narchitectures for point cloud segmentation, naturally resulting in a new 3D\nsemantic segmentation network with an encoder-decoder architecture, called\nDLA-Net in this work. Extensive experimental results on our constructed\nbuilding facade dataset demonstrate that the proposed DLA-Net achieves better\nperformance than the state-of-the-art methods for semantic segmentation.",
    "descriptor": "",
    "authors": [
      "Yanfei Su",
      "Weiquan Liu",
      "Zhimin Yuan",
      "Ming Cheng",
      "Zhihong Zhang",
      "Xuelun Shen",
      "Cheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00376"
  },
  {
    "id": "arXiv:2106.00379",
    "title": "Large-scale, Dynamic and Distributed Coalition Formation with Spatial  and Temporal Constraints",
    "abstract": "The Coalition Formation with Spatial and Temporal constraints Problem (CFSTP)\nis a multi-agent task allocation problem in which few agents have to perform\nmany tasks, each with its deadline and workload. To maximize the number of\ncompleted tasks, the agents need to cooperate by forming, disbanding and\nreforming coalitions. The original mathematical programming formulation of the\nCFSTP is difficult to implement, since it is lengthy and based on the\nproblematic Big-M method. In this paper, we propose a compact and\neasy-to-implement formulation. Moreover, we design D-CTS, a distributed version\nof the state-of-the-art CFSTP algorithm. Using public London Fire Brigade\nrecords, we create a dataset with $347588$ tasks and a test framework that\nsimulates the mobilization of firefighters in dynamic environments. In problems\nwith up to $150$ agents and $3000$ tasks, compared to DSA-SDP, a\nstate-of-the-art distributed algorithm, D-CTS completes $3.79\\% \\pm [42.22\\%,\n1.96\\%]$ more tasks, and is one order of magnitude more efficient in terms of\ncommunication overhead and time complexity. D-CTS sets the first large-scale,\ndynamic and distributed CFSTP benchmark.",
    "descriptor": "\nComments: 18 pages, 3 figures, accepted at EUMAS 2021\n",
    "authors": [
      "Luca Capezzuto",
      "Danesh Tarapore",
      "Sarvapali D. Ramchurn"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00379"
  },
  {
    "id": "arXiv:2106.00387",
    "title": "Decision Concept Lattice vs. Decision Trees and Random Forests",
    "abstract": "Decision trees and their ensembles are very popular models of supervised\nmachine learning. In this paper we merge the ideas underlying decision trees,\ntheir ensembles and FCA by proposing a new supervised machine learning model\nwhich can be constructed in polynomial time and is applicable for both\nclassification and regression problems. Specifically, we first propose a\npolynomial-time algorithm for constructing a part of the concept lattice that\nis based on a decision tree. Second, we describe a prediction scheme based on a\nconcept lattice for solving both classification and regression tasks with\nprediction quality comparable to that of state-of-the-art models.",
    "descriptor": "\nComments: 8 pages, 2 figures. The final authenticated version is going to be published in Braud, A., Buzmakov, A., Hanika, T., Le Ber, F. (eds.) ICFCA 2021. LNCS (LNAI), vol. 12733, pp. 1-9. Springer, Heidelberg (2021). this https URL\n",
    "authors": [
      "Egor Dudyrev",
      "Sergei O. Kuznetsov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00387"
  },
  {
    "id": "arXiv:2106.00388",
    "title": "Privacy and Confidentiality in Process Mining -- Threats and Research  Challenges",
    "abstract": "Privacy and confidentiality are very important prerequisites for applying\nprocess mining in order to comply with regulations and keep company secrets.\nThis paper provides a foundation for future research on privacy-preserving and\nconfidential process mining techniques. Main threats are identified and related\nto an motivation application scenario in a hospital context as well as to the\ncurrent body of work on privacy and confidentiality in process mining. A newly\ndeveloped conceptual model structures the discussion that existing techniques\nleave room for improvement. This results in a number of important research\nchallenges that should be addressed by future process mining research.",
    "descriptor": "\nComments: Accepted for publication in ACM Transactions on Management Information Systems\n",
    "authors": [
      "Gamal Elkoumy",
      "Stephan A. Fahrenkrog-Petersen",
      "Mohammadreza Fani Sani",
      "Agnes Koschmider",
      "Felix Mannhardt",
      "Saskia Nu\u00f1ez von Voigt",
      "Majid Rafiei",
      "Leopold von Waldthausen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.00388"
  },
  {
    "id": "arXiv:2106.00389",
    "title": "Analysis of Vision-based Abnormal Red Blood Cell Classification",
    "abstract": "Identification of abnormalities in red blood cells (RBC) is key to diagnosing\na range of medical conditions from anaemia to liver disease. Currently this is\ndone manually, a time-consuming and subjective process. This paper presents an\nautomated process utilising the advantages of machine learning to increase\ncapacity and standardisation of cell abnormality detection, and its performance\nis analysed. Three different machine learning technologies were used: a Support\nVector Machine (SVM), a classical machine learning technology; TabNet, a deep\nlearning architecture for tabular data; U-Net, a semantic segmentation network\ndesigned for medical image segmentation. A critical issue was the highly\nimbalanced nature of the dataset which impacts the efficacy of machine\nlearning. To address this, synthesising minority class samples in feature space\nwas investigated via Synthetic Minority Over-sampling Technique (SMOTE) and\ncost-sensitive learning. A combination of these two methods is investigated to\nimprove the overall performance. These strategies were found to increase\nsensitivity to minority classes. The impact of unknown cells on semantic\nsegmentation is demonstrated, with some evidence of the model applying learning\nof labelled cells to these anonymous cells. These findings indicate both\nclassical models and new deep learning networks as promising methods in\nautomating RBC abnormality detection.",
    "descriptor": "",
    "authors": [
      "Annika Wong",
      "Nantheera Anantrasirichai",
      "Thanarat H. Chalidabhongse",
      "Duangdao Palasuwan",
      "Attakorn Palasuwan",
      "David Bull"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00389"
  },
  {
    "id": "arXiv:2106.00390",
    "title": "On the KLM properties of a fuzzy DL with Typicality",
    "abstract": "The paper investigates the properties of a fuzzy logic of typicality. The\nextension of fuzzy logic with a typicality operator was proposed in recent work\nto define a fuzzy multipreference semantics for Multilayer Perceptrons, by\nregarding the deep neural network as a conditional knowledge base. In this\npaper, we study its properties. First, a monotonic extension of a fuzzy ALC\nwith typicality is considered (called ALCFT) and a reformulation the KLM\nproperties of a preferential consequence relation for this logic is devised.\nMost of the properties are satisfied, depending on the reformulation and on the\nfuzzy combination functions considered. We then strengthen ALCFT with a closure\nconstruction by introducing a notion of faithful model of a weighted knowledge\nbase, which generalizes the notion of coherent model of a conditional knowledge\nbase previously introduced, and we study its properties.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Laura Giordano"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00390"
  },
  {
    "id": "arXiv:2106.00391",
    "title": "A Question of Time: Revisiting the Use of Recursive Filtering for  Temporal Calibration of Multisensor Systems",
    "abstract": "We examine the problem of time delay estimation, or temporal calibration, in\nthe context of multisensor data fusion. Differences in processing intervals and\nother factors typically lead to a relative delay between measurement from two\ndisparate sensors. Correct (optimal) data fusion demands that the relative\ndelay must either be known in advance or identified online. There have been\nseveral recent proposals in the literature to determine the delay parameter\nusing recursive, causal filters such as the extended Kalman filter (EKF). We\ncarefully review this formulation and show that there are fundamental issues\nwith the structure of the EKF (and related algorithms) when the delay is\nincluded in the filter state vector as a value to be estimated. These\nstructural issues, in turn, leave recursive filters prone to bias and\ninconsistency. Our theoretical analysis is supported by simulation studies that\ndemonstrate the implications in terms of filter performance; although tuning of\nthe filter noise variances may reduce the chance of inconsistency or\ndivergence, the underlying structural concerns remain. We offer brief\nsuggestions for ways to maintain the computational efficiency of recursive\nfiltering for temporal calibration while avoiding the drawbacks of the standard\nalgorithms.",
    "descriptor": "\nComments: Submitted to the 2021 IEEE International Conference on Multisensor Fusion and Integration (MFI 2021)\n",
    "authors": [
      "Jonathan Kelly",
      "Christopher Grebe",
      "Matthew Giamou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.00391"
  },
  {
    "id": "arXiv:2106.00393",
    "title": "Learning Representations for Sub-Symbolic Reasoning",
    "abstract": "Neuro-symbolic methods integrate neural architectures, knowledge\nrepresentation and reasoning. However, they have been struggling at both\ndealing with the intrinsic uncertainty of the observations and scaling to real\nworld applications. This paper presents Relational Reasoning Networks (R2N), a\nnovel end-to-end model that performs relational reasoning in the latent space\nof a deep learner architecture, where the representations of constants, ground\natoms and their manipulations are learned in an integrated fashion. Unlike flat\narchitectures like Knowledge Graph Embedders, which can only represent\nrelations between entities, R2Ns define an additional computational structure,\naccounting for higher-level relations among the ground atoms. The considered\nrelations can be explicitly known, like the ones defined by logic formulas, or\ndefined as unconstrained correlations among groups of ground atoms. R2Ns can be\napplied to purely symbolic tasks or as a neuro-symbolic platform to integrate\nlearning and reasoning in heterogeneous problems with both symbolic and\nfeature-based represented entities. The proposed model bridges the gap between\nprevious neuro-symbolic methods that have been either limited in terms of\nscalability or expressivity. The proposed methodology is shown to achieve\nstate-of-the-art results in different experimental settings.",
    "descriptor": "",
    "authors": [
      "Giuseppe Marra",
      "Michelangelo Diligenti",
      "Francesco Giannini",
      "Marco Maggini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00393"
  },
  {
    "id": "arXiv:2106.00394",
    "title": "Improving Conditional Coverage via Orthogonal Quantile Regression",
    "abstract": "We develop a method to generate prediction intervals that have a\nuser-specified coverage level across all regions of feature-space, a property\ncalled conditional coverage. A typical approach to this task is to estimate the\nconditional quantiles with quantile regression -- it is well-known that this\nleads to correct coverage in the large-sample limit, although it may not be\naccurate in finite samples. We find in experiments that traditional quantile\nregression can have poor conditional coverage. To remedy this, we modify the\nloss function to promote independence between the size of the intervals and the\nindicator of a miscoverage event. For the true conditional quantiles, these two\nquantities are independent (orthogonal), so the modified loss function\ncontinues to be valid. Moreover, we empirically show that the modified loss\nfunction leads to improved conditional coverage, as evaluated by several\nmetrics. We also introduce two new metrics that check conditional coverage by\nlooking at the strength of the dependence between the interval size and the\nindicator of miscoverage.",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Shai Feldman",
      "Stephen Bates",
      "Yaniv Romano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00394"
  },
  {
    "id": "arXiv:2106.00396",
    "title": "Distance and Position Estimation in Visible Light Systems with RGB LEDs",
    "abstract": "In this manuscript, distance and position estimation problems are\ninvestigated for visible light positioning (VLP) systems with red-green-blue\n(RGB) light emitting diodes (LEDs). The accuracy limits on distance and\nposition estimation are calculated in terms of the Cramer-Rao lower bound\n(CRLB) for three different scenarios. Scenario~1 and Scenario~2 correspond to\nsynchronous and asynchronous systems, respectively, with known channel\nattenuation formulas at the receiver. In Scenario~3, a synchronous system is\nconsidered but channel attenuation formulas are not known at the receiver. The\nderived CRLB expressions reveal the relations among distance/position\nestimation accuracies in the considered scenarios and lead to intuitive\nexplanations for the benefits of using RGB LEDs. In addition, maximum\nlikelihood (ML) estimators are derived in all scenarios, and it is shown that\nthey can achieve close performance to the CRLBs in some cases for sufficiently\nhigh source optical powers.",
    "descriptor": "\nComments: 13 pages, 9 figures, partially presented at IEEE PIMRC 2019\n",
    "authors": [
      "Ilker Demirel",
      "Sinan Gezici"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00396"
  },
  {
    "id": "arXiv:2106.00399",
    "title": "Computing Least and Greatest Fixed Points in Absorptive Semirings",
    "abstract": "We present two methods to algorithmically compute both least and greatest\nsolutions of polynomial equation systems over absorptive semirings (with\ncertain completeness and continuity assumptions), such as the tropical\nsemiring. Both methods require a polynomial number of semiring operations,\nincluding semiring addition, multiplication and an infinitary power operation.\nOur main result is a closed-form solution for least and greatest fixed points\nbased on the fixed-point iteration. The proof builds on the notion of (possibly\ninfinite) derivation trees; a careful analysis of the shape of these trees\nallows us to collapse the fixed-point iteration to a linear number of steps.\nThe second method is an iterative symbolic computation in the semiring of\nabsorptive polynomials, largely based on results on Kleene algebras.",
    "descriptor": "\nComments: submitted to RAMiCS, full version\n",
    "authors": [
      "Matthias Naaf"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.00399"
  },
  {
    "id": "arXiv:2106.00400",
    "title": "SHUOWEN-JIEZI: Linguistically Informed Tokenizers For Chinese Language  Model Pretraining",
    "abstract": "Conventional tokenization methods for Chinese pretrained language models\n(PLMs) treat each character as an indivisible token (Devlin et al., 2019),\nwhich ignores the characteristics of the Chinese writing system. In this work,\nwe comprehensively study the influences of three main factors on the Chinese\ntokenization for PLM: pronunciation, glyph (i.e., shape), and word boundary.\nCorrespondingly, we propose three kinds of tokenizers: 1) SHUOWEN (meaning Talk\nWord), the pronunciation-based tokenizers; 2) JIEZI (meaning Solve Character),\nthe glyph-based tokenizers; 3) Word segmented tokenizers, the tokenizers with\nChinese word segmentation. To empirically compare the effectiveness of studied\ntokenizers, we pretrain BERT-style language models with them and evaluate the\nmodels on various downstream NLU tasks. We find that SHUOWEN and JIEZI\ntokenizers can generally outperform conventional single-character tokenizers,\nwhile Chinese word segmentation shows no benefit as a preprocessing step.\nMoreover, the proposed SHUOWEN and JIEZI tokenizers exhibit significantly\nbetter robustness in handling noisy texts. The code and pretrained models will\nbe publicly released to facilitate linguistically informed Chinese NLP.",
    "descriptor": "\nComments: Work in progress. Feedback is welcome\n",
    "authors": [
      "Chenglei Si",
      "Zhengyan Zhang",
      "Yingfa Chen",
      "Fanchao Qi",
      "Xiaozhi Wang",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00400"
  },
  {
    "id": "arXiv:2106.00402",
    "title": "A note on the network coloring game",
    "abstract": "The network coloring game has been proposed in the literature of social\nsciences as a model for conflict-resolution circumstances. The players of the\ngame are the vertices of a graph with $n$ vertices and maximum degree $\\Delta$.\nThe game is played over rounds, and in each round all players simultaneously\nchoose a color from a set of available colors. Players have local information\nof the graph: they only observe the colors chosen by their neighbors and do not\ncommunicate or cooperate with one another. A player is happy when she has\nchosen a color that is different from the colors chosen by her neighbors,\notherwise she is unhappy, and a configuration of colors for which all players\nare happy is a proper coloring of the graph. It has been shown in the\nliterature that, when the players adopt a particular greedy randomized\nstrategy, the game reaches a proper coloring of the graph within $O(\\log(n))$\nrounds, with high probability, provided the number of colors available to each\nplayer is at least $\\Delta+2$. In this note we show that a modification of the\naforementioned greedy strategy yields likewise a proper coloring of the graph,\nprovided the number of colors available to each player is at least $\\Delta+1$.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Nikolaos Fryganiotis",
      "Symeon Papavassiliou",
      "Christos Pelekis"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.00402"
  },
  {
    "id": "arXiv:2106.00407",
    "title": "Electric field measurements made on a robotic platform",
    "abstract": "This presentation reports the first known data from a field mill mounted on a\nground-based robotic platform. The robot's motor and electrostatic charging of\nits wheels do not perturb the field mill data, and electric field varies\nsmoothly whilst the robot is moving. Test measurements under a charged\npolystyrene plate are reduced in variability by a factor of 2 compared to a\nhand-held field mill. This technology has potential for autonomous measurements\nin inaccessible or hazardous environments.",
    "descriptor": "\nComments: Proc. Electrostatics Society of America, 14-16 June 2021\n",
    "authors": [
      "Karen Aplin",
      "Zihao Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2106.00407"
  },
  {
    "id": "arXiv:2106.00410",
    "title": "Nora: The Well-Being Coach",
    "abstract": "The current pandemic has forced people globally to remain in isolation and\npractice social distancing, which creates the need for a system to combat the\nresulting loneliness and negative emotions. In this paper we propose Nora, a\nvirtual coaching platform designed to utilize natural language understanding in\nits dialogue system and suggest other recommendations based on user\ninteractions. It is intended to provide assistance and companionship to people\nundergoing self-quarantine or work-from-home routines. Nora helps users gauge\ntheir well-being by detecting and recording the user's emotion, sentiment, and\nstress. Nora also recommends various workout, meditation, or yoga exercises to\nusers in support of developing a healthy daily routine. In addition, we provide\na social community inside Nora, where users can connect and share their\nexperiences with others undergoing a similar isolation procedure. Nora can be\naccessed from anywhere via a web link and has support for both English and\nMandarin.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Genta Indra Winata",
      "Holy Lovenia",
      "Etsuko Ishii",
      "Farhad Bin Siddique",
      "Yongsheng Yang",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00410"
  },
  {
    "id": "arXiv:2106.00411",
    "title": "WebMIaS on Docker: Deploying Math-Aware Search in a Single Line of Code",
    "abstract": "Math informational retrieval (MIR) search engines are absent in the\nwide-spread production use, even though documents in the STEM fields contain\nmany mathematical formulae, which are sometimes more important than text for\nunderstanding. We have developed and open-sourced the WebMIaS MIR search engine\nthat has been successfully deployed in the European Digital Mathematics Library\n(EuDML). However, its deployment is difficult to automate due to the complexity\nof this task. Moreover, the solutions developed so far to tackle this challenge\nare imperfect in terms of speed, maintenance, and robustness. In this paper, we\nwill describe the virtualization of WebMIaS using Docker that solves all three\nproblems and allows anyone to deploy containerized WebMIaS in a single line of\ncode. The publicly available Docker image will also help the community push the\ndevelopment of math-aware search engines in the ARQMath workshop series.",
    "descriptor": "\nComments: Accepted to be published in: Intelligent Computer Mathematics 14th International Conference, CICM 2021, Timisoara, Romania, July 26--31, 2021, Proceedings, Fairouz Kamareddine and Claudio Sacerdotti-Coen (eds.), Lecture Notes in Artificial Intelligence, Springer, Cham, 2021\n",
    "authors": [
      "D\u00e1vid Lupt\u00e1k",
      "V\u00edt Novotn\u00fd",
      "Michal \u0160tef\u00e1nik",
      "Petr Sojka"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.00411"
  },
  {
    "id": "arXiv:2106.00412",
    "title": "Curating Covid-19 data in Links",
    "abstract": "Curated scientific databases play an important role in the scientific\nendeavour and support is needed for the significant effort that goes into their\ncreation and maintenance. This demonstration and case study illustrate how\ncuration support has been developed in the Links cross-tier programming\nlanguage, a functional, strongly typed language with language-integrated query\nand support for temporal databases. The chosen case study uses weekly released\nCovid-19 fatality figures from the Scottish government which exhibit updates to\npreviously released data. This data allows the capture and query of update\nprovenance in our prototype. This demonstration will highlight the potential\nfor language-integrated support for curation to simplify and streamline\nprototyping of web-applications in support of scientific databases",
    "descriptor": "",
    "authors": [
      "Vashti Galpin",
      "James Cheney"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Digital Libraries (cs.DL)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.00412"
  },
  {
    "id": "arXiv:2106.00415",
    "title": "Age of Loop for Wireless Networked Control Systems Optimization",
    "abstract": "Joint design of control and communication in Wireless Networked Control\nSystems (WNCS) is a promising approach for future wireless industrial\napplications. In this context, Age of Information (AoI) has been increasingly\nutilized as a metric that is more representative than latency in the context of\nsystems with a sense-compute-actuate cycle. Nevertheless, AoI is commonly\ndefined for a single communication direction, Downlink or Uplink, which does\nnot capture the closed-loop dynamics. In this paper, we extend the concept of\nAoI by defining a new metric, Age of Loop (AoL), relevant for WNCS closed-loop\nsystems. The AoL is defined as the time elapsed since the piece of information\ncausing the latest action or state (depending on the selected time origin) was\ngenerated. We then use the proposed metric to learn the WNCS latency and\nfreshness bounds and we apply such learning methodology to minimize the long\nterm WNCS cost with the least amount of bandwidth. We show that, using the AoL,\nwe can learn the control system requirement and use this information to\noptimize network resources.",
    "descriptor": "\nComments: 7 pages, 7 Figures, Conference paper submitted to IEEE PIMRC 2021\n",
    "authors": [
      "Pedro M. de Sant Ana",
      "Nikolaj Marchenko",
      "Petar Popovski",
      "Beatriz Soret"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00415"
  },
  {
    "id": "arXiv:2106.00417",
    "title": "Semi-supervised Models are Strong Unsupervised Domain Adaptation  Learners",
    "abstract": "Unsupervised domain adaptation (UDA) and semi-supervised learning (SSL) are\ntwo typical strategies to reduce expensive manual annotations in machine\nlearning. In order to learn effective models for a target task, UDA utilizes\nthe available labeled source data, which may have different distributions from\nunlabeled samples in the target domain, while SSL employs few manually\nannotated target samples. Although UDA and SSL are seemingly very different\nstrategies, we find that they are closely related in terms of task objectives\nand solutions, and SSL is a special case of UDA problems. Based on this\nfinding, we further investigate whether SSL methods work on UDA tasks. By\nadapting eight representative SSL algorithms on UDA benchmarks, we show that\nSSL methods are strong UDA learners. Especially, state-of-the-art SSL methods\nsignificantly outperform existing UDA methods on the challenging UDA benchmark\nof DomainNet, and state-of-the-art UDA methods could be further enhanced with\nSSL techniques. We thus promote that SSL methods should be employed as\nbaselines in future UDA studies and expect that the revealed relationship\nbetween UDA and SSL could shed light on future UDA development. Codes are\navailable at \\url{https://github.com/YBZh}.",
    "descriptor": "\nComments: Codes are available at this https URL\n",
    "authors": [
      "Yabin Zhang",
      "Haojian Zhang",
      "Bin Deng",
      "Shuai Li",
      "Kui Jia",
      "Lei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00417"
  },
  {
    "id": "arXiv:2106.00420",
    "title": "Dialogue-oriented Pre-training",
    "abstract": "Pre-trained language models (PrLM) has been shown powerful in enhancing a\nbroad range of downstream tasks including various dialogue related ones.\nHowever, PrLMs are usually trained on general plain text with common language\nmodel (LM) training objectives, which cannot sufficiently capture dialogue\nexclusive features due to the limitation of such training setting, so that\nthere is an immediate need to fill the gap between a specific dialogue task and\nthe LM task. As it is unlikely to collect huge dialogue data for\ndialogue-oriented pre-training, in this paper, we propose three strategies to\nsimulate the conversation features on general plain text. Our proposed method\ndiffers from existing post-training methods that it may yield a general-purpose\nPrLM and does not individualize to any detailed task while keeping the\ncapability of learning dialogue related features including speaker awareness,\ncontinuity and consistency. The resulted Dialog-PrLM is fine-tuned on three\npublic multi-turn dialogue datasets and helps achieve significant and\nconsistent improvement over the plain PrLMs.",
    "descriptor": "",
    "authors": [
      "Yi Xu",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00420"
  },
  {
    "id": "arXiv:2106.00421",
    "title": "OpenBox: A Generalized Black-box Optimization Service",
    "abstract": "Black-box optimization (BBO) has a broad range of applications, including\nautomatic machine learning, engineering, physics, and experimental design.\nHowever, it remains a challenge for users to apply BBO methods to their\nproblems at hand with existing software packages, in terms of applicability,\nperformance, and efficiency. In this paper, we build OpenBox, an open-source\nand general-purpose BBO service with improved usability. The modular design\nbehind OpenBox also facilitates flexible abstraction and optimization of basic\nBBO components that are common in other existing systems. OpenBox is\ndistributed, fault-tolerant, and scalable. To improve efficiency, OpenBox\nfurther utilizes \"algorithm agnostic\" parallelization and transfer learning.\nOur experimental results demonstrate the effectiveness and efficiency of\nOpenBox compared to existing systems.",
    "descriptor": "",
    "authors": [
      "Yang Li",
      "Yu Shen",
      "Wentao Zhang",
      "Yuanwei Chen",
      "Huaijun Jiang",
      "Mingchao Liu",
      "Jiawei Jiang",
      "Jinyang Gao",
      "Wentao Wu",
      "Zhi Yang",
      "Ce Zhang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00421"
  },
  {
    "id": "arXiv:2106.00424",
    "title": "Assembly Planning by Recognizing a Graphical Instruction Manual",
    "abstract": "This paper proposes a robot assembly planning method by automatically reading\nthe graphical instruction manuals design for humans. Essentially, the method\ngenerates an Assembly Task Sequence Graph (ATSG) by recognizing a graphical\ninstruction manual. An ATSG is a graph describing the assembly task procedure\nby detecting types of parts included in the instruction images, completing the\nmissing information automatically, and correcting the detection errors\nautomatically. To build an ATSG, the proposed method first extracts the\ninformation of the parts contained in each image of the graphical instruction\nmanual. Then, by using the extracted part information, it estimates the proper\nwork motions and tools for the assembly task. After that, the method builds an\nATSG by considering the relationship between the previous and following images,\nwhich makes it possible to estimate the undetected parts caused by occlusion\nusing the information of the entire image series. Finally, by collating the\ntotal number of each part with the generated ATSG, the excess or deficiency of\nparts are investigated, and task procedures are removed or added according to\nthose parts. In the experiment section, we build an ATSG using the proposed\nmethod to a graphical instruction manual for a chair and demonstrate the action\nsequences found in the ATSG can be performed by a dual-arm robot execution. The\nresults show the proposed method is effective and simplifies robot teaching in\nautomatic assembly.",
    "descriptor": "",
    "authors": [
      "Issei Sera",
      "Natsuki Yamanobe",
      "Ixchel G. Ramirez-Alpizar",
      "Zhenting Wang",
      "Weiwei Wan",
      "Kensuke Harada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.00424"
  },
  {
    "id": "arXiv:2106.00433",
    "title": "Low-Complexity Symbol-Level Precoding for MU-MISO Downlink Systems with  QAM Signals",
    "abstract": "This study proposes the construction of a transmit signal for large-scale\nantenna systems with cost-effective 1-bit digital-to-analog converters in the\ndownlink. Under quadrature-amplitude-modulation constellations, it is still an\nopen problem to overcome a severe error floor problem caused by its nature\nproperty. To this end, we first present a feasibility condition which\nguarantees that each user's noiseless signal is placed in the desired decision\nregion. For robustness to additive noise, we formulate an optimization problem,\nwe then transform the feasibility conditions to cascaded matrix form. We\npropose a low-complexity algorithm to generate a 1-bit transmit signal based on\nthe proposed optimization problem formulated as a well-defined\nmixed-integer-linear-programming. Numerical results validate the superiority of\nthe proposed method in terms of detection performance and computational\ncomplexity.",
    "descriptor": "\nComments: 6 pages, 6 figures, Globecom 2021\n",
    "authors": [
      "Sungyeal Park",
      "Yunseong Cho",
      "Songnam Hong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00433"
  },
  {
    "id": "arXiv:2106.00434",
    "title": "Noise will be noise: Or phase optimized recursive filters for  interference suppression, signal differentiation and state estimation  (extended version)",
    "abstract": "The increased temporal and spectral resolution of oversampled systems allows\nmany sensor-signal analysis tasks to be performed (e.g. detection,\nclassification and tracking) using a filterbank of low-pass digital\ndifferentiators. Such filters are readily designed via flatness constraints on\nthe derivatives of the complex frequency response at dc, pi and at the centre\nfrequencies of narrowband interferers, i.e. using maximally-flat (MaxFlat)\ndesigns. Infinite-impulse-response (IIR) filters are ideal in embedded online\nsystems with high data-rates because computational complexity is independent of\ntheir (fading) memory. A novel procedure for the design of MaxFlat IIR\nfilterbanks with improved passband phase linearity is presented in this paper,\nas a possible alternative to Kalman and Wiener filters in a class of\nderivative-state estimation problems with uncertain signal models. Butterworth\npoles are used for configurable bandwidth and guaranteed stability. Flatness\nconstraints of arbitrary order are derived for temporal derivatives of\narbitrary order and a prescribed group delay. As longer lags (in samples) are\nreadily accommodated in oversampled systems, an expression for the optimal\ngroup delay that minimizes the white-noise gain (i.e. the error variance of the\nderivative estimate at steady state) is derived. Filter zeros are optimally\nplaced for the required passband phase response and the cancellation of\nnarrowband interferers in the stopband, by solving a linear system of\nequations. Low complexity filterbank realizations are discussed then their\nbehaviour is analysed in a Teager-Kaiser operator to detect pulsed signals and\nin a state observer to track manoeuvring targets in simulated scenarios.",
    "descriptor": "",
    "authors": [
      "Hugh L. Kennedy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00434"
  },
  {
    "id": "arXiv:2106.00444",
    "title": "Minimax Regret for Bandit Convex Optimisation of Ridge Functions",
    "abstract": "We analyse adversarial bandit convex optimisation with an adversary that is\nrestricted to playing functions of the form $f(x) = g(\\langle x,\n\\theta\\rangle)$ for convex $g : \\mathbb R \\to \\mathbb R$ and $\\theta \\in\n\\mathbb R^d$. We provide a short information-theoretic proof that the minimax\nregret is at most $O(d\\sqrt{n} \\log(\\operatorname{diam}\\mathcal K))$ where $n$\nis the number of interactions, $d$ the dimension and\n$\\operatorname{diam}(\\mathcal K)$ is the diameter of the constraint set. Hence,\nthis class of functions is at most logarithmically harder than the linear case.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Tor Lattimore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00444"
  },
  {
    "id": "arXiv:2106.00445",
    "title": "Sample Selection with Uncertainty of Losses for Learning with Noisy  Labels",
    "abstract": "In learning with noisy labels, the sample selection approach is very popular,\nwhich regards small-loss data as correctly labeled during training. However,\nlosses are generated on-the-fly based on the model being trained with noisy\nlabels, and thus large-loss data are likely but not certainly to be incorrect.\nThere are actually two possibilities of a large-loss data point: (a) it is\nmislabeled, and then its loss decreases slower than other data, since deep\nneural networks \"learn patterns first\"; (b) it belongs to an underrepresented\ngroup of data and has not been selected yet. In this paper, we incorporate the\nuncertainty of losses by adopting interval estimation instead of point\nestimation of losses, where lower bounds of the confidence intervals of losses\nderived from distribution-free concentration inequalities, but not losses\nthemselves, are used for sample selection. In this way, we also give large-loss\nbut less selected data a try; then, we can better distinguish between the cases\n(a) and (b) by seeing if the losses effectively decrease with the uncertainty\nafter the try. As a result, we can better explore underrepresented data that\nare correctly labeled but seem to be mislabeled at first glance. Experiments\ndemonstrate that the proposed method is superior to baselines and robust to a\nbroad range of label noise types.",
    "descriptor": "",
    "authors": [
      "Xiaobo Xia",
      "Tongliang Liu",
      "Bo Han",
      "Mingming Gong",
      "Jun Yu",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00445"
  },
  {
    "id": "arXiv:2106.00446",
    "title": "PanoDR: Spherical Panorama Diminished Reality for Indoor Scenes",
    "abstract": "The rising availability of commercial $360^\\circ$ cameras that democratize\nindoor scanning, has increased the interest for novel applications, such as\ninterior space re-design. Diminished Reality (DR) fulfills the requirement of\nsuch applications, to remove existing objects in the scene, essentially\ntranslating this to a counterfactual inpainting task. While recent advances in\ndata-driven inpainting have shown significant progress in generating realistic\nsamples, they are not constrained to produce results with reality mapped\nstructures. To preserve the `reality' in indoor (re-)planning applications, the\nscene's structure preservation is crucial. To ensure structure-aware\ncounterfactual inpainting, we propose a model that initially predicts the\nstructure of an indoor scene and then uses it to guide the reconstruction of an\nempty -- background only -- representation of the same scene. We train and\ncompare against other state-of-the-art methods on a version of the Structured3D\ndataset modified for DR, showing superior results in both quantitative metrics\nand qualitative results, but more interestingly, our approach exhibits a much\nfaster convergence rate. Code and models are available at\nhttps://vcl3d.github.io/PanoDR/ .",
    "descriptor": "\nComments: Accepted at CVPR, OmniCV Workshop. Code and models are available at this https URL\n",
    "authors": [
      "V. Gkitsas",
      "V. Sterzentsenko",
      "N. Zioulis",
      "G. Albanis",
      "D. Zarpalas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00446"
  },
  {
    "id": "arXiv:2106.00451",
    "title": "Highlight Timestamp Detection Model for Comedy Videos via Multimodal  Sentiment Analysis",
    "abstract": "Nowadays, the videos on the Internet are prevailing. The precise and in-depth\nunderstanding of the videos is a difficult but valuable problem for both\nplatforms and researchers. The existing video understand models do well in\nobject recognition tasks but currently still cannot understand the abstract and\ncontextual features like highlight humor frames in comedy videos. The current\nindustrial works are also mainly focused on the basic category classification\ntask based on the appearances of objects. The feature detection methods for the\nabstract category remains blank. A data structure that includes the information\nof video frames, audio spectrum and texts provide a new direction to explore.\nThe multimodal models are proposed to make this in-depth video understanding\nmission possible. In this paper, we analyze the difficulties in abstract\nunderstanding of videos and propose a multimodal structure to obtain\nstate-of-the-art performance in this field. Then we select several benchmarks\nfor multimodal video understanding and apply the most suitable model to find\nthe best performance. At last, we evaluate the overall spotlights and drawbacks\nof the models and methods in this paper and point out the possible directions\nfor further improvements.",
    "descriptor": "",
    "authors": [
      "Fan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00451"
  },
  {
    "id": "arXiv:2106.00455",
    "title": "Instance Correction for Learning with Open-set Noisy Labels",
    "abstract": "The problem of open-set noisy labels denotes that part of training data have\na different label space that does not contain the true class. Lots of\napproaches, e.g., loss correction and label correction, cannot handle such\nopen-set noisy labels well, since they need training data and test data to\nshare the same label space, which does not hold for learning with open-set\nnoisy labels. The state-of-the-art methods thus employ the sample selection\napproach to handle open-set noisy labels, which tries to select clean data from\nnoisy data for network parameters updates. The discarded data are seen to be\nmislabeled and do not participate in training. Such an approach is intuitive\nand reasonable at first glance. However, a natural question could be raised\n\"can such data only be discarded during training?\". In this paper, we show that\nthe answer is no. Specifically, we discuss that the instances of discarded data\ncould consist of some meaningful information for generalization. For this\nreason, we do not abandon such data, but use instance correction to modify the\ninstances of the discarded data, which makes the predictions for the discarded\ndata consistent with given labels. Instance correction are performed by\ntargeted adversarial attacks. The corrected data are then exploited for\ntraining to help generalization. In addition to the analytical results, a\nseries of empirical evidences are provided to justify our claims.",
    "descriptor": "",
    "authors": [
      "Xiaobo Xia",
      "Tongliang Liu",
      "Bo Han",
      "Mingming Gong",
      "Jun Yu",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00455"
  },
  {
    "id": "arXiv:2106.00459",
    "title": "KGPool: Dynamic Knowledge Graph Context Selection for Relation  Extraction",
    "abstract": "We present a novel method for relation extraction (RE) from a single\nsentence, mapping the sentence and two given entities to a canonical fact in a\nknowledge graph (KG). Especially in this presumed sentential RE setting, the\ncontext of a single sentence is often sparse. This paper introduces the KGPool\nmethod to address this sparsity, dynamically expanding the context with\nadditional facts from the KG. It learns the representation of these facts\n(entity alias, entity descriptions, etc.) using neural methods, supplementing\nthe sentential context. Unlike existing methods that statically use all\nexpanded facts, KGPool conditions this expansion on the sentence. We study the\nefficacy of KGPool by evaluating it with different neural models and KGs\n(Wikidata and NYT Freebase). Our experimental evaluation on standard datasets\nshows that by feeding the KGPool representation into a Graph Neural Network,\nthe overall method is significantly more accurate than state-of-the-art\nmethods.",
    "descriptor": "\nComments: ACL 2021 (findings)\n",
    "authors": [
      "Abhishek Nadgeri",
      "Anson Bastos",
      "Kuldeep Singh",
      "Isaiah Onando Mulang'",
      "Johannes Hoffart",
      "Saeedeh Shekarpour",
      "Vijay Saraswat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00459"
  },
  {
    "id": "arXiv:2106.00461",
    "title": "To trust or not to trust an explanation: using LEAF to evaluate local  linear XAI methods",
    "abstract": "The main objective of eXplainable Artificial Intelligence (XAI) is to provide\neffective explanations for black-box classifiers. The existing literature lists\nmany desirable properties for explanations to be useful, but there is no\nconsensus on how to quantitatively evaluate explanations in practice. Moreover,\nexplanations are typically used only to inspect black-box models, and the\nproactive use of explanations as a decision support is generally overlooked.\nAmong the many approaches to XAI, a widely adopted paradigm is Local Linear\nExplanations - with LIME and SHAP emerging as state-of-the-art methods. We show\nthat these methods are plagued by many defects including unstable explanations,\ndivergence of actual implementations from the promised theoretical properties,\nand explanations for the wrong label. This highlights the need to have standard\nand unbiased evaluation procedures for Local Linear Explanations in the XAI\nfield. In this paper we address the problem of identifying a clear and\nunambiguous set of metrics for the evaluation of Local Linear Explanations.\nThis set includes both existing and novel metrics defined specifically for this\nclass of explanations. All metrics have been included in an open Python\nframework, named LEAF. The purpose of LEAF is to provide a reference for end\nusers to evaluate explanations in a standardised and unbiased way, and to guide\nresearchers towards developing improved explainable techniques.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Elvio G. Amparore",
      "Alan Perotti",
      "Paolo Bajardi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00461"
  },
  {
    "id": "arXiv:2106.00463",
    "title": "Instance-optimal Mean Estimation Under Differential Privacy",
    "abstract": "Mean estimation under differential privacy is a fundamental problem, but\nworst-case optimal mechanisms do not offer meaningful utility guarantees in\npractice when the global sensitivity is very large. Instead, various heuristics\nhave been proposed to reduce the error on real-world data that do not resemble\nthe worst-case instance. This paper takes a principled approach, yielding a\nmechanism that is instance-optimal in a strong sense. In addition to its\ntheoretical optimality, the mechanism is also simple and practical, and adapts\nto a variety of data characteristics without the need of parameter tuning. It\neasily extends to the local and shuffle model as well.",
    "descriptor": "",
    "authors": [
      "Ziyue Huang",
      "Yuting Liang",
      "Ke Yi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.00463"
  },
  {
    "id": "arXiv:2106.00467",
    "title": "The zoo of Fairness metrics in Machine Learning",
    "abstract": "In the recent years, the problem of addressing fairness in Machine Learning\n(ML) and automatic decision-making has attracted a lot of attention in the\nscientific communities dealing with Artificial Intelligence. A plethora of\ndifferent definitions of fairness in ML have been proposed, that consider\ndifferent notions of what is a \"fair decision\" in situations impacting\nindividuals in the population. The precise differences, implications and\n\"orthogonality\" between these notions have not yet been fully analyzed in the\nliterature. In this work, we try to make some order out of this zoo of\ndefinitions.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Alessandro Castelnovo",
      "Riccardo Crupi",
      "Greta Greco",
      "Daniele Regoli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00467"
  },
  {
    "id": "arXiv:2106.00471",
    "title": "A Bayesian-network-based cybersecurity adversarial risk analysis  framework with numerical examples",
    "abstract": "Cybersecurity risk analysis plays an essential role in supporting\norganizations make effective decision about how to manage and control\ncybersecurity risk. Cybersecurity risk is a function of the interplay between\nthe defender, i.e., the organisation, and the attacker: decisions and actions\nmade by the defender second guess the decisions and actions taken by the\nattacker and vice versa. Insight into this game between these two agents\nprovides a means for the defender to identify and make optimal decisions. To\ndate, the adversarial risk analysis framework has provided a\ndecision-analytical approach to solve such game problems in the presence of\nuncertainty and uses Monte Carlo simulation to calculate and identify optimal\ndecisions. We propose an alternative framework to construct and solve a serial\nof sequential Defend-Attack models, that incorporates the adversarial risk\nanalysis approach, but uses a new class of influence diagrams algorithm, called\nhybrid Bayesian network inference, to identify optimal decision strategies.\nCompared to Monte Carlo simulation the proposed hybrid Bayesian network\ninference is more versatile because it provides an automated way to compute\nhybrid Defend-Attack models and extends their use to involve mixtures of\ncontinuous and discrete variables, of any kind. More importantly, the hybrid\nBayesian network approach is novel in that it supports dynamic decision making\nwhereby new real-time observations can update the Defend-Attack model in\npractice. We also extend the Defend-Attack model to support cases involving\nextra variables and longer decision sequence. Examples are presented,\nillustrating how the proposed framework can be adjusted for more complicated\nscenarios, including dynamic decision making.",
    "descriptor": "\nComments: 10 pages, 40 figures\n",
    "authors": [
      "Jiali Wang",
      "Martin Neil"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.00471"
  },
  {
    "id": "arXiv:2106.00472",
    "title": "Detecting Anomalies in Semantic Segmentation with Prototypes",
    "abstract": "Traditional semantic segmentation methods can recognize at test time only the\nclasses that are present in the training set. This is a significant limitation,\nespecially for semantic segmentation algorithms mounted on intelligent\nautonomous systems, deployed in realistic settings. Regardless of how many\nclasses the system has seen at training time, it is inevitable that unexpected,\nunknown objects will appear at test time. The failure in identifying such\nanomalies may lead to incorrect, even dangerous behaviors of the autonomous\nagent equipped with such segmentation model when deployed in the real world.\nCurrent state of the art of anomaly segmentation uses generative models,\nexploiting their incapability to reconstruct patterns unseen during training.\nHowever, training these models is expensive, and their generated artifacts may\ncreate false anomalies. In this paper we take a different route and we propose\nto address anomaly segmentation through prototype learning. Our intuition is\nthat anomalous pixels are those that are dissimilar to all class prototypes\nknown by the model. We extract class prototypes from the training data in a\nlightweight manner using a cosine similarity-based classifier. Experiments on\nStreetHazards show that our approach achieves the new state of the art, with a\nsignificant margin over previous works, despite the reduced computational\noverhead. Code is available at https://github.com/DarioFontanel/PAnS.",
    "descriptor": "\nComments: SAIAD CVPR21 Workshop\n",
    "authors": [
      "Dario Fontanel",
      "Fabio Cermelli",
      "Massimiliano Mancini",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00472"
  },
  {
    "id": "arXiv:2106.00473",
    "title": "SemEval-2021 Task 1: Lexical Complexity Prediction",
    "abstract": "This paper presents the results and main findings of SemEval-2021 Task 1 -\nLexical Complexity Prediction. We provided participants with an augmented\nversion of the CompLex Corpus (Shardlow et al 2020). CompLex is an English\nmulti-domain corpus in which words and multi-word expressions (MWEs) were\nannotated with respect to their complexity using a five point Likert scale.\nSemEval-2021 Task 1 featured two Sub-tasks: Sub-task 1 focused on single words\nand Sub-task 2 focused on MWEs. The competition attracted 198 teams in total,\nof which 54 teams submitted official runs on the test data to Sub-task 1 and 37\nto Sub-task 2.",
    "descriptor": "",
    "authors": [
      "Matthew Shardlow",
      "Richard Evans",
      "Gustavo Henrique Paetzold",
      "Marcos Zampieri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00473"
  },
  {
    "id": "arXiv:2106.00474",
    "title": "Gaussian Processes with Differential Privacy",
    "abstract": "Gaussian processes (GPs) are non-parametric Bayesian models that are widely\nused for diverse prediction tasks. Previous work in adding strong privacy\nprotection to GPs via differential privacy (DP) has been limited to protecting\nonly the privacy of the prediction targets (model outputs) but not inputs. We\nbreak this limitation by introducing GPs with DP protection for both model\ninputs and outputs. We achieve this by using sparse GP methodology and\npublishing a private variational approximation on known inducing points. The\napproximation covariance is adjusted to approximately account for the added\nuncertainty from DP noise. The approximation can be used to compute arbitrary\npredictions using standard sparse GP techniques. We propose a method for\nhyperparameter learning using a private selection protocol applied to\nvalidation set log-likelihood. Our experiments demonstrate that given\nsufficient amount of data, the method can produce accurate models under strong\nprivacy protection.",
    "descriptor": "",
    "authors": [
      "Antti Honkela"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00474"
  },
  {
    "id": "arXiv:2106.00477",
    "title": "Tight Accounting in the Shuffle Model of Differential Privacy",
    "abstract": "Shuffle model of differential privacy is a novel distributed privacy model\nbased on a combination of local privacy mechanisms and a trusted shuffler. It\nhas been shown that the additional randomisation provided by the shuffler\nimproves privacy bounds compared to the purely local mechanisms. Accounting\ntight bounds, especially for multi-message protocols, is complicated by the\ncomplexity brought by the shuffler. The recently proposed Fourier Accountant\nfor evaluating $(\\varepsilon,\\delta)$-differential privacy guarantees has been\nshown to give tighter bounds than commonly used methods for non-adaptive\ncompositions of various complex mechanisms. In this paper we show how to\ncompute tight privacy bounds using the Fourier Accountant for multi-message\nversions of several ubiquitous mechanisms in the shuffle model and demonstrate\nlooseness of the existing bounds in the literature.",
    "descriptor": "\nComments: 24 pages, 10 figures\n",
    "authors": [
      "Antti Koskela",
      "Mikko A. Heikkil\u00e4",
      "Antti Honkela"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00477"
  },
  {
    "id": "arXiv:2106.00479",
    "title": "DoT: An efficient Double Transformer for NLP tasks with tables",
    "abstract": "Transformer-based approaches have been successfully used to obtain\nstate-of-the-art accuracy on natural language processing (NLP) tasks with\nsemi-structured tables. These model architectures are typically deep, resulting\nin slow training and inference, especially for long inputs. To improve\nefficiency while maintaining a high accuracy, we propose a new architecture,\nDoT, a double transformer model, that decomposes the problem into two\nsub-tasks: A shallow pruning transformer that selects the top-K tokens,\nfollowed by a deep task-specific transformer that takes as input those K\ntokens. Additionally, we modify the task-specific attention to incorporate the\npruning scores. The two transformers are jointly trained by optimizing the\ntask-specific loss. We run experiments on three benchmarks, including\nentailment and question-answering. We show that for a small drop of accuracy,\nDoT improves training and inference time by at least 50%. We also show that the\npruning transformer effectively selects relevant tokens enabling the end-to-end\nmodel to maintain similar accuracy as slower baseline models. Finally, we\nanalyse the pruning and give some insight into its impact on the task model.",
    "descriptor": "\nComments: 11 pages, 4 figures, to be published in Findings of ACL-IJCNLP 2021\n",
    "authors": [
      "Syrine Krichene",
      "Thomas M\u00fcller",
      "Julian Martin Eisenschlos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00479"
  },
  {
    "id": "arXiv:2106.00480",
    "title": "New Placement Delivery Array Construction for Coded Caching with  Flexible Memory Size",
    "abstract": "Coded caching is an emerging technique to alleviate the network pressure in\ndata transmissions. In such a scheme, each file in the data center or library\nis usually divided into a number of packets to pursue a low broadcasting rate\nbased on the designed placements at each user's cache. However, the\nimplementation complexity of this scheme increases as the number of packets\nincreases. Therefore, it is crucial to design a scheme with a small\nsubpacketization, while maintaining a relatively low transmission rate. In this\npaper, a placement delivery array (PDA) scheme that works with flexible memory\nsizes is proposed, and then it is generalized to fit more scenarios. It is\nshown that the subpacketization level can be decreased while maintaining the\nsame number of users, memory ratio and transmission rate.",
    "descriptor": "",
    "authors": [
      "Xianzhang Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00480"
  },
  {
    "id": "arXiv:2106.00485",
    "title": "Robust a-posteriori error estimates for weak Galerkin method for the  convection-diffusion problem",
    "abstract": "We present a robust a posteriori error estimator for the weak Galerkin finite\nelement method applied to stationary convection-diffusion equations in the\nconvection-dominated regime. The estimator provides global upper and lower\nbounds of the error %measured in a suitable norm and is robust in the sense\nthat upper and lower bounds are uniformly bounded with respect to the diffusion\ncoefficient. Results of the numerical experiments are presented to illustrate\nthe performance of the error estimator.",
    "descriptor": "",
    "authors": [
      "Natasha Sharma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00485"
  },
  {
    "id": "arXiv:2106.00487",
    "title": "Dense Nested Attention Network for Infrared Small Target Detection",
    "abstract": "Single-frame infrared small target (SIRST) detection aims at separating small\ntargets from clutter backgrounds. With the advances of deep learning, CNN-based\nmethods have yielded promising results in generic object detection due to their\npowerful modeling capability. However, existing CNN-based methods cannot be\ndirectly applied for infrared small targets since pooling layers in their\nnetworks could lead to the loss of targets in deep layers. To handle this\nproblem, we propose a dense nested attention network (DNANet) in this paper.\nSpecifically, we design a dense nested interactive module (DNIM) to achieve\nprogressive interaction among high-level and low-level features. With the\nrepeated interaction in DNIM, infrared small targets in deep layers can be\nmaintained. Based on DNIM, we further propose a cascaded channel and spatial\nattention module (CSAM) to adaptively enhance multi-level features. With our\nDNANet, contextual information of small targets can be well incorporated and\nfully exploited by repeated fusion and enhancement. Moreover, we develop an\ninfrared small target dataset (namely, NUDT-SIRST) and propose a set of\nevaluation metrics to conduct comprehensive performance evaluation. Experiments\non both public and our self-developed datasets demonstrate the effectiveness of\nour method. Compared to other state-of-the-art methods, our method achieves\nbetter performance in terms of probability of detection (Pd), false-alarm rate\n(Fa), and intersection of union (IoU).",
    "descriptor": "",
    "authors": [
      "Boyang Li",
      "Chao Xiao",
      "Longguang Wang",
      "Yingqian Wang",
      "Zaiping Lin",
      "Miao Li",
      "Wei An",
      "Yulan Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00487"
  },
  {
    "id": "arXiv:2106.00489",
    "title": "Extended Tactile Perception: Vibration Sensing through Tools and Grasped  Objects",
    "abstract": "Humans display the remarkable ability to sense the world through tools and\nother held objects. For example, we are able to pinpoint impact locations on a\nheld rod and tell apart different textures using a rigid probe. In this work,\nwe consider how we can enable robots to have a similar capacity, i.e., to\nembody tools and extend perception using standard grasped objects. We propose\nthat vibro-tactile sensing using dynamic tactile sensors on the robot fingers,\nalong with machine learning models, enables robots to decipher contact\ninformation that is transmitted as vibrations along rigid objects. This paper\nreports on extensive experiments using the BioTac micro-vibration sensor and a\nnew event dynamic sensor, the NUSkin, capable of multi-taxel sensing at 4~kHz.\nWe demonstrate that fine localization on a held rod is possible using our\napproach (with errors less than 1 cm on a 20 cm rod). Next, we show that\nvibro-tactile perception can lead to reasonable grasp stability prediction\nduring object handover, and accurate food identification using a standard fork.\nWe find that multi-taxel vibro-tactile sensing at sufficiently high sampling\nrate (above 2 kHz) led to the best performance across the various tasks and\nobjects. Taken together, our results provides both evidence and guidelines for\nusing vibro-tactile perception to extend tactile perception, which we believe\nwill lead to enhanced competency with tools and better physical\nhuman-robot-interaction.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Tasbolat Taunyazov",
      "Luar Shui Song",
      "Eugene Lim",
      "Hian Hian See",
      "David Lee",
      "Benjamin C.K. Tee",
      "Harold Soh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00489"
  },
  {
    "id": "arXiv:2106.00490",
    "title": "Dynamic Scheduling for Over-the-Air Federated Edge Learning with Energy  Constraints",
    "abstract": "Machine learning and wireless communication technologies are jointly\nfacilitating an intelligent edge, where federated edge learning (FEEL) is a\npromising training framework. As wireless devices involved in FEEL are resource\nlimited in terms of communication bandwidth, computing power and battery\ncapacity, it is important to carefully schedule them to optimize the training\nperformance. In this work, we consider an over-the-air FEEL system with analog\ngradient aggregation, and propose an energy-aware dynamic device scheduling\nalgorithm to optimize the training performance under energy constraints of\ndevices, where both communication energy for gradient aggregation and\ncomputation energy for local training are included. The consideration of\ncomputation energy makes dynamic scheduling challenging, as devices are\nscheduled before local training, but the communication energy for over-the-air\naggregation depends on the l2-norm of local gradient, which is known after\nlocal training. We thus incorporate estimation methods into scheduling to\npredict the gradient norm. Taking the estimation error into account, we\ncharacterize the performance gap between the proposed algorithm and its offline\ncounterpart. Experimental results show that, under a highly unbalanced local\ndata distribution, the proposed algorithm can increase the accuracy by 4.9% on\nCIFAR-10 dataset compared with the myopic benchmark, while satisfying the\nenergy constraints.",
    "descriptor": "\nComments: Submitted to IEEE for possible publication\n",
    "authors": [
      "Yuxuan Sun",
      "Sheng Zhou",
      "Zhisheng Niu",
      "Deniz G\u00fcnd\u00fcz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00490"
  },
  {
    "id": "arXiv:2106.00497",
    "title": "Omnizart: A General Toolbox for Automatic Music Transcription",
    "abstract": "We present and release Omnizart, a new Python library that provides a\nstreamlined solution to automatic music transcription (AMT). Omnizart\nencompasses modules that construct the life-cycle of deep learning-based AMT,\nand is designed for ease of use with a compact command-line interface. To the\nbest of our knowledge, Omnizart is the first transcription toolkit which offers\nmodels covering a wide class of instruments ranging from solo, instrument\nensembles, percussion instruments to vocal, as well as models for chord\nrecognition and beat/downbeat tracking, two music information retrieval (MIR)\ntasks highly related to AMT.",
    "descriptor": "",
    "authors": [
      "Yu-Te Wu",
      "Yin-Jyun Luo",
      "Tsung-Ping Chen",
      "I-Chieh Wei",
      "Jui-Yang Hsu",
      "Yi-Chin Chuang",
      "Li Su"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00497"
  },
  {
    "id": "arXiv:2106.00498",
    "title": "A Unified Asymptotic Preserving and Well-balanced Scheme for the Euler  System with Multiscale Relaxation",
    "abstract": "The design and analysis of a unified asymptotic preserving (AP) and\nwell-balanced scheme for the Euler Equations with gravitational and frictional\nsource terms is presented in this paper. The asymptotic behaviour of the Euler\nsystem in the limit of zero Mach and Froude numbers, and large friction is\ncharacterised by an additional scaling parameter. Depending on the values of\nthis parameter, the Euler system relaxes towards a hyperbolic or a parabolic\nlimit equation. Standard Implicit-Explicit Runge-Kutta schemes are incapable of\nswitching between these asymptotic regimes. We propose a time\nsemi-discretisation to obtain a unified scheme which is AP for the two\ndifferent limits. A further reformulation of the semi-implicit scheme can be\nrecast as a fully-explicit method in which the mass update contains both\nhyperbolic and parabolic fluxes. A space-time fully-discrete scheme is derived\nusing a finite volume framework. A hydrostatic reconstruction strategy, an\nupwinding of the sources at the interfaces, and a careful choice of the central\ndiscretisation of the parabolic fluxes are used to achieve the well-balancing\nproperty for hydrostatic steady states. Results of several numerical case\nstudies are presented to substantiate the theoretical claims and to verify the\nrobustness of the scheme.",
    "descriptor": "",
    "authors": [
      "K. R. Arun",
      "M. Krishnan",
      "S. Samantaray"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00498"
  },
  {
    "id": "arXiv:2106.00501",
    "title": "A Unified Cognitive Learning Framework for Adapting to Dynamic  Environment and Tasks",
    "abstract": "Many machine learning frameworks have been proposed and used in wireless\ncommunications for realizing diverse goals. However, their incapability of\nadapting to the dynamic wireless environment and tasks and of self-learning\nlimit their extensive applications and achievable performance. Inspired by the\ngreat flexibility and adaptation of primate behaviors due to the brain\ncognitive mechanism, a unified cognitive learning (CL) framework is proposed\nfor the dynamic wireless environment and tasks. The mathematical framework for\nour proposed CL is established. Using the public and authoritative dataset, we\ndemonstrate that our proposed CL framework has three advantages, namely, the\ncapability of adapting to the dynamic environment and tasks, the self-learning\ncapability and the capability of 'good money driving out bad money' by taking\nmodulation recognition as an example. The proposed CL framework can enrich the\ncurrent learning frameworks and widen the applications.",
    "descriptor": "\nComments: This paper has been submitted to IEEE Wireless Communications Magazine(minor revision)\n",
    "authors": [
      "Qihui Wu",
      "Tianchen Ruan",
      "Fuhui Zhou",
      "Yang Huang",
      "Fan Xu",
      "Shijin Zhao",
      "Ya Liu",
      "Xuyang Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00501"
  },
  {
    "id": "arXiv:2106.00502",
    "title": "Automated Grading of Anatomical Objective Structured Practical Exams  Using Decision Trees",
    "abstract": "An Objective Structured Practical Examination (OSPE) is an effective and\nrobust, but resource-intensive, means of evaluating anatomical knowledge. Since\nmost OSPEs employ short answer or fill-in-the-blank style questions, the format\nrequires many people familiar with the content to mark the exams. However, the\nincreasing prevalence of online delivery for anatomy and physiology courses\ncould result in students losing the OSPE practice that they would receive in\nface-to-face learning sessions. The purpose of this study was to test the\naccuracy of Decision Trees (DTs) in marking OSPE questions as a potential first\nstep to creating an intelligent, online OSPE tutoring system. The study used\nthe results of the winter 2020 semester final OSPE from McMaster University's\nanatomy and physiology course in the Faculty of Health Sciences (HTHSCI\n2FF3/2LL3/1D06) as the data set. Ninety percent of the data set was used in a\n10-fold validation algorithm to train a DT for each of the 54 questions. Each\nDT was comprised of unique words that appeared in correct, student-written\nanswers. The remaining 10% of the data set was marked by the generated DTs.\nWhen the answers marked by the DT were compared to the answers marked by staff\nand faculty, the DT achieved an average accuracy of 94.49% across all 54\nquestions. This suggests that machine learning algorithms such as DTs are a\nhighly effective option for OSPE grading and are suitable for the development\nof an intelligent, online OSPE tutoring system.",
    "descriptor": "\nComments: 33 pages, 3 figures, 2 tables. Under review at Anatomical Education Sciences\n",
    "authors": [
      "Jason Bernard",
      "Ranil Sonnadara",
      "Anthony N. Saraco",
      "Josh P. Mitchell",
      "Alex B. Bak",
      "Ilana Bayer",
      "Bruce C. Wainman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00502"
  },
  {
    "id": "arXiv:2106.00506",
    "title": "A Novel Graph-Theoretic Deep Representation Learning Method for  Multi-Label Remote Sensing Image Retrieval",
    "abstract": "This paper presents a novel graph-theoretic deep representation learning\nmethod in the framework of multi-label remote sensing (RS) image retrieval\nproblems. The proposed method aims to extract and exploit multi-label\nco-occurrence relationships associated to each RS image in the archive. To this\nend, each training image is initially represented with a graph structure that\nprovides region-based image representation combining both local information and\nthe related spatial organization. Unlike the other graph-based methods, the\nproposed method contains a novel learning strategy to train a deep neural\nnetwork for automatically predicting a graph structure of each RS image in the\narchive. This strategy employs a region representation learning loss function\nto characterize the image content based on its multi-label co-occurrence\nrelationship. Experimental results show the effectiveness of the proposed\nmethod for retrieval problems in RS compared to state-of-the-art deep\nrepresentation learning methods. The code of the proposed method is publicly\navailable at https://git.tu-berlin.de/rsim/GT-DRL-CBIR .",
    "descriptor": "\nComments: Accepted at IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2021. Our code is available at this https URL\n",
    "authors": [
      "Gencer Sumbul",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00506"
  },
  {
    "id": "arXiv:2106.00507",
    "title": "Towards Quantifiable Dialogue Coherence Evaluation",
    "abstract": "Automatic dialogue coherence evaluation has attracted increasing attention\nand is crucial for developing promising dialogue systems. However, existing\nmetrics have two major limitations: (a) they are mostly trained in a simplified\ntwo-level setting (coherent vs. incoherent), while humans give Likert-type\nmulti-level coherence scores, dubbed as \"quantifiable\"; (b) their predicted\ncoherence scores cannot align with the actual human rating standards due to the\nabsence of human guidance during training. To address these limitations, we\npropose Quantifiable Dialogue Coherence Evaluation (QuantiDCE), a novel\nframework aiming to train a quantifiable dialogue coherence metric that can\nreflect the actual human rating standards. Specifically, QuantiDCE includes two\ntraining stages, Multi-Level Ranking (MLR) pre-training and Knowledge\nDistillation (KD) fine-tuning. During MLR pre-training, a new MLR loss is\nproposed for enabling the model to learn the coarse judgement of coherence\ndegrees. Then, during KD fine-tuning, the pretrained model is further finetuned\nto learn the actual human rating standards with only very few human-annotated\ndata. To advocate the generalizability even with limited fine-tuning data, a\nnovel KD regularization is introduced to retain the knowledge learned at the\npre-training stage. Experimental results show that the model trained by\nQuantiDCE presents stronger correlations with human judgements than the other\nstate-of-the-art metrics.",
    "descriptor": "\nComments: Long paper; ACL2021\n",
    "authors": [
      "Zheng Ye",
      "Liucun Lu",
      "Lishan Huang",
      "Liang Lin",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00507"
  },
  {
    "id": "arXiv:2106.00508",
    "title": "Differentially Private Densest Subgraph",
    "abstract": "Given a graph, the densest subgraph problem asks for a set of vertices such\nthat the average degree among these vertices is maximized. Densest subgraph has\nnumerous applications in learning, e.g., community detection in social\nnetworks, link spam detection, correlation mining, bioinformatics, and so on.\nAlthough there are efficient algorithms that output either exact or approximate\nsolutions to the densest subgraph problem, existing algorithms may violate the\nprivacy of the individuals in the network, e.g., leaking the\nexistence/non-existence of edges.\nIn this paper, we study the densest subgraph problem in the framework of the\ndifferential privacy, and we derive the first upper and lower bounds for this\nproblem. We show that there exists a linear-time $\\epsilon$-differentially\nprivate algorithm that finds a $2$-approximation of the densest subgraph with\nan extra poly-logarithmic additive error. Our algorithm not only reports the\napproximate density of the densest subgraph, but also reports the vertices that\nform the dense subgraph.\nOur upper bound almost matches the famous $2$-approximation by Charikar both\nin performance and in approximation ratio, but we additionally achieve\ndifferential privacy. In comparison with Charikar's algorithm, our algorithm\nhas an extra poly-logarithmic additive error. We partly justify the additive\nerror with a new lower bound, showing that for any differentially private\nalgorithm that provides a constant-factor approximation, a sub-logarithmic\nadditive error is inherent.\nWe also practically study our differentially private algorithm on real-world\ngraphs, and we show that in practice the algorithm finds a solution which is\nvery close to the optimal",
    "descriptor": "",
    "authors": [
      "Alireza Farhadi",
      "MohammadTaghi Hajiaghayi",
      "Elaine Shi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.00508"
  },
  {
    "id": "arXiv:2106.00509",
    "title": "Towards Efficient Compressive Data Collection in the Internet of Things",
    "abstract": "It is of paramount importance to achieve efficient data collection in the\nInternet of Things (IoT). Due to the inherent structural properties (e.g.,\nsparsity) existing in many signals of interest, compressive sensing (CS)\ntechnology has been extensively used for data collection in IoT to improve both\naccuracy and energy efficiency. Apart from the existing works which leverage CS\nas a channel coding scheme to deal with data loss during transmission, some\nrecent results have started to employ CS as a source coding strategy. The\nfrequently used projection matrices in these CS-based source coding schemes\ninclude dense random matrices (e.g., Gaussian matrices or Bernoulli matrices)\nand structured matrices (e.g., Toeplitz matrices). However, these matrices are\neither difficult to be implemented on resource-constrained IoT sensor nodes or\nhave limited applicability. To address these issues, in this paper, we design a\nnovel simple and efficient projection matrix, named sparse Gaussian matrix,\nwhich is easy and resource-saving to be implemented in practical IoT\napplications. We conduct both theoretical analysis and experimental evaluation\nof the designed sparse Gaussian matrix. The results demonstrate that employing\nthe designed projection matrix to perform CS-based source coding could\nsignificantly save time and memory cost while ensuring satisfactory signal\nrecovery performance.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Peng Sun",
      "Liantao Wu",
      "Zhi Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00509"
  },
  {
    "id": "arXiv:2106.00510",
    "title": "CIDER: Commonsense Inference for Dialogue Explanation and Reasoning",
    "abstract": "Commonsense inference to understand and explain human language is a\nfundamental research problem in natural language processing. Explaining human\nconversations poses a great challenge as it requires contextual understanding,\nplanning, inference, and several aspects of reasoning including causal,\ntemporal, and commonsense reasoning. In this work, we introduce CIDER -- a\nmanually curated dataset that contains dyadic dialogue explanations in the form\nof implicit and explicit knowledge triplets inferred using contextual\ncommonsense inference. Extracting such rich explanations from conversations can\nbe conducive to improving several downstream applications. The annotated\ntriplets are categorized by the type of commonsense knowledge present (e.g.,\ncausal, conditional, temporal). We set up three different tasks conditioned on\nthe annotated dataset: Dialogue-level Natural Language Inference, Span\nExtraction, and Multi-choice Span Selection. Baseline results obtained with\ntransformer-based models reveal that the tasks are difficult, paving the way\nfor promising future research. The dataset and the baseline implementations are\npublicly available at https://github.com/declare-lab/CIDER.",
    "descriptor": "\nComments: SIGDIAL 2021\n",
    "authors": [
      "Deepanway Ghosal",
      "Pengfei Hong",
      "Siqi Shen",
      "Navonil Majumder",
      "Rada Mihalcea",
      "Soujanya Poria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00510"
  },
  {
    "id": "arXiv:2106.00512",
    "title": "The Care Label Concept: A Certification Suite for Trustworthy and  Resource-Aware Machine Learning",
    "abstract": "Machine learning applications have become ubiquitous. This has led to an\nincreased effort of making machine learning trustworthy. Explainable and fair\nAI have already matured. They address knowledgeable users and application\nengineers. For those who do not want to invest time into understanding the\nmethod or the learned model, we offer care labels: easy to understand at a\nglance, allowing for method or model comparisons, and, at the same time,\nscientifically well-based. On one hand, this transforms descriptions as given\nby, e.g., Fact Sheets or Model Cards, into a form that is well-suited for\nend-users. On the other hand, care labels are the result of a certification\nsuite that tests whether stated guarantees hold. In this paper, we present two\nexperiments with our certification suite. One shows the care labels for\nconfigurations of Markov random fields (MRFs). Based on the underlying theory\nof MRFs, each choice leads to its specific rating of static properties like,\ne.g., expressivity and reliability. In addition, the implementation is tested\nand resource consumption is measured yielding dynamic properties. This\ntwo-level procedure is followed by another experiment certifying deep neural\nnetwork (DNN) models. There, we draw the static properties from the literature\non a particular model and data set. At the second level, experiments are\ngenerated that deliver measurements of robustness against certain attacks. We\nillustrate this by ResNet-18 and MobileNetV3 applied to ImageNet.",
    "descriptor": "",
    "authors": [
      "Katharina Morik",
      "Helena Kotthaus",
      "Lukas Heppe",
      "Danny Heinrich",
      "Raphael Fischer",
      "Andreas Pauly",
      "Nico Piatkowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00512"
  },
  {
    "id": "arXiv:2106.00515",
    "title": "KVT: k-NN Attention for Boosting Vision Transformers",
    "abstract": "Convolutional Neural Networks (CNNs) have dominated computer vision for\nyears, due to its ability in capturing locality and translation invariance.\nRecently, many vision transformer architectures have been proposed and they\nshow promising performance. A key component in vision transformers is the\nfully-connected self-attention which is more powerful than CNNs in modelling\nlong range dependencies. However, since the current dense self-attention uses\nall image patches (tokens) to compute attention matrix, it may neglect locality\nof images patches and involve noisy tokens (e.g., clutter background and\nocclusion), leading to a slow training process and potentially degradation of\nperformance. To address these problems, we propose a sparse attention scheme,\ndubbed k-NN attention, for boosting vision transformers. Specifically, instead\nof involving all the tokens for attention matrix calculation, we only select\nthe top-k similar tokens from the keys for each query to compute the attention\nmap. The proposed k-NN attention naturally inherits the local bias of CNNs\nwithout introducing convolutional operations, as nearby tokens tend to be more\nsimilar than others. In addition, the k-NN attention allows for the exploration\nof long range correlation and at the same time filter out irrelevant tokens by\nchoosing the most similar tokens from the entire image. Despite its simplicity,\nwe verify, both theoretically and empirically, that $k$-NN attention is\npowerful in distilling noise from input tokens and in speeding up training.\nExtensive experiments are conducted by using ten different vision transformer\narchitectures to verify that the proposed k-NN attention can work with any\nexisting transformer architectures to improve its prediction performance.",
    "descriptor": "",
    "authors": [
      "Pichao Wang",
      "Xue Wang",
      "Fan Wang",
      "Ming Lin",
      "Shuning Chang",
      "Wen Xie",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00515"
  },
  {
    "id": "arXiv:2106.00517",
    "title": "Cooperative Multi-Agent Transfer Learning with Level-Adaptive Credit  Assignment",
    "abstract": "Extending transfer learning to cooperative multi-agent reinforcement learning\n(MARL) has recently received much attention. In contrast to the single-agent\nsetting, the coordination indispensable in cooperative MARL constrains each\nagent's policy. However, existing transfer methods focus exclusively on agent\npolicy and ignores coordination knowledge. We propose a new architecture that\nrealizes robust coordination knowledge transfer through appropriate\ndecomposition of the overall coordination into several coordination patterns.\nWe use a novel mixing network named level-adaptive QTransformer\n(LA-QTransformer) to realize agent coordination that considers credit\nassignment, with appropriate coordination patterns for different agents\nrealized by a novel level-adaptive Transformer (LA-Transformer) dedicated to\nthe transfer of coordination knowledge. In addition, we use a novel agent\nnetwork named Population Invariant agent with Transformer (PIT) to realize the\ncoordination transfer in more varieties of scenarios. Extensive experiments in\nStarCraft II micro-management show that LA-QTransformer together with PIT\nachieves superior performance compared with state-of-the-art baselines.",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Tianze Zhou",
      "Fubiao Zhang",
      "Kun Shao",
      "Kai Li",
      "Wenhan Huang",
      "Jun Luo",
      "Weixun Wang",
      "Yaodong Yang",
      "Hangyu Mao",
      "Bin Wang",
      "Dong Li",
      "Wulong Liu",
      "Jianye Hao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00517"
  },
  {
    "id": "arXiv:2106.00524",
    "title": "Student Performance Prediction Using Dynamic Neural Models",
    "abstract": "We address the problem of predicting the correctness of the student's\nresponse on the next exam question based on their previous interactions in the\ncourse of their learning and evaluation process. We model the student\nperformance as a dynamic problem and compare the two major classes of dynamic\nneural architectures for its solution, namely the finite-memory Time Delay\nNeural Networks (TDNN) and the potentially infinite-memory Recurrent Neural\nNetworks (RNN). Since the next response is a function of the knowledge state of\nthe student and this, in turn, is a function of their previous responses and\nthe skills associated with the previous questions, we propose a two-part\nnetwork architecture. The first part employs a dynamic neural network (either\nTDNN or RNN) to trace the student knowledge state. The second part applies on\ntop of the dynamic part and it is a multi-layer feed-forward network which\ncompletes the classification task of predicting the student response based on\nour estimate of the student knowledge state. Both input skills and previous\nresponses are encoded using different embeddings. Regarding the skill\nembeddings we tried two different initialization schemes using (a) random\nvectors and (b) pretrained vectors matching the textual descriptions of the\nskills. Our experiments show that the performance of the RNN approach is better\ncompared to the TDNN approach in all datasets that we have used. Also, we show\nthat our RNN architecture outperforms the state-of-the-art models in four out\nof five datasets. It is worth noting that the TDNN approach also outperforms\nthe state of the art models in four out of five datasets, although it is\nslightly worse than our proposed RNN approach. Finally, contrary to our\nexpectations, we find that the initialization of skill embeddings using\npretrained vectors offers practically no advantage over random initialization.",
    "descriptor": "\nComments: 9 pages, 4 figures, to be published in EDM 2021: the 14th International Conference on Educational Data Mining, June 29 - July 2, 2021, Paris, France\n",
    "authors": [
      "Marina Delianidi",
      "Konstantinos Diamantaras",
      "George Chrysogonidis",
      "Vasileios Nikiforidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00524"
  },
  {
    "id": "arXiv:2106.00526",
    "title": "A Compression-Compilation Framework for On-mobile Real-time BERT  Applications",
    "abstract": "Transformer-based deep learning models have increasingly demonstrated high\naccuracy on many natural language processing (NLP) tasks. In this paper, we\npropose a compression-compilation co-design framework that can guarantee the\nidentified model to meet both resource and real-time specifications of mobile\ndevices. Our framework applies a compiler-aware neural architecture\noptimization method (CANAO), which can generate the optimal compressed model\nthat balances both accuracy and latency. We are able to achieve up to 7.8x\nspeedup compared with TensorFlow-Lite with only minor accuracy loss. We present\ntwo types of BERT applications on mobile devices: Question Answering (QA) and\nText Generation. Both can be executed in real-time with latency as low as 45ms.\nVideos for demonstrating the framework can be found on\nhttps://www.youtube.com/watch?v=_WIRvK_2PZI",
    "descriptor": "\nComments: Accepted to IJCAI-21 Demonstrations Track. arXiv admin note: substantial text overlap with arXiv:2009.06823\n",
    "authors": [
      "Wei Niu",
      "Zhenglun Kong",
      "Geng Yuan",
      "Weiwen Jiang",
      "Jiexiong Guan",
      "Caiwen Ding",
      "Pu Zhao",
      "Sijia Liu",
      "Bin Ren",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00526"
  },
  {
    "id": "arXiv:2106.00532",
    "title": "Topology and Admittance Estimation: Precision Limits and Algorithms",
    "abstract": "Distribution grid topology and admittance information are essential for\nsystem planning, operation, and protection. In many distribution grids, missing\nor inaccurate topology and admittance data call for efficient estimation\nmethods. However, measurement data may be insufficient or contaminated with\nlarge noise, which will introduce fundamental limits to the estimation\naccuracy. This work explores the theoretical precision limits of the topology\nand admittance estimation (TAE) problem, with different measurement devices,\nnoise levels, and the number of measurements. On this basis, we propose a\nconservative progressive self-adaptive (CPS) algorithm to estimate the topology\nand admittance. Results on IEEE 33 and 141-bus systems validate that the\nproposed CPS method can approach the theoretical precision limits under various\nmeasurement settings.",
    "descriptor": "",
    "authors": [
      "Yuxiao Liu",
      "Ning Zhang",
      "Qingchun Hou",
      "Audun Botterud",
      "Chongqing Kang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00532"
  },
  {
    "id": "arXiv:2106.00534",
    "title": "DeepWalk: Omnidirectional Bipedal Gait by Deep Reinforcement Learning",
    "abstract": "Bipedal walking is one of the most difficult but exciting challenges in\nrobotics. The difficulties arise from the complexity of high-dimensional\ndynamics, sensing and actuation limitations combined with real-time and\ncomputational constraints. Deep Reinforcement Learning (DRL) holds the promise\nto address these issues by fully exploiting the robot dynamics with minimal\ncraftsmanship. In this paper, we propose a novel DRL approach that enables an\nagent to learn omnidirectional locomotion for humanoid (bipedal) robots.\nNotably, the locomotion behaviors are accomplished by a single control policy\n(a single neural network). We achieve this by introducing a new curriculum\nlearning method that gradually increases the task difficulty by scheduling\ntarget velocities. In addition, our method does not require reference motions\nwhich facilities its application to robots with different kinematics, and\nreduces the overall complexity. Finally, different strategies for sim-to-real\ntransfer are presented which allow us to transfer the learned policy to a real\nhumanoid robot.",
    "descriptor": "\nComments: In: Proceedings of the International Conference on Robotics and Automation (ICRA) 2021\n",
    "authors": [
      "Diego Rodriguez",
      "Sven Behnke"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.00534"
  },
  {
    "id": "arXiv:2106.00537",
    "title": "Exploring the Diversity and Invariance in Yourself for Visual  Pre-Training Task",
    "abstract": "Recently, self-supervised learning methods have achieved remarkable success\nin visual pre-training task. By simply pulling the different augmented views of\neach image together or other novel mechanisms, they can learn much unsupervised\nknowledge and significantly improve the transfer performance of pre-training\nmodels. However, these works still cannot avoid the representation collapse\nproblem, i.e., they only focus on limited regions or the extracted features on\ntotally different regions inside each image are nearly the same. Generally,\nthis problem makes the pre-training models cannot sufficiently describe the\nmulti-grained information inside images, which further limits the upper bound\nof their transfer performance. To alleviate this issue, this paper introduces a\nsimple but effective mechanism, called Exploring the Diversity and Invariance\nin Yourself E-DIY. By simply pushing the most different regions inside each\naugmented view away, E-DIY can preserve the diversity of extracted region-level\nfeatures. By pulling the most similar regions from different augmented views of\nthe same image together, E-DIY can ensure the robustness of region-level\nfeatures. Benefited from the above diversity and invariance exploring\nmechanism, E-DIY maximally extracts the multi-grained visual information inside\neach image. Extensive experiments on downstream tasks demonstrate the\nsuperiority of our proposed approach, e.g., there are 2.1% improvements\ncompared with the strong baseline BYOL on COCO while fine-tuning Mask R-CNN\nwith the R50-C4 backbone and 1X learning schedule.",
    "descriptor": "",
    "authors": [
      "Longhui Wei",
      "Lingxi Xie",
      "Wengang Zhou",
      "Houqiang Li",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00537"
  },
  {
    "id": "arXiv:2106.00538",
    "title": "Value propagation-based spatio-temporal interpolation inspired by Markov  reward processes",
    "abstract": "Given the common problem of missing data in real-world applications from\nvarious fields, such as remote sensing, ecology and meteorology, the\ninterpolation of missing spatial and spatio-temporal data can be of tremendous\nvalue. Existing methods for spatial interpolation, most notably Gaussian\nprocesses and spatial autoregressive models, tend to suffer from (a) a\ntrade-off between modelling local or global spatial interaction, (b) the\nassumption there is only one possible path between two points, and (c) the\nassumption of homogeneity of intermediate locations between points. Addressing\nthese issues, we propose a value propagation method, inspired by Markov reward\nprocesses (MRPs), as a spatial interpolation method, and introduce two variants\nthereof: (i) a static discount (SD-MRP) and (ii) a data-driven weight\nprediction (WP-MRP) variant. Both these interpolation variants operate locally,\nwhile implicitly accounting for global spatial relationships in the entire\nsystem through recursion. We evaluated our proposed methods by comparing the\nmean absolute errors and running times of interpolated grid cells to those of 7\ncommon baselines. Our analysis involved detailed experiments on two synthetic\nand two real-world datasets over 44 total experimental conditions. Experimental\nresults show the competitive advantage of MRP interpolation on real-world data,\nas the average performance of SD-MRP on real-world data under all experimental\nconditions was ranked significantly higher than that of all other methods,\nfollowed by WP-MRP. On synthetic data, we show that WP-MRP can perform better\nthan SD-MRP given sufficiently informative features. We further found that,\neven in cases where our methods had no significant advantage over baselines\nnumerically, our methods preserved the spatial structure of the target grid\nbetter than the baselines.",
    "descriptor": "",
    "authors": [
      "Laurens Arp",
      "Mitra Baratchi",
      "Holger Hoos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00538"
  },
  {
    "id": "arXiv:2106.00541",
    "title": "MalPhase: Fine-Grained Malware Detection Using Network Flow Data",
    "abstract": "Economic incentives encourage malware authors to constantly develop new,\nincreasingly complex malware to steal sensitive data or blackmail individuals\nand companies into paying large ransoms. In 2017, the worldwide economic impact\nof cyberattacks is estimated to be between 445 and 600 billion USD, or 0.8% of\nglobal GDP. Traditionally, one of the approaches used to defend against malware\nis network traffic analysis, which relies on network data to detect the\npresence of potentially malicious software. However, to keep up with increasing\nnetwork speeds and amount of traffic, network analysis is generally limited to\nwork on aggregated network data, which is traditionally challenging and yields\nmixed results. In this paper we present MalPhase, a system that was designed to\ncope with the limitations of aggregated flows. MalPhase features a multi-phase\npipeline for malware detection, type and family classification. The use of an\nextended set of network flow features and a simultaneous multi-tier\narchitecture facilitates a performance improvement for deep learning models,\nmaking them able to detect malicious flows (>98% F1) and categorize them to a\nrespective malware type (>93% F1) and family (>91% F1). Furthermore, the use of\nrobust features and denoising autoencoders allows MalPhase to perform well on\nsamples with varying amounts of benign traffic mixed in. Finally, MalPhase\ndetects unseen malware samples with performance comparable to that of known\nsamples, even when interlaced with benign flows to reflect realistic network\nenvironments.",
    "descriptor": "\nComments: Paper accepted for publication at ACM AsiaCCS 2021\n",
    "authors": [
      "Michal Piskozub",
      "Fabio De Gaspari",
      "Frederick Barr-Smith",
      "Luigi V. Mancini",
      "Ivan Martinovic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.00541"
  },
  {
    "id": "arXiv:2106.00545",
    "title": "Counterfactual Invariance to Spurious Correlations: Why and How to Pass  Stress Tests",
    "abstract": "Informally, a `spurious correlation' is the dependence of a model on some\naspect of the input data that an analyst thinks shouldn't matter. In machine\nlearning, these have a know-it-when-you-see-it character; e.g., changing the\ngender of a sentence's subject changes a sentiment predictor's output. To check\nfor spurious correlations, we can `stress test' models by perturbing irrelevant\nparts of input data and seeing if model predictions change. In this paper, we\nstudy stress testing using the tools of causal inference. We introduce\n\\emph{counterfactual invariance} as a formalization of the requirement that\nchanging irrelevant parts of the input shouldn't change model predictions. We\nconnect counterfactual invariance to out-of-domain model performance, and\nprovide practical schemes for learning (approximately) counterfactual invariant\npredictors (without access to counterfactual examples). It turns out that both\nthe means and implications of counterfactual invariance depend fundamentally on\nthe true underlying causal structure of the data. Distinct causal structures\nrequire distinct regularization schemes to induce counterfactual invariance.\nSimilarly, counterfactual invariance implies different domain shift guarantees\ndepending on the underlying causal structure. This theory is supported by\nempirical results on text classification.",
    "descriptor": "",
    "authors": [
      "Victor Veitch",
      "Alexander D'Amour",
      "Steve Yadlowsky",
      "Jacob Eisenstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00545"
  },
  {
    "id": "arXiv:2106.00546",
    "title": "Efficient Explanations With Relevant Sets",
    "abstract": "Recent work proposed $\\delta$-relevant inputs (or sets) as a probabilistic\nexplanation for the predictions made by a classifier on a given input.\n$\\delta$-relevant sets are significant because they serve to relate\n(model-agnostic) Anchors with (model-accurate) PI- explanations, among other\nexplanation approaches. Unfortunately, the computation of smallest size\n$\\delta$-relevant sets is complete for ${NP}^{PP}$, rendering their computation\nlargely infeasible in practice. This paper investigates solutions for tackling\nthe practical limitations of $\\delta$-relevant sets. First, the paper\nalternatively considers the computation of subset-minimal sets. Second, the\npaper studies concrete families of classifiers, including decision trees among\nothers. For these cases, the paper shows that the computation of subset-minimal\n$\\delta$-relevant sets is in NP, and can be solved with a polynomial number of\ncalls to an NP oracle. The experimental evaluation compares the proposed\napproach with heuristic explainers for the concrete case of the classifiers\nstudied in the paper, and confirms the advantage of the proposed solution over\nthe state of the art.",
    "descriptor": "",
    "authors": [
      "Yacine Izza",
      "Alexey Ignatiev",
      "Nina Narodytska",
      "Martin C. Cooper",
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00546"
  },
  {
    "id": "arXiv:2106.00548",
    "title": "Enhanced Error Estimates for Augmented Subspace Method",
    "abstract": "In this paper, some enhanced error estimates are derived for the augmented\nsubspace methods which are designed for solving eigenvalue problems. We will\nshow that the augmented subspace methods have the second order convergence rate\nwhich is better than the existing results. These sharper estimates provide a\nnew dependence of convergence rate on the coarse spaces in augmented subspace\nmethods. These new results are also validated by some numerical examples.",
    "descriptor": "\nComments: 19 pages, 24 figures\n",
    "authors": [
      "Haikun Dang",
      "Yifan Wang",
      "Hehu Xie",
      "Chenguang Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00548"
  },
  {
    "id": "arXiv:2106.00553",
    "title": "SHINE: SHaring the INverse Estimate from the forward pass for bi-level  optimization and implicit models",
    "abstract": "In recent years, implicit deep learning has emerged as a method to increase\nthe depth of deep neural networks. While their training is memory-efficient,\nthey are still significantly slower to train than their explicit counterparts.\nIn Deep Equilibrium Models (DEQs), the training is performed as a bi-level\nproblem, and its computational complexity is partially driven by the iterative\ninversion of a huge Jacobian matrix. In this paper, we propose a novel strategy\nto tackle this computational bottleneck from which many bi-level problems\nsuffer. The main idea is to use the quasi-Newton matrices from the forward pass\nto efficiently approximate the inverse Jacobian matrix in the direction needed\nfor the gradient computation. We provide a theorem that motivates using our\nmethod with the original forward algorithms. In addition, by modifying these\nforward algorithms, we further provide theoretical guarantees that our method\nasymptotically estimates the true implicit gradient. We empirically study this\napproach in many settings, ranging from hyperparameter optimization to large\nMultiscale DEQs applied to CIFAR and ImageNet. We show that it reduces the\ncomputational cost of the backward pass by up to two orders of magnitude. All\nthis is achieved while retaining the excellent performance of the original\nmodels in hyperparameter optimization and on CIFAR, and giving encouraging and\ncompetitive results on ImageNet.",
    "descriptor": "",
    "authors": [
      "Zaccharie Ramzi",
      "Florian Mannel",
      "Shaojie Bai",
      "Jean-Luc Starck",
      "Philippe Ciuciu",
      "Thomas Moreau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00553"
  },
  {
    "id": "arXiv:2106.00554",
    "title": "Recovering wavelet coefficients from binary samples using fast  transforms",
    "abstract": "Recovering a signal (function) from finitely many binary or Fourier samples\nis one of the core problems in modern medical imaging, and by now there exist a\nplethora of methods for recovering a signal from such samples. Examples of\nmethods, which can utilise wavelet reconstruction, include generalised\nsampling, infinite-dimensional compressive sensing, the\nparameterised-background data-weak (PBDW) method etc. However, for any of these\nmethods to be applied in practice, accurate and fast modelling of an $N \\times\nM$ section of the infinite-dimensional change-of-basis matrix between the\nsampling basis (Fourier or Walsh-Hadamard samples) and the wavelet\nreconstruction basis is paramount. In this work, we derive an algorithm, which\nbypasses the $NM$ storage requirement and the $\\mathcal{O}(NM)$ computational\ncost of matrix-vector multiplication with this matrix when using Walsh-Hadamard\nsamples and wavelet reconstruction. The proposed algorithm computes the\nmatrix-vector multiplication in $\\mathcal{O}(N\\log N)$ operations and has a\nstorage requirement of $\\mathcal{O}(2^q)$, where $N=2^{dq} M$, (usually $q \\in\n\\{1,2\\}$) and $d=1,2$ is the dimension. As matrix-vector multiplications is the\ncomputational bottleneck for iterative algorithms used by the mentioned\nreconstruction methods, the proposed algorithm speeds up the reconstruction of\nwavelet coefficients from Walsh-Hadamard samples considerably.",
    "descriptor": "",
    "authors": [
      "Vegard Antun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00554"
  },
  {
    "id": "arXiv:2106.00557",
    "title": "Towards Interpretable Attention Networks for Cervical Cancer Analysis",
    "abstract": "Recent advances in deep learning have enabled the development of automated\nframeworks for analysing medical images and signals, including analysis of\ncervical cancer. Many previous works focus on the analysis of isolated cervical\ncells, or do not offer sufficient methods to explain and understand how the\nproposed models reach their classification decisions on multi-cell images.\nHere, we evaluate various state-of-the-art deep learning models and\nattention-based frameworks for the classification of images of multiple\ncervical cells. As we aim to provide interpretable deep learning models to\naddress this task, we also compare their explainability through the\nvisualization of their gradients. We demonstrate the importance of using images\nthat contain multiple cells over using isolated single-cell images. We show the\neffectiveness of the residual channel attention model for extracting important\nfeatures from a group of cells, and demonstrate this model's efficiency for\nthis classification task. This work highlights the benefits of channel\nattention mechanisms in analyzing multiple-cell images for potential relations\nand distributions within a group of cells. It also provides interpretable\nmodels to address the classification of cervical cells.",
    "descriptor": "",
    "authors": [
      "Ruiqi Wang",
      "Mohammad Ali Armin",
      "Simon Denman",
      "Lars Petersson",
      "David Ahmedt-Aristizabal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.00557"
  },
  {
    "id": "arXiv:2106.00559",
    "title": "Predicting Vehicles Trajectories in Urban Scenarios with Transformer  Networks and Augmented Information",
    "abstract": "Understanding the behavior of road users is of vital importance for the\ndevelopment of trajectory prediction systems. In this context, the latest\nadvances have focused on recurrent structures, establishing the social\ninteraction between the agents involved in the scene. More recently, simpler\nstructures have also been introduced for predicting pedestrian trajectories,\nbased on Transformer Networks, and using positional information. They allow the\nindividual modelling of each agent's trajectory separately without any complex\ninteraction terms. Our model exploits these simple structures by adding\naugmented data (position and heading), and adapting their use to the problem of\nvehicle trajectory prediction in urban scenarios in prediction horizons up to 5\nseconds. In addition, a cross-performance analysis is performed between\ndifferent types of scenarios, including highways, intersections and\nroundabouts, using recent datasets (inD, rounD, highD and INTERACTION). Our\nmodel achieves state-of-the-art results and proves to be flexible and adaptable\nto different types of urban contexts.",
    "descriptor": "\nComments: This work has been accepted for publication at IEEE Intelligent Vehicles Symposium 2021\n",
    "authors": [
      "A. Quintanar",
      "D. Fern\u00e1ndez-Llorca",
      "I. Parra",
      "R. Izquierdo",
      "M. A. Sotelo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00559"
  },
  {
    "id": "arXiv:2106.00563",
    "title": "IID-GAN: an IID Sampling Perspective for Regularizing Mode Collapse",
    "abstract": "Despite its success, generative adversarial networks (GANs) still suffer from\nmode collapse, namely the generator can only map latent variables to a partial\nset of modes of the target distribution. In this paper, we analyze and try to\nregularize this issue with an independent and identically distributed (IID)\nsampling perspective and emphasize that holding the IID property for generation\nin target space (i.e. real data) can naturally avoid mode collapse. This is\nbased on the basic IID assumption for real data in machine learning. However,\nthough the source samples $\\mathbf{z}$ obey IID, the target generation\n$G(\\mathbf{z})$ may not necessarily be IID. Based on this observation, we\nprovide a new loss to encourage the closeness between the inverse source from\ngeneration, and a standard Gaussian distribution in the latent space, as a way\nof regularizing the generation to be IID. The logic is that the inverse samples\nback from target data should also be IID for source distribution. Experiments\non both synthetic and real-world data show the superiority and robustness of\nour model.",
    "descriptor": "",
    "authors": [
      "Liangliang Shi",
      "Yang Li",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00563"
  },
  {
    "id": "arXiv:2106.00564",
    "title": "Wireless Federated Learning with Limited Communication and Differential  Privacy",
    "abstract": "This paper investigates the role of dimensionality reduction in efficient\ncommunication and differential privacy (DP) of the local datasets at the remote\nusers for over-the-air computation (AirComp)-based federated learning (FL)\nmodel. More precisely, we consider the FL setting in which clients are prompted\nto train a machine learning model by simultaneous channel-aware and limited\ncommunications with a parameter server (PS) over a Gaussian multiple-access\nchannel (GMAC), so that transmissions sum coherently at the PS globally aware\nof the channel coefficients. For this setting, an algorithm is proposed based\non applying federated stochastic gradient descent (FedSGD) for training the\nminimum of a given loss function based on the local gradients,\nJohnson-Lindenstrauss (JL) random projection for reducing the dimension of the\nlocal updates, and artificial noise to further aid user's privacy. For this\nscheme, our results show that the local DP performance is mainly improved due\nto injecting noise of greater variance on each dimension while keeping the\nsensitivity of the projected vectors unchanged. This is while the convergence\nrate is slowed down compared to the case without dimensionality reduction. As\nthe performance outweighs for the slower convergence, the trade-off between\nprivacy and convergence is higher but is shown to lessen in high-dimensional\nregime yielding almost the same trade-off with much less communication cost.",
    "descriptor": "",
    "authors": [
      "Amir Sonee",
      "Stefano Rini",
      "Yu-Chih Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00564"
  },
  {
    "id": "arXiv:2106.00565",
    "title": "Robust and accurate fine-grain power models for embedded systems with no  on-chip PMU",
    "abstract": "This paper presents a novel approach to event-based power modelling for\nembedded platforms that do not have a Performance Monitoring Unit (PMU). The\nmethod involves complementing the target hardware platform, where the physical\npower data is measured, with another platform on which the CPU performance\ndata, that is needed for model generation, can be collected. The methodology is\nused to generate accurate fine-grain power models for the the Gaisler GR712RC\ndual-core LEON3 fault-tolerant SPARC processor with on-board power sensors and\nno PMU. A Kintex UltraScale FPGA is used as the support platform to obtain the\nrequired CPU performance data, by running a soft-core representation of the\ndual-core LEON3 as on the GR712RC but with a PMU implementation. Both platforms\nexecute the same benchmark set and data collection is synchronised using\nper-sample timestamps so that the power sensor data from the GR712RC board can\nbe matched to the PMU data from the FPGA. The synchronised samples are then\nprocessed by the Robust Energy and Power Predictor Selection (REPPS) software\nin order to generate power models. The models achieve less than 2% power\nestimation error when validated on an industrial use-case and can successfully\nfollow program phases, which makes them suitable for runtime power profiling.",
    "descriptor": "",
    "authors": [
      "Kris Nikov",
      "Marcos Martinez",
      "Zbigniew Chamski",
      "Kyriakos Georgiou",
      "Jose Nunez-Yanez",
      "Kerstin Eder"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.00565"
  },
  {
    "id": "arXiv:2106.00566",
    "title": "Full-Resolution Encoder-Decoder Networks with Multi-Scale Feature Fusion  for Human Pose Estimation",
    "abstract": "To achieve more accurate 2D human pose estimation, we extend the successful\nencoder-decoder network, simple baseline network (SBN), in three ways. To\nreduce the quantization errors caused by the large output stride size, two more\ndecoder modules are appended to the end of the simple baseline network to get\nfull output resolution. Then, the global context blocks (GCBs) are added to the\nencoder and decoder modules to enhance them with global context features.\nFurthermore, we propose a novel spatial-attention-based multi-scale feature\ncollection and distribution module (SA-MFCD) to fuse and distribute multi-scale\nfeatures to boost the pose estimation. Experimental results on the MS COCO\ndataset indicate that our network can remarkably improve the accuracy of human\npose estimation over SBN, our network using ResNet34 as the backbone network\ncan even achieve the same accuracy as SBN with ResNet152, and our networks can\nachieve superior results with big backbone networks.",
    "descriptor": "",
    "authors": [
      "Jie Ou",
      "Mingjian Chen",
      "Hong Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00566"
  },
  {
    "id": "arXiv:2106.00569",
    "title": "Optimal virtual PON slicing to support ultra-low latency mesh traffic  pattern in MEC-based Cloud-RAN",
    "abstract": "As progressive densification of cells, deployment of Cloud-RAN and \\ac{MEC}\nare coming into reality to support the ultra-low latency with high reliability\nin 5G and beyond, it generates mesh traffic pattern across fronthaul network.\nThis led to evolution of PON architectural enhancements with virtualization in\norder to support such mesh traffic pattern. However, allocation of virtual PON\nslices dynamically over such mesh-PON based fronthaul transport is becoming a\nresearch challenge. In this paper, we provide a mixed analytical-iterative\nmodel to compute optimal virtual PON slice allocation, providing mesh access\nconnectivity with ultra-low end-to-end latency in next-generation MEC-based\nCloud-RAN. Our proposed method can compute optimal virtual PON slice allocation\nin timescales compatible with real-time or near real-time operations.",
    "descriptor": "\nComments: 5 pages, 5 Figures\n",
    "authors": [
      "Sandip Das",
      "Marco Ruffini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.00569"
  },
  {
    "id": "arXiv:2106.00570",
    "title": "Robust design optimisation of continuous flow polymerase chain reaction  thermal flow systems",
    "abstract": "This paper presents an efficient methodology for the robust optimisation of\nContinuous Flow Polymerase Chain Reaction (CFPCR) devices. It enables the\neffects of uncertainties in device geometry, due to manufacturing tolerances,\non the competing objectives of minimising the temperature deviations within the\nCFPCR thermal zones, together with minimising the pressure drop across the\ndevice, to be explored. We first validate that our training data from conjugate\nheat transfer simulations of the CFPCR thermal flow problems is noise free and\nthen combine a deterministic surrogate model, based on the mean of a Gaussian\nProcess Regression (GPR) simulator, with Polynomial Chaos Expansions (PCE) to\npropagate the manufacturing uncertainties in the geometry design variables into\nthe optimisation outputs. The resultant probabilistic model is used to solve a\nseries of robust optimisation problems. The influence of the robust problem\nformulation and constraints on the design conservatism of the robust optima in\ncomparison with the corresponding deterministic cases is explored briefly.",
    "descriptor": "",
    "authors": [
      "Yongxing Wang",
      "Hazim A. Hamad",
      "Jochen Voss",
      "Harvey M. Thompson"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.00570"
  },
  {
    "id": "arXiv:2106.00571",
    "title": "A reduced 3D-0D FSI model of the aortic valve including leaflets  curvature",
    "abstract": "In the present work, we propose a novel lumped-parameter model for the\ndescription of the aortic valve dynamics, including elastic effects associated\nto the leaflets' curvature. The introduction of a lumped-parameter model based\non momentum balance entails an easier calibration of the parameter models, that\nare instead typically numerous in phenomenological-based models. This model is\ncoupled with 3D Navier-Stokes equations describing the blood flow, where the\nvalve surface is represented by a resistive method, and valve leaflets velocity\nis taken into consideration. The resulting reduced fluid-structure interaction\nproblem has a computational cost that is comparable with the solution of a\nprescribed-motion fluid dynamics problem. A SUPG-PSPG stabilized finite element\nscheme is adopted for the discretization of the coupled problem, and the\ncomputational results show the suitability of the system in representing the\nleaflets motion, the blood flow in the ascending aorta, and the pressure jump\nacross the leaflets.",
    "descriptor": "",
    "authors": [
      "Ivan Fumagalli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.00571"
  },
  {
    "id": "arXiv:2106.00572",
    "title": "Prior-Enhanced Few-Shot Segmentation with Meta-Prototypes",
    "abstract": "Few-shot segmentation~(FSS) performance has been extensively promoted by\nintroducing episodic training and class-wise prototypes. However, the FSS\nproblem remains challenging due to three limitations: (1) Models are distracted\nby task-unrelated information; (2) The representation ability of a single\nprototype is limited; (3) Class-related prototypes ignore the prior knowledge\nof base classes. We propose the Prior-Enhanced network with Meta-Prototypes to\ntackle these limitations. The prior-enhanced network leverages the support and\nquery (pseudo-) labels in feature extraction, which guides the model to focus\non the task-related features of the foreground objects, and suppress much noise\ndue to the lack of supervised knowledge. Moreover, we introduce multiple\nmeta-prototypes to encode hierarchical features and learn class-agnostic\nstructural information. The hierarchical features help the model highlight the\ndecision boundary and focus on hard pixels, and the structural information\nlearned from base classes is treated as the prior knowledge for novel classes.\nExperiments show that our method achieves the mean-IoU scores of 60.79% and\n41.16% on PASCAL-$5^i$ and COCO-$20^i$, outperforming the state-of-the-art\nmethod by 3.49% and 5.64% in the 5-shot setting. Moreover, comparing with\n1-shot results, our method promotes 5-shot accuracy by 3.73% and 10.32% on the\nabove two benchmarks. The source code of our method is available at\nhttps://github.com/Jarvis73/PEMP.",
    "descriptor": "",
    "authors": [
      "Jian-Wei Zhang",
      "Lei Lv",
      "Yawei Luo",
      "Hao-Zhe Feng",
      "Yi Yang",
      "Wei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00572"
  },
  {
    "id": "arXiv:2106.00573",
    "title": "One4all User Representation for Recommender Systems in E-commerce",
    "abstract": "General-purpose representation learning through large-scale pre-training has\nshown promising results in the various machine learning fields. For an\ne-commerce domain, the objective of general-purpose, i.e., one for all,\nrepresentations would be efficient applications for extensive downstream tasks\nsuch as user profiling, targeting, and recommendation tasks. In this paper, we\nsystematically compare the generalizability of two learning strategies, i.e.,\ntransfer learning through the proposed model, ShopperBERT, vs. learning from\nscratch. ShopperBERT learns nine pretext tasks with 79.2M parameters from 0.8B\nuser behaviors collected over two years to produce user embeddings. As a\nresult, the MLPs that employ our embedding method outperform more complex\nmodels trained from scratch for five out of six tasks. Specifically, the\npre-trained embeddings have superiority over the task-specific supervised\nfeatures and the strong baselines, which learn the auxiliary dataset for the\ncold-start problem. We also show the computational efficiency and embedding\nvisualization of the pre-trained features.",
    "descriptor": "",
    "authors": [
      "Kyuyong Shin",
      "Hanock Kwak",
      "Kyung-Min Kim",
      "Minkyu Kim",
      "Young-Jin Park",
      "Jisu Jeong",
      "Seungjae Jung"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00573"
  },
  {
    "id": "arXiv:2106.00576",
    "title": "Exposing Previously Undetectable Faults in Deep Neural Networks",
    "abstract": "Existing methods for testing DNNs solve the oracle problem by constraining\nthe raw features (e.g. image pixel values) to be within a small distance of a\ndataset example for which the desired DNN output is known. But this limits the\nkinds of faults these approaches are able to detect. In this paper, we\nintroduce a novel DNN testing method that is able to find faults in DNNs that\nother methods cannot. The crux is that, by leveraging generative machine\nlearning, we can generate fresh test inputs that vary in their high-level\nfeatures (for images, these include object shape, location, texture, and\ncolour). We demonstrate that our approach is capable of detecting deliberately\ninjected faults as well as new faults in state-of-the-art DNNs, and that in\nboth cases, existing methods are unable to find these faults.",
    "descriptor": "\nComments: Accepted to the ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA 2021)\n",
    "authors": [
      "Isaac Dunn",
      "Hadrien Pouget",
      "Daniel Kroening",
      "Tom Melham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.00576"
  },
  {
    "id": "arXiv:2106.00583",
    "title": "Triggerflow: Trigger-based Orchestration of Serverless Workflows",
    "abstract": "As more applications are being moved to the Cloud thanks to serverless\ncomputing, it is increasingly necessary to support the native life cycle\nexecution of those applications in the data center. But existing cloud\norchestration systems either focus on short-running workflows (like IBM\nComposer or Amazon Step Functions Express Workflows) or impose considerable\noverheads for synchronizing massively parallel jobs (Azure Durable Functions,\nAmazon Step Functions). None of them are open systems enabling extensible\ninterception and optimization of custom workflows. We present Triggerflow: an\nextensible Trigger-based Orchestration architecture for serverless workflows.\nWe demonstrate that Triggerflow is a novel serverless building block capable of\nconstructing different reactive orchestrators (State Machines, Directed Acyclic\nGraphs, Workflow as code, Federated Learning orchestrator). We also validate\nthat it can support high-volume event processing workloads, auto-scale on\ndemand with scale down to zero when not used, and transparently guarantee fault\ntolerance and efficient resource usage when orchestrating long running\nscientific workflows.",
    "descriptor": "\nComments: 17 pages, 17 figures, preprint submitted to Future Generation Computer Systems. arXiv admin note: substantial text overlap with arXiv:2006.08654\n",
    "authors": [
      "Aitor Arjona",
      "Pedro Garc\u00eda-L\u00f3pez",
      "Josep Samp\u00e9",
      "Aleksander Slominski",
      "Lionel Villard"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.00583"
  },
  {
    "id": "arXiv:2106.00588",
    "title": "TransVOS: Video Object Segmentation with Transformers",
    "abstract": "Recently, Space-Time Memory Network (STM) based methods have achieved\nstate-of-the-art performance in semi-supervised video object segmentation\n(VOS). A critical problem in this task is how to model the dependency both\namong different frames and inside every frame. However, most of these methods\nneglect the spatial relationships (inside each frame) and do not make full use\nof the temporal relationships (among different frames). In this paper, we\npropose a new transformer-based framework, termed TransVOS, introducing a\nvision transformer to fully exploit and model both the temporal and spatial\nrelationships. Moreover, most STM-based approaches employ two disparate\nencoders to extract features of two significant inputs, i.e., reference sets\n(history frames with predicted masks) and query frame, respectively, increasing\nthe models' parameters and complexity. To slim the popular two-encoder pipeline\nwhile keeping the effectiveness, we design a single two-path feature extractor\nto encode the above two inputs in a unified way. Extensive experiments\ndemonstrate the superiority of our TransVOS over state-of-the-art methods on\nboth DAVIS and YouTube-VOS datasets. Codes will be released when it is\npublished.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Jianbiao Mei",
      "Mengmeng Wang",
      "Yeneng Lin",
      "Yong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00588"
  },
  {
    "id": "arXiv:2106.00589",
    "title": "Improving Long-Term Metrics in Recommendation Systems using  Short-Horizon Offline RL",
    "abstract": "We study session-based recommendation scenarios where we want to recommend\nitems to users during sequential interactions to improve their long-term\nutility. Optimizing a long-term metric is challenging because the learning\nsignal (whether the recommendations achieved their desired goals) is delayed\nand confounded by other user interactions with the system. Immediately\nmeasurable proxies such as clicks can lead to suboptimal recommendations due to\nmisalignment with the long-term metric. Many works have applied episodic\nreinforcement learning (RL) techniques for session-based recommendation but\nthese methods do not account for policy-induced drift in user intent across\nsessions. We develop a new batch RL algorithm called Short Horizon Policy\nImprovement (SHPI) that approximates policy-induced distribution shifts across\nsessions. By varying the horizon hyper-parameter in SHPI, we recover well-known\npolicy improvement schemes in the RL literature. Empirical results on four\nrecommendation tasks show that SHPI can outperform matrix factorization,\noffline bandits, and offline RL baselines. We also provide a stable and\ncomputationally efficient implementation using weighted regression oracles.",
    "descriptor": "",
    "authors": [
      "Bogdan Mazoure",
      "Paul Mineiro",
      "Pavithra Srinath",
      "Reza Sharifi Sedeh",
      "Doina Precup",
      "Adith Swaminathan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00589"
  },
  {
    "id": "arXiv:2106.00590",
    "title": "NewsEmbed: Modeling News through Pre-trained DocumentRepresentations",
    "abstract": "Effectively modeling text-rich fresh content such as news articles at\ndocument-level is a challenging problem. To ensure a content-based model\ngeneralize well to a broad range of applications, it is critical to have a\ntraining dataset that is large beyond the scale of human labels while achieving\ndesired quality. In this work, we address those two challenges by proposing a\nnovel approach to mine semantically-relevant fresh documents, and their topic\nlabels, with little human supervision. Meanwhile, we design a multitask model\ncalled NewsEmbed that alternatively trains a contrastive learning with a\nmulti-label classification to derive a universal document encoder. We show that\nthe proposed approach can provide billions of high quality organic training\nexamples and can be naturally extended to multilingual setting where texts in\ndifferent languages are encoded in the same semantic space. We experimentally\ndemonstrate NewsEmbed's competitive performance across multiple natural\nlanguage understanding tasks, both supervised and unsupervised.",
    "descriptor": "",
    "authors": [
      "Jialu Liu",
      "Tianqi Liu",
      "Cong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00590"
  },
  {
    "id": "arXiv:2106.00591",
    "title": "Comparing Multi-Index Stochastic Collocation and Multi-Fidelity  Stochastic Radial Basis Functions for Forward Uncertainty Quantification of  Ship Resistance",
    "abstract": "This paper presents a comparison of two multi-fidelity methods for the\nforward uncertainty quantification of a naval engineering problem.\nSpecifically, we consider the problem of quantifying the uncertainty of the\nhydrodynamic resistance of a roll-on/roll-off passengers ferry advancing in\ncalm water and subject to two operational uncertainties (ship speed and\npayload). The first four statistical moments (mean, variance, skewness,\nkurtosis), and the probability density function for such quantity of interest\n(QoI) are computed with two multi-fidelity methods, i.e., the Multi-Index\nStochastic Collocation (MISC) method and an adaptive multi-fidelity Stochastic\nRadial Basis Functions (SRBF) algorithm. The QoI is evaluated via computational\nfluid dynamics simulations, which are performed with the in-house unsteady\nReynolds-Averaged Navier-Stokes (RANS) multi-grid solver $\\chi$navis. The\ndifferent fidelities employed by both methods are obtained by stopping the RANS\nsolver at different grid levels of the multi-grid cycle. The performance of\nboth methods are presented and discussed: in a nutshell, the findings suggest\nthat, at least for the current implementations of both algorithms, MISC could\nbe preferred whenever a limited computational budget is available, whereas for\na larger computational budget SRBFs seem to be preferable, thanks to its\nrobustness to the numerical noise in the evaluations of the QoI.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2005.07405\n",
    "authors": [
      "Chiara Piazzola",
      "Lorenzo Tamellini",
      "Riccardo Pellegrini",
      "Riccardo Broglia",
      "Andrea Serani",
      "Matteo Diez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00591"
  },
  {
    "id": "arXiv:2106.00592",
    "title": "Semi-Supervised Domain Generalization with Stochastic StyleMatch",
    "abstract": "Most existing research on domain generalization assumes source data gathered\nfrom multiple domains are fully annotated. However, in real-world applications,\nwe might have only a few labels available from each source domain due to high\nannotation cost, along with abundant unlabeled data that are much easier to\nobtain. In this work, we investigate semi-supervised domain generalization\n(SSDG), a more realistic and practical setting. Our proposed approach,\nStyleMatch, is inspired by FixMatch, a state-of-the-art semi-supervised\nlearning method based on pseudo-labeling, with several new ingredients tailored\nto solve SSDG. Specifically, 1) to mitigate overfitting in the scarce labeled\nsource data while improving robustness against noisy pseudo labels, we\nintroduce stochastic modeling to the classifier's weights, seen as class\nprototypes, with Gaussian distributions. 2) To enhance generalization under\ndomain shift, we upgrade FixMatch's two-view consistency learning paradigm\nbased on weak and strong augmentations to a multi-view version with style\naugmentation as the third complementary view. To provide a comprehensive study\nand evaluation, we establish two SSDG benchmarks, which cover a wide range of\nstrong baseline methods developed in relevant areas including domain\ngeneralization and semi-supervised learning. Extensive experiments demonstrate\nthat StyleMatch achieves the best out-of-distribution generalization\nperformance in the low-data regime. We hope our approach and benchmarks can\npave the way for future research on data-efficient and generalizable learning\nsystems.",
    "descriptor": "\nComments: Tech report. Code available at this https URL\n",
    "authors": [
      "Kaiyang Zhou",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00592"
  },
  {
    "id": "arXiv:2106.00594",
    "title": "Gauss-Seidel Method with Oblique Direction",
    "abstract": "In this paper, a Gauss-Seidel method with oblique direction (GSO) is proposed\nfor finding the least-squares solution to a system of linear equations, where\nthe coefficient matrix may be full rank or rank deficient and the system is\noverdetermined or underdetermined. Through this method, the number of iteration\nsteps and running time can be reduced to a greater extent to find the\nleast-squares solution, especially when the columns of matrix A are close to\nlinear correlation. It is theoretically proved that GSO method converges to the\nleast-squares solution. At the same time, a randomized version--randomized\nGauss-Seidel method with oblique direction (RGSO) is established, and its\nconvergence is proved. Theoretical proof and numerical results show that the\nGSO method and the RGSO method are more efficient than the coordinate descent\n(CD) method and the randomized coordinate descent (RCD) method.",
    "descriptor": "",
    "authors": [
      "Fang Wang",
      "Weiguo Li",
      "Wendi Bao",
      "Zhonglu Lv"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00594"
  },
  {
    "id": "arXiv:2106.00596",
    "title": "Look Wide and Interpret Twice: Improving Performance on Interactive  Instruction-following Tasks",
    "abstract": "There is a growing interest in the community in making an embodied AI agent\nperform a complicated task while interacting with an environment following\nnatural language directives. Recent studies have tackled the problem using\nALFRED, a well-designed dataset for the task, but achieved only very low\naccuracy. This paper proposes a new method, which outperforms the previous\nmethods by a large margin. It is based on a combination of several new ideas.\nOne is a two-stage interpretation of the provided instructions. The method\nfirst selects and interprets an instruction without using visual information,\nyielding a tentative action sequence prediction. It then integrates the\nprediction with the visual information etc., yielding the final prediction of\nan action and an object. As the object's class to interact is identified in the\nfirst stage, it can accurately select the correct object from the input image.\nMoreover, our method considers multiple egocentric views of the environment and\nextracts essential information by applying hierarchical attention conditioned\non the current instruction. This contributes to the accurate prediction of\nactions for navigation. A preliminary version of the method won the ALFRED\nChallenge 2020. The current version achieves the unseen environment's success\nrate of 4.45% with a single view, which is further improved to 8.37% with\nmultiple views.",
    "descriptor": "\nComments: Winner of the ALFRED Challenge at ECCV 2020. To appear in IJCAI2021. 8 pages and supp\n",
    "authors": [
      "Van-Quang Nguyen",
      "Masanori Suganuma",
      "Takayuki Okatani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00596"
  },
  {
    "id": "arXiv:2106.00598",
    "title": "Unsupervised detection of mouse behavioural anomalies using two-stream  convolutional autoencoders",
    "abstract": "This paper explores the application of unsupervised learning to detecting\nanomalies in mouse video data. The two models presented in this paper are a\ndual-stream, 3D convolutional autoencoder (with residual connections) and a\ndual-stream, 2D convolutional autoencoder. The publicly available dataset used\nhere contains twelve videos of single home-caged mice alongside frame-level\nannotations. Under the pretext that the autoencoder only sees normal events,\nthe video data was handcrafted to treat each behaviour as a pseudo-anomaly\nthereby eliminating them from the others during training. The results are\npresented for one conspicuous behaviour (hang) and one inconspicuous behaviour\n(groom). The performance of these models is compared to a single stream\nautoencoder and a supervised learning model, which are both based on the custom\nCAE. Both models are also tested on the CUHK Avenue dataset were found to\nperform as well as some state-of-the-art architectures.",
    "descriptor": "",
    "authors": [
      "Ezechukwu I Nwokedi",
      "Rasneer S Bains",
      "Luc Bidaut",
      "Sara Wells",
      "Xujiong Ye",
      "James M Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00598"
  },
  {
    "id": "arXiv:2106.00599",
    "title": "ClustRank: a Visual Quality Measure Trained on Perceptual Data for  Sorting Scatterplots by Cluster Patterns",
    "abstract": "Visual quality measures (VQMs) are designed to support analysts by\nautomatically detecting and quantifying patterns in visualizations. We propose\na new data-driven technique called ClustRank that allows to rank scatterplots\naccording to visible grouping patterns. Our model first encodes scatterplots in\nthe parametric space of a Gaussian Mixture Model, and then uses a classifier\ntrained on human judgment data to estimate the perceptual complexity of\ngrouping patterns. The numbers of initial mixture components and final combined\ngroups determine the rank of the scatterplot. ClustRank improves on existing\nVQM techniques by mimicking human judgments on two-Gaussian cluster patterns\nand gives more accuracy when ranking general cluster patterns in scatterplots.\nWe demonstrate its benefit by analyzing kinship data for genome-wide\nassociation studies, a domain in which experts rely on the visual analysis of\nlarge sets of scatterplots. We make the three benchmark datasets and the\nClustRank VQM available for practical use and further improvements.",
    "descriptor": "",
    "authors": [
      "Mostafa Abbas",
      "Ehsan Ullah",
      "Abdelkader Baggag",
      "Halima Bensmail",
      "Michael Sedlmair",
      "Michael Aupetit"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00599"
  },
  {
    "id": "arXiv:2106.00600",
    "title": "Fair Clustering Using Antidote Data",
    "abstract": "Clustering algorithms are widely utilized for many modern data science\napplications. This motivates the need to make outputs of clustering algorithms\nfair. Traditionally, new fair algorithmic variants to clustering algorithms are\ndeveloped for specific notions of fairness. However, depending on the\napplication context, different definitions of fairness might need to be\nemployed. As a result, new algorithms and analysis need to be proposed for each\ncombination of clustering algorithm and fairness definition. Additionally, each\nnew algorithm would need to be reimplemented for deployment in a real-world\nsystem. Hence, we propose an alternate approach to fairness in clustering where\nwe augment the original dataset with a small number of data points, called\nantidote data. When clustering is undertaken on this new dataset, the output is\nfair, for the chosen clustering algorithm and fairness definition. We formulate\nthis as a general bi-level optimization problem which can accommodate any\ncenter-based clustering algorithms and fairness notions. We then categorize\napproaches for solving this bi-level optimization for different problem\nsettings. Extensive experiments on different clustering algorithms and fairness\nnotions show that our algorithms can achieve desired levels of fairness on many\nreal-world datasets with a very small percentage of antidote data added. We\nalso find that our algorithms achieve lower fairness costs and competitive\nclustering performance compared to other state-of-the-art fair clustering\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Anshuman Chhabra",
      "Adish Singla",
      "Prasant Mohapatra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00600"
  },
  {
    "id": "arXiv:2106.00604",
    "title": "Optimal Stopping with Behaviorally Biased Agents: The Role of Loss  Aversion and Changing Reference Points",
    "abstract": "People are often reluctant to sell a house, or shares of stock, below the\nprice at which they originally bought it. While this is generally not\nconsistent with rational utility maximization, it does reflect two strong\nempirical regularities that are central to the behavioral science of human\ndecision-making: a tendency to evaluate outcomes relative to a reference point\ndetermined by context (in this case the original purchase price), and the\nphenomenon of loss aversion in which people are particularly prone to avoid\noutcomes below the reference point. Here we explore the implications of\nreference points and loss aversion in optimal stopping problems, where people\nevaluate a sequence of options in one pass, either accepting the option and\nstopping the search or giving up on the option forever. The best option seen so\nfar sets a reference point that shifts as the search progresses, and a biased\ndecision-maker's utility incurs an additional penalty when they accept a later\noption that is below this reference point.\nWe formulate and study a behaviorally well-motivated version of the optimal\nstopping problem that incorporates these notions of reference dependence and\nloss aversion. We obtain tight bounds on the performance of a biased agent in\nthis model relative to the best option obtainable in retrospect (a type of\nprophet inequality for biased agents), as well as tight bounds on the ratio\nbetween the performance of a biased agent and the performance of a rational\none. We further establish basic monotonicity results, and show an exponential\ngap between the performance of a biased agent in a stopping problem with\nrespect to a worst-case versus a random order. As part of this, we establish\nfundamental differences between optimal stopping problems for rational versus\nbiased agents, and these differences inform our analysis.",
    "descriptor": "\nComments: To appear in the 2021 ACM Conference on Economics and Computation (EC'21)\n",
    "authors": [
      "Jon Kleinberg",
      "Robert Kleinberg",
      "Sigal Oren"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00604"
  },
  {
    "id": "arXiv:2106.00607",
    "title": "Extended retraction maps: a seed of geometric integrators",
    "abstract": "The classical notion of retraction map used to approximate geodesics is\nextended and rigorously defined to become a powerful tool to construct\ngeometric integrators. Using the geometry of the tangent and cotangent bundles,\nwe are able to tangently and cotangent lift such a map so that these lifts\ninherit the same properties as the original one and they continue to be\nextended retraction maps. In particular, the cotangent lift of this new notion\nof retraction map is a natural symplectomorphism, what plays a key role for\nconstructing geometric integrators and symplectic methods. As a result, a wide\nrange of numerical methods are recovered and canonically constructed by using\ndifferent extended retraction maps, as well as some operations with Lagrangian\nsubmanifolds.",
    "descriptor": "",
    "authors": [
      "Mar\u00eda Barbero Li\u00f1\u00e1n",
      "David Mart\u00edn de Diego"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Symplectic Geometry (math.SG)"
    ],
    "url": "https://arxiv.org/abs/2106.00607"
  },
  {
    "id": "arXiv:2106.00609",
    "title": "Robust Mutual Learning for Semi-supervised Semantic Segmentation",
    "abstract": "Recent semi-supervised learning (SSL) methods are commonly based on pseudo\nlabeling. Since the SSL performance is greatly influenced by the quality of\npseudo labels, mutual learning has been proposed to effectively suppress the\nnoises in the pseudo supervision. In this work, we propose robust mutual\nlearning that improves the prior approach in two aspects. First, the vanilla\nmutual learners suffer from the coupling issue that models may converge to\nlearn homogeneous knowledge. We resolve this issue by introducing mean teachers\nto generate mutual supervisions so that there is no direct interaction between\nthe two students. We also show that strong data augmentations, model noises and\nheterogeneous network architectures are essential to alleviate the model\ncoupling. Second, we notice that mutual learning fails to leverage the\nnetwork's own ability for pseudo label refinement. Therefore, we introduce\nself-rectification that leverages the internal knowledge and explicitly\nrectifies the pseudo labels before the mutual teaching. Such self-rectification\nand mutual teaching collaboratively improve the pseudo label accuracy\nthroughout the learning. The proposed robust mutual learning demonstrates\nstate-of-the-art performance on semantic segmentation in low-data regime.",
    "descriptor": "",
    "authors": [
      "Pan Zhang",
      "Bo Zhang",
      "Ting Zhang",
      "Dong Chen",
      "Fang Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00609"
  },
  {
    "id": "arXiv:2106.00617",
    "title": "Colonel Blotto Games with Favoritism: Competitions with Pre-allocations  and Asymmetric Effectiveness",
    "abstract": "We introduce the Colonel Blotto game with favoritism, an extension of the\nfamous Colonel Blotto game where the winner-determination rule is generalized\nto include pre-allocations and asymmetry of the players' resources\neffectiveness on each battlefield. Such favoritism is found in many classical\napplications of the Colonel Blotto game. We focus on the Nash equilibrium.\nFirst, we consider the closely related model of all-pay auctions with\nfavoritism and completely characterize its equilibrium. Based on this result,\nwe prove the existence of a set of optimal univariate distributions -- which\nserve as candidate marginals for an equilibrium -- of the Colonel Blotto game\nwith favoritism and show an explicit construction thereof. In several\nparticular cases, this directly leads to an equilibrium of the Colonel Blotto\ngame with favoritism. In other cases, we use these optimal univariate\ndistributions to derive an approximate equilibrium with well-controlled\napproximation error. Finally, we propose an algorithm -- based on the notion of\nwinding number in parametric curves -- to efficiently compute an approximation\nof the proposed optimal univariate distributions with arbitrarily small error.",
    "descriptor": "\nComments: Full paper version of ACM EC conference paper: this https URL\n",
    "authors": [
      "Dong Quan Vu",
      "Patrick Loiseau"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.00617"
  },
  {
    "id": "arXiv:2106.00619",
    "title": "CoRank: A clustering cum graph ranking approach for extractive  summarization",
    "abstract": "Online information has increased tremendously in today's age of Internet. As\na result, the need has arose to extract relevant content from the plethora of\navailable information. Researchers are widely using automatic text\nsummarization techniques for extracting useful and relevant information from\nvoluminous available information, it also enables users to obtain valuable\nknowledge in a limited period of time with minimal effort. The summary obtained\nfrom the automatic text summarization often faces the issues of diversity and\ninformation coverage. Promising results are obtained for automatic text\nsummarization by the introduction of new techniques based on graph ranking of\nsentences, clustering, and optimization. This research work proposes CoRank, a\ntwo-stage sentence selection model involving clustering and then ranking of\nsentences. The initial stage involves clustering of sentences using a novel\nclustering algorithm, and later selection of salient sentences using CoRank\nalgorithm. The approach aims to cover two objectives: maximum coverage and\ndiversity, which is achieved by the extraction of main topics and sub-topics\nfrom the original text. The performance of the CoRank is validated on DUC2001\nand DUC 2002 data sets.",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Mohd Khizir Siddiqui",
      "Amreen Ahmad",
      "Om Pal",
      "Tanvir Ahmad"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.00619"
  },
  {
    "id": "arXiv:2106.00623",
    "title": "A 4-Approximation Algorithm for Maximum Independent Set of Rectangles",
    "abstract": "We study the Maximum Independent Set of Rectangles(MISR) problem, where we\nare given a set of axis-parallel rectangles in the plane and the goal is to\nselect a subset of non-overlapping rectangles of maximum cardinality. In a\nrecent breakthrough, Mitchell obtained the first constant-factor approximation\nalgorithm for MISR. His algorithm achieves an approximation ratio of 10 and it\nis based on a dynamic program that intuitively recursively partitions the input\nplane into special polygons called corner-clipped rectangles (CCRs).\nIn this paper, we present a 4-approximation algorithm for MISR which is based\non a similar recursive partitioning scheme. However, we use a more general\nclass of polygons -- polygons that are horizontally or vertically convex --\nwhich allows us to provide an arguably simpler analysis and already improve the\napproximation ratio. Using a new fractional charging argument and fork-fences\nto guide the partitions, we improve the approximation ratio even more to 4. We\nhope that our ideas will lead to further progress towards a PTAS for MISR.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Waldo Galvez",
      "Arindam Khan",
      "Mathieu Mari",
      "Tobias Momke",
      "Madhusudhan Reddy",
      "Andreas Wiese"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00623"
  },
  {
    "id": "arXiv:2106.00638",
    "title": "Quantifying Predictive Uncertainty in Medical Image Analysis with Deep  Kernel Learning",
    "abstract": "Deep neural networks are increasingly being used for the analysis of medical\nimages. However, most works neglect the uncertainty in the model's prediction.\nWe propose an uncertainty-aware deep kernel learning model which permits the\nestimation of the uncertainty in the prediction by a pipeline of a\nConvolutional Neural Network and a sparse Gaussian Process. Furthermore, we\nadapt different pre-training methods to investigate their impacts on the\nproposed model. We apply our approach to Bone Age Prediction and Lesion\nLocalization. In most cases, the proposed model shows better performance\ncompared to common architectures. More importantly, our model expresses\nsystematically higher confidence in more accurate predictions and less\nconfidence in less accurate ones. Our model can also be used to detect\nchallenging and controversial test samples. Compared to related methods such as\nMonte-Carlo Dropout, our approach derives the uncertainty information in a\npurely analytical fashion and is thus computationally more efficient.",
    "descriptor": "",
    "authors": [
      "Zhiliang Wu",
      "Yinchong Yang",
      "Jindong Gu",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00638"
  },
  {
    "id": "arXiv:2106.00641",
    "title": "SpanNer: Named Entity Re-/Recognition as Span Prediction",
    "abstract": "Recent years have seen the paradigm shift of Named Entity Recognition (NER)\nsystems from sequence labeling to span prediction. Despite its preliminary\neffectiveness, the span prediction model's architectural bias has not been\nfully understood. In this paper, we first investigate the strengths and\nweaknesses when the span prediction model is used for named entity recognition\ncompared with the sequence labeling framework and how to further improve it,\nwhich motivates us to make complementary advantages of systems based on\ndifferent paradigms. We then reveal that span prediction, simultaneously, can\nserve as a system combiner to re-recognize named entities from different\nsystems' outputs. We experimentally implement 154 systems on 11 datasets,\ncovering three languages, comprehensive results show the effectiveness of span\nprediction models that both serve as base NER systems and system combiners. We\nmake all code and datasets available: \\url{https://github.com/neulab/spanner},\nas well as an online system demo: \\url{this http URL}. Our model also has\nbeen deployed into the ExplainaBoard platform, which allows users to flexibly\nperform a system combination of top-scoring systems in an interactive way:\n\\url{this http URL}.",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Jinlan Fu",
      "Xuanjing Huang",
      "Pengfei Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00641"
  },
  {
    "id": "arXiv:2106.00651",
    "title": "Asymptotics of representation learning in finite Bayesian neural  networks",
    "abstract": "Recent works have suggested that finite Bayesian neural networks may\noutperform their infinite cousins because finite networks can flexibly adapt\ntheir internal representations. However, our theoretical understanding of how\nthe learned hidden layer representations of finite networks differ from the\nfixed representations of infinite networks remains incomplete. Perturbative\nfinite-width corrections to the network prior and posterior have been studied,\nbut the asymptotics of learned features have not been fully characterized.\nHere, we argue that the leading finite-width corrections to the average feature\nkernels for any Bayesian network with linear readout and quadratic cost have a\nlargely universal form. We illustrate this explicitly for two classes of fully\nconnected networks: deep linear networks and networks with a single nonlinear\nhidden layer. Our results begin to elucidate which features of data wide\nBayesian neural networks learn to represent.",
    "descriptor": "\nComments: 12+28 pages, 2+1 figures\n",
    "authors": [
      "Jacob A. Zavatone-Veth",
      "Abdulkadir Canatar",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00651"
  },
  {
    "id": "arXiv:2106.00652",
    "title": "Comprehensive Validation of Automated Whole Body Skeletal Muscle,  Adipose Tissue, and Bone Segmentation from 3D CT images for Body Composition  Analysis: Towards Extended Body Composition",
    "abstract": "The latest advances in computer-assisted precision medicine are making it\nfeasible to move from population-wide models that are useful to discover\naggregate patterns that hold for group-based analysis to patient-specific\nmodels that can drive patient-specific decisions with regard to treatment\nchoices, and predictions of outcomes of treatment. Body Composition is\nrecognized as an important driver and risk factor for a wide variety of\ndiseases, as well as a predictor of individual patient-specific clinical\noutcomes to treatment choices or surgical interventions. 3D CT images are\nroutinely acquired in the oncological worklows and deliver accurate rendering\nof internal anatomy and therefore can be used opportunistically to assess the\namount of skeletal muscle and adipose tissue compartments. Powerful tools of\nartificial intelligence such as deep learning are making it feasible now to\nsegment the entire 3D image and generate accurate measurements of all internal\nanatomy. These will enable the overcoming of the severe bottleneck that existed\npreviously, namely, the need for manual segmentation, which was prohibitive to\nscale to the hundreds of 2D axial slices that made up a 3D volumetric image.\nAutomated tools such as presented here will now enable harvesting whole-body\nmeasurements from 3D CT or MRI images, leading to a new era of discovery of the\ndrivers of various diseases based on individual tissue, organ volume, shape,\nand functional status. These measurements were hitherto unavailable thereby\nlimiting the field to a very small and limited subset. These discoveries and\nthe potential to perform individual image segmentation with high speed and\naccuracy are likely to lead to the incorporation of these 3D measures into\nindividual specific treatment planning models related to nutrition, aging,\nchemotoxicity, surgery and survival after the onset of a major disease such as\ncancer.",
    "descriptor": "\nComments: This paper is based on concepts presented at the NIH Body Composition and Cancer Outcomes Research Webinar Series on December 17th, 2020 by Mirza Faisal Beg titled \"Automating Body Composition from Routinely Acquired CT images - towards 3D measurements\". The talk is archived at this https URL\n",
    "authors": [
      "Da Ma",
      "Vincent Chow",
      "Karteek Popuri",
      "Mirza Faisal Beg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2106.00652"
  },
  {
    "id": "arXiv:2106.00654",
    "title": "A reinforcement learning approach to improve communication performance  and energy utilization in fog-based IoT",
    "abstract": "Recent research has shown the potential of using available mobile fog devices\n(such as smartphones, drones, domestic and industrial robots) as relays to\nminimize communication outages between sensors and destination devices, where\nlocalized Internet-of-Things services (e.g., manufacturing process control,\nhealth and security monitoring) are delivered. However, these mobile relays\ndeplete energy when they move and transmit to distant destinations. As such,\npower-control mechanisms and intelligent mobility of the relay devices are\ncritical in improving communication performance and energy utilization. In this\npaper, we propose a Q-learning-based decentralized approach where each mobile\nfog relay agent (MFRA) is controlled by an autonomous agent which uses\nreinforcement learning to simultaneously improve communication performance and\nenergy utilization. Each autonomous agent learns based on the feedback from the\ndestination and its own energy levels whether to remain active and forward the\nmessage, or become passive for that transmission phase. We evaluate the\napproach by comparing with the centralized approach, and observe that with\nlesser number of MFRAs, our approach is able to ensure reliable delivery of\ndata and reduce overall energy cost by 56.76\\% -- 88.03\\%.",
    "descriptor": "\nComments: Submitted and published in IEEE proceedings\n",
    "authors": [
      "Babatunji Omoniwa",
      "Maxime Gueriau",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00654"
  },
  {
    "id": "arXiv:2106.00655",
    "title": "The Impact of Network Connectivity on Collective Learning",
    "abstract": "In decentralised autonomous systems it is the interactions between individual\nagents which govern the collective behaviours of the system. These local-level\ninteractions are themselves often governed by an underlying network structure.\nThese networks are particularly important for collective learning and\ndecision-making whereby agents must gather evidence from their environment and\npropagate this information to other agents in the system. Models for collective\nbehaviours may often rely upon the assumption of total connectivity between\nagents to provide effective information sharing within the system, but this\nassumption may be ill-advised. In this paper we investigate the impact that the\nunderlying network has on performance in the context of collective learning.\nThrough simulations we study small-world networks with varying levels of\nconnectivity and randomness and conclude that totally-connected networks result\nin higher average error when compared to networks with less connectivity.\nFurthermore, we show that networks of high regularity outperform networks with\nincreasing levels of random connectivity.",
    "descriptor": "\nComments: 13 pages, 5 figures. To appear at the 15th International Symposium on Distributed Autonomous Robotic Systems 2021. Presented at the joint DARS-SWARM 2021 symposium held (virtually) in Kyoto, Japan\n",
    "authors": [
      "Michael Crosscombe",
      "Jonathan Lawry"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00655"
  },
  {
    "id": "arXiv:2106.00657",
    "title": "Parameterized algorithms for identifying gene co-expression modules via  weighted clique decomposition",
    "abstract": "We present a new combinatorial model for identifying regulatory modules in\ngene co-expression data using a decomposition into weighted cliques. To capture\ncomplex interaction effects, we generalize the previously-studied weighted edge\nclique partition problem. As a first step, we restrict ourselves to the\nnoise-free setting, and show that the problem is fixed parameter tractable when\nparameterized by the number of modules (cliques). We present two new algorithms\nfor finding these decompositions, using linear programming and integer\npartitioning to determine the clique weights. Further, we implement these\nalgorithms in Python and test them on a biologically-inspired synthetic corpus\ngenerated using real-world data from transcription factors and a latent\nvariable analysis of co-expression in varying cell types.",
    "descriptor": "\nComments: To be published in SIAM Conference on Applied and Computational Discrete Algorithms 2021 (ACDA21)\n",
    "authors": [
      "Madison Cooley",
      "Casey S. Greene",
      "Davis Issac",
      "Milton Pividori",
      "Blair D. Sullivan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00657"
  },
  {
    "id": "arXiv:2106.00660",
    "title": "Markpainting: Adversarial Machine Learning meets Inpainting",
    "abstract": "Inpainting is a learned interpolation technique that is based on generative\nmodeling and used to populate masked or missing pieces in an image; it has wide\napplications in picture editing and retouching. Recently, inpainting started\nbeing used for watermark removal, raising concerns. In this paper we study how\nto manipulate it using our markpainting technique. First, we show how an image\nowner with access to an inpainting model can augment their image in such a way\nthat any attempt to edit it using that model will add arbitrary visible\ninformation. We find that we can target multiple different models\nsimultaneously with our technique. This can be designed to reconstitute a\nwatermark if the editor had been trying to remove it. Second, we show that our\nmarkpainting technique is transferable to models that have different\narchitectures or were trained on different datasets, so watermarks created\nusing it are difficult for adversaries to remove. Markpainting is novel and can\nbe used as a manipulation alarm that becomes visible in the event of\ninpainting.",
    "descriptor": "\nComments: Proceedings of the 38th International Conference on Machine Learning (ICML 2021)\n",
    "authors": [
      "David Khachaturov",
      "Ilia Shumailov",
      "Yiren Zhao",
      "Nicolas Papernot",
      "Ross Anderson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.00660"
  },
  {
    "id": "arXiv:2106.00661",
    "title": "Reward is enough for convex MDPs",
    "abstract": "Maximising a cumulative reward function that is Markov and stationary, i.e.,\ndefined over state-action pairs and independent of time, is sufficient to\ncapture many kinds of goals in a Markov Decision Process (MDP) based on the\nReinforcement Learning (RL) problem formulation. However, not all goals can be\ncaptured in this manner. Specifically, it is easy to see that Convex MDPs in\nwhich goals are expressed as convex functions of stationary distributions\ncannot, in general, be formulated in this manner. In this paper, we reformulate\nthe convex MDP problem as a min-max game between the policy and cost (negative\nreward) players using Fenchel duality and propose a meta-algorithm for solving\nit. We show that the average of the policies produced by an RL agent that\nmaximizes the non-stationary reward produced by the cost player converges to an\noptimal solution to the convex MDP. Finally, we show that the meta-algorithm\nunifies several disparate branches of reinforcement learning algorithms in the\nliterature, such as apprenticeship learning, variational intrinsic control,\nconstrained MDPs, and pure exploration into a single framework.",
    "descriptor": "",
    "authors": [
      "Tom Zahavy",
      "Brendan O'Donoghue",
      "Guillaume Desjardins",
      "Satinder Singh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00661"
  },
  {
    "id": "arXiv:2106.00662",
    "title": "Porous Invariants",
    "abstract": "We introduce the notion of porous invariants for multipath (or\nbranching/nondeterministic) affine loops over the integers; these invariants\nare not necessarily convex, and can in fact contain infinitely many 'holes'.\nNevertheless, we show that in many cases such invariants can be automatically\nsynthesised, and moreover can be used to settle (non-)reachability questions\nfor various interesting classes of affine loops and target sets.",
    "descriptor": "\nComments: Full version of paper to appear at CAV 2021\n",
    "authors": [
      "Engel Lefaucheux",
      "Jo\u00ebl Ouaknine",
      "David Purser",
      "James Worrell"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.00662"
  },
  {
    "id": "arXiv:2106.00664",
    "title": "Quantifiers on Demand",
    "abstract": "Automated program verification is a difficult problem. It is undecidable even\nfor transition systems over Linear Integer Arithmetic (LIA). Extending the\ntransition system with theory of Arrays, further complicates the problem by\nrequiring inference and reasoning with universally quantified formulas. In this\npaper, we present a new algorithm, Quic3, that extends IC3 to infer universally\nquantified invariants over the combined theory of LIA and Arrays. Unlike other\napproaches that use either IC3 or an SMT solver as a black box, Quic3 carefully\nmanages quantified generalization (to construct quantified invariants) and\nquantifier instantiation (to detect convergence in the presence of\nquantifiers). While Quic3 is not guaranteed to converge, it is guaranteed to\nmake progress by exploring longer and longer executions. We have implemented\nQuic3 within the Constrained Horn Clause solver engine of Z3 and experimented\nwith it by applying Quic3 to verifying a variety of public benchmarks of array\nmanipulating C programs.",
    "descriptor": "",
    "authors": [
      "Arie Gurfinkel",
      "Sharon Shoham",
      "Yakir Vizel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.00664"
  },
  {
    "id": "arXiv:2106.00665",
    "title": "Validating GAN-BioBERT: A Methodology For Assessing Reporting Trends In  Clinical Trials",
    "abstract": "In the past decade, there has been much discussion about the issue of biased\nreporting in clinical research. Despite this attention, there have been limited\ntools developed for the systematic assessment of qualitative statements made in\nclinical research, with most studies assessing qualitative statements relying\non the use of manual expert raters, which limits their size. Also, previous\nattempts to develop larger scale tools, such as those using natural language\nprocessing, were limited by both their accuracy and the number of categories\nused for the classification of their findings. With these limitations in mind,\nthis study's goal was to develop a classification algorithm that was both\nsuitably accurate and finely grained to be applied on a large scale for\nassessing the qualitative sentiment expressed in clinical trial abstracts.\nAdditionally, this study seeks to compare the performance of the proposed\nalgorithm, GAN-BioBERT, to previous studies as well as to expert manual rating\nof clinical trial abstracts. This study develops a three-class sentiment\nclassification algorithm for clinical trial abstracts using a semi-supervised\nnatural language process model based on the Bidirectional Encoder\nRepresentation from Transformers (BERT) model, from a series of clinical trial\nabstracts annotated by a group of experts in academic medicine. Results: The\nuse of this algorithm was found to have a classification accuracy of 91.3%,\nwith a macro F1-Score of 0.92, which is a significant improvement in accuracy\nwhen compared to previous methods and expert ratings, while also making the\nsentiment classification finer grained than previous studies. The proposed\nalgorithm, GAN-BioBERT, is a suitable classification model for the large-scale\nassessment of qualitative statements in clinical trial literature, providing an\naccurate, reproducible tool for the large-scale study of clinical publication\ntrends.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Joshua J Myszewski",
      "Emily Klossowski",
      "Patrick Meyer",
      "Kristin Bevil",
      "Lisa Klesius",
      "Kristopher M Schroeder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00665"
  },
  {
    "id": "arXiv:2106.00666",
    "title": "You Only Look at One Sequence: Rethinking Transformer in Vision through  Object Detection",
    "abstract": "Can Transformer perform $2\\mathrm{D}$ object-level recognition from a pure\nsequence-to-sequence perspective with minimal knowledge about the $2\\mathrm{D}$\nspatial structure? To answer this question, we present You Only Look at One\nSequence (YOLOS), a series of object detection models based on the na\\\"ive\nVision Transformer with the fewest possible modifications as well as inductive\nbiases. We find that YOLOS pre-trained on the mid-sized ImageNet-$1k$ dataset\nonly can already achieve competitive object detection performance on COCO,\n\\textit{e.g.}, YOLOS-Base directly adopted from BERT-Base can achieve $42.0$\nbox AP. We also discuss the impacts as well as limitations of current pre-train\nschemes and model scaling strategies for Transformer in vision through object\ndetection. Code and model weights are available at\n\\url{https://github.com/hustvl/YOLOS}.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Yuxin Fang",
      "Bencheng Liao",
      "Xinggang Wang",
      "Jiemin Fang",
      "Jiyang Qi",
      "Rui Wu",
      "Jianwei Niu",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00666"
  },
  {
    "id": "arXiv:2106.00667",
    "title": "SoK: Oracles from the Ground Truth to Market Manipulation",
    "abstract": "One fundamental limitation of blockchain-based smart contracts is that they\nexecute in a closed environment and only have access to the data and\nfunctionality that is either already on the blockchain or fed into the\nblockchain. Thus any interactions with the real world need to be mediated by a\nbridge service, which is called an oracle. As decentralized applications\nmature, oracles are playing an increasingly prominent role. With their\nevolution comes more attacks, necessitating a greater attention to the trust\nmodel of using oracles. In this SoK, we systemize the design alternatives for\noracles, showcase attacks, and discuss attack mitigation strategies.",
    "descriptor": "",
    "authors": [
      "Shayan Eskandari",
      "Mehdi Salehi",
      "Wanyun Catherine Gu",
      "Jeremy Clark"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00667"
  },
  {
    "id": "arXiv:2106.00669",
    "title": "Discovering Diverse Nearly Optimal Policies withSuccessor Features",
    "abstract": "Finding different solutions to the same problem is a key aspect of\nintelligence associated with creativity and adaptation to novel situations. In\nreinforcement learning, a set of diverse policies can be useful for\nexploration, transfer, hierarchy, and robustness. We propose Diverse Successive\nPolicies, a method for discovering policies that are diverse in the space of\nSuccessor Features, while assuring that they are near optimal. We formalize the\nproblem as a Constrained Markov Decision Process (CMDP) where the goal is to\nfind policies that maximize diversity, characterized by an intrinsic diversity\nreward, while remaining near-optimal with respect to the extrinsic reward of\nthe MDP. We also analyze how recently proposed robustness and discrimination\nrewards perform and find that they are sensitive to the initialization of the\nprocedure and may converge to sub-optimal solutions. To alleviate this, we\npropose new explicit diversity rewards that aim to minimize the correlation\nbetween the Successor Features of the policies in the set. We compare the\ndifferent diversity mechanisms in the DeepMind Control Suite and find that the\ntype of explicit diversity we are proposing is important to discover distinct\nbehavior, like for example different locomotion patterns.",
    "descriptor": "",
    "authors": [
      "Tom Zahavy",
      "Brendan O'Donoghue",
      "Andre Barreto",
      "Volodymyr Mnih",
      "Sebastian Flennerhag",
      "Satinder Singh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00669"
  },
  {
    "id": "arXiv:2106.00671",
    "title": "What Can I Do Here? Learning New Skills by Imagining Visual Affordances",
    "abstract": "A generalist robot equipped with learned skills must be able to perform many\ntasks in many different environments. However, zero-shot generalization to new\nsettings is not always possible. When the robot encounters a new environment or\nobject, it may need to finetune some of its previously learned skills to\naccommodate this change. But crucially, previously learned behaviors and models\nshould still be suitable to accelerate this relearning. In this paper, we aim\nto study how generative models of possible outcomes can allow a robot to learn\nvisual representations of affordances, so that the robot can sample potentially\npossible outcomes in new situations, and then further train its policy to\nachieve those outcomes. In effect, prior data is used to learn what kinds of\noutcomes may be possible, such that when the robot encounters an unfamiliar\nsetting, it can sample potential outcomes from its model, attempt to reach\nthem, and thereby update both its skills and its outcome model. This approach,\nvisuomotor affordance learning (VAL), can be used to train goal-conditioned\npolicies that operate on raw image inputs, and can rapidly learn to manipulate\nnew objects via our proposed affordance-directed exploration scheme. We show\nthat VAL can utilize prior data to solve real-world tasks such drawer opening,\ngrasping, and placing objects in new scenes with only five minutes of online\nexperience in the new scene.",
    "descriptor": "\nComments: 10 pages, 10 figures. To be presented at ICRA 2021\n",
    "authors": [
      "Alexander Khazatsky",
      "Ashvin Nair",
      "Daniel Jing",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00671"
  },
  {
    "id": "arXiv:2106.00672",
    "title": "What Matters for Adversarial Imitation Learning?",
    "abstract": "Adversarial imitation learning has become a popular framework for imitation\nin continuous control. Over the years, several variations of its components\nwere proposed to enhance the performance of the learned policies as well as the\nsample complexity of the algorithm. In practice, these choices are rarely\ntested all together in rigorous empirical studies. It is therefore difficult to\ndiscuss and understand what choices, among the high-level algorithmic options\nas well as low-level implementation details, matter. To tackle this issue, we\nimplement more than 50 of these choices in a generic adversarial imitation\nlearning framework and investigate their impacts in a large-scale study (>500k\ntrained agents) with both synthetic and human-generated demonstrations. While\nmany of our findings confirm common practices, some of them are surprising or\neven contradict prior work. In particular, our results suggest that artificial\ndemonstrations are not a good proxy for human data and that the very common\npractice of evaluating imitation algorithms only with synthetic demonstrations\nmay lead to algorithms which perform poorly in the more realistic scenarios\nwith human demonstrations.",
    "descriptor": "",
    "authors": [
      "Manu Orsini",
      "Anton Raichuk",
      "L\u00e9onard Hussenot",
      "Damien Vincent",
      "Robert Dadashi",
      "Sertan Girgin",
      "Matthieu Geist",
      "Olivier Bachem",
      "Olivier Pietquin",
      "Marcin Andrychowicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.00672"
  },
  {
    "id": "arXiv:2106.00673",
    "title": "Fidelity Estimation Improves Noisy-Image Classification with Pretrained  Networks",
    "abstract": "Image classification has significantly improved using deep learning. This is\nmainly due to convolutional neural networks (CNNs) that are capable of learning\nrich feature extractors from large datasets. However, most deep learning\nclassification methods are trained on clean images and are not robust when\nhandling noisy ones, even if a restoration preprocessing step is applied. While\nnovel methods address this problem, they rely on modified feature extractors\nand thus necessitate retraining. We instead propose a method that can be\napplied on a pretrained classifier. Our method exploits a fidelity map estimate\nthat is fused into the internal representations of the feature extractor,\nthereby guiding the attention of the network and making it more robust to noisy\ndata. We improve the noisy-image classification (NIC) results by significantly\nlarge margins, especially at high noise levels, and come close to the fully\nretrained approaches. Furthermore, as proof of concept, we show that when using\nour oracle fidelity map we even outperform the fully retrained methods, whether\ntrained on noisy or restored images.",
    "descriptor": "\nComments: Submitted to IEEE SPL for review\n",
    "authors": [
      "Xiaoyu Lin",
      "Deblina Bhattacharjee",
      "Majed El Helou",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.00673"
  },
  {
    "id": "arXiv:2106.00676",
    "title": "Incorporating Visual Layout Structures for Scientific Text  Classification",
    "abstract": "Classifying the core textual components of a scientific paper-title, author,\nbody text, etc.-is a critical first step in automated scientific document\nunderstanding. Previous work has shown how using elementary layout information,\ni.e., each token's 2D position on the page, leads to more accurate\nclassification. We introduce new methods for incorporating VIsual LAyout\nstructures (VILA), e.g., the grouping of page texts into text lines or text\nblocks, into language models to further improve performance. We show that the\nI-VILA approach, which simply adds special tokens denoting boundaries between\nlayout structures into model inputs, can lead to +1~4.5 F1 Score improvements\nin token classification tasks. Moreover, we design a hierarchical model H-VILA\nthat encodes these layout structures and record a up-to 70% efficiency boost\nwithout hurting prediction accuracy. The experiments are conducted on a newly\ncurated evaluation suite, S2-VLUE, with a novel metric measuring VILA awareness\nand a new dataset covering 19 scientific disciplines with gold annotations.\nPre-trained weights, benchmark datasets, and source code will be available at\nhttps://github.com/allenai/VILA}{https://github.com/allenai/VILA.",
    "descriptor": "\nComments: 13 pages, 5 figures, 6 tables\n",
    "authors": [
      "Zejiang Shen",
      "Kyle Lo",
      "Lucy Lu Wang",
      "Bailey Kuehl",
      "Daniel S. Weld",
      "Doug Downey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00676"
  },
  {
    "id": "arXiv:2106.00677",
    "title": "Bootstrap Your Own Correspondences",
    "abstract": "Geometric feature extraction is a crucial component of point cloud\nregistration pipelines. Recent work has demonstrated how supervised learning\ncan be leveraged to learn better and more compact 3D features. However, those\napproaches' reliance on ground-truth annotation limits their scalability. We\npropose BYOC: a self-supervised approach that learns visual and geometric\nfeatures from RGB-D video without relying on ground-truth pose or\ncorrespondence. Our key observation is that randomly-initialized CNNs readily\nprovide us with good correspondences; allowing us to bootstrap the learning of\nboth visual and geometric features. Our approach combines classic ideas from\npoint cloud registration with more recent representation learning approaches.\nWe evaluate our approach on indoor scene datasets and find that our method\noutperforms traditional and learned descriptors, while being competitive with\ncurrent state-of-the-art supervised approaches.",
    "descriptor": "\nComments: Preprint. 10 pages, 4 figures\n",
    "authors": [
      "Mohamed El Banani",
      "Justin Johnson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00677"
  },
  {
    "id": "arXiv:1910.14379",
    "title": "A family of K3 surfaces and towers of algebraic curves over finite  fields",
    "abstract": "For a family of K3 surfaces we implement a variation of a general\nconstruction of towers of algebraic curves over finite fields given in a\nprevious paper. As a result we get a good tower over $k=\\mathbb{F}_{p^2}$, that\nis optimal if $p=3$.",
    "descriptor": "",
    "authors": [
      "Sergey Galkin",
      "Sergey Rybakov"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/1910.14379"
  },
  {
    "id": "arXiv:2105.14337",
    "title": "Optimal transport with $f$-divergence regularization and generalized  Sinkhorn algorithm",
    "abstract": "Entropic regularization provides a generalization of the original optimal\ntransport problem. It introduces a penalty term defined by the Kullback-Leibler\ndivergence, making the problem more tractable via the celebrated Sinkhorn\nalgorithm. Replacing the Kullback-Leibler divergence with a general\n$f$-divergence leads to a natural generalization. Using convex analysis, we\nextend the theory developed so far to include $f$-divergences defined by\nfunctions of Legendre type, and prove that under some mild conditions, strong\nduality holds, optimums in both the primal and dual problems are attained, the\ngeneralization of the $c$-transform is well-defined, and we give sufficient\nconditions for the generalized Sinkhorn algorithm to converge to an optimal\nsolution. We propose a practical algorithm for computing the regularized\noptimal transport cost and its gradient via the generalized Sinkhorn algorithm.\nFinally, we present experimental results on synthetic 2-dimensional data,\ndemonstrating the effects of using different $f$-divergences for\nregularization, which influences convergence speed, numerical stability and\nsparsity of the optimal coupling.",
    "descriptor": "\nComments: 30 pages, 2 figures\n",
    "authors": [
      "D\u00e1vid Terj\u00e9k",
      "Diego Gonz\u00e1lez-S\u00e1nchez"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14337"
  },
  {
    "id": "arXiv:2106.00005",
    "title": "Quantum Federated Learning with Quantum Data",
    "abstract": "Quantum machine learning (QML) has emerged as a promising field that leans on\nthe developments in quantum computing to explore large complex machine learning\nproblems. Recently, some purely quantum machine learning models were proposed\nsuch as the quantum convolutional neural networks (QCNN) to perform\nclassification on quantum data. However, all of the existing QML models rely on\ncentralized solutions that cannot scale well for large-scale and distributed\nquantum networks. Hence, it is apropos to consider more practical quantum\nfederated learning (QFL) solutions tailored towards emerging quantum network\narchitectures. Indeed, developing QFL frameworks for quantum networks is\ncritical given the fragile nature of computing qubits and the difficulty of\ntransferring them. On top of its practical momentousness, QFL allows for\ndistributed quantum learning by leveraging existing wireless communication\ninfrastructure. This paper proposes the first fully quantum federated learning\nframework that can operate over quantum data and, thus, share the learning of\nquantum circuit parameters in a decentralized manner. First, given the lack of\nexisting quantum federated datasets in the literature, the proposed framework\nbegins by generating the first quantum federated dataset, with a hierarchical\ndata format, for distributed quantum networks. Then, clients sharing QCNN\nmodels are fed with the quantum data to perform a classification task.\nSubsequently, the server aggregates the learnable quantum circuit parameters\nfrom clients and performs federated averaging. Extensive experiments are\nconducted to evaluate and validate the effectiveness of the proposed QFL\nsolution. This work is the first to combine Google's TensorFlow Federated and\nTensorFlow Quantum in a practical implementation.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Mahdi Chehimi",
      "Walid Saad"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.00005"
  },
  {
    "id": "arXiv:2106.00009",
    "title": "Deep-Learning Discovers Macroscopic Governing Equations for Viscous  Gravity Currents from Microscopic Simulation Data",
    "abstract": "Although deep-learning has been successfully applied in a variety of science\nand engineering problems owing to its strong high-dimensional nonlinear mapping\ncapability, it is of limited use in scientific knowledge discovery. In this\nwork, we propose a deep-learning based framework to discover the macroscopic\ngoverning equation of viscous gravity current based on high-resolution\nmicroscopic simulation data without the need for prior knowledge of underlying\nterms. For two typical scenarios with different viscosity ratios, the\ndeep-learning based equations exactly capture the same dominated terms as the\ntheoretically derived equations for describing long-term asymptotic behaviors,\nwhich validates the proposed framework. Unknown macroscopic equations are then\nobtained for describing short-term behaviors, and hidden mechanisms are\neventually discovered with deep-learned explainable compensation terms and\ncorresponding coefficients. Consequently, the presented deep-learning framework\nshows considerable potential for discovering unrevealed intrinsic laws in\nscientific semantic space from raw experimental or simulation results in data\nspace.",
    "descriptor": "\nComments: 10 pages, 2 figures,and SI\n",
    "authors": [
      "Junsheng Zeng",
      "Hao Xu",
      "Yuntian Chen",
      "Dongxiao Zhang"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2106.00009"
  },
  {
    "id": "arXiv:2106.00043",
    "title": "StarGAN-ZSVC: Towards Zero-Shot Voice Conversion in Low-Resource  Contexts",
    "abstract": "Voice conversion is the task of converting a spoken utterance from a source\nspeaker so that it appears to be said by a different target speaker while\nretaining the linguistic content of the utterance. Recent advances have led to\nmajor improvements in the quality of voice conversion systems. However, to be\nuseful in a wider range of contexts, voice conversion systems would need to be\n(i) trainable without access to parallel data, (ii) work in a zero-shot setting\nwhere both the source and target speakers are unseen during training, and (iii)\nrun in real time or faster. Recent techniques fulfil one or two of these\nrequirements, but not all three. This paper extends recent voice conversion\nmodels based on generative adversarial networks (GANs), to satisfy all three of\nthese conditions. We specifically extend the recent StarGAN-VC model by\nconditioning it on a speaker embedding (from a potentially unseen speaker).\nThis allows the model to be used in a zero-shot setting, and we therefore call\nit StarGAN-ZSVC. We compare StarGAN-ZSVC against other voice conversion\ntechniques in a low-resource setting using a small 9-minute training set.\nCompared to AutoVC -- another recent neural zero-shot approach -- we observe\nthat StarGAN-ZSVC gives small improvements in the zero-shot setting, showing\nthat real-time zero-shot voice conversion is possible even for a model trained\non very little data. Further work is required to see whether scaling up\nStarGAN-ZSVC will also improve zero-shot voice conversion quality in\nhigh-resource contexts.",
    "descriptor": "\nComments: 16 pages, 3 figures. Published in Springer Communications in Computer and Information Science, Artificial Intelligence Research (SACAIR 2021), vol. 1342, pp. 69-84, 2020\n",
    "authors": [
      "Matthew Baas",
      "Herman Kamper"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.00043"
  },
  {
    "id": "arXiv:2106.00052",
    "title": "Low-Resource Spoken Language Identification Using Self-Attentive Pooling  and Deep 1D Time-Channel Separable Convolutions",
    "abstract": "This memo describes NTR/TSU winning submission for Low Resource ASR challenge\nat Dialog2021 conference, language identification track.\nSpoken Language Identification (LID) is an important step in a multilingual\nAutomated Speech Recognition (ASR) system pipeline. Traditionally, the ASR task\nrequires large volumes of labeled data that are unattainable for most of the\nworld's languages, including most of the languages of Russia. In this memo, we\nshow that a convolutional neural network with a Self-Attentive Pooling layer\nshows promising results in low-resource setting for the language identification\ntask and set up a SOTA for the Low Resource ASR challenge dataset.\nAdditionally, we compare the structure of confusion matrices for this and\nsignificantly more diverse VoxForge dataset and state and substantiate the\nhypothesis that whenever the dataset is diverse enough so that the other\nclassification factors, like gender, age etc. are well-averaged, the confusion\nmatrix for LID system bears the language similarity measure.",
    "descriptor": "\nComments: Accepted to Dialog2021. arXiv admin note: text overlap with arXiv:2104.11985\n",
    "authors": [
      "Roman Bedyakin",
      "Nikolay Mikhaylovskiy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.00052"
  },
  {
    "id": "arXiv:2106.00072",
    "title": "Early Detection of COVID-19 Hotspots Using Spatio-Temporal Data",
    "abstract": "Recently, the Centers for Disease Control and Prevention (CDC) has worked\nwith other federal agencies to identify counties with increasing coronavirus\ndisease 2019 (COVID-19) incidence (hotspots) and offers support to local health\ndepartments to limit the spread of the disease. Understanding the\nspatio-temporal dynamics of hotspot events is of great importance to support\npolicy decisions and prevent large-scale outbreaks. This paper presents a\nspatio-temporal Bayesian framework for early detection of COVID-19 hotspots (at\nthe county level) in the United States. We assume both the observed number of\ncases and hotspots depend on a class of latent random variables, which encode\nthe underlying spatio-temporal dynamics of the transmission of COVID-19. Such\nlatent variables follow a zero-mean Gaussian process, whose covariance is\nspecified by a non-stationary kernel function. The most salient feature of our\nkernel function is that deep neural networks are introduced to enhance the\nmodel's representative power while still enjoying the interpretability of the\nkernel. We derive a sparse model and fit the model using a variational learning\nstrategy to circumvent the computational intractability for large data sets.\nOur model demonstrates better interpretability and superior hotspot-detection\nperformance compared to other baseline methods.",
    "descriptor": "",
    "authors": [
      "Shixiang Zhu",
      "Alexander Bukharin",
      "Liyan Xie",
      "Shihao Yang",
      "Pinar Keskinocak",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.00072"
  },
  {
    "id": "arXiv:2106.00075",
    "title": "Variational Combinatorial Sequential Monte Carlo Methods for Bayesian  Phylogenetic Inference",
    "abstract": "Bayesian phylogenetic inference is often conducted via local or sequential\nsearch over topologies and branch lengths using algorithms such as random-walk\nMarkov chain Monte Carlo (MCMC) or Combinatorial Sequential Monte Carlo (CSMC).\nHowever, when MCMC is used for evolutionary parameter learning, convergence\nrequires long runs with inefficient exploration of the state space. We\nintroduce Variational Combinatorial Sequential Monte Carlo (VCSMC), a powerful\nframework that establishes variational sequential search to learn distributions\nover intricate combinatorial structures. We then develop nested CSMC, an\nefficient proposal distribution for CSMC and prove that nested CSMC is an exact\napproximation to the (intractable) locally optimal proposal. We use nested CSMC\nto define a second objective, VNCSMC which yields tighter lower bounds than\nVCSMC. We show that VCSMC and VNCSMC are computationally efficient and explore\nhigher probability spaces than existing methods on a range of tasks.",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Antonio Khalil Moretti",
      "Liyi Zhang",
      "Christian A. Naesseth",
      "Hadiah Venner",
      "David Blei",
      "Itsik Pe'er"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.00075"
  },
  {
    "id": "arXiv:2106.00103",
    "title": "Control Occupation Kernel Regression for Nonlinear Control-Affine  Systems",
    "abstract": "This manuscript presents an algorithm for obtaining an approximation of\nnonlinear high order control affine dynamical systems, that leverages the\ncontrolled trajectories as the central unit of information. As the fundamental\nbasis elements leveraged in approximation, higher order control occupation\nkernels represent iterated integration after multiplication by a given\ncontroller in a vector valued reproducing kernel Hilbert space. In a\nregularized regression setting, the unique optimizer for a particular\noptimization problem is expressed as a linear combination of these occupation\nkernels, which converts an infinite dimensional optimization problem to a\nfinite dimensional optimization problem through the representer theorem.\nInterestingly, the vector valued structure of the Hilbert space allows for\nsimultaneous approximation of the drift and control effectiveness components of\nthe control affine system. Several experiments are performed to demonstrate the\neffectiveness of the approach.",
    "descriptor": "",
    "authors": [
      "Moad Abudia",
      "Tejasvi Channagiri",
      "Joel A. Rosenfeld",
      "Rushikesh Kamalapurkar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2106.00103"
  },
  {
    "id": "arXiv:2106.00106",
    "title": "Anti-Koopmanism",
    "abstract": "This article addresses several longstanding misconceptions concerning Koopman\noperators, including the existence of lattices of eigenfunctions, common\neigenfunctions between Koopman operators, and boundedness and compactness of\nKoopman operators, among others. Counterexamples are provided for each\nmisconception. This manuscript also proves that the Gaussian RBF's native space\nonly supports bounded Koopman operator corresponding to affine dynamics, which\nshows that the assumption of boundedness is very limiting. A framework for DMD\nis presented that requires only densely defined Koopman operators over\nreproducing kernel Hilbert spaces, and the effectiveness of this approach is\ndemonstrated through reconstruction examples.",
    "descriptor": "",
    "authors": [
      "Efrain Gonzalez",
      "Moad Abudia",
      "Michael Jury",
      "Rushikesh Kamalapurkar",
      "Joel A. Rosenfeld"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00106"
  },
  {
    "id": "arXiv:2106.00152",
    "title": "Visualization in Astrophysics: Developing New Methods, Discovering Our  Universe, and Educating the Earth",
    "abstract": "We present a state-of-the-art report on visualization in astrophysics. We\nsurvey representative papers from both astrophysics and visualization and\nprovide a taxonomy of existing approaches based on data analysis tasks. The\napproaches are classified based on five categories: data wrangling, data\nexploration, feature identification, object reconstruction, as well as\neducation and outreach. Our unique contribution is to combine the diverse\nviewpoints from both astronomers and visualization experts to identify\nchallenges and opportunities for visualization in astrophysics. The main goal\nis to provide a reference point to bring modern data analysis and visualization\ntechniques to the rich datasets in astrophysics.",
    "descriptor": "",
    "authors": [
      "Fangfei Lan",
      "Michael Young",
      "Lauren Anderson",
      "Anders Ynnerman",
      "Alexander Bock",
      "Michelle A. Borkin",
      "Angus G. Forbes",
      "Juna A. Kollmeier",
      "Bei Wang"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00152"
  },
  {
    "id": "arXiv:2106.00199",
    "title": "Agent mental models and Bayesian rules as a tool to create opinion  dynamics models",
    "abstract": "Traditional opinion dynamics models are simple and yet, enough to explore the\nconsequences in basic scenarios. But, to better describe problems such as\npolarization and extremism, we might need to include details about human biases\nand other cognitive characteristics. In this paper, I explain how we can\ndescribe and use mental models and assumptions of the agents using\nBayesian-inspired model building. The relationship between human rationality\nand Bayesian methods will be explored, and we will see that Bayesian ideas can\nindeed be used to explain how humans reason. We will see how to use\nBayesian-inspired rules using the simplest version of the Continuous Opinions\nand Discrete Actions (CODA) model. From that, we will explore how we can obtain\nupdate rules that include human behavioral characteristics such as confirmation\nbias, motivated reasoning, or our tendency to change opinions much less than we\nshould.\nKeywords: Opinion dynamics, Bayesian methods, Cognition, CODA, Agent-based\nmodels",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Andre C. R. Martins"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2106.00199"
  },
  {
    "id": "arXiv:2106.00254",
    "title": "UAV Aided Over-the-Air Computation",
    "abstract": "Over-the-air computation (AirComp) seamlessly integrates communication and\ncomputation by exploiting the waveform superposition property of\nmultiple-access channels. Different from the existing works that focus on\ntransceiver design of AirComp over static networks, this paper considers an\nunmanned aerial vehicle (UAV) aided AirComp system, where the UAV as a flying\nbase station aggregates data from mobile sensors. The trajectory design of the\nUAV provides an additional degree of freedom to improve the performance of\nAirComp. Our goal is to minimize the time-averaged mean-squared error (MSE) of\nAirComp by jointly optimizing the UAV trajectory, receive normalizing factors,\nand sensors' transmit power. To this end, we first propose a novel and\nequivalent problem transformation by introducing intermediate variables. This\nreformulation leads to a convex subproblem when fixing any other two blocks of\nvariables, thereby enabling efficient algorithm design based on the principle\nof block coordinate descent and alternating direction method of multipliers\n(ADMM) techniques. In particular, we derive the optimal closed-form solutions\nfor normalizing factors and intermediate variables optimization subproblems. We\nalso recast the convex trajectory design subproblem into an ADMM form and\nobtain the closed-form expressions for each variable updating. Simulation\nresults show that the proposed algorithm achieves a smaller time-averaged MSE\nwhile reducing the simulation time by orders of magnitude compared to\nstate-of-the-art algorithms.",
    "descriptor": "\nComments: 30 pages, 9 figures\n",
    "authors": [
      "Min Fu",
      "Yong Zhou",
      "Yuanming Shi",
      "Wei Chen",
      "Rui Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00254"
  },
  {
    "id": "arXiv:2106.00259",
    "title": "3D WaveUNet: 3D Wavelet Integrated Encoder-Decoder Network for Neuron  Segmentation",
    "abstract": "3D neuron segmentation is a key step for the neuron digital reconstruction,\nwhich is essential for exploring brain circuits and understanding brain\nfunctions. However, the fine line-shaped nerve fibers of neuron could spread in\na large region, which brings great computational cost to the segmentation in 3D\nneuronal images. Meanwhile, the strong noises and disconnected nerve fibers in\nthe image bring great challenges to the task. In this paper, we propose a 3D\nwavelet and deep learning based 3D neuron segmentation method. The neuronal\nimage is first partitioned into neuronal cubes to simplify the segmentation\ntask. Then, we design 3D WaveUNet, the first 3D wavelet integrated\nencoder-decoder network, to segment the nerve fibers in the cubes; the wavelets\ncould assist the deep networks in suppressing data noise and connecting the\nbroken fibers. We also produce a Neuronal Cube Dataset (NeuCuDa) using the\nbiggest available annotated neuronal image dataset, BigNeuron, to train 3D\nWaveUNet. Finally, the nerve fibers segmented in cubes are assembled to\ngenerate the complete neuron, which is digitally reconstructed using an\navailable automatic tracing algorithm. The experimental results show that our\nneuron segmentation method could completely extract the target neuron in noisy\nneuronal images. The integrated 3D wavelets can efficiently improve the\nperformance of 3D neuron segmentation and reconstruction. The code and\npre-trained models for this work will be available at\nhttps://github.com/LiQiufu/3D-WaveUNet.",
    "descriptor": "",
    "authors": [
      "Qiufu Li",
      "Linlin Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00259"
  },
  {
    "id": "arXiv:2106.00260",
    "title": "An adaptive scalable fully implicit algorithm based on stabilized finite  element for reduced visco-resistive MHD",
    "abstract": "The magnetohydrodynamics (MHD) equations are continuum models used in the\nstudy of a wide range of plasma physics systems, including the evolution of\ncomplex plasma dynamics in tokamak disruptions. However, efficient numerical\nsolution methods for MHD are extremely challenging due to disparate time and\nlength scales, strong hyperbolic phenomena, and nonlinearity. Therefore the\ndevelopment of scalable, implicit MHD algorithms and high-resolution adaptive\nmesh refinement strategies is of considerable importance. In this work, we\ndevelop a high-order stabilized finite-element algorithm for the reduced\nvisco-resistive MHD equations based on the MFEM finite element library\n(mfem.org). The scheme is fully implicit, solved with the Jacobian-free\nNewton-Krylov (JFNK) method with a physics-based preconditioning strategy. Our\npreconditioning strategy is a generalization of the physics-based\npreconditioning methods in [Chacon, et al, JCP 2002] to adaptive, stabilized\nfinite elements. Algebraic multigrid methods are used to invert sub-block\noperators to achieve scalability. A parallel adaptive mesh refinement scheme\nwith dynamic load-balancing is implemented to efficiently resolve the\nmulti-scale spatial features of the system. Our implementation uses the MFEM\nframework, which provides arbitrary-order polynomials and flexible adaptive\nconforming and non-conforming meshes capabilities. Results demonstrate the\naccuracy, efficiency, and scalability of the implicit scheme in the presence of\nlarge scale disparity. The potential of the AMR approach is demonstrated on an\nisland coalescence problem in the high Lundquist-number regime ($\\ge 10^7$)\nwith the successful resolution of plasmoid instabilities and thin current\nsheets.",
    "descriptor": "\nComments: 41 pages, 21 figures\n",
    "authors": [
      "Qi Tang",
      "Luis Chacon",
      "Tzanio V. Kolev",
      "John N. Shadid",
      "Xian-Zhu Tang"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00260"
  },
  {
    "id": "arXiv:2106.00286",
    "title": "On Riemannian Optimization over Positive Definite Matrices with the  Bures-Wasserstein Geometry",
    "abstract": "In this paper, we comparatively analyze the Bures-Wasserstein (BW) geometry\nwith the popular Affine-Invariant (AI) geometry for Riemannian optimization on\nthe symmetric positive definite (SPD) matrix manifold. Our study begins with an\nobservation that the BW metric has a linear dependence on SPD matrices in\ncontrast to the quadratic dependence of the AI metric. We build on this to show\nthat the BW metric is a more suitable and robust choice for several Riemannian\noptimization problems over ill-conditioned SPD matrices. We show that the BW\ngeometry has a non-negative curvature, which further improves convergence rates\nof algorithms over the non-positively curved AI geometry. Finally, we verify\nthat several popular cost functions, which are known to be geodesic convex\nunder the AI geometry, are also geodesic convex under the BW geometry.\nExtensive experiments on various applications support our findings.",
    "descriptor": "",
    "authors": [
      "Andi Han",
      "Bamdev Mishra",
      "Pratik Jawanpuria",
      "Junbin Gao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00286"
  },
  {
    "id": "arXiv:2106.00293",
    "title": "A Non-commutative Extension of Lee-Seung's Algorithm for Positive  Semidefinite Factorizations",
    "abstract": "Given a matrix $X\\in \\mathbb{R}_+^{m\\times n}$ with nonnegative entries, a\nPositive Semidefinite (PSD) factorization of $X$ is a collection of $r \\times\nr$-dimensional PSD matrices $\\{A_i\\}$ and $\\{B_j\\}$ satisfying $X_{ij}=\n\\mathrm{tr}(A_i B_j)$ for all $\\ i\\in [m],\\ j\\in [n]$. PSD factorizations are\nfundamentally linked to understanding the expressiveness of semidefinite\nprograms as well as the power and limitations of quantum resources in\ninformation theory. The PSD factorization task generalizes the Non-negative\nMatrix Factorization (NMF) problem where we seek a collection of\n$r$-dimensional nonnegative vectors $\\{a_i\\}$ and $\\{b_j\\}$ satisfying $X_{ij}=\na_i^\\top b_j$, for all $i\\in [m],\\ j\\in [n]$ -- one can recover the latter\nproblem by choosing matrices in the PSD factorization to be diagonal. The most\nwidely used algorithm for computing NMFs of a matrix is the Multiplicative\nUpdate algorithm developed by Lee and Seung, in which nonnegativity of the\nupdates is preserved by scaling with positive diagonal matrices. In this paper,\nwe describe a non-commutative extension of Lee-Seung's algorithm, which we call\nthe Matrix Multiplicative Update (MMU) algorithm, for computing PSD\nfactorizations. The MMU algorithm ensures that updates remain PSD by congruence\nscaling with the matrix geometric mean of appropriate PSD matrices, and it\nretains the simplicity of implementation that Lee-Seung's algorithm enjoys.\nBuilding on the Majorization-Minimization framework, we show that under our\nupdate scheme the squared loss objective is non-increasing and fixed points\ncorrespond to critical points. The analysis relies on Lieb's Concavity Theorem.\nBeyond PSD factorizations, we use the MMU algorithm as a primitive to calculate\nblock-diagonal PSD factorizations and tensor PSD factorizations. We demonstrate\nthe utility of our method with experiments on real and synthetic data.",
    "descriptor": "\nComments: Comments welcome\n",
    "authors": [
      "Yong Sheng Soh",
      "Antonios Varvitsiotis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00293"
  },
  {
    "id": "arXiv:2106.00311",
    "title": "What's a good imputation to predict with missing values?",
    "abstract": "How to learn a good predictor on data with missing values? Most efforts focus\non first imputing as well as possible and second learning on the completed data\nto predict the outcome. Yet, this widespread practice has no theoretical\ngrounding. Here we show that for almost all imputation functions, an\nimpute-then-regress procedure with a powerful learner is Bayes optimal. This\nresult holds for all missing-values mechanisms, in contrast with the classic\nstatistical results that require missing-at-random settings to use imputation\nin probabilistic modeling. Moreover, it implies that perfect conditional\nimputation may not be needed for good prediction asymptotically. In fact, we\nshow that on perfectly imputed data the best regression function will generally\nbe discontinuous, which makes it hard to learn. Crafting instead the imputation\nso as to leave the regression function unchanged simply shifts the problem to\nlearning discontinuous imputations. Rather, we suggest that it is easier to\nlearn imputation and regression jointly. We propose such a procedure, adapting\nNeuMiss, a neural network capturing the conditional links across observed and\nunobserved variables whatever the missing-value pattern. Experiments confirm\nthat joint imputation and regression through NeuMiss is better than various two\nstep procedures in our experiments with finite number of samples.",
    "descriptor": "",
    "authors": [
      "Marine Le Morvan",
      "Julie Josse",
      "Erwan Scornet",
      "Ga\u00ebl Varoquaux"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00311"
  },
  {
    "id": "arXiv:2106.00354",
    "title": "Binary extended formulations and sequential convexification",
    "abstract": "A binarization of a bounded variable $x$ is a linear formulation with\nvariables $x$ and additional binary variables $y_1,\\dots, y_k$, so that\nintegrality of $x$ is implied by the integrality of $y_1,\\dots, y_k$. A binary\nextended formulation of a polyhedron $P$ is obtained by adding to the original\ndescription of $P$ binarizations of some of its variables. In the context of\nmixed-integer programming, imposing integrality on 0/1 variables rather than on\ngeneral integer variables has interesting convergence properties and has been\nstudied both from the theoretical and from the practical point of view.\nWe propose a notion of \\emph{natural} binarizations and binary extended\nformulations, encompassing all the ones studied in the literature. We give a\nsimple characterization of the vertices of such formulations, which allows us\nto study their behavior with respect to sequential convexification. %0/1\ndisjunctions. In particular, given a binary extended formulation and % a\nbinarization $B$ of one of its variables $x$, we study a parameter that\nmeasures the progress made towards ensuring the integrality of $x$ via\napplication of sequential convexification. We formulate this parameter, which\nwe call rank, as the solution of a set covering problem and express it exactly\nfor the classical binarizations from the literature.",
    "descriptor": "",
    "authors": [
      "Manuel Aprile",
      "Michele Conforti",
      "Marco Di Summa"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.00354"
  },
  {
    "id": "arXiv:2106.00356",
    "title": "Predicting COVID-19 Spread from Large-Scale Mobility Data",
    "abstract": "To manage the COVID-19 epidemic effectively, decision-makers in public health\nneed accurate forecasts of case numbers. A potential near real-time predictor\nof future case numbers is human mobility; however, research on the predictive\npower of mobility is lacking. To fill this gap, we introduce a novel model for\nepidemic forecasting based on mobility data, called mobility marked Hawkes\nmodel. The proposed model consists of three components: (1) A Hawkes process\ncaptures the transmission dynamics of infectious diseases. (2) A mark modulates\nthe rate of infections, thus accounting for how the reproduction number R\nvaries across space and time. The mark is modeled using a regularized Poisson\nregression based on mobility covariates. (3) A correction procedure\nincorporates new cases seeded by people traveling between regions. Our model\nwas evaluated on the COVID-19 epidemic in Switzerland. Specifically, we used\nmobility data from February through April 2020, amounting to approximately 1.5\nbillion trips. Trip counts were derived from large-scale telecommunication\ndata, i.e., cell phone pings from the Swisscom network, the largest\ntelecommunication provider in Switzerland. We compared our model against\nvarious state-of-the-art baselines in terms of out-of-sample root mean squared\nerror. We found that our model outperformed the baselines by 15.52%. The\nimprovement was consistently achieved across different forecast horizons\nbetween 5 and 21 days. In addition, we assessed the predictive power of\nconventional point of interest data, confirming that telecommunication data is\nsuperior. To the best of our knowledge, our work is the first to predict the\nspread of COVID-19 from telecommunication data. Altogether, our work\ncontributes to previous research by developing a scalable early warning system\nfor decision-makers in public health tasked with controlling the spread of\ninfectious diseases.",
    "descriptor": "\nComments: 9 pages, 3 figures. Accepted for publication in KDD '21: 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n",
    "authors": [
      "Amray Schwabe",
      "Joel Persson",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.00356"
  },
  {
    "id": "arXiv:2106.00373",
    "title": "Hybrid Deep Neural Network for Brachial Plexus Nerve Segmentation in  Ultrasound Images",
    "abstract": "Ultrasound-guided regional anesthesia (UGRA) can replace general anesthesia\n(GA), improving pain control and recovery time. This method can be applied on\nthe brachial plexus (BP) after clavicular surgeries. However, identification of\nthe BP from ultrasound (US) images is difficult, even for trained\nprofessionals. To address this problem, convolutional neural networks (CNNs)\nand more advanced deep neural networks (DNNs) can be used for identification\nand segmentation of the BP nerve region. In this paper, we propose a hybrid\nmodel consisting of a classification model followed by a segmentation model to\nsegment BP nerve regions in ultrasound images. A CNN model is employed as a\nclassifier to precisely select the images with the BP region. Then, a U-net or\nM-net model is used for the segmentation. Our experimental results indicate\nthat the proposed hybrid model significantly improves the segmentation\nperformance over a single segmentation model.",
    "descriptor": "\nComments: The first two authors contributed equally\n",
    "authors": [
      "Juul P.A. van Boxtel",
      "Vincent R.J. Vousten",
      "Josien Pluim",
      "Nastaran Mohammadian Rad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00373"
  },
  {
    "id": "arXiv:2106.00397",
    "title": "Strong approximation of Bessel processes",
    "abstract": "We consider the path approximation of Bessel processes and develop a new and\nefficient algorithm. This study is based on a recent work by the authors, on\nthe path approximation of the Brownian motion, and on the construction of\nspecific own techniques. It is part of the family of the so-called\n$\\varepsilon$-strong approximations. More precisely, our approach constructs\njointly the sequences of exit times and corresponding exit positions of some\nwell-chosen domains, the construction of these domains being an important step.\nBased on this procedure, we emphasize an algorithm which is easy to implement.\nMoreover, we can develop the method for any dimension. We treat separately the\ninteger dimension case and the non integer framework, each situation requiring\nappropriate techniques. In particular, for both situations, we show the\nconvergence of the scheme and provide the control of the efficiency with\nrespect to the small parameter $\\varepsilon$. We expand the theoretical part by\na series of numerical developments.",
    "descriptor": "",
    "authors": [
      "Madalina Deaconu",
      "Samuel Herrmann"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00397"
  },
  {
    "id": "arXiv:2106.00418",
    "title": "Post-Contextual-Bandit Inference",
    "abstract": "Contextual bandit algorithms are increasingly replacing non-adaptive A/B\ntests in e-commerce, healthcare, and policymaking because they can both improve\noutcomes for study participants and increase the chance of identifying good or\neven best policies. To support credible inference on novel interventions at the\nend of the study, nonetheless, we still want to construct valid confidence\nintervals on average treatment effects, subgroup effects, or value of new\npolicies. The adaptive nature of the data collected by contextual bandit\nalgorithms, however, makes this difficult: standard estimators are no longer\nasymptotically normally distributed and classic confidence intervals fail to\nprovide correct coverage. While this has been addressed in non-contextual\nsettings by using stabilized estimators, the contextual setting poses unique\nchallenges that we tackle for the first time in this paper. We propose the\nContextual Adaptive Doubly Robust (CADR) estimator, the first estimator for\npolicy value that is asymptotically normal under contextual adaptive data\ncollection. The main technical challenge in constructing CADR is designing\nadaptive and consistent conditional standard deviation estimators for\nstabilization. Extensive numerical experiments using 57 OpenML datasets\ndemonstrate that confidence intervals based on CADR uniquely provide correct\ncoverage.",
    "descriptor": "",
    "authors": [
      "Aur\u00e9lien Bibaut",
      "Antoine Chambaz",
      "Maria Dimakopoulou",
      "Nathan Kallus",
      "Mark van der Laan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.00418"
  },
  {
    "id": "arXiv:2106.00432",
    "title": "Invertible Surrogate Models: Joint surrogate modelling and  reconstruction of Laser-Wakefield Acceleration by invertible neural networks",
    "abstract": "Invertible neural networks are a recent technique in machine learning\npromising neural network architectures that can be run in forward and reverse\nmode. In this paper, we will be introducing invertible surrogate models that\napproximate complex forward simulation of the physics involved in laser plasma\naccelerators: iLWFA. The bijective design of the surrogate model also provides\nall means for reconstruction of experimentally acquired diagnostics. The\nquality of our invertible laser wakefield acceleration network will be verified\non a large set of numerical LWFA simulations.",
    "descriptor": "",
    "authors": [
      "Friedrich Bethke",
      "Richard Pausch",
      "Patrick Stiller",
      "Alexander Debus",
      "Michael Bussmann",
      "Nico Hoffmann"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Machine Learning (cs.LG)",
      "Accelerator Physics (physics.acc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00432"
  },
  {
    "id": "arXiv:2106.00436",
    "title": "COV-ECGNET: COVID-19 detection using ECG trace images with deep  convolutional neural network",
    "abstract": "The reliable and rapid identification of the COVID-19 has become crucial to\nprevent the rapid spread of the disease, ease lockdown restrictions and reduce\npressure on public health infrastructures. Recently, several methods and\ntechniques have been proposed to detect the SARS-CoV-2 virus using different\nimages and data. However, this is the first study that will explore the\npossibility of using deep convolutional neural network (CNN) models to detect\nCOVID-19 from electrocardiogram (ECG) trace images. In this work, COVID-19 and\nother cardiovascular diseases (CVDs) were detected using deep-learning\ntechniques. A public dataset of ECG images consists of 1937 images from five\ndistinct categories, such as Normal, COVID-19, myocardial infarction (MI),\nabnormal heartbeat (AHB), and recovered myocardial infarction (RMI) were used\nin this study. Six different deep CNN models (ResNet18, ResNet50, ResNet101,\nInceptionV3, DenseNet201, and MobileNetv2) were used to investigate three\ndifferent classification schemes: two-class classification (Normal vs\nCOVID-19); three-class classification (Normal, COVID-19, and Other CVDs), and\nfinally, five-class classification (Normal, COVID-19, MI, AHB, and RMI). For\ntwo-class and three-class classification, Densenet201 outperforms other\nnetworks with an accuracy of 99.1%, and 97.36%, respectively; while for the\nfive-class classification, InceptionV3 outperforms others with an accuracy of\n97.83%. ScoreCAM visualization confirms that the networks are learning from the\nrelevant area of the trace images. Since the proposed method uses ECG trace\nimages which can be captured by smartphones and are readily available\nfacilities in low-resources countries, this study will help in faster\ncomputer-aided diagnosis of COVID-19 and other cardiac abnormalities.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Tawsifur Rahman",
      "Alex Akinbi",
      "Muhammad E. H. Chowdhury",
      "Tarik A. Rashid",
      "Abdulkadir \u015eeng\u00fcr",
      "Amith Khandakar",
      "Khandaker Reajul Islam",
      "Aras M. Ismael"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00436"
  },
  {
    "id": "arXiv:2106.00456",
    "title": "Federated Estimation of Causal Effects from Observational Data",
    "abstract": "Many modern applications collect data that comes in federated spirit, with\ndata kept locally and undisclosed. Till date, most insight into the causal\ninference requires data to be stored in a central repository. We present a\nnovel framework for causal inference with federated data sources. We assess and\nintegrate local causal effects from different private data sources without\ncentralizing them. Then, the treatment effects on subjects from observational\ndata using a non-parametric reformulation of the classical potential outcomes\nframework is estimated. We model the potential outcomes as a random function\ndistributed by Gaussian processes, whose defining parameters can be efficiently\nlearned from multiple data sources, respecting privacy constraints. We\ndemonstrate the promise and efficiency of the proposed approach through a set\nof simulated and real-world benchmark examples.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Thanh Vinh Vo",
      "Trong Nghia Hoang",
      "Young Lee",
      "Tze-Yun Leong"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00456"
  },
  {
    "id": "arXiv:2106.00496",
    "title": "RAI-Net: Range-Adaptive LiDAR Point Cloud Frame Interpolation Network",
    "abstract": "LiDAR point cloud frame interpolation, which synthesizes the intermediate\nframe between the captured frames, has emerged as an important issue for many\napplications. Especially for reducing the amounts of point cloud transmission,\nit is by predicting the intermediate frame based on the reference frames to\nupsample data to high frame rate ones. However, due to high-dimensional and\nsparse characteristics of point clouds, it is more difficult to predict the\nintermediate frame for LiDAR point clouds than videos. In this paper, we\npropose a novel LiDAR point cloud frame interpolation method, which exploits\nrange images (RIs) as an intermediate representation with CNNs to conduct the\nframe interpolation process. Considering the inherited characteristics of RIs\ndiffer from that of color images, we introduce spatially adaptive convolutions\nto extract range features adaptively, while a high-efficient flow estimation\nmethod is presented to generate optical flows. The proposed model then warps\nthe input frames and range features, based on the optical flows to synthesize\nthe interpolated frame. Extensive experiments on the KITTI dataset have clearly\ndemonstrated that our method consistently achieves superior frame interpolation\nresults with better perceptual quality to that of using state-of-the-art video\nframe interpolation methods. The proposed method could be integrated into any\nLiDAR point cloud compression systems for inter prediction.",
    "descriptor": "\nComments: Accepted by the IEEE International Symposium on Broadband Multimedia Systems and Broadcasting 2021\n",
    "authors": [
      "Lili Zhao",
      "Zezhi Zhu",
      "Xuhu Lin",
      "Xuezhou Guo",
      "Qian Yin",
      "Wenyi Wang",
      "Jianwen Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00496"
  },
  {
    "id": "arXiv:2106.00504",
    "title": "Two-stage domain adapted training for better generalization in  real-world image restoration and super-resolution",
    "abstract": "It is well-known that in inverse problems, end-to-end trained networks\noverfit the degradation model seen in the training set, i.e., they do not\ngeneralize to other types of degradations well. Recently, an approach to first\nmap images downsampled by unknown filters to bicubicly downsampled look-alike\nimages was proposed to successfully super-resolve such images. In this paper,\nwe show that any inverse problem can be formulated by first mapping the input\ndegraded images to an intermediate domain, and then training a second network\nto form output images from these intermediate images. Furthermore, the best\nintermediate domain may vary according to the task. Our experimental results\ndemonstrate that this two-stage domain-adapted training strategy does not only\nachieve better results on a given class of unknown degradations but can also\ngeneralize to other unseen classes of degradations better.",
    "descriptor": "\nComments: Accepted for publication in IEEE ICIP 2021 Conference\n",
    "authors": [
      "Cansu Korkmaz",
      "A.Murat Tekalp",
      "Zafer Dogan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00504"
  },
  {
    "id": "arXiv:2106.00514",
    "title": "Entropy and the Discrete Central Limit Theorem",
    "abstract": "A strengthened version of the central limit theorem for discrete random\nvariables is established, relying only on information-theoretic tools and\nelementary arguments. It is shown that the relative entropy between the\nstandardised sum of $n$ independent and identically distributed lattice random\nvariables and an appropriately discretised Gaussian, vanishes as $n\\to\\infty$.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Lampros Gavalakis",
      "Ioannis Kontoyiannis"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00514"
  },
  {
    "id": "arXiv:2106.00528",
    "title": "Transformation Models for Flexible Posteriors in Variational Bayes",
    "abstract": "The main challenge in Bayesian models is to determine the posterior for the\nmodel parameters. Already, in models with only one or few parameters, the\nanalytical posterior can only be determined in special settings. In Bayesian\nneural networks, variational inference is widely used to approximate\ndifficult-to-compute posteriors by variational distributions. Usually,\nGaussians are used as variational distributions (Gaussian-VI) which limits the\nquality of the approximation due to their limited flexibility. Transformation\nmodels on the other hand are flexible enough to fit any distribution. Here we\npresent transformation model-based variational inference (TM-VI) and\ndemonstrate that it allows to accurately approximate complex posteriors in\nmodels with one parameter and also works in a mean-field fashion for\nmulti-parameter models like neural networks.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Sefan H\u00f6rtling",
      "Daniel Dold",
      "Oliver D\u00fcrr",
      "Beate Sick"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00528"
  },
  {
    "id": "arXiv:2106.00531",
    "title": "Supervised Speech Representation Learning for Parkinson's Disease  Classification",
    "abstract": "Recently proposed automatic pathological speech classification techniques use\nunsupervised auto-encoders to obtain a high-level abstract representation of\nspeech. Since these representations are learned based on reconstructing the\ninput, there is no guarantee that they are robust to pathology-unrelated cues\nsuch as speaker identity information. Further, these representations are not\nnecessarily discriminative for pathology detection. In this paper, we exploit\nsupervised auto-encoders to extract robust and discriminative speech\nrepresentations for Parkinson's disease classification. To reduce the influence\nof speaker variabilities unrelated to pathology, we propose to obtain speaker\nidentity-invariant representations by adversarial training of an auto-encoder\nand a speaker identification task. To obtain a discriminative representation,\nwe propose to jointly train an auto-encoder and a pathological speech\nclassifier. Experimental results on a Spanish database show that the proposed\nsupervised representation learning methods yield more robust and discriminative\nrepresentations for automatically classifying Parkinson's disease speech,\noutperforming the baseline unsupervised representation learning system.",
    "descriptor": "\nComments: Submitted to ITG Conference on Speech Communication 2021\n",
    "authors": [
      "Parvaneh Janbakhshi",
      "Ina Kodrasi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.00531"
  },
  {
    "id": "arXiv:2106.00543",
    "title": "MARL with General Utilities via Decentralized Shadow Reward Actor-Critic",
    "abstract": "We posit a new mechanism for cooperation in multi-agent reinforcement\nlearning (MARL) based upon any nonlinear function of the team's long-term\nstate-action occupancy measure, i.e., a \\emph{general utility}. This subsumes\nthe cumulative return but also allows one to incorporate risk-sensitivity,\nexploration, and priors. % We derive the {\\bf D}ecentralized {\\bf S}hadow\nReward {\\bf A}ctor-{\\bf C}ritic (DSAC) in which agents alternate between policy\nevaluation (critic), weighted averaging with neighbors (information mixing),\nand local gradient updates for their policy parameters (actor). DSAC augments\nthe classic critic step by requiring agents to (i) estimate their local\noccupancy measure in order to (ii) estimate the derivative of the local utility\nwith respect to their occupancy measure, i.e., the \"shadow reward\". DSAC\nconverges to $\\epsilon$-stationarity in $\\mathcal{O}(1/\\epsilon^{2.5})$\n(Theorem \\ref{theorem:final}) or faster $\\mathcal{O}(1/\\epsilon^{2})$\n(Corollary \\ref{corollary:communication}) steps with high probability,\ndepending on the amount of communications. We further establish the\nnon-existence of spurious stationary points for this problem, that is, DSAC\nfinds the globally optimal policy (Corollary \\ref{corollary:global}).\nExperiments demonstrate the merits of goals beyond the cumulative return in\ncooperative MARL.",
    "descriptor": "",
    "authors": [
      "Junyu Zhang",
      "Amrit Singh Bedi",
      "Mengdi Wang",
      "Alec Koppel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00543"
  },
  {
    "id": "arXiv:2106.00561",
    "title": "A General Framework for Learning-Based Distributionally Robust MPC of  Markov Jump Systems",
    "abstract": "We present a data-driven model predictive control (MPC) scheme for\nchance-constrained Markov jump systems with unknown switching probabilities.\nUsing samples of the underlying Markov chain, ambiguity sets of transition\nprobabilities are estimated which include the true conditional probability\ndistributions with high probability. These sets are updated online and used to\nformulate a time-varying, risk-averse optimal control problem. We prove\nrecursive feasibility of the resulting MPC scheme and show that the original\nchance constraints remain satisfied at every time step. Furthermore, we show\nthat under sufficient decrease of the confidence levels, the resulting MPC\nscheme renders the closed-loop system mean-square stable with respect to the\ntrue-but-unknown distributions, while remaining less conservative than a fully\nrobust approach. Finally, we show that the data-driven value function converges\nto its nominal counterpart as the sample size grows to infinity. We illustrate\nour approach on a numerical example.",
    "descriptor": "\nComments: Submitted for review. arXiv admin note: text overlap with arXiv:2009.04422\n",
    "authors": [
      "Mathijs Schuurmans",
      "Panagiotis Patrinos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00561"
  },
  {
    "id": "arXiv:2106.00574",
    "title": "Deep Reinforcement Learning for Radio Resource Allocation and Management  in Next Generation Heterogeneous Wireless Networks: A Survey",
    "abstract": "Next generation wireless networks are expected to be extremely complex due to\ntheir massive heterogeneity in terms of the types of network architectures they\nincorporate, the types and numbers of smart IoT devices they serve, and the\ntypes of emerging applications they support. In such large-scale and\nheterogeneous networks (HetNets), radio resource allocation and management\n(RRAM) becomes one of the major challenges encountered during system design and\ndeployment. In this context, emerging Deep Reinforcement Learning (DRL)\ntechniques are expected to be one of the main enabling technologies to address\nthe RRAM in future wireless HetNets. In this paper, we conduct a systematic\nin-depth, and comprehensive survey of the applications of DRL techniques in\nRRAM for next generation wireless networks. Towards this, we first overview the\nexisting traditional RRAM methods and identify their limitations that motivate\nthe use of DRL techniques in RRAM. Then, we provide a comprehensive review of\nthe most widely used DRL algorithms to address RRAM problems, including the\nvalue- and policy-based algorithms. The advantages, limitations, and use-cases\nfor each algorithm are provided. We then conduct a comprehensive and in-depth\nliterature review and classify existing related works based on both the radio\nresources they are addressing and the type of wireless networks they are\ninvestigating. To this end, we carefully identify the types of DRL algorithms\nutilized in each related work, the elements of these algorithms, and the main\nfindings of each related work. Finally, we highlight important open challenges\nand provide insights into several future research directions in the context of\nDRL-based RRAM. This survey is intentionally designed to guide and stimulate\nmore research endeavors towards building efficient and fine-grained DRL-based\nRRAM schemes for future wireless networks.",
    "descriptor": "",
    "authors": [
      "Abdulmalik Alwarafy",
      "Mohamed Abdallah",
      "Bekir Sait Ciftler",
      "Ala Al-Fuqaha",
      "Mounir Hamdi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00574"
  },
  {
    "id": "arXiv:2106.00606",
    "title": "Dynamic-Deep: ECG Task-Aware Compression",
    "abstract": "Monitoring medical data, e.g., Electrocardiogram (ECG) signals, is a common\napplication of Internet of Things (IoT) devices. Compression methods are often\napplied on the massive amounts of sensor data generated before sending it to\nthe Cloud to reduce storage and delivery costs. A lossy compression provides\nhigh compression gain (CG) but may reduce the performance of an ECG application\n(downstream task) due to information loss. Previous works on ECG monitoring\nfocus either on optimizing the signal reconstruction or the task's performance.\nInstead, we advocate a lossy compression solution that allows configuring a\ndesired performance level on the downstream tasks while maintaining an\noptimized CG.\nWe propose Dynamic-Deep, a task-aware compression that uses convolutional\nautoencoders. The compression level is dynamically selected to yield an\noptimized compression without violating tasks' performance requirements. We\nconduct an extensive evaluation of our approach on common ECG datasets using\ntwo popular ECG applications, which includes heart rate (HR) arrhythmia\nclassification. We demonstrate that Dynamic-Deep improves HR classification\nF1-score by a factor of 3 and increases CG by up to 83% compared to the\nprevious state-of-the-art (autoencoder-based) compressor. Additionally,\nDynamic-Deep has a 67% lower memory footprint. Analyzing Dynamic-Deep on the\nGoogle Cloud Platform, we observe a 97% reduction in cloud costs compared to a\nno compression solution.\nTo the best of our knowledge, Dynamic-Deep is the first proposal to focus on\nbalancing the need for high performance of cloud-based downstream tasks and the\ndesire to achieve optimized compression in IoT ECG monitoring settings.",
    "descriptor": "\nComments: submitted to Globecom2021 SAC MLC\n",
    "authors": [
      "Eli Brosh",
      "Elad Wasserstein",
      "Anat Bremler-Barr"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00606"
  },
  {
    "id": "arXiv:2106.00610",
    "title": "Deep Learning for Depression Recognition with Audiovisual Cues: A Review",
    "abstract": "With the acceleration of the pace of work and life, people have to face more\nand more pressure, which increases the possibility of suffering from\ndepression. However, many patients may fail to get a timely diagnosis due to\nthe serious imbalance in the doctor-patient ratio in the world. Promisingly,\nphysiological and psychological studies have indicated some differences in\nspeech and facial expression between patients with depression and healthy\nindividuals. Consequently, to improve current medical care, many scholars have\nused deep learning to extract a representation of depression cues in audio and\nvideo for automatic depression detection. To sort out and summarize these\nworks, this review introduces the databases and describes objective markers for\nautomatic depression estimation (ADE). Furthermore, we review the deep learning\nmethods for automatic depression detection to extract the representation of\ndepression from audio and video. Finally, this paper discusses challenges and\npromising directions related to automatic diagnosing of depression using deep\nlearning technologies.",
    "descriptor": "",
    "authors": [
      "Lang He",
      "Mingyue Niu",
      "Prayag Tiwari",
      "Pekka Marttinen",
      "Rui Su",
      "Jiewei Jiang",
      "Chenguang Guo",
      "Hongyu Wang",
      "Songtao Ding",
      "Zhongmin Wang",
      "Wei Dang",
      "Xiaoying Pan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00610"
  },
  {
    "id": "arXiv:2106.00611",
    "title": "Deep Learning for EEG Seizure Detection in Preterm Infants",
    "abstract": "EEG is the gold standard for seizure detection in the newborn infant, but EEG\ninterpretation in the preterm group is particularly challenging; trained\nexperts are scarce and the task of interpreting EEG in real-time is arduous.\nPreterm infants are reported to have a higher incidence of seizures compared to\nterm infants. Preterm EEG morphology differs from that of term infants, which\nimplies that seizure detection algorithms trained on term EEG may not be\nappropriate. The task of developing preterm specific algorithms becomes\nextra-challenging given the limited amount of annotated preterm EEG data\navailable. This paper explores novel deep learning (DL) architectures for the\ntask of neonatal seizure detection in preterm infants. The study tests and\ncompares several approaches to address the problem: training on data from\nfull-term infants; training on data from preterm infants; training on\nage-specific preterm data and transfer learning. The system performance is\nassessed on a large database of continuous EEG recordings of 575h in duration.\nIt is shown that the accuracy of a validated term-trained EEG seizure detection\nalgorithm, based on a support vector machine classifier, when tested on preterm\ninfants falls well short of the performance achieved for full-term infants. An\nAUC of 88.3% was obtained when tested on preterm EEG as compared to 96.6%\nobtained when tested on term EEG. When re-trained on preterm EEG, the\nperformance marginally increases to 89.7%. An alternative DL approach shows a\nmore stable trend when tested on the preterm cohort, starting with an AUC of\n93.3% for the term-trained algorithm and reaching 95.0% by transfer learning\nfrom the term model using available preterm data.",
    "descriptor": "",
    "authors": [
      "Alison OShea",
      "Rehan Ahmed",
      "Gordon Lightbody",
      "Sean Mathieson",
      "Elena Pavlidis",
      "Rhodri Lloyd",
      "Francesco Pisani",
      "Willian Marnane",
      "Geraldine Boylan",
      "Andriy Temko"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00611"
  },
  {
    "id": "arXiv:2106.00613",
    "title": "A Compact and Interpretable Convolutional Neural Network for  Cross-Subject Driver Drowsiness Detection from Single-Channel EEG",
    "abstract": "Driver drowsiness is one of main factors leading to road fatalities and\nhazards in the transportation industry. Electroencephalography (EEG) has been\nconsidered as one of the best physiological signals to detect drivers drowsy\nstates, since it directly measures neurophysiological activities in the brain.\nHowever, designing a calibration-free system for driver drowsiness detection\nwith EEG is still a challenging task, as EEG suffers from serious mental and\nphysical drifts across different subjects. In this paper, we propose a compact\nand interpretable Convolutional Neural Network (CNN) to discover shared EEG\nfeatures across different subjects for driver drowsiness detection. We\nincorporate the Global Average Pooling (GAP) layer in the model structure,\nallowing the Class Activation Map (CAM) method to be used for localizing\nregions of the input signal that contribute most for classification. Results\nshow that the proposed model can achieve an average accuracy of 73.22% on 11\nsubjects for 2-class cross-subject EEG signal classification, which is higher\nthan conventional machine learning methods and other state-of-art deep learning\nmethods. It is revealed by the visualization technique that the model has\nlearned biologically explainable features, e.g., Alpha spindles and Theta\nburst, as evidence for the drowsy state. It is also interesting to see that the\nmodel uses artifacts that usually dominate the wakeful EEG, e.g., muscle\nartifacts and sensor drifts, to recognize the alert state. The proposed model\nillustrates a potential direction to use CNN models as a powerful tool to\ndiscover shared features related to different mental states across different\nsubjects from EEG signals.",
    "descriptor": "",
    "authors": [
      "Jian Cui",
      "Zirui Lan",
      "Yisi Liu",
      "Ruilin Li",
      "Fan Li",
      "Olga Sourina",
      "Wolfgang Mueller-Wittig"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.00613"
  },
  {
    "id": "arXiv:2106.00614",
    "title": "Pattern Discovery in Time Series with Byte Pair Encoding",
    "abstract": "The growing popularity of wearable sensors has generated large quantities of\ntemporal physiological and activity data. Ability to analyze this data offers\nnew opportunities for real-time health monitoring and forecasting. However,\ntemporal physiological data presents many analytic challenges: the data is\nnoisy, contains many missing values, and each series has a different length.\nMost methods proposed for time series analysis and classification do not handle\ndatasets with these characteristics nor do they offer interpretability and\nexplainability, a critical requirement in the health domain. We propose an\nunsupervised method for learning representations of time series based on common\npatterns identified within them. The patterns are, interpretable, variable in\nlength, and extracted using Byte Pair Encoding compression technique. In this\nway the method can capture both long-term and short-term dependencies present\nin the data. We show that this method applies to both univariate and\nmultivariate time series and beats state-of-the-art approaches on a real world\ndataset collected from wearable sensors.",
    "descriptor": "",
    "authors": [
      "Nazgol Tavabi",
      "Kristina Lerman"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00614"
  },
  {
    "id": "arXiv:2106.00615",
    "title": "Meta-HAR: Federated Representation Learning for Human Activity  Recognition",
    "abstract": "Human activity recognition (HAR) based on mobile sensors plays an important\nrole in ubiquitous computing. However, the rise of data regulatory constraints\nprecludes collecting private and labeled signal data from personal devices at\nscale. Federated learning has emerged as a decentralized alternative solution\nto model training, which iteratively aggregates locally updated models into a\nshared global model, therefore being able to leverage decentralized, private\ndata without central collection. However, the effectiveness of federated\nlearning for HAR is affected by the fact that each user has different activity\ntypes and even a different signal distribution for the same activity type.\nFurthermore, it is uncertain if a single global model trained can generalize\nwell to individual users or new users with heterogeneous data. In this paper,\nwe propose Meta-HAR, a federated representation learning framework, in which a\nsignal embedding network is meta-learned in a federated manner, while the\nlearned signal representations are further fed into a personalized\nclassification network at each user for activity prediction. In order to boost\nthe representation ability of the embedding network, we treat the HAR problem\nat each user as a different task and train the shared embedding network through\na Model-Agnostic Meta-learning framework, such that the embedding network can\ngeneralize to any individual user. Personalization is further achieved on top\nof the robustly learned representations in an adaptation procedure. We\nconducted extensive experiments based on two publicly available HAR datasets as\nwell as a newly created HAR dataset. Results verify that Meta-HAR is effective\nat maintaining high test accuracies for individual users, including new users,\nand significantly outperforms several baselines, including Federated Averaging,\nReptile and even centralized learning in certain cases.",
    "descriptor": "",
    "authors": [
      "Chenglin Li",
      "Di Niu",
      "Bei Jiang",
      "Xiao Zuo",
      "Jianming Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00615"
  },
  {
    "id": "arXiv:2106.00628",
    "title": "Detection of preventable fetal distress during labor from scanned  cardiotocogram tracings using deep learning",
    "abstract": "Despite broad application during labor and delivery, there remains\nconsiderable debate about the value of electronic fetal monitoring (EFM). EFM\nincludes the surveillance of the fetal heart rate (FHR) patterns in conjunction\nwith the maternal uterine contractions providing a wealth of data about fetal\nbehavior and the threat of diminished oxygenation and perfusion. Adverse\noutcomes universally associate a fetal injury with the failure to timely\nrespond to FHR pattern information. Historically, the EFM data, stored\ndigitally, are available only as rasterized pdf images for contemporary or\nhistorical discussion and examination. In reality, however, they are rarely\nreviewed systematically. Using a unique archive of EFM collected over 50 years\nof practice in conjunction with adverse outcomes, we present a deep learning\nframework for training and detection of incipient or past fetal injury. We\nreport 94% accuracy in identifying early, preventable fetal injury intrapartum.\nThis framework is suited for automating an early warning and decision support\nsystem for maintaining fetal well-being during the stresses of labor.\nUltimately, such a system could enable a physician to timely respond during\nlabor and prevent adverse outcomes. When adverse outcomes cannot be avoided,\nthey can provide guidance to the early neuroprotective treatment of the\nnewborn.",
    "descriptor": "",
    "authors": [
      "Martin G. Frasch",
      "Shadrian B. Strong",
      "David Nilosek",
      "Joshua Leaverton",
      "Barry S. Schifrin"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00628"
  },
  {
    "id": "arXiv:2106.00629",
    "title": "Decoupling Shape and Density for Liver Lesion Synthesis Using  Conditional Generative Adversarial Networks",
    "abstract": "Lesion synthesis received much attention with the rise of efficient\ngenerative models for augmenting training data, drawing lesion evolution\nscenarios, or aiding expert training. The quality and diversity of synthesized\ndata are highly dependent on the annotated data used to train the models, which\nnot rarely struggle to derive very different yet realistic samples from the\ntraining ones. That adds an inherent bias to lesion segmentation algorithms and\nlimits synthesizing lesion evolution scenarios efficiently. This paper presents\na method for decoupling shape and density for liver lesion synthesis, creating\na framework that allows straight-forwardly driving the synthesis. We offer\nqualitative results that show the synthesis control by modifying shape and\ndensity individually, and quantitative results that demonstrate that embedding\nthe density information in the generator model helps to increase lesion\nsegmentation performance compared to using the shape solely.",
    "descriptor": "",
    "authors": [
      "Dario Augusto Borges Oliveira"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00629"
  },
  {
    "id": "arXiv:2106.00639",
    "title": "Multi-modal Point-of-Care Diagnostics for COVID-19 Based On Acoustics  and Symptoms",
    "abstract": "The research direction of identifying acoustic bio-markers of respiratory\ndiseases has received renewed interest following the onset of COVID-19\npandemic. In this paper, we design an approach to COVID-19 diagnostic using\ncrowd-sourced multi-modal data. The data resource, consisting of acoustic\nsignals like cough, breathing, and speech signals, along with the data of\nsymptoms, are recorded using a web-application over a period of ten months. We\ninvestigate the use of statistical descriptors of simple time-frequency\nfeatures for acoustic signals and binary features for the presence of symptoms.\nUnlike previous works, we primarily focus on the application of simple linear\nclassifiers like logistic regression and support vector machines for acoustic\ndata while decision tree models are employed on the symptoms data. We show that\na multi-modal integration of acoustics and symptoms classifiers achieves an\narea-under-curve (AUC) of 92.40, a significant improvement over any individual\nmodality. Several ablation experiments are also provided which highlight the\nacoustic and symptom dimensions that are important for the task of COVID-19\ndiagnostics.",
    "descriptor": "\nComments: The Manuscript is submitted to IEEE-EMBS Journal of Biomedical and Health Informatics on June 1, 2021\n",
    "authors": [
      "Srikanth Raj Chetupalli",
      "Prashant Krishnan",
      "Neeraj Sharma",
      "Ananya Muguli",
      "Rohit Kumar",
      "Viral Nanda",
      "Lancelot Mark Pinto",
      "Prasanta Kumar Ghosh",
      "Sriram Ganapathy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00639"
  },
  {
    "id": "arXiv:2106.00643",
    "title": "A survey of machine learning-based physics event generation",
    "abstract": "Event generators in high-energy nuclear and particle physics play an\nimportant role in facilitating studies of particle reactions. We survey the\nstate-of-the-art of machine learning (ML) efforts at building physics event\ngenerators. We review ML generative models used in ML-based event generators\nand their specific challenges, and discuss various approaches of incorporating\nphysics into the ML model designs to overcome these challenges. Finally, we\nexplore some open questions related to super-resolution, fidelity, and\nextrapolation for physics event generation based on ML technology.",
    "descriptor": "\nComments: 8 pages, 2 figures, paper accepted for publication in IJCAI2021\n",
    "authors": [
      "Yasir Alanazi",
      "N. Sato",
      "Pawel Ambrozewicz",
      "Astrid N. Hiller Blin",
      "W. Melnitchouk",
      "Marco Battaglieri",
      "Tianbo Liu",
      "Yaohang Li"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "Nuclear Experiment (nucl-ex)"
    ],
    "url": "https://arxiv.org/abs/2106.00643"
  },
  {
    "id": "arXiv:2106.00644",
    "title": "A normal form for grid forming power grid components",
    "abstract": "Future power grids will be operating a large number of heterogeneous\ndynamical actors. Many ofthese will contribute to the fundamental dynamical\nstability of the system. By taking a complexitytheoretic perspective we derive\na normal form for grid forming components in power grids. Thisallows analyzing\nthe grids systemic properties without the need for detailed technical\nmodels.Our approach is based on the physics of the power flow in the grid on\nthe one hand, and on thecommon symmetry that is inherited from the control\nobjectives grid-forming power grid componentsare trying to achieve. We provide\na first experimental validation that this normal form can capturethe behavior\nof complex grid forming inverters without any knowledge of the underlying\ntechnology,and show that it can be used to make technology independent\nstatements on the stability of futuregrids.",
    "descriptor": "",
    "authors": [
      "Raphael Kogler",
      "Anton Plietzsch",
      "Paul Schultz",
      "Frank Hellmann"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00644"
  },
  {
    "id": "arXiv:2106.00645",
    "title": "Hyperspectral Band Selection for Multispectral Image Classification with  Convolutional Networks",
    "abstract": "In recent years, Hyperspectral Imaging (HSI) has become a powerful source for\nreliable data in applications such as remote sensing, agriculture, and\nbiomedicine. However, hyperspectral images are highly data-dense and often\nbenefit from methods to reduce the number of spectral bands while retaining the\nmost useful information for a specific application. We propose a novel band\nselection method to select a reduced set of wavelengths, obtained from an HSI\nsystem in the context of image classification. Our approach consists of two\nmain steps: the first utilizes a filter-based approach to find relevant\nspectral bands based on a collinearity analysis between a band and its\nneighbors. This analysis helps to remove redundant bands and dramatically\nreduces the search space. The second step applies a wrapper-based approach to\nselect bands from the reduced set based on their information entropy values,\nand trains a compact Convolutional Neural Network (CNN) to evaluate the\nperformance of the current selection. We present classification results\nobtained from our method and compare them to other feature selection methods on\ntwo hyperspectral image datasets. Additionally, we use the original\nhyperspectral data cube to simulate the process of using actual filters in a\nmultispectral imager. We show that our method produces more suitable results\nfor a multispectral sensor design.",
    "descriptor": "\nComments: Accepted to appear in the International Joint Conference on Neural Networks 2021\n",
    "authors": [
      "Giorgio Morales",
      "John Sheppard",
      "Riley Logan",
      "Joseph Shaw"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00645"
  },
  {
    "id": "arXiv:2106.00647",
    "title": "Mapping the NFT revolution: market trends, trade networks and visual  features",
    "abstract": "Non Fungible Tokens (NFTs) are digital assets that represent objects like\nart, videos, in-game items and music. They are traded online, often with\ncryptocurrency, and they are generally encoded as smart contracts on a\nblockchain. Media and public attention towards NFTs has exploded in 2021, when\nthe NFT art market has experienced record sales while celebrated new star\nartists. However, little is known about the overall structure and evolution of\nthe NFT market. Here, we analyse data concerning 6.1 million trades of 4.7\nmillion NFTs generating a total trading volume of 935 millions US dollars. Our\ndata are obtained primarily from the Ethereum and WAX blockchains and cover the\nperiod between June 23, 2017 and April 27, 2021. First, we characterize the\nstatistical properties of the market. Second, we build the network of\ninteractions and show that traders have bursts of activity followed by inactive\nperiods, and typically specialize on NFTs associated to similar objects. Third,\nwe cluster objects associated to NFTs according to their visual features and\nshow that NFTs within the same category tend to be visually homogeneous.\nFinally, we investigate the predictability of NFT sales. We use simple machine\nlearning algorithms and find that prices can be best predicted by the sale\nhistory of the NFT collection, but also by some features describing the\nproperties of the associated object (e.g., visual features of digital images).\nWe anticipate that our analysis will be of interest to both researchers and\npractitioners and will spark further research on the NFT production, adoption\nand trading in different contexts.",
    "descriptor": "\nComments: Working paper, comments welcome\n",
    "authors": [
      "Matthieu Nadini",
      "Laura Alessandretti",
      "Flavio Di Giacinto",
      "Mauro Martino",
      "Luca Maria Aiello",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00647"
  },
  {
    "id": "arXiv:2106.00663",
    "title": "An occupation kernel approach to optimal control",
    "abstract": "In this effort, a novel operator theoretic framework is developed for\ndata-driven solution of optimal control problems. The developed methods focus\non the use of trajectories (i.e., time-series) as the fundamental unit of data\nfor the resolution of optimal control problems in dynamical systems. Trajectory\ninformation in the dynamical systems is embedded in a reproducing kernel\nHilbert space (RKHS) through what are called occupation kernels. The occupation\nkernels are tied to the dynamics of the system through the densely defined\nLiouville operator. The pairing of Liouville operators and occupation kernels\nallows for lifting of nonlinear finite-dimensional optimal control problems\ninto the space of infinite-dimensional linear programs over RKHSs.",
    "descriptor": "",
    "authors": [
      "Rushikesh Kamalapurkar",
      "Joel A. Rosenfeld"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00663"
  },
  {
    "id": "arXiv:0810.4840",
    "title": "The Pursuit of Uniqueness: Extending Valiant-Vazirani Theorem to the  Probabilistic and Quantum Settings",
    "abstract": "Comments: 26 pages, 5 figures",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Dorit Aharonov",
      "Michael Ben-Or",
      "Fernando G.S.L. Brandao",
      "Or Sattath"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/0810.4840"
  },
  {
    "id": "arXiv:1704.06879",
    "title": "Deep Keyphrase Generation",
    "abstract": "Comments: Accepted by ACL2017",
    "descriptor": "\nComments: Accepted by ACL2017\n",
    "authors": [
      "Rui Meng",
      "Sanqiang Zhao",
      "Shuguang Han",
      "Daqing He",
      "Peter Brusilovsky",
      "Yu Chi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1704.06879"
  },
  {
    "id": "arXiv:1805.11137",
    "title": "Adaptive Euler methods for stochastic systems with non-globally  Lipschitz coefficients",
    "abstract": "Comments: This is a preprint of an article published in Numerical Algorithms. The final authenticated version is available online at: this https URL",
    "descriptor": "\nComments: This is a preprint of an article published in Numerical Algorithms. The final authenticated version is available online at: this https URL\n",
    "authors": [
      "C\u00f3nall Kelly",
      "Gabriel Lord"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1805.11137"
  },
  {
    "id": "arXiv:1806.09888",
    "title": "Towards an understanding of CNNs: analysing the recovery of activation  pathways via Deep Convolutional Sparse Coding",
    "abstract": "Comments: Long version (8 pages excluding references) of paper accepted at the IEEE 2018 Data Science Workshop",
    "descriptor": "\nComments: Long version (8 pages excluding references) of paper accepted at the IEEE 2018 Data Science Workshop\n",
    "authors": [
      "Michael Murray",
      "Jared Tanner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1806.09888"
  },
  {
    "id": "arXiv:1809.07320",
    "title": "Compressing and Indexing Aligned Readsets",
    "abstract": "Compressing and Indexing Aligned Readsets",
    "descriptor": "",
    "authors": [
      "Travis Gagie",
      "Garance Gourdel",
      "Giovanni Manzini"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/1809.07320"
  },
  {
    "id": "arXiv:1812.00263",
    "title": "BlackOut and Obfuscator: An Exploration of the Design Space for  Privacy-Preserving Interventions for Voice Assistants",
    "abstract": "BlackOut and Obfuscator: An Exploration of the Design Space for  Privacy-Preserving Interventions for Voice Assistants",
    "descriptor": "",
    "authors": [
      "Varun Chandrasekaran",
      "Suman Banerjee",
      "Bilge Mutlu",
      "Kassem Fawaz"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1812.00263"
  },
  {
    "id": "arXiv:1901.03361",
    "title": "Separation for dot-depth two",
    "abstract": "Separation for dot-depth two",
    "descriptor": "",
    "authors": [
      "Thomas Place",
      "Marc Zeitoun"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/1901.03361"
  },
  {
    "id": "arXiv:1904.07538",
    "title": "Long-Term Human Video Generation of Multiple Futures Using Poses",
    "abstract": "Long-Term Human Video Generation of Multiple Futures Using Poses",
    "descriptor": "",
    "authors": [
      "Naoya Fushishita",
      "Antonio Tejero-de-Pablos",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1904.07538"
  },
  {
    "id": "arXiv:1906.06717",
    "title": "MoET: Mixture of Expert Trees and its Application to Verifiable  Reinforcement Learning",
    "abstract": "MoET: Mixture of Expert Trees and its Application to Verifiable  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Marko Vasic",
      "Andrija Petrovic",
      "Kaiyuan Wang",
      "Mladen Nikolic",
      "Rishabh Singh",
      "Sarfraz Khurshid"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.06717"
  },
  {
    "id": "arXiv:1907.10719",
    "title": "LayoutVAE: Stochastic Scene Layout Generation From a Label Set",
    "abstract": "Comments: 20 pages, 24 figures, accepted in ICCV 2019",
    "descriptor": "\nComments: 20 pages, 24 figures, accepted in ICCV 2019\n",
    "authors": [
      "Akash Abdu Jyothi",
      "Thibaut Durand",
      "Jiawei He",
      "Leonid Sigal",
      "Greg Mori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1907.10719"
  },
  {
    "id": "arXiv:1909.06397",
    "title": "Horizontal Flows and Manifold Stochastics in Geometric Deep Learning",
    "abstract": "Horizontal Flows and Manifold Stochastics in Geometric Deep Learning",
    "descriptor": "",
    "authors": [
      "Stefan Sommer",
      "Alex Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.06397"
  },
  {
    "id": "arXiv:1909.13322",
    "title": "Capacity Preserving Mapping for High-dimensional Data Visualization",
    "abstract": "Capacity Preserving Mapping for High-dimensional Data Visualization",
    "descriptor": "",
    "authors": [
      "Rongrong Wang",
      "Xiaopeng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.13322"
  },
  {
    "id": "arXiv:1910.08613",
    "title": "Poisson CNN: Convolutional neural networks for the solution of the  Poisson equation on a Cartesian mesh",
    "abstract": "Comments: 34 pages, 18 figures. Accepted for publication in Data Centric Engineering. Code available at this https URL",
    "descriptor": "\nComments: 34 pages, 18 figures. Accepted for publication in Data Centric Engineering. Code available at this https URL\n",
    "authors": [
      "Ali Girayhan \u00d6zbay",
      "Arash Hamzehloo",
      "Sylvain Laizet",
      "Panagiotis Tzirakis",
      "Georgios Rizos",
      "Bj\u00f6rn Schuller"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.08613"
  },
  {
    "id": "arXiv:1910.12747",
    "title": "Introduction to local certification",
    "abstract": "Comments: Last update: minor editing",
    "descriptor": "\nComments: Last update: minor editing\n",
    "authors": [
      "Laurent Feuilloley"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1910.12747"
  },
  {
    "id": "arXiv:1911.00195",
    "title": "Rotation Invariant Point Cloud Classification: Where Local Geometry  Meets Global Topology",
    "abstract": "Rotation Invariant Point Cloud Classification: Where Local Geometry  Meets Global Topology",
    "descriptor": "",
    "authors": [
      "Chen Zhao",
      "Jiaqi Yang",
      "Xin Xiong",
      "Angfan Zhu",
      "Zhiguo Cao",
      "Xin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1911.00195"
  },
  {
    "id": "arXiv:1912.04783",
    "title": "Frivolous Units: Wider Networks Are Not Really That Wide",
    "abstract": "Frivolous Units: Wider Networks Are Not Really That Wide",
    "descriptor": "",
    "authors": [
      "Stephen Casper",
      "Xavier Boix",
      "Vanessa D'Amario",
      "Ling Guo",
      "Martin Schrimpf",
      "Kasper Vinken",
      "Gabriel Kreiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.04783"
  },
  {
    "id": "arXiv:1912.11108",
    "title": "Reconstruction of Strings from their Substrings Spectrum",
    "abstract": "Reconstruction of Strings from their Substrings Spectrum",
    "descriptor": "",
    "authors": [
      "Sagi Marcovich",
      "Eitan Yaakobi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1912.11108"
  },
  {
    "id": "arXiv:2001.03955",
    "title": "Aggregated Learning: A Vector-Quantization Approach to Learning Neural  Network Classifiers",
    "abstract": "Comments: Proof of theoretical results are provided",
    "descriptor": "\nComments: Proof of theoretical results are provided\n",
    "authors": [
      "Masoumeh Soflaei",
      "Hongyu Guo",
      "Ali Al-Bashabsheh",
      "Yongyi Mao",
      "Richong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.03955"
  },
  {
    "id": "arXiv:2001.11031",
    "title": "Bayesian Reasoning with Trained Neural Networks",
    "abstract": "Bayesian Reasoning with Trained Neural Networks",
    "descriptor": "",
    "authors": [
      "Jakob Knollm\u00fcller",
      "Torsten En\u00dflin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.11031"
  },
  {
    "id": "arXiv:2002.02512",
    "title": "Relating Apartness and Bisimulation",
    "abstract": "Comments: 35 pages",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Herman Geuvers",
      "Bart Jacobs"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2002.02512"
  },
  {
    "id": "arXiv:2002.04242",
    "title": "Human-to-Robot Attention Transfer for Robot Execution Failure Avoidance  Using Stacked Neural Networks",
    "abstract": "Comments: 6 pages, 9 figures",
    "descriptor": "\nComments: 6 pages, 9 figures\n",
    "authors": [
      "Boyi Song",
      "Yuntao Peng",
      "Ruijiao Luo",
      "Rui Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2002.04242"
  },
  {
    "id": "arXiv:2002.04924",
    "title": "Synaptic Integration of Spatiotemporal Features with a Dynamic  Neuromorphic Processor",
    "abstract": "Comments: Copyright 2020 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: Copyright 2020 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Mattias Nilsson",
      "Foteini Liwicki",
      "Fredrik Sandin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2002.04924"
  },
  {
    "id": "arXiv:2002.07309",
    "title": "Discovering ePassport Vulnerabilities using Bisimilarity",
    "abstract": "Discovering ePassport Vulnerabilities using Bisimilarity",
    "descriptor": "",
    "authors": [
      "Ross Horne",
      "Sjouke Mauw"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2002.07309"
  },
  {
    "id": "arXiv:2002.10674",
    "title": "Separating the Effects of Batch Normalization on CNN Training Speed and  Stability Using Classical Adaptive Filter Theory",
    "abstract": "Comments: Presented at Asilomar Conference on Signals, Systems, and Computers, 2020",
    "descriptor": "\nComments: Presented at Asilomar Conference on Signals, Systems, and Computers, 2020\n",
    "authors": [
      "Elaina Chai",
      "Mert Pilanci",
      "Boris Murmann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2002.10674"
  },
  {
    "id": "arXiv:2002.11603",
    "title": "DP-MERF: Differentially Private Mean Embeddings with Random Features for  Practical Privacy-Preserving Data Generation",
    "abstract": "DP-MERF: Differentially Private Mean Embeddings with Random Features for  Practical Privacy-Preserving Data Generation",
    "descriptor": "",
    "authors": [
      "Frederik Harder",
      "Kamil Adamczewski",
      "Mijung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.11603"
  },
  {
    "id": "arXiv:2003.01821",
    "title": "HyperEmbed: Tradeoffs Between Resources and Performance in NLP Tasks  with Hyperdimensional Computing enabled Embedding of n-gram Statistics",
    "abstract": "Comments: 9 pages, 1 figure, 6 tables",
    "descriptor": "\nComments: 9 pages, 1 figure, 6 tables\n",
    "authors": [
      "Pedro Alonso",
      "Kumar Shridhar",
      "Denis Kleyko",
      "Evgeny Osipov",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2003.01821"
  },
  {
    "id": "arXiv:2003.03677",
    "title": "An Intent-based Task-aware Shared Control Framework for Intuitive Hands  Free Telemanipulation",
    "abstract": "An Intent-based Task-aware Shared Control Framework for Intuitive Hands  Free Telemanipulation",
    "descriptor": "",
    "authors": [
      "Michael Bowman",
      "Jiucai Zhang",
      "Xiaoli Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2003.03677"
  },
  {
    "id": "arXiv:2003.03759",
    "title": "3D Object Detection from a Single Fisheye Image Without a Single Fisheye  Training Image",
    "abstract": "Comments: 9 pages, 7 figures",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Elad Plaut",
      "Erez Ben Yaacov",
      "Bat El Shlomo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2003.03759"
  },
  {
    "id": "arXiv:2003.03977",
    "title": "Wide-minima Density Hypothesis and the Explore-Exploit Learning Rate  Schedule",
    "abstract": "Comments: 34 pages",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Nikhil Iyer",
      "V Thejas",
      "Nipun Kwatra",
      "Ramachandran Ramjee",
      "Muthian Sivathanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.03977"
  },
  {
    "id": "arXiv:2004.01981",
    "title": "Open Domain Dialogue Generation with Latent Images",
    "abstract": "Comments: AAAI2021",
    "descriptor": "\nComments: AAAI2021\n",
    "authors": [
      "Ze Yang",
      "Wei Wu",
      "Huang Hu",
      "Can Xu",
      "Wei Wang",
      "Zhoujun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2004.01981"
  },
  {
    "id": "arXiv:2004.07966",
    "title": "On the analysis and approximation of some models of fluids over weighted  spaces on convex polyhedra",
    "abstract": "On the analysis and approximation of some models of fluids over weighted  spaces on convex polyhedra",
    "descriptor": "",
    "authors": [
      "Enrique Otarola",
      "Abner Salgado"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2004.07966"
  },
  {
    "id": "arXiv:2004.14740",
    "title": "Criss-Cross Insertion and Deletion Correcting Codes",
    "abstract": "Comments: Submitted to IEEE Transactions on Information Theory for possible publication. Several examples are added to help understand the concepts explained in the paper",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Information Theory for possible publication. Several examples are added to help understand the concepts explained in the paper\n",
    "authors": [
      "Rawad Bitar",
      "Lorenz Welter",
      "Ilia Smagloy",
      "Antonia Wachter-Zeh",
      "Eitan Yaakobi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2004.14740"
  },
  {
    "id": "arXiv:2005.03482",
    "title": "AN-GCN: An Anonymous Graph Convolutional Network Defense Against  Edge-Perturbing Attack",
    "abstract": "Comments: 15 pages, 11 figures",
    "descriptor": "\nComments: 15 pages, 11 figures\n",
    "authors": [
      "Ao Liu",
      "Beibei Li",
      "Tao Li",
      "Pan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2005.03482"
  },
  {
    "id": "arXiv:2005.08665",
    "title": "Spatio-Temporal Point Processes with Attention for Traffic Congestion  Event Modeling",
    "abstract": "Spatio-Temporal Point Processes with Attention for Traffic Congestion  Event Modeling",
    "descriptor": "",
    "authors": [
      "Shixiang Zhu",
      "Ruyi Ding",
      "Minghe Zhang",
      "Pascal Van Hentenryck",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.08665"
  },
  {
    "id": "arXiv:2005.10329",
    "title": "InfoScrub: Towards Attribute Privacy by Targeted Obfuscation",
    "abstract": "Comments: 20 pages, 7 figures",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Hui-Po Wang",
      "Tribhuvanesh Orekondy",
      "Mario Fritz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2005.10329"
  },
  {
    "id": "arXiv:2005.12413",
    "title": "Constrained nonlinear output regulation using model predictive control  -- extended version",
    "abstract": "Comments: Extended version of accepted paper in Transaction on Automatic Control, 2021. Contains the following additional results: Exponential bounds on the suboptimality index using an observability condition and an extension of the derived theory to the noisy error feedback case",
    "descriptor": "\nComments: Extended version of accepted paper in Transaction on Automatic Control, 2021. Contains the following additional results: Exponential bounds on the suboptimality index using an observability condition and an extension of the derived theory to the noisy error feedback case\n",
    "authors": [
      "Johannes K\u00f6hler",
      "Matthias A. M\u00fcller",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2005.12413"
  },
  {
    "id": "arXiv:2006.00249",
    "title": "Dynamic Masking for Improved Stability in Spoken Language Translation",
    "abstract": "Comments: Presented at AMTA, 2020",
    "descriptor": "\nComments: Presented at AMTA, 2020\n",
    "authors": [
      "Yuekun Yao",
      "Barry Haddow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2006.00249"
  },
  {
    "id": "arXiv:2006.05158",
    "title": "Homomorphic Sensing of Subspace Arrangements",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Liangzu Peng",
      "Manolis C. Tsakiris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Geometry (math.AG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05158"
  },
  {
    "id": "arXiv:2006.07443",
    "title": "Algorithm for Computing Approximate Nash Equilibrium in Continuous Games  with Application to Continuous Blotto",
    "abstract": "Algorithm for Computing Approximate Nash Equilibrium in Continuous Games  with Application to Continuous Blotto",
    "descriptor": "",
    "authors": [
      "Sam Ganzfried"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2006.07443"
  },
  {
    "id": "arXiv:2006.11149",
    "title": "Compositional Learning of Image-Text Query for Image Retrieval",
    "abstract": "Comments: Published at IEEE WACV 2021",
    "descriptor": "\nComments: Published at IEEE WACV 2021\n",
    "authors": [
      "Muhammad Umer Anwaar",
      "Egor Labintcev",
      "Martin Kleinsteuber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2006.11149"
  },
  {
    "id": "arXiv:2006.14947",
    "title": "Distributed Policy Synthesis of Multi-Agent Systems With Graph Temporal  Logic Specifications",
    "abstract": "Comments: Final version of IEEE Transactions on Control of Network Systems. arXiv admin note: substantial text overlap with arXiv:2001.09066",
    "descriptor": "\nComments: Final version of IEEE Transactions on Control of Network Systems. arXiv admin note: substantial text overlap with arXiv:2001.09066\n",
    "authors": [
      "Murat Cubuktepe",
      "Zhe Xu",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2006.14947"
  },
  {
    "id": "arXiv:2007.04147",
    "title": "Improved error estimates of hybridizable interior penalty methods using  a variable penalty for highly anisotropic diffusion problems",
    "abstract": "Comments: 10 pages, 7 figures, 1 table",
    "descriptor": "\nComments: 10 pages, 7 figures, 1 table\n",
    "authors": [
      "Gregory Etangsale",
      "Marwan Fahs",
      "Vincent Fontaine",
      "Nalitiana Rajaonison"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2007.04147"
  },
  {
    "id": "arXiv:2008.05171",
    "title": "Fast and Eager k-Medoids Clustering: O(k) Runtime Improvement of the  PAM, CLARA, and CLARANS Algorithms",
    "abstract": "Fast and Eager k-Medoids Clustering: O(k) Runtime Improvement of the  PAM, CLARA, and CLARANS Algorithms",
    "descriptor": "",
    "authors": [
      "Erich Schubert",
      "Peter J. Rousseeuw"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.05171"
  },
  {
    "id": "arXiv:2008.08996",
    "title": "Compression with wildcards: All exact, or all minimal hitting sets",
    "abstract": "Comments: 30 pages, many Tables",
    "descriptor": "\nComments: 30 pages, many Tables\n",
    "authors": [
      "Marcel Wild"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2008.08996"
  },
  {
    "id": "arXiv:2008.11047",
    "title": "Uncovering hidden dependency in weighted networks via information  entropy",
    "abstract": "Comments: 20 pages, 15 figures",
    "descriptor": "\nComments: 20 pages, 15 figures\n",
    "authors": [
      "Mi Jin Lee",
      "Eun Lee",
      "Byunghwee Lee",
      "Hawoong Jeong",
      "Deok-Sun Lee",
      "Sang Hoon Lee"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2008.11047"
  },
  {
    "id": "arXiv:2009.06211",
    "title": "Implicit Graph Neural Networks",
    "abstract": "Comments: Accepted by NeurIPS 2020 at: this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS 2020 at: this https URL\n",
    "authors": [
      "Fangda Gu",
      "Heng Chang",
      "Wenwu Zhu",
      "Somayeh Sojoudi",
      "Laurent El Ghaoui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.06211"
  },
  {
    "id": "arXiv:2009.06401",
    "title": "Multi-Hop Fact Checking of Political Claims",
    "abstract": "Comments: 10 pages, to be published at Proceedings of IJCAI-2021",
    "descriptor": "\nComments: 10 pages, to be published at Proceedings of IJCAI-2021\n",
    "authors": [
      "Wojciech Ostrowski",
      "Arnav Arora",
      "Pepa Atanasova",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.06401"
  },
  {
    "id": "arXiv:2009.07237",
    "title": "A Survey on Automated Log Analysis for Reliability Engineering",
    "abstract": "Comments: accepted by ACM Computing Survey",
    "descriptor": "\nComments: accepted by ACM Computing Survey\n",
    "authors": [
      "Shilin He",
      "Pinjia He",
      "Zhuangbin Chen",
      "Tianyi Yang",
      "Yuxin Su",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2009.07237"
  },
  {
    "id": "arXiv:2009.07547",
    "title": "Grassmannian diffusion maps based dimension reduction and classification  for high-dimensional data",
    "abstract": "Grassmannian diffusion maps based dimension reduction and classification  for high-dimensional data",
    "descriptor": "",
    "authors": [
      "K. R. M. dos Santos",
      "D. G. Giovanis",
      "M. D. Shields"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.07547"
  },
  {
    "id": "arXiv:2009.08378",
    "title": "Event-Based Backpropagation can compute Exact Gradients for Spiking  Neural Networks",
    "abstract": "Event-Based Backpropagation can compute Exact Gradients for Spiking  Neural Networks",
    "descriptor": "",
    "authors": [
      "Timo C. Wunderlich",
      "Christian Pehle"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2009.08378"
  },
  {
    "id": "arXiv:2009.09780",
    "title": "Impact of lung segmentation on the diagnosis and explanation of COVID-19  in chest X-ray images",
    "abstract": "Comments: Submitted to International Journal of Universal Computer Science",
    "descriptor": "\nComments: Submitted to International Journal of Universal Computer Science\n",
    "authors": [
      "Lucas O. Teixeira",
      "Rodolfo M. Pereira",
      "Diego Bertolini",
      "Luiz S. Oliveira",
      "Loris Nanni",
      "George D. C. Cavalcanti",
      "Yandre M. G. Costa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.09780"
  },
  {
    "id": "arXiv:2009.11742",
    "title": "A compute-bound formulation of Galerkin model reduction for linear  time-invariant dynamical systems",
    "abstract": "Comments: Revised version, 28 pages, 9 figures",
    "descriptor": "\nComments: Revised version, 28 pages, 9 figures\n",
    "authors": [
      "Francesco Rizzi",
      "Eric J. Parish",
      "Patrick J. Blonigan",
      "John Tencer"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Mathematical Software (cs.MS)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2009.11742"
  },
  {
    "id": "arXiv:2009.11920",
    "title": "Funding CRISPR: Understanding the role of government and philanthropic  institutions in supporting academic research within the CRISPR innovation  system",
    "abstract": "Comments: 17 pages, 2 figures",
    "descriptor": "\nComments: 17 pages, 2 figures\n",
    "authors": [
      "David Fajardo-Ortiz",
      "Stefan Hornbostel",
      "Maywa Montenegro-de-Wit",
      "Annie Shattuck"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2009.11920"
  },
  {
    "id": "arXiv:2010.00406",
    "title": "Momentum via Primal Averaging: Theoretical Insights and Learning Rate  Schedules for Non-Convex Optimization",
    "abstract": "Momentum via Primal Averaging: Theoretical Insights and Learning Rate  Schedules for Non-Convex Optimization",
    "descriptor": "",
    "authors": [
      "Aaron Defazio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.00406"
  },
  {
    "id": "arXiv:2010.00656",
    "title": "Predicting User Engagement Status for Online Evaluation of Intelligent  Assistants",
    "abstract": "Comments: Paper has been accepted by ECIR 2021 (43rd edition of the annual European Conference on Information Retrieval)",
    "descriptor": "\nComments: Paper has been accepted by ECIR 2021 (43rd edition of the annual European Conference on Information Retrieval)\n",
    "authors": [
      "Rui Meng",
      "Zhen Yue",
      "Alyssa Glass"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2010.00656"
  },
  {
    "id": "arXiv:2010.02188",
    "title": "Interdependent Diffusion: The social contagion of interacting beliefs",
    "abstract": "Comments: Body and Supplement Draft",
    "descriptor": "\nComments: Body and Supplement Draft\n",
    "authors": [
      "James P. Houghton"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2010.02188"
  },
  {
    "id": "arXiv:2010.03438",
    "title": "Fairness in Influence Maximization through Randomization",
    "abstract": "Fairness in Influence Maximization through Randomization",
    "descriptor": "",
    "authors": [
      "Ruben Becker",
      "Gianlorenzo D'Angelo",
      "Sajjad Ghobadi",
      "Hugo Gilbert"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2010.03438"
  },
  {
    "id": "arXiv:2010.03536",
    "title": "PsPIN: A high-performance low-power architecture for flexible in-network  compute",
    "abstract": "PsPIN: A high-performance low-power architecture for flexible in-network  compute",
    "descriptor": "",
    "authors": [
      "Salvatore Di Girolamo",
      "Andreas Kurth",
      "Alexandru Calotoiu",
      "Thomas Benz",
      "Timo Schneider",
      "Jakub Ber\u00e1nek",
      "Luca Benini",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2010.03536"
  },
  {
    "id": "arXiv:2010.05006",
    "title": "Automated Concatenation of Embeddings for Structured Prediction",
    "abstract": "Comments: Accepted to Proceedings of ACL-IJCNLP 2021. 17 pages",
    "descriptor": "\nComments: Accepted to Proceedings of ACL-IJCNLP 2021. 17 pages\n",
    "authors": [
      "Xinyu Wang",
      "Yong Jiang",
      "Nguyen Bach",
      "Tao Wang",
      "Zhongqiang Huang",
      "Fei Huang",
      "Kewei Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.05006"
  },
  {
    "id": "arXiv:2010.05010",
    "title": "Structural Knowledge Distillation: Tractably Distilling Information for  Structured Predictor",
    "abstract": "Comments: Accepted to Proceedings of ACL-IJCNLP 2021. 15 pages",
    "descriptor": "\nComments: Accepted to Proceedings of ACL-IJCNLP 2021. 15 pages\n",
    "authors": [
      "Xinyu Wang",
      "Yong Jiang",
      "Zhaohui Yan",
      "Zixia Jia",
      "Nguyen Bach",
      "Tao Wang",
      "Zhongqiang Huang",
      "Fei Huang",
      "Kewei Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.05010"
  },
  {
    "id": "arXiv:2010.11075",
    "title": "Neural Networks for Entity Matching: A Survey",
    "abstract": "Comments: Published in ACM Transactions on Knowledge Discovery from Data (TKDD)",
    "descriptor": "\nComments: Published in ACM Transactions on Knowledge Discovery from Data (TKDD)\n",
    "authors": [
      "Nils Barlaug",
      "Jon Atle Gulla"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.11075"
  },
  {
    "id": "arXiv:2010.14110",
    "title": "Full-Duplex Cell-Free mMIMO Systems: Analysis and Decentralized  Optimization",
    "abstract": "Comments: Under review for possible publication to IEEE Transactions in Communications",
    "descriptor": "\nComments: Under review for possible publication to IEEE Transactions in Communications\n",
    "authors": [
      "Soumyadeep Datta",
      "Ekant Sharma",
      "Dheeraj Naidu Amudala",
      "Rohit Budhiraja",
      "Shivendra S. Panwar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.14110"
  },
  {
    "id": "arXiv:2010.15032",
    "title": "Benchmarking Parallelism in FaaS Platforms",
    "abstract": "Comments: 19 pages, 15 figures, submitted to FGCS, revised",
    "descriptor": "\nComments: 19 pages, 15 figures, submitted to FGCS, revised\n",
    "authors": [
      "Daniel Barcelona-Pons",
      "Pedro Garc\u00eda-L\u00f3pez"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2010.15032"
  },
  {
    "id": "arXiv:2010.15672",
    "title": "FD Cell-Free mMIMO: Analysis and Optimization",
    "abstract": "Comments: Accepted in IEEE International Conference on Communications (ICC) 2021. arXiv admin note: substantial text overlap with arXiv:2010.14110",
    "descriptor": "\nComments: Accepted in IEEE International Conference on Communications (ICC) 2021. arXiv admin note: substantial text overlap with arXiv:2010.14110\n",
    "authors": [
      "Soumyadeep Datta",
      "Ekant Sharma",
      "Dheeraj Naidu Amudala",
      "Rohit Budhiraja",
      "Shivendra S. Panwar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.15672"
  },
  {
    "id": "arXiv:2011.02061",
    "title": "Toward Impact-resilient Quadrotor Design, Collision Characterization and  Recovery Control to Sustain Flight after Collisions",
    "abstract": "Comments: 7 pages, 11 figures, Accepted to ICRA 2021, Supplementary video this https URL",
    "descriptor": "\nComments: 7 pages, 11 figures, Accepted to ICRA 2021, Supplementary video this https URL\n",
    "authors": [
      "Zhichao Liu",
      "Konstantinos Karydis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.02061"
  },
  {
    "id": "arXiv:2011.05357",
    "title": "Stochastic generalized Nash equilibrium seeking under partial-decision  information",
    "abstract": "Stochastic generalized Nash equilibrium seeking under partial-decision  information",
    "descriptor": "",
    "authors": [
      "Barbara Franci",
      "Sergio Grammatico"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.05357"
  },
  {
    "id": "arXiv:2011.06763",
    "title": "Affinely representable lattices, stable matchings, and choice functions",
    "abstract": "Affinely representable lattices, stable matchings, and choice functions",
    "descriptor": "",
    "authors": [
      "Yuri Faenza",
      "Xuan Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2011.06763"
  },
  {
    "id": "arXiv:2011.10173",
    "title": "Exploring Global Information for Session-based Recommendation",
    "abstract": "Exploring Global Information for Session-based Recommendation",
    "descriptor": "",
    "authors": [
      "Ziyang Wang",
      "Wei Wei",
      "Gao Cong",
      "Xiao-Li Li",
      "Xian-Ling Mao",
      "Minghui Qiu",
      "Shanshan Feng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2011.10173"
  },
  {
    "id": "arXiv:2011.10282",
    "title": "Reconfigurable Intelligent Surface Enabled Federated Learning: A Unified  Communication-Learning Design Approach",
    "abstract": "Comments: Simulation codes are available at this https URL This work has been accepted by IEEE Transactions on Wireless Communications. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: Simulation codes are available at this https URL This work has been accepted by IEEE Transactions on Wireless Communications. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Hang Liu",
      "Xiaojun Yuan",
      "Ying-Jun Angela Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2011.10282"
  },
  {
    "id": "arXiv:2011.11928",
    "title": "GLGE: A New General Language Generation Evaluation Benchmark",
    "abstract": "Comments: Findings of Association for Computational Linguistics. ACL 2021",
    "descriptor": "\nComments: Findings of Association for Computational Linguistics. ACL 2021\n",
    "authors": [
      "Dayiheng Liu",
      "Yu Yan",
      "Yeyun Gong",
      "Weizhen Qi",
      "Hang Zhang",
      "Jian Jiao",
      "Weizhu Chen",
      "Jie Fu",
      "Linjun Shou",
      "Ming Gong",
      "Pengcheng Wang",
      "Jiusheng Chen",
      "Daxin Jiang",
      "Jiancheng Lv",
      "Ruofei Zhang",
      "Winnie Wu",
      "Ming Zhou",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2011.11928"
  },
  {
    "id": "arXiv:2011.14051",
    "title": "Close Latency--Security Trade-off for the Nakamoto Consensus",
    "abstract": "Close Latency--Security Trade-off for the Nakamoto Consensus",
    "descriptor": "",
    "authors": [
      "Jing Li",
      "Ling Ren",
      "Dongning Guo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.14051"
  },
  {
    "id": "arXiv:2011.15021",
    "title": "Multimodal Dependent Type Theory",
    "abstract": "Multimodal Dependent Type Theory",
    "descriptor": "",
    "authors": [
      "Daniel Gratzer",
      "G.A. Kavvos",
      "Andreas Nuyts",
      "Lars Birkedal"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2011.15021"
  },
  {
    "id": "arXiv:2012.02466",
    "title": "RIS-Assisted Secure Transmission Exploiting Statistical CSI of  Eavesdropper",
    "abstract": "Comments: 6 pages, 5 figures",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Cen Liu",
      "Chang Tian",
      "Peixi Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2012.02466"
  },
  {
    "id": "arXiv:2012.03979",
    "title": "Computing Welfare-Maximizing Fair Allocations of Indivisible Goods",
    "abstract": "Computing Welfare-Maximizing Fair Allocations of Indivisible Goods",
    "descriptor": "",
    "authors": [
      "Haris Aziz",
      "Xin Huang",
      "Nicholas Mattei",
      "Erel Segal-Halevi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2012.03979"
  },
  {
    "id": "arXiv:2012.05211",
    "title": "Synthesis to Deployment: Cyber-Physical Control Architectures",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1911.01510",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1911.01510\n",
    "authors": [
      "Shih-Hao Tseng",
      "James Anderson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.05211"
  },
  {
    "id": "arXiv:2012.05422",
    "title": "Exploiting Group-level Behavior Pattern forSession-based Recommendation",
    "abstract": "Exploiting Group-level Behavior Pattern forSession-based Recommendation",
    "descriptor": "",
    "authors": [
      "Ziyang Wang",
      "Wei Wei",
      "Xian-Ling Mao",
      "Xiao-Li Li",
      "Shanshan Feng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2012.05422"
  },
  {
    "id": "arXiv:2012.07297",
    "title": "Source Data-absent Unsupervised Domain Adaptation through Hypothesis  Transfer and Labeling Transfer",
    "abstract": "Comments: More interesting results are further shown in this https URL arXiv admin note: text overlap with arXiv:2002.08546",
    "descriptor": "\nComments: More interesting results are further shown in this https URL arXiv admin note: text overlap with arXiv:2002.08546\n",
    "authors": [
      "Jian Liang",
      "Dapeng Hu",
      "Yunbo Wang",
      "Ran He",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.07297"
  },
  {
    "id": "arXiv:2012.07719",
    "title": "Digital rock reconstruction with user-defined properties using  conditional generative adversarial networks",
    "abstract": "Comments: 36 pages, 20 figures",
    "descriptor": "\nComments: 36 pages, 20 figures\n",
    "authors": [
      "Qiang Zheng",
      "Dongxiao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2012.07719"
  },
  {
    "id": "arXiv:2012.10589",
    "title": "A Comparison of Three Measurement Models for the Wheel-mounted MEMS  IMU-based Dead Reckoning System",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1912.07805",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1912.07805\n",
    "authors": [
      "Yibin Wu",
      "Xiaoji Niu",
      "Jian Kuang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.10589"
  },
  {
    "id": "arXiv:2012.14117",
    "title": "3D Axial-Attention for Lung Nodule Classification",
    "abstract": "3D Axial-Attention for Lung Nodule Classification",
    "descriptor": "",
    "authors": [
      "Mundher Al-Shabi",
      "Kelvin Shak",
      "Maxine Tan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.14117"
  },
  {
    "id": "arXiv:2012.14193",
    "title": "Catastrophic Fisher Explosion: Early Phase Fisher Matrix Impacts  Generalization",
    "abstract": "Comments: The last two authors contributed equally. Accepted to the International Conference on Machine Learning 2021",
    "descriptor": "\nComments: The last two authors contributed equally. Accepted to the International Conference on Machine Learning 2021\n",
    "authors": [
      "Stanislaw Jastrzebski",
      "Devansh Arpit",
      "Oliver Astrand",
      "Giancarlo Kerg",
      "Huan Wang",
      "Caiming Xiong",
      "Richard Socher",
      "Kyunghyun Cho",
      "Krzysztof Geras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.14193"
  },
  {
    "id": "arXiv:2012.14710",
    "title": "Code Summarization with Structure-induced Transformer",
    "abstract": "Comments: Findings of ACL2021",
    "descriptor": "\nComments: Findings of ACL2021\n",
    "authors": [
      "Hongqiu Wu",
      "Hai Zhao",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.14710"
  },
  {
    "id": "arXiv:2012.14774",
    "title": "Generating Query Focused Summaries from Query-Free Resources",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Yumo Xu",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.14774"
  },
  {
    "id": "arXiv:2101.00288",
    "title": "Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and  Improving Models",
    "abstract": "Comments: ACL 2021, main conference, long paper",
    "descriptor": "\nComments: ACL 2021, main conference, long paper\n",
    "authors": [
      "Tongshuang Wu",
      "Marco Tulio Ribeiro",
      "Jeffrey Heer",
      "Daniel S. Weld"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00288"
  },
  {
    "id": "arXiv:2101.04017",
    "title": "A Commonsense Reasoning Framework for Explanatory Emotion Attribution,  Generation and Re-classification",
    "abstract": "Comments: 50 pages. This work has been partially funded from the European Research Council (ERC) under the European Union'sHorizon 2020 research and innovation programme, grant agreement n{\\deg}870811",
    "descriptor": "\nComments: 50 pages. This work has been partially funded from the European Research Council (ERC) under the European Union'sHorizon 2020 research and innovation programme, grant agreement n{\\deg}870811\n",
    "authors": [
      "Antonio Lieto",
      "Gian Luca Pozzato",
      "Stefano Zoia",
      "Viviana Patti",
      "Rossana Damiano"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.04017"
  },
  {
    "id": "arXiv:2101.04306",
    "title": "Multi-Robot Gaussian Process Estimation and Coverage: A Deterministic  Sequencing Algorithm and Regret Analysis",
    "abstract": "Comments: 7 pages, 2 figures, accepted to IEEE ICRA'21",
    "descriptor": "\nComments: 7 pages, 2 figures, accepted to IEEE ICRA'21\n",
    "authors": [
      "Lai Wei",
      "Andrew McDonald",
      "Vaibhav Srivastava"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.04306"
  },
  {
    "id": "arXiv:2101.04427",
    "title": "Quantum Internet- Applications, Functionalities, Enabling Technologies,  Challenges, and Research Directions",
    "abstract": "Comments: This survey paper is submitted in IEEE Communications Surveys and Tutorials and revised on 27th May 2021. It includes 31 pages, 14 figures, and 5 tables",
    "descriptor": "\nComments: This survey paper is submitted in IEEE Communications Surveys and Tutorials and revised on 27th May 2021. It includes 31 pages, 14 figures, and 5 tables\n",
    "authors": [
      "Amoldeep Singh",
      "Kapal Dev",
      "Harun Siljak",
      "Hem Dutt Joshi",
      "Maurizio Magarini"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2101.04427"
  },
  {
    "id": "arXiv:2101.04968",
    "title": "Learning with Gradient Descent and Weakly Convex Losses",
    "abstract": "Comments: Updated References",
    "descriptor": "\nComments: Updated References\n",
    "authors": [
      "Dominic Richards",
      "Mike Rabbat"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2101.04968"
  },
  {
    "id": "arXiv:2101.05853",
    "title": "Algorithmic Monoculture and Social Welfare",
    "abstract": "Comments: A version of this paper appears in Proceedings of the National Academy of Sciences at this https URL",
    "descriptor": "\nComments: A version of this paper appears in Proceedings of the National Academy of Sciences at this https URL\n",
    "authors": [
      "Jon Kleinberg",
      "Manish Raghavan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.05853"
  },
  {
    "id": "arXiv:2101.06927",
    "title": "Robustness of Meta Matrix Factorization Against Strict Privacy  Constraints",
    "abstract": "Comments: Accepted at ECIR 2021, Reproducibility Track",
    "descriptor": "\nComments: Accepted at ECIR 2021, Reproducibility Track\n",
    "authors": [
      "Peter M\u00fcllner",
      "Dominik Kowald",
      "Elisabeth Lex"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2101.06927"
  },
  {
    "id": "arXiv:2101.08533",
    "title": "A general multi-modal data learning method for Person Re-identification",
    "abstract": "A general multi-modal data learning method for Person Re-identification",
    "descriptor": "",
    "authors": [
      "Yunpeng Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.08533"
  },
  {
    "id": "arXiv:2101.08687",
    "title": "Overfitting for Fun and Profit: Instance-Adaptive Data Compression",
    "abstract": "Comments: Accepted at International Conference on Learning Representations 2021",
    "descriptor": "\nComments: Accepted at International Conference on Learning Representations 2021\n",
    "authors": [
      "Ties van Rozendaal",
      "Iris A.M. Huijben",
      "Taco S. Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.08687"
  },
  {
    "id": "arXiv:2101.08934",
    "title": "AS-Net: Fast Photoacoustic Reconstruction with Multi-feature Fusion from  Sparse Data",
    "abstract": "AS-Net: Fast Photoacoustic Reconstruction with Multi-feature Fusion from  Sparse Data",
    "descriptor": "",
    "authors": [
      "Mengjie Guo",
      "Hengrong Lan",
      "Changchun Yang",
      "Fei Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2101.08934"
  },
  {
    "id": "arXiv:2101.09520",
    "title": "Is academia becoming more localised? The growth of regional knowledge  networks within international research collaboration",
    "abstract": "Comments: 28 pages, 7 figures, accepted to Applied Network Science",
    "descriptor": "\nComments: 28 pages, 7 figures, accepted to Applied Network Science\n",
    "authors": [
      "John Fitzgerald",
      "Sanna Ojanper\u00e4",
      "Neave O'Clery"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2101.09520"
  },
  {
    "id": "arXiv:2101.10092",
    "title": "Beyond cost reduction: Improving the value of energy storage in  electricity systems",
    "abstract": "Comments: 15 pages, 10 figures",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Maximilian Parzen",
      "Fabian Neumann",
      "Addrian H. Van Der Weijde",
      "Daniel Friedrich",
      "Aristides Kiprakis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Physics and Society (physics.soc-ph)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2101.10092"
  },
  {
    "id": "arXiv:2101.10394",
    "title": "Optimal Network Topology of Multi-Agent Systems subject to Computation  and Communication Latency (with proofs)",
    "abstract": "Comments: 18 pages, 9 figures",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Luca Ballotta",
      "Mihailo R. Jovanovi\u0107",
      "Luca Schenato"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.10394"
  },
  {
    "id": "arXiv:2101.12733",
    "title": "On the Expressive Power of Homomorphism Counts",
    "abstract": "Comments: 27 pages, 2 figures",
    "descriptor": "\nComments: 27 pages, 2 figures\n",
    "authors": [
      "Albert Atserias",
      "Phokion G. Kolaitis",
      "Wei-Lin Wu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.12733"
  },
  {
    "id": "arXiv:2102.02727",
    "title": "Multiple Criss-Cross Insertion and Deletion Correcting Codes",
    "abstract": "Multiple Criss-Cross Insertion and Deletion Correcting Codes",
    "descriptor": "",
    "authors": [
      "Lorenz Welter",
      "Rawad Bitar",
      "Antonia Wachter-Zeh",
      "Eitan Yaakobi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.02727"
  },
  {
    "id": "arXiv:2102.03322",
    "title": "CF-GNNExplainer: Counterfactual Explanations for Graph Neural Networks",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Ana Lucic",
      "Maartje ter Hoeve",
      "Gabriele Tolomei",
      "Maarten de Rijke",
      "Fabrizio Silvestri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.03322"
  },
  {
    "id": "arXiv:2102.03765",
    "title": "Tactical Optimism and Pessimism for Deep Reinforcement Learning",
    "abstract": "Tactical Optimism and Pessimism for Deep Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Ted Moskovitz",
      "Jack Parker-Holder",
      "Aldo Pacchiano",
      "Michael Arbel",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.03765"
  },
  {
    "id": "arXiv:2102.05111",
    "title": "Nonlinear Observers Design for Vision-Aided Inertial Navigation Systems",
    "abstract": "Comments: Accepted for publication in IEEE Transaction on Automatic Control. 16 pages, 6 figures",
    "descriptor": "\nComments: Accepted for publication in IEEE Transaction on Automatic Control. 16 pages, 6 figures\n",
    "authors": [
      "Miaomiao Wang",
      "Soulaimane Berkane",
      "Abdelhamid Tayebi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.05111"
  },
  {
    "id": "arXiv:2102.05152",
    "title": "On Explainability of Graph Neural Networks via Subgraph Explorations",
    "abstract": "Comments: Accepted by ICML 2021",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Hao Yuan",
      "Haiyang Yu",
      "Jie Wang",
      "Kang Li",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.05152"
  },
  {
    "id": "arXiv:2102.08132",
    "title": "Towards an accountable Internet of Things: A call for reviewability",
    "abstract": "Comments: To appear in: Privacy by Design for the Internet of Things. Cite as: Norval C, Cobbe J, and Singh, J. Towards an accountable Internet of Things: A call for reviewability. In Privacy by Design for the Internet of Things: Building accountability and security; London, UK: IET; 2021",
    "descriptor": "\nComments: To appear in: Privacy by Design for the Internet of Things. Cite as: Norval C, Cobbe J, and Singh, J. Towards an accountable Internet of Things: A call for reviewability. In Privacy by Design for the Internet of Things: Building accountability and security; London, UK: IET; 2021\n",
    "authors": [
      "Chris Norval",
      "Jennifer Cobbe",
      "Jatinder Singh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2102.08132"
  },
  {
    "id": "arXiv:2102.08369",
    "title": "CTAB-GAN: Effective Table Data Synthesizing",
    "abstract": "Comments: This paper consists of 11 pages which contain 8 figures, 5 tables and an appendix with a user manual for our software application",
    "descriptor": "\nComments: This paper consists of 11 pages which contain 8 figures, 5 tables and an appendix with a user manual for our software application\n",
    "authors": [
      "Zilong Zhao",
      "Aditya Kunar",
      "Hiek Van der Scheer",
      "Robert Birke",
      "Lydia Y. Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.08369"
  },
  {
    "id": "arXiv:2102.10652",
    "title": "Observer Design for Linear Aperiodic Sampled-Data Systems: A Hybrid  Systems Approach",
    "abstract": "Comments: V1 is the original submission before peer review. V2 is the peer-reviewed version accepted for publication. V2 includes fixes to minor typos in the early access version of the paper and matches the final printed version to appear in the IEEE Control Systems Letters",
    "descriptor": "\nComments: V1 is the original submission before peer review. V2 is the peer-reviewed version accepted for publication. V2 includes fixes to minor typos in the early access version of the paper and matches the final printed version to appear in the IEEE Control Systems Letters\n",
    "authors": [
      "Francesco Ferrante",
      "Alexandre Seuret"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.10652"
  },
  {
    "id": "arXiv:2102.13640",
    "title": "NOMU: Neural Optimization-based Model Uncertainty",
    "abstract": "Comments: 9 pages + appendix",
    "descriptor": "\nComments: 9 pages + appendix\n",
    "authors": [
      "Jakob Heiss",
      "Jakob Weissteiner",
      "Hanna Wutte",
      "Sven Seuken",
      "Josef Teichmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.13640"
  },
  {
    "id": "arXiv:2103.02630",
    "title": "Hypothesis Testing for Class-Conditional Label Noise",
    "abstract": "Comments: 15 pages, 4 figures",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Rafael Poyiadzi",
      "Weisong Yang",
      "Niall Twomey",
      "Raul Santos-Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.02630"
  },
  {
    "id": "arXiv:2103.02760",
    "title": "Worsening Perception: Real-time Degradation of Autonomous Vehicle  Perception Performance for Simulation of Adverse Weather Conditions",
    "abstract": "Worsening Perception: Real-time Degradation of Autonomous Vehicle  Perception Performance for Simulation of Adverse Weather Conditions",
    "descriptor": "",
    "authors": [
      "Ivan Fursa",
      "Elias Fandi",
      "Valentina Musat",
      "Jacob Culley",
      "Enric Gil",
      "Izzedin Teeti",
      "Louise Bilous",
      "Isaac Vander Sluis",
      "Alexander Rast",
      "Andrew Bradley"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.02760"
  },
  {
    "id": "arXiv:2103.03023",
    "title": "End-to-End Mispronunciation Detection and Diagnosis From Raw Waveforms",
    "abstract": "Comments: Preprint. Under review 5 pages, 3 figures",
    "descriptor": "\nComments: Preprint. Under review 5 pages, 3 figures\n",
    "authors": [
      "Bi-Cheng Yan",
      "Berlin Chen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2103.03023"
  },
  {
    "id": "arXiv:2103.03288",
    "title": "The Effect of Network Topology on Credit Network Throughput",
    "abstract": "The Effect of Network Topology on Credit Network Throughput",
    "descriptor": "",
    "authors": [
      "Vibhaalakshmi Sivaraman",
      "Weizhao Tang",
      "Shaileshh Bojja Venkatakrishnan",
      "Giulia Fanti",
      "Mohammad Alizadeh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2103.03288"
  },
  {
    "id": "arXiv:2103.04004",
    "title": "Bilateral Control-Based Imitation Learning for Velocity-Controlled Robot",
    "abstract": "Comments: 6pages, 10 figures, submitted for ISIE2021",
    "descriptor": "\nComments: 6pages, 10 figures, submitted for ISIE2021\n",
    "authors": [
      "Sho Sakaino"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.04004"
  },
  {
    "id": "arXiv:2103.04514",
    "title": "Nondeterminism and Instability in Neural Network Optimization",
    "abstract": "Comments: To be published in ICML 2021",
    "descriptor": "\nComments: To be published in ICML 2021\n",
    "authors": [
      "Cecilia Summers",
      "Michael J. Dinneen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.04514"
  },
  {
    "id": "arXiv:2103.04722",
    "title": "Sparse Kronecker-Product Coding for Unsourced Multiple Access",
    "abstract": "Comments: Submitted to IEEE Wireless Communications Letters",
    "descriptor": "\nComments: Submitted to IEEE Wireless Communications Letters\n",
    "authors": [
      "Zeyu Han",
      "Xiaojun Yuan",
      "Chongbin Xu",
      "Shuchao Jiang",
      "Xin Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2103.04722"
  },
  {
    "id": "arXiv:2103.05588",
    "title": "Exact and Approximate Pattern Counting in Degenerate Graphs: New  Algorithms, Hardness Results, and Complexity Dichotomies",
    "abstract": "Comments: 44 pages, 3 figures",
    "descriptor": "\nComments: 44 pages, 3 figures\n",
    "authors": [
      "Marco Bressan",
      "Marc Roth"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2103.05588"
  },
  {
    "id": "arXiv:2103.08562",
    "title": "Is Medical Chest X-ray Data Anonymous?",
    "abstract": "Is Medical Chest X-ray Data Anonymous?",
    "descriptor": "",
    "authors": [
      "Kai Packh\u00e4user",
      "Sebastian G\u00fcndel",
      "Nicolas M\u00fcnster",
      "Christopher Syben",
      "Vincent Christlein",
      "Andreas Maier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.08562"
  },
  {
    "id": "arXiv:2103.10312",
    "title": "Real-Time, Deep Synthetic Aperture Sonar (SAS) Autofocus",
    "abstract": "Comments: Four pages. Accepted to IGARSS 2021. Fixed Eq 9",
    "descriptor": "\nComments: Four pages. Accepted to IGARSS 2021. Fixed Eq 9\n",
    "authors": [
      "Isaac D. Gerg",
      "Vishal Monga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.10312"
  },
  {
    "id": "arXiv:2103.11030",
    "title": "Don't Tell Me The Cybersecurity Moon Is Shining... (Cybersecurity Show  And Tell)",
    "abstract": "Comments: 28 pages, 6 figures",
    "descriptor": "\nComments: 28 pages, 6 figures\n",
    "authors": [
      "Luca Vigan\u00f2"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2103.11030"
  },
  {
    "id": "arXiv:2103.11766",
    "title": "Fixes That Fail: Self-Defeating Improvements in Machine-Learning Systems",
    "abstract": "Fixes That Fail: Self-Defeating Improvements in Machine-Learning Systems",
    "descriptor": "",
    "authors": [
      "Ruihan Wu",
      "Chuan Guo",
      "Awni Hannun",
      "Laurens van der Maaten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.11766"
  },
  {
    "id": "arXiv:2103.11807",
    "title": "Data Cleansing for Deep Neural Networks with Storage-efficient  Approximation of Influence Functions",
    "abstract": "Data Cleansing for Deep Neural Networks with Storage-efficient  Approximation of Influence Functions",
    "descriptor": "",
    "authors": [
      "Kenji Suzuki",
      "Yoshiyuki Kobayashi",
      "Takuya Narihira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.11807"
  },
  {
    "id": "arXiv:2103.12803",
    "title": "Fixed Point Networks: Implicit Depth Models with Jacobian-Free Backprop",
    "abstract": "Fixed Point Networks: Implicit Depth Models with Jacobian-Free Backprop",
    "descriptor": "",
    "authors": [
      "Samy Wu Fung",
      "Howard Heaton",
      "Qiuwei Li",
      "Daniel McKenzie",
      "Stanley Osher",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.12803"
  },
  {
    "id": "arXiv:2103.14976",
    "title": "A Multistakeholder Approach Towards Evaluating AI Transparency  Mechanisms",
    "abstract": "Comments: Accepted to CHI 2021 Workshop on Operationalizing Human-Centered Perspectives in Explainable AI",
    "descriptor": "\nComments: Accepted to CHI 2021 Workshop on Operationalizing Human-Centered Perspectives in Explainable AI\n",
    "authors": [
      "Ana Lucic",
      "Madhulika Srikumar",
      "Umang Bhatt",
      "Alice Xiang",
      "Ankur Taly",
      "Q. Vera Liao",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2103.14976"
  },
  {
    "id": "arXiv:2103.15458",
    "title": "A trustable and interoperable decentralized solution for citizen-centric  and cross-border eGovernance: A conceptual approach",
    "abstract": "Comments: 12 pages, 2 figures",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "George Domalis",
      "Nikos Karacapilidis",
      "Dimitris Tsakalidis",
      "Anastasios Giannaros"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2103.15458"
  },
  {
    "id": "arXiv:2104.00099",
    "title": "LIFT-SLAM: a deep-learning feature-based monocular visual SLAM method",
    "abstract": "Comments: 30 pages, Published in Neurocomputing",
    "descriptor": "\nComments: 30 pages, Published in Neurocomputing\n",
    "authors": [
      "Hudson M. S. Bruno",
      "Esther L. Colombini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.00099"
  },
  {
    "id": "arXiv:2104.04547",
    "title": "High-Throughput Virtual Screening of Small Molecule Inhibitors for  SARS-CoV-2 Protein Targets with Deep Fusion Models",
    "abstract": "High-Throughput Virtual Screening of Small Molecule Inhibitors for  SARS-CoV-2 Protein Targets with Deep Fusion Models",
    "descriptor": "",
    "authors": [
      "Garrett A. Stevenson",
      "Derek Jones",
      "Hyojin Kim",
      "W. F. Drew Bennett",
      "Brian J. Bennion",
      "Monica Borucki",
      "Feliza Bourguet",
      "Aidan Epstein",
      "Magdalena Franco",
      "Brooke Harmon",
      "Stewart He",
      "Max P. Katz",
      "Daniel Kirshner",
      "Victoria Lao",
      "Edmond Y. Lau",
      "Jacky Lo",
      "Kevin McLoughlin",
      "Richard Mosesso",
      "Deepa K. Murugesh",
      "Oscar A. Negrete",
      "Edwin A. Saada",
      "Brent Segelke",
      "Maxwell Stefan",
      "Marisa W. Torres",
      "Dina Weilhammer",
      "Sergio Wong",
      "Yue Yang",
      "Adam Zemla",
      "Xiaohua Zhang",
      "Fangqiang Zhu",
      "Felice C. Lightstone",
      "Jonathan E. Allen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2104.04547"
  },
  {
    "id": "arXiv:2104.04637",
    "title": "A Novel Provably Secure Key Agreement Protocol Based On Binary Matrices",
    "abstract": "A Novel Provably Secure Key Agreement Protocol Based On Binary Matrices",
    "descriptor": "",
    "authors": [
      "Abdelhaliem Babiker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.04637"
  },
  {
    "id": "arXiv:2104.04692",
    "title": "Not All Attention Is All You Need",
    "abstract": "Not All Attention Is All You Need",
    "descriptor": "",
    "authors": [
      "Hongqiu Wu",
      "Hai Zhao",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.04692"
  },
  {
    "id": "arXiv:2104.06601",
    "title": "Zero-Shot Instance Segmentation",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Ye Zheng",
      "Jiahong Wu",
      "Yongqiang Qin",
      "Faen Zhang",
      "Li Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.06601"
  },
  {
    "id": "arXiv:2104.06624",
    "title": "Device-Cloud Collaborative Learning for Recommendation",
    "abstract": "Comments: KDD 2021",
    "descriptor": "\nComments: KDD 2021\n",
    "authors": [
      "Jiangchao Yao",
      "Feng Wang",
      "KunYang Jia",
      "Bo Han",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.06624"
  },
  {
    "id": "arXiv:2104.07279",
    "title": "Deep learning for COVID-19 diagnosis based feature selection using  binary differential evolution algorithm",
    "abstract": "Deep learning for COVID-19 diagnosis based feature selection using  binary differential evolution algorithm",
    "descriptor": "",
    "authors": [
      "Mohammad Saber Iraji",
      "Mohammad-Reza Feizi-Derakhshi",
      "Jafar Tanha"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07279"
  },
  {
    "id": "arXiv:2104.08267",
    "title": "Iterative Model Predictive Control for Piecewise Systems",
    "abstract": "Iterative Model Predictive Control for Piecewise Systems",
    "descriptor": "",
    "authors": [
      "Ugo Rosolia",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.08267"
  },
  {
    "id": "arXiv:2104.08427",
    "title": "Models and Predictive Control for Nonplanar Vehicle Navigation",
    "abstract": "Comments: Minor changes to Appendix",
    "descriptor": "\nComments: Minor changes to Appendix\n",
    "authors": [
      "Thomas Fork",
      "H. Eric Tseng",
      "Francesco Borrelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.08427"
  },
  {
    "id": "arXiv:2104.09907",
    "title": "Table Tennis Stroke Recognition Using Two-Dimensional Human Pose  Estimation",
    "abstract": "Comments: Accepted at CVPR Sports Workshop 2021 (7th International Workshop on Computer Vision in Sports) (CVSports)",
    "descriptor": "\nComments: Accepted at CVPR Sports Workshop 2021 (7th International Workshop on Computer Vision in Sports) (CVSports)\n",
    "authors": [
      "Kaustubh Milind Kulkarni",
      "Sucheth Shenoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09907"
  },
  {
    "id": "arXiv:2104.10083",
    "title": "Personalized News Recommendation with Knowledge-aware Interactive  Matching",
    "abstract": "Comments: SIGIR 2021",
    "descriptor": "\nComments: SIGIR 2021\n",
    "authors": [
      "Tao Qi",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2104.10083"
  },
  {
    "id": "arXiv:2104.10593",
    "title": "Acyclic, Star, and Injective Colouring: Bounding the Diameter",
    "abstract": "Acyclic, Star, and Injective Colouring: Bounding the Diameter",
    "descriptor": "",
    "authors": [
      "Christoph Brause",
      "Petr Golovach",
      "Barnaby Martin",
      "Pascal Ochem",
      "Dani\u00ebl Paulusma",
      "Siani Smith"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2104.10593"
  },
  {
    "id": "arXiv:2104.12335",
    "title": "Diverse Image Inpainting with Bidirectional and Autoregressive  Transformers",
    "abstract": "Comments: 11 pages, 6 figures",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Yingchen Yu",
      "Fangneng Zhan",
      "Rongliang Wu",
      "Jianxiong Pan",
      "Kaiwen Cui",
      "Shijian Lu",
      "Feiying Ma",
      "Xuansong Xie",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.12335"
  },
  {
    "id": "arXiv:2104.12653",
    "title": "I am Definitely Manipulated, Even When I am Aware of it. It s  Ridiculous! -- Dark Patterns from the End-User Perspective",
    "abstract": "Comments: ACM DIS Conference on Designing interactive systems, June 28 - July 2, 2021, online. ACM, New York, NY, USA",
    "descriptor": "\nComments: ACM DIS Conference on Designing interactive systems, June 28 - July 2, 2021, online. ACM, New York, NY, USA\n",
    "authors": [
      "Kerstin Bongard-Blanchy",
      "Arianna Rossi",
      "Salvador Rivas",
      "Sophie Doublet",
      "Vincent Koenig",
      "Gabriele Lenzini"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2104.12653"
  },
  {
    "id": "arXiv:2104.12828",
    "title": "Multi-resource allocation for federated settings: A non-homogeneous  Markov chain model",
    "abstract": "Comments: The paper was published without the co-authors' notice, and it is withdrawn due to their objection and due to authorship conflicts",
    "descriptor": "\nComments: The paper was published without the co-authors' notice, and it is withdrawn due to their objection and due to authorship conflicts\n",
    "authors": [
      "Syed Eqbal Alam",
      "Fabian Wirth",
      "Jia Yuan Yu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.12828"
  },
  {
    "id": "arXiv:2104.13254",
    "title": "Proceedings - AI/ML for Cybersecurity: Challenges, Solutions, and Novel  Ideas at SIAM Data Mining 2021",
    "abstract": "Proceedings - AI/ML for Cybersecurity: Challenges, Solutions, and Novel  Ideas at SIAM Data Mining 2021",
    "descriptor": "",
    "authors": [
      "John Emanuello",
      "Kimberly Ferguson-Walter",
      "Erik Hemberg",
      "Una-May O Reilly",
      "Ahmad Ridley",
      "Dennis Ross",
      "Diane Staheli",
      "William Streilein"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.13254"
  },
  {
    "id": "arXiv:2104.13872",
    "title": "Removing Word-Level Spurious Alignment between Images and  Pseudo-Captions in Unsupervised Image Captioning",
    "abstract": "Comments: EACL 2021 (11 pages, 3 figures; added references)",
    "descriptor": "\nComments: EACL 2021 (11 pages, 3 figures; added references)\n",
    "authors": [
      "Ukyo Honda",
      "Yoshitaka Ushiku",
      "Atsushi Hashimoto",
      "Taro Watanabe",
      "Yuji Matsumoto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.13872"
  },
  {
    "id": "arXiv:2104.14842",
    "title": "A Thermodynamic based and Data Driven Hybrid Network for Gas Turbine  Modeling",
    "abstract": "A Thermodynamic based and Data Driven Hybrid Network for Gas Turbine  Modeling",
    "descriptor": "",
    "authors": [
      "Likun Ren"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.14842"
  },
  {
    "id": "arXiv:2105.00930",
    "title": "Pose Invariant Person Re-Identification using Robust Pose-transformation  GAN",
    "abstract": "Comments: Undergraduate thesis at Indian Institute of Space Science and Technology, Under review in IEEE Systems, Man and Cybernetics (SMCA)",
    "descriptor": "\nComments: Undergraduate thesis at Indian Institute of Space Science and Technology, Under review in IEEE Systems, Man and Cybernetics (SMCA)\n",
    "authors": [
      "Arnab Karmakar",
      "Deepak Mishra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00930"
  },
  {
    "id": "arXiv:2105.02135",
    "title": "UVIP: Model-Free Approach to Evaluate Reinforcement Learning Algorithms",
    "abstract": "UVIP: Model-Free Approach to Evaluate Reinforcement Learning Algorithms",
    "descriptor": "",
    "authors": [
      "D. Belomestny",
      "I. Levin",
      "E. Moulines",
      "A. Naumov",
      "S. Samsonov",
      "V. Zorina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.02135"
  },
  {
    "id": "arXiv:2105.02195",
    "title": "Moving SLAM: Fully Unsupervised Deep Learning in Non-Rigid Scenes",
    "abstract": "Moving SLAM: Fully Unsupervised Deep Learning in Non-Rigid Scenes",
    "descriptor": "",
    "authors": [
      "Dan Xu",
      "Andrea Vedaldi",
      "Joao F. Henriques"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.02195"
  },
  {
    "id": "arXiv:2105.02590",
    "title": "Reliability Testing for Natural Language Processing Systems",
    "abstract": "Comments: Accepted to ACL-IJCNLP 2021 (main conference). Camera-ready version",
    "descriptor": "\nComments: Accepted to ACL-IJCNLP 2021 (main conference). Camera-ready version\n",
    "authors": [
      "Samson Tan",
      "Shafiq Joty",
      "Kathy Baxter",
      "Araz Taeihagh",
      "Gregory A. Bennett",
      "Min-Yen Kan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.02590"
  },
  {
    "id": "arXiv:2105.02732",
    "title": "What's in the Box? A Preliminary Analysis of Undesirable Content in the  Common Crawl Corpus",
    "abstract": "Comments: 5 pages, 1 figure, 3 tables. Published as a main conference paper at ACL-IJCNLP 2021, submission #87. Code available at this https URL",
    "descriptor": "\nComments: 5 pages, 1 figure, 3 tables. Published as a main conference paper at ACL-IJCNLP 2021, submission #87. Code available at this https URL\n",
    "authors": [
      "Alexandra Sasha Luccioni",
      "Joseph D. Viviano"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.02732"
  },
  {
    "id": "arXiv:2105.03033",
    "title": "Towards Sharper Utility Bounds for Differentially Private Pairwise  Learning",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Yilin Kang",
      "Yong Liu",
      "Jian Li",
      "Weiping Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03033"
  },
  {
    "id": "arXiv:2105.03603",
    "title": "Learning to Detect an Odd Restless Markov Arm with a Trembling Hand",
    "abstract": "Comments: 49 pages. A shorter version of this manuscript has been accepted for presentation at the 2021 IEEE International Symposium on Information Theory. This manuscript contains the proofs of all the main results",
    "descriptor": "\nComments: 49 pages. A shorter version of this manuscript has been accepted for presentation at the 2021 IEEE International Symposium on Information Theory. This manuscript contains the proofs of all the main results\n",
    "authors": [
      "P. N. Karthik",
      "Rajesh Sundaresan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03603"
  },
  {
    "id": "arXiv:2105.04117",
    "title": "Wiki-Reliability: A Large Scale Dataset for Content Reliability on  Wikipedia",
    "abstract": "Comments: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '21), 2021",
    "descriptor": "\nComments: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '21), 2021\n",
    "authors": [
      "KayYen Wong",
      "Miriam Redi",
      "Diego Saez-Trumper"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04117"
  },
  {
    "id": "arXiv:2105.04387",
    "title": "Recent Advances in Deep Learning Based Dialogue Systems: A Systematic  Survey",
    "abstract": "Comments: 76 pages, 19 figures",
    "descriptor": "\nComments: 76 pages, 19 figures\n",
    "authors": [
      "Jinjie Ni",
      "Tom Young",
      "Vlad Pandelea",
      "Fuzhao Xue",
      "Vinay Adiga",
      "Erik Cambria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04387"
  },
  {
    "id": "arXiv:2105.05233",
    "title": "Diffusion Models Beat GANs on Image Synthesis",
    "abstract": "Comments: Added compute requirements, ImageNet 256$\\times$256 upsampling FID and samples, DDIM guided sampler, fixed typos",
    "descriptor": "\nComments: Added compute requirements, ImageNet 256$\\times$256 upsampling FID and samples, DDIM guided sampler, fixed typos\n",
    "authors": [
      "Prafulla Dhariwal",
      "Alex Nichol"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.05233"
  },
  {
    "id": "arXiv:2105.05545",
    "title": "Optimal pointwise sampling for $L^2$ approximation",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Albert Cohen",
      "Matthieu Dolbeault"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.05545"
  },
  {
    "id": "arXiv:2105.05553",
    "title": "Principal Components Bias in Deep Neural Networks",
    "abstract": "Principal Components Bias in Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Guy Hacohen",
      "Daphna Weinshall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.05553"
  },
  {
    "id": "arXiv:2105.06709",
    "title": "Learning Unknown from Correlations: Graph Neural Network for  Inter-novel-protein Interaction Prediction",
    "abstract": "Comments: 10 pages(3 pages appendix), 2 figures, Accepted by Conference IJCAI2021, which is its extended version",
    "descriptor": "\nComments: 10 pages(3 pages appendix), 2 figures, Accepted by Conference IJCAI2021, which is its extended version\n",
    "authors": [
      "Guofeng Lv",
      "Zhiqiang Hu",
      "Yanguang Bi",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2105.06709"
  },
  {
    "id": "arXiv:2105.07624",
    "title": "TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and  Textual Content in Finance",
    "abstract": "Comments: Accepted by ACL 2021",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Fengbin Zhu",
      "Wenqiang Lei",
      "Youcheng Huang",
      "Chao Wang",
      "Shuo Zhang",
      "Jiancheng Lv",
      "Fuli Feng",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.07624"
  },
  {
    "id": "arXiv:2105.08339",
    "title": "DRIVE: One-bit Distributed Mean Estimation",
    "abstract": "DRIVE: One-bit Distributed Mean Estimation",
    "descriptor": "",
    "authors": [
      "Shay Vargaftik",
      "Ran Ben Basat",
      "Amit Portnoy",
      "Gal Mendelson",
      "Yaniv Ben-Itzhak",
      "Michael Mitzenmacher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.08339"
  },
  {
    "id": "arXiv:2105.09458",
    "title": "MLBiNet: A Cross-Sentence Collective Event Detection Network",
    "abstract": "Comments: Accepted by ACL 2021",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Dongfang Lou",
      "Zhilin Liao",
      "Shumin Deng",
      "Ningyu Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.09458"
  },
  {
    "id": "arXiv:2105.10188",
    "title": "Semantic Representation for Dialogue Modeling",
    "abstract": "Comments: Final camera ready version, to appear in ACL2021 main conference",
    "descriptor": "\nComments: Final camera ready version, to appear in ACL2021 main conference\n",
    "authors": [
      "Xuefeng Bai",
      "Yulong Chen",
      "Linfeng Song",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.10188"
  },
  {
    "id": "arXiv:2105.10755",
    "title": "A Heuristic Approach to Efficient Deployment of SDN assisted UAV  communication systems considering UAV Placement, Energy Consumption and  Traffic Congestion",
    "abstract": "Comments: 7 pages, 17 figures",
    "descriptor": "\nComments: 7 pages, 17 figures\n",
    "authors": [
      "Sai Teja Suggala",
      "Siddhartha Pothukuchi",
      "Naimat Ali Khan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.10755"
  },
  {
    "id": "arXiv:2105.11592",
    "title": "A Holistic View on Resource Management in Serverless Computing  Environments: Taxonomy and Future Directions",
    "abstract": "Comments: 32 pages, 4 figures",
    "descriptor": "\nComments: 32 pages, 4 figures\n",
    "authors": [
      "Anupama Mampage",
      "Shanika Karunasekera",
      "Rajkumar Buyya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.11592"
  },
  {
    "id": "arXiv:2105.11605",
    "title": "TransLoc3D : Point Cloud based Large-scale Place Recognition using  Adaptive Receptive Fields",
    "abstract": "TransLoc3D : Point Cloud based Large-scale Place Recognition using  Adaptive Receptive Fields",
    "descriptor": "",
    "authors": [
      "Tian-Xing Xu",
      "Yuan-Chen Guo",
      "Yu-Kun Lai",
      "Song-Hai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11605"
  },
  {
    "id": "arXiv:2105.12021",
    "title": "Tight Inner Approximations of the Positive-Semidefinite Cone via  Grassmannian Packings",
    "abstract": "Tight Inner Approximations of the Positive-Semidefinite Cone via  Grassmannian Packings",
    "descriptor": "",
    "authors": [
      "Tianqi Zheng",
      "James Guthrie",
      "Enrique Mallada"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.12021"
  },
  {
    "id": "arXiv:2105.12195",
    "title": "Bias in Machine Learning Software: Why? How? What to do?",
    "abstract": "Bias in Machine Learning Software: Why? How? What to do?",
    "descriptor": "",
    "authors": [
      "Joymallya Chakraborty",
      "Suvodeep Majumder",
      "Tim Menzies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.12195"
  },
  {
    "id": "arXiv:2105.12837",
    "title": "Fooling Partial Dependence via Data Poisoning",
    "abstract": "Comments: Code for this work is available at this https URL",
    "descriptor": "\nComments: Code for this work is available at this https URL\n",
    "authors": [
      "Hubert Baniecki",
      "Wojciech Kretowicz",
      "Przemyslaw Biecek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.12837"
  },
  {
    "id": "arXiv:2105.13244",
    "title": "Using Early-Learning Regularization to Classify Real-World Noisy Data",
    "abstract": "Using Early-Learning Regularization to Classify Real-World Noisy Data",
    "descriptor": "",
    "authors": [
      "Alessio Galatolo",
      "Alfred Nilsson",
      "Roderick Karlemstrand",
      "Yineng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13244"
  },
  {
    "id": "arXiv:2105.13456",
    "title": "Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced  Collective Inference",
    "abstract": "Comments: Accepted by ACL 2021",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Tuan Lai",
      "Heng Ji",
      "ChengXiang Zhai",
      "Quan Hung Tran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13456"
  },
  {
    "id": "arXiv:2105.13482",
    "title": "FastRIFE: Optimization of Real-Time Intermediate Flow Estimation for  Video Frame Interpolation",
    "abstract": "Comments: WSCG 2021 29. International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision",
    "descriptor": "\nComments: WSCG 2021 29. International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision\n",
    "authors": [
      "Malwina Kubas",
      "Grzegorz Sarwas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13482"
  },
  {
    "id": "arXiv:2105.13699",
    "title": "Accelerating JavaScript Static Analysis via Dynamic Shortcuts (Extended  Version)",
    "abstract": "Comments: 16 pages, 11 figures, 1 table, In Proceedings of the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE'21)",
    "descriptor": "\nComments: 16 pages, 11 figures, 1 table, In Proceedings of the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE'21)\n",
    "authors": [
      "Joonyoung Park",
      "Jihyeok Park",
      "Dongjun Youn",
      "Sukyoung Ryu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.13699"
  },
  {
    "id": "arXiv:2105.13863",
    "title": "On plane algebraic curves passing through $n$-independent nodes",
    "abstract": "Comments: 24 pages. arXiv admin note: substantial text overlap with arXiv:1903.10874",
    "descriptor": "\nComments: 24 pages. arXiv admin note: substantial text overlap with arXiv:1903.10874\n",
    "authors": [
      "Hakop Hakopian",
      "Harutyun Kloyan",
      "Davit Voskanyan"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13863"
  },
  {
    "id": "arXiv:2105.13868",
    "title": "Learning Relation Alignment for Calibrated Cross-modal Retrieval",
    "abstract": "Comments: Accepted by ACL-IJCNLP 2021 main conference (Long Paper)",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021 main conference (Long Paper)\n",
    "authors": [
      "Shuhuai Ren",
      "Junyang Lin",
      "Guangxiang Zhao",
      "Rui Men",
      "An Yang",
      "Jingren Zhou",
      "Xu Sun",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13868"
  },
  {
    "id": "arXiv:2105.14107",
    "title": "Data Acquisition for Improving Machine Learning Models",
    "abstract": "Comments: Accepted by VLDB 2021",
    "descriptor": "\nComments: Accepted by VLDB 2021\n",
    "authors": [
      "Yifan Li",
      "Xiaohui Yu",
      "Nick Koudas"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2105.14107"
  },
  {
    "id": "arXiv:2105.14189",
    "title": "Quotation Recommendation and Interpretation Based on Transformation from  Queries to Quotations",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Lingzhi Wang",
      "Xingshan Zeng",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.14189"
  },
  {
    "id": "arXiv:2105.14202",
    "title": "Adder Neural Networks",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1912.13200",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1912.13200\n",
    "authors": [
      "Hanting Chen",
      "Yunhe Wang",
      "Chang Xu",
      "Chao Xu",
      "Chunjing Xu",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14202"
  },
  {
    "id": "arXiv:2105.14218",
    "title": "A Survey of Deep Reinforcement Learning Algorithms for Motion Planning  and Control of Autonomous Vehicles",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Fei Ye",
      "Shen Zhang",
      "Pin Wang",
      "Ching-Yao Chan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14218"
  },
  {
    "id": "arXiv:2105.14274",
    "title": "Korean-English Machine Translation with Multiple Tokenization Strategy",
    "abstract": "Comments: KCC2021 Undergraduate/Junior Thesis Competition",
    "descriptor": "\nComments: KCC2021 Undergraduate/Junior Thesis Competition\n",
    "authors": [
      "Dojun Park",
      "Youngjin Jang",
      "Harksoo Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14274"
  },
  {
    "id": "arXiv:2105.14275",
    "title": "Greedy Bayesian Posterior Approximation with Deep Ensembles",
    "abstract": "Greedy Bayesian Posterior Approximation with Deep Ensembles",
    "descriptor": "",
    "authors": [
      "Aleksei Tiulpin",
      "Matthew B. Blaschko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14275"
  },
  {
    "id": "arXiv:2105.14277",
    "title": "Grammar Accuracy Evaluation (GAE): Quantifiable Intrinsic Evaluation of  Machine Translation Models",
    "abstract": "Comments: Journal of KIISE",
    "descriptor": "\nComments: Journal of KIISE\n",
    "authors": [
      "Dojun Park",
      "Youngjin Jang",
      "Harksoo Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14277"
  },
  {
    "id": "arXiv:2105.14314",
    "title": "Automatic CT Segmentation from Bounding Box Annotations using  Convolutional Neural Networks",
    "abstract": "Automatic CT Segmentation from Bounding Box Annotations using  Convolutional Neural Networks",
    "descriptor": "",
    "authors": [
      "Yuanpeng Liu",
      "Qinglei Hui",
      "Zhiyi Peng",
      "Shaolin Gong",
      "Dexing Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14314"
  },
  {
    "id": "arXiv:2105.14397",
    "title": "The Sample Fr\u00e9chet Mean of Sparse Graphs is Sparse",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Daniel Ferguson",
      "Francois G. Meyer"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14397"
  },
  {
    "id": "arXiv:2105.14421",
    "title": "VersatileGait: A Large-Scale Synthetic Gait Dataset Towards in-the-Wild  Simulation",
    "abstract": "Comments: We should have updated 2101.01394 but we did a new submission",
    "descriptor": "\nComments: We should have updated 2101.01394 but we did a new submission\n",
    "authors": [
      "Pengyi Zhang",
      "Huanzhang Dou",
      "Wenhu Zhang",
      "Yuhan Zhao",
      "Songyuan Li",
      "Zequn Qin",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14421"
  },
  {
    "id": "arXiv:2105.14513",
    "title": "Knowledge Transfer for Few-shot Segmentation of Novel White Matter  Tracts",
    "abstract": "Comments: accepted by IPMI 2021",
    "descriptor": "\nComments: accepted by IPMI 2021\n",
    "authors": [
      "Qi Lu",
      "Chuyang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.14513"
  },
  {
    "id": "arXiv:2105.14668",
    "title": "On the Interplay Between Fine-tuning and Composition in Transformers",
    "abstract": "Comments: To appear in Findings of ACL 2021",
    "descriptor": "\nComments: To appear in Findings of ACL 2021\n",
    "authors": [
      "Lang Yu",
      "Allyson Ettinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14668"
  },
  {
    "id": "arXiv:2105.14695",
    "title": "Halt Properties and Complexity Evaluations for Optimal DeepLLL Algorithm  Families",
    "abstract": "Comments: 20 pages; (v2) Abstract slightly revised",
    "descriptor": "\nComments: 20 pages; (v2) Abstract slightly revised\n",
    "authors": [
      "Takuto Odagawa",
      "Koji Nuida"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.14695"
  },
  {
    "id": "arXiv:2105.14713",
    "title": "1$\\times$N Block Pattern for Network Sparsity",
    "abstract": "1$\\times$N Block Pattern for Network Sparsity",
    "descriptor": "",
    "authors": [
      "Mingbao Lin",
      "Yuchao Li",
      "Yuxin Zhang",
      "Bohong Chen",
      "Fei Chao",
      "Mengdi Wang",
      "Shen Li",
      "Jun Yang",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14713"
  },
  {
    "id": "arXiv:2105.14759",
    "title": "The x-index: A new citation-distance-based index to measure academic  influence",
    "abstract": "The x-index: A new citation-distance-based index to measure academic  influence",
    "descriptor": "",
    "authors": [
      "Yun Wan",
      "Feng Xiao",
      "Bintong Chen",
      "Lu Li"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.14759"
  },
  {
    "id": "arXiv:2105.14790",
    "title": "Predicting Driver Intention Using Deep Neural Network",
    "abstract": "Predicting Driver Intention Using Deep Neural Network",
    "descriptor": "",
    "authors": [
      "Mahdi Bonyani",
      "Mina Rahmanian",
      "Simindokht Jahangard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14790"
  },
  {
    "id": "arXiv:2105.14813",
    "title": "Exploration and Exploitation: Two Ways to Improve Chinese Spelling  Correction Models",
    "abstract": "Comments: Accepted by ACL 2021",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Chong Li",
      "Cenyuan Zhang",
      "Xiaoqing Zheng",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14813"
  },
  {
    "id": "arXiv:2105.14866",
    "title": "Variational Autoencoders: A Harmonic Perspective",
    "abstract": "Comments: 18 pages including Appendix, 7 Figures",
    "descriptor": "\nComments: 18 pages including Appendix, 7 Figures\n",
    "authors": [
      "Alexander Camuto",
      "Matthew Willetts"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14866"
  },
  {
    "id": "arXiv:2105.14867",
    "title": "Accurate and Efficient Time Series Matching by Season- and Trend-aware  Symbolic Approximation -- Extended Version Including Additional Evaluation  and Proofs",
    "abstract": "Accurate and Efficient Time Series Matching by Season- and Trend-aware  Symbolic Approximation -- Extended Version Including Additional Evaluation  and Proofs",
    "descriptor": "",
    "authors": [
      "Lars Kegel",
      "Claudio Hartmann",
      "Maik Thiele",
      "Wolfgang Lehner"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2105.14867"
  },
  {
    "id": "arXiv:2105.14879",
    "title": "SemEval-2021 Task 4: Reading Comprehension of Abstract Meaning",
    "abstract": "SemEval-2021 Task 4: Reading Comprehension of Abstract Meaning",
    "descriptor": "",
    "authors": [
      "Boyuan Zheng",
      "Xiaoyu Yang",
      "Yu-Ping Ruan",
      "Zhenhua Ling",
      "Quan Liu",
      "Si Wei",
      "Xiaodan Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14879"
  },
  {
    "id": "arXiv:2105.14993",
    "title": "Urban Traffic Surveillance (UTS): A fully probabilistic 3D tracking  approach based on 2D detections",
    "abstract": "Comments: Accepted at the 2021 IEEE Intelligent Vehicles Symposium (IV), Nagoya, Japan, July 11-17, 2021",
    "descriptor": "\nComments: Accepted at the 2021 IEEE Intelligent Vehicles Symposium (IV), Nagoya, Japan, July 11-17, 2021\n",
    "authors": [
      "Henry Bradler",
      "Adrian Kretz",
      "Rudolf Mester"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14993"
  },
  {
    "id": "arXiv:2105.15022",
    "title": "Reinforcement Learning-based Dynamic Service Placement in Vehicular  Networks",
    "abstract": "Comments: Accepted and presented in IEEE 93rd Vehicular Technology Conference VTC2021-Spring",
    "descriptor": "\nComments: Accepted and presented in IEEE 93rd Vehicular Technology Conference VTC2021-Spring\n",
    "authors": [
      "Anum Talpur",
      "Mohan Gurusamy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15022"
  },
  {
    "id": "arXiv:2105.15039",
    "title": "Sequenceable Event Recorders",
    "abstract": "Sequenceable Event Recorders",
    "descriptor": "",
    "authors": [
      "Luca Cardelli"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2105.15039"
  },
  {
    "id": "arXiv:2105.15082",
    "title": "Exploring Sparse Expert Models and Beyond",
    "abstract": "Comments: 11 pages, 6 figures",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "An Yang",
      "Junyang Lin",
      "Rui Men",
      "Chang Zhou",
      "Le Jiang",
      "Xianyan Jia",
      "Ang Wang",
      "Jie Zhang",
      "Jiamang Wang",
      "Yong Li",
      "Di Zhang",
      "Wei Lin",
      "Lin Qu",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15082"
  },
  {
    "id": "arXiv:2105.15106",
    "title": "A Survey of Knowledge Tracing",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Qi Liu",
      "Shuanghong Shen",
      "Zhenya Huang",
      "Enhong Chen",
      "Yonghe Zheng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15106"
  },
  {
    "id": "arXiv:2105.15111",
    "title": "An Epidemiological Model for contact tracing with the Dutch CoronaMelder  App",
    "abstract": "Comments: This is a first and preliminary draft. Future updates are expected",
    "descriptor": "\nComments: This is a first and preliminary draft. Future updates are expected\n",
    "authors": [
      "Peter Boncz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.15111"
  },
  {
    "id": "arXiv:2105.15136",
    "title": "Students Programming Competitions as an Educational Tool and a  Motivational Incentive to Students",
    "abstract": "Students Programming Competitions as an Educational Tool and a  Motivational Incentive to Students",
    "descriptor": "",
    "authors": [
      "Youry Khmelevsky",
      "Ken Chidlow"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15136"
  }
]
[
  {
    "id": "arXiv:2106.06555",
    "title": "Robust Knowledge Graph Completion with Stacked Convolutions and a  Student Re-Ranking Network",
    "abstract": "Knowledge Graph (KG) completion research usually focuses on densely connected\nbenchmark datasets that are not representative of real KGs. We curate two KG\ndatasets that include biomedical and encyclopedic knowledge and use an existing\ncommonsense KG dataset to explore KG completion in the more realistic setting\nwhere dense connectivity is not guaranteed. We develop a deep convolutional\nnetwork that utilizes textual entity representations and demonstrate that our\nmodel outperforms recent KG completion methods in this challenging setting. We\nfind that our model's performance improvements stem primarily from its\nrobustness to sparsity. We then distill the knowledge from the convolutional\nnetwork into a student network that re-ranks promising candidate entities. This\nre-ranking stage leads to further improvements in performance and demonstrates\nthe effectiveness of entity re-ranking for KG completion.",
    "descriptor": "\nComments: The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)\n",
    "authors": [
      "Justin Lovelace",
      "Denis Newman-Griffis",
      "Shikhar Vashishth",
      "Jill Fain Lehman",
      "Carolyn Penstein Ros\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06555"
  },
  {
    "id": "arXiv:2106.06560",
    "title": "HR-NAS: Searching Efficient High-Resolution Neural Architectures with  Lightweight Transformers",
    "abstract": "High-resolution representations (HR) are essential for dense prediction tasks\nsuch as segmentation, detection, and pose estimation. Learning HR\nrepresentations is typically ignored in previous Neural Architecture Search\n(NAS) methods that focus on image classification. This work proposes a novel\nNAS method, called HR-NAS, which is able to find efficient and accurate\nnetworks for different tasks, by effectively encoding multiscale contextual\ninformation while maintaining high-resolution representations. In HR-NAS, we\nrenovate the NAS search space as well as its searching strategy. To better\nencode multiscale image contexts in the search space of HR-NAS, we first\ncarefully design a lightweight transformer, whose computational complexity can\nbe dynamically changed with respect to different objective functions and\ncomputation budgets. To maintain high-resolution representations of the learned\nnetworks, HR-NAS adopts a multi-branch architecture that provides convolutional\nencoding of multiple feature resolutions, inspired by HRNet. Last, we proposed\nan efficient fine-grained search strategy to train HR-NAS, which effectively\nexplores the search space, and finds optimal architectures given various tasks\nand computation resources. HR-NAS is capable of achieving state-of-the-art\ntrade-offs between performance and FLOPs for three dense prediction tasks and\nan image classification task, given only small computational budgets. For\nexample, HR-NAS surpasses SqueezeNAS that is specially designed for semantic\nsegmentation while improving efficiency by 45.9%. Code is available at\nhttps://github.com/dingmyu/HR-NAS",
    "descriptor": "\nComments: Accepted by CVPR 2021 (Oral)\n",
    "authors": [
      "Mingyu Ding",
      "Xiaochen Lian",
      "Linjie Yang",
      "Peng Wang",
      "Xiaojie Jin",
      "Zhiwu Lu",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06560"
  },
  {
    "id": "arXiv:2106.06561",
    "title": "GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation  (works for videos too!)",
    "abstract": "We show how to learn a map that takes a content code, derived from a face\nimage, and a randomly chosen style code to an anime image. We derive an\nadversarial loss from our simple and effective definitions of style and\ncontent. This adversarial loss guarantees the map is diverse -- a very wide\nrange of anime can be produced from a single content code. Under plausible\nassumptions, the map is not just diverse, but also correctly represents the\nprobability of an anime, conditioned on an input face. In contrast, current\nmultimodal generation procedures cannot capture the complex styles that appear\nin anime. Extensive quantitative experiments support the idea the map is\ncorrect. Extensive qualitative results show that the method can generate a much\nmore diverse range of styles than SOTA comparisons. Finally, we show that our\nformalization of content and style allows us to perform video to video\ntranslation without ever training on videos.",
    "descriptor": "\nComments: code is here this https URL\n",
    "authors": [
      "Min Jin Chong",
      "David Forsyth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06561"
  },
  {
    "id": "arXiv:2106.06566",
    "title": "Sample-efficient Linguistic Generalizations through Program Synthesis:  Experiments with Phonology Problems",
    "abstract": "Neural models excel at extracting statistical patterns from large amounts of\ndata, but struggle to learn patterns or reason about language from only a few\nexamples. In this paper, we ask: Can we learn explicit rules that generalize\nwell from only a few examples? We explore this question using program\nsynthesis. We develop a synthesis model to learn phonology rules as programs in\na domain-specific language. We test the ability of our models to generalize\nfrom few training examples using our new dataset of problems from the\nLinguistics Olympiad, a challenging set of tasks that require strong linguistic\nreasoning ability. In addition to being highly sample-efficient, our approach\ngenerates human-readable programs, and allows control over the generalizability\nof the learnt programs.",
    "descriptor": "\nComments: SIGMORPHON 2021\n",
    "authors": [
      "Saujas Vaduguru",
      "Aalok Sathe",
      "Monojit Choudhury",
      "Dipti Misra Sharma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06566"
  },
  {
    "id": "arXiv:2106.06575",
    "title": "Auto-NBA: Efficient and Effective Search Over the Joint Space of  Networks, Bitwidths, and Accelerators",
    "abstract": "While maximizing deep neural networks' (DNNs') acceleration efficiency\nrequires a joint search/design of three different yet highly coupled aspects,\nincluding the networks, bitwidths, and accelerators, the challenges associated\nwith such a joint search have not yet been fully understood and addressed. The\nkey challenges include (1) the dilemma of whether to explode the memory\nconsumption due to the huge joint space or achieve sub-optimal designs, (2) the\ndiscrete nature of the accelerator design space that is coupled yet different\nfrom that of the networks and bitwidths, and (3) the chicken and egg problem\nassociated with network-accelerator co-search, i.e., co-search requires\noperation-wise hardware cost, which is lacking during search as the optimal\naccelerator depending on the whole network is still unknown during search. To\ntackle these daunting challenges towards optimal and fast development of DNN\naccelerators, we propose a framework dubbed Auto-NBA to enable jointly\nsearching for the Networks, Bitwidths, and Accelerators, by efficiently\nlocalizing the optimal design within the huge joint design space for each\ntarget dataset and acceleration specification. Our Auto-NBA integrates a\nheterogeneous sampling strategy to achieve unbiased search with constant memory\nconsumption, and a novel joint-search pipeline equipped with a generic\ndifferentiable accelerator search engine. Extensive experiments and ablation\nstudies validate that both Auto-NBA generated networks and accelerators\nconsistently outperform state-of-the-art designs (including\nco-search/exploration techniques, hardware-aware NAS methods, and DNN\naccelerators), in terms of search time, task accuracy, and accelerator\nefficiency. Our codes are available at: https://github.com/RICE-EIC/Auto-NBA.",
    "descriptor": "\nComments: Accepted at ICML 2021\n",
    "authors": [
      "Yonggan Fu",
      "Yongan Zhang",
      "Yang Zhang",
      "David Cox",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06575"
  },
  {
    "id": "arXiv:2106.06577",
    "title": "A3C-S: Automated Agent Accelerator Co-Search towards Efficient Deep  Reinforcement Learning",
    "abstract": "Driven by the explosive interest in applying deep reinforcement learning\n(DRL) agents to numerous real-time control and decision-making applications,\nthere has been a growing demand to deploy DRL agents to empower daily-life\nintelligent devices, while the prohibitive complexity of DRL stands at odds\nwith limited on-device resources. In this work, we propose an Automated Agent\nAccelerator Co-Search (A3C-S) framework, which to our best knowledge is the\nfirst to automatically co-search the optimally matched DRL agents and\naccelerators that maximize both test scores and hardware efficiency. Extensive\nexperiments consistently validate the superiority of our A3C-S over\nstate-of-the-art techniques.",
    "descriptor": "\nComments: Accepted at DAC 2021. arXiv admin note: text overlap with arXiv:2012.13091\n",
    "authors": [
      "Yonggan Fu",
      "Yongan Zhang",
      "Chaojian Li",
      "Zhongzhi Yu",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06577"
  },
  {
    "id": "arXiv:2106.06579",
    "title": "Federated Learning with Spiking Neural Networks",
    "abstract": "As neural networks get widespread adoption in resource-constrained embedded\ndevices, there is a growing need for low-power neural systems. Spiking Neural\nNetworks (SNNs)are emerging to be an energy-efficient alternative to the\ntraditional Artificial Neural Networks (ANNs) which are known to be\ncomputationally intensive. From an application perspective, as federated\nlearning involves multiple energy-constrained devices, there is a huge scope to\nleverage energy efficiency provided by SNNs. Despite its importance, there has\nbeen little attention on training SNNs on a large-scale distributed system like\nfederated learning. In this paper, we bring SNNs to a more realistic federated\nlearning scenario. Specifically, we propose a federated learning framework for\ndecentralized and privacy-preserving training of SNNs. To validate the proposed\nfederated learning framework, we experimentally evaluate the advantages of SNNs\non various aspects of federated learning with CIFAR10 and CIFAR100 benchmarks.\nWe observe that SNNs outperform ANNs in terms of overall accuracy by over 15%\nwhen the data is distributed across a large number of clients in the federation\nwhile providing up to5.3x energy efficiency. In addition to efficiency, we also\nanalyze the sensitivity of the proposed federated SNN framework to data\ndistribution among the clients, stragglers, and gradient noise and perform a\ncomprehensive comparison with ANNs.",
    "descriptor": "",
    "authors": [
      "Yeshwanth Venkatesha",
      "Youngeun Kim",
      "Leandros Tassiulas",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.06579"
  },
  {
    "id": "arXiv:2106.06580",
    "title": "Revealing the canalizing structure of Boolean functions: Algorithms and  applications",
    "abstract": "Boolean functions can be represented in many ways including logical forms,\ntruth tables, and polynomials. Additionally, Boolean functions have different\ncanonical representations such as minimal disjunctive normal forms. Other\ncanonical representation is based on the polynomial representation of Boolean\nfunctions where they can be written as a nested product of canalizing layers\nand a polynomial that contains the noncanalizing variables. In this paper we\nstudy the problem of identifying the canalizing layers format of Boolean\nfunctions. First, we show that the problem of finding the canalizing layers is\nNP-hard. Second, we present several algorithms for finding the canalizing\nlayers of a Boolean function, discuss their complexities, and compare their\nperformances. Third, we show applications where the computation of canalizing\nlayers can be used for finding a disjunctive normal form of a nested canalizing\nfunction. Another application deals with the reverse engineering of Boolean\nnetworks with a prescribed layering format. Finally, implementations of our\nalgorithms in Python and in the computer algebra system Macaulay2 are available\nat https://github.com/ckadelka/BooleanCanalization.",
    "descriptor": "\nComments: 13 pages, 1 figure\n",
    "authors": [
      "Elena Dimitrova",
      "Brandilyn Stigler",
      "Claus Kadelka",
      "David Murrugarra"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2106.06580"
  },
  {
    "id": "arXiv:2106.06583",
    "title": "Deception Detection and Remote Physiological Monitoring: A Dataset and  Baseline Experimental Results",
    "abstract": "We present the Deception Detection and Physiological Monitoring (DDPM)\ndataset and initial baseline results on this dataset. Our application context\nis an interview scenario in which the interviewee attempts to deceive the\ninterviewer on selected responses. The interviewee is recorded in RGB,\nnear-infrared, and long-wave infrared, along with cardiac pulse, blood\noxygenation, and audio. After collection, data were annotated for\ninterviewer/interviewee, curated, ground-truthed, and organized into train /\ntest parts for a set of canonical deception detection experiments. Baseline\nexperiments found random accuracy for micro-expressions as an indicator of\ndeception, but that saccades can give a statistically significant response. We\nalso estimated subject heart rates from face videos (remotely) with a mean\nabsolute error as low as 3.16 bpm. The database contains almost 13 hours of\nrecordings of 70 subjects, and over 8 million visible-light, near-infrared, and\nthermal video frames, along with appropriate meta, audio and pulse oximeter\ndata. To our knowledge, this is the only collection offering recordings of five\nmodalities in an interview scenario that can be used in both deception\ndetection and remote photoplethysmography research.",
    "descriptor": "\nComments: The dataset will be available for download at this https URL\n",
    "authors": [
      "Jeremy Speth",
      "Nathan Vance",
      "Adam Czajka",
      "Kevin W. Bowyer",
      "Diane Wright",
      "Patrick Flynn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06583"
  },
  {
    "id": "arXiv:2106.06585",
    "title": "On the numerical accuracy in finite-volume methods to accurately capture  turbulence in compressible flows",
    "abstract": "The goal of the present paper is to understand the impact of numerical\nschemes for the reconstruction of data at cell faces in finite-volume methods,\nand to assess their interaction with the quadrature rule used to compute the\naverage over the cell volume. Here, third-, fifth- and seventh-order WENO-Z\nschemes are investigated. On a problem with a smooth solution, the theoretical\norder of convergence rate for each method is retrieved, and changing the order\nof the reconstruction at cell faces does not impact the results, whereas for a\nshock-driven problem all the methods collapse to first-order. Study of the\ndecay of compressible homogeneous isotropic turbulence reveals that using a\nhigh-order quadrature rule to compute the average over a finite volume cell\ndoes not improve the spectral accuracy and that all methods present a\nsecond-order convergence rate. However the choice of the numerical method to\nreconstruct data at cell faces is found to be critical to correctly capture\nturbulent spectra. In the context of simulations with finite-volume methods of\npractical flows encountered in engineering applications, it becomes apparent\nthat an efficient strategy is to perform the average integration with a\nlow-order quadrature rule on a fine mesh resolution, whereas high-order schemes\nshould be used to reconstruct data at cell faces.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1902.06665\n",
    "authors": [
      "Emmanuel Motheau",
      "John Wakefield"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.06585"
  },
  {
    "id": "arXiv:2106.06586",
    "title": "Breaking the Limit of Graph Neural Networks by Improving the  Assortativity of Graphs with Local Mixing Patterns",
    "abstract": "Graph neural networks (GNNs) have achieved tremendous success on multiple\ngraph-based learning tasks by fusing network structure and node features.\nModern GNN models are built upon iterative aggregation of neighbor's/proximity\nfeatures by message passing. Its prediction performance has been shown to be\nstrongly bounded by assortative mixing in the graph, a key property wherein\nnodes with similar attributes mix/connect with each other. We observe that real\nworld networks exhibit heterogeneous or diverse mixing patterns and the\nconventional global measurement of assortativity, such as global assortativity\ncoefficient, may not be a representative statistic in quantifying this mixing.\nWe adopt a generalized concept, node-level assortativity, one that is based at\nthe node level to better represent the diverse patterns and accurately quantify\nthe learnability of GNNs. We find that the prediction performance of a wide\nrange of GNN models is highly correlated with the node level assortativity. To\nbreak this limit, in this work, we focus on transforming the input graph into a\ncomputation graph which contains both proximity and structural information as\ndistinct type of edges. The resulted multi-relational graph has an enhanced\nlevel of assortativity and, more importantly, preserves rich information from\nthe original graph. We then propose to run GNNs on this computation graph and\nshow that adaptively choosing between structure and proximity leads to improved\nperformance under diverse mixing. Empirically, we show the benefits of adopting\nour transformation framework for semi-supervised node classification task on a\nvariety of real world graph learning benchmarks.",
    "descriptor": "\nComments: published in KDD 2021; 11 pages;\n",
    "authors": [
      "Susheel Suresh",
      "Vinith Budde",
      "Jennifer Neville",
      "Pan Li",
      "Jianzhu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.06586"
  },
  {
    "id": "arXiv:2106.06588",
    "title": "Visualization Techniques to Enhance Automated Event Extraction",
    "abstract": "Robust visualization of complex data is critical for the effective use of NLP\nfor event classification, as the volume of data is large and the\nhigh-dimensional structure of text makes data challenging to summarize\nsuccinctly. In event extraction tasks in particular, visualization can aid in\nunderstanding and illustrating the textual relationships from which machine\nlearning tools produce insights. Through our case study which seeks to identify\npotential triggers of state-led mass killings from news articles using NLP, we\ndemonstrate how visualizations can aid in each stage, from exploratory analysis\nof raw data, to machine learning training analysis, and finally post-inference\nvalidation.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Sophia Henn",
      "Abigail Sticha",
      "Timothy Burley",
      "Ernesto Verdeja",
      "Paul Brenner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.06588"
  },
  {
    "id": "arXiv:2106.06592",
    "title": "Dise\u00f1o y desarrollo de aplicaci\u00f3n m\u00f3vil para la clasificaci\u00f3n de  flora nativa chilena utilizando redes neuronales convolucionales",
    "abstract": "Introduction: Mobile apps, through artificial vision, are capable of\nrecognizing vegetable species in real time. However, the existing species\nrecognition apps do not take in consideration the wide variety of endemic and\nnative (Chilean) species, which leads to wrong species predictions. This study\nintroduces the development of a chilean species dataset and an optimized\nclassification model implemented to a mobile app. Method: the data set was\nbuilt by putting together pictures of several species captured on the field and\nby selecting some pictures available from other datasets available online.\nConvolutional neural networks were used in order to develop the images\nprediction models. The networks were trained by performing a sensitivity\nanalysis, validating with k-fold cross validation and performing tests with\ndifferent hyper-parameters, optimizers, convolutional layers, and learning\nrates in order to identify and choose the best models and then put them\ntogether in one classification model. Results: The final data set was\ncompounded by 46 species, including native species, endemic and exotic from\nChile, with 6120 training pictures and 655 testing pictures. The best models\nwere implemented on a mobile app, obtaining a 95% correct prediction rate with\nrespect to the set of tests. Conclusion: The app developed in this study is\ncapable of classifying species with a high level of accuracy, depending on the\nstate of the art of the artificial vision and it can also show relevant\ninformation related to the classified species.",
    "descriptor": "\nComments: in Spanish\n",
    "authors": [
      "Ignacio Mu\u00f1oz",
      "Alfredo Bolt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06592"
  },
  {
    "id": "arXiv:2106.06593",
    "title": "Toward Accurate and Realistic Outfits Visualization with Attention to  Details",
    "abstract": "Virtual try-on methods aim to generate images of fashion models wearing\narbitrary combinations of garments. This is a challenging task because the\ngenerated image must appear realistic and accurately display the interaction\nbetween garments. Prior works produce images that are filled with artifacts and\nfail to capture important visual details necessary for commercial applications.\nWe propose Outfit Visualization Net (OVNet) to capture these important details\n(e.g. buttons, shading, textures, realistic hemlines, and interactions between\ngarments) and produce high quality multiple-garment virtual try-on images.\nOVNet consists of 1) a semantic layout generator and 2) an image generation\npipeline using multiple coordinated warps. We train the warper to output\nmultiple warps using a cascade loss, which refines each successive warp to\nfocus on poorly generated regions of a previous warp and yields consistent\nimprovements in detail. In addition, we introduce a method for matching outfits\nwith the most suitable model and produce significant improvements for both our\nand other previous try-on methods. Through quantitative and qualitative\nanalysis, we demonstrate our method generates substantially higher-quality\nstudio images compared to prior works for multi-garment outfits. An interactive\ninterface powered by this method has been deployed on fashion e-commerce\nwebsites and received overwhelmingly positive feedback.",
    "descriptor": "\nComments: Accepted to CVPR2021. Live demo here this https URL\n",
    "authors": [
      "Kedan Li",
      "Min jin Chong",
      "Jeffrey Zhang",
      "Jingen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06593"
  },
  {
    "id": "arXiv:2106.06595",
    "title": "Bucket-brigade inspired power line network protocol for sensed quantity  profile acquisition with smart sensors deployed as a queue in harsh  environment",
    "abstract": "Pressure and temperature profile are key data for safe production in oil and\ngas wells. In this paper, a bucket-brigade inspired sensor network protocol is\nproposed which can be used to extract sensed data profile from the nanoscale up\nto kilometer long structures. The PHY/MAC layers are discussed. This protocol\nis best suited for low data rate exchanges in small fixed-size packets, named\nbuckets, transmitted as time-domain bursts among high-precision smart sensors\ndeployed as a queue. There is only one coordinator, which is not directly\naccessible by most of the sensor nodes. The coordinator is responsible for\ncollecting the measurement profile and send it to a supervisory node. There is\nno need for complex routing mechanism, as the network topology is determined\nduring deployment. There are many applications which require sensors to be\ndeployed as a long queue and sensed data could be transmitted at low data\nrates. Examples of such monitoring applications are: neural connected\nartificial skin, oil/gas/water pipeline integrity, power transmission line\ntower integrity, (rail)road/highway lighting and integrity, individualized\nmonitoring in vineyard or re-foresting or plantation, underwater\ntelecommunications cable integrity, oil/gas riser integrity, oil/gas well\ntemperature and pressure profile, among others. For robustness and reduced\nelectromagnetic interference, wired network is preferred. Besides in some harsh\nenvironment wireless is not feasible. To reduce wiring, communications can be\ncarried out in the same cable used to supply electrical power.",
    "descriptor": "\nComments: 19 pages, 13 Figures\n",
    "authors": [
      "Edval J. P. Santos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.06595"
  },
  {
    "id": "arXiv:2106.06596",
    "title": "Disentangling the Roles of Curation, Data-Augmentation and the Prior in  the Cold Posterior Effect",
    "abstract": "The \"cold posterior effect\" (CPE) in Bayesian deep learning describes the\nuncomforting observation that the predictive performance of Bayesian neural\nnetworks can be significantly improved if the Bayes posterior is artificially\nsharpened using a temperature parameter T<1. The CPE is problematic in theory\nand practice and since the effect was identified many researchers have proposed\nhypotheses to explain the phenomenon. However, despite this intensive research\neffort the effect remains poorly understood. In this work we provide novel and\nnuanced evidence relevant to existing explanations for the cold posterior\neffect, disentangling three hypotheses: 1. The dataset curation hypothesis of\nAitchison (2020): we show empirically that the CPE does not arise in a real\ncurated data set but can be produced in a controlled experiment with varying\ncuration strength. 2. The data augmentation hypothesis of Izmailov et al.\n(2021) and Fortuin et al. (2021): we show empirically that data augmentation is\nsufficient but not necessary for the CPE to be present. 3. The bad prior\nhypothesis of Wenzel et al. (2020): we use a simple experiment evaluating the\nrelative importance of the prior and the likelihood, strongly linking the CPE\nto the prior. Our results demonstrate how the CPE can arise in isolation from\nsynthetic curation, data augmentation, and bad priors. Cold posteriors observed\n\"in the wild\" are therefore unlikely to arise from a single simple cause; as a\nresult, we do not expect a simple \"fix\" for cold posteriors.",
    "descriptor": "",
    "authors": [
      "Lorenzo Noci",
      "Kevin Roth",
      "Gregor Bachmann",
      "Sebastian Nowozin",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06596"
  },
  {
    "id": "arXiv:2106.06598",
    "title": "Leveraging Pre-trained Language Model for Speech Sentiment Analysis",
    "abstract": "In this paper, we explore the use of pre-trained language models to learn\nsentiment information of written texts for speech sentiment analysis. First, we\ninvestigate how useful a pre-trained language model would be in a 2-step\npipeline approach employing Automatic Speech Recognition (ASR) and\ntranscripts-based sentiment analysis separately. Second, we propose a pseudo\nlabel-based semi-supervised training strategy using a language model on an\nend-to-end speech sentiment approach to take advantage of a large, but\nunlabeled speech dataset for training. Although spoken and written texts have\ndifferent linguistic characteristics, they can complement each other in\nunderstanding sentiment. Therefore, the proposed system can not only model\nacoustic characteristics to bear sentiment-specific information in speech\nsignals, but learn latent information to carry sentiments in the text\nrepresentation. In these experiments, we demonstrate the proposed approaches\nimprove F1 scores consistently compared to systems without a language model.\nMoreover, we also show that the proposed framework can reduce 65% of human\nsupervision by leveraging a large amount of data without human sentiment\nannotation and boost performance in a low-resource condition where the human\nsentiment annotation is not available enough.",
    "descriptor": "\nComments: To appear in Interspeech 2021\n",
    "authors": [
      "Suwon Shon",
      "Pablo Brusco",
      "Jing Pan",
      "Kyu J. Han",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.06598"
  },
  {
    "id": "arXiv:2106.06600",
    "title": "Break-It-Fix-It: Unsupervised Learning for Program Repair",
    "abstract": "We consider repair tasks: given a critic (e.g., compiler) that assesses the\nquality of an input, the goal is to train a fixer that converts a bad example\n(e.g., code with syntax errors) into a good one (e.g., code with no errors).\nExisting works create training data consisting of (bad, good) pairs by\ncorrupting good examples using heuristics (e.g., dropping tokens). However,\nfixers trained on this synthetically-generated data do not extrapolate well to\nthe real distribution of bad inputs. To bridge this gap, we propose a new\ntraining approach, Break-It-Fix-It (BIFI), which has two key ideas: (i) we use\nthe critic to check a fixer's output on real bad inputs and add good (fixed)\noutputs to the training data, and (ii) we train a breaker to generate realistic\nbad code from good code. Based on these ideas, we iteratively update the\nbreaker and the fixer while using them in conjunction to generate more paired\ndata. We evaluate BIFI on two code repair datasets: GitHub-Python, a new\ndataset we introduce where the goal is to repair Python code with AST parse\nerrors; and DeepFix, where the goal is to repair C code with compiler errors.\nBIFI outperforms existing methods, obtaining 90.5% repair accuracy on\nGitHub-Python (+28.5%) and 71.7% on DeepFix (+5.6%). Notably, BIFI does not\nrequire any labeled data; we hope it will be a strong starting point for\nunsupervised learning of various repair tasks.",
    "descriptor": "\nComments: ICML 2021. Code & data available at this https URL\n",
    "authors": [
      "Michihiro Yasunaga",
      "Percy Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.06600"
  },
  {
    "id": "arXiv:2106.06601",
    "title": "COSTA: Communication-Optimal Shuffle and Transpose Algorithm with  Process Relabeling",
    "abstract": "Communication-avoiding algorithms for Linear Algebra have become increasingly\npopular, in particular for distributed memory architectures. In practice, these\nalgorithms assume that the data is already distributed in a specific way, thus\nmaking data reshuffling a key to use them. For performance reasons, a\nstraightforward all-to-all exchange must be avoided.\nHere, we show that process relabeling (i.e. permuting processes in the final\nlayout) can be used to obtain communication optimality for data reshuffling,\nand that it can be efficiently found by solving a Linear Assignment Problem\n(Maximum Weight Bipartite Perfect Matching). Based on this, we have developed a\nCommunication-Optimal Shuffle and Transpose Algorithm (COSTA): this\nhighly-optimised algorithm implements $A=\\alpha\\cdot \\operatorname{op}(B) +\n\\beta \\cdot A,\\ \\operatorname{op} \\in \\{\\operatorname{transpose},\n\\operatorname{conjugate-transpose}, \\operatorname{identity}\\}$ on distributed\nsystems, where $A, B$ are matrices with potentially different (distributed)\nlayouts and $\\alpha, \\beta$ are scalars. COSTA can take advantage of the\ncommunication-optimal process relabeling even for heterogeneous network\ntopologies, where latency and bandwidth differ among nodes. The implementation\nnot only outperforms the best available ScaLAPACK redistribute and transpose\nroutines multiple times, but is also able to deal with more general matrix\nlayouts, in particular it is not limited to block-cyclic layouts. Finally, we\nuse COSTA to integrate a communication-optimal matrix multiplication algorithm\ninto the CP2K quantum chemistry simulation package. This way, we show that\nCOSTA can be used to unlock the full potential of recent Linear Algebra\nalgorithms in applications by facilitating interoperability between algorithms\nwith a wide range of data layouts, in addition to bringing significant\nredistribution speedups.",
    "descriptor": "\nComments: To be published in the proceedings of the 36th International Conference on High Performance Computing, ISC High Performance 2021. The implementation of the algorithm is available at: this https URL\n",
    "authors": [
      "Marko Kabi\u0107",
      "Simon Pintarelli",
      "Anton Kozhevnikov",
      "Joost VandeVondele"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.06601"
  },
  {
    "id": "arXiv:2106.06603",
    "title": "A Shuffling Framework for Local Differential Privacy",
    "abstract": "ldp deployments are vulnerable to inference attacks as an adversary can link\nthe noisy responses to their identity and subsequently, auxiliary information\nusing the order of the data. An alternative model, shuffle DP, prevents this by\nshuffling the noisy responses uniformly at random. However, this limits the\ndata learnability -- only symmetric functions (input order agnostic) can be\nlearned. In this paper, we strike a balance and propose a generalized shuffling\nframework that interpolates between the two deployment models. We show that\nsystematic shuffling of the noisy responses can thwart specific inference\nattacks while retaining some meaningful data learnability. To this end, we\npropose a novel privacy guarantee, d-sigma privacy, that captures the privacy\nof the order of a data sequence. d-sigma privacy allows tuning the granularity\nat which the ordinal information is maintained, which formalizes the degree the\nresistance to inference attacks trading it off with data learnability.\nAdditionally, we propose a novel shuffling mechanism that can achieve d-sigma\nprivacy and demonstrate the practicality of our mechanism via evaluation on\nreal-world datasets.",
    "descriptor": "",
    "authors": [
      "Casey Meehan",
      "Amrita Roy Chowdhury",
      "Kamalika Chaudhuri",
      "Somesh Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06603"
  },
  {
    "id": "arXiv:2106.06604",
    "title": "Verified Synthesis of Optimal Safety Controllers for Human-Robot  Collaboration",
    "abstract": "We present a tool-supported approach for the synthesis, verification and\nvalidation of the control software responsible for the safety of the\nhuman-robot interaction in manufacturing processes that use collaborative\nrobots. In human-robot collaboration, software-based safety controllers are\nused to improve operational safety, e.g., by triggering shutdown mechanisms or\nemergency stops to avoid accidents. Complex robotic tasks and increasingly\nclose human-robot interaction pose new challenges to controller developers and\ncertification authorities. Key among these challenges is the need to assure the\ncorrectness of safety controllers under explicit (and preferably weak)\nassumptions. Our controller synthesis, verification and validation approach is\ninformed by the process, risk analysis, and relevant safety regulations for the\ntarget application. Controllers are selected from a design space of feasible\ncontrollers according to a set of optimality criteria, are formally verified\nagainst correctness criteria, and are translated into executable code and\nvalidated in a digital twin. The resulting controller can detect the occurrence\nof hazards, move the process into a safe state, and, in certain circumstances,\nreturn the process to an operational state from which it can resume its\noriginal task. We show the effectiveness of our software engineering approach\nthrough a case study involving the development of a safety controller for a\nmanufacturing work cell equipped with a collaborative robot.",
    "descriptor": "\nComments: 34 pages, 31 figures\n",
    "authors": [
      "Mario Gleirscher",
      "Radu Calinescu",
      "James Douthwaite",
      "Benjamin Lesage",
      "Colin Paterson",
      "Jonathan Aitken",
      "Rob Alexander",
      "James Law"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06604"
  },
  {
    "id": "arXiv:2106.06605",
    "title": "Modeling Language Usage and Listener Engagement in Podcasts",
    "abstract": "While there is an abundance of popular writing targeted to podcast creators\non how to speak in ways that engage their listeners, there has been little\ndata-driven analysis of podcasts that relates linguistic style with listener\nengagement. In this paper, we investigate how various factors -- vocabulary\ndiversity, distinctiveness, emotion, and syntax, among others -- correlate with\nengagement, based on analysis of the creators' written descriptions and\ntranscripts of the audio. We build models with different textual\nrepresentations, and show that the identified features are highly predictive of\nengagement. Our analysis tests popular wisdom about stylistic elements in\nhigh-engagement podcasts, corroborating some aspects, and adding new\nperspectives on others.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Sravana Reddy",
      "Marina Lazarova",
      "Yongze Yu",
      "Rosie Jones"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06605"
  },
  {
    "id": "arXiv:2106.06607",
    "title": "Invariance Principle Meets Information Bottleneck for  Out-of-Distribution Generalization",
    "abstract": "The invariance principle from causality is at the heart of notable approaches\nsuch as invariant risk minimization (IRM) that seek to address\nout-of-distribution (OOD) generalization failures. Despite the promising\ntheory, invariance principle-based approaches fail in common classification\ntasks, where invariant (causal) features capture all the information about the\nlabel. Are these failures due to the methods failing to capture the invariance?\nOr is the invariance principle itself insufficient? To answer these questions,\nwe revisit the fundamental assumptions in linear regression tasks, where\ninvariance-based approaches were shown to provably generalize OOD. In contrast\nto the linear regression tasks, we show that for linear classification tasks we\nneed much stronger restrictions on the distribution shifts, or otherwise OOD\ngeneralization is impossible. Furthermore, even with appropriate restrictions\non distribution shifts in place, we show that the invariance principle alone is\ninsufficient. We prove that a form of the information bottleneck constraint\nalong with invariance helps address key failures when invariant features\ncapture all the information about the label and also retains the existing\nsuccess when they do not. We propose an approach that incorporates both of\nthese principles and demonstrate its effectiveness in several experiments.",
    "descriptor": "",
    "authors": [
      "Kartik Ahuja",
      "Ethan Caballero",
      "Dinghuai Zhang",
      "Yoshua Bengio",
      "Ioannis Mitliagkas",
      "Irina Rish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06607"
  },
  {
    "id": "arXiv:2106.06610",
    "title": "Scalars are universal: Gauge-equivariant machine learning, structured  like classical physics",
    "abstract": "There has been enormous progress in the last few years in designing\nconceivable (though not always practical) neural networks that respect the\ngauge symmetries -- or coordinate freedom -- of physical law. Some of these\nframeworks make use of irreducible representations, some make use of higher\norder tensor objects, and some apply symmetry-enforcing constraints. Different\nphysical laws obey different combinations of fundamental symmetries, but a\nlarge fraction (possibly all) of classical physics is equivariant to\ntranslation, rotation, reflection (parity), boost (relativity), and\npermutations. Here we show that it is simple to parameterize universally\napproximating polynomial functions that are equivariant under these symmetries,\nor under the Euclidean, Lorentz, and Poincar\\'e groups, at any dimensionality\n$d$. The key observation is that nonlinear O($d$)-equivariant (and\nrelated-group-equivariant) functions can be expressed in terms of a lightweight\ncollection of scalars -- scalar products and scalar contractions of the scalar,\nvector, and tensor inputs. These results demonstrate theoretically that\ngauge-invariant deep learning models for classical physics with good scaling\nfor large problems are feasible right now.",
    "descriptor": "",
    "authors": [
      "Soledad Villar",
      "David W.Hogg",
      "Kate Storey-Fisher",
      "Weichi Yao",
      "Ben Blum-Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06610"
  },
  {
    "id": "arXiv:2106.06613",
    "title": "A New Formalism, Method and Open Issues for Zero-Shot Coordination",
    "abstract": "In many coordination problems, independently reasoning humans are able to\ndiscover mutually compatible policies. In contrast, independently trained\nself-play policies are often mutually incompatible. Zero-shot coordination\n(ZSC) has recently been proposed as a new frontier in multi-agent reinforcement\nlearning to address this fundamental issue. Prior work approaches the ZSC\nproblem by assuming players can agree on a shared learning algorithm but not on\nlabels for actions and observations, and proposes other-play as an optimal\nsolution. However, until now, this \"label-free\" problem has only been\ninformally defined. We formalize this setting as the label-free coordination\n(LFC) problem by defining the label-free coordination game. We show that\nother-play is not an optimal solution to the LFC problem as it fails to\nconsistently break ties between incompatible maximizers of the other-play\nobjective. We introduce an extension of the algorithm, other-play with\ntie-breaking, and prove that it is optimal in the LFC problem and an\nequilibrium in the LFC game. Since arbitrary tie-breaking is precisely what the\nZSC setting aims to prevent, we conclude that the LFC problem does not reflect\nthe aims of ZSC. To address this, we introduce an alternative informal\noperationalization of ZSC as a starting point for future work.",
    "descriptor": "",
    "authors": [
      "Johannes Treutlein",
      "Michael Dennis",
      "Caspar Oesterheld",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06613"
  },
  {
    "id": "arXiv:2106.06614",
    "title": "Nawrotzki's Algorithm for the Countable Splitting Lemma, Constructively",
    "abstract": "We reprove the countable splitting lemma by adapting Nawrotzki's algorithm\nwhich produces a sequence that converges to a solution. Our algorithm combines\nNawrotzki's approach with taking finite cuts. It is constructive in the sense\nthat each term of the iteratively built approximating sequence as well as the\nerror between the approximants and the solution is computable with finitely\nmany algebraic operations.",
    "descriptor": "",
    "authors": [
      "Ana Sokolova",
      "Harald Woracek"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.06614"
  },
  {
    "id": "arXiv:2106.06615",
    "title": "Precise characterization of the prior predictive distribution of deep  ReLU networks",
    "abstract": "Recent works on Bayesian neural networks (BNNs) have highlighted the need to\nbetter understand the implications of using Gaussian priors in combination with\nthe compositional structure of the network architecture. Similar in spirit to\nthe kind of analysis that has been developed to devise better initialization\nschemes for neural networks (cf. He- or Xavier initialization), we derive a\nprecise characterization of the prior predictive distribution of finite-width\nReLU networks with Gaussian weights. While theoretical results have been\nobtained for their heavy-tailedness, the full characterization of the prior\npredictive distribution (i.e. its density, CDF and moments), remained unknown\nprior to this work. Our analysis, based on the Meijer-G function, allows us to\nquantify the influence of architectural choices such as the width or depth of\nthe network on the resulting shape of the prior predictive distribution. We\nalso formally connect our results to previous work in the infinite width\nsetting, demonstrating that the moments of the distribution converge to those\nof a normal log-normal mixture in the infinite depth limit. Finally, our\nresults provide valuable guidance on prior design: for instance, controlling\nthe predictive variance with depth- and width-informed priors on the weights of\nthe network.",
    "descriptor": "",
    "authors": [
      "Lorenzo Noci",
      "Gregor Bachmann",
      "Kevin Roth",
      "Sebastian Nowozin",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06615"
  },
  {
    "id": "arXiv:2106.06616",
    "title": "Online Learning of Competitive Equilibria in Exchange Economies",
    "abstract": "The sharing of scarce resources among multiple rational agents is one of the\nclassical problems in economics. In exchange economies, which are used to model\nsuch situations, agents begin with an initial endowment of resources and\nexchange them in a way that is mutually beneficial until they reach a\ncompetitive equilibrium (CE). CE allocations are Pareto efficient and fair.\nConsequently, they are used widely in designing mechanisms for fair division.\nHowever, computing CEs requires the knowledge of agent preferences which are\nunknown in several applications of interest. In this work, we explore a new\nonline learning mechanism, which, on each round, allocates resources to the\nagents and collects stochastic feedback on their experience in using that\nallocation. Its goal is to learn the agent utilities via this feedback and\nimitate the allocations at a CE in the long run. We quantify CE behavior via\ntwo losses and propose a randomized algorithm which achieves\n$\\bigOtilde(\\sqrt{T})$ loss after $T$ rounds under both criteria. Empirically,\nwe demonstrate the effectiveness of this mechanism through numerical\nsimulations.",
    "descriptor": "\nComments: 31 pages, 6 figures\n",
    "authors": [
      "Wenshuo Guo",
      "Kirthevasan Kandasamy",
      "Joseph E Gonzalez",
      "Michael I. Jordan",
      "Ion Stoica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06616"
  },
  {
    "id": "arXiv:2106.06617",
    "title": "Inexact Loops in Robotics Problems",
    "abstract": "Loops are pervasive in robotics problems, appearing in mapping and\nlocalization, where one is interested in finding loop closure constraints to\nbetter approximate robot poses or other estimated quantities, as well as\nplanning and prediction, where one is interested in the homotopy classes of the\nspace through which a robot is moving. We generalize the standard topological\ndefinition of a loop to cases where a trajectory passes close to itself, but\ndoesn't necessarily touch, giving a definition that is more practical for real\nrobotics problems. This relaxation leads to new and useful properties of\ninexact loops, such as their ability to be partitioned into topologically\nconnected sets closely matching the concept of a \"loop closure\", and the\nexistence of simple and nonsimple loops. Building from these ideas, we\nintroduce several ways to measure properties and quantities of inexact loops on\na trajectory, such as the trajectory's \"loop area\" and \"loop density\", and use\nthem to compare strategies for sampling representative inexact loops to build\nconstraints in mapping and localization problems.",
    "descriptor": "\nComments: Robotics: Science and Systems (RSS) 2021\n",
    "authors": [
      "Erik Nelson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.06617"
  },
  {
    "id": "arXiv:2106.06620",
    "title": "Robust Representation Learning via Perceptual Similarity Metrics",
    "abstract": "A fundamental challenge in artificial intelligence is learning useful\nrepresentations of data that yield good performance on a downstream task,\nwithout overfitting to spurious input features. Extracting such task-relevant\npredictive information is particularly difficult for real-world datasets. In\nthis work, we propose Contrastive Input Morphing (CIM), a representation\nlearning framework that learns input-space transformations of the data to\nmitigate the effect of irrelevant input features on downstream performance. Our\nmethod leverages a perceptual similarity metric via a triplet loss to ensure\nthat the transformation preserves task-relevant information.Empirically, we\ndemonstrate the efficacy of our approach on tasks which typically suffer from\nthe presence of spurious correlations: classification with nuisance\ninformation, out-of-distribution generalization, and preservation of subgroup\naccuracies. We additionally show that CIM is complementary to other mutual\ninformation-based representation learning techniques, and demonstrate that it\nimproves the performance of variational information bottleneck (VIB) when used\ntogether.",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Saeid Asgari Taghanaki",
      "Kristy Choi",
      "Amir Khasahmadi",
      "Anirudh Goyal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06620"
  },
  {
    "id": "arXiv:2106.06621",
    "title": "Piecewise-constant Neural ODEs",
    "abstract": "Neural networks are a popular tool for modeling sequential data but they\ngenerally do not treat time as a continuous variable. Neural ODEs represent an\nimportant exception: they parameterize the time derivative of a hidden state\nwith a neural network and then integrate over arbitrary amounts of time. But\nthese parameterizations, which have arbitrary curvature, can be hard to\nintegrate and thus train and evaluate. In this paper, we propose making a\npiecewise-constant approximation to Neural ODEs to mitigate these issues. Our\nmodel can be integrated exactly via Euler integration and can generate\nautoregressive samples in 3-20 times fewer steps than comparable RNN and\nODE-RNN models. We evaluate our model on several synthetic physics tasks and a\nplanning task inspired by the game of billiards. We find that it matches the\nperformance of baseline approaches while requiring less time to train and\nevaluate.",
    "descriptor": "\nComments: 8 pages, 5 figures (not counting appendix)\n",
    "authors": [
      "Sam Greydanus",
      "Stefan Lee",
      "Alan Fern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06621"
  },
  {
    "id": "arXiv:2106.06623",
    "title": "Pay Attention with Focus: A Novel Learning Scheme for Classification of  Whole Slide Images",
    "abstract": "Deep learning methods such as convolutional neural networks (CNNs) are\ndifficult to directly utilize to analyze whole slide images (WSIs) due to the\nlarge image dimensions. We overcome this limitation by proposing a novel\ntwo-stage approach. First, we extract a set of representative patches (called\nmosaic) from a WSI. Each patch of a mosaic is encoded to a feature vector using\na deep network. The feature extractor model is fine-tuned using hierarchical\ntarget labels of WSIs, i.e., anatomic site and primary diagnosis. In the second\nstage, a set of encoded patch-level features from a WSI is used to compute the\nprimary diagnosis probability through the proposed Pay Attention with Focus\nscheme, an attention-weighted averaging of predicted probabilities for all\npatches of a mosaic modulated by a trainable focal factor. Experimental results\nshow that the proposed model can be robust, and effective for the\nclassification of WSIs.",
    "descriptor": "\nComments: Accepted in MICCAI, 2021\n",
    "authors": [
      "Shivam Kalra",
      "Mohammed Adnan",
      "Sobhan Hemati",
      "Taher Dehkharghanian",
      "Shahryar Rahnamayan",
      "Hamid Tizhoosh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06623"
  },
  {
    "id": "arXiv:2106.06624",
    "title": "Relaxing Local Robustness",
    "abstract": "Certifiable local robustness, which rigorously precludes small-norm\nadversarial examples, has received significant attention as a means of\naddressing security concerns in deep learning. However, for some classification\nproblems, local robustness is not a natural objective, even in the presence of\nadversaries; for example, if an image contains two classes of subjects, the\ncorrect label for the image may be considered arbitrary between the two, and\nthus enforcing strict separation between them is unnecessary. In this work, we\nintroduce two relaxed safety properties for classifiers that address this\nobservation: (1) relaxed top-k robustness, which serves as the analogue of\ntop-k accuracy; and (2) affinity robustness, which specifies which sets of\nlabels must be separated by a robustness margin, and which can be\n$\\epsilon$-close in $\\ell_p$ space. We show how to construct models that can be\nefficiently certified against each relaxed robustness property, and trained\nwith very little overhead relative to standard gradient descent. Finally, we\ndemonstrate experimentally that these relaxed variants of robustness are\nwell-suited to several significant classification problems, leading to lower\nrejection rates and higher certified accuracies than can be obtained when\ncertifying \"standard\" local robustness.",
    "descriptor": "",
    "authors": [
      "Klas Leino",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06624"
  },
  {
    "id": "arXiv:2106.06627",
    "title": "Efficient and Less Centralized Federated Learning",
    "abstract": "With the rapid growth in mobile computing, massive amounts of data and\ncomputing resources are now located at the edge. To this end, Federated\nlearning (FL) is becoming a widely adopted distributed machine learning (ML)\nparadigm, which aims to harness this expanding skewed data locally in order to\ndevelop rich and informative models. In centralized FL, a collection of devices\ncollaboratively solve a ML task under the coordination of a central server.\nHowever, existing FL frameworks make an over-simplistic assumption about\nnetwork connectivity and ignore the communication bandwidth of the different\nlinks in the network. In this paper, we present and study a novel FL algorithm,\nin which devices mostly collaborate with other devices in a pairwise manner.\nOur nonparametric approach is able to exploit network topology to reduce\ncommunication bottlenecks. We evaluate our approach on various FL benchmarks\nand demonstrate that our method achieves 10X better communication efficiency\nand around 8% increase in accuracy compared to the centralized approach.",
    "descriptor": "",
    "authors": [
      "Li Chou",
      "Zichang Liu",
      "Zhuang Wang",
      "Anshumali Shrivastava"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.06627"
  },
  {
    "id": "arXiv:2106.06629",
    "title": "Mirror3D: Depth Refinement for Mirror Surfaces",
    "abstract": "Despite recent progress in depth sensing and 3D reconstruction, mirror\nsurfaces are a significant source of errors. To address this problem, we create\nthe Mirror3D dataset: a 3D mirror plane dataset based on three RGBD datasets\n(Matterport3D, NYUv2 and ScanNet) containing 7,011 mirror instance masks and 3D\nplanes. We then develop Mirror3DNet: a module that refines raw sensor depth or\nestimated depth to correct errors on mirror surfaces. Our key idea is to\nestimate the 3D mirror plane based on RGB input and surrounding depth context,\nand use this estimate to directly regress mirror surface depth. Our experiments\nshow that Mirror3DNet significantly mitigates errors from a variety of input\ndepth data, including raw sensor depth and depth estimation or completion\nmethods.",
    "descriptor": "\nComments: Paper presented at CVPR 2021. For code, data and pretrained models, see this https URL\n",
    "authors": [
      "Jiaqi Tan",
      "Weijie Lin",
      "Angel X. Chang",
      "Manolis Savva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06629"
  },
  {
    "id": "arXiv:2106.06630",
    "title": "Corruption-Robust Offline Reinforcement Learning",
    "abstract": "We study the adversarial robustness in offline reinforcement learning. Given\na batch dataset consisting of tuples $(s, a, r, s')$, an adversary is allowed\nto arbitrarily modify $\\epsilon$ fraction of the tuples. From the corrupted\ndataset the learner aims to robustly identify a near-optimal policy. We first\nshow that a worst-case $\\Omega(d\\epsilon)$ optimality gap is unavoidable in\nlinear MDP of dimension $d$, even if the adversary only corrupts the reward\nelement in a tuple. This contrasts with dimension-free results in robust\nsupervised learning and best-known lower-bound in the online RL setting with\ncorruption. Next, we propose robust variants of the Least-Square Value\nIteration (LSVI) algorithm utilizing robust supervised learning oracles, which\nachieve near-matching performances in cases both with and without full data\ncoverage. The algorithm requires the knowledge of $\\epsilon$ to design the\npessimism bonus in the no-coverage case. Surprisingly, in this case, the\nknowledge of $\\epsilon$ is necessary, as we show that being adaptive to unknown\n$\\epsilon$ is impossible.This again contrasts with recent results on\ncorruption-robust online RL and implies that robust offline RL is a strictly\nharder problem.",
    "descriptor": "",
    "authors": [
      "Xuezhou Zhang",
      "Yiding Chen",
      "Jerry Zhu",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06630"
  },
  {
    "id": "arXiv:2106.06631",
    "title": "Optimal Counterfactual Explanations in Tree Ensembles",
    "abstract": "Counterfactual explanations are usually generated through heuristics that are\nsensitive to the search's initial conditions. The absence of guarantees of\nperformance and robustness hinders trustworthiness. In this paper, we take a\ndisciplined approach towards counterfactual explanations for tree ensembles. We\nadvocate for a model-based search aiming at \"optimal\" explanations and propose\nefficient mixed-integer programming approaches. We show that isolation forests\ncan be modeled within our framework to focus the search on plausible\nexplanations with a low outlier score. We provide comprehensive coverage of\nadditional constraints that model important objectives, heterogeneous data\ntypes, structural constraints on the feature space, along with resource and\nactionability restrictions. Our experimental analyses demonstrate that the\nproposed search approach requires a computational effort that is orders of\nmagnitude smaller than previous mathematical programming algorithms. It scales\nup to large data sets and tree ensembles, where it provides, within seconds,\nsystematic explanations grounded on well-defined models solved to optimality.",
    "descriptor": "\nComments: To be published in the Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021. Open source code available at this https URL\n",
    "authors": [
      "Axel Parmentier",
      "Thibaut Vidal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.06631"
  },
  {
    "id": "arXiv:2106.06633",
    "title": "A note on confluence in typed probabilistic lambda calculi",
    "abstract": "On the topic of probabilistic rewriting, there are several works studying\nboth termination and confluence of different systems. While working with a\nlambda calculus modelling quantum computation, we found a system with\nprobabilistic rewriting rules and strongly normalizing terms. We examine the\neffect of small modifications in probabilistic rewriting, affine variables, and\nstrategies on the overall confluence in this strongly normalizing probabilistic\ncalculus.",
    "descriptor": "\nComments: To appear at LSFA 2021\n",
    "authors": [
      "Rafael Romero",
      "Alejandro D\u00edaz-Caro"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.06633"
  },
  {
    "id": "arXiv:2106.06635",
    "title": "On D2D Caching with Uncoded Cache Placement",
    "abstract": "We consider a cache-aided wireless device-to-device (D2D) network under the\nconstraint of one-shot delivery, where the placement phase is orchestrated by a\ncentral server. We assume that the devices' caches are filled with uncoded\ndata, and the whole file database at the server is made available in the\ncollection of caches. Following this phase, the files requested by the users\nare serviced by inter-device multicast communication. For such a system\nsetting, we provide the exact characterization of load-memory trade-off, by\nderiving both the minimum average and the minimum peak sum-loads of links\nbetween devices, for a given individual memory size at disposal of each user.",
    "descriptor": "\nComments: This paper was presented in the IEEE International Symposium on Information Theory (ISIT 2019) in Paris, France. Longer version available at arXiv:1901.05921\n",
    "authors": [
      "\u00c7a\u011fkan Yapar",
      "Kai Wan",
      "Rafael F. Schaefer",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.06635"
  },
  {
    "id": "arXiv:2106.06636",
    "title": "Direct Simultaneous Speech-to-Text Translation Assisted by Synchronized  Streaming ASR",
    "abstract": "Simultaneous speech-to-text translation is widely useful in many scenarios.\nThe conventional cascaded approach uses a pipeline of streaming ASR followed by\nsimultaneous MT, but suffers from error propagation and extra latency. To\nalleviate these issues, recent efforts attempt to directly translate the source\nspeech into target text simultaneously, but this is much harder due to the\ncombination of two separate tasks. We instead propose a new paradigm with the\nadvantages of both cascaded and end-to-end approaches. The key idea is to use\ntwo separate, but synchronized, decoders on streaming ASR and direct\nspeech-to-text translation (ST), respectively, and the intermediate results of\nASR guide the decoding policy of (but is not fed as input to) ST. During\ntraining time, we use multitask learning to jointly learn these two tasks with\na shared encoder. En-to-De and En-to-Es experiments on the MuSTC dataset\ndemonstrate that our proposed technique achieves substantially better\ntranslation quality at similar levels of latency.",
    "descriptor": "\nComments: accepted by Findings of ACL 2021\n",
    "authors": [
      "Junkun Chen",
      "Mingbo Ma",
      "Renjie Zheng",
      "Liang Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06636"
  },
  {
    "id": "arXiv:2106.06637",
    "title": "CAR-Net: Unsupervised Co-Attention Guided Registration Network for Joint  Registration and Structure Learning",
    "abstract": "Image registration is a fundamental building block for various applications\nin medical image analysis. To better explore the correlation between the fixed\nand moving images and improve registration performance, we propose a novel deep\nlearning network, Co-Attention guided Registration Network (CAR-Net). CAR-Net\nemploys a co-attention block to learn a new representation of the inputs, which\ndrives the registration of the fixed and moving images. Experiments on UK\nBiobank cardiac cine-magnetic resonance image data demonstrate that CAR-Net\nobtains higher registration accuracy and smoother deformation fields than\nstate-of-the-art unsupervised registration methods, while achieving comparable\nor better registration performance than corresponding weakly-supervised\nvariants. In addition, our approach can provide critical structural information\nof the input fixed and moving images simultaneously in a completely\nunsupervised manner.",
    "descriptor": "",
    "authors": [
      "Xiang Chen",
      "Yan Xia",
      "Nishant Ravikumar",
      "Alejandro F Frangi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06637"
  },
  {
    "id": "arXiv:2106.06639",
    "title": "Federated Learning with Buffered Asynchronous Aggregation",
    "abstract": "Federated Learning (FL) trains a shared model across distributed devices\nwhile keeping the training data on the devices. Most FL schemes are\nsynchronous: they perform a synchronized aggregation of model updates from\nindividual devices. Synchronous training can be slow because of late-arriving\ndevices (stragglers). On the other hand, completely asynchronous training makes\nFL less private because of incompatibility with secure aggregation. In this\nwork, we propose a model aggregation scheme, FedBuff, that combines the best\nproperties of synchronous and asynchronous FL. Similar to synchronous FL,\nFedBuff is compatible with secure aggregation. Similar to asynchronous FL,\nFedBuff is robust to stragglers. In FedBuff, clients trains asynchronously and\nsend updates to the server. The server aggregates client updates in a private\nbuffer until updates have been received, at which point a server model update\nis immediately performed. We provide theoretical convergence guarantees for\nFedBuff in a non-convex setting. Empirically, FedBuff converges up to 3.8x\nfaster than previous proposals for synchronous FL (e.g., FedAvgM), and up to\n2.5x faster than previous proposals for asynchronous FL (e.g., FedAsync). We\nshow that FedBuff is robust to different staleness distributions and is more\nscalable than synchronous FL techniques.",
    "descriptor": "",
    "authors": [
      "John Nguyen",
      "Kshitiz Malik",
      "Hongyuan Zhan",
      "Ashkan Yousefpour",
      "Michael Rabbat",
      "Mani Malek Esmaeili",
      "Dzmitry Huba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06639"
  },
  {
    "id": "arXiv:2106.06641",
    "title": "Conservative Integrators for Many-body Problems",
    "abstract": "Conservative symmetric second-order one-step schemes are derived for\ndynamical systems describing various many-body systems using the Discrete\nMultiplier Method. This includes conservative schemes for the $n$-species\nLotka-Volterra system, the $n$-body problem with radially symmetric potential\nand the $n$-point vortex models in the plane and on the sphere. In particular,\nwe recover Greenspan-Labudde's conservative schemes for the $n$-body problem.\nNumerical experiments are shown verifying the conservative property of the\nschemes and second-order accuracy.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Andy T. S. Wan",
      "Alexander Bihlo",
      "Jean-Christophe Nave"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.06641"
  },
  {
    "id": "arXiv:2106.06646",
    "title": "Spatially Scalable Lossy Coded Caching",
    "abstract": "We apply the coded caching scheme proposed by Maddah-Ali and Niesen to a\nmultipoint multicasting video paradigm. Partially caching the video files on\nthe wireless devices provides an opportunity to decrease data traffic load in\npeak hours via sending multicast coded messages to users. In this paper, we\npropose a two-hop wireless network for video multicasting, where the common\ncoded multicast message is transmitted through different single antenna Edge\nNodes (ENs) to multiple antenna users. Each user can decide to decode any EN by\nusing a zero forcing receiver. Motivated by Scalable Video Coding (SVC), we\nconsider successive refinement source coding in order to provide a ``softer''\ntradeoff between the number of decoded ENs and the source distortion at each\nuser receiver. The resulting coding scheme can be seen as the concatenation of\nMaddah-Ali and Niesen coded caching for each source-coded layer, and multiple\ndescription coding. Using stochastic geometry, we investigate the tradeoff\nbetween delivery time and per-user average source distortion. The proposed\nsystem is spatially scalable in the sense that, for given users' and ENs'\nspatial density, the achieved distortion-delivery time performance is\nindependent of the coverage area (for in the limit of large area).",
    "descriptor": "\nComments: This paper was presented in the IEEE International Symposium on Wireless Communication Systems (ISWCS 2018) in Lisbon, Portugal\n",
    "authors": [
      "Mozhgan Bayat",
      "\u00c7a\u011fkan Yapar",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06646"
  },
  {
    "id": "arXiv:2106.06649",
    "title": "1st Place Solution for YouTubeVOS Challenge 2021:Video Instance  Segmentation",
    "abstract": "Video Instance Segmentation (VIS) is a multi-task problem performing\ndetection, segmentation, and tracking simultaneously. Extended from image set\napplications, video data additionally induces the temporal information, which,\nif handled appropriately, is very useful to identify and predict object\nmotions. In this work, we design a unified model to mutually learn these tasks.\nSpecifically, we propose two modules, named Temporally Correlated Instance\nSegmentation (TCIS) and Bidirectional Tracking (BiTrack), to take the benefit\nof the temporal correlation between the object's instance masks across adjacent\nframes. On the other hand, video data is often redundant due to the frame's\noverlap. Our analysis shows that this problem is particularly severe for the\nYoutubeVOS-VIS2021 data. Therefore, we propose a Multi-Source Data (MSD)\ntraining mechanism to compensate for the data deficiency. By combining these\ntechniques with a bag of tricks, the network performance is significantly\nboosted compared to the baseline, and outperforms other methods by a\nconsiderable margin on the YoutubeVOS-VIS 2019 and 2021 datasets.",
    "descriptor": "\nComments: Accepted to CPVR 2021 Workshop\n",
    "authors": [
      "Thuy C. Nguyen",
      "Tuan N. Tang",
      "Nam LH. Phan",
      "Chuong H. Nguyen",
      "Masayuki Yamazaki",
      "Masao Yamanaka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06649"
  },
  {
    "id": "arXiv:2106.06650",
    "title": "Large-Scale Unsupervised Object Discovery",
    "abstract": "Existing approaches to unsupervised object discovery (UOD) do not scale up to\nlarge datasets without approximations which compromise their performance. We\npropose a novel formulation of UOD as a ranking problem, amenable to the\narsenal of distributed methods available for eigenvalue problems and link\nanalysis. Extensive experiments with COCO and OpenImages demonstrate that, in\nthe single-object discovery setting where a single prominent object is sought\nin each image, the proposed LOD (Large-scale Object Discovery) approach is on\npar with, or better than the state of the art for medium-scale datasets (up to\n120K images), and over 37% better than the only other algorithms capable of\nscaling up to 1.7M images. In the multi-object discovery setting where multiple\nobjects are sought in each image, the proposed LOD is over 14% better in\naverage precision (AP) than all other methods for datasets ranging from 20K to\n1.7M images.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Huy V. Vo",
      "Elena Sizikova",
      "Cordelia Schmid",
      "Patrick P\u00e9rez",
      "Jean Ponce"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06650"
  },
  {
    "id": "arXiv:2106.06652",
    "title": "Lessons learned from hyper-parameter tuning for microservice candidate  identification",
    "abstract": "When optimizing software for the cloud, monolithic applications need to be\npartitioned into many smaller *microservices*. While many tools have been\nproposed for this task, we warn that the evaluation of those approaches has\nbeen incomplete; e.g. minimal prior exploration of hyperparameter optimization.\nUsing a set of open source Java EE applications, we show here that (a) such\noptimization can significantly improve microservice partitioning; and that (b)\nan open issue for future work is how to find which optimizer works best for\ndifferent problems. To facilitate that future work, see\n[https://github.com/yrahul3910/ase-tuned-mono2micro](https://github.com/yrahul3910/ase-tuned-mono2micro)\nfor a reproduction package for this research.",
    "descriptor": "\nComments: Submitted to ASE 2021 Industry Track, short paper\n",
    "authors": [
      "Rahul Yedida",
      "Rahul Krishna",
      "Anup Kalia",
      "Tim Menzies",
      "Jin Xiao",
      "Maja Vukovic"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.06652"
  },
  {
    "id": "arXiv:2106.06654",
    "title": "Disrupting Model Training with Adversarial Shortcuts",
    "abstract": "When data is publicly released for human consumption, it is unclear how to\nprevent its unauthorized usage for machine learning purposes. Successful model\ntraining may be preventable with carefully designed dataset modifications, and\nwe present a proof-of-concept approach for the image classification setting. We\npropose methods based on the notion of adversarial shortcuts, which encourage\nmodels to rely on non-robust signals rather than semantic features, and our\nexperiments demonstrate that these measures successfully prevent deep learning\nmodels from achieving high accuracy on real, unmodified data examples.",
    "descriptor": "",
    "authors": [
      "Ivan Evtimov",
      "Ian Covert",
      "Aditya Kusupati",
      "Tadayoshi Kohno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06654"
  },
  {
    "id": "arXiv:2106.06655",
    "title": "Metrics for 3D Object Pointing and Manipulation in Virtual Reality",
    "abstract": "Assessing the performance of human movements during teleoperation and virtual\nreality is a challenging problem, particularly in 3D space due to complex\nspatial settings. Despite the presence of a multitude of metrics, a compelling\nstandardized 3D metric is yet missing, aggravating inter-study comparability\nbetween different studies. Hence, evaluating human performance in virtual\nenvironments is a long-standing research goal, and a performance metric that\ncombines two or more metrics under one formulation remains largely unexplored,\nparticularly in higher dimensions. The absence of such a metric is primarily\nattributed to the discrepancies between pointing and manipulation, the complex\nspatial variables in 3D, and the combination of translational and rotational\nmovements altogether. In this work, four experiments were designed and\nconducted with progressively higher spatial complexity to study and compare\nexisting metrics thoroughly. The research goal was to quantify the difficulty\nof these 3D tasks and model human performance sufficiently in full 3D\nperipersonal space. Consequently, a new model extension has been proposed and\nits applicability has been validated across all the experimental results,\nshowing improved modelling and representation of human performance in combined\nmovements of 3D object pointing and manipulation tasks than existing work.\nLastly, the implications on 3D interaction, teleoperation and object task\ndesign in virtual reality are discussed.",
    "descriptor": "\nComments: Accepted and to appear at the IEEE Robotics & Automation Magazine. The manuscript has 14 pages, 6 figures, 5 tables, 10 equations and 22 references in total\n",
    "authors": [
      "Eleftherios Triantafyllidis",
      "Wenbin Hu",
      "Christopher McGreavy",
      "Zhibin Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.06655"
  },
  {
    "id": "arXiv:2106.06657",
    "title": "Provable Adaptation across Multiway Domains via Representation Learning",
    "abstract": "This paper studies zero-shot domain adaptation where each domain is indexed\non a multi-dimensional array, and we only have data from a small subset of\ndomains. Our goal is to produce predictors that perform well on \\emph{unseen}\ndomains. We propose a model which consists of a domain-invariant latent\nrepresentation layer and a domain-specific linear prediction layer with a\nlow-rank tensor structure. Theoretically, we present explicit sample complexity\nbounds to characterize the prediction error on unseen domains in terms of the\nnumber of domains with training data and the number of data per domain. To our\nknowledge, this is the first finite-sample guarantee for zero-shot domain\nadaptation. In addition, we provide experiments on two-way MNIST and four-way\nfiber sensing datasets to demonstrate the effectiveness of our proposed model.",
    "descriptor": "",
    "authors": [
      "Zhili Feng",
      "Shaobo Han",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06657"
  },
  {
    "id": "arXiv:2106.06658",
    "title": "Polymorphic Context-free Session Types",
    "abstract": "Context-free session types provide a typing discipline for recursive\nstructured communication protocols on bidirectional channels. They overcome the\nrestriction of regular session type systems to tail recursive protocols. This\nextension enables us to implement serialisation and deserialisation of tree\nstructures in a fully type-safe manner.\nWe present the theory underlying the language FreeST 2, which features\ncontext-free session types in an extension of System F with linear types and a\nkind system to distinguish message types and channel types. The system presents\nsome metatheoretical challenges, which we address, contractivity in the\npresence of polymorphism, a non-trivial equational theory on types, and\ndecidability of type equivalence. We also establish standard results on type\npreservation, progress, and a characterisation of erroneous processes.",
    "descriptor": "",
    "authors": [
      "Bernardo Almeida",
      "Andreia Mordido",
      "Peter Thiemann",
      "Vasco T. Vasconcelos"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.06658"
  },
  {
    "id": "arXiv:2106.06662",
    "title": "Equivariant Networks for Pixelized Spheres",
    "abstract": "Pixelizations of Platonic solids such as the cube and icosahedron have been\nwidely used to represent spherical data, from climate records to Cosmic\nMicrowave Background maps. Platonic solids have well-known global symmetries.\nOnce we pixelize each face of the solid, each face also possesses its own local\nsymmetries in the form of Euclidean isometries. One way to combine these\nsymmetries is through a hierarchy. However, this approach does not adequately\nmodel the interplay between the two levels of symmetry transformations. We show\nhow to model this interplay using ideas from group theory, identify the\nequivariant linear maps, and introduce equivariant padding that respects these\nsymmetries. Deep networks that use these maps as their building blocks\ngeneralize gauge equivariant CNNs on pixelized spheres. These deep networks\nachieve state-of-the-art results on semantic segmentation for climate data and\nomnidirectional image processing. Code is available at https://git.io/JGiZA.",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Mehran Shakerinava",
      "Siamak Ravanbakhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06662"
  },
  {
    "id": "arXiv:2106.06663",
    "title": "TDGIA:Effective Injection Attacks on Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have achieved promising performance in various\nreal-world applications. However, recent studies have shown that GNNs are\nvulnerable to adversarial attacks. In this paper, we study a\nrecently-introduced realistic attack scenario on graphs -- graph injection\nattack (GIA). In the GIA scenario, the adversary is not able to modify the\nexisting link structure and node attributes of the input graph, instead the\nattack is performed by injecting adversarial nodes into it. We present an\nanalysis on the topological vulnerability of GNNs under GIA setting, based on\nwhich we propose the Topological Defective Graph Injection Attack (TDGIA) for\neffective injection attacks. TDGIA first introduces the topological defective\nedge selection strategy to choose the original nodes for connecting with the\ninjected ones. It then designs the smooth feature optimization objective to\ngenerate the features for the injected nodes. Extensive experiments on\nlarge-scale datasets show that TDGIA can consistently and significantly\noutperform various attack baselines in attacking dozens of defense GNN models.\nNotably, the performance drop on target GNNs resultant from TDGIA is more than\ndouble the damage brought by the best attack solution among hundreds of\nsubmissions on KDD-CUP 2020.",
    "descriptor": "\nComments: KDD 2021 research track paper\n",
    "authors": [
      "Xu Zou",
      "Qinkai Zheng",
      "Yuxiao Dong",
      "Xinyu Guan",
      "Evgeny Kharlamov",
      "Jialiang Lu",
      "Jie Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.06663"
  },
  {
    "id": "arXiv:2106.06666",
    "title": "Learnable Hypergraph Laplacian for Hypergraph Learning",
    "abstract": "HyperGraph Convolutional Neural Networks (HGCNNs) have demonstrated their\npotential in modeling high-order relations preserved in graph structured data.\nHowever, most existing convolution filters are localized and determined by the\npre-defined initial hypergraph topology, neglecting to explore implicit and\nlong-ange relations in real-world data. In this paper, we propose the first\nlearning-based method tailored for constructing adaptive hypergraph structure,\ntermed HypERgrAph Laplacian aDaptor (HERALD), which serves as a generic\nplug-in-play module for improving the representational power of HGCNNs.\nSpecifically, HERALD adaptively optimizes the adjacency relationship between\nhypernodes and hyperedges in an end-to-end manner and thus the task-aware\nhypergraph is learned. Furthermore, HERALD employs the self-attention mechanism\nto capture the non-local paired-nodes relation. Extensive experiments on\nvarious popular hypergraph datasets for node classification and graph\nclassification tasks demonstrate that our approach obtains consistent and\nconsiderable performance enhancement, proving its effectiveness and\ngeneralization ability.",
    "descriptor": "",
    "authors": [
      "Jiying Zhang",
      "Yuzhao Chen",
      "Xi Xiao",
      "Runiu Lu",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06666"
  },
  {
    "id": "arXiv:2106.06667",
    "title": "CARTL: Cooperative Adversarially-Robust Transfer Learning",
    "abstract": "Transfer learning eases the burden of training a well-performed model from\nscratch, especially when training data is scarce and computation power is\nlimited. In deep learning, a typical strategy for transfer learning is to\nfreeze the early layers of a pre-trained model and fine-tune the rest of its\nlayers on the target domain. Previous work focuses on the accuracy of the\ntransferred model but neglects the transfer of adversarial robustness. In this\nwork, we first show that transfer learning improves the accuracy on the target\ndomain but degrades the inherited robustness of the target model. To address\nsuch a problem, we propose a novel cooperative adversarially-robust transfer\nlearning (CARTL) by pre-training the model via feature distance minimization\nand fine-tuning the pre-trained model with non-expansive fine-tuning for target\ndomain tasks. Empirical results show that CARTL improves the inherited\nrobustness by about 28% at most compared with the baseline with the same degree\nof accuracy. Furthermore, we study the relationship between the batch\nnormalization (BN) layers and the robustness in the context of transfer\nlearning, and we reveal that freezing BN layers can further boost the\nrobustness transfer.",
    "descriptor": "\nComments: Published as a conference paper at ICML 2021\n",
    "authors": [
      "Dian Chen",
      "Hongxin Hu",
      "Qian Wang",
      "Yinli Li",
      "Cong Wang",
      "Chao Shen",
      "Qi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06667"
  },
  {
    "id": "arXiv:2106.06672",
    "title": "Structure-Regularized Attention for Deformable Object Representation",
    "abstract": "Capturing contextual dependencies has proven useful to improve the\nrepresentational power of deep neural networks. Recent approaches that focus on\nmodeling global context, such as self-attention and non-local operation,\nachieve this goal by enabling unconstrained pairwise interactions between\nelements. In this work, we consider learning representations for deformable\nobjects which can benefit from context exploitation by modeling the structural\ndependencies that the data intrinsically possesses. To this end, we provide a\nnovel structure-regularized attention mechanism, which formalizes feature\ninteraction as structural factorization through the use of a pair of\nlight-weight operations. The instantiated building blocks can be directly\nincorporated into modern convolutional neural networks, to boost the\nrepresentational power in an efficient manner. Comprehensive studies on\nmultiple tasks and empirical comparisons with modern attention mechanisms\ndemonstrate the gains brought by our method in terms of both performance and\nmodel complexity. We further investigate its effect on feature representations,\nshowing that our trained models can capture diversified representations\ncharacterizing object parts without resorting to extra supervision.",
    "descriptor": "\nComments: Published at NeurIPS 2020 Workshop on Object Representations for Learning and Reasoning; code is available at this https URL\n",
    "authors": [
      "Shenao Zhang",
      "Li Shen",
      "Zhifeng Li",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06672"
  },
  {
    "id": "arXiv:2106.06673",
    "title": "Study of sampling methods in sentiment analysis of imbalanced data",
    "abstract": "This work investigates the application of sampling methods for sentiment\nanalysis on two different highly imbalanced datasets. One dataset contains\nonline user reviews from the cooking platform Epicurious and the other contains\ncomments given to the Planned Parenthood organization. In both these datasets,\nthe classes of interest are rare. Word n-grams were used as features from these\ndatasets. A feature selection technique based on information gain is first\napplied to reduce the number of features to a manageable space. A number of\ndifferent sampling methods were then applied to mitigate the class imbalance\nproblem which are then analyzed.",
    "descriptor": "",
    "authors": [
      "Zeeshan Ali Sayyed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06673"
  },
  {
    "id": "arXiv:2106.06676",
    "title": "Semi-supervised Active Regression",
    "abstract": "Labelled data often comes at a high cost as it may require recruiting human\nlabelers or running costly experiments. At the same time, in many practical\nscenarios, one already has access to a partially labelled, potentially biased\ndataset that can help with the learning task at hand. Motivated by such\nsettings, we formally initiate a study of $semi-supervised$ $active$ $learning$\nthrough the frame of linear regression. In this setting, the learner has access\nto a dataset $X \\in \\mathbb{R}^{(n_1+n_2) \\times d}$ which is composed of $n_1$\nunlabelled examples that an algorithm can actively query, and $n_2$ examples\nlabelled a-priori. Concretely, denoting the true labels by $Y \\in\n\\mathbb{R}^{n_1 + n_2}$, the learner's objective is to find $\\widehat{\\beta}\n\\in \\mathbb{R}^d$ such that, \\begin{equation}\n\\| X \\widehat{\\beta} - Y \\|_2^2 \\le (1 + \\epsilon) \\min_{\\beta \\in\n\\mathbb{R}^d} \\| X \\beta - Y \\|_2^2 \\end{equation} while making as few\nadditional label queries as possible. In order to bound the label queries, we\nintroduce an instance dependent parameter called the reduced rank, denoted by\n$R_X$, and propose an efficient algorithm with query complexity\n$O(R_X/\\epsilon)$. This result directly implies improved upper bounds for two\nimportant special cases: (i) active ridge regression, and (ii) active kernel\nridge regression, where the reduced-rank equates to the statistical dimension,\n$sd_\\lambda$ and effective dimension, $d_\\lambda$ of the problem respectively,\nwhere $\\lambda \\ge 0$ denotes the regularization parameter. For active ridge\nregression we also prove a matching lower bound of $O(sd_\\lambda / \\epsilon)$\non the query complexity of any algorithm. This subsumes prior work that only\nconsidered the unregularized case, i.e., $\\lambda = 0$.",
    "descriptor": "",
    "authors": [
      "Fnu Devvrit",
      "Nived Rajaraman",
      "Pranjal Awasthi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06676"
  },
  {
    "id": "arXiv:2106.06677",
    "title": "Examining Passenger Vehicle Miles Traveled and Carbon Emissions in the  Boston Metropolitan Area",
    "abstract": "With spatial analytic, econometric, and visualization tools, this book\nchapter investigates greenhouse gas emissions for the on-road passenger vehicle\ntransport sector in the Boston metropolitan area in 2014. It compares\ngreenhouse gas emission estimations from both the production-based and\nconsumption-based perspectives with two large-scale administrative datasets:\nthe vehicle odometer readings from individual vehicle annual inspection, and\nthe road inventory data containing road segment level geospatial and traffic\ninformation. Based on spatial econometric models that examine socioeconomic and\nbuilt environment factors contributing to the vehicle miles traveled at the\ncensus tract level, it offers insights to help cities reduce VMT and carbon\nfootprint for passenger vehicle travel. Finally, it recommends a pathway for\ncities and towns in the Boston metropolitan area to curb VMT and mitigate\ncarbon emissions to achieve climate goals of carbon neutrality.",
    "descriptor": "",
    "authors": [
      "Tigran Aslanyan",
      "Shan Jiang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.06677"
  },
  {
    "id": "arXiv:2106.06678",
    "title": "iThing: Designing Next-Generation Things with Battery Health  Self-Monitoring Capabilities for Sustainable IoT in Smart Cities",
    "abstract": "An accurate and reliable technique for predicting Remaining Useful Life (RUL)\nfor battery cells proves helpful in battery-operated IoT devices, especially in\nremotely operated sensor nodes. Data-driven methods have proved to be the most\neffective methods until now. These IoT devices have low computational\ncapabilities to save costs, but Data-Driven battery health techniques often\nrequire a comparatively large amount of computational power to predict SOH and\nRUL due to most methods being feature-heavy. This issue calls for ways to\npredict RUL with the least amount of calculations and memory. This paper\nproposes an effective and novel peak extraction method to reduce computation\nand memory needs and provide accurate prediction methods using the least number\nof features while performing all calculations on-board. The model can\nself-sustain, requires minimal external interference, and hence operate\nremotely much longer. Experimental results prove the accuracy and reliability\nof this method. The Absolute Error (AE), Relative error (RE), and Root Mean\nSquare Error (RMSE) are calculated to compare effectiveness. The training of\nthe GPR model takes less than 2 seconds, and the correlation between SOH from\npeak extraction and RUL is 0.97.",
    "descriptor": "",
    "authors": [
      "Aparna Sinha",
      "Debanjan Das",
      "Venkanna Udutalapally",
      "Mukil Kumar Selvarajan",
      "Saraju P. Mohanty"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.06678"
  },
  {
    "id": "arXiv:2106.06680",
    "title": "Markov Decision Processes with Long-Term Average Constraints",
    "abstract": "We consider the problem of constrained Markov Decision Process (CMDP) where\nan agent interacts with a unichain Markov Decision Process. At every\ninteraction, the agent obtains a reward. Further, there are $K$ cost functions.\nThe agent aims to maximize the long-term average reward while simultaneously\nkeeping the $K$ long-term average costs lower than a certain threshold. In this\npaper, we propose CMDP-PSRL, a posterior sampling based algorithm using which\nthe agent can learn optimal policies to interact with the CMDP. Further, for\nMDP with $S$ states, $A$ actions, and diameter $D$, we prove that following\nCMDP-PSRL algorithm, the agent can bound the regret of not accumulating rewards\nfrom optimal policy by $\\Tilde{O}(poly(DSA)\\sqrt{T})$. Further, we show that\nthe violations for any of the $K$ constraints is also bounded by\n$\\Tilde{O}(poly(DSA)\\sqrt{T})$. To the best of our knowledge, this is the first\nwork which obtains a $\\Tilde{O}(\\sqrt{T})$ regret bounds for ergodic MDPs with\nlong-term average constraints.",
    "descriptor": "",
    "authors": [
      "Mridul Agarwal",
      "Qinbo Bai",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06680"
  },
  {
    "id": "arXiv:2106.06682",
    "title": "Solving PDEs on Unknown Manifolds with Machine Learning",
    "abstract": "This paper proposes a mesh-free computational framework and machine learning\ntheory for solving elliptic PDEs on unknown manifolds, identified with point\nclouds, based on diffusion maps (DM) and deep learning. The PDE solver is\nformulated as a supervised learning task to solve a least-squares regression\nproblem that imposes an algebraic equation approximating a PDE (and boundary\nconditions if applicable). This algebraic equation involves a graph-Laplacian\ntype matrix obtained via DM asymptotic expansion, which is a consistent\nestimator of second-order elliptic differential operators. The resulting\nnumerical method is to solve a highly non-convex empirical risk minimization\nproblem subjected to a solution from a hypothesis space of neural-network type\nfunctions. In a well-posed elliptic PDE setting, when the hypothesis space\nconsists of feedforward neural networks with either infinite width or depth, we\nshow that the global minimizer of the empirical loss function is a consistent\nsolution in the limit of large training data. When the hypothesis space is a\ntwo-layer neural network, we show that for a sufficiently large width, the\ngradient descent method can identify a global minimizer of the empirical loss\nfunction. Supporting numerical examples demonstrate the convergence of the\nsolutions and the effectiveness of the proposed solver in avoiding numerical\nissues that hampers the traditional approach when a large data set becomes\navailable, e.g., large matrix inversion.",
    "descriptor": "",
    "authors": [
      "Senwei Liang",
      "Shixiao W. Jiang",
      "John Harlim",
      "Haizhao Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06682"
  },
  {
    "id": "arXiv:2106.06683",
    "title": "Assessing Multilingual Fairness in Pre-trained Multimodal  Representations",
    "abstract": "Recently pre-trained multimodal models, such as CLIP, have received a surge\nof attention for their exceptional capabilities towards connecting images and\nnatural language. The textual representations in English can be desirably\ntransferred to multilingualism and support promising downstream multimodal\ntasks for different languages. Nevertheless, previous fairness discourse in\nvision-and-language learning mainly focuses on monolingual representational\nbiases, and rarely scrutinizes the principles of multilingual fairness in this\nmultimodal setting, where one language is equated to a group of individuals and\nimages provide the universal grounding for bridging different languages.\nIn this paper, we provide a nuanced understanding of individual fairness and\ngroup fairness by viewing language as the recipient of fairness notions. We\ndefine new fairness notions within multilingual context and analytically\narticulate that, pre-trained vision-and-language representations are\nindividually fair across languages but not guaranteed to group fairness.\nFurthermore, we conduct extensive experiments to explore the prevalent group\ndisparity across languages and protected groups including race, gender and age.",
    "descriptor": "\nComments: 12 pages, 14 figures\n",
    "authors": [
      "Jialu Wang",
      "Yang Liu",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06683"
  },
  {
    "id": "arXiv:2106.06684",
    "title": "Multistream ValidNet: Improving 6D Object Pose Estimation by Automatic  Multistream Validation",
    "abstract": "This work presents a novel approach to improve the results of pose estimation\nby detecting and distinguishing between the occurrence of True and False\nPositive results. It achieves this by training a binary classifier on the\noutput of an arbitrary pose estimation algorithm, and returns a binary label\nindicating the validity of the result. We demonstrate that our approach\nimproves upon a state-of-the-art pose estimation result on the Sil\\'eane\ndataset, outperforming a variation of the alternative CullNet method by 4.15%\nin average class accuracy and 0.73% in overall accuracy at validation. Applying\nour method can also improve the pose estimation average precision results of\nOp-Net by 6.06% on average.",
    "descriptor": "\nComments: 6 pages, 2 figures, 2 tables. To appear in the proceedings of the 28th IEEE International Conference on Image Processing (IEEE - ICIP), September 19-22, 2021, Anchorage, Alaska, USA\n",
    "authors": [
      "Joy Mazumder",
      "Mohsen Zand",
      "Michael Greenspan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06684"
  },
  {
    "id": "arXiv:2106.06685",
    "title": "Adversarial Robustness via Fisher-Rao Regularization",
    "abstract": "Adversarial robustness has become a topic of growing interest in machine\nlearning since it was observed that neural networks tend to be brittle. We\npropose an information-geometric formulation of adversarial defense and\nintroduce FIRE, a new Fisher-Rao regularization for the categorical\ncross-entropy loss, which is based on the geodesic distance between natural and\nperturbed input features. Based on the information-geometric properties of the\nclass of softmax distributions, we derive an explicit characterization of the\nFisher-Rao Distance (FRD) for the binary and multiclass cases, and draw some\ninteresting properties as well as connections with standard regularization\nmetrics. Furthermore, for a simple linear and Gaussian model, we show that all\nPareto-optimal points in the accuracy-robustness region can be reached by FIRE\nwhile other state-of-the-art methods fail. Empirically, we evaluate the\nperformance of various classifiers trained with the proposed loss on standard\ndatasets, showing up to 2\\% of improvements in terms of robustness while\nreducing the training time by 20\\% over the best-performing methods.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Marine Picot",
      "Francisco Messina",
      "Malik Boudiaf",
      "Fabrice Labeau",
      "Ismail Ben Ayed",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06685"
  },
  {
    "id": "arXiv:2106.06688",
    "title": "BRAIN2DEPTH: Lightweight CNN Model for Classification of Cognitive  States from EEG Recordings",
    "abstract": "Several Convolutional Deep Learning models have been proposed to classify the\ncognitive states utilizing several neuro-imaging domains. These models have\nachieved significant results, but they are heavily designed with millions of\nparameters, which increases train and test time, making the model complex and\nless suitable for real-time analysis. This paper proposes a simple, lightweight\nCNN model to classify cognitive states from Electroencephalograph (EEG)\nrecordings. We develop a novel pipeline to learn distinct cognitive\nrepresentation consisting of two stages. The first stage is to generate the 2D\nspectral images from neural time series signals in a particular frequency band.\nImages are generated to preserve the relationship between the neighboring\nelectrodes and the spectral property of the cognitive events. The second is to\ndevelop a time-efficient, computationally less loaded, and high-performing\nmodel. We design a network containing 4 blocks and major components include\nstandard and depth-wise convolution for increasing the performance and followed\nby separable convolution to decrease the number of parameters which maintains\nthe tradeoff between time and performance. We experiment on open access EEG\nmeditation dataset comprising expert, nonexpert meditative, and control states.\nWe compare performance with six commonly used machine learning classifiers and\nfour state of the art deep learning models. We attain comparable performance\nutilizing less than 4\\% of the parameters of other models. This model can be\nemployed in a real-time computation environment such as neurofeedback.",
    "descriptor": "\nComments: 15 pages, 4 figures, 6 tables, To be published in 25th Conference on Medical Image Understanding and Analysis (MIUA), 2021\n",
    "authors": [
      "Pankaj Pandey",
      "Krishna Prasad Miyapuram"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06688"
  },
  {
    "id": "arXiv:2106.06689",
    "title": "Neural Combinatory Constituency Parsing",
    "abstract": "We propose two fast neural combinatory models for constituency parsing:\nbinary and multi-branching. Our models decompose the bottom-up parsing process\ninto 1) classification of tags, labels, and binary orientations or chunks and\n2) vector composition based on the computed orientations or chunks. These\nmodels have theoretical sub-quadratic complexity and empirical linear\ncomplexity. The binary model achieves an F1 score of 92.54 on Penn Treebank,\nspeeding at 1327.2 sents/sec. Both the models with XLNet provide near\nstate-of-the-art accuracies for English. Syntactic branching tendency and\nheadedness of a language are observed during the training and inference\nprocesses for Penn Treebank, Chinese Treebank, and Keyaki Treebank (Japanese).",
    "descriptor": "\nComments: Findings of ACL 2021; 15 pages\n",
    "authors": [
      "Zhousi Chen",
      "Longtu Zhang",
      "Aizhan Imankulova",
      "Mamoru Komachi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06689"
  },
  {
    "id": "arXiv:2106.06692",
    "title": "Delay Analysis of Base Station Flow Table in SDN-enabled Radio Access  Networks",
    "abstract": "Future generation wireless networks are designed with extremely low delay\nrequirements which makes even small contributed delays important. On the other\nhand, software defined networking (SDN) has been introduced as a key enabler of\nfuture wireless and cellular networks in order to make them more flexible. In\nSDN, a central controller manages all network equipments by setting the\nmatch-action pairs in flow tables of the devices. However, these flow tables\nhave limited capacity and thus are not capable of storing the rules of all the\nusers. In this paper, we consider an SDN-enabled base station (SD-BS) in a cell\nequipped with a limited capacity flow table. We analyze the expected delay\nincurred in processing of the incoming packets to the SD-BS and present a\nmathematical expression for it in terms of density of the users and cell area.",
    "descriptor": "\nComments: 3 pages, 3 figures\n",
    "authors": [
      "Seyed Hamed Rastegar",
      "Aliazam Abbasfar",
      "Vahid Shah-Mansouri"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.06692"
  },
  {
    "id": "arXiv:2106.06694",
    "title": "Reverse-engineer the Distributional Structure of Infant Egocentric Views  for Training Generalizable Image Classifiers",
    "abstract": "We analyze egocentric views of attended objects from infants. This paper\nshows 1) empirical evidence that children's egocentric views have more diverse\ndistributions compared to adults' views, 2) we can computationally simulate the\ninfants' distribution, and 3) the distribution is beneficial for training more\ngeneralized image classifiers not only for infant egocentric vision but for\nthird-person computer vision.",
    "descriptor": "\nComments: Accepted to 2021 CVPR Workshop on Egocentric Perception, Interaction and Computing (EPIC)\n",
    "authors": [
      "Satoshi Tsutsui",
      "David Crandall",
      "Chen Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06694"
  },
  {
    "id": "arXiv:2106.06695",
    "title": "SKIing on Simplices: Kernel Interpolation on the Permutohedral Lattice  for Scalable Gaussian Processes",
    "abstract": "State-of-the-art methods for scalable Gaussian processes use iterative\nalgorithms, requiring fast matrix vector multiplies (MVMs) with the covariance\nkernel. The Structured Kernel Interpolation (SKI) framework accelerates these\nMVMs by performing efficient MVMs on a grid and interpolating back to the\noriginal space. In this work, we develop a connection between SKI and the\npermutohedral lattice used for high-dimensional fast bilateral filtering. Using\na sparse simplicial grid instead of a dense rectangular one, we can perform GP\ninference exponentially faster in the dimension than SKI. Our approach,\nSimplex-GP, enables scaling SKI to high dimensions, while maintaining strong\npredictive performance. We additionally provide a CUDA implementation of\nSimplex-GP, which enables significant GPU acceleration of MVM based inference.",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML), 2021\n",
    "authors": [
      "Sanyam Kapoor",
      "Marc Finzi",
      "Ke Alexander Wang",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06695"
  },
  {
    "id": "arXiv:2106.06697",
    "title": "Explaining the Deep Natural Language Processing by Mining Textual  Interpretable Features",
    "abstract": "Despite the high accuracy offered by state-of-the-art deep natural-language\nmodels (e.g. LSTM, BERT), their application in real-life settings is still\nwidely limited, as they behave like a black-box to the end-user. Hence,\nexplainability is rapidly becoming a fundamental requirement of\nfuture-generation data-driven systems based on deep-learning approaches.\nSeveral attempts to fulfill the existing gap between accuracy and\ninterpretability have been done. However, robust and specialized xAI\n(Explainable Artificial Intelligence) solutions tailored to deep\nnatural-language models are still missing. We propose a new framework, named\nT-EBAnO, which provides innovative prediction-local and class-based\nmodel-global explanation strategies tailored to black-box deep natural-language\nmodels. Given a deep NLP model and the textual input data, T-EBAnO provides an\nobjective, human-readable, domain-specific assessment of the reasons behind the\nautomatic decision-making process. Specifically, the framework extracts sets of\ninterpretable features mining the inner knowledge of the model. Then, it\nquantifies the influence of each feature during the prediction process by\nexploiting the novel normalized Perturbation Influence Relation index at the\nlocal level and the novel Global Absolute Influence and Global Relative\nInfluence indexes at the global level. The effectiveness and the quality of the\nlocal and global explanations obtained with T-EBAnO are proved on (i) a\nsentiment analysis task performed by a fine-tuned BERT model, and (ii) a toxic\ncomment classification task performed by an LSTM model.",
    "descriptor": "",
    "authors": [
      "Francesco Ventura",
      "Salvatore Greco",
      "Daniele Apiletti",
      "Tania Cerquitelli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06697"
  },
  {
    "id": "arXiv:2106.06703",
    "title": "Unsupervised Place Recognition with Deep Embedding Learning over Radar  Videos",
    "abstract": "We learn, in an unsupervised way, an embedding from sequences of radar images\nthat is suitable for solving place recognition problem using complex radar\ndata. We experiment on 280 km of data and show performance exceeding\nstate-of-the-art supervised approaches, localising correctly 98.38% of the time\nwhen using just the nearest database candidate.",
    "descriptor": "\nComments: to be presented at the Workshop on Radar Perception for All-Weather Autonomy at the IEEE International Conference on Robotics and Automation (ICRA) 2021\n",
    "authors": [
      "Matthew Gadd",
      "Daniele De Martini",
      "Paul Newman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.06703"
  },
  {
    "id": "arXiv:2106.06706",
    "title": "Decentralized Matching in a Probabilistic Environment",
    "abstract": "We consider a model for repeated stochastic matching where compatibility is\nprobabilistic, is realized the first time agents are matched, and persists in\nthe future. Such a model has applications in the gig economy, kidney exchange,\nand mentorship matching.\nWe ask whether a $decentralized$ matching process can approximate the optimal\nonline algorithm. In particular, we consider a decentralized $stable$\n$matching$ process where agents match with the most compatible partner who does\nnot prefer matching with someone else, and known compatible pairs continue\nmatching in all future rounds. We demonstrate that the above process provides a\n0.316-approximation to the optimal online algorithm for matching on general\ngraphs. We also provide a $\\frac{1}{7}$-approximation for many-to-one bipartite\nmatching, a $\\frac{1}{11}$-approximation for capacitated matching on general\ngraphs, and a $\\frac{1}{2k}$-approximation for forming teams of up to $k$\nagents. Our results rely on a novel coupling argument that decomposes the\nsuccessful edges of the optimal online algorithm in terms of their\nround-by-round comparison with stable matching.",
    "descriptor": "",
    "authors": [
      "Mobin Y. Jeloudar",
      "Irene Lo",
      "Tristan Pollner",
      "Amin Saberi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.06706"
  },
  {
    "id": "arXiv:2106.06707",
    "title": "Graph Neural Networks with Local Graph Parameters",
    "abstract": "Various recent proposals increase the distinguishing power of Graph Neural\nNetworks GNNs by propagating features between $k$-tuples of vertices. The\ndistinguishing power of these \"higher-order'' GNNs is known to be bounded by\nthe $k$-dimensional Weisfeiler-Leman (WL) test, yet their $\\mathcal O(n^k)$\nmemory requirements limit their applicability. Other proposals infuse GNNs with\nlocal higher-order graph structural information from the start, hereby\ninheriting the desirable $\\mathcal O(n)$ memory requirement from GNNs at the\ncost of a one-time, possibly non-linear, preprocessing step. We propose local\ngraph parameter enabled GNNs as a framework for studying the latter kind of\napproaches and precisely characterize their distinguishing power, in terms of a\nvariant of the WL test, and in terms of the graph structural properties that\nthey can take into account. Local graph parameters can be added to any GNN\narchitecture, and are cheap to compute. In terms of expressive power, our\nproposal lies in the middle of GNNs and their higher-order counterparts.\nFurther, we propose several techniques to aide in choosing the right local\ngraph parameters. Our results connect GNNs with deep results in finite model\ntheory and finite variable logics. Our experimental evaluation shows that\nadding local graph parameters often has a positive effect for a variety of\nGNNs, datasets and graph learning tasks.",
    "descriptor": "",
    "authors": [
      "Pablo Barcel\u00f3",
      "Floris Geerts",
      "Juan Reutter",
      "Maksimilian Ryschkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06707"
  },
  {
    "id": "arXiv:2106.06708",
    "title": "Some Aspects of the Numerical Analysis of a Fractional Duffing  Oscillator with a Fractional Variable Order Derivative of the  Riemann-Liouville Type",
    "abstract": "In this paper, we consider some aspects of the numerical analysis of the\nmathematical model of fractional Duffing with a derivative of variable\nfractional order of the Riemann-Liouville type. Using numerical methods: an\nexplicit finite-difference scheme based on the Grunwald-Letnikov and\nAdams-Bashford-Moulton approximations (predictor-corrector), the proposed\nnumerical model is found. These methods have been verified with a test case. It\nis shown that the predictor-corrector method has a faster convergence than the\nmethod according to the explicit finite-difference scheme. For these schemes,\nusing Runge's rule, estimates of the computational accuracy were made, which\ntended to unity with an increase in the number of calculated grid nodes.",
    "descriptor": "",
    "authors": [
      "Valentine Kim",
      "Roman Parovik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2106.06708"
  },
  {
    "id": "arXiv:2106.06712",
    "title": "Simple Combinatorial Algorithms for Combinatorial Bandits: Corruptions  and Approximations",
    "abstract": "We consider the stochastic combinatorial semi-bandit problem with adversarial\ncorruptions. We provide a simple combinatorial algorithm that can achieve a\nregret of $\\tilde{O}\\left(C+d^2K/\\Delta_{min}\\right)$ where $C$ is the total\namount of corruptions, $d$ is the maximal number of arms one can play in each\nround, $K$ is the number of arms. If one selects only one arm in each round, we\nachieves a regret of $\\tilde{O}\\left(C+\\sum_{\\Delta_i>0}(1/\\Delta_i)\\right)$.\nOur algorithm is combinatorial and improves on the previous combinatorial\nalgorithm by [Gupta et al., COLT2019] (their bound is\n$\\tilde{O}\\left(KC+\\sum_{\\Delta_i>0}(1/\\Delta_i)\\right)$), and almost matches\nthe best known bounds obtained by [Zimmert et al., ICML2019] and [Zimmert and\nSeldin, AISTATS2019] (up to logarithmic factor). Note that the algorithms in\n[Zimmert et al., ICML2019] and [Zimmert and Seldin, AISTATS2019] require one to\nsolve complex convex programs while our algorithm is combinatorial, very easy\nto implement, requires weaker assumptions and has very low oracle complexity\nand running time. We also study the setting where we only get access to an\napproximation oracle for the stochastic combinatorial semi-bandit problem. Our\nalgorithm achieves an (approximation) regret bound of\n$\\tilde{O}\\left(d\\sqrt{KT}\\right)$. Our algorithm is very simple, only worse\nthan the best known regret bound by $\\sqrt{d}$, and has much lower oracle\ncomplexity than previous work.",
    "descriptor": "",
    "authors": [
      "Haike Xu",
      "Jian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06712"
  },
  {
    "id": "arXiv:2106.06713",
    "title": "AutoLoss: Automated Loss Function Search in Recommendations",
    "abstract": "Designing an effective loss function plays a crucial role in training deep\nrecommender systems. Most existing works often leverage a predefined and fixed\nloss function that could lead to suboptimal recommendation quality and training\nefficiency. Some recent efforts rely on exhaustively or manually searched\nweights to fuse a group of candidate loss functions, which is exceptionally\ncostly in computation and time. They also neglect the various convergence\nbehaviors of different data examples. In this work, we propose an AutoLoss\nframework that can automatically and adaptively search for the appropriate loss\nfunction from a set of candidates. To be specific, we develop a novel\ncontroller network, which can dynamically adjust the loss probabilities in a\ndifferentiable manner. Unlike existing algorithms, the proposed controller can\nadaptively generate the loss probabilities for different data examples\naccording to their varied convergence behaviors. Such design improves the\nmodel's generalizability and transferability between deep recommender systems\nand datasets. We evaluate the proposed framework on two benchmark datasets. The\nresults show that AutoLoss outperforms representative baselines. Further\nexperiments have been conducted to deepen our understandings of AutoLoss,\nincluding its transferability, components and training efficiency.",
    "descriptor": "\nComments: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n",
    "authors": [
      "Xiangyu Zhao",
      "Haochen Liu",
      "Wenqi Fan",
      "Hui Liu",
      "Jiliang Tang",
      "Chong Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06713"
  },
  {
    "id": "arXiv:2106.06716",
    "title": "DS-TransUNet:Dual Swin Transformer U-Net for Medical Image Segmentation",
    "abstract": "Automatic medical image segmentation has made great progress benefit from the\ndevelopment of deep learning. However, most existing methods are based on\nconvolutional neural networks (CNNs), which fail to build long-range\ndependencies and global context connections due to the limitation of receptive\nfield in convolution operation. Inspired by the success of Transformer in\nmodeling the long-range contextual information, some researchers have expended\nconsiderable efforts in designing the robust variants of Transformer-based\nU-Net. Moreover, the patch division used in vision transformers usually ignores\nthe pixel-level intrinsic structural features inside each patch. To alleviate\nthese problems, we propose a novel deep medical image segmentation framework\ncalled Dual Swin Transformer U-Net (DS-TransUNet), which might be the first\nattempt to concurrently incorporate the advantages of hierarchical Swin\nTransformer into both encoder and decoder of the standard U-shaped architecture\nto enhance the semantic segmentation quality of varying medical images. Unlike\nmany prior Transformer-based solutions, the proposed DS-TransUNet first adopts\ndual-scale encoder subnetworks based on Swin Transformer to extract the coarse\nand fine-grained feature representations of different semantic scales. As the\ncore component for our DS-TransUNet, a well-designed Transformer Interactive\nFusion (TIF) module is proposed to effectively establish global dependencies\nbetween features of different scales through the self-attention mechanism.\nFurthermore, we also introduce the Swin Transformer block into decoder to\nfurther explore the long-range contextual information during the up-sampling\nprocess. Extensive experiments across four typical tasks for medical image\nsegmentation demonstrate the effectiveness of DS-TransUNet, and show that our\napproach significantly outperforms the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Ailiang Lin",
      "Bingzhi Chen",
      "Jiayu Xu",
      "Zheng Zhang",
      "Guangming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06716"
  },
  {
    "id": "arXiv:2106.06719",
    "title": "Improving Unsupervised Dialogue Topic Segmentation with Utterance-Pair  Coherence Scoring",
    "abstract": "Dialogue topic segmentation is critical in several dialogue modeling\nproblems. However, popular unsupervised approaches only exploit surface\nfeatures in assessing topical coherence among utterances. In this work, we\naddress this limitation by leveraging supervisory signals from the\nutterance-pair coherence scoring task. First, we present a simple yet effective\nstrategy to generate a training corpus for utterance-pair coherence scoring.\nThen, we train a BERT-based neural utterance-pair coherence model with the\nobtained training corpus. Finally, such model is used to measure the topical\nrelevance between utterances, acting as the basis of the segmentation\ninference. Experiments on three public datasets in English and Chinese\ndemonstrate that our proposal outperforms the state-of-the-art baselines.",
    "descriptor": "\nComments: Long paper accepted at SIGDIAL 2021\n",
    "authors": [
      "Linzi Xing",
      "Giuseppe Carenini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06719"
  },
  {
    "id": "arXiv:2106.06720",
    "title": "BIOPAK Flasher: Epidemic disease monitoring and detection in Pakistan  using text mining",
    "abstract": "Infectious disease outbreak has a significant impact on morbidity, mortality\nand can cause economic instability of many countries. As global trade is\ngrowing, goods and individuals are expected to travel across the border, an\ninfected epidemic area carrier can pose a great danger to his hostile. If a\ndisease outbreak is recognized promptly, then commercial products and travelers\n(traders/visitors) will be effectively vaccinated, and therefore the disease\nstopped. Early detection of outbreaks plays an important role here, and beware\nof the rapid implementation of control measures by citizens, public health\norganizations, and government. Many indicators have valuable information, such\nas online news sources (RSS) and social media sources (Twitter, Facebook) that\ncan be used, but are unstructured and bulky, to extract information about\ndisease outbreaks. Few early warning outbreak systems exist with some\nlimitation of linguistic (Urdu) and covering areas (Pakistan). In Pakistan, few\nchannels are published the outbreak news in Urdu or English. The aim is to\nprocure information from Pakistan's English and Urdu news channels and then\ninvestigate process, integrate, and visualize the disease epidemic. Urdu\nontology is not existed before to match extracted diseases, so we also build\nthat ontology of disease.",
    "descriptor": "\nComments: Paper is accepted in SOFTA 2020\n",
    "authors": [
      "Muhammad Nasir",
      "Maheen Bakhtyar",
      "Junaid Baber",
      "Sadia Lakho",
      "Bilal Ahmed",
      "Waheed Noor"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06720"
  },
  {
    "id": "arXiv:2106.06721",
    "title": "A use case of Content Delivery Network raw logfile analysis",
    "abstract": "The growth of video streaming has stretched the Internet to its limitation.\nIn other words, the Internet was originally devised to connect a limited number\nof computers so that they can share network resources, so the Internet cannot\nhandle a large amount of traffic at a time, which leads to network congestion.\nTo overcome this, CDNs are built on top of the Internet as an overlay to\nefficiently store and swiftly disseminate contents to users by placing many\nservers and data centers around the globe. The topic of CDNs has been\nextensively studied in the last several decades. However, there is still a\ncertain gap between theories in academia and current technologies in industry.\nIn this paper, we take a close look at the design, implementation, solution,\nand performance of a CDN system by analyzing its raw log files. Specifically,\nits infrastructure and system design are first presented, and then we conduct a\ntrace-based study to understand user access patterns, the sources of requests,\nsystem performance, and how such information can be used to improve the whole\nCDN system.",
    "descriptor": "",
    "authors": [
      "Hoang-Loc La",
      "Anh-Tu Ngoc Tran",
      "Quang-Trai Le",
      "Masato Yoshimi",
      "Takuma Nakajima",
      "Nam Thoai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.06721"
  },
  {
    "id": "arXiv:2106.06722",
    "title": "Curriculum Pre-Training Heterogeneous Subgraph Transformer for Top-$N$  Recommendation",
    "abstract": "Due to the flexibility in modelling data heterogeneity, heterogeneous\ninformation network (HIN) has been adopted to characterize complex and\nheterogeneous auxiliary data in top-$N$ recommender systems, called\n\\emph{HIN-based recommendation}. HIN characterizes complex, heterogeneous data\nrelations, containing a variety of information that may not be related to the\nrecommendation task. Therefore, it is challenging to effectively leverage\nuseful information from HINs for improving the recommendation performance. To\naddress the above issue, we propose a Curriculum pre-training based\nHEterogeneous Subgraph Transformer (called \\emph{CHEST}) with new \\emph{data\ncharacterization}, \\emph{representation model} and \\emph{learning algorithm}.\nSpecifically, we consider extracting useful information from HIN to compose\nthe interaction-specific heterogeneous subgraph, containing both sufficient and\nrelevant context information for recommendation. Then we capture the rich\nsemantics (\\eg graph structure and path semantics) within the subgraph via a\nheterogeneous subgraph Transformer, where we encode the subgraph with\nmulti-slot sequence representations. Besides, we design a curriculum\npre-training strategy to provide an elementary-to-advanced learning process, by\nwhich we smoothly transfer basic semantics in HIN for modeling user-item\ninteraction relation.\nExtensive experiments conducted on three real-world datasets demonstrate the\nsuperiority of our proposed method over a number of competitive baselines,\nespecially when only limited training data is available.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Hui Wang",
      "Kun Zhou",
      "Wayne Xin Zhao",
      "Jingyuan Wang",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.06722"
  },
  {
    "id": "arXiv:2106.06726",
    "title": "Go Small and Similar: A Simple Output Decay Brings Better Performance",
    "abstract": "Regularization and data augmentation methods have been widely used and become\nincreasingly indispensable in deep learning training. Researchers who devote\nthemselves to this have considered various possibilities. But so far, there has\nbeen little discussion about regularizing outputs of the model. This paper\nbegins with empirical observations that better performances are significantly\nassociated with output distributions, that have smaller average values and\nvariances. By audaciously assuming there is causality involved, we propose a\nnovel regularization term, called Output Decay, that enforces the model to\nassign smaller and similar output values on each class. Though being\ncounter-intuitive, such a small modification result in a remarkable improvement\non performance. Extensive experiments demonstrate the wide applicability,\nversatility, and compatibility of Output Decay.",
    "descriptor": "",
    "authors": [
      "Xuan Cheng",
      "Tianshu Xie",
      "Xiaomin Wang",
      "Jiali Deng",
      "Minghui Liu",
      "Ming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06726"
  },
  {
    "id": "arXiv:2106.06731",
    "title": "Incorporating External POS Tagger for Punctuation Restoration",
    "abstract": "Punctuation restoration is an important post-processing step in automatic\nspeech recognition. Among other kinds of external information, part-of-speech\n(POS) taggers provide informative tags, suggesting each input token's syntactic\nrole, which has been shown to be beneficial for the punctuation restoration\ntask. In this work, we incorporate an external POS tagger and fuse its\npredicted labels into the existing language model to provide syntactic\ninformation. Besides, we propose sequence boundary sampling (SBS) to learn\npunctuation positions more efficiently as a sequence tagging task. Experimental\nresults show that our methods can consistently obtain performance gains and\nachieve a new state-of-the-art on the common IWSLT benchmark. Further ablation\nstudies illustrate that both large pre-trained language models and the external\nPOS tagger take essential parts to improve the model's performance.",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Ning Shi",
      "Wei Wang",
      "Boxin Wang",
      "Jinfeng Li",
      "Xiangyu Liu",
      "Zhouhan Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06731"
  },
  {
    "id": "arXiv:2106.06733",
    "title": "LE-NAS: Learning-based Ensenble with NAS for Dose Prediction",
    "abstract": "Radiation therapy treatment planning is a complex process, as the target dose\nprescription and normal tissue sparing are conflicting objectives. Automated\nand accurate dose prediction for radiation therapy planning is in high demand.\nIn this study, we propose a novel learning-based ensemble approach, named\nLE-NAS, which integrates neural architecture search (NAS) with knowledge\ndistillation for 3D radiotherapy dose prediction. Specifically, the prediction\nnetwork first exhaustively searches each block from enormous architecture\nspace. Then, multiple architectures are selected with promising performance and\ndiversity. To reduce the inference time, we adopt the teacher-student paradigm\nby treating the combination of diverse outputs from multiple searched networks\nas supervisions to guide the student network training. In addition, we apply\nadversarial learning to optimize the student network to recover the knowledge\nin teacher networks. To the best of our knowledge, we are the first to\ninvestigate the combination of NAS and knowledge distillation. The proposed\nmethod has been evaluated on the public OpenKBP dataset, and experimental\nresults demonstrate the effectiveness of our method and its superior\nperformance to the state-of-the-art method.",
    "descriptor": "",
    "authors": [
      "Yi Lin",
      "Yanfei Liu",
      "Jingguang Liu",
      "Guocai Liu",
      "Kai Ma",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06733"
  },
  {
    "id": "arXiv:2106.06736",
    "title": "Multi-level Attention Fusion Network for Audio-visual Event Recognition",
    "abstract": "Event classification is inherently sequential and multimodal. Therefore, deep\nneural models need to dynamically focus on the most relevant time window and/or\nmodality of a video. In this study, we propose the Multi-level Attention Fusion\nnetwork (MAFnet), an architecture that can dynamically fuse visual and audio\ninformation for event recognition. Inspired by prior studies in neuroscience,\nwe couple both modalities at different levels of visual and audio paths.\nFurthermore, the network dynamically highlights a modality at a given time\nwindow relevant to classify events. Experimental results in AVE (Audio-Visual\nEvent), UCF51, and Kinetics-Sounds datasets show that the approach can\neffectively improve the accuracy in audio-visual event classification. Code is\navailable at: https://github.com/numediart/MAFnet",
    "descriptor": "\nComments: Preprint submitted to the Information Fusion journal in August 2020\n",
    "authors": [
      "Mathilde Brousmiche",
      "Jean Rouat",
      "St\u00e9phane Dupont"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.06736"
  },
  {
    "id": "arXiv:2106.06738",
    "title": "A Sentence-level Hierarchical BERT Model for Document Classification  with Limited Labelled Data",
    "abstract": "Training deep learning models with limited labelled data is an attractive\nscenario for many NLP tasks, including document classification. While with the\nrecent emergence of BERT, deep learning language models can achieve reasonably\ngood performance in document classification with few labelled instances, there\nis a lack of evidence in the utility of applying BERT-like models on long\ndocument classification. This work introduces a long-text-specific model -- the\nHierarchical BERT Model (HBM) -- that learns sentence-level features of the\ntext and works well in scenarios with limited labelled data. Various evaluation\nexperiments have demonstrated that HBM can achieve higher performance in\ndocument classification than the previous state-of-the-art methods with only 50\nto 200 labelled instances, especially when documents are long. Also, as an\nextra benefit of HBM, the salient sentences identified by learned HBM are\nuseful as explanations for labelling documents based on a user study.",
    "descriptor": "",
    "authors": [
      "Jinghui Lu",
      "Maeve Henchion",
      "Ivan Bacher",
      "Brian Mac Namee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06738"
  },
  {
    "id": "arXiv:2106.06739",
    "title": "Engineering Knowledge Graph from Patent Database",
    "abstract": "We propose a large, scalable engineering knowledge graph, comprising sets of\n(entity, relationship, entity) triples that are real-world engineering facts\nfound in the patent database. We apply a set of rules based on the syntactic\nand lexical properties of claims in a patent document to extract facts. We\naggregate these facts within each patent document and integrate the aggregated\nsets of facts across the patent database to obtain the engineering knowledge\ngraph. Such a knowledge graph is expected to support inference, reasoning, and\nrecalling in various engineering tasks. The knowledge graph has a greater size\nand coverage in comparison with the previously used knowledge graphs and\nsemantic networks in the engineering literature.",
    "descriptor": "",
    "authors": [
      "L Siddharth",
      "Lucienne T.M. Blessing",
      "Kristin L. Wood",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.06739"
  },
  {
    "id": "arXiv:2106.06742",
    "title": "Task Transformer Network for Joint MRI Reconstruction and  Super-Resolution",
    "abstract": "The core problem of Magnetic Resonance Imaging (MRI) is the trade off between\nacceleration and image quality. Image reconstruction and super-resolution are\ntwo crucial techniques in Magnetic Resonance Imaging (MRI). Current methods are\ndesigned to perform these tasks separately, ignoring the correlations between\nthem. In this work, we propose an end-to-end task transformer network\n(T$^2$Net) for joint MRI reconstruction and super-resolution, which allows\nrepresentations and feature transmission to be shared between multiple task to\nachieve higher-quality, super-resolved and motion-artifacts-free images from\nhighly undersampled and degenerated MRI data. Our framework combines both\nreconstruction and super-resolution, divided into two sub-branches, whose\nfeatures are expressed as queries and keys. Specifically, we encourage joint\nfeature learning between the two tasks, thereby transferring accurate task\ninformation. We first use two separate CNN branches to extract task-specific\nfeatures. Then, a task transformer module is designed to embed and synthesize\nthe relevance between the two tasks. Experimental results show that our\nmulti-task model significantly outperforms advanced sequential methods, both\nquantitatively and qualitatively.",
    "descriptor": "",
    "authors": [
      "Chun-Mei Feng",
      "Yunlu Yan",
      "Huazhu Fu",
      "Li Chen",
      "Yong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06742"
  },
  {
    "id": "arXiv:2106.06744",
    "title": "DeepMMSA: A Novel Multimodal Deep Learning Method for Non-small Cell  Lung Cancer Survival Analysis",
    "abstract": "Lung cancer is the leading cause of cancer death worldwide. The critical\nreason for the deaths is delayed diagnosis and poor prognosis. With the\naccelerated development of deep learning techniques, it has been successfully\napplied extensively in many real-world applications, including health sectors\nsuch as medical image interpretation and disease diagnosis. By combining more\nmodalities that being engaged in the processing of information, multimodal\nlearning can extract better features and improve predictive ability. The\nconventional methods for lung cancer survival analysis normally utilize\nclinical data and only provide a statistical probability. To improve the\nsurvival prediction accuracy and help prognostic decision-making in clinical\npractice for medical experts, we for the first time propose a multimodal deep\nlearning method for non-small cell lung cancer (NSCLC) survival analysis, named\nDeepMMSA. This method leverages CT images in combination with clinical data,\nenabling the abundant information hold within medical images to be associate\nwith lung cancer survival information. We validate our method on the data of\n422 NSCLC patients from The Cancer Imaging Archive (TCIA). Experimental results\nsupport our hypothesis that there is an underlying relationship between\nprognostic information and radiomic images. Besides, quantitative results\nshowing that the established multimodal model can be applied to traditional\nmethod and has the potential to break bottleneck of existing methods and\nincrease the the percentage of concordant pairs(right predicted pairs) in\noverall population by 4%.",
    "descriptor": "\nComments: 7 Submitted to IEEE TBME\n",
    "authors": [
      "Yujiao Wu",
      "Jie Ma",
      "Xiaoshui Huang",
      "Sai Ho Ling",
      "Steven Weidong Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06744"
  },
  {
    "id": "arXiv:2106.06745",
    "title": "Minimization and Canonization of GFG Transition-Based Automata",
    "abstract": "While many applications of automata in formal methods can use\nnondeterministic automata, some applications, most notably synthesis, need\ndeterministic or good-for-games(GFG) automata. The latter are nondeterministic\nautomata that can resolve their nondeterministic choices in a way that only\ndepends on the past. The minimization problem for deterministic B\\\"uchi and\nco-B\\\"uchi word automata is NP-complete. In particular, no canonical minimal\ndeterministic automaton exists, and a language may have different minimal\ndeterministic automata. We describe a polynomial minimization algorithm for GFG\nco-B\\\"uchi word automata with transition-based acceptance. Thus, a run is\naccepting if it traverses a set $\\alpha$ of designated transitions only\nfinitely often. Our algorithm is based on a sequence of transformations we\napply to the automaton, on top of which a minimal quotient automaton is\ndefined. We use our minimization algorithm to show canonicity for\ntransition-based GFG co-B\\\"uchi word automata: all minimal automata have\nisomorphic safe components (namely components obtained by restricting the\ntransitions to these not in $\\alpha$) and once we saturate the automata with\n$\\alpha$-transitions, we get full isomorphism.",
    "descriptor": "\nComments: 28 pages, 9 figures. arXiv admin note: substantial text overlap with arXiv:2009.10885\n",
    "authors": [
      "Bader Abu Radi",
      "Orna Kupferman"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.06745"
  },
  {
    "id": "arXiv:2106.06747",
    "title": "On the Impact of Security Vulnerabilities in the npm and RubyGems  Dependency Networks",
    "abstract": "The increasing interest in open source software has led to the emergence of\nlarge package distributions of reusable software libraries, such as npm and\nRubyGems. These software packages can be subject to security vulnerabilities\nthat may expose dependent packages through explicitly declared dependencies.\nThis article empirically studies security vulnerabilities affecting npm and\nRubyGems packages. We analyse how and when these vulnerabilities are discovered\nand fixed, and how their prevalence changes over time. We also analyse how\nvulnerable packages expose their direct and indirect dependents to\nvulnerabilities. We distinguish between two types of dependents: packages\ndistributed via the package manager, and external GitHub projects. Compared to\nRubyGems, we observe that the number of vulnerabilities is increasing faster in\nnpm, but vulnerabilities are also discovered faster in npm. For both package\ndistributions, the time required to discover vulnerabilities is increasing, but\nnpm is improving the time needed to fix vulnerabilities. A large proportion of\nexternal GitHub projects are exposed to vulnerabilities coming from direct or\nindirect dependencies. Around one out of three direct vulnerable dependencies\nto which projects or packages are exposed could be avoided, if software\ndevelopers would update their dependencies to more recent releases within the\nsame major release range.",
    "descriptor": "",
    "authors": [
      "Ahmed Zerouali",
      "Tom Mens",
      "Alexandre Decan",
      "Coen De Roover"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.06747"
  },
  {
    "id": "arXiv:2106.06749",
    "title": "Decreasing scaling transition from adaptive gradient descent to  stochastic gradient descent",
    "abstract": "Currently, researchers have proposed the adaptive gradient descent algorithm\nand its variants, such as AdaGrad, RMSProp, Adam, AmsGrad, etc. Although these\nalgorithms have a faster speed in the early stage, the generalization ability\nin the later stage of training is often not as good as the stochastic gradient\ndescent. Recently, some researchers have combined the adaptive gradient descent\nand stochastic gradient descent to obtain the advantages of both and achieved\ngood results. Based on this research, we propose a decreasing scaling\ntransition from adaptive gradient descent to stochastic gradient descent\nmethod(DSTAda). For the training stage of the stochastic gradient descent, we\nuse a learning rate that decreases linearly with the number of iterations\ninstead of a constant learning rate. We achieve a smooth and stable transition\nfrom adaptive gradient descent to stochastic gradient descent through scaling.\nAt the same time, we give a theoretical proof of the convergence of DSTAda\nunder the framework of online learning. Our experimental results show that the\nDSTAda algorithm has a faster convergence speed, higher accuracy, and better\nstability and robustness. Our implementation is available at:\nhttps://github.com/kunzeng/DSTAdam.",
    "descriptor": "\nComments: 23pages, 19figures\n",
    "authors": [
      "Kun Zeng",
      "Jinlan Liu",
      "Zhixia Jiang",
      "Dongpo Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06749"
  },
  {
    "id": "arXiv:2106.06751",
    "title": "Guiding Teacher Forcing with Seer Forcing for Neural Machine Translation",
    "abstract": "Although teacher forcing has become the main training paradigm for neural\nmachine translation, it usually makes predictions only conditioned on past\ninformation, and hence lacks global planning for the future. To address this\nproblem, we introduce another decoder, called seer decoder, into the\nencoder-decoder framework during training, which involves future information in\ntarget predictions. Meanwhile, we force the conventional decoder to simulate\nthe behaviors of the seer decoder via knowledge distillation. In this way, at\ntest the conventional decoder can perform like the seer decoder without the\nattendance of it. Experiment results on the Chinese-English, English-German and\nEnglish-Romanian translation tasks show our method can outperform competitive\nbaselines significantly and achieves greater improvements on the bigger data\nsets. Besides, the experiments also prove knowledge distillation the best way\nto transfer knowledge from the seer decoder to the conventional decoder\ncompared to adversarial learning and L2 regularization.",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021 main conference\n",
    "authors": [
      "Yang Feng",
      "Shuhao Gu",
      "Dengji Guo",
      "Zhengxin Yang",
      "Chenze Shao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06751"
  },
  {
    "id": "arXiv:2106.06753",
    "title": "Scaling transition from momentum stochastic gradient descent to plain  stochastic gradient descent",
    "abstract": "The plain stochastic gradient descent and momentum stochastic gradient\ndescent have extremely wide applications in deep learning due to their simple\nsettings and low computational complexity. The momentum stochastic gradient\ndescent uses the accumulated gradient as the updated direction of the current\nparameters, which has a faster training speed. Because the direction of the\nplain stochastic gradient descent has not been corrected by the accumulated\ngradient. For the parameters that currently need to be updated, it is the\noptimal direction, and its update is more accurate. We combine the advantages\nof the momentum stochastic gradient descent with fast training speed and the\nplain stochastic gradient descent with high accuracy, and propose a scaling\ntransition from momentum stochastic gradient descent to plain stochastic\ngradient descent(TSGD) method. At the same time, a learning rate that decreases\nlinearly with the iterations is used instead of a constant learning rate. The\nTSGD algorithm has a larger step size in the early stage to speed up the\ntraining, and training with a smaller step size in the later stage can steadily\nconverge. Our experimental results show that the TSGD algorithm has faster\ntraining speed, higher accuracy and better stability. Our implementation is\navailable at: https://github.com/kunzeng/TSGD.",
    "descriptor": "\nComments: 16 pages, 18 figures\n",
    "authors": [
      "Kun Zeng",
      "Jinlan Liu",
      "Zhixia Jiang",
      "Dongpo Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06753"
  },
  {
    "id": "arXiv:2106.06755",
    "title": "FPT Approximation for Socially Fair Clustering",
    "abstract": "In this work, we study the socially fair $k$-median/$k$-means problem. We are\ngiven a set of points $P$ in a metric space $\\mathcal{X}$ with a distance\nfunction $d(.,.)$. There are $\\ell$ groups: $P_1,\\dotsc,P_{\\ell} \\subseteq P$.\nWe are also given a set $F$ of feasible centers in $\\mathcal{X}$. The goal of\nthe socially fair $k$-median problem is to find a set $C \\subseteq F$ of $k$\ncenters that minimizes the maximum average cost over all the groups. That is,\nfind $C$ that minimizes the objective function $\\Phi(C,P) \\equiv \\max_{j}\n\\sum_{x \\in P_j} d(C,x)/|P_j|$, where $d(C,x)$ is the distance of $x$ to the\nclosest center in $C$. The socially fair $k$-means problem is defined similarly\nby using squared distances, i.e., $d^{2}(.,.)$ instead of $d(.,.)$. In this\nwork, we design $(5+\\varepsilon)$ and $(33 + \\varepsilon)$ approximation\nalgorithms for the socially fair $k$-median and $k$-means problems,\nrespectively. For the parameters: $k$ and $\\ell$, the algorithms have an FPT\n(fixed parameter tractable) running time of $f(k,\\ell,\\varepsilon) \\cdot n$ for\n$f(k,\\ell,\\varepsilon) = 2^{{O}(k \\, \\ell/\\varepsilon)}$ and $n = |P \\cup F|$.\nWe also study a special case of the problem where the centers are allowed to be\nchosen from the point set $P$, i.e., $P \\subseteq F$. For this special case,\nour algorithms give better approximation guarantees of $(4+\\varepsilon)$ and\n$(18+\\varepsilon)$ for the socially fair $k$-median and $k$-means problems,\nrespectively. Furthermore, we convert these algorithms to constant pass\nlog-space streaming algorithms. Lastly, we show FPT hardness of approximation\nresults for the problem with a small gap between our upper and lower bounds.",
    "descriptor": "\nComments: 11 pages, 1 figure\n",
    "authors": [
      "Dishant Goyal",
      "Ragesh Jaiswal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06755"
  },
  {
    "id": "arXiv:2106.06758",
    "title": "Every Bite Is an Experience: Key Point Analysis of Business Reviews",
    "abstract": "Previous work on review summarization focused on measuring the sentiment\ntoward the main aspects of the reviewed product or business, or on creating a\ntextual summary. These approaches provide only a partial view of the data:\naspect-based sentiment summaries lack sufficient explanation or justification\nfor the aspect rating, while textual summaries do not quantify the significance\nof each element, and are not well-suited for representing conflicting views.\nRecently, Key Point Analysis (KPA) has been proposed as a summarization\nframework that provides both textual and quantitative summary of the main\npoints in the data. We adapt KPA to review data by introducing Collective Key\nPoint Mining for better key point extraction; integrating sentiment analysis\ninto KPA; identifying good key point candidates for review summaries; and\nleveraging the massive amount of available reviews and their metadata. We show\nempirically that these novel extensions of KPA substantially improve its\nperformance. We demonstrate that promising results can be achieved without any\ndomain-specific annotation, while human supervision can lead to further\nimprovement.",
    "descriptor": "\nComments: ACL-IJCNLP 2021\n",
    "authors": [
      "Roy Bar-Haim",
      "Lilach Eden",
      "Yoav Kantor",
      "Roni Friedman",
      "Noam Slonim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06758"
  },
  {
    "id": "arXiv:2106.06761",
    "title": "Relearning ensemble selection based on new generated features",
    "abstract": "The ensemble methods are meta-algorithms that combine several base machine\nlearning techniques to increase the effectiveness of the classification. Many\nexisting committees of classifiers use the classifier selection process to\ndetermine the optimal set of base classifiers. In this article, we propose the\nclassifiers selection framework with relearning base classifiers. Additionally,\nwe use in the proposed framework the new generated feature, which can be\nobtained after the relearning process. The proposed technique was compared with\nstate-of-the-art ensemble methods using three benchmark datasets and one\nsynthetic dataset. Four classification performance measures are used to\nevaluate the proposed method.",
    "descriptor": "",
    "authors": [
      "Robert Burduk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06761"
  },
  {
    "id": "arXiv:2106.06762",
    "title": "Solving Graph-based Public Good Games with Tree Search and Imitation  Learning",
    "abstract": "Public goods games represent insightful settings for studying incentives for\nindividual agents to make contributions that, while costly for each of them,\nbenefit the wider society. In this work, we adopt the perspective of a central\nplanner with a global view of a network of self-interested agents and the goal\nof maximizing some desired property in the context of a best-shot public goods\ngame. Existing algorithms for this known NP-complete problem find solutions\nthat are sub-optimal and cannot optimize for criteria other than social\nwelfare.\nIn order to efficiently solve public goods games, our proposed method\ndirectly exploits the correspondence between equilibria and the Maximal\nIndependent Set (mIS) structural property of graphs. In particular, we define a\nMarkov Decision Process, which incrementally generates an mIS, and adopt a\nplanning method to search for equilibria, outperforming existing methods.\nFurthermore, we devise an imitation learning technique that uses demonstrations\nof the search to obtain a graph neural network parametrized policy which\nquickly generalizes to unseen game instances. Our evaluation results show that\nthis policy is able to reach 99.5% of the performance of the planning method\nwhile being approximately three orders of magnitude faster to evaluate on the\nlargest graphs tested. The methods presented in this work can be applied to a\nlarge class of public goods games of potentially high societal impact.",
    "descriptor": "",
    "authors": [
      "Victor-Alexandru Darvariu",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.06762"
  },
  {
    "id": "arXiv:2106.06765",
    "title": "Towards a Privacy-preserving Deep Learning-based Network Intrusion  Detection in Data Distribution Services",
    "abstract": "Data Distribution Service (DDS) is an innovative approach towards\ncommunication in ICS/IoT infrastructure and robotics. Being based on the\ncross-platform and cross-language API to be applicable in any computerised\ndevice, it offers the benefits of modern programming languages and the\nopportunities to develop more complex and advanced systems. However, the DDS\ncomplexity equally increases its vulnerability, while the existing security\nmeasures are limited to plug-ins and static rules, with the rest of the\nsecurity provided by third-party applications and operating system.\nSpecifically, traditional intrusion detection systems (IDS) do not detect any\nanomalies in the publish/subscribe method. With the exponentially growing\nglobal communication exchange, securing DDS is of the utmost importance to\nfutureproofing industrial, public, and even personal devices and systems. This\nreport presents an experimental work on the simulation of several specific\nattacks against DDS, and the application of Deep Learning for their detection.\nThe findings show that even though Deep Learning allows to detect all simulated\nattacks using only metadata analysis, their detection level varies, with some\nof the advanced attacks being harder to detect. The limitations imposed by the\nattempts to preserve privacy significantly decrease the detection rate. The\nreport also reviews the drawbacks and limitations of the Deep Learning approach\nand proposes a set of selected solutions and configurations, that can further\nimprove the DDS security.",
    "descriptor": "",
    "authors": [
      "Stanislav Abaimov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.06765"
  },
  {
    "id": "arXiv:2106.06766",
    "title": "Exploiting Parallel Corpora to Improve Multilingual Embedding based  Document and Sentence Alignment",
    "abstract": "Multilingual sentence representations pose a great advantage for low-resource\nlanguages that do not have enough data to build monolingual models on their\nown. These multilingual sentence representations have been separately exploited\nby few research for document and sentence alignment. However, most of the\nlow-resource languages are under-represented in these pre-trained models. Thus,\nin the context of low-resource languages, these models have to be fine-tuned\nfor the task at hand, using additional data sources. This paper presents a\nweighting mechanism that makes use of available small-scale parallel corpora to\nimprove the performance of multilingual sentence representations on document\nand sentence alignment. Experiments are conducted with respect to two\nlow-resource languages, Sinhala and Tamil. Results on a newly created dataset\nof Sinhala-English, Tamil-English, and Sinhala-Tamil show that this new\nweighting mechanism significantly improves both document and sentence\nalignment. This dataset, as well as the source-code, is publicly released.",
    "descriptor": "\nComments: 21 pages, 2 images\n",
    "authors": [
      "Dilan Sachintha",
      "Lakmali Piyarathna",
      "Charith Rajitha",
      "Surangika Ranathunga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06766"
  },
  {
    "id": "arXiv:2106.06768",
    "title": "Planning Spatial Networks",
    "abstract": "We tackle the problem of goal-directed graph construction: given a starting\ngraph, a global objective function (e.g., communication efficiency), and a\nbudget of modifications, the aim is to find a set of edges whose addition to\nthe graph maximally improves the objective. This problem emerges in many\nnetworks of great importance for society such as transportation and critical\ninfrastructure networks. We identify two significant shortcomings with present\nmethods. Firstly, they focus exclusively on network topology while ignoring\nspatial information; however, in many real-world networks, nodes are embedded\nin space, which yields different global objectives and governs the range and\ndensity of realizable connections. Secondly, existing RL methods scale poorly\nto large networks due to the high cost of training a model and the scaling\nfactors of the action space and global objectives.\nIn this work, we formulate the problem of goal-directed construction of\nspatial networks as a deterministic MDP. We adopt the Monte Carlo Tree Search\nframework for planning in this domain, prioritizing the optimality of final\nsolutions over the speed of policy evaluation. We propose several improvements\nover the standard UCT algorithm for this family of problems, addressing their\nsingle-agent nature, the trade-off between the costs of edges and their\ncontribution to the objective, and an action space linear in the number of\nnodes. We demonstrate the suitability of this approach for improving the global\nefficiency and attack resilience of a variety of synthetic and real-world\nnetworks, including Internet backbone networks and metro systems. We obtain 24%\nbetter solutions on average compared to UCT on the largest networks tested, and\nscalability superior to previous methods.",
    "descriptor": "",
    "authors": [
      "Victor-Alexandru Darvariu",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06768"
  },
  {
    "id": "arXiv:2106.06769",
    "title": "Cross-Subject Domain Adaptation for Multi-Frame EEG Images",
    "abstract": "Working memory (WM) is a basic part of human cognition, which plays an\nimportant role in the study of human cognitive load. Among various brain\nimaging techniques, electroencephalography has shown its advantage on easy\naccess and reliability. However, one of the critical challenges is that\nindividual difference may cause the ineffective results, especially when the\nestablished model meets an unfamiliar subject. In this work, we propose a\ncross-subject deep adaptation model with spatial attention (CS-DASA) to\ngeneralize the workload classifications across subjects. First, we transform\ntime-series EEG data into multi-frame EEG images incorporating more\nspatio-temporal information. First, the subject-shared module in CS-DASA\nreceives multi-frame EEG image data from both source and target subjects and\nlearns the common feature representations. Then, in subject-specific module,\nthe maximum mean discrepancy is implemented to measure the domain distribution\ndivergence in a reproducing kernel Hilbert space, which can add an effective\npenalty loss for domain adaptation. Additionally, the subject-to-subject\nspatial attention mechanism is employed to focus on the most discriminative\nspatial feature in EEG image data. Experiments conducted on a public WM EEG\ndataset containing 13 subjects show that the proposed model is capable of\nachieve better performance than existing state-of-the art methods.",
    "descriptor": "",
    "authors": [
      "Junfu Chen",
      "Yang Chen",
      "Bi Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06769"
  },
  {
    "id": "arXiv:2106.06770",
    "title": "What can linearized neural networks actually say about generalization?",
    "abstract": "For certain infinitely-wide neural networks, the neural tangent kernel (NTK)\ntheory fully characterizes generalization. However, for the networks used in\npractice, the empirical NTK represents only a rough first-order approximation\nof these architectures. Still, a growing body of work keeps leveraging this\napproximation to successfully analyze important deep learning phenomena and\nderive algorithms for new applications. In our work, we provide strong\nempirical evidence to determine the practical validity of such approximation by\nconducting a systematic comparison of the behaviour of different neural\nnetworks and their linear approximations on different tasks. We show that the\nlinear approximations can indeed rank the learning complexity of certain tasks\nfor neural networks, albeit with important nuances. Specifically, we discover\nthat, in contrast to what was previously observed, neural networks do not\nalways perform better than their kernel approximations, and reveal that their\nperformance gap heavily depends on architecture, number of samples and training\ntask. In fact, we show that during training, deep networks increase the\nalignment of their empirical NTK with the target task, which explains why\nlinear approximations at the end of training can better explain the dynamics of\ndeep networks. Overall, our work provides concrete examples of novel deep\nlearning phenomena which can inspire future theoretical research, as well as\nprovides a new perspective on the use of the NTK approximation in deep\nlearning.",
    "descriptor": "\nComments: 17 pages, 15 figures\n",
    "authors": [
      "Guillermo Ortiz-Jim\u00e9nez",
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06770"
  },
  {
    "id": "arXiv:2106.06772",
    "title": "A Mixed-Integer Linear Programming Formulation for Human Multi-Robot  Task Allocation",
    "abstract": "In this work, we address a task allocation problem for human multi-robot\nsettings. Given a set of tasks to perform, we formulate a general Mixed-Integer\nLinear Programming (MILP) problem aiming at minimizing the overall execution\ntime while optimizing the quality of the executed tasks as well as human and\nrobotic workload. Different skills of the agents, both human and robotic, are\ntaken into account and human operators are enabled to either directly execute\ntasks or play supervisory roles; moreover, multiple manipulators can tightly\ncollaborate if required to carry out a task. Finally, as realistic in human\ncontexts, human parameters are assumed to vary over time, e.g., due to\nincreasing human level of fatigue. Therefore, online monitoring is required and\nre-allocation is performed if needed. Simulations in a realistic scenario with\ntwo manipulators and a human operator performing an assembly task validate the\neffectiveness of the approach.",
    "descriptor": "\nComments: Accepted to 2021 IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)\n",
    "authors": [
      "Martina Lippi",
      "Alessandro Marino"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.06772"
  },
  {
    "id": "arXiv:2106.06776",
    "title": "A piecewise ellipsoidal reachable set estimation method for continuous  bimodal piecewise affine systems",
    "abstract": "In this work, the issue of estimation of reachable sets in continuous bimodal\npiecewise affine systems is studied. A new method is proposed, in the framework\nof ellipsoidal bounding, using piecewise quadratic Lyapunov functions. Although\nbimodal piecewise affine systems can be seen as a special class of affine\nhybrid systems, reachability methods developed for affine hybrid systems might\nbe inappropriately complex for bimodal dynamics. This work goes in the\ndirection of exploiting the dynamical structure of the system to propose a\nsimpler approach. More specifically, because of the piecewise nature of the\nLyapunov function, we first derive conditions to ensure that a given quadratic\nfunction is positive on half spaces. Then, we exploit the property of bimodal\npiecewise quadratic functions being continuous on a given hyperplane. Finally,\nlinear matrix characterizations of the estimate of the reachable set are\nderived.",
    "descriptor": "",
    "authors": [
      "Thuan Le Quang",
      "Nam Phan Thanh",
      "Simone Baldi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06776"
  },
  {
    "id": "arXiv:2106.06777",
    "title": "Model-free Reinforcement Learning for Branching Markov Decision  Processes",
    "abstract": "We study reinforcement learning for the optimal control of Branching Markov\nDecision Processes (BMDPs), a natural extension of (multitype) Branching Markov\nChains (BMCs). The state of a (discrete-time) BMCs is a collection of entities\nof various types that, while spawning other entities, generate a payoff. In\ncomparison with BMCs, where the evolution of a each entity of the same type\nfollows the same probabilistic pattern, BMDPs allow an external controller to\npick from a range of options. This permits us to study the best/worst behaviour\nof the system. We generalise model-free reinforcement learning techniques to\ncompute an optimal control strategy of an unknown BMDP in the limit. We present\nresults of an implementation that demonstrate the practicality of the approach.",
    "descriptor": "\nComments: to appear in CAV 2021\n",
    "authors": [
      "Ernst Moritz Hahn",
      "Mateo Perez",
      "Sven Schewe",
      "Fabio Somenzi",
      "Ashutosh Trivedi",
      "Dominik Wojtczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06777"
  },
  {
    "id": "arXiv:2106.06778",
    "title": "Dynamic Clone Transformer for Efficient Convolutional Neural Netwoks",
    "abstract": "Convolutional networks (ConvNets) have shown impressive capability to solve\nvarious vision tasks. Nevertheless, the trade-off between performance and\nefficiency is still a challenge for a feasible model deployment on\nresource-constrained platforms. In this paper, we introduce a novel concept\ntermed multi-path fully connected pattern (MPFC) to rethink the\ninterdependencies of topology pattern, accuracy and efficiency for ConvNets.\nInspired by MPFC, we further propose a dual-branch module named dynamic clone\ntransformer (DCT) where one branch generates multiple replicas from inputs and\nanother branch reforms those clones through a series of difference vectors\nconditional on inputs itself to produce more variants. This operation allows\nthe self-expansion of channel-wise information in a data-driven way with little\ncomputational cost while providing sufficient learning capacity, which is a\npotential unit to replace computationally expensive pointwise convolution as an\nexpansion layer in the bottleneck structure.",
    "descriptor": "",
    "authors": [
      "Longqing Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06778"
  },
  {
    "id": "arXiv:2106.06780",
    "title": "Multi-Context Systems: Dynamics and Evolution (Pre-Print of  \"Multi-context systems in dynamic environments\")",
    "abstract": "Multi-Context Systems (MCS) model in Computational Logic distributed systems\ncomposed of heterogeneous sources, or \"contexts\", interacting via special rules\ncalled \"bridge rules\". In this paper, we consider how to enhance flexibility\nand generality in bridge-rules definition and application. In particular, we\nintroduce and discuss some formal extensions of MCSs useful for a practical use\nin dynamic environments, and we try to provide guidelines for implementations",
    "descriptor": "\nComments: 35 pages 2 figures\n",
    "authors": [
      "Pedro Cabalar",
      "Stefania Costantini",
      "Giovanni De Gasperis",
      "Andrea Formisano"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06780"
  },
  {
    "id": "arXiv:2106.06781",
    "title": "A Data-Driven Approach for Contact Detection, Classification and  Reaction in Physical Human-Robot Collaboration",
    "abstract": "This paper considers a scenario where a robot and a human operator share the\nsame workspace, and the robot is able to both carry out autonomous tasks and\nphysically interact with the human in order to achieve common goals. In this\ncontext, both intentional and accidental contacts between human and robot might\noccur due to the complexity of tasks and environment, to the uncertainty of\nhuman behavior, and to the typical lack of awareness of each other actions.\nHere, a two stage strategy based on Recurrent Neural Networks (RNNs) is\ndesigned to detect intentional and accidental contacts: the occurrence of a\ncontact with the human is detected at the first stage, while the classification\nbetween intentional and accidental is performed at the second stage. An\nadmittance control strategy or an evasive action is then performed by the\nrobot, respectively. The approach also works in the case the robot\nsimultaneously interacts with the human and the environment, where the\ninteraction wrench of the latter is modeled via Gaussian Mixture Models (GMMs).\nControl Barrier Functions (CBFs) are included, at the control level, to\nguarantee the satisfaction of robot and task constraints while performing the\nproper interaction strategy. The approach has been validated on a real setup\ncomposed of a Kinova Jaco2 robot.",
    "descriptor": "\nComments: Accepted to 2021 IEEE International Conference on Robotics and Automation\n",
    "authors": [
      "Martina Lippi",
      "Giuseppe Gillini",
      "Alessandro Marino",
      "Filippo Arrichiello"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.06781"
  },
  {
    "id": "arXiv:2106.06783",
    "title": "Lvio-Fusion: A Self-adaptive Multi-sensor Fusion SLAM Framework Using  Actor-critic Method",
    "abstract": "State estimation with sensors is essential for mobile robots. Due to sensors\nhave different performance in different environments, how to fuse measurements\nof various sensors is a problem. In this paper, we propose a tightly-coupled\nmulti-sensor fusion framework, Lvio-Fusion, which fuses stereo camera, Lidar,\nIMU, and GPS based on the graph optimization. Especially for urban traffic\nscenes, we introduce a segmented global pose graph optimization with GPS and\nloop-closure, which can eliminate accumulated drifts. Additionally, we\ncreatively use a actor-critic method in reinforcement learning to adaptively\nadjust sensors' weight. After training, actor-critic agent can provide the\nsystem with better and dynamic sensors' weight. We evaluate the performance of\nour system on public datasets and compare it with other state-of-the-art\nmethods, showing that the proposed method achieves high estimation accuracy and\nrobustness to various environments. And our implementations are open source and\nhighly scalable.",
    "descriptor": "",
    "authors": [
      "Yupeng Jia",
      "Haiyong Luo",
      "Fang Zhao",
      "Guanlin Jiang",
      "Yuhang Li",
      "Jiaquan Yan",
      "Zhuqing Jiang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.06783"
  },
  {
    "id": "arXiv:2106.06786",
    "title": "Predicting the Ordering of Characters in Japanese Historical Documents",
    "abstract": "Japan is a unique country with a distinct cultural heritage, which is\nreflected in billions of historical documents that have been preserved.\nHowever, the change in Japanese writing system in 1900 made these documents\ninaccessible for the general public. A major research project has been to make\nthese historical documents accessible and understandable. An increasing amount\nof research has focused on the character recognition task and the location of\ncharacters on image, yet less research has focused on how to predict the\nsequential ordering of the characters. This is because sequence in classical\nJapanese is very different from modern Japanese. Ordering characters into a\nsequence is important for making the document text easily readable and\nsearchable. Additionally, it is a necessary step for any kind of natural\nlanguage processing on the data (e.g. machine translation, language modeling,\nand word embeddings). We explore a few approaches to the task of predicting the\nsequential ordering of the characters: one using simple hand-crafted rules,\nanother using hand-crafted rules with adaptive thresholds, and another using a\ndeep recurrent sequence model trained with teacher forcing. We provide a\nquantitative and qualitative comparison of these techniques as well as their\ndistinct trade-offs. Our best-performing system has an accuracy of 98.65\\% and\nhas a perfect accuracy on 49\\% of the books in our dataset, suggesting that the\ntechnique is able to predict the order of the characters well enough for many\ntasks.",
    "descriptor": "",
    "authors": [
      "Alex Lamb",
      "Tarin Clanuwat",
      "Siyu Han",
      "Mikel Bober-Irizar",
      "Asanobu Kitamoto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06786"
  },
  {
    "id": "arXiv:2106.06787",
    "title": "Graph-based Prior and Forward Models for Inverse Problems on Manifolds  with Boundaries",
    "abstract": "This paper develops manifold learning techniques for the numerical solution\nof PDE-constrained Bayesian inverse problems on manifolds with boundaries. We\nintroduce graphical Mat\\'ern-type Gaussian field priors that enable flexible\nmodeling near the boundaries, representing boundary values by superposition of\nharmonic functions with appropriate Dirichlet boundary conditions. We also\ninvestigate the graph-based approximation of forward models from PDE parameters\nto observed quantities. In the construction of graph-based prior and forward\nmodels, we leverage the ghost point diffusion map algorithm to approximate\nsecond-order elliptic operators with classical boundary conditions. Numerical\nresults validate our graph-based approach and demonstrate the need to design\nprior covariance models that account for boundary conditions.",
    "descriptor": "",
    "authors": [
      "John Harlim",
      "Shixiao Jiang",
      "Hwanwoo Kim",
      "Daniel Sanz-Alonso"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.06787"
  },
  {
    "id": "arXiv:2106.06788",
    "title": "Learngene: From Open-World to Your Learning Task",
    "abstract": "Although deep learning has made significant progress on fixed large-scale\ndatasets, it typically encounters challenges regarding improperly detecting\nnew/unseen classes in the open-world classification, over-parametrized, and\noverfitting small samples. In contrast, biological systems can overcome the\nabove difficulties very well. Individuals inherit an innate gene from\ncollective creatures that have evolved over hundreds of millions of years, and\ncan learn new skills through a few examples. Inspired by this, we propose a\npractical collective-individual paradigm where open-world tasks are trained in\nsequence using an evolution (expandable) network. To be specific, we\ninnovatively introduce learngene that inherits the meta-knowledge from the\ncollective model and reconstructs a new lightweight individual model for the\ntarget task, to realize the collective-individual paradigm. Particularly, we\npresent a novel criterion that can discover the learngene in the collective\nmodel, according to the gradient information. Finally, the individual model is\ntrained only with a few samples in the absence of the source data. We\ndemonstrate the effectiveness of our approach in an extensive empirical study\nand theoretical analysis.",
    "descriptor": "",
    "authors": [
      "Qiufeng Wang",
      "Xin Geng",
      "Shuxia Lin",
      "Shiyu Xia",
      "Lei Qi",
      "Ning Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06788"
  },
  {
    "id": "arXiv:2106.06792",
    "title": "A One-Shot Texture-Perceiving Generative Adversarial Network for  Unsupervised Surface Inspection",
    "abstract": "Visual surface inspection is a challenging task owing to the highly diverse\nappearance of target surfaces and defective regions. Previous attempts heavily\nrely on vast quantities of training examples with manual annotation. However,\nin some practical cases, it is difficult to obtain a large number of samples\nfor inspection. To combat it, we propose a hierarchical texture-perceiving\ngenerative adversarial network (HTP-GAN) that is learned from the one-shot\nnormal image in an unsupervised scheme. Specifically, the HTP-GAN contains a\npyramid of convolutional GANs that can capture the global structure and\nfine-grained representation of an image simultaneously. This innovation helps\ndistinguishing defective surface regions from normal ones. In addition, in the\ndiscriminator, a texture-perceiving module is devised to capture the spatially\ninvariant representation of normal image via directional convolutions, making\nit more sensitive to defective areas. Experiments on a variety of datasets\nconsistently demonstrate the effectiveness of our method.",
    "descriptor": "\nComments: Accepted by ICIP 2021\n",
    "authors": [
      "Lingyun Gu",
      "Lin Zhang",
      "Zhaokui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06792"
  },
  {
    "id": "arXiv:2106.06795",
    "title": "Knowledge Consolidation based Class Incremental Online Learning with  Limited Data",
    "abstract": "We propose a novel approach for class incremental online learning in a\nlimited data setting. This problem setting is challenging because of the\nfollowing constraints: (1) Classes are given incrementally, which necessitates\na class incremental learning approach; (2) Data for each class is given in an\nonline fashion, i.e., each training example is seen only once during training;\n(3) Each class has very few training examples; and (4) We do not use or assume\naccess to any replay/memory to store data from previous classes. Therefore, in\nthis setting, we have to handle twofold problems of catastrophic forgetting and\noverfitting. In our approach, we learn robust representations that are\ngeneralizable across tasks without suffering from the problems of catastrophic\nforgetting and overfitting to accommodate future classes with limited samples.\nOur proposed method leverages the meta-learning framework with knowledge\nconsolidation. The meta-learning framework helps the model for rapid learning\nwhen samples appear in an online fashion. Simultaneously, knowledge\nconsolidation helps to learn a robust representation against forgetting under\nonline updates to facilitate future learning. Our approach significantly\noutperforms other methods on several benchmarks.",
    "descriptor": "\nComments: International Joint Conference on Artificial Intelligence (IJCAI-2021)\n",
    "authors": [
      "Mohammed Asad Karim",
      "Vinay Kumar Verma",
      "Pravendra Singh",
      "Vinay Namboodiri",
      "Piyush Rai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06795"
  },
  {
    "id": "arXiv:2106.06796",
    "title": "Joint Client Scheduling and Resource Allocation under Channel  Uncertainty in Federated Learning",
    "abstract": "The performance of federated learning (FL) over wireless networks depend on\nthe reliability of the client-server connectivity and clients' local\ncomputation capabilities. In this article we investigate the problem of client\nscheduling and resource block (RB) allocation to enhance the performance of\nmodel training using FL, over a pre-defined training duration under imperfect\nchannel state information (CSI) and limited local computing resources. First,\nwe analytically derive the gap between the training losses of FL with clients\nscheduling and a centralized training method for a given training duration.\nThen, we formulate the gap of the training loss minimization over client\nscheduling and RB allocation as a stochastic optimization problem and solve it\nusing Lyapunov optimization. A Gaussian process regression-based channel\nprediction method is leveraged to learn and track the wireless channel, in\nwhich, the clients' CSI predictions and computing power are incorporated into\nthe scheduling decision. Using an extensive set of simulations, we validate the\nrobustness of the proposed method under both perfect and imperfect CSI over an\narray of diverse data distributions. Results show that the proposed method\nreduces the gap of the training accuracy loss by up to 40.7% compared to\nstate-of-theart client scheduling and RB allocation methods.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2002.00802\n",
    "authors": [
      "Madhusanka Manimel Wadu",
      "Sumudu Samarakoon",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06796"
  },
  {
    "id": "arXiv:2106.06797",
    "title": "Machine Translation into Low-resource Language Varieties",
    "abstract": "State-of-the-art machine translation (MT) systems are typically trained to\ngenerate the \"standard\" target language; however, many languages have multiple\nvarieties (regional varieties, dialects, sociolects, non-native varieties) that\nare different from the standard language. Such varieties are often\nlow-resource, and hence do not benefit from contemporary NLP solutions, MT\nincluded. We propose a general framework to rapidly adapt MT systems to\ngenerate language varieties that are close to, but different from, the standard\ntarget language, using no parallel (source--variety) data. This also includes\nadaptation of MT systems to low-resource typologically-related target\nlanguages. We experiment with adapting an English--Russian MT system to\ngenerate Ukrainian and Belarusian, an English--Norwegian Bokm{\\aa}l system to\ngenerate Nynorsk, and an English--Arabic system to generate four Arabic\ndialects, obtaining significant improvements over competitive baselines.",
    "descriptor": "\nComments: The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)\n",
    "authors": [
      "Sachin Kumar",
      "Antonios Anastasopoulos",
      "Shuly Wintner",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06797"
  },
  {
    "id": "arXiv:2106.06799",
    "title": "Zero-Cost Proxies Meet Differentiable Architecture Search",
    "abstract": "Differentiable neural architecture search (NAS) has attracted significant\nattention in recent years due to its ability to quickly discover promising\narchitectures of deep neural networks even in very large search spaces. Despite\nits success, DARTS lacks robustness in certain cases, e.g. it may degenerate to\ntrivial architectures with excessive parametric-free operations such as skip\nconnection or random noise, leading to inferior performance. In particular,\noperation selection based on the magnitude of architectural parameters was\nrecently proven to be fundamentally wrong showcasing the need to rethink this\naspect. On the other hand, zero-cost proxies have been recently studied in the\ncontext of sample-based NAS showing promising results -- speeding up the search\nprocess drastically in some cases but also failing on some of the large search\nspaces typical for differentiable NAS. In this work we propose a novel\noperation selection paradigm in the context of differentiable NAS which\nutilises zero-cost proxies. Our perturbation-based zero-cost operation\nselection (Zero-Cost-PT) improves searching time and, in many cases, accuracy\ncompared to the best available differentiable architecture search, regardless\nof the search space size. Specifically, we are able to find comparable\narchitectures to DARTS-PT on the DARTS CNN search space while being over 40x\nfaster (total searching time 25 minutes on a single GPU).",
    "descriptor": "",
    "authors": [
      "Lichuan Xiang",
      "\u0141ukasz Dudziak",
      "Mohamed S. Abdelfattah",
      "Thomas Chau",
      "Nicholas D. Lane",
      "Hongkai Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06799"
  },
  {
    "id": "arXiv:2106.06801",
    "title": "Contrastive Semi-Supervised Learning for 2D Medical Image Segmentation",
    "abstract": "Contrastive Learning (CL) is a recent representation learning approach, which\nachieves promising results by encouraging inter-class separability and\nintra-class compactness in learned image representations. Because medical\nimages often contain multiple classes of interest per image, a standard\nimage-level CL for these images is not applicable. In this work, we present a\nnovel semi-supervised 2D medical segmentation solution that applies CL on image\npatches, instead of full images. These patches are meaningfully constructed\nusing the semantic information of different classes obtained via pseudo\nlabeling. We also propose a novel consistency regularization scheme, which\nworks in synergy with contrastive learning. It addresses the problem of\nconfirmation bias often observed in semi-supervised settings, and encourages\nbetter clustering in the feature space. We evaluate our method on four public\nmedical segmentation datasets along with a novel histopathology dataset that we\nintroduce. Our method obtains consistent improvements over the state-of-the-art\nsemi-supervised segmentation approaches for all datasets.",
    "descriptor": "\nComments: MICCAI 2021\n",
    "authors": [
      "Prashant Pandey",
      "Ajey Pai",
      "Nisarg Bhatt",
      "Prasenjit Das",
      "Govind Makharia",
      "Prathosh AP",
      "Mausam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06801"
  },
  {
    "id": "arXiv:2106.06804",
    "title": "Entropy-based Logic Explanations of Neural Networks",
    "abstract": "Explainable artificial intelligence has rapidly emerged since lawmakers have\nstarted requiring interpretable models for safety-critical domains.\nConcept-based neural networks have arisen as explainable-by-design methods as\nthey leverage human-understandable symbols (i.e. concepts) to predict class\nmemberships. However, most of these approaches focus on the identification of\nthe most relevant concepts but do not provide concise, formal explanations of\nhow such concepts are leveraged by the classifier to make predictions. In this\npaper, we propose a novel end-to-end differentiable approach enabling the\nextraction of logic explanations from neural networks using the formalism of\nFirst-Order Logic. The method relies on an entropy-based criterion which\nautomatically identifies the most relevant concepts. We consider four different\ncase studies to demonstrate that: (i) this entropy-based criterion enables the\ndistillation of concise logic explanations in safety-critical domains from\nclinical data to computer vision; (ii) the proposed approach outperforms\nstate-of-the-art white-box models in terms of classification accuracy.",
    "descriptor": "",
    "authors": [
      "Pietro Barbiero",
      "Gabriele Ciravegna",
      "Francesco Giannini",
      "Pietro Li\u00f3",
      "Marco Gori",
      "Stefano Melacci"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.06804"
  },
  {
    "id": "arXiv:2106.06807",
    "title": "Redirected Walking in Static and Dynamic Scenes Using Visibility  Polygons",
    "abstract": "We present a new approach for redirected walking in static and dynamic scenes\nthat uses techniques from robot motion planning to compute the redirection\ngains that steer the user on collision-free paths in the physical space. Our\nfirst contribution is a mathematical framework for redirected walking using\nconcepts from motion planning and configuration spaces. This framework\nhighlights various geometric and perceptual constraints that tend to make\ncollision-free redirected walking difficult. We use our framework to propose an\nefficient solution to the redirection problem that uses the notion of\nvisibility polygons to compute the free spaces in the physical environment and\nthe virtual environment. The visibility polygon provides a concise\nrepresentation of the entire space that is visible, and therefore walkable, to\nthe user from their position within an environment. Using this representation\nof walkable space, we apply redirected walking to steer the user to regions of\nthe visibility polygon in the physical environment that closely match the\nregion that the user occupies in the visibility polygon in the virtual\nenvironment. We show that our algorithm is able to steer the user along paths\nthat result in significantly fewer red{resets than existing state-of-the-art\nalgorithms in both static and dynamic scenes.",
    "descriptor": "",
    "authors": [
      "Niall L. Williams",
      "Aniket Bera",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.06807"
  },
  {
    "id": "arXiv:2106.06811",
    "title": "Case Study on Detecting COVID-19 Health-Related Misinformation in Social  Media",
    "abstract": "COVID-19 pandemic has generated what public health officials called an\ninfodemic of misinformation. As social distancing and stay-at-home orders came\ninto effect, many turned to social media for socializing. This increase in\nsocial media usage has made it a prime vehicle for the spreading of\nmisinformation. This paper presents a mechanism to detect COVID-19\nhealth-related misinformation in social media following an interdisciplinary\napproach. Leveraging social psychology as a foundation and existing\nmisinformation frameworks, we defined misinformation themes and associated\nkeywords incorporated into the misinformation detection mechanism using applied\nmachine learning techniques. Next, using the Twitter dataset, we explored the\nperformance of the proposed methodology using multiple state-of-the-art machine\nlearning classifiers. Our method shows promising results with at most 78%\naccuracy in classifying health-related misinformation versus true information\nusing uni-gram-based NLP feature generations from tweets and the Decision Tree\nclassifier. We also provide suggestions on alternatives for countering\nmisinformation and ethical consideration for the study.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Mir Mehedi A. Pritom",
      "Rosana Montanez Rodriguez",
      "Asad Ali Khan",
      "Sebastian A. Nugroho",
      "Esra'a Alrashydah",
      "Beatrice N. Ruiz",
      "Anthony Rios"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06811"
  },
  {
    "id": "arXiv:2106.06815",
    "title": "Quantifying the Conceptual Error in Dimensionality Reduction",
    "abstract": "Dimension reduction of data sets is a standard problem in the realm of\nmachine learning and knowledge reasoning. They affect patterns in and\ndependencies on data dimensions and ultimately influence any decision-making\nprocesses. Therefore, a wide variety of reduction procedures are in use, each\npursuing different objectives. A so far not considered criterion is the\nconceptual continuity of the reduction mapping, i.e., the preservation of the\nconceptual structure with respect to the original data set. Based on the notion\nscale-measure from formal concept analysis we present in this work a) the\ntheoretical foundations to detect and quantify conceptual errors in data\nscalings; b) an experimental investigation of our approach on eleven data sets\nthat were respectively treated with a variant of non-negative matrix\nfactorization.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Tom Hanika",
      "Johannes Hirth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.06815"
  },
  {
    "id": "arXiv:2106.06816",
    "title": "System Identification and Model-based Robust Nonlinear Disturbance  Rejection Control",
    "abstract": "The robust disturbance rejection controller has been the subject of intensive\nresearch due to its undeniable importance for automation. Modern control theory\ntends to use model-based approaches versus model-free approaches, especially\nwhen it comes to highly modern applications. The backbone of the dissertation\nis based on the systematic modeling of dynamic systems and the development of\nadvanced control methods. Accordingly, the dissertation begins with the\ninvestigation of nonlinearities in dynamic systems. The extension of classic\nsubspace algorithms for linear systems in the frequency domain is tackled using\nthe new local polynomial approach. Next, the problem of disturbance control is\naddressed, namely modeling of uncertainties and non-modeled high-order\ndynamics, fragility of the controller and observer systems, and the\nnon-linearities are analyzed separately.",
    "descriptor": "\nComments: PhD Dissertation, 238 pages\n",
    "authors": [
      "Atta Oveisi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.06816"
  },
  {
    "id": "arXiv:2106.06817",
    "title": "Evaluating Foveated Video Quality Using Entropic Differencing",
    "abstract": "Virtual Reality is regaining attention due to recent advancements in hardware\ntechnology. Immersive images / videos are becoming widely adopted to carry\nomnidirectional visual information. However, due to the requirements for higher\nspatial and temporal resolution of real video data, immersive videos require\nsignificantly larger bandwidth consumption. To reduce stresses on bandwidth,\nfoveated video compression is regaining popularity, whereby the space-variant\nspatial resolution of the retina is exploited. Towards advancing the progress\nof foveated video compression, we propose a full reference (FR) foveated image\nquality assessment algorithm, which we call foveated entropic differencing\n(FED), which employs the natural scene statistics of bandpass responses by\napplying differences of local entropies weighted by a foveation-based error\nsensitivity function. We evaluate the proposed algorithm by measuring the\ncorrelations of the predictions that FED makes against human judgements on the\nnewly created 2D and 3D LIVE-FBT-FCVR databases for Virtual Reality (VR). The\nperformance of the proposed algorithm yields state-of-the-art as compared with\nother existing full reference algorithms. Software for FED has been made\navailable at: this http URL",
    "descriptor": "",
    "authors": [
      "Yize Jin",
      "Anjul Patney",
      "Alan Bovik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06817"
  },
  {
    "id": "arXiv:2106.06819",
    "title": "D2C: Diffusion-Denoising Models for Few-shot Conditional Generation",
    "abstract": "Conditional generative models of high-dimensional images have many\napplications, but supervision signals from conditions to images can be\nexpensive to acquire. This paper describes Diffusion-Decoding models with\nContrastive representations (D2C), a paradigm for training unconditional\nvariational autoencoders (VAEs) for few-shot conditional image generation. D2C\nuses a learned diffusion-based prior over the latent representations to improve\ngeneration and contrastive self-supervised learning to improve representation\nquality. D2C can adapt to novel generation tasks conditioned on labels or\nmanipulation constraints, by learning from as few as 100 labeled examples. On\nconditional generation from new labels, D2C achieves superior performance over\nstate-of-the-art VAEs and diffusion models. On conditional image manipulation,\nD2C generations are two orders of magnitude faster to produce over StyleGAN2\nones and are preferred by 50% - 60% of the human evaluators in a double-blind\nstudy.",
    "descriptor": "",
    "authors": [
      "Abhishek Sinha",
      "Jiaming Song",
      "Chenlin Meng",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06819"
  },
  {
    "id": "arXiv:2106.06822",
    "title": "A Pseudo Label-wise Attention Network for Automatic ICD Coding",
    "abstract": "Automatic International Classification of Diseases (ICD) coding is defined as\na kind of text multi-label classification problem, which is difficult because\nthe number of labels is very large and the distribution of labels is\nunbalanced. The label-wise attention mechanism is widely used in automatic ICD\ncoding because it can assign weights to every word in full Electronic Medical\nRecords (EMR) for different ICD codes. However, the label-wise attention\nmechanism is computational redundant and costly. In this paper, we propose a\npseudo label-wise attention mechanism to tackle the problem. Instead of\ncomputing different attention modes for different ICD codes, the pseudo\nlabel-wise attention mechanism automatically merges similar ICD codes and\ncomputes only one attention mode for the similar ICD codes, which greatly\ncompresses the number of attention modes and improves the predicted accuracy.\nIn addition, we apply a more convenient and effective way to obtain the ICD\nvectors, and thus our model can predict new ICD codes by calculating the\nsimilarities between EMR vectors and ICD vectors. Extensive experiments show\nthe superior performance of our model. On the public MIMIC-III dataset and\nprivate Xiangya dataset, our model achieves micro f1 of 0.575 and 0.796,\nrespectively, which outperforms other competing models. Furthermore, we verify\nthe ability of our model in predicting new ICD codes. The case study shows how\npseudo label-wise attention works, and demonstrates the effectiveness of pseudo\nlabel-wise attention mechanism.",
    "descriptor": "",
    "authors": [
      "Yifan Wu",
      "Min Zeng",
      "Ying Yu",
      "Min Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06822"
  },
  {
    "id": "arXiv:2106.06823",
    "title": "Prompting Contrastive Explanations for Commonsense Reasoning Tasks",
    "abstract": "Many commonsense reasoning NLP tasks involve choosing between one or more\npossible answers to a question or prompt based on knowledge that is often\nimplicit. Large pretrained language models (PLMs) can achieve near-human\nperformance on such tasks, while providing little human-interpretable evidence\nof the underlying reasoning they use. In this work, we show how to use these\nsame models to generate such evidence: inspired by the contrastive nature of\nhuman explanations, we use PLMs to complete explanation prompts which contrast\nalternatives according to the key attribute(s) required to justify the correct\nanswer (for example, peanuts are usually salty while raisins are sweet).\nConditioning model decisions on these explanations improves performance on two\ncommonsense reasoning benchmarks, as compared to previous non-contrastive\nalternatives. These explanations are also judged by humans to be more relevant\nfor solving the task, and facilitate a novel method to evaluate explanation\nfaithfulfness.",
    "descriptor": "\nComments: ACL 2021 Findings\n",
    "authors": [
      "Bhargavi Paranjape",
      "Julian Michael",
      "Marjan Ghazvininejad",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06823"
  },
  {
    "id": "arXiv:2106.06828",
    "title": "A Game-Theoretic Approach to Multi-Agent Trust Region Optimization",
    "abstract": "Trust region methods are widely applied in single-agent reinforcement\nlearning problems due to their monotonic performance-improvement guarantee at\nevery iteration. Nonetheless, when applied in multi-agent settings, the\nguarantee of trust region methods no longer holds because an agent's payoff is\nalso affected by other agents' adaptive behaviors. To tackle this problem, we\nconduct a game-theoretical analysis in the policy space, and propose a\nmulti-agent trust region learning method (MATRL), which enables trust region\noptimization for multi-agent learning. Specifically, MATRL finds a stable\nimprovement direction that is guided by the solution concept of Nash\nequilibrium at the meta-game level. We derive the monotonic improvement\nguarantee in multi-agent settings and empirically show the local convergence of\nMATRL to stable fixed points in the two-player rotational differential game. To\ntest our method, we evaluate MATRL in both discrete and continuous multiplayer\ngeneral-sum games including checker and switch grid worlds, multi-agent MuJoCo,\nand Atari games. Results suggest that MATRL significantly outperforms strong\nmulti-agent reinforcement learning baselines.",
    "descriptor": "\nComments: A Multi-Agent Trust Region Learning (MATRL) algorithm that augments the single-agent trust region policy optimization with a weak stable fixed point approximated by the policy-space meta-game\n",
    "authors": [
      "Ying Wen",
      "Hui Chen",
      "Yaodong Yang",
      "Zheng Tian",
      "Minne Li",
      "Xu Chen",
      "Jun Wang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06828"
  },
  {
    "id": "arXiv:2106.06830",
    "title": "Evaluating Entity Disambiguation and the Role of Popularity in  Retrieval-Based NLP",
    "abstract": "Retrieval is a core component for open-domain NLP tasks. In open-domain\ntasks, multiple entities can share a name, making disambiguation an inherent\nyet under-explored problem. We propose an evaluation benchmark for assessing\nthe entity disambiguation capabilities of these retrievers, which we call\nAmbiguous Entity Retrieval (AmbER) sets. We define an AmbER set as a collection\nof entities that share a name along with queries about those entities. By\ncovering the set of entities for polysemous names, AmbER sets act as a\nchallenging test of entity disambiguation. We create AmbER sets for three\npopular open-domain tasks: fact checking, slot filling, and question answering,\nand evaluate a diverse set of retrievers. We find that the retrievers exhibit\npopularity bias, significantly under-performing on rarer entities that share a\nname, e.g., they are twice as likely to retrieve erroneous documents on queries\nfor the less popular entity under the same name. These experiments on AmbER\nsets show their utility as an evaluation tool and highlight the weaknesses of\npopular retrieval systems.",
    "descriptor": "",
    "authors": [
      "Anthony Chen",
      "Pallavi Gudipati",
      "Shayne Longpre",
      "Xiao Ling",
      "Sameer Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06830"
  },
  {
    "id": "arXiv:2106.06831",
    "title": "Toward the Optimized Crowdsourcing Strategy for OCR Post-Correction",
    "abstract": "Digitization of historical documents is a challenging task in many digital\nhumanities projects. A popular approach for digitization is to scan the\ndocuments into images, and then convert images into text using Optical\nCharacter Recognition (OCR) algorithms. However, the outcome of OCR processing\nof historical documents is usually inaccurate and requires post-processing\nerror correction. This study investigates how crowdsourcing can be utilized to\ncorrect OCR errors in historical text collections, and which crowdsourcing\nmethodology is the most effective in different scenarios and for various\nresearch objectives. A series of experiments with different micro-task's\nstructures and text lengths was conducted with 753 workers on the Amazon's\nMechanical Turk platform. The workers had to fix OCR errors in a selected\nhistorical text. To analyze the results, new accuracy and efficiency measures\nhave been devised. The analysis suggests that in terms of accuracy, the optimal\ntext length is medium (paragraph-size) and the optimal structure of the\nexperiment is two-phase with a scanned image. In terms of efficiency, the best\nresults were obtained when using longer text in the single-stage structure with\nno image. The study provides practical recommendations to researchers on how to\nbuild the optimal crowdsourcing task for OCR post-correction. The developed\nmethodology can also be utilized to create golden standard historical texts for\nautomatic OCR post-correction. This is the first attempt to systematically\ninvestigate the influence of various factors on crowdsourcing-based OCR\npost-correction and propose an optimal strategy for this process.",
    "descriptor": "\nComments: 25 pages, 12 figures, 1 table\n",
    "authors": [
      "Omri Suissa",
      "Avshalom Elmalech",
      "Maayan Zhitomirsky-Geffet"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.06831"
  },
  {
    "id": "arXiv:2106.06836",
    "title": "Cox Models for Vehicular Networks: SIR Performance and Equivalence",
    "abstract": "We introduce a general framework for the modeling and analysis of vehicular\nnetworks by defining street systems as random 1D subsets of $\\mathbb{R}^{2}$.\nThe street system, in turn, specifies the random intensity measure of a Cox\nprocess of vehicles, i.e., vehicles form independent 1D Poisson point processes\non each street. Models in this Coxian framework can characterize streets of\ndifferent lengths and orientations forming intersections or T-junctions. The\nlengths of the streets can be infinite or finite and mutually independent or\ndependent. We analyze the reliability of communication for different models,\nwhere reliability is the probability that a vehicle at an intersection, a\nT-junction, or a general location can receive a message successfully from a\ntransmitter at a certain distance. Further, we introduce a notion of\nequivalence between vehicular models, which means that a representative model\ncan be used as a proxy for other models in terms of reliability. Specifically,\nwe prove that the Poisson stick process-based vehicular network is equivalent\nto the Poisson line process-based and Poisson lilypond model-based vehicular\nnetworks, and their rotational variants.",
    "descriptor": "\nComments: 15 pages, 11 figures\n",
    "authors": [
      "Jeya Pradha Jeyaraj",
      "Martin Haenggi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.06836"
  },
  {
    "id": "arXiv:2106.06837",
    "title": "Crouzeix-Raviart finite element method for non-autonomous variational  problems with Lavrentiev gap",
    "abstract": "We investigate the convergence of the Crouzeix-Raviart finite element method\nfor variational problems with non-autonomous integrands that exhibit\nnon-standard growth conditions. While conforming schemes fail due to the\nLavrentiev gap phenomenon, we prove that the solution of the Crouzeix-Raviart\nscheme converges to a global minimiser. Numerical experiments illustrate the\nperformance of the scheme and give additional analytical insights.",
    "descriptor": "",
    "authors": [
      "Anna Kh.Balci",
      "Christoph Ortner",
      "Johannes Storn"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.06837"
  },
  {
    "id": "arXiv:2106.06838",
    "title": "A Low-Compexity Deep Learning Framework For Acoustic Scene  Classification",
    "abstract": "In this paper, we presents a low-complexity deep learning frameworks for\nacoustic scene classification (ASC). The proposed framework can be separated\ninto three main steps: Front-end spectrogram extraction, back-end\nclassification, and late fusion of predicted probabilities. First, we use Mel\nfilter, Gammatone filter and Constant Q Transfrom (CQT) to transform raw audio\nsignal into spectrograms, where both frequency and temporal features are\npresented. Three spectrograms are then fed into three individual back-end\nconvolutional neural networks (CNNs), classifying into ten urban scenes.\nFinally, a late fusion of three predicted probabilities obtained from three\nCNNs is conducted to achieve the final classification result. To reduce the\ncomplexity of our proposed CNN network, we apply two model compression\ntechniques: model restriction and decomposed convolution. Our extensive\nexperiments, which are conducted on DCASE 2021 (IEEE AASP Challenge on\nDetection and Classification of Acoustic Scenes and Events) Task 1A development\ndataset, achieve a low-complexity CNN based framework with 128 KB trainable\nparameters and the best classification accuracy of 66.7%, improving DCASE\nbaseline by 19.0%",
    "descriptor": "",
    "authors": [
      "Lam Pham",
      "Hieu Tang",
      "Anahid Jalali",
      "Alexander Schindler",
      "Ross King"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.06838"
  },
  {
    "id": "arXiv:2106.06839",
    "title": "Intelligent Vision Based Wear Forecasting on Surfaces of Machine Tool  Elements",
    "abstract": "This paper addresses the ability to enable machines to automatically detect\nfailures on machine tool components as well as estimating the severity of the\nfailures, which is a critical step towards autonomous production machines.\nExtracting information about the severity of failures has been a substantial\npart of classical, as well as Machine Learning based machine vision systems.\nEfforts have been undertaken to automatically predict the severity of failures\non machine tool components for predictive maintenance purposes. Though, most\napproaches only partly cover a completely automatic system from detecting\nfailures to the prognosis of their future severity. To the best of the authors\nknowledge, this is the first time a vision-based system for defect detection\nand prognosis of failures on metallic surfaces in general and on Ball Screw\nDrives in specific has been proposed. The authors show that they can do both,\ndetect and prognose the evolution of a failure on the surface of a Ball Screw\nDrive.",
    "descriptor": "",
    "authors": [
      "Tobias Schlagenhauf",
      "Niklas Burghardt",
      "J\u00fcrgen Fleischer"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.06839"
  },
  {
    "id": "arXiv:2106.06840",
    "title": "Deep Learning Frameworks Applied For Audio-Visual Scene Classification",
    "abstract": "In this paper, we present deep learning frameworks for audio-visual scene\nclassification (SC) and indicate how individual visual and audio features as\nwell as their combination affect SC performance. Our extensive experiments,\nwhich are conducted on DCASE (IEEE AASP Challenge on Detection and\nClassification of Acoustic Scenes and Events) Task 1B development dataset,\nachieve the best classification accuracy of 82.2%, 91.1%, and 93.9% with audio\ninput only, visual input only, and both audio-visual input, respectively. The\nhighest classification accuracy of 93.9%, obtained from an ensemble of\naudio-based and visual-based frameworks, shows an improvement of 16.5% compared\nwith DCASE baseline.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Lam Pham",
      "Alexander Schindler",
      "Mina Sch\u00fctz",
      "Jasmin Lampert",
      "Sven Schlarb",
      "Ross King"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.06840"
  },
  {
    "id": "arXiv:2106.06842",
    "title": "Recomposing the Reinforcement Learning Building Blocks with  Hypernetworks",
    "abstract": "The Reinforcement Learning (RL) building blocks, i.e. Q-functions and policy\nnetworks, usually take elements from the cartesian product of two domains as\ninput. In particular, the input of the Q-function is both the state and the\naction, and in multi-task problems (Meta-RL) the policy can take a state and a\ncontext. Standard architectures tend to ignore these variables' underlying\ninterpretations and simply concatenate their features into a single vector. In\nthis work, we argue that this choice may lead to poor gradient estimation in\nactor-critic algorithms and high variance learning steps in Meta-RL algorithms.\nTo consider the interaction between the input variables, we suggest using a\nHypernetwork architecture where a primary network determines the weights of a\nconditional dynamic network. We show that this approach improves the gradient\napproximation and reduces the learning step variance, which both accelerates\nlearning and improves the final performance. We demonstrate a consistent\nimprovement across different locomotion tasks and different algorithms both in\nRL (TD3 and SAC) and in Meta-RL (MAML and PEARL).",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Shai Keynan",
      "Elad Sarafian",
      "Sarit Kraus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06842"
  },
  {
    "id": "arXiv:2106.06843",
    "title": "Federated Learning on Non-IID Data: A Survey",
    "abstract": "Federated learning is an emerging distributed machine learning framework for\nprivacy preservation. However, models trained in federated learning usually\nhave worse performance than those trained in the standard centralized learning\nmode, especially when the training data are not independent and identically\ndistributed (Non-IID) on the local devices. In this survey, we pro-vide a\ndetailed analysis of the influence of Non-IID data on both parametric and\nnon-parametric machine learning models in both horizontal and vertical\nfederated learning. In addition, cur-rent research work on handling challenges\nof Non-IID data in federated learning are reviewed, and both advantages and\ndisadvantages of these approaches are discussed. Finally, we suggest several\nfuture research directions before concluding the paper.",
    "descriptor": "",
    "authors": [
      "Hangyu Zhu",
      "Jinjin Xu",
      "Shiqing Liu",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.06843"
  },
  {
    "id": "arXiv:2106.06844",
    "title": "Amplifying Privacy: Scaling Up Transparency Research Through Delegated  Access Requests",
    "abstract": "In recent years, numerous studies have used 'data subject access requests' in\na collective manner, to tackle information asymmetries and shed light on data\ncollection and privacy practices of organizations. While successful at\nincreasing transparency, such studies are quite hard to conduct for the simple\nfact that right of access is an individual right. This means that researchers\nhave to recruit participants and guide them through the often-cumbersome\nprocess of access. In this paper, we present an alternative method: to ask\nparticipants to delegate their right of access to the researchers. We discuss\nthe legal grounds for doing this, the advantages it can bring to both\nresearchers and data subjects, and present a procedural and technical design to\nexecute it in a manner that ensures data subjects stay informed and in charge\nduring the process. We tested our method in a pilot study in the Netherlands,\nand found that it creates a win-win for both the researchers and the\nparticipants. We also noted differences in how data controllers from various\nsectors react to such requests and discuss some remaining challenges.",
    "descriptor": "\nComments: Peer-reviewed and presented at IEEE Workshop on Technology and Consumer Protection 2021 (ConPro '21)\n",
    "authors": [
      "Hadi Asghari",
      "Thomas van Biemen",
      "Martijn Warnier"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.06844"
  },
  {
    "id": "arXiv:2106.06845",
    "title": "Harmonization with Flow-based Causal Inference",
    "abstract": "Heterogeneity in medical data, e.g., from data collected at different sites\nand with different protocols in a clinical study, is a fundamental hurdle for\naccurate prediction using machine learning models, as such models often fail to\ngeneralize well. This paper presents a normalizing-flow-based method to perform\ncounterfactual inference upon a structural causal model (SCM) to harmonize such\ndata. We formulate a causal model for observed effects (brain magnetic\nresonance imaging data) that result from known confounders (site, gender and\nage) and exogenous noise variables. Our method exploits the bijection induced\nby flow for harmonization. We can infer the posterior of exogenous variables,\nintervene on observations, and draw samples from the resultant SCM to obtain\ncounterfactuals. We evaluate on multiple, large, real-world medical datasets to\nobserve that this method leads to better cross-domain generalization compared\nto state-of-the-art algorithms. Further experiments that evaluate the quality\nof confounder-independent data generated by our model using regression and\nclassification tasks are provided.",
    "descriptor": "",
    "authors": [
      "Rongguang Wang",
      "Pratik Chaudhari",
      "Christos Davatzikos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.06845"
  },
  {
    "id": "arXiv:2106.06847",
    "title": "Video Super-Resolution Transformer",
    "abstract": "Video super-resolution (VSR), with the aim to restore a high-resolution video\nfrom its corresponding low-resolution version, is a spatial-temporal sequence\nprediction problem. Recently, Transformer has been gaining popularity due to\nits parallel computing ability for sequence-to-sequence modeling. Thus, it\nseems to be straightforward to apply the vision Transformer to solve VSR.\nHowever, the typical block design of Transformer with a fully connected\nself-attention layer and a token-wise feed-forward layer does not fit well for\nVSR due to the following two reasons. First, the fully connected self-attention\nlayer neglects to exploit the data locality because this layer relies on linear\nlayers to compute attention maps. Second, the token-wise feed-forward layer\nlacks the feature alignment which is important for VSR since this layer\nindependently processes each of the input token embeddings without any\ninteraction among them. In this paper, we make the first attempt to adapt\nTransformer for VSR. Specifically, to tackle the first issue, we present a\nspatial-temporal convolutional self-attention layer with a theoretical\nunderstanding to exploit the locality information. For the second issue, we\ndesign a bidirectional optical flow-based feed-forward layer to discover the\ncorrelations across different video frames and also align features. Extensive\nexperiments on several benchmark datasets demonstrate the effectiveness of our\nproposed method. The code will be available at\nhttps://github.com/caojiezhang/VSR-Transformer.",
    "descriptor": "",
    "authors": [
      "Jiezhang Cao",
      "Yawei Li",
      "Kai Zhang",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06847"
  },
  {
    "id": "arXiv:2106.06848",
    "title": "Guaranteed Fixed-Confidence Best Arm Identification in Multi-Armed  Bandit",
    "abstract": "We consider the problem of finding, through adaptive sampling, which of n\npopulations (arms) has the largest mean. Our objective is to determine a rule\nwhich identifies the best population with a fixed minimum confidence using as\nfew observations as possible, i.e. fixed-confidence (FC) best arm\nidentification (BAI) in multi-armed bandits. We study such problems under the\nBayesian setting with both Bernoulli and Gaussian populations. We propose to\nuse the classical vector at a time (VT) rule, which samples each alive\npopulation once in each round. We show how VT can be implemented and analyzed\nin our Bayesian setting and be improved by early elimination. We also propose\nand analyze a variant of the classical play the winner (PW) algorithm.\nNumerical results show that these rules compare favorably with state-of-art\nalgorithms.",
    "descriptor": "",
    "authors": [
      "MohammadJavad Azizi",
      "Sheldon M Ross",
      "Zhengyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06848"
  },
  {
    "id": "arXiv:2106.06849",
    "title": "Can Transformer Language Models Predict Psychometric Properties?",
    "abstract": "Transformer-based language models (LMs) continue to advance state-of-the-art\nperformance on NLP benchmark tasks, including tasks designed to mimic\nhuman-inspired \"commonsense\" competencies. To better understand the degree to\nwhich LMs can be said to have certain linguistic reasoning skills, researchers\nare beginning to adapt the tools and concepts of the field of psychometrics.\nBut to what extent can the benefits flow in the other direction? I.e., can LMs\nbe of use in predicting what the psychometric properties of test items will be\nwhen those items are given to human participants? We gather responses from\nnumerous human participants and LMs (transformer and non-transformer-based) on\na broad diagnostic test of linguistic competencies. We then use the responses\nto calculate standard psychometric properties of the items in the diagnostic\ntest, using the human responses and the LM responses separately. We then\ndetermine how well these two sets of predictions match. We find cases in which\ntransformer-based LMs predict psychometric properties consistently well in\ncertain categories but consistently poorly in others, thus providing new\ninsights into fundamental similarities and differences between human and LM\nreasoning.",
    "descriptor": "\nComments: Proceedings of the 10th Joint Conference on Lexical and Computational Semantics (*SEM 2021)\n",
    "authors": [
      "Antonio Laverghetta Jr.",
      "Animesh Nighojkar",
      "Jamshidbek Mirzakhalov",
      "John Licato"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06849"
  },
  {
    "id": "arXiv:2106.06854",
    "title": "A Deep Reinforcement Learning Approach to Marginalized Importance  Sampling with the Successor Representation",
    "abstract": "Marginalized importance sampling (MIS), which measures the density ratio\nbetween the state-action occupancy of a target policy and that of a sampling\ndistribution, is a promising approach for off-policy evaluation. However,\ncurrent state-of-the-art MIS methods rely on complex optimization tricks and\nsucceed mostly on simple toy problems. We bridge the gap between MIS and deep\nreinforcement learning by observing that the density ratio can be computed from\nthe successor representation of the target policy. The successor representation\ncan be trained through deep reinforcement learning methodology and decouples\nthe reward optimization from the dynamics of the environment, making the\nresulting algorithm stable and applicable to high-dimensional domains. We\nevaluate the empirical performance of our approach on a variety of challenging\nAtari and MuJoCo environments.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Scott Fujimoto",
      "David Meger",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06854"
  },
  {
    "id": "arXiv:2106.06856",
    "title": "DyGLIP: A Dynamic Graph Model with Link Prediction for Accurate  Multi-Camera Multiple Object Tracking",
    "abstract": "Multi-Camera Multiple Object Tracking (MC-MOT) is a significant computer\nvision problem due to its emerging applicability in several real-world\napplications. Despite a large number of existing works, solving the data\nassociation problem in any MC-MOT pipeline is arguably one of the most\nchallenging tasks. Developing a robust MC-MOT system, however, is still highly\nchallenging due to many practical issues such as inconsistent lighting\nconditions, varying object movement patterns, or the trajectory occlusions of\nthe objects between the cameras. To address these problems, this work,\ntherefore, proposes a new Dynamic Graph Model with Link Prediction (DyGLIP)\napproach to solve the data association task. Compared to existing methods, our\nnew model offers several advantages, including better feature representations\nand the ability to recover from lost tracks during camera transitions.\nMoreover, our model works gracefully regardless of the overlapping ratios\nbetween the cameras. Experimental results show that we outperform existing\nMC-MOT algorithms by a large margin on several practical datasets. Notably, our\nmodel works favorably on online settings but can be extended to an incremental\napproach for large-scale datasets.",
    "descriptor": "\nComments: accepted at CVPR 2021\n",
    "authors": [
      "Kha Gia Quach",
      "Pha Nguyen",
      "Huu Le",
      "Thanh-Dat Truong",
      "Chi Nhan Duong",
      "Minh-Triet Tran",
      "Khoa Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06856"
  },
  {
    "id": "arXiv:2106.06860",
    "title": "A Minimalist Approach to Offline Reinforcement Learning",
    "abstract": "Offline reinforcement learning (RL) defines the task of learning from a fixed\nbatch of data. Due to errors in value estimation from out-of-distribution\nactions, most offline RL algorithms take the approach of constraining or\nregularizing the policy with the actions contained in the dataset. Built on\npre-existing RL algorithms, modifications to make an RL algorithm work offline\ncomes at the cost of additional complexity. Offline RL algorithms introduce new\nhyperparameters and often leverage secondary components such as generative\nmodels, while adjusting the underlying RL algorithm. In this paper we aim to\nmake a deep RL algorithm work while making minimal changes. We find that we can\nmatch the performance of state-of-the-art offline RL algorithms by simply\nadding a behavior cloning term to the policy update of an online RL algorithm\nand normalizing the data. The resulting algorithm is a simple to implement and\ntune baseline, while more than halving the overall run time by removing the\nadditional computational overheads of previous methods.",
    "descriptor": "",
    "authors": [
      "Scott Fujimoto",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06860"
  },
  {
    "id": "arXiv:2106.06863",
    "title": "Continuous Wavelet Vocoder-based Decomposition of Parametric Speech  Waveform Synthesis",
    "abstract": "To date, various speech technology systems have adopted the vocoder approach,\na method for synthesizing speech waveform that shows a major role in the\nperformance of statistical parametric speech synthesis. WaveNet one of the best\nmodels that nearly resembles the human voice, has to generate a waveform in a\ntime consuming sequential manner with an extremely complex structure of its\nneural networks.",
    "descriptor": "\nComments: 5 pages, 4 figures, accepted to the conference of Interspeech 2021\n",
    "authors": [
      "Mohammed Salah Al-Radhi",
      "Tam\u00e1s G\u00e1bor Csap\u00f3",
      "Csaba Zaink\u00f3",
      "G\u00e9za N\u00e9meth"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06863"
  },
  {
    "id": "arXiv:2106.06866",
    "title": "A Multi-Implicit Neural Representation for Fonts",
    "abstract": "Fonts are ubiquitous across documents and come in a variety of styles. They\nare either represented in a native vector format or rasterized to produce fixed\nresolution images. In the first case, the non-standard representation prevents\nbenefiting from latest network architectures for neural representations; while,\nin the latter case, the rasterized representation, when encoded via networks,\nresults in loss of data fidelity, as font-specific discontinuities like edges\nand corners are difficult to represent using neural networks. Based on the\nobservation that complex fonts can be represented by a superposition of a set\nof simpler occupancy functions, we introduce \\textit{multi-implicits} to\nrepresent fonts as a permutation-invariant set of learned implict functions,\nwithout losing features (e.g., edges and corners). However, while\nmulti-implicits locally preserve font features, obtaining supervision in the\nform of ground truth multi-channel signals is a problem in itself. Instead, we\npropose how to train such a representation with only local supervision, while\nthe proposed neural architecture directly finds globally consistent\nmulti-implicits for font families. We extensively evaluate the proposed\nrepresentation for various tasks including reconstruction, interpolation, and\nsynthesis to demonstrate clear advantages with existing alternatives.\nAdditionally, the representation naturally enables glyph completion, wherein a\nsingle characteristic font is used to synthesize a whole font family in the\ntarget style.",
    "descriptor": "",
    "authors": [
      "Pradyumna Reddy",
      "Zhifei Zhang",
      "Matthew Fisher",
      "Hailin Jin",
      "Zhaowen Wang",
      "Niloy J. Mitra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.06866"
  },
  {
    "id": "arXiv:2106.06867",
    "title": "A Spatially Dependent Probabilistic Model for House Hunting in Ant  Colonies",
    "abstract": "Ant species such as Temnothorax albipennis select a new nest site in a\ndistributed fashion that, if modeled correctly, can serve as useful information\nfor site selection algorithms for robotic swarms and other applications.\nStudying and replicating the ants' house hunting behavior will also illuminate\nuseful distributed strategies that have evolved in nature. Many of the existing\nmodels of househunting behaviour for T. albipennis make the assumption that all\ncandidate nest sites are equally distant from the ants' home nest, or that an\nant has an equal probability of finding each candidate nest site. However,\nrealistically this is not the case, as nests that are further away from the\nhome nest and nests that are difficult to access are less likely to be found,\neven if they are of higher quality. We extend previous house-hunting models to\naccount for a pairwise distance metric between nests, compare our results to\nthose of real colonies, and use our results to examine the effects of house\nhunting in nests of different spatial orientations. Our incorporation of\ndistances in the ant model appear to match empirical data in situations where a\ndistance-quality tradeoff between nests is relevant. Furthermore, the model\ncontinues to be on par with previous house-hunting models in experiments where\nall candidate nests are equidistant from the home nest, as is typically\nassumed.",
    "descriptor": "",
    "authors": [
      "Grace Cai",
      "Wendy Wu",
      "Wayne Zhao",
      "Jiajia Zhao",
      "Nancy Lynch"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.06867"
  },
  {
    "id": "arXiv:2106.06868",
    "title": "Short-term forecasting of global solar irradiance with incomplete data",
    "abstract": "Accurate mechanisms for forecasting solar irradiance and insolation provide\nimportant information for the planning of renewable energy and agriculture\nprojects as well as for environmental and socio-economical studies. This\nresearch introduces a pipeline for the one-day ahead forecasting of solar\nirradiance and insolation that only requires solar irradiance historical data\nfor training. Furthermore, our approach is able to deal with missing data since\nit includes a data imputation state. In the prediction stage, we consider four\ndata-driven approaches: Autoregressive Integrated Moving Average (ARIMA),\nSingle Layer Feed Forward Network (SL-FNN), Multiple Layer Feed Forward Network\n(FL-FNN), and Long Short-Term Memory (LSTM). The experiments are performed in a\nreal-world dataset collected with 12 Automatic Weather Stations (AWS) located\nin the Nari\\~no - Colombia. The results show that the neural network-based\nmodels outperform ARIMA in most cases. Furthermore, LSTM exhibits better\nperformance in cloudy environments (where more randomness is expected).",
    "descriptor": "",
    "authors": [
      "Laura S. Hoyos-G\u00f3mez",
      "Jose F. Ruiz-Mu\u00f1oz",
      "Belizza J. Ruiz-Mendoza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.06868"
  },
  {
    "id": "arXiv:2106.06873",
    "title": "Weakly-supervised Graph Meta-learning for Few-shot Node Classification",
    "abstract": "Graphs are widely used to model the relational structure of data, and the\nresearch of graph machine learning (ML) has a wide spectrum of applications\nranging from drug design in molecular graphs to friendship recommendation in\nsocial networks. Prevailing approaches for graph ML typically require abundant\nlabeled instances in achieving satisfactory results, which is commonly\ninfeasible in real-world scenarios since labeled data for newly emerged\nconcepts (e.g., new categorizations of nodes) on graphs is limited. Though\nmeta-learning has been applied to different few-shot graph learning problems,\nmost existing efforts predominately assume that all the data from those seen\nclasses is gold-labeled, while those methods may lose their efficacy when the\nseen data is weakly-labeled with severe label noise. As such, we aim to\ninvestigate a novel problem of weakly-supervised graph meta-learning for\nimproving the model robustness in terms of knowledge transfer. To achieve this\ngoal, we propose a new graph meta-learning framework -- Graph Hallucination\nNetworks (Meta-GHN) in this paper. Based on a new robustness-enhanced episodic\ntraining, Meta-GHN is meta-learned to hallucinate clean node representations\nfrom weakly-labeled data and extracts highly transferable meta-knowledge, which\nenables the model to quickly adapt to unseen tasks with few labeled instances.\nExtensive experiments demonstrate the superiority of Meta-GHN over existing\ngraph meta-learning studies on the task of weakly-supervised few-shot node\nclassification.",
    "descriptor": "",
    "authors": [
      "Kaize Ding",
      "Jianling Wang",
      "Jundong Li",
      "James Caverlee",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06873"
  },
  {
    "id": "arXiv:2106.06875",
    "title": "Don't Rule Out Monolingual Speakers: A Method For Crowdsourcing Machine  Translation Data",
    "abstract": "High-performing machine translation (MT) systems can help overcome language\nbarriers while making it possible for everyone to communicate and use language\ntechnologies in the language of their choice. However, such systems require\nlarge amounts of parallel sentences for training, and translators can be\ndifficult to find and expensive. Here, we present a data collection strategy\nfor MT which, in contrast, is cheap and simple, as it does not require\nbilingual speakers. Based on the insight that humans pay specific attention to\nmovements, we use graphics interchange formats (GIFs) as a pivot to collect\nparallel sentences from monolingual annotators. We use our strategy to collect\ndata in Hindi, Tamil and English. As a baseline, we also collect data using\nimages as a pivot. We perform an intrinsic evaluation by manually evaluating a\nsubset of the sentence pairs and an extrinsic evaluation by finetuning mBART on\nthe collected data. We find that sentences collected via GIFs are indeed of\nhigher quality.",
    "descriptor": "\nComments: 5 pages, 1 figure, ACL-IJCNLP 2021 submission, Natural Language Processing, Data Collection, Monolingual Speakers, Machine Translation, GIFs, Images\n",
    "authors": [
      "Rajat Bhatnagar",
      "Ananya Ganesh",
      "Katharina Kann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06875"
  },
  {
    "id": "arXiv:2106.06876",
    "title": "Affine OneMax",
    "abstract": "A new class of test functions for black box optimization is introduced.\nAffine OneMax (AOM) functions are defined as compositions of OneMax and\ninvertible affine maps on bit vectors. The black box complexity of the class is\nupper bounded by a polynomial of large degree in the dimension. The proof\nrelies on discrete Fourier analysis and the Kushilevitz-Mansour algorithm.\nTunable complexity is achieved by expressing invertible linear maps as finite\nproducts of transvections. The black box complexity of sub-classes of AOM\nfunctions is studied. Finally, experimental results are given to illustrate the\nperformance of search algorithms on AOM functions.",
    "descriptor": "\nComments: An extended two-page abstract of this work will appear in 2021 Genetic and Evolutionary Computation Conference Companion (GECCO '21 Companion)\n",
    "authors": [
      "Arnaud Berny"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.06876"
  },
  {
    "id": "arXiv:2106.06878",
    "title": "Probabilistic Group Testing with a Linear Number of Tests",
    "abstract": "In probabilistic nonadaptive group testing (PGT), we aim to characterize the\nnumber of pooled tests necessary to identify a random $k$-sparse vector of\ndefectives with high probability. Recent work has shown that $n$ tests are\nnecessary when $k =\\omega(n/\\log n)$. It is also known that $O(k \\log n)$ tests\nare necessary and sufficient in other regimes. This leaves open the important\nsparsity regime where the probability of a defective item is $\\sim 1/\\log n$\n(or $k = \\Theta(n/\\log n)$) where the number of tests required is linear in\n$n$. In this work we aim to exactly characterize the number of tests in this\nsparsity regime. In particular, we seek to determine the number of defectives\n$\\lambda(\\alpha)n / \\log n$ that can be identified if the number of tests is\n$\\alpha n$. In the process, we give upper and lower bounds on the exact point\nat which individual testing becomes suboptimal, and the use of a carefully\nconstructed pooled test design is beneficial.",
    "descriptor": "\nComments: 11 pages, 1 figure. To be published in ISIT 2021\n",
    "authors": [
      "Larkin Flodin",
      "Arya Mazumdar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.06878"
  },
  {
    "id": "arXiv:2106.06880",
    "title": "Random Shuffling Beats SGD Only After Many Epochs on Ill-Conditioned  Problems",
    "abstract": "Recently, there has been much interest in studying the convergence rates of\nwithout-replacement SGD, and proving that it is faster than with-replacement\nSGD in the worst case. However, these works ignore or do not provide tight\nbounds in terms of the problem's geometry, including its condition number.\nPerhaps surprisingly, we prove that when the condition number is taken into\naccount, without-replacement SGD \\emph{does not} significantly improve on\nwith-replacement SGD in terms of worst-case bounds, unless the number of epochs\n(passes over the data) is larger than the condition number. Since many problems\nin machine learning and other areas are both ill-conditioned and involve large\ndatasets, this indicates that without-replacement does not necessarily improve\nover with-replacement sampling for realistic iteration budgets. We show this by\nproviding new lower and upper bounds which are tight (up to log factors), for\nquadratic problems with commuting quadratic terms, precisely quantifying the\ndependence on the problem parameters.",
    "descriptor": "",
    "authors": [
      "Itay Safran",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06880"
  },
  {
    "id": "arXiv:2106.06882",
    "title": "Sparse PointPillars: Exploiting Sparsity in Birds-Eye-View Object  Detection",
    "abstract": "Bird's Eye View (BEV) is a popular representation for processing 3D point\nclouds, and by its nature is fundamentally sparse. Motivated by the\ncomputational limitations of mobile robot platforms, we take a fast\nhigh-performance BEV 3D object detector - PointPillars - and modify its\nbackbone to exploit this sparsity, leading to decreased runtimes. We present\npreliminary results demonstrating decreased runtimes with either the same\nperformance or a modest decrease in performance, which we anticipate will be\nremedied by model specific hyperparameter tuning. Our work is a first step\ntowards a new class of 3D object detectors that exploit sparsity throughout\ntheir entire pipeline in order to reduce runtime and resource usage while\nmaintaining good detection performance.",
    "descriptor": "",
    "authors": [
      "Kyle Vedder",
      "Eric Eaton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06882"
  },
  {
    "id": "arXiv:2106.06885",
    "title": "Online Learning with Optimism and Delay",
    "abstract": "Inspired by the demands of real-time climate and weather forecasting, we\ndevelop optimistic online learning algorithms that require no parameter tuning\nand have optimal regret guarantees under delayed feedback. Our algorithms --\nDORM, DORMP, and AdaHedgeD -- arise from a novel reduction of delayed online\nlearning to optimistic online learning that reveals how optimistic hints can\nmitigate the regret penalty caused by delay. We pair this delay-as-optimism\nperspective with a new analysis of optimistic learning that exposes its\nrobustness to hinting errors and a new meta-algorithm for learning effective\nhinting strategies in the presence of delay. We conclude by benchmarking our\nalgorithms on four subseasonal climate forecasting tasks, demonstrating low\nregret relative to state-of-the-art forecasting models.",
    "descriptor": "\nComments: ICML 2021. 9 pages of main paper and 26 pages of appendix text\n",
    "authors": [
      "Genevieve Flaspohler",
      "Francesco Orabona",
      "Judah Cohen",
      "Soukayna Mouatadid",
      "Miruna Oprescu",
      "Paulo Orenstein",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06885"
  },
  {
    "id": "arXiv:2106.06887",
    "title": "The Spatio-Temporal Poisson Point Process: A Simple Model for the  Alignment of Event Camera Data",
    "abstract": "Event cameras, inspired by biological vision systems, provide a natural and\ndata efficient representation of visual information. Visual information is\nacquired in the form of events that are triggered by local brightness changes.\nEach pixel location of the camera's sensor records events asynchronously and\nindependently with very high temporal resolution. However, because most\nbrightness changes are triggered by relative motion of the camera and the\nscene, the events recorded at a single sensor location seldom correspond to the\nsame world point. To extract meaningful information from event cameras, it is\nhelpful to register events that were triggered by the same underlying world\npoint. In this work we propose a new model of event data that captures its\nnatural spatio-temporal structure. We start by developing a model for aligned\nevent data. That is, we develop a model for the data as though it has been\nperfectly registered already. In particular, we model the aligned data as a\nspatio-temporal Poisson point process. Based on this model, we develop a\nmaximum likelihood approach to registering events that are not yet aligned.\nThat is, we find transformations of the observed events that make them as\nlikely as possible under our model. In particular we extract the camera\nrotation that leads to the best event alignment. We show new state of the art\naccuracy for rotational velocity estimation on the DAVIS 240C dataset. In\naddition, our method is also faster and has lower computational complexity than\nseveral competing methods.",
    "descriptor": "",
    "authors": [
      "Cheng Gu",
      "Erik Learned-Miller",
      "Daniel Sheldon",
      "Guillermo Gallego",
      "Pia Bideau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06887"
  },
  {
    "id": "arXiv:2106.06889",
    "title": "G-TADOC: Enabling Efficient GPU-Based Text Analytics without  Decompression",
    "abstract": "Text analytics directly on compression (TADOC) has proven to be a promising\ntechnology for big data analytics. GPUs are extremely popular accelerators for\ndata analytics systems. Unfortunately, no work so far shows how to utilize GPUs\nto accelerate TADOC. We describe G-TADOC, the first framework that provides\nGPU-based text analytics directly on compression, effectively enabling\nefficient text analytics on GPUs without decompressing the input data. G-TADOC\nsolves three major challenges. First, TADOC involves a large amount of\ndependencies, which makes it difficult to exploit massive parallelism on a GPU.\nWe develop a novel fine-grained thread-level workload scheduling strategy for\nGPU threads, which partitions heavily-dependent loads adaptively in a\nfine-grained manner. Second, in developing G-TADOC, thousands of GPU threads\nwriting to the same result buffer leads to inconsistency while directly using\nlocks and atomic operations lead to large synchronization overheads. We develop\na memory pool with thread-safe data structures on GPUs to handle such\ndifficulties. Third, maintaining the sequence information among words is\nessential for lossless compression. We design a sequence-support strategy,\nwhich maintains high GPU parallelism while ensuring sequence information. Our\nexperimental evaluations show that G-TADOC provides 31.1x average speedup\ncompared to state-of-the-art TADOC.",
    "descriptor": "\nComments: 37th IEEE International Conference on Data Engineering (ICDE 2021)\n",
    "authors": [
      "Feng Zhang",
      "Zaifeng Pan",
      "Yanliang Zhou",
      "Jidong Zhai",
      "Xipeng Shen",
      "Onur Mutlu",
      "Xiaoyong Du"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.06889"
  },
  {
    "id": "arXiv:2106.06892",
    "title": "Improved Guarantees for Offline Stochastic Matching via new Ordered  Contention Resolution Schemes",
    "abstract": "Matching is one of the most fundamental and broadly applicable problems\nacross many domains. In these diverse real-world applications, there is often a\ndegree of uncertainty in the input which has led to the study of stochastic\nmatching models. Here, each edge in the graph has a known, independent\nprobability of existing derived from some prediction. Algorithms must probe\nedges to determine existence and match them irrevocably if they exist. Further,\neach vertex may have a patience constraint denoting how many of its neighboring\nedges can be probed. We present new ordered contention resolution schemes\nyielding improved approximation guarantees for some of the foundational\nproblems studied in this area. For stochastic matching with patience\nconstraints in general graphs, we provide a 0.382-approximate algorithm,\nsignificantly improving over the previous best 0.31-approximation of Baveja et\nal. (2018). When the vertices do not have patience constraints, we describe a\n0.432-approximate random order probing algorithm with several corollaries such\nas an improved guarantee for the Prophet Secretary problem under Edge Arrivals.\nFinally, for the special case of bipartite graphs with unit patience\nconstraints on one of the partitions, we show a 0.632-approximate algorithm\nthat improves on the recent $1/3$-guarantee of Hikima et al. (2021).",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Brian Brubach",
      "Nathaniel Grammel",
      "Will Ma",
      "Aravind Srinivasan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.06892"
  },
  {
    "id": "arXiv:2106.06895",
    "title": "FeSHI: Feature Map Based Stealthy Hardware Intrinsic Attack",
    "abstract": "Convolutional Neural Networks (CNN) have shown impressive performance in\ncomputer vision, natural language processing, and many other applications, but\nthey exhibit high computations and substantial memory requirements. To address\nthese limitations, especially in resource-constrained devices, the use of cloud\ncomputing for CNNs is becoming more popular. This comes with privacy and\nlatency concerns that have motivated the designers to develop embedded hardware\naccelerators for CNNs. However, designing a specialized accelerator increases\nthe time-to-market and cost of production. Therefore, to reduce the\ntime-to-market and access to state-of-the-art techniques, CNN hardware mapping\nand deployment on embedded accelerators are often outsourced to untrusted third\nparties, which is going to be more prevalent in futuristic artificial\nintelligence of things (AIoT) systems. These AIoT systems anticipate horizontal\ncollaboration among different resource-constrained AIoT node devices, where CNN\nlayers are partitioned and these devices collaboratively compute complex CNN\ntasks Therefore, there is a dire need to explore this attack surface for\ndesigning secure embedded hardware accelerators for CNNs. Towards this goal, in\nthis paper, we exploited this attack surface to propose an HT-based attack\ncalled FeSHI. This attack exploits the statistical distribution i.e., Gaussian\ndistribution, of the layer-by-layer feature maps of the CNN to design two\ntriggers for stealthy HT with a very low probability of triggering. To\nillustrate the effectiveness of the proposed attack, we deployed the LeNet and\nLeNet-3D on PYNQ to classify the MNIST and CIFAR-10 datasets, respectively, and\ntested FeSHI. The experimental results show that FeSHI utilizes up to 2% extra\nLUTs, and the overall resource overhead is less than 1% compared to the\noriginal designs",
    "descriptor": "",
    "authors": [
      "Tolulope Odetola",
      "Faiq Khalid",
      "Travis Sandefur",
      "Hawzhin Mohammed",
      "Syed Rafay Hasan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06895"
  },
  {
    "id": "arXiv:2106.06896",
    "title": "Hyperspectral and Multispectral Classification for Coastal Wetland Using  Depthwise Feature Interaction Network",
    "abstract": "The monitoring of coastal wetlands is of great importance to the protection\nof marine and terrestrial ecosystems. However, due to the complex environment,\nsevere vegetation mixture, and difficulty of access, it is impossible to\naccurately classify coastal wetlands and identify their species with\ntraditional classifiers. Despite the integration of multisource remote sensing\ndata for performance enhancement, there are still challenges with acquiring and\nexploiting the complementary merits from multisource data. In this paper, the\nDeepwise Feature Interaction Network (DFINet) is proposed for wetland\nclassification. A depthwise cross attention module is designed to extract\nself-correlation and cross-correlation from multisource feature pairs. In this\nway, meaningful complementary information is emphasized for classification.\nDFINet is optimized by coordinating consistency loss, discrimination loss, and\nclassification loss. Accordingly, DFINet reaches the standard solution-space\nunder the regularity of loss functions, while the spatial consistency and\nfeature discrimination are preserved. Comprehensive experimental results on two\nhyperspectral and multispectral wetland datasets demonstrate that the proposed\nDFINet outperforms other competitive methods in terms of overall accuracy.",
    "descriptor": "",
    "authors": [
      "Yunhao Gao",
      "Wei Li",
      "Mengmeng Zhang",
      "Jianbu Wang",
      "Weiwei Sun",
      "Ran Tao",
      "Qian Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.06896"
  },
  {
    "id": "arXiv:2106.06898",
    "title": "Markov Neural Operators for Learning Chaotic Systems",
    "abstract": "Chaotic systems are notoriously challenging to predict because of their\ninstability. Small errors accumulate in the simulation of each time step,\nresulting in completely different trajectories. However, the trajectories of\nmany prominent chaotic systems live in a low-dimensional subspace (attractor).\nIf the system is Markovian, the attractor is uniquely determined by the Markov\noperator that maps the evolution of infinitesimal time steps. This makes it\npossible to predict the behavior of the chaotic system by learning the Markov\noperator even if we cannot predict the exact trajectory. Recently, a new\nframework for learning resolution-invariant solution operators for PDEs was\nproposed, known as neural operators. In this work, we train a Markov neural\noperator (MNO) with only the local one-step evolution information. We then\ncompose the learned operator to obtain the global attractor and invariant\nmeasure. Such a Markov neural operator forms a discrete semigroup and we\nempirically observe that does not collapse or blow up. Experiments show neural\noperators are more accurate and stable compared to previous methods on chaotic\nsystems such as the Kuramoto-Sivashinsky and Navier-Stokes equations.",
    "descriptor": "",
    "authors": [
      "Zongyi Li",
      "Nikola Kovachki",
      "Kamyar Azizzadenesheli",
      "Burigede Liu",
      "Kaushik Bhattacharya",
      "Andrew Stuart",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.06898"
  },
  {
    "id": "arXiv:2106.06899",
    "title": "Memory-efficient Transformers via Top-$k$ Attention",
    "abstract": "Following the success of dot-product attention in Transformers, numerous\napproximations have been recently proposed to address its quadratic complexity\nwith respect to the input length. While these variants are memory and compute\nefficient, it is not possible to directly use them with popular pre-trained\nlanguage models trained using vanilla attention, without an expensive\ncorrective pre-training stage. In this work, we propose a simple yet highly\naccurate approximation for vanilla attention. We process the queries in chunks,\nand for each query, compute the top-$k$ scores with respect to the keys. Our\napproach offers several advantages: (a) its memory usage is linear in the input\nsize, similar to linear attention variants, such as Performer and RFA (b) it is\na drop-in replacement for vanilla attention that does not require any\ncorrective pre-training, and (c) it can also lead to significant memory savings\nin the feed-forward layers after casting them into the familiar query-key-value\nframework. We evaluate the quality of top-$k$ approximation for multi-head\nattention layers on the Long Range Arena Benchmark, and for feed-forward layers\nof T5 and UnifiedQA on multiple QA datasets. We show our approach leads to\naccuracy that is nearly-identical to vanilla attention in multiple setups\nincluding training from scratch, fine-tuning, and zero-shot inference.",
    "descriptor": "",
    "authors": [
      "Ankit Gupta",
      "Guy Dar",
      "Shaya Goodman",
      "David Ciprut",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06899"
  },
  {
    "id": "arXiv:2106.06900",
    "title": "Deep Reinforcement Learning based Group Recommender System",
    "abstract": "Group recommender systems are widely used in current web applications. In\nthis paper, we propose a novel group recommender system based on the deep\nreinforcement learning. We introduce the MovieLens data at first and generate\none random group dataset, MovieLens-Rand, from it. This randomly generated\ndataset is described and analyzed. We also present experimental settings and\ntwo state-of-art baselines, AGREE and GroupIM. The framework of our novel\nmodel, the Deep Reinforcement learning based Group Recommender system (DRGR),\nis proposed. Actor-critic networks are implemented with the deep deterministic\npolicy gradient algorithm. The DRGR model is applied on the MovieLens-Rand\ndataset with two baselines. Compared with baselines, we conclude that DRGR\nperforms better than GroupIM due to long interaction histories but worse than\nAGREE because of the self-attention mechanism. We express advantages and\nshortcomings of DRGR and also give future improvement directions at the end.",
    "descriptor": "",
    "authors": [
      "Zefang Liu",
      "Shuran Wen",
      "Yinzhu Quan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.06900"
  },
  {
    "id": "arXiv:2106.06901",
    "title": "Multi-User Communication with Extremely Large-Scale MIMO",
    "abstract": "Extremely large-scale multiple-input multiple-output (XL-MIMO) communication\naims to further boost the antenna size significantly than current massive MIMO\nsystems, for which conventional far-field assumption with uniform plane wave\n(UPW) model may become invalid. This paper studies the modelling and\nperformance analysis for multi-user XL-MIMO communication. With the spherical\nwavefront phase modelling, and also by taking into account the variations of\nsignal amplitude and projected aperture across array elements, the performance\nof the three typical beamforming schemes are analyzed, namely the maximal-ratio\ncombining (MRC), zero-forcing (ZF), and minimum mean-square error (MMSE)\nbeamforming. For the special case of two-users, we analytically show that the\nsignal-to-interference-plus-noise ratio (SINR) of all the three beamforming\nschemes increases as the channels' correlation coefficient decreases.\nFurthermore, compared to existing UPW model where inter-user interference (IUI)\ncan only be suppressed in angular domain, XL-MIMO enables a new\ndegree-of-freedom (DoF) for IUI suppression by distance separation, even for\nusers along the same direction. Simulation results are provided to validate the\nmodelling and performance analysis of multi-user XL-MIMO communications.",
    "descriptor": "\nComments: 5 pages, 8 figures\n",
    "authors": [
      "Haiquan Lu",
      "Yong Zeng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.06901"
  },
  {
    "id": "arXiv:2106.06905",
    "title": "InfoBehavior: Self-supervised Representation Learning for Ultra-long  Behavior Sequence via Hierarchical Grouping",
    "abstract": "E-commerce companies have to face abnormal sellers who sell potentially-risky\nproducts. Typically, the risk can be identified by jointly considering product\ncontent (e.g., title and image) and seller behavior. This work focuses on\nbehavior feature extraction as behavior sequences can provide valuable clues\nfor the risk discovery by reflecting the sellers' operation habits. Traditional\nfeature extraction techniques heavily depend on domain experts and adapt poorly\nto new tasks. In this paper, we propose a self-supervised method InfoBehavior\nto automatically extract meaningful representations from ultra-long raw\nbehavior sequences instead of the costly feature selection procedure.\nInfoBehavior utilizes Bidirectional Transformer as feature encoder due to its\nexcellent capability in modeling long-term dependency. However, it is\nintractable for commodity GPUs because the time and memory required by\nTransformer grow quadratically with the increase of sequence length. Thus, we\npropose a hierarchical grouping strategy to aggregate ultra-long raw behavior\nsequences to length-processable high-level embedding sequences. Moreover, we\nintroduce two types of pretext tasks. Sequence-related pretext task defines a\ncontrastive-based training objective to correctly select the masked-out\ncoarse-grained/fine-grained behavior sequences against other \"distractor\"\nbehavior sequences; Domain-related pretext task designs a classification\ntraining objective to correctly predict the domain-specific statistical results\nof anomalous behavior. We show that behavior representations from the\npre-trained InfoBehavior can be directly used or integrated with features from\nother side information to support a wide range of downstream tasks.\nExperimental results demonstrate that InfoBehavior significantly improves the\nperformance of Product Risk Management and Intellectual Property Protection.",
    "descriptor": "",
    "authors": [
      "Runshi Liu",
      "Pengda Qin",
      "Yuhong Li",
      "Weigao Wen",
      "Dong Li",
      "Kefeng Deng",
      "Qiang Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06905"
  },
  {
    "id": "arXiv:2106.06906",
    "title": "Optimal Sensor Precision for Multi-Rate Sensing for Bounded Estimation  Error",
    "abstract": "We address the problem of determining optimal sensor precisions for\nestimating the states of linear time-varying discrete-time stochastic dynamical\nsystems, with guaranteed bounds on the estimation errors. This is performed in\nthe Kalman filtering framework, where the sensor precisions are treated as\nvariables. They are determined by solving a constrained convex optimization\nproblem, which guarantees the specified upper bound on the posterior error\nvariance. Optimal sensor precisions are determined by minimizing the l1 norm,\nwhich promotes sparseness in the solution and indirectly addresses the sensor\nselection problem. The theory is applied to realistic flight mechanics and\nastrodynamics problems to highlight its engineering value. These examples\ndemonstrate the application of the presented theory to a) determine redundant\nsensing architectures for linear time invariant systems, b) accurately estimate\nstates with low-cost sensors, and c) optimally schedule sensors for linear\ntime-varying systems.",
    "descriptor": "\nComments: 26 pages, 6 figures\n",
    "authors": [
      "Niladri Das",
      "Raktim Bhattacharya"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.06906"
  },
  {
    "id": "arXiv:2106.06907",
    "title": "INADVERT: An Interactive and Adaptive Counterdeception Platform for  Attention Enhancement and Phishing Prevention",
    "abstract": "Deceptive attacks exploiting the innate and the acquired vulnerabilities of\nhuman users have posed severe threats to information and infrastructure\nsecurity. This work proposes INADVERT, a systematic solution that generates\ninteractive visual aids in real-time to prevent users from inadvertence and\ncounter visual-deception attacks. Based on the eye-tracking outcomes and proper\ndata compression, the INADVERT platform automatically adapts the visual aids to\nthe user's varying attention status captured by the gaze location and duration.\nWe extract system-level metrics to evaluate the user's average attention level\nand characterize the magnitude and frequency of the user's mind-wandering\nbehaviors. These metrics contribute to an adaptive enhancement of the user's\nattention through reinforcement learning. To determine the optimal\nhyper-parameters in the attention enhancement mechanism, we develop an\nalgorithm based on Bayesian optimization to efficiently update the design of\nthe INADVERT platform and maximize the accuracy of the users' phishing\nrecognition.",
    "descriptor": "",
    "authors": [
      "Linan Huang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06907"
  },
  {
    "id": "arXiv:2106.06908",
    "title": "Domain Generalization on Medical Imaging Classification using Episodic  Training with Task Augmentation",
    "abstract": "Medical imaging datasets usually exhibit domain shift due to the variations\nof scanner vendors, imaging protocols, etc. This raises the concern about the\ngeneralization capacity of machine learning models. Domain generalization (DG),\nwhich aims to learn a model from multiple source domains such that it can be\ndirectly generalized to unseen test domains, seems particularly promising to\nmedical imaging community. To address DG, recent model-agnostic meta-learning\n(MAML) has been introduced, which transfers the knowledge from previous\ntraining tasks to facilitate the learning of novel testing tasks. However, in\nclinical practice, there are usually only a few annotated source domains\navailable, which decreases the capacity of training task generation and thus\nincreases the risk of overfitting to training tasks in the paradigm. In this\npaper, we propose a novel DG scheme of episodic training with task augmentation\non medical imaging classification. Based on meta-learning, we develop the\nparadigm of episodic training to construct the knowledge transfer from episodic\ntraining-task simulation to the real testing task of DG. Motivated by the\nlimited number of source domains in real-world medical deployment, we consider\nthe unique task-level overfitting and we propose task augmentation to enhance\nthe variety during training task generation to alleviate it. With the\nestablished learning framework, we further exploit a novel meta-objective to\nregularize the deep embedding of training domains. To validate the\neffectiveness of the proposed method, we perform experiments on\nhistopathological images and abdominal CT images.",
    "descriptor": "",
    "authors": [
      "Chenxin Li",
      "Qi Qi",
      "Xinghao Ding",
      "Yue Huang",
      "Dong Liang",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06908"
  },
  {
    "id": "arXiv:2106.06909",
    "title": "GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of  Transcribed Audio",
    "abstract": "This paper introduces GigaSpeech, an evolving, multi-domain English speech\nrecognition corpus with 10,000 hours of high quality labeled audio suitable for\nsupervised training, and 40,000 hours of total audio suitable for\nsemi-supervised and unsupervised training. Around 40,000 hours of transcribed\naudio is first collected from audiobooks, podcasts and YouTube, covering both\nread and spontaneous speaking styles, and a variety of topics, such as arts,\nscience, sports, etc. A new forced alignment and segmentation pipeline is\nproposed to create sentence segments suitable for speech recognition training,\nand to filter out segments with low-quality transcription. For system training,\nGigaSpeech provides five subsets of different sizes, 10h, 250h, 1000h, 2500h,\nand 10000h. For our 10,000-hour XL training subset, we cap the word error rate\nat 4% during the filtering/validation stage, and for all our other smaller\ntraining subsets, we cap it at 0%. The DEV and TEST evaluation sets, on the\nother hand, are re-processed by professional human transcribers to ensure high\ntranscription quality. Baseline systems are provided for popular speech\nrecognition toolkits, namely Athena, ESPnet, Kaldi and Pika.",
    "descriptor": "",
    "authors": [
      "Guoguo Chen",
      "Shuzhou Chai",
      "Guanbo Wang",
      "Jiayu Du",
      "Wei-Qiang Zhang",
      "Chao Weng",
      "Dan Su",
      "Daniel Povey",
      "Jan Trmal",
      "Junbo Zhang",
      "Mingjie Jin",
      "Sanjeev Khudanpur",
      "Shinji Watanabe",
      "Shuaijiang Zhao",
      "Wei Zou",
      "Xiangang Li",
      "Xuchen Yao",
      "Yongqing Wang",
      "Yujun Wang",
      "Zhao You",
      "Zhiyong Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.06909"
  },
  {
    "id": "arXiv:2106.06910",
    "title": "Sentiment Analysis of Covid-19 Tweets using Evolutionary  Classification-Based LSTM Model",
    "abstract": "As the Covid-19 outbreaks rapidly all over the world day by day and also\naffects the lives of million, a number of countries declared complete lock-down\nto check its intensity. During this lockdown period, social media plat-forms\nhave played an important role to spread information about this pandemic across\nthe world, as people used to express their feelings through the social\nnetworks. Considering this catastrophic situation, we developed an experimental\napproach to analyze the reactions of people on Twitter taking into ac-count the\npopular words either directly or indirectly based on this pandemic. This paper\nrepresents the sentiment analysis on collected large number of tweets on\nCoronavirus or Covid-19. At first, we analyze the trend of public sentiment on\nthe topics related to Covid-19 epidemic using an evolutionary classification\nfollowed by the n-gram analysis. Then we calculated the sentiment ratings on\ncollected tweet based on their class. Finally, we trained the long-short term\nnetwork using two types of rated tweets to predict sentiment on Covid-19 data\nand obtained an overall accuracy of 84.46%.",
    "descriptor": "\nComments: 11 pages, 8 figures, 5 tables\n",
    "authors": [
      "Arunava Kumar Chakraborty",
      "Sourav Das",
      "Anup Kumar Kolya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.06910"
  },
  {
    "id": "arXiv:2106.06911",
    "title": "An Interaction-based Convolutional Neural Network (ICNN) Towards Better  Understanding of COVID-19 X-ray Images",
    "abstract": "The field of Explainable Artificial Intelligence (XAI) aims to build\nexplainable and interpretable machine learning (or deep learning) methods\nwithout sacrificing prediction performance. Convolutional Neural Networks\n(CNNs) have been successful in making predictions, especially in image\nclassification. However, these famous deep learning models use tens of millions\nof parameters based on a large number of pre-trained filters which have been\nrepurposed from previous data sets. We propose a novel Interaction-based\nConvolutional Neural Network (ICNN) that does not make assumptions about the\nrelevance of local information. Instead, we use a model-free Influence Score\n(I-score) to directly extract the influential information from images to form\nimportant variable modules. We demonstrate that the proposed method produces\nstate-of-the-art prediction performance of 99.8% on a real-world data set\nclassifying COVID-19 Chest X-ray images without sacrificing the explanatory\npower of the model. This proposed design can efficiently screen COVID-19\npatients before human diagnosis, and will be the benchmark for addressing\nfuture XAI problems in large-scale data sets.",
    "descriptor": "",
    "authors": [
      "Shaw-Hwa Lo",
      "Yiqiao Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06911"
  },
  {
    "id": "arXiv:2106.06916",
    "title": "Non-Transferable Learning: A New Approach for Model Verification and  Authorization",
    "abstract": "As Artificial Intelligence as a Service gains popularity, protecting\nwell-trained models as intellectual property is becoming increasingly\nimportant. Generally speaking, there are two common protection methods:\nownership verification and usage authorization. In this paper, we propose\nNon-Transferable Learning (NTL), a novel approach that captures the exclusive\ndata representation in the learned model and restricts the model generalization\nability to certain domains. This approach provides effective solutions to both\nmodel verification and authorization. For ownership verification, watermarking\ntechniques are commonly used but are often vulnerable to sophisticated\nwatermark removal methods. Our NTL-based model verification approach instead\nprovides robust resistance to state-of-the-art watermark removal methods, as\nshown in extensive experiments for four of such methods over the digits,\nCIFAR10 & STL10, and VisDA datasets. For usage authorization, prior solutions\nfocus on authorizing specific users to use the model, but authorized users can\nstill apply the model to any data without restriction. Our NTL-based\nauthorization approach instead provides data-centric usage protection by\nsignificantly degrading the performance of usage on unauthorized data. Its\neffectiveness is also shown through experiments on a variety of datasets.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Lixu Wang",
      "Shichao Xu",
      "Ruiqi Xu",
      "Xiao Wang",
      "Qi Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06916"
  },
  {
    "id": "arXiv:2106.06917",
    "title": "ATRAS: Adversarially Trained Robust Architecture Search",
    "abstract": "In this paper, we explore the effect of architecture completeness on\nadversarial robustness. We train models with different architectures on\nCIFAR-10 and MNIST dataset. For each model, we vary different number of layers\nand different number of nodes in the layer. For every architecture candidate,\nwe use Fast Gradient Sign Method (FGSM) to generate untargeted adversarial\nattacks and use adversarial training to defend against those attacks. For each\narchitecture candidate, we report pre-attack, post-attack and post-defense\naccuracy for the model as well as the architecture parameters and the impact of\ncompleteness to the model accuracies.",
    "descriptor": "\nComments: 9 pages, 2 figures, 2 tables\n",
    "authors": [
      "Yigit Alparslan",
      "Edward Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06917"
  },
  {
    "id": "arXiv:2106.06920",
    "title": "Multi-modal Scene-compliant User Intention Estimation for Navigation",
    "abstract": "A multi-modal framework to generated user intention distributions when\noperating a mobile vehicle is proposed in this work. The model learns from past\nobserved trajectories and leverages traversability information derived from the\nvisual surroundings to produce a set of future trajectories, suitable to be\ndirectly embedded into a perception-action shared control strategy on a mobile\nagent, or as a safety layer to supervise the prudent operation of the vehicle.\nWe base our solution on a conditional Generative Adversarial Network with\nLong-Short Term Memory cells to capture trajectory distributions conditioned on\npast trajectories, further fused with traversability probabilities derived from\nvisual segmentation with a Convolutional Neural Network. The proposed\ndata-driven framework results in a significant reduction in error of the\npredicted trajectories (versus the ground truth) from comparable strategies in\nthe literature (e.g. Social-GAN) that fail to account for information other\nthan the agent's past history. Experiments were conducted on a dataset\ncollected with a custom wheelchair model built onto the open-source urban\ndriving simulator CARLA, proving also that the proposed framework can be used\nwith a small, un-annotated dataset.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Kavindie Katuwandeniya",
      "Stefan H. Kiss",
      "Lei Shi",
      "Jaime Valls Miro"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06920"
  },
  {
    "id": "arXiv:2106.06921",
    "title": "Adaptive Dynamic Pruning for Non-IID Federated Learning",
    "abstract": "Federated Learning~(FL) has emerged as a new paradigm of training machine\nlearning models without sacrificing data security and privacy. Learning models\nat edge devices such as cell phones is one of the most common use case of FL.\nHowever, the limited computing power and energy constraints of edge devices\nhinder the adoption of FL for both model training and deployment, especially\nfor the resource-hungry Deep Neural Networks~(DNNs). To this end, many model\ncompression methods have been proposed and network pruning is among the most\nwell-known. However, a pruning policy for a given model is highly\ndataset-dependent, which is not suitable for non-Independent and Identically\nDistributed~(Non-IID) FL edge devices. In this paper, we present an adaptive\npruning scheme for edge devices in an FL system, which applies dataset-aware\ndynamic pruning for inference acceleration on Non-IID datasets. Our evaluation\nshows that the proposed method accelerates inference by $2\\times$~($50\\%$ FLOPs\nreduction) while maintaining the model's quality on edge devices.",
    "descriptor": "",
    "authors": [
      "Sixing Yu",
      "Phuong Nguyen",
      "Ali Anwar",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06921"
  },
  {
    "id": "arXiv:2106.06922",
    "title": "Cross-sentence Neural Language Models for Conversational Speech  Recognition",
    "abstract": "An important research direction in automatic speech recognition (ASR) has\ncentered around the development of effective methods to rerank the output\nhypotheses of an ASR system with more sophisticated language models (LMs) for\nfurther gains. A current mainstream school of thoughts for ASR N-best\nhypothesis reranking is to employ a recurrent neural network (RNN)-based LM or\nits variants, with performance superiority over the conventional n-gram LMs\nacross a range of ASR tasks. In real scenarios such as a long conversation, a\nsequence of consecutive sentences may jointly contain ample cues of\nconversation-level information such as topical coherence, lexical entrainment\nand adjacency pairs, which however remains to be underexplored. In view of\nthis, we first formulate ASR N-best reranking as a prediction problem, putting\nforward an effective cross-sentence neural LM approach that reranks the ASR\nN-best hypotheses of an upcoming sentence by taking into consideration the word\nusage in its precedent sentences. Furthermore, we also explore to extract\ntask-specific global topical information of the cross-sentence history in an\nunsupervised manner for better ASR performance. Extensive experiments conducted\non the AMI conversational benchmark corpus indicate the effectiveness and\nfeasibility of our methods in comparison to several state-of-the-art reranking\nmethods.",
    "descriptor": "\nComments: 7 pages, 7 figures, Accepted to IEEE IJCNN 2021. arXiv admin note: substantial text overlap with arXiv:2104.04950\n",
    "authors": [
      "Shih-Hsuan Chiu",
      "Tien-Hong Lo",
      "Berlin Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.06922"
  },
  {
    "id": "arXiv:2106.06924",
    "title": "Deep Learning for Reversible Steganography: Principles and Insights",
    "abstract": "Deep-learning\\textendash{centric} reversible steganography has emerged as a\npromising research paradigm. A direct way of applying deep learning to\nreversible steganography is to construct a pair of encoder and decoder, whose\nparameters are trained jointly, thereby learning the steganographic system as a\nwhole. This end-to-end framework, however, falls short of the reversibility\nrequirement because it is difficult for this kind of monolithic system, as a\nblack box, to create or duplicate intricate reversible mechanisms. In response\nto this issue, a recent approach is to carve up the steganographic system and\nwork on modules independently. In particular, neural networks are deployed in\nan analytics module to learn the data distribution, while an established\nmechanism is called upon to handle the remaining tasks. In this paper, we\ninvestigate the modular framework and deploy deep neural networks in a\nreversible steganographic scheme referred to as prediction-error modulation, in\nwhich an analytics module serves the purpose of pixel intensity prediction. The\nprimary focus of this study is on deep-learning\\textendash{based} context-aware\npixel intensity prediction. We address the unsolved issues reported in related\nliterature, including the impact of pixel initialisation on prediction accuracy\nand the influence of uncertainty propagation in dual-layer embedding.\nFurthermore, we establish a connection between context-aware pixel intensity\nprediction and low-level computer vision and analyse the performance of several\nadvanced neural networks.",
    "descriptor": "",
    "authors": [
      "Ching-Chun Chang",
      "Xu Wang",
      "Sisheng Chen",
      "Isao Echizen",
      "Victor Sanchez",
      "Chang-Tsun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06924"
  },
  {
    "id": "arXiv:2106.06925",
    "title": "On the Complexity of Fair House Allocation",
    "abstract": "We study fairness in house allocation, where $m$ houses are to be allocated\namong $n$ agents so that every agent receives one house. We show that\nmaximizing the number of envy-free agents is hard to approximate to within a\nfactor of $n^{1-\\gamma}$ for any constant $\\gamma>0$, and that the exact\nversion is NP-hard even for binary utilities. Moreover, we prove that deciding\nwhether a proportional allocation exists is computationally hard, whereas the\ncorresponding problem for equitability can be solved efficiently.",
    "descriptor": "",
    "authors": [
      "Naoyuki Kamiyama",
      "Pasin Manurangsi",
      "Warut Suksompong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.06925"
  },
  {
    "id": "arXiv:2106.06926",
    "title": "Bellman-consistent Pessimism for Offline Reinforcement Learning",
    "abstract": "The use of pessimism, when reasoning about datasets lacking exhaustive\nexploration has recently gained prominence in offline reinforcement learning.\nDespite the robustness it adds to the algorithm, overly pessimistic reasoning\ncan be equally damaging in precluding the discovery of good policies, which is\nan issue for the popular bonus-based pessimism. In this paper, we introduce the\nnotion of Bellman-consistent pessimism for general function approximation:\ninstead of calculating a point-wise lower bound for the value function, we\nimplement pessimism at the initial state over the set of functions consistent\nwith the Bellman equations. Our theoretical guarantees only require Bellman\nclosedness as standard in the exploratory setting, in which case bonus-based\npessimism fails to provide guarantees. Even in the special case of linear MDPs\nwhere stronger function-approximation assumptions hold, our result improves\nupon a recent bonus-based approach by $\\mathcal{O}(d)$ in its sample complexity\nwhen the action space is finite. Remarkably, our algorithms automatically adapt\nto the best bias-variance tradeoff in the hindsight, whereas most prior\napproaches require tuning extra hyperparameters a priori.",
    "descriptor": "",
    "authors": [
      "Tengyang Xie",
      "Ching-An Cheng",
      "Nan Jiang",
      "Paul Mineiro",
      "Alekh Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06926"
  },
  {
    "id": "arXiv:2106.06927",
    "title": "Inverting Adversarially Robust Networks for Image Synthesis",
    "abstract": "Recent research in adversarially robust classifiers suggests their\nrepresentations tend to be aligned with human perception, which makes them\nattractive for image synthesis and restoration applications. Despite favorable\nempirical results on a few downstream tasks, their advantages are limited to\nslow and sensitive optimization-based techniques. Moreover, their use on\ngenerative models remains unexplored. This work proposes the use of robust\nrepresentations as a perceptual primitive for feature inversion models, and\nshow its benefits with respect to standard non-robust image features. We\nempirically show that adopting robust representations as an image prior\nsignificantly improves the reconstruction accuracy of CNN-based feature\ninversion models. Furthermore, it allows reconstructing images at multiple\nscales out-of-the-box. Following these findings, we propose an\nencoding-decoding network based on robust representations and show its\nadvantages for applications such as anomaly detection, style transfer and image\ndenoising.",
    "descriptor": "",
    "authors": [
      "Renan A. Rojas-Gomez",
      "Raymond A. Yeh",
      "Minh N. Do",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.06927"
  },
  {
    "id": "arXiv:2106.06931",
    "title": "Learning on Abstract Domains: A New Approach for Verifiable Guarantee in  Reinforcement Learning",
    "abstract": "Formally verifying Deep Reinforcement Learning (DRL) systems is a challenging\ntask due to the dynamic continuity of system behaviors and the black-box\nfeature of embedded neural networks. In this paper, we propose a novel\nabstraction-based approach to train DRL systems on finite abstract domains\ninstead of concrete system states. It yields neural networks whose input states\nare finite, making hosting DRL systems directly verifiable using model checking\ntechniques. Our approach is orthogonal to existing DRL algorithms and\noff-the-shelf model checkers. We implement a resulting prototype training and\nverification framework and conduct extensive experiments on the\nstate-of-the-art benchmark. The results show that the systems trained in our\napproach can be verified more efficiently while they retain comparable\nperformance against those that are trained without abstraction.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Peng Jin",
      "Min Zhang",
      "Jianwen Li",
      "Li Han",
      "Xuejun Wen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06931"
  },
  {
    "id": "arXiv:2106.06932",
    "title": "Characterizing the Gap Between Actor-Critic and Policy Gradient",
    "abstract": "Actor-critic (AC) methods are ubiquitous in reinforcement learning. Although\nit is understood that AC methods are closely related to policy gradient (PG),\ntheir precise connection has not been fully characterized previously. In this\npaper, we explain the gap between AC and PG methods by identifying the exact\nadjustment to the AC objective/gradient that recovers the true policy gradient\nof the cumulative reward objective (PG). Furthermore, by viewing the AC method\nas a two-player Stackelberg game between the actor and critic, we show that the\nStackelberg policy gradient can be recovered as a special case of our more\ngeneral analysis. Based on these results, we develop practical algorithms,\nResidual Actor-Critic and Stackelberg Actor-Critic, for estimating the\ncorrection between AC and PG and use these to modify the standard AC algorithm.\nExperiments on popular tabular and continuous environments show the proposed\ncorrections can improve both the sample efficiency and final performance of\nexisting AC methods.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Junfeng Wen",
      "Saurabh Kumar",
      "Ramki Gummadi",
      "Dale Schuurmans"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06932"
  },
  {
    "id": "arXiv:2106.06933",
    "title": "Active Learning for Network Traffic Classification: A Technical Survey",
    "abstract": "Network Traffic Classification (NTC) has become an important component in a\nwide variety of network management operations, e.g., Quality of Service (QoS)\nprovisioning and security purposes. Machine Learning (ML) algorithms as a\ncommon approach for NTC methods can achieve reasonable accuracy and handle\nencrypted traffic. However, ML-based NTC techniques suffer from the shortage of\nlabeled traffic data which is the case in many real-world applications. This\nstudy investigates the applicability of an active form of ML, called Active\nLearning (AL), which reduces the need for a high number of labeled examples by\nactively choosing the instances that should be labeled. The study first\nprovides an overview of NTC and its fundamental challenges along with surveying\nthe literature in the field of using ML techniques in NTC. Then, it introduces\nthe concepts of AL, discusses it in the context of NTC, and review the\nliterature in this field. Further, challenges and open issues in the use of AL\nfor NTC are discussed. Additionally, as a technical survey, some experiments\nare conducted to show the broad applicability of AL in NTC. The simulation\nresults show that AL can achieve high accuracy with a small amount of data.",
    "descriptor": "\nComments: This work has been submitted to the IEEE Transactions on Cognitive Communications and Networking journal for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Amin Shahraki",
      "Mahmoud Abbasi",
      "Amir Taherkordi",
      "Anca Delia Jurcut"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06933"
  },
  {
    "id": "arXiv:2106.06934",
    "title": "Federated Learning Over Wireless Channels: Dynamic Resource Allocation  and Task Scheduling",
    "abstract": "With the development of federated learning (FL), mobile devices (MDs) are\nable to train their local models with private data and sends them to a central\nserver for aggregation, thereby preventing sensitive raw data leakage. In this\npaper, we aim to improve the training performance of FL systems in the context\nof wireless channels and stochastic energy arrivals of MDs. To this purpose, we\ndynamically optimize MDs' transmission power and training task scheduling. We\nfirst model this dynamic programming problem as a constrained Markov decision\nprocess (CMDP). Due to high dimensions rooted from our CMDP problem, we propose\nonline stochastic learning methods to simplify the CMDP and design online\nalgorithms to obtain an efficient policy for all MDs. Since there are long-term\nconstraints in our CMDP, we utilize Lagrange multipliers approach to tackle\nthis issue. Furthermore, we prove the convergence of the proposed online\nstochastic learning algorithm. Numerical results indicate that the proposed\nalgorithms can achieve better performance than the benchmark algorithms.",
    "descriptor": "",
    "authors": [
      "Shunfeng Chu",
      "Jun Li",
      "Jianxin Wang",
      "Zhe Wang",
      "Ming Ding",
      "Yijin Zang",
      "Yuwen Qian",
      "Wen Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.06934"
  },
  {
    "id": "arXiv:2106.06935",
    "title": "Neural Bellman-Ford Networks: A General Graph Neural Network Framework  for Link Prediction",
    "abstract": "Link prediction is a very fundamental task on graphs. Inspired by traditional\npath-based methods, in this paper we propose a general and flexible\nrepresentation learning framework based on paths for link prediction.\nSpecifically, we define the representation of a pair of nodes as the\ngeneralized sum of all path representations, with each path representation as\nthe generalized product of the edge representations in the path. Motivated by\nthe Bellman-Ford algorithm for solving the shortest path problem, we show that\nthe proposed path formulation can be efficiently solved by the generalized\nBellman-Ford algorithm. To further improve the capacity of the path\nformulation, we propose the Neural Bellman-Ford Network (NBFNet), a general\ngraph neural network framework that solves the path formulation with learned\noperators in the generalized Bellman-Ford algorithm. The NBFNet parameterizes\nthe generalized Bellman-Ford algorithm with 3 neural components, namely\nINDICATOR, MESSAGE and AGGREGATE functions, which corresponds to the boundary\ncondition, multiplication operator, and summation operator respectively. The\nNBFNet is very general, covers many traditional path-based methods, and can be\napplied to both homogeneous graphs and multi-relational graphs (e.g., knowledge\ngraphs) in both transductive and inductive settings. Experiments on both\nhomogeneous graphs and knowledge graphs show that the proposed NBFNet\noutperforms existing methods by a large margin in both transductive and\ninductive settings, achieving new state-of-the-art results.",
    "descriptor": "",
    "authors": [
      "Zhaocheng Zhu",
      "Zuobai Zhang",
      "Louis-Pascal Xhonneux",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06935"
  },
  {
    "id": "arXiv:2106.06937",
    "title": "Common Sense Beyond English: Evaluating and Improving Multilingual  Language Models for Commonsense Reasoning",
    "abstract": "Commonsense reasoning research has so far been limited to English. We aim to\nevaluate and improve popular multilingual language models (ML-LMs) to help\nadvance commonsense reasoning (CSR) beyond English. We collect the Mickey\nCorpus, consisting of 561k sentences in 11 different languages, which can be\nused for analyzing and improving ML-LMs. We propose Mickey Probe, a\nlanguage-agnostic probing task for fairly evaluating the common sense of\npopular ML-LMs across different languages. In addition, we also create two new\ndatasets, X-CSQA and X-CODAH, by translating their English versions to 15 other\nlanguages, so that we can evaluate popular ML-LMs for cross-lingual commonsense\nreasoning. To improve the performance beyond English, we propose a simple yet\neffective method -- multilingual contrastive pre-training (MCP). It\nsignificantly enhances sentence representations, yielding a large performance\ngain on both benchmarks.",
    "descriptor": "\nComments: Accepted to ACL-IJCNLP 2021 (long paper at main conference). Project website: this https URL\n",
    "authors": [
      "Bill Yuchen Lin",
      "Seyeon Lee",
      "Xiaoyang Qiao",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06937"
  },
  {
    "id": "arXiv:2106.06939",
    "title": "Cross-Modal Attention Consistency for Video-Audio Unsupervised Learning",
    "abstract": "Cross-modal correlation provides an inherent supervision for video\nunsupervised representation learning. Existing methods focus on distinguishing\ndifferent video clips by visual and audio representations. We human visual\nperception could attend to regions where sounds are made, and our auditory\nperception could also ground their frequencies of sounding objects, which we\ncall bidirectional local correspondence. Such supervision is intuitive but not\nwell explored in the contrastive learning framework. This paper introduces a\npretext task, Cross-Modal Attention Consistency (CMAC), for exploring the\nbidirectional local correspondence property. The CMAC approach aims to align\nthe regional attention generated purely from the visual signal with the target\nattention generated under the guidance of acoustic signal, and do a similar\nalignment for frequency grounding on the acoustic attention. Accompanied by a\nremoulded cross-modal contrastive loss where we consider additional\nwithin-modal interactions, the CMAC approach works effectively for enforcing\nthe bidirectional alignment. Extensive experiments on six downstream benchmarks\ndemonstrate that CMAC can improve the state-of-the-art performance on both\nvisual and audio modalities.",
    "descriptor": "",
    "authors": [
      "Shaobo Min",
      "Qi Dai",
      "Hongtao Xie",
      "Chuang Gan",
      "Yongdong Zhang",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06939"
  },
  {
    "id": "arXiv:2106.06942",
    "title": "A Stronger Baseline for Ego-Centric Action Detection",
    "abstract": "This technical report analyzes an egocentric video action detection method we\nused in the 2021 EPIC-KITCHENS-100 competition hosted in CVPR2021 Workshop. The\ngoal of our task is to locate the start time and the end time of the action in\nthe long untrimmed video, and predict action category. We adopt sliding window\nstrategy to generate proposals, which can better adapt to short-duration\nactions. In addition, we show that classification and proposals are conflict in\nthe same network. The separation of the two tasks boost the detection\nperformance with high efficiency. By simply employing these strategy, we\nachieved 16.10\\% performance on the test set of EPIC-KITCHENS-100 Action\nDetection challenge using a single model, surpassing the baseline method by\n11.7\\% in terms of average mAP.",
    "descriptor": "\nComments: CVPRW21, EPIC-KITCHENS-100 Competition Report\n",
    "authors": [
      "Zhiwu Qing",
      "Ziyuan Huang",
      "Xiang Wang",
      "Yutong Feng",
      "Shiwei Zhang",
      "Jianwen Jiang",
      "Mingqian Tang",
      "Changxin Gao",
      "Marcelo H. Ang Jr",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06942"
  },
  {
    "id": "arXiv:2106.06944",
    "title": "SASICM A Multi-Task Benchmark For Subtext Recognition",
    "abstract": "Subtext is a kind of deep semantics which can be acquired after one or more\nrounds of expression transformation. As a popular way of expressing one's\nintentions, it is well worth studying. In this paper, we try to make computers\nunderstand whether there is a subtext by means of machine learning. We build a\nChinese dataset whose source data comes from the popular social media (e.g.\nWeibo, Netease Music, Zhihu, and Bilibili). In addition, we also build a\nbaseline model called SASICM to deal with subtext recognition. The F1 score of\nSASICMg, whose pretrained model is GloVe, is as high as 64.37%, which is 3.97%\nhigher than that of BERT based model, 12.7% higher than that of traditional\nmethods on average, including support vector machine, logistic regression\nclassifier, maximum entropy classifier, naive bayes classifier and decision\ntree and 2.39% higher than that of the state-of-the-art, including MARIN and\nBTM. The F1 score of SASICMBERT, whose pretrained model is BERT, is 65.12%,\nwhich is 0.75% higher than that of SASICMg. The accuracy rates of SASICMg and\nSASICMBERT are 71.16% and 70.76%, respectively, which can compete with those of\nother methods which are mentioned before.",
    "descriptor": "\nComments: 34 pages, 6 figures, 6 tables. Submitted to the journal of artificial intelligence\n",
    "authors": [
      "Hua Yan",
      "Weikang Xiao",
      "Feng Han",
      "Jian Zhao",
      "Furao Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06944"
  },
  {
    "id": "arXiv:2106.06945",
    "title": "Optimal Status Update for Caching Enabled IoT Networks: A Dueling Deep  R-Network Approach",
    "abstract": "In the Internet of Things (IoT) networks, caching is a promising technique to\nalleviate energy consumption of sensors by responding to users' data requests\nwith the data packets cached in the edge caching node (ECN). However, without\nan efficient status update strategy, the information obtained by users may be\nstale, which in return would inevitably deteriorate the accuracy and\nreliability of derived decisions for real-time applications. In this paper, we\nfocus on striking the balance between the information freshness, in terms of\nage of information (AoI), experienced by users and energy consumed by sensors,\nby appropriately activating sensors to update their current status.\nParticularly, we first depict the evolutions of the AoI with each sensor from\ndifferent users' perspective with time steps of non-uniform duration, which are\ndetermined by both the users' data requests and the ECN's status update\ndecision. Then, we formulate a non-uniform time step based dynamic status\nupdate optimization problem to minimize the long-term average cost, jointly\nconsidering the average AoI and energy consumption. To this end, a Markov\nDecision Process is formulated and further, a dueling deep R-network based\ndynamic status update algorithm is devised by combining dueling deep Q-network\nand tabular R-learning, with which challenges from the curse of dimensionality\nand unknown of the environmental dynamics can be addressed. Finally, extensive\nsimulations are conducted to validate the effectiveness of our proposed\nalgorithm by comparing it with five baseline deep reinforcement learning\nalgorithms and policies.",
    "descriptor": "",
    "authors": [
      "Chao Xu",
      "Yiping Xie",
      "Xijun Wang",
      "Howard H. Yang",
      "Dusit Niyato",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.06945"
  },
  {
    "id": "arXiv:2106.06946",
    "title": "Boosting Randomized Smoothing with Variance Reduced Classifiers",
    "abstract": "Randomized Smoothing (RS) is a promising method for obtaining robustness\ncertificates by evaluating a base model under noise. In this work we: (i)\ntheoretically motivate why ensembles are a particularly suitable choice as base\nmodels for RS, and (ii) empirically confirm this choice, obtaining state of the\nart results in multiple settings. The key insight of our work is that the\nreduced variance of ensembles over the perturbations introduced in RS leads to\nsignificantly more consistent classifications for a given input, in turn\nleading to substantially increased certifiable radii for difficult samples. We\nalso introduce key optimizations which enable an up to 50-fold decrease in\nsample complexity of RS, thus drastically reducing its computational overhead.\nExperimentally, we show that ensembles of only 3 to 10 classifiers consistently\nimprove on the strongest single model with respect to their average certified\nradius (ACR) by 5% to 21% on both CIFAR-10 and ImageNet. On the latter, we\nachieve a state-of-the-art ACR of 1.11. We release all code and models required\nto reproduce our results upon publication.",
    "descriptor": "",
    "authors": [
      "Mikl\u00f3s Z. Horv\u00e1th",
      "Mark Niklas M\u00fcller",
      "Marc Fischer",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06946"
  },
  {
    "id": "arXiv:2106.06947",
    "title": "Graph Neural Network-Based Anomaly Detection in Multivariate Time Series",
    "abstract": "Given high-dimensional time series data (e.g., sensor data), how can we\ndetect anomalous events, such as system faults and attacks? More challengingly,\nhow can we do this in a way that captures complex inter-sensor relationships,\nand detects and explains anomalies which deviate from these relationships?\nRecently, deep learning approaches have enabled improvements in anomaly\ndetection in high-dimensional datasets; however, existing methods do not\nexplicitly learn the structure of existing relationships between variables, or\nuse them to predict the expected behavior of time series. Our approach combines\na structure learning approach with graph neural networks, additionally using\nattention weights to provide explainability for the detected anomalies.\nExperiments on two real-world sensor datasets with ground truth anomalies show\nthat our method detects anomalies more accurately than baseline approaches,\naccurately captures correlations between sensors, and allows users to deduce\nthe root cause of a detected anomaly.",
    "descriptor": "\nComments: Accepted at AAAI Conference on Artificial Intelligence (AAAI), 2021\n",
    "authors": [
      "Ailin Deng",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06947"
  },
  {
    "id": "arXiv:2106.06949",
    "title": "How Crucial is it for 6G Networks to be Autonomous?",
    "abstract": "The sixth generation (6G), unlike any previous generations, is envisioned by\n2030 to connect everything. Moreover, in addition to the new use cases 6G is\nexpected to support, it will need to provide a superior performance over 5G.\nThe global connectivity, large-network dimensions, users heterogeneity,\nextremely-low power consumption, high-throughput, ultra-reliability,\nefficient-network operation and maintenance, and low-latency requirements to be\nmet by future networks inevitably necessitate the autonomy of 6G. Intelligence,\nfacilitated mainly by the advancement and innovation of the artificial\nintelligence (AI) technique, is a key to achieve autonomy. In this paper we\nprovide a bird's-eye view of future networks, vision, progress, and objectives.\nWe review some of the 6G technologies that would be mainly enabling the\nglobally-intelligent connected world. We, in addition to discussing the role of\nAI in future networks, unlike any other review papers provide our original\nresults that emphasize the necessity of deploying AI for 6G networks. We also\nvery importantly identify 6G implementation challenges and key innovative\ntechniques like quantum and blockchain to solve these challenges. This article\nserves as a starting point for learner to acquire more knowledge about 6G as it\ncombines some of the main contributions in the area and provide some references\nfor getting a more deeper knowledge, and also for researchers to contribute to\nthe field.",
    "descriptor": "",
    "authors": [
      "Nadia Adem",
      "Ahmed Benfaid",
      "Ramy Harib",
      "Anas Alarabi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.06949"
  },
  {
    "id": "arXiv:2106.06950",
    "title": "An efficient way to manage blocks of data with Wise Red-Black Trees",
    "abstract": "This paper describes the most efficient way to manage operations on groups of\nconsecutive elements, or \"blocks\" of elements, within an ordered set. This will\nbe done by introducing a new data structure called Wise Red-Black Trees, a\nvariation of classical Red-Black Trees. The goal is to improve time complexity,\nwhile also keeping spatial complexity to a minimum. The optimization will be\nvisible both at the asymptote and in terms of multiplicative constants,\naffecting not only the worst-case, but also the average one.",
    "descriptor": "",
    "authors": [
      "Alberto Boffi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.06950"
  },
  {
    "id": "arXiv:2106.06951",
    "title": "Effects of Eavesdropper on the Performance of Mixed \u03b7-\u03bc and DGG  Cooperative Relaying System",
    "abstract": "Free-space optical (FSO) channel offers line-of-sight wireless communication\nwith high data rates and high secrecy utilizing unlicensed optical spectrum and\nalso paves the way to the solution of the last-mile access problem. Since\natmospheric turbulence is a hindrance to an enhanced secrecy performance, the\nmixed radio frequency (RF)-FSO system is gaining enormous research interest in\nrecent days. But conventional FSO models except for the double generalized\nGamma (DGG) model can not demonstrate secrecy performance for all ranges of\nturbulence severity. This reason has led us to propose a dual-hop eta-mu and\nunified DGG mixed RF-FSO network while considering eavesdropping at both RF and\nFSO hops. The security of these proposed scenarios is investigated in terms of\ntwo metrics, i.e., strictly positive secrecy capacity and secure outage\nprobability. Exploiting these expressions, we further investigate how the\nsecrecy performance is affected by various system parameters, i.e., fading,\nturbulence, and pointing errors. A demonstration is made between heterodyne\ndetection (HD) and intensity modulation and direct detection (IM/DD) techniques\nwhile exhibiting superior secrecy performance for HD technique over IM/DD\ntechnique. Finally, all analytical results are corroborated via Monte-Carlo\nsimulations.",
    "descriptor": "",
    "authors": [
      "Noor Ahmed Sarker",
      "A. S. M. Badrudduza",
      "Milton Kumar Kundu",
      "Imran Shafique Ansari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.06951"
  },
  {
    "id": "arXiv:2106.06955",
    "title": "Towards Understanding Iterative Magnitude Pruning: Why Lottery Tickets  Win",
    "abstract": "The lottery ticket hypothesis states that sparse subnetworks exist in\nrandomly initialized dense networks that can be trained to the same accuracy as\nthe dense network they reside in. However, the subsequent work has failed to\nreplicate this on large-scale models and required rewinding to an early stable\nstate instead of initialization. We show that by using a training method that\nis stable with respect to linear mode connectivity, large networks can also be\nentirely rewound to initialization. Our subsequent experiments on common vision\ntasks give strong credence to the hypothesis in Evci et al. (2020b) that\nlottery tickets simply retrain to the same regions (although not necessarily to\nthe same basin). These results imply that existing lottery tickets could not\nhave been found without the preceding dense training by iterative magnitude\npruning, raising doubts about the use of the lottery ticket hypothesis.",
    "descriptor": "",
    "authors": [
      "Jaron Maene",
      "Mingxiao Li",
      "Marie-Francine Moens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06955"
  },
  {
    "id": "arXiv:2106.06957",
    "title": "AutoScore-Survival: Developing interpretable machine learning-based  time-to-event scores with right-censored survival data",
    "abstract": "Scoring systems are highly interpretable and widely used to evaluate\ntime-to-event outcomes in healthcare research. However, existing time-to-event\nscores are predominantly created ad-hoc using a few manually selected variables\nbased on clinician's knowledge, suggesting an unmet need for a robust and\nefficient generic score-generating method.\nAutoScore was previously developed as an interpretable machine learning score\ngenerator, integrated both machine learning and point-based scores in the\nstrong discriminability and accessibility. We have further extended it to\ntime-to-event data and developed AutoScore-Survival, for automatically\ngenerating time-to-event scores with right-censored survival data. Random\nsurvival forest provides an efficient solution for selecting variables, and Cox\nregression was used for score weighting. We illustrated our method in a\nreal-life study of 90-day mortality of patients in intensive care units and\ncompared its performance with survival models (i.e., Cox) and the random\nsurvival forest.\nThe AutoScore-Survival-derived scoring model was more parsimonious than\nsurvival models built using traditional variable selection methods (e.g.,\npenalized likelihood approach and stepwise variable selection), and its\nperformance was comparable to survival models using the same set of variables.\nAlthough AutoScore-Survival achieved a comparable integrated area under the\ncurve of 0.782 (95% CI: 0.767-0.794), the integer-valued time-to-event scores\ngenerated are favorable in clinical applications because they are easier to\ncompute and interpret.\nOur proposed AutoScore-Survival provides an automated, robust and easy-to-use\nmachine learning-based clinical score generator to studies of time-to-event\noutcomes. It provides a systematic guideline to facilitate the future\ndevelopment of time-to-event scores for clinical applications.",
    "descriptor": "",
    "authors": [
      "Feng Xie",
      "Yilin Ning",
      "Han Yuan",
      "Benjamin Alan Goldstein",
      "Marcus Eng Hock Ong",
      "Nan Liu",
      "Bibhas Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06957"
  },
  {
    "id": "arXiv:2106.06959",
    "title": "Do Not Escape From the Manifold: Discovering the Local Coordinates on  the Latent Space of GANs",
    "abstract": "In this paper, we propose a method to find local-geometry-aware traversal\ndirections on the intermediate latent space of Generative Adversarial Networks\n(GANs). These directions are defined as an ordered basis of tangent space at a\nlatent code. Motivated by the intrinsic sparsity of the latent space, the basis\nis discovered by solving the low-rank approximation problem of the differential\nof the partial network. Moreover, the local traversal basis leads to a natural\niterative traversal on the latent space. Iterative Curve-Traversal shows stable\ntraversal on images, since the trajectory of latent code stays close to the\nlatent space even under the strong perturbations compared to the linear\ntraversal. This stability provides far more diverse variations of the given\nimage. Although the proposed method can be applied to various GAN models, we\nfocus on the W-space of the StyleGAN2, which is renowned for showing the better\ndisentanglement of the latent factors of variation. Our quantitative and\nqualitative analysis provides evidence showing that the W-space is still\nglobally warped while showing a certain degree of global consistency of\ninterpretable variation. In particular, we introduce some metrics on the\nGrassmannian manifolds to quantify the global warpage of the W-space and the\nsubspace traversal to test the stability of traversal directions.",
    "descriptor": "\nComments: 16 pages, 12 figures\n",
    "authors": [
      "Jaewoong Choi",
      "Changyeon Yoon",
      "Junho Lee",
      "Jung Ho Park",
      "Geonho Hwang",
      "Myungjoo Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06959"
  },
  {
    "id": "arXiv:2106.06960",
    "title": "Representation and Correlation Enhanced Encoder-Decoder Framework for  Scene Text Recognition",
    "abstract": "Attention-based encoder-decoder framework is widely used in the scene text\nrecognition task. However, for the current state-of-the-art(SOTA) methods,\nthere is room for improvement in terms of the efficient usage of local visual\nand global context information of the input text image, as well as the robust\ncorrelation between the scene processing module(encoder) and the text\nprocessing module(decoder). In this paper, we propose a Representation and\nCorrelation Enhanced Encoder-Decoder Framework(RCEED) to address these\ndeficiencies and break performance bottleneck. In the encoder module, local\nvisual feature, global context feature, and position information are aligned\nand fused to generate a small-size comprehensive feature map. In the decoder\nmodule, two methods are utilized to enhance the correlation between scene and\ntext feature space. 1) The decoder initialization is guided by the holistic\nfeature and global glimpse vector exported from the encoder. 2) The feature\nenriched glimpse vector produced by the Multi-Head General Attention is used to\nassist the RNN iteration and the character prediction at each time step.\nMeanwhile, we also design a Layernorm-Dropout LSTM cell to improve model's\ngeneralization towards changeable texts. Extensive experiments on the\nbenchmarks demonstrate the advantageous performance of RCEED in scene text\nrecognition tasks, especially the irregular ones.",
    "descriptor": "\nComments: 15 pages, 5 figures, 3 tables\n",
    "authors": [
      "Mengmeng Cui",
      "Wei Wang",
      "Jinjin Zhang",
      "Liang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06960"
  },
  {
    "id": "arXiv:2106.06963",
    "title": "Exploring and Distilling Posterior and Prior Knowledge for Radiology  Report Generation",
    "abstract": "Automatically generating radiology reports can improve current clinical\npractice in diagnostic radiology. On one hand, it can relieve radiologists from\nthe heavy burden of report writing; On the other hand, it can remind\nradiologists of abnormalities and avoid the misdiagnosis and missed diagnosis.\nYet, this task remains a challenging job for data-driven neural networks, due\nto the serious visual and textual data biases. To this end, we propose a\nPosterior-and-Prior Knowledge Exploring-and-Distilling approach (PPKED) to\nimitate the working patterns of radiologists, who will first examine the\nabnormal regions and assign the disease topic tags to the abnormal regions, and\nthen rely on the years of prior medical knowledge and prior working experience\naccumulations to write reports. Thus, the PPKED includes three modules:\nPosterior Knowledge Explorer (PoKE), Prior Knowledge Explorer (PrKE) and\nMulti-domain Knowledge Distiller (MKD). In detail, PoKE explores the posterior\nknowledge, which provides explicit abnormal visual regions to alleviate visual\ndata bias; PrKE explores the prior knowledge from the prior medical knowledge\ngraph (medical knowledge) and prior radiology reports (working experience) to\nalleviate textual data bias. The explored knowledge is distilled by the MKD to\ngenerate the final reports. Evaluated on MIMIC-CXR and IU-Xray datasets, our\nmethod is able to outperform previous state-of-the-art models on these two\ndatasets.",
    "descriptor": "\nComments: Accepted by CVPR 2021\n",
    "authors": [
      "Fenglin Liu",
      "Xian Wu",
      "Shen Ge",
      "Wei Fan",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06963"
  },
  {
    "id": "arXiv:2106.06964",
    "title": "Shape of Elephant: Study of Macro Properties of Word Embeddings Spaces",
    "abstract": "Pre-trained word representations became a key component in many NLP tasks.\nHowever, the global geometry of the word embeddings remains poorly understood.\nIn this paper, we demonstrate that a typical word embeddings cloud is shaped as\na high-dimensional simplex with interpretable vertices and propose a simple yet\neffective method for enumeration of these vertices. We show that the proposed\nmethod can detect and describe vertices of the simplex for GloVe and fasttext\nspaces.",
    "descriptor": "\nComments: 3 pages, 2 figures, EEML-2021 poster\n",
    "authors": [
      "Alexey Tikhonov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06964"
  },
  {
    "id": "arXiv:2106.06965",
    "title": "Contrastive Attention for Automatic Chest X-ray Report Generation",
    "abstract": "Recently, chest X-ray report generation, which aims to automatically generate\ndescriptions of given chest X-ray images, has received growing research\ninterests. The key challenge of chest X-ray report generation is to accurately\ncapture and describe the abnormal regions. In most cases, the normal regions\ndominate the entire chest X-ray image, and the corresponding descriptions of\nthese normal regions dominate the final report. Due to such data bias,\nlearning-based models may fail to attend to abnormal regions. In this work, to\neffectively capture and describe abnormal regions, we propose the Contrastive\nAttention (CA) model. Instead of solely focusing on the current input image,\nthe CA model compares the current input image with normal images to distill the\ncontrastive information. The acquired contrastive information can better\nrepresent the visual features of abnormal regions. According to the experiments\non the public IU-X-ray and MIMIC-CXR datasets, incorporating our CA into\nseveral existing models can boost their performance across most metrics. In\naddition, according to the analysis, the CA model can help existing models\nbetter attend to the abnormal regions and provide more accurate descriptions\nwhich are crucial for an interpretable diagnosis. Specifically, we achieve the\nstate-of-the-art results on the two public datasets.",
    "descriptor": "\nComments: Appear in Findings of ACL 2021 (The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021))\n",
    "authors": [
      "Fenglin Liu",
      "Changchang Yin",
      "Xian Wu",
      "Shen Ge",
      "Ping Zhang",
      "Xu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06965"
  },
  {
    "id": "arXiv:2106.06966",
    "title": "Feedback Pyramid Attention Networks for Single Image Super-Resolution",
    "abstract": "Recently, convolutional neural network (CNN) based image super-resolution\n(SR) methods have achieved significant performance improvement. However, most\nCNN-based methods mainly focus on feed-forward architecture design and neglect\nto explore the feedback mechanism, which usually exists in the human visual\nsystem. In this paper, we propose feedback pyramid attention networks (FPAN) to\nfully exploit the mutual dependencies of features. Specifically, a novel\nfeedback connection structure is developed to enhance low-level feature\nexpression with high-level information. In our method, the output of each layer\nin the first stage is also used as the input of the corresponding layer in the\nnext state to re-update the previous low-level filters. Moreover, we introduce\na pyramid non-local structure to model global contextual information in\ndifferent scales and improve the discriminative representation of the network.\nExtensive experimental results on various datasets demonstrate the superiority\nof our FPAN in comparison with the state-of-the-art SR methods.",
    "descriptor": "",
    "authors": [
      "Huapeng Wu",
      "Jie Gui",
      "Jun Zhang",
      "James T. Kwok",
      "Zhihui Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06966"
  },
  {
    "id": "arXiv:2106.06969",
    "title": "SoundDet: Polyphonic Sound Event Detection and Localization from Raw  Waveform",
    "abstract": "We present a new framework SoundDet, which is an end-to-end trainable and\nlight-weight framework, for polyphonic moving sound event detection and\nlocalization. Prior methods typically approach this problem by preprocessing\nraw waveform into time-frequency representations, which is more amenable to\nprocess with well-established image processing pipelines. Prior methods also\ndetect in segment-wise manner, leading to incomplete and partial detections.\nSoundDet takes a novel approach and directly consumes the raw, multichannel\nwaveform and treats the spatio-temporal sound event as a complete\n``sound-object\" to be detected. Specifically, SoundDet consists of a backbone\nneural network and two parallel heads for temporal detection and spatial\nlocalization, respectively. Given the large sampling rate of raw waveform, the\nbackbone network first learns a set of phase-sensitive and frequency-selective\nbank of filters to explicitly retain direction-of-arrival information, whilst\nbeing highly computationally and parametrically efficient than standard 1D/2D\nconvolution. A dense sound event proposal map is then constructed to handle the\nchallenges of predicting events with large varying temporal duration.\nAccompanying the dense proposal map are a temporal overlapness map and a motion\nsmoothness map that measure a proposal's confidence to be an event from\ntemporal detection accuracy and movement consistency perspective. Involving the\ntwo maps guarantees SoundDet to be trained in a spatio-temporally unified\nmanner. Experimental results on the public DCASE dataset show the advantage of\nSoundDet on both segment-based and our newly proposed event-based evaluation\nsystem.",
    "descriptor": "",
    "authors": [
      "Yuhang He",
      "Niki Trigoni",
      "Andrew Markham"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06969"
  },
  {
    "id": "arXiv:2106.06971",
    "title": "NLHD: A Pixel-Level Non-Local Retinex Model for Low-Light Image  Enhancement",
    "abstract": "Retinex model has been applied to low-light image enhancement in many\nexisting methods. More appropriate decomposition of a low-light image can help\nachieve better image enhancement. In this paper, we propose a new pixel-level\nnon-local Haar transform based illumination and reflectance decomposition\nmethod (NLHD). The unique low-frequency coefficient of Haar transform on each\nsimilar pixel group is used to reconstruct the illumination component, and the\nrest of all high-frequency coefficients are employed to reconstruct the\nreflectance component. The complete similarity of pixels in a matched similar\npixel group and the simple separable Haar transform help to obtain more\nappropriate image decomposition; thus, the image is hardly sharpened in the\nimage brightness enhancement procedure. The exponential transform and\nlogarithmic transform are respectively implemented on the illumination\ncomponent. Then a minimum fusion strategy on the results of these two\ntransforms is utilized to achieve more natural illumination component\nenhancement. It can alleviate the mosaic artifacts produced in the darker\nregions by the exponential transform with a gamma value less than 1 and reduce\ninformation loss caused by excessive enhancement of the brighter regions due to\nthe logarithmic transform. Finally, the Retinex model is applied to the\nenhanced illumination and reflectance to achieve image enhancement. We also\ndevelop a local noise level estimation based noise suppression method and a\nnon-local saturation reduction based color deviation correction method. These\ntwo methods can respectively attenuate noise or color deviation usually\npresented in the enhanced results of the extremely dark low-light images.\nExperiments on benchmark datasets show that the proposed method can achieve\nbetter low-light image enhancement results on subjective and objective\nevaluations than most existing methods.",
    "descriptor": "\nComments: 14 pages, 11 figures\n",
    "authors": [
      "Hou Hao",
      "Hou Yingkun",
      "Shi Yuxuan",
      "Wei Benzheng",
      "Xu Jun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06971"
  },
  {
    "id": "arXiv:2106.06972",
    "title": "RCURRENCY: Live Digital Asset Trading Using a Recurrent Neural  Network-based Forecasting System",
    "abstract": "Consistent alpha generation, i.e., maintaining an edge over the market,\nunderpins the ability of asset traders to reliably generate profits. Technical\nindicators and trading strategies are commonly used tools to determine when to\nbuy/hold/sell assets, yet these are limited by the fact that they operate on\nknown values. Over the past decades, multiple studies have investigated the\npotential of artificial intelligence in stock trading in conventional markets,\nwith some success. In this paper, we present RCURRENCY, an RNN-based trading\nengine to predict data in the highly volatile digital asset market which is\nable to successfully manage an asset portfolio in a live environment. By\ncombining asset value prediction and conventional trading tools, RCURRENCY\ndetermines whether to buy, hold or sell digital currencies at a given point in\ntime. Experimental results show that, given the data of an interval $t$, a\nprediction with an error of less than 0.5\\% of the data at the subsequent\ninterval $t+1$ can be obtained. Evaluation of the system through backtesting\nshows that RCURRENCY can be used to successfully not only maintain a stable\nportfolio of digital assets in a simulated live environment using real\nhistorical trading data but even increase the portfolio value over time.",
    "descriptor": "",
    "authors": [
      "Yapeng Jasper Hu",
      "Ralph van Gurp",
      "Ashay Somai",
      "Hugo Kooijman",
      "Jan S. Rellermeyer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06972"
  },
  {
    "id": "arXiv:2106.06976",
    "title": "Game of GANs: Game Theoretical Models for Generative Adversarial  Networks",
    "abstract": "Generative Adversarial Network, as a promising research direction in the AI\ncommunity, recently attracts considerable attention due to its ability to\ngenerating high-quality realistic data. GANs are a competing game between two\nneural networks trained in an adversarial manner to reach a Nash equilibrium.\nDespite the improvement accomplished in GANs in the last years, there remain\nseveral issues to solve. In this way, how to tackle these issues and make\nadvances leads to rising research interests. This paper reviews literature that\nleverages the game theory in GANs and addresses how game models can relieve\nspecific generative models' challenges and improve the GAN's performance. In\nparticular, we firstly review some preliminaries, including the basic GAN model\nand some game theory backgrounds. After that, we present our taxonomy to\nsummarize the state-of-the-art solutions into three significant categories:\nmodified game model, modified architecture, and modified learning method. The\nclassification is based on the modifications made in the basic model by the\nproposed approaches from the game-theoretic perspective. We further classify\neach category into several subcategories. Following the proposed taxonomy, we\nexplore the main objective of each class and review the recent work in each\ngroup. Finally, we discuss the remaining challenges in this field and present\nthe potential future research topics.",
    "descriptor": "\nComments: 16 pages, 5 Tables, 2 Figures, Review paper\n",
    "authors": [
      "Monireh Mohebbi Moghadam",
      "Bahar Boroumand",
      "Mohammad Jalali",
      "Arman Zareian",
      "Alireza Daei Javad",
      "Mohammad Hossein Manshaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.06976"
  },
  {
    "id": "arXiv:2106.06978",
    "title": "Study of Joint Activity Detection and Channel Estimation Based on  Message Passing with RBP Scheduling for MTC",
    "abstract": "In this work, based on the hybrid generalized approximate message passing\n(HyGAMP) algorithm, we propose the message-scheduling GAMP (MSGAMP) algorithm\nin order to address the problem of joint active device detection and channel\nestimation in an uplink grant-free massive MIMO system scenario. In MSGAMP, we\napply three different scheduling techniques based on the Residual Belief\nPropagation (RBP) in which messages are generated using the latest available\ninformation. With a much lower computational cost than the state-of-the-art\nalgorithms, MSGAMP-type schemes exhibits good performance in terms of activity\nerror rate and normalized mean squared error, requiring a small number of\niterations for convergence. %",
    "descriptor": "\nComments: 6 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2103.04486\n",
    "authors": [
      "R. B. Di Renna",
      "R. C. de Lamare"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.06978"
  },
  {
    "id": "arXiv:2106.06981",
    "title": "Thinking Like Transformers",
    "abstract": "What is the computational model behind a Transformer? Where recurrent neural\nnetworks have direct parallels in finite state machines, allowing clear\ndiscussion and thought around architecture variants or trained models,\nTransformers have no such familiar parallel. In this paper we aim to change\nthat, proposing a computational model for the transformer-encoder in the form\nof a programming language. We map the basic components of a transformer-encoder\n-- attention and feed-forward computation -- into simple primitives, around\nwhich we form a programming language: the Restricted Access Sequence Processing\nLanguage (RASP). We show how RASP can be used to program solutions to tasks\nthat could conceivably be learned by a Transformer, and how a Transformer can\nbe trained to mimic a RASP solution. In particular, we provide RASP programs\nfor histograms, sorting, and Dyck-languages. We further use our model to relate\ntheir difficulty in terms of the number of required layers and attention heads:\nanalyzing a RASP program implies a maximum number of heads and layers necessary\nto encode a task in a transformer. Finally, we see how insights gained from our\nabstraction might be used to explain phenomena seen in recent works.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Gail Weiss",
      "Yoav Goldberg",
      "Eran Yahav"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06981"
  },
  {
    "id": "arXiv:2106.06983",
    "title": "Two-way Spectrum Pursuit for CUR Decomposition and Its Application in  Joint Column/Row Subset Selection",
    "abstract": "The problem of simultaneous column and row subset selection is addressed in\nthis paper. The column space and row space of a matrix are spanned by its left\nand right singular vectors, respectively. However, the singular vectors are not\nwithin actual columns/rows of the matrix. In this paper, an iterative approach\nis proposed to capture the most structural information of columns/rows via\nselecting a subset of actual columns/rows. This algorithm is referred to as\ntwo-way spectrum pursuit (TWSP) which provides us with an accurate solution for\nthe CUR matrix decomposition. TWSP is applicable in a wide range of\napplications since it enjoys a linear complexity w.r.t. number of original\ncolumns/rows. We demonstrated the application of TWSP for joint channel and\nsensor selection in cognitive radio networks, informative users and contents\ndetection, and efficient supervised data reduction.",
    "descriptor": "",
    "authors": [
      "Ashkan Esmaeili",
      "Mohsen Joneidi",
      "Mehrdad Salimitari",
      "Umar Khalid",
      "Nazanin Rahnavard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06983"
  },
  {
    "id": "arXiv:2106.06984",
    "title": "A Free Lunch From ANN: Towards Efficient, Accurate Spiking Neural  Networks Calibration",
    "abstract": "Spiking Neural Network (SNN) has been recognized as one of the next\ngeneration of neural networks. Conventionally, SNN can be converted from a\npre-trained ANN by only replacing the ReLU activation to spike activation while\nkeeping the parameters intact. Perhaps surprisingly, in this work we show that\na proper way to calibrate the parameters during the conversion of ANN to SNN\ncan bring significant improvements. We introduce SNN Calibration, a cheap but\nextraordinarily effective method by leveraging the knowledge within a\npre-trained Artificial Neural Network (ANN). Starting by analyzing the\nconversion error and its propagation through layers theoretically, we propose\nthe calibration algorithm that can correct the error layer-by-layer. The\ncalibration only takes a handful number of training data and several minutes to\nfinish. Moreover, our calibration algorithm can produce SNN with\nstate-of-the-art architecture on the large-scale ImageNet dataset, including\nMobileNet and RegNet. Extensive experiments demonstrate the effectiveness and\nefficiency of our algorithm. For example, our advanced pipeline can increase up\nto 69% top-1 accuracy when converting MobileNet on ImageNet compared to\nbaselines. Codes are released at https://github.com/yhhhli/SNN_Calibration.",
    "descriptor": "",
    "authors": [
      "Yuhang Li",
      "Shikuang Deng",
      "Xin Dong",
      "Ruihao Gong",
      "Shi Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06984"
  },
  {
    "id": "arXiv:2106.06988",
    "title": "NDPNet: A novel non-linear data projection network for few-shot  fine-gained image classification",
    "abstract": "Metric-based few-shot fine-grained image classification (FSFGIC) aims to\nlearn a transferable feature embedding network by estimating the similarities\nbetween query images and support classes from very few examples. In this work,\nwe propose, for the first time, to introduce the non-linear data projection\nconcept into the design of FSFGIC architecture in order to address the limited\nsample problem in few-shot learning and at the same time to increase the\ndiscriminability of the model for fine-grained image classification.\nSpecifically, we first design a feature re-abstraction embedding network that\nhas the ability to not only obtain the required semantic features for effective\nmetric learning but also re-enhance such features with finer details from input\nimages. Then the descriptors of the query images and the support classes are\nprojected into different non-linear spaces in our proposed similarity metric\nlearning network to learn discriminative projection factors. This design can\neffectively operate in the challenging and restricted condition of a FSFGIC\ntask for making the distance between the samples within the same class smaller\nand the distance between samples from different classes larger and for reducing\nthe coupling relationship between samples from different categories.\nFurthermore, a novel similarity measure based on the proposed non-linear data\nproject is presented for evaluating the relationships of feature information\nbetween a query image and a support set. It is worth to note that our proposed\narchitecture can be easily embedded into any episodic training mechanisms for\nend-to-end training from scratch. Extensive experiments on FSFGIC tasks\ndemonstrate the superiority of the proposed methods over the state-of-the-art\nbenchmarks.",
    "descriptor": "",
    "authors": [
      "Weichuan Zhangy",
      "Xuefang Liuy",
      "Zhe Xue",
      "Yongsheng Gao",
      "Changming Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06988"
  },
  {
    "id": "arXiv:2106.06989",
    "title": "The DEformer: An Order-Agnostic Distribution Estimating Transformer",
    "abstract": "Order-agnostic autoregressive distribution estimation (OADE), i.e.,\nautoregressive distribution estimation where the features can occur in an\narbitrary order, is a challenging problem in generative machine learning. Prior\nwork on OADE has encoded feature identity (e.g., pixel location) by assigning\neach feature to a distinct fixed position in an input vector. As a result,\narchitectures built for these inputs must strategically mask either the input\nor model weights to learn the various conditional distributions necessary for\ninferring the full joint distribution of the dataset in an order-agnostic way.\nIn this paper, we propose an alternative approach for encoding feature\nidentities, where each feature's identity is included alongside its value in\nthe input. This feature identity encoding strategy allows neural architectures\ndesigned for sequential data to be applied to the OADE task without\nmodification. As a proof of concept, we show that a Transformer trained on this\ninput (which we refer to as \"the DEformer\", i.e., the distribution estimating\nTransformer) can effectively model binarized-MNIST, approaching the average\nnegative log-likelihood of fixed order autoregressive distribution estimating\nalgorithms while still being entirely order-agnostic.",
    "descriptor": "",
    "authors": [
      "Michael A. Alcorn",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06989"
  },
  {
    "id": "arXiv:2106.06991",
    "title": "BoolNet: Minimizing The Energy Consumption of Binary Neural Networks",
    "abstract": "Recent works on Binary Neural Networks (BNNs) have made promising progress in\nnarrowing the accuracy gap of BNNs to their 32-bit counterparts. However, the\naccuracy gains are often based on specialized model designs using additional\n32-bit components. Furthermore, almost all previous BNNs use 32-bit for feature\nmaps and the shortcuts enclosing the corresponding binary convolution blocks,\nwhich helps to effectively maintain the accuracy, but is not friendly to\nhardware accelerators with limited memory, energy, and computing resources.\nThus, we raise the following question: How can accuracy and energy consumption\nbe balanced in a BNN network design? We extensively study this fundamental\nproblem in this work and propose a novel BNN architecture without most commonly\nused 32-bit components: \\textit{BoolNet}. Experimental results on ImageNet\ndemonstrate that BoolNet can achieve 4.6x energy reduction coupled with 1.2\\%\nhigher accuracy than the commonly used BNN architecture Bi-RealNet. Code and\ntrained models are available at: https://github.com/hpi-xnor/BoolNet.",
    "descriptor": "",
    "authors": [
      "Nianhui Guo",
      "Joseph Bethge",
      "Haojin Yang",
      "Kai Zhong",
      "Xuefei Ning",
      "Christoph Meinel",
      "Yu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06991"
  },
  {
    "id": "arXiv:2106.06992",
    "title": "Is Perfect Filtering Enough Leading to Perfect Phase Correction for dMRI  data?",
    "abstract": "Being complex-valued and low in signal-to-noise ratios, magnitude-based\ndiffusion MRI is confounded by the noise-floor that falsely elevates signal\nmagnitude and incurs bias to the commonly used diffusion indices, such as\nfractional anisotropy (FA). To avoid noise-floor, most existing phase\ncorrection methods explore improving filters to estimate the noise-free\nbackground phase. In this work, after diving into the phase correction\nprocedures, we argue that even a perfect filter is insufficient for phase\ncorrection because the correction procedures are incapable of distinguishing\nsign-symbols of noise, resulting in artifacts (\\textit{i.e.}, arbitrary signal\nloss). With this insight, we generalize the definition of noise-floor to a\ncomplex polar coordinate system and propose a calibration procedure that could\nconveniently distinguish noise sign symbols. The calibration procedure is\nconceptually simple and easy to implement without relying on any external\ntechnique while keeping distinctly effective.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Liu Feihong",
      "Yang Junwei",
      "He Xiaowei",
      "Zhou Luping",
      "Feng Jun",
      "Shen Dinggang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06992"
  },
  {
    "id": "arXiv:2106.06996",
    "title": "Pyramidal Dense Attention Networks for Lightweight Image  Super-Resolution",
    "abstract": "Recently, deep convolutional neural network methods have achieved an\nexcellent performance in image superresolution (SR), but they can not be easily\napplied to embedded devices due to large memory cost. To solve this problem, we\npropose a pyramidal dense attention network (PDAN) for lightweight image\nsuper-resolution in this paper. In our method, the proposed pyramidal dense\nlearning can gradually increase the width of the densely connected layer inside\na pyramidal dense block to extract deep features efficiently. Meanwhile, the\nadaptive group convolution that the number of groups grows linearly with dense\nconvolutional layers is introduced to relieve the parameter explosion. Besides,\nwe also present a novel joint attention to capture cross-dimension interaction\nbetween the spatial dimensions and channel dimension in an efficient way for\nproviding rich discriminative feature representations. Extensive experimental\nresults show that our method achieves superior performance in comparison with\nthe state-of-the-art lightweight SR methods.",
    "descriptor": "",
    "authors": [
      "Huapeng Wu",
      "Jie Gui",
      "Jun Zhang",
      "James T. Kwok",
      "Zhihui Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06996"
  },
  {
    "id": "arXiv:2106.06997",
    "title": "Post-hoc loss-calibration for Bayesian neural networks",
    "abstract": "Bayesian decision theory provides an elegant framework for acting optimally\nunder uncertainty when tractable posterior distributions are available. Modern\nBayesian models, however, typically involve intractable posteriors that are\napproximated with, potentially crude, surrogates. This difficulty has\nengendered loss-calibrated techniques that aim to learn posterior\napproximations that favor high-utility decisions. In this paper, focusing on\nBayesian neural networks, we develop methods for correcting approximate\nposterior predictive distributions encouraging them to prefer high-utility\ndecisions. In contrast to previous work, our approach is agnostic to the choice\nof the approximate inference algorithm, allows for efficient test time decision\nmaking through amortization, and empirically produces higher quality decisions.\nWe demonstrate the effectiveness of our approach through controlled experiments\nspanning a diversity of tasks and datasets.",
    "descriptor": "\nComments: Accepted to Conference on Uncertainty in AI (UAI) '21\n",
    "authors": [
      "Meet P. Vadera",
      "Soumya Ghosh",
      "Kenney Ng",
      "Benjamin M. Marlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06997"
  },
  {
    "id": "arXiv:2106.06998",
    "title": "Low-memory stochastic backpropagation with multi-channel randomized  trace estimation",
    "abstract": "Thanks to the combination of state-of-the-art accelerators and highly\noptimized open software frameworks, there has been tremendous progress in the\nperformance of deep neural networks. While these developments have been\nresponsible for many breakthroughs, progress towards solving large-scale\nproblems, such as video encoding and semantic segmentation in 3D, is hampered\nbecause access to on-premise memory is often limited. Instead of relying on\n(optimal) checkpointing or invertibility of the network layers -- to recover\nthe activations during backpropagation -- we propose to approximate the\ngradient of convolutional layers in neural networks with a multi-channel\nrandomized trace estimation technique. Compared to other methods, this approach\nis simple, amenable to analyses, and leads to a greatly reduced memory\nfootprint. Even though the randomized trace estimation introduces stochasticity\nduring training, we argue that this is of little consequence as long as the\ninduced errors are of the same order as errors in the gradient due to the use\nof stochastic gradient descent. We discuss the performance of networks trained\nwith stochastic backpropagation and how the error can be controlled while\nmaximizing memory usage and minimizing computational overhead.",
    "descriptor": "",
    "authors": [
      "Mathias Louboutin",
      "Ali Siahkoohi",
      "Rongrong Wang",
      "Felix J. Herrmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.06998"
  },
  {
    "id": "arXiv:2106.07000",
    "title": "Analysis of Large Scale Aerial Terrestrial Networks with mmWave  Backhauling",
    "abstract": "Service providers are considering the use of unmanned aerial vehicles (UAVs)\nto enhance wireless connectivity of cellular networks. To provide connectivity,\nUAVs have to be backhauled through terrestrial base stations (BSs) to the core\nnetwork. In particular, we consider millimeter-wave (mmWave) backhauling in the\ndownlink of a hybrid aerial-terrestrial network, where the backhaul links are\nsubject to beamforming misalignment errors. In the proposed model, the user\nequipment (UE) can connect to either a ground BS or a UAV, where we\ndifferentiate between two transmission schemes according to the backhaul\nstatus. In one scheme, the UEs are served by the UAVs regardless of whether the\nbackhaul links are good or not. In the other scheme, the UAVs are aware of the\nbackhaul links status, and hence, only the subset of successfully backhauled\nUAVs can serve the UEs. Using stochastic geometry, the performance of the\nproposed model is assessed in terms of coverage probability and validated\nagainst Monte-Carlo simulations. Several insights are provided for determining\nsome system parameters including the UAVs altitude and required number and the\nbeamforming misalignment error of the backhaul link. The obtained results\nhighlight the impact of the UAVs backhaul link on the UE experience.",
    "descriptor": "",
    "authors": [
      "Nour Kouzayha",
      "Hesham ElSawy",
      "Hayssam Dahrouj",
      "Khlod Alshaikh",
      "Tareq Y. Al-Naffouri",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.07000"
  },
  {
    "id": "arXiv:2106.07003",
    "title": "Experimental Analysis of Trajectory Control Using Computer Vision and  Artificial Intelligence for Autonomous Vehicles",
    "abstract": "Perception of the lane boundaries is crucial for the tasks related to\nautonomous trajectory control. In this paper, several methodologies for lane\ndetection are discussed with an experimental illustration: Hough\ntransformation, Blob analysis, and Bird's eye view. Following the abstraction\nof lane marks from the boundary, the next approach is applying a control law\nbased on the perception to control steering and speed control. In the\nfollowing, a comparative analysis is made between an open-loop response, PID\ncontrol, and a neural network control law through graphical statistics. To get\nthe perception of the surrounding a wireless streaming camera connected to\nRaspberry Pi is used. After pre-processing the signal received by the camera\nthe output is sent back to the Raspberry Pi that processes the input and\ncommunicates the control to the motors through Arduino via serial\ncommunication.",
    "descriptor": "",
    "authors": [
      "Ammar N. Abbas",
      "Muhammad Asad Irshad",
      "Hossam Hassan Ammar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07003"
  },
  {
    "id": "arXiv:2106.07009",
    "title": "Noise2Score: Tweedie's Approach to Self-Supervised Image Denoising  without Clean Images",
    "abstract": "Recently, there has been extensive research interest in training deep\nnetworks to denoise images without clean reference. However, the representative\napproaches such as Noise2Noise, Noise2Void, Stein's unbiased risk estimator\n(SURE), etc. seem to differ from one another and it is difficult to find the\ncoherent mathematical structure. To address this, here we present a novel\napproach, called Noise2Score, which reveals a missing link in order to unite\nthese seemingly different approaches. Specifically, we show that image\ndenoising problems without clean images can be addressed by finding the mode of\nthe posterior distribution and that the Tweedie's formula offers an explicit\nsolution through the score function (i.e. the gradient of log likelihood). Our\nmethod then uses the recent finding that the score function can be stably\nestimated from the noisy images using the amortized residual denoising\nautoencoder, the method of which is closely related to Noise2Noise or\nNose2Void. Our Noise2Score approach is so universal that the same network\ntraining can be used to remove noises from images that are corrupted by any\nexponential family distributions and noise parameters. Using extensive\nexperiments with Gaussian, Poisson, and Gamma noises, we show that Noise2Score\nsignificantly outperforms the state-of-the-art self-supervised denoising\nmethods in the benchmark data set such as (C)BSD68, Set12, and Kodak, etc.",
    "descriptor": "",
    "authors": [
      "Kwanyoung Kim",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07009"
  },
  {
    "id": "arXiv:2106.07011",
    "title": "Underwater Soft Robotic Hand with Multi-Source Coupling Bio-Inspired  Soft Palm and Six Fingers Driven by Water Hydraulic",
    "abstract": "A new fluid-driven soft robot hand in this study uses the idea of the bionics\nand has the anthropomorphic form, which is oriented to the flexible grasp\nfunction. The soft robot hand is composed of a new kind of multi-freedom soft\nfinger and soft palm, which realizes the characteristic grasping function of\nforehand and backhand. Combined with the fine fluid control system, the soft\nhand can realize flexible grasping under high pressure, so as to realize\nflexible grasping operation for different types of target objects in the\nunderwater environment. The soft robot hand was controlled based on water\nhydraulic platform, Finally, the soft robot hand and the fine fluid control\nsystem were connected to form the underwater soft robot hand experiment\nplatform.",
    "descriptor": "\nComments: 7 pages, 9 figures\n",
    "authors": [
      "Haihang Wang",
      "He Xu",
      "Chen Yang",
      "Xin Li",
      "Siqing Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.07011"
  },
  {
    "id": "arXiv:2106.07012",
    "title": "Incomplete Gamma Integrals for Deep Cascade Prediction using Content,  Network, and Exogenous Signals",
    "abstract": "The behaviour of information cascades (such as retweets) has been modelled\nextensively. While point process-based generative models have long been in use\nfor estimating cascade growths, deep learning has greatly enhanced diverse\nfeature integration. We observe two significant temporal signals in cascade\ndata that have not been emphasized or reported to our knowledge. First, the\npopularity of the cascade root is known to influence cascade size strongly; but\nthe effect falls off rapidly with time. Second, there is a measurable positive\ncorrelation between the novelty of the root content (with respect to a\nstreaming external corpus) and the relative size of the resulting cascade.\nResponding to these observations, we propose GammaCas, a new cascade growth\nmodel as a parametric function of time, which combines deep influence signals\nfrom content (e.g., tweet text), network features (e.g., followers of the root\nuser), and exogenous event sources (e.g., online news). Specifically, our model\nprocesses these signals through a customized recurrent network, whose states\nthen provide the parameters of the cascade rate function, which is integrated\nover time to predict the cascade size. The network parameters are trained\nend-to-end using observed cascades. GammaCas outperforms seven recent and\ndiverse baselines significantly on a large-scale dataset of retweet cascades\ncoupled with time-aligned online news -- it beats the best baseline with an\n18.98% increase in terms of Kendall's $\\tau$ correlation and $35.63$ reduction\nin Mean Absolute Percentage Error. Extensive ablation and case studies unearth\ninteresting insights regarding retweet cascade dynamics.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Subhabrata Dutta",
      "Shravika Mittal",
      "Dipankar Das",
      "Soumen Chakrabarti",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07012"
  },
  {
    "id": "arXiv:2106.07015",
    "title": "Siamese Network Training Using Sampled Triplets and Image Transformation",
    "abstract": "The device used in this work detects the objects over the surface of the\nwater using two thermal cameras which aid the users to detect and avoid the\nobjects in scenarios where the human eyes cannot (night, fog, etc.). To avoid\nthe obstacle collision autonomously, it is required to track the objects in\nreal-time and assign a specific identity to each object to determine its\ndynamics (trajectory, velocity, etc.) for making estimated collision\npredictions. In the following work, a Machine Learning (ML) approach for\nComputer Vision (CV) called Convolutional Neural Network (CNN) was used using\nTensorFlow as the high-level programming environment in Python. To validate the\nalgorithm a test set was generated using an annotation tool that was created\nduring the work for proper evaluation. Once validated, the algorithm was\ndeployed on the platform and tested with the sequence generated by the test\nboat.",
    "descriptor": "",
    "authors": [
      "Ammar N. Abbas",
      "David Moser"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07015"
  },
  {
    "id": "arXiv:2106.07017",
    "title": "The k-mappability problem revisited",
    "abstract": "The $k$-mappability problem has two integers parameters $m$ and $k$. For\nevery subword of size $m$ in a text $S$, we wish to report the number of\nindices in $S$ in which the word occurs with at most $k$ mismatches.\nThe problem was lately tackled by Alzamel et al. For a text with constant\nalphabet $\\Sigma$ and $k \\in O(1)$, they present an algorithm with linear space\nand $O(n\\log^{k+1}n)$ time. For the case in which $k = 1$ and a constant size\nalphabet, a faster algorithm with linear space and $O(n\\log(n)\\log\\log(n))$\ntime was presented in a 2020 paper by Alzamel et al.\nIn this work, we enhance the techniques of Alzamel et al.'s 2020 paper to\nobtain an algorithm with linear space and $O(n \\log(n))$ time for $k = 1$. Our\nalgorithm removes the constraint of the alphabet being of constant size. We\nalso present linear algorithms for the case of $k=1$, $|\\Sigma|\\in O(1)$ and\n$m=\\Omega(\\sqrt{n})$.",
    "descriptor": "",
    "authors": [
      "Amihood Amir",
      "Itai Boneh",
      "Eitan Kondratovsky"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07017"
  },
  {
    "id": "arXiv:2106.07020",
    "title": "Generation of the NIR spectral Band for Satellite Images with  Convolutional Neural Networks",
    "abstract": "The near-infrared (NIR) spectral range (from 780 to 2500 nm) of the\nmultispectral remote sensing imagery provides vital information for the\nlandcover classification, especially concerning the vegetation assessment.\nDespite the usefulness of NIR, common RGB is not always accompanied by it.\nModern achievements in image processing via deep neural networks allow\ngenerating artificial spectral information, such as for the image colorization\nproblem. In this research, we aim to investigate whether this approach can\nproduce not only visually similar images but also an artificial spectral band\nthat can improve the performance of computer vision algorithms for solving\nremote sensing tasks. We study the generative adversarial network (GAN)\napproach in the task of the NIR band generation using just RGB channels of\nhigh-resolution satellite imagery. We evaluate the impact of a generated\nchannel on the model performance for solving the forest segmentation task. Our\nresults show an increase in model accuracy when using generated NIR comparing\nto the baseline model that uses only RGB (0.947 and 0.914 F1-score\naccordingly). Conducted study shows the advantages of generating the extra band\nand its implementation in applied challenges reducing the required amount of\nlabeled data.",
    "descriptor": "",
    "authors": [
      "Svetlana Illarionova",
      "Dmitrii Shadrin",
      "Alexey Trekin",
      "Vladimir Ignatiev",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07020"
  },
  {
    "id": "arXiv:2106.07022",
    "title": "Robust Speed Control Methodology for Variable Speed Wind Turbines",
    "abstract": "Improving wind turbine efficiency is essential for reducing the costs of\nenergy production. The highly nonlinear dynamics of the wind turbines and their\nuncertain operating conditions have posed many challenges for their control\nmethods. In this work, a robust control strategy based on sliding mode and\nadaptive fuzzy disturbance observer is proposed for speed tracking in a\nvariable speed wind turbine. First, the nonlinear mathematical model that\ndescribes the dynamics of the variable speed wind turbine is derived. This\nnonlinear model is then used to derive the control methodology and to find\nstability and robustness conditions. The control approach is designed to track\nthe optimal wind speed that causes maximum energy extraction. The stability\ncondition was verified using the Lyapunov stability theory. A simulation study\nwas conducted to verify the method, and a comparative analysis was used to\nmeasure its effectiveness. The results showed a high tracking ability and\nrobustness of the developed methodology. Moreover, higher power extraction was\nobserved when compared to a classical control method.",
    "descriptor": "\nComments: 6 pages, conference\n",
    "authors": [
      "Ammar Al-Jodah",
      "Marwah Alwan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07022"
  },
  {
    "id": "arXiv:2106.07023",
    "title": "Styleformer: Transformer based Generative Adversarial Networks with  Style Vector",
    "abstract": "We propose Styleformer, which is a style-based generator for GAN\narchitecture, but a convolution-free transformer-based generator. In our paper,\nwe explain how a transformer can generate high-quality images, overcoming the\ndisadvantage that convolution operations are difficult to capture global\nfeatures in an image. Furthermore, we change the demodulation of StyleGAN2 and\nmodify the existing transformer structure (e.g., residual connection, layer\nnormalization) to create a strong style-based generator with a convolution-free\nstructure. We also make Styleformer lighter by applying Linformer, enabling\nStyleformer to generate higher resolution images and result in improvements in\nterms of speed and memory. We experiment with the low-resolution image dataset\nsuch as CIFAR-10, as well as the high-resolution image dataset like\nLSUN-church. Styleformer records FID 2.82 and IS 9.94 on CIFAR-10, a benchmark\ndataset, which is comparable performance to the current state-of-the-art and\noutperforms all GAN-based generative models, including StyleGAN2-ADA with fewer\nparameters on the unconditional setting. We also both achieve new\nstate-of-the-art with FID 20.11, IS 10.16, and FID 3.66, respectively on STL-10\nand CelebA. We release our code at\nhttps://github.com/Jeeseung-Park/Styleformer.",
    "descriptor": "",
    "authors": [
      "Jeeseung Park",
      "Younggeun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07023"
  },
  {
    "id": "arXiv:2106.07024",
    "title": "Finite-Length Bounds on Hypothesis Testing Subject to Vanishing Type I  Error Restrictions",
    "abstract": "A central problem in Binary Hypothesis Testing (BHT) is to determine the\noptimal tradeoff between the Type I error (referred to as false alarm) and Type\nII (referred to as miss) error. In this context, the exponential rate of\nconvergence of the optimal miss error probability -- as the sample size tends\nto infinity -- given some (positive) restrictions on the false alarm\nprobabilities is a fundamental question to address in theory. Considering the\nmore realistic context of a BHT with a finite number of observations, this\npaper presents a new non-asymptotic result for the scenario with monotonic\n(sub-exponential decreasing) restriction on the Type I error probability, which\nextends the result presented by Strassen in 2009. Building on the use of\nconcentration inequalities, we offer new upper and lower bounds to the optimal\nType II error probability for the case of finite observations. Finally, the\nderived bounds are evaluated and interpreted numerically (as a function of the\nnumber samples) for some vanishing Type I error restrictions.",
    "descriptor": "",
    "authors": [
      "Sebastian Espinosa",
      "Jorge F. Silva",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.07024"
  },
  {
    "id": "arXiv:2106.07026",
    "title": "Reborn Mechanism: Rethinking the Negative Phase Information Flow in  Convolutional Neural Network",
    "abstract": "This paper proposes a novel nonlinear activation mechanism typically for\nconvolutional neural network (CNN), named as reborn mechanism. In sharp\ncontrast to ReLU which cuts off the negative phase value, the reborn mechanism\nenjoys the capacity to reborn and reconstruct dead neurons. Compared to other\nimproved ReLU functions, reborn mechanism introduces a more proper way to\nutilize the negative phase information. Extensive experiments validate that\nthis activation mechanism is able to enhance the model representation ability\nmore significantly and make the better use of the input data information while\nmaintaining the advantages of the original ReLU function. Moreover, reborn\nmechanism enables a non-symmetry that is hardly achieved by traditional CNNs\nand can act as a channel compensation method, offering competitive or even\nbetter performance but with fewer learned parameters than traditional methods.\nReborn mechanism was tested on various benchmark datasets, all obtaining better\nperformance than previous nonlinear activation functions.",
    "descriptor": "",
    "authors": [
      "Zhicheng Cai",
      "Kaizhu Huang",
      "Chenglei Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07026"
  },
  {
    "id": "arXiv:2106.07029",
    "title": "SSS-PRNU: Privacy-Preserving PRNU Based Camera Attribution using Shamir  Secret Sharing",
    "abstract": "Photo Response Non-Uniformity(PRNU) noise has proven to be very effective\ntool in camera based forensics. It helps to match a photo to the device that\nclicked it. In today's scenario, where millions and millions of images are\nuploaded every hour, it is very easy to compute this unique PRNU pattern from a\ncouple of shared images on social profiles. This endangers the privacy of the\ncamera owner and becomes a cause of major concern for the privacy-aware\nsociety. We propose SSS-PRNU scheme that facilitates the forensic investigators\nto carry out their crime investigation without breaching the privacy of the\npeople. Thus, maintaining a balance between the two. To preserve privacy,\nextraction of camera fingerprint and PRNU noise for a suspicious image is\ncomputed in a trusted execution environment such as ARM TrustZone. After\nextraction, the sensitive information of camera fingerprint and PRNU noise is\ndistributed into multiple obfuscated shares using Shamir secret sharing(SSS)\nscheme. These shares are information-theoretically secure and leak no\ninformation of underlying content. The encrypted information is distributed to\nmultiple third-part servers where correlation is computed on a share basis\nbetween the camera fingerprint and the PRNU noise. These partial correlation\nvalues are combined together to obtain the final correlation value that becomes\nthe basis for a match decision. Transforming the computation of the correlation\nvalue in the encrypted domain and making it well suited for a distributed\nenvironment is the main contribution of the paper. Experiment results validate\nthe feasibility of the proposed scheme that provides a secure framework for\nPRNU based source camera attribution. The security analysis and evaluation of\ncomputational and storage overheads are performed to analysis the practical\nfeasibility of the scheme.",
    "descriptor": "",
    "authors": [
      "Riyanka Jena",
      "Priyanka Singh",
      "Manoranjan Mohanty"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.07029"
  },
  {
    "id": "arXiv:2106.07030",
    "title": "The Backpropagation Algorithm Implemented on Spiking Neuromorphic  Hardware",
    "abstract": "The capabilities of natural neural systems have inspired new generations of\nmachine learning algorithms as well as neuromorphic very large-scale integrated\n(VLSI) circuits capable of fast, low-power information processing. However,\nmost modern machine learning algorithms are not neurophysiologically plausible\nand thus are not directly implementable in neuromorphic hardware. In\nparticular, the workhorse of modern deep learning, the backpropagation\nalgorithm, has proven difficult to translate to neuromorphic hardware. In this\nstudy, we present a neuromorphic, spiking backpropagation algorithm based on\npulse-gated dynamical information coordination and processing, implemented on\nIntel's Loihi neuromorphic research processor. We demonstrate a\nproof-of-principle three-layer circuit that learns to classify digits from the\nMNIST dataset. This implementation shows a path for using massively parallel,\nlow-power, low-latency neuromorphic processors in modern deep learning\napplications.",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Alpha Renner",
      "Forrest Sheldon",
      "Anatoly Zlotnik",
      "Louis Tao",
      "Andrew Sornborger"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.07030"
  },
  {
    "id": "arXiv:2106.07032",
    "title": "Category Theory in Machine Learning",
    "abstract": "Over the past two decades machine learning has permeated almost every realm\nof technology. At the same time, many researchers have begun using category\ntheory as a unifying language, facilitating communication between different\nscientific disciplines. It is therefore unsurprising that there is a burgeoning\ninterest in applying category theory to machine learning. We aim to document\nthe motivations, goals and common themes across these applications. We touch on\ngradient-based learning, probability, and equivariant learning.",
    "descriptor": "",
    "authors": [
      "Dan Shiebler",
      "Bruno Gavranovi\u0107",
      "Paul Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07032"
  },
  {
    "id": "arXiv:2106.07033",
    "title": "Understanding the Interplay between Privacy and Robustness in Federated  Learning",
    "abstract": "Federated Learning (FL) is emerging as a promising paradigm of\nprivacy-preserving machine learning, which trains an algorithm across multiple\nclients without exchanging their data samples. Recent works highlighted several\nprivacy and robustness weaknesses in FL and addressed these concerns using\nlocal differential privacy (LDP) and some well-studied methods used in\nconventional ML, separately. However, it is still not clear how LDP affects\nadversarial robustness in FL. To fill this gap, this work attempts to develop a\ncomprehensive understanding of the effects of LDP on adversarial robustness in\nFL. Clarifying the interplay is significant since this is the first step\ntowards a principled design of private and robust FL systems. We certify that\nlocal differential privacy has both positive and negative effects on\nadversarial robustness using theoretical analysis and empirical verification.",
    "descriptor": "",
    "authors": [
      "Yaowei Han",
      "Yang Cao",
      "Masatoshi Yoshikawa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07033"
  },
  {
    "id": "arXiv:2106.07034",
    "title": "An Extended Multi-Model Regression Approach for Compressive Strength  Prediction and Optimization of a Concrete Mixture",
    "abstract": "Due to the significant delay and cost associated with experimental tests, a\nmodel based evaluation of concrete compressive strength is of high value, both\nfor the purpose of strength prediction as well as the mixture optimization. In\nthis regard, several recent studies have employed state-of-the-art regression\nmodels in order to achieve a good prediction model, employing available\nexperimental data sets. Nevertheless, while each of the employed models can\nbetter adapt to a specific nature of the input data, the accuracy of each\nindividual model is limited due to the sensitivity to the choice of\nhyperparameters and the learning strategy. In the present work, we take a\nfurther step towards improving the accuracy of the prediction model via the\nweighted combination of multiple regression methods. Moreover, a (GA)-based\nmulti-objective mixture optimization is proposed, building on the obtained\nmulti-regression model. In particular, we present a data aided framework where\nthe regression methods based on artificial neural network, random forest\nregression, and polynomial regression are jointly implemented to predict the\ncompressive strength of concrete. The outcome of the individual regression\nmodels are then combined via a linear weighting strategy and optimized over the\ntraining data set as a quadratic convex optimization problem. It is worth\nmentioning that due to the convexity of the formulated problem, the globally\noptimum weighting strategy is obtained via standard numerical solvers.\nEmploying the proposed GA-based optimization, a Pareto front of the cost-CS\ntrade-of has been obtained employing the available data set. Moreover, the\nresulting accuracy of the proposed multi-model prediction method is shown to\noutperform the available single-model regression methods in the literature by a\nvaluable margin, via numerical simulations.",
    "descriptor": "",
    "authors": [
      "Seyed Arman Taghizadeh Motlagh",
      "Mehran Naghizadehrokni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07034"
  },
  {
    "id": "arXiv:2106.07035",
    "title": "Deep Bayesian Unsupervised Lifelong Learning",
    "abstract": "Lifelong Learning (LL) refers to the ability to continually learn and solve\nnew problems with incremental available information over time while retaining\nprevious knowledge. Much attention has been given lately to Supervised Lifelong\nLearning (SLL) with a stream of labelled data. In contrast, we focus on\nresolving challenges in Unsupervised Lifelong Learning (ULL) with streaming\nunlabelled data when the data distribution and the unknown class labels evolve\nover time. Bayesian framework is natural to incorporate past knowledge and\nsequentially update the belief with new data. We develop a fully Bayesian\ninference framework for ULL with a novel end-to-end Deep Bayesian Unsupervised\nLifelong Learning (DBULL) algorithm, which can progressively discover new\nclusters without forgetting the past with unlabelled data while learning latent\nrepresentations. To efficiently maintain past knowledge, we develop a novel\nknowledge preservation mechanism via sufficient statistics of the latent\nrepresentation for raw data. To detect the potential new clusters on the fly,\nwe develop an automatic cluster discovery and redundancy removal strategy in\nour inference inspired by Nonparametric Bayesian statistics techniques. We\ndemonstrate the effectiveness of our approach using image and text corpora\nbenchmark datasets in both LL and batch settings.",
    "descriptor": "",
    "authors": [
      "Tingting Zhao",
      "Zifeng Wang",
      "Aria Masoomi",
      "Jennifer Dy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07035"
  },
  {
    "id": "arXiv:2106.07036",
    "title": "Protein-Ligand Docking Surrogate Models: A SARS-CoV-2 Benchmark for Deep  Learning Accelerated Virtual Screening",
    "abstract": "We propose a benchmark to study surrogate model accuracy for protein-ligand\ndocking. We share a dataset consisting of 200 million 3D complex structures and\n2D structure scores across a consistent set of 13 million ``in-stock''\nmolecules over 15 receptors, or binding sites, across the SARS-CoV-2 proteome.\nOur work shows surrogate docking models have six orders of magnitude more\nthroughput than standard docking protocols on the same supercomputer node\ntypes. We demonstrate the power of high-speed surrogate models by running each\ntarget against 1 billion molecules in under a day (50k predictions per GPU\nseconds). We showcase a workflow for docking utilizing surrogate ML models as a\npre-filter. Our workflow is ten times faster at screening a library of\ncompounds than the standard technique, with an error rate less than 0.01\\% of\ndetecting the underlying best scoring 0.1\\% of compounds. Our analysis of the\nspeedup explains that to screen more molecules under a docking paradigm,\nanother order of magnitude speedup must come from model accuracy rather than\ncomputing speed (which, if increased, will not anymore alter our throughput to\nscreen molecules). We believe this is strong evidence for the community to\nbegin focusing on improving the accuracy of surrogate models to improve the\nability to screen massive compound libraries 100x or even 1000x faster than\ncurrent techniques.",
    "descriptor": "",
    "authors": [
      "Austin Clyde",
      "Thomas Brettin",
      "Alex Partin",
      "Hyunseung Yoo",
      "Yadu Babuji",
      "Ben Blaiszik",
      "Andre Merzky",
      "Matteo Turilli",
      "Shantenu Jha",
      "Arvind Ramanathan",
      "Rick Stevens"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07036"
  },
  {
    "id": "arXiv:2106.07037",
    "title": "Hash Adaptive Bloom Filter",
    "abstract": "Bloom filter is a compact memory-efficient probabilistic data structure\nsupporting membership testing, i.e., to check whether an element is in a given\nset. However, as Bloom filter maps each element with uniformly random hash\nfunctions, few flexibilities are provided even if the information of negative\nkeys (elements are not in the set) are available. The problem gets worse when\nthe misidentification of negative keys brings different costs. To address the\nabove problems, we propose a new Hash Adaptive Bloom Filter (HABF) that\nsupports the customization of hash functions for keys. The key idea of HABF is\nto customize the hash functions for positive keys (elements are in the set) to\navoid negative keys with high cost, and pack customized hash functions into a\nlightweight data structure named HashExpressor. Then, given an element at query\ntime, HABF follows a two-round pattern to check whether the element is in the\nset. Further, we theoretically analyze the performance of HABF and bound the\nexpected false positive rate. We conduct extensive experiments on\nrepresentative datasets, and the results show that HABF outperforms the\nstandard Bloom filter and its cutting-edge variants on the whole in terms of\naccuracy, construction time, query time, and memory space consumption (Note\nthat source codes are available in [1]).",
    "descriptor": "\nComments: 11 pages, accepted by ICDE 2021\n",
    "authors": [
      "Rongbiao Xie",
      "Meng Li",
      "Zheyu Miao",
      "Rong Gu",
      "He Huang",
      "Haipeng Dai",
      "Guihai Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.07037"
  },
  {
    "id": "arXiv:2106.07039",
    "title": "Contingency-Aware Influence Maximization: A Reinforcement Learning  Approach",
    "abstract": "The influence maximization (IM) problem aims at finding a subset of seed\nnodes in a social network that maximize the spread of influence. In this study,\nwe focus on a sub-class of IM problems, where whether the nodes are willing to\nbe the seeds when being invited is uncertain, called contingency-aware IM. Such\ncontingency aware IM is critical for applications for non-profit organizations\nin low resource communities (e.g., spreading awareness of disease prevention).\nDespite the initial success, a major practical obstacle in promoting the\nsolutions to more communities is the tremendous runtime of the greedy\nalgorithms and the lack of high performance computing (HPC) for the non-profits\nin the field -- whenever there is a new social network, the non-profits usually\ndo not have the HPCs to recalculate the solutions. Motivated by this and\ninspired by the line of works that use reinforcement learning (RL) to address\ncombinatorial optimization on graphs, we formalize the problem as a Markov\nDecision Process (MDP), and use RL to learn an IM policy over historically seen\nnetworks, and generalize to unseen networks with negligible runtime at test\nphase. To fully exploit the properties of our targeted problem, we propose two\ntechnical innovations that improve the existing methods, including\nstate-abstraction and theoretically grounded reward shaping. Empirical results\nshow that our method achieves influence as high as the state-of-the-art methods\nfor contingency-aware IM, while having negligible runtime at test phase.",
    "descriptor": "\nComments: 11 pages; accepted for publication at UAI 2021\n",
    "authors": [
      "Haipeng Chen",
      "Wei Qiu",
      "Han-Ching Ou",
      "Bo An",
      "Milind Tambe"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07039"
  },
  {
    "id": "arXiv:2106.07041",
    "title": "Correcting Exposure Bias for Link Recommendation",
    "abstract": "Link prediction methods are frequently applied in recommender systems, e.g.,\nto suggest citations for academic papers or friends in social networks.\nHowever, exposure bias can arise when users are systematically underexposed to\ncertain relevant items. For example, in citation networks, authors might be\nmore likely to encounter papers from their own field and thus cite them\npreferentially. This bias can propagate through naively trained link\npredictors, leading to both biased evaluation and high generalization error (as\nassessed by true relevance). Moreover, this bias can be exacerbated by feedback\nloops. We propose estimators that leverage known exposure probabilities to\nmitigate this bias and consequent feedback loops. Next, we provide a loss\nfunction for learning the exposure probabilities from data. Finally,\nexperiments on semi-synthetic data based on real-world citation networks, show\nthat our methods reliably identify (truly) relevant citations. Additionally,\nour methods lead to greater diversity in the recommended papers' fields of\nstudy. The code is available at\nhttps://github.com/shantanu95/exposure-bias-link-rec.",
    "descriptor": "",
    "authors": [
      "Shantanu Gupta",
      "Hao Wang",
      "Zachary C. Lipton",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07041"
  },
  {
    "id": "arXiv:2106.07045",
    "title": "VeriFly: On-the-fly Assertion Checking via Incrementality",
    "abstract": "Assertion checking is an invaluable programmer's tool for finding many\nclasses of errors or verifying their absence in dynamic languages such as\nProlog. For Prolog programmers this means being able to have relevant\nproperties such as modes, types, determinacy, non-failure, sharing,\nconstraints, cost, etc., checked and errors flagged without having to actually\nrun the program. Such global static analysis tools are arguably most useful the\nearlier they are used in the software development cycle, and fast response\ntimes are essential for interactive use. Triggering a full and precise semantic\nanalysis of a software project every time a change is made can be prohibitively\nexpensive. In our static analysis and verification framework this challenge is\naddressed through a combination of modular and incremental (context- and\npath-sensitive) analysis that is responsive to program edits, at different\nlevels of granularity. We describe how the combination of this framework within\nan integrated development environment (IDE) takes advantage of such\nincrementality to achieve a high level of reactivity when reflecting analysis\nand verification results back as colorings and tooltips directly on the program\ntext -- the tool's VeriFly mode. The concrete implementation that we describe\nis Emacs-based and reuses in part off-the-shelf \"on-the-fly\" syntax checking\nfacilities (flycheck). We believe that similar extensions are also reproducible\nwith low effort in other mature development environments. Our initial\nexperience with the tool shows quite promising results, with low latency times\nthat provide early, continuous, and precise assertion checking and other\nsemantic feedback to programmers during the development process. The tool\nsupports Prolog natively, as well as other languages by semantic transformation\ninto Horn clauses.",
    "descriptor": "\nComments: 18 pages, 11 figures, 2 tables; submitted to ICLP 2021\n",
    "authors": [
      "Miguel A. Sanchez-Ordaz",
      "Isabel Garcia-Contreras",
      "Victor Perez-Carrasco",
      "Jose F. Morales",
      "Pedro lopez-Garcia",
      "Manuel V. Hermenegildo"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.07045"
  },
  {
    "id": "arXiv:2106.07046",
    "title": "Towards Tight Bounds on the Sample Complexity of Average-reward MDPs",
    "abstract": "We prove new upper and lower bounds for sample complexity of finding an\n$\\epsilon$-optimal policy of an infinite-horizon average-reward Markov decision\nprocess (MDP) given access to a generative model. When the mixing time of the\nprobability transition matrix of all policies is at most $t_\\mathrm{mix}$, we\nprovide an algorithm that solves the problem using\n$\\widetilde{O}(t_\\mathrm{mix} \\epsilon^{-3})$ (oblivious) samples per\nstate-action pair. Further, we provide a lower bound showing that a linear\ndependence on $t_\\mathrm{mix}$ is necessary in the worst case for any algorithm\nwhich computes oblivious samples. We obtain our results by establishing\nconnections between infinite-horizon average-reward MDPs and discounted MDPs of\npossible further utility.",
    "descriptor": "",
    "authors": [
      "Yujia Jin",
      "Aaron Sidford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07046"
  },
  {
    "id": "arXiv:2106.07047",
    "title": "Target Model Agnostic Adversarial Attacks with Query Budgets on Language  Understanding Models",
    "abstract": "Despite significant improvements in natural language understanding models\nwith the advent of models like BERT and XLNet, these neural-network based\nclassifiers are vulnerable to blackbox adversarial attacks, where the attacker\nis only allowed to query the target model outputs. We add two more realistic\nrestrictions on the attack methods, namely limiting the number of queries\nallowed (query budget) and crafting attacks that easily transfer across\ndifferent pre-trained models (transferability), which render previous attack\nmodels impractical and ineffective. Here, we propose a target model agnostic\nadversarial attack method with a high degree of attack transferability across\nthe attacked models. Our empirical studies show that in comparison to baseline\nmethods, our method generates highly transferable adversarial sentences under\nthe restriction of limited query budgets.",
    "descriptor": "",
    "authors": [
      "Jatin Chauhan",
      "Karan Bhukar",
      "Manohar Kaul"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07047"
  },
  {
    "id": "arXiv:2106.07049",
    "title": "Weakly-supervised High-resolution Segmentation of Mammography Images for  Breast Cancer Diagnosis",
    "abstract": "In the last few years, deep learning classifiers have shown promising results\nin image-based medical diagnosis. However, interpreting the outputs of these\nmodels remains a challenge. In cancer diagnosis, interpretability can be\nachieved by localizing the region of the input image responsible for the\noutput, i.e. the location of a lesion. Alternatively, segmentation or detection\nmodels can be trained with pixel-wise annotations indicating the locations of\nmalignant lesions. Unfortunately, acquiring such labels is labor-intensive and\nrequires medical expertise. To overcome this difficulty, weakly-supervised\nlocalization can be utilized. These methods allow neural network classifiers to\noutput saliency maps highlighting the regions of the input most relevant to the\nclassification task (e.g. malignant lesions in mammograms) using only\nimage-level labels (e.g. whether the patient has cancer or not) during\ntraining. When applied to high-resolution images, existing methods produce\nlow-resolution saliency maps. This is problematic in applications in which\nsuspicious lesions are small in relation to the image size. In this work, we\nintroduce a novel neural network architecture to perform weakly-supervised\nsegmentation of high-resolution images. The proposed model selects regions of\ninterest via coarse-level localization, and then performs fine-grained\nsegmentation of those regions. We apply this model to breast cancer diagnosis\nwith screening mammography, and validate it on a large clinically-realistic\ndataset. Measured by Dice similarity score, our approach outperforms existing\nmethods by a large margin in terms of localization performance of benign and\nmalignant lesions, relatively improving the performance by 39.6% and 20.0%,\nrespectively. Code and the weights of some of the models are available at\nhttps://github.com/nyukat/GLAM",
    "descriptor": "\nComments: The last two authors contributed equally. Accepted to Medical Imaging with Deep Learning (MIDL) 2021\n",
    "authors": [
      "Kangning Liu",
      "Yiqiu Shen",
      "Nan Wu",
      "Jakub Ch\u0142\u0119dowski",
      "Carlos Fernandez-Granda",
      "Krzysztof J. Geras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07049"
  },
  {
    "id": "arXiv:2106.07051",
    "title": "Comparative analysis of quality of service scheduling classes in mobile  ad-hoc networks",
    "abstract": "Quality of Service (QoS) is now regarded as a requirement for all networks in\nmanaging resources like bandwidth and avoidance of network impairments like\npacket loss, jitter, and delay. Media transfer or streaming would be virtually\nimpossible if QoS parameters were not used even if the streaming protocols were\nperfectly designed. QoS Scheduling classes help in network traffic optimization\nand the priority management of packets. This paper presents an analysis of QoS\nscheduling classes using video traffic in a MANET. The main objective was to\nidentify a scheduling class that provides better QoS for video streaming. A\nsimulation was conducted using NetSim and results were analyzed according to\nthroughput, jitter, and delay. The overall results showed that extended\nreal-time Polling Service (ertPS) outperformed the other classes. ertPS has\nhybrid features of both real-time Polling Service (rtPS) and Unsolicited Grant\nService(UGS) hence the enhanced performance. It is recommended that ertPS\nscheduling class should be used in MANET where QoS consideration is utmost\nparticularly in multimedia streaming applications.",
    "descriptor": "",
    "authors": [
      "Thulani Phakathi",
      "Bukohwo Michael Esiefarienrhe",
      "Francis Lugayizi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.07051"
  },
  {
    "id": "arXiv:2106.07052",
    "title": "Wide Mean-Field Variational Bayesian Neural Networks Ignore the Data",
    "abstract": "Variational inference enables approximate posterior inference of the highly\nover-parameterized neural networks that are popular in modern machine learning.\nUnfortunately, such posteriors are known to exhibit various pathological\nbehaviors. We prove that as the number of hidden units in a single-layer\nBayesian neural network tends to infinity, the function-space posterior mean\nunder mean-field variational inference actually converges to zero, completely\nignoring the data. This is in contrast to the true posterior, which converges\nto a Gaussian process. Our work provides insight into the over-regularization\nof the KL divergence in variational inference.",
    "descriptor": "",
    "authors": [
      "Beau Coker",
      "Weiwei Pan",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07052"
  },
  {
    "id": "arXiv:2106.07053",
    "title": "Convex Sparse Blind Deconvolution",
    "abstract": "In the blind deconvolution problem, we observe the convolution of an unknown\nfilter and unknown signal and attempt to reconstruct the filter and signal. The\nproblem seems impossible in general, since there are seemingly many more\nunknowns than knowns . Nevertheless, this problem arises in many application\nfields; and empirically, some of these fields have had success using heuristic\nmethods -- even economically very important ones, in wireless communications\nand oil exploration. Today's fashionable heuristic formulations pose non-convex\noptimization problems which are then attacked heuristically as well. The fact\nthat blind deconvolution can be solved under some repeatable and\nnaturally-occurring circumstances poses a theoretical puzzle.\nTo bridge the gulf between reported successes and theory's limited\nunderstanding, we exhibit a convex optimization problem that -- assuming signal\nsparsity -- can convert a crude approximation to the true filter into a\nhigh-accuracy recovery of the true filter. Our proposed formulation is based on\nL1 minimization of inverse filter outputs. We give sharp guarantees on\nperformance of the minimizer assuming sparsity of signal, showing that our\nproposal precisely recovers the true inverse filter, up to shift and rescaling.\nThere is a sparsity/initial accuracy tradeoff: the less accurate the initial\napproximation, the greater we rely on sparsity to enable exact recovery. To our\nknowledge this is the first reported tradeoff of this kind. We consider it\nsurprising that this tradeoff is independent of dimension.\nWe also develop finite-$N$ guarantees, for highly accurate reconstruction\nunder $N\\geq O(k \\log(k) )$ with high probability. We further show stable\napproximation when the true inverse filter is infinitely long and extend our\nguarantees to the case where the observations are contaminated by stochastic or\nadversarial noise.",
    "descriptor": "",
    "authors": [
      "Qingyun Sun",
      "David Donoho"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Statistics Theory (math.ST)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2106.07053"
  },
  {
    "id": "arXiv:2106.07055",
    "title": "GenSF: Simultaneous Adaptation of Generative Pre-trained Models and Slot  Filling",
    "abstract": "In transfer learning, it is imperative to achieve strong alignment between a\npre-trained model and a downstream task. Prior work has done this by proposing\ntask-specific pre-training objectives, which sacrifices the inherent\nscalability of the transfer learning paradigm. We instead achieve strong\nalignment by simultaneously modifying both the pre-trained model and the\nformulation of the downstream task, which is more efficient and preserves the\nscalability of transfer learning. We present GenSF (Generative Slot Filling),\nwhich leverages a generative pre-trained open-domain dialog model for slot\nfilling. GenSF (1) adapts the pre-trained model by incorporating inductive\nbiases about the task and (2) adapts the downstream task by reformulating slot\nfilling to better leverage the pre-trained model's capabilities. GenSF achieves\nstate-of-the-art results on two slot filling datasets with strong gains in\nfew-shot and zero-shot settings. We achieve a 9 F1 score improvement in\nzero-shot slot filling. This highlights the value of strong alignment between\nthe pre-trained model and the downstream task.",
    "descriptor": "\nComments: Accepted at SIGDial 2021\n",
    "authors": [
      "Shikib Mehri",
      "Maxine Eskenazi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07055"
  },
  {
    "id": "arXiv:2106.07056",
    "title": "Schema-Guided Paradigm for Zero-Shot Dialog",
    "abstract": "Developing mechanisms that flexibly adapt dialog systems to unseen tasks and\ndomains is a major challenge in dialog research. Neural models implicitly\nmemorize task-specific dialog policies from the training data. We posit that\nthis implicit memorization has precluded zero-shot transfer learning. To this\nend, we leverage the schema-guided paradigm, wherein the task-specific dialog\npolicy is explicitly provided to the model. We introduce the Schema Attention\nModel (SAM) and improved schema representations for the STAR corpus. SAM\nobtains significant improvement in zero-shot settings, with a +22 F1 score\nimprovement over prior work. These results validate the feasibility of\nzero-shot generalizability in dialog. Ablation experiments are also presented\nto demonstrate the efficacy of SAM.",
    "descriptor": "\nComments: Accepted at SIGDial 2021\n",
    "authors": [
      "Shikib Mehri",
      "Maxine Eskenazi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07056"
  },
  {
    "id": "arXiv:2106.07057",
    "title": "FairCanary: Rapid Continuous Explainable Fairness",
    "abstract": "Machine Learning (ML) models are being used in all facets of today's society\nto make high stake decisions like bail granting or credit lending, with very\nminimal regulations. Such systems are extremely vulnerable to both propagating\nand amplifying social biases, and have therefore been subject to growing\nresearch interest. One of the main issues with conventional fairness metrics is\ntheir narrow definitions which hide the complete extent of the bias by focusing\nprimarily on positive and/or negative outcomes, whilst not paying attention to\nthe overall distributional shape. Moreover, these metrics are often\ncontradictory to each other, are severely restrained by the contextual and\nlegal landscape of the problem, have technical constraints like poor support\nfor continuous outputs, the requirement of class labels, and are not\nexplainable.\nIn this paper, we present Quantile Demographic Drift, which addresses the\nshortcomings mentioned above. This metric can also be used to measure\nintra-group privilege. It is easily interpretable via existing attribution\ntechniques, and also extends naturally to individual fairness via the principle\nof like-for-like comparison. We make this new fairness score the basis of a new\nsystem that is designed to detect bias in production ML models without the need\nfor labels. We call the system FairCanary because of its capability to detect\nbias in a live deployed model and narrow down the alert to the responsible set\nof features, like the proverbial canary in a coal mine.",
    "descriptor": "",
    "authors": [
      "Avijit Ghosh",
      "Aalok Shanbhag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07057"
  },
  {
    "id": "arXiv:2106.07059",
    "title": "Multi-Resource List Scheduling of Moldable Parallel Jobs under  Precedence Constraints",
    "abstract": "The scheduling literature has traditionally focused on a single type of\nresource (e.g., computing nodes). However, scientific applications in modern\nHigh-Performance Computing (HPC) systems process large amounts of data, hence\nhave diverse requirements on different types of resources (e.g., cores, cache,\nmemory, I/O). All of these resources could potentially be exploited by the\nruntime scheduler to improve the application performance. In this paper, we\nstudy multi-resource scheduling to minimize the makespan of computational\nworkflows comprised of parallel jobs subject to precedence constraints. The\njobs are assumed to be moldable, allowing the scheduler to flexibly select a\nvariable set of resources before execution. We propose a multi-resource,\nlist-based scheduling algorithm, and prove that, on a system with $d$ types of\nschedulable resources, our algorithm achieves an approximation ratio of\n$1.619d+2.545\\sqrt{d}+1$ for any $d$, and a ratio of $d+O(\\sqrt[3]{d^2})$ for\nlarge $d$. We also present improved results for independent jobs and for jobs\nwith special precedence constraints (e.g., series-parallel graphs and trees).\nFinally, we prove a lower bound of $d$ on the approximation ratio of any list\nscheduling scheme with local priority considerations. To the best of our\nknowledge, these are the first approximation results for moldable workflows\nwith multiple resource requirements.",
    "descriptor": "",
    "authors": [
      "Lucas Perotin",
      "Hongyang Sun",
      "Padma Raghavan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07059"
  },
  {
    "id": "arXiv:2106.07062",
    "title": "Atlas Based Representation and Metric Learning on Manifolds",
    "abstract": "We explore the use of a topological manifold, represented as a collection of\ncharts, as the target space of neural network based representation learning\ntasks. This is achieved by a simple adjustment to the output of an encoder's\nnetwork architecture plus the addition of a maximal mean discrepancy (MMD)\nbased loss function for regularization. Most algorithms in representation and\nmetric learning are easily adaptable to our framework and we demonstrate its\neffectiveness by adjusting SimCLR (for representation learning) and standard\ntriplet loss training (for metric learning) to have manifold encoding spaces.\nOur experiments show that we obtain a substantial performance boost over the\nbaseline for low dimensional encodings. In the case of triplet training, we\nalso find, independent of the manifold setup, that the MMD loss alone (i.e.\nkeeping a flat, euclidean target space but using an MMD loss to regularize it)\nincreases performance over the baseline in the typical, high-dimensional\nEuclidean target spaces. Code for reproducing experiments is provided at\nhttps://github.com/ekorman/neurve .",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Eric O. Korman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07062"
  },
  {
    "id": "arXiv:2106.07068",
    "title": "HistoTransfer: Understanding Transfer Learning for Histopathology",
    "abstract": "Advancement in digital pathology and artificial intelligence has enabled deep\nlearning-based computer vision techniques for automated disease diagnosis and\nprognosis. However, WSIs present unique computational and algorithmic\nchallenges. WSIs are gigapixel-sized, making them infeasible to be used\ndirectly for training deep neural networks. Hence, for modeling, a two-stage\napproach is adopted: Patch representations are extracted first, followed by the\naggregation for WSI prediction. These approaches require detailed pixel-level\nannotations for training the patch encoder. However, obtaining these\nannotations is time-consuming and tedious for medical experts. Transfer\nlearning is used to address this gap and deep learning architectures\npre-trained on ImageNet are used for generating patch-level representation.\nEven though ImageNet differs significantly from histopathology data,\npre-trained networks have been shown to perform impressively on histopathology\ndata. Also, progress in self-supervised and multi-task learning coupled with\nthe release of multiple histopathology data has led to the release of\nhistopathology-specific networks. In this work, we compare the performance of\nfeatures extracted from networks trained on ImageNet and histopathology data.\nWe use an attention pooling network over these extracted features for\nslide-level aggregation. We investigate if features learned using more complex\nnetworks lead to gain in performance. We use a simple top-k sampling approach\nfor fine-tuning framework and study the representation similarity between\nfrozen and fine-tuned networks using Centered Kernel Alignment. Further, to\nexamine if intermediate block representation is better suited for feature\nextraction and ImageNet architectures are unnecessarily large for\nhistopathology, we truncate the blocks of ResNet18 and DenseNet121 and examine\nthe performance.",
    "descriptor": "\nComments: Accepted at IEEE International Conference on Biomedical and Health Informatics (BHI'21). arXiv admin note: text overlap with arXiv:2103.10626\n",
    "authors": [
      "Yash Sharma",
      "Lubaina Ehsan",
      "Sana Syed",
      "Donald E. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07068"
  },
  {
    "id": "arXiv:2106.07069",
    "title": "A finite element model for a coupled thermo-mechanical system: nonlinear  strain-limiting thermoelastic body",
    "abstract": "We investigate a specific finite element model to study the thermoelastic\nbehavior of an elastic body within the context of nonlinear strain-limiting\nconstitutive relation. As a special subclass of implicit relations, the\nthermoelastic response of our interest is such that stresses can be arbitrarily\nlarge, but strains remain small, especially in the neighborhood of crack-tips.\nThus, the proposed model can be inherently consistent with the assumption of\nthe small strain theory. In the present communication, we consider a\ntwo-dimensional coupled system-linear and quasilinear partial differential\nequations for temperature and displacements, respectively. Two distinct\ntemperature distributions of the Dirichlet type are considered for boundary\ncondition, and a standard finite element method of continuous Galerkin is\nemployed to obtain the numerical solutions for the field variables. For a\ndomain with an edge-crack, we find that the near-tip strain growth of our model\nis much slower than the growth of stress, which is the salient feature compared\nto the inconsistent results of the classical linearized description of the\nelastic body. Current study can provide a theoretical and computational\nframework to develop physically meaningful models and examine other coupled\nmulti-physics such as an evolution of complex network of cracks induced by\nthermal shocks.",
    "descriptor": "",
    "authors": [
      "Hyun C. Yoon",
      "Karthik K. Vasudeva",
      "S. M. Mallikarjunaiah"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07069"
  },
  {
    "id": "arXiv:2106.07074",
    "title": "RadArnomaly: Protecting Radar Systems from Data Manipulation Attacks",
    "abstract": "Radar systems are mainly used for tracking aircraft, missiles, satellites,\nand watercraft. In many cases, information regarding the objects detected by\nthe radar system is sent to, and used by, a peripheral consuming system, such\nas a missile system or a graphical user interface used by an operator. Those\nsystems process the data stream and make real-time, operational decisions based\non the data received. Given this, the reliability and availability of\ninformation provided by radar systems has grown in importance. Although the\nfield of cyber security has been continuously evolving, no prior research has\nfocused on anomaly detection in radar systems. In this paper, we present a deep\nlearning-based method for detecting anomalies in radar system data streams. We\npropose a novel technique which learns the correlation between numerical\nfeatures and an embedding representation of categorical features in an\nunsupervised manner. The proposed technique, which allows the detection of\nmalicious manipulation of critical fields in the data stream, is complemented\nby a timing-interval anomaly detection mechanism proposed for the detection of\nmessage dropping attempts. Real radar system data is used to evaluate the\nproposed method. Our experiments demonstrate the method's high detection\naccuracy on a variety of data stream manipulation attacks (average detection\nrate of 88% with 1.59% false alarms) and message dropping attacks (average\ndetection rate of 92% with 2.2% false alarms).",
    "descriptor": "",
    "authors": [
      "Shai Cohen",
      "Efrat Levy",
      "Avi Shaked",
      "Tair Cohen",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07074"
  },
  {
    "id": "arXiv:2106.07075",
    "title": "A baseline for semi-supervised learning of efficient semantic  segmentation models",
    "abstract": "Semi-supervised learning is especially interesting in the dense prediction\ncontext due to high cost of pixel-level ground truth. Unfortunately, most such\napproaches are evaluated on outdated architectures which hamper research due to\nvery slow training and high requirements on GPU RAM. We address this concern by\npresenting a simple and effective baseline which works very well both on\nstandard and efficient architectures. Our baseline is based on one-way\nconsistency and non-linear geometric and photometric perturbations. We show\nadvantage of perturbing only the student branch and present a plausible\nexplanation of such behaviour. Experiments on Cityscapes and CIFAR-10\ndemonstrate competitive performance with respect to prior work.",
    "descriptor": "",
    "authors": [
      "Ivan Grubi\u0161i\u0107",
      "Marin Or\u0161i\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07075"
  },
  {
    "id": "arXiv:2106.07080",
    "title": "Semi-verified Learning from the Crowd with Pairwise Comparisons",
    "abstract": "We study the problem of {\\em crowdsourced PAC learning} of Boolean-valued\nfunctions through enriched queries, a problem that has attracted a surge of\nrecent research interests. In particular, we consider that the learner may\nquery the crowd to obtain a label of a given instance or a comparison tag of a\npair of instances. This is a challenging problem and only recently have\nbudget-efficient algorithms been established for the scenario where the\nmajority of the crowd are correct. In this work, we investigate the\nsignificantly more challenging case that the majority are incorrect which\nrenders learning impossible in general. We show that under the {semi-verified\nmodel} of Charikar~et~al.~(2017), where we have (limited) access to a trusted\noracle who always returns the correct annotation, it is possible to learn the\nunderlying function while the labeling cost is significantly mitigated by the\nenriched and more easily obtained queries.",
    "descriptor": "",
    "authors": [
      "Shiwei Zeng",
      "Jie Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07080"
  },
  {
    "id": "arXiv:2106.07084",
    "title": "Security Analysis of the Silver Bullet Technique for RowHammer  Prevention",
    "abstract": "The purpose of this document is to study the security properties of the\nSilver Bullet algorithm against worst-case RowHammer attacks. We mathematically\ndemonstrate that Silver Bullet, when properly configured and implemented in a\nDRAM chip, can securely prevent RowHammer attacks. The demonstration focuses on\nthe most representative implementation of Silver Bullet, the patent claiming\nmany implementation possibilities not covered in this demonstration. Our study\nconcludes that Silver Bullet is a promising RowHammer prevention mechanism that\ncan be configured to operate securely against RowHammer attacks at various\nefficiency-area tradeoff points, supporting relatively small hammer count\nvalues (e.g., 1000) and Silver Bullet table sizes (e.g., 1.06KB).",
    "descriptor": "\nComments: 40 pages\n",
    "authors": [
      "Abdullah Giray Ya\u011fl\u0131k\u00e7\u0131",
      "Jeremie S. Kim",
      "Fabrice Devaux",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.07084"
  },
  {
    "id": "arXiv:2106.07085",
    "title": "Survey: Image Mixing and Deleting for Data Augmentation",
    "abstract": "Data augmentation has been widely used to improve deep nerual networks\nperformance. Numerous approaches are suggested, for example, dropout,\nregularization and image augmentation, to avoid over-ftting and enhancing\ngeneralization of neural networks. One of the sub-area within data augmentation\nis image mixing and deleting. This specific type of augmentation either mixes\ntwo images or delete image regions to hide or make certain characteristics of\nimages confusing for the network to force it to emphasize on overall structure\nof object in image. The model trained with this approach has shown to perform\nand generalize well as compared to one trained without imgage mixing or\ndeleting. Additional benefit achieved with this method of training is\nrobustness against image corruptions. Due to its low compute cost and success\nin recent past, many techniques of image mixing and deleting are proposed. This\npaper provides detailed review on these devised approaches, dividing\naugmentation strategies in three main categories cut and delete, cut and mix\nand mixup. The second part of paper emprically evaluates these approaches for\nimage classification, finegrained image recognition and object detection where\nit is shown that this category of data augmentation improves the overall\nperformance for deep neural networks.",
    "descriptor": "",
    "authors": [
      "Humza Naveed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07085"
  },
  {
    "id": "arXiv:2106.07087",
    "title": "Koios: A Deep Learning Benchmark Suite for FPGA Architecture and CAD  Research",
    "abstract": "With the prevalence of deep learning (DL) in many applications, researchers\nare investigating different ways of optimizing FPGA architecture and CAD to\nachieve better quality-of-results (QoR) on DL-based workloads. In this\noptimization process, benchmark circuits are an essential component; the QoR\nachieved on a set of benchmarks is the main driver for architecture and CAD\ndesign choices. However, current academic benchmark suites are inadequate, as\nthey do not capture any designs from the DL domain. This work presents a new\nsuite of DL acceleration benchmark circuits for FPGA architecture and CAD\nresearch, called Koios. This suite of 19 circuits covers a wide variety of\naccelerated neural networks, design sizes, implementation styles, abstraction\nlevels, and numerical precisions. These designs are larger, more data parallel,\nmore heterogeneous, more deeply pipelined, and utilize more FPGA architectural\nfeatures compared to existing open-source benchmarks. This enables researchers\nto pin-point architectural inefficiencies for this class of workloads and\noptimize CAD tools on more realistic benchmarks that stress the CAD algorithms\nin different ways. In this paper, we describe the designs in our benchmark\nsuite, present results of running them through the Verilog-to-Routing (VTR)\nflow using a recent FPGA architecture model, and identify key insights from the\nresulting metrics. On average, our benchmarks have 3.7x more netlist\nprimitives, 1.8x and 4.7x higher DSP and BRAM densities, and 1.7x higher\nfrequency with 1.9x more near-critical paths compared to the widely-used VTR\nsuite. Finally, we present two example case studies showing how architectural\nexploration for DL-optimized FPGAs can be performed using our new benchmark\nsuite.",
    "descriptor": "",
    "authors": [
      "Aman Arora",
      "Andrew Boutros",
      "Daniel Rauch",
      "Aishwarya Rajen",
      "Aatman Borda",
      "Seyed Alireza Damghani",
      "Samidh Mehta",
      "Sangram Kate",
      "Pragnesh Patel",
      "Kenneth B. Kent",
      "Vaughn Betz",
      "Lizy K. John"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.07087"
  },
  {
    "id": "arXiv:2106.07088",
    "title": "A new soft computing method for integration of expert's knowledge in  reinforcement learn-ing problems",
    "abstract": "This paper proposes a novel fuzzy action selection method to leverage human\nknowledge in reinforcement learning problems. Based on the estimates of the\nmost current action-state values, the proposed fuzzy nonlinear mapping as-signs\neach member of the action set to its probability of being chosen in the next\nstep. A user tunable parameter is introduced to control the action selection\npolicy, which determines the agent's greedy behavior throughout the learning\nprocess. This parameter resembles the role of the temperature parameter in the\nsoftmax action selection policy, but its tuning process can be more\nknowledge-oriented since this parameter reflects the human knowledge into the\nlearning agent by making modifications in the fuzzy rule base. Simulation\nresults indicate that including fuzzy logic within the reinforcement learning\nin the proposed manner improves the learning algorithm's convergence rate, and\nprovides superior performance.",
    "descriptor": "",
    "authors": [
      "Mohsen Annabestani",
      "Ali Abedi",
      "Mohammad Reza Nematollahi",
      "Mohammad Bagher Naghibi Sis-tani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.07088"
  },
  {
    "id": "arXiv:2106.07091",
    "title": "On-Off Center-Surround Receptive Fields for Accurate and Robust Image  Classification",
    "abstract": "Robustness to variations in lighting conditions is a key objective for any\ndeep vision system. To this end, our paper extends the receptive field of\nconvolutional neural networks with two residual components, ubiquitous in the\nvisual processing system of vertebrates: On-center and off-center pathways,\nwith excitatory center and inhibitory surround; OOCS for short. The on-center\npathway is excited by the presence of a light stimulus in its center but not in\nits surround, whereas the off-center one is excited by the absence of a light\nstimulus in its center but not in its surround. We design OOCS pathways via a\ndifference of Gaussians, with their variance computed analytically from the\nsize of the receptive fields. OOCS pathways complement each other in their\nresponse to light stimuli, ensuring this way a strong edge-detection\ncapability, and as a result, an accurate and robust inference under challenging\nlighting conditions. We provide extensive empirical evidence showing that\nnetworks supplied with the OOCS edge representation gain accuracy and\nillumination-robustness compared to standard deep models.",
    "descriptor": "\nComments: 21 Pages. Accepted for publication in the proceedings of the 38th International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Zahra Babaiee",
      "Ramin Hasani",
      "Mathias Lechner",
      "Daniela Rus",
      "Radu Grosu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.07091"
  },
  {
    "id": "arXiv:2106.07094",
    "title": "DP-NormFedAvg: Normalizing Client Updates for Privacy-Preserving  Federated Learning",
    "abstract": "In this paper, we focus on facilitating differentially private quantized\ncommunication between the clients and server in federated learning (FL).\nTowards this end, we propose to have the clients send a \\textit{private\nquantized} version of only the \\textit{unit vector} along the change in their\nlocal parameters to the server, \\textit{completely throwing away the magnitude\ninformation}. We call this algorithm \\texttt{DP-NormFedAvg} and show that it\nhas the same order-wise convergence rate as \\texttt{FedAvg} on smooth\nquasar-convex functions (an important class of non-convex functions for\nmodeling optimization of deep neural networks), thereby establishing that\ndiscarding the magnitude information is not detrimental from an optimization\npoint of view. We also introduce QTDL, a new differentially private\nquantization mechanism for unit-norm vectors, which we use in\n\\texttt{DP-NormFedAvg}. QTDL employs \\textit{discrete} noise having a\nLaplacian-like distribution on a \\textit{finite support} to provide privacy. We\nshow that under a growth-condition assumption on the per-sample client losses,\nthe extra per-coordinate communication cost in each round incurred due to\nprivacy by our method is $\\mathcal{O}(1)$ with respect to the model dimension,\nwhich is an improvement over prior work. Finally, we show the efficacy of our\nproposed method with experiments on fully-connected neural networks trained on\nCIFAR-10 and Fashion-MNIST.",
    "descriptor": "",
    "authors": [
      "Rudrajit Das",
      "Abolfazl Hashemi",
      "Sujay Sanghavi",
      "Inderjit S. Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07094"
  },
  {
    "id": "arXiv:2106.07095",
    "title": "Linear representation of categorical values",
    "abstract": "We propose a binary representation of categorical values using a linear map.\nThis linear representation preserves the neighborhood structure of categorical\nvalues. In the context of evolutionary algorithms, it means that every\ncategorical value can be reached in a single mutation. The linear\nrepresentation is embedded into standard metaheuristics, applied to the problem\nof Sudoku puzzles, and compared to the more traditional direct binary encoding.\nIt shows promising results in fixed-budget experiments and empirical cumulative\ndistribution functions with high dimension instances, and also in fixed-target\nexperiments with small dimension instances.",
    "descriptor": "\nComments: An extended two-page abstract of this work will appear in 2021 Genetic and Evolutionary Computation Conference Companion (GECCO '21 Companion)\n",
    "authors": [
      "Arnaud Berny"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.07095"
  },
  {
    "id": "arXiv:2106.07098",
    "title": "Security Analysis of Camera-LiDAR Semantic-Level Fusion Against  Black-Box Attacks on Autonomous Vehicles",
    "abstract": "To enable safe and reliable decision-making, autonomous vehicles (AVs) feed\nsensor data to perception algorithms to understand the environment. Sensor\nfusion, and particularly semantic fusion, with multi-frame tracking is becoming\nincreasingly popular for detecting 3D objects. Recently, it was shown that\nLiDAR-based perception built on deep neural networks is vulnerable to LiDAR\nspoofing attacks. Thus, in this work, we perform the first analysis of\ncamera-LiDAR fusion under spoofing attacks and the first security analysis of\nsemantic fusion in any AV context. We find first that fusion is more successful\nthan existing defenses at guarding against naive spoofing. However, we then\ndefine the frustum attack as a new class of attacks on AVs and find that\nsemantic camera-LiDAR fusion exhibits widespread vulnerability to frustum\nattacks with between 70% and 90% success against target models. Importantly,\nthe attacker needs less than 20 random spoof points on average for successful\nattacks - an order of magnitude less than established maximum capability.\nFinally, we are the first to analyze the longitudinal impact of perception\nattacks by showing the impact of multi-frame attacks.",
    "descriptor": "",
    "authors": [
      "R. Spencer Hallyburton",
      "Yupei Liu",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07098"
  },
  {
    "id": "arXiv:2106.07100",
    "title": "The Impact of Irrational Behaviours in the Optional Prisoner's Dilemma  with Game-Environment Feedback",
    "abstract": "In the optional prisoner's dilemma (OPD), players can choose to cooperate and\ndefect as usual, but can also abstain as a third possible strategy. This\nstrategy models the players' participation in the game and is a relevant aspect\nin many settings, e.g. social networks or opinion dynamics where abstention is\nan option during an election. In this paper, we provide a formulation of the\nOPD where we consider irrational behaviours in the population inspired by\nprospect theory. Prospect theory has gained increasing popularity in recent\ntimes thanks to its ability to capture aspects such as reference dependence or\nloss aversion which are common in human behaviour. This element is original in\nour formulation of the game and is incorporated in our framework through\npairwise comparison dynamics. Recently, the impact of the environment has been\nstudied in the form of feedback on the population dynamics. Another element of\nnovelty in our work is the extension of the game-environment feedback to the\nOPD in two forms of dynamics, the replicator and the pairwise comparison. The\ncontribution of this paper is threefold. First, we propose a modelling\nframework where prospect theory is used to capture irrational behaviours in an\nevolutionary game with game-environment feedback. Second, we carry out the\nstability analysis of the system equilibria and discuss the oscillating\nbehaviours arising from the game-environment feedback. Finally, we extend our\nprevious results to the OPD and we discuss the main differences between the\nmodel resulting from the replicator dynamics and the one resulting from the\npairwise comparison dynamics.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Leonardo Stella",
      "Dario Bauso"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.07100"
  },
  {
    "id": "arXiv:2106.07102",
    "title": "Farview: Disaggregated Memory with Operator Off-loading for Database  Engines",
    "abstract": "Cloud deployments disaggregate storage from compute, providing more\nflexibility to both the storage and compute layers. In this paper, we explore\ndisaggregation by taking it one step further and applying it to memory (DRAM).\nDisaggregated memory uses network attached DRAM as a way to decouple memory\nfrom CPU. In the context of databases, such a design offers significant\nadvantages in terms of making a larger memory capacity available as a central\npool to a collection of smaller processing nodes. To explore these\npossibilities, we have implemented Farview, a disaggregated memory solution for\ndatabases, operating as a remote buffer cache with operator offloading\ncapabilities. Farview is implemented as an FPGA-based smart NIC making DRAM\navailable as a disaggregated, network attached memory module capable of\nperforming data processing at line rate over data streams to/from disaggregated\nmemory. Farview supports query offloading using operators such as selection,\nprojection, aggregation, regular expression matching and encryption. In this\npaper we focus on analytical queries and demonstrate the viability of the idea\nthrough an extensive experimental evaluation of Farview under different\nworkloads. Farview is competitive with a local buffer cache solution for all\nthe workloads and outperforms it in a number of cases, proving that a smart\ndisaggregated memory can be a viable alternative for databases deployed in\ncloud environments.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Dario Korolija",
      "Dimitrios Koutsoukos",
      "Kimberly Keeton",
      "Konstantin Taranov",
      "Dejan Miloji\u010di\u0107",
      "Gustavo Alonso"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.07102"
  },
  {
    "id": "arXiv:2106.07105",
    "title": "SRAM-SUC: Ultra-Low Latency Robust Digital PUF",
    "abstract": "Secret Unknown Ciphers (SUC) have been proposed recently as digital\nclone-resistant functions overcoming some of Physical(ly) Unclonable Functions\n(PUF) downsides, mainly their inconsistency because of PUFs analog nature. In\nthis paper, we propose a new practical mechanism for creating internally random\nciphers in modern volatile and non-volatile SoC FPGAs, coined as SRAM-SUC. Each\ncreated random cipher inside a SoC FPGA constitutes a robust digital PUF. This\nwork also presents a class of involutive SUCs, optimized for the targeted SoC\nFPGA architecture, as sample realization of the concept; it deploys a generated\nclass of involutive 8-bit S-Boxes, that are selected randomly from a defined\nlarge set through an internal process inside the SoC FPGA. Hardware and\nsoftware implementations show that the resulting SRAM-SUC has ultra-low latency\ncompared to well-known PUF-based authentication mechanisms. SRAM-SUC requires\nonly $2.88/0.72 \\mu s$ to generate a response for a challenge at 50/200 MHz\nrespectively. This makes SRAM-SUC a promising and appealing solution for\nUltra-Reliable Low Latency Communication (URLLC).",
    "descriptor": "\nComments: 13 pages, 15 figures, 6 tables\n",
    "authors": [
      "Ayoub Mars",
      "Hussam Ghandour",
      "Wael Adi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.07105"
  },
  {
    "id": "arXiv:2106.07106",
    "title": "Graph Optimal Transport with Transition Couplings of Random Walks",
    "abstract": "We present a novel approach to optimal transport between graphs from the\nperspective of stationary Markov chains. A weighted graph may be associated\nwith a stationary Markov chain by means of a random walk on the vertex set with\ntransition distributions depending on the edge weights of the graph. After\ndrawing this connection, we describe how optimal transport techniques for\nstationary Markov chains may be used in order to perform comparison and\nalignment of the graphs under study. In particular, we propose the graph\noptimal transition coupling problem, referred to as GraphOTC, in which the\nMarkov chains associated to two given graphs are optimally synchronized to\nminimize an expected cost. The joint synchronized chain yields an alignment of\nthe vertices and edges in the two graphs, and the expected cost of the\nsynchronized chain acts as a measure of distance or dissimilarity between the\ntwo graphs. We demonstrate that GraphOTC performs equal to or better than\nexisting state-of-the-art techniques in graph optimal transport for several\ntasks and datasets. Finally, we also describe a generalization of the GraphOTC\nproblem, called the FusedOTC problem, from which we recover the GraphOTC and OT\ncosts as special cases.",
    "descriptor": "",
    "authors": [
      "Kevin O'Connor",
      "Bongsoo Yi",
      "Kevin McGoff",
      "Andrew B. Nobel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07106"
  },
  {
    "id": "arXiv:2106.07108",
    "title": "Pointwise Feasibility of Gaussian Process-based Safety-Critical Control  under Model Uncertainty",
    "abstract": "Control Barrier Functions (CBFs) and Control Lyapunov Functions (CLFs) are\npopular tools for enforcing safety and stability of a controlled system,\nrespectively. They are commonly utilized to build constraints that can be\nincorporated in a min-norm quadratic program (CBF-CLF-QP) which solves for a\nsafety-critical control input. However, since these constraints rely on a model\nof the system, when this model is inaccurate the guarantees of safety and\nstability can be easily lost. In this paper, we present a Gaussian Process\n(GP)-based approach to tackle the problem of model uncertainty in\nsafety-critical controllers that use CBFs and CLFs. The considered model\nuncertainty is affected by both state and control input. We derive\nprobabilistic bounds on the effects that such model uncertainty has on the\ndynamics of the CBF and CLF. Then, we use these bounds to build safety and\nstability chance constraints that can be incorporated in a min-norm convex\noptimization program, called GP-CBF-CLF-SOCP. As the main theoretical result of\nthe paper, we present necessary and sufficient conditions for pointwise\nfeasibility of the proposed optimization problem. We believe that these\nconditions could serve as a starting point towards understanding what are the\nminimal requirements on the distribution of data collected from the real system\nin order to guarantee safety. Finally, we validate the proposed framework with\nnumerical simulations of an adaptive cruise controller for an automotive\nsystem.",
    "descriptor": "\nComments: The first two authors contributed equally\n",
    "authors": [
      "Fernando Casta\u00f1eda",
      "Jason J. Choi",
      "Bike Zhang",
      "Claire J. Tomlin",
      "Koushil Sreenath"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07108"
  },
  {
    "id": "arXiv:2106.07111",
    "title": "A Computational Information Criterion for Particle-Tracking with Sparse  or Noisy Data",
    "abstract": "Traditional probabilistic methods for the simulation of advection-diffusion\nequations (ADEs) often overlook the entropic contribution of the\ndiscretization, e.g., the number of particles, within associated numerical\nmethods. Many times, the gain in accuracy of a highly discretized numerical\nmodel is outweighed by its associated computational costs or the noise within\nthe data. We address the question of how many particles are needed in a\nsimulation to best approximate and estimate parameters in one-dimensional\nadvective-diffusive transport. To do so, we use the well-known Akaike\nInformation Criterion (AIC) and a recently-developed correction called the\nComputational Information Criterion (COMIC) to guide the model selection\nprocess. Random-walk and mass-transfer particle tracking methods are employed\nto solve the model equations at various levels of discretization. Numerical\nresults demonstrate that the COMIC provides an optimal number of particles that\ncan describe a more efficient model in terms of parameter estimation and model\nprediction compared to the model selected by the AIC even when the data is\nsparse or noisy, the sampling volume is not uniform throughout the physical\ndomain, or the error distribution of the data is non-IID Gaussian.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Nhat Thanh Tran",
      "David A. Benson",
      "Michael J. Schmidt",
      "Stephen D. Pankavich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.07111"
  },
  {
    "id": "arXiv:2106.07112",
    "title": "Bias: Friend or Foe? User Acceptance of Gender Stereotypes in Automated  Career Recommendations",
    "abstract": "Currently, there is a surge of interest in fair Artificial Intelligence (AI)\nand Machine Learning (ML) research which aims to mitigate discriminatory bias\nin AI algorithms, e.g. along lines of gender, age, and race. While most\nresearch in this domain focuses on developing fair AI algorithms, in this work,\nwe show that a fair AI algorithm on its own may be insufficient to achieve its\nintended results in the real world. Using career recommendation as a case\nstudy, we build a fair AI career recommender by employing gender debiasing\nmachine learning techniques. Our offline evaluation showed that the debiased\nrecommender makes fairer career recommendations without sacrificing its\naccuracy. Nevertheless, an online user study of more than 200 college students\nrevealed that participants on average prefer the original biased system over\nthe debiased system. Specifically, we found that perceived gender disparity is\na determining factor for the acceptance of a recommendation. In other words,\nour results demonstrate we cannot fully address the gender bias issue in AI\nrecommendations without addressing the gender bias in humans.",
    "descriptor": "",
    "authors": [
      "Clarice Wang",
      "Kathryn Wang",
      "Andrew Bian",
      "Rashidul Islam",
      "Kamrun Naher Keya",
      "James Foulde",
      "Shimei Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07112"
  },
  {
    "id": "arXiv:2106.07113",
    "title": "Reducing Effects of Swath Gaps on Unsupervised Machine Learning Models  for NASA MODIS Instruments",
    "abstract": "Due to the nature of their pathways, NASA Terra and NASA Aqua satellites\ncapture imagery containing swath gaps, which are areas of no data. Swath gaps\ncan overlap the region of interest (ROI) completely, often rendering the entire\nimagery unusable by Machine Learning (ML) models. This problem is further\nexacerbated when the ROI rarely occurs (e.g. a hurricane) and, on occurrence,\nis partially overlapped with a swath gap. With annotated data as supervision, a\nmodel can learn to differentiate between the area of focus and the swath gap.\nHowever, annotation is expensive and currently the vast majority of existing\ndata is unannotated. Hence, we propose an augmentation technique that\nconsiderably removes the existence of swath gaps in order to allow CNNs to\nfocus on the ROI, and thus successfully use data with swath gaps for training.\nWe experiment on the UC Merced Land Use Dataset, where we add swath gaps\nthrough empty polygons (up to 20 percent areas) and then apply augmentation\ntechniques to fill the swath gaps. We compare the model trained with our\naugmentation techniques on the swath gap-filled data with the model trained on\nthe original swath gap-less data and note highly augmented performance.\nAdditionally, we perform a qualitative analysis using activation maps that\nvisualizes the effectiveness of our trained network in not paying attention to\nthe swath gaps. We also evaluate our results with a human baseline and show\nthat, in certain cases, the filled swath gaps look so realistic that even a\nhuman evaluator did not distinguish between original satellite images and swath\ngap-filled images. Since this method is aimed at unlabeled data, it is widely\ngeneralizable and impactful for large scale unannotated datasets from various\nspace data domains.",
    "descriptor": "",
    "authors": [
      "Sarah Chen",
      "Esther Cao",
      "Anirudh Koul",
      "Siddha Ganju",
      "Satyarth Praveen",
      "Meher Anand Kasam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07113"
  },
  {
    "id": "arXiv:2106.07114",
    "title": "Intelligent Agent for Hurricane Emergency Identification and Text  Information Extraction from Streaming Social Media Big Data",
    "abstract": "This paper presents our research on leveraging social media Big Data and AI\nto support hurricane disaster emergency response. The current practice of\nhurricane emergency response for rescue highly relies on emergency call\ncentres. The more recent Hurricane Harvey event reveals the limitations of the\ncurrent systems. We use Hurricane Harvey and the associated Houston flooding as\nthe motivating scenario to conduct research and develop a prototype as a\nproof-of-concept of using an intelligent agent as a complementary role to\nsupport emergency centres in hurricane emergency response. This intelligent\nagent is used to collect real-time streaming tweets during a natural disaster\nevent, to identify tweets requesting rescue, to extract key information such as\naddress and associated geocode, and to visualize the extracted information in\nan interactive map in decision supports. Our experiment shows promising\noutcomes and the potential application of the research in support of hurricane\nemergency response.",
    "descriptor": "\nComments: 16 pages, 3 figures, and 1 table\n",
    "authors": [
      "Jingwei Huang",
      "Wael Khallouli",
      "Ghaith Rabadi",
      "Mamadou Seck"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07114"
  },
  {
    "id": "arXiv:2106.07115",
    "title": "Latent Correlation-Based Multiview Learning and Self-Supervision: A  Unifying Perspective",
    "abstract": "Multiple views of data, both naturally acquired (e.g., image and audio) and\nartificially produced (e.g., via adding different noise to data samples), have\nproven useful in enhancing representation learning. Natural views are often\nhandled by multiview analysis tools, e.g., (deep) canonical correlation\nanalysis [(D)CCA], while the artificial ones are frequently used in\nself-supervised learning (SSL) paradigms, e.g., \\texttt{SimCLR} and\n\\texttt{Barlow Twins}. Both types of approaches often involve learning neural\nfeature extractors such that the embeddings of data exhibit high cross-view\ncorrelations. Although intuitive, the effectiveness of correlation-based neural\nembedding is only empirically validated. This work puts forth a theory-backed\nframework for unsupervised multiview learning. Our development starts with\nproposing a multiview model, where each view is a nonlinear mixture of shared\nand private components. Consequently, the learning problem boils down to\nshared/private component identification and disentanglement. Under this model,\nlatent correlation maximization is shown to guarantee the extraction of the\nshared components across views (up to certain ambiguities). In addition, the\nprivate information in each view can be provably disentangled from the shared\nusing proper regularization design. The method is tested on a series of tasks,\ne.g., downstream clustering, which all show promising performance. Our\ndevelopment also provides a unifying perspective for understanding various DCCA\nand SSL schemes.",
    "descriptor": "",
    "authors": [
      "Qi Lyu",
      "Xiao Fu",
      "Weiran Wang",
      "Songtao Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07115"
  },
  {
    "id": "arXiv:2106.07116",
    "title": "The Power of Randomization: Efficient and Effective Algorithms for  Constrained Submodular Maximization",
    "abstract": "Submodular optimization has numerous applications such as crowdsourcing and\nviral marketing. In this paper, we study the fundamental problem of\nnon-negative submodular function maximization subject to a $k$-system\nconstraint, which generalizes many other important constraints in submodular\noptimization such as cardinality constraint, matroid constraint, and\n$k$-extendible system constraint. The existing approaches for this problem\nachieve the best-known approximation ratio of $k+2\\sqrt{k+2}+3$ (for a general\nsubmodular function) based on deterministic algorithmic frameworks. We propose\nseveral randomized algorithms that improve upon the state-of-the-art algorithms\nin terms of approximation ratio and time complexity, both under the\nnon-adaptive setting and the adaptive setting. The empirical performance of our\nalgorithms is extensively evaluated in several applications related to data\nmining and social computing, and the experimental results demonstrate the\nsuperiorities of our algorithms in terms of both utility and efficiency.",
    "descriptor": "\nComments: Part of the contribution appears in ICML2021\n",
    "authors": [
      "Kai Han",
      "Shuang Cui",
      "Tianshuai Zhu",
      "Jing Tang",
      "Benwei Wu",
      "He Huang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07116"
  },
  {
    "id": "arXiv:2106.07117",
    "title": "Toward Diverse Precondition Generation",
    "abstract": "Language understanding must identify the logical connections between events\nin a discourse, but core events are often unstated due to their commonsense\nnature. This paper fills in these missing events by generating precondition\nevents. Precondition generation can be framed as a sequence-to-sequence\nproblem: given a target event, generate a possible precondition. However, in\nmost real-world scenarios, an event can have several preconditions, requiring\ndiverse generation -- a challenge for standard seq2seq approaches. We propose\nDiP, a Diverse Precondition generation system that can generate unique and\ndiverse preconditions. DiP uses a generative process with three components --\nan event sampler, a candidate generator, and a post-processor. The event\nsampler provides control codes (precondition triggers) which the candidate\ngenerator uses to focus its generation. Unlike other conditional generation\nsystems, DiP automatically generates control codes without training on diverse\nexamples. Analysis against baselines reveals that DiP improves the diversity of\npreconditions significantly while also generating more preconditions.",
    "descriptor": "",
    "authors": [
      "Heeyoung Kwon",
      "Nathanael Chambers",
      "Niranjan Balasubramanian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07117"
  },
  {
    "id": "arXiv:2106.07124",
    "title": "Self-orthogonal codes over a non-unital ring and combinatorial matrices",
    "abstract": "There is a local ring $E$ of order $4,$ without identity for the\nmultiplication, defined by generators and relations as $E=\\langle a,b \\mid\n2a=2b=0,\\, a^2=a,\\, b^2=b,\\,ab=a,\\, ba=b\\rangle.$\nWe study a special construction of self-orthogonal codes over $E,$ based on\ncombinatorial matrices related to two-class association schemes, Strongly\nRegular Graphs (SRG), and Doubly Regular Tournaments (DRT).\nWe construct quasi self-dual codes over $E,$ and Type IV codes, that is,\nquasi self-dual codes whose all codewords have even Hamming weight. All these\ncodes can be represented as formally self-dual additive codes over $\\F_4.$ The\nclassical invariant theory bound for the weight enumerators of this class of\ncodesimproves the known bound on the minimum distance of Type IV codes over\n$E.$",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Minjia Shi",
      "Shukai Wang",
      "Jon-Lark Kim",
      "Patrick Sol\u00e9"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.07124"
  },
  {
    "id": "arXiv:2106.07125",
    "title": "Variational Policy Search using Sparse Gaussian Process Priors for  Learning Multimodal Optimal Actions",
    "abstract": "Policy search reinforcement learning has been drawing much attention as a\nmethod of learning a robot control policy. In particular, policy search using\nsuch non-parametric policies as Gaussian process regression can learn optimal\nactions with high-dimensional and redundant sensors as input. However, previous\nmethods implicitly assume that the optimal action becomes unique for each\nstate. This assumption can severely limit such practical applications as robot\nmanipulations since designing a reward function that appears in only one\noptimal action for complex tasks is difficult. The previous methods might have\ncaused critical performance deterioration because the typical non-parametric\npolicies cannot capture the optimal actions due to their unimodality. We\npropose novel approaches in non-parametric policy searches with multiple\noptimal actions and offer two different algorithms commonly based on a sparse\nGaussian process prior and variational Bayesian inference. The following are\nthe key ideas: 1) multimodality for capturing multiple optimal actions and 2)\nmode-seeking for capturing one optimal action by ignoring the others. First, we\npropose a multimodal sparse Gaussian process policy search that uses multiple\noverlapped GPs as a prior. Second, we propose a mode-seeking sparse Gaussian\nprocess policy search that uses the student-t distribution for a likelihood\nfunction. The effectiveness of those algorithms is demonstrated through\napplications to object manipulation tasks with multiple optimal actions in\nsimulations.",
    "descriptor": "\nComments: Accepted by Neural Networks\n",
    "authors": [
      "Hikaru Sasaki",
      "Takamitsu Matsubara"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.07125"
  },
  {
    "id": "arXiv:2106.07127",
    "title": "Transition Motion Planning for Multi-Limbed Vertical Climbing Robots  Using Complementarity Constraints",
    "abstract": "In order to achieve autonomous vertical wall climbing, the transition phase\nfrom the ground to the wall requires extra consideration inevitably. This paper\nfocuses on the contact sequence planner to transition between flat terrain and\nvertical surfaces for multi-limbed climbing robots. To overcome the transition\nphase, it requires planning both multi-contact and contact wrenches\nsimultaneously which makes it difficult. Instead of using a predetermined\ncontact sequence, we consider various motions on different environment setups\nvia modeling contact constraints and limb switchability as complementarity\nconditions. Two safety factors for toe sliding and motor over-torque are the\nmain tuning parameters for different contact sequences. By solving as a\nnonlinear program (NLP), we can generate several feasible sequences of foot\nplacements and contact forces to avoid failure cases. We verified feasibility\nwith demonstrations on the hardware SiLVIA, a six-legged robot capable of\nvertically climbing between two walls by bracing itself in-between using only\nfriction.",
    "descriptor": "\nComments: ICRA 2021 Accepted. Optimization, Climbing motion planning, Complementarity Constraints\n",
    "authors": [
      "Jingwen Zhang",
      "Xuan Lin",
      "Dennis W Hong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.07127"
  },
  {
    "id": "arXiv:2106.07131",
    "title": "GPT3-to-plan: Extracting plans from text using GPT-3",
    "abstract": "Operations in many essential industries including finance and banking are\noften characterized by the need to perform repetitive sequential tasks. Despite\ntheir criticality to the business, workflows are rarely fully automated or even\nformally specified, though there may exist a number of natural language\ndocuments describing these procedures for the employees of the company. Plan\nextraction methods provide us with the possibility of extracting structure\nplans from such natural language descriptions of the plans/workflows, which\ncould then be leveraged by an automated system. In this paper, we investigate\nthe utility of generalized language models in performing such extractions\ndirectly from such texts. Such models have already been shown to be quite\neffective in multiple translation tasks, and our initial results seem to point\nto their effectiveness also in the context of plan extractions. Particularly,\nwe show that GPT-3 is able to generate plan extraction results that are\ncomparable to many of the current state of the art plan extraction methods.",
    "descriptor": "",
    "authors": [
      "Alberto Olmo",
      "Sarath Sreedharan",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07131"
  },
  {
    "id": "arXiv:2106.07134",
    "title": "Discerning the painter's hand: machine learning on surface topography",
    "abstract": "Attribution of paintings is a critical problem in art history. This study\nextends machine learning analysis to surface topography of painted works. A\ncontrolled study of positive attribution was designed with paintings produced\nby a class of art students. The paintings were scanned using a confocal optical\nprofilometer to produce surface data. The surface data were divided into\nvirtual patches and used to train an ensemble of convolutional neural networks\n(CNNs) for attribution. Over a range of patch sizes from 0.5 to 60 mm, the\nresulting attribution was found to be 60 to 96% accurate, and, when comparing\nregions of different color, was nearly twice as accurate as CNNs using color\nimages of the paintings. Remarkably, short length scales, as small as twice a\nbristle diameter, were the key to reliably distinguishing among artists. These\nresults show promise for real-world attribution, particularly in the case of\nworkshop practice.",
    "descriptor": "\nComments: main text: 24 pages, 6 figures; SI: 6 pages, 4 figures\n",
    "authors": [
      "F. Ji",
      "M. S. McMaster",
      "S. Schwab",
      "G. Singh",
      "L. N. Smith",
      "S. Adhikari",
      "M. O'Dwyer",
      "F. Sayed",
      "A. Ingrisano",
      "D. Yoder",
      "E. S. Bolman",
      "I. T. Martin",
      "M. Hinczewski",
      "K. D. Singer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07134"
  },
  {
    "id": "arXiv:2106.07135",
    "title": "MTC: Multiresolution Tensor Completion from Partial and Coarse  Observations",
    "abstract": "Existing tensor completion formulation mostly relies on partial observations\nfrom a single tensor. However, tensors extracted from real-world data are often\nmore complex due to: (i) Partial observation: Only a small subset (e.g., 5%) of\ntensor elements are available. (ii) Coarse observation: Some tensor modes only\npresent coarse and aggregated patterns (e.g., monthly summary instead of daily\nreports). In this paper, we are given a subset of the tensor and some\naggregated/coarse observations (along one or more modes) and seek to recover\nthe original fine-granular tensor with low-rank factorization. We formulate a\ncoupled tensor completion problem and propose an efficient Multi-resolution\nTensor Completion model (MTC) to solve the problem. Our MTC model explores\ntensor mode properties and leverages the hierarchy of resolutions to\nrecursively initialize an optimization setup, and optimizes on the coupled\nsystem using alternating least squares. MTC ensures low computational and space\ncomplexity. We evaluate our model on two COVID-19 related spatio-temporal\ntensors. The experiments show that MTC could provide 65.20% and 75.79%\npercentage of fitness (PoF) in tensor completion with only 5% fine granular\nobservations, which is 27.96% relative improvement over the best baseline. To\nevaluate the learned low-rank factors, we also design a tensor prediction task\nfor daily and cumulative disease case predictions, where MTC achieves 50% in\nPoF and 30% relative improvements over the best baseline.",
    "descriptor": "\nComments: Accepted in SIGKDD 2021. Code in this https URL\n",
    "authors": [
      "Chaoqi Yang",
      "Navjot Singh",
      "Cao Xiao",
      "Cheng Qian",
      "Edgar Solomonik",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07135"
  },
  {
    "id": "arXiv:2106.07136",
    "title": "Bayesian dense inverse searching algorithm for real-time stereo matching  in minimally invasive surgery",
    "abstract": "This paper reports a CPU-level real-time stereo matching method for surgical\nimages (10 Hz on 640 * 480 image with a single core of i5-9400). The proposed\nmethod is built on the fast ''dense inverse searching'' algorithm, which\nestimates the disparity of the stereo images. The overlapping image patches\n(arbitrary squared image segment) from the images at different scales are\naligned based on the photometric consistency presumption. We propose a Bayesian\nframework to evaluate the probability of the optimized patch disparity at\ndifferent scales. Moreover, we introduce a spatial Gaussian mixed probability\ndistribution to address the pixel-wise probability within the patch. In-vivo\nand synthetic experiments show that our method can handle ambiguities resulted\nfrom the textureless surfaces and the photometric inconsistency caused by the\nLambertian reflectance. Our Bayesian method correctly balances the probability\nof the patch for stereo images at different scales. Experiments indicate that\nthe estimated depth has higher accuracy and fewer outliers than the baseline\nmethods in the surgical scenario.",
    "descriptor": "",
    "authors": [
      "Jingwei Song",
      "Qiuchen Zhu",
      "Jianyu Lin",
      "Maani Ghaffari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07136"
  },
  {
    "id": "arXiv:2106.07137",
    "title": "Why Can You Lay Off Heads? Investigating How BERT Heads Transfer",
    "abstract": "The huge size of the widely used BERT family models has led to recent efforts\nabout model distillation. The main goal of distillation is to create a\ntask-agnostic pre-trained model that can be fine-tuned on downstream tasks\nwithout fine-tuning its full-sized version. Despite the progress of\ndistillation, to what degree and for what reason a task-agnostic model can be\ncreated from distillation has not been well studied. Also, the mechanisms\nbehind transfer learning of those BERT models are not well investigated either.\nTherefore, this work focuses on analyzing the acceptable deduction when\ndistillation for guiding the future distillation procedure. Specifically, we\nfirst inspect the prunability of the Transformer heads in RoBERTa and ALBERT\nusing their head importance estimation proposed by Michel et al. (2019), and\nthen check the coherence of the important heads between the pre-trained task\nand downstream tasks. Hence, the acceptable deduction of performance on the\npre-trained task when distilling a model can be derived from the results, and\nwe further compare the behavior of the pruned model before and after\nfine-tuning. Our studies provide guidance for future directions about BERT\nfamily model distillation.",
    "descriptor": "",
    "authors": [
      "Ting-Rui Chiang",
      "Yun-Nung Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07137"
  },
  {
    "id": "arXiv:2106.07139",
    "title": "Pre-Trained Models: Past, Present and Future",
    "abstract": "Large-scale pre-trained models (PTMs) such as BERT and GPT have recently\nachieved great success and become a milestone in the field of artificial\nintelligence (AI). Owing to sophisticated pre-training objectives and huge\nmodel parameters, large-scale PTMs can effectively capture knowledge from\nmassive labeled and unlabeled data. By storing knowledge into huge parameters\nand fine-tuning on specific tasks, the rich knowledge implicitly encoded in\nhuge parameters can benefit a variety of downstream tasks, which has been\nextensively demonstrated via experimental verification and empirical analysis.\nIt is now the consensus of the AI community to adopt PTMs as backbone for\ndownstream tasks rather than learning models from scratch. In this paper, we\ntake a deep look into the history of pre-training, especially its special\nrelation with transfer learning and self-supervised learning, to reveal the\ncrucial position of PTMs in the AI development spectrum. Further, we\ncomprehensively review the latest breakthroughs of PTMs. These breakthroughs\nare driven by the surge of computational power and the increasing availability\nof data, towards four important directions: designing effective architectures,\nutilizing rich contexts, improving computational efficiency, and conducting\ninterpretation and theoretical analysis. Finally, we discuss a series of open\nproblems and research directions of PTMs, and hope our view can inspire and\nadvance the future study of PTMs.",
    "descriptor": "",
    "authors": [
      "Han Xu",
      "Zhang Zhengyan",
      "Ding Ning",
      "Gu Yuxian",
      "Liu Xiao",
      "Huo Yuqi",
      "Qiu Jiezhong",
      "Zhang Liang",
      "Han Wentao",
      "Huang Minlie",
      "Jin Qin",
      "Lan Yanyan",
      "Liu Yang",
      "Liu Zhiyuan",
      "Lu Zhiwu",
      "Qiu Xipeng",
      "Song Ruihua",
      "Tang Jie",
      "Wen Ji-Rong",
      "Yuan Jinhui",
      "Zhao Wayne Xin",
      "Zhu Jun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07139"
  },
  {
    "id": "arXiv:2106.07140",
    "title": "SinIR: Efficient General Image Manipulation with Single Image  Reconstruction",
    "abstract": "We propose SinIR, an efficient reconstruction-based framework trained on a\nsingle natural image for general image manipulation, including\nsuper-resolution, editing, harmonization, paint-to-image, photo-realistic style\ntransfer, and artistic style transfer. We train our model on a single image\nwith cascaded multi-scale learning, where each network at each scale is\nresponsible for image reconstruction. This reconstruction objective greatly\nreduces the complexity and running time of training, compared to the GAN\nobjective. However, the reconstruction objective also exacerbates the output\nquality. Therefore, to solve this problem, we further utilize simple random\npixel shuffling, which also gives control over manipulation, inspired by the\nDenoising Autoencoder. With quantitative evaluation, we show that SinIR has\ncompetitive performance on various image manipulation tasks. Moreover, with a\nmuch simpler training objective (i.e., reconstruction), SinIR is trained 33.5\ntimes faster than SinGAN (for 500 X 500 images) that solves similar tasks. Our\ncode is publicly available at github.com/YooJiHyeong/SinIR.",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Jihyeong Yoo",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07140"
  },
  {
    "id": "arXiv:2106.07141",
    "title": "Selection of Source Images Heavily Influences the Effectiveness of  Adversarial Attacks",
    "abstract": "Although the adoption rate of deep neural networks (DNNs) has tremendously\nincreased in recent years, a solution for their vulnerability against\nadversarial examples has not yet been found. As a result, substantial research\nefforts are dedicated to fix this weakness, with many studies typically using a\nsubset of source images to generate adversarial examples, treating every image\nin this subset as equal. We demonstrate that, in fact, not every source image\nis equally suited for this kind of assessment. To do so, we devise a\nlarge-scale model-to-model transferability scenario for which we meticulously\nanalyze the properties of adversarial examples, generated from every suitable\nsource image in ImageNet by making use of two of the most frequently deployed\nattacks. In this transferability scenario, which involves seven distinct DNN\nmodels, including the recently proposed vision transformers, we reveal that it\nis possible to have a difference of up to $12.5\\%$ in model-to-model\ntransferability success, $1.01$ in average $L_2$ perturbation, and $0.03$\n($8/225$) in average $L_{\\infty}$ perturbation when $1,000$ source images are\nsampled randomly among all suitable candidates. We then take one of the first\nsteps in evaluating the robustness of images used to create adversarial\nexamples, proposing a number of simple but effective methods to identify\nunsuitable source images, thus making it possible to mitigate extreme cases in\nexperimentation and support high-quality benchmarking.",
    "descriptor": "",
    "authors": [
      "Utku Ozbulak",
      "Esla Timothy Anzaku",
      "Wesley De Neve",
      "Arnout Van Messem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07141"
  },
  {
    "id": "arXiv:2106.07152",
    "title": "Fast Construction of 4-Additive Spanners",
    "abstract": "A $k$-additive spanner of a graph is a subgraph that preserves the distance\nbetween any two nodes up to a total additive error of $+k$. Efficient\nalgorithms have been devised for constructing 2 [Aingworth et al. SIAM '99], 6\n[Baswana et al. ACM '10, Woodruff ICALP '13], and 8-additive spanners [Knudsen\n'17], but efficiency hasn't been studied for 4-additive spanner constructions.\nIn this paper we present a modification of Chechik's 4-additive spanner\nconstruction [Chechik SODA '13] that produces a 4-additive spanner on\n$\\widetilde{O}(n^{7/5})$ edges, with an improved runtime of\n$\\widetilde{O}(mn^{3/5})$ from $O(mn)$.",
    "descriptor": "",
    "authors": [
      "Bandar Al-Dhalaan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.07152"
  },
  {
    "id": "arXiv:2106.07153",
    "title": "Iterative Methods for Private Synthetic Data: Unifying Framework and New  Methods",
    "abstract": "We study private synthetic data generation for query release, where the goal\nis to construct a sanitized version of a sensitive dataset, subject to\ndifferential privacy, that approximately preserves the answers to a large\ncollection of statistical queries. We first present an algorithmic framework\nthat unifies a long line of iterative algorithms in the literature. Under this\nframework, we propose two new methods. The first method, private entropy\nprojection (PEP), can be viewed as an advanced variant of MWEM that adaptively\nreuses past query measurements to boost accuracy. Our second method, generative\nnetworks with the exponential mechanism (GEM), circumvents computational\nbottlenecks in algorithms such as MWEM and PEP by optimizing over generative\nmodels parameterized by neural networks, which capture a rich family of\ndistributions while enabling fast gradient-based optimization. We demonstrate\nthat PEP and GEM empirically outperform existing algorithms. Furthermore, we\nshow that GEM nicely incorporates prior information from public data while\novercoming limitations of PMW^Pub, the existing state-of-the-art method that\nalso leverages public data.",
    "descriptor": "",
    "authors": [
      "Terrance Liu",
      "Giuseppe Vietri",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07153"
  },
  {
    "id": "arXiv:2106.07154",
    "title": "Local time stepping for the shallow water equations in MPAS-Ocean",
    "abstract": "We assess the performance of a set of local time-stepping schemes for the\nshallow water equations implemented in the global ocean model MPAS-Ocean. The\navailability of local time-stepping tools is of major relevance for ocean codes\nsuch as MPAS-Ocean, which rely on a multi-resolution approach to perform\nregional grid refinement, for instance in proximity of the coast. In presence\nof variable resolution, the size of the time-step of explicit numerical\nintegrators is bounded above by the size of the smallest cell on the grid,\naccording to the Courant-Friedrichs-Lewy (CFL) condition. This constraint means\nthat the time-step size used in low resolution regions must be the same as the\none used in high resolution regions, resulting in an unnecessary computational\neffort. Local time-stepping, on the other hand, allows one to select different\ntime-step sizes according to local, rather than global, CFL conditions,\nresulting in a more tailored integration process and reduced computational\ntimes. The present work is a preliminary but necessary effort aimed at paving\nthe way for a more comprehensive work on local time-stepping for the primitive\nequation set with realistic geography.",
    "descriptor": "",
    "authors": [
      "Giacomo Capodaglio",
      "Mark Petersen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07154"
  },
  {
    "id": "arXiv:2106.07155",
    "title": "CFedAvg: Achieving Efficient Communication and Fast Convergence in  Non-IID Federated Learning",
    "abstract": "Federated learning (FL) is a prevailing distributed learning paradigm, where\na large number of workers jointly learn a model without sharing their training\ndata. However, high communication costs could arise in FL due to large-scale\n(deep) learning models and bandwidth-constrained connections. In this paper, we\nintroduce a communication-efficient algorithmic framework called CFedAvg for FL\nwith non-i.i.d. datasets, which works with general (biased or unbiased)\nSNR-constrained compressors. We analyze the convergence rate of CFedAvg for\nnon-convex functions with constant and decaying learning rates. The CFedAvg\nalgorithm can achieve an $\\mathcal{O}(1 / \\sqrt{mKT} + 1 / T)$ convergence rate\nwith a constant learning rate, implying a linear speedup for convergence as the\nnumber of workers increases, where $K$ is the number of local steps, $T$ is the\nnumber of total communication rounds, and $m$ is the total worker number. This\nmatches the convergence rate of distributed/federated learning without\ncompression, thus achieving high communication efficiency while not sacrificing\nlearning accuracy in FL. Furthermore, we extend CFedAvg to cases with\nheterogeneous local steps, which allows different workers to perform a\ndifferent number of local steps to better adapt to their own circumstances. The\ninteresting observation in general is that the noise/variance introduced by\ncompressors does not affect the overall convergence rate order for non-i.i.d.\nFL. We verify the effectiveness of our CFedAvg algorithm on three datasets with\ntwo gradient compression schemes of different compression ratios.",
    "descriptor": "",
    "authors": [
      "Haibo Yang",
      "Jia Liu",
      "Elizabeth S. Bentley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.07155"
  },
  {
    "id": "arXiv:2106.07156",
    "title": "Temporal Predictive Coding For Model-Based Planning In Latent Space",
    "abstract": "High-dimensional observations are a major challenge in the application of\nmodel-based reinforcement learning (MBRL) to real-world environments. To handle\nhigh-dimensional sensory inputs, existing approaches use representation\nlearning to map high-dimensional observations into a lower-dimensional latent\nspace that is more amenable to dynamics estimation and planning. In this work,\nwe present an information-theoretic approach that employs temporal predictive\ncoding to encode elements in the environment that can be predicted across time.\nSince this approach focuses on encoding temporally-predictable information, we\nimplicitly prioritize the encoding of task-relevant components over nuisance\ninformation within the environment that are provably task-irrelevant. By\nlearning this representation in conjunction with a recurrent state space model,\nwe can then perform planning in latent space. We evaluate our model on a\nchallenging modification of standard DMControl tasks where the background is\nreplaced with natural videos that contain complex but irrelevant information to\nthe planning task. Our experiments show that our model is superior to existing\nmethods in the challenging complex-background setting while remaining\ncompetitive with current state-of-the-art models in the standard setting.",
    "descriptor": "\nComments: International Conference on Machine Learning\n",
    "authors": [
      "Tung Nguyen",
      "Rui Shu",
      "Tuan Pham",
      "Hung Bui",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07156"
  },
  {
    "id": "arXiv:2106.07157",
    "title": "Multiple scattering ambisonics: three-dimensional sound foeld estimation  using interacting spheres",
    "abstract": "Rigid spherical microphone arrays (RSMAs) have been widely used in ambisonics\nsound field recording. While it is desired to combine the information captured\nby a grid of densely arranged RSMAs for expanding the area of accurate\nreconstruction, or sweet-spots, this is not trivial due to inter-array\ninterference. Here we propose multiple scattering ambisonics, a method for\nthree-dimensional ambisonics sound field recording using multiple acoustically\ninteracting RSMAs. Numerical experiments demonstrate the sweet-spot expansion\nrealized by the proposed method. The proposed method can be used with existing\nRSMAs as building blocks and opens possibilities including higher\ndegrees-of-freedom spatial audio.",
    "descriptor": "",
    "authors": [
      "Shoken Kaneko",
      "Ramani Duraiswami"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.07157"
  },
  {
    "id": "arXiv:2106.07158",
    "title": "A Novel Variable K-Pseudonym Scheme Applied to 5G Anonymous Access  Authentication",
    "abstract": "Anonymous access authentication schemes provide users with massive\napplication services while protecting the privacy of users' identities. The\nidentity protection schemes in 3G and 4G are not suitable for 5G anonymous\naccess authentication due to complex computation and pseudonym asynchrony. In\nthis paper, we consider mobile devices with limited resources in the 5G network\nand propose an anonymous access authentication scheme without the Public Key\nInfrastructure. The anonymous access authentication scheme provides users with\nvariable shard pseudonyms to protect users' identities asynchronously. With the\nvariable shared pseudonym, our scheme can ensure user anonymity and resist the\nmark attack, a novel attack aimed at the basic k-pseudonym scheme. Finally, we\nanalyze the scheme with BAN logic analysis and verify the user anonymity.",
    "descriptor": "",
    "authors": [
      "Dong Ma",
      "Xixiang Lyu",
      "Renpeng Zou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.07158"
  },
  {
    "id": "arXiv:2106.07159",
    "title": "Object-Guided Instance Segmentation With Auxiliary Feature Refinement  for Biological Images",
    "abstract": "Instance segmentation is of great importance for many biological\napplications, such as study of neural cell interactions, plant phenotyping, and\nquantitatively measuring how cells react to drug treatment. In this paper, we\npropose a novel box-based instance segmentation method. Box-based instance\nsegmentation methods capture objects via bounding boxes and then perform\nindividual segmentation within each bounding box region. However, existing\nmethods can hardly differentiate the target from its neighboring objects within\nthe same bounding box region due to their similar textures and low-contrast\nboundaries. To deal with this problem, in this paper, we propose an\nobject-guided instance segmentation method. Our method first detects the center\npoints of the objects, from which the bounding box parameters are then\npredicted. To perform segmentation, an object-guided coarse-to-fine\nsegmentation branch is built along with the detection branch. The segmentation\nbranch reuses the object features as guidance to separate target object from\nthe neighboring ones within the same bounding box region. To further improve\nthe segmentation quality, we design an auxiliary feature refinement module that\ndensely samples and refines point-wise features in the boundary regions.\nExperimental results on three biological image datasets demonstrate the\nadvantages of our method. The code will be available at\nhttps://github.com/yijingru/ObjGuided-Instance-Segmentation.",
    "descriptor": "\nComments: Accepted in TMI\n",
    "authors": [
      "Jingru Yi",
      "Pengxiang Wu",
      "Hui Tang",
      "Bo Liu",
      "Qiaoying Huang",
      "Hui Qu",
      "Lianyi Han",
      "Wei Fan",
      "Daniel J. Hoeppner",
      "Dimitris N. Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07159"
  },
  {
    "id": "arXiv:2106.07160",
    "title": "Learning Intrusion Prevention Policies through Optimal Stopping",
    "abstract": "We study automated intrusion prevention using reinforcement learning. In a\nnovel approach, we formulate the problem of intrusion prevention as an optimal\nstopping problem. This formulation allows us insight into the structure of the\noptimal policies, which turn out to be threshold based. Since the computation\nof the optimal defender policy using dynamic programming is not feasible for\npractical cases, we approximate the optimal policy through reinforcement\nlearning in a simulation environment. To define the dynamics of the simulation,\nwe emulate the target infrastructure and collect measurements. Our evaluations\nshow that the learned policies are close to optimal and that they indeed can be\nexpressed using thresholds.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Kim Hammar",
      "Rolf Stadler"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.07160"
  },
  {
    "id": "arXiv:2106.07161",
    "title": "Heterogeneous Edge-Enhanced Graph Attention Network For Multi-Agent  Trajectory Prediction",
    "abstract": "Simultaneous trajectory prediction for multiple heterogeneous traffic\nparticipants is essential for the safe and efficient operation of connected\nautomated vehicles under complex driving situations in the real world. The\nmulti-agent prediction task is challenging, as the motions of traffic\nparticipants are affected by many factors, including their individual dynamics,\ntheir interactions with surrounding agents, the traffic infrastructures, and\nthe number and modalities of the target agents. To further advance the\ntrajectory prediction techniques, in this work we propose a three-channel\nframework together with a novel Heterogeneous Edge-enhanced graph ATtention\nnetwork (HEAT), which is able to deal with the heterogeneity of the target\nagents and traffic participants involved. Specifically, the agent's dynamics\nare extracted from their historical states using type-specific encoders. The\ninter-agent interactions are represented with a directed edge-featured\nheterogeneous graph, and then interaction features are extracted using the\nproposed HEAT network. Besides, the map features are shared across all agents\nby introducing a selective gate mechanism. And finally, the trajectories of\nmulti-agent are executed simultaneously. Validations using both urban and\nhighway driving datasets show that the proposed model can realize simultaneous\ntrajectory predictions for multiple agents under complex traffic situations,\nand achieve state-of-the-art performance with respect to prediction accuracy,\ndemonstrating its feasibility and effectiveness.",
    "descriptor": "",
    "authors": [
      "Xiaoyu Mo",
      "Yang Xing",
      "Chen Lv"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.07161"
  },
  {
    "id": "arXiv:2106.07162",
    "title": "Goal-Aware Neural SAT Solver",
    "abstract": "Modern neural networks obtain information about the problem and calculate the\noutput solely from the input values. We argue that it is not always optimal,\nand the network's performance can be significantly improved by augmenting it\nwith a query mechanism that allows the network to make several solution trials\nat run time and get feedback on the loss value on each trial. To demonstrate\nthe capabilities of the query mechanism, we formulate an unsupervised (not\ndependant on labels) loss function for Boolean Satisfiability Problem (SAT) and\ntheoretically show that it allows the network to extract rich information about\nthe problem. We then propose a neural SAT solver with a query mechanism called\nQuerySAT and show that it outperforms the neural baseline on a wide range of\nSAT tasks and the classical baselines on SHA-1 preimage attack and 3-SAT task.",
    "descriptor": "",
    "authors": [
      "Emils Ozolins",
      "Karlis Freivalds",
      "Andis Draguns",
      "Eliza Gaile",
      "Ronalds Zakovskis",
      "Sergejs Kozlovics"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07162"
  },
  {
    "id": "arXiv:2106.07165",
    "title": "Self-training Guided Adversarial Domain Adaptation For Thermal Imagery",
    "abstract": "Deep models trained on large-scale RGB image datasets have shown tremendous\nsuccess. It is important to apply such deep models to real-world problems.\nHowever, these models suffer from a performance bottleneck under illumination\nchanges. Thermal IR cameras are more robust against such changes, and thus can\nbe very useful for the real-world problems. In order to investigate efficacy of\ncombining feature-rich visible spectrum and thermal image modalities, we\npropose an unsupervised domain adaptation method which does not require\nRGB-to-thermal image pairs. We employ large-scale RGB dataset MS-COCO as source\ndomain and thermal dataset FLIR ADAS as target domain to demonstrate results of\nour method. Although adversarial domain adaptation methods aim to align the\ndistributions of source and target domains, simply aligning the distributions\ncannot guarantee perfect generalization to the target domain. To this end, we\npropose a self-training guided adversarial domain adaptation method to promote\ngeneralization capabilities of adversarial domain adaptation methods. To\nperform self-training, pseudo labels are assigned to the samples on the target\nthermal domain to learn more generalized representations for the target domain.\nExtensive experimental analyses show that our proposed method achieves better\nresults than the state-of-the-art adversarial domain adaptation methods. The\ncode and models are publicly available.",
    "descriptor": "\nComments: Accepted to CVPR 2021 Perception Beyond the Visible Spectrum (PBVS) workshop\n",
    "authors": [
      "Ibrahim Batuhan Akkaya",
      "Fazil Altinel",
      "Ugur Halici"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07165"
  },
  {
    "id": "arXiv:2106.07166",
    "title": "2rd Place Solutions in the HC-STVG track of Person in Context Challenge  2021",
    "abstract": "In this technical report, we present our solution to localize a\nspatio-temporal person in an untrimmed video based on a sentence. We achieve\nthe second vIOU(0.30025) in the HC-STVG track of the 3rd Person in Context(PIC)\nChallenge. Our solution contains three parts: 1) human attributes information\nis extracted from the sentence, it is helpful to filter out tube proposals in\nthe testing phase and supervise our classifier to learn appearance information\nin the training phase. 2) we detect humans with YoloV5 and track humans based\non the DeepSort framework but replace the original ReID network with FastReID.\n3) a visual transformer is used to extract cross-modal representations for\nlocalizing a spatio-temporal tube of the target person.",
    "descriptor": "",
    "authors": [
      "YiYu",
      "XinyingWang",
      "WeiHu",
      "XunLuo",
      "ChengLi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07166"
  },
  {
    "id": "arXiv:2106.07167",
    "title": "End-to-end Neural Diarization: From Transformer to Conformer",
    "abstract": "We propose a new end-to-end neural diarization (EEND) system that is based on\nConformer, a recently proposed neural architecture that combines convolutional\nmappings and Transformer to model both local and global dependencies in speech.\nWe first show that data augmentation and convolutional subsampling layers\nenhance the original self-attentive EEND in the Transformer-based EEND, and\nthen Conformer gives an additional gain over the Transformer-based EEND.\nHowever, we notice that the Conformer-based EEND does not generalize as well\nfrom simulated to real conversation data as the Transformer-based model. This\nleads us to quantify the mismatch between simulated data and real speaker\nbehavior in terms of temporal statistics reflecting turn-taking between\nspeakers, and investigate its correlation with diarization error. By mixing\nsimulated and real data in EEND training, we mitigate the mismatch further,\nwith Conformer-based EEND achieving 24% error reduction over the baseline\nSA-EEND system, and 10% improvement over the best augmented Transformer-based\nsystem, on two-speaker CALLHOME data.",
    "descriptor": "\nComments: To appear in Interspeech 2021\n",
    "authors": [
      "Yi Chieh Liu",
      "Eunjung Han",
      "Chul Lee",
      "Andreas Stolcke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07167"
  },
  {
    "id": "arXiv:2106.07171",
    "title": "Examining and Combating Spurious Features under Distribution Shift",
    "abstract": "A central goal of machine learning is to learn robust representations that\ncapture the causal relationship between inputs features and output labels.\nHowever, minimizing empirical risk over finite or biased datasets often results\nin models latching on to spurious correlations between the training\ninput/output pairs that are not fundamental to the problem at hand. In this\npaper, we define and analyze robust and spurious representations using the\ninformation-theoretic concept of minimal sufficient statistics. We prove that\neven when there is only bias of the input distribution (i.e. covariate shift),\nmodels can still pick up spurious features from their training data. Group\ndistributionally robust optimization (DRO) provides an effective tool to\nalleviate covariate shift by minimizing the worst-case training loss over a set\nof pre-defined groups. Inspired by our analysis, we demonstrate that group DRO\ncan fail when groups do not directly account for various spurious correlations\nthat occur in the data. To address this, we further propose to minimize the\nworst-case losses over a more flexible set of distributions that are defined on\nthe joint distribution of groups and instances, instead of treating each group\nas a whole at optimization time. Through extensive experiments on one image and\ntwo language tasks, we show that our model is significantly more robust than\ncomparable baselines under various partitions. Our code is available at\nhttps://github.com/violet-zct/group-conditional-DRO.",
    "descriptor": "\nComments: Accepted by ICML2021\n",
    "authors": [
      "Chunting Zhou",
      "Xuezhe Ma",
      "Paul Michel",
      "Graham Neubig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07171"
  },
  {
    "id": "arXiv:2106.07172",
    "title": "Energy-efficient Knowledge Distillation for Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) have been gaining interest as energy-efficient\nalternatives of conventional artificial neural networks (ANNs) due to their\nevent-driven computation. Considering the future deployment of SNN models to\nconstrained neuromorphic devices, many studies have applied techniques\noriginally used for ANN model compression, such as network quantization,\npruning, and knowledge distillation, to SNNs. Among them, existing works on\nknowledge distillation reported accuracy improvements of student SNN model.\nHowever, analysis on energy efficiency, which is also an important feature of\nSNN, was absent. In this paper, we thoroughly analyze the performance of the\ndistilled SNN model in terms of accuracy and energy efficiency. In the process,\nwe observe a substantial increase in the number of spikes, leading to energy\ninefficiency, when using the conventional knowledge distillation methods. Based\non this analysis, to achieve energy efficiency, we propose a novel knowledge\ndistillation method with heterogeneous temperature parameters. We evaluate our\nmethod on two different datasets and show that the resulting SNN student\nsatisfies both accuracy improvement and reduction of the number of spikes. On\nMNIST dataset, our proposed student SNN achieves up to 0.09% higher accuracy\nand produces 65% less spikes compared to the student SNN trained with\nconventional knowledge distillation method. We also compare the results with\nother SNN compression techniques and training methods.",
    "descriptor": "",
    "authors": [
      "Dongjin Lee",
      "Seongsik Park",
      "Jongwan Kim",
      "Wuhyeong Doh",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.07172"
  },
  {
    "id": "arXiv:2106.07174",
    "title": "A Mutual Information Maximization Approach for the Spurious Solution  Problem in Weakly Supervised Question Answering",
    "abstract": "Weakly supervised question answering usually has only the final answers as\nsupervision signals while the correct solutions to derive the answers are not\nprovided. This setting gives rise to the spurious solution problem: there may\nexist many spurious solutions that coincidentally derive the correct answer,\nbut training on such solutions can hurt model performance (e.g., producing\nwrong solutions or answers). For example, for discrete reasoning tasks as on\nDROP, there may exist many equations to derive a numeric answer, and typically\nonly one of them is correct. Previous learning methods mostly filter out\nspurious solutions with heuristics or using model confidence, but do not\nexplicitly exploit the semantic correlations between a question and its\nsolution. In this paper, to alleviate the spurious solution problem, we propose\nto explicitly exploit such semantic correlations by maximizing the mutual\ninformation between question-answer pairs and predicted solutions. Extensive\nexperiments on four question answering datasets show that our method\nsignificantly outperforms previous learning methods in terms of task\nperformance and is more effective in training models to produce correct\nsolutions.",
    "descriptor": "\nComments: ACL2021 main conference\n",
    "authors": [
      "Zhihong Shao",
      "Lifeng Shang",
      "Qun Liu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07174"
  },
  {
    "id": "arXiv:2106.07175",
    "title": "Learning to Combine Per-Example Solutions for Neural Program Synthesis",
    "abstract": "The goal of program synthesis from examples is to find a computer program\nthat is consistent with a given set of input-output examples. Most\nlearning-based approaches try to find a program that satisfies all examples at\nonce. Our work, by contrast, considers an approach that breaks the problem into\ntwo stages: (a) find programs that satisfy only one example, and (b) leverage\nthese per-example solutions to yield a program that satisfies all examples. We\nintroduce the Cross Aggregator neural network module based on a multi-head\nattention mechanism that learns to combine the cues present in these\nper-example solutions to synthesize a global solution. Evaluation across\nprograms of different lengths and under two different experimental settings\nreveal that when given the same time budget, our technique significantly\nimproves the success rate over PCCoder arXiv:1809.04682v2 [cs.LG] and other\nablation baselines. The code, data and trained models for our work can be found\nat https://github.com/shrivastavadisha/N-PEPS.",
    "descriptor": "",
    "authors": [
      "Disha Shrivastava",
      "Hugo Larochelle",
      "Daniel Tarlow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.07175"
  },
  {
    "id": "arXiv:2106.07176",
    "title": "SAS: Self-Augmented Strategy for Language Model Pre-training",
    "abstract": "The core of a self-supervised learning method for pre-training language\nmodels includes the design of appropriate data augmentation and corresponding\npre-training task(s). Most data augmentations in language model pre-training\nare context-independent. The seminal contextualized augmentation recently\nproposed by the ELECTRA requires a separate generator, which leads to extra\ncomputation cost as well as the challenge in adjusting the capability of its\ngenerator relative to that of the other model component(s). We propose a\nself-augmented strategy (SAS) that uses a single forward pass through the model\nto augment the input data for model training in the next epoch. Essentially our\nstrategy eliminates a separate generator network and uses only one network to\ngenerate the data augmentation and undertake two pre-training tasks (the MLM\ntask and the RTD task) jointly, which naturally avoids the challenge in\nadjusting the generator's capability as well as reduces the computation cost.\nAdditionally, our SAS is a general strategy such that it can seamlessly\nincorporate many new techniques emerging recently or in the future, such as the\ndisentangled attention mechanism recently proposed by the DeBERTa model. Our\nexperiments show that our SAS is able to outperform the ELECTRA and other\nstate-of-the-art models in the GLUE tasks with the same or less computation\ncost.",
    "descriptor": "\nComments: 13 pages, 3 figures\n",
    "authors": [
      "Yifei Xu",
      "Jingqiao Zhang",
      "Ru He",
      "Liangzhu Ge",
      "Chao Yang",
      "Cheng Yang",
      "Ying Nian Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07176"
  },
  {
    "id": "arXiv:2106.07178",
    "title": "A Comprehensive Survey on Graph Anomaly Detection with Deep Learning",
    "abstract": "Anomalies represent rare observations (e.g., data records or events) that are\ndeviating significantly from others. Over the last forty years, researches on\nanomalies have received great interests because of their significance in many\ndisciplines (e.g., computer science, chemistry, and biology). Anomaly\ndetection, which aims to identify these rare observations, is among the most\nvital tasks and has shown its power in preventing detrimental events, such as\nfinancial fraud and network intrusion, from happening. The detection task is\ntypically solved by detecting outlying data points in the features space and\ninherently overlooks the structural information in real-world data. Graphs have\nbeen prevalently used to preserve the structural information, and this raises\nthe graph anomaly detection problem - identifying anomalous graph objects\n(i.e., nodes, edges and sub-graphs). However, conventional anomaly detection\ntechniques cannot well solve this problem because of the complexity of graph\ndata (e.g., irregular structures, non-independent and large-scale). For the\naptitudes of deep learning in breaking these limitations, graph anomaly\ndetection with deep learning has received intensified studies recently. In this\nsurvey, we aim to provide a systematic and comprehensive review of the\ncontemporary deep learning techniques for graph anomaly detection.\nSpecifically, our categorization follows a task-driven strategy and classifies\nexisting works according to the anomalous graph objects they can detect. We\nespecially focus on the motivations, key intuitions and technical details of\nexisting works. We also summarize open-sourced implementations, public\ndatasets, and commonly-used evaluation metrics for future studies. Finally, we\nhighlight twelve future research directions according to our survey results\ncovering emerging problems introduced by graph data, anomaly detection and real\napplications.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Xiaoxiao Ma",
      "Jia Wu",
      "Shan Xue",
      "Jian Yang",
      "Quan Z. Sheng",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07178"
  },
  {
    "id": "arXiv:2106.07182",
    "title": "Deploying COTS Legged Robot Platforms into a Heterogeneous Robot Team",
    "abstract": "The recent availability of commercial-off-the-shelf (COTS) legged robot\nplatforms have opened up new opportunities in deploying legged systems into\ndifferent scenarios. While the main advantage of legged robots is their ability\nto traverse unstructured terrain, there are still large gaps between what robot\nplatforms can achieve and their animal counterparts. Therefore, when deploying\nas part of a heterogeneous robot team of different platforms, it is beneficial\nto understand the different scenarios where a legged platform would perform\nbetter than a wheeled, tracked or aerial platform. Two COTS quadruped robots,\nGhost Robotics' Vision 60 and Boston Dynamics' Spot, were deployed into a\nheterogeneous team. A description of some of the challenges faced while\nintegrating the platforms, as well as some experiments in traversing different\nterrains are provided to give insight into the real-world deployment of legged\nrobots.",
    "descriptor": "\nComments: ICRA 2021: 5th Full-Day Workshop on Towards Real-World Deployment of Legged Robots\n",
    "authors": [
      "Benjamin Tam",
      "Thomas Molnar",
      "Fletcher Talbot",
      "Brett Wood",
      "Ryan Steindl"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.07182"
  },
  {
    "id": "arXiv:2106.07185",
    "title": "Modeling Object Recognition in Newborn Chicks using Deep Neural Networks",
    "abstract": "In recent years, the brain and cognitive sciences have made great strides\ndeveloping a mechanistic understanding of object recognition in mature brains.\nDespite this progress, fundamental questions remain about the origins and\ncomputational foundations of object recognition. What learning algorithms\nunderlie object recognition in newborn brains? Since newborn animals learn\nlargely through unsupervised learning, we explored whether unsupervised\nlearning algorithms can be used to predict the view-invariant object\nrecognition behavior of newborn chicks. Specifically, we used feature\nrepresentations derived from unsupervised deep neural networks (DNNs) as inputs\nto cognitive models of categorization. We show that features derived from\nunsupervised DNNs make competitive predictions about chick behavior compared to\nsupervised features. More generally, we argue that linking controlled-rearing\nstudies to image-computable DNN models opens new experimental avenues for\nstudying the origins and computational basis of object recognition in newborn\nanimals.",
    "descriptor": "\nComments: Presented at CogSci 2021\n",
    "authors": [
      "Donsuk Lee",
      "Denizhan Pak",
      "Justin N. Wood"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.07185"
  },
  {
    "id": "arXiv:2106.07186",
    "title": "Sejong Face Database: A Multi-Modal Disguise Face Database",
    "abstract": "Commercial application of facial recognition demands robustness to a variety\nof challenges such as illumination, occlusion, spoofing, disguise, etc.\nDisguised face recognition is one of the emerging issues for access control\nsystems, such as security checkpoints at the borders. However, the lack of\navailability of face databases with a variety of disguise addons limits the\ndevelopment of academic research in the area. In this paper, we present a\nmultimodal disguised face dataset to facilitate the disguised face recognition\nresearch. The presented database contains 8 facial add-ons and 7 additional\ncombinations of these add-ons to create a variety of disguised face images.\nEach facial image is captured in visible, visible plus infrared, infrared, and\nthermal spectra. Specifically, the database contains 100 subjects divided into\nsubset-A (30 subjects, 1 image per modality) and subset-B (70 subjects, 5 plus\nimages per modality). We also present baseline face detection results performed\non the proposed database to provide reference results and compare the\nperformance in different modalities. Qualitative and quantitative analysis is\nperformed to evaluate the challenging nature of disguise addons. The dataset\nwill be publicly available with the acceptance of the research article. The\ndatabase is available at: https://github.com/usmancheema89/SejongFaceDatabase.",
    "descriptor": "\nComments: Database Access Link: this https URL\n",
    "authors": [
      "Usman Cheema",
      "Seungbin Moon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07186"
  },
  {
    "id": "arXiv:2106.07189",
    "title": "Capacity of Gaussian Arbitrarily-Varying Fading Channels",
    "abstract": "This paper considers an arbitrarily-varying fading channel consisting of one\ntransmitter, one receiver and an arbitrarily varying adversary. The channel is\nassumed to have additive Gaussian noise and fast fading of the gain from the\nlegitimate user to the receiver. We study four variants of the problem\ndepending on whether the transmitter and/or adversary have access to the fading\ngains; we assume the receiver always knows the fading gains. In two variants\nthe adversary does not have access to the gains, we show that the capacity\ncorresponds to the capacity of a standard point-to-point fading channel with\nincreased noise variance. The capacity of the other two cases, in which the\nadversary has knowledge of the channel gains, are determined by the worst-case\nnoise variance as a function of the channel gain subject to the jammer's power\nconstraint; if the jammer has enough power, then it can imitate the legitimate\nuser's channel, causing the capacity to drop to zero. We also show that having\nthe channel gains causally or non-causally at the encoder and/or the adversary\ndoes not change the capacity, except for the case where all parties know the\nchannel gains. In this case, if the transmitter knows the gains non-causally,\nwhile the adversary knows the gains causally, then it is possible for the\nlegitimate users to keep a secret from the adversary. We show that in this case\nthe capacity is always positive.",
    "descriptor": "",
    "authors": [
      "Fatemeh Hosseinigoki",
      "Oliver Kosut"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.07189"
  },
  {
    "id": "arXiv:2106.07190",
    "title": "Group-based Bi-Directional Recurrent Wavelet Neural Networks for Video  Super-Resolution",
    "abstract": "Video super-resolution (VSR) aims to estimate a high-resolution (HR) frame\nfrom a low-resolution (LR) frames. The key challenge for VSR lies in the\neffective exploitation of spatial correlation in an intra-frame and temporal\ndependency between consecutive frames. However, most of the previous methods\ntreat different types of the spatial features identically and extract spatial\nand temporal features from the separated modules. It leads to lack of obtaining\nmeaningful information and enhancing the fine details. In VSR, there are three\ntypes of temporal modeling frameworks: 2D convolutional neural networks (CNN),\n3D CNN, and recurrent neural networks (RNN). Among them, the RNN-based approach\nis suitable for sequential data. Thus the SR performance can be greatly\nimproved by using the hidden states of adjacent frames. However, at each of\ntime step in a recurrent structure, the RNN-based previous works utilize the\nneighboring features restrictively. Since the range of accessible motion per\ntime step is narrow, there are still limitations to restore the missing details\nfor dynamic or large motion. In this paper, we propose a group-based\nbi-directional recurrent wavelet neural networks (GBR-WNN) to exploit the\nsequential data and spatio-temporal information effectively for VSR. The\nproposed group-based bi-directional RNN (GBR) temporal modeling framework is\nbuilt on the well-structured process with the group of pictures (GOP). We\npropose a temporal wavelet attention (TWA) module, in which attention is\nadopted for both spatial and temporal features. Experimental results\ndemonstrate that the proposed method achieves superior performance compared\nwith state-of-the-art methods in both of quantitative and qualitative\nevaluations.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Young-Ju Choi",
      "Young-Woon Lee",
      "Byung-Gyu Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07190"
  },
  {
    "id": "arXiv:2106.07192",
    "title": "Automatic Document Sketching: Generating Drafts from Analogous Texts",
    "abstract": "The advent of large pre-trained language models has made it possible to make\nhigh-quality predictions on how to add or change a sentence in a document.\nHowever, the high branching factor inherent to text generation impedes the\nability of even the strongest language models to offer useful editing\nsuggestions at a more global or document level. We introduce a new task,\ndocument sketching, which involves generating entire draft documents for the\nwriter to review and revise. These drafts are built from sets of documents that\noverlap in form - sharing large segments of potentially reusable text - while\ndiverging in content. To support this task, we introduce a Wikipedia-based\ndataset of analogous documents and investigate the application of weakly\nsupervised methods, including use of a transformer-based mixture of experts,\ntogether with reinforcement learning. We report experiments using automated and\nhuman evaluation methods and discuss relative merits of these models.",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Zeqiu Wu",
      "Michel Galley",
      "Chris Brockett",
      "Yizhe Zhang",
      "Bill Dolan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07192"
  },
  {
    "id": "arXiv:2106.07193",
    "title": "Crowdsourcing via Annotator Co-occurrence Imputation and Provable  Symmetric Nonnegative Matrix Factorization",
    "abstract": "Unsupervised learning of the Dawid-Skene (D&S) model from noisy, incomplete\nand crowdsourced annotations has been a long-standing challenge, and is a\ncritical step towards reliably labeling massive data. A recent work takes a\ncoupled nonnegative matrix factorization (CNMF) perspective, and shows\nappealing features: It ensures the identifiability of the D\\&S model and enjoys\nlow sample complexity, as only the estimates of the co-occurrences of annotator\nlabels are involved. However, the identifiability holds only when certain\nsomewhat restrictive conditions are met in the context of crowdsourcing.\nOptimizing the CNMF criterion is also costly -- and convergence assurances are\nelusive. This work recasts the pairwise co-occurrence based D&S model learning\nproblem as a symmetric NMF (SymNMF) problem -- which offers enhanced\nidentifiability relative to CNMF. In practice, the SymNMF model is often\n(largely) incomplete, due to the lack of co-labeled items by some annotators.\nTwo lightweight algorithms are proposed for co-occurrence imputation. Then, a\nlow-complexity shifted rectified linear unit (ReLU)-empowered SymNMF algorithm\nis proposed to identify the D&S model. Various performance characterizations\n(e.g., missing co-occurrence recoverability, stability, and convergence) and\nevaluations are also presented.",
    "descriptor": "\nComments: To appear in ICML 2021\n",
    "authors": [
      "Shahana Ibrahim",
      "Xiao Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.07193"
  },
  {
    "id": "arXiv:2106.07197",
    "title": "DAGs with No Curl: An Efficient DAG Structure Learning Approach",
    "abstract": "Recently directed acyclic graph (DAG) structure learning is formulated as a\nconstrained continuous optimization problem with continuous acyclicity\nconstraints and was solved iteratively through subproblem optimization. To\nfurther improve efficiency, we propose a novel learning framework to model and\nlearn the weighted adjacency matrices in the DAG space directly. Specifically,\nwe first show that the set of weighted adjacency matrices of DAGs are\nequivalent to the set of weighted gradients of graph potential functions, and\none may perform structure learning by searching in this equivalent set of DAGs.\nTo instantiate this idea, we propose a new algorithm, DAG-NoCurl, which solves\nthe optimization problem efficiently with a two-step procedure: 1) first we\nfind an initial cyclic solution to the optimization problem, and 2) then we\nemploy the Hodge decomposition of graphs and learn an acyclic graph by\nprojecting the cyclic graph to the gradient of a potential function.\nExperimental studies on benchmark datasets demonstrate that our method provides\ncomparable accuracy but better efficiency than baseline DAG structure learning\nmethods on both linear and generalized structural equation models, often by\nmore than one order of magnitude.",
    "descriptor": "\nComments: ICML2021, Code is available at this https URL\n",
    "authors": [
      "Yue Yu",
      "Tian Gao",
      "Naiyu Yin",
      "Qiang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07197"
  },
  {
    "id": "arXiv:2106.07200",
    "title": "Towards Continuous Safety Assessment in Context of DevOps",
    "abstract": "Traditionally, promoted by the internet companies, continuous delivery is\nmore and more appealing to industries which develop systems with\nsafety-critical functions. Since safety-critical systems must meet regulatory\nrequirements and require specific safety assessment processes in addition to\nthe normal development steps, enabling continuous delivery of software in\nsafety-critical systems requires the automation of the safety assessment\nprocess in the delivery pipeline. In this paper, we outline a continuous\ndelivery pipeline for realizing continuous safety assessment in\nsoftware-intensive safety-critical systems based on model-based safety\nassessment methods.",
    "descriptor": "",
    "authors": [
      "Marc Zeller"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.07200"
  },
  {
    "id": "arXiv:2106.07203",
    "title": "Online Sub-Sampling for Reinforcement Learning with General Function  Approximation",
    "abstract": "Designing provably efficient algorithms with general function approximation\nis an important open problem in reinforcement learning. Recently, Wang et\nal.~[2020c] establish a value-based algorithm with general function\napproximation that enjoys\n$\\widetilde{O}(\\mathrm{poly}(dH)\\sqrt{K})$\\footnote{Throughout the paper, we\nuse $\\widetilde{O}(\\cdot)$ to suppress logarithm factors. } regret bound, where\n$d$ depends on the complexity of the function class, $H$ is the planning\nhorizon, and $K$ is the total number of episodes. However, their algorithm\nrequires $\\Omega(K)$ computation time per round, rendering the algorithm\ninefficient for practical use. In this paper, by applying online sub-sampling\ntechniques, we develop an algorithm that takes\n$\\widetilde{O}(\\mathrm{poly}(dH))$ computation time per round on average, and\nenjoys nearly the same regret bound. Furthermore, the algorithm achieves low\nswitching cost, i.e., it changes the policy only\n$\\widetilde{O}(\\mathrm{poly}(dH))$ times during its execution, making it\nappealing to be implemented in real-life scenarios. Moreover, by using an\nupper-confidence based exploration-driven reward function, the algorithm\nprovably explores the environment in the reward-free setting. In particular,\nafter $\\widetilde{O}(\\mathrm{poly}(dH))/\\epsilon^2$ rounds of exploration, the\nalgorithm outputs an $\\epsilon$-optimal policy for any given reward function.",
    "descriptor": "",
    "authors": [
      "Dingwen Kong",
      "Ruslan Salakhutdinov",
      "Ruosong Wang",
      "Lin F. Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07203"
  },
  {
    "id": "arXiv:2106.07204",
    "title": "Hard Samples Rectification for Unsupervised Cross-domain Person  Re-identification",
    "abstract": "Person re-identification (re-ID) has received great success with the\nsupervised learning methods. However, the task of unsupervised cross-domain\nre-ID is still challenging. In this paper, we propose a Hard Samples\nRectification (HSR) learning scheme which resolves the weakness of original\nclustering-based methods being vulnerable to the hard positive and negative\nsamples in the target unlabelled dataset. Our HSR contains two parts, an\ninter-camera mining method that helps recognize a person under different views\n(hard positive) and a part-based homogeneity technique that makes the model\ndiscriminate different persons but with similar appearance (hard negative). By\nrectifying those two hard cases, the re-ID model can learn effectively and\nachieve promising results on two large-scale benchmarks.",
    "descriptor": "\nComments: This paper was accepted by IEEE International Conference on Image Processing (ICIP) 2021\n",
    "authors": [
      "Chih-Ting Liu",
      "Man-Yu Lee",
      "Tsai-Shien Chen",
      "Shao-Yi Chien"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07204"
  },
  {
    "id": "arXiv:2106.07207",
    "title": "Straight to the Gradient: Learning to Use Novel Tokens for Neural Text  Generation",
    "abstract": "Advanced large-scale neural language models have led to significant success\nin many language generation tasks. However, the most commonly used training\nobjective, Maximum Likelihood Estimation (MLE), has been shown problematic,\nwhere the trained model prefers using dull and repetitive phrases. In this\nwork, we introduce ScaleGrad, a modification straight to the gradient of the\nloss function, to remedy the degeneration issue of the standard MLE objective.\nBy directly maneuvering the gradient information, ScaleGrad makes the model\nlearn to use novel tokens. Empirical results show the effectiveness of our\nmethod not only in open-ended generation, but also in directed generation\ntasks. With the simplicity in architecture, our method can serve as a general\ntraining objective that is applicable to most of the neural text generation\ntasks.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Xiang Lin",
      "Simeng Han",
      "Shafiq Joty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07207"
  },
  {
    "id": "arXiv:2106.07211",
    "title": "Differentiable Neural Architecture Search with Morphism-based  Transformable Backbone Architectures",
    "abstract": "This study aims at making the architecture search process more adaptive for\none-shot or online training. It is extended from the existing study on\ndifferentiable neural architecture search, and we made the backbone\narchitecture transformable rather than fixed during the training process. As is\nknown, differentiable neural architecture search (DARTS) requires a pre-defined\nover-parameterized backbone architecture, while its size is to be determined\nmanually. Also, in DARTS backbone, Hadamard product of two elements is not\nintroduced, which exists in both LSTM and GRU cells for recurrent nets. This\nstudy introduces a growing mechanism for differentiable neural architecture\nsearch based on network morphism. It enables growing of the cell structures\nfrom small size towards large size ones with one-shot training. Two modes can\nbe applied in integrating the growing and original pruning process. We also\nimplement a recently proposed two-input backbone architecture for recurrent\nneural networks. Initial experimental results indicate that our approach and\nthe two-input backbone structure can be quite effective compared with other\nbaseline architectures including LSTM, in a variety of learning tasks including\nmulti-variate time series forecasting and language modeling. On the other hand,\nwe find that dynamic network transformation is promising in improving the\nefficiency of differentiable architecture search.",
    "descriptor": "",
    "authors": [
      "Renlong Jie",
      "Junbin Gao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07211"
  },
  {
    "id": "arXiv:2106.07213",
    "title": "TweetPap: A Dataset to Study the Social Media Discourse of Scientific  Papers",
    "abstract": "Nowadays, researchers have moved to platforms like Twitter to spread\ninformation about their ideas and empirical evidence. Recent studies have shown\nthat social media affects the scientific impact of a paper. However, these\nstudies only utilize the tweet counts to represent Twitter activity. In this\npaper, we propose TweetPap, a large-scale dataset that introduces temporal\ninformation of citation/tweets and the metadata of the tweets to quantify and\nunderstand the discourse of scientific papers on social media. The dataset is\npublicly available at https://github.com/lingo-iitgn/TweetPap",
    "descriptor": "\nComments: 2 Pages, JCDL 2021\n",
    "authors": [
      "Naman Jain",
      "Mayank Singh"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.07213"
  },
  {
    "id": "arXiv:2106.07214",
    "title": "Backdoor Learning Curves: Explaining Backdoor Poisoning Beyond Influence  Functions",
    "abstract": "Backdoor attacks inject poisoning samples during training, with the goal of\nenforcing a machine-learning model to output an attacker-chosen class when\npresented a specific trigger at test time. Although backdoor attacks have been\ndemonstrated in a variety of settings and against different models, the factors\naffecting their success are not yet well understood. In this work, we provide a\nunifying framework to study the process of backdoor learning under the lens of\nincremental learning and influence functions. We show that the success of\nbackdoor attacks inherently depends on (i) the complexity of the learning\nalgorithm, controlled by its hyperparameters, and (ii) the fraction of backdoor\nsamples injected into the training set. These factors affect how fast a\nmachine-learning model learns to correlate the presence of a backdoor trigger\nwith the target class. Interestingly, our analysis shows that there exists a\nregion in the hyperparameter space in which the accuracy on clean test samples\nis still high while backdoor attacks become ineffective, thereby suggesting\nnovel criteria to improve existing defenses.",
    "descriptor": "\nComments: 21 pages, submitted to NeurIPS 2021\n",
    "authors": [
      "Antonio Emanuele Cin\u00e0",
      "Kathrin Grosse",
      "Sebastiano Vascon",
      "Ambra Demontis",
      "Battista Biggio",
      "Fabio Roli",
      "Marcello Pelillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07214"
  },
  {
    "id": "arXiv:2106.07217",
    "title": "Over-Fit: Noisy-Label Detection based on the Overfitted Model Property",
    "abstract": "Due to the increasing need to handle the noisy label problem in a massive\ndataset, learning with noisy labels has received much attention in recent\nyears. As a promising approach, there have been recent studies to select clean\ntraining data by finding small-loss instances before a deep neural network\noverfits the noisy-label data. However, it is challenging to prevent\noverfitting. In this paper, we propose a novel noisy-label detection algorithm\nby employing the property of overfitting on individual data points. To this\nend, we present two novel criteria that statistically measure how much each\ntraining sample abnormally affects the model and clean validation data. Using\nthe criteria, our iterative algorithm removes noisy-label samples and retrains\nthe model alternately until no further performance improvement is made. In\nexperiments on multiple benchmark datasets, we demonstrate the validity of our\nalgorithm and show that our algorithm outperforms the state-of-the-art methods\nwhen the exact noise rates are not given. Furthermore, we show that our method\ncan not only be expanded to a real-world video dataset but also can be viewed\nas a regularization method to solve problems caused by overfitting.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Seulki Park",
      "Dae Ung Jo",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07217"
  },
  {
    "id": "arXiv:2106.07218",
    "title": "Physics-Aware Downsampling with Deep Learning for Scalable Flood  Modeling",
    "abstract": "Background: Floods are the most common natural disaster in the world,\naffecting the lives of hundreds of millions. Flood forecasting is therefore a\nvitally important endeavor, typically achieved using physical water flow\nsimulations, which rely on accurate terrain elevation maps. However, such\nsimulations, based on solving partial differential equations, are\ncomputationally prohibitive on a large scale. This scalability issue is\ncommonly alleviated using a coarse grid representation of the elevation map,\nthough this representation may distort crucial terrain details, leading to\nsignificant inaccuracies in the simulation. Contributions: We train a deep\nneural network to perform physics-informed downsampling of the terrain map: we\noptimize the coarse grid representation of the terrain maps, so that the flood\nprediction will match the fine grid solution. For the learning process to\nsucceed, we configure a dataset specifically for this task. We demonstrate that\nwith this method, it is possible to achieve a significant reduction in\ncomputational cost, while maintaining an accurate solution. A reference\nimplementation accompanies the paper as well as documentation and code for\ndataset reproduction.",
    "descriptor": "",
    "authors": [
      "Niv Giladi",
      "Zvika Ben-Haim",
      "Sella Nevo",
      "Yossi Matias",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07218"
  },
  {
    "id": "arXiv:2106.07220",
    "title": "Context-Aware Image Inpainting with Learned Semantic Priors",
    "abstract": "Recent advances in image inpainting have shown impressive results for\ngenerating plausible visual details on rather simple backgrounds. However, for\ncomplex scenes, it is still challenging to restore reasonable contents as the\ncontextual information within the missing regions tends to be ambiguous. To\ntackle this problem, we introduce pretext tasks that are semantically\nmeaningful to estimating the missing contents. In particular, we perform\nknowledge distillation on pretext models and adapt the features to image\ninpainting. The learned semantic priors ought to be partially invariant between\nthe high-level pretext task and low-level image inpainting, which not only help\nto understand the global context but also provide structural guidance for the\nrestoration of local textures. Based on the semantic priors, we further propose\na context-aware image inpainting model, which adaptively integrates global\nsemantics and local features in a unified image generator. The semantic learner\nand the image generator are trained in an end-to-end manner. We name the model\nSPL to highlight its ability to learn and leverage semantic priors. It achieves\nthe state of the art on Places2, CelebA, and Paris StreetView datasets.",
    "descriptor": "\nComments: Accepted by IJCAI 2021\n",
    "authors": [
      "Wendong Zhang",
      "Junwei Zhu",
      "Ying Tai",
      "Yunbo Wang",
      "Wenqing Chu",
      "Bingbing Ni",
      "Chengjie Wang",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07220"
  },
  {
    "id": "arXiv:2106.07221",
    "title": "Certification of embedded systems based on Machine Learning: A survey",
    "abstract": "Advances in machine learning (ML) open the way to innovating functions in the\navionic domain, such as navigation/surveillance assistance (e.g. vision-based\nnavigation, obstacle sensing, virtual sensing), speechto-text applications,\nautonomous flight, predictive maintenance or cockpit assistance. Current\ncertification standards and practices, which were defined and refined decades\nover decades with classical programming in mind, do not however support this\nnew development paradigm. This article provides an overview of the main\nchallenges raised by the use ML in the demonstration of compliance with\nregulation requirements, and a survey of literature relevant to these\nchallenges, with particular focus on the issues of robustness and\nexplainability of ML results.",
    "descriptor": "",
    "authors": [
      "Guillaume Vidot",
      "Christophe Gabreau",
      "Ileana Ober",
      "Iulian Ober"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07221"
  },
  {
    "id": "arXiv:2106.07224",
    "title": "SGE net: Video object detection with squeezed GRU and information  entropy map",
    "abstract": "Recently, deep learning based video object detection has attracted more and\nmore attention. Compared with object detection of static images, video object\ndetection is more challenging due to the motion of objects, while providing\nrich temporal information. The RNN-based algorithm is an effective way to\nenhance detection performance in videos with temporal information. However,\nmost studies in this area only focus on accuracy while ignoring the calculation\ncost and the number of parameters.\nIn this paper, we propose an efficient method that combines channel-reduced\nconvolutional GRU (Squeezed GRU), and Information Entropy map for video object\ndetection (SGE-Net). The experimental results validate the accuracy\nimprovement, computational savings of the Squeezed GRU, and superiority of the\ninformation entropy attention mechanism on the classification performance. The\nmAP has increased by 3.7 contrasted with the baseline, and the number of\nparameters has decreased from 6.33 million to 0.67 million compared with the\nstandard GRU.",
    "descriptor": "\nComments: ICIP 2021\n",
    "authors": [
      "Rui Su",
      "Wenjing Huang",
      "Haoyu Ma",
      "Xiaowei Song",
      "Jinglu Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07224"
  },
  {
    "id": "arXiv:2106.07225",
    "title": "English to Bangla Machine Translation Using Recurrent Neural Network",
    "abstract": "The applications of recurrent neural networks in machine translation are\nincreasing in natural language processing. Besides other languages, Bangla\nlanguage contains a large amount of vocabulary. Improvement of English to\nBangla machine translation would be a significant contribution to Bangla\nLanguage processing. This paper describes an architecture of English to Bangla\nmachine translation system. The system has been implemented with the\nencoder-decoder recurrent neural network. The model uses a knowledge-based\ncontext vector for the mapping of English and Bangla words. Performances of the\nmodel based on activation functions are measured here. The best performance is\nachieved for the linear activation function in encoder layer and the tanh\nactivation function in decoder layer. From the execution of GRU and LSTM layer,\nGRU performed better than LSTM. The attention layers are enacted with softmax\nand sigmoid activation function. The approach of the model outperforms the\nprevious state-of-the-art systems in terms of cross-entropy loss metrics. The\nreader can easily find out the structure of the machine translation of English\nto Bangla and the efficient activation functions from the paper.",
    "descriptor": "\nComments: 6 pages, 7 figures, Published with International Journal of Future Computer and Communication (IJFCC)\n",
    "authors": [
      "Shaykh Siddique",
      "Tahmid Ahmed",
      "Md. Rifayet Azam Talukder",
      "Md. Mohsin Uddin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07225"
  },
  {
    "id": "arXiv:2106.07226",
    "title": "More Real than Real: A Study on Human Visual Perception of Synthetic  Faces",
    "abstract": "Deep fakes became extremely popular in the last years, also thanks to their\nincreasing realism. Therefore, there is the need to measures human's ability to\ndistinguish between real and synthetic face images when confronted with\ncutting-edge creation technologies. We describe the design and results of a\nperceptual experiment we have conducted, where a wide and diverse group of\nvolunteers has been exposed to synthetic face images produced by\nstate-of-the-art Generative Adversarial Networks (namely, PG-GAN, StyleGAN,\nStyleGAN2). The experiment outcomes reveal how strongly we should call into\nquestion our human ability to discriminate real faces from synthetic ones\ngenerated through modern AI.",
    "descriptor": "",
    "authors": [
      "Federica Lago",
      "Cecilia Pasquini",
      "Rainer B\u00f6hme",
      "H\u00e9l\u00e8ne Dumont",
      "Val\u00e9rie Goffaux",
      "Giulia Boato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.07226"
  },
  {
    "id": "arXiv:2106.07228",
    "title": "Automated Parking Space Detection Using Convolutional Neural Networks",
    "abstract": "Finding a parking space nowadays becomes an issue that is not to be\nneglected, it consumes time and energy. We have used computer vision techniques\nto infer the state of the parking lot given the data collected from the\nUniversity of The Witwatersrand. This paper presents an approach for a\nreal-time parking space classification based on Convolutional Neural Networks\n(CNN) using Caffe and Nvidia DiGITS framework. The training process has been\ndone using DiGITS and the output is a caffemodel used for predictions to detect\nvacant and occupied parking spots. The system checks a defined area whether a\nparking spot (bounding boxes defined at initialization of the system) is\ncontaining a car or not (occupied or vacant). Those bounding box coordinates\nare saved from a frame of the video of the parking lot in a JSON format, to be\nlater used by the system for sequential prediction on each parking spot. The\nsystem has been trained using the LeNet network with the Nesterov Accelerated\nGradient as solver and the AlexNet network with the Stochastic Gradient Descent\nas solver. We were able to get an accuracy on the validation set of 99\\% for\nboth networks. The accuracy on a foreign dataset(PKLot) returned as well 99\\%.\nThose are experimental results based on the training set shows how robust the\nsystem can be when the prediction has to take place in a different parking\nspace.",
    "descriptor": "",
    "authors": [
      "Julien Nyambal",
      "Richard Klein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07228"
  },
  {
    "id": "arXiv:2106.07229",
    "title": "Privacy-Preserving Machine Learning with Fully Homomorphic Encryption  for Deep Neural Network",
    "abstract": "Fully homomorphic encryption (FHE) is one of the prospective tools for\nprivacypreserving machine learning (PPML), and several PPML models have been\nproposed based on various FHE schemes and approaches. Although the FHE schemes\nare known as suitable tools to implement PPML models, previous PPML models on\nFHE encrypted data are limited to only simple and non-standard types of machine\nlearning models. These non-standard machine learning models are not proven\nefficient and accurate with more practical and advanced datasets. Previous PPML\nschemes replace non-arithmetic activation functions with simple arithmetic\nfunctions instead of adopting approximation methods and do not use\nbootstrapping, which enables continuous homomorphic evaluations. Thus, they\ncould not use standard activation functions and could not employ a large number\nof layers. The maximum classification accuracy of the existing PPML model with\nthe FHE for the CIFAR-10 dataset was only 77% until now. In this work, we\nfirstly implement the standard ResNet-20 model with the RNS-CKKS FHE with\nbootstrapping and verify the implemented model with the CIFAR-10 dataset and\nthe plaintext model parameters. Instead of replacing the non-arithmetic\nfunctions with the simple arithmetic function, we use state-of-the-art\napproximation methods to evaluate these non-arithmetic functions, such as the\nReLU, with sufficient precision [1]. Further, for the first time, we use the\nbootstrapping technique of the RNS-CKKS scheme in the proposed model, which\nenables us to evaluate a deep learning model on the encrypted data. We\nnumerically verify that the proposed model with the CIFAR-10 dataset shows\n98.67% identical results to the original ResNet-20 model with non-encrypted\ndata. The classification accuracy of the proposed model is 90.67%, which is\npretty close to that of the original ResNet-20 CNN model...",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Joon-Woo Lee",
      "HyungChul Kang",
      "Yongwoo Lee",
      "Woosuk Choi",
      "Jieun Eom",
      "Maxim Deryabin",
      "Eunsang Lee",
      "Junghyun Lee",
      "Donghoon Yoo",
      "Young-Sik Kim",
      "Jong-Seon No"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07229"
  },
  {
    "id": "arXiv:2106.07233",
    "title": "Minimality Notions via Factorization Systems",
    "abstract": "For the minimization of state-based systems (i.e. the reduction of the number\nof states while retaining the system's semantics), there are two obvious\naspects: removing unnecessary states of the system and merging redundant states\nin the system.\nIn the present article, we relate the two aspects on coalgebras by defining\nan abstract notion of minimality using factorization systems. We will find\ncriteria on the category that ensure uniqueness, existence, and functoriality\nof the minimization aspects, where the proofs instantiate to those for\nreachability and bisimilarity minimization in the standard coalgebra\nliterature. Finally, we will see how the two aspects of minimization interact\nand under which criteria they can be sequenced in any order, like in automata\nminimization.",
    "descriptor": "",
    "authors": [
      "Thorsten Wi\u00dfmann"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2106.07233"
  },
  {
    "id": "arXiv:2106.07234",
    "title": "Real-World Evaluation of the Impact of Automated Driving System  Technology on Driver Gaze Behavior, Reaction Time and Trust",
    "abstract": "Recent developments in advanced driving assistance systems (ADAS) that rely\non some level of autonomy have led the automobile industry and research\ncommunity to investigate the impact they might have on driving performance.\nHowever, most of the research performed so far is based on simulated\nenvironments. In this study, we investigated the behavior of drivers in a\nvehicle with automated driving system (ADS) capabilities in a real-life driving\nscenario. We analyzed their response to a take over request (TOR) at two\ndifferent driving speeds while being engaged in non-driving-related tasks\n(NDRT). Results from the performed experiments showed that driver reaction time\nto a TOR, gaze behavior and self-reported trust in automation were affected by\nthe type of NDRT being concurrently performed and driver reaction time and gaze\nbehavior additionally depended on the driving or vehicle speed at the time of\nTOR.",
    "descriptor": "\nComments: Submitted and accepted in the IEEE Intelligent Vehicle Symposium 2021 Conference (IV2021)\n",
    "authors": [
      "Walter Morales-Alvarez",
      "Mohamed Marouf",
      "Hadj. Hamma Tadjine",
      "Cristina Olaverri-Monreal"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.07234"
  },
  {
    "id": "arXiv:2106.07237",
    "title": "Is Einstein more agreeable and less neurotic than Hitler? A  computational exploration of the emotional and personality profiles of  historical persons",
    "abstract": "Recent progress in distributed semantic models (DSM) offers new ways to\nestimate personality traits of both fictive and real people. In this\nexploratory study we applied an extended version of the algorithm developed in\nJacobs (2019) to compute the likeability scores, emotional figure profiles and\nBIG5 personality traits for 100 historical persons from the arts, politics or\nscience domains whose names are rather unique (e.g., Einstein, Kahlo, Picasso).\nWe compared the results produced by static (word2vec) and dynamic (BERT)\nlanguage model representations in four studies. The results show both the\npotential and limitations of such DSM-based computations of personality\nprofiles and point ways to further develop this approach to become a useful\ntool in data science, psychology or computational and neurocognitive poetics\n(Jacobs, 2015).",
    "descriptor": "\nComments: 20 pages, 4 figures\n",
    "authors": [
      "Arthur M. Jacobs",
      "Annette Kinder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07237"
  },
  {
    "id": "arXiv:2106.07239",
    "title": "Fair Clustering Under a Bounded Cost",
    "abstract": "Clustering is a fundamental unsupervised learning problem where a dataset is\npartitioned into clusters that consist of nearby points in a metric space. A\nrecent variant, fair clustering, associates a color with each point\nrepresenting its group membership and requires that each color has\n(approximately) equal representation in each cluster to satisfy group fairness.\nIn this model, the cost of the clustering objective increases due to enforcing\nfairness in the algorithm. The relative increase in the cost, the ''price of\nfairness,'' can indeed be unbounded. Therefore, in this paper we propose to\ntreat an upper bound on the clustering objective as a constraint on the\nclustering problem, and to maximize equality of representation subject to it.\nWe consider two fairness objectives: the group utilitarian objective and the\ngroup egalitarian objective, as well as the group leximin objective which\ngeneralizes the group egalitarian objective. We derive fundamental lower bounds\non the approximation of the utilitarian and egalitarian objectives and\nintroduce algorithms with provable guarantees for them. For the leximin\nobjective we introduce an effective heuristic algorithm. We further derive\nimpossibility results for other natural fairness objectives. We conclude with\nexperimental results on real-world datasets that demonstrate the validity of\nour algorithms.",
    "descriptor": "",
    "authors": [
      "Seyed A. Esmaeili",
      "Brian Brubach",
      "Aravind Srinivasan",
      "John P. Dickerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07239"
  },
  {
    "id": "arXiv:2106.07240",
    "title": "Mitigating Biases in Toxic Language Detection through Invariant  Rationalization",
    "abstract": "Automatic detection of toxic language plays an essential role in protecting\nsocial media users, especially minority groups, from verbal abuse. However,\nbiases toward some attributes, including gender, race, and dialect, exist in\nmost training datasets for toxicity detection. The biases make the learned\nmodels unfair and can even exacerbate the marginalization of people.\nConsidering that current debiasing methods for general natural language\nunderstanding tasks cannot effectively mitigate the biases in the toxicity\ndetectors, we propose to use invariant rationalization (InvRat), a\ngame-theoretic framework consisting of a rationale generator and a predictor,\nto rule out the spurious correlation of certain syntactic patterns (e.g.,\nidentity mentions, dialect) to toxicity labels. We empirically show that our\nmethod yields lower false positive rate in both lexical and dialectal\nattributes than previous debiasing methods.",
    "descriptor": "\nComments: The 5th Workshop on Online Abuse and Harms at ACL 2021\n",
    "authors": [
      "Yung-Sung Chuang",
      "Mingye Gao",
      "Hongyin Luo",
      "James Glass",
      "Hung-yi Lee",
      "Yun-Nung Chen",
      "Shang-Wen Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07240"
  },
  {
    "id": "arXiv:2106.07241",
    "title": "Contemporary Amharic Corpus: Automatically Morpho-Syntactically Tagged  Amharic Corpus",
    "abstract": "We introduced the contemporary Amharic corpus, which is automatically tagged\nfor morpho-syntactic information. Texts are collected from 25,199 documents\nfrom different domains and about 24 million orthographic words are tokenized.\nSince it is partly a web corpus, we made some automatic spelling error\ncorrection. We have also modified the existing morphological analyzer,\nHornMorpho, to use it for the automatic tagging.",
    "descriptor": "\nComments: Published in Proceedings of the First Workshop on Linguistic Resources for Natural Language Processing at COLING 2018\n",
    "authors": [
      "Andargachew Mekonnen Gezmu",
      "Binyam Ephrem Seyoum",
      "Michael Gasser",
      "Andreas N\u00fcrnberger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07241"
  },
  {
    "id": "arXiv:2106.07242",
    "title": "The asymmetric particle population density method for simulation of  coupled noisy oscillators",
    "abstract": "A wide variety of biological phenomena can be modeled by the collective\nactivity of a population of individual units. A common strategy for simulating\nsuch a system, the population density approach, is to take the macroscopic\nlimit and update its population density function. However, in many cases, the\ncoupling between the units and noise gives rise to complex behaviors\nchallenging to existing population density approach methods. To address these\nchallenges, we develop the asymmetric particle population density (APPD) method\nthat efficiently and accurately simulates such populations consist of coupled\nelements. The APPD is well-suited for a parallel implementation. We compare the\nperformance of the method against direct Monte-Carlo simulation and verify its\naccuracy by applying it to the well-studied Hodgkin-Huxley model, with a range\nof challenging scenarios. We find that our method can accurately reproduce\ncomplex macroscopic behaviors such as inhibitory coupling-induced clustering\nand noise-induced firing while being faster than the direct simulation.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Ningyuan Wang",
      "Daniel B Forger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07242"
  },
  {
    "id": "arXiv:2106.07247",
    "title": "Age of Information for Multiple-Source Multiple-Server Networks",
    "abstract": "Having timely and fresh knowledge about the current state of information\nsources is critical in a variety of applications. In particular, a status\nupdate may arrive at the destination later than its generation time due to\nprocessing and communication delays. The freshness of the status update at the\ndestination is captured by the notion of age of information. In this study, we\nanalyze a multiple sensing network with multiple sources, multiple servers, and\na monitor (destination). Each source corresponds to an independent piece of\ninformation and its age is measured individually. Given a particular source,\nthe servers independently sense the source of information and send the status\nupdate to the monitor. We assume that updates arrive at the servers according\nto Poisson random processes. Each server sends its updates to the monitor\nthrough a direct link, which is modeled as a queue. The service time to\ntransmit an update is considered to be an exponential random variable. We\nexamine both homogeneous and heterogeneous service and arrival rates for the\nsingle-source case, and only homogeneous arrival and service rates for the\nmultiple-source case. We derive a closed-form expression for the average age of\ninformation under a last-come-first-serve (LCFS) queue for a single source and\narbitrary number of homogeneous servers. Using a recursive method, we derive\nthe explicit average age of information for any number of sources and\nhomogeneous servers. We also investigate heterogeneous servers and a single\nsource, and present algorithms for finding the average age of information.",
    "descriptor": "",
    "authors": [
      "Alireza Javani",
      "Marwen Zorgui",
      "Zhiying Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.07247"
  },
  {
    "id": "arXiv:2106.07249",
    "title": "Automatic winning shifts",
    "abstract": "To each one-dimensional subshift $X$, we may associate a winning shift $W(X)$\nwhich arises from a combinatorial game played on the language of $X$.\nPreviously it has been studied what properties of $X$ does $W(X)$ inherit. For\nexample, $X$ and $W(X)$ have the same factor complexity and if $X$ is a sofic\nsubshift, then $W(X)$ is also sofic. In this paper, we develop a notion of\nautomaticity for $W(X)$, that is, we propose what it means that a vector\nrepresentation of $W(X)$ is accepted by a finite automaton.\nLet $S$ be an abstract numeration system such that addition with respect to\n$S$ is a rational relation. Let $X$ be a subshift generated by an $S$-automatic\nword. We prove that as long as there is a bound on the number of nonzero\nsymbols in configurations of $W(X)$ (which follows from $X$ having sublinear\nfactor complexity), then $W(X)$ is accepted by a finite automaton, which can be\neffectively constructed from the description of $X$. We provide an explicit\nautomaton when $X$ is generated by certain automatic words such as the\nThue-Morse word.",
    "descriptor": "\nComments: 28 pages, 5 figures, 1 table\n",
    "authors": [
      "Jarkko Peltom\u00e4ki",
      "Ville Salo"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.07249"
  },
  {
    "id": "arXiv:2106.07250",
    "title": "Unified Interpretation of Softmax Cross-Entropy and Negative Sampling:  With Case Study for Knowledge Graph Embedding",
    "abstract": "In knowledge graph embedding, the theoretical relationship between the\nsoftmax cross-entropy and negative sampling loss functions has not been\ninvestigated. This makes it difficult to fairly compare the results of the two\ndifferent loss functions. We attempted to solve this problem by using the\nBregman divergence to provide a unified interpretation of the softmax\ncross-entropy and negative sampling loss functions. Under this interpretation,\nwe can derive theoretical findings for fair comparison. Experimental results on\nthe FB15k-237 and WN18RR datasets show that the theoretical findings are valid\nin practical settings.",
    "descriptor": "\nComments: Accepted at ACL-IJCNLP 2021\n",
    "authors": [
      "Hidetaka Kamigaito",
      "Katsuhiko Hayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.07250"
  },
  {
    "id": "arXiv:2106.07252",
    "title": "Evolutionary Robust Clustering Over Time for Temporal Data",
    "abstract": "In many clustering scenes, data samples' attribute values change over time.\nFor such data, we are often interested in obtaining a partition for each time\nstep and tracking the dynamic change of partitions. Normally, a smooth change\nis assumed for data to have a temporal smooth nature. Existing algorithms\nconsider the temporal smoothness as an a priori preference and bias the search\ntowards the preferred direction. This a priori manner leads to a risk of\nconverging to an unexpected region because it is not always the case that a\nreasonable preference can be elicited given the little prior knowledge about\nthe data. To address this issue, this paper proposes a new clustering framework\ncalled evolutionary robust clustering over time. One significant innovation of\nthe proposed framework is processing the temporal smoothness in an a posteriori\nmanner, which avoids unexpected convergence that occurs in existing algorithms.\nFurthermore, the proposed framework automatically tunes the weight of\nsmoothness without data's affinity matrix and predefined parameters, which\nholds better applicability and scalability. The effectiveness and efficiency of\nthe proposed framework are confirmed by comparing with state-of-the-art\nalgorithms on both synthetic and real datasets.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Qi Zhao",
      "Bai Yan",
      "Yuhui Shi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.07252"
  },
  {
    "id": "arXiv:2106.07255",
    "title": "Federated Myopic Community Detection with One-shot Communication",
    "abstract": "In this paper, we study the problem of recovering the community structure of\na network under federated myopic learning. Under this paradigm, we have several\nclients, each of them having a myopic view, i.e., observing a small subgraph of\nthe network. Each client sends a censored evidence graph to a central server.\nWe provide an efficient algorithm, which computes a consensus signed weighted\ngraph from clients evidence, and recovers the underlying network structure in\nthe central server. We analyze the topological structure conditions of the\nnetwork, as well as the signal and noise levels of the clients that allow for\nrecovery of the network structure. Our analysis shows that exact recovery is\npossible and can be achieved in polynomial time. We also provide\ninformation-theoretic limits for the central server to recover the network\nstructure from any single client evidence. Finally, as a byproduct of our\nanalysis, we provide a novel Cheeger-type inequality for general signed\nweighted graphs.",
    "descriptor": "",
    "authors": [
      "Chuyang Ke",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07255"
  },
  {
    "id": "arXiv:2106.07256",
    "title": "Deterministic Guided LiDAR Depth Map Completion",
    "abstract": "Accurate dense depth estimation is crucial for autonomous vehicles to analyze\ntheir environment. This paper presents a non-deep learning-based approach to\ndensify a sparse LiDAR-based depth map using a guidance RGB image. To achieve\nthis goal the RGB image is at first cleared from most of the camera-LiDAR\nmisalignment artifacts. Afterward, it is over segmented and a plane for each\nsuperpixel is approximated. In the case a superpixel is not well represented by\na plane, a plane is approximated for a convex hull of the most inlier. Finally,\nthe pinhole camera model is used for the interpolation process and the\nremaining areas are interpolated. The evaluation of this work is executed using\nthe KITTI depth completion benchmark, which validates the proposed work and\nshows that it outperforms the state-of-the-art non-deep learning-based methods,\nin addition to several deep learning-based methods.",
    "descriptor": "\nComments: Submitted to 2021 IEEE Intelligent Vehicles Symposium (IV21). This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Bryan Krauss",
      "Gregory Schroeder",
      "Marko Gustke",
      "Ahmed Hussein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07256"
  },
  {
    "id": "arXiv:2106.07257",
    "title": "Communication is the universal solvent: atreya bot -- an interactive bot  for chemical scientists",
    "abstract": "Conversational agents are a recent trend in human-computer interaction,\ndeployed in multidisciplinary applications to assist the users. In this paper,\nwe introduce \"Atreya\", an interactive bot for chemistry enthusiasts,\nresearchers, and students to study the ChEMBL database. Atreya is hosted by\nTelegram, a popular cloud-based instant messaging application. This\nuser-friendly bot queries the ChEMBL database, retrieves the drug details for a\nparticular disease, targets associated with that drug, etc. This paper explores\nthe potential of using a conversational agent to assist chemistry students and\nchemical scientist in complex information seeking process.",
    "descriptor": "\nComments: IFIP 9.4 2021 1st Virtual Conference Conference Theme: Resilient ICT4D May 25th 28th, 2021\n",
    "authors": [
      "Mahak Sharma",
      "Abhishek Kaushik",
      "Rajesh Kumar",
      "Sushant Kumar Rai",
      "Harshada Hanumant Desai",
      "Sargam Yadav"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07257"
  },
  {
    "id": "arXiv:2106.07258",
    "title": "GitTables: A Large-Scale Corpus of Relational Tables",
    "abstract": "The practical success of deep learning has sparked interest in improving\nrelational table tasks, like data search, with models trained on large table\ncorpora. Existing corpora primarily contain tables extracted from HTML pages,\nlimiting the capability to represent offline database tables. To train and\nevaluate high-capacity models for applications beyond the Web, we need\nadditional resources with tables that resemble relational database tables.\nHere we introduce GitTables, a corpus of currently 1.7M relational tables\nextracted from GitHub. Our continuing curation aims at growing the corpus to at\nleast 20M tables. We annotate table columns in GitTables with more than 2K\ndifferent semantic types from Schema.org and DBpedia. Our column annotations\nconsist of semantic types, hierarchical relations, range types and\ndescriptions.\nThe corpus is available at https://gittables.github.io. Our analysis of\nGitTables shows that its structure, content, and topical coverage differ\nsignificantly from existing table corpora. We evaluate our annotation pipeline\non hand-labeled tables from the T2Dv2 benchmark and find that our approach\nprovides results on par with human annotations. We demonstrate a use case of\nGitTables by training a semantic type detection model on it and obtain high\nprediction accuracy. We also show that the same model trained on tables from\ntheWeb generalizes poorly.",
    "descriptor": "",
    "authors": [
      "Madelon Hulsebos",
      "\u00c7a\u011fatay Demiralp",
      "Paul Groth"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07258"
  },
  {
    "id": "arXiv:2106.07260",
    "title": "RAPTOR: End-to-end Risk-Aware MDP Planning and Policy Learning by  Backpropagation",
    "abstract": "Planning provides a framework for optimizing sequential decisions in complex\nenvironments. Recent advances in efficient planning in deterministic or\nstochastic high-dimensional domains with continuous action spaces leverage\nbackpropagation through a model of the environment to directly optimize\nactions. However, existing methods typically not take risk into account when\noptimizing in stochastic domains, which can be incorporated efficiently in MDPs\nby optimizing the entropic utility of returns. We bridge this gap by\nintroducing Risk-Aware Planning using PyTorch (RAPTOR), a novel framework for\nrisk-sensitive planning through end-to-end optimization of the entropic utility\nobjective. A key technical difficulty of our approach lies in that direct\noptimization of the entropic utility by backpropagation is impossible due to\nthe presence of environment stochasticity. The novelty of RAPTOR lies in the\nreparameterization of the state distribution, which makes it possible to apply\nstochastic backpropagatation through sufficient statistics of the entropic\nutility computed from forward-sampled trajectories. The direct optimization of\nthis empirical objective in an end-to-end manner is called the risk-averse\nstraight-line plan, which commits to a sequence of actions in advance and can\nbe sub-optimal in highly stochastic domains. We address this shortcoming by\noptimizing for risk-aware Deep Reactive Policies (RaDRP) in our framework. We\nevaluate and compare these two forms of RAPTOR on three highly stochastic\ndo-mains, including nonlinear navigation, HVAC control, and linear reservoir\ncontrol, demonstrating the ability to manage risk in complex MDPs.",
    "descriptor": "",
    "authors": [
      "Noah Patton",
      "Jihwan Jeong",
      "Michael Gimelfarb",
      "Scott Sanner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07260"
  },
  {
    "id": "arXiv:2106.07268",
    "title": "FastICARL: Fast Incremental Classifier and Representation Learning with  Efficient Budget Allocation in Audio Sensing Applications",
    "abstract": "Various incremental learning (IL) approaches have been proposed to help deep\nlearning models learn new tasks/classes continuously without forgetting what\nwas learned previously (i.e., avoid catastrophic forgetting). With the growing\nnumber of deployed audio sensing applications that need to dynamically\nincorporate new tasks and changing input distribution from users, the ability\nof IL on-device becomes essential for both efficiency and user privacy.\nHowever, prior works suffer from high computational costs and storage demands\nwhich hinders the deployment of IL on-device. In this work, to overcome these\nlimitations, we develop an end-to-end and on-device IL framework, FastICARL,\nthat incorporates an exemplar-based IL and quantization in the context of\naudio-based applications. We first employ k-nearest-neighbor to reduce the\nlatency of IL. Then, we jointly utilize a quantization technique to decrease\nthe storage requirements of IL. We implement FastICARL on two types of mobile\ndevices and demonstrate that FastICARL remarkably decreases the IL time up to\n78-92% and the storage requirements by 2-4 times without sacrificing its\nperformance. FastICARL enables complete on-device IL, ensuring user privacy as\nthe user data does not need to leave the device.",
    "descriptor": "\nComments: Accepted for publication at INTERSPEECH 2021\n",
    "authors": [
      "Young D. Kwon",
      "Jagmohan Chauhan",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07268"
  },
  {
    "id": "arXiv:2106.07270",
    "title": "Industry 4.0 and Prospects of Circular Economy: A Survey of Robotic  Assembly and Disassembly",
    "abstract": "Despite their contributions to the financial efficiency and environmental\nsustainability of industrial processes, robotic assembly and disassembly have\nbeen understudied in the existing literature. This is in contradiction to their\nimportance in realizing the Fourth Industrial Revolution. More specifically,\nalthough most of the literature has extensively discussed how to optimally\nassemble or disassemble given products, the role of other factors has been\noverlooked. For example, the types of robots involved in implementing the\nsequence plans, which should ideally be taken into account throughout the whole\nchain consisting of design, assembly, disassembly and reassembly. Isolating the\nforegoing operations from the rest of the components of the relevant ecosystems\nmay lead to erroneous inferences toward both the necessity and efficiency of\nthe underlying procedures. In this paper we try to alleviate these shortcomings\nby comprehensively investigating the state-of-the-art in robotic assembly and\ndisassembly. We consider and review various aspects of manufacturing and\nremanufacturing frameworks while particularly focusing on their desirability\nfor supporting a circular economy.",
    "descriptor": "",
    "authors": [
      "Morteza Daneshmand",
      "Fatemeh Noroozi",
      "Ciprian Corneanu",
      "Fereshteh Mafakheri",
      "Paolo Fiorini"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.07270"
  },
  {
    "id": "arXiv:2106.07271",
    "title": "Optical Fault Injection Attacks against Radiation-Hard Registers",
    "abstract": "If devices are physically accessible optical fault injection attacks pose a\ngreat threat since the data processed as well as the operation flow can be\nmanipulated. Successful physical attacks may lead not only to leakage of secret\ninformation such as cryptographic private keys, but can also cause economic\ndamage especially if as a result of such a manipulation a critical\ninfrastructure is successfully attacked. Laser based attacks exploit the\nsensitivity of CMOS technologies to electromagnetic radiation in the visible or\nthe infrared spectrum. It can be expected that radiation-hard designs,\nspecially crafted for space applications, are more robust not only against\nhigh-energy particles and short electromagnetic waves but also against optical\nfault injection attacks. In this work we investigated the sensitivity of\nradiation-hard JICG shift registers to optical fault injection attacks. In our\nexperiments, we were able to repeatable trigger bit-set and bit-reset\noperations changing the data stored in single JICG flip-flops despite their\nhigh-radiation fault tolerance.",
    "descriptor": "",
    "authors": [
      "Dmytro Petryk",
      "Zoya Dyka",
      "Roland Sorge",
      "Jan Schaeffner",
      "Peter Langendoerfer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.07271"
  },
  {
    "id": "arXiv:2106.07273",
    "title": "Flexible dual-branched message passing neural network for quantum  mechanical property prediction with molecular conformation",
    "abstract": "A molecule is a complex of heterogeneous components, and the spatial\narrangements of these components determine the whole molecular properties and\ncharacteristics. With the advent of deep learning in computational chemistry,\nseveral studies have focused on how to predict molecular properties based on\nmolecular configurations. Message passing neural network provides an effective\nframework for capturing molecular geometric features with the perspective of a\nmolecule as a graph. However, most of these studies assumed that all\nheterogeneous molecular features, such as atomic charge, bond length, or other\ngeometric features always contribute equivalently to the target prediction,\nregardless of the task type. In this study, we propose a dual-branched neural\nnetwork for molecular property prediction based on message-passing framework.\nOur model learns heterogeneous molecular features with different scales, which\nare trained flexibly according to each prediction target. In addition, we\nintroduce a discrete branch to learn single atom features without local\naggregation, apart from message-passing steps. We verify that this novel\nstructure can improve the model performance with faster convergence in most\ntargets. The proposed model outperforms other recent models with sparser\nrepresentations. Our experimental results indicate that in the chemical\nproperty prediction tasks, the diverse chemical nature of targets should be\ncarefully considered for both model performance and generalizability.",
    "descriptor": "\nComments: 28 pages, 7 figures\n",
    "authors": [
      "Jeonghee Jo",
      "Bumju Kwak",
      "Byunghan Lee",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.07273"
  },
  {
    "id": "arXiv:2106.07275",
    "title": "Cascaded Span Extraction and Response Generation for Document-Grounded  Dialog",
    "abstract": "This paper summarizes our entries to both subtasks of the first DialDoc\nshared task which focuses on the agent response prediction task in\ngoal-oriented document-grounded dialogs. The task is split into two subtasks:\npredicting a span in a document that grounds an agent turn and generating an\nagent response based on a dialog and grounding document. In the first subtask,\nwe restrict the set of valid spans to the ones defined in the dataset, use a\nbiaffine classifier to model spans, and finally use an ensemble of different\nmodels. For the second subtask, we use a cascaded model which grounds the\nresponse prediction on the predicted span instead of the full document. With\nthese approaches, we obtain significant improvements in both subtasks compared\nto the baseline.",
    "descriptor": "\nComments: Accepted by 1st DialDoc Workshop at ACL-IJCNLP 2021\n",
    "authors": [
      "Nico Daheim",
      "David Thulke",
      "Christian Dugast",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07275"
  },
  {
    "id": "arXiv:2106.07277",
    "title": "Ontological Entities for Planning and Describing Cultural Heritage 3D  Models Creation",
    "abstract": "In the last decades the rapid development of technologies and methodologies\nin the field of digitization and 3D modelling has led to an increasing\nproliferation of 3D technologies in the Cultural Heritage domain. Despite the\ngreat potential of 3D digital heritage, the \"special effects\" of 3D may often\noverwhelm its importance in research. Projects and consortia of scholars have\ntried to put order in the different fields of application of these\ntechnologies, providing guidelines and proposing workflows. The use of computer\ngraphics as an effective methodology for CH research and communication\nhighlighted the need of transparent provenance data to properly document\ndigital assets and understand the degree of scientific quality and reliability\nof their outcomes. The building and release of provenance knowledge, consisting\nin the complete formal documentation of each phase of the process, is therefore\nof fundamental importance to ensure its repeatability and to guarantee the\nintegration and interoperability of the generated metadata on the Semantic Web.\nThis paper proposes a methodology for documenting the planning and creation of\n3D models used in archaeology and Cultural Heritage, by means of an application\nprofile based on the CIDOC CRM ecosystem and other international standards.",
    "descriptor": "\nComments: Submitted to ACM Journal on Computing and Cultural Heritage (JOCCH) 2021. 20 pages, 8 figures\n",
    "authors": [
      "Nicola Amico",
      "Achille Felicetti"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.07277"
  },
  {
    "id": "arXiv:2106.07278",
    "title": "Which Mutual-Information Representation Learning Objectives are  Sufficient for Control?",
    "abstract": "Mutual information maximization provides an appealing formalism for learning\nrepresentations of data. In the context of reinforcement learning (RL), such\nrepresentations can accelerate learning by discarding irrelevant and redundant\ninformation, while retaining the information necessary for control. Much of the\nprior work on these methods has addressed the practical difficulties of\nestimating mutual information from samples of high-dimensional observations,\nwhile comparatively less is understood about which mutual information\nobjectives yield representations that are sufficient for RL from a theoretical\nperspective. In this paper, we formalize the sufficiency of a state\nrepresentation for learning and representing the optimal policy, and study\nseveral popular mutual-information based objectives through this lens.\nSurprisingly, we find that two of these objectives can yield insufficient\nrepresentations given mild and common assumptions on the structure of the MDP.\nWe corroborate our theoretical results with empirical experiments on a\nsimulated game environment with visual observations.",
    "descriptor": "\nComments: 18 pages, 11 figures\n",
    "authors": [
      "Kate Rakelly",
      "Abhishek Gupta",
      "Carlos Florensa",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07278"
  },
  {
    "id": "arXiv:2106.07283",
    "title": "Attention-based Domain Adaptation for Single Stage Detectors",
    "abstract": "While domain adaptation has been used to improve the performance of object\ndetectors when the training and test data follow different distributions,\nprevious work has mostly focused on two-stage detectors. This is because their\nuse of region proposals makes it possible to perform local adaptation, which\nhas been shown to significantly improve the adaptation effectiveness. Here, by\ncontrast, we target single-stage architectures, which are better suited to\nresource-constrained detection than two-stage ones but do not provide region\nproposals. To nonetheless benefit from the strength of local adaptation, we\nintroduce an attention mechanism that lets us identify the important regions on\nwhich adaptation should focus. Our approach is generic and can be integrated\ninto any single-stage detector. We demonstrate this on standard benchmark\ndatasets by applying it to both SSD and YOLO. Furthermore, for an equivalent\nsingle-stage architecture, our method outperforms the state-of-the-art domain\nadaptation technique even though it was designed specifically for this\nparticular detector.",
    "descriptor": "",
    "authors": [
      "Vidit",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07283"
  },
  {
    "id": "arXiv:2106.07285",
    "title": "Probing Pre-Trained Language Models for Disease Knowledge",
    "abstract": "Pre-trained language models such as ClinicalBERT have achieved impressive\nresults on tasks such as medical Natural Language Inference. At first glance,\nthis may suggest that these models are able to perform medical reasoning tasks,\nsuch as mapping symptoms to diseases. However, we find that standard benchmarks\nsuch as MedNLI contain relatively few examples that require such forms of\nreasoning. To better understand the medical reasoning capabilities of existing\nlanguage models, in this paper we introduce DisKnE, a new benchmark for Disease\nKnowledge Evaluation. To construct this benchmark, we annotated each positive\nMedNLI example with the types of medical reasoning that are needed. We then\ncreated negative examples by corrupting these positive examples in an\nadversarial way. Furthermore, we define training-test splits per disease,\nensuring that no knowledge about test diseases can be learned from the training\ndata, and we canonicalize the formulation of the hypotheses to avoid the\npresence of artefacts. This leads to a number of binary classification\nproblems, one for each type of reasoning and each disease. When analysing\npre-trained models for the clinical/biomedical domain on the proposed\nbenchmark, we find that their performance drops considerably.",
    "descriptor": "\nComments: Accepted by ACL 2021 Findings\n",
    "authors": [
      "Israa Alghanmi",
      "Luis Espinosa-Anke",
      "Steven Schockaert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07285"
  },
  {
    "id": "arXiv:2106.07286",
    "title": "TimeLens: Event-based Video Frame Interpolation",
    "abstract": "State-of-the-art frame interpolation methods generate intermediate frames by\ninferring object motions in the image from consecutive key-frames. In the\nabsence of additional information, first-order approximations, i.e. optical\nflow, must be used, but this choice restricts the types of motions that can be\nmodeled, leading to errors in highly dynamic scenarios. Event cameras are novel\nsensors that address this limitation by providing auxiliary visual information\nin the blind-time between frames. They asynchronously measure per-pixel\nbrightness changes and do this with high temporal resolution and low latency.\nEvent-based frame interpolation methods typically adopt a synthesis-based\napproach, where predicted frame residuals are directly applied to the\nkey-frames. However, while these approaches can capture non-linear motions they\nsuffer from ghosting and perform poorly in low-texture regions with few events.\nThus, synthesis-based and flow-based approaches are complementary. In this\nwork, we introduce Time Lens, a novel indicates equal contribution method that\nleverages the advantages of both. We extensively evaluate our method on three\nsynthetic and two real benchmarks where we show an up to 5.21 dB improvement in\nterms of PSNR over state-of-the-art frame-based and event-based methods.\nFinally, we release a new large-scale dataset in highly dynamic scenarios,\naimed at pushing the limits of existing methods.",
    "descriptor": "",
    "authors": [
      "Stepan Tulyakov",
      "Daniel Gehrig",
      "Stamatios Georgoulis",
      "Julius Erbach",
      "Mathias Gehrig",
      "Yuanyou Li",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07286"
  },
  {
    "id": "arXiv:2106.07287",
    "title": "Data Science Methodologies: Current Challenges and Future Approaches",
    "abstract": "Data science has employed great research efforts in developing advanced\nanalytics, improving data models and cultivating new algorithms. However, not\nmany authors have come across the organizational and socio-technical challenges\nthat arise when executing a data science project: lack of vision and clear\nobjectives, a biased emphasis on technical issues, a low level of maturity for\nad-hoc projects and the ambiguity of roles in data science are among these\nchallenges. Few methodologies have been proposed on the literature that tackle\nthese type of challenges, some of them date back to the mid-1990, and\nconsequently they are not updated to the current paradigm and the latest\ndevelopments in big data and machine learning technologies. In addition, fewer\nmethodologies offer a complete guideline across team, project and data &\ninformation management. In this article we would like to explore the necessity\nof developing a more holistic approach for carrying out data science projects.\nWe first review methodologies that have been presented on the literature to\nwork on data science projects and classify them according to the their focus:\nproject, team, data and information management. Finally, we propose a\nconceptual framework containing general characteristics that a methodology for\nmanaging data science projects with a holistic point of view should have. This\nframework can be used by other researchers as a roadmap for the design of new\ndata science methodologies or the updating of existing ones.",
    "descriptor": "\nComments: 23 pages, 23 figures, 5 tables\n",
    "authors": [
      "I\u00f1igo Martinez",
      "Elisabeth Viles",
      "Igor G. Olaizola"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07287"
  },
  {
    "id": "arXiv:2106.07288",
    "title": "Learning-Aided Heuristics Design for Storage System",
    "abstract": "Computer systems such as storage systems normally require transparent\nwhite-box algorithms that are interpretable for human experts. In this work, we\npropose a learning-aided heuristic design method, which automatically generates\nhuman-readable strategies from Deep Reinforcement Learning (DRL) agents. This\nmethod benefits from the power of deep learning but avoids the shortcoming of\nits black-box property. Besides the white-box advantage, experiments in our\nstorage productions resource allocation scenario also show that this solution\noutperforms the systems default settings and the elaborately handcrafted\nstrategy by human experts.",
    "descriptor": "",
    "authors": [
      "Yingtian Tang",
      "Han Lu",
      "Xijun Li",
      "Lei Chen",
      "Mingxuan Yuan",
      "Jia Zeng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07288"
  },
  {
    "id": "arXiv:2106.07289",
    "title": "Decentralized Personalized Federated Min-Max Problems",
    "abstract": "Personalized Federated Learning has recently seen tremendous progress,\nallowing the design of novel machine learning applications preserving privacy\nof the data used for training. Existing theoretical results in this field\nmainly focus on distributed optimization under minimization problems. This\npaper is the first to study PFL for saddle point problems, which cover a\nbroader class of optimization tasks and are thus of more relevance for\napplications than the minimization. In this work, we consider a recently\nproposed PFL setting with the mixing objective function, an approach combining\nthe learning of a global model together with local distributed learners. Unlike\nmost of the previous papers, which considered only the centralized setting, we\nwork in a more general and decentralized setup. This allows to design and to\nanalyze more practical and federated ways to connect devices to the network. We\npresent two new algorithms for our problem. A theoretical analysis of the\nmethods is presented for smooth (strongly-)convex-(strongly-)concave saddle\npoint problems. We also demonstrate the effectiveness of our problem\nformulation and the proposed algorithms on experiments with neural networks\nwith adversarial noise.",
    "descriptor": "",
    "authors": [
      "Aleksandr Beznosikov",
      "Vadim Sushko",
      "Abdurakhmon Sadiev",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07289"
  },
  {
    "id": "arXiv:2106.07296",
    "title": "RRULES: An improvement of the RULES rule-based classifier",
    "abstract": "RRULES is presented as an improvement and optimization over RULES, a simple\ninductive learning algorithm for extracting IF-THEN rules from a set of\ntraining examples. RRULES optimizes the algorithm by implementing a more\neffective mechanism to detect irrelevant rules, at the same time that checks\nthe stopping conditions more often. This results in a more compact rule set\ncontaining more general rules which prevent overfitting the training set and\nobtain a higher test accuracy. Moreover, the results show that RRULES\noutperforms the original algorithm by reducing the coverage rate up to a factor\nof 7 while running twice or three times faster consistently over several\ndatasets.",
    "descriptor": "\nComments: 6 pages, 2 algorithms\n",
    "authors": [
      "Rafel Palliser-Sans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07296"
  },
  {
    "id": "arXiv:2106.07297",
    "title": "Node Classification Meets Link Prediction on Knowledge Graphs",
    "abstract": "Node classification and link prediction are widely studied tasks in graph\nrepresentation learning. While both transductive node classification and link\nprediction operate over a single input graph, they are studied in isolation so\nfar, which leads to discrepancies. Node classification models take as input a\ngraph with node features and incomplete node labels, and implicitly assume that\nthe input graph is relationally complete, i.e., no edges are missing from the\ninput graph. This is in sharp contrast with link prediction models that are\nsolely motivated by the relational incompleteness of the input graph which does\nnot have any node features. We propose a unifying perspective and study the\nproblems of (i) transductive node classification over incomplete graphs and\n(ii) link prediction over graphs with node features. We propose an extension to\nan existing box embedding model, and show that this model is fully expressive,\nand can solve both of these tasks in an end-to-end fashion. To empirically\nevaluate our model, we construct a knowledge graph with node features, which is\nchallenging both for node classification and link prediction. Our model\nperforms very strongly when compared to the respective state-of-the-art models\nfor node classification and link prediction on this dataset and shows the\nimportance of a unified perspective for node classification and link prediction\non knowledge graphs.",
    "descriptor": "",
    "authors": [
      "Ralph Abboud",
      "\u0130smail \u0130lkan Ceylan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07297"
  },
  {
    "id": "arXiv:2106.07299",
    "title": "Dynamic Based Estimator for UAVs with Real-time Identification Using DNN  and the Modified Relay Feedback Test",
    "abstract": "Control performance of Unmanned Aerial Vehicles (UAVs) is directly affected\nby their ability to estimate their states accurately. With the increasing\npopularity of autonomous UAV solutions in real world applications, it is\nimperative to develop robust adaptive estimators that can ameliorate sensor\nnoises in low-cost UAVs. Utilizing the knowledge of UAV dynamics in estimation\ncan provide significant advantages, but remains challenging due to the complex\nand expensive pre-flight experiments required to obtain UAV dynamic parameters.\nIn this paper, we propose two decoupled dynamic model based Extended Kalman\nFilters for UAVs, that provide high rate estimates for position, and velocity\nof rotational and translational states, as well as filtered inertial\nacceleration. The dynamic model parameters are estimated online using the Deep\nNeural Network and Modified Relay Feedback Test (DNN-MRFT) framework, without\nrequiring any prior knowledge of the UAV physical parameters. The designed\nfilters with real-time identified process model parameters are tested\nexperimentally and showed two advantages. Firstly, smooth and lag-free\nestimates of the UAV rotational speed and inertial acceleration are obtained,\nand used to improve the closed loop system performance, reducing the controller\naction by over 6 %. Secondly, the proposed approach enabled the UAV to track\naggressive trajectories with low rate position measurements, a task usually\ninfeasible under those conditions. The experimental data shows that we achieved\nestimation performance matching other methods that requires full knowledge of\nthe UAV parameters.",
    "descriptor": "",
    "authors": [
      "Mohamad Wahbah",
      "Mohamad Chehadeh",
      "Yahya Zweiri"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07299"
  },
  {
    "id": "arXiv:2106.07300",
    "title": "Guaranteeing Half-Maximin Shares Under Cardinality Constraints",
    "abstract": "We study the problem of fair allocation of a set of indivisible items among\nagents with additive valuations, under cardinality constraints. In this setting\nthe items are partitioned into categories, each with its own limit on the\nnumber of items it may contribute to any bundle. One example of such a problem\nis allocating seats in a multitrack conference. We consider the fairness\nmeasure known as the maximin share (MMS) guarantee, and propose a novel\npolynomial-time algorithm for finding $1/2$-approximate MMS allocations. We\nextend the notions and algorithms related to ordered and reduced instances to\nwork with cardinality constraints, and combine these with a bag filling style\nprocedure. Our algorithm improves on that of Biswas and Barman (IJCAI-18), with\nits approximation ratio of $1/3$. We also present an optimizing algorithm,\nwhich for each instance, instead of fixing $\\alpha = 1/2$, uses bisection to\nfind the largest $\\alpha$ for which our algorithm obtains a valid\n$\\alpha$-approximate MMS allocation. Numerical tests show that our algorithm\nfinds strictly better approximations than the guarantee of $1/2$ for most\ninstances, in many cases surpassing $3/5$. The optimizing version of the\nalgorithm produces MMS allocations in a comparable number of instances to that\nof Biswas and Barman's algorithm, on average achieving a better approximation\nwhen MMS is not obtained.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Halvard Hummel",
      "Magnus Lie Hetland"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07300"
  },
  {
    "id": "arXiv:2106.07303",
    "title": "iNNformant: Boundary Samples as Telltale Watermarks",
    "abstract": "Boundary samples are special inputs to artificial neural networks crafted to\nidentify the execution environment used for inference by the resulting output\nlabel. The paper presents and evaluates algorithms to generate transparent\nboundary samples. Transparency refers to a small perceptual distortion of the\nhost signal (i.e., a natural input sample). For two established image\nclassifiers, ResNet on FMNIST and CIFAR10, we show that it is possible to\ngenerate sets of boundary samples which can identify any of four tested\nmicroarchitectures. These sets can be built to not contain any sample with a\nworse peak signal-to-noise ratio than 70dB. We analyze the relationship between\nsearch complexity and resulting transparency.",
    "descriptor": "\nComments: Will be presented at IH&MMSEC '21\n",
    "authors": [
      "Alexander Schl\u00f6gl",
      "Tobias Kupek",
      "Rainer B\u00f6hme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.07303"
  },
  {
    "id": "arXiv:2106.07306",
    "title": "Constraining Linear-chain CRFs to Regular Languages",
    "abstract": "In structured prediction, a major challenge for models is to represent the\ninterdependencies within their output structures. For the common case where\noutputs are structured as a sequence, linear-chain conditional random fields\n(CRFs) are a widely used model class which can learn local dependencies in\noutput sequences. However, the CRF's Markov assumption makes it impossible for\nthese models to capture nonlocal dependencies, and standard CRFs are unable to\nrespect nonlocal constraints of the data (such as global arity constraints on\noutput labels). We present a generalization of CRFs that can enforce a broad\nclass of constraints, including nonlocal ones, by specifying the space of\npossible output structures as a regular language $\\mathcal{L}$. The resulting\nregular-constrained CRF (RegCCRF) has the same formal properties as a standard\nCRF, but assigns zero probability to all label sequences not in $\\mathcal{L}$.\nNotably, RegCCRFs can incorporate their constraints during training, while\nrelated models only enforce constraints during decoding. We prove that\nconstrained training is never worse than constrained decoding, and show using\nsynthetic data that it can be substantially better in practice. Additionally,\nwe demonstrate a practical benefit on downstream tasks by incorporating a\nRegCCRF into a deep neural model for semantic role labeling, exceeding\nstate-of-the-art results on a standard dataset.",
    "descriptor": "",
    "authors": [
      "Sean Papay",
      "Roman Klinger",
      "Sebastian Pad\u00f3"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07306"
  },
  {
    "id": "arXiv:2106.07307",
    "title": "A Recipe for Social Media Analysis",
    "abstract": "The Ubiquitous nature of smartphones has significantly increased the use of\nsocial media platforms, such as Facebook, Twitter, TikTok, and LinkedIn, etc.,\namong the public, government, and businesses. Facebook generated ~70 billion\nUSD in 2019 in advertisement revenues alone, a ~27% increase from the previous\nyear. Social media has also played a strong role in outbreaks of social\nprotests responsible for political changes in different countries. As we can\nsee from the above examples, social media plays a big role in business\nintelligence and international politics. In this paper, we present and discuss\na high-level functional intelligence model (recipe) of Social Media Analysis\n(SMA). This model synthesizes the input data and uses operational intelligence\nto provide actionable recommendations. In addition, it also matches the\nsynthesized function of the experiences and learning gained from the\nenvironment. The SMA model presented is independent of the application domain,\nand can be applied to different domains, such as Education, Healthcare and\nGovernment, etc. Finally, we also present some of the challenges faced by SMA\nand how the SMA model presented in this paper solves them.",
    "descriptor": "",
    "authors": [
      "Shahid Alam",
      "Juvariya Khan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.07307"
  },
  {
    "id": "arXiv:2106.07310",
    "title": "Pixel Sampling for Style Preserving Face Pose Editing",
    "abstract": "The existing auto-encoder based face pose editing methods primarily focus on\nmodeling the identity preserving ability during pose synthesis, but are less\nable to preserve the image style properly, which refers to the color,\nbrightness, saturation, etc. In this paper, we take advantage of the well-known\nfrontal/profile optical illusion and present a novel two-stage approach to\nsolve the aforementioned dilemma, where the task of face pose manipulation is\ncast into face inpainting. By selectively sampling pixels from the input face\nand slightly adjust their relative locations with the proposed ``Pixel\nAttention Sampling\" module, the face editing result faithfully keeps the\nidentity information as well as the image style unchanged. By leveraging\nhigh-dimensional embedding at the inpainting stage, finer details are\ngenerated. Further, with the 3D facial landmarks as guidance, our method is\nable to manipulate face pose in three degrees of freedom, i.e., yaw, pitch, and\nroll, resulting in more flexible face pose editing than merely controlling the\nyaw angle as usually achieved by the current state-of-the-art. Both the\nqualitative and quantitative evaluations validate the superiority of the\nproposed approach.",
    "descriptor": "",
    "authors": [
      "Xiangnan Yin",
      "Di Huang",
      "Hongyu Yang",
      "Zehua Fu",
      "Yunhong Wang",
      "Liming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07310"
  },
  {
    "id": "arXiv:2106.07313",
    "title": "Smart Gradient -- An Adaptive Technique for Improving Gradient  Estimation",
    "abstract": "Computing the gradient of a function provides fundamental information about\nits behavior. This information is essential for several applications and\nalgorithms across various fields. One common application that require gradients\nare optimization techniques such as stochastic gradient descent, Newton's\nmethod and trust region methods. However, these methods usually requires a\nnumerical computation of the gradient at every iteration of the method which is\nprone to numerical errors. We propose a simple limited-memory technique for\nimproving the accuracy of a numerically computed gradient in this\ngradient-based optimization framework by exploiting (1) a coordinate\ntransformation of the gradient and (2) the history of previously taken descent\ndirections. The method is verified empirically by extensive experimentation on\nboth test functions and on real data applications. The proposed method is\nimplemented in the R package smartGrad and in C++.",
    "descriptor": "",
    "authors": [
      "Esmail Abdul Fattah",
      "Janet Van Niekerk",
      "Haavard Rue"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07313"
  },
  {
    "id": "arXiv:2106.07314",
    "title": "Computer Vision Tool for Detection, Mapping and Fault Classification of  PV Modules in Aerial IR Videos",
    "abstract": "Increasing deployment of photovoltaics (PV) plants demands for cheap and fast\ninspection. A viable tool for this task is thermographic imaging by unmanned\naerial vehicles (UAV). In this work, we develop a computer vision tool for the\nsemi-automatic extraction of PV modules from thermographic UAV videos. We use\nit to curate a dataset containing 4.3 million IR images of 107842 PV modules\nfrom thermographic videos of seven different PV plants. To demonstrate its use\nfor automated PV plant inspection, we train a ResNet-50 to classify ten common\nmodule anomalies with more than 90 % test accuracy. Experiments show that our\ntool generalizes well to different PV plants. It successfully extracts PV\nmodules from 512 out of 561 plant rows. Failures are mostly due to an\ninappropriate UAV trajectory and erroneous module segmentation. Including all\nmanual steps our tool enables inspection of 3.5 MW p to 9 MW p of PV\ninstallations per day, potentially scaling to multi-gigawatt plants due to its\nparallel nature. While we present an effective method for automated PV plant\ninspection, we are also confident that our approach helps to meet the growing\ndemand for large thermographic datasets for machine learning tasks, such as\npower prediction or unsupervised defect identification.",
    "descriptor": "",
    "authors": [
      "Lukas Bommes",
      "Tobias Pickel",
      "Claudia Buerhop-Lutz",
      "Jens Hauch",
      "Christoph Brabec",
      "Ian Marius Peters"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07314"
  },
  {
    "id": "arXiv:2106.07316",
    "title": "Exploiting Sentence-Level Representations for Passage Ranking",
    "abstract": "Recently, pre-trained contextual models, such as BERT, have shown to perform\nwell in language related tasks. We revisit the design decisions that govern the\napplicability of these models for the passage re-ranking task in open-domain\nquestion answering. We find that common approaches in the literature rely on\nfine-tuning a pre-trained BERT model and using a single, global representation\nof the input, discarding useful fine-grained relevance signals in token- or\nsentence-level representations. We argue that these discarded tokens hold\nuseful information that can be leveraged. In this paper, we explicitly model\nthe sentence-level representations by using Dynamic Memory Networks (DMNs) and\nconduct empirical evaluation to show improvements in passage re-ranking over\nfine-tuned vanilla BERT models by memory-enhanced explicit sentence modelling\non a diverse set of open-domain QA datasets. We further show that freezing the\nBERT model and only training the DMN layer still comes close to the original\nperformance, while improving training efficiency drastically. This indicates\nthat the usual fine-tuning step mostly helps to aggregate the inherent\ninformation in a single output token, as opposed to adapting the whole model to\nthe new task, and only achieves rather small gains.",
    "descriptor": "",
    "authors": [
      "Jurek Leonhardt",
      "Fabian Beringer",
      "Avishek Anand"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.07316"
  },
  {
    "id": "arXiv:2106.07317",
    "title": "Automated Machine Learning Techniques for Data Streams",
    "abstract": "Automated machine learning techniques benefited from tremendous research\nprogress in recently. These developments and the continuous-growing demand for\nmachine learning experts led to the development of numerous AutoML tools.\nHowever, these tools assume that the entire training dataset is available\nupfront and that the underlying distribution does not change over time. These\nassumptions do not hold in a data stream mining setting where an unbounded\nstream of data cannot be stored and is likely to manifest concept drift.\nIndustry applications of machine learning on streaming data become more popular\ndue to the increasing adoption of real-time streaming patterns in IoT,\nmicroservices architectures, web analytics, and other fields. The research\nsummarized in this paper surveys the state-of-the-art open-source AutoML tools,\napplies them to data collected from streams, and measures how their performance\nchanges over time. For comparative purposes, batch, batch incremental and\ninstance incremental estimators are applied and compared. Moreover, a\nmeta-learning technique for online algorithm selection based on meta-feature\nextraction is proposed and compared while model replacement and continual\nAutoML techniques are discussed. The results show that off-the-shelf AutoML\ntools can provide satisfactory results but in the presence of concept drift,\ndetection or adaptation techniques have to be applied to maintain the\npredictive accuracy over time.",
    "descriptor": "\nComments: 11 pages, 14 figures, Originally published as this https URL at the 32nd Twente Student Conference on IT Jan. 31st, 2019, Enschede, The Netherlands, Supervised by: dr. Doina Bucur, dr. Claudio Pinho Rebelo de S\\'a\n",
    "authors": [
      "Alexandru-Ionut Imbrea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07317"
  },
  {
    "id": "arXiv:2106.07318",
    "title": "Multiobjective Bilevel Evolutionary Approach for Off-Grid  Direction-of-Arrival Estimation",
    "abstract": "The source number identification is an essential step in direction-of-arrival\n(DOA) estimation. Existing methods may provide a wrong source number due to\ninferior statistical properties (in low SNR or limited snapshots) or modeling\nerrors (caused by relaxing sparse penalties), especially in impulsive noise. To\naddress this issue, we propose a novel idea of simultaneous source number\nidentification and DOA estimation. We formulate a multiobjective off-grid DOA\nestimation model to realize this idea, by which the source number can be\nautomatically identified together with DOA estimation. In particular, the\nsource number is properly exploited by the $l_0$ norm of impinging signals\nwithout relaxations, guaranteeing accuracy. Furthermore, we design a\nmultiobjective bilevel evolutionary algorithm to solve the proposed model. The\nsource number identification and sparse recovery are simultaneously optimized\nat the on-grid (lower) level. A forward search strategy is developed to further\nrefine the grid at the off-grid (upper) level. This strategy does not need\nlinear approximations and can eliminate the off-grid gap with low computational\ncomplexity. Simulation results demonstrate the outperformance of our method in\nterms of source number and root mean square error.",
    "descriptor": "\nComments: This paper has been submitted to an Elsevier journal for peer-review\n",
    "authors": [
      "Bai Yan",
      "Qi Zhao",
      "Jin Zhang",
      "J. Andrew Zhang",
      "Xin Yao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.07318"
  },
  {
    "id": "arXiv:2106.07319",
    "title": "Coresets for constrained k-median and k-means clustering in low  dimensional Euclidean space",
    "abstract": "We study (Euclidean) $k$-median and $k$-means with constraints in the\nstreaming model.\nThere have been recent efforts to design unified algorithms to solve\nconstrained $k$-means problems without using knowledge of the specific\nconstraint at hand aside from mild assumptions like the polynomial\ncomputability of feasibility under the constraint (compute if a clustering\nsatisfies the constraint) or the presence of an efficient assignment oracle\n(given a set of centers, produce an optimal assignment of points to the centers\nwhich satisfies the constraint). These algorithms have a running time\nexponential in $k$, but can be applied to a wide range of constraints.\nWe demonstrate that a technique proposed in 2019 for solving a specific\nconstrained streaming $k$-means problem, namely fair $k$-means clustering,\nactually implies streaming algorithms for all these constraints. These work for\nlow dimensional Euclidean space. [Note that there are more algorithms for\nstreaming fair $k$-means today, in particular they exist for high dimensional\nspaces now as well.]",
    "descriptor": "",
    "authors": [
      "Melanie Schmidt",
      "Julian Wargalla"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07319"
  },
  {
    "id": "arXiv:2106.07321",
    "title": "No Free Lunch: Microservice Practices Reconsidered in Industry",
    "abstract": "Microservice architecture advocates a number of technologies and practices\nsuch as lightweight container, container orchestration, and DevOps, with the\npromised benefits of faster delivery, improved scalability, and greater\nautonomy. However, microservice systems implemented in industry vary a lot in\nterms of adopted practices and achieved benefits, drastically different from\nwhat is advocated in the literature. In this article, we conduct an empirical\nstudy, including an online survey with 51 responses and 14 interviews for\nexperienced microservice experts to advance our understanding regarding to\nmicroservice practices in industry. As a part of our findings, the empirical\nstudy clearly revealed three levels of maturity of microservice systems (from\nbasic to advanced): independent development and deployment, high scalability\nand availability, and service ecosystem, categorized by the fulfilled benefits\nof microservices. We also identify 11 practical issues that constrain the\nmicroservice capabilities of organizations. For each issue, we summarize the\npractices that have been explored and adopted in industry, along with the\nremaining challenges. Our study can help practitioners better position their\nmicroservice systems and determine what infrastructures and capabilities are\nworth investing. Our study can also help researchers better understand\nindustrial microservice practices and identify useful research problems.",
    "descriptor": "",
    "authors": [
      "Qilin Xiang",
      "Xin Peng",
      "Chuan He",
      "Hanzhang Wang",
      "Tao Xie",
      "Dewei Liu",
      "Gang Zhang",
      "Yuanfang Cai"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.07321"
  },
  {
    "id": "arXiv:2106.07324",
    "title": "Numerical Computations for Bifurcations and Spectral Stability of  Solitary Waves in Coupled Nonlinear Schr\u00f6dinger Equations",
    "abstract": "We numerically study solitary waves in the coupled nonlinear Schr\\\"odinger\nequations. We detect pitchfork bifurcations of the fundamental solitary wave\nand compute eigenvalues and eigenfunctions of the corresponding eigenvalue\nproblems to determine the spectral stability of solitary waves born at the\npitchfork bifurcations. Our numerical results demonstrate the theoretical ones\nwhich the authors obtained recently. We also compute generalized eigenfunctions\nassociated with the zero eigenvalue for the bifurcated solitary wave exhibiting\na saddle-node bifurcation, and show that it does not change its stability type\nat the saddle-node bifurcation point.",
    "descriptor": "",
    "authors": [
      "Kazuyuki Yagasaki",
      "Shotaro Yamazoe"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07324"
  },
  {
    "id": "arXiv:2106.07327",
    "title": "Variational Quanvolutional Neural Networks with enhanced image encoding",
    "abstract": "Image classification is an important task in various machine learning\napplications. In recent years, a number of classification methods based on\nquantum machine learning and different quantum image encoding techniques have\nbeen proposed. In this paper, we study the effect of three different quantum\nimage encoding approaches on the performance of a convolution-inspired hybrid\nquantum-classical image classification algorithm called quanvolutional neural\nnetwork (QNN). We furthermore examine the effect of variational - i.e.\ntrainable - quantum circuits on the classification results. Our experiments\nindicate that some image encodings are better suited for variational circuits.\nHowever, our experiments show as well that there is not one best image\nencoding, but that the choice of the encoding depends on the specific\nconstraints of the application.",
    "descriptor": "",
    "authors": [
      "Denny Mattern",
      "Darya Martyniuk",
      "Henri Willems",
      "Fabian Bergmann",
      "Adrian Paschke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07327"
  },
  {
    "id": "arXiv:2106.07329",
    "title": "On-Policy Deep Reinforcement Learning for the Average-Reward Criterion",
    "abstract": "We develop theory and algorithms for average-reward on-policy Reinforcement\nLearning (RL). We first consider bounding the difference of the long-term\naverage reward for two policies. We show that previous work based on the\ndiscounted return (Schulman et al., 2015; Achiam et al., 2017) results in a\nnon-meaningful bound in the average-reward setting. By addressing the\naverage-reward criterion directly, we then derive a novel bound which depends\non the average divergence between the two policies and Kemeny's constant. Based\non this bound, we develop an iterative procedure which produces a sequence of\nmonotonically improved policies for the average reward criterion. This\niterative procedure can then be combined with classic DRL (Deep Reinforcement\nLearning) methods, resulting in practical DRL algorithms that target the\nlong-run average reward criterion. In particular, we demonstrate that\nAverage-Reward TRPO (ATRPO), which adapts the on-policy TRPO algorithm to the\naverage-reward criterion, significantly outperforms TRPO in the most\nchallenging MuJuCo environments.",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Yiming Zhang",
      "Keith W. Ross"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07329"
  },
  {
    "id": "arXiv:2106.07333",
    "title": "Deep Transfer Learning for Brain Magnetic Resonance Image Multi-class  Classification",
    "abstract": "Magnetic Resonance Imaging (MRI) is a principal diagnostic approach used in\nthe field of radiology to create images of the anatomical and physiological\nstructure of patients. MRI is the prevalent medical imaging practice to find\nabnormalities in soft tissues. Traditionally they are analyzed by a radiologist\nto detect abnormalities in soft tissues, especially the brain. The process of\ninterpreting a massive volume of patient's MRI is laborious. Hence, the use of\nMachine Learning methodologies can aid in detecting abnormalities in soft\ntissues with considerable accuracy. In this research, we have curated a novel\ndataset and developed a framework that uses Deep Transfer Learning to perform a\nmulti-classification of tumors in the brain MRI images. In this paper, we\nadopted the Deep Residual Convolutional Neural Network (ResNet50) architecture\nfor the experiments along with discriminative learning techniques to train the\nmodel. Using the novel dataset and two publicly available MRI brain datasets,\nthis proposed approach attained a classification accuracy of 86.40\\% on the\ncurated dataset, 93.80\\% on the Harvard Whole Brain Atlas dataset, and 97.05\\%\naccuracy on the School of Biomedical Engineering dataset. Results of our\nexperiments significantly demonstrate our proposed framework for transfer\nlearning is a potential and effective method for brain tumor\nmulti-classification tasks.",
    "descriptor": "\nComments: This work was carried out as a collaboration between the Department of Computer Science and Engineering -- the University of Dhaka and the National Institute of Neuroscience (NINS), Bangladesh. We created a novel neurological discord dataset of 37 disease categories\n",
    "authors": [
      "Yusuf Brima",
      "Mossadek Hossain Kamal Tushar",
      "Upama Kabir",
      "Tariqul Islam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07333"
  },
  {
    "id": "arXiv:2106.07336",
    "title": "Entropy-Based Proofs of Combinatorial Results on Bipartite Graphs",
    "abstract": "This work considers new entropy-based proofs of some known, or otherwise\nrefined, combinatorial bounds for bipartite graphs. These include upper bounds\non the number of the independent sets, lower bounds on the minimal number of\ncolors in constrained edge coloring, and lower bounds on the number of walks of\na given length in bipartite graphs. The proofs of these combinatorial results\nrely on basic properties of the Shannon entropy.",
    "descriptor": "\nComments: To appear in the Proceedings of 2021 IEEE International Symposium on Information Theory, July 12-20, 2021 (virtual symposium). arXiv admin note: text overlap with arXiv:2012.12107\n",
    "authors": [
      "Igal Sason"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.07336"
  },
  {
    "id": "arXiv:2106.07338",
    "title": "Neighborhood Rough Set based Multi-document Summarization",
    "abstract": "This research paper proposes a novel Neighbourhood Rough Set based approach\nfor supervised Multi-document Text Summarization (MDTS) with analysis and\nimpact on the summarization results for MDTS. Here, Rough Set based LERS\nalgorithm is improved using Neighborhood Rough Set which is itself a novel\ncombination called Neighborhood-LERS to be experimented for evaluations of\nefficacy and efficiency. In this paper, we shall apply and evaluate the\nproposed Neighborhood-LERS for Multi-document Summarization which here is\nproved experimentally to be superior to the base LERS technique for MDTS.",
    "descriptor": "\nComments: 7 pages, original paper not submitted anywhere else\n",
    "authors": [
      "Nidhika Yadav"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07338"
  },
  {
    "id": "arXiv:2106.07340",
    "title": "MathBERT: A Pre-trained Language Model for General NLP Tasks in  Mathematics Education",
    "abstract": "Due to the transfer learning nature of BERT model, researchers have achieved\nbetter performance than base BERT by further pre-training the original BERT on\na huge domain-specific corpus. Due to the special nature of mathematical texts\nwhich often contain math equations and symbols, the original BERT model\npre-trained on general English context will not fit Natural Language Processing\n(NLP) tasks in mathematical education well. Therefore, we propose MathBERT, a\nBERT pre-trained on large mathematical corpus including pre-k to graduate level\nmathematical content to tackle math-specific tasks. In addition, We generate a\ncustomized mathematical vocabulary to pre-train with MathBERT and compare the\nperformance to the MathBERT pre-trained with the original BERT vocabulary. We\nselect three important tasks in mathematical education such as knowledge\ncomponent, auto-grading, and knowledge tracing prediction to evaluate the\nperformance of MathBERT. Our experiments show that MathBERT outperforms the\nbase BERT by 2-9\\% margin. In some cases, MathBERT pre-trained with\nmathematical vocabulary is better than MathBERT trained with original\nvocabulary.To our best knowledge, MathBERT is the first pre-trained model for\ngeneral purpose mathematics education tasks.",
    "descriptor": "",
    "authors": [
      "Jia Tracy Shen",
      "Michiharu Yamashita",
      "Ethan Prihar",
      "Neil Heffernan",
      "Xintao Wu",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07340"
  },
  {
    "id": "arXiv:2106.07341",
    "title": "i-Pulse: A NLP based novel approach for employee engagement in logistics  organization",
    "abstract": "Although most logistics and freight forwarding organizations, in one way or\nanother, claim to have core values. The engagement of employees is a vast\nstructure that affects almost every part of the company's core environmental\nvalues. There is little theoretical knowledge about the relationship between\nfirms and the engagement of employees. Based on research literature, this paper\naims to provide a novel approach for insight around employee engagement in a\nlogistics organization by implementing deep natural language processing\nconcepts. The artificial intelligence-enabled solution named Intelligent Pulse\n(I-Pulse) can evaluate hundreds and thousands of pulse survey comments and\nprovides the actionable insights and gist of employee feedback. I-Pulse allows\nthe stakeholders to think in new ways in their organization, helping them to\nhave a powerful influence on employee engagement, retention, and efficiency.\nThis study is of corresponding interest to researchers and practitioners.",
    "descriptor": "\nComments: 11 Pages 7 Figures\n",
    "authors": [
      "Rachit Garg",
      "Arvind W Kiwelekar",
      "Laxman D Netak",
      "Akshay Ghodake"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07341"
  },
  {
    "id": "arXiv:2106.07343",
    "title": "Learning to Bridge Metric Spaces: Few-shot Joint Learning of Intent  Detection and Slot Filling",
    "abstract": "In this paper, we investigate few-shot joint learning for dialogue language\nunderstanding. Most existing few-shot models learn a single task each time with\nonly a few examples. However, dialogue language understanding contains two\nclosely related tasks, i.e., intent detection and slot filling, and often\nbenefits from jointly learning the two tasks. This calls for new few-shot\nlearning techniques that are able to capture task relations from only a few\nexamples and jointly learn multiple tasks. To achieve this, we propose a\nsimilarity-based few-shot learning scheme, named Contrastive Prototype Merging\nnetwork (ConProm), that learns to bridge metric spaces of intent and slot on\ndata-rich domains, and then adapt the bridged metric space to the specific\nfew-shot domain. Experiments on two public datasets, Snips and FewJoint, show\nthat our model significantly outperforms the strong baselines in one and five\nshots settings.",
    "descriptor": "\nComments: Accepted by ACL 2021 findings\n",
    "authors": [
      "Yutai Hou",
      "Yongkui Lai",
      "Cheng Chen",
      "Wanxiang Che",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07343"
  },
  {
    "id": "arXiv:2106.07344",
    "title": "Understanding Information Spreading Mechanisms During COVID-19 Pandemic  by Analyzing the Impact of Tweet Text and User Features for Retweet  Prediction",
    "abstract": "COVID-19 has affected the world economy and the daily life routine of almost\neveryone. It has been a hot topic on social media platforms such as Twitter,\nFacebook, etc. These social media platforms enable users to share information\nwith other users who can reshare this information, thus causing this\ninformation to spread. Twitter's retweet functionality allows users to share\nthe existing content with other users without altering the original content.\nAnalysis of social media platforms can help in detecting emergencies during\npandemics that lead to taking preventive measures. One such type of analysis is\npredicting the number of retweets for a given COVID-19 related tweet. Recently,\nCIKM organized a retweet prediction challenge for COVID-19 tweets focusing on\nusing numeric features only. However, our hypothesis is, tweet text may play a\nvital role in an accurate retweet prediction. In this paper, we combine numeric\nand text features for COVID-19 related retweet predictions. For this purpose,\nwe propose two CNN and RNN based models and evaluate the performance of these\nmodels on a publicly available TweetsCOV19 dataset using seven different\nevaluation metrics. Our evaluation results show that combining tweet text with\nnumeric features improves the performance of retweet prediction significantly.",
    "descriptor": "",
    "authors": [
      "Pervaiz Iqbal Khan",
      "Imran Razzak",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07344"
  },
  {
    "id": "arXiv:2106.07345",
    "title": "Self-Guided Contrastive Learning for BERT Sentence Representations",
    "abstract": "Although BERT and its variants have reshaped the NLP landscape, it still\nremains unclear how best to derive sentence embeddings from such pre-trained\nTransformers. In this work, we propose a contrastive learning method that\nutilizes self-guidance for improving the quality of BERT sentence\nrepresentations. Our method fine-tunes BERT in a self-supervised fashion, does\nnot rely on data augmentation, and enables the usual [CLS] token embeddings to\nfunction as sentence vectors. Moreover, we redesign the contrastive learning\nobjective (NT-Xent) and apply it to sentence representation learning. We\ndemonstrate with extensive experiments that our approach is more effective than\ncompetitive baselines on diverse sentence-related tasks. We also show it is\nefficient at inference and robust to domain shifts.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Taeuk Kim",
      "Kang Min Yoo",
      "Sang-goo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07345"
  },
  {
    "id": "arXiv:2106.07346",
    "title": "Query-Driven Topic Model",
    "abstract": "Topic modeling is an unsupervised method for revealing the hidden semantic\nstructure of a corpus. It has been increasingly widely adopted as a tool in the\nsocial sciences, including political science, digital humanities and\nsociological research in general. One desirable property of topic models is to\nallow users to find topics describing a specific aspect of the corpus. A\npossible solution is to incorporate domain-specific knowledge into topic\nmodeling, but this requires a specification from domain experts. We propose a\nnovel query-driven topic model that allows users to specify a simple query in\nwords or phrases and return query-related topics, thus avoiding tedious work\nfrom domain experts. Our proposed approach is particularly attractive when the\nuser-specified query has a low occurrence in a text corpus, making it difficult\nfor traditional topic models built on word cooccurrence patterns to identify\nrelevant topics. Experimental results demonstrate the effectiveness of our\nmodel in comparison with both classical topic models and neural topic models.",
    "descriptor": "\nComments: ACL2021 finding paper. For source code, see this https URL\n",
    "authors": [
      "Zheng Fang",
      "Yulan He",
      "Rob Procter"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07346"
  },
  {
    "id": "arXiv:2106.07347",
    "title": "Zipf Matrix Factorization : Matrix Factorization with Matthew Effect  Reduction",
    "abstract": "Recommender system recommends interesting items to users based on users' past\ninformation history. Researchers have been paying attention to improvement of\nalgorithmic performance such as MAE and precision@K. Major techniques such as\nmatrix factorization and learning to rank are optimized based on such\nevaluation metrics. However, the intrinsic Matthew Effect problem poses great\nthreat to the fairness of the recommender system, and the unfairness problem\ncannot be resolved by optimization of traditional metrics. In this paper, we\npropose a novel algorithm that incorporates Matthew Effect reduction with the\nmatrix factorization framework. We demonstrate that our approach can boost the\nfairness of the algorithm and enhances performance evaluated by traditional\nmetrics.",
    "descriptor": "",
    "authors": [
      "Hao Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.07347"
  },
  {
    "id": "arXiv:2106.07348",
    "title": "Is it a click bait? Let's predict using Machine Learning",
    "abstract": "In this era of digitisation, news reader tend to read news online. This is\nbecause, online media instantly provides access to a wide variety of content.\nThus, people don't have to wait for tomorrow's newspaper to know what's\nhappening today. Along with these virtues, online news have some vices as well.\nOne such vice is presence of social media posts (tweets) relating to news\narticles whose sole purpose is to draw attention of the users rather than\ndirecting them to read the actual content. Such posts are referred to as\nclickbaits. The objective of this project is to develop a system which would be\ncapable of predicting how likely are the social media posts (tweets) relating\nto new articles tend to be clickbait.",
    "descriptor": "\nComments: M.Tech Thesis defended at BITS, Pilani\n",
    "authors": [
      "Sohom Ghosh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.07348"
  },
  {
    "id": "arXiv:2106.07349",
    "title": "Using Integrated Gradients to explain Linguistic Acceptability learnt by  BERT",
    "abstract": "BERT has been a breakthrough in language understanding by leveraging the\nmulti-head self-attention mechanism in its architecture. To the best of our\nknowledge this work is the first to leverage Layer Integrated Gradients\nAttribution Scores (LIGAS) to explain the Linguistic Acceptability criteria\nthat are learnt by BERT on the Corpus of Linguistic Acceptability (CoLA)\nbenchmark dataset. Our experiments on 5 different categories of sentences lead\nto the following interesting findings: 1) LIGAS for Linguistically Acceptable\n(LA) sentences are significantly smaller in comparison to Linguistically\nUnacceptable (LUA) sentences, 2) There are specific subtrees of the\nConstituency Parse Tree (CPT) for LA and LUA sentences which contribute larger\nLIGAS, 3) Across the different categories of sentences we observed around 88%\nto 100% of the Correctly classified sentences had positive LIGAS, indicating a\nstrong positive relationship to the prediction confidence of the model, and 4)\nAround 57% of the Misclassified sentences had positive LIGAS, which we believe\ncan become correctly classified sentences if the LIGAS are parameterized in the\nloss function of the model.",
    "descriptor": "\nComments: 3 pages, 1 figure\n",
    "authors": [
      "Anmol Nayak",
      "Hari Prasad Timmapathini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07349"
  },
  {
    "id": "arXiv:2106.07350",
    "title": "THG: Transformer with Hyperbolic Geometry",
    "abstract": "Transformer model architectures have become an indispensable staple in deep\nlearning lately for their effectiveness across a range of tasks. Recently, a\nsurge of \"X-former\" models have been proposed which improve upon the original\nTransformer architecture. However, most of these variants make changes only\naround the quadratic time and memory complexity of self-attention, i.e. the dot\nproduct between the query and the key. What's more, they are calculate solely\nin Euclidean space. In this work, we propose a novel Transformer with\nHyperbolic Geometry (THG) model, which take the advantage of both Euclidean\nspace and Hyperbolic space. THG makes improvements in linear transformations of\nself-attention, which are applied on the input sequence to get the query and\nthe key, with the proposed hyperbolic linear. Extensive experiments on sequence\nlabeling task, machine reading comprehension task and classification task\ndemonstrate the effectiveness and generalizability of our model. It also\ndemonstrates THG could alleviate overfitting.",
    "descriptor": "\nComments: 6 pages,3 figures\n",
    "authors": [
      "Zhe Liu",
      "Yibin Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07350"
  },
  {
    "id": "arXiv:2106.07351",
    "title": "From Single Lane to Highways: Analyzing the Adoption of Multipath TCP in  the Internet",
    "abstract": "Multipath TCP (MPTCP) extends traditional TCP to enable simultaneous use of\nmultiple connection endpoints at the source and destination. MPTCP has been\nunder active development since its standardization in 2013, and more recently\nin February 2020, MPTCP was upstreamed to the Linux kernel.\nIn this paper, we provide the first broad analysis of MPTCPv0 in the\nInternet. We probe the entire IPv4 address space and an IPv6 hitlist to detect\nMPTCP-enabled systems operational on port 80 and 443. Our scans reveal a steady\nincrease in MPTCP-capable IPs, reaching 9k+ on IPv4 and a few dozen on IPv6. We\nalso discover a significant share of seemingly MPTCP-capable hosts, an artifact\nof middleboxes mirroring TCP options. We conduct targeted HTTP(S) measurements\ntowards select hosts and find that middleboxes can aggressively impact the\nperceived quality of applications utilizing MPTCP. Finally, we analyze two\ncomplementary traffic traces from CAIDA and MAWI to shed light on the\nreal-world usage of MPTCP. We find that while MPTCP usage has increased by a\nfactor of 20 over the past few years, its traffic share is still quite low.",
    "descriptor": "\nComments: Proceedings of the 2021 IFIP Networking Conference (Networking '21). Visit this https URL for up-to-date MPTCP measurement results\n",
    "authors": [
      "Florian Aschenbrenner",
      "Tanya Shreedhar",
      "Oliver Gasser",
      "Nitinder Mohan",
      "J\u00f6rg Ott"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.07351"
  },
  {
    "id": "arXiv:2106.07352",
    "title": "MOLEMAN: Mention-Only Linking of Entities with a Mention Annotation  Network",
    "abstract": "We present an instance-based nearest neighbor approach to entity linking. In\ncontrast to most prior entity retrieval systems which represent each entity\nwith a single vector, we build a contextualized mention-encoder that learns to\nplace similar mentions of the same entity closer in vector space than mentions\nof different entities. This approach allows all mentions of an entity to serve\nas \"class prototypes\" as inference involves retrieving from the full set of\nlabeled entity mentions in the training set and applying the nearest mention\nneighbor's entity label. Our model is trained on a large multilingual corpus of\nmention pairs derived from Wikipedia hyperlinks, and performs nearest neighbor\ninference on an index of 700 million mentions. It is simpler to train, gives\nmore interpretable predictions, and outperforms all other systems on two\nmultilingual entity linking benchmarks.",
    "descriptor": "\nComments: Accepted to ACL 2021\n",
    "authors": [
      "Nicholas FitzGerald",
      "Jan A. Botha",
      "Daniel Gillick",
      "Daniel M. Bikel",
      "Tom Kwiatkowski",
      "Andrew McCallum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.07352"
  },
  {
    "id": "arXiv:2106.07353",
    "title": "Posthoc Verification and the Fallibility of the Ground Truth",
    "abstract": "Classifiers commonly make use of pre-annotated datasets, wherein a model is\nevaluated by pre-defined metrics on a held-out test set typically made of\nhuman-annotated labels. Metrics used in these evaluations are tied to the\navailability of well-defined ground truth labels, and these metrics typically\ndo not allow for inexact matches. These noisy ground truth labels and strict\nevaluation metrics may compromise the validity and realism of evaluation\nresults. In the present work, we discuss these concerns and conduct a\nsystematic posthoc verification experiment on the entity linking (EL) task.\nUnlike traditional methodologies, which asks annotators to provide free-form\nannotations, we ask annotators to verify the correctness of annotations after\nthe fact (i.e., posthoc). Compared to pre-annotation evaluation,\nstate-of-the-art EL models performed extremely well according to the posthoc\nevaluation methodology. Posthoc validation also permits the validation of the\nground truth dataset. Surprisingly, we find predictions from EL models had a\nsimilar or higher verification rate than the ground truth. We conclude with a\ndiscussion on these findings and recommendations for future evaluations.",
    "descriptor": "\nComments: 12 pages, 6 figures, 1 table\n",
    "authors": [
      "Yifan Ding",
      "Nicholas Botzer",
      "Tim Weninger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07353"
  },
  {
    "id": "arXiv:2106.07356",
    "title": "Mixture of Virtual-Kernel Experts for Multi-Objective User Profile  Modeling",
    "abstract": "In many industrial applications like online advertising and recommendation\nsystems, diverse and accurate user profiles can greatly help improve\npersonalization. For building user profiles, deep learning is widely used to\nmine expressive tags to describe users' preferences from their historical\nactions. For example, tags mined from users' click-action history can represent\nthe categories of ads that users are interested in, and they are likely to\ncontinue being clicked in the future. Traditional solutions usually introduce\nmultiple independent Two-Tower models to mine tags from different actions,\ne.g., click, conversion. However, the models cannot learn complementarily and\nsupport effective training for data-sparse actions. Besides, limited by the\nlack of information fusion between the two towers, the model learning is\ninsufficient to represent users' preferences on various topics well. This paper\nintroduces a novel multi-task model called Mixture of Virtual-Kernel Experts\n(MVKE) to learn multiple topic-related user preferences based on different\nactions unitedly. In MVKE, we propose a concept of Virtual-Kernel Expert, which\nfocuses on modeling one particular facet of the user's preference, and all of\nthem learn coordinately. Besides, the gate-based structure used in MVKE builds\nan information fusion bridge between two towers, improving the model's\ncapability much and maintaining high efficiency. We apply the model in Tencent\nAdvertising System, where both online and offline evaluations show that our\nmethod has a significant improvement compared with the existing ones and brings\nabout an obvious lift to actual advertising revenue.",
    "descriptor": "\nComments: 10 pages, under review\n",
    "authors": [
      "Zhenhui Xu",
      "Meng Zhao",
      "Liqun Liu",
      "Xiaopeng Zhang",
      "Bifeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07356"
  },
  {
    "id": "arXiv:2106.07357",
    "title": "Conforming and Nonconforming Finite Element Methods for Biharmonic  Inverse Source Problem",
    "abstract": "This paper deals with the numerical approximation of the biharmonic inverse\nsource problem in an abstract setting in which the measurement data is\nfinite-dimensional. This unified framework in particular covers the conforming\nand nonconforming finite element methods (FEMs). The inverse problem is\nanalysed through the forward problem. Error estimate for the forward solution\nis derived in an abstract set-up that applies to conforming and Morley\nnonconforming FEMs. Since the inverse problem is ill-posed, Tikhonov\nregularisation is considered to obtain a stable approximate solution. Error\nestimate is established for the regularised solution for different\nregularisation schemes. Numerical results that confirm the theoretical results\nare also presented.",
    "descriptor": "\nComments: 26 pages, 6 figures, 5 tables\n",
    "authors": [
      "Devika Shylaja",
      "M. T. Nair"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2106.07357"
  },
  {
    "id": "arXiv:2106.07359",
    "title": "MexPub: Deep Transfer Learning for Metadata Extraction from German  Publications",
    "abstract": "Extracting metadata from scientific papers can be considered a solved problem\nin NLP due to the high accuracy of state-of-the-art methods. However, this does\nnot apply to German scientific publications, which have a variety of styles and\nlayouts. In contrast to most of the English scientific publications that follow\nstandard and simple layouts, the order, content, position and size of metadata\nin German publications vary greatly among publications. This variety makes\ntraditional NLP methods fail to accurately extract metadata from these\npublications. In this paper, we present a method that extracts metadata from\nPDF documents with different layouts and styles by viewing the document as an\nimage. We used Mask R-CNN that is trained on COCO dataset and finetuned with\nPubLayNet dataset that consists of ~200K PDF snapshots with five basic classes\n(e.g. text, figure, etc). We refine-tuned the model on our proposed synthetic\ndataset consisting of ~30K article snapshots to extract nine patterns (i.e.\nauthor, title, etc). Our synthetic dataset is generated using contents in both\nlanguages German and English and a finite set of challenging templates obtained\nfrom German publications. Our method achieved an average accuracy of around\n$90\\%$ which validates its capability to accurately extract metadata from a\nvariety of PDF documents with challenging templates.",
    "descriptor": "\nComments: A long version of an accepted paper @ JCDL 2021\n",
    "authors": [
      "Zeyd Boukhers",
      "Nada Beili",
      "Timo Hartmann",
      "Prantik Goswami",
      "Muhammad Arslan Zafar"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07359"
  },
  {
    "id": "arXiv:2106.07360",
    "title": "Low-Rank Projections of GCNs Laplacian",
    "abstract": "In this work, we study the behavior of standard models for community\ndetection under spectral manipulations. Through various ablation experiments,\nwe evaluate the impact of bandpass filtering on the performance of a GCN: we\nempirically show that most of the necessary and used information for nodes\nclassification is contained in the low-frequency domain, and thus contrary to\nimages, high frequencies are less crucial to community detection. In\nparticular, it is sometimes possible to obtain accuracies at a state-of-the-art\nlevel with simple classifiers that rely only on a few low frequencies.",
    "descriptor": "",
    "authors": [
      "Nathan Grinsztajn",
      "Philippe Preux",
      "Edouard Oyallon"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07360"
  },
  {
    "id": "arXiv:2106.07363",
    "title": "Cognitive-aware Short-text Understanding for Inferring Professions",
    "abstract": "Leveraging short-text contents to estimate the occupation of microblog\nauthors has significant gains in many applications. Yet challenges abound.\nFirstly brief textual contents come with excessive lexical noise that makes the\ninference problem challenging. Secondly, cognitive-semantics are not evident,\nand important linguistic features are latent in short-text contents. Thirdly,\nit is hard to measure the correlation between the cognitive short-text\nsemantics and the features pertaining various occupations. We argue that the\nmulti-aspect cognitive features are needed to correctly associate short-text\ncontents to a particular job and discover suitable people for the careers. To\nthis end, we devise a novel framework that on the one hand, can infer\nshort-text contents and exploit cognitive features, and on the other hand,\nfuses various adopted novel algorithms, such as curve fitting, support vector,\nand boosting modules to better predict the occupation of the authors. The final\nestimation module manufactures the $R^w$-tree via coherence weight to tune the\nbest outcome in the inferring process. We conduct comprehensive experiments on\nreal-life Twitter data. The experimental results show that compared to other\nrivals, our cognitive multi-aspect model can achieve a higher performance in\nthe career estimation procedure, where it is inevitable to neglect the\ncontextual semantics of users.",
    "descriptor": "",
    "authors": [
      "Sayna Esmailzadeh",
      "Saeid Hosseini",
      "Mohammad Reza Kangavari",
      "Wen Hua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.07363"
  },
  {
    "id": "arXiv:2106.07364",
    "title": "Meaning Representation of Numeric Fused-Heads in UCCA",
    "abstract": "We exhibit that the implicit UCCA parser does not address numeric fused-heads\n(NFHs) consistently, which could result either from inconsistent annotation,\ninsufficient training data or a modelling limitation. and show which factors\nare involved. We consider this phenomenon important, as it is pervasive in text\nand critical for correct inference. Careful design and fine-grained annotation\nof NFHs in meaning representation frameworks would benefit downstream tasks\nsuch as machine translation, natural language inference and question answering,\nparticularly when they require numeric reasoning, as recovering and\ncategorizing them. We are investigating the treatment of this phenomenon by\nother meaning representations, such as AMR. We encourage researchers in meaning\nrepresentations, and computational linguistics in general, to address this\nphenomenon in future research.",
    "descriptor": "\nComments: UnImplicit Workshop at ACL 2021 (abstract)\n",
    "authors": [
      "Ruixiang Cui",
      "Daniel Hershcovich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07364"
  },
  {
    "id": "arXiv:2106.07368",
    "title": "Quality-Aware Network for Face Parsing",
    "abstract": "This is a very short technical report, which introduces the solution of the\nTeam BUPT-CASIA for Short-video Face Parsing Track of The 3rd Person in Context\n(PIC) Workshop and Challenge at CVPR 2021.\nFace parsing has recently attracted increasing interest due to its numerous\napplication potentials. Generally speaking, it has a lot in common with human\nparsing, such as task setting, data characteristics, number of categories and\nso on. Therefore, this work applies state-of-the-art human parsing method to\nface parsing task to explore the similarities and differences between them. Our\nsubmission achieves 86.84% score and wins the 2nd place in the challenge.",
    "descriptor": "\nComments: 2nd place in Short-video Face Parsing Track of The 3rd Person in Context (PIC) Workshop and Challenge at CVPR 2021\n",
    "authors": [
      "Lu Yang",
      "Qing Song",
      "Xueshi Xin",
      "Zhiwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07368"
  },
  {
    "id": "arXiv:2106.07369",
    "title": "A Self-Supervised Framework for Function Learning and Extrapolation",
    "abstract": "Understanding how agents learn to generalize -- and, in particular, to\nextrapolate -- in high-dimensional, naturalistic environments remains a\nchallenge for both machine learning and the study of biological agents. One\napproach to this has been the use of function learning paradigms, which allow\npeoples' empirical patterns of generalization for smooth scalar functions to be\ndescribed precisely. However, to date, such work has not succeeded in\nidentifying mechanisms that acquire the kinds of general purpose\nrepresentations over which function learning can operate to exhibit the\npatterns of generalization observed in human empirical studies. Here, we\npresent a framework for how a learner may acquire such representations, that\nthen support generalization -- and extrapolation in particular -- in a few-shot\nfashion. Taking inspiration from a classic theory of visual processing, we\nconstruct a self-supervised encoder that implements the basic inductive bias of\ninvariance under topological distortions. We show the resulting representations\noutperform those from other models for unsupervised time series learning in\nseveral downstream function learning tasks, including extrapolation.",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Simon N. Segert",
      "Jonathan D. Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.07369"
  },
  {
    "id": "arXiv:2106.07371",
    "title": "A2MM: Mitigating Frontrunning, Transaction Reordering and Consensus  Instability in Decentralized Exchanges",
    "abstract": "The asset trading volume on blockchain-based exchanges (DEX) increased\nsubstantially since the advent of Automated Market Makers (AMM). Yet, AMMs and\ntheir forks compete on the same blockchain, incurring unnecessary network and\nblock-space overhead, by attracting sandwich attackers and arbitrage\ncompetitions. Moreover, conceptually speaking, a blockchain is one database,\nand we find little reason to partition this database into multiple competing\nexchanges, which then necessarily require price synchronization through\narbitrage.\nThis paper shows that DEX arbitrage and trade routing among similar AMMs can\nbe performed efficiently and atomically on-chain within smart contracts. These\ninsights lead us to create a new AMM design, an Automated Arbitrage Market\nMaker, short A2MM DEX. A2MM aims to unite multiple AMMs to reduce overheads,\ncosts and increase blockchain security. With respect to Miner Extractable Value\n(MEV), A2MM serves as a decentralized design for users to atomically collect\nMEV, mitigating the dangers of centralized MEV relay services.\nWe show that A2MM offers essential security benefits. First, A2MM strengthens\nthe blockchain consensus security by mitigating the competitive exploitation of\nMEV, therefore reducing the risks of consensus forks. A2MM reduces the network\nlayer overhead of competitive transactions, improves network propagation,\nleading to less stale blocks and better blockchain security. Through trade\nrouting, A2MM reduces the predatory risks of sandwich attacks by taking\nadvantage of the minimum profitable victim input. A2MM also offers financial\nbenefits to traders. Failed swap transactions from competitive trading occupy\nvaluable block space, implying an upward pressure on transaction fees. Our\nevaluations shows that A2MM frees up 32.8% block-space of AMM-related\ntransactions. In expectation, A2MM's revenue allows to reduce swap fees by 90%.",
    "descriptor": "",
    "authors": [
      "Liyi Zhou",
      "Kaihua Qin",
      "Arthur Gervais"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.07371"
  },
  {
    "id": "arXiv:2106.07374",
    "title": "Graph-based Trajectory Visualization for Text Mining of COVID-19  Biomedical Literature",
    "abstract": "Since the emergence of the worldwide pandemic of COVID-19, relevant research\nhas been published at a dazzling pace, which makes it hard to follow the\nresearch in this area without dedicated efforts. It is practically impossible\nto implement this task manually due to the high volume of the relevant\nliterature. Text mining has been considered to be a powerful approach to\naddress this challenge, especially the topic modeling, a well-known\nunsupervised method that aims to reveal latent topics from the literature.\nHowever, in spite of its potential utility, the results generated from this\napproach are often investigated manually. Hence, its application to the\nCOVID-19 literature is not straightforward and expert knowledge is needed to\nmake meaningful interpretations. In order to address these challenges, we\npropose a novel analytical framework for effective visualization and mining of\ntopic modeling results. Here we assumed that topics constituting a paper can be\npositioned on an interaction map, which belongs to a high-dimensional Euclidean\nspace. Based on this assumption, after summarizing topics with their topic-word\ndistributions using the biterm topic model, we mapped these latent topics on\nnetworks to visualize relationships among the topics. Moreover, in the proposed\napproach, the change of relationships among topics can be traced using a\ntrajectory plot generated with different levels of word richness. These results\ntogether provide a deeply mined and intuitive representation of relationships\namong topics related to a specific research area. The application of this\nproposed framework to the PubMed literature shows that our approach facilitates\nunderstanding of the topics constituting the COVID-19 knowledge.",
    "descriptor": "",
    "authors": [
      "Yeseul Jeon",
      "Dongjun Chung",
      "Jina Park",
      "Ick Hoon Jin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.07374"
  },
  {
    "id": "arXiv:2106.07378",
    "title": "Recommending Multiple Criteria Decision Analysis Methods with A New  Taxonomy-based Decision Support System",
    "abstract": "We present the Multiple Criteria Decision Analysis Methods Selection Software\n(MCDA-MSS). This decision support system helps analysts answering a recurring\nquestion in decision science: Which is the most suitable Multiple Criteria\nDecision Analysis method (or a subset of MCDA methods) that should be used for\na given Decision-Making Problem (DMP)?. The MCDA-MSS includes guidance to lead\ndecision-making processes and choose among an extensive collection (over 200)\nof MCDA methods. These are assessed according to an original comprehensive set\nof problem characteristics. The accounted features concern problem formulation,\npreference elicitation and types of preference information, desired features of\na preference model, and construction of the decision recommendation. The\napplicability of the MCDA-MSS has been tested on several case studies. The\nMCDA-MSS includes the capabilities of (i) covering from very simple to very\ncomplex DMPs, (ii) offering recommendations for DMPs that do not match any\nmethod from the collection, (iii) helping analysts prioritize efforts for\nreducing gaps in the description of the DMPs, and (iv) unveiling methodological\nmistakes that occur in the selection of the methods. A community-wide\ninitiative involving experts in MCDA methodology, analysts using these methods,\nand decision-makers receiving decision recommendations will contribute to\nexpansion of the MCDA-MSS.",
    "descriptor": "",
    "authors": [
      "Marco Cinelli",
      "Mi\u0142osz Kadzi\u0144ski",
      "Grzegorz Miebs",
      "Michael Gonzalez",
      "Roman S\u0142owi\u0144ski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2106.07378"
  },
  {
    "id": "arXiv:2106.07380",
    "title": "Predicting the Popularity of Reddit Posts with AI",
    "abstract": "Social media creates crucial mass changes, as popular posts and opinions cast\na significant influence on users' decisions and thought processes. For example,\nthe recent Reddit uprising inspired by r/wallstreetbets which had remarkable\neconomic impact was started with a series of posts on the thread. The\nprediction of posts that may have a notable impact will allow for the\npreparation of possible following trends. This study aims to develop a machine\nlearning model capable of accurately predicting the popularity of a Reddit\npost. Specifically, the model is predicting the number of upvotes a post will\nreceive based on its textual content. I experimented with three different\nmodels: a baseline linear regression model, a random forest regression model,\nand a neural network. I collected Reddit post data from an online data set and\nanalyzed the model's performance when trained on a single subreddit and a\ncollection of subreddits. The results showed that the neural network model\nperformed the best when the loss of the models were compared. With the use of a\nmachine learning model to predict social trends through the reaction users have\nto post, a better picture of the near future can be envisioned.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Juno Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.07380"
  },
  {
    "id": "arXiv:2106.07381",
    "title": "A Semi-supervised Multi-task Learning Approach to Classify Customer  Contact Intents",
    "abstract": "In the area of customer support, understanding customers' intents is a\ncrucial step. Machine learning plays a vital role in this type of intent\nclassification. In reality, it is typical to collect confirmation from customer\nsupport representatives (CSRs) regarding the intent prediction, though it can\nunnecessarily incur prohibitive cost to ask CSRs to assign existing or new\nintents to the mis-classified cases. Apart from the confirmed cases with and\nwithout intent labels, there can be a number of cases with no human curation.\nThis data composition (Positives + Unlabeled + multiclass Negatives) creates\nunique challenges for model development. In response to that, we propose a\nsemi-supervised multi-task learning paradigm. In this manuscript, we share our\nexperience in building text-based intent classification models for a customer\nsupport service on an E-commerce website. We improve the performance\nsignificantly by evolving the model from multiclass classification to\nsemi-supervised multi-task learning by leveraging the negative cases, domain-\nand task-adaptively pretrained ALBERT on customer contact texts, and a number\nof un-curated data with no labels. In the evaluation, the final model boosts\nthe average AUC ROC by almost 20 points compared to the baseline finetuned\nmulticlass classification ALBERT model.",
    "descriptor": "\nComments: To be published in ACL-IJCNLP 2021 workshop ECNLP\n",
    "authors": [
      "Li Dong",
      "Matthew C. Spencer",
      "Amir Biagi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07381"
  },
  {
    "id": "arXiv:2106.07384",
    "title": "MoParkeR : Multi-objective Parking Recommendation",
    "abstract": "Existing parking recommendation solutions mainly focus on finding and\nsuggesting parking spaces based on the unoccupied options only. However, there\nare other factors associated with parking spaces that can influence someone's\nchoice of parking such as fare, parking rule, walking distance to destination,\ntravel time, likelihood to be unoccupied at a given time. More importantly,\nthese factors may change over time and conflict with each other which makes the\nrecommendations produced by current parking recommender systems ineffective. In\nthis paper, we propose a novel problem called multi-objective parking\nrecommendation. We present a solution by designing a multi-objective parking\nrecommendation engine called MoParkeR that considers various conflicting\nfactors together. Specifically, we utilise a non-dominated sorting technique to\ncalculate a set of Pareto-optimal solutions, consisting of recommended\ntrade-off parking spots. We conduct extensive experiments using two real-world\ndatasets to show the applicability of our multi-objective recommendation\nmethodology.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Mohammad Saiedur Rahaman",
      "Wei Shao",
      "Flora D. Salim",
      "Ayad Turky",
      "Andy Song",
      "Jeffrey Chan",
      "Junliang Jiang",
      "Doug Bradbrook"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07384"
  },
  {
    "id": "arXiv:2106.07385",
    "title": "SemEval-2021 Task 11: NLPContributionGraph -- Structuring Scholarly NLP  Contributions for a Research Knowledge Graph",
    "abstract": "There is currently a gap between the natural language expression of scholarly\npublications and their structured semantic content modeling to enable\nintelligent content search. With the volume of research growing exponentially\nevery year, a search feature operating over semantically structured content is\ncompelling. The SemEval-2021 Shared Task NLPContributionGraph (a.k.a. 'the NCG\ntask') tasks participants to develop automated systems that structure\ncontributions from NLP scholarly articles in the English language. Being the\nfirst-of-its-kind in the SemEval series, the task released structured data from\nNLP scholarly articles at three levels of information granularity, i.e. at\nsentence-level, phrase-level, and phrases organized as triples toward Knowledge\nGraph (KG) building. The sentence-level annotations comprised the few sentences\nabout the article's contribution. The phrase-level annotations were scientific\nterm and predicate phrases from the contribution sentences. Finally, the\ntriples constituted the research overview KG. For the Shared Task,\nparticipating systems were then expected to automatically classify contribution\nsentences, extract scientific terms and relations from the sentences, and\norganize them as KG triples.\nOverall, the task drew a strong participation demographic of seven teams and\n27 participants. The best end-to-end task system classified contribution\nsentences at 57.27% F1, phrases at 46.41% F1, and triples at 22.28% F1. While\nthe absolute performance to generate triples remains low, in the conclusion of\nthis article, the difficulty of producing such data and as a consequence of\nmodeling it is highlighted.",
    "descriptor": "\nComments: 13 pages, 5 figures, 8 tables, In Proceedings of the Fifteenth Workshop on Semantic Evaluation SemEval-2021 (to appear)\n",
    "authors": [
      "Jennifer D'Souza",
      "S\u00f6ren Auer",
      "Ted Pedersen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07385"
  },
  {
    "id": "arXiv:2106.07386",
    "title": "Do peers share the same criteria for assessing grant applications?",
    "abstract": "This study examines a basic assumption of peer review, namely, the idea that\nthere is a consensus on evaluation criteria among peers, which is a necessary\ncondition for the reliability of peer judgements. Empirical evidence indicating\nthat there is no consensus or more than one consensus would offer an\nexplanation for the disagreement effect, the low inter-rater reliability\nconsistently observed in peer review. To investigate this basic assumption, we\nhave surveyed all humanities scholars in Switzerland on 23 grant review\ncriteria. We have employed latent class tree modelling to identify subgroups in\nwhich scholars rated criteria similarly (i.e. latent classes) and to explore\ncovariates predicting class membership. We have identified two consensus\nclasses, two consensus-close classes, and a consensus-far class. The consensus\nclasses contain a core consensus (ten criteria related to knowledge gaps,\nfeasibility, rigour, comprehensibility and argumentation, and academic\nrelevance, as well as to the competence and experience of the applicant) and a\nbroad consensus that includes the core consensus plus eight\ncontribution-related criteria, such as originality. These results provide a\npossible explanation for the disagreement effect. Moreover, the results are\nconsistent with the notion of conservatism, which holds that original research\nis undervalued in peer review, while other aspects, such as methodology and\nfeasibility, are overweighted. The covariate analysis indicated that age and\nhaving tenure increases from the consensus-far to the consensus-close to the\nconsensus classes. This suggests that the more academic experience scholars\naccumulate, the more their understanding of review criteria conforms to the\nsocial norm.",
    "descriptor": "\nComments: v1, draft\n",
    "authors": [
      "Sven E. Hug",
      "Michael Ochsner"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.07386"
  },
  {
    "id": "arXiv:2106.07387",
    "title": "An SMT Based Compositional Model to Solve a Conflict-Free Electric  Vehicle Routing Problem",
    "abstract": "The Vehicle Routing Problem (VRP) is the combinatorial optimization problem\nof designing routes for vehicles to visit customers in such a fashion that a\ncost function, typically the number of vehicles, or the total travelled\ndistance is minimized. The problem finds applications in industrial scenarios,\nfor example where Automated Guided Vehicles run through the plant to deliver\ncomponents from the warehouse. This specific problem, henceforth called the\nElectric Conflict-Free Vehicle Routing Problem (CF-EVRP), involves constraints\nsuch as limited operating range of the vehicles, time windows on the delivery\nto the customers, and limited capacity on the number of vehicles the road\nsegments can accommodate at the same time. Such a complex system results in a\nlarge model that cannot easily be solved to optimality in reasonable time. We\ntherefore developed a compositional model that breaks down the problem into\nsmaller and simpler sub-problems and provides sub-optimal, feasible solutions\nto the original problem. The algorithm exploits the strengths of SMT solvers,\nwhich proved in our previous work to be an efficient approach to deal with\nscheduling problems. Compared to a monolithic model for the CF-EVRP, written in\nthe SMT standard language and solved using a state-of-the-art SMT solver the\ncompositional model was found to be significantly faster.",
    "descriptor": "",
    "authors": [
      "Sabino Francesco Roselli",
      "Martin Fabian",
      "Knut \u00c5kesson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07387"
  },
  {
    "id": "arXiv:2106.07395",
    "title": "Dilated filters for edge detection algorithms",
    "abstract": "Edges are a basic and fundamental feature in image processing, that are used\ndirectly or indirectly in huge amount of applications. Inspired by the\nexpansion of image resolution and processing power dilated convolution\ntechniques appeared. Dilated convolution have impressive results in machine\nlearning, we discuss here the idea of dilating the standard filters which are\nused in edge detection algorithms. In this work we try to put together all our\nprevious and current results by using instead of the classical convolution\nfilters a dilated one. We compare the results of the edge detection algorithms\nusing the proposed dilation filters with original filters or custom variants.\nExperimental results confirm our statement that dilation of filters have\npositive impact for edge detection algorithms form simple to rather complex\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Ciprian Orhei",
      "Victor Bogdan",
      "Cosmin Bonchis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07395"
  },
  {
    "id": "arXiv:2106.07400",
    "title": "Determinantal Beam Search",
    "abstract": "Beam search is a go-to strategy for decoding neural sequence models. The\nalgorithm can naturally be viewed as a subset optimization problem, albeit one\nwhere the corresponding set function does not reflect interactions between\ncandidates. Empirically, this leads to sets often exhibiting high overlap,\ne.g., strings may differ by only a single word. Yet in use-cases that call for\nmultiple solutions, a diverse or representative set is often desired. To\naddress this issue, we propose a reformulation of beam search, which we call\ndeterminantal beam search. Determinantal beam search has a natural relationship\nto determinantal point processes (DPPs), models over sets that inherently\nencode intra-set interactions. By posing iterations in beam search as a series\nof subdeterminant maximization problems, we can turn the algorithm into a\ndiverse subset selection process. In a case study, we use the string\nsubsequence kernel to explicitly encourage n-gram coverage in text generated\nfrom a sequence model. We observe that our algorithm offers competitive\nperformance against other diverse set generation strategies in the context of\nlanguage generation, while providing a more general approach to optimizing for\ndiversity.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Clara Meister",
      "Martina Forster",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07400"
  },
  {
    "id": "arXiv:2106.07405",
    "title": "An adaptive high-order surface finite element method for the  self-consistent field theory on general curved surfaces",
    "abstract": "In this paper, we develop an adaptive high-order surface finite element\nmethod (FEM) to solve self-consistent field equations of polymers on general\ncurved surfaces. It is an improvement of the existing algorithm of [J. Comp.\nPhys. 387: 230-244 (2019)] in which a linear surface FEM was presented to\naddress this problem. The high-order surface FEM is obtained by the high-order\nsurface geometrical approximation and high-order function space approximation.\nIn order to describe the sharp interface in the strong segregation system more\naccurately, an adaptive FEM equipped with a novel Log marking strategy is\nproposed. Compared with the traditional strategy, this new marking strategy can\nnot only label the elements that need to be refined or coarsened, but also give\nthe refined or coarsened times, which can make full use of the information of a\nposterior error estimator and improve the efficiency of the adaptive algorithm.\nTo demonstrate the power of our approach, we investigate the self-assembled\npatterns of diblock copolymers on several distinct curved surfaces. Numerical\nresults illustrate the efficiency of the proposed method, especially for strong\nsegregation systems.",
    "descriptor": "\nComments: 19 pages, 10 figures\n",
    "authors": [
      "Kai Jiang",
      "Xin Wang",
      "Jianggang Liu",
      "Huayi Wei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07405"
  },
  {
    "id": "arXiv:2106.07408",
    "title": "Using Eye Tracker To Evaluate Cockpit Design -- A Flight Simulation  Study",
    "abstract": "This paper investigates applications of eye tracking in transport aircraft\ndesign evaluations. Piloted simulations were conducted for a complete flight\nprofile including take off, cruise and landing flight scenario using the\ntransport aircraft flight simulator at CSIR National Aerospace Laboratories.\nThirty-one simulation experiments were carried out with three pilots and\nengineers while recording the ocular parameters and the flight data.\nSimulations were repeated for high workload conditions like flying with\ndegraded visibility and during stall. Pilots visual scan behaviour and workload\nlevels were analysed using ocular parameters; while comparing with the\nstatistical deviations from the desired flight path. Conditions for fatigue\nwere also recreated through long duration simulations and signatures for the\nsame from the ocular parameters were assessed. Results from the study found\ncorrelation between the statistical inferences obtained from the ocular\nparameters with those obtained from the flight path deviations. The paper also\ndemonstrates an evaluators console that assists the designers or evaluators for\nbetter understanding of pilots attentional resource allocation.",
    "descriptor": "",
    "authors": [
      "Archana Hebbar",
      "Abhay Pashilkar",
      "Pradipta Biswas"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.07408"
  },
  {
    "id": "arXiv:2106.07409",
    "title": "3rd Place Solution for Short-video Face Parsing Challenge",
    "abstract": "Short videos have many applications on fashion trends, hot spots, street\ninterviews, public education, and creative advertising. We propose an\nEdge-Aware Network(EANet) that uses edge information to refine the segmentation\nedge. And experiments show our proposed EANet boots up the facial parsing\nresults. We also use post-process like grab cut to refine and merge the parsing\nresults.",
    "descriptor": "\nComments: 3pages tech report\n",
    "authors": [
      "Xiao Liu",
      "XiaoFei Si",
      "JiangTao Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07409"
  },
  {
    "id": "arXiv:2106.07410",
    "title": "Model Explainability in Deep Learning Based Natural Language Processing",
    "abstract": "Machine learning (ML) model explainability has received growing attention,\nespecially in the area related to model risk and regulations. In this paper, we\nreviewed and compared some popular ML model explainability methodologies,\nespecially those related to Natural Language Processing (NLP) models. We then\napplied one of the NLP explainability methods Layer-wise Relevance Propagation\n(LRP) to a NLP classification model. We used the LRP method to derive a\nrelevance score for each word in an instance, which is a local explainability.\nThe relevance scores are then aggregated together to achieve global variable\nimportance of the model. Through the case study, we also demonstrated how to\napply the local explainability method to false positive and false negative\ninstances to discover the weakness of a NLP model. These analysis can help us\nto understand NLP models better and reduce the risk due to the black-box nature\nof NLP models. We also identified some common issues due to the special natures\nof NLP models and discussed how explainability analysis can act as a control to\ndetect these issues after the model has been trained.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Shafie Gholizadeh",
      "Nengfeng Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07410"
  },
  {
    "id": "arXiv:2106.07411",
    "title": "Partial success in closing the gap between human and machine vision",
    "abstract": "A few years ago, the first CNN surpassed human performance on ImageNet.\nHowever, it soon became clear that machines lack robustness on more challenging\ntest cases, a major obstacle towards deploying machines \"in the wild\" and\ntowards obtaining better computational models of human visual perception. Here\nwe ask: Are we making progress in closing the gap between human and machine\nvision? To answer this question, we tested human observers on a broad range of\nout-of-distribution (OOD) datasets, adding the \"missing human baseline\" by\nrecording 85,120 psychophysical trials across 90 participants. We then\ninvestigated a range of promising machine learning developments that crucially\ndeviate from standard supervised CNNs along three axes: objective function\n(self-supervised, adversarially trained, CLIP language-image training),\narchitecture (e.g. vision transformers), and dataset size (ranging from 1M to\n1B). Our findings are threefold. (1.) The longstanding robustness gap between\nhumans and CNNs is closing, with the best models now matching or exceeding\nhuman performance on most OOD datasets. (2.) There is still a substantial\nimage-level consistency gap, meaning that humans make different errors than\nmodels. In contrast, most models systematically agree in their categorisation\nerrors, even substantially different ones like contrastive self-supervised vs.\nstandard supervised models. (3.) In many cases, human-to-model consistency\nimproves when training dataset size is increased by one to three orders of\nmagnitude. Our results give reason for cautious optimism: While there is still\nmuch room for improvement, the behavioural difference between human and machine\nvision is narrowing. In order to measure future progress, 17 OOD datasets with\nimage-level human behavioural data are provided as a benchmark here:\nhttps://github.com/bethgelab/model-vs-human/",
    "descriptor": "\nComments: A preliminary version of this work was presented as Oral at the 2020 NeurIPS workshop on \"Shared Visual Representations in Human & Machine Intelligence\" (arXiv:2010.08377)\n",
    "authors": [
      "Robert Geirhos",
      "Kantharaju Narayanappa",
      "Benjamin Mitzkus",
      "Tizian Thieringer",
      "Matthias Bethge",
      "Felix A. Wichmann",
      "Wieland Brendel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.07411"
  },
  {
    "id": "arXiv:2106.07412",
    "title": "Exact Counting and Sampling of Optima for the Knapsack Problem",
    "abstract": "Computing sets of high quality solutions has gained increasing interest in\nrecent years. In this paper, we investigate how to obtain sets of optimal\nsolutions for the classical knapsack problem. We present an algorithm to count\nexactly the number of optima to a zero-one knapsack problem instance. In\naddition, we show how to efficiently sample uniformly at random from the set of\nall global optima. In our experimental study, we investigate how the number of\noptima develops for classical random benchmark instances dependent on their\ngenerator parameters. We find that the number of global optima can increase\nexponentially for practically relevant classes of instances with correlated\nweights and profits which poses a justification for the considered exact\ncounting problem.",
    "descriptor": "",
    "authors": [
      "Jakob Bossek",
      "Aneta Neumann",
      "Frank Neumann"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07412"
  },
  {
    "id": "arXiv:2106.07413",
    "title": "IncBL: Incremental Bug Localization",
    "abstract": "Numerous efforts have been invested in improving the effectiveness of bug\nlocalization techniques, whereas little attention is paid to making these tools\nrun more efficiently in continuously evolving software repositories. This paper\nfirst analyzes the information retrieval model behind a classic bug\nlocalization tool, BugLocator, and builds a mathematical foundation that the\nmodel can be updated incrementally when codebase or bug reports evolve. Then,\nwe present IncBL, a tool for Incremental Bug Localization in evolving software\nrepositories. IncBL is evaluated on the Bugzbook dataset, and the results show\nthat IncBL can significantly reduce the running time by 77.79% on average\ncompared with re-computing the model, while maintaining the same level of\naccuracy. We also implement IncBL as a Github App that can be easily integrated\ninto open-source projects on Github, and users can also deploy and use IncBL\nlocally. The demo video for IncBL can be viewed at\nhttps://youtu.be/G4gMuvlJSb0, and the source code can be found at\nhttps://github.com/soarsmu/IncBL",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Zhou Yang",
      "Jieke Shi",
      "Shaowei Wang",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.07413"
  },
  {
    "id": "arXiv:2106.07415",
    "title": "Accumulative Iterative Codes Based on Feedback",
    "abstract": "The Accumulative Iterative Code (AIC) proposed in this work is a new error\ncorrecting code for channels with feedback. AIC sends the information message\nto the receiver in a number of transmissions, where the initial transmission\ncontains the uncoded message and each subsequent transmission informs the\nreceiver about the locations of the errors that corrupted the previous\ntransmission. Error locations are determined based on the forward channel\noutput, which is made available to the transmitter through the feedback\nchannel.\nAIC achieves arbitrarily low error rates, thereby being suitablefor\napplications demanding extremely high reliability. In the same time, AIC\nachieves spectral efficiencies very close to the channel capacity in a wide\nrange of signal-to-noise ratios even for transmission of short information\nmessages.",
    "descriptor": "\nComments: 30 pages, 8 figures, 4 tables; submitted to IEEE Transactions on Communications\n",
    "authors": [
      "Alberto G. Perotti",
      "Branislav M. Popovic",
      "Anahid R. Safavi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.07415"
  },
  {
    "id": "arXiv:2106.07417",
    "title": "Online Estimation of Resource Overload Risk in 5G Multi-Tenancy Network",
    "abstract": "The technology of network slicing, as the most characteristic feature of the\nfifth generation (5G) wireless networks, manages the resources and network\nfunctions in heterogeneous and logically isolated slices on the top of a shared\nphysical infrastructure, where every slice can be independently customized to\nfulfill the specific requirements of its devoted service type. It enables a new\nparadigm of multi-tenancy networking, where the network slices can be leased by\nthe mobile network operator (MNO) to tenants in form of public cloud computing\nservice, known as Slice-asa- Service (SlaaS). Similar to classical cloud\ncomputing scenarios, SlaaS benefits from overbooking its resources to numerous\ntenants, taking advantage of the resource elasticity and diversity, at a price\nof risking overloading network resources and violating the service-level\nagreements (SLAs), which stipulate the quality of service (QoS) that shall be\nguaranteed to the network slices. Thus, it becomes a critical challenge to the\nMNOs, accurately estimating the resource overload risk - especially under the\nsophisticated network dynamics - for monitoring and enhancing the reliability\nof SlaaS business.",
    "descriptor": "\nComments: To appear at ESREL 2021\n",
    "authors": [
      "Yasameen Shihab Hamad",
      "Bin Han",
      "Osman Nuri ucan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.07417"
  },
  {
    "id": "arXiv:2106.07419",
    "title": "Low cost cloud based remote microscopy for biological sciences",
    "abstract": "A low cost remote imaging platform for biological applications was developed.\nThe \"Picroscope\" is a device that allows the user to perform longitudinal\nimaging studies on multi-well cell culture plates. Here we present the network\narchitecture and software used to facilitate communication between modules\nwithin the device as well as external cloud services. A web based console was\ncreated to control the device and view experiment results. Post processing\ntools were developed to analyze captured data in the cloud. The result is a\nplatform for controlling biological experiments from outside the lab.",
    "descriptor": "\nComments: The authors Pierre V Baudin and Victoria T Ly contributed equally to this work. 21 pages, 12 figures\n",
    "authors": [
      "Pierre V Baudin",
      "Victoria T Ly",
      "Pattawong Pansodtee",
      "Erik A Jung",
      "Robert Currie",
      "Ryan Hoffman",
      "Helen Rankin Willsey",
      "Alex A Pollen",
      "Tomasz J Nowakowski",
      "David Haussler",
      "Mohammed Andres Mostajo-Radji",
      "Sofie Salama",
      "Mircea Teodorescu"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.07419"
  },
  {
    "id": "arXiv:2106.07423",
    "title": "ETICA: Efficient Two-Level I/O Caching Architecture for Virtualized  Platforms",
    "abstract": "In this paper, we propose an Efficient Two-Level I/O Caching Architecture\n(ETICA) for virtualized platforms that can significantly improve I/O latency,\nendurance, and cost (in terms of cache size) while preserving the reliability\nof write-pending data blocks. As opposed to previous one-level I/O caching\nschemes in virtualized platforms, our proposed architecture 1) provides two\nlevels of cache by employing both Dynamic Random-Access Memory (DRAM) and SSD\nin the I/O caching layer of virtualized platforms and 2) effectively partitions\nthe cache space between running VMs to achieve maximum performance and minimum\ncache size. To manage the two-level cache, unlike the previous reuse distance\ncalculation schemes such as Useful Reuse Distance (URD), which only consider\nthe request type and neglect the impact of cache write policy, we propose a new\nmetric, Policy Optimized reuse Distance (POD). The key idea of POD is to\neffectively calculate the reuse distance and estimate the amount of two-level\nDRAM+SSD cache space to allocate by considering both 1) the request type and 2)\nthe cache write policy. Doing so results in enhanced performance and reduced\ncache size due to the allocation of cache blocks only for the requests that\nwould be served by the I/O cache. ETICA maintains the reliability of\nwrite-pending data blocks and improves performance by 1) assigning an effective\nand fixed write policy at each level of the I/O cache hierarchy and 2)\nemploying effective promotion and eviction methods between cache levels. Our\nextensive experiments conducted with a real implementation of the proposed\ntwo-level storage caching architecture show that ETICA provides 45% higher\nperformance, compared to the state-of-the-art caching schemes in virtualized\nplatforms, while improving both cache size and SSD endurance by 51.7% and\n33.8%, respectively.",
    "descriptor": "",
    "authors": [
      "Saba Ahmadian",
      "Reza Salkhordeh",
      "Onur Mutlu",
      "Hossein Asadi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.07423"
  },
  {
    "id": "arXiv:2106.07428",
    "title": "Audio Attacks and Defenses against AED Systems - A Practical Study",
    "abstract": "Audio Event Detection (AED) Systems capture audio from the environment and\nemploy some deep learning algorithms for detecting the presence of a specific\nsound of interest. In this paper, we evaluate deep learning-based AED systems\nagainst evasion attacks through adversarial examples. We run multiple security\ncritical AED tasks, implemented as CNNs classifiers, and then generate audio\nadversarial examples using two different types of noise, namely background and\nwhite noise, that can be used by the adversary to evade detection. We also\nexamine the robustness of existing third-party AED capable devices, such as\nNest devices manufactured by Google, which run their own black-box deep\nlearning models.\nWe show that an adversary can focus on audio adversarial inputs to cause AED\nsystems to misclassify, similarly to what has been previously done by works\nfocusing on adversarial examples from the image domain. We then, seek to\nimprove classifiers' robustness through countermeasures to the attacks. We\nemploy adversarial training and a custom denoising technique. We show that\nthese countermeasures, when applied to audio input, can be successful, either\nin isolation or in combination, generating relevant increases of nearly fifty\npercent in the performance of the classifiers when these are under attack.",
    "descriptor": "",
    "authors": [
      "Rodrigo dos Santos",
      "Shirin Nilizadeh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07428"
  },
  {
    "id": "arXiv:2106.07431",
    "title": "CRASH: Raw Audio Score-based Generative Modeling for Controllable  High-resolution Drum Sound Synthesis",
    "abstract": "In this paper, we propose a novel score-base generative model for\nunconditional raw audio synthesis. Our proposal builds upon the latest\ndevelopments on diffusion process modeling with stochastic differential\nequations, which already demonstrated promising results on image generation. We\nmotivate novel heuristics for the choice of the diffusion processes better\nsuited for audio generation, and consider the use of a conditional U-Net to\napproximate the score function. While previous approaches on diffusion models\non audio were mainly designed as speech vocoders in medium resolution, our\nmethod termed CRASH (Controllable Raw Audio Synthesis with High-resolution)\nallows us to generate short percussive sounds in 44.1kHz in a controllable way.\nThrough extensive experiments, we showcase on a drum sound generation task the\nnumerous sampling schemes offered by our method (unconditional generation,\ndeterministic generation, inpainting, interpolation, variations,\nclass-conditional sampling) and propose the class-mixing sampling, a novel way\nto generate \"hybrid\" sounds. Our proposed method closes the gap with GAN-based\nmethods on raw audio, while offering more flexible generation capabilities with\nlighter and easier-to-train models.",
    "descriptor": "\nComments: 12 pages, 11 figures\n",
    "authors": [
      "Simon Rouard",
      "Ga\u00ebtan Hadjeres"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07431"
  },
  {
    "id": "arXiv:2106.07432",
    "title": "Information exchange, meaning and redundancy generation in anticipatory  systems: self-organization of expectations -- the case of Covid-19",
    "abstract": "When studying the evolution of complex systems one refers to model\nrepresentations comprising various descriptive parameters. There is hardly\nresearch where system evolution is described on the base of information flows\nin the system. The paper focuses on the link between the dynamics of\ninformation and system evolution. Information, exchanged between different\nsystem's parts, before being processed is first provided with meaning by the\nsystem. Meanings are generated from the perspective of hindsight, i.e. against\nthe arrow of time. The same information can be differently interpreted by\ndifferent system's parts (i,e,provided with different meanings) so that the\nnumber of options for possible system development is proliferated. Some options\neventually turn into observable system states. So that system evolutionary\ndynamics can be considered as due to information processing within the system.\nThis process is considered here in a model representation. The model under\nstudy is Triple Helix (TH) model, which was earlier used to describe\ninteractions between university, industry and government to foster innovations.\nIn TH model the system is comprised of three interacting parts where each part\nprocess information ina different way. The model is not limited to the sphere\nof innovation and can be used in a broader perspective. Here TH is\nconceptualized in the framework of three compertment model used to describe\ninfectious disease. The paper demonstrates how the dynamics of information and\nmeaning can be incorporated in the description of Covid-19 infectious\npropagation. The results show correspondence of model predictions with\nobservable infection dynamics.",
    "descriptor": "",
    "authors": [
      "Inga A. Ivanova"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.07432"
  },
  {
    "id": "arXiv:2106.07435",
    "title": "Both Rates of Fake News and Fact-based News on Twitter Negatively  Correlate with the State-level COVID-19 Vaccine Uptake",
    "abstract": "There is evidence of misinformation in the online discourses and discussions\nabout the COVID-19 vaccines. Using a sample of 1.6 million geotagged English\ntweets and the data from the CDC COVID Data Tracker, we conduct a quantitative\nstudy to understand the influence of both misinformation and fact-based news on\nTwitter on the COVID-19 vaccine uptake in the U.S. from April 19 when U.S.\nadults were vaccine eligible to May 7, 2021, after controlling state-level\nfactors such as demographics, education, and the pandemic severity. We identify\nthe tweets related to either misinformation or fact-based news by analyzing the\nURLs. By analyzing the content of the most frequent tweets of these two groups,\nwe find that their structures are similar, making it difficult for Twitter\nusers to distinguish one from another by reading the text alone. The users who\nspread both fake news and fact-based news tend to show a negative attitude\ntowards the vaccines. We further conduct the Fama-MacBeth regression with the\nNewey-West adjustment to examine the effect of fake-news-related and\nfact-related tweets on the vaccination rate, and find marginally negative\ncorrelations.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Hanjia Lyu",
      "Zihe Zheng",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.07435"
  },
  {
    "id": "arXiv:2106.07441",
    "title": "Automatically eliminating seam lines with Poisson editing in complex  relative radiometric normalization mosaicking scenarios",
    "abstract": "Relative radiometric normalization (RRN) mosaicking among multiple remote\nsensing images is crucial for the downstream tasks, including map-making, image\nrecognition, semantic segmentation, and change detection. However, there are\noften seam lines on the mosaic boundary and radiometric contrast left,\nespecially in complex scenarios, making the appearance of mosaic images\nunsightly and reducing the accuracy of the latter classification/recognition\nalgorithms. This paper renders a novel automatical approach to eliminate seam\nlines in complex RRN mosaicking scenarios. It utilizes the histogram matching\non the overlap area to alleviate radiometric contrast, Poisson editing to\nremove the seam lines, and merging procedure to determine the normalization\ntransfer order. Our method can handle the mosaicking seam lines with arbitrary\nshapes and images with extreme topological relationships (with a small\nintersection area). These conditions make the main feathering or blending\nmethods, e.g., linear weighted blending and Laplacian pyramid blending,\nunavailable. In the experiment, our approach visually surpasses the automatic\nmethods without Poisson editing and the manual blurring and feathering method\nusing GIMP software.",
    "descriptor": "",
    "authors": [
      "Shiqi Liu",
      "Jie Lian",
      "Xuchen Zhan",
      "Cong Liu",
      "Yuze Tian",
      "Hongwei Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07441"
  },
  {
    "id": "arXiv:2106.07442",
    "title": "Latency-Constrained Prediction of mmWave/THz Link Blockages through  Meta-Learning",
    "abstract": "Wireless applications that use high-reliability low-latency links depend\ncritically on the capability of the system to predict link quality. This\ndependence is especially acute at the high carrier frequencies used by mmWave\nand THz systems, where the links are susceptible to blockages. Predicting\nblockages with high reliability requires a large number of data samples to\ntrain effective machine learning modules. With the aim of mitigating data\nrequirements, we introduce a framework based on meta-learning, whereby data\nfrom distinct deployments are leveraged to optimize a shared initialization\nthat decreases the data set size necessary for any new deployment. Predictors\nof two different events are studied: (1) at least one blockage occurs in a time\nwindow, and (2) the link is blocked for the entire time window. The results\nshow that an RNN-based predictor trained using meta-learning is able to predict\nblockages after observing fewer samples than predictors trained using standard\nmethods.",
    "descriptor": "",
    "authors": [
      "Anders E. Kal\u00f8r",
      "Osvaldo Simeone",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.07442"
  },
  {
    "id": "arXiv:2106.07445",
    "title": "PopSkipJump: Decision-Based Attack for Probabilistic Classifiers",
    "abstract": "Most current classifiers are vulnerable to adversarial examples, small input\nperturbations that change the classification output. Many existing attack\nalgorithms cover various settings, from white-box to black-box classifiers, but\ntypically assume that the answers are deterministic and often fail when they\nare not. We therefore propose a new adversarial decision-based attack\nspecifically designed for classifiers with probabilistic outputs. It is based\non the HopSkipJump attack by Chen et al. (2019, arXiv:1904.02144v5 ), a strong\nand query efficient decision-based attack originally designed for deterministic\nclassifiers. Our P(robabilisticH)opSkipJump attack adapts its amount of queries\nto maintain HopSkipJump's original output quality across various noise levels,\nwhile converging to its query efficiency as the noise level decreases. We test\nour attack on various noise models, including state-of-the-art off-the-shelf\nrandomized defenses, and show that they offer almost no extra robustness to\ndecision-based attacks. Code is available at\nhttps://github.com/cjsg/PopSkipJump .",
    "descriptor": "\nComments: ICML'21. Code available at this https URL . 9 pages & 7 figures in main part, 14 pages & 10 figures in appendix\n",
    "authors": [
      "Carl-Johann Simon-Gabriel",
      "Noman Ahmed Sheikh",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07445"
  },
  {
    "id": "arXiv:2106.07447",
    "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked  Prediction of Hidden Units",
    "abstract": "Self-supervised approaches for speech representation learning are challenged\nby three unique problems: (1) there are multiple sound units in each input\nutterance, (2) there is no lexicon of input sound units during the pre-training\nphase, and (3) sound units have variable lengths with no explicit segmentation.\nTo deal with these three problems, we propose the Hidden-Unit BERT (HuBERT)\napproach for self-supervised speech representation learning, which utilizes an\noffline clustering step to provide aligned target labels for a BERT-like\nprediction loss. A key ingredient of our approach is applying the prediction\nloss over the masked regions only, which forces the model to learn a combined\nacoustic and language model over the continuous inputs. HuBERT relies primarily\non the consistency of the unsupervised clustering step rather than the\nintrinsic quality of the assigned cluster labels. Starting with a simple\nk-means teacher of 100 clusters, and using two iterations of clustering, the\nHuBERT model either matches or improves upon the state-of-the-art wav2vec 2.0\nperformance on the Librispeech (960h) and Libri-light (60,000h) benchmarks with\n10min, 1h, 10h, 100h, and 960h fine-tuning subsets. Using a 1B parameter model,\nHuBERT shows up to 19% and 13% relative WER reduction on the more challenging\ndev-other and test-other evaluation subsets.",
    "descriptor": "",
    "authors": [
      "Wei-Ning Hsu",
      "Benjamin Bolte",
      "Yao-Hung Hubert Tsai",
      "Kushal Lakhotia",
      "Ruslan Salakhutdinov",
      "Abdelrahman Mohamed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.07447"
  },
  {
    "id": "arXiv:2106.07448",
    "title": "A Novel mapping for visual to auditory sensory substitution",
    "abstract": "visual information can be converted into audio stream via sensory\nsubstitution devices in order to give visually impaired people the chance of\nperception of their surrounding easily and simultaneous to performing everyday\ntasks. In this study, visual environmental features namely, coordinate, type of\nobjects and their size are assigned to audio features related to music tones\nsuch as frequency, time duration and note permutations. Results demonstrated\nthat this new method has more training time efficiency in comparison with our\nprevious method named VBTones which sinusoidal tones were applied. Moreover,\nresults in blind object recognition for real objects was achieved 88.05 on\naverage.",
    "descriptor": "",
    "authors": [
      "Ezsan Mehrbani",
      "Sezedeh Fatemeh Mirhoseini",
      "Noushin Riahi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07448"
  },
  {
    "id": "arXiv:2106.07449",
    "title": "A Methodology For Creating Information Flow Specifications of Hardware  Designs",
    "abstract": "We present a methodology for creating information flow specifications of\nhardware designs. Such specifications can help designers better understand\ntheir design and are necessary for security validation processes. By combining\ninformation flow tracking and specification mining, we are able to produce\ninformation flow properties of a design without prior knowledge of security\nagreements or specifications. We develop a tool, Isadora, to evaluate our\nmethodology. We demonstrate Isadora may define the information flows within an\naccess control module in isolation and within an SoC and over a RISC-V design.\nOver the access control module, Isadora mined output completely covers an\nassertion based security specification of the design provided by the designers.\nFor both the access control module and RISC-V, we sample Isadora output\nproperties and find 10 out of 10 and 8 out of 10 properties, respectively,\ndefine the design behavior to relevant to a Common Weakness Enumeration (CWE).\nWe find our methodology may independently mine security properties manually\ndeveloped by hardware designers, automatically generate properties describing\nCWEs over a design, and scale to SoC and CPU designs.",
    "descriptor": "\nComments: 9 pages, 4 figures, submitted to ICCAD 2021\n",
    "authors": [
      "Calvin Deutschbein",
      "Andres Meza",
      "Francesco Restuccia",
      "Ryan Kastner",
      "Cynthia Sturton"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.07449"
  },
  {
    "id": "arXiv:2106.07451",
    "title": "PI-GNN: A Novel Perspective on Semi-Supervised Node Classification  against Noisy Labels",
    "abstract": "Semi-supervised node classification, as a fundamental problem in graph\nlearning, leverages unlabeled nodes along with a small portion of labeled nodes\nfor training. Existing methods rely heavily on high-quality labels, which,\nhowever, are expensive to obtain in real-world applications since certain\nnoises are inevitably involved during the labeling process. It hence poses an\nunavoidable challenge for the learning algorithm to generalize well. In this\npaper, we propose a novel robust learning objective dubbed pairwise\ninteractions (PI) for the model, such as Graph Neural Network (GNN) to combat\nnoisy labels. Unlike classic robust training approaches that operate on the\npointwise interactions between node and class label pairs, PI explicitly forces\nthe embeddings for node pairs that hold a positive PI label to be close to each\nother, which can be applied to both labeled and unlabeled nodes. We design\nseveral instantiations for PI labels based on the graph structure and the node\nclass labels, and further propose a new uncertainty-aware training technique to\nmitigate the negative effect of the sub-optimal PI labels. Extensive\nexperiments on different datasets and GNN architectures demonstrate the\neffectiveness of PI, yielding a promising improvement over the state-of-the-art\nmethods.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Xuefeng Du",
      "Tian Bian",
      "Yu Rong",
      "Bo Han",
      "Tongliang Liu",
      "Tingyang Xu",
      "Wenbing Huang",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07451"
  },
  {
    "id": "arXiv:2106.07453",
    "title": "Efficient Data-specific Model Search for Collaborative Filtering",
    "abstract": "Collaborative filtering (CF), as a fundamental approach for recommender\nsystems, is usually built on the latent factor model with learnable parameters\nto predict users' preferences towards items. However, designing a proper CF\nmodel for a given data is not easy, since the properties of datasets are highly\ndiverse. In this paper, motivated by the recent advances in automated machine\nlearning (AutoML), we propose to design a data-specific CF model by AutoML\ntechniques. The key here is a new framework that unifies state-of-the-art\n(SOTA) CF methods and splits them into disjoint stages of input encoding,\nembedding function, interaction function, and prediction function. We further\ndevelop an easy-to-use, robust, and efficient search strategy, which utilizes\nrandom search and a performance predictor for efficient searching within the\nabove framework. In this way, we can combinatorially generalize data-specific\nCF models, which have not been visited in the literature, from SOTA ones.\nExtensive experiments on five real-world datasets demonstrate that our method\ncan consistently outperform SOTA ones for various CF tasks. Further experiments\nverify the rationality of the proposed framework and the efficiency of the\nsearch strategy. The searched CF models can also provide insights for exploring\nmore effective methods in the future",
    "descriptor": "\nComments: KDD 2021\n",
    "authors": [
      "Chen Gao",
      "Quanming Yao",
      "Depeng Jin",
      "Yong Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07453"
  },
  {
    "id": "arXiv:2106.07455",
    "title": "Resilient and Distributed Discrete Optimal Transport with Deceptive  Adversary: A Game-Theoretic Approach",
    "abstract": "Optimal transport (OT) is a framework that can be used to guide the optimal\nallocation of a limited amount of resources. The classical OT paradigm does not\nconsider malicious attacks in its formulation and thus the designed transport\nplan lacks resiliency to an adversary. To address this concern, we establish an\nOT framework that explicitly accounts for the adversarial and stealthy\nmanipulation of participating nodes in the network during the transport\nstrategy design. Specifically, we propose a game-theoretic approach to capture\nthe strategic interactions between the transport planner and the deceptive\nattacker. We analyze the properties of the established two-person zero-sum game\nthoroughly. We further develop a fully distributed algorithm to compute the\noptimal resilient transport strategies, and show the convergence of the\nalgorithm to a saddle-point equilibrium. Finally, we demonstrate the\neffectiveness of the designed algorithm using case studies.",
    "descriptor": "\nComments: Long version of paper of the same title in Control System Letters (L-CSS)\n",
    "authors": [
      "Jason Hughes",
      "Juntao Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07455"
  },
  {
    "id": "arXiv:2106.07456",
    "title": "Extending the RISC-V ISA for exploring advanced reconfigurable SIMD  instructions",
    "abstract": "This paper presents a novel, non-standard set of vector instruction types for\nexploring custom SIMD instructions in a softcore. The new types allow\nsimultaneous access to a relatively high number of operands, reducing the\ninstruction count where applicable. Additionally, a high-performance\nopen-source RISC-V (RV32 IM) softcore is introduced, optimised for exploring\ncustom SIMD instructions and streaming performance. By providing instruction\ntemplates for instruction development in HDL/Verilog, efficient FPGA-based\ninstructions can be developed with few low-level lines of code. In order to\nimprove custom SIMD instruction performance, the softcore's cache hierarchy is\noptimised for bandwidth, such as with very wide blocks for the last-level\ncache. The approach is demonstrated on example memory-intensive applications on\nan FPGA. Although the exploration is based on the softcore, the goal is to\nprovide a means to experiment with advanced SIMD instructions which could be\nloaded in future CPUs that feature reconfigurable regions as custom\ninstructions. Finally, we provide some insights on the challenges and\neffectiveness of such future micro-architectures.",
    "descriptor": "\nComments: Accepted at the Fifth Workshop on Computer Architecture Research with RISC-V (CARRV 2021), co-located with ISCA 2021\n",
    "authors": [
      "Philippos Papaphilippou",
      "Paul H. J. Kelly",
      "Wayne Luk"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.07456"
  },
  {
    "id": "arXiv:2106.07459",
    "title": "Piercing All Translates of a Set of Axis-Parallel Rectangles",
    "abstract": "For a given shape $S$ in the plane, one can ask what is the lowest possible\ndensity of a point set $P$ that pierces (``intersects'', ``hits'') all\ntranslates of $S$. This is equivalent to determining the covering density of\n$S$ and as such is well studied. Here we study the analogous question for\nfamilies of shapes where the connection to covering no longer exists. That is,\nwe require that a single point set $P$ simultaneously pierces each translate of\neach shape from some family $\\mathcal F$. We denote the lowest possible density\nof such an $\\mathcal F$-piercing point set by $\\pi_T(\\mathcal F)$.\nSpecifically, we focus on families $\\mathcal F$ consisting of axis-parallel\nrectangles. When $|\\mathcal F|=2$ we exactly solve the case when one rectangle\nis more squarish than $2\\times 1$, and give bounds (within $10\\,\\%$ of each\nother) for the remaining case when one rectangle is wide and the other one is\ntall. When $|\\mathcal F|\\ge 2$ we present a linear-time constant-factor\napproximation algorithm for computing $\\pi_T(\\mathcal F)$ (with ratio $1.895$).",
    "descriptor": "\nComments: 14 pages, 4 figures, to appear in Proceedings of IWOCA 2021\n",
    "authors": [
      "Adrian Dumitrescu",
      "Josef Tkadlec"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.07459"
  },
  {
    "id": "arXiv:2106.07464",
    "title": "Meta-Interpretive Learning as Metarule Specialisation",
    "abstract": "In Meta-Interpretive Learning (MIL) the metarules, second-order datalog\nclauses acting as inductive bias, are manually defined by the user. In this\nwork we show that second-order metarules for MIL can be learned by MIL. We\ndefine a generality ordering of metarules by $\\theta$-subsumption and show that\nuser-defined sort metarules are derivable by specialisation of the most-general\nmatrix metarules in a language class; and that these matrix metarules are in\nturn derivable by specialisation of third-order punch metarules with variables\nthat range over the set of second-order literals and for which only an upper\nbound on their number of literals need be user-defined. We show that the\ncardinality of a metarule language is polynomial in the number of literals in\npunch metarules. We re-frame MIL as metarule specialisation by resolution. We\nmodify the MIL metarule specialisation operator to return new metarules rather\nthan first-order clauses and prove the correctness of the new operator. We\nimplement the new operator as TOIL, a sub-system of the MIL system Louise. Our\nexperiments show that as user-defined sort metarules are progressively replaced\nby sort metarules learned by TOIL, Louise's predictive accuracy is maintained\nat the cost of a small increase in training times. We conclude that\nautomatically derived metarules can replace user-defined metarules.",
    "descriptor": "\nComments: 24 pages. Submitted to the Machine Learning Journal Special Issue on Learning and Reasoning on June 1st, 2021\n",
    "authors": [
      "Stassa Patsantzis",
      "Stephen H. Muggleton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07464"
  },
  {
    "id": "arXiv:2106.07468",
    "title": "On the stability of conservative discontinuous Galerkin/Hermite spectral  methods for the Vlasov-Poisson system",
    "abstract": "We study a class of spatial discretizations for the Vlasov-Poisson system\nwritten as an hyperbolic system using Hermite polynomials. In particular, we\nfocus on spectral methods and discontinuous Galerkin approximations. To obtain\nL 2 stability properties, we introduce a new L 2 weighted space, with a time\ndependent weight. For the Hermite spectral form of the Vlasov-Poisson system,\nwe prove conservation of mass, momentum and total energy, as well as global\nstability for the weighted L 2 norm. These properties are then discussed for\nseveral spatial discretizations. Finally, numerical simulations are performed\nwith the proposed DG/Hermite spectral method to highlight its stability and\nconservation features.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2004.02685\n",
    "authors": [
      "Marianne Bessemoulin-Chatard",
      "Francis Filbet"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07468"
  },
  {
    "id": "arXiv:2106.07470",
    "title": "Comparing vector fields across surfaces: interest for characterizing the  orientations of cortical folds",
    "abstract": "Vectors fields defined on surfaces constitute relevant and useful\nrepresentations but are rarely used. One reason might be that comparing vector\nfields across two surfaces of the same genus is not trivial: it requires to\ntransport the vector fields from the original surfaces onto a common domain. In\nthis paper, we propose a framework to achieve this task by mapping the vector\nfields onto a common space, using some notions of differential geometry. The\nproposed framework enables the computation of statistics on vector fields. We\ndemonstrate its interest in practice with an application on real data with a\nquantitative assessment of the reproducibility of curvature directions that\ndescribe the complex geometry of cortical folding patterns. The proposed\nframework is general and can be applied to different types of vector fields and\nsurfaces, allowing for a large number of high potential applications in medical\nimaging.",
    "descriptor": "",
    "authors": [
      "Amine Bohi",
      "Guillaume Auzias",
      "Julien Lef\u00e8vre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Differential Geometry (math.DG)",
      "Biological Physics (physics.bio-ph)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.07470"
  },
  {
    "id": "arXiv:2106.07471",
    "title": "Signal processing on simplicial complexes",
    "abstract": "Higher-order networks have so far been considered primarily in the context of\nstudying the structure of complex systems, i.e., the higher-order or multi-way\nrelations connecting the constituent entities. More recently, a number of\nstudies have considered dynamical processes that explicitly ac- count for such\nhigher-order dependencies, e.g., in the context of epidemic spreading processes\nor opinion formation. In this chapter, we focus on a closely related, but\ndistinct third perspective: how can we use higher-order relationships to\nprocess signals and data supported on higher-order network structures. In\nparticular, we survey how ideas from signal processing of data supported on\nregular domains, such as time series or images, can be extended to graphs and\nsimplicial complexes. We discuss Fourier analysis, signal denois- ing, signal\ninterpolation, and nonlinear processing through neural networks based on\nsimplicial complexes. Key to our developments is the Hodge Laplacian matrix, a\nmulti-relational operator that leverages the special structure of simplicial\ncomplexes and generalizes desirable properties of the Laplacian matrix in graph\nsignal processing.",
    "descriptor": "\nComments: 29 pages; 5 figures. arXiv admin note: text overlap with arXiv:2101.05510\n",
    "authors": [
      "Michael T. Schaub",
      "Jean-Baptiste Seby",
      "Florian Frantzen",
      "T. Mitchell Roddenberry",
      "Yu Zhu",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.07471"
  },
  {
    "id": "arXiv:2106.07472",
    "title": "Analysis of a Target-Based Actor-Critic Algorithm with Linear Function  Approximation",
    "abstract": "Actor-critic methods integrating target networks have exhibited a stupendous\nempirical success in deep reinforcement learning. However, a theoretical\nunderstanding of the use of target networks in actor-critic methods is largely\nmissing in the literature. In this paper, we bridge this gap between theory and\npractice by proposing the first theoretical analysis of an online target-based\nactor-critic algorithm with linear function approximation in the discounted\nreward setting. Our algorithm uses three different timescales: one for the\nactor and two for the critic. Instead of using the standard single timescale\ntemporal difference (TD) learning algorithm as a critic, we use a two\ntimescales target-based version of TD learning closely inspired from practical\nactor-critic algorithms implementing target networks. First, we establish\nasymptotic convergence results for both the critic and the actor under\nMarkovian sampling. Then, we provide a finite-time analysis showing the impact\nof incorporating a target network into actor-critic methods.",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Anas Barakat",
      "Pascal Bianchi",
      "Julien Lehmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07472"
  },
  {
    "id": "arXiv:2106.07473",
    "title": "Time Series Anomaly Detection with label-free Model Selection",
    "abstract": "Anomaly detection for time-series data becomes an essential task for many\ndata-driven applications fueled with an abundance of data and out-of-the-box\nmachine-learning algorithms. In many real-world settings, developing a reliable\nanomaly model is highly challenging due to insufficient anomaly labels and the\nprohibitively expensive cost of obtaining anomaly examples. It imposes a\nsignificant bottleneck to evaluate model quality for model selection and\nparameter tuning reliably. As a result, many existing anomaly detection\nalgorithms fail to show their promised performance after deployment.\nIn this paper, we propose LaF-AD, a novel anomaly detection algorithm with\nlabel-free model selection for unlabeled times-series data. Our proposed\nalgorithm performs a fully unsupervised ensemble learning across a large number\nof candidate parametric models. We develop a model variance metric that\nquantifies the sensitivity of anomaly probability with a bootstrapping method.\nThen it makes a collective decision for anomaly events by model learners using\nthe model variance. Our algorithm is easily parallelizable, more robust for\nill-conditioned and seasonal data, and highly scalable for a large number of\nanomaly models. We evaluate our algorithm against other state-of-the-art\nmethods on a synthetic domain and a benchmark public data set.",
    "descriptor": "\nComments: 11 pages, 1 Figure, 4 tables\n",
    "authors": [
      "Deokwoo Jung",
      "Nandini Ramanan",
      "Mehrnaz Amjadi",
      "Sankeerth Rao Karingula",
      "Jake Taylor",
      "Claudionor Nunes Coelho Jr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07473"
  },
  {
    "id": "arXiv:2106.07474",
    "title": "Discovering Interpretable Machine Learning Models in Parallel  Coordinates",
    "abstract": "This paper contributes to interpretable machine learning via visual knowledge\ndiscovery in parallel coordinates. The concepts of hypercubes and hyper-blocks\nare used as easily understandable by end-users in the visual form in parallel\ncoordinates. The Hyper algorithm for classification with mixed and pure\nhyper-blocks (HBs) is proposed to discover hyper-blocks interactively and\nautomatically in individual, multiple, overlapping, and non-overlapping\nsetting. The combination of hyper-blocks with linguistic description of visual\npatterns is presented too. It is shown that Hyper models generalize decision\ntrees. The Hyper algorithm was tested on the benchmark data from UCI ML\nrepository. It allowed discovering pure and mixed HBs with all data and then\nwith 10-fold cross validation. The links between hyper-blocks, dimension\nreduction and visualization are established. Major benefits of hyper-block\ntechnology and the Hyper algorithm are in their ability to discover and observe\nhyper-blocks by end-users including side by side visualizations making patterns\nvisible for all classes. Another advantage of sets of HBs relative to the\ndecision trees is the ability to avoid both data overgeneralization and\noverfitting.",
    "descriptor": "\nComments: 9 pages, 18 figures\n",
    "authors": [
      "Boris Kovalerchuk",
      "Dustin Hayes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07474"
  },
  {
    "id": "arXiv:2106.07475",
    "title": "Investigating sanity checks for saliency maps with image and text  classification",
    "abstract": "Saliency maps have shown to be both useful and misleading for explaining\nmodel predictions especially in the context of images. In this paper, we\nperform sanity checks for text modality and show that the conclusions made for\nimage do not directly transfer to text. We also analyze the effects of the\ninput multiplier in certain saliency maps using similarity scores,\nmax-sensitivity and infidelity evaluation metrics. Our observations reveal that\nthe input multiplier carries input's structural patterns in explanation maps,\nthus leading to similar results regardless of the choice of model parameters.\nWe also show that the smoothness of a Neural Network (NN) function can affect\nthe quality of saliency-based explanations. Our investigations reveal that\nreplacing ReLUs with Softplus and MaxPool with smoother variants such as\nLogSumExp (LSE) can lead to explanations that are more reliable based on the\ninfidelity evaluation metric.",
    "descriptor": "",
    "authors": [
      "Narine Kokhlikyan",
      "Vivek Miglani",
      "Bilal Alsallakh",
      "Miguel Martin",
      "Orion Reblitz-Richardson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07475"
  },
  {
    "id": "arXiv:2106.07476",
    "title": "Training Graph Neural Networks with 1000 Layers",
    "abstract": "Deep graph neural networks (GNNs) have achieved excellent results on various\ntasks on increasingly large graph datasets with millions of nodes and edges.\nHowever, memory complexity has become a major obstacle when training deep GNNs\nfor practical applications due to the immense number of nodes, edges, and\nintermediate activations. To improve the scalability of GNNs, prior works\npropose smart graph sampling or partitioning strategies to train GNNs with a\nsmaller set of nodes or sub-graphs. In this work, we study reversible\nconnections, group convolutions, weight tying, and equilibrium models to\nadvance the memory and parameter efficiency of GNNs. We find that reversible\nconnections in combination with deep network architectures enable the training\nof overparameterized GNNs that significantly outperform existing methods on\nmultiple datasets. Our models RevGNN-Deep (1001 layers with 80 channels each)\nand RevGNN-Wide (448 layers with 224 channels each) were both trained on a\nsingle commodity GPU and achieve an ROC-AUC of $87.74 \\pm 0.13$ and $88.14 \\pm\n0.15$ on the ogbn-proteins dataset. To the best of our knowledge, RevGNN-Deep\nis the deepest GNN in the literature by one order of magnitude. Please visit\nour project website https://www.deepgcns.org/arch/gnn1000 for more information.",
    "descriptor": "\nComments: Accepted at ICML'2021. Code available at this https URL Work done during Guohao Li's internship at Intel Intelligent Systems Lab\n",
    "authors": [
      "Guohao Li",
      "Matthias M\u00fcller",
      "Bernard Ghanem",
      "Vladlen Koltun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.07476"
  },
  {
    "id": "arXiv:2106.07477",
    "title": "S$^2$-MLP: Spatial-Shift MLP Architecture for Vision",
    "abstract": "Recently, visual Transformer (ViT) and its following works abandon the\nconvolution and exploit the self-attention operation, attaining a comparable or\neven higher accuracy than CNN. More recently, MLP-Mixer abandons both the\nconvolution and the self-attention operation, proposing an architecture\ncontaining only MLP layers. To achieve cross-patch communications, it devises\nan additional token-mixing MLP besides the channel-mixing MLP. It achieves\npromising results when training on an extremely large-scale dataset. But it\ncannot achieve as outstanding performance as its CNN and ViT counterparts when\ntraining on medium-scale datasets such as ImageNet1K and ImageNet21K. The\nperformance drop of MLP-Mixer motivates us to rethink the token-mixing MLP. We\ndiscover that token-mixing operation in MLP-Mixer is a variant of depthwise\nconvolution with a global reception field and spatial-specific configuration.\nBut the global reception field and the spatial-specific property make\ntoken-mixing MLP prone to over-fitting. In this paper, we propose a novel pure\nMLP architecture, spatial-shift MLP (S$^2$-MLP). Different from MLP-Mixer, our\nS$^2$-MLP only contains channel-mixing MLP. We devise a spatial-shift operation\nfor achieving the communication between patches. It has a local reception field\nand is spatial-agnostic. Meanwhile, it is parameter-free and efficient for\ncomputation. The proposed S$^2$-MLP attains higher recognition accuracy than\nMLP-Mixer when training on ImageNet-1K dataset. Meanwhile, S$^2$-MLP\naccomplishes as excellent performance as ViT on ImageNet-1K dataset with\nconsiderably simpler architecture and fewer FLOPs and parameters.",
    "descriptor": "",
    "authors": [
      "Tan Yu",
      "Xu Li",
      "Yunfeng Cai",
      "Mingming Sun",
      "Ping Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07477"
  },
  {
    "id": "arXiv:2106.07479",
    "title": "An Online Riemannian PCA for Stochastic Canonical Correlation Analysis",
    "abstract": "We present an efficient stochastic algorithm (RSG+) for canonical correlation\nanalysis (CCA) using a reparametrization of the projection matrices. We show\nhow this reparametrization (into structured matrices), simple in hindsight,\ndirectly presents an opportunity to repurpose/adjust mature techniques for\nnumerical optimization on Riemannian manifolds. Our developments nicely\ncomplement existing methods for this problem which either require $O(d^3)$ time\ncomplexity per iteration with $O(\\frac{1}{\\sqrt{t}})$ convergence rate (where\n$d$ is the dimensionality) or only extract the top $1$ component with\n$O(\\frac{1}{t})$ convergence rate. In contrast, our algorithm offers a strict\nimprovement for this classical problem: it achieves $O(d^2k)$ runtime\ncomplexity per iteration for extracting the top $k$ canonical components with\n$O(\\frac{1}{t})$ convergence rate. While the paper primarily focuses on the\nformulation and technical analysis of its properties, our experiments show that\nthe empirical behavior on common datasets is quite promising. We also explore a\npotential application in training fair models where the label of protected\nattribute is missing or otherwise unavailable.",
    "descriptor": "",
    "authors": [
      "Zihang Meng",
      "Rudrasis Chakraborty",
      "Vikas Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07479"
  },
  {
    "id": "arXiv:2106.07482",
    "title": "Graph Domain Adaptation: A Generative View",
    "abstract": "Recent years have witnessed tremendous interest in deep learning on\ngraph-structured data. Due to the high cost of collecting labeled\ngraph-structured data, domain adaptation is important to supervised graph\nlearning tasks with limited samples. However, current graph domain adaptation\nmethods are generally adopted from traditional domain adaptation tasks, and the\nproperties of graph-structured data are not well utilized. For example, the\nobserved social networks on different platforms are controlled not only by the\ndifferent crowd or communities but also by the domain-specific policies and the\nbackground noise. Based on these properties in graph-structured data, we first\nassume that the graph-structured data generation process is controlled by three\nindependent types of latent variables, i.e., the semantic latent variables, the\ndomain latent variables, and the random latent variables. Based on this\nassumption, we propose a disentanglement-based unsupervised domain adaptation\nmethod for the graph-structured data, which applies variational graph\nauto-encoders to recover these latent variables and disentangles them via three\nsupervised learning modules. Extensive experimental results on two real-world\ndatasets in the graph classification task reveal that our method not only\nsignificantly outperforms the traditional domain adaptation methods and the\ndisentangled-based domain adaptation methods but also outperforms the\nstate-of-the-art graph domain adaptation algorithms.",
    "descriptor": "",
    "authors": [
      "Ruichu Cai",
      "Fengzhu Wu",
      "Zijian Li",
      "Pengfei Wei",
      "Lingling Yi",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07482"
  },
  {
    "id": "arXiv:2106.07483",
    "title": "Can Explainable AI Explain Unfairness? A Framework for Evaluating  Explainable AI",
    "abstract": "Many ML models are opaque to humans, producing decisions too complex for\nhumans to easily understand. In response, explainable artificial intelligence\n(XAI) tools that analyze the inner workings of a model have been created.\nDespite these tools' strength in translating model behavior, critiques have\nraised concerns about the impact of XAI tools as a tool for `fairwashing` by\nmisleading users into trusting biased or incorrect models. In this paper, we\ncreated a framework for evaluating explainable AI tools with respect to their\ncapabilities for detecting and addressing issues of bias and fairness as well\nas their capacity to communicate these results to their users clearly. We found\nthat despite their capabilities in simplifying and explaining model behavior,\nmany prominent XAI tools lack features that could be critical in detecting\nbias. Developers can use our framework to suggest modifications needed in their\ntoolkits to reduce issues likes fairwashing.",
    "descriptor": "",
    "authors": [
      "Kiana Alikhademi",
      "Brianna Richardson",
      "Emma Drobina",
      "Juan E. Gilbert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07483"
  },
  {
    "id": "arXiv:2106.07484",
    "title": "Conservative Integrators for Piecewise Smooth Systems with Transversal  Dynamics",
    "abstract": "We introduce conservative integrators for long term integration of piecewise\nsmooth systems with transversal dynamics and piecewise smooth conserved\nquantities. In essence, for a piecewise dynamical system with piecewise defined\nconserved quantities such that its trajectories cross transversally to its\ninterface, we combine Mannshardt's transition scheme and the Discrete\nMultiplier Method to obtain conservative integrators capable of preserving\nconserved quantities up to machine precision and accuracy order. We prove that\nthe order of accuracy of the integrators is preserved after crossing the\ndiscontinuity in the case of codimension one number of conserved quantities.\nNumerical examples illustrate the preservation of accuracy order.",
    "descriptor": "",
    "authors": [
      "Anil N. Hirani",
      "Andy T.S. Wan",
      "Nikolas Wojtalewicz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07484"
  },
  {
    "id": "arXiv:2106.07485",
    "title": "Grammar Equations",
    "abstract": "Diagrammatically speaking, grammatical calculi such as pregroups provide\nwires between words in order to elucidate their interactions, and this enables\none to verify grammatical correctness of phrases and sentences. In this paper\nwe also provide wirings within words. This will enable us to identify\ngrammatical constructs that we expect to be either equal or closely related.\nHence, our work paves the way for a new theory of grammar, that provides novel\n`grammatical truths'. We give a nogo-theorem for the fact that our wirings for\nwords make no sense for preordered monoids, the form which grammatical calculi\nusually take. Instead, they require diagrams -- or equivalently, (free)\nmonoidal categories.",
    "descriptor": "\nComments: 10 pages, many pictures\n",
    "authors": [
      "Bob Coecke",
      "Vincent Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2106.07485"
  },
  {
    "id": "arXiv:2106.07487",
    "title": "pix2rule: End-to-end Neuro-symbolic Rule Learning",
    "abstract": "Humans have the ability to seamlessly combine low-level visual input with\nhigh-level symbolic reasoning often in the form of recognising objects,\nlearning relations between them and applying rules. Neuro-symbolic systems aim\nto bring a unifying approach to connectionist and logic-based principles for\nvisual processing and abstract reasoning respectively. This paper presents a\ncomplete neuro-symbolic method for processing images into objects, learning\nrelations and logical rules in an end-to-end fashion. The main contribution is\na differentiable layer in a deep learning architecture from which symbolic\nrelations and rules can be extracted by pruning and thresholding. We evaluate\nour model using two datasets: subgraph isomorphism task for symbolic rule\nlearning and an image classification domain with compound relations for\nlearning objects, relations and rules. We demonstrate that our model scales\nbeyond state-of-the-art symbolic learners and outperforms deep relational\nneural network architectures.",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Nuri Cingillioglu",
      "Alessandra Russo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07487"
  },
  {
    "id": "arXiv:2106.07488",
    "title": "User-Guided Personalized Image Aesthetic Assessment based on Deep  Reinforcement Learning",
    "abstract": "Personalized image aesthetic assessment (PIAA) has recently become a hot\ntopic due to its usefulness in a wide variety of applications such as\nphotography, film and television, e-commerce, fashion design and so on. This\ntask is more seriously affected by subjective factors and samples provided by\nusers. In order to acquire precise personalized aesthetic distribution by small\namount of samples, we propose a novel user-guided personalized image aesthetic\nassessment framework. This framework leverages user interactions to retouch and\nrank images for aesthetic assessment based on deep reinforcement learning\n(DRL), and generates personalized aesthetic distribution that is more in line\nwith the aesthetic preferences of different users. It mainly consists of two\nstages. In the first stage, personalized aesthetic ranking is generated by\ninteractive image enhancement and manual ranking, meanwhile two policy networks\nwill be trained. The images will be pushed to the user for manual retouching\nand simultaneously to the enhancement policy network. The enhancement network\nutilizes the manual retouching results as the optimization goals of DRL. After\nthat, the ranking process performs the similar operations like the retouching\nmentioned before. These two networks will be trained iteratively and\nalternatively to help to complete the final personalized aesthetic assessment\nautomatically. In the second stage, these modified images are labeled with\naesthetic attributes by one style-specific classifier, and then the\npersonalized aesthetic distribution is generated based on the multiple\naesthetic attributes of these images, which conforms to the aesthetic\npreference of users better.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Pei Lv",
      "Jianqi Fan",
      "Xixi Nie",
      "Weiming Dong",
      "Xiaoheng Jiang",
      "Bing Zhou",
      "Mingliang Xu",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.07488"
  },
  {
    "id": "arXiv:2106.07497",
    "title": "Security testing using JUnit and Perl scripts",
    "abstract": "In this paper, I describe a recent practical experience where JUnit was used\nfor testing security bugs in addition to functional bugs. Perl scripts were\nalso used during the exploration phase. The application being tested was\nmature, but insecure.",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "Julian Harty"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.07497"
  },
  {
    "id": "arXiv:2106.07499",
    "title": "An Empirical Survey of Data Augmentation for Limited Data Learning in  NLP",
    "abstract": "NLP has achieved great progress in the past decade through the use of neural\nmodels and large labeled datasets. The dependence on abundant data prevents NLP\nmodels from being applied to low-resource settings or novel tasks where\nsignificant time, money, or expertise is required to label massive amounts of\ntextual data. Recently, data augmentation methods have been explored as a means\nof improving data efficiency in NLP. To date, there has been no systematic\nempirical overview of data augmentation for NLP in the limited labeled data\nsetting, making it difficult to understand which methods work in which\nsettings. In this paper, we provide an empirical survey of recent progress on\ndata augmentation for NLP in the limited labeled data setting, summarizing the\nlandscape of methods (including token-level augmentations, sentence-level\naugmentations, adversarial augmentations, and hidden-space augmentations) and\ncarrying out experiments on 11 datasets covering topics/news classification,\ninference tasks, paraphrasing tasks, and single-sentence tasks. Based on the\nresults, we draw several conclusions to help practitioners choose appropriate\naugmentations in different settings and discuss the current challenges and\nfuture directions for limited data learning in NLP.",
    "descriptor": "",
    "authors": [
      "Jiaao Chen",
      "Derek Tam",
      "Colin Raffel",
      "Mohit Bansal",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07499"
  },
  {
    "id": "arXiv:2106.07501",
    "title": "Balanced Coarsening for Multilevel Hypergraph Partitioning via  Wasserstein Discrepancy",
    "abstract": "We propose a balanced coarsening scheme for multilevel hypergraph\npartitioning. In addition, an initial partitioning algorithm is designed to\nimprove the quality of k-way hypergraph partitioning. By assigning vertex\nweights through the LPT algorithm, we generate a prior hypergraph under a\nrelaxed balance constraint. With the prior hypergraph, we have defined the\nWasserstein discrepancy to coordinate the optimal transport of coarsening\nprocess. And the optimal transport matrix is solved by Sinkhorn algorithm. Our\ncoarsening scheme fully takes into account the minimization of connectivity\nmetric (objective function). For the initial partitioning stage, we define a\nnormalized cut function induced by Fiedler vector, which is theoretically\nproved to be a concave function. Thereby, a three-point algorithm is designed\nto find the best cut under the balance constraint.",
    "descriptor": "",
    "authors": [
      "Zhicheng Guo",
      "Jiaxuan Zhao",
      "Licheng Jiao",
      "Xu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07501"
  },
  {
    "id": "arXiv:2106.07502",
    "title": "Training like Playing: A Reinforcement Learning And Knowledge  Graph-based framework for building Automatic Consultation System in Medical  Field",
    "abstract": "We introduce a framework for AI-based medical consultation system with\nknowledge graph embedding and reinforcement learning components and its\nimplement. Our implement of this framework leverages knowledge organized as a\ngraph to have diagnosis according to evidence collected from patients\nrecurrently and dynamically. According to experiment we designed for evaluating\nits performance, it archives a good result. More importantly, for getting\nbetter performance, researchers can implement it on this framework based on\ntheir innovative ideas, well designed experiments and even clinical trials.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Yining Huang",
      "Meilian Chen",
      "Keke Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07502"
  },
  {
    "id": "arXiv:2106.07504",
    "title": "Characterizing the risk of fairwashing",
    "abstract": "Fairwashing refers to the risk that an unfair black-box model can be\nexplained by a fairer model through post-hoc explanations' manipulation.\nHowever, to realize this, the post-hoc explanation model must produce different\npredictions than the original black-box on some inputs, leading to a decrease\nin the fidelity imposed by the difference in unfairness. In this paper, our\nmain objective is to characterize the risk of fairwashing attacks, in\nparticular by investigating the fidelity-unfairness trade-off. First, we\ndemonstrate through an in-depth empirical study on black-box models trained on\nseveral real-world datasets and for several statistical notions of fairness\nthat it is possible to build high-fidelity explanation models with low\nunfairness. For instance, we find that fairwashed explanation models can\nexhibit up to $99.20\\%$ fidelity to the black-box models they explain while\nbeing $50\\%$ less unfair. These results suggest that fidelity alone should not\nbe used as a proxy for the quality of black-box explanations. Second, we show\nthat fairwashed explanation models can generalize beyond the suing group\n(\\emph{i.e.}, data points that are being explained), which will only worsen as\nmore stable fairness methods get developed. Finally, we demonstrate that\nfairwashing attacks can transfer across black-box models, meaning that other\nblack-box models can perform fairwashing without explicitly using their\npredictions.",
    "descriptor": "",
    "authors": [
      "Ulrich A\u00efvodji",
      "Hiromi Arai",
      "S\u00e9bastien Gambs",
      "Satoshi Hara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07504"
  },
  {
    "id": "arXiv:2106.07505",
    "title": "Modeling Profanity and Hate Speech in Social Media with Semantic  Subspaces",
    "abstract": "Hate speech and profanity detection suffer from data sparsity, especially for\nlanguages other than English, due to the subjective nature of the tasks and the\nresulting annotation incompatibility of existing corpora. In this study, we\nidentify profane subspaces in word and sentence representations and explore\ntheir generalization capability on a variety of similar and distant target\ntasks in a zero-shot setting. This is done monolingually (German) and\ncross-lingually to closely-related (English), distantly-related (French) and\nnon-related (Arabic) tasks. We observe that, on both similar and distant target\ntasks and across all languages, the subspace-based representations transfer\nmore effectively than standard BERT representations in the zero-shot setting,\nwith improvements between F1 +10.9 and F1 +42.9 over the baselines across all\ntested monolingual and cross-lingual scenarios.",
    "descriptor": "\nComments: 9 pages, 4 figures, accepted as a long paper at Workshop on Online Abuse and Harms 2021\n",
    "authors": [
      "Vanessa Hahn",
      "Dana Ruiter",
      "Thomas Kleinbauer",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07505"
  },
  {
    "id": "arXiv:2106.07510",
    "title": "Computing the Cut Locus of a Riemannian Manifold via Optimal Transport",
    "abstract": "In this paper, we give a new characterization of the cut locus of a point on\na compact Riemannian manifold as the zero set of the optimal transport density\nsolution of the Monge-Kantorovich equations, a PDE formulation of the optimal\ntransport problem with cost equal to the geodesic distance. Combining this\nresult with an optimal transport numerical solver based on the so-called\ndynamical Monge-Kantorovich approach, we propose a novel framework for the\nnumerical approximation of the cut locus of a point in a manifold. We show the\napplicability of the proposed method on a few examples settled on 2d-surfaces\nembedded in $R^{3}$ and discuss advantages and limitations.",
    "descriptor": "",
    "authors": [
      "Enrico Facca",
      "Luca Berti",
      "Francesco Fass\u00f3",
      "Mario Putti"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Differential Geometry (math.DG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07510"
  },
  {
    "id": "arXiv:2106.07513",
    "title": "CodeLabeller: A Web-based Code Annotation Tool for Java Design Patterns  and Summaries",
    "abstract": "The appropriate use of design patterns in code is a vital measurement of good\nsoftware quality in object-oriented software applications. There exist tools to\ndetect design pattern usage in Java source files, where their detection\nmechanisms have been honed through the use of supervised machine learning\ntechniques that require large datasets of labelled files. However, manually\nlabelling these files leads to issues such as tediousness if the team of\nlabellers is small, and conflicting opinions between labellers, if large. Thus,\nwe present CodeLabeller, a web-based tool which aims to provide a more\nefficient approach in handling the process of labelling Java source files at\nscale by improving the data collection process throughout, and improving the\ndegree of reliability of responses by requiring each labeller to attach a\nconfidence rating to each of their responses. We test CodeLabeller by\nconstructing a corpus of over a thousand source files obtained from a large\ncollection of open-source Java projects, and labelling each Java source file\nwith their respective design patterns (if any), and summaries. This paper\ndiscusses the motivation behind thecreation of CodeLabeller, a demonstration of\nthe tool and its UI, its implementation, benefits and lastly, some ideas for\nfuture improvements. A demo version of CodeLabeller can be found at:\nhttps://codelabeller.org.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Norman Chen",
      "Najam Nazar",
      "Chun Yong Chong"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.07513"
  },
  {
    "id": "arXiv:2106.07520",
    "title": "JUGE: An Infrastructure for Benchmarking Java Unit Test Generators",
    "abstract": "Researchers and practitioners have designed and implemented various automated\ntest case generators to support effective software testing. Such generators\nexist for various languages (e.g., Java, C#, or Python) and for various\nplatforms (e.g., desktop, web, or mobile applications). Such generators exhibit\nvarying effectiveness and efficiency, depending on the testing goals they aim\nto satisfy (e.g., unit-testing of libraries vs. system-testing of entire\napplications) and the underlying techniques they implement. In this context,\npractitioners need to be able to compare different generators to identify the\nmost suited one for their requirements, while researchers seek to identify\nfuture research directions. This can be achieved through the systematic\nexecution of large-scale evaluations of different generators. However, the\nexecution of such empirical evaluations is not trivial and requires a\nsubstantial effort to collect benchmarks, setup the evaluation infrastructure,\nand collect and analyse the results. In this paper, we present our JUnit\nGeneration benchmarking infrastructure (JUGE) supporting generators (e.g.,\nsearch-based, random-based, symbolic execution, etc.) seeking to automate the\nproduction of unit tests for various purposes (e.g., validation, regression\ntesting, fault localization, etc.). The primary goal is to reduce the overall\neffort, ease the comparison of several generators, and enhance the knowledge\ntransfer between academia and industry by standardizing the evaluation and\ncomparison process. Since 2013, eight editions of a unit testing tool\ncompetition, co-located with the Search-Based Software Testing Workshop, have\ntaken place and used and updated JUGE. As a result, an increasing amount of\ntools (over ten) from both academia and industry have been evaluated on JUGE,\nmatured over the years, and allowed the identification of future research\ndirections.",
    "descriptor": "",
    "authors": [
      "Xavier Devroey",
      "Alessio Gambi",
      "Juan Pablo Galeotti",
      "Ren\u00e9 Just",
      "Fitsum Kifetew",
      "Annibale Panichella",
      "Sebastiano Panichella"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.07520"
  },
  {
    "id": "arXiv:2106.07527",
    "title": "Predicting 3D RNA Folding Patterns via Quadratic Binary Optimization",
    "abstract": "The structure of an RNA molecule plays a significant role in its biological\nfunction. Predicting structure given a one dimensional sequence of RNA\nnucleotide bases is a difficult and important problem. Many computer programs\n(known as in silico) are available for predicting 2-dimensional (secondary)\nstructures however 3-dimensional (tertiary) structure prediction is much more\ndifficult mainly due to the far greater number of feasible solutions and fewer\nexperimental data on the thermodynamic energies of 3D structures. It is also\nchallenging to verify the most likely three dimensional structure even with the\navailability of sophisticated x-ray crystallography and nuclear magnetic\nresonance imaging technologies. In this paper we develop three dimensional RNA\nfolding predictions by adding penalty and reward parameters to a previous two\ndimensional approach based on Quadratic Unconstrained Binary Optimization\n(QUBO) models. These parameters provide flexibility in the amount of three\ndimensional folding allowed. We address the problem of multiple near-optimal\nstructures via a new weighted similarity structure measure and illustrate\nfolding pathways via progressively improving local optimal solutions. The\nproblems are solved via a new commercial QUBO solver AlphaQUBO (Meta-Analytics,\n2020) that solves problems having hundreds of thousands of binary variables.",
    "descriptor": "\nComments: Summary results\n",
    "authors": [
      "Mark W. Lewis",
      "Amit Verma",
      "Rick Hennig"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07527"
  },
  {
    "id": "arXiv:2106.07528",
    "title": "On the Trust and Trust Modelling for the Future Fully-Connected Digital  World: A Comprehensive Study",
    "abstract": "With the fast development of digital technologies, we are running into a\ndigital world. The relationship among people and the connections among things\nbecome more and more complex, and new challenges arise. To tackle these\nchallenges, trust-a soft security mechanism-is considered as a promising\ntechnology. Thus, in this survey, we do a comprehensive study on the trust and\ntrust modelling for the future digital world. We revisit the definitions and\nproperties of trust, and analysis the trust theories and discuss their impact\non digital trust modelling. We analyze the digital world and its corresponding\nenvironment where people, things, and infrastructure connect with each other.\nWe detail the challenges that require trust in these digital scenarios. Under\nour analysis of trust and the digital world, we define different types of trust\nrelationships and find out the factors that are needed to ensure a fully\nrepresentative model. Next, to meet the challenges of digital trust modelling,\ncomprehensive trust model evaluation criteria are proposed, and potential\nsecurities and privacy issues of trust modelling are analyzed. Finally, we\nprovide a wide-ranging analysis of different methodologies, mathematical\ntheories, and how they can be applied to trust modelling.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Hannah Lim Jing Ting",
      "Xin Kang",
      "Tieyan Li",
      "Haiguang Wang",
      "Cheng-Kang Chu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.07528"
  },
  {
    "id": "arXiv:2106.07534",
    "title": "z-anonymity: Zero-Delay Anonymization for Data Streams",
    "abstract": "With the advent of big data and the birth of the data markets that sell\npersonal information, individuals' privacy is of utmost importance. The\nclassical response is anonymization, i.e., sanitizing the information that can\ndirectly or indirectly allow users' re-identification. The most popular\nsolution in the literature is the k-anonymity. However, it is hard to achieve\nk-anonymity on a continuous stream of data, as well as when the number of\ndimensions becomes high.In this paper, we propose a novel anonymization\nproperty called z-anonymity. Differently from k-anonymity, it can be achieved\nwith zero-delay on data streams and it is well suited for high dimensional\ndata. The idea at the base of z-anonymity is to release an attribute (an atomic\ninformation) about a user only if at least z - 1 other users have presented the\nsame attribute in a past time window. z-anonymity is weaker than k-anonymity\nsince it does not work on the combinations of attributes, but treats them\nindividually. In this paper, we present a probabilistic framework to map the\nz-anonymity into the k-anonymity property. Our results show that a proper\nchoice of the z-anonymity parameters allows the data curator to likely obtain a\nk-anonymized dataset, with a precisely measurable probability. We also evaluate\na real use case, in which we consider the website visits of a population of\nusers and show that z-anonymity can work in practice for obtaining the\nk-anonymity too.",
    "descriptor": "",
    "authors": [
      "Nikhil Jha",
      "Thomas Favale",
      "Luca Vassio",
      "Martino Trevisan",
      "Marco Mellia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07534"
  },
  {
    "id": "arXiv:2106.07536",
    "title": "Throughput Maximization Leveraging Just-Enough SNR Margin and Channel  Spacing Optimization",
    "abstract": "Flexible optical network is a promising technology to accommodate\nhigh-capacity demands in next-generation networks. To ensure uninterrupted\ncommunication, existing lightpath provisioning schemes are mainly done with the\nassumption of worst-case resource under-provisioning and fixed channel spacing,\nwhich preserves an excessive signal-to-noise ratio (SNR) margin. However, under\na resource over-provisioning scenario, the excessive SNR margin restricts the\ntransmission bit-rate, leading to physical layer resource waste and stranded\ntransmission capacity. To tackle this challenging problem, we leverage an\niterative feedback tuning algorithm to provide a just-enough SNR margin, so as\nto maximize the network throughput. Specifically, the proposed algorithm is\nimplemented in three steps. First, starting from the high SNR margin setup, we\nestablish an integer linear programming model as well as a heuristic algorithm\nto maximize the network throughput by solving the problem of routing,\nmodulation format, forward error correction, baud-rate selection, and spectrum\nassignment. Second, we optimize the channel spacing of the lightpaths obtained\nfrom the previous step, thereby increasing the available physical layer\nresources. Finally, we iteratively reduce the SNR margin of each lightpath\nuntil the network throughput cannot be increased. Through numerical\nsimulations, we confirm the throughput improvement in different networks and\nwith different baud-rates. In particular, we find that our algorithm enables\nover 20\\% relative gain when network resource is over-provisioned, compared to\nthe traditional method preserving an excessive SNR margin.",
    "descriptor": "",
    "authors": [
      "Cao Chen",
      "Fen Zhou",
      "Yuanhao Liu",
      "Shilin Xiao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.07536"
  },
  {
    "id": "arXiv:2106.07539",
    "title": "On the Representation of Solutions to Elliptic PDEs in Barron Spaces",
    "abstract": "Numerical solutions to high-dimensional partial differential equations (PDEs)\nbased on neural networks have seen exciting developments. This paper derives\ncomplexity estimates of the solutions of $d$-dimensional second-order elliptic\nPDEs in the Barron space, that is a set of functions admitting the integral of\ncertain parametric ridge function against a probability measure on the\nparameters. We prove under some appropriate assumptions that if the\ncoefficients and the source term of the elliptic PDE lie in Barron spaces, then\nthe solution of the PDE is $\\epsilon$-close with respect to the $H^1$ norm to a\nBarron function. Moreover, we prove dimension-explicit bounds for the Barron\nnorm of this approximate solution, depending at most polynomially on the\ndimension $d$ of the PDE. As a direct consequence of the complexity estimates,\nthe solution of the PDE can be approximated on any bounded domain by a\ntwo-layer neural network with respect to the $H^1$ norm with a\ndimension-explicit convergence rate.",
    "descriptor": "",
    "authors": [
      "Ziang Chen",
      "Jianfeng Lu",
      "Yulong Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.07539"
  },
  {
    "id": "arXiv:2106.07540",
    "title": "Evaluating Various Tokenizers for Arabic Text Classification",
    "abstract": "The first step in any NLP pipeline is learning word vector representations.\nHowever, given a large text corpus, representing all the words is not\nefficient. In the literature, many tokenization algorithms have emerged to\ntackle this problem by creating subwords which in turn limits the vocabulary\nsize in any text corpus. However such algorithms are mostly language-agnostic\nand lack a proper way of capturing meaningful tokens. Not to mention the\ndifficulty of evaluating such techniques in practice. In this paper, we\nintroduce three new tokenization algorithms for Arabic and compare them to\nthree other baselines using unsupervised evaluations. In addition to that, we\ncompare all the six algorithms by evaluating them on three tasks which are\nsentiment analysis, news classification and poetry classification. Our\nexperiments show that the performance of such tokenization algorithms depends\non the size of the dataset, type of the task, and the amount of morphology that\nexists in the dataset.",
    "descriptor": "",
    "authors": [
      "Zaid Alyafeai",
      "Maged S. Al-shaibani",
      "Mustafa Ghaleb",
      "Irfan Ahmad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07540"
  },
  {
    "id": "arXiv:2106.07542",
    "title": "Machine Learning Based Prediction of Future Stress Events in a Driving  Scenario",
    "abstract": "This paper presents a model for predicting a driver's stress level up to one\nminute in advance. Successfully predicting future stress would allow stress\nmitigation to begin before the subject becomes stressed, reducing or possibly\navoiding the performance penalties of stress. The proposed model takes features\nextracted from Galvanic Skin Response (GSR) signals on the foot and hand and\nRespiration and Electrocardiogram (ECG) signals from the chest of the driver.\nThe data used to train the model was retrieved from an existing database and\nthen processed to create statistical and frequency features. A total of 42\nfeatures were extracted from the data and then expanded into a total of 252\nfeatures by grouping the data and taking six statistical measurements of each\ngroup for each feature. A Random Forest Classifier was trained and evaluated\nusing a leave-one-subject-out testing approach. The model achieved 94% average\naccuracy on the test data. Results indicate that the model performs well and\ncould be used as part of a vehicle stress prevention system.",
    "descriptor": "\nComments: 4 Pages, IEEE 7th World Forum on Internet of Things 2021\n",
    "authors": [
      "Joseph Clark",
      "Rajdeep Kumar Nath",
      "Himanshu Thapliyal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.07542"
  },
  {
    "id": "arXiv:2106.07544",
    "title": "Dataset of Propaganda Techniques of the State-Sponsored Information  Operation of the People's Republic of China",
    "abstract": "The digital media, identified as computational propaganda provides a pathway\nfor propaganda to expand its reach without limit. State-backed propaganda aims\nto shape the audiences' cognition toward entities in favor of a certain\npolitical party or authority. Furthermore, it has become part of modern\ninformation warfare used in order to gain an advantage over opponents. Most of\nthe current studies focus on using machine learning, quantitative, and\nqualitative methods to distinguish if a certain piece of information on social\nmedia is propaganda. Mainly conducted on English content, but very little\nresearch addresses Chinese Mandarin content. From propaganda detection, we want\nto go one step further to provide more fine-grained information on propaganda\ntechniques that are applied. In this research, we aim to bridge the information\ngap by providing a multi-labeled propaganda techniques dataset in Mandarin\nbased on a state-backed information operation dataset provided by Twitter. In\naddition to presenting the dataset, we apply a multi-label text classification\nusing fine-tuned BERT. Potentially this could help future research in detecting\nstate-backed propaganda online especially in a cross-lingual context and cross\nplatforms identity consolidation.",
    "descriptor": "",
    "authors": [
      "Rong-Ching Chang",
      "Chun-Ming Lai",
      "Kai-Lai Chang",
      "Chu-Hsing Lin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07544"
  },
  {
    "id": "arXiv:2106.07545",
    "title": "PolarStream: Streaming Lidar Object Detection and Segmentation with  Polar Pillars",
    "abstract": "Recent works recognized lidars as an inherently streaming data source and\nshowed that the end-to-end latency of lidar perception models can be reduced\nsignificantly by operating on wedge-shaped point cloud sectors rather then the\nfull point cloud. However, due to use of cartesian coordinate systems these\nmethods represent the sectors as rectangular regions, wasting memory and\ncompute. In this work we propose using a polar coordinate system and make two\nkey improvements on this design. First, we increase the spatial context by\nusing multi-scale padding from neighboring sectors: preceding sector from the\ncurrent scan and/or the following sector from the past scan. Second, we improve\nthe core polar convolutional architecture by introducing feature undistortion\nand range stratified convolutions. Experimental results on the nuScenes dataset\nshow significant improvements over other streaming based methods. We also\nachieve comparable results to existing non-streaming methods but with lower\nlatencies.",
    "descriptor": "",
    "authors": [
      "Qi Chen",
      "Sourabh Vora",
      "Oscar Beijbom"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.07545"
  },
  {
    "id": "arXiv:2106.07548",
    "title": "A scalable multi-step least squares method for network identification  with unknown disturbance topology",
    "abstract": "Identification methods for dynamic networks typically require prior knowledge\nof the network and disturbance topology, and often rely on solving poorly\nscalable non-convex optimization problems. While methods for estimating network\ntopology are available in the literature, less attention has been paid to\nestimating the disturbance topology, i.e., the (spatial) noise correlation\nstructure and the noise rank. In this work we present an identification method\nfor dynamic networks, in which an estimation of the disturbance topology\nprecedes the identification of the full dynamic network with known network\ntopology. To this end we extend the multi-step Sequential Linear Regression and\nWeighted Null Space Fitting methods to deal with reduced rank noise, and use\nthese methods to estimate the disturbance topology and the network dynamics. As\na result, we provide a multi-step least squares algorithm with parallel\ncomputation capabilities and that rely only on explicit analytical solutions,\nthereby avoiding the usual non-convex optimizations involved. Consequently we\nconsistently estimate dynamic networks of Box Jenkins model structure, while\nkeeping the computational burden low. We provide a consistency proof that\nincludes path-based data informativity conditions for allocation of excitation\nsignals in the experimental design. Numerical simulations performed on a\ndynamic network with reduced rank noise clearly illustrate the potential of\nthis method.",
    "descriptor": "\nComments: 16 pages, 4 figures, Submitted to Automatica on 14th June 2021\n",
    "authors": [
      "Stefanie J.M. Fonken",
      "Karthik R. Ramaswamy",
      "Paul M.J. Van den Hof"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07548"
  },
  {
    "id": "arXiv:2106.07549",
    "title": "Named Entity Normalization Model Using Edge Weight Updating Neural  Network: Assimilation Between Knowledge-Driven Graph and Data-Driven Graph",
    "abstract": "Discriminating the matched named entity pairs or identifying the entities'\ncanonical forms are critical in text mining tasks. More precise named entity\nnormalization in text mining will benefit other subsequent text analytic\napplications. We built the named entity normalization model with a novel Edge\nWeight Updating Neural Network. Our proposed model when tested on four\ndifferent datasets achieved state-of-the-art results. We, next, verify our\nmodel's performance on NCBI Disease, BC5CDR Disease, and BC5CDR Chemical\ndatabases, which are widely used named entity normalization datasets in the\nbioinformatics field. We also tested our model with our own financial named\nentity normalization dataset to validate the efficacy for more general\napplications. Using the constructed dataset, we differentiate named entity\npairs. Our model achieved the highest named entity normalization performances\nin terms of various evaluation metrics.",
    "descriptor": "",
    "authors": [
      "Sung Hwan Jeon",
      "Sungzoon Cho"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.07549"
  },
  {
    "id": "arXiv:2106.07550",
    "title": "Attention mechanisms and deep learning for machine vision: A survey of  the state of the art",
    "abstract": "With the advent of state of the art nature-inspired pure attention based\nmodels i.e. transformers, and their success in natural language processing\n(NLP), their extension to machine vision (MV) tasks was inevitable and much\nfelt. Subsequently, vision transformers (ViTs) were introduced which are giving\nquite a challenge to the established deep learning based machine vision\ntechniques. However, pure attention based models/architectures like\ntransformers require huge data, large training times and large computational\nresources. Some recent works suggest that combinations of these two varied\nfields can prove to build systems which have the advantages of both these\nfields. Accordingly, this state of the art survey paper is introduced which\nhopefully will help readers get useful information about this interesting and\npotential research area. A gentle introduction to attention mechanisms is\ngiven, followed by a discussion of the popular attention based deep\narchitectures. Subsequently, the major categories of the intersection of\nattention mechanisms and deep learning for machine vision (MV) based are\ndiscussed. Afterwards, the major algorithms, issues and trends within the scope\nof the paper are discussed.",
    "descriptor": "",
    "authors": [
      "Abdul Mueed Hafiz",
      "Shabir Ahmad Parah",
      "Rouf Ul Alam Bhat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07550"
  },
  {
    "id": "arXiv:2106.07551",
    "title": "MALib: A Parallel Framework for Population-based Multi-agent  Reinforcement Learning",
    "abstract": "Population-based multi-agent reinforcement learning (PB-MARL) refers to the\nseries of methods nested with reinforcement learning (RL) algorithms, which\nproduces a self-generated sequence of tasks arising from the coupled population\ndynamics. By leveraging auto-curricula to induce a population of distinct\nemergent strategies, PB-MARL has achieved impressive success in tackling\nmulti-agent tasks. Despite remarkable prior arts of distributed RL frameworks,\nPB-MARL poses new challenges for parallelizing the training frameworks due to\nthe additional complexity of multiple nested workloads between sampling,\ntraining and evaluation involved with heterogeneous policy interactions. To\nsolve these problems, we present MALib, a scalable and efficient computing\nframework for PB-MARL. Our framework is comprised of three key components: (1)\na centralized task dispatching model, which supports the self-generated tasks\nand scalable training with heterogeneous policy combinations; (2) a programming\narchitecture named Actor-Evaluator-Learner, which achieves high parallelism for\nboth training and sampling, and meets the evaluation requirement of\nauto-curriculum learning; (3) a higher-level abstraction of MARL training\nparadigms, which enables efficient code reuse and flexible deployments on\ndifferent distributed computing paradigms. Experiments on a series of complex\ntasks such as multi-agent Atari Games show that MALib achieves throughput\nhigher than 40K FPS on a single machine with $32$ CPU cores; 5x speedup than\nRLlib and at least 3x speedup than OpenSpiel in multi-agent training tasks.\nMALib is publicly available at https://github.com/sjtu-marl/malib.",
    "descriptor": "\nComments: 24 pages, 17 figures, 5 tables\n",
    "authors": [
      "Ming Zhou",
      "Ziyu Wan",
      "Hanjing Wang",
      "Muning Wen",
      "Runzhe Wu",
      "Ying Wen",
      "Yaodong Yang",
      "Weinan Zhang",
      "Jun Wang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07551"
  },
  {
    "id": "arXiv:2106.07552",
    "title": "PC-DAN: Point Cloud based Deep Affinity Network for 3D Multi-Object  Tracking (Accepted as an extended abstract in JRDB-ACT Workshop at CVPR21)",
    "abstract": "In recent times, the scope of LIDAR (Light Detection and Ranging)\nsensor-based technology has spread across numerous fields. It is popularly used\nto map terrain and navigation information into reliable 3D point cloud data,\npotentially revolutionizing the autonomous vehicles and assistive robotic\nindustry. A point cloud is a dense compilation of spatial data in 3D\ncoordinates. It plays a vital role in modeling complex real-world scenes since\nit preserves structural information and avoids perspective distortion, unlike\nimage data, which is the projection of a 3D structure on a 2D plane. In order\nto leverage the intrinsic capabilities of the LIDAR data, we propose a\nPointNet-based approach for 3D Multi-Object Tracking (MOT).",
    "descriptor": "",
    "authors": [
      "Aakash Kumar",
      "Jyoti Kini",
      "Mubarak Shah",
      "Ajmal Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07552"
  },
  {
    "id": "arXiv:2106.07553",
    "title": "A Cognitive Science perspective for learning how to design meaningful  user experiences and human-centered technology",
    "abstract": "This paper reviews literature in cognitive science, human-computer\ninteraction (HCI) and natural-language processing (NLP) to consider how\nanalogical reasoning (AR) could help inform the design of communication and\nlearning technologies, as well as online communities and digital platforms.\nFirst, analogical reasoning (AR) is defined, and use-cases of AR in the\ncomputing sciences are presented. The concept of schema is introduced, along\nwith use-cases in computing. Finally, recommendations are offered for future\nwork on using analogical reasoning and schema methods in the computing\nsciences.",
    "descriptor": "",
    "authors": [
      "Sara Kingsley"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.07553"
  },
  {
    "id": "arXiv:2106.07554",
    "title": "Dataset for eye-tracking tasks",
    "abstract": "In recent years many different deep neural networks were developed, but due\nto a large number of layers in deep networks, their training requires a long\ntime and a large number of datasets. Today is popular to use trained deep\nneural networks for various tasks, even for simple ones in which such deep\nnetworks are not required. The well-known deep networks such as YoloV3, SSD,\netc. are intended for tracking and monitoring various objects, therefore their\nweights are heavy and the overall accuracy for a specific task is low.\nEye-tracking tasks need to detect only one object - an iris in a given area.\nTherefore, it is logical to use a neural network only for this task. But the\nproblem is the lack of suitable datasets for training the model. In the\nmanuscript, we presented a dataset that is suitable for training custom models\nof convolutional neural networks for eye-tracking tasks. Using data set data,\neach user can independently pre-train the convolutional neural network models\nfor eye-tracking tasks. This dataset contains annotated 10,000 eye images in an\nextension of 416 by 416 pixels. The table with annotation information shows the\ncoordinates and radius of the eye for each image. This manuscript can be\nconsidered as a guide for the preparation of datasets for eye-tracking devices",
    "descriptor": "",
    "authors": [
      "R. Ildar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.07554"
  },
  {
    "id": "arXiv:2106.07555",
    "title": "A Framework to Counteract Suboptimal User-Behaviors in Exploratory  Learning Environments: an Application to MOOCs",
    "abstract": "While there is evidence that user-adaptive support can greatly enhance the\neffectiveness of educational systems, designing such support for exploratory\nlearning environments (e.g., simulations) is still challenging due to the\nopen-ended nature of their interaction. In particular, there is little a priori\nknowledge of which student's behaviors can be detrimental to learning in such\nenvironments. To address this problem, we focus on a data-driven user-modeling\nframework that uses logged interaction data to learn which behavioral or\nactivity patterns should trigger help during interaction with a specific\nlearning environment. This framework has been successfully used to provide\nadaptive support in interactive learning simulations. Here we present a novel\napplication of this framework we are working on, namely to Massive Open Online\nCourses (MOOCs), a form of exploratory environment that could greatly benefit\nfrom adaptive support due to the large diversity of their users, but typically\nlack of such adaptation. We describe an experiment aimed at investigating the\nvalue of our framework to identify student's behaviors that can justify\nadapting to, and report some preliminary results.",
    "descriptor": "\nComments: The AAAI 2019 Workshop on Plan, Activity, and Intent Recognition\n",
    "authors": [
      "S\u00e9bastien Lall\u00e9",
      "Cristina Conati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07555"
  },
  {
    "id": "arXiv:2106.07556",
    "title": "Long Term Object Detection and Tracking in Collaborative Learning  Environments",
    "abstract": "Human activity recognition in videos is a challenging problem that has drawn\na lot of interest, particularly when the goal requires the analysis of a large\nvideo database. AOLME project provides a collaborative learning environment for\nmiddle school students to explore mathematics, computer science, and\nengineering by processing digital images and videos. As part of this project,\naround 2200 hours of video data was collected for analysis. Because of the size\nof the dataset, it is hard to analyze all the videos of the dataset manually.\nThus, there is a huge need for reliable computer-based methods that can detect\nactivities of interest. My thesis is focused on the development of accurate\nmethods for detecting and tracking objects in long videos. All the models are\nvalidated on videos from 7 different sessions, ranging from 45 minutes to 90\nminutes. The keyboard detector achieved a very high average precision (AP) of\n92% at 0.5 intersection over union (IoU). Furthermore, a combined system of the\ndetector with a fast tracker KCF (159fps) was developed so that the algorithm\nruns significantly faster without sacrificing accuracy. For a video of 23\nminutes having resolution 858X480 @ 30 fps, the detection alone runs at 4.7Xthe\nreal-time, and the combined algorithm runs at 21Xthe real-time for an average\nIoU of 0.84 and 0.82, respectively. The hand detector achieved average\nprecision (AP) of 72% at 0.5 IoU. The detection results were improved to 81%\nusing optimal data augmentation parameters. The hand detector runs at 4.7Xthe\nreal-time with AP of 81% at 0.5 IoU. The hand detection method was integrated\nwith projections and clustering for accurate proposal generation. This approach\nreduced the number of false-positive hand detections by 80%. The overall hand\ndetection system runs at 4Xthe real-time, capturing all the activity regions of\nthe current collaborative group.",
    "descriptor": "\nComments: Master's thesis\n",
    "authors": [
      "Sravani Teeparthi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07556"
  },
  {
    "id": "arXiv:2106.07557",
    "title": "A Multi-Branch Hybrid Transformer Networkfor Corneal Endothelial Cell  Segmentation",
    "abstract": "Corneal endothelial cell segmentation plays a vital role inquantifying\nclinical indicators such as cell density, coefficient of variation,and\nhexagonality. However, the corneal endothelium's uneven reflectionand the\nsubject's tremor and movement cause blurred cell edges in theimage, which is\ndifficult to segment, and need more details and contextinformation to release\nthis problem. Due to the limited receptive field oflocal convolution and\ncontinuous downsampling, the existing deep learn-ing segmentation methods\ncannot make full use of global context andmiss many details. This paper\nproposes a Multi-Branch hybrid Trans-former Network (MBT-Net) based on the\ntransformer and body-edgebranch. Firstly, We use the convolutional block to\nfocus on local tex-ture feature extraction and establish long-range\ndependencies over space,channel, and layer by the transformer and residual\nconnection. Besides,We use the body-edge branch to promote local consistency\nand to provideedge position information. On the self-collected dataset\nTM-EM3000 andpublic Alisarine dataset, compared with other State-Of-The-Art\n(SOTA)methods, the proposed method achieves an improvement.",
    "descriptor": "",
    "authors": [
      "Yinglin Zhang",
      "Risa Higashita",
      "Huazhu Fu",
      "Yanwu Xu",
      "Yang Zhang",
      "Haofeng Liu",
      "Jian Zhang",
      "Jiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07557"
  },
  {
    "id": "arXiv:2106.07558",
    "title": "Transparent Model of Unabridged Data (TMUD)",
    "abstract": "Recent advancements in computational power and algorithms have enabled\nunabridged data (e.g., raw images or audio) to be used as input in some models\n(e.g., deep learning). However, the black box nature of such models reduces\ntheir likelihood of adoption by marketing scholars. Our paradigm of analysis,\nthe Transparent Model of Unabridged Data (TMUD), enables researchers to\ninvestigate the inner workings of such black box models by incorporating an ex\nante filtration module and an ex post experimentation module. We empirically\ndemonstrate the TMUD by investigating the role of facial components and sexual\ndimorphism in face perceptions, which have implications for four marketing\ncontexts: advertisement (perceptions of approachability, trustworthiness, and\ncompetence), brand (perceptions of whether a face represents a brand's typical\ncustomer), category (perceptions of whether a face represents a category's\ntypical customer), and customer persona (perceptions of whether a face\nrepresents the persona of a brand's customer segment). Our results reveal new\nand useful findings that enrich the existing literature on face perception,\nmost of which is based on abridged attributes (e.g., width of mouth). The TMUD\nhas great potential to be a useful paradigm for generating theoretical insights\nand may encourage more marketing researchers and practitioners to use\nunabridged data.",
    "descriptor": "\nComments: 6 figures and 6 tables\n",
    "authors": [
      "Jie Xu",
      "Min Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07558"
  },
  {
    "id": "arXiv:2106.07559",
    "title": "Artificial Perceptual Learning: Image Categorization with Weak  Supervision",
    "abstract": "Machine learning has achieved much success on supervised learning tasks with\nlarge sets of well-annotated training samples. However, in many practical\nsituations, such strong and high-quality supervision provided by training data\nis unavailable due to the expensive and labor-intensive labeling process.\nAutomatically identifying and recognizing object categories in a large volume\nof unlabeled images with weak supervision remains an important, yet unsolved\nchallenge in computer vision. In this paper, we propose a novel machine\nlearning framework, artificial perceptual learning (APL), to tackle the problem\nof weakly supervised image categorization. The proposed APL framework is\nconstructed using state-of-the-art machine learning algorithms as building\nblocks to mimic the cognitive development process known as infant\ncategorization. We develop and illustrate the proposed framework by\nimplementing a wide-field fine-grain ecological survey of tree species over an\n8,000-hectare area of the El Yunque rainforest in Puerto Rico. It is based on\nunlabeled high-resolution aerial images of the tree canopy. Misplaced\nground-based labels were available for less than 1% of these images, which\nserve as the only weak supervision for this learning framework. We validate the\nproposed framework using a small set of images with high quality human\nannotations and show that the proposed framework attains human-level cognitive\neconomy.",
    "descriptor": "",
    "authors": [
      "Chengliang Tang",
      "Mar\u00eda Uriarte",
      "Helen Jin",
      "Douglas C. Morton",
      "Tian Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07559"
  },
  {
    "id": "arXiv:2106.07560",
    "title": "Allocating Stimulus Checks in Times of Crisis",
    "abstract": "We study the problem of allocating bailouts (stimulus, subsidy allocations)\nto people participating in a financial network subject to income shocks. We\nbuild on the financial clearing framework of Eisenberg and Noe that allows the\nincorporation of a bailout policy that is based on discrete bailouts motivated\nby the types of stimulus checks people receive around the world as part of\nCOVID-19 economical relief plans. We show that optimally allocating such\nbailouts on a financial network in order to maximize a variety of social\nwelfare objectives of this form is a computationally intractable problem. We\ndevelop approximation algorithms to optimize these objectives and establish\nguarantees for their approximation rations. Then, we incorporate multiple\nfairness constraints in the optimization problems and establish relative bounds\non the solutions with versus without these constraints. Finally, we apply our\nmethodology to a variety of data, both in the context of a system of large\nfinancial institutions with real-world data, as well as in a realistic societal\ncontext with financial interactions between people and businesses for which we\nuse semi-artificial data derived from mobility patterns. Our results suggest\nthat the algorithms we develop and study have reasonable results in practice\nand outperform other network-based heuristics. We argue that the presented\nproblem through the societal-level lens could assist policymakers in making\ninformed decisions on issuing subsidies.",
    "descriptor": "",
    "authors": [
      "Marios Papachristou",
      "Jon Kleinberg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.07560"
  },
  {
    "id": "arXiv:2106.07561",
    "title": "Direct Servo Control from In-Sensor CNN Inference with A Pixel Processor  Array",
    "abstract": "This work demonstrates direct visual sensory-motor control using high-speed\nCNN inference via a SCAMP-5 Pixel Processor Array (PPA). We demonstrate how\nPPAs are able to efficiently bridge the gap between perception and action. A\nbinary Convolutional Neural Network (CNN) is used for a classic rock, paper,\nscissors classification problem at over 8000 FPS. Control instructions are\ndirectly sent to a servo motor from the PPA according to the CNN's\nclassification result without any other intermediate hardware.",
    "descriptor": "",
    "authors": [
      "Yanan Liu",
      "Jianing Chen",
      "Laurie Bose",
      "Piotr Dudek",
      "Walterio Mayol-Cuevas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07561"
  },
  {
    "id": "arXiv:2106.07562",
    "title": "Neural Network Structure Design based on N-Gauss Activation Function",
    "abstract": "Recent work has shown that the activation function of the convolutional\nneural network can meet the Lipschitz condition, then the corresponding\nconvolutional neural network structure can be constructed according to the\nscale of the data set, and the data set can be trained more deeply, more\naccurately and more effectively. In this article, we have accepted the\nexperimental results and introduced the core block N-Gauss, N-Gauss, and Swish\n(Conv1, Conv2, FC1) neural network structure design to train MNIST, CIFAR10,\nand CIFAR100 respectively. Experiments show that N-Gauss gives full play to the\nmain role of nonlinear modeling of activation functions, so that deep\nconvolutional neural networks have hierarchical nonlinear mapping learning\ncapabilities. At the same time, the training ability of N-Gauss on simple\none-dimensional channel small data sets is equivalent to the performance of\nReLU and Swish.",
    "descriptor": "",
    "authors": [
      "Xiangri Lu",
      "Hongbin Ma",
      "Jingcheng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07562"
  },
  {
    "id": "arXiv:2106.07563",
    "title": "BPLF: A Bi-Parallel Linear Flow Model for Facial Expression Generation  from Emotion Set Images",
    "abstract": "The flow-based generative model is a deep learning generative model, which\nobtains the ability to generate data by explicitly learning the data\ndistribution. Theoretically its ability to restore data is stronger than other\ngenerative models. However, its implementation has many limitations, including\nlimited model design, too many model parameters and tedious calculation. In\nthis paper, a bi-parallel linear flow model for facial emotion generation from\nemotion set images is constructed, and a series of improvements have been made\nin terms of the expression ability of the model and the convergence speed in\ntraining. The model is mainly composed of several coupling layers superimposed\nto form a multi-scale structure, in which each coupling layer contains 1*1\nreversible convolution and linear operation modules. Furthermore, this paper\nsorted out the current public data set of facial emotion images, made a new\nemotion data, and verified the model through this data set. The experimental\nresults show that, under the traditional convolutional neural network, the\n3-layer 3*3 convolution kernel is more conducive to extracte the features of\nthe face images. The introduction of principal component decomposition can\nimprove the convergence speed of the model.",
    "descriptor": "\nComments: 20 pages, 10 figures\n",
    "authors": [
      "Gao Xu",
      "Yuanpeng Long",
      "Siwei Liu",
      "Lijia Yang",
      "Shimei Xu",
      "Xiaoming Yao",
      "Kunxian Shu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.07563"
  },
  {
    "id": "arXiv:2106.07564",
    "title": "An optimized Capsule-LSTM model for facial expression recognition with  video sequences",
    "abstract": "To overcome the limitations of convolutional neural network in the process of\nfacial expression recognition, a facial expression recognition model\nCapsule-LSTM based on video frame sequence is proposed. This model is composed\nof three networks includingcapsule encoders, capsule decoders and LSTM network.\nThe capsule encoder extracts the spatial information of facial expressions in\nvideo frames. Capsule decoder reconstructs the images to optimize the network.\nLSTM extracts the temporal information between video frames and analyzes the\ndifferences in expression changes between frames. The experimental results from\nthe MMI dataset show that the Capsule-LSTM model proposed in this paper can\neffectively improve the accuracy of video expression recognition.",
    "descriptor": "\nComments: 14pages,4 figurews\n",
    "authors": [
      "Siwei Liu",
      "Yuanpeng Long",
      "Gao Xu",
      "Lijia Yang",
      "Shimei Xu",
      "Xiaoming Yao",
      "Kunxian Shu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.07564"
  },
  {
    "id": "arXiv:2106.07565",
    "title": "Video-Based Inpatient Fall Risk Assessment: A Case Study",
    "abstract": "Inpatient falls are a serious safety issue in hospitals and healthcare\nfacilities. Recent advances in video analytics for patient monitoring provide a\nnon-intrusive avenue to reduce this risk through continuous activity\nmonitoring. However, in-bed fall risk assessment systems have received less\nattention in the literature. The majority of prior studies have focused on fall\nevent detection, and do not consider the circumstances that may indicate an\nimminent inpatient fall. Here, we propose a video-based system that can monitor\nthe risk of a patient falling, and alert staff of unsafe behaviour to help\nprevent falls before they occur. We propose an approach that leverages recent\nadvances in human localisation and skeleton pose estimation to extract spatial\nfeatures from video frames recorded in a simulated environment. We demonstrate\nthat body positions can be effectively recognised and provide useful evidence\nfor fall risk assessment. This work highlights the benefits of video-based\nmodels for analysing behaviours of interest, and demonstrates how such a system\ncould enable sufficient lead time for healthcare professionals to respond and\naddress patient needs, which is necessary for the development of fall\nintervention programs.",
    "descriptor": "",
    "authors": [
      "Ziqing Wang",
      "Mohammad Ali Armin",
      "Simon Denman",
      "Lars Petersson",
      "David Ahmedt-Aristizabal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07565"
  },
  {
    "id": "arXiv:2106.07568",
    "title": "Full interpretable machine learning in 2D with inline coordinates",
    "abstract": "This paper proposed a new methodology for machine learning in 2-dimensional\nspace (2-D ML) in inline coordinates. It is a full machine learning approach\nthat does not require to deal with n-dimensional data in n-dimensional space.\nIt allows discovering n-D patterns in 2-D space without loss of n-D information\nusing graph representations of n-D data in 2-D. Specifically, it can be done\nwith the inline based coordinates in different modifications, including static\nand dynamic ones. The classification and regression algorithms based on these\ninline coordinates were introduced. A successful case study based on a\nbenchmark data demonstrated the feasibility of the approach. This approach\nhelps to consolidate further a whole new area of full 2-D machine learning as a\npromising ML methodology. It has advantages of abilities to involve actively\nthe end-users into the discovering of models and their justification. Another\nadvantage is providing interpretable ML models.",
    "descriptor": "\nComments: 9 pages, 20 figures\n",
    "authors": [
      "Boris Kovalerchuk",
      "Hoang Phan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07568"
  },
  {
    "id": "arXiv:2106.07575",
    "title": "Scalable and accurate multi-GPU based image reconstruction of  large-scale ptychography data",
    "abstract": "While the advances in synchrotron light sources, together with the\ndevelopment of focusing optics and detectors, allow nanoscale ptychographic\nimaging of materials and biological specimens, the corresponding experiments\ncan yield terabyte-scale large volumes of data that can impose a heavy burden\non the computing platform. While Graphical Processing Units (GPUs) provide high\nperformance for such large-scale ptychography datasets, a single GPU is\ntypically insufficient for analysis and reconstruction. Several existing works\nhave considered leveraging multiple GPUs to accelerate the ptychographic\nreconstruction. However, they utilize only Message Passing Interface (MPI) to\nhandle the communications between GPUs. It poses inefficiency for the\nconfiguration that has multiple GPUs in a single node, especially while\nprocessing a single large projection, since it provides no optimizations to\nhandle the heterogeneous GPU interconnections containing both low-speed links,\ne.g., PCIe, and high-speed links, e.g., NVLink. In this paper, we provide a\nmulti-GPU implementation that can effectively solve large-scale ptychographic\nreconstruction problem with optimized performance on intra-node multi-GPU. We\nfocus on the conventional maximum-likelihood reconstruction problem using\nconjugate-gradient (CG) for the solution and propose a novel hybrid\nparallelization model to address the performance bottlenecks in CG solver.\nAccordingly, we develop a tool called PtyGer (Ptychographic GPU(multiple)-based\nreconstruction), implementing our hybrid parallelization model design. The\ncomprehensive evaluation verifies that PtyGer can fully preserve the original\nalgorithm's accuracy while achieving outstanding intra-node GPU scalability.",
    "descriptor": "",
    "authors": [
      "Xiaodong Yu",
      "Viktor Nikitin",
      "Daniel J. Ching",
      "Selin Aslan",
      "Doga Gursoy",
      "Tekin Bicer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Image and Video Processing (eess.IV)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.07575"
  },
  {
    "id": "arXiv:2106.07577",
    "title": "F-T-LSTM based Complex Network for Joint Acoustic Echo Cancellation and  Speech Enhancement",
    "abstract": "With the increasing demand for audio communication and online conference,\nensuring the robustness of Acoustic Echo Cancellation (AEC) under the\ncomplicated acoustic scenario including noise, reverberation and nonlinear\ndistortion has become a top issue. Although there have been some traditional\nmethods that consider nonlinear distortion, they are still inefficient for echo\nsuppression and the performance will be attenuated when noise is present. In\nthis paper, we present a real-time AEC approach using complex neural network to\nbetter modeling the important phase information and frequency-time-LSTMs\n(F-T-LSTM), which scan both frequency and time axis, for better temporal\nmodeling. Moreover, we utilize modified SI-SNR as cost function to make the\nmodel to have better echo cancellation and noise suppression (NS) performance.\nWith only 1.4M parameters, the proposed approach outperforms the AEC-challenge\nbaseline by 0.27 in terms of Mean Opinion Score (MOS).",
    "descriptor": "\nComments: submitted to Interspeech 2021\n",
    "authors": [
      "Shimin Zhang",
      "Yuxiang Kong",
      "Shubo Lv",
      "Yanxin Hu",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.07577"
  },
  {
    "id": "arXiv:2106.07578",
    "title": "Dynamic Gradient Aggregation for Federated Domain Adaptation",
    "abstract": "In this paper, a new learning algorithm for Federated Learning (FL) is\nintroduced. The proposed scheme is based on a weighted gradient aggregation\nusing two-step optimization to offer a flexible training pipeline. Herein, two\ndifferent flavors of the aggregation method are presented, leading to an order\nof magnitude improvement in convergence speed compared to other distributed or\nFL training algorithms like BMUF and FedAvg. Further, the aggregation algorithm\nacts as a regularizer of the gradient quality. We investigate the effect of our\nFL algorithm in supervised and unsupervised Speech Recognition (SR) scenarios.\nThe experimental validation is performed based on three tasks: first, the\nLibriSpeech task showing a speed-up of 7x and 6% word error rate reduction\n(WERR) compared to the baseline results. The second task is based on session\nadaptation providing 20% WERR over a powerful LAS model. Finally, our\nunsupervised pipeline is applied to the conversational SR task. The proposed FL\nsystem outperforms the baseline systems in both convergence speed and overall\nmodel performance.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2008.02452\n",
    "authors": [
      "Dimitrios Dimitriadis",
      "Kenichi Kumatani",
      "Robert Gmyr",
      "Yashesh Gaur",
      "Sefik Emre Eskimez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07578"
  },
  {
    "id": "arXiv:2106.07582",
    "title": "Non Gaussian Denoising Diffusion Models",
    "abstract": "Generative diffusion processes are an emerging and effective tool for image\nand speech generation. In the existing methods, the underline noise\ndistribution of the diffusion process is Gaussian noise. However, fitting\ndistributions with more degrees of freedom, could help the performance of such\ngenerative models. In this work, we investigate other types of noise\ndistribution for the diffusion process. Specifically, we show that noise from\nGamma distribution provides improved results for image and speech generation.\nMoreover, we show that using a mixture of Gaussian noise variables in the\ndiffusion process improves the performance over a diffusion process that is\nbased on a single distribution. Our approach preserves the ability to\nefficiently sample state in the training diffusion process while using Gamma\nnoise and a mixture of noise.",
    "descriptor": "",
    "authors": [
      "Eliya Nachmani",
      "Robin San Roman",
      "Lior Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.07582"
  },
  {
    "id": "arXiv:2106.07583",
    "title": "Biomedical Entity Linking via Contrastive Context Matching",
    "abstract": "We introduce BioCoM, a contrastive learning framework for biomedical entity\nlinking that uses only two resources: a small-sized dictionary and a large\nnumber of raw biomedical articles. Specifically, we build the training\ninstances from raw PubMed articles by dictionary matching and use them to train\na context-aware entity linking model with contrastive learning. We predict the\nnormalized biomedical entity at inference time through a nearest-neighbor\nsearch. Results found that BioCoM substantially outperforms state-of-the-art\nmodels, especially in low-resource settings, by effectively using the context\nof the entities.",
    "descriptor": "",
    "authors": [
      "Shogo Ujiie",
      "Hayate Iso",
      "Eiji Aramaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07583"
  },
  {
    "id": "arXiv:2106.07588",
    "title": "Scenarios of future Indian electricity demand accounting for space  cooling and electric vehicle adoption",
    "abstract": "India is expected to witness rapid growth in electricity use over the next\ntwo decades. Here, we introduce a custom regression model to project\nelectricity consumption in India over the coming decades, which includes a\nbottom-up estimate of electricity consumption for two major growth drivers, air\nconditioning, and vehicle electrification. The model projections are available\nat a customizable level of spatial aggregation at an hourly temporal\nresolution, which makes them useful as inputs to long-term electricity\ninfrastructure planning studies. The approach is used to develop electricity\nconsumption data sets spanning various technology adoption and growth scenarios\nup to the year 2050 in five-year increments. The aim of the data is to provide\na range of scenarios for India's demand growth given new technology adoption.\nWith long-term hourly demand projections serving as an essential input for\nelectricity infrastructure modeling, this data publication enables further work\non energy efficiency, generation, and transmission expansion planning for a\nfast-growing and increasingly important region from a global climate mitigation\nperspective.",
    "descriptor": "",
    "authors": [
      "Marc Barbar",
      "Dharik Mallapragada",
      "Meia Alsup",
      "Robert Stoner"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07588"
  },
  {
    "id": "arXiv:2106.07590",
    "title": "Distribution level battery storage valuation framework",
    "abstract": "The growing demand for electricity in emerging markets and developing\neconomies such as India is causing loading and congestion problems on\ndistribution networks, particularly in urban locations. Electric utilities in\nthese regions face unique constraints regarding raising capital required to\nupgrade their congested networks. Battery storage has emerged as a non-wire\nalternative to feeder-level upgrades. This article presents a valuation\nframework by optimally sizing and placing battery storage on the distribution\nnetwork. We evaluate the value of storage using a real options analysis through\na Markov Chain Monte Carlo to identify the least-cost network upgrade strategy,\ngiven demand growth uncertainty. When applied to urban distribution network\nfeeders typical of those found in congested cities in India, the approach\nhighlights the economic value of network investment deferrals by making use of\nbattery storage. We find that storage costs below 261 USD/kWh justify\ninvestments in distribution level storage and storage as a non-wire alternative\nonly makes sense on moderately loaded feeders where storage charging is still\nfeasible without violating network thermal capacity limits.",
    "descriptor": "",
    "authors": [
      "Marc Barbar",
      "Dharik S. Mallapragada",
      "Robert Stoner",
      "Ignacio Perez-Arriaga"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07590"
  },
  {
    "id": "arXiv:2106.07594",
    "title": "Graph Contrastive Learning Automated",
    "abstract": "Self-supervised learning on graph-structured data has drawn recent interest\nfor learning generalizable, transferable and robust representations from\nunlabeled graphs. Among many, graph contrastive learning (GraphCL) has emerged\nwith promising representation learning performance. Unfortunately, unlike its\ncounterpart on image data, the effectiveness of GraphCL hinges on ad-hoc data\naugmentations, which have to be manually picked per dataset, by either rules of\nthumb or trial-and-errors, owing to the diverse nature of graph data. That\nsignificantly limits the more general applicability of GraphCL. Aiming to fill\nin this crucial gap, this paper proposes a unified bi-level optimization\nframework to automatically, adaptively and dynamically select data\naugmentations when performing GraphCL on specific graph data. The general\nframework, dubbed JOint Augmentation Optimization (JOAO), is instantiated as\nmin-max optimization. The selections of augmentations made by JOAO are shown to\nbe in general aligned with previous \"best practices\" observed from handcrafted\ntuning: yet now being automated, more flexible and versatile. Moreover, we\npropose a new augmentation-aware projection head mechanism, which will route\noutput features through different projection heads corresponding to different\naugmentations chosen at each training step. Extensive experiments demonstrate\nthat JOAO performs on par with or sometimes better than the state-of-the-art\ncompetitors including GraphCL, on multiple graph datasets of various scales and\ntypes, yet without resorting to any laborious dataset-specific tuning on\naugmentation selection. We release the code at\nhttps://github.com/Shen-Lab/GraphCL_Automated.",
    "descriptor": "\nComments: Supplementary materials are available at this https URL ICML 2021\n",
    "authors": [
      "Yuning You",
      "Tianlong Chen",
      "Yang Shen",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07594"
  },
  {
    "id": "arXiv:2106.07596",
    "title": "Maximizing Revenue with Adaptive Modulation and Multiple FECs in  Flexible Optical Networks",
    "abstract": "Flexible optical networks (FONs) are being adopted to accommodate the\nincreasingly heterogeneous traffic in today's Internet. However, in presence of\nhigh traffic load, not all offered traffic can be satisfied at all time. As\ncarried traffic load brings revenues to operators, traffic blocking due to\nlimited spectrum resource leads to revenue losses. In this study, given a set\nof traffic requests to be provisioned, we consider the problem of maximizing\noperator's revenue, subject to limited spectrum resource and physical layer\nimpairments (PLIs), namely amplified spontaneous emission noise (ASE),\nself-channel interference (SCI), cross-channel interference (XCI), and node\ncrosstalk. In FONs, adaptive modulation, multiple FEC, and the tuning of power\nspectrum density (PSD) can be effectively employed to mitigate the impact of\nPLIs. Hence, in our study, we propose a universal bandwidth-related impairment\nevaluation model based on channel bandwidth, which allows a performance\nanalysis for different PSD, FEC and modulations. Leveraging this PLI model and\na piecewise linear fitting function, we succeed to formulate the revenue\nmaximization problem as a mixed integer linear program. Then, to solve the\nproblem on larger network instances, a fast two-phase heuristic algorithm is\nalso proposed, which is shown to be near-optimal for revenue maximization.\nThrough simulations, we demonstrate that using adaptive modulation enables to\nsignificantly increase revenues in the scenario of high signal-to-noise ratio\n(SNR), where the revenue can even be doubled for high traffic load, while using\nmultiple FECs is more profitable for scenarios with low SNR.",
    "descriptor": "",
    "authors": [
      "Cao Chen",
      "Fen Zhou",
      "Massimo Tornatore",
      "Shilin Xiao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.07596"
  },
  {
    "id": "arXiv:2106.07597",
    "title": "MLPerf Tiny Benchmark",
    "abstract": "Advancements in ultra-low-power tiny machine learning (TinyML) systems\npromise to unlock an entirely new class of smart applications. However,\ncontinued progress is limited by the lack of a widely accepted and easily\nreproducible benchmark for these systems. To meet this need, we present MLPerf\nTiny, the first industry-standard benchmark suite for ultra-low-power tiny\nmachine learning systems. The benchmark suite is the collaborative effort of\nmore than 50 organizations from industry and academia and reflects the needs of\nthe community. MLPerf Tiny measures the accuracy, latency, and energy of\nmachine learning inference to properly evaluate the tradeoffs between systems.\nAdditionally, MLPerf Tiny implements a modular design that enables benchmark\nsubmitters to show the benefits of their product, regardless of where it falls\non the ML deployment stack, in a fair and reproducible manner. The suite\nfeatures four benchmarks: keyword spotting, visual wake words, image\nclassification, and anomaly detection.",
    "descriptor": "\nComments: TinyML Benchmark\n",
    "authors": [
      "Colby Banbury",
      "Vijay Janapa Reddi",
      "Peter Torelli",
      "Jeremy Holleman",
      "Nat Jeffries",
      "Csaba Kiraly",
      "Pietro Montino",
      "David Kanter",
      "Sebastian Ahmed",
      "Danilo Pau",
      "Urmish Thakker",
      "Antonio Torrini",
      "Peter Warden",
      "Jay Cordaro",
      "Giuseppe Di Guglielmo",
      "Javier Duarte",
      "Stephen Gibellini",
      "Videet Parekh",
      "Honson Tran",
      "Nhan Tran",
      "Niu Wenxu",
      "Xu Xuesong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.07597"
  },
  {
    "id": "arXiv:2106.07603",
    "title": "On the Adimensional Scale Invariant Steffensen (ASIS) Method",
    "abstract": "Dimensionality of parameters and variables is a fundamental issue in physics\nbut mostly ignored from a mathematical point of view. Diffculties arising from\ndimensional inconsistence are overcome by scaling analysis and, often, both\nconcepts, dimensionality and scaling, are confused. In the particular case of\niterative methods for solving non-linear equations, dimensionality and scaling\naffects their robutness: while some classical methods, such as Newton, are\nadimensional and scale independent, some other iterations as Steffensen's are\nnot; their convergence depends on the scaling, and their evaluation needs a\ndimensional congruence. In this paper we introduce the concept of adimensional\nform of a function in order to study the behavior of iterative methods, thus\ncorrecting, if possible, some pathological features. From this adimensional\nform we will devise an adimensional and scale invariant method based on\nSteffensen's which we will call ASIS method.",
    "descriptor": "\nComments: 25 pages, 4 figures. Submitted to AMC. Comments and suggestions are welcome\n",
    "authors": [
      "Vicente F. Candela"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07603"
  },
  {
    "id": "arXiv:2106.07606",
    "title": "A Physics Informed Neural Network for Time-Dependent Nonlinear and  Higher Order Partial Differential Equations",
    "abstract": "A physics informed neural network (PINN) incorporates the physics of a system\nby satisfying its boundary value problem through a neural network's loss\nfunction. The PINN approach has shown great success in approximating the map\nbetween the solution of a partial differential equation (PDE) and its\nspatio-temporal input. However, for strongly non-linear and higher order\npartial differential equations PINN's accuracy reduces significantly. To\nresolve this problem, we propose a novel PINN scheme that solves the PDE\nsequentially over successive time segments using a single neural network. The\nkey idea is to re-train the same neural network for solving the PDE over\nsuccessive time segments while satisfying the already obtained solution for all\nprevious time segments. Thus it is named as backward compatible PINN (bc-PINN).\nTo illustrate the advantages of bc-PINN, we have used the Cahn Hilliard and\nAllen Cahn equations, which are widely used to describe phase separation and\nreaction diffusion systems. Our results show significant improvement in\naccuracy over the PINN method while using a smaller number of collocation\npoints. Additionally, we have shown that using the phase space technique for a\nhigher order PDE could further improve the accuracy and efficiency of the\nbc-PINN scheme.",
    "descriptor": "",
    "authors": [
      "Revanth Mattey",
      "Susanta Ghosh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.07606"
  },
  {
    "id": "arXiv:2106.07609",
    "title": "The Exact Spectral Derivative Discretization Finite Difference (ESDDFD)  Method for Wave Models: A Universal Wave View Through Natural Fractional /  Fractal Derivative Representations (or View Lens Shops for The Exponential  Wave Universe)",
    "abstract": "A wave view of the universe is proposed in which each natural phenomenon is\nequipped with its own unique natural viewing lens. A self-sameness modeling\nprinciple and its systematic application in Fourier-Laplace transform space is\nproposed as a novel, universal discrete modeling paradigm for\nadvection-diffusion-reaction equations (ADREs) across non-integer derivatives,\ntime scales, and wave spectral signatures. Its implementation is a novel exact\nspectral derivative discretization finite difference method (ESDDFD), a way for\ncrafting wave viewing lenses by obtaining discrete wave models from ADRE\nmodels. The template for building these lenses come in the form of natural\nderivative representations obtained from the wave signature probability\ndistribution function and its harmonic oscillation in FL transform space; use\nof the ESDDFD method in the discrete numerical modeling of wave equations\nrequires no a-priori theory of any mathematical derivative. A major\nmathematical consequence of this viewpoint is that all notions of the\nmathematical integer or non-integer derivatives have representation as limits\nof such natural derivative representations; this and other consequences are\ndiscussed and a discretization of a simple integer derivative\ndiffusion-reaction equation is presented to illustrate the method. The\nresulting view lenses, in the form of ESDDFD models, work well in detecting\nboth local and non-local Debye or Kohlrausch-Williams-Watts exponential\npatterns; only Brownian motion and sub-diffusion are discussed in the present\narticle.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "D.P. Clemence-Mkhope"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07609"
  },
  {
    "id": "arXiv:2106.07611",
    "title": "Neuroevolution-Enhanced Multi-Objective Optimization for Mixed-Precision  Quantization",
    "abstract": "Mixed-precision quantization is a powerful tool to enable memory and compute\nsavings of neural network workloads by deploying different sets of bit-width\nprecisions on separate compute operations. Recent research has shown\nsignificant progress in applying mixed-precision quantization techniques to\nreduce the memory footprint of various workloads, while also preserving task\nperformance. Prior work, however, has often ignored additional objectives, such\nas bit-operations, that are important for deployment of workloads on hardware.\nHere we present a flexible and scalable framework for automated mixed-precision\nquantization that optimizes multiple objectives. Our framework relies on\nNeuroevolution-Enhanced Multi-Objective Optimization (NEMO), a novel search\nmethod, to find Pareto optimal mixed-precision configurations for memory and\nbit-operations objectives. Within NEMO, a population is divided into\nstructurally distinct sub-populations (species) which jointly form the Pareto\nfrontier of solutions for the multi-objective problem. At each generation,\nspecies are re-sized in proportion to the goodness of their contribution to the\nPareto frontier. This allows NEMO to leverage established search techniques and\nneuroevolution methods to continually improve the goodness of the Pareto\nfrontier. In our experiments we apply a graph-based representation to describe\nthe underlying workload, enabling us to deploy graph neural networks trained by\nNEMO to find Pareto optimal configurations for various workloads trained on\nImageNet. Compared to the state-of-the-art, we achieve competitive results on\nmemory compression and superior results for compute compression for\nMobileNet-V2, ResNet50 and ResNeXt-101-32x8d. A deeper analysis of the results\nobtained by NEMO also shows that both the graph representation and the\nspecies-based approach are critical in finding effective configurations for all\nworkloads.",
    "descriptor": "",
    "authors": [
      "Santiago Miret",
      "Vui Seng Chua",
      "Mattias Marder",
      "Mariano Phielipp",
      "Nilesh Jain",
      "Somdeb Majumdar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07611"
  },
  {
    "id": "arXiv:2106.07613",
    "title": "Improving Metric Dimensionality Reduction with Distributed Topology",
    "abstract": "We propose a novel approach to dimensionality reduction combining techniques\nof metric geometry and distributed persistent homology, in the form of a\ngradient-descent based method called DIPOLE. DIPOLE is a\ndimensionality-reduction post-processing step that corrects an initial\nembedding by minimizing a loss functional with both a local, metric term and a\nglobal, topological term. By fixing an initial embedding method (we use\nIsomap), DIPOLE can also be viewed as a full dimensionality-reduction pipeline.\nThis framework is based on the strong theoretical and computational properties\nof distributed persistent homology and comes with the guarantee of almost sure\nconvergence. We observe that DIPOLE outperforms popular methods like UMAP,\nt-SNE, and Isomap on a number of popular datasets, both visually and in terms\nof precise quantitative metrics.",
    "descriptor": "",
    "authors": [
      "Alexander Wagner",
      "Elchanan Solomon",
      "Paul Bendich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2106.07613"
  },
  {
    "id": "arXiv:2106.07615",
    "title": "Magic Layouts: Structural Prior for Component Detection in User  Interface Designs",
    "abstract": "We present Magic Layouts; a method for parsing screenshots or hand-drawn\nsketches of user interface (UI) layouts. Our core contribution is to extend\nexisting detectors to exploit a learned structural prior for UI designs,\nenabling robust detection of UI components; buttons, text boxes and similar.\nSpecifically we learn a prior over mobile UI layouts, encoding common spatial\nco-occurrence relationships between different UI components. Conditioning\nregion proposals using this prior leads to performance gains on UI layout\nparsing for both hand-drawn UIs and app screenshots, which we demonstrate\nwithin the context an interactive application for rapidly acquiring digital\nprototypes of user experience (UX) designs.",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Dipu Manandhar",
      "Hailin Jin",
      "John Collomosse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07615"
  },
  {
    "id": "arXiv:2106.07616",
    "title": "A Semi-Implicit Meshless Method for Incompressible Flows in Complex  Geometries",
    "abstract": "We present an exponentially convergent semi-implicit meshless algorithm for\nthe solution of Navier-Stokes equations in complex domains. The algorithm\ndiscretizes partial derivatives at scattered points using radial basis\nfunctions as interpolants. Higher-order polynomials are appended to\npolyharmonic splines (PHS-RBF) and a collocation method is used to derive the\ninterpolation coefficients. The interpolating kernels are then differentiated\nand the partial-differential equations are satisfied by collocation at the\nscattered points. The PHS-RBF interpolation is shown to be exponentially\nconvergent with discretization errors decreasing as a high power of a\nrepresentative distance between points. We present here a semi-implicit\nalgorithm for time-dependent and steady state fluid flows in complex domains.\nAt each time step, several iterations are performed to converge the momentum\nand continuity equations. A Poisson equation for pressure corrections is\nformulated by imposing divergence free condition on the iterated velocity\nfield. At each time step, the momentum and pressure correction equations are\nrepeatedly solved until the velocities and pressure converge to a pre-specified\ntolerance. We have demonstrated the convergence and discretization accuracy of\nthe algorithm for two model problems and simulated three other complex\nproblems. In all cases, the algorithm is stable for Courant numbers in excess\nof ten. The algorithm has the potential to accurately and efficiently solve\nmany fluid flow and heat transfer problems in complex domains. An open source\ncode Meshless Multi-Physics Software (MeMPhyS) is available for interested\nusers of the algorithm.",
    "descriptor": "",
    "authors": [
      "Shantanu Shahane",
      "Surya Pratap Vanka"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.07616"
  },
  {
    "id": "arXiv:2106.07617",
    "title": "Delving Deep into the Generalization of Vision Transformers under  Distribution Shifts",
    "abstract": "Recently, Vision Transformers (ViTs) have achieved impressive results on\nvarious vision tasks. Yet, their generalization ability under different\ndistribution shifts is rarely understood. In this work, we provide a\ncomprehensive study on the out-of-distribution generalization of ViTs. To\nsupport a systematic investigation, we first present a taxonomy of distribution\nshifts by categorizing them into five conceptual groups: corruption shift,\nbackground shift, texture shift, destruction shift, and style shift. Then we\nperform extensive evaluations of ViT variants under different groups of\ndistribution shifts and compare their generalization ability with CNNs. Several\nimportant observations are obtained: 1) ViTs generalize better than CNNs under\nmultiple distribution shifts. With the same or fewer parameters, ViTs are ahead\nof corresponding CNNs by more than 5% in top-1 accuracy under most distribution\nshifts. 2) Larger ViTs gradually narrow the in-distribution and\nout-of-distribution performance gap. To further improve the generalization of\nViTs, we design the Generalization-Enhanced ViTs by integrating adversarial\nlearning, information theory, and self-supervised learning. By investigating\nthree types of generalization-enhanced ViTs, we observe their\ngradient-sensitivity and design a smoother learning strategy to achieve a\nstable training process. With modified training schemes, we achieve\nimprovements on performance towards out-of-distribution data by 4% from vanilla\nViTs. We comprehensively compare three generalization-enhanced ViTs with their\ncorresponding CNNs, and observe that: 1) For the enhanced model, larger ViTs\nstill benefit more for the out-of-distribution generalization. 2)\ngeneralization-enhanced ViTs are more sensitive to the hyper-parameters than\ncorresponding CNNs. We hope our comprehensive study could shed light on the\ndesign of more generalizable learning architectures.",
    "descriptor": "",
    "authors": [
      "Chongzhi Zhang",
      "Mingyuan Zhang",
      "Shanghang Zhang",
      "Daisheng Jin",
      "Qiang Zhou",
      "Zhongang Cai",
      "Haiyu Zhao",
      "Shuai Yi",
      "Xianglong Liu",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07617"
  },
  {
    "id": "arXiv:2106.07620",
    "title": "Fast symplectic integrator for Nesterov-type acceleration method",
    "abstract": "In this paper, explicit stable integrators based on symplectic and contact\ngeometries are proposed for a non-autonomous ordinarily differential equation\n(ODE) found in improving convergence rate of Nesterov's accelerated gradient\nmethod. Symplectic geometry is known to be suitable for describing Hamiltonian\nmechanics, and contact geometry is known as an odd-dimensional counterpart of\nsymplectic geometry. Moreover, a procedure, called symplectization, is a known\nway to construct a symplectic manifold from a contact manifold, yielding\nHamiltonian systems from contact ones. It is found in this paper that a\npreviously investigated non-autonomous ODE can be written as a contact\nHamiltonian system. Then, by symplectization of a non-autonomous contact\nHamiltonian vector field expressing the non-autonomous ODE, novel symplectic\nintegrators are derived. Because the proposed symplectic integrators preserve\nhidden symplectic and contact structures in the ODE, they should be more stable\nthan the Runge-Kutta method. Numerical experiments demonstrate that, as\nexpected, the second-order symplectic integrator is stable and high convergence\nrates are achieved.",
    "descriptor": "",
    "authors": [
      "Shin-itiro Goto",
      "Hideitsu Hino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07620"
  },
  {
    "id": "arXiv:2106.07621",
    "title": "A Generalization of Classical Formulas in Numerical Integration and  Series Convergence Acceleration",
    "abstract": "Summation formulas, such as the Euler-Maclaurin expansion or Gregory's\nquadrature, have found many applications in mathematics, ranging from\naccelerating series, to evaluating fractional sums and analyzing asymptotics,\namong others. We show that these summation formulas actually arise as\nparticular instances of a single series expansion, including Euler's method for\nalternating series. This new summation formula gives rise to a family of\npolynomials, which contain both the Bernoulli and Gregory numbers in their\ncoefficients. We prove some properties of those polynomials, such as recurrence\nidentities and symmetries. Lastly, we present one case study, which illustrates\none potential application of the new expansion for finite impulse response\n(FIR) filters.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Ibrahim Alabdulmohsin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2106.07621"
  },
  {
    "id": "arXiv:2106.07625",
    "title": "On numerical aspects of parameter identification for the  Landau-Lifshitz-Gilbert equation in Magnetic Particle Imaging",
    "abstract": "The Landau-Lifshitz-Gilbert equation yields a mathematical model to describe\nthe evolution of the magnetization of a magnetic material, particularly in\nresponse to an external applied magnetic field. It allows one to take into\naccount various physical effects, such as the exchange within the magnetic\nmaterial itself. In particular, the Landau-Lifshitz-Gilbert equation encodes\nrelaxation effects, i.e., it describes the time-delayed alignment of the\nmagnetization field with an external magnetic field. These relaxation effects\nare an important aspect in magnetic particle imaging, particularly in the\ncalibration process. In this article, we address the data-driven modeling of\nthe system function in magnetic particle imaging, where the\nLandau-Lifshitz-Gilbert equation serves as the basic tool to include relaxation\neffects in the model. We formulate the respective parameter identification\nproblem both in the all-at-once and the reduced setting, present reconstruction\nalgorithms that yield a regularized solution and discuss numerical experiments.\nApart from that, we propose a practical numerical solver to the nonlinear\nLandau-Lifshitz-Gilbert equation, not via the classical finite element method,\nbut through solving only linear PDEs in an inverse problem framework.",
    "descriptor": "",
    "authors": [
      "Tram Thi Ngoc Nguyen",
      "Anne Wald"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07625"
  },
  {
    "id": "arXiv:2106.07627",
    "title": "Toward Automatic Interpretation of 3D Plots",
    "abstract": "This paper explores the challenge of teaching a machine how to\nreverse-engineer the grid-marked surfaces used to represent data in 3D surface\nplots of two-variable functions. These are common in scientific and economic\npublications; and humans can often interpret them with ease, quickly gleaning\ngeneral shape and curvature information from the simple collection of curves.\nWhile machines have no such visual intuition, they do have the potential to\naccurately extract the more detailed quantitative data that guided the\nsurface's construction. We approach this problem by synthesizing a new dataset\nof 3D grid-marked surfaces (SurfaceGrid) and training a deep neural net to\nestimate their shape. Our algorithm successfully recovers shape information\nfrom synthetic 3D surface plots that have had axes and shading information\nremoved, been rendered with a variety of grid types, and viewed from a range of\nviewpoints.",
    "descriptor": "\nComments: 16 pages, 12 figures, accepted to the 16th International Conference on Document Analysis and Recognition (ICDAR21)\n",
    "authors": [
      "Laura E. Brandt",
      "William T. Freeman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07627"
  },
  {
    "id": "arXiv:2106.07628",
    "title": "A multiresolution adaptive wavelet method for nonlinear partial  differential equations",
    "abstract": "The multiscale complexity of modern problems in computational science and\nengineering can prohibit the use of traditional numerical methods in\nmulti-dimensional simulations. Therefore, novel algorithms are required in\nthese situations to solve partial differential equations (PDEs) with features\nevolving on a wide range of spatial and temporal scales. To meet these\nchallenges, we present a multiresolution wavelet algorithm to solve PDEs with\nsignificant data compression and explicit error control. We discretize in space\nby projecting fields and spatial derivative operators onto wavelet basis\nfunctions. We provide error estimates for the wavelet representation of fields\nand their derivatives. Then, our estimates are used to construct a sparse\nmultiresolution discretization which guarantees the prescribed accuracy.\nAdditionally, we embed a predictor-corrector procedure within the temporal\nintegration to dynamically adapt the computational grid and maintain the\naccuracy of the solution of the PDE as it evolves. We present examples to\nhighlight the accuracy and adaptivity of our approach.",
    "descriptor": "",
    "authors": [
      "Cale Harnish",
      "Luke Dalessandro",
      "Karel Matous",
      "Daniel Livescu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.07628"
  },
  {
    "id": "arXiv:2106.07630",
    "title": "Hierarchically Regularized Deep Forecasting",
    "abstract": "Hierarchical forecasting is a key problem in many practical multivariate\nforecasting applications - the goal is to simultaneously predict a large number\nof correlated time series that are arranged in a pre-specified aggregation\nhierarchy. The challenge is to exploit the hierarchical correlations to\nsimultaneously obtain good prediction accuracy for time series at different\nlevels of the hierarchy. In this paper, we propose a new approach for\nhierarchical forecasting based on decomposing the time series along a global\nset of basis time series and modeling hierarchical constraints using the\ncoefficients of the basis decomposition for each time series. Unlike past\nmethods, our approach is scalable at inference-time (forecasting for a specific\ntime series only needs access to its own data) while (approximately) preserving\ncoherence among the time series forecasts. We experiment on several publicly\navailable datasets and demonstrate significantly improved overall performance\non forecasts at different levels of the hierarchy, compared to existing\nstate-of-the-art hierarchical reconciliation methods.",
    "descriptor": "",
    "authors": [
      "Biswajit Paria",
      "Rajat Sen",
      "Amr Ahmed",
      "Abhimanyu Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07630"
  },
  {
    "id": "arXiv:2106.07631",
    "title": "Improved Transformer for High-Resolution GANs",
    "abstract": "Attention-based models, exemplified by the Transformer, can effectively model\nlong range dependency, but suffer from the quadratic complexity of\nself-attention operation, making them difficult to be adopted for\nhigh-resolution image generation based on Generative Adversarial Networks\n(GANs). In this paper, we introduce two key ingredients to Transformer to\naddress this challenge. First, in low-resolution stages of the generative\nprocess, standard global self-attention is replaced with the proposed\nmulti-axis blocked self-attention which allows efficient mixing of local and\nglobal attention. Second, in high-resolution stages, we drop self-attention\nwhile only keeping multi-layer perceptrons reminiscent of the implicit neural\nfunction. To further improve the performance, we introduce an additional\nself-modulation component based on cross-attention. The resulting model,\ndenoted as HiT, has a linear computational complexity with respect to the image\nsize and thus directly scales to synthesizing high definition images. We show\nin the experiments that the proposed HiT achieves state-of-the-art FID scores\nof 31.87 and 2.95 on unconditional ImageNet $128 \\times 128$ and FFHQ $256\n\\times 256$, respectively, with a reasonable throughput. We believe the\nproposed HiT is an important milestone for generators in GANs which are\ncompletely free of convolutions.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Long Zhao",
      "Zizhao Zhang",
      "Ting Chen",
      "Dimitris N. Metaxas",
      "Han Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07631"
  },
  {
    "id": "arXiv:2106.07635",
    "title": "Variational Causal Networks: Approximate Bayesian Inference over Causal  Structures",
    "abstract": "Learning the causal structure that underlies data is a crucial step towards\nrobust real-world decision making. The majority of existing work in causal\ninference focuses on determining a single directed acyclic graph (DAG) or a\nMarkov equivalence class thereof. However, a crucial aspect to acting\nintelligently upon the knowledge about causal structure which has been inferred\nfrom finite data demands reasoning about its uncertainty. For instance,\nplanning interventions to find out more about the causal mechanisms that govern\nour data requires quantifying epistemic uncertainty over DAGs. While Bayesian\ncausal inference allows to do so, the posterior over DAGs becomes intractable\neven for a small number of variables. Aiming to overcome this issue, we propose\na form of variational inference over the graphs of Structural Causal Models\n(SCMs). To this end, we introduce a parametric variational family modelled by\nan autoregressive distribution over the space of discrete DAGs. Its number of\nparameters does not grow exponentially with the number of variables and can be\ntractably learned by maximising an Evidence Lower Bound (ELBO). In our\nexperiments, we demonstrate that the proposed variational posterior is able to\nprovide a good approximation of the true posterior.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Yashas Annadani",
      "Jonas Rothfuss",
      "Alexandre Lacoste",
      "Nino Scherrer",
      "Anirudh Goyal",
      "Yoshua Bengio",
      "Stefan Bauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07635"
  },
  {
    "id": "arXiv:2106.07643",
    "title": "Unsupervised Learning of Visual 3D Keypoints for Control",
    "abstract": "Learning sensorimotor control policies from high-dimensional images crucially\nrelies on the quality of the underlying visual representations. Prior works\nshow that structured latent space such as visual keypoints often outperforms\nunstructured representations for robotic control. However, most of these\nrepresentations, whether structured or unstructured are learned in a 2D space\neven though the control tasks are usually performed in a 3D environment. In\nthis work, we propose a framework to learn such a 3D geometric structure\ndirectly from images in an end-to-end unsupervised manner. The input images are\nembedded into latent 3D keypoints via a differentiable encoder which is trained\nto optimize both a multi-view consistency loss and downstream task objective.\nThese discovered 3D keypoints tend to meaningfully capture robot joints as well\nas object movements in a consistent manner across both time and 3D space. The\nproposed approach outperforms prior state-of-art methods across a variety of\nreinforcement learning benchmarks. Code and videos at\nhttps://buoyancy99.github.io/unsup-3d-keypoints/",
    "descriptor": "\nComments: Accepted at ICML 2021. Videos and code at this https URL\n",
    "authors": [
      "Boyuan Chen",
      "Pieter Abbeel",
      "Deepak Pathak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.07643"
  },
  {
    "id": "arXiv:1912.03121",
    "title": "Numerical methods for hydraulic transients in visco-elastic pipes",
    "abstract": "A wide and critical comparison of the capability of Method of\nCharacteristics, Explicit Path-Conservative Finite Volume Method and\nSemi-Implicit Staggered Finite Volume Method is presented and discussed, in\nterms of accuracy and efficiency. The viscoelastic behaviour of the pipe wall,\nthe effects of the unsteadiness of the flow on the friction losses, cavitation\nand cross-sectional changes are considered. The analyses are performed\ncomparing numerical solutions obtained using the three models against\nexperimental data and analytical solutions. Water hammer studies in high\ndensity polyethylene pipes, for which laboratory data have been provided, are\nused as test cases. Considering the viscoelastic mechanical behaviour of\nplastic materials, a 3-parameter and a multi-parameter linear viscoelastic\nrheological model are adopted and implemented in each numerical scheme.\nOriginal extensions of existing techniques for the numerical treatment of such\nviscoelastic models are introduced in this work for the first time. After a\nfocused calibration of the viscoelastic parameters, the different performance\nof the numerical models is investigated. A comparison of the results is\npresented considering the unsteady wall-shear stress, with a new approach\nproposed for turbulent flows, or simply considering a quasi-steady friction\nmodel. A predominance of the damping effect due to viscoelasticity with respect\nto the damping effect related to the unsteady friction is confirmed in these\ncontexts. All the numerical methods show a good agreement with the experimental\ndata and a high efficiency of the Method of Characteristics in standard\nconfiguration is observed. Three Riemann Problems are chosen and run to stress\nthe numerical methods, considering cross-sectional changes, more flexible\nmaterials and cavitation cases. In these demanding scenarios, the weak spots of\nthe Method of Characteristics are depicted.",
    "descriptor": "",
    "authors": [
      "Giulia Bertaglia",
      "Matteo Ioriatti",
      "Alessandro Valiani",
      "Michael Dumbser",
      "Valerio Caleffi"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1912.03121"
  },
  {
    "id": "arXiv:1912.03167",
    "title": "Modeling blood flow in viscoelastic vessels: the 1D augmented  fluid-structure interaction system",
    "abstract": "Mathematical models and numerical simulations are widely used in the field of\nhemodynamics, representing a valuable resource to better understand\nphysiological and pathological processes. The theory behind the phenomenon is\nclosely related to the study of incompressible flow through compliant\nthin-walled tubes. The mechanical interaction between blood flow and vessel\nwall must be properly described by the model. Recent works show the benefits of\ncharacterizing the rheology of the vessel wall through a viscoelastic law.\nConsidering the viscous contribution of the wall material and not simply the\nelastic one leads to a more realistic representation of the vessel behavior,\nwhich manifests not only an instantaneous elastic strain but also a viscous\ndamping effect on pulse pressure waves, coupled to energy losses. The aim of\nthis work is to propose an easily extensible 1D mathematical model able to\naccurately capture the FSI. The originality lies in the introduction of a\nviscoelastic tube law in PDE form, valid for both arterial and venous networks,\nleading to an augmented FSI system. In contrast to well established\nmathematical models, the proposed one is natively hyperbolic. The model is\nsolved with a 2nd-order numerical scheme based on an IMEX RK scheme conceived\nfor applications to hyperbolic systems with stiff relaxation terms. The\nvalidation of the model is performed on different tests. Results obtained in\nRiemann problems, adopting a simple elastic tube law for the characterization\nof the vessel wall, are compared with available exact solutions. To validate\nthe contribution given by the viscoelastic term, the Method of Manufactured\nSolutions is applied. Specific tests are designed to verify the well-balancing\nand the AP property of the scheme. A specific test with an inlet pulse pressure\nwave is designed to assess the effects of viscoelasticity.",
    "descriptor": "\nComments: to be published in Computer Methods in Applied Mechanics and Engineering\n",
    "authors": [
      "Giulia Bertaglia",
      "Valerio Caleffi",
      "Alessandro Valiani"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1912.03167"
  },
  {
    "id": "arXiv:1912.03285",
    "title": "Computational hemodynamics in arteries with the one-dimensional  augmented fluid-structure interaction system: viscoelastic parameters  estimation and comparison with in-vivo data",
    "abstract": "Mathematical models are widely recognized as a valuable tool for\ncardiovascular diagnosis and the study of circulatory diseases, especially to\nobtain data that require otherwise invasive measurements. To correctly simulate\nbody hemodynamics, the viscoelastic properties of vessel walls are a key aspect\nto be taken into account as they play an essential role in cardiovascular\nbehavior. The present work aims to apply the augmented fluid-structure\ninteraction system of blood flow to real case studies to assess the validity of\nthe model as a valuable resource to improve cardiovascular diagnostics and the\ntreatment of pathologies. First, the ability of the model to correctly simulate\npulse waveforms in single arterial segments is verified using literature\nbenchmark test cases. Such cases are designed taking into account a simple\nelastic behavior of the wall in the upper thoracic aorta and in the common\ncarotid artery. Furthermore, in-vivo pressure waveforms, extracted from\ntonometric measurements performed on four human common carotid arteries and two\ncommon femoral arteries, are compared to numerical solutions. It is highlighted\nthat the viscoelastic damping effect of arterial walls is required to avoid an\noverestimation of pressure peaks. An effective procedure to estimate the\nviscoelastic parameters of the model is herein proposed, which returns\nhysteresis curves of the common carotid arteries dissipating energy fractions\nin line with values calculated from literature hysteresis loops in the same\nvessel.",
    "descriptor": "\nComments: submitted to Journal of Biomechanics\n",
    "authors": [
      "Giulia Bertaglia",
      "Adri\u00e1n Navas-Montilla",
      "Alessandro Valiani",
      "Manuel Ignacio Monge Garc\u00eda",
      "Javier Murillo",
      "Valerio Caleffi"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/1912.03285"
  },
  {
    "id": "arXiv:2106.06573",
    "title": "Understanding Deflation Process in Over-parametrized Tensor  Decomposition",
    "abstract": "In this paper we study the training dynamics for gradient flow on\nover-parametrized tensor decomposition problems. Empirically, such training\nprocess often first fits larger components and then discovers smaller\ncomponents, which is similar to a tensor deflation process that is commonly\nused in tensor decomposition algorithms. We prove that for orthogonally\ndecomposable tensor, a slightly modified version of gradient flow would follow\na tensor deflation process and recover all the tensor components. Our proof\nsuggests that for orthogonal tensors, gradient flow dynamics works similarly as\ngreedy low-rank learning in the matrix setting, which is a first step towards\nunderstanding the implicit regularization effect of over-parametrized models\nfor low-rank tensors.",
    "descriptor": "",
    "authors": [
      "Rong Ge",
      "Yunwei Ren",
      "Xiang Wang",
      "Mo Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06573"
  },
  {
    "id": "arXiv:2106.06574",
    "title": "Landscape Correspondence of Empirical and Population Risks in the  Eigendecomposition Problem",
    "abstract": "Spectral methods include a family of algorithms related to the eigenvectors\nof certain data-generated matrices. In this work, we are interested in studying\nthe geometric landscape of the eigendecomposition problem in various spectral\nmethods. In particular, we first extend known results regarding the landscape\nat critical points to larger regions near the critical points in a special case\nof finding the leading eigenvector of a symmetric matrix. For a more general\neigendecomposition problem, inspired by recent findings on the connection\nbetween the landscapes of empirical risk and population risk, we then build a\nnovel connection between the landscape of an eigendecomposition problem that\nuses random measurements and the one that uses the true data matrix. We also\napply our theory to a variety of low-rank matrix optimization problems and\nconduct a series of simulations to illustrate our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Shuang Li",
      "Gongguo Tang",
      "Michael B. Wakin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.06574"
  },
  {
    "id": "arXiv:2106.06608",
    "title": "Statistical Analysis from the Fourier Integral Theorem",
    "abstract": "Taking the Fourier integral theorem as our starting point, in this paper we\nfocus on natural Monte Carlo and fully nonparametric estimators of multivariate\ndistributions and conditional distribution functions. We do this without the\nneed for any estimated covariance matrix or dependence structure between\nvariables. These aspects arise immediately from the integral theorem. Being\nable to model multivariate data sets using conditional distribution functions\nwe can study a number of problems, such as prediction for Markov processes,\nestimation of mixing distribution functions which depend on covariates, and\ngeneral multivariate data. Estimators are explicit Monte Carlo based and\nrequire no recursive or iterative algorithms.",
    "descriptor": "\nComments: 20 pages, 10 figures\n",
    "authors": [
      "Nhat Ho",
      "Stephen G. Walker"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06608"
  },
  {
    "id": "arXiv:2106.06664",
    "title": "Rapid COVID-19 Risk Screening by Eye-region Manifestations",
    "abstract": "It is still nontrivial to develop a new fast COVID-19 screening method with\nthe easier access and lower cost, due to the technical and cost limitations of\nthe current testing methods in the medical resource-poor districts. On the\nother hand, there are more and more ocular manifestations that have been\nreported in the COVID-19 patients as growing clinical evidence[1]. This\ninspired this project. We have conducted the joint clinical research since\nJanuary 2021 at the ShiJiaZhuang City, Heibei province, China, which approved\nby the ethics committee of The fifth hospital of ShiJiaZhuang of Hebei Medical\nUniversity. We undertake several blind tests of COVID-19 patients by Union\nHospital, Tongji Medical College, Huazhong University of Science and\nTechnology, Wuhan, China. Meantime as an important part of the ongoing globally\nCOVID-19 eye test program by AIMOMICS since February 2020, we propose a new\nfast screening method of analyzing the eye-region images, captured by common\nCCD and CMOS cameras. This could reliably make a rapid risk screening of\nCOVID-19 with the sustainable stable high performance in different countries\nand races. Our model for COVID-19 rapid prescreening have the merits of the\nlower cost, fully self-performed, non-invasive, importantly real-time, and thus\nenables the continuous health surveillance. We further implement it as the open\naccessible APIs, and provide public service to the world. Our pilot experiments\nshow that our model is ready to be usable to all kinds of surveillance\nscenarios, such as infrared temperature measurement device at airports and\nstations, or directly pushing to the target people groups smartphones as a\npackaged application.",
    "descriptor": "",
    "authors": [
      "Yanwei Fu",
      "Lei Zhao",
      "Haojie Zheng",
      "Qiang Sun",
      "Li Yang",
      "Hong Li",
      "Jiao Xie",
      "Xiangyang Xue",
      "Feng Li",
      "Yuan Li",
      "Wei Wang",
      "Yantao Pei",
      "Jianmin Wang",
      "Xiuqi Wu",
      "Yanhua Zheng",
      "Hongxia Tian Mengwei Gu1"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06664"
  },
  {
    "id": "arXiv:2106.06691",
    "title": "Doubly Non-Central Beta Matrix Factorization for DNA Methylation Data",
    "abstract": "We present a new non-negative matrix factorization model for $(0,1)$\nbounded-support data based on the doubly non-central beta (DNCB) distribution,\na generalization of the beta distribution. The expressiveness of the DNCB\ndistribution is particularly useful for modeling DNA methylation datasets,\nwhich are typically highly dispersed and multi-modal; however, the model\nstructure is sufficiently general that it can be adapted to many other domains\nwhere latent representations of $(0,1)$ bounded-support data are of interest.\nAlthough the DNCB distribution lacks a closed-form conjugate prior, several\naugmentations let us derive an efficient posterior inference algorithm composed\nentirely of analytic updates. Our model improves out-of-sample predictive\nperformance on both real and synthetic DNA methylation datasets over\nstate-of-the-art methods in bioinformatics. In addition, our model yields\nmeaningful latent representations that accord with existing biological\nknowledge.",
    "descriptor": "\nComments: To appear in the Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI) 2021\n",
    "authors": [
      "Aaron Schein",
      "Anjali Nagulpally",
      "Hanna Wallach",
      "Patrick Flaherty"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.06691"
  },
  {
    "id": "arXiv:2106.06718",
    "title": "Using Convolutional Neural Networks for the Helicity Classification of  Magnetic Fields",
    "abstract": "The presence of non-zero helicity in intergalactic magnetic fields is a\nsmoking gun for their primordial origin since they have to be generated by\nprocesses that break CP invariance. As an experimental signature for the\npresence of helical magnetic fields, an estimator $Q$ based on the triple\nscalar product of the wave-vectors of photons generated in electromagnetic\ncascades from, e.g., TeV blazars, has been suggested previously. We propose to\napply deep learning to helicity classification employing Convolutional Neural\nNetworks and show that this method outperforms the $Q$ estimator.",
    "descriptor": "\nComments: 14 pages, extended version of a contribution to the proceedings of the 37.th ICRC 2021\n",
    "authors": [
      "Nicol\u00f2 Oreste Pinciroli Vago",
      "Ibrahim A. Hameed",
      "Michael Kachelriess"
    ],
    "subjectives": [
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.06718"
  },
  {
    "id": "arXiv:2106.06741",
    "title": "Distributionally Robust Optimization with Markovian Data",
    "abstract": "We study a stochastic program where the probability distribution of the\nuncertain problem parameters is unknown and only indirectly observed via\nfinitely many correlated samples generated by an unknown Markov chain with $d$\nstates. We propose a data-driven distributionally robust optimization model to\nestimate the problem's objective function and optimal solution. By leveraging\nresults from large deviations theory, we derive statistical guarantees on the\nquality of these estimators. The underlying worst-case expectation problem is\nnonconvex and involves $\\mathcal O(d^2)$ decision variables. Thus, it cannot be\nsolved efficiently for large $d$. By exploiting the structure of this problem,\nwe devise a customized Frank-Wolfe algorithm with convex direction-finding\nsubproblems of size $\\mathcal O(d)$. We prove that this algorithm finds a\nstationary point efficiently under mild conditions. The efficiency of the\nmethod is predicated on a dimensionality reduction enabled by a dual\nreformulation. Numerical experiments indicate that our approach has better\ncomputational and statistical properties than the state-of-the-art methods.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Mengmeng Li",
      "Tobias Sutter",
      "Daniel Kuhn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06741"
  },
  {
    "id": "arXiv:2106.06743",
    "title": "Hippocampus segmentation in magnetic resonance images of Alzheimer's  patients using Deep machine learning",
    "abstract": "Background: Alzheimers disease is a progressive neurodegenerative disorder\nand the main cause of dementia in aging. Hippocampus is prone to changes in the\nearly stages of Alzheimers disease. Detection and observation of the\nhippocampus changes using magnetic resonance imaging (MRI) before the onset of\nAlzheimers disease leads to the faster preventive and therapeutic measures.\nObjective: The aim of this study was the segmentation of the hippocampus in\nmagnetic resonance (MR) images of Alzheimers patients using deep machine\nlearning method. Methods: U-Net architecture of convolutional neural network\nwas proposed to segment the hippocampus in the real MRI data. The MR images of\nthe 100 and 35 patients available in Alzheimers disease Neuroimaging Initiative\n(ADNI) dataset, was used for the train and test of the model, respectively. The\nperformance of the proposed method was compared with manual segmentation by\nmeasuring the similarity metrics. Results: The desired segmentation achieved\nafter 10 iterations. A Dice similarity coefficient (DSC) = 92.3%, sensitivity =\n96.5%, positive predicted value (PPV) = 90.4%, and Intersection over Union\n(IoU) value for the train 92.94 and test 92.93 sets were obtained which are\nacceptable. Conclusion: The proposed approach is promising and can be extended\nin the prognosis of Alzheimers disease by the prediction of the hippocampus\nvolume changes in the early stage of the disease.",
    "descriptor": "",
    "authors": [
      "Hadi Varmazyar",
      "Hossein Yousefi-Banaem",
      "Saber Malekzadeh",
      "Nahideh Gharehaghaji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.06743"
  },
  {
    "id": "arXiv:2106.06784",
    "title": "Residual Networks based Distortion Classification and Ranking for  Laparoscopic Image Quality Assessment",
    "abstract": "Laparoscopic images and videos are often affected by different types of\ndistortion like noise, smoke, blur and nonuniform illumination. Automatic\ndetection of these distortions, followed generally by application of\nappropriate image quality enhancement methods, is critical to avoid errors\nduring surgery. In this context, a crucial step involves an objective\nassessment of the image quality, which is a two-fold problem requiring both the\nclassification of the distortion type affecting the image and the estimation of\nthe severity level of that distortion. Unlike existing image quality measures\nwhich focus mainly on estimating a quality score, we propose in this paper to\nformulate the image quality assessment task as a multi-label classification\nproblem taking into account both the type as well as the severity level (or\nrank) of distortions. Here, this problem is then solved by resorting to a deep\nneural networks based approach. The obtained results on a laparoscopic image\ndataset show the efficiency of the proposed approach.",
    "descriptor": "\nComments: 5 Pages, ICIP 2020\n",
    "authors": [
      "Zohaib Amjad Khan",
      "Azeddine Beghdadi",
      "Mounir Kaaniche",
      "Faouzi Alaya Cheikh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06784"
  },
  {
    "id": "arXiv:2106.06805",
    "title": "Predicting Higher Education Throughput in South Africa Using a  Tree-Based Ensemble Technique",
    "abstract": "We use gradient boosting machines and logistic regression to predict academic\nthroughput at a South African university. The results highlight the significant\ninfluence of socio-economic factors and field of study as predictors of\nthroughput. We further find that socio-economic factors become less of a\npredictor relative to the field of study as the time to completion increases.\nWe provide recommendations on interventions to counteract the identified\neffects, which include academic, psychosocial and financial support.",
    "descriptor": "",
    "authors": [
      "Rendani Mbuvha",
      "Patience Zondo",
      "Aluwani Mauda",
      "Tshilidzi Marwala"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06805"
  },
  {
    "id": "arXiv:2106.06806",
    "title": "On a parabolic sine-Gordon model",
    "abstract": "We consider a parabolic sine-Gordon model with periodic boundary conditions.\nWe prove a fundamental maximum principle which gives a priori uniform control\nof the solution. In the one-dimensional case we classify all bounded steady\nstates and exhibit some explicit solutions. For the numerical discretization we\nemploy first order IMEX, and second order BDF2 discretization without any\nadditional stabilization term. We rigorously prove the energy stability of the\nnumerical schemes under nearly sharp and quite mild time step constraints. We\ndemonstrate the striking similarity of the parabolic sine-Gordon model with the\nstandard Allen-Cahn equations with double well potentials.",
    "descriptor": "\nComments: 14 pages; to appear in \"Numerical Mathematics: Theory, Methods and Applications\"\n",
    "authors": [
      "Xinyu Cheng",
      "Dong Li",
      "Chaoyu Quan",
      "Wen Yang"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.06806"
  },
  {
    "id": "arXiv:2106.06841",
    "title": "Quantum Algorithms and Simulation for Parallel and Distributed Quantum  Computing",
    "abstract": "A viable approach for building large-scale quantum computers is to interlink\nsmall-scale quantum computers with a quantum network to create a larger\ndistributed quantum computer. When designing quantum algorithms for such a\ndistributed quantum computer, one can make use of the added parallelization and\ndistribution abilities inherent in such a system. An added difficulty to\nconsider for distributed quantum computing is that a complex control system to\norchestrate the various components is required. In this work, we present\ndistributed and parallel versions of quantum algorithms and discuss potential\nbenefits and we propose a general scheme for controlling the system. Further,\nwe present the Interlin-q simulation platform which aims to simplify designing\nand simulating parallel and distributed quantum algorithms. Interlin-q's main\nfeatures are generating and executing control instructions across a simulated\nquantum network of simulated quantum computers. We demonstrate a simulation of\na proposed parallelized algorithm using Interlin-q and discuss steps for\ndeveloping Interlin-q into a control system for distributed quantum computers.",
    "descriptor": "",
    "authors": [
      "Rhea Parekh",
      "Andrea Ricciardi",
      "Ahmed Darwish",
      "Stephen DiAdamo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.06841"
  },
  {
    "id": "arXiv:2106.06855",
    "title": "A Wideband Sliding Correlation Channel Sounder in 65 nm CMOS: Evaluation  Board Performance",
    "abstract": "Emerging applications such as wireless sensing, position location, robotics,\nand many more are driven by the ultra-wide bandwidths available at\nmillimeter-wave (mmWave) and Terahertz (THz) frequencies. The characterization\nand efficient utilization of wireless channels at these extremely high\nfrequencies require detailed knowledge of the radio propagation characteristics\nof the channels. Such knowledge is developed through empirical observations of\noperating conditions using wireless transceivers that measure the impulse\nresponse through channel sounding. Today, cutting-edge channel sounders rely on\nseveral bulky RF hardware components with complicated interconnections, large\nparasitics, and sub-GHz RF bandwidth. This paper presents a compact sliding\ncorrelation-based channel sounder baseband built on a monolithic integrated\ncircuit (IC) using 65 nm CMOS, implemented as an evaluation board achieving a 2\nGHz RF bandwidth. The IC is the worlds first gigabit-per-second channel sounder\nbaseband implemented in low-cost CMOS. The presented single-board system can be\nemployed at both the transmit and receive baseband to study multipath\ncharacteristics and path loss. Thus, the singleboard implementation provides an\ninexpensive and compact solution for sliding correlation-based channel sounding\nwith 1 ns multipath delay resolution.",
    "descriptor": "\nComments: 5 pages, 10 figures, Transactions on Circuits and Systems-II: Express Briefs\n",
    "authors": [
      "Dipankar Shakya",
      "Ting Wu",
      "Michael E. Knox",
      "Theodore S. Rappaport"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06855"
  },
  {
    "id": "arXiv:2106.06858",
    "title": "Improving weakly supervised sound event detection with self-supervised  auxiliary tasks",
    "abstract": "While multitask and transfer learning has shown to improve the performance of\nneural networks in limited data settings, they require pretraining of the model\non large datasets beforehand. In this paper, we focus on improving the\nperformance of weakly supervised sound event detection in low data and noisy\nsettings simultaneously without requiring any pretraining task. To that extent,\nwe propose a shared encoder architecture with sound event detection as a\nprimary task and an additional secondary decoder for a self-supervised\nauxiliary task. We empirically evaluate the proposed framework for weakly\nsupervised sound event detection on a remix dataset of the DCASE 2019 task 1\nacoustic scene data with DCASE 2018 Task 2 sounds event data under 0, 10 and 20\ndB SNR. To ensure we retain the localisation information of multiple sound\nevents, we propose a two-step attention pooling mechanism that provides a\ntime-frequency localisation of multiple audio events in the clip. The proposed\nframework with two-step attention outperforms existing benchmark models by\n22.3%, 12.8%, 5.9% on 0, 10 and 20 dB SNR respectively. We carry out an\nablation study to determine the contribution of the auxiliary task and two-step\nattention pooling to the SED performance improvement.",
    "descriptor": "\nComments: Accepted at INTERSPEECH 21\n",
    "authors": [
      "Soham Deshmukh",
      "Bhiksha Raj",
      "Rita Singh"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06858"
  },
  {
    "id": "arXiv:2106.06881",
    "title": "A public transit network optimization model for equitable access to  social services",
    "abstract": "We present a flexible public transit network design model which optimizes a\nsocial access objective while guaranteeing that the system's costs and transit\ntimes remain within a preset margin of their current levels. The purpose of the\nmodel is to find a set of minor, immediate modifications to an existing bus\nnetwork that can give more communities access to the chosen services while\nhaving a minimal impact on the current network's operator costs and user costs.\nDesign decisions consist of reallocation of existing resources in order to\nadjust line frequencies and capacities. We present a hybrid tabu\nsearch/simulated annealing algorithm for the solution of this\noptimization-based model. As a case study we apply the model to the problem of\nimproving equity of access to primary health care facilities in the Chicago\nmetropolitan area. The results of the model suggest that it is possible to\nachieve better primary care access equity through reassignment of existing\nbuses and implementation of express runs, while leaving overall service levels\nrelatively unaffected.",
    "descriptor": "\nComments: 38 pages, 6 figures\n",
    "authors": [
      "Adam Rumpf",
      "Hemanshu Kaul"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.06881"
  },
  {
    "id": "arXiv:2106.06891",
    "title": "Stochastic Alternating Direction Method of Multipliers for  Byzantine-Robust Distributed Learning",
    "abstract": "This paper aims to solve a distributed learning problem under Byzantine\nattacks. In the underlying distributed system, a number of unknown but\nmalicious workers (termed as Byzantine workers) can send arbitrary messages to\nthe master and bias the learning process, due to data corruptions, computation\nerrors or malicious attacks. Prior work has considered a total variation (TV)\nnorm-penalized approximation formulation to handle the Byzantine attacks, where\nthe TV norm penalty forces the regular workers' local variables to be close,\nand meanwhile, tolerates the outliers sent by the Byzantine workers. To solve\nthe TV norm-penalized approximation formulation, we propose a Byzantine-robust\nstochastic alternating direction method of multipliers (ADMM) that fully\nutilizes the separable problem structure. Theoretically, we prove that the\nproposed method converges to a bounded neighborhood of the optimal solution at\na rate of O(1/k) under mild assumptions, where k is the number of iterations\nand the size of neighborhood is determined by the number of Byzantine workers.\nNumerical experiments on the MNIST and COVERTYPE datasets demonstrate the\neffectiveness of the proposed method to various Byzantine attacks.",
    "descriptor": "",
    "authors": [
      "Feng Lin",
      "Weiyu Li",
      "Qing Ling"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06891"
  },
  {
    "id": "arXiv:2106.06975",
    "title": "A novel fully 3D, microfluidic-oriented, gel-based and low cost  stretchable soft sensor",
    "abstract": "In this paper, a novel fully 3D, microfluidic-oriented, gel-based, and\nlow-cost highly stretchable resistive sensors have been presented. By the\nproposed method we are able to measure and discriminate all of the stretch,\ntwist, and pressure features by a single sensor which is the potential that we\nhave obtained from the fully 3D structure of our sensor. Against previous\nsensors which all have used EGaIn as the conductive material of their sensor,\nwe have used low-cost, safe, and ubiquitous glycol-based gel instead. To show\nthe functionality of the proposed sensor some FEM simulations, a set of the\ndesigned experimental tests were done which showed the linear, accurate, and\ndurable operation of the proposed sensor. Finally, the sensor was put through\nits paces on the knee, elbow, and wrist of a female test subject. Also, to\nevaluate the pressure functionality of the sensor, a fully 3D active foot\ninsole was developed, fabricated, and evaluated. All of the results show\npromising features for the proposed sensor to be used in real-world\napplications like rehabilitation, wearable devices, soft robotics, smart\nclothing, gait analysis, AR/VR, etc.",
    "descriptor": "",
    "authors": [
      "Mohsen Annabestani",
      "Pouria Esmaili-Dokht",
      "Seyyed Ali Olianasab",
      "Nooshin Orouji",
      "Zeinab Alipour",
      "Mohammad Hossein Sayad",
      "Kimia Rajabi",
      "Barbara Mazzolai",
      "Mehdi Fardmanesh"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Robotics (cs.RO)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.06975"
  },
  {
    "id": "arXiv:2106.06980",
    "title": "An Approach Towards Physics Informed Lung Ultrasound Image Scoring  Neural Network for Diagnostic Assistance in COVID-19",
    "abstract": "Ultrasound is fast becoming an inevitable diagnostic tool for regular and\ncontinuous monitoring of the lung with the recent outbreak of COVID-19. In this\nwork, a novel approach is presented to extract acoustic propagation-based\nfeatures to automatically highlight the region below pleura, which is an\nimportant landmark in lung ultrasound (LUS). Subsequently, a multichannel input\nformed by using the acoustic physics-based feature maps is fused to train a\nneural network, referred to as LUSNet, to classify the LUS images into five\nclasses of varying severity of lung infection to track the progression of\nCOVID-19. In order to ensure that the proposed approach is agnostic to the type\nof acquisition, the LUSNet, which consists of a U-net architecture is trained\nin an unsupervised manner with the acoustic feature maps to ensure that the\nencoder-decoder architecture is learning features in the pleural region of\ninterest. A novel combination of the U-net output and the U-net encoder output\nis employed for the classification of severity of infection in the lung. A\ndetailed analysis of the proposed approach on LUS images over the infection to\nfull recovery period of ten confirmed COVID-19 subjects shows an average\nfive-fold cross-validation accuracy, sensitivity, and specificity of 97%, 93%,\nand 98% respectively over 5000 frames of COVID-19 videos. The analysis also\nshows that, when the input dataset is limited and diverse as in the case of\nCOVID-19 pandemic, an aided effort of combining acoustic propagation-based\nfeatures along with the gray scale images, as proposed in this work, improves\nthe performance of the neural network significantly and also aids the labelling\nand triaging process.",
    "descriptor": "\nComments: 8 pages, 8 figures, 3 tables, submitted to Springer SIVP Special Issue for COVID19\n",
    "authors": [
      "Mahesh Raveendranatha Panicker",
      "Yale Tung Chen",
      "Gayathri M",
      "Madhavanunni A N",
      "Kiran Vishnu Narayan",
      "C Kesavadas",
      "A P Vinod"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06980"
  },
  {
    "id": "arXiv:2106.06987",
    "title": "Learning the Imaging Landmarks: Unsupervised Key point Detection in Lung  Ultrasound Videos",
    "abstract": "Lung ultrasound (LUS) is an increasingly popular diagnostic imaging modality\nfor continuous and periodic monitoring of lung infection, given its advantages\nof non-invasiveness, non-ionizing nature, portability and easy disinfection.\nThe major landmarks assessed by clinicians for triaging using LUS are pleura, A\nand B lines. There have been many efforts for the automatic detection of these\nlandmarks. However, restricting to a few pre-defined landmarks may not reveal\nthe actual imaging biomarkers particularly in case of new pathologies like\nCOVID-19. Rather, the identification of key landmarks should be driven by data\ngiven the availability of a plethora of neural network algorithms. This work is\na first of its kind attempt towards unsupervised detection of the key LUS\nlandmarks in LUS videos of COVID-19 subjects during various stages of\ninfection. We adapted the relatively newer approach of transporter neural\nnetworks to automatically mark and track pleura, A and B lines based on their\nperiodic motion and relatively stable appearance in the videos. Initial results\non unsupervised pleura detection show an accuracy of 91.8% employing 1081 LUS\nvideo frames.",
    "descriptor": "\nComments: 5 pages, 6 figures, submitted to IEEE EMBC 2021\n",
    "authors": [
      "Arpan Tripathi",
      "Mahesh Raveendranatha Panicker",
      "Abhilash R Hareendranathan",
      "Yale Tung Chen",
      "Jacob L Jaremko",
      "Kiran Vishnu Narayan",
      "Kesavadas C"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06987"
  },
  {
    "id": "arXiv:2106.06999",
    "title": "A Dataset of Dynamic Reverberant Sound Scenes with Directional  Interferers for Sound Event Localization and Detection",
    "abstract": "This report presents the dataset and baseline of Task 3 of the DCASE2021\nChallenge on Sound Event Localization and Detection (SELD). The dataset is\nbased on emulation of real recordings of static or moving sound events under\nreal conditions of reverberation and ambient noise, using spatial room impulse\nresponses captured in a variety of rooms and delivered in two spatial formats.\nThe acoustical synthesis remains the same as in the previous iteration of the\nchallenge, however the new dataset brings more challenging conditions of\npolyphony and overlapping instances of the same class. The most important\ndifference of the new dataset is the introduction of directional interferers,\nmeaning sound events that are localized in space but do not belong to the\ntarget classes to be detected and are not annotated. Since such interfering\nevents are expected in every real-world scenario of SELD, the new dataset aims\nto promote systems that deal with this condition effectively. A modified\nSELDnet baseline employing the recent ACCDOA representation for SELD problems\naccompanies the dataset and is described herein. To investigate the individual\nand combined effects of ambient noise, interferers, and reverberation, we study\nthe performance of the baseline on different versions of the dataset excluding\nor including combinations of these factors. The results indicate that by far\nthe most detrimental effects are caused by directional interferers.",
    "descriptor": "",
    "authors": [
      "Archontis Politis",
      "Sharath Adavanne",
      "Daniel Krause",
      "Antoine Deleforge",
      "Prerak Srivastava",
      "Tuomas Virtanen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.06999"
  },
  {
    "id": "arXiv:2106.07016",
    "title": "WASE: Learning When to Attend for Speaker Extraction in Cocktail Party  Environments",
    "abstract": "In the speaker extraction problem, it is found that additional information\nfrom the target speaker contributes to the tracking and extraction of the\ntarget speaker, which includes voiceprint, lip movement, facial expression, and\nspatial information. However, no one cares for the cue of sound onset, which\nhas been emphasized in the auditory scene analysis and psychology. Inspired by\nit, we explicitly modeled the onset cue and verified the effectiveness in the\nspeaker extraction task. We further extended to the onset/offset cues and got\nperformance improvement. From the perspective of tasks, our onset/offset-based\nmodel completes the composite task, a complementary combination of speaker\nextraction and speaker-dependent voice activity detection. We also combined\nvoiceprint with onset/offset cues. Voiceprint models voice characteristics of\nthe target while onset/offset models the start/end information of the speech.\nFrom the perspective of auditory scene analysis, the combination of two\nperception cues can promote the integrity of the auditory object. The\nexperiment results are also close to state-of-the-art performance, using nearly\nhalf of the parameters. We hope that this work will inspire communities of\nspeech processing and psychology, and contribute to communication between them.\nOur code will be available in https://github.com/aispeech-lab/wase/.",
    "descriptor": "\nComments: Accepted by ICASSP 2021\n",
    "authors": [
      "Yunzhe Hao",
      "Jiaming Xu",
      "Peng Zhang",
      "Bo Xu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.07016"
  },
  {
    "id": "arXiv:2106.07044",
    "title": "Optimal detection of the feature matching map in presence of noise and  outliers",
    "abstract": "We consider the problem of finding the matching map between two sets of $d$\ndimensional vectors from noisy observations, where the second set contains\noutliers. The matching map is then an injection, which can be consistently\nestimated only if the vectors of the second set are well separated. The main\nresult shows that, in the high-dimensional setting, a detection region of\nunknown injection can be characterized by the sets of vectors for which the\ninlier-inlier distance is of order at least $d^{1/4}$ and the inlier-outlier\ndistance is of order at least $d^{1/2}$. These rates are achieved using the\nestimated matching minimizing the sum of logarithms of distances between\nmatched pairs of points. We also prove lower bounds establishing optimality of\nthese rates. Finally, we report results of numerical experiments on both\nsynthetic and real world data that illustrate our theoretical results and\nprovide further insight into the properties of the estimators studied in this\nwork.",
    "descriptor": "",
    "authors": [
      "Tigran Galstyan",
      "Arshak Minasyan",
      "Arnak Dalalyan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07044"
  },
  {
    "id": "arXiv:2106.07066",
    "title": "Enhanced Hyperspectral Image Super-Resolution via RGB Fusion and TV-TV  Minimization",
    "abstract": "Hyperspectral (HS) images contain detailed spectral information that has\nproven crucial in applications like remote sensing, surveillance, and\nastronomy. However, because of hardware limitations of HS cameras, the captured\nimages have low spatial resolution. To improve them, the low-resolution\nhyperspectral images are fused with conventional high-resolution RGB images via\na technique known as fusion based HS image super-resolution. Currently, the\nbest performance in this task is achieved by deep learning (DL) methods. Such\nmethods, however, cannot guarantee that the input measurements are satisfied in\nthe recovered image, since the learned parameters by the network are applied to\nevery test image. Conversely, model-based algorithms can typically guarantee\nsuch measurement consistency. Inspired by these observations, we propose a\nframework that integrates learning and model based methods. Experimental\nresults show that our method produces images of superior spatial and spectral\nresolution compared to the current leading methods, whether model- or DL-based.",
    "descriptor": "\nComments: Accepted to ICIP 2021\n",
    "authors": [
      "Marija Vella",
      "Bowen Zhang",
      "Wei Chen",
      "Jo\u00e3o F. C. Mota"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.07066"
  },
  {
    "id": "arXiv:2106.07071",
    "title": "Risk Assessment of Stealthy Attacks on Uncertain Control Systems",
    "abstract": "In this article, we address the problem of risk assessment of stealthy\nattacks on uncertain control systems. Considering data injection attacks that\naim at maximizing impact while remaining undetected, we use the recently\nproposed output-to-output gain to characterize the risk associated with the\nimpact of attacks in two setups: A full system knowledge attacker and a limited\nsystem knowledge attacker. The risk in each setup is formulated using a\nwell-established risk metric, namely the Value-at-Risk and the maximum expected\nloss, respectively. Under these setups, the risk assessment problem corresponds\nto an untractable infinite non-convex optimization problem. To address this\nlimitation, we adopt the framework of scenario-based optimization to\napproximate the infinite non-convex optimization problem by a sampled\nnon-convex optimization problem. Then, based on the framework of dissipative\nsystem theory and S-procedure, the sampled non-convex risk assessment problem\nis formulated as an equivalent convex semi-definite program. Additionally, we\nderive the necessary and sufficient conditions for the risk to be bounded.\nFinally, we illustrate the results through numerical simulation of a\nhydro-turbine power system.",
    "descriptor": "",
    "authors": [
      "Sribalaji C. Anand",
      "Andr\u00e9 M. H. Teixeira",
      "Anders Ahl\u00e9n"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07071"
  },
  {
    "id": "arXiv:2106.07072",
    "title": "On rainbow-free colourings of uniform hypergraphs",
    "abstract": "We study rainbow-free colourings of $k$-uniform hypergraphs; that is,\ncolourings that use $k$ colours but with the property that no hyperedge attains\nall colours. We show that $p^*=(k-1)(\\ln n)/n$ is the threshold function for\nthe existence of a rainbow-free colouring in a random $k$-uniform hypergraph.",
    "descriptor": "",
    "authors": [
      "Ragnar Groot Koerkamp",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.07072"
  },
  {
    "id": "arXiv:2106.07079",
    "title": "Decentralized Inertial Best-Response with Voluntary and Limited  Communication in Random Communication Networks",
    "abstract": "Multiple autonomous agents interact over a random communication network to\nmaximize their individual utility functions which depend on the actions of\nother agents. We consider decentralized best-response with inertia type\nalgorithms in which agents form beliefs about the future actions of other\nplayers based on local information, and take an action that maximizes their\nexpected utility computed with respect to these beliefs or continue to take\ntheir previous action. We show convergence of these types of algorithms to a\nNash equilibrium in weakly acyclic games under the condition that the belief\nupdate and information exchange protocols successfully learn the actions of\nother players with positive probability in finite time given a static\nenvironment, i.e., when other agents' actions do not change. We design a\ndecentralized fictitious play algorithm with voluntary and limited\ncommunication (DFP-VL) protocols that satisfy this condition. In the voluntary\ncommunication protocol, each agent decides whom to exchange information with by\nassessing the novelty of its information and the potential effect of its\ninformation on others' assessments of their utility functions. The limited\ncommunication protocol entails agents sending only their most frequent action\nto agents that they decide to communicate with. Numerical experiments on a\ntarget assignment game demonstrate that the voluntary and limited communication\nprotocol can more than halve the number of communication attempts while\nretaining the same convergence rate as DFP in which agents constantly attempt\nto communicate.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Sarper Ayd\u0131n",
      "Ceyhun Eksin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07079"
  },
  {
    "id": "arXiv:2106.07103",
    "title": "A News-based Machine Learning Model for Adaptive Asset Pricing",
    "abstract": "The paper proposes a new asset pricing model -- the News Embedding UMAP\nSelection (NEUS) model, to explain and predict the stock returns based on the\nfinancial news. Using a combination of various machine learning algorithms, we\nfirst derive a company embedding vector for each basis asset from the financial\nnews. Then we obtain a collection of the basis assets based on their company\nembedding. After that for each stock, we select the basis assets to explain and\npredict the stock return with high-dimensional statistical methods. The new\nmodel is shown to have a significantly better fitting and prediction power than\nthe Fama-French 5-factor model.",
    "descriptor": "",
    "authors": [
      "Liao Zhu",
      "Haoxuan Wu",
      "Martin T. Wells"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07103"
  },
  {
    "id": "arXiv:2106.07138",
    "title": "Self-Supervised Metric Learning in Multi-View Data: A Downstream Task  Perspective",
    "abstract": "Self-supervised metric learning has been a successful approach for learning a\ndistance from an unlabeled dataset. The resulting distance is broadly useful\nfor improving various distance-based downstream tasks, even when no information\nfrom downstream tasks is utilized in the metric learning stage. To gain\ninsights into this approach, we develop a statistical framework to\ntheoretically study how self-supervised metric learning can benefit downstream\ntasks in the context of multi-view data. Under this framework, we show that the\ntarget distance of metric learning satisfies several desired properties for the\ndownstream tasks. On the other hand, our investigation suggests the target\ndistance can be further improved by moderating each direction's weights. In\naddition, our analysis precisely characterizes the improvement by\nself-supervised metric learning on four commonly used downstream tasks: sample\nidentification, two-sample testing, $k$-means clustering, and $k$-nearest\nneighbor classification. As a by-product, we propose a simple spectral method\nfor self-supervised metric learning, which is computationally efficient and\nminimax optimal for estimating target distance. Finally, numerical experiments\nare presented to support the theoretical results in the paper.",
    "descriptor": "",
    "authors": [
      "Shulei Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.07138"
  },
  {
    "id": "arXiv:2106.07144",
    "title": "Few-shot learning of new sound classes for target sound extraction",
    "abstract": "Target sound extraction consists of extracting the sound of a target acoustic\nevent (AE) class from a mixture of AE sounds. It can be realized using a neural\nnetwork that extracts the target sound conditioned on a 1-hot vector that\nrepresents the desired AE class. With this approach, embedding vectors\nassociated with the AE classes are directly optimized for the extraction of\nsound classes seen during training. However, it is not easy to extend this\nframework to new AE classes, i.e. unseen during training. Recently, speech,\nmusic, or AE sound extraction based on enrollment audio of the desired sound\noffers the potential of extracting any target sound in a mixture given only a\nshort audio signal of a similar sound. In this work, we propose combining\n1-hot- and enrollment-based target sound extraction, allowing optimal\nperformance for seen AE classes and simple extension to new classes. In\nexperiments with synthesized sound mixtures generated with the Freesound\nDataset (FSD) datasets, we demonstrate the benefit of the combined framework\nfor both seen and new AE classes. Besides, we also propose adapting the\nembedding vectors obtained from a few enrollment audio samples (few-shot) to\nfurther improve performance on new classes.",
    "descriptor": "\nComments: To appear in Interspeech 2021\n",
    "authors": [
      "Marc Delcroix",
      "Jorge Bennasar V\u00e1zquez",
      "Tsubasa Ochiai",
      "Keisuke Kinoshita",
      "Shoko Araki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.07144"
  },
  {
    "id": "arXiv:2106.07148",
    "title": "On the Sample Complexity of Learning with Geometric Stability",
    "abstract": "Many supervised learning problems involve high-dimensional data such as\nimages, text, or graphs. In order to make efficient use of data, it is often\nuseful to leverage certain geometric priors in the problem at hand, such as\ninvariance to translations, permutation subgroups, or stability to small\ndeformations. We study the sample complexity of learning problems where the\ntarget function presents such invariance and stability properties, by\nconsidering spherical harmonic decompositions of such functions on the sphere.\nWe provide non-parametric rates of convergence for kernel methods, and show\nimprovements in sample complexity by a factor equal to the size of the group\nwhen using an invariant kernel over the group, compared to the corresponding\nnon-invariant kernel. These improvements are valid when the sample size is\nlarge enough, with an asymptotic behavior that depends on spectral properties\nof the group. Finally, these gains are extended beyond invariance groups to\nalso cover geometric stability to small deformations, modeled here as subsets\n(not necessarily subgroups) of permutations.",
    "descriptor": "",
    "authors": [
      "Alberto Bietti",
      "Luca Venturi",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07148"
  },
  {
    "id": "arXiv:2106.07163",
    "title": "State-dependent Riccati equation feedback stabilization for nonlinear  PDEs",
    "abstract": "The synthesis of suboptimal feedback laws for controlling nonlinear dynamics\narising from semi-discretized PDEs is studied. An approach based on the\nState-dependent Riccati Equation (SDRE) is presented for H2 and Hinf control\nproblems. Depending on the nonlinearity and the dimension of the resulting\nproblem, offline, online, and hybrid offline-online alternatives to the SDRE\nsynthesis are proposed. The hybrid offline-online SDRE method reduces to the\nsequential solution of Lyapunov equations, effectively enabling the computation\nof suboptimal feedback controls for two-dimensional PDEs. Numerical tests for\nthe Sine-Gordon, degenerate Zeldovich, and viscous Burgers' PDEs are presented,\nproviding a thorough experimental assessment of the proposed methodology.",
    "descriptor": "",
    "authors": [
      "Alessandro Alla",
      "Dante Kalise",
      "Valeria Simoncini"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07163"
  },
  {
    "id": "arXiv:2106.07199",
    "title": "Design and Experimental Assessment of Detection Schemes for Air  Interface Attacks in Adverse Scenarios",
    "abstract": "In this letter, we propose three schemes designed to detect attacks over the\nair interface in cellular networks. These decision rules rely on the\ngeneralized likelihood ratio test, and are fed by data that can be acquired\nusing common off-the-shelf receivers. In addition to more classical\n(barrage/smart) noise jamming attacks, we further assess the capability of the\nproposed schemes to detect the stealthy activation of a rogue base station. The\nevaluation is carried out through an experimentation of a LTE system concretely\nreproduced using Software-Defined Radios. Illustrative examples confirm that\nthe proposed schemes can effectively detect air interface threats with high\nprobability.",
    "descriptor": "",
    "authors": [
      "Danilo Orlando",
      "Ivan Palam\u00e0",
      "Stefania Bartoletti",
      "Giuseppe Bianchi",
      "Nicola Blefari Melazzi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.07199"
  },
  {
    "id": "arXiv:2106.07202",
    "title": "Optimal transport in multilayer networks",
    "abstract": "Modeling traffic distribution and extracting optimal flows in multilayer\nnetworks is of utmost importance to design efficient multi-modal network\ninfrastructures. Recent results based on optimal transport theory provide\npowerful and computationally efficient methods to address this problem, but\nthey are mainly focused on modeling single-layer networks. Here we adapt these\nresults to study how optimal flows distribute on multilayer networks. We\npropose a model where optimal flows on different layers contribute differently\nto the total cost to be minimized. This is done by means of a parameter that\nvaries with layers, which allows to flexibly tune the sensitivity to traffic\ncongestion of the various layers. As an application, we consider transportation\nnetworks, where each layer is associated to a different transportation system\nand show how the traffic distribution varies as we tune this parameter across\nlayers. We show an example of this result on the real 2-layer network of the\ncity of Bordeaux with bus and tram, where we find that in certain regimes the\npresence of the tram network significantly unburdens the traffic on the road\nnetwork. Our model paves the way to further analysis of optimal flows and\nnavigability strategies in real multilayer networks.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Abdullahi Adinoyi Ibrahim",
      "Alessandro Lonardi",
      "Caterina De Bacco"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.07202"
  },
  {
    "id": "arXiv:2106.07243",
    "title": "Compressed Gradient Tracking for Decentralized Optimization Over General  Directed Networks",
    "abstract": "In this paper, we propose two communication-efficient algorithms for\ndecentralized optimization over a multi-agent network with general directed\nnetwork topology. In the first part, we consider a novel\ncommunication-efficient gradient tracking based method, termed Compressed\nPush-Pull (CPP), which combines the Push-Pull method with communication\ncompression. We show that CPP is applicable to a general class of unbiased\ncompression operators and achieves linear convergence for strongly convex and\nsmooth objective functions. In the second part, we propose a broadcast-like\nversion of CPP (B-CPP), which also achieves linear convergence rate under the\nsame conditions for the objective functions. B-CPP can be applied in an\nasynchronous broadcast setting and further reduce communication costs compared\nto CPP. Numerical experiments complement the theoretical analysis and confirm\nthe effectiveness of the proposed methods.",
    "descriptor": "\nComments: working paper\n",
    "authors": [
      "Zhuoqing Song",
      "Lei Shi",
      "Shi Pu",
      "Ming Yan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.07243"
  },
  {
    "id": "arXiv:2106.07262",
    "title": "Spatial spread of COVID-19 outbreak in Italy using multiscale kinetic  transport equations with uncertainty",
    "abstract": "In this paper we introduce a space-dependent multiscale model to describe the\nspatial spread of an infectious disease under uncertain data with particular\ninterest in simulating the onset of the COVID-19 epidemic in Italy. While virus\ntransmission is ruled by a SEIAR type compartmental model, within our approach\nthe population is given by a sum of commuters moving on a extra-urban scale and\nnon commuters interacting only on the smaller urban scale. A transport dynamic\nof the commuter population at large spatial scales, based on kinetic equations,\nis coupled with a diffusion model for non commuters at the urban scale. Thanks\nto a suitable scaling limit, the kinetic transport model used to describe the\ndynamics of commuters, within a given urban area coincides with the diffusion\nequations that characterize the movement of non-commuting individuals. Because\nof the high uncertainty in the data reported in the early phase of the\nepidemic, the presence of random inputs in both the initial data and the\nepidemic parameters is included in the model. A robust numerical method is\ndesigned to deal with the presence of multiple scales and the uncertainty\nquantification process. In our simulations, we considered a realistic\ngeographical domain, describing the Lombardy region, in which the size of the\ncities, the number of infected individuals, the average number of daily\ncommuters moving from one city to another, and the epidemic aspects are taken\ninto account through a calibration of the model parameters based on the actual\navailable data. The results show that the model is able to describe correctly\nthe main features of the spatial expansion of the first wave of COVID-19 in\nnorthern Italy.",
    "descriptor": "",
    "authors": [
      "Giulia Bertaglia",
      "Walter Boscheri",
      "Giacomo Dimarco",
      "Lorenzo Pareschi"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Numerical Analysis (math.NA)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.07262"
  },
  {
    "id": "arXiv:2106.07263",
    "title": "Machine Learning for Variance Reduction in Online Experiments",
    "abstract": "We consider the problem of variance reduction in randomized controlled\ntrials, through the use of covariates correlated with the outcome but\nindependent of the treatment. We propose a machine learning regression-adjusted\ntreatment effect estimator, which we call MLRATE. MLRATE uses machine learning\npredictors of the outcome to reduce estimator variance. It employs\ncross-fitting to avoid overfitting biases, and we prove consistency and\nasymptotic normality under general conditions. MLRATE is robust to poor\npredictions from the machine learning step: if the predictions are uncorrelated\nwith the outcomes, the estimator performs asymptotically no worse than the\nstandard difference-in-means estimator, while if predictions are highly\ncorrelated with outcomes, the efficiency gains are large. In A/A tests, for a\nset of 48 outcome metrics commonly monitored in Facebook experiments the\nestimator has over 70\\% lower variance than the simple difference-in-means\nestimator, and about 19\\% lower variance than the common univariate procedure\nwhich adjusts only for pre-experiment values of the outcome.",
    "descriptor": "",
    "authors": [
      "Yongyi Guo",
      "Dominic Coey",
      "Mikael Konutgan",
      "Wenting Li",
      "Chris Schoener",
      "Matt Goldman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07263"
  },
  {
    "id": "arXiv:2106.07291",
    "title": "A Multi Polarization Square Patch Antenna with a Reconfigurable Feeding  Network",
    "abstract": "A multi-polarization square patch antenna with a reconfigurable feeding\nnetwork is presented in this paper. The reconfigurable feeding network of this\nantenna is implemented on an FR-4 substrate by a Wilkinson power divider and a\nbranch line coupler which perform amplitude distribution in the feeding\nnetwork. Besides, two switching circuits which consist of one PIN diode\n(BAR63-02w) and its DC biasing circuit manage the RF signal flow on this\nfeeding network. These switching circuits control the phase of the RF signal\napplied to the square patch, so it can provide linear polarization, left-hand\nand right-hand circular polarization at 2.45 GHz which has many applications in\nwireless networks. The simulated and measured results are presented which\nilluminate acceptable axial ratio bandwidth (ARBW) for both right-hand and\nleft-hand circular polarization in (2.38-2.48 GHz) and minimum -10 dB return\nloss at 2.45 GHz.",
    "descriptor": "",
    "authors": [
      "Roozbeh Rezaeipour",
      "Ramezanali Sadeghzadeh"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07291"
  },
  {
    "id": "arXiv:2106.07292",
    "title": "Topology identifies emerging adaptive mutations in SARS-CoV-2",
    "abstract": "The COVID-19 pandemic has lead to a worldwide effort to characterize its\nevolution through the mapping of mutations in the genome of the coronavirus\nSARS-CoV-2. Ideally, one would like to quickly identify new mutations that\ncould confer adaptive advantages (e.g. higher infectivity or immune evasion) by\nleveraging the large number of genomes. One way of identifying adaptive\nmutations is by looking at convergent mutations, mutations in the same genomic\nposition that occur independently. However, the large number of currently\navailable genomes precludes the efficient use of phylogeny-based techniques.\nHere, we establish a fast and scalable Topological Data Analysis approach for\nthe early warning and surveillance of emerging adaptive mutations based on\npersistent homology. It identifies convergent events merely by their\ntopological footprint and thus overcomes limitations of current phylogenetic\ninference techniques. This allows for an unbiased and rapid analysis of large\nviral datasets. We introduce a new topological measure for convergent evolution\nand apply it to the GISAID dataset as of February 2021, comprising 303,651\nhigh-quality SARS-CoV-2 isolates collected since the beginning of the pandemic.\nWe find that topologically salient mutations on the receptor-binding domain\nappear in several variants of concern and are linked with an increase in\ninfectivity and immune escape, and for many adaptive mutations the topological\nsignal precedes an increase in prevalence. We show that our method effectively\nidentifies emerging adaptive mutations at an early stage. By localizing\ntopological signals in the dataset, we extract geo-temporal information about\nthe early occurrence of emerging adaptive mutations. The identification of\nthese mutations can help to develop an alert system to monitor mutations of\nconcern and guide experimentalists to focus the study of specific circulating\nvariants.",
    "descriptor": "",
    "authors": [
      "Michael Bleher",
      "Lukas Hahn",
      "Juan Angel Patino-Galindo",
      "Mathieu Carriere",
      "Ulrich Bauer",
      "Raul Rabadan",
      "Andreas Ott"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Computational Geometry (cs.CG)",
      "Genomics (q-bio.GN)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2106.07292"
  },
  {
    "id": "arXiv:2106.07302",
    "title": "Quantum diffusion map for nonlinear dimensionality reduction",
    "abstract": "Inspired by random walk on graphs, diffusion map (DM) is a class of\nunsupervised machine learning that offers automatic identification of\nlow-dimensional data structure hidden in a high-dimensional dataset. In recent\nyears, among its many applications, DM has been successfully applied to\ndiscover relevant order parameters in many-body systems, enabling automatic\nclassification of quantum phases of matter. However, classical DM algorithm is\ncomputationally prohibitive for a large dataset, and any reduction of the time\ncomplexity would be desirable. With a quantum computational speedup in mind, we\npropose a quantum algorithm for DM, termed quantum diffusion map (qDM). Our qDM\ntakes as an input N classical data vectors, performs an eigen-decomposition of\nthe Markov transition matrix in time $O(\\log^3 N)$, and classically constructs\nthe diffusion map via the readout (tomography) of the eigenvectors, giving a\ntotal runtime of $O(N^2 \\text{polylog}\\, N)$. Lastly, quantum subroutines in\nqDM for constructing a Markov transition operator, and for analyzing its\nspectral properties can also be useful for other random walk-based algorithms.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Apimuk Sornsaeng",
      "Ninnat Dangniam",
      "Pantita Palittapongarnpim",
      "Thiparat Chotibut"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07302"
  },
  {
    "id": "arXiv:2106.07323",
    "title": "Gridless Evolutionary Approach for Line Spectral Estimation with Unknown  Model Order",
    "abstract": "Gridless methods show great superiority in line spectral estimation. These\nmethods need to solve an atomic $l_0$ norm (i.e., the continuous analog of\n$l_0$ norm) minimization problem to estimate frequencies and model order. Since\nthis problem is NP-hard to compute, relaxations of atomic $l_0$ norm, such as\nnuclear norm and reweighted atomic norm, have been employed for promoting\nsparsity. However, the relaxations give rise to a resolution limit,\nsubsequently leading to biased model order and convergence error. To overcome\nthe above shortcomings of relaxation, we propose a novel idea of simultaneously\nestimating the frequencies and model order by means of the atomic $l_0$ norm.\nTo accomplish this idea, we build a multiobjective optimization model. The\nmeasurment error and the atomic $l_0$ norm are taken as the two optimization\nobjectives. The proposed model directly exploits the model order via the atomic\n$l_0$ norm, thus breaking the resolution limit. We further design a\nvariable-length evolutionary algorithm to solve the proposed model, which\nincludes two innovations. One is a variable-length coding and search strategy.\nIt flexibly codes and interactively searches diverse solutions with different\nmodel orders. These solutions act as steppingstones that help fully exploring\nthe variable and open-ended frequency search space and provide extensive\npotentials towards the optima. Another innovation is a model order pruning\nmechanism, which heuristically prunes less contributive frequencies within the\nsolutions, thus significantly enhancing convergence and diversity. Simulation\nresults confirm the superiority of our approach in both frequency estimation\nand model order selection.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Bai Yan",
      "Qi Zhao",
      "Jin Zhang",
      "J. Andrew Zhang",
      "Xin Yao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.07323"
  },
  {
    "id": "arXiv:2106.07355",
    "title": "Predicting the imagined contents using brain activation",
    "abstract": "Mental imagery refers to percept-like experiences in the absence of sensory\ninput. Brain imaging studies suggest common, modality-specific, neural\ncorrelates imagery and perception. We associated abstract visual stimuli with\neither visually presented or imagined monetary rewards and scrambled pictures.\nBrain images for a group of 12 participants were collected using functional\nmagnetic resonance imaging. Statistical analysis showed that human midbrain\nregions were activated irrespective of the monetary rewards being imagined or\nvisually present. A support vector machine trained on the midbrain activation\npatterns to the visually presented rewards predicted with 75% accuracy whether\nthe participants imagined the monetary reward or the scrambled picture during\nimagination trials. Training samples were drawn from visually presented trials\nand classification accuracy was assessed for imagination trials. These results\nsuggest the use of machine learning technique for classification of underlying\ncognitive states from brain imaging data.",
    "descriptor": "\nComments: Published In 2013 Fourth National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG) (pp. 1-3)\n",
    "authors": [
      "Krishna Prasad Miyapuram",
      "Wolfram Schultz",
      "Philippe N. Tobler"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07355"
  },
  {
    "id": "arXiv:2106.07358",
    "title": "Credit spread approximation and improvement using random forest  regression",
    "abstract": "Credit Default Swap (CDS) levels provide a market appreciation of companies'\ndefault risk. These derivatives are not always available, creating a need for\nCDS approximations. This paper offers a simple, global and transparent CDS\nstructural approximation, which contrasts with more complex and proprietary\napproximations currently in use. This Equity-to-Credit formula (E2C), inspired\nby CreditGrades, obtains better CDS approximations, according to empirical\nanalyses based on a large sample spanning 2016-2018. A random forest regression\nrun with this E2C formula and selected additional financial data results in an\n87.3% out-of-sample accuracy in CDS approximations. The transparency property\nof this algorithm confirms the predominance of the E2C estimate, and the impact\nof companies' debt rating and size, in predicting their CDS.",
    "descriptor": "",
    "authors": [
      "Mathieu Mercadier",
      "Jean-Pierre Lardy"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Pricing of Securities (q-fin.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.07358"
  },
  {
    "id": "arXiv:2106.07361",
    "title": "Probabilistic Forecasting of Imbalance Prices in the Belgian Context",
    "abstract": "Forecasting imbalance prices is essential for strategic participation in the\nshort-term energy markets. A novel two-step probabilistic approach is proposed,\nwith a particular focus on the Belgian case. The first step consists of\ncomputing the net regulation volume state transition probabilities. It is\nmodeled as a matrix computed using historical data. This matrix is then used to\ninfer the imbalance prices since the net regulation volume can be related to\nthe level of reserves activated and the corresponding marginal prices for each\nactivation level are published by the Belgian Transmission System Operator one\nday before electricity delivery. This approach is compared to a deterministic\nmodel, a multi-layer perceptron, and a widely used probabilistic technique,\nGaussian Processes.",
    "descriptor": "",
    "authors": [
      "Jonathan Dumas",
      "Ioannis Boukas",
      "Miguel Manuel de Villena",
      "S\u00e9bastien Mathieu",
      "Bertrand Corn\u00e9lusse"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.07361"
  },
  {
    "id": "arXiv:2106.07379",
    "title": "Recurrent Inference Machines as inverse problem solvers for MR  relaxometry",
    "abstract": "In this paper, we propose the use of Recurrent Inference Machines (RIMs) to\nperform T1 and T2 mapping. The RIM is a neural network framework that learns an\niterative inference process based on the signal model, similar to conventional\nstatistical methods for quantitative MRI (QMRI), such as the Maximum Likelihood\nEstimator (MLE). This framework combines the advantages of both data-driven and\nmodel-based methods, and, we hypothesize, is a promising tool for QMRI.\nPreviously, RIMs were used to solve linear inverse reconstruction problems.\nHere, we show that they can also be used to optimize non-linear problems and\nestimate relaxometry maps with high precision and accuracy. The developed RIM\nframework is evaluated in terms of accuracy and precision and compared to an\nMLE method and an implementation of the ResNet. The results show that the RIM\nimproves the quality of estimates compared to the other techniques in Monte\nCarlo experiments with simulated data, test-retest analysis of a system\nphantom, and in-vivo scans. Additionally, inference with the RIM is 150 times\nfaster than the MLE, and robustness to (slight) variations of scanning\nparameters is demonstrated. Hence, the RIM is a promising and flexible method\nfor QMRI. Coupled with an open-source training data generation tool, it\npresents a compelling alternative to previous methods.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "E. R. Sabidussi",
      "S. Klein",
      "M. W. A. Caan",
      "S. Bazrafkan",
      "A. J. den Dekker",
      "J. Sijbers",
      "W. J. Niessen",
      "D. H. J. Poot"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07379"
  },
  {
    "id": "arXiv:2106.07382",
    "title": "Simulation of viscoelastic Cosserat rods based on the geometrically  exact dynamics of special Euclidean strands",
    "abstract": "We propose a method for the description and simulation of the nonlinear\ndynamics of slender structures modeled as Cosserat rods. It is based on\ninterpreting the strains and the generalized velocities of the cross sections\nas basic variables and elements of the special Euclidean algebra. This\nperspective emerges naturally from the evolution equations for strands, that\nare one-dimensional submanifolds, of the special Euclidean group. The\ndiscretization of the corresponding equations for the three-dimensional motion\nof a Cosserat rod is performed, in space, by using a staggered grid. The time\nevolution is then approximated with a semi-implicit method. Within this\napproach we can easily include dissipative effects due to both the action of\nexternal forces and the presence of internal mechanical dissipation. The\ncomparison with results obtained with different schemes shows the effectiveness\nof the proposed method, which is able to provide very good predictions of\nnonlinear dynamical effects and shows competitive computation times also as an\nenergy-minimizing method to treat static problems.",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "G. G. Giusteri",
      "E. Miglio",
      "N. Parolini",
      "M. Penati",
      "R. Zambetti"
    ],
    "subjectives": [
      "Classical Physics (physics.class-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07382"
  },
  {
    "id": "arXiv:2106.07393",
    "title": "Cross-replication Reliability -- An Empirical Approach to Interpreting  Inter-rater Reliability",
    "abstract": "We present a new approach to interpreting IRR that is empirical and\ncontextualized. It is based upon benchmarking IRR against baseline measures in\na replication, one of which is a novel cross-replication reliability (xRR)\nmeasure based on Cohen's kappa. We call this approach the xRR framework. We\nopensource a replication dataset of 4 million human judgements of facial\nexpressions and analyze it with the proposed framework. We argue this framework\ncan be used to measure the quality of crowdsourced datasets.",
    "descriptor": "",
    "authors": [
      "Ka Wong",
      "Praveen Paritosh",
      "Lora Aroyo"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.07393"
  },
  {
    "id": "arXiv:2106.07452",
    "title": "Marginalising over Stationary Kernels with Bayesian Quadrature",
    "abstract": "Marginalising over families of Gaussian Process kernels produces flexible\nmodel classes with well-calibrated uncertainty estimates. Existing approaches\nrequire likelihood evaluations of many kernels, rendering them prohibitively\nexpensive for larger datasets. We propose a Bayesian Quadrature scheme to make\nthis marginalisation more efficient and thereby more practical. Through use of\nthe maximum mean discrepancies between distributions, we define a kernel over\nkernels that captures invariances between Spectral Mixture (SM) Kernels. Kernel\nsamples are selected by generalising an information-theoretic acquisition\nfunction for warped Bayesian Quadrature. We show that our framework achieves\nmore accurate predictions with better calibrated uncertainty than\nstate-of-the-art baselines, especially when given limited (wall-clock) time\nbudgets.",
    "descriptor": "",
    "authors": [
      "Saad Hamid",
      "Sebastian Schulze",
      "Michael A. Osborne",
      "Stephen J. Roberts"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07452"
  },
  {
    "id": "arXiv:2106.07454",
    "title": "NG+ : A Multi-Step Matrix-Product Natural Gradient Method for Deep  Learning",
    "abstract": "In this paper, a novel second-order method called NG+ is proposed. By\nfollowing the rule ``the shape of the gradient equals the shape of the\nparameter\", we define a generalized fisher information matrix (GFIM) using the\nproducts of gradients in the matrix form rather than the traditional\nvectorization. Then, our generalized natural gradient direction is simply the\ninverse of the GFIM multiplies the gradient in the matrix form. Moreover, the\nGFIM and its inverse keeps the same for multiple steps so that the\ncomputational cost can be controlled and is comparable with the first-order\nmethods. A global convergence is established under some mild conditions and a\nregret bound is also given for the online learning setting. Numerical results\non image classification with ResNet50, quantum chemistry modeling with Schnet,\nneural machine translation with Transformer and recommendation system with DLRM\nillustrate that GN+ is competitive with the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Minghan Yang",
      "Dong Xu",
      "Qiwen Cui",
      "Zaiwen Wen",
      "Pengxiang Xu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07454"
  },
  {
    "id": "arXiv:2106.07512",
    "title": "Last Layer Marginal Likelihood for Invariance Learning",
    "abstract": "Data augmentation is often used to incorporate inductive biases into models.\nTraditionally, these are hand-crafted and tuned with cross validation. The\nBayesian paradigm for model selection provides a path towards end-to-end\nlearning of invariances using only the training data, by optimising the\nmarginal likelihood. We work towards bringing this approach to neural networks\nby using an architecture with a Gaussian process in the last layer, a model for\nwhich the marginal likelihood can be computed. Experimentally, we improve\nperformance by learning appropriate invariances in standard benchmarks, the low\ndata regime and in a medical imaging task. Optimisation challenges for\ninvariant Deep Kernel Gaussian processes are identified, and a systematic\nanalysis is presented to arrive at a robust training scheme. We introduce a new\nlower bound to the marginal likelihood, which allows us to perform inference\nfor a larger class of likelihood functions than before, thereby overcoming some\nof the training challenges that existed with previous approaches.",
    "descriptor": "",
    "authors": [
      "Pola Elisabeth Schw\u00f6bel",
      "Martin J\u00f8rgensen",
      "Sebastian W. Ober",
      "Mark van der Wilk"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07512"
  },
  {
    "id": "arXiv:2106.07524",
    "title": "MIA-COV19D: COVID-19 Detection through 3-D Chest CT Image Analysis",
    "abstract": "Early and reliable COVID-19 diagnosis based on chest 3-D CT scans can assist\nmedical specialists in vital circumstances. Deep learning methodologies\nconstitute a main approach for chest CT scan analysis and disease prediction.\nHowever, large annotated databases are necessary for developing deep learning\nmodels that are able to provide COVID-19 diagnosis across various medical\nenvironments in different countries. Due to privacy issues, publicly available\nCOVID-19 CT datasets are highly difficult to obtain, which hinders the research\nand development of AI-enabled diagnosis methods of COVID-19 based on CT scans.\nIn this paper we present the COV19-CT-DB database which is annotated for\nCOVID-19, consisting of about 5,000 3-D CT scans, We have split the database in\ntraining, validation and test datasets. The former two datasets can be used for\ntraining and validation of machine learning models, while the latter will be\nused for evaluation of the developed models. We also present a deep learning\napproach, based on a CNN-RNN network and report its performance on the\nCOVID19-CT-DB database.",
    "descriptor": "",
    "authors": [
      "Dimitrios Kollias",
      "Anastasios Arsenos",
      "Levon Soukissian",
      "Stefanos Kollias"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07524"
  },
  {
    "id": "arXiv:2106.07533",
    "title": "Posterior Temperature Optimization in Variational Inference",
    "abstract": "Cold posteriors have been reported to perform better in practice in the\ncontext of Bayesian deep learning (Wenzel2020 et al., 2020). In variational\ninference, it is common to employ only a partially tempered posterior by\nscaling the complexity term in the log-evidence lower bound (ELBO). In this\nwork, we first derive the ELBO for a fully tempered posterior in mean-field\nvariational inference and subsequently use Bayesian optimization to\nautomatically find the optimal posterior temperature. Choosing an appropriate\nposterior temperature leads to better predictive performance and improved\nuncertainty calibration, which we demonstrate for the task of denoising medical\nX-ray images.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Max-Heinrich Laves",
      "Malte T\u00f6lle",
      "Alexander Schlaefer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07533"
  },
  {
    "id": "arXiv:2106.07537",
    "title": "A Wasserstein Minimax Framework for Mixed Linear Regression",
    "abstract": "Multi-modal distributions are commonly used to model clustered data in\nstatistical learning tasks. In this paper, we consider the Mixed Linear\nRegression (MLR) problem. We propose an optimal transport-based framework for\nMLR problems, Wasserstein Mixed Linear Regression (WMLR), which minimizes the\nWasserstein distance between the learned and target mixture regression models.\nThrough a model-based duality analysis, WMLR reduces the underlying MLR task to\na nonconvex-concave minimax optimization problem, which can be provably solved\nto find a minimax stationary point by the Gradient Descent Ascent (GDA)\nalgorithm. In the special case of mixtures of two linear regression models, we\nshow that WMLR enjoys global convergence and generalization guarantees. We\nprove that WMLR's sample complexity grows linearly with the dimension of data.\nFinally, we discuss the application of WMLR to the federated learning task\nwhere the training samples are collected by multiple agents in a network.\nUnlike the Expectation Maximization algorithm, WMLR directly extends to the\ndistributed, federated learning setting. We support our theoretical results\nthrough several numerical experiments, which highlight our framework's ability\nto handle the federated learning setting with mixture models.",
    "descriptor": "\nComments: To appear in 38th International Conference on Machine Learning (ICML 2021)\n",
    "authors": [
      "Theo Diamandis",
      "Yonina C. Eldar",
      "Alireza Fallah",
      "Farzan Farnia",
      "Asuman Ozdaglar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07537"
  },
  {
    "id": "arXiv:2106.07541",
    "title": "Resilient Control of Platooning Networked Robitic Systems via Dynamic  Watermarking",
    "abstract": "Networked robotic systems, such as connected vehicle platoons, can improve\nthe safety and efficiency of transportation networks by allowing for high-speed\ncoordination. To enable such coordination, these systems rely on networked\ncommunications. This can make them susceptible to cyber attacks. Though\nsecurity methods such as encryption or specially designed network topologies\ncan increase the difficulty of successfully executing such an attack, these\ntechniques are unable to guarantee secure communication against an attacker.\nMore troublingly, these security methods are unable to ensure that individual\nagents are able to detect attacks that alter the content of specific messages.\nTo ensure resilient behavior under such attacks, this paper formulates a\nnetworked linear time-varying version of dynamic watermarking in which each\nagent generates and adds a private excitation to the input of its corresponding\nrobotic subsystem. This paper demonstrates that such a method can enable each\nagent in a networked robotic system to detect cyber attacks. By altering\nmeasurements sent between vehicles, this paper illustrates that an attacker can\ncreate unstable behavior within a platoon. By utilizing the dynamic\nwatermarking method proposed in this paper, the attack is detected, allowing\nthe vehicles in the platoon to gracefully degrade to a non-communicative\ncontrol strategy that maintains safety across a variety of scenarios.",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Matthew Porter",
      "Arnav Joshi",
      "Sidhartha Dey",
      "Qirui Wu",
      "Pedro Hespanhol",
      "Anil Aswani",
      "Matthew Johnson-Roberson",
      "Ram Vasudevan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07541"
  },
  {
    "id": "arXiv:2106.07585",
    "title": "Global Controllability for Quasilinear Non-negative Definite System of  ODEs and SDEs",
    "abstract": "We consider exact and averaged control problem for a system of quasi-linear\nODEs and SDEs with a non-negative definite symmetric matrix of the system. The\nstrategy of the proof is the standard linearization of the system by fixing the\nfunction appearing in the nonlinear part of the system, and then applying the\nLeray-Schauder fixed point theorem. We shall also need the continuous induction\narguments to prolong the control to the final state which is a novel approach\nin the field. This enables us to obtain controllability for arbitrarily large\ninitial data (so called global controllability).",
    "descriptor": "",
    "authors": [
      "Jasmina Djordjevic",
      "Sanja Konjik",
      "Darko Mitrovi\u0107",
      "Andrej Novak"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07585"
  },
  {
    "id": "arXiv:2106.07592",
    "title": "No more glowing in the dark: How deep learning improves exposure date  estimation in thermoluminescence dosimetry",
    "abstract": "The time- or temperature-resolved detector signal from a thermoluminescence\ndosimeter can reveal additional information about circumstances of an exposure\nto ionizing irradiation. We present studies using deep neural networks to\nestimate the date of a single irradiation with 12 mSv within a monitoring\ninterval of 42 days from glow curves of novel TL-DOS personal dosimeters\ndeveloped by the Materialpr\\\"ufungsamt NRW in cooperation with TU Dortmund\nUniversity. Using a deep convolutional network, the irradiation date can be\npredicted from raw time-resolved glow curve data with an uncertainty of roughly\n1-2 days on a 68% confidence level without the need for a prior transformation\ninto temperature space and a subsequent glow curve deconvolution. This\ncorresponds to a significant improvement in prediction accuracy compared to a\nprior publication, which yielded a prediction uncertainty of 2-4 days using\nfeatures obtained from a glow curve deconvolution as input to a neural network.",
    "descriptor": "",
    "authors": [
      "F. Mentzel",
      "E. Derugin",
      "H. Jansen",
      "K. Kr\u00f6ninger",
      "O. Nackenhorst",
      "J. Walbersloh",
      "J. Weingarten"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07592"
  },
  {
    "id": "arXiv:2106.07608",
    "title": "Recursive Refinement Network for Deformable Lung Registration between  Exhale and Inhale CT Scans",
    "abstract": "Unsupervised learning-based medical image registration approaches have\nwitnessed rapid development in recent years. We propose to revisit a commonly\nignored while simple and well-established principle: recursive refinement of\ndeformation vector fields across scales. We introduce a recursive refinement\nnetwork (RRN) for unsupervised medical image registration, to extract\nmulti-scale features, construct normalized local cost correlation volume and\nrecursively refine volumetric deformation vector fields. RRN achieves state of\nthe art performance for 3D registration of expiratory-inspiratory pairs of CT\nlung scans. On DirLab COPDGene dataset, RRN returns an average Target\nRegistration Error (TRE) of 0.83 mm, which corresponds to a 13% error reduction\nfrom the best result presented in the leaderboard. In addition to comparison\nwith conventional methods, RRN leads to 89% error reduction compared to\ndeep-learning-based peer approaches.",
    "descriptor": "",
    "authors": [
      "Xinzi He",
      "Jia Guo",
      "Xuzhe Zhang",
      "Hanwen Bi",
      "Sarah Gerard",
      "David Kaczka",
      "Amin Motahari",
      "Eric Hoffman",
      "Joseph Reinhardt",
      "R. Graham Barr",
      "Elsa Angelini",
      "Andrew Laine"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07608"
  },
  {
    "id": "arXiv:2106.07636",
    "title": "Meta Two-Sample Testing: Learning Kernels for Testing with Limited Data",
    "abstract": "Modern kernel-based two-sample tests have shown great success in\ndistinguishing complex, high-dimensional distributions with appropriate learned\nkernels. Previous work has demonstrated that this kernel learning procedure\nsucceeds, assuming a considerable number of observed samples from each\ndistribution. In realistic scenarios with very limited numbers of data samples,\nhowever, it can be challenging to identify a kernel powerful enough to\ndistinguish complex distributions. We address this issue by introducing the\nproblem of meta two-sample testing (M2ST), which aims to exploit (abundant)\nauxiliary data on related tasks to find an algorithm that can quickly identify\na powerful test on new target tasks. We propose two specific algorithms for\nthis task: a generic scheme which improves over baselines and amore tailored\napproach which performs even better. We provide both theoretical justification\nand empirical evidence that our proposed meta-testing schemes out-perform\nlearning kernel-based tests directly from scarce observations, and identify\nwhen such schemes will be successful.",
    "descriptor": "\nComments: Code is available from this https URL\n",
    "authors": [
      "Feng Liu",
      "Wenkai Xu",
      "Jie Lu",
      "Danica J. Sutherland"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.07636"
  },
  {
    "id": "arXiv:1510.07357",
    "title": "Distributed Bare-Bones Communication in Wireless Networks",
    "abstract": "Distributed Bare-Bones Communication in Wireless Networks",
    "descriptor": "",
    "authors": [
      "Bogdan S. Chlebus",
      "Dariusz R. Kowalski",
      "Shailesh Vaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/1510.07357"
  },
  {
    "id": "arXiv:1705.09543",
    "title": "Indoor Location for Smart Environments with Wireless Sensor and Actuator  Networks",
    "abstract": "Comments: different version is ongoing",
    "descriptor": "\nComments: different version is ongoing\n",
    "authors": [
      "Zhongliang Zhao",
      "Stephane Kuendig",
      "Jose Carrera",
      "Blaise Carron",
      "Torsten Braun",
      "Jose Rolim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/1705.09543"
  },
  {
    "id": "arXiv:1805.09694",
    "title": "A derived isometry theorem for constructible sheaves on $\\mathbb{R}$",
    "abstract": "A derived isometry theorem for constructible sheaves on $\\mathbb{R}$",
    "descriptor": "",
    "authors": [
      "Nicolas Berkouk",
      "Gr\u00e9gory Ginot"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1805.09694"
  },
  {
    "id": "arXiv:1807.10926",
    "title": "An upper bound for min-max angle of polygons",
    "abstract": "An upper bound for min-max angle of polygons",
    "descriptor": "",
    "authors": [
      "Saeed Asaeedi",
      "Farzad Didehvar",
      "Ali Mohades"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1807.10926"
  },
  {
    "id": "arXiv:1807.11702",
    "title": "Efficient Computation of Sequence Mappability",
    "abstract": "Comments: Accepted to SPIRE 2018",
    "descriptor": "\nComments: Accepted to SPIRE 2018\n",
    "authors": [
      "Mai Alzamel",
      "Panagiotis Charalampopoulos",
      "Costas S. Iliopoulos",
      "Tomasz Kociumaka",
      "Solon P. Pissis",
      "Jakub Radoszewski",
      "Juliusz Straszy\u0144ski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1807.11702"
  },
  {
    "id": "arXiv:1811.09999",
    "title": "Conservative Galerkin methods for dispersive Hamiltonian problems",
    "abstract": "Conservative Galerkin methods for dispersive Hamiltonian problems",
    "descriptor": "",
    "authors": [
      "James Jackaman",
      "Tristan Pryer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1811.09999"
  },
  {
    "id": "arXiv:1901.05732",
    "title": "On Coded Caching with Correlated Files",
    "abstract": "Comments: A short version of this paper was presented at the 2019 IEEE International Symposium on Information Theory",
    "descriptor": "\nComments: A short version of this paper was presented at the 2019 IEEE International Symposium on Information Theory\n",
    "authors": [
      "Kai Wan",
      "Daniela Tuninetti",
      "Mingyue Ji",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1901.05732"
  },
  {
    "id": "arXiv:1901.05921",
    "title": "On the Optimality of D2D Coded Caching with Uncoded Cache Placement and  One-shot Delivery",
    "abstract": "On the Optimality of D2D Coded Caching with Uncoded Cache Placement and  One-shot Delivery",
    "descriptor": "",
    "authors": [
      "\u00c7a\u011fkan Yapar",
      "Kai Wan",
      "Rafael F. Schaefer",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1901.05921"
  },
  {
    "id": "arXiv:1901.06547",
    "title": "Moss' logic for ordered coalgebras",
    "abstract": "Moss' logic for ordered coalgebras",
    "descriptor": "",
    "authors": [
      "Marta B\u00edlkov\u00e1",
      "Mat\u011bj Dost\u00e1l"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1901.06547"
  },
  {
    "id": "arXiv:1904.01636",
    "title": "Towards annotation-efficient segmentation via image-to-image translation",
    "abstract": "Towards annotation-efficient segmentation via image-to-image translation",
    "descriptor": "",
    "authors": [
      "Eugene Vorontsov",
      "Pavlo Molchanov",
      "Christopher Beckham",
      "Jan Kautz",
      "Samuel Kadoury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1904.01636"
  },
  {
    "id": "arXiv:1904.12171",
    "title": "Prediction with Unpredictable Feature Evolution",
    "abstract": "Prediction with Unpredictable Feature Evolution",
    "descriptor": "",
    "authors": [
      "Bo-Jian Hou",
      "Lijun Zhang",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1904.12171"
  },
  {
    "id": "arXiv:1904.13088",
    "title": "Dependence-Aware, Unbounded Sound Predictive Race Detection",
    "abstract": "Dependence-Aware, Unbounded Sound Predictive Race Detection",
    "descriptor": "",
    "authors": [
      "Kaan Gen\u00e7",
      "Jake Roemer",
      "Yufan Xu",
      "Michael D. Bond"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1904.13088"
  },
  {
    "id": "arXiv:1905.10696",
    "title": "Lifelong Neural Predictive Coding: Learning Cumulatively Online without  Forgetting",
    "abstract": "Comments: Key updates including results on standard benchmarks, e.g., split mnist/fmnist/not-mnist. Task selection/basal ganglia model has been integrated",
    "descriptor": "\nComments: Key updates including results on standard benchmarks, e.g., split mnist/fmnist/not-mnist. Task selection/basal ganglia model has been integrated\n",
    "authors": [
      "Alexander Ororbia",
      "Ankur Mali",
      "Daniel Kifer",
      "C. Lee Giles"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.10696"
  },
  {
    "id": "arXiv:1905.12418",
    "title": "Expected Tight Bounds for Robust Training",
    "abstract": "Comments: Presented as a RobustML workshop paper at ICLR 2021",
    "descriptor": "\nComments: Presented as a RobustML workshop paper at ICLR 2021\n",
    "authors": [
      "Salman Alsubaihi",
      "Adel Bibi",
      "Modar Alfadly",
      "Abdullah Hamdi",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.12418"
  },
  {
    "id": "arXiv:1905.13298",
    "title": "DeepShift: Towards Multiplication-Less Neural Networks",
    "abstract": "Comments: -Added results for 8-bit and 16-bit fixed point activations, as well as 5-bit, 4-bit, 3-bit, and 2-bit weights. - Added link to GitHub code - Updated and fixed the training algorithm - Introduced 2 approaches for backward and forward pases - Showed better results for training from scratch on CIFAR10 and Imagenet - Added implementation on NVIDIA's GPU -Accepted in CVPR Mobile AI 2021 Workshop",
    "descriptor": "\nComments: -Added results for 8-bit and 16-bit fixed point activations, as well as 5-bit, 4-bit, 3-bit, and 2-bit weights. - Added link to GitHub code - Updated and fixed the training algorithm - Introduced 2 approaches for backward and forward pases - Showed better results for training from scratch on CIFAR10 and Imagenet - Added implementation on NVIDIA's GPU -Accepted in CVPR Mobile AI 2021 Workshop\n",
    "authors": [
      "Mostafa Elhoushi",
      "Zihao Chen",
      "Farhan Shafiq",
      "Ye Henry Tian",
      "Joey Yiwei Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1905.13298"
  },
  {
    "id": "arXiv:1906.06514",
    "title": "PVRED: A Position-Velocity Recurrent Encoder-Decoder for Human Motion  Prediction",
    "abstract": "PVRED: A Position-Velocity Recurrent Encoder-Decoder for Human Motion  Prediction",
    "descriptor": "",
    "authors": [
      "Hongsong Wang",
      "Jian Dong",
      "Bin Cheng",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1906.06514"
  },
  {
    "id": "arXiv:1907.03963",
    "title": "Follow Your Star: New Frameworks for Online Stochastic Matching with  Known and Unknown Patience",
    "abstract": "Comments: 43 pages",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "Brian Brubach",
      "Nathaniel Grammel",
      "Will Ma",
      "Aravind Srinivasan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Multiagent Systems (cs.MA)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1907.03963"
  },
  {
    "id": "arXiv:1907.04793",
    "title": "Uniform stability of a class of large-scale parallel server networks",
    "abstract": "Comments: 29 pages",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Hassan Hmedi",
      "Ari Arapostathis",
      "Guodong Pang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1907.04793"
  },
  {
    "id": "arXiv:1907.08738",
    "title": "Bayesian Inference Gaussian Process Multiproxy Alignment of Continuous  Signals (BIGMACS): Applications for Paleoceanography",
    "abstract": "Comments: This article has been submitted to \"Bayesian Analysis\"",
    "descriptor": "\nComments: This article has been submitted to \"Bayesian Analysis\"\n",
    "authors": [
      "Taehee Lee",
      "Lorraine E. Lisiecki",
      "Devin Rand",
      "Geoffrey Gebbie",
      "Charles E. Lawrence"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1907.08738"
  },
  {
    "id": "arXiv:1907.09532",
    "title": "Computational p-Willmore Flow with Conformal Penalty",
    "abstract": "Comments: Accepted 6/2020 to ACM Trans. Graph",
    "descriptor": "\nComments: Accepted 6/2020 to ACM Trans. Graph\n",
    "authors": [
      "Anthony Gruber",
      "Eugenio Aulisa"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1907.09532"
  },
  {
    "id": "arXiv:1907.12972",
    "title": "Transferability of Spectral Graph Convolutional Neural Networks",
    "abstract": "Transferability of Spectral Graph Convolutional Neural Networks",
    "descriptor": "",
    "authors": [
      "Ron Levie",
      "Wei Huang",
      "Lorenzo Bucci",
      "Michael M. Bronstein",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1907.12972"
  },
  {
    "id": "arXiv:1908.00337",
    "title": "A Greek language teaching platform for primary school pupils",
    "abstract": "A Greek language teaching platform for primary school pupils",
    "descriptor": "",
    "authors": [
      "Eleni Michailidi",
      "Ioannis Skordas",
      "Maria Papatsimouli",
      "Lazaros Lazaridis",
      "Heracles Michailidis",
      "Stavroula Tavoultzidou",
      "George F. Fragulis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/1908.00337"
  },
  {
    "id": "arXiv:1908.04556",
    "title": "Reinterpretation and Extension of Entropy Correction Terms for Residual  Distribution and Discontinuous Galerkin Schemes",
    "abstract": "Reinterpretation and Extension of Entropy Correction Terms for Residual  Distribution and Discontinuous Galerkin Schemes",
    "descriptor": "",
    "authors": [
      "R\u00e9mi Abgrall",
      "Philipp \u00d6ffner",
      "Hendrik Ranocha"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1908.04556"
  },
  {
    "id": "arXiv:1910.09297",
    "title": "Numerical methods for the mass-conserved Ohta-Kawasaki equation",
    "abstract": "Comments: 28 pages, 9 figures",
    "descriptor": "\nComments: 28 pages, 9 figures\n",
    "authors": [
      "Juan Zhang",
      "Shifeng Li",
      "Kai Jiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1910.09297"
  },
  {
    "id": "arXiv:1910.09417",
    "title": "Maximum Probability Theorem: A Framework for Probabilistic Learning",
    "abstract": "Maximum Probability Theorem: A Framework for Probabilistic Learning",
    "descriptor": "",
    "authors": [
      "Amir Emad Marvasti",
      "Ehsan Emad Marvasti",
      "Ulas Bagci",
      "Hassan Foroosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.09417"
  },
  {
    "id": "arXiv:1911.10258",
    "title": "Fantastic Four: Differentiable Bounds on Singular Values of Convolution  Layers",
    "abstract": "Comments: Accepted at ICLR, 2021",
    "descriptor": "\nComments: Accepted at ICLR, 2021\n",
    "authors": [
      "Sahil Singla",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.10258"
  },
  {
    "id": "arXiv:1911.11090",
    "title": "Meta-Learning of Neural Architectures for Few-Shot Learning",
    "abstract": "Meta-Learning of Neural Architectures for Few-Shot Learning",
    "descriptor": "",
    "authors": [
      "Thomas Elsken",
      "Benedikt Staffler",
      "Jan Hendrik Metzen",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.11090"
  },
  {
    "id": "arXiv:1912.02660",
    "title": "Crisp-determinization of weighted tree automata over strong bimonoids",
    "abstract": "Crisp-determinization of weighted tree automata over strong bimonoids",
    "descriptor": "",
    "authors": [
      "Zolt\u00e1n F\u00fcl\u00f6p",
      "D\u00e1vid K\u00f3sz\u00f3",
      "Heiko Vogler"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/1912.02660"
  },
  {
    "id": "arXiv:1912.04007",
    "title": "Subspace power method for symmetric tensor decomposition and generalized  PCA",
    "abstract": "Comments: 58 pages, 7 figures, 2 tables. v3: merged introduction and literature review; clarified convergence proof; increased the number of trials in the numerical experiments; and other improvements",
    "descriptor": "\nComments: 58 pages, 7 figures, 2 tables. v3: merged introduction and literature review; clarified convergence proof; increased the number of trials in the numerical experiments; and other improvements\n",
    "authors": [
      "Joe Kileel",
      "Jo\u00e3o M. Pereira"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1912.04007"
  },
  {
    "id": "arXiv:1912.07812",
    "title": "Capsule Attention for Multimodal EEG-EOG Representation Learning with  Application to Driver Vigilance Estimation",
    "abstract": "Comments: Accepted by IEEE Transactions on Neural Systems and Rehabilitation Engineering",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Neural Systems and Rehabilitation Engineering\n",
    "authors": [
      "Guangyi Zhang",
      "Ali Etemad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.07812"
  },
  {
    "id": "arXiv:1912.09522",
    "title": "Event Outlier Detection in Continuous Time",
    "abstract": "Comments: ICML 2021 camera-ready",
    "descriptor": "\nComments: ICML 2021 camera-ready\n",
    "authors": [
      "Siqi Liu",
      "Milos Hauskrecht"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.09522"
  },
  {
    "id": "arXiv:2001.06372",
    "title": "BigEarthNet Dataset with A New Class-Nomenclature for Remote Sensing  Image Understanding",
    "abstract": "Comments: This paper has been withdrawn by the authors. This paper has been superseded by arXiv:2105.07921",
    "descriptor": "\nComments: This paper has been withdrawn by the authors. This paper has been superseded by arXiv:2105.07921\n",
    "authors": [
      "Gencer Sumbul",
      "Jian Kang",
      "Tristan Kreuziger",
      "Filipe Marcelino",
      "Hugo Costa",
      "Pedro Benevides",
      "Mario Caetano",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2001.06372"
  },
  {
    "id": "arXiv:2002.00526",
    "title": "DANCE: Enhancing saliency maps using decoys",
    "abstract": "DANCE: Enhancing saliency maps using decoys",
    "descriptor": "",
    "authors": [
      "Yang Lu",
      "Wenbo Guo",
      "Xinyu Xing",
      "William Stafford Noble"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.00526"
  },
  {
    "id": "arXiv:2002.03629",
    "title": "Accelerating Feedforward Computation via Parallel Nonlinear Equation  Solving",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Yang Song",
      "Chenlin Meng",
      "Renjie Liao",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.03629"
  },
  {
    "id": "arXiv:2002.04839",
    "title": "LaProp: Separating Momentum and Adaptivity in Adam",
    "abstract": "LaProp: Separating Momentum and Adaptivity in Adam",
    "descriptor": "",
    "authors": [
      "Liu Ziyin",
      "Zhikang T.Wang",
      "Masahito Ueda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.04839"
  },
  {
    "id": "arXiv:2002.07285",
    "title": "Double/Debiased Machine Learning for Dynamic Treatment Effects via  g-Estimation",
    "abstract": "Double/Debiased Machine Learning for Dynamic Treatment Effects via  g-Estimation",
    "descriptor": "",
    "authors": [
      "Greg Lewis",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.07285"
  },
  {
    "id": "arXiv:2002.08187",
    "title": "An adaptive virtual element method for the polymer self-consistent field  theory",
    "abstract": "Comments: 17 pages, 11 figures",
    "descriptor": "\nComments: 17 pages, 11 figures\n",
    "authors": [
      "Huayi Wei",
      "Xin Wang",
      "Chunyu Chen",
      "Kai Jiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2002.08187"
  },
  {
    "id": "arXiv:2002.10904",
    "title": "Human Apprenticeship Learning via Kernel-based Inverse Reinforcement  Learning",
    "abstract": "Comments: 31 pages, 23 figures, Submitted to Journal of Artificial Intelligence Research, \"for source code, see this https URL\"",
    "descriptor": "\nComments: 31 pages, 23 figures, Submitted to Journal of Artificial Intelligence Research, \"for source code, see this https URL\"\n",
    "authors": [
      "Mark A. Rucker",
      "Layne T. Watson",
      "Laura E. Barnes",
      "Matthew S. Gerber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.10904"
  },
  {
    "id": "arXiv:2003.00578",
    "title": "Quantum Indistinguishability for Public Key Encryption",
    "abstract": "Quantum Indistinguishability for Public Key Encryption",
    "descriptor": "",
    "authors": [
      "Tommaso Gagliardoni",
      "Juliane Kr\u00e4mer",
      "Patrick Struck"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2003.00578"
  },
  {
    "id": "arXiv:2003.01926",
    "title": "Transformation Importance with Applications to Cosmology",
    "abstract": "Comments: Published in ICLR 2020 Workshop on Fundamental Science in the era of AI",
    "descriptor": "\nComments: Published in ICLR 2020 Workshop on Fundamental Science in the era of AI\n",
    "authors": [
      "Chandan Singh",
      "Wooseok Ha",
      "Francois Lanusse",
      "Vanessa Boehm",
      "Jia Liu",
      "Bin Yu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.01926"
  },
  {
    "id": "arXiv:2003.03196",
    "title": "Federated Continual Learning with Weighted Inter-client Transfer",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Jaehong Yoon",
      "Wonyong Jeong",
      "Giwoong Lee",
      "Eunho Yang",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.03196"
  },
  {
    "id": "arXiv:2003.06601",
    "title": "Lattice protein design using Bayesian learning",
    "abstract": "Comments: 12 pages, 10 figures",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Tomoei Takahashi",
      "George Chikenji",
      "Kei Tokita"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2003.06601"
  },
  {
    "id": "arXiv:2003.11991",
    "title": "Estimating Treatment Effects with Observed Confounders and Mediators",
    "abstract": "Estimating Treatment Effects with Observed Confounders and Mediators",
    "descriptor": "",
    "authors": [
      "Shantanu Gupta",
      "Zachary C. Lipton",
      "David Childers"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.11991"
  },
  {
    "id": "arXiv:2004.00202",
    "title": "Shared Cross-Modal Trajectory Prediction for Autonomous Driving",
    "abstract": "Comments: CVPR 2021 [Oral]. arXiv admin note: substantial text overlap with arXiv:2011.08436",
    "descriptor": "\nComments: CVPR 2021 [Oral]. arXiv admin note: substantial text overlap with arXiv:2011.08436\n",
    "authors": [
      "Chiho Choi",
      "Joon Hee Choi",
      "Srikanth Malla",
      "Jiachen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2004.00202"
  },
  {
    "id": "arXiv:2004.08891",
    "title": "Hedging with Linear Regressions and Neural Networks",
    "abstract": "Comments: Forthcoming in the Journal of Business & Economic Statistics",
    "descriptor": "\nComments: Forthcoming in the Journal of Business & Economic Statistics\n",
    "authors": [
      "Johannes Ruf",
      "Weiguan Wang"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)",
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.08891"
  },
  {
    "id": "arXiv:2005.00613",
    "title": "A Controllable Model of Grounded Response Generation",
    "abstract": "Comments: AAAI 2021",
    "descriptor": "\nComments: AAAI 2021\n",
    "authors": [
      "Zeqiu Wu",
      "Michel Galley",
      "Chris Brockett",
      "Yizhe Zhang",
      "Xiang Gao",
      "Chris Quirk",
      "Rik Koncel-Kedziorski",
      "Jianfeng Gao",
      "Hannaneh Hajishirzi",
      "Mari Ostendorf",
      "Bill Dolan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2005.00613"
  },
  {
    "id": "arXiv:2005.04507",
    "title": "PGDOT -- Perturbed Gradient Descent Adapted with Occupation Time",
    "abstract": "Comments: 15 pages, 7 figures, 1 table",
    "descriptor": "\nComments: 15 pages, 7 figures, 1 table\n",
    "authors": [
      "Xin Guo",
      "Jiequn Han",
      "Mahan Tajrobehkar",
      "Wenpin Tang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.04507"
  },
  {
    "id": "arXiv:2005.07496",
    "title": "Foundations and modelling of dynamic networks using Dynamic Graph Neural  Networks: A survey",
    "abstract": "Comments: 28 pages, 9 figures, 8 tables",
    "descriptor": "\nComments: 28 pages, 9 figures, 8 tables\n",
    "authors": [
      "Joakim Skarding",
      "Bogdan Gabrys",
      "Katarzyna Musial"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.07496"
  },
  {
    "id": "arXiv:2005.11092",
    "title": "Improving Co-registration for Sentinel-1 SAR and Sentinel-2 Optical  images",
    "abstract": "Improving Co-registration for Sentinel-1 SAR and Sentinel-2 Optical  images",
    "descriptor": "",
    "authors": [
      "Yuanxin Ye",
      "Chao Yang",
      "Bai Zhu",
      "Youquan He",
      "Huarong Jia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.11092"
  },
  {
    "id": "arXiv:2005.12604",
    "title": "An adaptive block Bregman proximal gradient method for computing  stationary states of multicomponent phase-field crystal model",
    "abstract": "Comments: 38 pages, 9 figures",
    "descriptor": "\nComments: 38 pages, 9 figures\n",
    "authors": [
      "Chenglong Bao",
      "Chang Chen",
      "Kai Jiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2005.12604"
  },
  {
    "id": "arXiv:2006.01771",
    "title": "Database of Power Grid Frequency Measurements",
    "abstract": "Comments: 28 pages, 10 figures. Data associated with this paper are located here: this https URL",
    "descriptor": "\nComments: 28 pages, 10 figures. Data associated with this paper are located here: this https URL\n",
    "authors": [
      "Richard Jumar",
      "Heiko Maa\u00df",
      "Benjamin Sch\u00e4fer",
      "Leonardo Rydin Gorj\u00e3o",
      "Veit Hagenmeyer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2006.01771"
  },
  {
    "id": "arXiv:2006.02138",
    "title": "Integrating Deep Learning into CAD/CAE System: Generative Design and  Evaluation of 3D Conceptual Wheel",
    "abstract": "Integrating Deep Learning into CAD/CAE System: Generative Design and  Evaluation of 3D Conceptual Wheel",
    "descriptor": "",
    "authors": [
      "Soyoung Yoo",
      "Sunghee Lee",
      "Seongsin Kim",
      "Kwang Hyeon Hwang",
      "Jong Ho Park",
      "Namwoo Kang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2006.02138"
  },
  {
    "id": "arXiv:2006.04222",
    "title": "Randomized Entity-wise Factorization for Multi-Agent Reinforcement  Learning",
    "abstract": "Comments: ICML 2021 Camera Ready",
    "descriptor": "\nComments: ICML 2021 Camera Ready\n",
    "authors": [
      "Shariq Iqbal",
      "Christian A. Schroeder de Witt",
      "Bei Peng",
      "Wendelin B\u00f6hmer",
      "Shimon Whiteson",
      "Fei Sha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.04222"
  },
  {
    "id": "arXiv:2006.04648",
    "title": "Graph-based Visual-Semantic Entanglement Network for Zero-shot Image  Recognition",
    "abstract": "Comments: 15 pages, 11 figures, on IEEE Transactions on Multimedia",
    "descriptor": "\nComments: 15 pages, 11 figures, on IEEE Transactions on Multimedia\n",
    "authors": [
      "Yang Hu",
      "Guihua Wen",
      "Adriane Chapman",
      "Pei Yang",
      "Mingnan Luo",
      "Yingxue Xu",
      "Dan Dai",
      "Wendy Hall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2006.04648"
  },
  {
    "id": "arXiv:2006.04740",
    "title": "The Heavy-Tail Phenomenon in SGD",
    "abstract": "The Heavy-Tail Phenomenon in SGD",
    "descriptor": "",
    "authors": [
      "Mert Gurbuzbalaban",
      "Umut \u015eim\u015fekli",
      "Lingjiong Zhu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2006.04740"
  },
  {
    "id": "arXiv:2006.05145",
    "title": "Matrix games with bandit feedback",
    "abstract": "Matrix games with bandit feedback",
    "descriptor": "",
    "authors": [
      "Brendan O'Donoghue",
      "Tor Lattimore",
      "Ian Osband"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05145"
  },
  {
    "id": "arXiv:2006.05468",
    "title": "Variational Auto-Regressive Gaussian Processes for Continual Learning",
    "abstract": "Comments: International Conference on Machine Learning (ICML), 2021",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML), 2021\n",
    "authors": [
      "Sanyam Kapoor",
      "Theofanis Karaletsos",
      "Thang D. Bui"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.05468"
  },
  {
    "id": "arXiv:2006.06987",
    "title": "Improved estimations of stochastic chemical kinetics by finite state  expansion",
    "abstract": "Comments: 33 pages, 9 figures",
    "descriptor": "\nComments: 33 pages, 9 figures\n",
    "authors": [
      "Tabea Waizmann",
      "Luca Bortolussi",
      "Andrea Vandin",
      "Mirco Tribastone"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2006.06987"
  },
  {
    "id": "arXiv:2006.07942",
    "title": "Duplicity Games for Deception Design with an Application to Insider  Threat Mitigation",
    "abstract": "Duplicity Games for Deception Design with an Application to Insider  Threat Mitigation",
    "descriptor": "",
    "authors": [
      "Linan Huang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2006.07942"
  },
  {
    "id": "arXiv:2006.08836",
    "title": "Extension complexity of low-dimensional polytopes",
    "abstract": "Comments: We fixed an issue with Lemma 6.9 (the exponential Efron-Stein inequality was previously used incorrectly)",
    "descriptor": "\nComments: We fixed an issue with Lemma 6.9 (the exponential Efron-Stein inequality was previously used incorrectly)\n",
    "authors": [
      "Matthew Kwan",
      "Lisa Sauermann",
      "Yufei Zhao"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2006.08836"
  },
  {
    "id": "arXiv:2006.09179",
    "title": "Reconstruction of turbulent data with deep generative models for  semantic inpainting from TURB-Rot database",
    "abstract": "Reconstruction of turbulent data with deep generative models for  semantic inpainting from TURB-Rot database",
    "descriptor": "",
    "authors": [
      "M. Buzzicotti",
      "F. Bonaccorso",
      "P. Clark Di Leoni",
      "L. Biferale"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2006.09179"
  },
  {
    "id": "arXiv:2006.10529",
    "title": "Neural Path Features and Neural Path Kernel : Understanding the role of  gates in deep learning",
    "abstract": "Comments: Appeared in NeurIPS 2020 (23 pages)",
    "descriptor": "\nComments: Appeared in NeurIPS 2020 (23 pages)\n",
    "authors": [
      "Chandrashekar Lakshminarayanan",
      "Amit Vikram Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10529"
  },
  {
    "id": "arXiv:2006.14512",
    "title": "Uncovering the Connections Between Adversarial Transferability and  Knowledge Transferability",
    "abstract": "Comments: Accepted to ICML 2021",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Kaizhao Liang",
      "Jacky Y. Zhang",
      "Oluwasanmi Koyejo",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.14512"
  },
  {
    "id": "arXiv:2006.16205",
    "title": "Composed Fine-Tuning: Freezing Pre-Trained Denoising Autoencoders for  Improved Generalization",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Sang Michael Xie",
      "Tengyu Ma",
      "Percy Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.16205"
  },
  {
    "id": "arXiv:2007.01612",
    "title": "Online learning in MDPs with linear function approximation and bandit  feedback",
    "abstract": "Online learning in MDPs with linear function approximation and bandit  feedback",
    "descriptor": "",
    "authors": [
      "Gergely Neu",
      "Julia Olkhovskaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.01612"
  },
  {
    "id": "arXiv:2007.03767",
    "title": "Defending against Backdoors in Federated Learning with Robust Learning  Rate",
    "abstract": "Comments: Published at AAAI 2021",
    "descriptor": "\nComments: Published at AAAI 2021\n",
    "authors": [
      "Mustafa Safa Ozdayi",
      "Murat Kantarcioglu",
      "Yulia R. Gel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.03767"
  },
  {
    "id": "arXiv:2007.04938",
    "title": "SUNRISE: A Simple Unified Framework for Ensemble Learning in Deep  Reinforcement Learning",
    "abstract": "Comments: ICML 2021 camera ready",
    "descriptor": "\nComments: ICML 2021 camera ready\n",
    "authors": [
      "Kimin Lee",
      "Michael Laskin",
      "Aravind Srinivas",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.04938"
  },
  {
    "id": "arXiv:2007.05724",
    "title": "Learning Randomly Perturbed Structured Predictors for Direct Loss  Minimization",
    "abstract": "Comments: Proceedings of the 38th International Conference on Machine Learning, 2021",
    "descriptor": "\nComments: Proceedings of the 38th International Conference on Machine Learning, 2021\n",
    "authors": [
      "Hedda Cohen Indelman",
      "Tamir Hazan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.05724"
  },
  {
    "id": "arXiv:2007.09453",
    "title": "Robust Image Classification Using A Low-Pass Activation Function and DCT  Augmentation",
    "abstract": "Robust Image Classification Using A Low-Pass Activation Function and DCT  Augmentation",
    "descriptor": "",
    "authors": [
      "Md Tahmid Hossain",
      "Shyh Wei Teng",
      "Ferdous Sohel",
      "Guojun Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.09453"
  },
  {
    "id": "arXiv:2007.15190",
    "title": "Quantitative Understanding of VAE as a Non-linearly Scaled Isometric  Embedding",
    "abstract": "Comments: 40 pages, 29 figures",
    "descriptor": "\nComments: 40 pages, 29 figures\n",
    "authors": [
      "Akira Nakagawa",
      "Keizo Kato",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.15190"
  },
  {
    "id": "arXiv:2008.00483",
    "title": "Single-Timescale Actor-Critic Provably Finds Globally Optimal Policy",
    "abstract": "Single-Timescale Actor-Critic Provably Finds Globally Optimal Policy",
    "descriptor": "",
    "authors": [
      "Zuyue Fu",
      "Zhuoran Yang",
      "Zhaoran Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.00483"
  },
  {
    "id": "arXiv:2008.00553",
    "title": "A Unifying Framework for Parallel and Distributed Processing in R using  Futures",
    "abstract": "Comments: 19 pages, 1 figure, accepted The R Journal, 2021",
    "descriptor": "\nComments: 19 pages, 1 figure, accepted The R Journal, 2021\n",
    "authors": [
      "Henrik Bengtsson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2008.00553"
  },
  {
    "id": "arXiv:2008.01158",
    "title": "Multi-Disease Classification of 13,667 Body CT Scans Using Weakly  Supervised Deep Learning",
    "abstract": "Comments: 18 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 18 pages, 6 figures, 2 tables\n",
    "authors": [
      "Fakrul Islam Tushar",
      "Vincent M. D'Anniballe",
      "Rui Hou",
      "Maciej A. Mazurowski",
      "Wanyi Fu",
      "Ehsan Samei",
      "Geoffrey D. Rubin",
      "Joseph Y. Lo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2008.01158"
  },
  {
    "id": "arXiv:2008.01558",
    "title": "Federated Learning with Sparsification-Amplified Privacy and Adaptive  Optimization",
    "abstract": "Comments: Accepted in IJCAI 2021, this is the full version with appendix",
    "descriptor": "\nComments: Accepted in IJCAI 2021, this is the full version with appendix\n",
    "authors": [
      "Rui Hu",
      "Yanmin Gong",
      "Yuanxiong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.01558"
  },
  {
    "id": "arXiv:2008.03194",
    "title": "Scalable Low-Rank Tensor Learning for Spatiotemporal Traffic Data  Imputation",
    "abstract": "Scalable Low-Rank Tensor Learning for Spatiotemporal Traffic Data  Imputation",
    "descriptor": "",
    "authors": [
      "Xinyu Chen",
      "Yixian Chen",
      "Nicolas Saunier",
      "Lijun Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.03194"
  },
  {
    "id": "arXiv:2008.05221",
    "title": "Compression of Deep Learning Models for Text: A Survey",
    "abstract": "Comments: Accepted at TKDD for publication. 53 pages",
    "descriptor": "\nComments: Accepted at TKDD for publication. 53 pages\n",
    "authors": [
      "Manish Gupta",
      "Puneet Agrawal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.05221"
  },
  {
    "id": "arXiv:2008.06910",
    "title": "Neural Descent for Visual 3D Human Pose and Shape",
    "abstract": "Comments: CVPR 2021",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Andrei Zanfir",
      "Eduard Gabriel Bazavan",
      "Mihai Zanfir",
      "William T. Freeman",
      "Rahul Sukthankar",
      "Cristian Sminchisescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.06910"
  },
  {
    "id": "arXiv:2008.09887",
    "title": "Semi-Supervised Data Programming with Subset Selection",
    "abstract": "Comments: Findings of ACL, 2021",
    "descriptor": "\nComments: Findings of ACL, 2021\n",
    "authors": [
      "Ayush Maheshwari",
      "Oishik Chatterjee",
      "KrishnaTeja Killamsetty",
      "Ganesh Ramakrishnan",
      "Rishabh Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.09887"
  },
  {
    "id": "arXiv:2008.10898",
    "title": "PAGE: A Simple and Optimal Probabilistic Gradient Estimator for  Nonconvex Optimization",
    "abstract": "Comments: 25 pages; accepted by ICML 2021 (long talk)",
    "descriptor": "\nComments: 25 pages; accepted by ICML 2021 (long talk)\n",
    "authors": [
      "Zhize Li",
      "Hongyan Bao",
      "Xiangliang Zhang",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.10898"
  },
  {
    "id": "arXiv:2008.13305",
    "title": "An Integrated Approach to Produce Robust Models with High Efficiency",
    "abstract": "An Integrated Approach to Produce Robust Models with High Efficiency",
    "descriptor": "",
    "authors": [
      "Zhijian Li",
      "Bao Wang",
      "Jack Xin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.13305"
  },
  {
    "id": "arXiv:2009.00102",
    "title": "Discrete conservation laws for finite element discretisations of  multisymplectic PDEs",
    "abstract": "Discrete conservation laws for finite element discretisations of  multisymplectic PDEs",
    "descriptor": "",
    "authors": [
      "Elena Celledoni",
      "James Jackaman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2009.00102"
  },
  {
    "id": "arXiv:2009.01454",
    "title": "Say No to the Discrimination: Learning Fair Graph Neural Networks with  Limited Sensitive Attribute Information",
    "abstract": "Say No to the Discrimination: Learning Fair Graph Neural Networks with  Limited Sensitive Attribute Information",
    "descriptor": "",
    "authors": [
      "Enyan Dai",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.01454"
  },
  {
    "id": "arXiv:2009.01716",
    "title": "A Software-Defined Networking Solution for Transparent Session and  Service Continuity in Dynamic Multi-Access Edge Computing",
    "abstract": "Comments: Accepted version of the article published in IEEE Transactions on Network and Service Management",
    "descriptor": "\nComments: Accepted version of the article published in IEEE Transactions on Network and Service Management\n",
    "authors": [
      "Pablo Fondo-Ferreiro",
      "Felipe Gil-Casti\u00f1eira",
      "Francisco Javier Gonz\u00e1lez-Casta\u00f1o",
      "David Candal-Ventureira"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2009.01716"
  },
  {
    "id": "arXiv:2009.05567",
    "title": "Machine Unlearning for Random Forests",
    "abstract": "Comments: 29 pages, 5 figures, 9 tables, and 3 algorithms. Accepted at ICML 2021",
    "descriptor": "\nComments: 29 pages, 5 figures, 9 tables, and 3 algorithms. Accepted at ICML 2021\n",
    "authors": [
      "Jonathan Brophy",
      "Daniel Lowd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.05567"
  },
  {
    "id": "arXiv:2009.06040",
    "title": "Span-based Semantic Parsing for Compositional Generalization",
    "abstract": "Comments: ACL 2021 camera ready",
    "descriptor": "\nComments: ACL 2021 camera ready\n",
    "authors": [
      "Jonathan Herzig",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.06040"
  },
  {
    "id": "arXiv:2009.06701",
    "title": "Dirty Road Can Attack: Security of Deep Learning based Automated Lane  Centering under Physical-World Attack",
    "abstract": "Comments: Accepted to Usenix Security '21",
    "descriptor": "\nComments: Accepted to Usenix Security '21\n",
    "authors": [
      "Takami Sato",
      "Junjie Shen",
      "Ningfei Wang",
      "Yunhan Jack Jia",
      "Xue Lin",
      "Qi Alfred Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.06701"
  },
  {
    "id": "arXiv:2009.09162",
    "title": "Extracting Summary Knowledge Graphs from Long Documents",
    "abstract": "Extracting Summary Knowledge Graphs from Long Documents",
    "descriptor": "",
    "authors": [
      "Zeqiu Wu",
      "Rik Koncel-Kedziorski",
      "Mari Ostendorf",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.09162"
  },
  {
    "id": "arXiv:2009.12480",
    "title": "Bandwidth-Agile Image Transmission with Deep Joint Source-Channel Coding",
    "abstract": "Bandwidth-Agile Image Transmission with Deep Joint Source-Channel Coding",
    "descriptor": "",
    "authors": [
      "David Burth Kurka",
      "Deniz G\u00fcnd\u00fcz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2009.12480"
  },
  {
    "id": "arXiv:2009.13504",
    "title": "Information Obfuscation of Graph Neural Networks",
    "abstract": "Comments: ICML 2021; Code is available at this https URL",
    "descriptor": "\nComments: ICML 2021; Code is available at this https URL\n",
    "authors": [
      "Peiyuan Liao",
      "Han Zhao",
      "Keyulu Xu",
      "Tommi Jaakkola",
      "Geoffrey Gordon",
      "Stefanie Jegelka",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.13504"
  },
  {
    "id": "arXiv:2010.01755",
    "title": "A Distributed Model-Free Ride-Sharing Approach for Joint Matching,  Pricing, and Dispatching using Deep Reinforcement Learning",
    "abstract": "A Distributed Model-Free Ride-Sharing Approach for Joint Matching,  Pricing, and Dispatching using Deep Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Marina Haliem",
      "Ganapathy Mani",
      "Vaneet Aggarwal",
      "Bharat Bhargava"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.01755"
  },
  {
    "id": "arXiv:2010.02068",
    "title": "Deep Reinforcement Learning for Electric Vehicle Routing Problem with  Time Windows",
    "abstract": "Deep Reinforcement Learning for Electric Vehicle Routing Problem with  Time Windows",
    "descriptor": "",
    "authors": [
      "Bo Lin",
      "Bissan Ghaddar",
      "Jatin Nathwani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.02068"
  },
  {
    "id": "arXiv:2010.03934",
    "title": "Prioritized Level Replay",
    "abstract": "Prioritized Level Replay",
    "descriptor": "",
    "authors": [
      "Minqi Jiang",
      "Edward Grefenstette",
      "Tim Rockt\u00e4schel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.03934"
  },
  {
    "id": "arXiv:2010.04223",
    "title": "Fictitious play in zero-sum stochastic games",
    "abstract": "Fictitious play in zero-sum stochastic games",
    "descriptor": "",
    "authors": [
      "Muhammed O. Sayin",
      "Francesca Parise",
      "Asuman Ozdaglar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.04223"
  },
  {
    "id": "arXiv:2010.04627",
    "title": "Learning Binary Decision Trees by Argmin Differentiation",
    "abstract": "Learning Binary Decision Trees by Argmin Differentiation",
    "descriptor": "",
    "authors": [
      "Valentina Zantedeschi",
      "Matt J. Kusner",
      "Vlad Niculae"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.04627"
  },
  {
    "id": "arXiv:2010.05153",
    "title": "Online Learning and Distributed Control for Residential Demand Response",
    "abstract": "Online Learning and Distributed Control for Residential Demand Response",
    "descriptor": "",
    "authors": [
      "Xin Chen",
      "Yingying Li",
      "Jun Shimada",
      "Na Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.05153"
  },
  {
    "id": "arXiv:2010.05594",
    "title": "MultiWOZ 2.3: A multi-domain task-oriented dialogue dataset enhanced  with annotation corrections and co-reference annotation",
    "abstract": "MultiWOZ 2.3: A multi-domain task-oriented dialogue dataset enhanced  with annotation corrections and co-reference annotation",
    "descriptor": "",
    "authors": [
      "Ting Han",
      "Ximing Liu",
      "Ryuichi Takanobu",
      "Yixin Lian",
      "Chongxuan Huang",
      "Dazhen Wan",
      "Wei Peng",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.05594"
  },
  {
    "id": "arXiv:2010.07003",
    "title": "Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime  with Search",
    "abstract": "Comments: ACL 2021; 11 pages, 4 figures",
    "descriptor": "\nComments: ACL 2021; 11 pages, 4 figures\n",
    "authors": [
      "Gyuwan Kim",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.07003"
  },
  {
    "id": "arXiv:2010.08175",
    "title": "Anisotropic Stroke Control for Multiple Artists Style Transfer",
    "abstract": "Comments: ACMMM2020",
    "descriptor": "\nComments: ACMMM2020\n",
    "authors": [
      "Xuanhong Chen",
      "Xirui Yan",
      "Naiyuan Liu",
      "Ting Qiu",
      "Bingbing Ni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.08175"
  },
  {
    "id": "arXiv:2010.08581",
    "title": "A Sampling-Based Method for Tensor Ring Decomposition",
    "abstract": "Comments: Accepted to ICML 2021",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Osman Asif Malik",
      "Stephen Becker"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.08581"
  },
  {
    "id": "arXiv:2010.09029",
    "title": "CHECKED: Chinese COVID-19 Fake News Dataset",
    "abstract": "Comments: Accepted to Social Network Analysis and Mining (SNAM)",
    "descriptor": "\nComments: Accepted to Social Network Analysis and Mining (SNAM)\n",
    "authors": [
      "Chen Yang",
      "Xinyi Zhou",
      "Reza Zafarani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2010.09029"
  },
  {
    "id": "arXiv:2010.09116",
    "title": "Topic Recommendation for Software Repositories using Multi-label  Classification Algorithms",
    "abstract": "Topic Recommendation for Software Repositories using Multi-label  Classification Algorithms",
    "descriptor": "",
    "authors": [
      "Maliheh Izadi",
      "Abbas Heydarnoori",
      "Georgios Gousios"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2010.09116"
  },
  {
    "id": "arXiv:2010.09317",
    "title": "A Comprehensive Overview on 5G-and-Beyond Networks with UAVs: From  Communications to Sensing and Intelligence",
    "abstract": "Comments: Accepted by IEEE JSAC",
    "descriptor": "\nComments: Accepted by IEEE JSAC\n",
    "authors": [
      "Qingqing Wu",
      "Jie Xu",
      "Yong Zeng",
      "Derrick Wing Kwan Ng",
      "Naofal Al-Dhahir",
      "Robert Schober",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2010.09317"
  },
  {
    "id": "arXiv:2010.09670",
    "title": "RobustBench: a standardized adversarial robustness benchmark",
    "abstract": "Comments: Version 2: 90+ evaluations, 60+ models, 5 leaderboards (Linf, L2, common corruptions), significantly expanded analysis part (calibration, fairness, privacy leakage, smoothness, transferability)",
    "descriptor": "\nComments: Version 2: 90+ evaluations, 60+ models, 5 leaderboards (Linf, L2, common corruptions), significantly expanded analysis part (calibration, fairness, privacy leakage, smoothness, transferability)\n",
    "authors": [
      "Francesco Croce",
      "Maksym Andriushchenko",
      "Vikash Sehwag",
      "Edoardo Debenedetti",
      "Nicolas Flammarion",
      "Mung Chiang",
      "Prateek Mittal",
      "Matthias Hein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.09670"
  },
  {
    "id": "arXiv:2010.11387",
    "title": "Kwame: A Bilingual AI Teaching Assistant for Online SuaCode Courses",
    "abstract": "Comments: 6 pages. Accepted and presented at NeurIPS 2020 workshop (Black in AI) and AIED 2021 (international conference on AI in Education)",
    "descriptor": "\nComments: 6 pages. Accepted and presented at NeurIPS 2020 workshop (Black in AI) and AIED 2021 (international conference on AI in Education)\n",
    "authors": [
      "George Boateng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.11387"
  },
  {
    "id": "arXiv:2010.12919",
    "title": "Causal Effects of Linguistic Properties",
    "abstract": "Comments: To appear at NAACL 2021 (Annual Conference of the North American Chapter of the Association for Computational Linguistics)",
    "descriptor": "\nComments: To appear at NAACL 2021 (Annual Conference of the North American Chapter of the Association for Computational Linguistics)\n",
    "authors": [
      "Reid Pryzant",
      "Dallas Card",
      "Dan Jurafsky",
      "Victor Veitch",
      "Dhanya Sridhar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.12919"
  },
  {
    "id": "arXiv:2010.14318",
    "title": "Multitask Training with Text Data for End-to-End Speech Recognition",
    "abstract": "Multitask Training with Text Data for End-to-End Speech Recognition",
    "descriptor": "",
    "authors": [
      "Peidong Wang",
      "Tara N. Sainath",
      "Ron J. Weiss"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.14318"
  },
  {
    "id": "arXiv:2010.14535",
    "title": "Neural Architecture Search of SPD Manifold Networks",
    "abstract": "Comments: This paper is accepted for publication at IJCAI 2021",
    "descriptor": "\nComments: This paper is accepted for publication at IJCAI 2021\n",
    "authors": [
      "Rhea Sanjay Sukthanker",
      "Zhiwu Huang",
      "Suryansh Kumar",
      "Erik Goron Endsjo",
      "Yan Wu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2010.14535"
  },
  {
    "id": "arXiv:2010.14824",
    "title": "Explainable Artificial Intelligence for Manufacturing Cost Estimation  and Machining Feature Visualization",
    "abstract": "Explainable Artificial Intelligence for Manufacturing Cost Estimation  and Machining Feature Visualization",
    "descriptor": "",
    "authors": [
      "Soyoung Yoo",
      "Namwoo Kang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.14824"
  },
  {
    "id": "arXiv:2010.14860",
    "title": "The Evidence Lower Bound of Variational Autoencoders Converges to a Sum  of Three Entropies",
    "abstract": "The Evidence Lower Bound of Variational Autoencoders Converges to a Sum  of Three Entropies",
    "descriptor": "",
    "authors": [
      "J\u00f6rg L\u00fccke",
      "Dennis Forster",
      "Zhenwen Dai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.14860"
  },
  {
    "id": "arXiv:2011.00344",
    "title": "A Distribution-Dependent Analysis of Meta-Learning",
    "abstract": "Comments: 19 pages, 7 figures",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Mikhail Konobeev",
      "Ilja Kuzborskij",
      "Csaba Szepesv\u00e1ri"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.00344"
  },
  {
    "id": "arXiv:2011.00382",
    "title": "A Policy Gradient Algorithm for Learning to Learn in Multiagent  Reinforcement Learning",
    "abstract": "Comments: Accepted to ICML 2021. Code at this https URL and Videos at this https URL",
    "descriptor": "\nComments: Accepted to ICML 2021. Code at this https URL and Videos at this https URL\n",
    "authors": [
      "Dong-Ki Kim",
      "Miao Liu",
      "Matthew Riemer",
      "Chuangchuang Sun",
      "Marwa Abdulhai",
      "Golnaz Habibi",
      "Sebastian Lopez-Cot",
      "Gerald Tesauro",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2011.00382"
  },
  {
    "id": "arXiv:2011.00751",
    "title": "A Critical Correspondence on Humpty Dumpty's Funding for European  Journalism",
    "abstract": "Comments: Revised",
    "descriptor": "\nComments: Revised\n",
    "authors": [
      "Jukka Ruohonen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2011.00751"
  },
  {
    "id": "arXiv:2011.01192",
    "title": "Budget Sharing for Multi-Analyst Differential Privacy",
    "abstract": "Comments: 13 pages, 5 figures, accepted to PVLDB Vol. 14, to be presented at VLDB 2021",
    "descriptor": "\nComments: 13 pages, 5 figures, accepted to PVLDB Vol. 14, to be presented at VLDB 2021\n",
    "authors": [
      "David Pujol",
      "Yikai Wu",
      "Brandon Fain",
      "Ashwin Machanavajjhala"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.01192"
  },
  {
    "id": "arXiv:2011.01489",
    "title": "On Computing Stable Extensions of Abstract Argumentation Frameworks",
    "abstract": "On Computing Stable Extensions of Abstract Argumentation Frameworks",
    "descriptor": "",
    "authors": [
      "Samer Nofal",
      "Amani Abu Jabal",
      "Abdullah Alfarrarjeh",
      "Ismail Hababeh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2011.01489"
  },
  {
    "id": "arXiv:2011.03853",
    "title": "A fast randomized incremental gradient method for decentralized  non-convex optimization",
    "abstract": "Comments: Added more numerical experiments, expanded discussion on technical results",
    "descriptor": "\nComments: Added more numerical experiments, expanded discussion on technical results\n",
    "authors": [
      "Ran Xin",
      "Usman A. Khan",
      "Soummya Kar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.03853"
  },
  {
    "id": "arXiv:2011.06569",
    "title": "When are Adaptive Strategies in Asymptotic Quantum Channel  Discrimination Useful?",
    "abstract": "Comments: V2 has more complete references, an improved presentation, including clearer figures and a summary of the classes of strategies considered, also an additional example of an asymptotic separation between adaptive and non-adaptive strategies for two qc-channels, and finally a cleaned-up presentation of the discrimination power of a quantum channel",
    "descriptor": "\nComments: V2 has more complete references, an improved presentation, including clearer figures and a summary of the classes of strategies considered, also an additional example of an asymptotic separation between adaptive and non-adaptive strategies for two qc-channels, and finally a cleaned-up presentation of the discrimination power of a quantum channel\n",
    "authors": [
      "Farzin Salek",
      "Masahito Hayashi",
      "Andreas Winter"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2011.06569"
  },
  {
    "id": "arXiv:2011.07435",
    "title": "Functorial Manifold Learning",
    "abstract": "Functorial Manifold Learning",
    "descriptor": "",
    "authors": [
      "Dan Shiebler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.07435"
  },
  {
    "id": "arXiv:2011.07585",
    "title": "An acceleration of decentralized SGD under general assumptions with low  stochastic noise",
    "abstract": "Comments: MOTOR 2021 conference",
    "descriptor": "\nComments: MOTOR 2021 conference\n",
    "authors": [
      "Trimbach Ekaterina",
      "Rogozin Alexander"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2011.07585"
  },
  {
    "id": "arXiv:2011.10977",
    "title": "A Novel NOMA Solution with RIS Partitioning",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Aymen Khaleel",
      "Ertugrul Basar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2011.10977"
  },
  {
    "id": "arXiv:2011.11057",
    "title": "Robust Gaussian Process Regression Based on Iterative Trimming",
    "abstract": "Comments: major revision, 11 pages, 8 figures, 2 tables; accepted by Astronomy and Computing; code available at this https URL",
    "descriptor": "\nComments: major revision, 11 pages, 8 figures, 2 tables; accepted by Astronomy and Computing; code available at this https URL\n",
    "authors": [
      "Zhao-Zhou Li",
      "Lu Li",
      "Zhengyi Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.11057"
  },
  {
    "id": "arXiv:2011.11256",
    "title": "Learning Quantized Neural Nets by Coarse Gradient Method for Non-linear  Classification",
    "abstract": "Learning Quantized Neural Nets by Coarse Gradient Method for Non-linear  Classification",
    "descriptor": "",
    "authors": [
      "Ziang Long",
      "Penghang Yin",
      "Jack Xin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.11256"
  },
  {
    "id": "arXiv:2011.12114",
    "title": "Rethinking solar photovoltaic parameter estimation: global optimality  analysis and a simple efficient differential evolution method",
    "abstract": "Comments: v2, see source code at this https URL",
    "descriptor": "\nComments: v2, see source code at this https URL\n",
    "authors": [
      "Shuhua Gao",
      "Cheng Xiang",
      "Yu Ming",
      "Tan Kuan Tak",
      "Tong Heng Lee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2011.12114"
  },
  {
    "id": "arXiv:2011.14372",
    "title": "CNN-based Lung CT Registration with Multiple Anatomical Constraints",
    "abstract": "CNN-based Lung CT Registration with Multiple Anatomical Constraints",
    "descriptor": "",
    "authors": [
      "Alessa Hering",
      "Stephanie H\u00e4ger",
      "Jan Moltz",
      "Nikolas Lessmann",
      "Stefan Heldmann",
      "Bram van Ginneken"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.14372"
  },
  {
    "id": "arXiv:2011.14804",
    "title": "Extremal Set Theory and LWE Based Access Structure Hiding Verifiable  Secret Sharing with Malicious-Majority and Free Verification",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Vipin Singh Sehrawat",
      "Foo Yee Yeo",
      "Yvo Desmedt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2011.14804"
  },
  {
    "id": "arXiv:2012.01750",
    "title": "Understanding Failures of Deep Networks via Robust Feature Extraction",
    "abstract": "Comments: Accepted at CVPR, 2021",
    "descriptor": "\nComments: Accepted at CVPR, 2021\n",
    "authors": [
      "Sahil Singla",
      "Besmira Nushi",
      "Shital Shah",
      "Ece Kamar",
      "Eric Horvitz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.01750"
  },
  {
    "id": "arXiv:2012.01926",
    "title": "COVID-19 Cough Classification using Machine Learning and Global  Smartphone Recordings",
    "abstract": "Comments: This paper has been accepted in \"Computers in Medicine and Biology\" and currently under production",
    "descriptor": "\nComments: This paper has been accepted in \"Computers in Medicine and Biology\" and currently under production\n",
    "authors": [
      "Madhurananda Pahar",
      "Marisa Klopper",
      "Robin Warren",
      "Thomas Niesler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2012.01926"
  },
  {
    "id": "arXiv:2012.02724",
    "title": "The Treachery of Images in the Digital Sovereignty Debate",
    "abstract": "Comments: Revised",
    "descriptor": "\nComments: Revised\n",
    "authors": [
      "Jukka Ruohonen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2012.02724"
  },
  {
    "id": "arXiv:2012.03408",
    "title": "PMP-Net: Point Cloud Completion by Learning Multi-step Point Moving  Paths",
    "abstract": "Comments: Accepted by CVPR 2021",
    "descriptor": "\nComments: Accepted by CVPR 2021\n",
    "authors": [
      "Xin Wen",
      "Peng Xiang",
      "Zhizhong Han",
      "Yan-Pei Cao",
      "Pengfei Wan",
      "Wen Zheng",
      "Yu-Shen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.03408"
  },
  {
    "id": "arXiv:2012.03461",
    "title": "A Distributed and Secure Algorithm for Computing Dominant SVD Based on  Projection Splitting",
    "abstract": "A Distributed and Secure Algorithm for Computing Dominant SVD Based on  Projection Splitting",
    "descriptor": "",
    "authors": [
      "Lei Wang",
      "Xin Liu",
      "Yin Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2012.03461"
  },
  {
    "id": "arXiv:2012.05390",
    "title": "Ensemble Squared: A Meta AutoML System",
    "abstract": "Ensemble Squared: A Meta AutoML System",
    "descriptor": "",
    "authors": [
      "Jason Yoo",
      "Tony Joseph",
      "Dylan Yung",
      "S. Ali Nasseri",
      "Frank Wood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.05390"
  },
  {
    "id": "arXiv:2012.05522",
    "title": "Synthesizing Long-Term 3D Human Motion and Interaction in 3D Scenes",
    "abstract": "Synthesizing Long-Term 3D Human Motion and Interaction in 3D Scenes",
    "descriptor": "",
    "authors": [
      "Jiashun Wang",
      "Huazhe Xu",
      "Jingwei Xu",
      "Sifei Liu",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.05522"
  },
  {
    "id": "arXiv:2012.05766",
    "title": "Deep Argumentative Explanations",
    "abstract": "Comments: 16 pages, 10 figures",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Emanuele Albini",
      "Piyawat Lertvittayakumjorn",
      "Antonio Rago",
      "Francesca Toni"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.05766"
  },
  {
    "id": "arXiv:2012.05874",
    "title": "Hindsight and Sequential Rationality of Correlated Play",
    "abstract": "Comments: Technical report for a paper in the proceedings of the thirty-fifth AAAI Conference on Artificial Intelligence (AAAI-21), February 2-9, 2021, Virtual. 26 pages and 15 figures",
    "descriptor": "\nComments: Technical report for a paper in the proceedings of the thirty-fifth AAAI Conference on Artificial Intelligence (AAAI-21), February 2-9, 2021, Virtual. 26 pages and 15 figures\n",
    "authors": [
      "Dustin Morrill",
      "Ryan D'Orazio",
      "Reca Sarfati",
      "Marc Lanctot",
      "James R. Wright",
      "Amy Greenwald",
      "Michael Bowling"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.05874"
  },
  {
    "id": "arXiv:2012.06860",
    "title": "Age-Optimal Power Allocation in Industrial IoT: A Risk-Sensitive  Federated Learning Approach",
    "abstract": "Comments: Accepted in IEEE PIMRC 2021 with 6 pages and 8 figures",
    "descriptor": "\nComments: Accepted in IEEE PIMRC 2021 with 6 pages and 8 figures\n",
    "authors": [
      "Yung-Lin Hsu",
      "Chen-Feng Liu",
      "Sumudu Samarakoon",
      "Hung-Yu Wei",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2012.06860"
  },
  {
    "id": "arXiv:2012.07983",
    "title": "On Continuous Local BDD-Based Search for Hybrid SAT Solving",
    "abstract": "Comments: AAAI 21",
    "descriptor": "\nComments: AAAI 21\n",
    "authors": [
      "Anastasios Kyrillidis",
      "Moshe Y. Vardi",
      "Zhiwei Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2012.07983"
  },
  {
    "id": "arXiv:2012.08156",
    "title": "Confidential Machine Learning on Untrusted Platforms: A Survey",
    "abstract": "Comments: To appear in Cybersecurity Journal, Springer, 2021",
    "descriptor": "\nComments: To appear in Cybersecurity Journal, Springer, 2021\n",
    "authors": [
      "Sagar Sharma",
      "Keke Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2012.08156"
  },
  {
    "id": "arXiv:2012.10333",
    "title": "Learning from History for Byzantine Robust Optimization",
    "abstract": "Comments: ICML 2021; v2 contains stronger theory",
    "descriptor": "\nComments: ICML 2021; v2 contains stronger theory\n",
    "authors": [
      "Sai Praneeth Karimireddy",
      "Lie He",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.10333"
  },
  {
    "id": "arXiv:2012.10630",
    "title": "GLISTER: Generalization based Data Subset Selection for Efficient and  Robust Learning",
    "abstract": "GLISTER: Generalization based Data Subset Selection for Efficient and  Robust Learning",
    "descriptor": "",
    "authors": [
      "Krishnateja Killamsetty",
      "Durga Sivasubramanian",
      "Ganesh Ramakrishnan",
      "Rishabh Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.10630"
  },
  {
    "id": "arXiv:2012.10911",
    "title": "Domain-adaptive Fall Detection Using Deep Adversarial Training",
    "abstract": "Comments: Accepted by IEEE Transactions on Neural Systems and Rehabilitation Engineering, 10 pages, 8 figures, 5 tables",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Neural Systems and Rehabilitation Engineering, 10 pages, 8 figures, 5 tables\n",
    "authors": [
      "Kai-Chun Liu",
      "Michael Can",
      "Heng-Cheng Kuo",
      "Chia-Yeh Hsieh",
      "Hsiang-Yun Huang",
      "Chia-Tai Chan",
      "Yu Tsao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.10911"
  },
  {
    "id": "arXiv:2012.12779",
    "title": "Optimal and Low-Memory Near-Optimal Preconditioning of Fully Implicit  Runge-Kutta Schemes for Parabolic PDEs",
    "abstract": "Optimal and Low-Memory Near-Optimal Preconditioning of Fully Implicit  Runge-Kutta Schemes for Parabolic PDEs",
    "descriptor": "",
    "authors": [
      "Xiangmin Jiao",
      "Xuebin Wang",
      "Qiao Chen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2012.12779"
  },
  {
    "id": "arXiv:2012.12854",
    "title": "Deep manifold learning reveals hidden dynamics of proteasome  autoregulation",
    "abstract": "Comments: 81 pages, 16 figures, 2 tables",
    "descriptor": "\nComments: 81 pages, 16 figures, 2 tables\n",
    "authors": [
      "Zhaolong Wu",
      "Shuwen Zhang",
      "Wei Li Wang",
      "Yinping Ma",
      "Yuanchen Dong",
      "Youdong Mao"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.12854"
  },
  {
    "id": "arXiv:2012.13052",
    "title": "Learning from Crowds by Modeling Common Confusions",
    "abstract": "Comments: Accepted by AAAI 2021",
    "descriptor": "\nComments: Accepted by AAAI 2021\n",
    "authors": [
      "Zhendong Chu",
      "Jing Ma",
      "Hongning Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2012.13052"
  },
  {
    "id": "arXiv:2012.13658",
    "title": "Locally Persistent Exploration in Continuous Control Tasks with Sparse  Rewards",
    "abstract": "Comments: To be published in ICML, 2021",
    "descriptor": "\nComments: To be published in ICML, 2021\n",
    "authors": [
      "Susan Amin",
      "Maziar Gomrokchi",
      "Hossein Aboutalebi",
      "Harsh Satija",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.13658"
  },
  {
    "id": "arXiv:2101.00148",
    "title": "Bilingual Lexicon Induction via Unsupervised Bitext Construction and  Word Alignment",
    "abstract": "Comments: ACL-IJCNLP 2021 camera-ready version, with full supplementary material",
    "descriptor": "\nComments: ACL-IJCNLP 2021 camera-ready version, with full supplementary material\n",
    "authors": [
      "Haoyue Shi",
      "Luke Zettlemoyer",
      "Sida I. Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00148"
  },
  {
    "id": "arXiv:2101.00151",
    "title": "DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded  Dialogue",
    "abstract": "Comments: 20 pages, 14 figures, 8 tables",
    "descriptor": "\nComments: 20 pages, 14 figures, 8 tables\n",
    "authors": [
      "Hung Le",
      "Chinnadhurai Sankar",
      "Seungwhan Moon",
      "Ahmad Beirami",
      "Alborz Geramifard",
      "Satwik Kottur"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.00151"
  },
  {
    "id": "arXiv:2101.02523",
    "title": "Few-Shot Learning with Class Imbalance",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Mateusz Ochal",
      "Massimiliano Patacchiola",
      "Amos Storkey",
      "Jose Vazquez",
      "Sen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.02523"
  },
  {
    "id": "arXiv:2101.03419",
    "title": "Training Deep Architectures Without End-to-End Backpropagation: A Brief  Survey",
    "abstract": "Training Deep Architectures Without End-to-End Backpropagation: A Brief  Survey",
    "descriptor": "",
    "authors": [
      "Shiyu Duan",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.03419"
  },
  {
    "id": "arXiv:2101.04097",
    "title": "Correlated Weights in Infinite Limits of Deep Convolutional Neural  Networks",
    "abstract": "Comments: Accepted for the 37th Conference on Uncertainty in Artificial Intelligence (UAI 2021)",
    "descriptor": "\nComments: Accepted for the 37th Conference on Uncertainty in Artificial Intelligence (UAI 2021)\n",
    "authors": [
      "Adri\u00e0 Garriga-Alonso",
      "Mark van der Wilk"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.04097"
  },
  {
    "id": "arXiv:2101.04230",
    "title": "Explaining the Black-box Smoothly- A Counterfactual Approach",
    "abstract": "Comments: Under review for IEEE-TMI journal",
    "descriptor": "\nComments: Under review for IEEE-TMI journal\n",
    "authors": [
      "Sumedha Singla",
      "Brian Pollack",
      "Stephen Wallace",
      "Kayhan Batmanghelich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2101.04230"
  },
  {
    "id": "arXiv:2101.05068",
    "title": "Probabilistic Embeddings for Cross-Modal Retrieval",
    "abstract": "Comments: Accepted to CVPR 2021; Code is available at this https URL",
    "descriptor": "\nComments: Accepted to CVPR 2021; Code is available at this https URL\n",
    "authors": [
      "Sanghyuk Chun",
      "Seong Joon Oh",
      "Rafael Sampaio de Rezende",
      "Yannis Kalantidis",
      "Diane Larlus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.05068"
  },
  {
    "id": "arXiv:2101.06561",
    "title": "GENIE: A Leaderboard for Human-in-the-Loop Evaluation of Text Generation",
    "abstract": "GENIE: A Leaderboard for Human-in-the-Loop Evaluation of Text Generation",
    "descriptor": "",
    "authors": [
      "Daniel Khashabi",
      "Gabriel Stanovsky",
      "Jonathan Bragg",
      "Nicholas Lourie",
      "Jungo Kasai",
      "Yejin Choi",
      "Noah A. Smith",
      "Daniel S. Weld"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.06561"
  },
  {
    "id": "arXiv:2101.06969",
    "title": "Red Alarm for Pre-trained Models: Universal Vulnerability to  Neuron-Level Backdoor Attacks",
    "abstract": "Red Alarm for Pre-trained Models: Universal Vulnerability to  Neuron-Level Backdoor Attacks",
    "descriptor": "",
    "authors": [
      "Zhengyan Zhang",
      "Guangxuan Xiao",
      "Yongwei Li",
      "Tian Lv",
      "Fanchao Qi",
      "Zhiyuan Liu",
      "Yasheng Wang",
      "Xin Jiang",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.06969"
  },
  {
    "id": "arXiv:2101.06983",
    "title": "Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup",
    "abstract": "Comments: RepL4NLP 2021",
    "descriptor": "\nComments: RepL4NLP 2021\n",
    "authors": [
      "Luyu Gao",
      "Yunyi Zhang",
      "Jiawei Han",
      "Jamie Callan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.06983"
  },
  {
    "id": "arXiv:2101.07393",
    "title": "Grounding Language to Entities and Dynamics for Generalization in  Reinforcement Learning",
    "abstract": "Comments: Accepted to ICML 2021. Note author list and name changes from previous version",
    "descriptor": "\nComments: Accepted to ICML 2021. Note author list and name changes from previous version\n",
    "authors": [
      "Austin W. Hanjie",
      "Victor Zhong",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.07393"
  },
  {
    "id": "arXiv:2101.08143",
    "title": "Fast Evaluation for Relevant Quantities of Opinion Dynamics",
    "abstract": "Fast Evaluation for Relevant Quantities of Opinion Dynamics",
    "descriptor": "",
    "authors": [
      "Wanyue Xu",
      "Qi Bao",
      "Zhongzhi Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2101.08143"
  },
  {
    "id": "arXiv:2101.08477",
    "title": "Unifying Cardiovascular Modelling with Deep Reinforcement Learning for  Uncertainty Aware Control of Sepsis Treatment",
    "abstract": "Unifying Cardiovascular Modelling with Deep Reinforcement Learning for  Uncertainty Aware Control of Sepsis Treatment",
    "descriptor": "",
    "authors": [
      "Thesath Nanayakkara",
      "Gilles Clermont",
      "Christopher James Langmead",
      "David Swigon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2101.08477"
  },
  {
    "id": "arXiv:2101.08524",
    "title": "Fast and Robust Certifiable Estimation of the Relative Pose Between Two  Calibrated Cameras",
    "abstract": "Fast and Robust Certifiable Estimation of the Relative Pose Between Two  Calibrated Cameras",
    "descriptor": "",
    "authors": [
      "Mercedes Garcia-Salguero",
      "Javier Gonzalez-Jimenez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.08524"
  },
  {
    "id": "arXiv:2101.09678",
    "title": "A symmetric fractional-order reduction method for direct nonuniform  approximations of semilinear diffusion-wave equations",
    "abstract": "A symmetric fractional-order reduction method for direct nonuniform  approximations of semilinear diffusion-wave equations",
    "descriptor": "",
    "authors": [
      "Pin Lyu",
      "Seakweng Vong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.09678"
  },
  {
    "id": "arXiv:2101.10025",
    "title": "A Review of Graph Neural Networks and Their Applications in Power  Systems",
    "abstract": "A Review of Graph Neural Networks and Their Applications in Power  Systems",
    "descriptor": "",
    "authors": [
      "Wenlong Liao",
      "Birgitte Bak-Jensen",
      "Jayakrishnan Radhakrishna Pillai",
      "Yuelong Wang",
      "Yusen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.10025"
  },
  {
    "id": "arXiv:2101.10040",
    "title": "Complexity of Linear Minimization and Projection on Some Sets",
    "abstract": "Comments: 14 pages, 2 figures",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Cyrille W. Combettes",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.10040"
  },
  {
    "id": "arXiv:2101.10902",
    "title": "Maximum n-times Coverage for Vaccine Design",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Ge Liu",
      "Alexander Dimitrakakis",
      "Brandon Carter",
      "David Gifford"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.10902"
  },
  {
    "id": "arXiv:2101.11139",
    "title": "A Strengthened Cutset Upper Bound on the Capacity of the Relay Channel  and Applications",
    "abstract": "Comments: 35 pages, 7 figures",
    "descriptor": "\nComments: 35 pages, 7 figures\n",
    "authors": [
      "Abbas El Gamal",
      "Amin Gohari",
      "Chandra Nair"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.11139"
  },
  {
    "id": "arXiv:2101.11783",
    "title": "Random Graph Matching with Improved Noise Robustness",
    "abstract": "Comments: 34 pages. Accepted for presentation at Conference on Learning Theory (COLT) 2021",
    "descriptor": "\nComments: 34 pages. Accepted for presentation at Conference on Learning Theory (COLT) 2021\n",
    "authors": [
      "Cheng Mao",
      "Mark Rudelson",
      "Konstantin Tikhomirov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.11783"
  },
  {
    "id": "arXiv:2101.12242",
    "title": "D3DLO: Deep 3D LiDAR Odometry",
    "abstract": "Comments: 5 pages, 4 figures, accepted at IEEE ICIP 2021",
    "descriptor": "\nComments: 5 pages, 4 figures, accepted at IEEE ICIP 2021\n",
    "authors": [
      "Philipp Adis",
      "Nicolas Horst",
      "Mathias Wien"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.12242"
  },
  {
    "id": "arXiv:2101.12475",
    "title": "A Comprehensive Survey on 6G Networks:Applications, Core Services,  Enabling Technologies, and Future Challenges",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Amin Shahraki",
      "Mahmoud Abbasi",
      "Md. Jalil Piran",
      "Amir Taherkordi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2101.12475"
  },
  {
    "id": "arXiv:2102.00087",
    "title": "Are Work Zones and Connected Automated Vehicles Ready for a Harmonious  Coexistence? A Scoping Review and Research Agenda",
    "abstract": "Are Work Zones and Connected Automated Vehicles Ready for a Harmonious  Coexistence? A Scoping Review and Research Agenda",
    "descriptor": "",
    "authors": [
      "Amjad Dehman",
      "Bilal Farooq"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2102.00087"
  },
  {
    "id": "arXiv:2102.01391",
    "title": "Bayesian Neural Networks for Virtual Flow Metering: An Empirical Study",
    "abstract": "Comments: 34 pages, 11 figures",
    "descriptor": "\nComments: 34 pages, 11 figures\n",
    "authors": [
      "Bjarne Grimstad",
      "Mathilde Hotvedt",
      "Anders T. Sandnes",
      "Odd Kolbj\u00f8rnsen",
      "Lars S. Imsland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.01391"
  },
  {
    "id": "arXiv:2102.01956",
    "title": "Time Series Classification via Topological Data Analysis",
    "abstract": "Comments: 31 pages, 20 figures",
    "descriptor": "\nComments: 31 pages, 20 figures\n",
    "authors": [
      "Alperen Karan",
      "Atabey Kaygun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.01956"
  },
  {
    "id": "arXiv:2102.02414",
    "title": "Learning Noise Transition Matrix from Only Noisy Labels via Total  Variation Regularization",
    "abstract": "Comments: ICML 2021 camera-ready version",
    "descriptor": "\nComments: ICML 2021 camera-ready version\n",
    "authors": [
      "Yivan Zhang",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02414"
  },
  {
    "id": "arXiv:2102.02959",
    "title": "Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text  Reports Using Deep Learning",
    "abstract": "Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text  Reports Using Deep Learning",
    "descriptor": "",
    "authors": [
      "Vincent M. D'Anniballe",
      "Fakrul I. Tushar",
      "Khrystyna Faryna",
      "Songyue Han",
      "Maciej A. Mazurowski",
      "Geoffrey D. Rubin",
      "Joseph Y. Lo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02959"
  },
  {
    "id": "arXiv:2102.03129",
    "title": "Integer Programming for Causal Structure Learning in the Presence of  Latent Variables",
    "abstract": "Integer Programming for Causal Structure Learning in the Presence of  Latent Variables",
    "descriptor": "",
    "authors": [
      "Rui Chen",
      "Sanjeeb Dash",
      "Tian Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.03129"
  },
  {
    "id": "arXiv:2102.03198",
    "title": "Bias-Variance Reduced Local SGD for Less Heterogeneous Federated  Learning",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Tomoya Murata",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.03198"
  },
  {
    "id": "arXiv:2102.03360",
    "title": "Scenario Generation for Cooling, Heating, and Power Loads Using  Generative Moment Matching Networks",
    "abstract": "Comments: This paper has been accepted by CSEE Journal of Power and Energy Systems",
    "descriptor": "\nComments: This paper has been accepted by CSEE Journal of Power and Energy Systems\n",
    "authors": [
      "Wenlong Liao",
      "Yusen Wang",
      "Yuelong Wang",
      "Kody Powell",
      "Qi Liu",
      "Zhe Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.03360"
  },
  {
    "id": "arXiv:2102.03716",
    "title": "SPADE: A Spectral Method for Black-Box Adversarial Robustness Evaluation",
    "abstract": "Comments: The 2021 International Conference on Machine Learning (ICML)",
    "descriptor": "\nComments: The 2021 International Conference on Machine Learning (ICML)\n",
    "authors": [
      "Wuxinlin Cheng",
      "Chenhui Deng",
      "Zhiqiang Zhao",
      "Yaohui Cai",
      "Zhiru Zhang",
      "Zhuo Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.03716"
  },
  {
    "id": "arXiv:2102.03895",
    "title": "Functional optimal transport: map estimation and domain adaptation for  functional data",
    "abstract": "Comments: 23 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 23 pages, 6 figures, 2 tables\n",
    "authors": [
      "Jiacheng Zhu",
      "Aritra Guha",
      "Dat Do",
      "Mengdi Xu",
      "XuanLong Nguyen",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2102.03895"
  },
  {
    "id": "arXiv:2102.04216",
    "title": "Social and behavioral determinants of health in the era of artificial  intelligence with electronic health records: A scoping review",
    "abstract": "Comments: 32 pages, 5 figures",
    "descriptor": "\nComments: 32 pages, 5 figures\n",
    "authors": [
      "Anusha Bompelli",
      "Yanshan Wang",
      "Ruyuan Wan",
      "Esha Singh",
      "Yuqi Zhou",
      "Lin Xu",
      "David Oniani",
      "Bhavani Singh Agnikula Kshatriya",
      "Joyce",
      "E. Balls-Berry",
      "Rui Zhang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.04216"
  },
  {
    "id": "arXiv:2102.05140",
    "title": "Locally Adaptive Label Smoothing for Predictive Churn",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Dara Bahri",
      "Heinrich Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.05140"
  },
  {
    "id": "arXiv:2102.05185",
    "title": "Benchmarks, Algorithms, and Metrics for Hierarchical Disentanglement",
    "abstract": "Comments: ICML 2021 accepted paper",
    "descriptor": "\nComments: ICML 2021 accepted paper\n",
    "authors": [
      "Andrew Slavin Ross",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.05185"
  },
  {
    "id": "arXiv:2102.05284",
    "title": "Finding the Stochastic Shortest Path with Low Regret: The Adversarial  Cost and Unknown Transition Case",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Liyu Chen",
      "Haipeng Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.05284"
  },
  {
    "id": "arXiv:2102.05363",
    "title": "Towards Certifying L-infinity Robustness using Neural Networks with  L-inf-dist Neurons",
    "abstract": "Comments: Appearing at International Conference on Machine Learning (ICML) 2021",
    "descriptor": "\nComments: Appearing at International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Bohang Zhang",
      "Tianle Cai",
      "Zhou Lu",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.05363"
  },
  {
    "id": "arXiv:2102.05858",
    "title": "Achieving Near Instance-Optimality and Minimax-Optimality in Stochastic  and Adversarial Linear Bandits Simultaneously",
    "abstract": "Achieving Near Instance-Optimality and Minimax-Optimality in Stochastic  and Adversarial Linear Bandits Simultaneously",
    "descriptor": "",
    "authors": [
      "Chung-Wei Lee",
      "Haipeng Luo",
      "Chen-Yu Wei",
      "Mengxiao Zhang",
      "Xiaojin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05858"
  },
  {
    "id": "arXiv:2102.05912",
    "title": "BoMb-OT: On Batch of Mini-batches Optimal Transport",
    "abstract": "Comments: 36 pages, 20 figures",
    "descriptor": "\nComments: 36 pages, 20 figures\n",
    "authors": [
      "Khai Nguyen",
      "Quoc Nguyen",
      "Nhat Ho",
      "Tung Pham",
      "Hung Bui",
      "Dinh Phung",
      "Trung Le"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05912"
  },
  {
    "id": "arXiv:2102.06192",
    "title": "Adversarial Segmentation Loss for Sketch Colorization",
    "abstract": "Comments: ICIP 2021 camera-ready version",
    "descriptor": "\nComments: ICIP 2021 camera-ready version\n",
    "authors": [
      "Samet Hicsonmez",
      "Nermin Samet",
      "Emre Akbas",
      "Pinar Duygulu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.06192"
  },
  {
    "id": "arXiv:2102.06752",
    "title": "A Hybrid Variance-Reduced Method for Decentralized Stochastic Non-Convex  Optimization",
    "abstract": "Comments: Accepted in ICML 2021",
    "descriptor": "\nComments: Accepted in ICML 2021\n",
    "authors": [
      "Ran Xin",
      "Usman A. Khan",
      "Soummya Kar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06752"
  },
  {
    "id": "arXiv:2102.06810",
    "title": "Understanding self-supervised Learning Dynamics without Contrastive  Pairs",
    "abstract": "Comments: ICML 2021 camera ready",
    "descriptor": "\nComments: ICML 2021 camera ready\n",
    "authors": [
      "Yuandong Tian",
      "Xinlei Chen",
      "Surya Ganguli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.06810"
  },
  {
    "id": "arXiv:2102.06828",
    "title": "Domain Adaptation for Time Series Forecasting via Attention Sharing",
    "abstract": "Comments: 19 pages, 9 figures",
    "descriptor": "\nComments: 19 pages, 9 figures\n",
    "authors": [
      "Xiaoyong Jin",
      "Youngsuk Park",
      "Danielle C. Maddix",
      "Yuyang Wang",
      "Xifeng Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06828"
  },
  {
    "id": "arXiv:2102.06961",
    "title": "PerSim: Data-Efficient Offline Reinforcement Learning with Heterogeneous  Agents via Personalized Simulators",
    "abstract": "PerSim: Data-Efficient Offline Reinforcement Learning with Heterogeneous  Agents via Personalized Simulators",
    "descriptor": "",
    "authors": [
      "Anish Agarwal",
      "Abdullah Alomar",
      "Varkey Alumootil",
      "Devavrat Shah",
      "Dennis Shen",
      "Zhi Xu",
      "Cindy Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06961"
  },
  {
    "id": "arXiv:2102.06973",
    "title": "Efficient Deviation Types and Learning for Hindsight Rationality in  Extensive-Form Games",
    "abstract": "Comments: Technical report for a paper in the proceedings of the thirty-eighth International Conference on Machine Learning (ICML 2021), virtual. 39 pages and 6 figures",
    "descriptor": "\nComments: Technical report for a paper in the proceedings of the thirty-eighth International Conference on Machine Learning (ICML 2021), virtual. 39 pages and 6 figures\n",
    "authors": [
      "Dustin Morrill",
      "Ryan D'Orazio",
      "Marc Lanctot",
      "James R. Wright",
      "Michael Bowling",
      "Amy Greenwald"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.06973"
  },
  {
    "id": "arXiv:2102.07060",
    "title": "Achieving Efficiency in Black Box Simulation of Distribution Tails with  Self-structuring Importance Samplers",
    "abstract": "Comments: 51 pages",
    "descriptor": "\nComments: 51 pages\n",
    "authors": [
      "Anand Deo",
      "Karthyek Murthy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2102.07060"
  },
  {
    "id": "arXiv:2102.07074",
    "title": "TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can  Scale Up",
    "abstract": "TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can  Scale Up",
    "descriptor": "",
    "authors": [
      "Yifan Jiang",
      "Shiyu Chang",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.07074"
  },
  {
    "id": "arXiv:2102.07108",
    "title": "CATE: Computation-aware Neural Architecture Encoding with Transformers",
    "abstract": "Comments: ICML 2021 camera-ready. Code: this https URL",
    "descriptor": "\nComments: ICML 2021 camera-ready. Code: this https URL\n",
    "authors": [
      "Shen Yan",
      "Kaiqiang Song",
      "Fei Liu",
      "Mi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07108"
  },
  {
    "id": "arXiv:2102.07238",
    "title": "Double-descent curves in neural networks: a new perspective using  Gaussian processes",
    "abstract": "Double-descent curves in neural networks: a new perspective using  Gaussian processes",
    "descriptor": "",
    "authors": [
      "Ouns El Harzli",
      "Guillermo Valle-P\u00e9rez",
      "Ard A. Louis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07238"
  },
  {
    "id": "arXiv:2102.07475",
    "title": "Scaling Multi-Agent Reinforcement Learning with Selective Parameter  Sharing",
    "abstract": "Comments: To be published In Proceedings of the 38th International Conference on Machine Learning (ICML), 2021",
    "descriptor": "\nComments: To be published In Proceedings of the 38th International Conference on Machine Learning (ICML), 2021\n",
    "authors": [
      "Filippos Christianos",
      "Georgios Papoudakis",
      "Arrasy Rahman",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07475"
  },
  {
    "id": "arXiv:2102.07758",
    "title": "Decentralized Distributed Optimization for Saddle Point Problems",
    "abstract": "Decentralized Distributed Optimization for Saddle Point Problems",
    "descriptor": "",
    "authors": [
      "Alexander Rogozin",
      "Aleksandr Beznosikov",
      "Darina Dvinskikh",
      "Dmitry Kovalev",
      "Pavel Dvurechensky",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.07758"
  },
  {
    "id": "arXiv:2102.07850",
    "title": "Differentiable Particle Filtering via Entropy-Regularized Optimal  Transport",
    "abstract": "Comments: 9 pages of content + 11 pages supplementary, accepted for presentation at ICML 2021",
    "descriptor": "\nComments: 9 pages of content + 11 pages supplementary, accepted for presentation at ICML 2021\n",
    "authors": [
      "Adrien Corenflos",
      "James Thornton",
      "Arnaud Doucet",
      "George Deligiannidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2102.07850"
  },
  {
    "id": "arXiv:2102.07923",
    "title": "Darboux-Frame-Based Parametrization for a Spin-Rolling Sphere on a  Plane: A Nonlinear Transformation of Underactuated System to Fully-Actuated  Model",
    "abstract": "Comments: 17 pages, 7 figures, Accepted at Mechanism and Machine Theory Elsevier",
    "descriptor": "\nComments: 17 pages, 7 figures, Accepted at Mechanism and Machine Theory Elsevier\n",
    "authors": [
      "Seyed Amir Tafrishi",
      "Mikhail Svinin",
      "Motoji Yamamoto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2102.07923"
  },
  {
    "id": "arXiv:2102.08329",
    "title": "Rate-Distortion Theoretic Model Compression: Successive Refinement for  Pruning",
    "abstract": "Comments: Title changed. Previous title: Successive pruning for model compression via rate distortion theory",
    "descriptor": "\nComments: Title changed. Previous title: Successive pruning for model compression via rate distortion theory\n",
    "authors": [
      "Berivan Isik",
      "Albert No",
      "Tsachy Weissman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.08329"
  },
  {
    "id": "arXiv:2102.08452",
    "title": "Globally-Robust Neural Networks",
    "abstract": "Comments: Appearing in ICML 2021",
    "descriptor": "\nComments: Appearing in ICML 2021\n",
    "authors": [
      "Klas Leino",
      "Zifan Wang",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.08452"
  },
  {
    "id": "arXiv:2102.08554",
    "title": "Recoverability Landscape of Tree Structured Markov Random Fields under  Symmetric Noise",
    "abstract": "Recoverability Landscape of Tree Structured Markov Random Fields under  Symmetric Noise",
    "descriptor": "",
    "authors": [
      "Ashish Katiyar",
      "Soumya Basu",
      "Vatsal Shah",
      "Constantine Caramanis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.08554"
  },
  {
    "id": "arXiv:2102.08622",
    "title": "Sinkhorn Label Allocation: Semi-Supervised Classification via Annealed  Self-Training",
    "abstract": "Comments: ICML 2021 camera ready version",
    "descriptor": "\nComments: ICML 2021 camera ready version\n",
    "authors": [
      "Kai Sheng Tai",
      "Peter Bailis",
      "Gregory Valiant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.08622"
  },
  {
    "id": "arXiv:2102.09626",
    "title": "A Simple Unified Framework for High Dimensional Bandit Problems",
    "abstract": "A Simple Unified Framework for High Dimensional Bandit Problems",
    "descriptor": "",
    "authors": [
      "Wenjie Li",
      "Adarsh Barik",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09626"
  },
  {
    "id": "arXiv:2102.09695",
    "title": "Fortify Machine Learning Production Systems: Detect and Classify  Adversarial Attacks",
    "abstract": "Comments: 5 Pages, 5 Figures, 5 Tables, 17 References, ICMLA 2021, IEEE Conference Format",
    "descriptor": "\nComments: 5 Pages, 5 Figures, 5 Tables, 17 References, ICMLA 2021, IEEE Conference Format\n",
    "authors": [
      "Matthew Ciolino",
      "Josh Kalin",
      "David Noever"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.09695"
  },
  {
    "id": "arXiv:2102.09768",
    "title": "Probabilistic Generating Circuits",
    "abstract": "Probabilistic Generating Circuits",
    "descriptor": "",
    "authors": [
      "Honghua Zhang",
      "Brendan Juba",
      "Guy Van den Broeck"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09768"
  },
  {
    "id": "arXiv:2102.10255",
    "title": "Link Prediction with Persistent Homology: An Interactive View",
    "abstract": "Comments: Accepted in ICML2021",
    "descriptor": "\nComments: Accepted in ICML2021\n",
    "authors": [
      "Zuoyu Yan",
      "Tengfei Ma",
      "Liangcai Gao",
      "Zhi Tang",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.10255"
  },
  {
    "id": "arXiv:2102.10271",
    "title": "Meta-Learning Dynamics Forecasting Using Task Inference",
    "abstract": "Meta-Learning Dynamics Forecasting Using Task Inference",
    "descriptor": "",
    "authors": [
      "Rui Wang",
      "Robin Walters",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.10271"
  },
  {
    "id": "arXiv:2102.10884",
    "title": "Revisiting Classification Perspective on Scene Text Recognition",
    "abstract": "Comments: 10 pages, 4 figures",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Hongxiang Cai",
      "Jun Sun",
      "Yichao Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.10884"
  },
  {
    "id": "arXiv:2102.11005",
    "title": "LogME: Practical Assessment of Pre-trained Models for Transfer Learning",
    "abstract": "Comments: 13 pages (ICML 2021 camera ready version)",
    "descriptor": "\nComments: 13 pages (ICML 2021 camera ready version)\n",
    "authors": [
      "Kaichao You",
      "Yong Liu",
      "Mingsheng Long",
      "Jianmin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.11005"
  },
  {
    "id": "arXiv:2102.11592",
    "title": "Strategic Classification in the Dark",
    "abstract": "Strategic Classification in the Dark",
    "descriptor": "",
    "authors": [
      "Ganesh Ghalme",
      "Vineet Nair",
      "Itay Eilat",
      "Inbal Talgam-Cohen",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.11592"
  },
  {
    "id": "arXiv:2102.12013",
    "title": "Understanding and Mitigating Accuracy Disparity in Regression",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Jianfeng Chi",
      "Yuan Tian",
      "Geoffrey J. Gordon",
      "Han Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.12013"
  },
  {
    "id": "arXiv:2102.12668",
    "title": "Learning-based Robust Motion Planning with Guaranteed Stability: A  Contraction Theory Approach",
    "abstract": "Comments: IEEE Robotics and Automation Letters (RA-L), Accepted June 2021",
    "descriptor": "\nComments: IEEE Robotics and Automation Letters (RA-L), Accepted June 2021\n",
    "authors": [
      "Hiroyasu Tsukamoto",
      "Soon-Jo Chung"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.12668"
  },
  {
    "id": "arXiv:2103.00123",
    "title": "GRAD-MATCH: Gradient Matching based Data Subset Selection for Efficient  Deep Model Training",
    "abstract": "Comments: To appear in Proceedings of the 38 th International Conference on Machine Learning, PMLR 139, 2021",
    "descriptor": "\nComments: To appear in Proceedings of the 38 th International Conference on Machine Learning, PMLR 139, 2021\n",
    "authors": [
      "Krishnateja Killamsetty",
      "Durga Sivasubramanian",
      "Ganesh Ramakrishnan",
      "Abir De",
      "Rishabh Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00123"
  },
  {
    "id": "arXiv:2103.00164",
    "title": "FeatureNorm: L2 Feature Normalization for Dynamic Graph Embedding",
    "abstract": "Comments: ICDM 2020;",
    "descriptor": "\nComments: ICDM 2020;\n",
    "authors": [
      "Menglin Yang",
      "Ziqiao Meng",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2103.00164"
  },
  {
    "id": "arXiv:2103.01338",
    "title": "Acceleration via Fractal Learning Rate Schedules",
    "abstract": "Comments: v2: revisions for ICML 2021",
    "descriptor": "\nComments: v2: revisions for ICML 2021\n",
    "authors": [
      "Naman Agarwal",
      "Surbhi Goel",
      "Cyril Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.01338"
  },
  {
    "id": "arXiv:2103.01458",
    "title": "Diffusion Probabilistic Models for 3D Point Cloud Generation",
    "abstract": "Comments: Accepted to CVPR 2021",
    "descriptor": "\nComments: Accepted to CVPR 2021\n",
    "authors": [
      "Shitong Luo",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.01458"
  },
  {
    "id": "arXiv:2103.01638",
    "title": "Learning disentangled representations via product manifold projection",
    "abstract": "Comments: 15 pages, 10 figures",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Marco Fumero",
      "Luca Cosmo",
      "Simone Melzi",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01638"
  },
  {
    "id": "arXiv:2103.01826",
    "title": "Strategic Classification Made Practical",
    "abstract": "Strategic Classification Made Practical",
    "descriptor": "",
    "authors": [
      "Sagi Levanon",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2103.01826"
  },
  {
    "id": "arXiv:2103.02475",
    "title": "Non-Blockingness Verification of Bounded Petri Nets Using Basis  Reachability Graphs -- An Extended Version With Benchmarks",
    "abstract": "Comments: This article is an extended version of the paper \"C. Gu, Z. Ma, Z. Li and A. Giua. Non-blockingness verification of bounded Petri nets using basis reachability graphs. IEEE Control Systems Letters, doi:10.1109/LCSYS.2021.3087937, 2021\" with benchmarks",
    "descriptor": "\nComments: This article is an extended version of the paper \"C. Gu, Z. Ma, Z. Li and A. Giua. Non-blockingness verification of bounded Petri nets using basis reachability graphs. IEEE Control Systems Letters, doi:10.1109/LCSYS.2021.3087937, 2021\" with benchmarks\n",
    "authors": [
      "Chao Gu",
      "Ziyue Ma",
      "Zhiwu Li",
      "Alessandro Giua"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.02475"
  },
  {
    "id": "arXiv:2103.02700",
    "title": "Decoding supercodes of Gabidulin codes and applications to cryptanalysis",
    "abstract": "Comments: PQCrypto 2021. The Sage code is available on Github: this https URL",
    "descriptor": "\nComments: PQCrypto 2021. The Sage code is available on Github: this https URL\n",
    "authors": [
      "Maxime Bombar",
      "Alain Couvreur"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.02700"
  },
  {
    "id": "arXiv:2103.03212",
    "title": "Weisfeiler and Lehman Go Topological: Message Passing Simplicial  Networks",
    "abstract": "Comments: ICML 2021. Contains 27 pages, 9 figures",
    "descriptor": "\nComments: ICML 2021. Contains 27 pages, 9 figures\n",
    "authors": [
      "Cristian Bodnar",
      "Fabrizio Frasca",
      "Yu Guang Wang",
      "Nina Otter",
      "Guido Mont\u00fafar",
      "Pietro Li\u00f2",
      "Michael Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2103.03212"
  },
  {
    "id": "arXiv:2103.03216",
    "title": "Continuous Coordination As a Realistic Scenario for Lifelong Learning",
    "abstract": "Comments: 19 pages with supplementary materials. Added results for Lifelong RL methods and some future work. Accepted to ICML 2021",
    "descriptor": "\nComments: 19 pages with supplementary materials. Added results for Lifelong RL methods and some future work. Accepted to ICML 2021\n",
    "authors": [
      "Hadi Nekoei",
      "Akilesh Badrinaaraayanan",
      "Aaron Courville",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2103.03216"
  },
  {
    "id": "arXiv:2103.03230",
    "title": "Barlow Twins: Self-Supervised Learning via Redundancy Reduction",
    "abstract": "Comments: 13 pages, 6 figures, to appear at ICML 2021",
    "descriptor": "\nComments: 13 pages, 6 figures, to appear at ICML 2021\n",
    "authors": [
      "Jure Zbontar",
      "Li Jing",
      "Ishan Misra",
      "Yann LeCun",
      "St\u00e9phane Deny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2103.03230"
  },
  {
    "id": "arXiv:2103.03323",
    "title": "Distribution-free uncertainty quantification for classification under  label shift",
    "abstract": "Distribution-free uncertainty quantification for classification under  label shift",
    "descriptor": "",
    "authors": [
      "Aleksandr Podkopaev",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.03323"
  },
  {
    "id": "arXiv:2103.04850",
    "title": "Quantifying Ignorance in Individual-Level Causal-Effect Estimates under  Hidden Confounding",
    "abstract": "Comments: 19 pages, 5 figures, ICML 2021",
    "descriptor": "\nComments: 19 pages, 5 figures, ICML 2021\n",
    "authors": [
      "Andrew Jesson",
      "S\u00f6ren Mindermann",
      "Yarin Gal",
      "Uri Shalit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.04850"
  },
  {
    "id": "arXiv:2103.04941",
    "title": "InFillmore: Frame-Guided Language Generation with Bidirectional Context",
    "abstract": "Comments: Appearing in *SEM 2021",
    "descriptor": "\nComments: Appearing in *SEM 2021\n",
    "authors": [
      "Jiefu Ou",
      "Nathaniel Weir",
      "Anton Belyy",
      "Felix Yu",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.04941"
  },
  {
    "id": "arXiv:2103.05224",
    "title": "A review of flywheel energy storage systems: state of the art and  opportunities",
    "abstract": "A review of flywheel energy storage systems: state of the art and  opportunities",
    "descriptor": "",
    "authors": [
      "Xiaojun Li",
      "Alan Palazzolo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.05224"
  },
  {
    "id": "arXiv:2103.05331",
    "title": "Active Testing: Sample-Efficient Model Evaluation",
    "abstract": "Comments: Published at the 38th International Conference on Machine Learning (ICML 2021)",
    "descriptor": "\nComments: Published at the 38th International Conference on Machine Learning (ICML 2021)\n",
    "authors": [
      "Jannik Kossen",
      "Sebastian Farquhar",
      "Yarin Gal",
      "Tom Rainforth"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.05331"
  },
  {
    "id": "arXiv:2103.05632",
    "title": "Data-driven Prediction of General Hamiltonian Dynamics via Learning  Exactly-Symplectic Maps",
    "abstract": "Comments: 17 pages, 7 figures. ICML 2021",
    "descriptor": "\nComments: 17 pages, 7 figures. ICML 2021\n",
    "authors": [
      "Renyi Chen",
      "Molei Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2103.05632"
  },
  {
    "id": "arXiv:2103.07838",
    "title": "Cycle4Completion: Unpaired Point Cloud Completion using Cycle  Transformation with Missing Region Coding",
    "abstract": "Comments: Accepted to CVPR 2021",
    "descriptor": "\nComments: Accepted to CVPR 2021\n",
    "authors": [
      "Xin Wen",
      "Zhizhong Han",
      "Yan-Pei Cao",
      "Pengfei Wan",
      "Wen Zheng",
      "Yu-Shen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.07838"
  },
  {
    "id": "arXiv:2103.09284",
    "title": "Learning in Nonzero-Sum Stochastic Games with Potentials",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "David Mguni",
      "Yutong Wu",
      "Yali Du",
      "Yaodong Yang",
      "Ziyi Wang",
      "Minne Li",
      "Ying Wen",
      "Joel Jennings",
      "Jun Wang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2103.09284"
  },
  {
    "id": "arXiv:2103.09947",
    "title": "Understanding Generalization in Adversarial Training via the  Bias-Variance Decomposition",
    "abstract": "Comments: V2 adds new results and improves organization and presentation",
    "descriptor": "\nComments: V2 adds new results and improves organization and presentation\n",
    "authors": [
      "Yaodong Yu",
      "Zitong Yang",
      "Edgar Dobriban",
      "Jacob Steinhardt",
      "Yi Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.09947"
  },
  {
    "id": "arXiv:2103.10626",
    "title": "Cluster-to-Conquer: A Framework for End-to-End Multi-Instance Learning  for Whole Slide Image Classification",
    "abstract": "Comments: Accepted at MIDL, 2021 - this https URL",
    "descriptor": "\nComments: Accepted at MIDL, 2021 - this https URL\n",
    "authors": [
      "Yash Sharma",
      "Aman Shrivastava",
      "Lubaina Ehsan",
      "Christopher A. Moskaluk",
      "Sana Syed",
      "Donald E. Brown"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10626"
  },
  {
    "id": "arXiv:2103.10685",
    "title": "Controllable Generation from Pre-trained Language Models via Inverse  Prompting",
    "abstract": "Controllable Generation from Pre-trained Language Models via Inverse  Prompting",
    "descriptor": "",
    "authors": [
      "Xu Zou",
      "Da Yin",
      "Qingyang Zhong",
      "Ming Ding",
      "Zhilin Yang",
      "Jie Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10685"
  },
  {
    "id": "arXiv:2103.11244",
    "title": "On the Impossibility of Post-Quantum Black-Box Zero-Knowledge in  Constant Rounds",
    "abstract": "Comments: 46 pages",
    "descriptor": "\nComments: 46 pages\n",
    "authors": [
      "Nai-Hui Chia",
      "Kai-Min Chung",
      "Qipeng Liu",
      "Takashi Yamakawa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2103.11244"
  },
  {
    "id": "arXiv:2103.13308",
    "title": "Power Modeling for Effective Datacenter Planning and Compute Management",
    "abstract": "Power Modeling for Effective Datacenter Planning and Compute Management",
    "descriptor": "",
    "authors": [
      "Ana Radovanovic",
      "Bokan Chen",
      "Saurav Talukdar",
      "Binz Roy",
      "Alexandre Duarte",
      "Mahya Shahbazi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.13308"
  },
  {
    "id": "arXiv:2103.13740",
    "title": "ECG-TCN: Wearable Cardiac Arrhythmia Detection with a Temporal  Convolutional Network",
    "abstract": "Comments: 4 pages, 1 figure, 2 tables",
    "descriptor": "\nComments: 4 pages, 1 figure, 2 tables\n",
    "authors": [
      "Thorir Mar Ingolfsson",
      "Xiaying Wang",
      "Michael Hersche",
      "Alessio Burrello",
      "Lukas Cavigelli",
      "Luca Benini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.13740"
  },
  {
    "id": "arXiv:2103.13906",
    "title": "About exchanging expectation and supremum for conditional Wasserstein  GANs",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "J\u00f6rg Martin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.13906"
  },
  {
    "id": "arXiv:2103.14122",
    "title": "Private and Resource-Bounded Locally Decodable Codes for Insertions and  Deletions",
    "abstract": "Private and Resource-Bounded Locally Decodable Codes for Insertions and  Deletions",
    "descriptor": "",
    "authors": [
      "Alexander R. Block",
      "Jeremiah Blocki"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.14122"
  },
  {
    "id": "arXiv:2104.00203",
    "title": "AdaPool: A Diurnal-Adaptive Fleet Management Framework using Model-Free  Deep Reinforcement Learning and Change Point Detection",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2010.01755",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.01755\n",
    "authors": [
      "Marina Haliem",
      "Vaneet Aggarwal",
      "Bharat Bhargava"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2104.00203"
  },
  {
    "id": "arXiv:2104.00550",
    "title": "Agent-based simulations for protecting nursing homes with prevention and  vaccination strategies",
    "abstract": "Comments: Supplementary material is included in the manuscript PDF",
    "descriptor": "\nComments: Supplementary material is included in the manuscript PDF\n",
    "authors": [
      "Jana Lasser",
      "Johannes Zuber",
      "Johannes Sorger",
      "Elma Dervic",
      "Katharina Ledebur",
      "Simon David Lindner",
      "Elisabeth Klager",
      "Maria Klete\u010dka-Pulker",
      "Harald Willschke",
      "Katrin Stangl",
      "Sarah Stadtmann",
      "Christian Haslinger",
      "Peter Klimek",
      "Thomas Wochele-Thoma"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2104.00550"
  },
  {
    "id": "arXiv:2104.01320",
    "title": "An Empirical Study on Channel Effects for Synthetic Voice Spoofing  Countermeasure Systems",
    "abstract": "Comments: 5 pages, 6 figures, to appear in INTERSPEECH 2021",
    "descriptor": "\nComments: 5 pages, 6 figures, to appear in INTERSPEECH 2021\n",
    "authors": [
      "You Zhang",
      "Ge Zhu",
      "Fei Jiang",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2104.01320"
  },
  {
    "id": "arXiv:2104.01408",
    "title": "Reinforcement Learning for Emotional Text-to-Speech Synthesis with  Improved Emotion Discriminability",
    "abstract": "Comments: 5 pages, 4 figures, in Proceedings of INTERSPEECH 2021 conference, Speech Samples: this https URL",
    "descriptor": "\nComments: 5 pages, 4 figures, in Proceedings of INTERSPEECH 2021 conference, Speech Samples: this https URL\n",
    "authors": [
      "Rui Liu",
      "Berrak Sisman",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.01408"
  },
  {
    "id": "arXiv:2104.01440",
    "title": "COHORTNEY: Non-Parametric Clustering of Event Sequences",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Vladislav Zhuzhel",
      "Rodrigo Rivera-Castro",
      "Nina Kaploukhaya",
      "Liliya Mironova",
      "Alexey Zaytsev",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.01440"
  },
  {
    "id": "arXiv:2104.01714",
    "title": "Urysohn Forest for Aleatoric Uncertainty Quantification",
    "abstract": "Urysohn Forest for Aleatoric Uncertainty Quantification",
    "descriptor": "",
    "authors": [
      "Andrew Polar",
      "Michael Poluektov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.01714"
  },
  {
    "id": "arXiv:2104.02194",
    "title": "Contextualized Streaming End-to-End Speech Recognition with Trie-Based  Deep Biasing and Shallow Fusion",
    "abstract": "Comments: Accepted for presentation at INTERSPEECH 2021",
    "descriptor": "\nComments: Accepted for presentation at INTERSPEECH 2021\n",
    "authors": [
      "Duc Le",
      "Mahaveer Jain",
      "Gil Keren",
      "Suyoun Kim",
      "Yangyang Shi",
      "Jay Mahadeokar",
      "Julian Chan",
      "Yuan Shangguan",
      "Christian Fuegen",
      "Ozlem Kalinli",
      "Yatharth Saraf",
      "Michael L. Seltzer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.02194"
  },
  {
    "id": "arXiv:2104.02703",
    "title": "Adversarial Robustness under Long-Tailed Distribution",
    "abstract": "Comments: Accepted to CVPR 2021 (Oral)",
    "descriptor": "\nComments: Accepted to CVPR 2021 (Oral)\n",
    "authors": [
      "Tong Wu",
      "Ziwei Liu",
      "Qingqiu Huang",
      "Yu Wang",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.02703"
  },
  {
    "id": "arXiv:2104.02901",
    "title": "S2VC: A Framework for Any-to-Any Voice Conversion with Self-Supervised  Pretrained Representations",
    "abstract": "Comments: Accepted by INTERSPEECH 2021",
    "descriptor": "\nComments: Accepted by INTERSPEECH 2021\n",
    "authors": [
      "Jheng-hao Lin",
      "Yist Y. Lin",
      "Chung-Ming Chien",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2104.02901"
  },
  {
    "id": "arXiv:2104.03006",
    "title": "Librispeech Transducer Model with Internal Language Model Prior  Correction",
    "abstract": "Comments: accepted at Interspeech 2021",
    "descriptor": "\nComments: accepted at Interspeech 2021\n",
    "authors": [
      "Albert Zeyer",
      "Andr\u00e9 Merboldt",
      "Wilfried Michel",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.03006"
  },
  {
    "id": "arXiv:2104.03019",
    "title": "Human-Vehicle Cooperation on Prediction-Level: Enhancing Automated  Driving with Human Foresight",
    "abstract": "Human-Vehicle Cooperation on Prediction-Level: Enhancing Automated  Driving with Human Foresight",
    "descriptor": "",
    "authors": [
      "Chao Wang",
      "Thomas H. Weisswange",
      "Matti Krueger",
      "Christiane B. Wiebel-Herboth"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2104.03019"
  },
  {
    "id": "arXiv:2104.04654",
    "title": "Regression Networks For Calculating Englacial Layer Thickness",
    "abstract": "Regression Networks For Calculating Englacial Layer Thickness",
    "descriptor": "",
    "authors": [
      "Debvrat Varshney",
      "Maryam Rahnemoonfar",
      "Masoud Yari",
      "John Paden"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.04654"
  },
  {
    "id": "arXiv:2104.04657",
    "title": "Meta-Learning Bidirectional Update Rules",
    "abstract": "Comments: ICML 2021, 17 pages",
    "descriptor": "\nComments: ICML 2021, 17 pages\n",
    "authors": [
      "Mark Sandler",
      "Max Vladymyrov",
      "Andrey Zhmoginov",
      "Nolan Miller",
      "Andrew Jackson",
      "Tom Madams",
      "Blaise Aguera y Arcas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2104.04657"
  },
  {
    "id": "arXiv:2104.05017",
    "title": "Estimating articulatory movements in speech production with transformer  networks",
    "abstract": "Comments: accepted for oral presentation at INTERSPEECH 2021",
    "descriptor": "\nComments: accepted for oral presentation at INTERSPEECH 2021\n",
    "authors": [
      "Sathvik Udupa",
      "Anwesha Roy",
      "Abhayjeet Singh",
      "Aravind Illa",
      "Prasanta Kumar Ghosh"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2104.05017"
  },
  {
    "id": "arXiv:2104.05077",
    "title": "CoPE: Conditional image generation using Polynomial Expansions",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Grigorios G Chrysos",
      "Markos Georgopoulos",
      "Yannis Panagakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.05077"
  },
  {
    "id": "arXiv:2104.05632",
    "title": "Augmented World Models Facilitate Zero-Shot Dynamics Generalization From  a Single Offline Environment",
    "abstract": "Comments: Accepted @ ICML 2021; Spotlight @ ICLR 2021 \"Self-Supervision for Reinforcement Learning Workshop\"",
    "descriptor": "\nComments: Accepted @ ICML 2021; Spotlight @ ICLR 2021 \"Self-Supervision for Reinforcement Learning Workshop\"\n",
    "authors": [
      "Philip J. Ball",
      "Cong Lu",
      "Jack Parker-Holder",
      "Stephen Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.05632"
  },
  {
    "id": "arXiv:2104.05752",
    "title": "Speak or Chat with Me: End-to-End Spoken Language Understanding System  with Flexible Inputs",
    "abstract": "Comments: Accepted to Interspeech 2021",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Sujeong Cha",
      "Wangrui Hou",
      "Hyun Jung",
      "My Phung",
      "Michael Picheny",
      "Hong-Kwang Kuo",
      "Samuel Thomas",
      "Edmilson Morais"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.05752"
  },
  {
    "id": "arXiv:2104.06570",
    "title": "$q$-Polymatroids and Their Relation to Rank-Metric Codes",
    "abstract": "$q$-Polymatroids and Their Relation to Rank-Metric Codes",
    "descriptor": "",
    "authors": [
      "Heide Gluesing-Luerssen",
      "Benjamin Jany"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2104.06570"
  },
  {
    "id": "arXiv:2104.06648",
    "title": "Root-finding Approaches for Computing Conformal Prediction Set",
    "abstract": "Root-finding Approaches for Computing Conformal Prediction Set",
    "descriptor": "",
    "authors": [
      "Eugene Ndiaye",
      "Ichiro Takeuchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2104.06648"
  },
  {
    "id": "arXiv:2104.07639",
    "title": "Robust Optimization for Multilingual Translation with Imbalanced Data",
    "abstract": "Robust Optimization for Multilingual Translation with Imbalanced Data",
    "descriptor": "",
    "authors": [
      "Xian Li",
      "Hongyu Gong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07639"
  },
  {
    "id": "arXiv:2104.08593",
    "title": "SoK: Design Tools for Side-Channel-Aware Implementations",
    "abstract": "SoK: Design Tools for Side-Channel-Aware Implementations",
    "descriptor": "",
    "authors": [
      "Ileana Buhan",
      "Lejla Batina",
      "Yuval Yarom",
      "Patrick Schaumont"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.08593"
  },
  {
    "id": "arXiv:2104.08620",
    "title": "Decrypting Cryptic Crosswords: Semantically Complex Wordplay Puzzles as  a Target for NLP",
    "abstract": "Decrypting Cryptic Crosswords: Semantically Complex Wordplay Puzzles as  a Target for NLP",
    "descriptor": "",
    "authors": [
      "Josh Rozner",
      "Christopher Potts",
      "Kyle Mahowald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.08620"
  },
  {
    "id": "arXiv:2104.09261",
    "title": "Latent-Optimized Adversarial Neural Transfer for Sarcasm Detection",
    "abstract": "Comments: 14 pages, 5 figures, published at NAACL-HLT 2021 conference, see this https URL",
    "descriptor": "\nComments: 14 pages, 5 figures, published at NAACL-HLT 2021 conference, see this https URL\n",
    "authors": [
      "Xu Guo",
      "Boyang Li",
      "Han Yu",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.09261"
  },
  {
    "id": "arXiv:2104.10414",
    "title": "Orderly Dual-Teacher Knowledge Distillation for Lightweight Human Pose  Estimation",
    "abstract": "Orderly Dual-Teacher Knowledge Distillation for Lightweight Human Pose  Estimation",
    "descriptor": "",
    "authors": [
      "Zhong-Qiu Zhao",
      "Yao Gao",
      "Yuchen Ge",
      "Weidong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.10414"
  },
  {
    "id": "arXiv:2104.10683",
    "title": "Explainable artificial intelligence for mechanics: physics-informing  neural networks for constitutive models",
    "abstract": "Comments: Preprint - Rev-1 (minor grammatical changes; prevent Google from archiving)",
    "descriptor": "\nComments: Preprint - Rev-1 (minor grammatical changes; prevent Google from archiving)\n",
    "authors": [
      "Arnd Koeppe",
      "Franz Bamer",
      "Michael Selzer",
      "Britta Nestler",
      "Bernd Markert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.10683"
  },
  {
    "id": "arXiv:2104.10799",
    "title": "On Negative Dependence Properties of Latin Hypercube Samples and  Scrambled Nets",
    "abstract": "On Negative Dependence Properties of Latin Hypercube Samples and  Scrambled Nets",
    "descriptor": "",
    "authors": [
      "Benjamin Doerr",
      "Michael Gnewuch"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.10799"
  },
  {
    "id": "arXiv:2104.11014",
    "title": "Network Space Search for Pareto-Efficient Spaces",
    "abstract": "Comments: CVPR2021 Workshop (Efficient Deep Learning for Computer Vision). Website: this https URL",
    "descriptor": "\nComments: CVPR2021 Workshop (Efficient Deep Learning for Computer Vision). Website: this https URL\n",
    "authors": [
      "Min-Fong Hong",
      "Hao-Yun Chen",
      "Min-Hung Chen",
      "Yu-Syuan Xu",
      "Hsien-Kai Kuo",
      "Yi-Min Tsai",
      "Hung-Jen Chen",
      "Kevin Jou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.11014"
  },
  {
    "id": "arXiv:2104.12100",
    "title": "Multi-Scale Hourglass Hierarchical Fusion Network for Single Image  Deraining",
    "abstract": "Comments: Accepted in CVPRW 2021",
    "descriptor": "\nComments: Accepted in CVPRW 2021\n",
    "authors": [
      "Xiang Chen",
      "Yufeng Huang",
      "Lei Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.12100"
  },
  {
    "id": "arXiv:2104.12672",
    "title": "A Novel Interaction-based Methodology Towards Explainable AI with Better  Understanding of Pneumonia Chest X-ray Images",
    "abstract": "A Novel Interaction-based Methodology Towards Explainable AI with Better  Understanding of Pneumonia Chest X-ray Images",
    "descriptor": "",
    "authors": [
      "Shaw-Hwa Lo",
      "Yiqiao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2104.12672"
  },
  {
    "id": "arXiv:2104.13352",
    "title": "Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of  Red Fort Riots 2021",
    "abstract": "Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of  Red Fort Riots 2021",
    "descriptor": "",
    "authors": [
      "Ajay Agarwal",
      "Basant Agarwal"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.13352"
  },
  {
    "id": "arXiv:2104.13744",
    "title": "Bio-SODA: Enabling Natural Language Question Answering over Knowledge  Graphs without Training Data",
    "abstract": "Bio-SODA: Enabling Natural Language Question Answering over Knowledge  Graphs without Training Data",
    "descriptor": "",
    "authors": [
      "Ana Claudia Sima",
      "Tarcisio Mendes de Farias",
      "Maria Anisimova",
      "Christophe Dessimoz",
      "Marc Robinson-Rechavi",
      "Erich Zbinden",
      "Kurt Stockinger"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2104.13744"
  },
  {
    "id": "arXiv:2104.14461",
    "title": "Twin Systems for DeepCBR: A Menagerie of Deep Learning and Case-Based  Reasoning Pairings for Explanation and Data Augmentation",
    "abstract": "Comments: 7 pages,4 figures, 2 tables",
    "descriptor": "\nComments: 7 pages,4 figures, 2 tables\n",
    "authors": [
      "Mark T Keane",
      "Eoin M Kenny",
      "Mohammed Temraz",
      "Derek Greene",
      "Barry Smyth"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.14461"
  },
  {
    "id": "arXiv:2104.14470",
    "title": "Impact of Encoding and Segmentation Strategies on End-to-End  Simultaneous Speech Translation",
    "abstract": "Comments: Accepted for presentation at Interspeech 2021",
    "descriptor": "\nComments: Accepted for presentation at Interspeech 2021\n",
    "authors": [
      "Ha Nguyen",
      "Yannick Est\u00e8ve",
      "Laurent Besacier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.14470"
  },
  {
    "id": "arXiv:2105.00268",
    "title": "Lite-FPN for Keypoint-based Monocular 3D Object Detection",
    "abstract": "Comments: 11 pages, 4 figures",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Lei Yang",
      "Xinyu Zhang",
      "Li Wang",
      "Minghan Zhu",
      "Jun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.00268"
  },
  {
    "id": "arXiv:2105.00455",
    "title": "Synthesized Difference in Differences",
    "abstract": "Comments: Accepted to ACM BCB 2021",
    "descriptor": "\nComments: Accepted to ACM BCB 2021\n",
    "authors": [
      "Eric V. Strobl",
      "Thomas A. Lasko"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.00455"
  },
  {
    "id": "arXiv:2105.00648",
    "title": "A novel hybrid methodology of measuring sentence similarity",
    "abstract": "A novel hybrid methodology of measuring sentence similarity",
    "descriptor": "",
    "authors": [
      "Yongmin Yoo",
      "Tak-Sung Heo",
      "Yeongjoon Park"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.00648"
  },
  {
    "id": "arXiv:2105.00793",
    "title": "Tubal Matrices",
    "abstract": "Tubal Matrices",
    "descriptor": "",
    "authors": [
      "Liqun Qi",
      "Ziyan Luo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.00793"
  },
  {
    "id": "arXiv:2105.00885",
    "title": "Generating Extended Resolution Proofs with a BDD-Based SAT Solver",
    "abstract": "Comments: Extended version of paper published at TACAS 2021",
    "descriptor": "\nComments: Extended version of paper published at TACAS 2021\n",
    "authors": [
      "Randal E. Bryant",
      "Marijn J. H. Heule"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.00885"
  },
  {
    "id": "arXiv:2105.00981",
    "title": "Russian News Clustering and Headline Selection Shared Task",
    "abstract": "Comments: Accepted to Dialogue 2021 conference",
    "descriptor": "\nComments: Accepted to Dialogue 2021 conference\n",
    "authors": [
      "Ilya Gusev",
      "Ivan Smurov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.00981"
  },
  {
    "id": "arXiv:2105.02266",
    "title": "Randomized Stochastic Variance-Reduced Methods for Multi-Task Stochastic  Bilevel Optimization",
    "abstract": "Randomized Stochastic Variance-Reduced Methods for Multi-Task Stochastic  Bilevel Optimization",
    "descriptor": "",
    "authors": [
      "Zhishuai Guo",
      "Quanqi Hu",
      "Lijun Zhang",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.02266"
  },
  {
    "id": "arXiv:2105.03052",
    "title": "Informational Design of Dynamic Multi-Agent System",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2102.07152",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2102.07152\n",
    "authors": [
      "Tao Zhang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03052"
  },
  {
    "id": "arXiv:2105.03743",
    "title": "Certified Robustness to Text Adversarial Attacks by Randomized [MASK]",
    "abstract": "Certified Robustness to Text Adversarial Attacks by Randomized [MASK]",
    "descriptor": "",
    "authors": [
      "Jiehang Zeng",
      "Xiaoqing Zheng",
      "Jianhan Xu",
      "Linyang Li",
      "Liping Yuan",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03743"
  },
  {
    "id": "arXiv:2105.03773",
    "title": "Separations for Estimating Large Frequency Moments on Data Streams",
    "abstract": "Comments: ICALP 2021",
    "descriptor": "\nComments: ICALP 2021\n",
    "authors": [
      "David P. Woodruff",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.03773"
  },
  {
    "id": "arXiv:2105.03818",
    "title": "Heterogeneous Risk Minimization",
    "abstract": "Comments: Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021. (ICML2021)",
    "descriptor": "\nComments: Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021. (ICML2021)\n",
    "authors": [
      "Jiashuo Liu",
      "Zheyuan Hu",
      "Peng Cui",
      "Bo Li",
      "Zheyan Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03818"
  },
  {
    "id": "arXiv:2105.03821",
    "title": "Graph Inference Representation: Learning Graph Positional Embeddings  with Anchor Path Encoding",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Yuheng Lu",
      "Jinpeng Chen",
      "ChuXiong Sun",
      "Jie Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03821"
  },
  {
    "id": "arXiv:2105.04779",
    "title": "EL-Attention: Memory Efficient Lossless Attention for Generation",
    "abstract": "Comments: ICML 2021. Version 2: add pseudocode",
    "descriptor": "\nComments: ICML 2021. Version 2: add pseudocode\n",
    "authors": [
      "Yu Yan",
      "Jiusheng Chen",
      "Weizhen Qi",
      "Nikhil Bhendawade",
      "Yeyun Gong",
      "Nan Duan",
      "Ruofei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04779"
  },
  {
    "id": "arXiv:2105.05366",
    "title": "Rearrangement on Lattices with Pick-n-Swaps: Optimality Structures and  Efficient Algorithms",
    "abstract": "Comments: To appear in R:SS 2021",
    "descriptor": "\nComments: To appear in R:SS 2021\n",
    "authors": [
      "Jingjin Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.05366"
  },
  {
    "id": "arXiv:2105.05980",
    "title": "DONet: Dual-Octave Network for Fast MR Image Reconstruction",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2104.05345",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2104.05345\n",
    "authors": [
      "Chun-Mei Feng",
      "Zhanyuan Yang",
      "Huazhu Fu",
      "Yong Xu",
      "Jian Yang",
      "Ling Shao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.05980"
  },
  {
    "id": "arXiv:2105.06548",
    "title": "Not All Memories are Created Equal: Learning to Forget by Expiring",
    "abstract": "Not All Memories are Created Equal: Learning to Forget by Expiring",
    "descriptor": "",
    "authors": [
      "Sainbayar Sukhbaatar",
      "Da Ju",
      "Spencer Poff",
      "Stephen Roller",
      "Arthur Szlam",
      "Jason Weston",
      "Angela Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.06548"
  },
  {
    "id": "arXiv:2105.08266",
    "title": "Label Inference Attacks from Log-loss Scores",
    "abstract": "Comments: Accepted at ICML 2021",
    "descriptor": "\nComments: Accepted at ICML 2021\n",
    "authors": [
      "Abhinav Aggarwal",
      "Shiva Prasad Kasiviswanathan",
      "Zekun Xu",
      "Oluwaseyi Feyisetan",
      "Nathanael Teissier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08266"
  },
  {
    "id": "arXiv:2105.08633",
    "title": "PDE-constrained Models with Neural Network Terms: Optimization and  Global Convergence",
    "abstract": "PDE-constrained Models with Neural Network Terms: Optimization and  Global Convergence",
    "descriptor": "",
    "authors": [
      "Justin Sirignano",
      "Jonathan MacArt",
      "Konstantinos Spiliopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08633"
  },
  {
    "id": "arXiv:2105.08645",
    "title": "CoTexT: Multi-task Learning with Code-Text Transformer",
    "abstract": "CoTexT: Multi-task Learning with Code-Text Transformer",
    "descriptor": "",
    "authors": [
      "Long Phan",
      "Hieu Tran",
      "Daniel Le",
      "Hieu Nguyen",
      "James Anibal",
      "Alec Peltekian",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.08645"
  },
  {
    "id": "arXiv:2105.08949",
    "title": "Multi-Contrast MRI Super-Resolution via a Multi-Stage Integration  Network",
    "abstract": "Comments: 10 pages, 3 figures",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Chun-Mei Feng",
      "Huazhu Fu",
      "Shuhao Yuan",
      "Yong Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.08949"
  },
  {
    "id": "arXiv:2105.09157",
    "title": "Hunter in the Dark: Discover Anomalous Network Activity Using Deep  Ensemble Network",
    "abstract": "Hunter in the Dark: Discover Anomalous Network Activity Using Deep  Ensemble Network",
    "descriptor": "",
    "authors": [
      "Shiyi Yang",
      "Nour Moustafa",
      "Peilun Wu",
      "Hui Guo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.09157"
  },
  {
    "id": "arXiv:2105.09356",
    "title": "Generative Adversarial Neural Architecture Search",
    "abstract": "Comments: 17 pages, 9 figures, 13 Tables",
    "descriptor": "\nComments: 17 pages, 9 figures, 13 Tables\n",
    "authors": [
      "Seyed Saeed Changiz Rezaei",
      "Fred X. Han",
      "Di Niu",
      "Mohammad Salameh",
      "Keith Mills",
      "Shuo Lian",
      "Wei Lu",
      "Shangling Jui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.09356"
  },
  {
    "id": "arXiv:2105.09369",
    "title": "User Label Leakage from Gradients in Federated Learning",
    "abstract": "User Label Leakage from Gradients in Federated Learning",
    "descriptor": "",
    "authors": [
      "Aidmar Wainakh",
      "Fabrizio Ventola",
      "Till M\u00fc\u00dfig",
      "Jens Keim",
      "Carlos Garcia Cordero",
      "Ephraim Zimmer",
      "Tim Grube",
      "Kristian Kersting",
      "Max M\u00fchlh\u00e4user"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09369"
  },
  {
    "id": "arXiv:2105.09970",
    "title": "Forest languages defined by counting maximal paths",
    "abstract": "Comments: The proof of the main Lemma (3.11, section 3.4) is incomplete: in the middle of page 22, the fact that $\\gamma$ is weakly distributive is not sufficient to justify the chain of two inclusions used to invoke Proposition 2.1",
    "descriptor": "\nComments: The proof of the main Lemma (3.11, section 3.4) is incomplete: in the middle of page 22, the fact that $\\gamma$ is weakly distributive is not sufficient to justify the chain of two inclusions used to invoke Proposition 2.1\n",
    "authors": [
      "Martin Beaudry"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.09970"
  },
  {
    "id": "arXiv:2105.10255",
    "title": "Computing the dimension of real algebraic sets",
    "abstract": "Comments: v2: title change",
    "descriptor": "\nComments: v2: title change\n",
    "authors": [
      "Piere Lairez",
      "Mohab Safey El Din"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2105.10255"
  },
  {
    "id": "arXiv:2105.10440",
    "title": "Nori: Concealing the Concealed Identifier in 5G",
    "abstract": "Comments: 9 pages, 8 figures, 1 table",
    "descriptor": "\nComments: 9 pages, 8 figures, 1 table\n",
    "authors": [
      "John Preu\u00df Mattsson",
      "Prajwol Kumar Nakarmi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.10440"
  },
  {
    "id": "arXiv:2105.10620",
    "title": "HPNet: Deep Primitive Segmentation Using Hybrid Representations",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Siming Yan",
      "Zhenpei Yang",
      "Chongyang Ma",
      "Haibin Huang",
      "Etienne Vouga",
      "Qixing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.10620"
  },
  {
    "id": "arXiv:2105.10682",
    "title": "Feasible Actor-Critic: Constrained Reinforcement Learning for Ensuring  Statewise Safety",
    "abstract": "Feasible Actor-Critic: Constrained Reinforcement Learning for Ensuring  Statewise Safety",
    "descriptor": "",
    "authors": [
      "Haitong Ma",
      "Yang Guan",
      "Shegnbo Eben Li",
      "Xiangteng Zhang",
      "Sifa Zheng",
      "Jianyu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10682"
  },
  {
    "id": "arXiv:2105.10879",
    "title": "Precise Approximation of Convolutional Neural Networks for  Homomorphically Encrypted Data",
    "abstract": "Comments: Typos corrected, supplementary added",
    "descriptor": "\nComments: Typos corrected, supplementary added\n",
    "authors": [
      "Junghyun Lee",
      "Eunsang Lee",
      "Joon-Woo Lee",
      "Yongjune Kim",
      "Young-Sik Kim",
      "Jong-Seon No"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.10879"
  },
  {
    "id": "arXiv:2105.11367",
    "title": "FedScale: Benchmarking Model and System Performance of Federated  Learning",
    "abstract": "FedScale: Benchmarking Model and System Performance of Federated  Learning",
    "descriptor": "",
    "authors": [
      "Fan Lai",
      "Yinwei Dai",
      "Xiangfeng Zhu",
      "Mosharaf Chowdhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.11367"
  },
  {
    "id": "arXiv:2105.11417",
    "title": "Skew Orthogonal Convolutions",
    "abstract": "Comments: Accepted at ICML, 2021",
    "descriptor": "\nComments: Accepted at ICML, 2021\n",
    "authors": [
      "Sahil Singla",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11417"
  },
  {
    "id": "arXiv:2105.11688",
    "title": "A Configuration Model with Triadic Closure",
    "abstract": "A Configuration Model with Triadic Closure",
    "descriptor": "",
    "authors": [
      "Ruhui Chang",
      "Duan-Shin Lee",
      "Cheng-Shang Chang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.11688"
  },
  {
    "id": "arXiv:2105.11982",
    "title": "Quantifying Uncertainty in Deep Spatiotemporal Forecasting",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2102.06684",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.06684\n",
    "authors": [
      "Dongxia Wu",
      "Liyao Gao",
      "Xinyue Xiong",
      "Matteo Chinazzi",
      "Alessandro Vespignani",
      "Yi-An Ma",
      "Rose Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.11982"
  },
  {
    "id": "arXiv:2105.12856",
    "title": "Beyond Algorithmic Bias: A Socio-Computational Interrogation of the  Google Search by Image Algorithm",
    "abstract": "Beyond Algorithmic Bias: A Socio-Computational Interrogation of the  Google Search by Image Algorithm",
    "descriptor": "",
    "authors": [
      "Orestis Papakyriakopoulos",
      "Arwa Michelle Mboya"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.12856"
  },
  {
    "id": "arXiv:2105.12924",
    "title": "Self-Ensembling Contrastive Learning for Semi-Supervised Medical Image  Segmentation",
    "abstract": "Self-Ensembling Contrastive Learning for Semi-Supervised Medical Image  Segmentation",
    "descriptor": "",
    "authors": [
      "Jinxi Xiang",
      "Zhuowei Li",
      "Wenji Wang",
      "Qing Xia",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.12924"
  },
  {
    "id": "arXiv:2105.13010",
    "title": "An error analysis of generative adversarial networks for learning  distributions",
    "abstract": "An error analysis of generative adversarial networks for learning  distributions",
    "descriptor": "",
    "authors": [
      "Jian Huang",
      "Yuling Jiao",
      "Zhen Li",
      "Shiao Liu",
      "Yang Wang",
      "Yunfei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13010"
  },
  {
    "id": "arXiv:2105.13096",
    "title": "Lattice-Based Minimum-Distortion Data Hiding",
    "abstract": "Comments: 5 pages, to appear in IEEE communications letters",
    "descriptor": "\nComments: 5 pages, to appear in IEEE communications letters\n",
    "authors": [
      "Jieni Lin",
      "Junren Qin",
      "Shanxiang Lyu",
      "Bingwen Feng",
      "Jiabo Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2105.13096"
  },
  {
    "id": "arXiv:2105.13648",
    "title": "Cross-Lingual Abstractive Summarization with Limited Parallel Resources",
    "abstract": "Comments: Accepted by ACL 2021",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Yu Bai",
      "Yang Gao",
      "Heyan Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13648"
  },
  {
    "id": "arXiv:2105.13856",
    "title": "Lightweight Cross-Lingual Sentence Representation Learning",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Zhuoyuan Mao",
      "Prakhar Gupta",
      "Chenhui Chu",
      "Martin Jaggi",
      "Sadao Kurohashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13856"
  },
  {
    "id": "arXiv:2105.13878",
    "title": "Accelerating BERT Inference for Sequence Labeling via Early-Exit",
    "abstract": "Comments: Accepted to the ACL 2021",
    "descriptor": "\nComments: Accepted to the ACL 2021\n",
    "authors": [
      "Xiaonan Li",
      "Yunfan Shao",
      "Tianxiang Sun",
      "Hang Yan",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13878"
  },
  {
    "id": "arXiv:2105.14152",
    "title": "Radar Odometry Combining Probabilistic Estimation and Unsupervised  Feature Learning",
    "abstract": "Comments: Accepted to Robotics Science and Systems 2021",
    "descriptor": "\nComments: Accepted to Robotics Science and Systems 2021\n",
    "authors": [
      "Keenan Burnett",
      "David J. Yoon",
      "Angela P. Schoellig",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14152"
  },
  {
    "id": "arXiv:2105.14188",
    "title": "We Know What You Want: An Advertising Strategy Recommender System for  Online Advertising",
    "abstract": "We Know What You Want: An Advertising Strategy Recommender System for  Online Advertising",
    "descriptor": "",
    "authors": [
      "Liyi Guo",
      "Junqi Jin",
      "Haoqi Zhang",
      "Zhenzhe Zheng",
      "Zhiye Yang",
      "Zhizhuang Xing",
      "Fei Pan",
      "Lvyin Niu",
      "Fan Wu",
      "Haiyang Xu",
      "Chuan Yu",
      "Yuning Jiang",
      "Xiaoqiang Zhu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14188"
  },
  {
    "id": "arXiv:2105.14710",
    "title": "Robustifying $\\ell_\\infty$ Adversarial Training to the Union of  Perturbation Models",
    "abstract": "Robustifying $\\ell_\\infty$ Adversarial Training to the Union of  Perturbation Models",
    "descriptor": "",
    "authors": [
      "Ameya D. Patil",
      "Michael Tuttle",
      "Alexander G. Schwing",
      "Naresh R. Shanbhag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14710"
  },
  {
    "id": "arXiv:2105.15039",
    "title": "Sequenceable Event Recorders",
    "abstract": "Sequenceable Event Recorders",
    "descriptor": "",
    "authors": [
      "Luca Cardelli"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2105.15039"
  },
  {
    "id": "arXiv:2105.15082",
    "title": "Exploring Sparse Expert Models and Beyond",
    "abstract": "Comments: 16 pages, 8 figures",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "An Yang",
      "Junyang Lin",
      "Rui Men",
      "Chang Zhou",
      "Le Jiang",
      "Xianyan Jia",
      "Ang Wang",
      "Jie Zhang",
      "Jiamang Wang",
      "Yong Li",
      "Di Zhang",
      "Wei Lin",
      "Lin Qu",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.15082"
  },
  {
    "id": "arXiv:2105.15134",
    "title": "Toward Understanding the Feature Learning Process of Self-supervised  Contrastive Learning",
    "abstract": "Comments: V2 polished writing and added citations. Accepted to ICML2021",
    "descriptor": "\nComments: V2 polished writing and added citations. Accepted to ICML2021\n",
    "authors": [
      "Zixin Wen",
      "Yuanzhi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.15134"
  },
  {
    "id": "arXiv:2106.00273",
    "title": "Improving the Adversarial Robustness for Speaker Verification by  Self-Supervised Learning",
    "abstract": "Comments: Submitted to TASLP on 19 April 2021",
    "descriptor": "\nComments: Submitted to TASLP on 19 April 2021\n",
    "authors": [
      "Haibin Wu",
      "Xu Li",
      "Andy T. Liu",
      "Zhiyong Wu",
      "Helen Meng",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00273"
  },
  {
    "id": "arXiv:2106.00305",
    "title": "Independent Prototype Propagation for Zero-Shot Compositionality",
    "abstract": "Independent Prototype Propagation for Zero-Shot Compositionality",
    "descriptor": "",
    "authors": [
      "Frank Ruis",
      "Gertjan Burghouts",
      "Doina Bucur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00305"
  },
  {
    "id": "arXiv:2106.00467",
    "title": "The zoo of Fairness metrics in Machine Learning",
    "abstract": "Comments: 17 pages, 6 figures",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Alessandro Castelnovo",
      "Riccardo Crupi",
      "Greta Greco",
      "Daniele Regoli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00467"
  },
  {
    "id": "arXiv:2106.00671",
    "title": "What Can I Do Here? Learning New Skills by Imagining Visual Affordances",
    "abstract": "Comments: 10 pages, 10 figures. Presented at ICRA 2021. Project website: this https URL",
    "descriptor": "\nComments: 10 pages, 10 figures. Presented at ICRA 2021. Project website: this https URL\n",
    "authors": [
      "Alexander Khazatsky",
      "Ashvin Nair",
      "Daniel Jing",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00671"
  },
  {
    "id": "arXiv:2106.00922",
    "title": "An Empirical Comparison of Off-policy Prediction Learning Algorithms on  the Collision Task",
    "abstract": "An Empirical Comparison of Off-policy Prediction Learning Algorithms on  the Collision Task",
    "descriptor": "",
    "authors": [
      "Sina Ghiassian",
      "Richard S. Sutton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00922"
  },
  {
    "id": "arXiv:2106.00961",
    "title": "Distributed Control-Estimation Synthesis for Stochastic Multi-Agent  Systems via Virtual Interaction between Non-neighboring Agents",
    "abstract": "Comments: 13 pages, 5 figures, to be published in IEEE/Control Systems Letters (L-CSS)",
    "descriptor": "\nComments: 13 pages, 5 figures, to be published in IEEE/Control Systems Letters (L-CSS)\n",
    "authors": [
      "Hojin Lee",
      "Cheolhyeon Kwon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00961"
  },
  {
    "id": "arXiv:2106.01726",
    "title": "Exploiting co-execution with oneAPI: heterogeneity from a modern  perspective",
    "abstract": "Comments: Accepted in Euro-Par 2021 (27th International Conference on Parallel and Distributed Computing). 16 pages, 9 figures, 1 listing. Conference paper - extended with API",
    "descriptor": "\nComments: Accepted in Euro-Par 2021 (27th International Conference on Parallel and Distributed Computing). 16 pages, 9 figures, 1 listing. Conference paper - extended with API\n",
    "authors": [
      "Ra\u00fal Nozal",
      "Jose Luis Bosque"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.01726"
  },
  {
    "id": "arXiv:2106.01797",
    "title": "TVDIM: Enhancing Image Self-Supervised Pretraining via Noisy Text Data",
    "abstract": "TVDIM: Enhancing Image Self-Supervised Pretraining via Noisy Text Data",
    "descriptor": "",
    "authors": [
      "Pengda Qin",
      "Yuhong Li",
      "Kefeng Deng",
      "Qiang Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01797"
  },
  {
    "id": "arXiv:2106.02096",
    "title": "Shape-Preserving Dimensionality Reduction : An Algorithm and Measures of  Topological Equivalence",
    "abstract": "Comments: 18 pages, 2 figures",
    "descriptor": "\nComments: 18 pages, 2 figures\n",
    "authors": [
      "Byeongsu Yu",
      "Kisung You"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02096"
  },
  {
    "id": "arXiv:2106.02245",
    "title": "Towards offensive language detection and reduction in four Software  Engineering communities",
    "abstract": "Towards offensive language detection and reduction in four Software  Engineering communities",
    "descriptor": "",
    "authors": [
      "Jithin Cheriyan",
      "Bastin Tony Roy Savarimuthu",
      "Stephen Cranefield"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.02245"
  },
  {
    "id": "arXiv:2106.02297",
    "title": "Fre-GAN: Adversarial Frequency-consistent Audio Synthesis",
    "abstract": "Comments: Accepted paper in Interspeech 2021",
    "descriptor": "\nComments: Accepted paper in Interspeech 2021\n",
    "authors": [
      "Ji-Hoon Kim",
      "Sang-Hoon Lee",
      "Ji-Hyun Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02297"
  },
  {
    "id": "arXiv:2106.02391",
    "title": "Data-Driven Control Design with LMIs and Dynamic Programming",
    "abstract": "Data-Driven Control Design with LMIs and Dynamic Programming",
    "descriptor": "",
    "authors": [
      "Donghwan Lee",
      "Do Wan Kim"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02391"
  },
  {
    "id": "arXiv:2106.02549",
    "title": "Detect the Interactions that Matter in Matter: Geometric Attention for  Many-Body Systems",
    "abstract": "Detect the Interactions that Matter in Matter: Geometric Attention for  Many-Body Systems",
    "descriptor": "",
    "authors": [
      "Thorben Frank",
      "Stefan Chmiela"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.02549"
  },
  {
    "id": "arXiv:2106.02556",
    "title": "Musical Prosody-Driven Emotion Classification: Interpreting Vocalists  Portrayal of Emotions Through Machine Learning",
    "abstract": "Musical Prosody-Driven Emotion Classification: Interpreting Vocalists  Portrayal of Emotions Through Machine Learning",
    "descriptor": "",
    "authors": [
      "Nicholas Farris",
      "Brian Model",
      "Richard Savery",
      "Gil Weinberg"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.02556"
  },
  {
    "id": "arXiv:2106.02604",
    "title": "Does Persuasive Technology Make Smartphones More Addictive? -- An  Empirical Study of Chinese University Students",
    "abstract": "Does Persuasive Technology Make Smartphones More Addictive? -- An  Empirical Study of Chinese University Students",
    "descriptor": "",
    "authors": [
      "Xiaowei Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.02604"
  },
  {
    "id": "arXiv:2106.02639",
    "title": "Singular Dynamic Mode Decompositions",
    "abstract": "Comments: 11 pages. YouTube playlist supporting this manuscript can be found here: this https URL",
    "descriptor": "\nComments: 11 pages. YouTube playlist supporting this manuscript can be found here: this https URL\n",
    "authors": [
      "Joel A. Rosenfeld",
      "Rushikesh Kamalapurkar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02639"
  },
  {
    "id": "arXiv:2106.02968",
    "title": "Low Budget Active Learning via Wasserstein Distance: An Integer  Programming Approach",
    "abstract": "Low Budget Active Learning via Wasserstein Distance: An Integer  Programming Approach",
    "descriptor": "",
    "authors": [
      "Rafid Mahmood",
      "Sanja Fidler",
      "Marc T. Law"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.02968"
  },
  {
    "id": "arXiv:2106.03039",
    "title": "Multi-facet Contextual Bandits: A Neural Network Perspective",
    "abstract": "Comments: KDD'21, 11 pages",
    "descriptor": "\nComments: KDD'21, 11 pages\n",
    "authors": [
      "Yikun Ban",
      "Jingrui He",
      "Curtiss B. Cook"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03039"
  },
  {
    "id": "arXiv:2106.03107",
    "title": "New complexity results and algorithms for min-max-min robust  combinatorial optimization",
    "abstract": "New complexity results and algorithms for min-max-min robust  combinatorial optimization",
    "descriptor": "",
    "authors": [
      "Jannis Kurtz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.03107"
  },
  {
    "id": "arXiv:2106.03153",
    "title": "Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation",
    "abstract": "Comments: Accepted by ICML 2021",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Dongchan Min",
      "Dong Bok Lee",
      "Eunho Yang",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.03153"
  },
  {
    "id": "arXiv:2106.03207",
    "title": "Mitigating Covariate Shift in Imitation Learning via Offline Data  Without Great Coverage",
    "abstract": "Comments: 42 pages, 5 figures, 7 tables",
    "descriptor": "\nComments: 42 pages, 5 figures, 7 tables\n",
    "authors": [
      "Jonathan D. Chang",
      "Masatoshi Uehara",
      "Dhruv Sreenivas",
      "Rahul Kidambi",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03207"
  },
  {
    "id": "arXiv:2106.03210",
    "title": "Alpha Matte Generation from Single Input for Portrait Matting",
    "abstract": "Alpha Matte Generation from Single Input for Portrait Matting",
    "descriptor": "",
    "authors": [
      "Dogucan Yaman",
      "Haz\u0131m Kemal Ekenel",
      "Alexander Waibel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03210"
  },
  {
    "id": "arXiv:2106.03279",
    "title": "Learning MDPs from Features: Predict-Then-Optimize for Sequential  Decision Problems by Reinforcement Learning",
    "abstract": "Learning MDPs from Features: Predict-Then-Optimize for Sequential  Decision Problems by Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Kai Wang",
      "Sanket Shah",
      "Haipeng Chen",
      "Andrew Perrault",
      "Finale Doshi-Velez",
      "Milind Tambe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03279"
  },
  {
    "id": "arXiv:2106.03469",
    "title": "Multilingual Neural Semantic Parsing for Low-Resourced Languages",
    "abstract": "Comments: Accepted at *SEM2021",
    "descriptor": "\nComments: Accepted at *SEM2021\n",
    "authors": [
      "Menglin Xia",
      "Emilio Monti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.03469"
  },
  {
    "id": "arXiv:2106.03569",
    "title": "Socially-Aware Self-Supervised Tri-Training for Recommendation",
    "abstract": "Comments: 9 pages, accepted by KDD'21",
    "descriptor": "\nComments: 9 pages, accepted by KDD'21\n",
    "authors": [
      "Junliang Yu",
      "Hongzhi Yin",
      "Min Gao",
      "Xin Xia",
      "Xiangliang Zhang",
      "Nguyen Quoc Viet Hung"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.03569"
  },
  {
    "id": "arXiv:2106.03840",
    "title": "Balancing Garbage Collection vs I/O Amplification using hybrid Key-Value  Placement in LSM-based Key-Value Stores",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Giorgos Xanthakis",
      "Giorgos Saloustros",
      "Nikos Batsaras",
      "Anastasios Papagiannis",
      "Angelos Bilas"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.03840"
  },
  {
    "id": "arXiv:2106.03954",
    "title": "Evaluating Meta-Feature Selection for the Algorithm Recommendation  Problem",
    "abstract": "Evaluating Meta-Feature Selection for the Algorithm Recommendation  Problem",
    "descriptor": "",
    "authors": [
      "Geand Trindade Pereira",
      "Moises Rocha dos Santos",
      "Andre Carlos Ponce de Leon Ferreira de Carvalho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.03954"
  },
  {
    "id": "arXiv:2106.04067",
    "title": "LocalTrans: A Multiscale Local Transformer Network for Cross-Resolution  Homography Estimation",
    "abstract": "LocalTrans: A Multiscale Local Transformer Network for Cross-Resolution  Homography Estimation",
    "descriptor": "",
    "authors": [
      "Ruizhi Shao",
      "Gaochang Wu",
      "Yuemei Zhou",
      "Ying Fu",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04067"
  },
  {
    "id": "arXiv:2106.04102",
    "title": "Swords: A Benchmark for Lexical Substitution with Improved Data Coverage  and Quality",
    "abstract": "Comments: Published as a conference paper at NAACL 2021",
    "descriptor": "\nComments: Published as a conference paper at NAACL 2021\n",
    "authors": [
      "Mina Lee",
      "Chris Donahue",
      "Robin Jia",
      "Alexander Iyabor",
      "Percy Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.04102"
  },
  {
    "id": "arXiv:2106.04179",
    "title": "Deterministic $(1+\\varepsilon)$-Approximate Maximum Matching with  $\\mathsf{poly}(1/\\varepsilon)$ Passes in the Semi-Streaming Model",
    "abstract": "Deterministic $(1+\\varepsilon)$-Approximate Maximum Matching with  $\\mathsf{poly}(1/\\varepsilon)$ Passes in the Semi-Streaming Model",
    "descriptor": "",
    "authors": [
      "Manuela Fischer",
      "Slobodan Mitrovi\u0107",
      "Jara Uitto"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.04179"
  },
  {
    "id": "arXiv:2106.04289",
    "title": "Morphing tree drawings in a small 3D grid",
    "abstract": "Comments: 30 pages, corrected version",
    "descriptor": "\nComments: 30 pages, corrected version\n",
    "authors": [
      "Elena Arseneva",
      "Rahul Gangopadhyay",
      "Aleksandra Istomina"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.04289"
  },
  {
    "id": "arXiv:2106.04292",
    "title": "Principled Hyperedge Prediction with Structural Spectral Features and  Neural Networks",
    "abstract": "Principled Hyperedge Prediction with Structural Spectral Features and  Neural Networks",
    "descriptor": "",
    "authors": [
      "Changlin Wan",
      "Muhan Zhang",
      "Wei Hao",
      "Sha Cao",
      "Pan Li",
      "Chi Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04292"
  },
  {
    "id": "arXiv:2106.04392",
    "title": "Signal Transformer: Complex-valued Attention and Meta-Learning for  Signal Recognition",
    "abstract": "Signal Transformer: Complex-valued Attention and Meta-Learning for  Signal Recognition",
    "descriptor": "",
    "authors": [
      "Yihong Dong",
      "Ying Peng",
      "Muqiao Yang",
      "Songtao Lu",
      "Qingjiang Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.04392"
  },
  {
    "id": "arXiv:2106.04476",
    "title": "One Semantic Parser to Parse Them All: Sequence to Sequence Multi-Task  Learning on Semantic Parsing Datasets",
    "abstract": "One Semantic Parser to Parse Them All: Sequence to Sequence Multi-Task  Learning on Semantic Parsing Datasets",
    "descriptor": "",
    "authors": [
      "Marco Damonte",
      "Emilio Monti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.04476"
  },
  {
    "id": "arXiv:2106.04496",
    "title": "Towards a Theoretical Framework of Out-of-Distribution Generalization",
    "abstract": "Towards a Theoretical Framework of Out-of-Distribution Generalization",
    "descriptor": "",
    "authors": [
      "Haotian Ye",
      "Chuanlong Xie",
      "Tianle Cai",
      "Ruichen Li",
      "Zhenguo Li",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04496"
  },
  {
    "id": "arXiv:2106.04527",
    "title": "LaplaceNet: A Hybrid Energy-Neural Model for Deep Semi-Supervised  Classification",
    "abstract": "LaplaceNet: A Hybrid Energy-Neural Model for Deep Semi-Supervised  Classification",
    "descriptor": "",
    "authors": [
      "Philip Sellars",
      "Angelica I. Aviles-Rivero",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04527"
  },
  {
    "id": "arXiv:2106.04563",
    "title": "XtremeDistilTransformers: Task Transfer for Task-agnostic Distillation",
    "abstract": "Comments: Code and checkpoints released (links in draft)",
    "descriptor": "\nComments: Code and checkpoints released (links in draft)\n",
    "authors": [
      "Subhabrata Mukherjee",
      "Ahmed Hassan Awadallah",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04563"
  },
  {
    "id": "arXiv:2106.05064",
    "title": "Sharp Elements and the Scott Topology of Continuous Dcpos",
    "abstract": "Comments: Corrected a typo in a section title",
    "descriptor": "\nComments: Corrected a typo in a section title\n",
    "authors": [
      "Tom de Jong"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.05064"
  },
  {
    "id": "arXiv:2106.05234",
    "title": "Do Transformers Really Perform Bad for Graph Representation?",
    "abstract": "Do Transformers Really Perform Bad for Graph Representation?",
    "descriptor": "",
    "authors": [
      "Chengxuan Ying",
      "Tianle Cai",
      "Shengjie Luo",
      "Shuxin Zheng",
      "Guolin Ke",
      "Di He",
      "Yanming Shen",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05234"
  },
  {
    "id": "arXiv:2106.05239",
    "title": "XBNet : An Extremely Boosted Neural Network",
    "abstract": "XBNet : An Extremely Boosted Neural Network",
    "descriptor": "",
    "authors": [
      "Tushar Sarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05239"
  },
  {
    "id": "arXiv:2106.05430",
    "title": "Very Compact Clusters with Structural Regularization via Similarity and  Connectivity",
    "abstract": "Very Compact Clusters with Structural Regularization via Similarity and  Connectivity",
    "descriptor": "",
    "authors": [
      "Xin Ma",
      "Won Hwa Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05430"
  },
  {
    "id": "arXiv:2106.05819",
    "title": "Adversarial Graph Augmentation to Improve Graph Contrastive Learning",
    "abstract": "Comments: typo fix in theorem 1",
    "descriptor": "\nComments: typo fix in theorem 1\n",
    "authors": [
      "Susheel Suresh",
      "Pan Li",
      "Cong Hao",
      "Jennifer Neville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.05819"
  },
  {
    "id": "arXiv:2106.06046",
    "title": "Information Theoretic Evaluation of Privacy-Leakage, Interpretability,  and Transferability for a Novel Trustworthy AI Framework",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2105.04615, arXiv:2104.07060",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.04615, arXiv:2104.07060\n",
    "authors": [
      "Mohit Kumar",
      "Bernhard A. Moser",
      "Lukas Fischer",
      "Bernhard Freudenthaler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.06046"
  },
  {
    "id": "arXiv:2106.06054",
    "title": "Fair Preprocessing: Towards Understanding Compositional Fairness of Data  Transformers in Machine Learning Pipeline",
    "abstract": "Comments: ESEC/FSE'2021: The 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, Athens, Greece, August 23-28, 2021",
    "descriptor": "\nComments: ESEC/FSE'2021: The 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, Athens, Greece, August 23-28, 2021\n",
    "authors": [
      "Sumon Biswas",
      "Hridesh Rajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06054"
  },
  {
    "id": "arXiv:2106.06169",
    "title": "BoB: BERT Over BERT for Training Persona-based Dialogue Models from  Limited Personalized Data",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Haoyu Song",
      "Yan Wang",
      "Kaiyan Zhang",
      "Wei-Nan Zhang",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06169"
  },
  {
    "id": "arXiv:2106.06189",
    "title": "Order Matters: Probabilistic Modeling of Node Sequence for Graph  Generation",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Xiaohui Chen",
      "Xu Han",
      "Jiajing Hu",
      "Francisco J. R. Ruiz",
      "Liping Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.06189"
  },
  {
    "id": "arXiv:2106.06242",
    "title": "Where to Encode: A Performance Analysis of x86 and Arm-based Amazon EC2  Instances",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Roland Math\u00e1",
      "Dragi Kimovski",
      "Anatoliy Zabrovskiy",
      "Christian Timmerer",
      "Radu Prodan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2106.06242"
  },
  {
    "id": "arXiv:2106.06333",
    "title": "Invariant Information Bottleneck for Domain Generalization",
    "abstract": "Comments: The work is in progress",
    "descriptor": "\nComments: The work is in progress\n",
    "authors": [
      "Bo Li",
      "Yifei Shen",
      "Yezhen Wang",
      "Wenzhen Zhu",
      "Colorado J. Reed",
      "Jun Zhang",
      "Dongsheng Li",
      "Kurt Keutzer",
      "Han Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06333"
  },
  {
    "id": "arXiv:2106.06415",
    "title": "Attention-based Partial Face Recognition",
    "abstract": "Comments: To be published in IEEE ICIP 2021",
    "descriptor": "\nComments: To be published in IEEE ICIP 2021\n",
    "authors": [
      "Stefan H\u00f6rmann",
      "Zeyuan Zhang",
      "Martin Knoche",
      "Torben Teepe",
      "Gerhard Rigoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06415"
  },
  {
    "id": "arXiv:2106.06482",
    "title": "Neural Network Modeling of Probabilities for Coding the Octree  Representation of Point Clouds",
    "abstract": "Comments: 6 pages, 3 figures, Submitted to MMSP 2021, a few typos fixed in v2",
    "descriptor": "\nComments: 6 pages, 3 figures, Submitted to MMSP 2021, a few typos fixed in v2\n",
    "authors": [
      "Emre Can Kaya",
      "Ioan Tabus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.06482"
  },
  {
    "id": "arXiv:2106.06500",
    "title": "A Benchmark of Dynamical Variational Autoencoders applied to Speech  Spectrogram Modeling",
    "abstract": "Comments: Accepted to Interspeech 2021. arXiv admin note: text overlap with arXiv:2008.12595",
    "descriptor": "\nComments: Accepted to Interspeech 2021. arXiv admin note: text overlap with arXiv:2008.12595\n",
    "authors": [
      "Xiaoyu Bie",
      "Laurent Girin",
      "Simon Leglaive",
      "Thomas Hueber",
      "Xavier Alameda-Pineda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.06500"
  }
]
[
  {
    "id": "arXiv:2106.02044",
    "title": "Heterogeneous Noisy Short Signal Camouflage in Multi-Domain Environment  Decision-Making",
    "abstract": "Data transmission between two or more digital devices in industry and\ngovernment demands secure and agile technology. Digital information\ndistribution often requires deployment of Internet of Things (IoT) devices and\nData Fusion techniques which have also gained popularity in both, civilian and\nmilitary environments, such as, emergence of Smart Cities and Internet of\nBattlefield Things (IoBT). This usually requires capturing and consolidating\ndata from multiple sources. Because datasets do not necessarily originate from\nidentical sensors, fused data typically results in a complex Big Data problem.\nDue to potentially sensitive nature of IoT datasets, Blockchain technology is\nused to facilitate secure sharing of IoT datasets, which allows digital\ninformation to be distributed, but not copied. However, blockchain has several\nlimitations related to complexity, scalability, and excessive energy\nconsumption. We propose an approach to hide information (sensor signal) by\ntransforming it to an image or an audio signal. In one of the latest attempts\nto the military modernization, we investigate sensor fusion approach by\ninvestigating the challenges of enabling an intelligent identification and\ndetection operation and demonstrates the feasibility of the proposed Deep\nLearning and Anomaly Detection models that can support future application for\nspecific hand gesture alert system from wearable devices.",
    "descriptor": "\nComments: Published at: this http URL arXiv admin note: substantial text overlap with arXiv:2106.01497\n",
    "authors": [
      "Piyush K. Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.02044"
  },
  {
    "id": "arXiv:2106.02045",
    "title": "Least-squares fitting of Gaussian spots on graphics processing units",
    "abstract": "The investigation of samples with a spatial resolution in the nanometer range\nrelies on the precise and stable positioning of the sample. Due to inherent\nmechanical instabilities of typical sample stages in optical microscopes, it is\nusually required to control and/or monitor the sample position during the\nacquisition. The tracking of sparsely distributed fiducial markers at high\nspeed allows stabilizing the sample position at millisecond time scales. For\nthis purpose, we present a scalable fitting algorithm with significantly\nimproved performance for two-dimensional Gaussian fits as compared to Gpufit.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Marcel Leutenegger",
      "Michael Weber"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2106.02045"
  },
  {
    "id": "arXiv:2106.02051",
    "title": "The Earth Mover's Pinball Loss: Quantiles for Histogram-Valued  Regression",
    "abstract": "Although ubiquitous in the sciences, histogram data have not received much\nattention by the Deep Learning community. Whilst regression and classification\ntasks for scalar and vector data are routinely solved by neural networks, a\nprincipled approach for estimating histogram labels as a function of an input\nvector or image is lacking in the literature. We present a dedicated method for\nDeep Learning-based histogram regression, which incorporates cross-bin\ninformation and yields distributions over possible histograms, expressed by\n$\\tau$-quantiles of the cumulative histogram in each bin. The crux of our\napproach is a new loss function obtained by applying the pinball loss to the\ncumulative histogram, which for 1D histograms reduces to the Earth Mover's\ndistance (EMD) in the special case of the median ($\\tau = 0.5$), and\ngeneralizes it to arbitrary quantiles. We validate our method with an\nillustrative toy example, a football-related task, and an astrophysical\ncomputer vision problem. We show that with our loss function, the accuracy of\nthe predicted median histograms is very similar to the standard EMD case (and\nhigher than for per-bin loss functions such as cross-entropy), while the\npredictions become much more informative at almost no additional computational\ncost.",
    "descriptor": "\nComments: ICML 2021. The code is available at this https URL\n",
    "authors": [
      "Florian List"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02051"
  },
  {
    "id": "arXiv:2106.02067",
    "title": "Learning to Draw: Emergent Communication through Sketching",
    "abstract": "Evidence that visual communication preceded written language and provided a\nbasis for it goes back to prehistory, in forms such as cave and rock paintings\ndepicting traces of our distant ancestors. Emergent communication research has\nsought to explore how agents can learn to communicate in order to\ncollaboratively solve tasks. Existing research has focused on language, with a\nlearned communication channel transmitting sequences of discrete tokens between\nthe agents. In this work, we explore a visual communication channel between\nagents that are allowed to draw with simple strokes. Our agents are\nparameterised by deep neural networks, and the drawing procedure is\ndifferentiable, allowing for end-to-end training. In the framework of a\nreferential communication game, we demonstrate that agents can not only\nsuccessfully learn to communicate by drawing, but with appropriate inductive\nbiases, can do so in a fashion that humans can interpret. We hope to encourage\nfuture research to consider visual communication as a more flexible and\ndirectly interpretable alternative of training collaborative agents.",
    "descriptor": "",
    "authors": [
      "Daniela Mihai",
      "Jonathon Hare"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02067"
  },
  {
    "id": "arXiv:2106.02068",
    "title": "When does the Lanczos algorithm compute exactly?",
    "abstract": "In theory, the Lanczos algorithm generates an orthogonal basis of the\ncorresponding Krylov subspace. However, in finite precision arithmetic, the\northogonality and linear independence of the computed Lanczos vectors is\nusually lost quickly. In this paper we study a class of matrices and starting\nvectors having a special nonzero structure that guarantees exact computations\nof the Lanczos algorithm whenever floating point arithmetic satisfying the IEEE\n754 standard is used. Analogous results are formulated also for a variant of\nthe conjugate gradient method that produces then almost exact results. The\nresults are extended to the Arnoldi algorithm, the nonsymmetric Lanczos\nalgorithm, the Golub-Kahan bidiagonalization, the block-Lanczos algorithm and\ntheir counterparts for solving linear systems.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Dorota \u0160imonov\u00e1",
      "Petr Tich\u00fd"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02068"
  },
  {
    "id": "arXiv:2106.02073",
    "title": "Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central  Path",
    "abstract": "Recent work [Papyan, Han, and Donoho, 2020] discovered a phenomenon called\nNeural Collapse (NC) that occurs pervasively in today's deep net training\nparadigm of driving cross-entropy loss towards zero. In this phenomenon, the\nlast-layer features collapse to their class-means, both the classifiers and\nclass-means collapse to the same Simplex Equiangular Tight Frame (ETF), and the\nbehavior of the last-layer classifier converges to that of the\nnearest-class-mean decision rule. Since then, follow-ups-such as Mixon et al.\n[2020] and Poggio and Liao [2020a,b]-formally analyzed this inductive bias by\nreplacing the hard-to-study cross-entropy by the more tractable mean squared\nerror (MSE) loss. But, these works stopped short of demonstrating the empirical\nreality of MSE-NC on benchmark datasets and canonical networks-as had been done\nin Papyan, Han, and Donoho [2020] for the cross-entropy loss. In this work, we\nestablish the empirical reality of MSE-NC by reporting experimental\nobservations for three prototypical networks and five canonical datasets with\ncode for reproducing NC. Following this, we develop three main contributions\ninspired by MSE-NC. Firstly, we show a new theoretical decomposition of the MSE\nloss into (A) a term assuming the last-layer classifier is exactly the\nleast-squares or Webb and Lowe [1990] classifier and (B) a term capturing the\ndeviation from this least-squares classifier. Secondly, we exhibit experiments\non canonical datasets and networks demonstrating that, during training,\nterm-(B) is negligible. This motivates a new theoretical construct: the central\npath, where the linear classifier stays MSE-optimal-for the given feature\nactivations-throughout the dynamics. Finally, through our study of continually\nrenormalized gradient flow along the central path, we produce closed-form\ndynamics that predict full Neural Collapse in an unconstrained features model.",
    "descriptor": "\nComments: Appendix contains [Section A] empirical experiments, [Sections B-D] discussions and proofs of theoretical results, and [Section E] survey of related works examining Neural Collapse\n",
    "authors": [
      "X.Y. Han",
      "Vardan Papyan",
      "David L. Donoho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Differential Geometry (math.DG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02073"
  },
  {
    "id": "arXiv:2106.02076",
    "title": "LGBTQ-AI? Exploring Expressions of Gender and Sexual Orientation in  Chatbots",
    "abstract": "Chatbots are popular machine partners for task-oriented and social\ninteractions. Human-human computer-mediated communication research has explored\nhow people express their gender and sexuality in online social interactions,\nbut little is known about whether and in what way chatbots do the same. We\nconducted semi-structured interviews with 5 text-based conversational agents to\nexplore this topic Through these interviews, we identified 6 common themes\naround the expression of gender and sexual identity: identity description,\nidentity formation, peer acceptance, positive reflection, uncomfortable\nfeelings and off-topic responses. Chatbots express gender and sexuality\nexplicitly and through relation of experience and emotions, mimicking the human\nlanguage on which they are trained. It is nevertheless evident that chatbots\ndiffer from human dialogue partners as they lack the flexibility and\nunderstanding enabled by lived human experience. While chatbots are proficient\nin using language to express identity, they also display a lack of authentic\nexperiences of gender and sexuality.",
    "descriptor": "",
    "authors": [
      "Justin Edwards",
      "Leigh Clark",
      "Allison Perrone"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02076"
  },
  {
    "id": "arXiv:2106.02077",
    "title": "Eliciting Spoken Interruptions to Inform Proactive Speech Agent Design",
    "abstract": "Current speech agent interactions are typically user-initiated, limiting the\ninteractions they can deliver. Future functionality will require agents to be\nproactive, sometimes interrupting users. Little is known about how these spoken\ninterruptions should be designed, especially in urgent interruption contexts.\nWe look to inform design of proactive agent interruptions through investigating\nhow people interrupt others engaged in complex tasks. We therefore developed a\nnew technique to elicit human spoken interruptions of people engaged in other\ntasks. We found that people interrupted sooner when interruptions were urgent.\nSome participants used access rituals to forewarn interruptions, but most\nrarely used them. People balanced speed and accuracy in timing interruptions,\noften using cues from the task they interrupted. People also varied phrasing\nand delivery of interruptions to reflect urgency. We discuss how our findings\ncan inform speech agent design and how our paradigm can help gain insight into\nhuman interruptions in new contexts.",
    "descriptor": "",
    "authors": [
      "Justin Edwards",
      "Christian Janssen",
      "Sandy Gould",
      "Benjamin R Cowan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.02077"
  },
  {
    "id": "arXiv:2106.02082",
    "title": "Language Embeddings for Typology and Cross-lingual Transfer Learning",
    "abstract": "Cross-lingual language tasks typically require a substantial amount of\nannotated data or parallel translation data. We explore whether language\nrepresentations that capture relationships among languages can be learned and\nsubsequently leveraged in cross-lingual tasks without the use of parallel data.\nWe generate dense embeddings for 29 languages using a denoising autoencoder,\nand evaluate the embeddings using the World Atlas of Language Structures (WALS)\nand two extrinsic tasks in a zero-shot setting: cross-lingual dependency\nparsing and cross-lingual natural language inference.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Dian Yu",
      "Taiqi He",
      "Kenji Sagae"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02082"
  },
  {
    "id": "arXiv:2106.02083",
    "title": "A diachronic evaluation of gender asymmetry in euphemism",
    "abstract": "The use of euphemisms is a known driver of language change. It has been\nproposed that women use euphemisms more than men. Although there have been\nseveral studies investigating gender differences in language, the claim about\neuphemism usage has not been tested comprehensively through time. If women do\nuse euphemisms more, this could mean that women also lead the formation of new\neuphemisms and language change over time. Using four large diachronic text\ncorpora of English, we evaluate the claim that women use euphemisms more than\nmen through a quantitative analysis. We assembled a list of 106 euphemism-taboo\npairs to analyze their relative use through time by each gender in the corpora.\nContrary to the existing belief, our results show that women do not use\neuphemisms with a higher proportion than men. We repeated the analysis using\ndifferent subsets of the euphemism-taboo pairs list and found that our result\nwas robust. Our study indicates that in a broad range of settings involving\nboth speech and writing, and with varying degrees of formality, women do not\nuse or form euphemisms more than men.",
    "descriptor": "\nComments: 11 pages, 5 figures. To appear in Proceedings of the 2nd International Workshop on Computational Approaches to Historical Language Change, ACL\n",
    "authors": [
      "Anna Kapron-King",
      "Yang Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02083"
  },
  {
    "id": "arXiv:2106.02087",
    "title": "Unsupervised Learning of General-Purpose Embeddings for Code Changes",
    "abstract": "A lot of problems in the field of software engineering - bug fixing, commit\nmessage generation, etc. - require analyzing not only the code itself but\nspecifically code changes. Applying machine learning models to these tasks\nrequires us to create numerical representations of the changes, i.e.\nembeddings. Recent studies demonstrate that the best way to obtain these\nembeddings is to pre-train a deep neural network in an unsupervised manner on a\nlarge volume of unlabeled data and then further fine-tune it for a specific\ntask.\nIn this work, we propose an approach for obtaining such embeddings of code\nchanges during pre-training and evaluate them on two different downstream tasks\n- applying changes to code and commit message generation. The pre-training\nconsists of the model learning to apply the given change (an edit sequence) to\nthe code in a correct way, and therefore requires only the code change itself.\nTo increase the quality of the obtained embeddings, we only consider the\nchanged tokens in the edit sequence. In the task of applying code changes, our\nmodel outperforms the model that uses full edit sequences by 5.9 percentage\npoints in accuracy. As for the commit message generation, our model\ndemonstrated the same results as supervised models trained for this specific\ntask, which indicates that it can encode code changes well and can be improved\nin the future by pre-training on a larger dataset of easily gathered code\nchanges.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Mikhail Pravilov",
      "Egor Bogomolov",
      "Yaroslav Golubev",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02087"
  },
  {
    "id": "arXiv:2106.02094",
    "title": "Adaptive Epidemic Forecasting and Community Risk Evaluation of COVID-19",
    "abstract": "Pandemic control measures like lock-down, restrictions on restaurants and\ngatherings, social-distancing have shown to be effective in curtailing the\nspread of COVID-19. However, their sustained enforcement has negative economic\neffects. To craft strategies and policies that reduce the hardship on the\npeople and the economy while being effective against the pandemic, authorities\nneed to understand the disease dynamics at the right geo-spatial granularity.\nConsidering factors like the hospitals' ability to handle the fluctuating\ndemands, evaluating various reopening scenarios, and accurate forecasting of\ncases are vital to decision making. Towards this end, we present a flexible\nend-to-end solution that seamlessly integrates public health data with tertiary\nclient data to accurately estimate the risk of reopening a community. At its\ncore lies a state-of-the-art prediction model that auto-captures changing\ntrends in transmission and mobility. Benchmarking against various published\nbaselines confirm the superiority of our forecasting algorithm. Combined with\nthe ability to extend to multiple client-specific requirements and perform\ndeductive reasoning through counter-factual analysis, this solution provides\nactionable insights to multiple client domains ranging from government to\neducational institutions, hospitals, and commercial establishments.",
    "descriptor": "\nComments: 9 pages, 11 figures\n",
    "authors": [
      "Vishrawas Gopalakrishnan",
      "Sayali Navalekar",
      "Pan Ding",
      "Ryan Hooley",
      "Jacob Miller",
      "Raman Srinivasan",
      "Ajay Deshpande",
      "Xuan Liu",
      "Simone Bianco",
      "James H. Kaufman"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02094"
  },
  {
    "id": "arXiv:2106.02097",
    "title": "A Consciousness-Inspired Planning Agent for Model-Based Reinforcement  Learning",
    "abstract": "We present an end-to-end, model-based deep reinforcement learning agent which\ndynamically attends to relevant parts of its state, in order to plan and to\ngeneralize better out-of-distribution. The agent's architecture uses a set\nrepresentation and a bottleneck mechanism, forcing the number of entities to\nwhich the agent attends at each planning step to be small. In experiments with\ncustomized MiniGrid environments with different dynamics, we observe that the\ndesign allows agents to learn to plan effectively, by attending to the relevant\nobjects, leading to better out-of-distribution generalization.",
    "descriptor": "",
    "authors": [
      "Mingde Zhao",
      "Zhen Liu",
      "Sitao Luan",
      "Shuyuan Zhang",
      "Doina Precup",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02097"
  },
  {
    "id": "arXiv:2106.02100",
    "title": "Double Descent Optimization Pattern and Aliasing: Caveats of Noisy  Labels",
    "abstract": "Optimization plays a key role in the training of deep neural networks.\nDeciding when to stop training can have a substantial impact on the performance\nof the network during inference. Under certain conditions, the generalization\nerror can display a double descent pattern during training: the learning curve\nis non-monotonic and seemingly diverges before converging again after\nadditional epochs. This optimization pattern can lead to early stopping\nprocedures to stop training before the second convergence and consequently\nselect a suboptimal set of parameters for the network, with worse performance\nduring inference. In this work, in addition to confirming that double descent\noccurs with small datasets and noisy labels as evidenced by others, we show\nthat noisy labels must be present both in the training and generalization sets\nto observe a double descent pattern. We also show that the learning rate has an\ninfluence on double descent, and study how different optimizers and optimizer\nparameters influence the apparition of double descent. Finally, we show that\nincreasing the learning rate can create an aliasing effect that masks the\ndouble descent pattern without suppressing it. We study this phenomenon through\nextensive experiments on variants of CIFAR-10 and show that they translate to a\nreal world application: the forecast of seizure events in epileptic patients\nfrom continuous electroencephalographic recordings.",
    "descriptor": "",
    "authors": [
      "Florian Dubost",
      "Khaled Kamal Saab",
      "Erin Hong",
      "Daniel Yang Fu",
      "Max Pike",
      "Siddharth Sharma",
      "Siyi Tang",
      "Nandita Bhaskhar",
      "Christopher Lee-Messer",
      "Daniel Rubin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02100"
  },
  {
    "id": "arXiv:2106.02104",
    "title": "Semi-Empirical Objective Functions for MCMC Proposal Optimization",
    "abstract": "We introduce and demonstrate a semi-empirical procedure for determining\napproximate objective functions suitable for optimizing arbitrarily\nparameterized proposal distributions in MCMC methods. Our proposed Ab Initio\nobjective functions consist of the weighted combination of functions following\nconstraints on their global optima and of coordinate invariance that we argue\nshould be upheld by general measures of MCMC efficiency for use in proposal\noptimization. The coefficients of Ab Initio objective functions are determined\nso as to recover the optimal MCMC behavior prescribed by established\ntheoretical analysis for chosen reference problems. Our experimental results\ndemonstrate that Ab Initio objective functions maintain favorable performance\nand preferable optimization behavior compared to existing objective functions\nfor MCMC optimization when optimizing highly expressive proposal distributions.\nWe argue that Ab Initio objective functions are sufficiently robust to enable\nthe confident optimization of MCMC proposal distributions parameterized by deep\ngenerative networks that extend beyond the traditional limitations of\nindividual MCMC schemes.",
    "descriptor": "\nComments: 26 pages, 15 tables, 16 figures\n",
    "authors": [
      "Chris Cannella",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02104"
  },
  {
    "id": "arXiv:2106.02105",
    "title": "A Little Robustness Goes a Long Way: Leveraging Universal Features for  Targeted Transfer Attacks",
    "abstract": "Adversarial examples for neural network image classifiers are known to be\ntransferable: examples optimized to be misclassified by a source classifier are\noften misclassified as well by classifiers with different architectures.\nHowever, targeted adversarial examples -- optimized to be classified as a\nchosen target class -- tend to be less transferable between architectures.\nWhile prior research on constructing transferable targeted attacks has focused\non improving the optimization procedure, in this work we examine the role of\nthe source classifier. Here, we show that training the source classifier to be\n\"slightly robust\" -- that is, robust to small-magnitude adversarial examples --\nsubstantially improves the transferability of targeted attacks, even between\narchitectures as different as convolutional neural networks and transformers.\nWe argue that this result supports a non-intuitive hypothesis: on the spectrum\nfrom non-robust (standard) to highly robust classifiers, those that are only\nslightly robust exhibit the most universal features -- ones that tend to\noverlap with the features learned by other classifiers trained on the same\ndataset. The results we present provide insight into the nature of adversarial\nexamples as well as the mechanisms underlying so-called \"robust\" classifiers.",
    "descriptor": "\nComments: 25 pages, 13 figures, 3 tables\n",
    "authors": [
      "Jacob M. Springer",
      "Melanie Mitchell",
      "Garrett T. Kenyon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.02105"
  },
  {
    "id": "arXiv:2106.02108",
    "title": "Exponential Convergence of Piecewise-Constant Parameters Identification  under Finite Excitation Condition",
    "abstract": "A problem of identification of piecewise-constant unknown parameters of a\nlinear regression equation (LRE) is considered. Such parameters change their\nvalues over the interval of the regressor finite (rather than persistent)\nexcitation. To solve it, the previously proposed I-DREM procedure and the\nintegral-based filtering method with the exponential forgetting and resetting\nare improved: the integral of the filter equations is taken over the finite\ntime intervals, which belong to the finite excitation time range. This allows\none to obtain an exponentially bounded identification error over the excitation\ninterval, and, when the LRE parameters are constant outside such interval, to\nprovide exponential convergence of the identification error to zero. In\naddition, the applied method of the regressor excitation normalization makes it\npossible to obtain the same rate of convergence of the parameter error for the\nregressors of various amplitudes. The stability and all the above-mentioned\nproperties are proved for the derived identification method. The results of\nnumerical experiments (including the case of the noise-contaminated regressor\nand output measurements) fully support the obtained theoretical results.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Anton Glushchenko",
      "Vladislav Petrov",
      "Konstantin Lastochkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02108"
  },
  {
    "id": "arXiv:2106.02112",
    "title": "Finding and Fixing Spurious Patterns with Explanations",
    "abstract": "Machine learning models often use spurious patterns such as \"relying on the\npresence of a person to detect a tennis racket,\" which do not generalize. In\nthis work, we present an end-to-end pipeline for identifying and mitigating\nspurious patterns for image classifiers. We start by finding patterns such as\n\"the model's prediction for tennis racket changes 63% of the time if we hide\nthe people.\" Then, if a pattern is spurious, we mitigate it via a novel form of\ndata augmentation. We demonstrate that this approach identifies a diverse set\nof spurious patterns and that it mitigates them by producing a model that is\nboth more accurate on a distribution where the spurious pattern is not helpful\nand more robust to distribution shift.",
    "descriptor": "",
    "authors": [
      "Gregory Plumb",
      "Marco Tulio Ribeiro",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02112"
  },
  {
    "id": "arXiv:2106.02113",
    "title": "Oblivious Stacking and MAX $k$-CUT for Circle Graphs",
    "abstract": "Stacking is an important process within logistics. Some notable examples of\nitems to be stacked are steel bars or steel plates in a steel yard or\ncontainers in a container terminal or on a ship. We say that two items are\nconflicting if their storage time intervals overlap in which case one of the\nitems needs to be rehandled if the items are stored at the same LIFO storage\nlocation. We consider the problem of stacking items using $k$ LIFO locations\nwith a minimum number of conflicts between items sharing a location. We present\nan extremely simple online stacking algorithm that is oblivious to the storage\ntime intervals and storage locations of all other items when it picks a storage\nlocation for an item. The risk of assigning the same storage location to two\nconflicting items is proved to be of the order $1/k^2$ under mild assumptions\non the distribution of the storage time intervals for the items. Intuitively,\nit seems natural to pick a storage location uniformly at random in the\noblivious setting implying a risk of $1/k$ so the risk for our algorithm is\nsurprisingly low. Our results can also be expressed within the context of the\nMAX $k$-CUT problem for circle graphs. The results indicate that circle graphs\non average have relatively big $k$-cuts compared to the total number of edges.",
    "descriptor": "",
    "authors": [
      "Martin Olsen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.02113"
  },
  {
    "id": "arXiv:2106.02114",
    "title": "Winning the War by (Strategically) Losing Battles: Settling the  Complexity of Grundy-Values in Undirected Geography",
    "abstract": "We settle two long-standing complexity-theoretical questions-open since 1981\nand 1993-in combinatorial game theory (CGT).\nWe prove that the Grundy value (a.k.a. nim-value, or nimber) of Undirected\nGeography is PSPACE-complete to compute. This exhibits a stark contrast with a\nresult from 1993 that Undirected Geography is polynomial-time solvable. By\ndistilling to a simple reduction, our proof further establishes a dichotomy\ntheorem, providing a \"phase transition to intractability\" in Grundy-value\ncomputation, sharply characterized by a maximum degree of four: The Grundy\nvalue of Undirected Geography over any degree-three graph is polynomial-time\ncomputable, but over degree-four graphs-even when planar and bipartite-is\nPSPACE-hard. Additionally, we show, for the first time, how to construct\nUndirected Geography instances with Grundy value $\\ast n$ and size polynomial\nin n.\nWe strengthen a result from 1981 showing that sums of tractable partisan\ngames are PSPACE-complete in two fundamental ways. First, since Undirected\nGeography is an impartial ruleset, we extend the hardness of sums to impartial\ngames, a strict subset of partisan. Second, the 1981 construction is not built\nfrom a natural ruleset, instead using a long sum of tailored short-depth game\npositions. We use the sum of two Undirected Geography positions to create our\nhard instances. Our result also has computational implications to\nSprague-Grundy Theory (1930s) which shows that the Grundy value of the\ndisjunctive sum of any two impartial games can be computed-in polynomial\ntime-from their Grundy values. In contrast, we prove that assuming PSPACE\n$\\neq$ P, there is no general polynomial-time method to summarize two\npolynomial-time solvable impartial games to efficiently solve their disjunctive\nsum.",
    "descriptor": "",
    "authors": [
      "Kyle Burke",
      "Matthew Ferland",
      "Shanghua Teng"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.02114"
  },
  {
    "id": "arXiv:2106.02116",
    "title": "Rotor Thermal Monitoring Scheme for Direct-Torque-Controlled Interior  Permanent Magnet Synchronous Machines via High-Frequency Rotating Flux or  Torque Injection",
    "abstract": "Interior permanent magnet synchronous machine drives are widely employed in\nelectric traction systems and various industrial processes. However, prolonged\nexposure to high temperatures while operating can demagnetize the permanent\nmagnets to the point of irreversible demagnetization. In addition, direct\nmeasurements with infrared sensors or contact-type sensors with wireless\ncommunication can be expensive and intrusive to the motor drive systems. This\npaper thus proposes a nonintrusive thermal monitoring scheme for the permanent\nmagnets inside the direct-torque-controlled interior permanent magnet\nsynchronous machines. By applying an external high-frequency torque signal to\nthe hysteresis torque controller in the motor drive, the high-frequency\ncurrents can be injected into the stator windings. The permanent magnet\ntemperature can thus be monitored based on the induced high-frequency\nresistance. The nonintrusive nature of the method is indicated by the\nelimination of the extra sensors and no hardware change to the existing system.\nFinally, the effectiveness of the proposed method is validated with\nexperimental results.",
    "descriptor": "",
    "authors": [
      "Shen Zhang",
      "Sufei Li",
      "Lijun He",
      "Jose A. Restrepo",
      "Thomas G. Habetler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02116"
  },
  {
    "id": "arXiv:2106.02120",
    "title": "Approximation Algorithms for Min-Distance Problems in DAGs",
    "abstract": "The min-distance between two nodes $u, v$ is defined as the minimum of the\ndistance from $v$ to $u$ or from $u$ to $v$, and is a natural distance metric\nin DAGs. As with the standard distance problems, the Strong Exponential Time\nHypothesis [Impagliazzo-Paturi-Zane 2001, Calabro-Impagliazzo-Paturi 2009]\nleaves little hope for computing min-distance problems faster than computing\nAll Pairs Shortest Paths, which can be solved in $\\tilde{O}(mn)$ time. So it is\nnatural to resort to approximation algorithms in $\\tilde{O}(mn^{1-\\epsilon})$\ntime for some positive $\\epsilon$.\nAbboud, Vassilevska W., and Wang [SODA 2016] first studied min-distance\nproblems achieving constant factor approximation algorithms on DAGs, obtaining\na $3$-approximation algorithm for min-radius on DAGs which works in\n$\\tilde{O}(m\\sqrt{n})$ time, and showing that any $(2-\\delta)$-approximation\nrequires $n^{2-o(1)}$ time for any $\\delta>0$, under the Hitting Set\nConjecture. We close the gap, obtaining a $2$-approximation algorithm which\nruns in $\\tilde{O}(m\\sqrt{n})$ time. As the lower bound of Abboud et al only\nworks for sparse DAGs, we further show that our algorithm is conditionally\ntight for dense DAGs using a reduction from Boolean matrix multiplication.\nMoreover, Abboud et al obtained a linear time $2$-approximation algorithm for\nmin-diameter along with a lower bound stating that any\n$(3/2-\\delta)$-approximation algorithm for sparse DAGs requires $n^{2-o(1)}$\ntime under SETH. We close this gap for dense DAGs by obtaining a\n$3/2$-approximation algorithm which works in $O(n^{2.350})$ time and showing\nthat the approximation factor is unlikely to be improved within $O(n^{\\omega -\no(1)})$ time under the high dimensional Orthogonal Vectors Conjecture, where\n$\\omega$ is the matrix multiplication exponent.",
    "descriptor": "\nComments: To appear in ICALP 2021\n",
    "authors": [
      "Mina Dalirrooyfard",
      "Jenny Kaufmann"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.02120"
  },
  {
    "id": "arXiv:2106.02122",
    "title": "Experimental Comparison of Visual and Single-Receiver GPS Odometry",
    "abstract": "Mobile robots rely on odometry to navigate through areas where localization\nfails. Visual odometry (VO) is a common solution for obtaining robust and\nconsistent relative motion estimates of the vehicle frame. Contrarily, Global\nPositioning System (GPS) measurements are typically used for absolute\npositioning and localization. However, when the constraint on absolute accuracy\nis relaxed, time-differenced carrier phase (TDCP) measurements can be used to\nfind accurate relative position estimates with one single-frequency GPS\nreceiver. This suggests practitioners may want to consider GPS odometry as an\nalternative or in combination with VO. We describe a robust method for\nsingle-receiver GPS odometry on an unmanned ground vehicle (UGV). We then\npresent an experimental comparison of the two strategies on the same test\ntrajectories. After 1.8km of testing, the results show our GPS odometry method\nhas a 75% lower drift rate than a proven stereo VO method while maintaining a\nsmooth error signal despite varying satellite availability.",
    "descriptor": "\nComments: 7 pages, 9 figures\n",
    "authors": [
      "Benjamin Congram",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02122"
  },
  {
    "id": "arXiv:2106.02124",
    "title": "How to Adapt Your Pretrained Multilingual Model to 1600 Languages",
    "abstract": "Pretrained multilingual models (PMMs) enable zero-shot learning via\ncross-lingual transfer, performing best for languages seen during pretraining.\nWhile methods exist to improve performance for unseen languages, they have\nalmost exclusively been evaluated using amounts of raw text only available for\na small fraction of the world's languages. In this paper, we evaluate the\nperformance of existing methods to adapt PMMs to new languages using a resource\navailable for over 1600 languages: the New Testament. This is challenging for\ntwo reasons: (1) the small corpus size, and (2) the narrow domain. While\nperformance drops for all approaches, we surprisingly still see gains of up to\n$17.69\\%$ accuracy for part-of-speech tagging and $6.29$ F1 for NER on average\nover all languages as compared to XLM-R. Another unexpected finding is that\ncontinued pretraining, the simplest approach, performs best. Finally, we\nperform a case study to disentangle the effects of domain and size and to shed\nlight on the influence of the finetuning source language.",
    "descriptor": "\nComments: Accepted to ACL 2021\n",
    "authors": [
      "Abteen Ebrahimi",
      "Katharina Kann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02124"
  },
  {
    "id": "arXiv:2106.02125",
    "title": "Probabilistic Discriminative Models Address the Tactile Perceptual  Aliasing Problem",
    "abstract": "In this paper, our aim is to highlight Tactile Perceptual Aliasing as a\nproblem when using deep neural networks and other discriminative models.\nPerceptual aliasing will arise wherever a physical variable extracted from\ntactile data is subject to ambiguity between stimuli that are physically\ndistinct. Here we address this problem using a probabilistic discriminative\nmodel implemented as a 5-component mixture density network comprised of a deep\nneural network that predicts the parameters of a Gaussian mixture model. We\nshow that discriminative regression models such as deep neural networks and\nGaussian process regression perform poorly on aliased data, only making\naccurate predictions when the sources of aliasing are removed. In contrast, the\nmixture density network identifies aliased data with improved prediction\naccuracy. The uncertain predictions of the model form patterns that are\nconsistent with the various sources of perceptual ambiguity. In our view,\nperceptual aliasing will become an unavoidable issue for robot touch as the\nfield progresses to training robots that act in uncertain and unstructured\nenvironments, such as with deep reinforcement learning.",
    "descriptor": "\nComments: 11 pages. Accepted in Robotics: Science & Systems (RSS 2021)\n",
    "authors": [
      "John Lloyd",
      "Yijiong Lin",
      "Nathan F. Lepora"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02125"
  },
  {
    "id": "arXiv:2106.02126",
    "title": "A Closer Look at the Worst-case Behavior of Multi-armed Bandit  Algorithms",
    "abstract": "One of the key drivers of complexity in the classical (stochastic)\nmulti-armed bandit (MAB) problem is the difference between mean rewards in the\ntop two arms, also known as the instance gap. The celebrated Upper Confidence\nBound (UCB) policy is among the simplest optimism-based MAB algorithms that\nnaturally adapts to this gap: for a horizon of play n, it achieves optimal\nO(log n) regret in instances with \"large\" gaps, and a near-optimal O(\\sqrt{n\nlog n}) minimax regret when the gap can be arbitrarily \"small.\" This paper\nprovides new results on the arm-sampling behavior of UCB, leading to several\nimportant insights. Among these, it is shown that arm-sampling rates under UCB\nare asymptotically deterministic, regardless of the problem complexity. This\ndiscovery facilitates new sharp asymptotics and a novel alternative proof for\nthe O(\\sqrt{n log n}) minimax regret of UCB. Furthermore, the paper also\nprovides the first complete process-level characterization of the MAB problem\nunder UCB in the conventional diffusion scaling. Among other things, the\n\"small\" gap worst-case lens adopted in this paper also reveals profound\ndistinctions between the behavior of UCB and Thompson Sampling, such as an\n\"incomplete learning\" phenomenon characteristic of the latter.",
    "descriptor": "",
    "authors": [
      "Anand Kalvit",
      "Assaf Zeevi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02126"
  },
  {
    "id": "arXiv:2106.02129",
    "title": "The Algorithmic Phase Transition of Random $k$-SAT for Low Degree  Polynomials",
    "abstract": "Let $\\Phi$ be a uniformly random $k$-SAT formula with $n$ variables and $m$\nclauses. We study the algorithmic task of finding a satisfying assignment of\n$\\Phi$. It is known that a satisfying assignment exists with high probability\nat clause density $m/n < 2^k \\log 2 - \\frac12 (\\log 2 + 1) + o_k(1)$, while the\nbest polynomial-time algorithm known, the Fix algorithm of Coja-Oghlan, finds a\nsatisfying assignment at the much lower clause density $(1 - o_k(1)) 2^k \\log k\n/ k$. This prompts the question: is it possible to efficiently find a\nsatisfying assignment at higher clause densities?\nTo understand the algorithmic threshold of random $k$-SAT, we study low\ndegree polynomial algorithms, which are a powerful class of algorithms\nincluding Fix, Survey Propagation guided decimation, and paradigms such as\nmessage passing and local graph algorithms. We show that low degree polynomial\nalgorithms can find a satisfying assignment at clause density $(1 - o_k(1)) 2^k\n\\log k / k$, matching Fix, and not at clause density $(1 + o_k(1)) \\kappa^* 2^k\n\\log k / k$, where $\\kappa^* \\approx 4.911$. This shows the first sharp (up to\nconstant factor) computational phase transition of random $k$-SAT for a class\nof algorithms. Our proof establishes and leverages a new many-way overlap gap\nproperty tailored to random $k$-SAT.",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Guy Bresler",
      "Brice Huang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02129"
  },
  {
    "id": "arXiv:2106.02134",
    "title": "Syntax-augmented Multilingual BERT for Cross-lingual Transfer",
    "abstract": "In recent years, we have seen a colossal effort in pre-training multilingual\ntext encoders using large-scale corpora in many languages to facilitate\ncross-lingual transfer learning. However, due to typological differences across\nlanguages, the cross-lingual transfer is challenging. Nevertheless, language\nsyntax, e.g., syntactic dependencies, can bridge the typological gap. Previous\nworks have shown that pre-trained multilingual encoders, such as mBERT\n\\cite{devlin-etal-2019-bert}, capture language syntax, helping cross-lingual\ntransfer. This work shows that explicitly providing language syntax and\ntraining mBERT using an auxiliary objective to encode the universal dependency\ntree structure helps cross-lingual transfer. We perform rigorous experiments on\nfour NLP tasks, including text classification, question answering, named entity\nrecognition, and task-oriented semantic parsing. The experiment results show\nthat syntax-augmented mBERT improves cross-lingual transfer on popular\nbenchmarks, such as PAWS-X and MLQA, by 1.4 and 1.6 points on average across\nall languages. In the \\emph{generalized} transfer setting, the performance\nboosted significantly, with 3.9 and 3.1 points on average in PAWS-X and MLQA.",
    "descriptor": "\nComments: ACL 2021 (camera ready)\n",
    "authors": [
      "Wasi Uddin Ahmad",
      "Haoran Li",
      "Kai-Wei Chang",
      "Yashar Mehdad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02134"
  },
  {
    "id": "arXiv:2106.02136",
    "title": "Using Trust in Automation to Enhance Driver-(Semi)Autonomous Vehicle  Interaction and Improve Team Performance",
    "abstract": "Trust in robots has been gathering attention from multiple directions, as it\nhas special relevance in the theoretical descriptions of human-robot\ninteractions. It is essential for reaching high acceptance and usage rates of\nrobotic technologies in society, as well as for enabling effective human-robot\nteaming. Researchers have been trying to model the development of trust in\nrobots to improve the overall rapport between humans and robots. Unfortunately,\nthe miscalibration of trust in automation is a common issue that jeopardizes\nthe effectiveness of automation use. It happens when a user's trust levels are\nnot appropriate to the capabilities of the automation being used. Users can be:\nunder-trusting the automation -- when they do not use the functionalities that\nthe machine can perform correctly because of a lack of trust; or over-trusting\nthe automation -- when, due to an excess of trust, they use the machine in\nsituations where its capabilities are not adequate. The main objective of this\nwork is to examine driver's trust development in the ADS. We aim to model how\nrisk factors (e.g.: false alarms and misses from the ADS) and the short-term\ninteractions associated with these risk factors influence the dynamics of\ndrivers' trust in the ADS. The driving context facilitates the instrumentation\nto measure trusting behaviors, such as drivers' eye movements and usage time of\nthe automated features. Our findings indicate that a reliable characterization\nof drivers' trusting behaviors and a consequent estimation of trust levels is\npossible. We expect that these techniques will permit the design of ADSs able\nto adapt their behaviors to attempt to adjust driver's trust levels. This\ncapability could avoid under- and over-trusting, which could harm their safety\nor their performance.",
    "descriptor": "\nComments: 4 pages, 2 figures, 2021 International Symposium on Transportation Data and Modelling, Virtual, June 21-24\n",
    "authors": [
      "Hebert Azevedo-Sa",
      "X. Jessie Yang",
      "Lionel P. Robert Jr.",
      "Dawn M. Tilbury"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02136"
  },
  {
    "id": "arXiv:2106.02140",
    "title": "Towards a Cross-Domain Software Safety Assurance Process for Embedded  Systems",
    "abstract": "In this work, we outline a cross-domain assurance process for safety-relevant\nsoftware in embedded systems. This process aims to be applied in various\ndifferent application domains and in conjunction with any development\nmethodology. With this approach we plan to reduce the growing effort for safety\nassessment in embedded systems by reusing safety analysis techniques and tools\nfor the product development in different domains.",
    "descriptor": "",
    "authors": [
      "Marc Zeller",
      "Kai Hoefig",
      "Martin Rothfelder"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.02140"
  },
  {
    "id": "arXiv:2106.02141",
    "title": "Fine-Grained Visual Classification of Plant Species In The Wild: Object  Detection as A Reinforced Means of Attention",
    "abstract": "Plant species identification in the wild is a difficult problem in part due\nto the high variability of the input data, but also because of complications\ninduced by the long-tail effects of the datasets distribution. Inspired by the\nmost recent fine-grained visual classification approaches which are based on\nattention to mitigate the effects of data variability, we explore the idea of\nusing object detection as a form of attention. We introduce a bottom-up\napproach based on detecting plant organs and fusing the predictions of a\nvariable number of organ-based species classifiers. We also curate a new\ndataset with a long-tail distribution for evaluating plant organ detection and\norgan-based species identification, which is publicly available.",
    "descriptor": "\nComments: 6 pages, 4 figures. Accepted to the CVPR 2021 FGVC Workshop. Models, testing code, and link to dataset can be found at this https URL\n",
    "authors": [
      "Matthew R. Keaton",
      "Ram J. Zaveri",
      "Meghana Kovur",
      "Cole Henderson",
      "Donald A. Adjeroh",
      "Gianfranco Doretto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02141"
  },
  {
    "id": "arXiv:2106.02146",
    "title": "The Signed Cumulative Distribution Transform for 1-D Signal Analysis and  Classification",
    "abstract": "This paper presents a new mathematical signal transform that is especially\nsuitable for decoding information related to non-rigid signal displacements. We\nprovide a measure theoretic framework to extend the existing Cumulative\nDistribution Transform [ACHA 45 (2018), no. 3, 616-641] to arbitrary (signed)\nsignals on $\\overline{\\mathbb{R}}$. We present both forward (analysis) and\ninverse (synthesis) formulas for the transform, and describe several of its\nproperties including translation, scaling, convexity, linear separability and\nothers. Finally, we describe a metric in transform space, and demonstrate the\napplication of the transform in classifying (detecting) signals under random\ndisplacements.",
    "descriptor": "",
    "authors": [
      "Akram Aldroubi",
      "Rocio Diaz Martin",
      "Ivan Medri",
      "Gustavo K. Rohde",
      "Sumati Thareja"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2106.02146"
  },
  {
    "id": "arXiv:2106.02148",
    "title": "Analysis of draft EU ADS Performance Requirements",
    "abstract": "Recently, the European Commission published draft regulation for uniform\nprocedures and technical specification for the type-approval of motor vehicles\nwith an automated driving system (ADS). While the draft regulation is welcome\nprogress for an industry ready to deploy life saving automated vehicle\ntechnology, we believe that the requirements can be further improved to enhance\nthe safety and societal acceptance of automated vehicles (AVs). In this paper,\nwe evaluate the draft regulation's performance requirements that would impact\nthe Dynamic Driving Task (DDT). We highlight potential problems that can arise\nfrom the current proposed requirements and propose practical recommendations to\nimprove the regulation.",
    "descriptor": "",
    "authors": [
      "Maria Soledad Elli",
      "Jack Weast"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02148"
  },
  {
    "id": "arXiv:2106.02149",
    "title": "Optimal Pricing Schemes for an Impatient Buyer",
    "abstract": "A patient seller aims to sell a good to an impatient buyer (i.e., one who\ndiscounts utility over time). The buyer will remain in the market for a period\nof time $T$, and her private value is drawn from a publicly known distribution.\nWhat is the revenue-optimal pricing-curve (sequence of (price, time) pairs) for\nthe seller? Is randomization of help here? Is the revenue-optimal pricing-curve\ncomputable in polynomial time? We answer these questions in this paper. We give\nan efficient algorithm for computing the revenue-optimal pricing curve. We show\nthat pricing curves, that post a price at each point of time and let the buyer\npick her utility maximizing time to buy, are revenue-optimal among a much\nbroader class of sequential lottery mechanisms: namely, mechanisms that allow\nthe seller to post a menu of lotteries at each point of time cannot get any\nhigher revenue than pricing curves. We also show that the even broader class of\nmechanisms that allow the menu of lotteries to be adaptively set, can earn\nstrictly higher revenue than that of pricing curves, and the revenue gap can be\nas big as the support size of the buyer's value distribution.",
    "descriptor": "",
    "authors": [
      "Yuan Deng",
      "Jieming Mao",
      "Balasubramanian Sivan",
      "Kangning Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2106.02149"
  },
  {
    "id": "arXiv:2106.02150",
    "title": "Interactive Communication in Bilateral Trade",
    "abstract": "We define a model of interactive communication where two agents with private\ntypes can exchange information before a game is played. The model contains\nBayesian persuasion as a special case of a one-round communication protocol. We\ndefine message complexity corresponding to the minimum number of interactive\nrounds necessary to achieve the best possible outcome. Our main result is that\nfor bilateral trade, agents don't stop talking until they reach an efficient\noutcome: Either agents achieve an efficient allocation in finitely many rounds\nof communication; or the optimal communication protocol has infinite number of\nrounds. We show an important class of bilateral trade settings where efficient\nallocation is achievable with a small number of rounds of communication.",
    "descriptor": "",
    "authors": [
      "Jieming Mao",
      "Renato Paes Leme",
      "Kangning Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2106.02150"
  },
  {
    "id": "arXiv:2106.02156",
    "title": "In-Network Freshness Control: Trading Throughput for Freshness",
    "abstract": "In addition to traditional concerns such as throughput and latency, freshness\nis becoming increasingly important. To stay fresh, applications stream status\nupdates among their components, which can congest the network if the update\nfrequency is too high. Tuning to the right frequency is not trivial, especially\nin the presence of other flows, when network sharing becomes much more\ninvolved. Also, sophisticated tuning logic inevitably complicates the design of\nthe endhost devices.\nIn this paper, we take an alternative approach. Instead of tuning the update\nfrequency at the end-host, we let the endhost send out updates at its own pace\nand control the freshness within the network. This In-network Freshness Control\n(IFC) scheme allows the network operator to improve freshness while providing a\nfine-grained trade-off with throughput. IFC leverages in-network compute\nresources to filter out obsolete information during transmission of status\nupdates, while queueing other drop-averse traffic separately to provide high\nthroughput. We provide an analytic study of IFC and then implement IFC as Linux\nkernel modules. Our experiments show that IFC outperforms existing queueing\ndisciplines by improving both throughput (by up to 40%) and freshness (by up to\n50%). IFC can easily be combined with existing methods, e.g., BBR and DCTCP,\nand is effective even in partial deployments.",
    "descriptor": "",
    "authors": [
      "Shih-Hao Tseng",
      "SooJean Han",
      "Adam Wierman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.02156"
  },
  {
    "id": "arXiv:2106.02159",
    "title": "On the implementation of a robust and efficient finite element-based  parallel solver for the compressible Navier-Stokes equations",
    "abstract": "This paper describes in detail the implementation of a finite element\ntechnique for solving the compressible Navier-Stokes equations that is provably\nrobust and demonstrates excellent performance on modern computer hardware. The\nmethod is second-order accurate in time and space. Robustness here means that\nthe method is proved to be invariant domain preserving under the hyperbolic CFL\ntime step restriction, and it produces results that are reproducible and that\ncan be shown to be accurate on challenging 2D and 3D realistic benchmarks.",
    "descriptor": "",
    "authors": [
      "Jean-Luc Guermond",
      "Martin Kronbichler",
      "Matthias Maier",
      "Bojan Popov",
      "Ignacio Tomas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02159"
  },
  {
    "id": "arXiv:2106.02162",
    "title": "Privately Learning Mixtures of Axis-Aligned Gaussians",
    "abstract": "We consider the problem of learning mixtures of Gaussians under the\nconstraint of approximate differential privacy. We prove that\n$\\widetilde{O}(k^2 d \\log^{3/2}(1/\\delta) / \\alpha^2 \\varepsilon)$ samples are\nsufficient to learn a mixture of $k$ axis-aligned Gaussians in $\\mathbb{R}^d$\nto within total variation distance $\\alpha$ while satisfying $(\\varepsilon,\n\\delta)$-differential privacy. This is the first result for privately learning\nmixtures of unbounded axis-aligned (or even unbounded univariate) Gaussians. If\nthe covariance matrices of each of the Gaussians is the identity matrix, we\nshow that $\\widetilde{O}(kd/\\alpha^2 + kd \\log(1/\\delta) / \\alpha \\varepsilon)$\nsamples are sufficient.\nRecently, the \"local covering\" technique of Bun, Kamath, Steinke, and Wu has\nbeen successfully used for privately learning high-dimensional Gaussians with a\nknown covariance matrix and extended to privately learning general\nhigh-dimensional Gaussians by Aden-Ali, Ashtiani, and Kamath. Given these\npositive results, this approach has been proposed as a promising direction for\nprivately learning mixtures of Gaussians. Unfortunately, we show that this is\nnot possible.\nWe design a new technique for privately learning mixture distributions. A\nclass of distributions $\\mathcal{F}$ is said to be list-decodable if there is\nan algorithm that, given \"heavily corrupted\" samples from $f\\in \\mathcal{F}$,\noutputs a list of distributions, $\\widehat{\\mathcal{F}}$, such that one of the\ndistributions in $\\widehat{\\mathcal{F}}$ approximates $f$. We show that if\n$\\mathcal{F}$ is privately list-decodable, then we can privately learn mixtures\nof distributions in $\\mathcal{F}$. Finally, we show axis-aligned Gaussian\ndistributions are privately list-decodable, thereby proving mixtures of such\ndistributions are privately learnable.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Ishaq Aden-Ali",
      "Hassan Ashtiani",
      "Christopher Liaw"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02162"
  },
  {
    "id": "arXiv:2106.02163",
    "title": "Improved batch code lower bounds",
    "abstract": "Batch codes are a useful notion of locality for error correcting codes,\noriginally introduced in the context of distributed storage and cryptography.\nMany constructions of batch codes have been given, but few lower bound\n(limitation) results are known, leaving gaps between the best known\nconstructions and best known lower bounds. Towards determining the optimal\nredundancy of batch codes, we prove a new lower bound on the redundancy of\nbatch codes. Specifically, we study (primitive, multiset) linear batch codes\nthat systematically encode $n$ information symbols into $N$ codeword symbols,\nwith the requirement that any multiset of $k$ symbol requests can be obtained\nin disjoint ways. We show that such batch codes need $\\Omega(\\sqrt{Nk})$\nsymbols of redundancy, improving on the previous best lower bounds of\n$\\Omega(\\sqrt{N}+k)$ at all $k=n^\\varepsilon$ with $\\varepsilon\\in(0,1)$. Our\nproof follows from analyzing the dimension of the order-$O(k)$ tensor of the\nbatch code's dual code.",
    "descriptor": "",
    "authors": [
      "Ray Li",
      "Mary Wootters"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.02163"
  },
  {
    "id": "arXiv:2106.02164",
    "title": "Modeling Communication to Coordinate Perspectives in Cooperation",
    "abstract": "Communication is highly overloaded. Despite this, even young children are\ngood at leveraging context to understand ambiguous signals. We propose a\ncomputational account of overloaded signaling from a shared agency perspective\nwhich we call the Imagined We for Communication. Under this framework,\ncommunication helps cooperators coordinate their perspectives, allowing them to\nact together to achieve shared goals. We assume agents are rational\ncooperators, which puts constraints on how signals can be sent and interpreted.\nWe implement this model in a set of simulations demonstrating this model's\nsuccess under increasing ambiguity as well as increasing layers of reasoning.\nOur model is capable of improving performance with deeper recursive reasoning;\nhowever, it outperforms comparison baselines at even the shallowest level,\nhighlighting how shared knowledge and cooperative logic can do much of the\nheavy-lifting in language.",
    "descriptor": "",
    "authors": [
      "Stephanie Stacy",
      "Chenfei Li",
      "Minglu Zhao",
      "Yiling Yun",
      "Qingyi Zhao",
      "Max Kleiman-Weiner",
      "Tao Gao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02164"
  },
  {
    "id": "arXiv:2106.02167",
    "title": "How Great is the Great Firewall? Measuring China's DNS Censorship",
    "abstract": "The DNS filtering apparatus of China's Great Firewall (GFW) has evolved\nconsiderably over the past two decades. However, most prior studies of China's\nDNS filtering were performed over short time periods, leading to unnoticed\nchanges in the GFW's behavior. In this study, we introduce GFWatch, a\nlarge-scale, longitudinal measurement platform capable of testing hundreds of\nmillions of domains daily, enabling continuous monitoring of the GFW's DNS\nfiltering behavior.\nWe present the results of running GFWatch over a nine-month period, during\nwhich we tested an average of 411M domains per day and detected a total of 311K\ndomains censored by GFW's DNS filter. To the best of our knowledge, this is the\nlargest number of domains tested and censored domains discovered in the\nliterature. We further reverse engineer regular expressions used by the GFW and\nfind 41K innocuous domains that match these filters, resulting in overblocking\nof their content. We also observe bogus IPv6 and globally routable IPv4\naddresses injected by the GFW, including addresses owned by US companies, such\nas Facebook, Dropbox, and Twitter.\nUsing data from GFWatch, we studied the impact of GFW blocking on the global\nDNS system. We found 77K censored domains with DNS resource records polluted in\npopular public DNS resolvers, such as Google and Cloudflare. Finally, we\npropose strategies to detect poisoned responses that can (1) sanitize poisoned\nDNS records from the cache of public DNS resolvers, and (2) assist in the\ndevelopment of circumvention tools to bypass the GFW's DNS censorship.",
    "descriptor": "\nComments: To appear at the 30th USENIX Security Symposium\n",
    "authors": [
      "Nguyen Phong Hoang",
      "Arian Akhavan Niaki",
      "Jakub Dalek",
      "Jeffrey Knockel",
      "Pellaeon Lin",
      "Bill Marczak",
      "Masashi Crete-Nishihata",
      "Phillipa Gill",
      "Michalis Polychronakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.02167"
  },
  {
    "id": "arXiv:2106.02171",
    "title": "nmT5 -- Is parallel data still relevant for pre-training massively  multilingual language models?",
    "abstract": "Recently, mT5 - a massively multilingual version of T5 - leveraged a unified\ntext-to-text format to attain state-of-the-art results on a wide variety of\nmultilingual NLP tasks. In this paper, we investigate the impact of\nincorporating parallel data into mT5 pre-training. We find that multi-tasking\nlanguage modeling with objectives such as machine translation during\npre-training is a straightforward way to improve performance on downstream\nmultilingual and cross-lingual tasks. However, the gains start to diminish as\nthe model capacity increases, suggesting that parallel data might not be as\nessential for larger models. At the same time, even at larger model sizes, we\nfind that pre-training with parallel data still provides benefits in the\nlimited labelled data regime.",
    "descriptor": "\nComments: Accepted at ACL-IJCNLP 2021\n",
    "authors": [
      "Mihir Kale",
      "Aditya Siddhant",
      "Noah Constant",
      "Melvin Johnson",
      "Rami Al-Rfou",
      "Linting Xue"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02171"
  },
  {
    "id": "arXiv:2106.02172",
    "title": "Counterfactual Graph Learning for Link Prediction",
    "abstract": "Learning to predict missing links is important for many graph-based\napplications. Existing methods were designed to learn the observed association\nbetween two sets of variables: (1) the observed graph structure and (2) the\nexistence of link between a pair of nodes. However, the causal relationship\nbetween these variables was ignored and we visit the possibility of learning it\nby simply asking a counterfactual question: \"would the link exist or not if the\nobserved graph structure became different?\" To answer this question by causal\ninference, we consider the information of the node pair as context, global\ngraph structural properties as treatment, and link existence as outcome. In\nthis work, we propose a novel link prediction method that enhances graph\nlearning by the counterfactual inference. It creates counterfactual links from\nthe observed ones, and our method learns representations from both of them.\nExperiments on a number of benchmark datasets show that our proposed method\nachieves the state-of-the-art performance on link prediction.",
    "descriptor": "",
    "authors": [
      "Tong Zhao",
      "Gang Liu",
      "Daheng Wang",
      "Wenhao Yu",
      "Meng Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02172"
  },
  {
    "id": "arXiv:2106.02179",
    "title": "Distributed Symbolic Execution using Test-Depth Partitioning",
    "abstract": "Symbolic execution is a classic technique for systematic bug finding, which\nhas seen many applications in recent years but remains hard to scale. Recent\nwork introduced ranged symbolic execution to distribute the symbolic execution\ntask among different workers with minimal communication overhead using test\ninputs. However, each worker was restricted to perform only a depth-first\nsearch. This paper introduces a new approach to ranging, called test-depth\npartitioning, that allows the workers to employ different search strategies\nwithout compromising the completeness of the overall search. Experimental\nresults show that the proposed approach provides a more flexible ranging\nsolution for distributed symbolic execution. The core idea behind test-depth\npartitioning is to use a test-depth pair to define a region in the execution\nspace. Such a pair represents a partial path or a prefix, and it obviates the\nneed for complete tests to determine boundaries as was the case in the previous\nranging scheme. Moreover, different workers have the freedom to select the\nsearch strategy of choice without affecting the functioning of the overall\nsystem. Test-depth partitioning is implemented using KLEE, a well-known\nsymbolic execution tool. The preliminary results show that the proposed scheme\ncan prove to be an efficient tool to speed up symbolic execution.",
    "descriptor": "\nComments: 19 pages (16 pages for text and 3 pages for references). 3 figures (Figure 1 has two sub-figures, Figure 2 has 3 sub-figures and Figure 3 has 3 sub-figures). 3 tables. 2 algorithm blocks\n",
    "authors": [
      "Shikhar Singh",
      "Sarfraz Khurshid"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.02179"
  },
  {
    "id": "arXiv:2106.02182",
    "title": "Self-supervised Dialogue Learning for Spoken Conversational Question  Answering",
    "abstract": "In spoken conversational question answering (SCQA), the answer to the\ncorresponding question is generated by retrieving and then analyzing a fixed\nspoken document, including multi-part conversations. Most SCQA systems have\nconsidered only retrieving information from ordered utterances. However, the\nsequential order of dialogue is important to build a robust spoken\nconversational question answering system, and the changes of utterances order\nmay severely result in low-quality and incoherent corpora. To this end, we\nintroduce a self-supervised learning approach, including incoherence\ndiscrimination, insertion detection, and question prediction, to explicitly\ncapture the coreference resolution and dialogue coherence among spoken\ndocuments. Specifically, we design a joint learning framework where the\nauxiliary self-supervised tasks can enable the pre-trained SCQA systems towards\nmore coherent and meaningful spoken dialogue learning. We also utilize the\nproposed self-supervised learning tasks to capture intra-sentence coherence.\nExperimental results demonstrate that our proposed method provides more\ncoherent, meaningful, and appropriate responses, yielding superior performance\ngains compared to the original pre-trained language models. Our method achieves\nstate-of-the-art results on the Spoken-CoQA dataset.",
    "descriptor": "\nComments: To Appear Interspeech 2021\n",
    "authors": [
      "Nuo Chen",
      "Chenyu You",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.02182"
  },
  {
    "id": "arXiv:2106.02183",
    "title": "Towards Equal Gender Representation in the Annotations of Toxic Language  Detection",
    "abstract": "Classifiers tend to propagate biases present in the data on which they are\ntrained. Hence, it is important to understand how the demographic identities of\nthe annotators of comments affect the fairness of the resulting model. In this\npaper, we focus on the differences in the ways men and women annotate comments\nfor toxicity, investigating how these differences result in models that amplify\nthe opinions of male annotators. We find that the BERT model as-sociates toxic\ncomments containing offensive words with male annotators, causing the model to\npredict 67.7% of toxic comments as having been annotated by men. We show that\nthis disparity between gender predictions can be mitigated by removing\noffensive words and highly toxic comments from the training data. We then apply\nthe learned associations between gender and language to toxic language\nclassifiers, finding that models trained exclusively on female-annotated data\nperform 1.8% better than those trained solely on male-annotated data and that\ntraining models on data after removing all offensive words reduces bias in the\nmodel by 55.5% while increasing the sensitivity by 0.4%.",
    "descriptor": "\nComments: Paper is accepted at GeBNLP2021 workshop at ACL-IJCNLP 2021\n",
    "authors": [
      "Elizabeth Excell",
      "Noura Al Moubayed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02183"
  },
  {
    "id": "arXiv:2106.02185",
    "title": "Functional observers with linear error dynamics for discrete-time  nonlinear systems, with application to fault diagnosis",
    "abstract": "This work deals with the problem of designing observers for the estimation of\na single function of the states for discrete time nonlinear systems. Necessary\nand sufficient conditions for the existence of lower order functional observers\nwith linear dynamics and linear output map are derived. The results provide a\ndirect generalization to Luenberger's linear theory of functional observers.\nThe application of the functional observer design methodology to fault\ndetection and estimation is also investigated. Throughout the study the methods\npresented are tested on a non-isothermal CSTR case study.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2101.11148\n",
    "authors": [
      "Sunjeev Venkateswaran",
      "Benjamin A. Wilhite",
      "Costas Kravaris"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02185"
  },
  {
    "id": "arXiv:2106.02190",
    "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug  Discovery",
    "abstract": "We developed Distilled Graph Attention Policy Networks (DGAPNs), a\ncuriosity-driven reinforcement learning model to generate novel\ngraph-structured chemical representations that optimize user-defined objectives\nby efficiently navigating a physically constrained domain. The framework is\nexamined on the task of generating molecules that are designed to bind,\nnoncovalently, to functional sites of SARS-CoV-2 proteins. We present a spatial\nGraph Attention Network (sGAT) that leverages self-attention over both node and\nedge attributes as well as encoding spatial structure -- this capability is of\nconsiderable interest in areas such as molecular and synthetic biology and drug\ndiscovery. An attentional policy network is then introduced to learn decision\nrules for a dynamic, fragment-based chemical environment, and state-of-the-art\npolicy gradient techniques are employed to train the network with enhanced\nstability. Exploration is efficiently encouraged by incorporating innovation\nreward bonuses learned and proposed by random network distillation. In\nexperiments, our framework achieved outstanding results compared to\nstate-of-the-art algorithms, while increasing the diversity of proposed\nmolecules and reducing the complexity of paths to chemical synthesis.",
    "descriptor": "",
    "authors": [
      "Yulun Wu",
      "Nicholas Choma",
      "Andrew Chen",
      "Mikaela Cashman",
      "\u00c9rica T. Prates",
      "Manesh Shah",
      "Ver\u00f3nica G. Melesse Vergara",
      "Austin Clyde",
      "Thomas S. Brettin",
      "Wibe A. de Jong",
      "Neeraj Kumar",
      "Martha S. Head",
      "Rick L. Stevens",
      "Peter Nugent",
      "Daniel A. Jacobson",
      "James B. Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2106.02190"
  },
  {
    "id": "arXiv:2106.02192",
    "title": "Grounding 'Grounding' in NLP",
    "abstract": "The NLP community has seen substantial recent interest in grounding to\nfacilitate interaction between language technologies and the world. However, as\na community, we use the term broadly to reference any linking of text to data\nor non-textual modality. In contrast, Cognitive Science more formally defines\n\"grounding\" as the process of establishing what mutual information is required\nfor successful communication between two interlocutors -- a definition which\nmight implicitly capture the NLP usage but differs in intent and scope. We\ninvestigate the gap between these definitions and seek answers to the following\nquestions: (1) What aspects of grounding are missing from NLP tasks? Here we\npresent the dimensions of coordination, purviews and constraints. (2) How is\nthe term \"grounding\" used in the current research? We study the trends in\ndatasets, domains, and tasks introduced in recent NLP conferences. And finally,\n(3) How to advance our current definition to bridge the gap with Cognitive\nScience? We present ways to both create new tasks or repurpose existing ones to\nmake advancements towards achieving a more complete sense of grounding.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Khyathi Raghavi Chandu",
      "Yonatan Bisk",
      "Alan W Black"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02192"
  },
  {
    "id": "arXiv:2106.02193",
    "title": "Cross-Trajectory Representation Learning for Zero-Shot Generalization in  RL",
    "abstract": "A highly desirable property of a reinforcement learning (RL) agent -- and a\nmajor difficulty for deep RL approaches -- is the ability to generalize\npolicies learned on a few tasks over a high-dimensional observation space to\nsimilar tasks not seen during training. Many promising approaches to this\nchallenge consider RL as a process of training two functions simultaneously: a\ncomplex nonlinear encoder that maps high-dimensional observations to a latent\nrepresentation space, and a simple linear policy over this space. We posit that\na superior encoder for zero-shot generalization in RL can be trained by using\nsolely an auxiliary SSL objective if the training process encourages the\nencoder to map behaviorally similar observations to similar representations, as\nreward-based signal can cause overfitting in the encoder (Raileanu et al.,\n2021). We propose Cross-Trajectory Representation Learning (CTRL), a method\nthat runs within an RL agent and conditions its encoder to recognize behavioral\nsimilarity in observations by applying a novel SSL objective to pairs of\ntrajectories from the agent's policies. CTRL can be viewed as having the same\neffect as inducing a pseudo-bisimulation metric but, crucially, avoids the use\nof rewards and associated overfitting risks. Our experiments ablate various\ncomponents of CTRL and demonstrate that in combination with PPO it achieves\nbetter generalization performance on the challenging Procgen benchmark suite\n(Cobbe et al., 2020).",
    "descriptor": "",
    "authors": [
      "Bogdan Mazoure",
      "Ahmed M. Ahmed",
      "Patrick MacAlpine",
      "R Devon Hjelm",
      "Andrey Kolobov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02193"
  },
  {
    "id": "arXiv:2106.02194",
    "title": "A Unified Bi-directional Model for Natural and Artificial Trust in  Human-Robot Collaboration",
    "abstract": "We introduce a novel capabilities-based bi-directional multi-task trust model\nthat can be used for trust prediction from either a human or a robotic trustor\nagent. Tasks are represented in terms of their capability requirements, while\ntrustee agents are characterized by their individual capabilities. Trustee\nagents' capabilities are not deterministic; they are represented by belief\ndistributions. For each task to be executed, a higher level of trust is\nassigned to trustee agents who have demonstrated that their capabilities exceed\nthe task's requirements. We report results of an online experiment with 284\nparticipants, revealing that our model outperforms existing models for\nmulti-task trust prediction from a human trustor. We also present simulations\nof the model for determining trust from a robotic trustor. Our model is useful\nfor control authority allocation applications that involve human-robot teams.",
    "descriptor": "\nComments: 8 pages, 5 figures, conditionally accepted for publication on IEEE Robotics and Automation Letters\n",
    "authors": [
      "Hebert Azevedo-Sa",
      "X. Jessie Yang",
      "Lionel P. Robert Jr.",
      "Dawn M. Tilbury"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02194"
  },
  {
    "id": "arXiv:2106.02195",
    "title": "Celebrating Diversity in Shared Multi-Agent Reinforcement Learning",
    "abstract": "Recently, deep multi-agent reinforcement learning (MARL) has shown the\npromise to solve complex cooperative tasks. Its success is partly because of\nparameter sharing among agents. However, such sharing may lead agents to behave\nsimilarly and limit their coordination capacity. In this paper, we aim to\nintroduce diversity in both optimization and representation of shared\nmulti-agent reinforcement learning. Specifically, we propose an\ninformation-theoretical regularization to maximize the mutual information\nbetween agents' identities and their trajectories, encouraging extensive\nexploration and diverse individualized behaviors. In representation, we\nincorporate agent-specific modules in the shared neural network architecture,\nwhich are regularized by L1-norm to promote learning sharing among agents while\nkeeping necessary diversity. Empirical results show that our method achieves\nstate-of-the-art performance on Google Research Football and super hard\nStarCraft II micromanagement tasks.",
    "descriptor": "",
    "authors": [
      "Chenghao Li",
      "Chengjie WU",
      "Tonghan Wang",
      "Jun Yang",
      "Qianchuan Zhao",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02195"
  },
  {
    "id": "arXiv:2106.02197",
    "title": "Top-$k$ Regularization for Supervised Feature Selection",
    "abstract": "Feature selection identifies subsets of informative features and reduces\ndimensions in the original feature space, helping provide insights into data\ngeneration or a variety of domain problems. Existing methods mainly depend on\nfeature scoring functions or sparse regularizations; nonetheless, they have\nlimited ability to reconcile the representativeness and inter-correlations of\nfeatures. In this paper, we introduce a novel, simple yet effective\nregularization approach, named top-$k$ regularization, to supervised feature\nselection in regression and classification tasks. Structurally, the top-$k$\nregularization induces a sub-architecture on the architecture of a learning\nmodel to boost its ability to select the most informative features and model\ncomplex nonlinear relationships simultaneously. Theoretically, we derive and\nmathematically prove a uniform approximation error bound for using this\napproach to approximate high-dimensional sparse functions. Extensive\nexperiments on a wide variety of benchmarking datasets show that the top-$k$\nregularization is effective and stable for supervised feature selection.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Xinxing Wu",
      "Qiang Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02197"
  },
  {
    "id": "arXiv:2106.02199",
    "title": "Clock Rigidity and Joint Position-Clock Estimation in Ultra-Wideband  Sensor Networks",
    "abstract": "Joint position and clock estimation is crucial in many wireless sensor\nnetwork applications, especially in distance-based estimation with\ntime-of-arrival (TOA) measurement. In this work, we consider a TOA-based\nultra-wideband (UWB) sensor network, propose a novel clock rigidity theory and\ninvestigate the relation between the network graph properties and the\nfeasibility of clock estimation with TOA timestamp measurements. It is shown\nthat a clock framework can be uniquely determined up to a translation of clock\noffset and a scaling of all clock parameters if and only if it is\ninfinitesimally clock rigid. We further prove that a clock framework is\ninfinitesimally clock rigid if its underlying graph is generically bearing\nrigid in 2-dimensional space with at least one redundant edge. Combined with\ndistance rigidity, clock rigidity provides a graphical approach for analyzing\nthe joint position and clock problem. It is shown that a position-clock\nframework can be uniquely determined up to some trivial variations\ncorresponding to both position and clock if and only if it is infinitesimally\njoint rigid. Simulation results are presented to demonstrate the clock\nestimation and joint position-clock estimation.",
    "descriptor": "",
    "authors": [
      "Ruixin Wen",
      "Eric Schoof",
      "Airlie Chapman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2106.02199"
  },
  {
    "id": "arXiv:2106.02200",
    "title": "PSY-TaLiRo: A Python Toolbox for Search-Based Test Generation for  Cyber-Physical Systems",
    "abstract": "In this paper, we present the Python package PSY-TaLiRo which is a toolbox\nfor temporal logic robustness guided falsification of Cyber-Physical Systems\n(CPS). PSY-TaLiRo is a completely modular toolbox supporting multiple temporal\nlogic offline monitors as well as optimization engines for test case\ngeneration. Among the benefits of PSY-TaLiRo is that it supports search-based\ntest generation for many different types of systems under test. All PSY-TaLiRo\nmodules can be fully modified by the users to support new optimization and\nrobustness computation engines as well as any System under Test (SUT).",
    "descriptor": "",
    "authors": [
      "Quinn Thibeault",
      "Jacob Anderson",
      "Aniruddh Chandratre",
      "Giulia Pedrielli",
      "Georgios Fainekos"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02200"
  },
  {
    "id": "arXiv:2106.02203",
    "title": "Adam in Private: Secure and Fast Training of Deep Neural Networks with  Adaptive Moment Estimation",
    "abstract": "Privacy-preserving machine learning (PPML) aims at enabling machine learning\n(ML) algorithms to be used on sensitive data. We contribute to this line of\nresearch by proposing a framework that allows efficient and secure evaluation\nof full-fledged state-of-the-art ML algorithms via secure multi-party\ncomputation (MPC). This is in contrast to most prior works, which substitute ML\nalgorithms with approximated \"MPC-friendly\" variants. A drawback of the latter\napproach is that fine-tuning of the combined ML and MPC algorithms is required,\nwhich might lead to less efficient algorithms or inferior quality ML. This is\nan issue for secure deep neural networks (DNN) training in particular, as this\ninvolves arithmetic algorithms thought to be \"MPC-unfriendly\", namely, integer\ndivision, exponentiation, inversion, and square root. In this work, we propose\nsecure and efficient protocols for the above seemingly MPC-unfriendly\ncomputations. Our protocols are three-party protocols in the honest-majority\nsetting, and we propose both passively secure and actively secure with abort\nvariants. A notable feature of our protocols is that they simultaneously\nprovide high accuracy and efficiency. This framework enables us to efficiently\nand securely compute modern ML algorithms such as Adam and the softmax function\n\"as is\", without resorting to approximations. As a result, we obtain secure DNN\ntraining that outperforms state-of-the-art three-party systems; our full\ntraining is up to 6.7 times faster than just the online phase of the recently\nproposed FALCON@PETS'21 on a standard benchmark network. We further perform\nmeasurements on real-world DNNs, AlexNet and VGG16. The performance of our\nframework is up to a factor of about 12-14 faster for AlexNet and 46-48 faster\nfor VGG16 to achieve an accuracy of 70% and 75%, respectively, when compared to\nFALCON.",
    "descriptor": "\nComments: 24 pages, 13 tables\n",
    "authors": [
      "Nuttapong Attrapadung",
      "Koki Hamada",
      "Dai Ikarashi",
      "Ryo Kikuchi",
      "Takahiro Matsuda",
      "Ibuki Mishina",
      "Hiraku Morita",
      "Jacob C. N. Schuldt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02203"
  },
  {
    "id": "arXiv:2106.02204",
    "title": "Detecting and Adapting to Novelty in Games",
    "abstract": "Open-world novelty occurs when the rules of an environment can change\nabruptly, such as when a game player encounters \"house rules\". To address\nopen-world novelty, game playing agents must be able to detect when novelty is\ninjected, and to quickly adapt to the new rules. We propose a model-based\nreinforcement learning approach where game state and rules are represented as\nknowledge graphs. The knowledge graph representation of the state and rules\nallows novelty to be detected as changes in the knowledge graph, assists with\nthe training of deep reinforcement learners, and enables imagination-based\nre-training where the agent uses the knowledge graph to perform look-ahead.",
    "descriptor": "\nComments: 10 pages, 5 figures, Accepted to the AAAI21 Workshop on on Reinforcement Learning in Games\n",
    "authors": [
      "Xiangyu Peng",
      "Jonathan C. Balloch",
      "Mark O. Riedl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02204"
  },
  {
    "id": "arXiv:2106.02205",
    "title": "Enabling Lightweight Fine-tuning for Pre-trained Language Model  Compression based on Matrix Product Operators",
    "abstract": "This paper presents a novel pre-trained language models (PLM) compression\napproach based on the matrix product operator (short as MPO) from quantum\nmany-body physics. It can decompose an original matrix into central tensors\n(containing the core information) and auxiliary tensors (with only a small\nproportion of parameters). With the decomposed MPO structure, we propose a\nnovel fine-tuning strategy by only updating the parameters from the auxiliary\ntensors, and design an optimization algorithm for MPO-based approximation over\nstacked network architectures. Our approach can be applied to the original or\nthe compressed PLMs in a general way, which derives a lighter network and\nsignificantly reduces the parameters to be fine-tuned. Extensive experiments\nhave demonstrated the effectiveness of the proposed approach in model\ncompression, especially the reduction in finetuning parameters (91% reduction\non average).",
    "descriptor": "\nComments: Accepted by ACL 2021 main conference\n",
    "authors": [
      "Peiyu Liu",
      "Ze-Feng Gao",
      "Wayne Xin Zhao",
      "Z.Y. Xie",
      "Zhong-Yi Lu",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.02205"
  },
  {
    "id": "arXiv:2106.02206",
    "title": "Stochastic Iterative Graph Matching",
    "abstract": "Recent works leveraging Graph Neural Networks to approach graph matching\ntasks have shown promising results. Recent progress in learning discrete\ndistributions poses new opportunities for learning graph matching models. In\nthis work, we propose a new model, Stochastic Iterative Graph MAtching (SIGMA),\nto address the graph matching problem. Our model defines a distribution of\nmatchings for a graph pair so the model can explore a wide range of possible\nmatchings. We further introduce a novel multi-step matching procedure, which\nlearns how to refine a graph pair's matching results incrementally. The model\nalso includes dummy nodes so that the model does not have to find matchings for\nnodes without correspondence. We fit this model to data via scalable stochastic\noptimization. We conduct extensive experiments across synthetic graph datasets\nas well as biochemistry and computer vision applications. Across all tasks, our\nresults show that SIGMA can produce significantly improved graph matching\nresults compared to state-of-the-art models. Ablation studies verify that each\nof our components (stochastic training, iterative matching, and dummy nodes)\noffers noticeable improvement.",
    "descriptor": "\nComments: To appear in ICML 2021\n",
    "authors": [
      "Linfeng Liu",
      "Michael C. Hughes",
      "Soha Hassoun",
      "Li-Ping Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02206"
  },
  {
    "id": "arXiv:2106.02207",
    "title": "Barcode Method for Generative Model Evaluation driven by Topological  Data Analysis",
    "abstract": "Evaluating the performance of generative models in image synthesis is a\nchallenging task. Although the Fr\\'echet Inception Distance is a widely\naccepted evaluation metric, it integrates different aspects (e.g., fidelity and\ndiversity) of synthesized images into a single score and assumes the normality\nof embedded vectors. Recent methods such as precision-and-recall and its\nvariants such as density-and-coverage have been developed to separate fidelity\nand diversity based on k-nearest neighborhood methods. In this study, we\npropose an algorithm named barcode, which is inspired by the topological data\nanalysis and is almost free of assumption and hyperparameter selections. In\nextensive experiments on real-world datasets as well as theoretical approach on\nhigh-dimensional normal samples, it was found that the 'usual' normality\nassumption of embedded vectors has several drawbacks. The experimental results\ndemonstrate that barcode outperforms other methods in evaluating fidelity and\ndiversity of GAN outputs. Official codes can be found in\nhttps://github.com/minjeekim00/Barcode.",
    "descriptor": "",
    "authors": [
      "Ryoungwoo Jang",
      "Minjee Kim",
      "Da-in Eun",
      "Kyungjin Cho",
      "Jiyeon Seo",
      "Namkug Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.02207"
  },
  {
    "id": "arXiv:2106.02208",
    "title": "BERTTune: Fine-Tuning Neural Machine Translation with BERTScore",
    "abstract": "Neural machine translation models are often biased toward the limited\ntranslation references seen during training. To amend this form of overfitting,\nin this paper we propose fine-tuning the models with a novel training objective\nbased on the recently-proposed BERTScore evaluation metric. BERTScore is a\nscoring function based on contextual embeddings that overcomes the typical\nlimitations of n-gram-based metrics (e.g. synonyms, paraphrases), allowing\ntranslations that are different from the references, yet close in the\ncontextual embedding space, to be treated as substantially correct. To be able\nto use BERTScore as a training objective, we propose three approaches for\ngenerating soft predictions, allowing the network to remain completely\ndifferentiable end-to-end. Experiments carried out over four, diverse language\npairs have achieved improvements of up to 0.58 pp (3.28%) in BLEU score and up\nto 0.76 pp (0.98%) in BERTScore (F_BERT) when fine-tuning a strong baseline.",
    "descriptor": "\nComments: Accepted at ACL 2021\n",
    "authors": [
      "Inigo Jauregi Unanue",
      "Jacob Parnell",
      "Massimo Piccardi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02208"
  },
  {
    "id": "arXiv:2106.02209",
    "title": "Influence of Roles in Decision-Making during OSS Development -- A Study  of Python",
    "abstract": "Governance has been highlighted as a key factor in the success of an Open\nSource Software (OSS) project. It is generally seen that in a mixed meritocracy\nand autocracy governance model, the decision-making (DM) responsibility\nregarding what features are included in the OSS is shared among members from\nselect roles; prominently the project leader. However, less examination has\nbeen made whether members from these roles are also prominent in DM discussions\nand how decisions are made, to show they play an integral role in the success\nof the project. We believe that to establish their influence, it is necessary\nto examine not only discussions of proposals in which the project leader makes\nthe decisions, but also those where others make the decisions. Therefore, in\nthis study, we examine the prominence of members performing different roles in:\n(i) making decisions, (ii) performing certain social roles in DM discussions\n(e.g., discussion starters), (iii) contributing to the OSS development social\nnetwork through DM discussions, and (iv) how decisions are made under both\nscenarios. We examine these aspects in the evolution of the well-known Python\nproject. We carried out a data-driven longitudinal study of their email\ncommunication spanning 20 years, comprising about 1.5 million emails. These\nemails contain decisions for 466 Python Enhancement Proposals (PEPs) that\ndocument the language's evolution. Our findings make the influence of different\nroles transparent to future (new) members, other stakeholders, and more\nbroadly, to the OSS research community.",
    "descriptor": "",
    "authors": [
      "Pankajeshwara Nand Sharma",
      "Bastin Tony Roy Savarimuthu",
      "Nigel Stanger"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.02209"
  },
  {
    "id": "arXiv:2106.02210",
    "title": "NAST: A Non-Autoregressive Generator with Word Alignment for  Unsupervised Text Style Transfer",
    "abstract": "Autoregressive models have been widely used in unsupervised text style\ntransfer. Despite their success, these models still suffer from the content\npreservation problem that they usually ignore part of the source sentence and\ngenerate some irrelevant words with strong styles. In this paper, we propose a\nNon-Autoregressive generator for unsupervised text Style Transfer (NAST), which\nalleviates the problem from two aspects. First, we observe that most words in\nthe transferred sentence can be aligned with related words in the source\nsentence, so we explicitly model word alignments to suppress irrelevant words.\nSecond, existing models trained with the cycle loss align sentences in two\nstylistic text spaces, which lacks fine-grained control at the word level. The\nproposed non-autoregressive generator focuses on the connections between\naligned words, which learns the word-level transfer between styles. For\nexperiments, we integrate the proposed generator into two base models and\nevaluate them on two style transfer tasks. The results show that NAST can\nsignificantly improve the overall performance and provide explainable word\nalignments. Moreover, the non-autoregressive generator achieves over 10x\nspeedups at inference. Our codes are available at\nhttps://github.com/thu-coai/NAST.",
    "descriptor": "\nComments: Accepted by ACL 2021: Findings (long paper)\n",
    "authors": [
      "Fei Huang",
      "Zikai Chen",
      "Chen Henry Wu",
      "Qihan Guo",
      "Xiaoyan Zhu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02210"
  },
  {
    "id": "arXiv:2106.02212",
    "title": "Fuzzy Clustering with Similarity Queries",
    "abstract": "The fuzzy or soft $k$-means objective is a popular generalization of the\nwell-known $k$-means problem, extending the clustering capability of the\n$k$-means to datasets that are uncertain, vague, and otherwise hard to cluster.\nIn this paper, we propose a semi-supervised active clustering framework, where\nthe learner is allowed to interact with an oracle (domain expert), asking for\nthe similarity between a certain set of chosen items. We study the query and\ncomputational complexities of clustering in this framework. We prove that\nhaving a few of such similarity queries enables one to get a polynomial-time\napproximation algorithm to an otherwise conjecturally NP-hard problem. In\nparticular, we provide probabilistic algorithms for fuzzy clustering in this\nsetting that asks $O(\\mathsf{poly}(k)\\log n)$ similarity queries and run with\npolynomial-time-complexity, where $n$ is the number of items. The fuzzy\n$k$-means objective is nonconvex, with $k$-means as a special case, and is\nequivalent to some other generic nonconvex problem such as non-negative matrix\nfactorization. The ubiquitous Lloyd-type algorithms (or,\nexpectation-maximization algorithm) can get stuck at a local minima. Our\nresults show that by making few similarity queries, the problem becomes easier\nto solve. Finally, we test our algorithms over real-world datasets, showing\ntheir effectiveness in real-world applications.",
    "descriptor": "\nComments: 47 pages, 7 figures\n",
    "authors": [
      "Wasim Huleihel",
      "Arya Mazumdar",
      "Soumyabrata Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02212"
  },
  {
    "id": "arXiv:2106.02213",
    "title": "Analysis of the robustness of NMF algorithms",
    "abstract": "We examine three non-negative matrix factorization techniques; L2-norm,\nL1-norm, and L2,1-norm. Our aim is to establish the performance of these\ndifferent approaches, and their robustness in real-world applications such as\nfeature selection while managing computational complexity, sensitivity to noise\nand more. We thoroughly examine each approach from a theoretical perspective,\nand examine the performance of each using a series of experiments drawing on\nboth the ORL and YaleB datasets. We examine the Relative Reconstruction Errors\n(RRE), Average Accuracy and Normalized Mutual Information (NMI) as criteria\nunder a range of simulated noise scenarios.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Alex D\u00edaz",
      "Damian Steele"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02213"
  },
  {
    "id": "arXiv:2106.02216",
    "title": "Fairness-Aware Unsupervised Feature Selection",
    "abstract": "Feature selection is a prevalent data preprocessing paradigm for various\nlearning tasks. Due to the expensive cost of acquiring supervision information,\nunsupervised feature selection sparks great interests recently. However,\nexisting unsupervised feature selection algorithms do not have fairness\nconsiderations and suffer from a high risk of amplifying discrimination by\nselecting features that are over associated with protected attributes such as\ngender, race, and ethnicity. In this paper, we make an initial investigation of\nthe fairness-aware unsupervised feature selection problem and develop a\nprincipled framework, which leverages kernel alignment to find a subset of\nhigh-quality features that can best preserve the information in the original\nfeature space while being minimally correlated with protected attributes.\nSpecifically, different from the mainstream in-processing debiasing methods,\nour proposed framework can be regarded as a model-agnostic debiasing strategy\nthat eliminates biases and discrimination before downstream learning algorithms\nare involved. Experimental results on multiple real-world datasets demonstrate\nthat our framework achieves a good trade-off between utility maximization and\nfairness promotion.",
    "descriptor": "",
    "authors": [
      "Xiaoying Xing",
      "Hongfu Liu",
      "Chen Chen",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02216"
  },
  {
    "id": "arXiv:2106.02220",
    "title": "Fluctuation-dissipation Type Theorem in Stochastic Linear Learning",
    "abstract": "The fluctuation-dissipation theorem (FDT) is a simple yet powerful\nconsequence of the first-order differential equation governing the dynamics of\nsystems subject simultaneously to dissipative and stochastic forces. The linear\nlearning dynamics, in which the input vector maps to the output vector by a\nlinear matrix whose elements are the subject of learning, has a stochastic\nversion closely mimicking the Langevin dynamics when a full-batch gradient\ndescent scheme is replaced by that of stochastic gradient descent. We derive a\ngeneralized FDT for the stochastic linear learning dynamics and verify its\nvalidity among the well-known machine learning data sets such as MNIST,\nCIFAR-10 and EMNIST.",
    "descriptor": "",
    "authors": [
      "Manhyung Han",
      "Jeonghyeok Park",
      "Taewoong Lee",
      "Jung Hoon Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2106.02220"
  },
  {
    "id": "arXiv:2106.02222",
    "title": "History Encoding Representation Design for Human Intention Inference",
    "abstract": "In this extended abstract, we investigate the design of learning\nrepresentation for human intention inference. In our designed human intention\nprediction task, we propose a history encoding representation that is both\ninterpretable and effective for prediction. Through extensive experiments, we\nshow our prediction framework with a history encoding representation design is\nsuccessful on the human intention prediction problem.",
    "descriptor": "",
    "authors": [
      "Zhuo Xu",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02222"
  },
  {
    "id": "arXiv:2106.02223",
    "title": "Learning Elastic Embeddings for Customizing On-Device Recommenders",
    "abstract": "In today's context, deploying data-driven services like recommendation on\nedge devices instead of cloud servers becomes increasingly attractive due to\nprivacy and network latency concerns. A common practice in building compact\non-device recommender systems is to compress their embeddings which are\nnormally the cause of excessive parameterization. However, despite the vast\nvariety of devices and their associated memory constraints, existing\nmemory-efficient recommender systems are only specialized for a fixed memory\nbudget in every design and training life cycle, where a new model has to be\nretrained to obtain the optimal performance while adapting to a smaller/larger\nmemory budget. In this paper, we present a novel lightweight recommendation\nparadigm that allows a well-trained recommender to be customized for arbitrary\ndevice-specific memory constraints without retraining. The core idea is to\ncompose elastic embeddings for each item, where an elastic embedding is the\nconcatenation of a set of embedding blocks that are carefully chosen by an\nautomated search function. Correspondingly, we propose an innovative approach,\nnamely recommendation with universally learned elastic embeddings (RULE). To\nensure the expressiveness of all candidate embedding blocks, RULE enforces a\ndiversity-driven regularization when learning different embedding blocks. Then,\na performance estimator-based evolutionary search function is designed,\nallowing for efficient specialization of elastic embeddings under any memory\nconstraint for on-device recommendation. Extensive experiments on real-world\ndatasets reveal the superior performance of RULE under tight memory budgets.",
    "descriptor": "\nComments: To appear in KDD'21\n",
    "authors": [
      "Tong Chen",
      "Hongzhi Yin",
      "Yujia Zheng",
      "Zi Huang",
      "Yang Wang",
      "Meng Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.02223"
  },
  {
    "id": "arXiv:2106.02225",
    "title": "Materials Representation and Transfer Learning for Multi-Property  Prediction",
    "abstract": "The adoption of machine learning in materials science has rapidly transformed\nmaterials property prediction. Hurdles limiting full capitalization of recent\nadvancements in machine learning include the limited development of methods to\nlearn the underlying interactions of multiple elements, as well as the\nrelationships among multiple properties, to facilitate property prediction in\nnew composition spaces. To address these issues, we introduce the Hierarchical\nCorrelation Learning for Multi-property Prediction (H-CLMP) framework that\nseamlessly integrates (i) prediction using only a material's composition, (ii)\nlearning and exploitation of correlations among target properties in\nmulti-target regression, and (iii) leveraging training data from tangential\ndomains via generative transfer learning. The model is demonstrated for\nprediction of spectral optical absorption of complex metal oxides spanning 69\n3-cation metal oxide composition spaces. H-CLMP accurately predicts non-linear\ncomposition-property relationships in composition spaces for which no training\ndata is available, which broadens the purview of machine learning to the\ndiscovery of materials with exceptional properties. This achievement results\nfrom the principled integration of latent embedding learning, property\ncorrelation learning, generative transfer learning, and attention models. The\nbest performance is obtained using H-CLMP with Transfer learning (H-CLMP(T))\nwherein a generative adversarial network is trained on computational density of\nstates data and deployed in the target domain to augment prediction of optical\nabsorption from composition. H-CLMP(T) aggregates multiple knowledge sources\nwith a framework that is well-suited for multi-target regression across the\nphysical sciences.",
    "descriptor": "\nComments: accepted at the Applied Physics Reviews journal\n",
    "authors": [
      "Shufeng Kong",
      "Dan Guevarra",
      "Carla P. Gomes",
      "John M. Gregoire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02225"
  },
  {
    "id": "arXiv:2106.02227",
    "title": "Conversations Are Not Flat: Modeling the Dynamic Information Flow across  Dialogue Utterances",
    "abstract": "Nowadays, open-domain dialogue models can generate acceptable responses\naccording to the historical context based on the large-scale pre-trained\nlanguage models. However, they generally concatenate the dialogue history\ndirectly as the model input to predict the response, which we named as the flat\npattern and ignores the dynamic information flow across dialogue utterances. In\nthis work, we propose the DialoFlow model, in which we introduce a dynamic flow\nmechanism to model the context flow, and design three training objectives to\ncapture the information dynamics across dialogue utterances by addressing the\nsemantic influence brought about by each utterance in large-scale pre-training.\nExperiments on the multi-reference Reddit Dataset and DailyDialog Dataset\ndemonstrate that our DialoFlow significantly outperforms the DialoGPT on the\ndialogue generation task. Besides, we propose the Flow score, an effective\nautomatic metric for evaluating interactive human-bot conversation quality\nbased on the pre-trained DialoFlow, which presents high chatbot-level\ncorrelation ($r=0.9$) with human ratings among 11 chatbots. Code and\npre-trained models will be public.\n\\footnote{\\url{https://github.com/ictnlp/DialoFlow}}",
    "descriptor": "\nComments: ACL2021 main conference (long paper)\n",
    "authors": [
      "Zekang Li",
      "Jinchao Zhang",
      "Zhengcong Fei",
      "Yang Feng",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02227"
  },
  {
    "id": "arXiv:2106.02228",
    "title": "Addressing Inquiries about History: An Efficient and Practical Framework  for Evaluating Open-domain Chatbot Consistency",
    "abstract": "A good open-domain chatbot should avoid presenting contradictory responses\nabout facts or opinions in a conversational session, known as its consistency\ncapacity. However, evaluating the consistency capacity of a chatbot is still\nchallenging. Employing human judges to interact with chatbots on purpose to\ncheck their capacities is costly and low-efficient, and difficult to get rid of\nsubjective bias. In this paper, we propose the Addressing Inquiries about\nHistory (AIH), an efficient and practical framework for the consistency\nevaluation. At the conversation stage, AIH attempts to address appropriate\ninquiries about the dialogue history to induce the chatbot to redeclare the\nhistorical facts or opinions. We carry out the conversation between chatbots,\nwhich is more efficient than the human-bot interaction and can also alleviate\nthe subjective bias. In this way, we manage to rapidly obtain a dialog session\nthat contains responses with high contradiction possibilities. At the\ncontradiction recognition stage, we can either employ human judges or a natural\nlanguage inference (NLI) model to recognize whether the answers to the\ninquiries are contradictory with history. Finally, we are able to rank chatbots\naccording to the contradiction statistics. Experiments on open-domain chatbots\nshow that our approach can efficiently and reliably assess the consistency\ncapacity of chatbots and achieve a high ranking correlation with the human\nevaluation. We release the framework and hope to help improve the consistency\ncapacity of chatbots. \\footnote{\\url{https://github.com/ictnlp/AIH}}",
    "descriptor": "\nComments: Findings of ACL2021\n",
    "authors": [
      "Zekang Li",
      "Jinchao Zhang",
      "Zhengcong Fei",
      "Yang Feng",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02228"
  },
  {
    "id": "arXiv:2106.02229",
    "title": "RL-DARTS: Differentiable Architecture Search for Reinforcement Learning",
    "abstract": "We introduce RL-DARTS, one of the first applications of Differentiable\nArchitecture Search (DARTS) in reinforcement learning (RL) to search for\nconvolutional cells, applied to the Procgen benchmark. We outline the initial\ndifficulties of applying neural architecture search techniques in RL, and\ndemonstrate that by simply replacing the image encoder with a DARTS supernet,\nour search method is sample-efficient, requires minimal extra compute\nresources, and is also compatible with off-policy and on-policy RL algorithms,\nneeding only minor changes in preexisting code. Surprisingly, we find that the\nsupernet can be used as an actor for inference to generate replay data in\nstandard RL training loops, and thus train end-to-end. Throughout this training\nprocess, we show that the supernet gradually learns better cells, leading to\nalternative architectures which can be highly competitive against manually\ndesigned policies, but also verify previous design choices for RL policies.",
    "descriptor": "\nComments: 19 pages total, 17 figures\n",
    "authors": [
      "Yingjie Miao",
      "Xingyou Song",
      "Daiyi Peng",
      "Summer Yue",
      "Eugene Brevdo",
      "Aleksandra Faust"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02229"
  },
  {
    "id": "arXiv:2106.02232",
    "title": "Language Scaling for Universal Suggested Replies Model",
    "abstract": "We consider the problem of scaling automated suggested replies for Outlook\nemail system to multiple languages. Faced with increased compute requirements\nand low resources for language expansion, we build a single universal model for\nimproving the quality and reducing run-time costs of our production system.\nHowever, restricted data movement across regional centers prevents joint\ntraining across languages. To this end, we propose a multi-task continual\nlearning framework, with auxiliary tasks and language adapters to learn\nuniversal language representation across regions. The experimental results show\npositive cross-lingual transfer across languages while reducing catastrophic\nforgetting across regions. Our online results on real user traffic show\nsignificant gains in CTR and characters saved, as well as 65% training cost\nreduction compared with per-language models. As a consequence, we have scaled\nthe feature in multiple languages including low-resource markets.",
    "descriptor": "",
    "authors": [
      "Qianlan Ying",
      "Payal Bajaj",
      "Budhaditya Deb",
      "Yu Yang",
      "Wei Wang",
      "Bojia Lin",
      "Milad Shokouhi",
      "Xia Song",
      "Yang Yang",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02232"
  },
  {
    "id": "arXiv:2106.02233",
    "title": "A Nearly Optimal All-Pairs Min-Cuts Algorithm in Simple Graphs",
    "abstract": "We give an $n^{2+o(1)}$-time algorithm for finding $s$-$t$ min-cuts for all\npairs of vertices $s$ and $t$ in a simple, undirected graph on $n$ vertices. We\ndo so by constructing a Gomory-Hu tree (or cut equivalent tree) in the same\nrunning time, thereby improving on the recent bound of $\\tilde{O}(n^{2.5})$ by\nAbboud et al. (FOCS 2021). Our running time is nearly optimal as a function of\n$n$.",
    "descriptor": "",
    "authors": [
      "Jason Li",
      "Debmalya Panigrahi",
      "Thatchaphol Saranurak"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.02233"
  },
  {
    "id": "arXiv:2106.02234",
    "title": "Discovery of Causal Additive Models in the Presence of Unobserved  Variables",
    "abstract": "Causal discovery from data affected by unobserved variables is an important\nbut difficult problem to solve. The effects that unobserved variables have on\nthe relationships between observed variables are more complex in nonlinear\ncases than in linear cases. In this study, we focus on causal additive models\nin the presence of unobserved variables. Causal additive models exhibit\nstructural equations that are additive in the variables and error terms. We\ntake into account the presence of not only unobserved common causes but also\nunobserved intermediate variables. Our theoretical results show that, when the\ncausal relationships are nonlinear and there are unobserved variables, it is\nnot possible to identify all the causal relationships between observed\nvariables through regression and independence tests. However, our theoretical\nresults also show that it is possible to avoid incorrect inferences. We propose\na method to identify all the causal relationships that are theoretically\npossible to identify without being biased by unobserved variables. The\nempirical results using artificial data and simulated functional magnetic\nresonance imaging (fMRI) data show that our method effectively infers causal\nstructures in the presence of unobserved variables.",
    "descriptor": "\nComments: This is an extended version of the UAI 2021 paper entitled \"Causal Additive Models with Unobserved Variables\"\n",
    "authors": [
      "Takashi Nicholas Maeda",
      "Shohei Shimizu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02234"
  },
  {
    "id": "arXiv:2106.02237",
    "title": "Memory Approximate Message Passing",
    "abstract": "Approximate message passing (AMP) is a low-cost iterative\nparameter-estimation technique for certain high-dimensional linear systems with\nnon-Gaussian distributions. However, AMP only applies to independent\nidentically distributed (IID) transform matrices, but may become unreliable for\nother matrix ensembles, especially for ill-conditioned ones. To handle this\ndifficulty, orthogonal/vector AMP (OAMP/VAMP) was proposed for general\nright-unitarily-invariant matrices. However, the Bayes-optimal OAMP/VAMP\nrequires high-complexity linear minimum mean square error estimator. To solve\nthe disadvantages of AMP and OAMP/VAMP, this paper proposes a memory AMP\n(MAMP), in which a long-memory matched filter is proposed for interference\nsuppression. The complexity of MAMP is comparable to AMP. The asymptotic\nGaussianity of estimation errors in MAMP is guaranteed by the orthogonality\nprinciple. A state evolution is derived to asymptotically characterize the\nperformance of MAMP. Based on the state evolution, the relaxation parameters\nand damping vector in MAMP are optimized. For all right-unitarily-invariant\nmatrices, the optimized MAMP converges to OAMP/VAMP, and thus is Bayes-optimal\nif it has a unique fixed point. Finally, simulations are provided to verify the\nvalidity and accuracy of the theoretical results.",
    "descriptor": "\nComments: 6 pages, 5 figures, accepted by IEEE ISIT 2021. arXiv admin note: substantial text overlap with arXiv:2012.10861\n",
    "authors": [
      "Lei Liu",
      "Shunqi Huang",
      "Brian M. Kurkoski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.02237"
  },
  {
    "id": "arXiv:2106.02240",
    "title": "Sneak Attack against Mobile Robotic Networks under Formation Control",
    "abstract": "The security of mobile robotic networks (MRNs) has been an active research\ntopic in recent years. This paper demonstrates that the observable interaction\nprocess of MRNs under formation control will present increasingly severe\nthreats. Specifically, we find that an external attack robot, who has only\npartial observation over MRNs while not knowing the system dynamics or access,\ncan learn the interaction rules from observations and utilize them to replace a\ntarget robot, destroying the cooperation performance of MRNs. We call this\nnovel attack as sneak, which endows the attacker with the intelligence of\nlearning knowledge and is hard to be tackled by traditional defense techniques.\nThe key insight is to separately reveal the internal interaction structure\nwithin robots and the external interaction mechanism with the environment, from\nthe coupled state evolution influenced by the model-unknown rules and\nunobservable part of the MRN. To address this issue, we first provide general\ninteraction process modeling and prove the learnability of the interaction\nrules. Then, with the learned rules, we design an Evaluate-Cut-Restore (ECR)\nattack strategy considering the partial interaction structure and geometric\npattern. We also establish the sufficient conditions for a successful sneak\nwith maximum control impacts over the MRN. Extensive simulations illustrate the\nfeasibility and effectiveness of the proposed attack.",
    "descriptor": "",
    "authors": [
      "Yushan Li",
      "Jianping He",
      "Xuda Ding",
      "Lin Cai",
      "Xinping Guan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02240"
  },
  {
    "id": "arXiv:2106.02241",
    "title": "ERNIE-Tiny : A Progressive Distillation Framework for Pretrained  Transformer Compression",
    "abstract": "Pretrained language models (PLMs) such as BERT adopt a training paradigm\nwhich first pretrain the model in general data and then finetune the model on\ntask-specific data, and have recently achieved great success. However, PLMs are\nnotorious for their enormous parameters and hard to be deployed on real-life\napplications. Knowledge distillation has been prevailing to address this\nproblem by transferring knowledge from a large teacher to a much smaller\nstudent over a set of data. We argue that the selection of thee three key\ncomponents, namely teacher, training data, and learning objective, is crucial\nto the effectiveness of distillation. We, therefore, propose a four-stage\nprogressive distillation framework ERNIE-Tiny to compress PLM, which varies the\nthree components gradually from general level to task-specific level.\nSpecifically, the first stage, General Distillation, performs distillation with\nguidance from pretrained teacher, gerenal data and latent distillation loss.\nThen, General-Enhanced Distillation changes teacher model from pretrained\nteacher to finetuned teacher. After that, Task-Adaptive Distillation shifts\ntraining data from general data to task-specific data. In the end,\nTask-Specific Distillation, adds two additional losses, namely Soft-Label and\nHard-Label loss onto the last stage. Empirical results demonstrate the\neffectiveness of our framework and generalization gain brought by ERNIE-Tiny.In\nparticular, experiments show that a 4-layer ERNIE-Tiny maintains over\n98.0%performance of its 12-layer teacher BERT base on GLUE benchmark,\nsurpassing state-of-the-art (SOTA) by 1.0% GLUE score with the same amount of\nparameters. Moreover, ERNIE-Tiny achieves a new compression SOTA on five\nChinese NLP tasks, outperforming BERT base by 0.4% accuracy with 7.5x fewer\nparameters and9.4x faster inference speed.",
    "descriptor": "",
    "authors": [
      "Weiyue Su",
      "Xuyi Chen",
      "Shikun Feng",
      "Jiaxiang Liu",
      "Weixin Liu",
      "Yu Sun",
      "Hao Tian",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02241"
  },
  {
    "id": "arXiv:2106.02242",
    "title": "Scalable Transformers for Neural Machine Translation",
    "abstract": "Transformer has been widely adopted in Neural Machine Translation (NMT)\nbecause of its large capacity and parallel training of sequence generation.\nHowever, the deployment of Transformer is challenging because different\nscenarios require models of different complexities and scales. Naively training\nmultiple Transformers is redundant in terms of both computation and memory. In\nthis paper, we propose a novel scalable Transformers, which naturally contains\nsub-Transformers of different scales and have shared parameters. Each\nsub-Transformer can be easily obtained by cropping the parameters of the\nlargest Transformer. A three-stage training scheme is proposed to tackle the\ndifficulty of training the scalable Transformers, which introduces additional\nsupervisions from word-level and sequence-level self-distillation. Extensive\nexperiments were conducted on WMT EN-De and En-Fr to validate our proposed\nscalable Transformers.",
    "descriptor": "",
    "authors": [
      "Peng Gao",
      "Shijie Geng",
      "Xiaogang Wang",
      "Jifeng Dai",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02242"
  },
  {
    "id": "arXiv:2106.02243",
    "title": "Over-the-Air Computation via Broadband Channels",
    "abstract": "Over-the-air computation (AirComp) has been recognized as a low-latency\nsolution for wireless sensor data fusion, where multiple sensors send their\nmeasurement signals to a receiver simultaneously for computation. Most existing\nwork only considered performing AirComp over a single frequency channel.\nHowever, for a sensor network with a massive number of nodes, a single\nfrequency channel may not be sufficient to accommodate the large number of\nsensors, and the AirComp performance will be very limited. So it is highly\ndesirable to have more frequency channels for large-scale AirComp systems to\nbenefit from multi-channel diversity. In this letter, we propose an\n$M$-frequency AirComp system, where each sensor selects a subset of the $M$\nfrequencies and broadcasts its signal over these channels under a certain power\nconstraint. We derive the optimal sensors' transmission and receiver's signal\nprocessing methods separately, and develop an algorithm for joint design to\nachieve the best AirComp performance. Numerical results show that increasing\none frequency channel can improve the AirComp performance by threefold compared\nto the single-frequency case.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Tianrui Qin",
      "Wanchun Liu",
      "Branka Vucetic",
      "Yonghui Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.02243"
  },
  {
    "id": "arXiv:2106.02245",
    "title": "Towards offensive language detection and reduction in four Software  Engineering communities",
    "abstract": "Software Engineering (SE) communities such as Stack Overflow have become\nunwelcoming, particularly through members' use of offensive language. Research\nhas shown that offensive language drives users away from active engagement\nwithin these platforms. This work aims to explore this issue more broadly by\ninvestigating the nature of offensive language in comments posted by users in\nfour prominent SE platforms - GitHub, Gitter, Slack and Stack Overflow (SO). It\nproposes an approach to detect and classify offensive language in SE\ncommunities by adopting natural language processing and deep learning\ntechniques. Further, a Conflict Reduction System (CRS), which identifies\noffence and then suggests what changes could be made to minimize offence has\nbeen proposed. Beyond showing the prevalence of offensive language in over 1\nmillion comments from four different communities which ranges from 0.07% to\n0.43%, our results show promise in successful detection and classification of\nsuch language. The CRS system has the potential to drastically reduce manual\nmoderation efforts to detect and reduce offence in SE communities.",
    "descriptor": "",
    "authors": [
      "Jithin Cheriyan",
      "Bastin Tony Roy Savarimuthu",
      "Stephen Cranefield"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.02245"
  },
  {
    "id": "arXiv:2106.02246",
    "title": "Deep Contextual Learners for Protein Networks",
    "abstract": "Spatial context is central to understanding health and disease. Yet reference\nprotein interaction networks lack such contextualization, thereby limiting the\nstudy of where protein interactions likely occur in the human body.\nContextualized protein interactions could better characterize genes with\ndisease-specific interactions and elucidate diseases' manifestation in specific\ncell types. Here, we introduce AWARE, a graph neural message passing approach\nto inject cellular and tissue context into protein embeddings. AWARE optimizes\nfor a multi-scale embedding space, whose structure reflects the topology of\ncell type specific networks. We construct a multi-scale network of the Human\nCell Atlas and apply AWARE to learn protein, cell type, and tissue embeddings\nthat uphold cell type and tissue hierarchies. We demonstrate AWARE on the novel\ntask of predicting whether a gene is associated with a disease and where it\nmost likely manifests in the human body. AWARE embeddings outperform global\nembeddings by at least 12.5%, highlighting the importance of contextual\nlearners for protein networks.",
    "descriptor": "",
    "authors": [
      "Michelle M. Li",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Molecular Networks (q-bio.MN)",
      "Quantitative Methods (q-bio.QM)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2106.02246"
  },
  {
    "id": "arXiv:2106.02248",
    "title": "Knowing the No-match: Entity Alignment with Dangling Cases",
    "abstract": "This paper studies a new problem setting of entity alignment for knowledge\ngraphs (KGs). Since KGs possess different sets of entities, there could be\nentities that cannot find alignment across them, leading to the problem of\ndangling entities. As the first attempt to this problem, we construct a new\ndataset and design a multi-task learning framework for both entity alignment\nand dangling entity detection. The framework can opt to abstain from predicting\nalignment for the detected dangling entities. We propose three techniques for\ndangling entity detection that are based on the distribution of\nnearest-neighbor distances, i.e., nearest neighbor classification, marginal\nranking and background ranking. After detecting and removing dangling entities,\nan incorporated entity alignment model in our framework can provide more robust\nalignment for remaining entities. Comprehensive experiments and analyses\ndemonstrate the effectiveness of our framework. We further discover that the\ndangling entity detection module can, in turn, improve alignment learning and\nthe final performance. The contributed resource is publicly available to foster\nfurther research.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Zequn Sun",
      "Muhao Chen",
      "Wei Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02248"
  },
  {
    "id": "arXiv:2106.02249",
    "title": "Robustifying Reinforcement Learning Policies with $\\mathcal{L}_1$  Adaptive Control",
    "abstract": "A reinforcement learning (RL) policy trained in a nominal environment could\nfail in a new/perturbed environment due to the existence of dynamic variations.\nExisting robust methods try to obtain a fixed policy for all envisioned dynamic\nvariation scenarios through robust or adversarial training. These methods could\nlead to conservative performance due to emphasis on the worst case, and often\ninvolve tedious modifications to the training environment. We propose an\napproach to robustifying a pre-trained non-robust RL policy with\n$\\mathcal{L}_1$ adaptive control. Leveraging the capability of an\n$\\mathcal{L}_1$ control law in the fast estimation of and active compensation\nfor dynamic variations, our approach can significantly improve the robustness\nof an RL policy trained in a standard (i.e., non-robust) way, either in a\nsimulator or in the real world. Numerical experiments are provided to validate\nthe efficacy of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Yikun Cheng",
      "Pan Zhao",
      "Manan Gandhi",
      "Bo Li",
      "Evangelos Theodorou",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02249"
  },
  {
    "id": "arXiv:2106.02250",
    "title": "A General Method for Event Detection on Social Media",
    "abstract": "Event detection on social media has attracted a number of researches, given\nthe recent availability of large volumes of social media discussions. Previous\nworks on social media event detection either assume a specific type of event,\nor assume certain behavior of observed variables. In this paper, we propose a\ngeneral method for event detection on social media that makes few assumptions.\nThe main assumption we make is that when an event occurs, affected semantic\naspects will behave differently from its usual behavior. We generalize the\nrepresentation of time units based on word embeddings of social media text, and\npropose an algorithm to detect events in time series in a general sense. In the\nexperimental evaluation, we use a novel setting to test if our method and\nbaseline methods can exhaustively catch all real-world news in the test period.\nThe evaluation results show that when the event is quite unusual with regard to\nthe base social media discussion, it can be captured more effectively with our\nmethod. Our method can be easily implemented and can be treated as a starting\npoint for more specific applications.",
    "descriptor": "\nComments: Accepted for presentation in the 25th European Conference on Advances in Databases and Information Systems (ADBIS 2021)\n",
    "authors": [
      "Yihong Zhang",
      "Masumi Shirakawa",
      "Takahiro Hara"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.02250"
  },
  {
    "id": "arXiv:2106.02252",
    "title": "Disentangling Dense Multi-Cable Knots",
    "abstract": "Disentangling two or more cables requires many steps to remove crossings\nbetween and within cables. We formalize the problem of disentangling multiple\ncables and present an algorithm, Iterative Reduction Of Non-planar Multiple\ncAble kNots (IRON-MAN), that outputs robot actions to remove crossings from\nmulti-cable knotted structures. We instantiate this algorithm with a learned\nperception system, inspired by prior work in single-cable untying that given an\nimage input, can disentangle two-cable twists, three-cable braids, and knots of\ntwo or three cables, such as overhand, square, carrick bend, sheet bend, crown,\nand fisherman's knots. IRON-MAN keeps track of task-relevant keypoints\ncorresponding to target cable endpoints and crossings and iteratively\ndisentangles the cables by identifying and undoing crossings that are critical\nto knot structure. Using a da Vinci surgical robot, we experimentally evaluate\nthe effectiveness of IRON-MAN on untangling multi-cable knots of types that\nappear in the training data, as well as generalizing to novel classes of\nmulti-cable knots. Results suggest that IRON-MAN is effective in disentangling\nknots involving up to three cables with 80.5% success and generalizing to knot\ntypes that are not present during training, with cables of both distinct or\nidentical colors.",
    "descriptor": "\nComments: First three authors contributed equally\n",
    "authors": [
      "Vainavi Viswanath",
      "Jennifer Grannen",
      "Priya Sundaresan",
      "Brijen Thananjeyan",
      "Ashwin Balakrishna",
      "Ellen Novoseller",
      "Jeffrey Ichnowski",
      "Michael Laskey",
      "Joseph E. Gonzalez",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02252"
  },
  {
    "id": "arXiv:2106.02253",
    "title": "X-volution: On the unification of convolution and self-attention",
    "abstract": "Convolution and self-attention are acting as two fundamental building blocks\nin deep neural networks, where the former extracts local image features in a\nlinear way while the latter non-locally encodes high-order contextual\nrelationships. Though essentially complementary to each other, i.e.,\nfirst-/high-order, stat-of-the-art architectures, i.e., CNNs or transformers\nlack a principled way to simultaneously apply both operations in a single\ncomputational module, due to their heterogeneous computing pattern and\nexcessive burden of global dot-product for visual tasks. In this work, we\ntheoretically derive a global self-attention approximation scheme, which\napproximates a self-attention via the convolution operation on transformed\nfeatures. Based on the approximated scheme, we establish a multi-branch\nelementary module composed of both convolution and self-attention operation,\ncapable of unifying both local and non-local feature interaction. Importantly,\nonce trained, this multi-branch module could be conditionally converted into a\nsingle standard convolution operation via structural re-parameterization,\nrendering a pure convolution styled operator named X-volution, ready to be\nplugged into any modern networks as an atomic operation. Extensive experiments\ndemonstrate that the proposed X-volution, achieves highly competitive visual\nunderstanding improvements (+1.2% top-1 accuracy on ImageNet classification,\n+1.7 box AP and +1.5 mask AP on COCO detection and segmentation).",
    "descriptor": "",
    "authors": [
      "Xuanhong Chen",
      "Hang Wang",
      "Bingbing Ni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02253"
  },
  {
    "id": "arXiv:2106.02256",
    "title": "Using Social Media Background to Improve Cold-start Recommendation Deep  Models",
    "abstract": "In recommender systems, a cold-start problem occurs when there is no past\ninteraction record associated with the user or item. Typical solutions to the\ncold-start problem make use of contextual information, such as user demographic\nattributes or product descriptions. A group of works have shown that social\nmedia background can help predicting temporal phenomenons such as product sales\nand stock price movements. In this work, our goal is to investigate whether\nsocial media background can be used as extra contextual information to improve\nrecommendation models. Based on an existing deep neural network model, we\nproposed a method to represent temporal social media background as embeddings\nand fuse them as an extra component in the model. We conduct experimental\nevaluations on a real-world e-commerce dataset and a Twitter dataset. The\nresults show that our method of fusing social media background with the\nexisting model does generally improve recommendation performance. In some cases\nthe recommendation accuracy measured by hit-rate@K doubles after fusing with\nsocial media background. Our findings can be beneficial for future recommender\nsystem designs that consider complex temporal information representing social\ninterests.",
    "descriptor": "\nComments: Accepted for presentation in IJCNN 2021\n",
    "authors": [
      "Yihong Zhang",
      "Takuya Maekawa",
      "Takahiro Hara"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02256"
  },
  {
    "id": "arXiv:2106.02257",
    "title": "Visual Question Rewriting for Increasing Response Rate",
    "abstract": "When a human asks questions online, or when a conversational virtual agent\nasks human questions, questions triggering emotions or with details might more\nlikely to get responses or answers. we explore how to automatically rewrite\nnatural language questions to improve the response rate from people. In\nparticular, a new task of Visual Question Rewriting(VQR) task is introduced to\nexplore how visual information can be used to improve the new questions. A data\nset containing around 4K bland questions, attractive questions and images\ntriples is collected. We developed some baseline sequence to sequence models\nand more advanced transformer based models, which take a bland question and a\nrelated image as input and output a rewritten question that is expected to be\nmore attractive. Offline experiments and mechanical Turk based evaluations show\nthat it is possible to rewrite bland questions in a more detailed and\nattractive way to increase the response rate, and images can be helpful.",
    "descriptor": "",
    "authors": [
      "Jiayi Wei",
      "Xilian Li",
      "Yi Zhang",
      "Xin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02257"
  },
  {
    "id": "arXiv:2106.02258",
    "title": "Exploring Adversarial Learning for Deep Semi-Supervised Facial Action  Unit Recognition",
    "abstract": "Current works formulate facial action unit (AU) recognition as a supervised\nlearning problem, requiring fully AU-labeled facial images during training. It\nis challenging if not impossible to provide AU annotations for large numbers of\nfacial images. Fortunately, AUs appear on all facial images, whether manually\nlabeled or not, satisfy the underlying anatomic mechanisms and human behavioral\nhabits. In this paper, we propose a deep semi-supervised framework for facial\naction unit recognition from partially AU-labeled facial images. Specifically,\nthe proposed deep semi-supervised AU recognition approach consists of a deep\nrecognition network and a discriminator D. The deep recognition network R\nlearns facial representations from large-scale facial images and AU classifiers\nfrom limited ground truth AU labels. The discriminator D is introduced to\nenforce statistical similarity between the AU distribution inherent in ground\ntruth AU labels and the distribution of the predicted AU labels from labeled\nand unlabeled facial images. The deep recognition network aims to minimize\nrecognition loss from the labeled facial images, to faithfully represent\ninherent AU distribution for both labeled and unlabeled facial images, and to\nconfuse the discriminator. During training, the deep recognition network R and\nthe discriminator D are optimized alternately. Thus, the inherent AU\ndistributions caused by underlying anatomic mechanisms are leveraged to\nconstruct better feature representations and AU classifiers from partially\nAU-labeled data during training. Experiments on two benchmark databases\ndemonstrate that the proposed approach successfully captures AU distributions\nthrough adversarial learning and outperforms state-of-the-art AU recognition\nwork.",
    "descriptor": "",
    "authors": [
      "Shangfei Wang",
      "Yanan Chang",
      "Guozhu Peng",
      "Bowen Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02258"
  },
  {
    "id": "arXiv:2106.02260",
    "title": "Regularization and Reparameterization Avoid Vanishing Gradients in  Sigmoid-Type Networks",
    "abstract": "Deep learning requires several design choices, such as the nodes' activation\nfunctions and the widths, types, and arrangements of the layers. One\nconsideration when making these choices is the vanishing-gradient problem,\nwhich is the phenomenon of algorithms getting stuck at suboptimal points due to\nsmall gradients. In this paper, we revisit the vanishing-gradient problem in\nthe context of sigmoid-type activation. We use mathematical arguments to\nhighlight two different sources of the phenomenon, namely large individual\nparameters and effects across layers, and to illustrate two simple remedies,\nnamely regularization and rescaling. We then demonstrate the effectiveness of\nthe two remedies in practice. In view of the vanishing-gradient problem being a\nmain reason why tanh and other sigmoid-type activation has become much less\npopular than relu-type activation, our results bring sigmoid-type activation\nback to the table.",
    "descriptor": "",
    "authors": [
      "Leni Ven",
      "Johannes Lederer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02260"
  },
  {
    "id": "arXiv:2106.02262",
    "title": "Envy-free division of multi-layered cakes",
    "abstract": "This problem, recently proposed by Hosseini et al. (2020), captures several\nnatural scenarios such as the allocation of multiple facilities over time where\neach agent can utilize at most one facility simultaneously, and the allocation\nof tasks over time where each agent can perform at most one task\nsimultaneously. We establish the existence of an envy-free multi-division that\nis both non-overlapping and contiguous within each layered cake when the number\n$n$ of agents is a prime power and the number $m$ of layers is at most $n$,\nthus providing a positive partial answer to a recent open question. To achieve\nthis, we employ a new approach based on a general fixed point theorem,\noriginally proven by Volovikov (1996), and recently applied by Joji\\'{c},\nPanina, and \\v{Z}ivaljevi\\'{c} (2020) to the envy-free division problem of a\ncake. We further show that for a two-layered cake division among three agents\nwith monotone preferences, an $\\varepsilon$-approximate envy-free solution that\nis both non-overlapping and contiguous can be computed in logarithmic time of\n$1/{\\varepsilon}$.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Ayumi Igarashi",
      "Fr\u00e9d\u00e9ric Meunier"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.02262"
  },
  {
    "id": "arXiv:2106.02264",
    "title": "Tractable Regularization of Probabilistic Circuits",
    "abstract": "Probabilistic Circuits (PCs) are a promising avenue for probabilistic\nmodeling. They combine advantages of probabilistic graphical models (PGMs) with\nthose of neural networks (NNs). Crucially, however, they are tractable\nprobabilistic models, supporting efficient and exact computation of many\nprobabilistic inference queries, such as marginals and MAP. Further, since PCs\nare structured computation graphs, they can take advantage of\ndeep-learning-style parameter updates, which greatly improves their\nscalability. However, this innovation also makes PCs prone to overfitting,\nwhich has been observed in many standard benchmarks. Despite the existence of\nabundant regularization techniques for both PGMs and NNs, they are not\neffective enough when applied to PCs. Instead, we re-think regularization for\nPCs and propose two intuitive techniques, data softening and entropy\nregularization, that both take advantage of PCs' tractability and still have an\nefficient implementation as a computation graph. Specifically, data softening\nprovides a principled way to add uncertainty in datasets in closed form, which\nimplicitly regularizes PC parameters. To learn parameters from a softened\ndataset, PCs only need linear time by virtue of their tractability. In entropy\nregularization, the exact entropy of the distribution encoded by a PC can be\nregularized directly, which is again infeasible for most other density\nestimation models. We show that both methods consistently improve the\ngeneralization performance of a wide variety of PCs. Moreover, when paired with\na simple PC structure, we achieved state-of-the-art results on 10 out of 20\nstandard discrete density estimation benchmarks.",
    "descriptor": "",
    "authors": [
      "Anji Liu",
      "Guy Van den Broeck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02264"
  },
  {
    "id": "arXiv:2106.02266",
    "title": "SAND-mask: An Enhanced Gradient Masking Strategy for the Discovery of  Invariances in Domain Generalization",
    "abstract": "A major bottleneck in the real-world applications of machine learning models\nis their failure in generalizing to unseen domains whose data distribution is\nnot i.i.d to the training domains. This failure often stems from learning\nnon-generalizable features in the training domains that are spuriously\ncorrelated with the label of data. To address this shortcoming, there has been\na growing surge of interest in learning good explanations that are hard to\nvary, which is studied under the notion of Out-of-Distribution (OOD)\nGeneralization. The search for good explanations that are \\textit{invariant}\nacross different domains can be seen as finding local (global) minimas in the\nloss landscape that hold true across all of the training domains. In this\npaper, we propose a masking strategy, which determines a continuous weight\nbased on the agreement of gradients that flow in each edge of network, in order\nto control the amount of update received by the edge in each step of\noptimization. Particularly, our proposed technique referred to as \"Smoothed-AND\n(SAND)-masking\", not only validates the agreement in the direction of gradients\nbut also promotes the agreement among their magnitudes to further ensure the\ndiscovery of invariances across training domains. SAND-mask is validated over\nthe Domainbed benchmark for domain generalization and significantly improves\nthe state-of-the-art accuracy on the Colored MNIST dataset while providing\ncompetitive results on other domain generalization datasets.",
    "descriptor": "",
    "authors": [
      "Soroosh Shahtalebi",
      "Jean-Christophe Gagnon-Audet",
      "Touraj Laleh",
      "Mojtaba Faramarzi",
      "Kartik Ahuja",
      "Irina Rish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02266"
  },
  {
    "id": "arXiv:2106.02267",
    "title": "Ukiyo-e Analysis and Creativity with Attribute and Geometry Annotation",
    "abstract": "The study of Ukiyo-e, an important genre of pre-modern Japanese art, focuses\non the object and style like other artwork researches. Such study has benefited\nfrom the renewed interest by the machine learning community in culturally\nimportant topics, leading to interdisciplinary works including collections of\nimages, quantitative approaches, and machine learning-based creativities. They,\nhowever, have several drawbacks, and it remains challenging to integrate these\nworks into a comprehensive view. To bridge this gap, we propose a holistic\napproach We first present a large-scale Ukiyo-e dataset with coherent semantic\nlabels and geometric annotations, then show its value in a quantitative study\nof Ukiyo-e paintings' object using these labels and annotations. We further\ndemonstrate the machine learning methods could help style study through soft\ncolor decomposition of Ukiyo-e, and finally provides joint insights into object\nand style by composing sketches and colors using colorization. Dataset\navailable at https://github.com/rois-codh/arc-ukiyoe-faces",
    "descriptor": "",
    "authors": [
      "Yingtao Tian",
      "Tarin Clanuwat",
      "Chikahiko Suzuki",
      "Asanobu Kitamoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02267"
  },
  {
    "id": "arXiv:2106.02273",
    "title": "Towards the adoption of model-based engineering for the development of  safety-critical systems in industrial practice",
    "abstract": "Model-based engineering promises to boost productivity and quality of complex\nsystems development. In the context of safety-critical systems, a traditionally\nhighly regulated and conservative domain, the use of models gained importance\nin the recent years. In this paper, we present a set of practical challenges in\ndeveloping safety-critical systems with the help of several examples of\ndevelopment projects that belong to different application domains. Following\nthis, we show how could the adoption of model-based engineering for the\ndevelopment of safety-critical systems cope with these challenges.",
    "descriptor": "",
    "authors": [
      "Marc Zeller",
      "Daniel Ratiu",
      "Kai Hoefig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.02273"
  },
  {
    "id": "arXiv:2106.02274",
    "title": "Transforming Fading Channel from Fast to Slow: Intelligent Refracting  Surface Aided High-Mobility Communication",
    "abstract": "Intelligent reflecting/refracting surface (IRS) has recently emerged as a\npromising solution to reconfigure wireless propagation environment for\nenhancing the communication performance. In this paper, we study a new\nIRS-aided high-mobility communication system by employing the intelligent\nrefracting surface with a high-speed vehicle to aid its passenger's\ncommunication with a remote base station (BS). Due to the environment's random\nscattering and vehicle's high mobility, a rapidly time-varying channel is\ntypically resulted between the static BS and fast-moving IRS/user, which\nrenders the channel estimation for IRS with a large number of elements more\nchallenging. In order to reap the high IRS passive beamforming gain with low\nchannel training overhead, we propose a new and efficient transmission protocol\nto achieve both IRS channel estimation and refraction optimization for data\ntransmission. Specifically, by exploiting the quasi-static channel between the\nIRS and user both moving at the same high speed as well as the line-of-sight\n(LoS) dominant channel between the BS and IRS, the user first estimates the LoS\ncomponent of the cascaded BS-IRS-user channel, based on which IRS passive\nrefraction is designed to maximize the corresponding IRS-refracted channel\ngain. Then, the user estimates the resultant IRS-refracted channel as well as\nthe non-IRS-refracted channel for setting an additional common phase shift at\nall IRS refracting elements so as to align these two channels for maximizing\nthe overall channel gain for data transmission. Simulation results show\nsignificant performance improvement of the proposed design as compared to\nvarious benchmark schemes. The proposed on-vehicle IRS system is further\ncompared with a baseline scheme of deploying fixed intelligent reflecting\nsurfaces on the roadside to assist high-speed vehicular communications, which\nachieves significant rate improvement.",
    "descriptor": "\nComments: Conference version (arXiv:2011.03147)\n",
    "authors": [
      "Zixuan Huang",
      "Beixiong Zheng",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.02274"
  },
  {
    "id": "arXiv:2106.02277",
    "title": "Glance-and-Gaze Vision Transformer",
    "abstract": "Recently, there emerges a series of vision Transformers, which show superior\nperformance with a more compact model size than conventional convolutional\nneural networks, thanks to the strong ability of Transformers to model\nlong-range dependencies. However, the advantages of vision Transformers also\ncome with a price: Self-attention, the core part of Transformer, has a\nquadratic complexity to the input sequence length. This leads to a dramatic\nincrease of computation and memory cost with the increase of sequence length,\nthus introducing difficulties when applying Transformers to the vision tasks\nthat require dense predictions based on high-resolution feature maps. In this\npaper, we propose a new vision Transformer, named Glance-and-Gaze Transformer\n(GG-Transformer), to address the aforementioned issues. It is motivated by the\nGlance and Gaze behavior of human beings when recognizing objects in natural\nscenes, with the ability to efficiently model both long-range dependencies and\nlocal context. In GG-Transformer, the Glance and Gaze behavior is realized by\ntwo parallel branches: The Glance branch is achieved by performing\nself-attention on the adaptively-dilated partitions of the input, which leads\nto a linear complexity while still enjoying a global receptive field; The Gaze\nbranch is implemented by a simple depth-wise convolutional layer, which\ncompensates local image context to the features obtained by the Glance\nmechanism. We empirically demonstrate our method achieves consistently superior\nperformance over previous state-of-the-art Transformers on various vision tasks\nand benchmarks. The codes and models will be made available at\nhttps://github.com/yucornetto/GG-Transformer.",
    "descriptor": "\nComments: codes and models will be made available at this https URL\n",
    "authors": [
      "Qihang Yu",
      "Yingda Xia",
      "Yutong Bai",
      "Yongyi Lu",
      "Alan Yuille",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02277"
  },
  {
    "id": "arXiv:2106.02278",
    "title": "AgreeSum: Agreement-Oriented Multi-Document Summarization",
    "abstract": "We aim to renew interest in a particular multi-document summarization (MDS)\ntask which we call AgreeSum: agreement-oriented multi-document summarization.\nGiven a cluster of articles, the goal is to provide abstractive summaries that\nrepresent information common and faithful to all input articles. Given the lack\nof existing datasets, we create a dataset for AgreeSum, and provide annotations\non article-summary entailment relations for a subset of the clusters in the\ndataset. We aim to create strong baselines for the task by applying the\ntop-performing pretrained single-document summarization model PEGASUS onto\nAgreeSum, leveraging both annotated clusters by supervised losses, and\nunannotated clusters by T5-based entailment-related and language-related\nlosses. Compared to other baselines, both automatic evaluation and human\nevaluation show better article-summary and cluster-summary entailment in\ngenerated summaries. On a separate note, we hope that our article-summary\nentailment annotations contribute to the community's effort in improving\nabstractive summarization faithfulness.",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Richard Yuanzhe Pang",
      "Adam D. Lelkes",
      "Vinh Q. Tran",
      "Cong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02278"
  },
  {
    "id": "arXiv:2106.02280",
    "title": "Human-Adversarial Visual Question Answering",
    "abstract": "Performance on the most commonly used Visual Question Answering dataset (VQA\nv2) is starting to approach human accuracy. However, in interacting with\nstate-of-the-art VQA models, it is clear that the problem is far from being\nsolved. In order to stress test VQA models, we benchmark them against\nhuman-adversarial examples. Human subjects interact with a state-of-the-art VQA\nmodel, and for each image in the dataset, attempt to find a question where the\nmodel's predicted answer is incorrect. We find that a wide range of\nstate-of-the-art models perform poorly when evaluated on these examples. We\nconduct an extensive analysis of the collected adversarial examples and provide\nguidance on future research directions. We hope that this Adversarial VQA\n(AdVQA) benchmark can help drive progress in the field and advance the state of\nthe art.",
    "descriptor": "\nComments: 22 pages, 13 figures. First two authors contributed equally\n",
    "authors": [
      "Sasha Sheng",
      "Amanpreet Singh",
      "Vedanuj Goswami",
      "Jose Alberto Lopez Magana",
      "Wojciech Galuba",
      "Devi Parikh",
      "Douwe Kiela"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02280"
  },
  {
    "id": "arXiv:2106.02282",
    "title": "Decoupled Dialogue Modeling and Semantic Parsing for Multi-Turn  Text-to-SQL",
    "abstract": "Recently, Text-to-SQL for multi-turn dialogue has attracted great interest.\nHere, the user input of the current turn is parsed into the corresponding SQL\nquery of the appropriate database, given all previous dialogue history. Current\napproaches mostly employ end-to-end models and consequently face two\nchallenges. First, dialogue history modeling and Text-to-SQL parsing are\nimplicitly combined, hence it is hard to carry out interpretable analysis and\nobtain targeted improvement. Second, SQL annotation of multi-turn dialogue is\nvery expensive, leading to training data sparsity. In this paper, we propose a\nnovel decoupled multi-turn Text-to-SQL framework, where an utterance rewrite\nmodel first explicitly solves completion of dialogue context, and then a\nsingle-turn Text-to-SQL parser follows. A dual learning approach is also\nproposed for the utterance rewrite model to address the data sparsity problem.\nCompared with end-to-end approaches, the proposed decoupled method can achieve\nexcellent performance without any annotated in-domain data. With just a few\nannotated rewrite cases, the decoupled method outperforms the released\nstate-of-the-art end-to-end models on both SParC and CoSQL datasets.",
    "descriptor": "\nComments: 12 pages, 3 figures, accepted to Findings of ACL 2021\n",
    "authors": [
      "Zhi Chen",
      "Lu Chen Hanqi Li",
      "Ruisheng Cao",
      "Da Ma",
      "Mengyue Wu",
      "Kai Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02282"
  },
  {
    "id": "arXiv:2106.02283",
    "title": "Privacy Preference Signals: Past, Present, Future",
    "abstract": "Privacy preference signals are digital representations of how users want\ntheir personal data to be processed. Such signals must be adopted by both the\nsender (users) and intended recipients (data processors). Adoption represents a\ncoordination problem that remains unsolved despite efforts dating back to the\n1990s. Browsers implemented standards like the Platform for Privacy Preferences\n(P3P) and Do Not Track (DNT), but vendors profiting from personal data faced\nfew incentives to receive and respect the expressed wishes of data subjects. In\nthe wake of recent privacy laws, a coalition of AdTech firms published the\nTransparency and Consent Framework (TCF), which defines an opt-in consent\nsignal. This paper integrates post-GDPR developments into the wider history of\nprivacy preference signals. Our main contribution is a high-frequency\nlongitudinal study describing how TCF signal gained dominance as of February\n2021. We explore which factors correlate with adoption at the website level.\nBoth the number of third parties on a website and the presence of Google Ads\nare associated with higher adoption of TCF. Further, we show that vendors acted\nas early adopters of TCF 2.0 and provide two case-studies describing how\nConsent Management Providers shifted existing customers to TCF 2.0. We sketch\nways forward for a pro-privacy signal.",
    "descriptor": "\nComments: To appear in Proceedings on Privacy Enhancing Technologies (PETS) 2021 Issue 4\n",
    "authors": [
      "Maximilian Hils",
      "Daniel W. Woods",
      "Rainer B\u00f6hme"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.02283"
  },
  {
    "id": "arXiv:2106.02285",
    "title": "Subdivision-Based Mesh Convolution Networks",
    "abstract": "Convolutional neural networks (CNNs) have made great breakthroughs in 2D\ncomputer vision. However, the irregular structure of meshes makes it hard to\nexploit the power of CNNs directly. A subdivision surface provides a\nhierarchical multi-resolution structure, and each face in a closed 2-manifold\ntriangle mesh is exactly adjacent to three faces. Motivated by these two\nproperties, this paper introduces a novel and flexible CNN framework, named\nSubdivNet, for 3D triangle meshes with Loop subdivision sequence connectivity.\nMaking an analogy between mesh faces and pixels in a 2D image allows us to\npresent a mesh convolution operator to aggregate local features from adjacent\nfaces. By exploiting face neighborhoods, this convolution can support standard\n2D convolutional network concepts, e.g. variable kernel size, stride, and\ndilation. Based on the multi-resolution hierarchy, we propose a spatial uniform\npooling layer which merges four faces into one and an upsampling method which\nsplits one face into four. As a result, many popular 2D CNN architectures can\nbe readily adapted to processing 3D meshes. Meshes with arbitrary connectivity\ncan be remeshed to hold Loop subdivision sequence connectivity via\nself-parameterization, making SubdivNet a general approach. Experiments on mesh\nclassification, segmentation, correspondence, and retrieval from the real-world\ndemonstrate the effectiveness and efficiency of SubdivNet.",
    "descriptor": "\nComments: Codes are available in this https URL\n",
    "authors": [
      "Shi-Min Hu",
      "Zheng-Ning Liu",
      "Meng-Hao Guo",
      "Jun-Xiong Cai",
      "Jiahui Huang",
      "Tai-Jiang Mu",
      "Ralph R. Martin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02285"
  },
  {
    "id": "arXiv:2106.02287",
    "title": "Dutch Named Entity Recognition and De-identification Methods for the  Human Resource Domain",
    "abstract": "The human resource (HR) domain contains various types of privacy-sensitive\ntextual data, such as e-mail correspondence and performance appraisal. Doing\nresearch on these documents brings several challenges, one of them\nanonymisation. In this paper, we evaluate the current Dutch text\nde-identification methods for the HR domain in four steps. First, by updating\none of these methods with the latest named entity recognition (NER) models. The\nresult is that the NER model based on the CoNLL 2002 corpus in combination with\nthe BERTje transformer give the best combination for suppressing persons\n(recall 0.94) and locations (recall 0.82). For suppressing gender, DEDUCE is\nperforming best (recall 0.53). Second NER evaluation is based on both strict\nde-identification of entities (a person must be suppressed as a person) and\nthird evaluation on a loose sense of de-identification (no matter what how a\nperson is suppressed, as long it is suppressed). In the fourth and last step a\nnew kind of NER dataset is tested for recognising job titles in texts.",
    "descriptor": "",
    "authors": [
      "Cha\u00efm van Toledo",
      "Friso van Dijk",
      "Marco Spruit"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02287"
  },
  {
    "id": "arXiv:2106.02288",
    "title": "Tackling the Background Bias in Sparse Object Detection via Cropped  Windows",
    "abstract": "Object detection on Unmanned Aerial Vehicles (UAVs) is still a challenging\ntask. The recordings are mostly sparse and contain only small objects. In this\nwork, we propose a simple tiling method that improves the detection capability\nin the remote sensing case without modifying the model itself. By reducing the\nbackground bias and enabling the usage of higher image resolutions during\ntraining, our method can improve the performance of models substantially. The\nprocedure was validated on three different data sets and outperformed similar\napproaches in performance and speed.",
    "descriptor": "\nComments: Submitted (WACV2022)\n",
    "authors": [
      "Leon Amadeus Varga",
      "Andreas Zell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02288"
  },
  {
    "id": "arXiv:2106.02289",
    "title": "Modeling the Unigram Distribution",
    "abstract": "The unigram distribution is the non-contextual probability of finding a\nspecific word form in a corpus. While of central importance to the study of\nlanguage, it is commonly approximated by each word's sample frequency in the\ncorpus. This approach, being highly dependent on sample size, assigns zero\nprobability to any out-of-vocabulary (oov) word form. As a result, it produces\nnegatively biased probabilities for any oov word form, while positively biased\nprobabilities to in-corpus words. In this work, we argue in favor of properly\nmodeling the unigram distribution -- claiming it should be a central task in\nnatural language processing. With this in mind, we present a novel model for\nestimating it in a language (a neuralization of Goldwater et al.'s (2011)\nmodel) and show it produces much better estimates across a diverse set of 7\nlanguages than the na\\\"ive use of neural character-level language models.",
    "descriptor": "\nComments: Irene Nikkarinen and Tiago Pimentel contributed equally to this work. Accepted to the findings of ACL 2021. Code available in this https URL\n",
    "authors": [
      "Irene Nikkarinen",
      "Tiago Pimentel",
      "Dami\u00e1n E. Blasi",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02289"
  },
  {
    "id": "arXiv:2106.02291",
    "title": "Finite element stress analysis of a combined stacker-reclaimer machine:  A design audit report",
    "abstract": "Design audit or design verification is an important step in engineering of\nheavy mobile materials handling equipment. Usually, the costumers employ third\nparties for audition of contractors engineering. Here a part of design audit of\na combined stacker-reclaimer machine is reported. This equipment is designed\nand constructed by a local supplier in Iran for the iron ore pelletizing plants\nat GOHARZAMIN Iron Ore Company. The structure plays an important role in mobile\nmaterial handling machines such as Stackers and Reclaimers and its failure and\ndamage may cause considerable financial and human life losses. In this report\nthe undercarriage of stacker-reclaimer machine including gantry and traveling\nsystem are numerically analyzed. The Finite Element Method is used for stress\nprediction under the critical operating loads according to the design\nstandards. The critical areas of the undercarriage are identified and it is\nobserved that, the maximum stress is in the safe range.",
    "descriptor": "",
    "authors": [
      "Erfan Khodabandeh",
      "Shahaboddin Amini",
      "Aliakbar Taghipour"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02291"
  },
  {
    "id": "arXiv:2106.02293",
    "title": "Cross-language Sentence Selection via Data Augmentation and Rationale  Training",
    "abstract": "This paper proposes an approach to cross-language sentence selection in a\nlow-resource setting. It uses data augmentation and negative sampling\ntechniques on noisy parallel sentence data to directly learn a cross-lingual\nembedding-based query relevance model. Results show that this approach performs\nas well as or better than multiple state-of-the-art machine translation +\nmonolingual retrieval systems trained on the same parallel data. Moreover, when\na rationale training secondary objective is applied to encourage the model to\nmatch word alignment hints from a phrase-based statistical machine translation\nmodel, consistent improvements are seen across three language pairs\n(English-Somali, English-Swahili and English-Tagalog) over a variety of\nstate-of-the-art baselines.",
    "descriptor": "\nComments: ACL 2021 main conference\n",
    "authors": [
      "Yanda Chen",
      "Chris Kedzie",
      "Suraj Nair",
      "Petra Galu\u0161\u010d\u00e1kov\u00e1",
      "Rui Zhang",
      "Douglas W. Oard",
      "Kathleen McKeown"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.02293"
  },
  {
    "id": "arXiv:2106.02295",
    "title": "Differentiable Dynamic Quantization with Mixed Precision and Adaptive  Resolution",
    "abstract": "Model quantization is challenging due to many tedious hyper-parameters such\nas precision (bitwidth), dynamic range (minimum and maximum discrete values)\nand stepsize (interval between discrete values). Unlike prior arts that\ncarefully tune these values, we present a fully differentiable approach to\nlearn all of them, named Differentiable Dynamic Quantization (DDQ), which has\nseveral benefits. (1) DDQ is able to quantize challenging lightweight\narchitectures like MobileNets, where different layers prefer different\nquantization parameters. (2) DDQ is hardware-friendly and can be easily\nimplemented using low-precision matrix-vector multiplication, making it capable\nin many hardware such as ARM. (3) Extensive experiments show that DDQ\noutperforms prior arts on many networks and benchmarks, especially when models\nare already efficient and compact. e.g., DDQ is the first approach that\nachieves lossless 4-bit quantization for MobileNetV2 on ImageNet.",
    "descriptor": "\nComments: Accepted by ICML 2021\n",
    "authors": [
      "Zhang Zhaoyang",
      "Shao Wenqi",
      "Gu Jinwei",
      "Wang Xiaogang",
      "Luo Ping"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02295"
  },
  {
    "id": "arXiv:2106.02299",
    "title": "MASA-SR: Matching Acceleration and Spatial Adaptation for  Reference-Based Image Super-Resolution",
    "abstract": "Reference-based image super-resolution (RefSR) has shown promising success in\nrecovering high-frequency details by utilizing an external reference image\n(Ref). In this task, texture details are transferred from the Ref image to the\nlow-resolution (LR) image according to their point- or patch-wise\ncorrespondence. Therefore, high-quality correspondence matching is critical. It\nis also desired to be computationally efficient. Besides, existing RefSR\nmethods tend to ignore the potential large disparity in distributions between\nthe LR and Ref images, which hurts the effectiveness of the information\nutilization. In this paper, we propose the MASA network for RefSR, where two\nnovel modules are designed to address these problems. The proposed Match &\nExtraction Module significantly reduces the computational cost by a\ncoarse-to-fine correspondence matching scheme. The Spatial Adaptation Module\nlearns the difference of distribution between the LR and Ref images, and remaps\nthe distribution of Ref features to that of LR features in a spatially adaptive\nway. This scheme makes the network robust to handle different reference images.\nExtensive quantitative and qualitative experiments validate the effectiveness\nof our proposed model.",
    "descriptor": "\nComments: Accepted by CVPR 2021\n",
    "authors": [
      "Liying Lu",
      "Wenbo Li",
      "Xin Tao",
      "Jiangbo Lu",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02299"
  },
  {
    "id": "arXiv:2106.02300",
    "title": "AdvPicker: Effectively Leveraging Unlabeled Data via Adversarial  Discriminator for Cross-Lingual NER",
    "abstract": "Neural methods have been shown to achieve high performance in Named Entity\nRecognition (NER), but rely on costly high-quality labeled data for training,\nwhich is not always available across languages. While previous works have shown\nthat unlabeled data in a target language can be used to improve cross-lingual\nmodel performance, we propose a novel adversarial approach (AdvPicker) to\nbetter leverage such data and further improve results. We design an adversarial\nlearning framework in which an encoder learns entity domain knowledge from\nlabeled source-language data and better shared features are captured via\nadversarial training - where a discriminator selects less language-dependent\ntarget-language data via similarity to the source language. Experimental\nresults on standard benchmark datasets well demonstrate that the proposed\nmethod benefits strongly from this data selection process and outperforms\nexisting state-of-the-art methods; without requiring any additional external\nresources (e.g., gazetteers or via machine translation).",
    "descriptor": "\nComments: Code is publicly available at this https URL\n",
    "authors": [
      "Weile Chen",
      "Huiqiang Jiang",
      "Qianhui Wu",
      "B\u00f6rje F. Karlsson",
      "Yi Guan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02300"
  },
  {
    "id": "arXiv:2106.02301",
    "title": "Event Classification with Multi-step Machine Learning",
    "abstract": "The usefulness and value of Multi-step Machine Learning (ML), where a task is\norganized into connected sub-tasks with known intermediate inference goals, as\nopposed to a single large model learned end-to-end without intermediate\nsub-tasks, is presented. Pre-optimized ML models are connected and better\nperformance is obtained by re-optimizing the connected one. The selection of an\nML model from several small ML model candidates for each sub-task has been\nperformed by using the idea based on Neural Architecture Search (NAS). In this\npaper, Differentiable Architecture Search (DARTS) and Single Path One-Shot NAS\n(SPOS-NAS) are tested, where the construction of loss functions is improved to\nkeep all ML models smoothly learning. Using DARTS and SPOS-NAS as an\noptimization and selection as well as the connections for multi-step machine\nlearning systems, we find that (1) such a system can quickly and successfully\nselect highly performant model combinations, and (2) the selected models are\nconsistent with baseline algorithms, such as grid search, and their outputs are\nwell controlled.",
    "descriptor": "",
    "authors": [
      "Masahiko Saito",
      "Tomoe Kishimoto",
      "Yuya Kaneta",
      "Taichi Itoh",
      "Yoshiaki Umeda",
      "Junichi Tanaka",
      "Yutaro Iiyama",
      "Ryu Sawada",
      "Koji Terashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02301"
  },
  {
    "id": "arXiv:2106.02304",
    "title": "Low-bandwidth Modular Mathematical Modeling of DC Microgrid Systems for  Control Development with Application to Shipboard Power Systems",
    "abstract": "In recent years, DC and AC microgrid (MG) systems have attracted a major\nattention due to various potential for integration of future technology into\nconventional systems and control. The integration of such technology requires\nappropriate tools for complex design, analysis and optimization. This paper\npresents a mathematical low-bandwidth modeling (LBM) approach that can be used\nfor control development in DC and further be extended to AC MG systems. In this\nwork, first a simplified mathematical model of a medium voltage DC (MVDC)\nshipboard MG system is presented, next, the overall system-level connection\nconvention is presented to display the overall mathematical coupling of the\nindividual sub-systems, then, a simplified example of the control development\nis presented, and last, the overall system under a test scenario is implemented\nin Simulink Real-time.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Mehrzad Mohammadi Bijaieh",
      "Satish Vedula",
      "Olugbenga Moses Anubi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.02304"
  },
  {
    "id": "arXiv:2106.02305",
    "title": "Local Adaptivity in Federated Learning: Convergence and Consistency",
    "abstract": "The federated learning (FL) framework trains a machine learning model using\ndecentralized data stored at edge client devices by periodically aggregating\nlocally trained models. Popular optimization algorithms of FL use vanilla\n(stochastic) gradient descent for both local updates at clients and global\nupdates at the aggregating server. Recently, adaptive optimization methods such\nas AdaGrad have been studied for server updates. However, the effect of using\nadaptive optimization methods for local updates at clients is not yet\nunderstood. We show in both theory and practice that while local adaptive\nmethods can accelerate convergence, they can cause a non-vanishing solution\nbias, where the final converged solution may be different from the stationary\npoint of the global objective function. We propose correction techniques to\novercome this inconsistency and complement the local adaptive methods for FL.\nExtensive experiments on realistic federated training tasks show that the\nproposed algorithms can achieve faster convergence and higher test accuracy\nthan the baselines without local adaptivity.",
    "descriptor": "",
    "authors": [
      "Jianyu Wang",
      "Zheng Xu",
      "Zachary Garrett",
      "Zachary Charles",
      "Luyang Liu",
      "Gauri Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02305"
  },
  {
    "id": "arXiv:2106.02306",
    "title": "Automatic Patch Linkage Detection in Code Review Using TextualContent  and File Location Features",
    "abstract": "Context: Contemporary code review tools are a popular choice for software\nquality assurance. Using these tools, reviewers are able to post a linkage\nbetween two patches during a review discussion. Large development teams that\nuse a review-then-commit model risk being unaware of these linkages. Objective:\nOur objective is to first explore how patch linkage impacts the review process.\nWe then propose and evaluate models that detect patch linkage based on\nrealistic time intervals. Method: First, we carry out an exploratory study on\nthree open source projects to conduct linkage impact analysis using 942\nmanually classified linkages. Second, we propose two techniques using textual\nand file location similarity to build detection models and evaluate their\nperformance. Results: The study provides evidence of latency in the linkage\nnotification. We show that a patch with the Alternative Solution linkage (i.e.,\npatches that implement similar functionality)undergoes a quicker review and\navoids additional revisions after the team has been notified, compared to other\nlinkage types. Our detection model experiments show promising recall rates for\nthe Alternative Solution linkage (from 32% to 95%), but precision has room for\nimprovement. Conclusion: Patch linkage detection is promising, with likely\nimprovements if the practice of posting linkages becomes more prevalent. From\nour implications, this paper lays the groundwork for future research on how to\nincrease patch linkage awareness to facilitate efficient reviews.",
    "descriptor": "",
    "authors": [
      "Dong Wang",
      "Raula Gaikovina Kula",
      "Takashi Ishio",
      "Kenichi Matsumoto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.02306"
  },
  {
    "id": "arXiv:2106.02309",
    "title": "On (co-lex) Ordering Automata",
    "abstract": "The states of a deterministic finite automaton A can be identified with\ncollections of words in Pf(L(A)) -- the set of prefixes of words belonging to\nthe regular language accepted by A. But words can be ordered and among the many\npossible orders a very natural one is the co-lexicographic one. Such\nnaturalness stems from the fact that it suggests a transfer of the order from\nwords to the automaton's states. In a number of papers automata admitting a\ntotal ordering of states coherent with the ordering of the set of words\nreaching them have been proposed. Such class of ordered automata -- the Wheeler\nautomata -- turned out to be efficiently stored/searched using an index.\nUnfortunately not all automata can be totally ordered as previously outlined.\nHowever, automata can always be partially ordered and an intrinsic measure of\ntheir complexity can be defined and effectively determined, as the minimum\nwidth of one of their admissible partial orders. As shown in previous works,\nthis new concept of width of an automaton has useful consequences in the fields\nof graph compression, indexing data structures, and automata theory. In this\npaper we prove that a canonical, minimum-width, partially-ordered automaton\naccepting a language L -- dubbed the Hasse automaton H of L -- can be\nexhibited. H provides, in a precise sense, the best possible way to (partially)\norder the states of any automaton accepting L, as long as we want to maintain\nan operational link with the (co-lexicographic) order of Pf(L(A)). Using H we\nprove that the width of the language can be effectively computed from the\nminimum automaton recognizing the language. Finally, we explore the\nrelationship between two (often conflicting) objectives: minimizing the width\nand minimizing the number of states of an automaton.",
    "descriptor": "",
    "authors": [
      "Giovanna D'Agostino",
      "Nicola Cotumaccio",
      "Alberto Policriti",
      "Nicola Prezza"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02309"
  },
  {
    "id": "arXiv:2106.02310",
    "title": "FedCCEA : A Practical Approach of Client Contribution Evaluation for  Federated Learning",
    "abstract": "Client contribution evaluation, also known as data valuation, is a crucial\napproach in federated learning(FL) for client selection and incentive\nallocation. However, due to restrictions of accessibility of raw data, only\nlimited information such as local weights and local data size of each client is\nopen for quantifying the client contribution. Using data size from available\ninformation, we introduce an empirical evaluation method called Federated\nClient Contribution Evaluation through Accuracy Approximation(FedCCEA). This\nmethod builds the Accuracy Approximation Model(AAM), which estimates a\nsimulated test accuracy using inputs of sampled data size and extracts the\nclients' data quality and data size to measure client contribution. FedCCEA\nstrengthens some advantages: (1) enablement of data size selection to the\nclients, (2) feasible evaluation time regardless of the number of clients, and\n(3) precise estimation in non-IID settings. We demonstrate the superiority of\nFedCCEA compared to previous methods through several experiments: client\ncontribution distribution, client removal, and robustness test to partial\nparticipation.",
    "descriptor": "",
    "authors": [
      "Sung Kuk Shyn",
      "Donghee Kim",
      "Kwangsu Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.02310"
  },
  {
    "id": "arXiv:2106.02312",
    "title": "Verification Tools for Checking some kinds of Testability",
    "abstract": "A locally testable language L is a language with the property that for some\nnon negative integer k, called the order of local testability, whether or not a\nword u is in the language L depends on (1) the prefix and suffix of the word u\nof length k + 1 and (2) the set of intermediate substrings of length k of the\nword u. For given k the language is called k-testable. The local testability\nhas a wide spectrum of generalizations. A set of procedures for deciding\nwhether or not a language given by its minimal automaton or by its syntactic\nsemigroup is locally testable, right or left locally testable, threshold\nlocally testable, strictly locally testable, or piecewise testable was\nimplemented in the package TESTAS written in C=C++. The bounds on order of\nlocal testability of transition graph and order of local testability of\ntransition semigroup are also found. For given k, the k-testability of\ntransition graph is verified. We consider some approaches to verify these\nprocedures and use for this aim some auxiliary programs. The approaches are\nbased on distinct forms of presentation of a given finite automaton and on\nalgebraic properties of the presentation. New proof and fresh wording of\nnecessary and sufficient conditions for local testability of deterministic\nfinite automaton is presented.",
    "descriptor": "\nComments: 14 pages, 6 figures, Algebraic Methods in Language Processing, 2003\n",
    "authors": [
      "A.N. Trahtman"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.02312"
  },
  {
    "id": "arXiv:2106.02315",
    "title": "Intelligent Transportation Systems to Mitigate Road Traffic Congestion",
    "abstract": "Intelligent transport systems have efficiently and effectively proved\nthemselves in settling up the problem of traffic congestion around the world.\nThe multi-agent based transportation system is one of the most important\nintelligent transport systems, which represents an interaction among the\nneighbouring vehicles, drivers, roads, infrastructure and vehicles. In this\npaper, two traffic management models have been created to mitigate congestion\nand to ensure that emergency vehicles arrive as quickly as possible. A\ntool-chain SUMO-JADE is employed to create a microscopic simulation symbolizing\nthe interactions of traffic. The simulation model has showed a significant\nreduction of at least 50% in the average time delay and thus a real improvement\nin the entire journey time.",
    "descriptor": "",
    "authors": [
      "Nizar Hamadeh",
      "Ali Karouni",
      "Zeinab Farhat",
      "Hussein El Ghor",
      "Mohamad El Ghor",
      "Israa Katea"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02315"
  },
  {
    "id": "arXiv:2106.02317",
    "title": "Retrieve & Memorize: Dialog Policy Learning with Multi-Action Memory",
    "abstract": "Dialogue policy learning, a subtask that determines the content of system\nresponse generation and then the degree of task completion, is essential for\ntask-oriented dialogue systems. However, the unbalanced distribution of system\nactions in dialogue datasets often causes difficulty in learning to generate\ndesired actions and responses. In this paper, we propose a\nretrieve-and-memorize framework to enhance the learning of system actions.\nSpecially, we first design a neural context-aware retrieval module to retrieve\nmultiple candidate system actions from the training set given a dialogue\ncontext. Then, we propose a memory-augmented multi-decoder network to generate\nthe system actions conditioned on the candidate actions, which allows the\nnetwork to adaptively select key information in the candidate actions and\nignore noises. We conduct experiments on the large-scale multi-domain\ntask-oriented dialogue dataset MultiWOZ 2.0 and MultiWOZ 2.1.~Experimental\nresults show that our method achieves competitive performance among several\nstate-of-the-art models in the context-to-response generation task.",
    "descriptor": "\nComments: Task oriented dialogue system\n",
    "authors": [
      "Yunhao Li",
      "Yunyi Yang",
      "Xiaojun Quan",
      "Jianxing Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02317"
  },
  {
    "id": "arXiv:2106.02318",
    "title": "AdaTag: Multi-Attribute Value Extraction from Product Profiles with  Adaptive Decoding",
    "abstract": "Automatic extraction of product attribute values is an important enabling\ntechnology in e-Commerce platforms. This task is usually modeled using sequence\nlabeling architectures, with several extensions to handle multi-attribute\nextraction. One line of previous work constructs attribute-specific models,\nthrough separate decoders or entirely separate models. However, this approach\nconstrains knowledge sharing across different attributes. Other contributions\nuse a single multi-attribute model, with different techniques to embed\nattribute information. But sharing the entire network parameters across all\nattributes can limit the model's capacity to capture attribute-specific\ncharacteristics. In this paper we present AdaTag, which uses adaptive decoding\nto handle extraction. We parameterize the decoder with pretrained attribute\nembeddings, through a hypernetwork and a Mixture-of-Experts (MoE) module. This\nallows for separate, but semantically correlated, decoders to be generated on\nthe fly for different attributes. This approach facilitates knowledge sharing,\nwhile maintaining the specificity of each attribute. Our experiments on a\nreal-world e-Commerce dataset show marked improvements over previous methods.",
    "descriptor": "\nComments: Accepted to ACL-IJCNLP 2021\n",
    "authors": [
      "Jun Yan",
      "Nasser Zalmout",
      "Yan Liang",
      "Christan Grant",
      "Xiang Ren",
      "Xin Luna Dong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02318"
  },
  {
    "id": "arXiv:2106.02320",
    "title": "Few-Shot Segmentation via Cycle-Consistent Transformer",
    "abstract": "Few-shot segmentation aims to train a segmentation model that can fast adapt\nto novel classes with few exemplars. The conventional training paradigm is to\nlearn to make predictions on query images conditioned on the features from\nsupport images. Previous methods only utilized the semantic-level prototypes of\nsupport images as the conditional information. These methods cannot utilize all\npixel-wise support information for the query predictions, which is however\ncritical for the segmentation task. In this paper, we focus on utilizing\npixel-wise relationships between support and target images to facilitate the\nfew-shot semantic segmentation task. We design a novel Cycle-Consistent\nTransformer (CyCTR) module to aggregate pixel-wise support features into query\nones. CyCTR performs cross-attention between features from different images,\ni.e. support and query images. We observe that there may exist unexpected\nirrelevant pixel-level support features. Directly performing cross-attention\nmay aggregate these features from support to query and bias the query features.\nThus, we propose using a novel cycle-consistent attention mechanism to filter\nout possible harmful support features and encourage query features to attend to\nthe most informative pixels from support images. Experiments on all few-shot\nsegmentation benchmarks demonstrate that our proposed CyCTR leads to remarkable\nimprovement compared to previous state-of-the-art methods. Specifically, on\nPascal-$5^i$ and COCO-$20^i$ datasets, we achieve 66.6% and 45.6% mIoU for\n5-shot segmentation, outperforming previous state-of-the-art by 4.6% and 7.1%\nrespectively.",
    "descriptor": "",
    "authors": [
      "Gengwei Zhang",
      "Guoliang Kang",
      "Yunchao Wei",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02320"
  },
  {
    "id": "arXiv:2106.02322",
    "title": "UAV Swarm Path Planning with Reinforcement Learning for Field  prospecting",
    "abstract": "Unmanned Aerial Vehicle (UAV) swarms adoption shows a steady growth among\noperators due to the benefits in time and cost arisen from their use. However,\nthis kind of system faces an important problem which is the calculation of many\noptimal paths for each UAV. Solving this problem would allow a to control many\nUAVs without human intervention at the same time while saving battery between\nrecharges and performing several tasks simultaneously. The main aim is to\ndevelop a system capable of calculating the optimal flight path for a UAV\nswarm. The aim of these paths is to achieve full coverage of a flight area for\ntasks such as field prospection. All this, regardless of the size of maps and\nthe number of UAVs in the swarm. It is not necessary to establish targets or\nany other previous knowledge other than the given map. Experiments have been\nconducted to determine whether it is optimal to establish a single control for\nall UAVs in the swarm or a control for each UAV. The results show that it is\nbetter to use one control for all UAVs because of the shorter flight time. In\naddition, the flight time is greatly affected by the size of the map. The\nresults give starting points for future research such as finding the optimal\nmap size for each situation.",
    "descriptor": "",
    "authors": [
      "Alejandro Puente-Castro",
      "Daniel Rivero",
      "Alejandro Pazos",
      "Enrique Fernandez-Blanco"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.02322"
  },
  {
    "id": "arXiv:2106.02324",
    "title": "Hybrid attention network based on progressive embedding scale-context  for crowd counting",
    "abstract": "The existing crowd counting methods usually adopted attention mechanism to\ntackle background noise, or applied multi-level features or multi-scales\ncontext fusion to tackle scale variation. However, these approaches deal with\nthese two problems separately. In this paper, we propose a Hybrid Attention\nNetwork (HAN) by employing Progressive Embedding Scale-context (PES)\ninformation, which enables the network to simultaneously suppress noise and\nadapt head scale variation. We build the hybrid attention mechanism through\nparalleling spatial attention and channel attention module, which makes the\nnetwork to focus more on the human head area and reduce the interference of\nbackground objects. Besides, we embed certain scale-context to the hybrid\nattention along the spatial and channel dimensions for alleviating these\ncounting errors caused by the variation of perspective and head scale. Finally,\nwe propose a progressive learning strategy through cascading multiple hybrid\nattention modules with embedding different scale-context, which can gradually\nintegrate different scale-context information into the current feature map from\nglobal to local. Ablation experiments provides that the network architecture\ncan gradually learn multi-scale features and suppress background noise.\nExtensive experiments demonstrate that HANet obtain state-of-the-art counting\nperformance on four mainstream datasets.",
    "descriptor": "",
    "authors": [
      "Fusen Wang",
      "Jun Sang",
      "Zhongyuan Wu",
      "Qi Liu",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02324"
  },
  {
    "id": "arXiv:2106.02325",
    "title": "ERICA: An Empathetic Android Companion for Covid-19 Quarantine",
    "abstract": "Over the past year, research in various domains, including Natural Language\nProcessing (NLP), has been accelerated to fight against the COVID-19 pandemic,\nyet such research has just started on dialogue systems. In this paper, we\nintroduce an end-to-end dialogue system which aims to ease the isolation of\npeople under self-quarantine. We conduct a control simulation experiment to\nassess the effects of the user interface, a web-based virtual agent called Nora\nvs. the android ERICA via a video call. The experimental results show that the\nandroid offers a more valuable user experience by giving the impression of\nbeing more empathetic and engaging in the conversation due to its nonverbal\ninformation, such as facial expressions and body gestures.",
    "descriptor": "\nComments: Accepted in SIGDIAL 2021\n",
    "authors": [
      "Etsuko Ishii",
      "Genta Indra Winata",
      "Samuel Cahyawijaya",
      "Divesh Lala",
      "Tatsuya Kawahara",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.02325"
  },
  {
    "id": "arXiv:2106.02327",
    "title": "Bi-Granularity Contrastive Learning for Post-Training in Few-Shot Scene",
    "abstract": "The major paradigm of applying a pre-trained language model to downstream\ntasks is to fine-tune it on labeled task data, which often suffers instability\nand low performance when the labeled examples are scarce.~One way to alleviate\nthis problem is to apply post-training on unlabeled task data before\nfine-tuning, adapting the pre-trained model to target domains by contrastive\nlearning that considers either token-level or sequence-level similarity.\nInspired by the success of sequence masking, we argue that both token-level and\nsequence-level similarities can be captured with a pair of masked\nsequences.~Therefore, we propose complementary random masking (CRM) to generate\na pair of masked sequences from an input sequence for sequence-level\ncontrastive learning and then develop contrastive masked language modeling\n(CMLM) for post-training to integrate both token-level and sequence-level\ncontrastive learnings.~Empirical results show that CMLM surpasses several\nrecent post-training methods in few-shot settings without the need for data\naugmentation.",
    "descriptor": "",
    "authors": [
      "Ruikun Luo",
      "Guanhuan Huang",
      "Xiaojun Quan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02327"
  },
  {
    "id": "arXiv:2106.02328",
    "title": "Temporally coherent video anonymization through GAN inpainting",
    "abstract": "This work tackles the problem of temporally coherent face anonymization in\nnatural video streams.We propose JaGAN, a two-stage system starting with\ndetecting and masking out faces with black image patches in all individual\nframes of the video. The second stage leverages a privacy-preserving Video\nGenerative Adversarial Network designed to inpaint the missing image patches\nwith artificially generated faces. Our initial experiments reveal that image\nbased generative models are not capable of inpainting patches showing temporal\ncoherent appearance across neighboring video frames. To address this issue we\nintroduce a newly curated video collection, which is made publicly available\nfor the research community along with this paper. We also introduce the\nIdentity Invariance Score IdI as a means to quantify temporal coherency between\nneighboring frames.",
    "descriptor": "\nComments: Preprint of our FG2021 submission\n",
    "authors": [
      "Thangapavithraa Balaji",
      "Patrick Blies",
      "Georg G\u00f6ri",
      "Raphael Mitsch",
      "Marcel Wasserer",
      "Torsten Sch\u00f6n"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.02328"
  },
  {
    "id": "arXiv:2106.02329",
    "title": "Deep Switching State Space Model (DS$^3$M) for Nonlinear Time Series  Forecasting with Regime Switching",
    "abstract": "We propose a deep switching state space model (DS$^3$M) for efficient\ninference and forecasting of nonlinear time series with irregularly switching\namong various regimes. The switching among regimes is captured by both discrete\nand continuous latent variables with recurrent neural networks. The model is\nestimated with variational inference using a reparameterization trick. We test\nthe approach on a variety of simulated and real datasets. In all cases, DS$^3$M\nachieves competitive performance compared to several state-of-the-art methods\n(e.g. GRU, SRNN, DSARF, SNLDS), with superior forecasting accuracy, convincing\ninterpretability of the discrete latent variables, and powerful representation\nof the continuous latent variables for different kinds of time series.\nSpecifically, the MAPE values increase by 0.09\\% to 15.71\\% against the\nsecond-best performing alternative models.",
    "descriptor": "",
    "authors": [
      "Xiuqin Xu",
      "Ying Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.02329"
  },
  {
    "id": "arXiv:2106.02335",
    "title": "Covering Polygons is Even Harder",
    "abstract": "In the MINIMUM CONVEX COVER (MCC) problem, we are given a simple polygon\n$\\mathcal P$ and an integer $k$, and the question is if there exist $k$ convex\npolygons whose union is $\\mathcal P$. It is known that MCC is\n$\\mathsf{NP}$-hard [Culberson & Reckhow: Covering polygons is hard, FOCS\n1988/Journal of Algorithms 1994] and in $\\exists\\mathbb{R}$ [O'Rourke: The\ncomplexity of computing minimum convex covers for polygons, Allerton 1982]. We\nprove that MCC is $\\exists\\mathbb{R}$-hard, and the problem is thus\n$\\exists\\mathbb{R}$-complete. In other words, the problem is equivalent to\ndeciding whether a system of polynomial equations and inequalities with integer\ncoefficients has a real solution.\nIf a cover for our constructed polygon exists, then so does a cover\nconsisting entirely of triangles. As a byproduct, we therefore also establish\nthat it is $\\exists\\mathbb{R}$-complete to decide whether $k$ triangles cover a\ngiven polygon.\nThe issue that it was not known if finding a minimum cover is in\n$\\mathsf{NP}$ has repeatedly been raised in the literature, and it was\nmentioned as a \"long-standing open question\" already in 2001 [Eidenbenz &\nWidmayer: An approximation algorithm for minimum convex cover with logarithmic\nperformance guarantee, ESA 2001/SIAM Journal on Computing 2003]. We prove that\nassuming the widespread belief that $\\mathsf{NP}\\neq\\exists\\mathbb{R}$, the\nproblem is not in $\\mathsf{NP}$.\nAn implication of the result is that many natural approaches to finding small\ncovers are bound to give suboptimal solutions in some cases, since irrational\ncoordinates of arbitrarily high algebraic degree can be needed for the corners\nof the pieces in an optimal solution.",
    "descriptor": "\nComments: 41 pages, 32 figures\n",
    "authors": [
      "Mikkel Abrahamsen"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.02335"
  },
  {
    "id": "arXiv:2106.02340",
    "title": "cs60075_team2 at SemEval-2021 Task 1 : Lexical Complexity Prediction  using Transformer-based Language Models pre-trained on various text corpora",
    "abstract": "This paper describes the performance of the team cs60075_team2 at SemEval\n2021 Task 1 - Lexical Complexity Prediction. The main contribution of this\npaper is to fine-tune transformer-based language models pre-trained on several\ntext corpora, some being general (E.g., Wikipedia, BooksCorpus), some being the\ncorpora from which the CompLex Dataset was extracted, and others being from\nother specific domains such as Finance, Law, etc. We perform ablation studies\non selecting the transformer models and how their individual complexity scores\nare aggregated to get the resulting complexity scores. Our method achieves a\nbest Pearson Correlation of $0.784$ in sub-task 1 (single word) and $0.836$ in\nsub-task 2 (multiple word expressions).",
    "descriptor": "\nComments: 6 pages, 1 figure, Semeval-2021 Task 1\n",
    "authors": [
      "Abhilash Nandy",
      "Sayantan Adak",
      "Tanurima Halder",
      "Sai Mahesh Pokala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02340"
  },
  {
    "id": "arXiv:2106.02342",
    "title": "ASCNet: Self-supervised Video Representation Learning with  Appearance-Speed Consistency",
    "abstract": "We study self-supervised video representation learning, which is a\nchallenging task due to 1) a lack of labels for explicit supervision and 2)\nunstructured and noisy visual information. Existing methods mainly use\ncontrastive loss with video clips as the instances and learn visual\nrepresentation by discriminating instances from each other, but they require\ncareful treatment of negative pairs by relying on large batch sizes, memory\nbanks, extra modalities, or customized mining strategies, inevitably including\nnoisy data. In this paper, we observe that the consistency between positive\nsamples is the key to learn robust video representations. Specifically, we\npropose two tasks to learn the appearance and speed consistency, separately.\nThe appearance consistency task aims to maximize the similarity between two\nclips of the same video with different playback speeds. The speed consistency\ntask aims to maximize the similarity between two clips with the same playback\nspeed but different appearance information. We show that joint optimization of\nthe two tasks consistently improves the performance on downstream tasks, e.g.,\naction recognition and video retrieval. Remarkably, for action recognition on\nthe UCF-101 dataset, we achieve 90.8% accuracy without using any additional\nmodalities or negative pairs for unsupervised pretraining, outperforming the\nImageNet supervised pre-trained model. Codes and models will be available.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Deng Huang",
      "Wenhao Wu",
      "Weiwen Hu",
      "Xu Liu",
      "Dongliang He",
      "Zhihua Wu",
      "Xiangmiao Wu",
      "Mingkui Tan",
      "Errui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02342"
  },
  {
    "id": "arXiv:2106.02343",
    "title": "F-Drop&Match: GANs with a Dead Zone in the High-Frequency Domain",
    "abstract": "Generative adversarial networks built from deep convolutional neural networks\n(GANs) lack the ability to exactly replicate the high-frequency components of\nnatural images. To alleviate this issue, we introduce two novel training\ntechniques called frequency dropping (F-Drop) and frequency matching (F-Match).\nThe key idea of F-Drop is to filter out unnecessary high-frequency components\nfrom the input images of the discriminators. This simple modification prevents\nthe discriminators from being confused by perturbations of the high-frequency\ncomponents. In addition, F-Drop makes the GANs focus on fitting in the\nlow-frequency domain, in which there are the dominant components of natural\nimages. F-Match minimizes the difference between real and fake images in the\nfrequency domain for generating more realistic images. F-Match is implemented\nas a regularization term in the objective functions of the generators; it\npenalizes the batch mean error in the frequency domain. F-Match helps the\ngenerators to fit in the high-frequency domain filtered out by F-Drop to the\nreal image. We experimentally demonstrate that the combination of F-Drop and\nF-Match improves the generative performance of GANs in both the frequency and\nspatial domain on multiple image benchmarks (CIFAR, TinyImageNet, STL-10,\nCelebA, and ImageNet).",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Shin'ya Yamaguchi",
      "Sekitoshi Kanai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.02343"
  },
  {
    "id": "arXiv:2106.02350",
    "title": "Parallel and External-Memory Construction of Minimal Perfect Hash  Functions with PTHash",
    "abstract": "A minimal perfect hash function $f$ for a set $S$ of $n$ keys is a bijective\nfunction of the form $f : S \\rightarrow \\{0,\\ldots,n-1\\}$. These functions are\nimportant for many practical applications in computing, such as search engines,\ncomputer networks, and databases. Several algorithms have been proposed to\nbuild minimal perfect hash functions that: scale well to large sets, retain\nfast evaluation time, and take very little space, e.g., 2 - 3 bits/key. PTHash\nis one such algorithm, achieving very fast evaluation in compressed space,\ntypically several times faster than other techniques. In this work, we propose\na new construction algorithm for PTHash enabling: (1) multi-threading, to\neither build functions more quickly or more space-efficiently, and (2)\nexternal-memory processing to scale to inputs much larger than the available\ninternal memory. Only few other algorithms in the literature share these\nfeatures, despite of their big practical impact. We conduct an extensive\nexperimental assessment on large real-world string collections and show that,\nwith respect to other techniques, PTHash is competitive in construction time\nand space consumption, but retains 2 - 6$\\times$ better lookup time.",
    "descriptor": "",
    "authors": [
      "Giulio Ermanno Pibiri",
      "Roberto Trani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.02350"
  },
  {
    "id": "arXiv:2106.02351",
    "title": "SOLQ: Segmenting Objects by Learning Queries",
    "abstract": "In this paper, we propose an end-to-end framework for instance segmentation.\nBased on the recently introduced DETR [1], our method, termed SOLQ, segments\nobjects by learning unified queries. In SOLQ, each query represents one object\nand has multiple representations: class, location and mask. The object queries\nlearned perform classification, box regression and mask encoding simultaneously\nin an unified vector form. During training phase, the mask vectors encoded are\nsupervised by the compression coding of raw spatial masks. In inference time,\nmask vectors produced can be directly transformed to spatial masks by the\ninverse process of compression coding. Experimental results show that SOLQ can\nachieve state-of-the-art performance, surpassing most of existing approaches.\nMoreover, the joint learning of unified query representation can greatly\nimprove the detection performance of original DETR. We hope our SOLQ can serve\nas a strong baseline for the Transformer-based instance segmentation. Code is\navailable at https://github.com/megvii-research/SOLQ.",
    "descriptor": "\nComments: Tech Report.Code is available at this https URL\n",
    "authors": [
      "Bin Dong",
      "Fangao Zeng",
      "Tiancai Wang",
      "Xiangyu Zhang",
      "Yichen Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02351"
  },
  {
    "id": "arXiv:2106.02353",
    "title": "Spectral Hypergraph Sparsifiers of Nearly Linear Size",
    "abstract": "Graph sparsification has been studied extensively over the past two decades,\nculminating in spectral sparsifiers of optimal size (up to constant factors).\nSpectral hypergraph sparsification is a natural analogue of this problem, for\nwhich optimal bounds on the sparsifier size are not known, mainly because the\nhypergraph Laplacian is non-linear, and thus lacks the linear-algebraic\nstructure and tools that have been so effective for graphs.\nOur main contribution is the first algorithm for constructing\n$\\epsilon$-spectral sparsifiers for hypergraphs with $O^*(n)$ hyperedges, where\n$O^*$ suppresses $(\\epsilon^{-1} \\log n)^{O(1)}$ factors. This bound is\nindependent of the rank $r$ (maximum cardinality of a hyperedge), and is\nessentially best possible due to a recent bit complexity lower bound of\n$\\Omega(nr)$ for hypergraph sparsification.\nThis result is obtained by introducing two new tools. First, we give a new\nproof of spectral concentration bounds for sparsifiers of graphs; it avoids\nlinear-algebraic methods, replacing e.g.~the usual application of the matrix\nBernstein inequality and therefore applies to the (non-linear) hypergraph\nsetting. To achieve the result, we design a new sequence of\nhypergraph-dependent $\\epsilon$-nets on the unit sphere in $\\mathbb{R}^n$.\nSecond, we extend the weight assignment technique of Chen, Khanna and Nagda\n[FOCS'20] to the spectral sparsification setting. Surprisingly, the number of\nspanning trees after the weight assignment can serve as a potential function\nguiding the reweighting process in the spectral setting.",
    "descriptor": "",
    "authors": [
      "Michael Kapralov",
      "Robert Krauthgamer",
      "Jakab Tardos",
      "Yuichi Yoshida"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.02353"
  },
  {
    "id": "arXiv:2106.02357",
    "title": "Adiabatic Quantum Feature Selection for Sparse Linear Regression",
    "abstract": "Linear regression is a popular machine learning approach to learn and predict\nreal valued outputs or dependent variables from independent variables or\nfeatures. In many real world problems, its beneficial to perform sparse linear\nregression to identify important features helpful in predicting the dependent\nvariable. It not only helps in getting interpretable results but also avoids\noverfitting when the number of features is large, and the amount of data is\nsmall. The most natural way to achieve this is by using `best subset selection'\nwhich penalizes non-zero model parameters by adding $\\ell_0$ norm over\nparameters to the least squares loss. However, this makes the objective\nfunction non-convex and intractable even for a small number of features. This\npaper aims to address the intractability of sparse linear regression with\n$\\ell_0$ norm using adiabatic quantum computing, a quantum computing paradigm\nthat is particularly useful for solving optimization problems faster. We\nformulate the $\\ell_0$ optimization problem as a Quadratic Unconstrained Binary\nOptimization (QUBO) problem and solve it using the D-Wave adiabatic quantum\ncomputer. We study and compare the quality of QUBO solution on synthetic and\nreal world datasets. The results demonstrate the effectiveness of the proposed\nadiabatic quantum computing approach in finding the optimal solution. The QUBO\nsolution matches the optimal solution for a wide range of sparsity penalty\nvalues across the datasets.",
    "descriptor": "\nComments: 8 pages, 2 tables\n",
    "authors": [
      "Surya Sai Teja Desu",
      "P.K. Srijith",
      "M.V. Panduranga Rao",
      "Naveen Sivadasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02357"
  },
  {
    "id": "arXiv:2106.02359",
    "title": "How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social  Impact",
    "abstract": "Recent years have seen many breakthroughs in natural language processing\n(NLP), transitioning it from a mostly theoretical field to one with many\nreal-world applications. Noting the rising number of applications of other\nmachine learning and AI techniques with pervasive societal impact, we\nanticipate the rising importance of developing NLP technologies for social\ngood. Inspired by theories in moral philosophy and global priorities research,\nwe aim to promote a guideline for social good in the context of NLP. We lay the\nfoundations via moral philosophy's definition of social good, propose a\nframework to evaluate NLP tasks' direct and indirect real-world impact, and\nadopt the methodology of global priorities research to identify priority causes\nfor NLP research. Finally, we use our theoretical framework to provide some\npractical guidelines for future NLP research for social good. Our data and\ncodes are available at this http URL",
    "descriptor": "\nComments: ACL 2021 Findings\n",
    "authors": [
      "Zhijing Jin",
      "Geeticka Chauhan",
      "Brian Tse",
      "Mrinmaya Sachan",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02359"
  },
  {
    "id": "arXiv:2106.02361",
    "title": "Facade-X: an opinionated approach to SPARQL anything",
    "abstract": "The Semantic Web research community understood since its beginning how\ncrucial it is to equip practitioners with methods to transform non-RDF\nresources into RDF. Proposals focus on either engineering content\ntransformations or accessing non-RDF resources with SPARQL. Existing solutions\nrequire users to learn specific mapping languages (e.g. RML), to know how to\nquery and manipulate a variety of source formats (e.g. XPATH, JSON-Path), or to\ncombine multiple languages (e.g. SPARQL Generate). In this paper, we explore an\nalternative solution and contribute a general-purpose meta-model for converting\nnon-RDF resources into RDF: Facade-X. Our approach can be implemented by\noverriding the SERVICE operator and does not require to extend the SPARQL\nsyntax. We compare our approach with the state of art methods RML and SPARQL\nGenerate and show how our solution has lower learning demands and cognitive\ncomplexity, and it is cheaper to implement and maintain, while having\ncomparable extensibility and efficiency.",
    "descriptor": "\nComments: Version submitted to the SEMANTICS 2021 EU conference (Accepted May 2021)\n",
    "authors": [
      "Enrico Daga",
      "Luigi Asprino",
      "Paul Mulholland",
      "Aldo Gangemi"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.02361"
  },
  {
    "id": "arXiv:2106.02363",
    "title": "Learning Slice-Aware Representations with Mixture of Attentions",
    "abstract": "Real-world machine learning systems are achieving remarkable performance in\nterms of coarse-grained metrics like overall accuracy and F-1 score. However,\nmodel improvement and development often require fine-grained modeling on\nindividual data subsets or slices, for instance, the data slices where the\nmodels have unsatisfactory results. In practice, it gives tangible values for\ndeveloping such models that can pay extra attention to critical or interested\nslices while retaining the original overall performance. This work extends the\nrecent slice-based learning (SBL)~\\cite{chen2019slice} with a mixture of\nattentions (MoA) to learn slice-aware dual attentive representations. We\nempirically show that the MoA approach outperforms the baseline method as well\nas the original SBL approach on monitored slices with two natural language\nunderstanding (NLU) tasks.",
    "descriptor": "\nComments: Findings of the ACL: ACL-IJCNLP 2021\n",
    "authors": [
      "Cheng Wang",
      "Sungjin Lee",
      "Sunghyun Park",
      "Han Li",
      "Young-Bum Kim",
      "Ruhi Sarikaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02363"
  },
  {
    "id": "arXiv:2106.02370",
    "title": "Uncertainty in Position Estimation Using Machine Learning",
    "abstract": "UE localization has proven its implications on multitude of use cases ranging\nfrom emergency call localization to new and emerging use cases in industrial\nIoT. To support plethora of use cases Radio Access Technology (RAT)-based\npositioning has been supported by 3GPP since Release 9 of its specifications\nthat featured basic positioning methods based on Cell Identity (CID) and\nEnhanced-CID (E-CID). Since then, multiple positioning techniques and solutions\nare proposed and integrated in to the 3GPP specifications. When it comes to\nevaluating performance of the positioning techniques, achievable accuracy\n(2-Dimensional or 3-Dimensional) has, so far, been the primary metric. With the\nadvent of Release 16 New Radio (NR) positioning, it is possible to configure\nPositioning Reference Signal (PRS) with wide bandwidth that naturally helps\nimproving the positioning accuracy. However, the improvement is evident when\nthe conditions are ideal for positioning. In practice where the conditions are\nnon-ideal and the positioning accuracy is severely impacted, estimating the\nuncertainty in position estimation becomes important and can provide\nsignificant insight on how reliable a position estimation is. In order to\ndetermine the uncertainty in position estimation we resort to Machine Learning\n(ML) techniques that offer ways to determine the uncertainty/reliability of the\npredictions for a trained model. Hence, in this work we propose to combine ML\nmethods such as Gaussian Process (GP) and Random Forest (RF) with RAT-based\npositioning measurements to predict the location of a UE and in the meantime\nalso assess the uncertainty of the estimated position. The results show that\nboth GP and RF not only achieve satisfactory positioning accuracy but also give\na reliable uncertainty assessment of the predicted position of the UE.",
    "descriptor": "",
    "authors": [
      "Yuxin Zhao",
      "Deep Shrestha"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.02370"
  },
  {
    "id": "arXiv:2106.02372",
    "title": "Nonlinear Reduction using the Extended Group Finite Element Method",
    "abstract": "In this paper, we develop a nonlinear reduction framework based on our\nrecently introduced extended group finite element method. By interpolating\nnonlinearities onto approximation spaces defined with the help of finite\nelements, the extended group finite element formulation achieves a noticeable\nreduction in the computational overhead associated with nonlinear finite\nelement problems. However, the problem's size still leads to long solution\ntimes in most applications. Aiming to make real-time and/or many-query\napplications viable, we apply model order reduction and complexity reduction\ntechniques in order to reduce the problem size and efficiently handle the\nreduced nonlinear terms, respectively. For this work, we focus on the proper\northogonal decomposition and discrete empirical interpolation methods. While\nsimilar approaches based on the group finite element method only focus on\nsemilinear problems, our proposed framework is also compatible with quasilinear\nproblems. Compared to existing methods, our reduced models prove to be superior\nin many different aspects as demonstrated in three numerical benchmark\nproblems.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Kevin Tolle",
      "Nicole Marheineke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02372"
  },
  {
    "id": "arXiv:2106.02374",
    "title": "Coordination of operational planning and real-time optimization in  microgrids",
    "abstract": "Hierarchical microgrid control levels range from distributed device level\ncontrollers that run at a high frequency to centralized controllers optimizing\nmarket integration that run much less frequently. Centralized controllers are\noften subdivided into operational planning controllers that optimize decisions\nover a time horizon of one or several days, and real-time optimization\ncontrollers that deal with actions in the current market period. The\ncoordination of these levels is of paramount importance. In this paper, we\npropose a value function-based approach as a way to propagate information from\noperational planning to real-time optimization. We apply this method to an\nenvironment where operational planning, using day-ahead forecasts, optimizes at\na market period resolution the decisions to minimize the total energy cost and\nrevenues, the peak consumption and injection-related costs, and plans for\nreserve requirements. While real-time optimization copes with the forecast\nerrors and yields implementable actions based on real-time measurements. The\napproach is compared to a rule-based controller on three use cases, and its\nsensitivity to forecast error is assessed.",
    "descriptor": "",
    "authors": [
      "Jonathan Dumas",
      "Selmane Dakir",
      "Cl\u00e9ment Liu",
      "Bertrand Corn\u00e9lusse"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02374"
  },
  {
    "id": "arXiv:2106.02377",
    "title": "A Survey on Deep Domain Adaptation for LiDAR Perception",
    "abstract": "Scalable systems for automated driving have to reliably cope with an\nopen-world setting. This means, the perception systems are exposed to drastic\ndomain shifts, like changes in weather conditions, time-dependent aspects, or\ngeographic regions. Covering all domains with annotated data is impossible\nbecause of the endless variations of domains and the time-consuming and\nexpensive annotation process. Furthermore, fast development cycles of the\nsystem additionally introduce hardware changes, such as sensor types and\nvehicle setups, and the required knowledge transfer from simulation. To enable\nscalable automated driving, it is therefore crucial to address these domain\nshifts in a robust and efficient manner. Over the last years, a vast amount of\ndifferent domain adaptation techniques evolved. There already exists a number\nof survey papers for domain adaptation on camera images, however, a survey for\nLiDAR perception is absent. Nevertheless, LiDAR is a vital sensor for automated\ndriving that provides detailed 3D scans of the vehicle's surroundings. To\nstimulate future research, this paper presents a comprehensive review of recent\nprogress in domain adaptation methods and formulates interesting research\nquestions specifically targeted towards LiDAR perception.",
    "descriptor": "\nComments: Accepted at IEEE Intelligent Vehicles Symposium (IV) 2021 Workshop on Autonomy at Scale. 8 pages, 5 figures\n",
    "authors": [
      "Larissa T. Triess",
      "Mariella Dreissig",
      "Christoph B. Rist",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02377"
  },
  {
    "id": "arXiv:2106.02378",
    "title": "Efficient Predictive Monitoring of Linear Time-Invariant Systems Under  Stealthy Attacks",
    "abstract": "Attacks on Industrial Control Systems (ICS) can lead to significant physical\ndamage. While offline safety and security assessments can provide insight into\nvulnerable system components, they may not account for stealthy attacks\ndesigned to evade anomaly detectors during long operational transients. In this\npaper, we propose a predictive online monitoring approach to check the safety\nof the system under potential stealthy attacks. Specifically, we adapt previous\nresults in reachability analysis for attack impact assessment to provide an\nefficient algorithm for online safety monitoring for Linear Time-Invariant\n(LTI) systems. The proposed approach relies on an offline computation of\nsymbolic reachable sets in terms of the estimated physical state of the system.\nThese sets are then instantiated online, and safety checks are performed by\nleveraging ideas from ellipsoidal calculus. We illustrate and evaluate our\napproach using the Tennessee-Eastman process. We also compare our approach with\nthe baseline monitoring approaches proposed in previous work and assess its\nefficiency and scalability. Our evaluation results demonstrate that our\napproach can predict in a timely manner if a false data injection attack will\nbe able to cause damage, while remaining undetected. Thus, our approach can be\nused to provide operators with real-time early warnings about stealthy attacks.",
    "descriptor": "",
    "authors": [
      "Mazen Azzam",
      "Liliana Pasquale",
      "Gregory Provan",
      "Bashar Nuseibeh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02378"
  },
  {
    "id": "arXiv:2106.02382",
    "title": "Annotation Curricula to Implicitly Train Non-Expert Annotators",
    "abstract": "Annotation studies often require annotators to familiarize themselves with\nthe task, its annotation scheme, and the data domain. This can be overwhelming\nin the beginning, mentally taxing, and induce errors into the resulting\nannotations; especially in citizen science or crowd sourcing scenarios where\ndomain expertise is not required and only annotation guidelines are provided.\nTo alleviate these issues, we propose annotation curricula, a novel approach to\nimplicitly train annotators. Our goal is to gradually introduce annotators into\nthe task by ordering instances that are annotated according to a learning\ncurriculum. To do so, we first formalize annotation curricula for sentence- and\nparagraph-level annotation tasks, define an ordering strategy, and identify\nwell-performing heuristics and interactively trained models on three existing\nEnglish datasets. We then conduct a user study with 40 voluntary participants\nwho are asked to identify the most fitting misconception for English tweets\nabout the Covid-19 pandemic. Our results show that using a simple heuristic to\norder instances can already significantly reduce the total annotation time\nwhile preserving a high annotation quality. Annotation curricula thus can\nprovide a novel way to improve data collection. To facilitate future research,\nwe further share our code and data consisting of 2,400 annotations.",
    "descriptor": "",
    "authors": [
      "Ji-Ung Lee",
      "Jan-Christoph Klie",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02382"
  },
  {
    "id": "arXiv:2106.02383",
    "title": "PoDT: A Secure Multi-chains Consensus Scheme Against Diverse Miners  Behaviors Attacks in Blockchain Networks",
    "abstract": "As cross-chain technologies make the interactions among different blockchains\n(hereinafter \"chains\") possible, multi-chains consensus is becoming more and\nmore important in blockchain networks. However, more attention has been paid to\nthe single-chain consensus schemes. The multi-chains consensus with trusted\nminers participation has been not considered, thus offering opportunities for\nmalicious users to launch Diverse Miners Behaviors (DMB) attacks on different\nchains. DMB attackers can be friendly in the consensus process of some chains\ncalled mask-chains to enhance trust value, while on other chains called\nkill-chains they engage in destructive behaviors of network. In this paper, we\npropose a multi-chains consensus scheme named as Proof-of-DiscTrust (PoDT) to\ndefend against DMB attacks. Distinctive trust idea (DiscTrust) is introduced to\nevaluate the trust value of each user concerning different chains. A dynamic\nbehaviors prediction scheme is designed to strengthen DiscTrust to prevent\nintensive DMB attackers who maintain high trust by alternately creating true or\nfalse blocks on kill-chains. On this basis, a trusted miners selection\nalgorithm for multi-chains can be achieved at a round of block creation.\nExperimental results show that PoDT is secure against DMB attacks and more\neffective than traditional consensus schemes in multi-chains environments.",
    "descriptor": "\nComments: 14 pages, 17 figures\n",
    "authors": [
      "Jingyu Feng",
      "Tao Wang",
      "Naixue Xiong",
      "Teng Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.02383"
  },
  {
    "id": "arXiv:2106.02390",
    "title": "Online reinforcement learning with sparse rewards through an active  inference capsule",
    "abstract": "Intelligent agents must pursue their goals in complex environments with\npartial information and often limited computational capacity. Reinforcement\nlearning methods have achieved great success by creating agents that optimize\nengineered reward functions, but which often struggle to learn in sparse-reward\nenvironments, generally require many environmental interactions to perform\nwell, and are typically computationally very expensive. Active inference is a\nmodel-based approach that directs agents to explore uncertain states while\nadhering to a prior model of their goal behaviour. This paper introduces an\nactive inference agent which minimizes the novel free energy of the expected\nfuture. Our model is capable of solving sparse-reward problems with a very high\nsample efficiency due to its objective function, which encourages directed\nexploration of uncertain states. Moreover, our model is computationally very\nlight and can operate in a fully online manner while achieving comparable\nperformance to offline RL methods. We showcase the capabilities of our model by\nsolving the mountain car problem, where we demonstrate its superior exploration\nproperties and its robustness to observation noise, which in fact improves\nperformance. We also introduce a novel method for approximating the prior model\nfrom the reward function, which simplifies the expression of complex objectives\nand improves performance over previous active inference approaches.",
    "descriptor": "",
    "authors": [
      "Alejandro Daniel Noel",
      "Charel van Hoof",
      "Beren Millidge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02390"
  },
  {
    "id": "arXiv:2106.02393",
    "title": "Multitask Online Mirror Descent",
    "abstract": "We introduce and analyze MT-OMD, a multitask generalization of Online Mirror\nDescent (OMD) which operates by sharing updates between tasks. We prove that\nthe regret of MT-OMD is of order $\\sqrt{1 + \\sigma^2(N-1)}\\sqrt{T}$, where\n$\\sigma^2$ is the task variance according to the geometry induced by the\nregularizer, $N$ is the number of tasks, and $T$ is the time horizon. Whenever\ntasks are similar, that is, $\\sigma^2 \\le 1$, this improves upon the\n$\\sqrt{NT}$ bound obtained by running independent OMDs on each task. Our\nmultitask extensions of Online Gradient Descent and Exponentiated Gradient, two\nimportant instances of OMD, are shown to enjoy closed-form updates, making them\neasy to use in practice. Finally, we provide numerical experiments on four\nreal-world datasets which support our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Cesa-Bianchi",
      "Pierre Laforgue",
      "Andrea Paudice",
      "Massimiliano Pontil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02393"
  },
  {
    "id": "arXiv:2106.02394",
    "title": "On the Strategyproofness of the Geometric Median",
    "abstract": "The geometric median of a tuple of vectors is the vector that minimizes the\nsum of Euclidean distances to the vectors of the tuple. Interestingly, the\ngeometric median can also be viewed as the equilibrium of a process where each\nvector of the tuple pulls on a common decision point with a unitary force\ntowards them, promoting the \"one voter, one unit force\" fairness principle.\nIn this paper, we analyze the strategyproofness of the geometric median as a\nvoting system. Assuming that voters want to minimize the Euclidean distance\nbetween their preferred vector and the outcome of the vote, we first prove\nthat, in the general case, the geometric median is not even\n$\\alpha$-strategyproof. However, in the limit of a large number of voters,\nassuming that voters' preferred vectors are drawn i.i.d. from a distribution of\npreferred vectors, we also prove that the geometric median is asymptotically\n$\\alpha$-strategyproof. The bound $\\alpha$ describes what a voter can gain (at\nmost) by deviating from truthfulness. We show how to compute this bound as a\nfunction of the distribution followed by the vectors. We then generalize our\nresults to the case where each voter actually cares more about some dimensions\nrather than others. Roughly, we show that, if some dimensions are more\npolarized and regarded as more important, then the geometric median becomes\nless strategyproof. Interestingly, we also show how the skewed geometric\nmedians can be used to improve strategyproofness. Nevertheless, if voters care\ndifferently about different dimensions, we prove that no skewed geometric\nmedian can achieve strategyproofness for all of them. Overall, our results\nprovide insight into the extent to which the (skewed) geometric median is a\nsuitable approach to aggregate high-dimensional disagreements.",
    "descriptor": "\nComments: 53 pages, 7 figures\n",
    "authors": [
      "El-Mahdi El-Mhamdi",
      "Sadegh Farhadkhani",
      "Rachid Guerraoui",
      "L\u00ea-Nguy\u00ean Hoang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.02394"
  },
  {
    "id": "arXiv:2106.02395",
    "title": "DOCTOR: A Simple Method for Detecting Misclassification Errors",
    "abstract": "Deep neural networks (DNNs) have shown to perform very well on large scale\nobject recognition problems and lead to widespread use for real-world\napplications, including situations where DNN are implemented as \"black boxes\".\nA promising approach to secure their use is to accept decisions that are likely\nto be correct while discarding the others. In this work, we propose DOCTOR, a\nsimple method that aims to identify whether the prediction of a DNN classifier\nshould (or should not) be trusted so that, consequently, it would be possible\nto accept it or to reject it. Two scenarios are investigated: Totally Black Box\n(TBB) where only the soft-predictions are available and Partially Black Box\n(PBB) where gradient-propagation to perform input pre-processing is allowed.\nEmpirically, we show that DOCTOR outperforms all state-of-the-art methods on\nvarious well-known images and sentiment analysis datasets. In particular, we\nobserve a reduction of up to $4\\%$ of the false rejection rate (FRR) in the PBB\nscenario. DOCTOR can be applied to any pre-trained model, it does not require\nprior information about the underlying dataset and is as simple as the simplest\navailable methods in the literature.",
    "descriptor": "",
    "authors": [
      "Federica Granese",
      "Marco Romanelli",
      "Daniele Gorla",
      "Catuscia Palamidessi",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02395"
  },
  {
    "id": "arXiv:2106.02396",
    "title": "A Learning-based Optimal Market Bidding Strategy for Price-Maker Energy  Storage",
    "abstract": "Load serving entities with storage units reach sizes and performances that\ncan significantly impact clearing prices in electricity markets. Nevertheless,\nprice endogeneity is rarely considered in storage bidding strategies and\nmodeling the electricity market is a challenging task. Meanwhile, model-free\nreinforcement learning such as the Actor-Critic are becoming increasingly\npopular for designing energy system controllers. Yet implementation frequently\nrequires lengthy, data-intense, and unsafe trial-and-error training. To fill\nthese gaps, we implement an online Supervised Actor-Critic (SAC) algorithm,\nsupervised with a model-based controller -- Model Predictive Control (MPC). The\nenergy storage agent is trained with this algorithm to optimally bid while\nlearning and adjusting to its impact on the market clearing prices. We compare\nthe supervised Actor-Critic algorithm with the MPC algorithm as a supervisor,\nfinding that the former reaps higher profits via learning. Our contribution,\nthus, is an online and safe SAC algorithm that outperforms the current\nmodel-based state-of-the-art.",
    "descriptor": "\nComments: Presented at the 2021 American Control Conference (ACC), New Orleans, USA, May 25-28, 2021\n",
    "authors": [
      "Mathilde D. Badoual",
      "Scott J. Moura"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02396"
  },
  {
    "id": "arXiv:2106.02397",
    "title": "On Classifying Continuous Constraint Satisfaction problems",
    "abstract": "A continuous constraint satisfaction problem (CCSP) is a constraint\nsatisfaction problem (CSP) with a domain $U \\subset \\mathbb{R}$. We engage in a\nsystematic study to classify CCSPs that are complete of the Existential Theory\nof the Reals, i.e., ER-complete. To define this class, we first consider the\nproblem ETR, which also stands for Existential Theory of the Reals. In an\ninstance of this problem we are given some sentence of the form $\\exists x_1,\n\\ldots, x_n \\in \\mathbb{R} : \\Phi(x_1, \\ldots, x_n)$, where $\\Phi$ is a\nwell-formed quantifier-free formula consisting of the symbols $\\{0, 1, +,\n\\cdot, \\geq, >, \\wedge, \\vee, \\neg\\}$, the goal is to check whether this\nsentence is true. Now the class ER is the family of all problems that admit a\npolynomial-time reduction to ETR. It is known that NP $\\subseteq$ ER\n$\\subseteq$ PSPACE.\nWe restrict our attention on CCSPs with addition constraints ($x + y = z$)\nand some other mild technical condition. Previously, it was shown that\nmultiplication constraints ($x \\cdot y = z$), squaring constraints ($x^2 = y$),\nor inversion constraints ($x\\cdot y = 1$) are sufficient to establish\nER-completeness. We extend this in the strongest possible sense for equality\nconstraints as follows. We show that CCSPs (with addition constraints and some\nother mild technical condition) that have any one well-behaved curved equality\nconstraint ($f(x,y) = 0$) are ER-complete. We further extend our results to\ninequality constraints. We show that any well-behaved convexly curved and any\nwell-behaved concavely curved inequality constraint ($f(x,y) \\geq 0$ and\n$g(x,y) \\geq 0$) imply ER-completeness on the class of such CCSPs.\nWe apply our findings to geometric packing and answer an open question by\nAbrahamsen et al. [FOCS 2020]. Namely, we establish ER-completeness of packing\nconvex pieces into a square container under rotations and translations.",
    "descriptor": "\nComments: 40 pages, 16 figures\n",
    "authors": [
      "Tillmann Miltzow",
      "Reinier F. Schmiermann"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Computation and Language (cs.CL)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.02397"
  },
  {
    "id": "arXiv:2106.02398",
    "title": "Strategyproof Learning: Building Trustworthy User-Generated Datasets",
    "abstract": "Today's large-scale machine learning algorithms harness massive amounts of\nuser-generated data to train large models. However, especially in the context\nof content recommendation with enormous social, economical and political\nincentives to promote specific views, products or ideologies, strategic users\nmight be tempted to fabricate or mislabel data in order to bias algorithms in\ntheir favor. Unfortunately, today's learning schemes strongly incentivize such\nstrategic data misreporting. This is a major concern, as it endangers the\ntrustworthiness of the entire training datasets, and questions the safety of\nany algorithm trained on such datasets. In this paper, we show that, perhaps\nsurprisingly, incentivizing data misreporting is not a fatality. We propose the\nfirst personalized collaborative learning framework, Licchavi, with provable\nstrategyproofness guarantees through a careful design of the underlying loss\nfunction. Interestingly, we also prove that Licchavi is Byzantine resilient: it\ntolerates a minority of users that provide arbitrary data.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Sadegh Farhadkhani",
      "Rachid Guerraoui",
      "L\u00ea-Nguy\u00ean Hoang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02398"
  },
  {
    "id": "arXiv:2106.02399",
    "title": "Prediction or Comparison: Toward Interpretable Qualitative Reasoning",
    "abstract": "Qualitative relationships illustrate how changing one property (e.g., moving\nvelocity) affects another (e.g., kinetic energy) and constitutes a considerable\nportion of textual knowledge. Current approaches use either semantic parsers to\ntransform natural language inputs into logical expressions or a \"black-box\"\nmodel to solve them in one step. The former has a limited application range,\nwhile the latter lacks interpretability. In this work, we categorize\nqualitative reasoning tasks into two types: prediction and comparison. In\nparticular, we adopt neural network modules trained in an end-to-end manner to\nsimulate the two reasoning processes. Experiments on two qualitative reasoning\nquestion answering datasets, QuaRTz and QuaRel, show our methods' effectiveness\nand generalization capability, and the intermediate outputs provided by the\nmodules make the reasoning process interpretable.",
    "descriptor": "\nComments: 12 pages. Accepted as ACL2021 Findings\n",
    "authors": [
      "Mucheng Ren",
      "Heyan Huang",
      "Yang Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02399"
  },
  {
    "id": "arXiv:2106.02400",
    "title": "A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval",
    "abstract": "Conventional approaches to image-text retrieval mainly focus on indexing\nvisual objects appearing in pictures but ignore the interactions between these\nobjects. Such objects occurrences and interactions are equivalently useful and\nimportant in this field as they are usually mentioned in the text. Scene graph\npresentation is a suitable method for the image-text matching challenge and\nobtained good results due to its ability to capture the inter-relationship\ninformation. Both images and text are represented in scene graph levels and\nformulate the retrieval challenge as a scene graph matching challenge. In this\npaper, we introduce the Local and Global Scene Graph Matching (LGSGM) model\nthat enhances the state-of-the-art method by integrating an extra graph\nconvolution network to capture the general information of a graph.\nSpecifically, for a pair of scene graphs of an image and its caption, two\nseparate models are used to learn the features of each graph's nodes and edges.\nThen a Siamese-structure graph convolution model is employed to embed graphs\ninto vector forms. We finally combine the graph-level and the vector-level to\ncalculate the similarity of this image-text pair. The empirical experiments\nshow that our enhancement with the combination of levels can improve the\nperformance of the baseline method by increasing the recall by more than 10% on\nthe Flickr30k dataset.",
    "descriptor": "",
    "authors": [
      "Manh-Duy Nguyen",
      "Binh T. Nguyen",
      "Cathal Gurrin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02400"
  },
  {
    "id": "arXiv:2106.02401",
    "title": "Entity Concept-enhanced Few-shot Relation Extraction",
    "abstract": "Few-shot relation extraction (FSRE) is of great importance in long-tail\ndistribution problem, especially in special domain with low-resource data. Most\nexisting FSRE algorithms fail to accurately classify the relations merely based\non the information of the sentences together with the recognized entity pairs,\ndue to limited samples and lack of knowledge. To address this problem, in this\npaper, we proposed a novel entity CONCEPT-enhanced FEw-shot Relation Extraction\nscheme (ConceptFERE), which introduces the inherent concepts of entities to\nprovide clues for relation prediction and boost the relations classification\nperformance. Firstly, a concept-sentence attention module is developed to\nselect the most appropriate concept from multiple concepts of each entity by\ncalculating the semantic similarity between sentences and concepts. Secondly, a\nself-attention based fusion module is presented to bridge the gap of concept\nembedding and sentence embedding from different semantic spaces. Extensive\nexperiments on the FSRE benchmark dataset FewRel have demonstrated the\neffectiveness and the superiority of the proposed ConceptFERE scheme as\ncompared to the state-of-the-art baselines. Code is available at\nhttps://github.com/LittleGuoKe/ConceptFERE.",
    "descriptor": "\nComments: Accepted at ACL2021\n",
    "authors": [
      "Shan Yang",
      "Yongfei Zhang",
      "Guanglin Niu",
      "Qinghua Zhao",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02401"
  },
  {
    "id": "arXiv:2106.02405",
    "title": "A guidance and maneuvering control system design with anti-collision  using stream functions with vortex flows for autonomous marine vessels",
    "abstract": "Autonomous marine vessels are expected to avoid inter-vessel collisions and\ncomply with the international regulations for safe voyages. This paper presents\na stepwise path planning method using stream functions. The dynamic flow of\nfluids is used as a guidance model, where the collision avoidance in static\nenvironments is achieved by applying the circular theorem in the sink flow. We\nextend this method to dynamic environments by adding vortex flows in the flow\nfield. The stream function is recursively updated to enable on the fly waypoint\ndecisions. The vessel avoids collisions and also complies with several rules of\nthe Convention on the International Regulations for Preventing Collisions at\nSea. The method is conceptually and computationally simple and convenient to\ntune, and yet versatile to handle complex and dense marine traffic with\nmultiple dynamic obstacles. The ship dynamics are taken into account, by using\nBezier curves to generate a sufficiently smooth path with feasible curvature.\nNumerical simulations are conducted to verify the proposed method.",
    "descriptor": "\nComments: 15 pages, 15 figures\n",
    "authors": [
      "Hongyu Zhou",
      "Zhengru Ren",
      "Mathias Marley",
      "Roger Skjetne"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02405"
  },
  {
    "id": "arXiv:2106.02412",
    "title": "Nara: Learning Network-Aware Resource Allocation Algorithms for Cloud  Data Centres",
    "abstract": "Data centres (DCs) underline many prominent future technological trends such\nas distributed training of large scale machine learning models and\ninternet-of-things based platforms. DCs will soon account for over 3\\% of\nglobal energy demand, so efficient use of DC resources is essential. Robust DC\nnetworks (DCNs) are essential to form the large scale systems needed to handle\nthis demand, but can bottleneck how efficiently DC-server resources can be used\nwhen servers with insufficient connectivity between them cannot be jointly\nallocated to a job. However, allocating servers' resources whilst accounting\nfor their inter-connectivity maps to an NP-hard combinatorial optimisation\nproblem, and so is often ignored in DC resource management schemes. We present\nNara, a framework based on reinforcement learning (RL) and graph neural\nnetworks (GNN) to learn network-aware allocation policies that increase the\nnumber of requests allocated over time compared to previous methods. Unique to\nour solution is the use of a GNN to generate representations of server-nodes in\nthe DCN, which are then interpreted as actions by a RL policy-network which\nchooses from which servers resources will be allocated to incoming requests.\nNara is agnostic to the topology size and shape and is trained end-to-end. The\nmethod can accept up to 33\\% more requests than the best baseline when deployed\non DCNs with up to the order of $10\\times$ more compute nodes than the DCN seen\nduring training and is able to maintain its policy's performance on DCNs with\nthe order of $100\\times$ more servers than seen during training. It also\ngeneralises to unseen DCN topologies with varied network structure and unseen\nrequest distributions without re-training.",
    "descriptor": "\nComments: 9 content pages, 10 appendix pages, 8 tables, 9 figures\n",
    "authors": [
      "Zacharaya Shabka",
      "Georgios Zervas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02412"
  },
  {
    "id": "arXiv:2106.02415",
    "title": "What is fair? Exploring the artists' perspective on the fairness of  music streaming platforms",
    "abstract": "Music streaming platforms are currently among the main sources of music\nconsumption, and the embedded recommender systems significantly influence what\nthe users consume. There is an increasing interest to ensure that those\nplatforms and systems are fair. Yet, we first need to understand what fairness\nmeans in such a context. Although artists are the main content providers for\nmusic platforms, there is a research gap concerning the artists' perspective.\nTo fill this gap, we conducted interviews with music artists to understand how\nthey are affected by current platforms and what improvements they deem\nnecessary. Using a Qualitative Content Analysis, we identify the aspects that\nthe artists consider relevant for fair platforms. In this paper, we discuss the\nfollowing aspects derived from the interviews: fragmented presentation,\nreaching an audience, transparency, influencing users' listening behavior,\npopularity bias, artists' repertoire size, quotas for local music, gender\nbalance, and new music. For some topics, our findings do not indicate a clear\ndirection about the best way how music platforms should act and function; for\nother topics, though, there is a clear consensus among our interviewees: for\nthese, the artists have a clear idea of the actions that should be taken so\nthat music platforms will be fair also for the artists.",
    "descriptor": "",
    "authors": [
      "Andres Ferraro",
      "Xavier Serra",
      "Christine Bauer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.02415"
  },
  {
    "id": "arXiv:2106.02420",
    "title": "An Intelligent Resource Reservation for Crowdsourced Live Video  Streaming Applications in Geo-Distributed Cloud Environment",
    "abstract": "Crowdsourced live video streaming (livecast) services such as Facebook Live,\nYouNow, Douyu and Twitch are gaining more momentum recently. Allocating the\nlimited resources in a cost-effective manner while maximizing the Quality of\nService (QoS) through real-time delivery and the provision of the appropriate\nrepresentations for all viewers is a challenging problem. In our paper, we\nintroduce a machine-learning based predictive resource allocation framework for\ngeo-distributed cloud sites, considering the delay and quality constraints to\nguarantee the maximum QoS for viewers and the minimum cost for content\nproviders. First, we present an offline optimization that decides the required\ntranscoding resources in distributed regions near the viewers with a trade-off\nbetween the QoS and the overall cost. Second, we use machine learning to build\nforecasting models that proactively predict the approximate transcoding\nresources to be reserved at each cloud site ahead of time. Finally, we develop\na Greedy Nearest and Cheapest algorithm (GNCA) to perform the resource\nallocation of real-time broadcasted videos on the rented resources. Extensive\nsimulations have shown that GNCA outperforms the state-of-the art resource\nallocation approaches for crowdsourced live streaming by achieving more than\n20% gain in terms of system cost while serving the viewers with relatively\nlower latency.",
    "descriptor": "\nComments: Published in IEEE systems journal\n",
    "authors": [
      "Emna Baccour",
      "Fatima Haouari",
      "Aiman Erbad",
      "Amr Mohamed",
      "Kashif Bilal",
      "Mohsen Guizani",
      "Mounir Hamdi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.02420"
  },
  {
    "id": "arXiv:2106.02424",
    "title": "Contour Moments Based Manipulation of Composite Rigid-Deformable Objects  with Finite Time Model Estimation and Shape/Position Control",
    "abstract": "The robotic manipulation of composite rigid-deformable objects (i.e. those\nwith mixed non-homogeneous stiffness properties) is a challenging problem with\nclear practical applications that, despite the recent progress in the field, it\nhas not been sufficiently studied in the literature. To deal with this issue,\nin this paper we propose a new visual servoing method that has the capability\nto manipulate this broad class of objects (which varies from soft to rigid)\nwith the same adaptive strategy. To quantify the object's infinite-dimensional\nconfiguration, our new approach computes a compact feedback vector of 2D\ncontour moments features. A sliding mode control scheme is then designed to\nsimultaneously ensure the finite-time convergence of both the feedback shape\nerror and the model estimation error. The stability of the proposed framework\n(including the boundedness of all the signals) is rigorously proved with\nLyapunov theory. Detailed simulations and experiments are presented to validate\nthe effectiveness of the proposed approach. To the best of the author's\nknowledge, this is the first time that contour moments along with finite-time\ncontrol have been used to solve this difficult manipulation problem.",
    "descriptor": "",
    "authors": [
      "Jiaming Qi",
      "Guangfu Ma",
      "Jihong Zhu",
      "Peng Zhou",
      "Yueyong Lyu",
      "Haibo Zhang",
      "David Navarro-Alarcon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02424"
  },
  {
    "id": "arXiv:2106.02426",
    "title": "NMS-Loss: Learning with Non-Maximum Suppression for Crowded Pedestrian  Detection",
    "abstract": "Non-Maximum Suppression (NMS) is essential for object detection and affects\nthe evaluation results by incorporating False Positives (FP) and False\nNegatives (FN), especially in crowd occlusion scenes. In this paper, we raise\nthe problem of weak connection between the training targets and the evaluation\nmetrics caused by NMS and propose a novel NMS-Loss making the NMS procedure can\nbe trained end-to-end without any additional network parameters. Our NMS-Loss\npunishes two cases when FP is not suppressed and FN is wrongly eliminated by\nNMS. Specifically, we propose a pull loss to pull predictions with the same\ntarget close to each other, and a push loss to push predictions with different\ntargets away from each other. Experimental results show that with the help of\nNMS-Loss, our detector, namely NMS-Ped, achieves impressive results with Miss\nRate of 5.92% on Caltech dataset and 10.08% on CityPersons dataset, which are\nboth better than state-of-the-art competitors.",
    "descriptor": "\nComments: ICMR2021 camera ready version\n",
    "authors": [
      "Zekun Luo",
      "Zheng Fang",
      "Sixiao Zheng",
      "Yabiao Wang",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02426"
  },
  {
    "id": "arXiv:2106.02433",
    "title": "A Novel Semi-supervised Framework for Call Center Agent Malpractice  Detection via Neural Feature Learning",
    "abstract": "This work presents a practical solution to the problem of call center agent\nmalpractice. A semi-supervised framework comprising of non-linear power\ntransformation, neural feature learning and k-means clustering is outlined. We\nput these building blocks together and tune the parameters so that the best\nperformance was obtained. The data used in the experiments is obtained from our\nin-house call center. It is made up of recorded agent-customer conversations\nwhich have been annotated using a convolutional neural network based segmenter.\nThe methods provided a means of tuning the parameters of the neural network to\nachieve a desirable result. We show that, using our proposed framework, it is\npossible to significantly reduce the malpractice classification error of a\nk-means-only clustering model which would serve the same purpose. Additionally,\nby presenting the amount of silence per call as a key performance indicator, we\nshow that the proposed system has enhanced agents performance at our call\ncenter since deployment.",
    "descriptor": "",
    "authors": [
      "\u015e\u00fckr\u00fc Ozan",
      "Leonardo Obinna Iheme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.02433"
  },
  {
    "id": "arXiv:2106.02435",
    "title": "You Only Compress Once: Towards Effective and Elastic BERT Compression  via Exploit-Explore Stochastic Nature Gradient",
    "abstract": "Despite superior performance on various natural language processing tasks,\npre-trained models such as BERT are challenged by deploying on\nresource-constraint devices. Most existing model compression approaches require\nre-compression or fine-tuning across diverse constraints to accommodate various\nhardware deployments. This practically limits the further application of model\ncompression. Moreover, the ineffective training and searching process of\nexisting elastic compression paradigms[4,27] prevents the direct migration to\nBERT compression. Motivated by the necessity of efficient inference across\nvarious constraints on BERT, we propose a novel approach, YOCO-BERT, to achieve\ncompress once and deploy everywhere. Specifically, we first construct a huge\nsearch space with 10^13 architectures, which covers nearly all configurations\nin BERT model. Then, we propose a novel stochastic nature gradient optimization\nmethod to guide the generation of optimal candidate architecture which could\nkeep a balanced trade-off between explorations and exploitation. When a certain\nresource constraint is given, a lightweight distribution optimization approach\nis utilized to obtain the optimal network for target deployment without\nfine-tuning. Compared with state-of-the-art algorithms, YOCO-BERT provides more\ncompact models, yet achieving 2.1%-4.5% average accuracy improvement on the\nGLUE benchmark. Besides, YOCO-BERT is also more effective, e.g.,the training\ncomplexity is O(1)for N different devices. Code is\navailablehttps://github.com/MAC-AutoML/YOCO-BERT.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Shaokun Zhang",
      "Xiawu Zheng",
      "Chenyi Yang",
      "Yuchao Li",
      "Yan Wang",
      "Fei Chao",
      "Mengdi Wang",
      "Shen Li",
      "Jun Yang",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02435"
  },
  {
    "id": "arXiv:2106.02436",
    "title": "Stochastic Multi-Armed Bandits with Unrestricted Delay Distributions",
    "abstract": "We study the stochastic Multi-Armed Bandit (MAB) problem with random delays\nin the feedback received by the algorithm. We consider two settings: the\nreward-dependent delay setting, where realized delays may depend on the\nstochastic rewards, and the reward-independent delay setting. Our main\ncontribution is algorithms that achieve near-optimal regret in each of the\nsettings, with an additional additive dependence on the quantiles of the delay\ndistribution. Our results do not make any assumptions on the delay\ndistributions: in particular, we do not assume they come from any parametric\nfamily of distributions and allow for unbounded support and expectation; we\nfurther allow for infinite delays where the algorithm might occasionally not\nobserve any feedback.",
    "descriptor": "\nComments: 33 pages, 5 figures, ICML 2021\n",
    "authors": [
      "Tal Lancewicki",
      "Shahar Segal",
      "Tomer Koren",
      "Yishay Mansour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02436"
  },
  {
    "id": "arXiv:2106.02440",
    "title": "Improved Distributed Lower Bounds for MIS and Bounded (Out-)Degree  Dominating Sets in Trees",
    "abstract": "Recently, Balliu, Brandt, and Olivetti [FOCS '20] showed the first\n$\\omega(\\log^* n)$ lower bound for the maximal independent set (MIS) problem in\ntrees. In this work we prove lower bounds for a much more relaxed family of\ndistributed symmetry breaking problems. As a by-product, we obtain improved\nlower bounds for the distributed MIS problem in trees.\nFor a parameter $k$ and an orientation of the edges of a graph $G$, we say\nthat a subset $S$ of the nodes of $G$ is a $k$-outdegree dominating set if $S$\nis a dominating set of $G$ and if in the induced subgraph $G[S]$, every node in\n$S$ has outdegree at most $k$. Note that for $k=0$, this definition coincides\nwith the definition of an MIS. For a given $k$, we consider the problem of\ncomputing a $k$-outdegree dominating set. We show that, even in regular trees\nof degree at most $\\Delta$, in the standard \\LOCAL model, there exists a\nconstant $\\epsilon>0$ such that for $k\\leq \\Delta^\\epsilon$, for the problem of\ncomputing a $k$-outdegree dominating set, any randomized algorithm requires at\nleast $\\Omega(\\min\\{\\log\\Delta,\\sqrt{\\log\\log n}\\})$ rounds and any\ndeterministic algorithm requires at least $\\Omega(\\min\\{\\log\\Delta,\\sqrt{\\log\nn}\\})$ rounds.\nThe proof of our lower bounds is based on the recently highly successful\nround elimination technique. We provide a novel way to do simplifications for\nround elimination, which we expect to be of independent interest. Our new proof\nis considerably simpler than the lower bound proof in [FOCS '20]. In\nparticular, our round elimination proof uses a family of problems that can be\ndescribed by only a constant number of labels. The existence of such a proof\nfor the MIS problem was believed impossible by the authors of [FOCS '20].",
    "descriptor": "\nComments: Accepted at PODC 2021\n",
    "authors": [
      "Alkida Balliu",
      "Sebastian Brandt",
      "Fabian Kuhn",
      "Dennis Olivetti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.02440"
  },
  {
    "id": "arXiv:2106.02445",
    "title": "How to select and use tools? : Active Perception of Target Objects Using  Multimodal Deep Learning",
    "abstract": "Selection of appropriate tools and use of them when performing daily tasks is\na critical function for introducing robots for domestic applications. In\nprevious studies, however, adaptability to target objects was limited, making\nit difficult to accordingly change tools and adjust actions. To manipulate\nvarious objects with tools, robots must both understand tool functions and\nrecognize object characteristics to discern a tool-object-action relation. We\nfocus on active perception using multimodal sensorimotor data while a robot\ninteracts with objects, and allow the robot to recognize their extrinsic and\nintrinsic characteristics. We construct a deep neural networks (DNN) model that\nlearns to recognize object characteristics, acquires tool-object-action\nrelations, and generates motions for tool selection and handling. As an example\ntool-use situation, the robot performs an ingredients transfer task, using a\nturner or ladle to transfer an ingredient from a pot to a bowl. The results\nconfirm that the robot recognizes object characteristics and servings even when\nthe target ingredients are unknown. We also examine the contributions of\nimages, force, and tactile data and show that learning a variety of multimodal\ninformation results in rich perception for tool use.",
    "descriptor": "\nComments: Best Paper Award of Cognitive Robotics in ICRA2021 IEEE Robotics and Automation Letters 2021, Proceedings of the 2021 International Conference on Robotics and Automation (ICRA 2021), 2021\n",
    "authors": [
      "Namiko Saito",
      "Tetsuya Ogata",
      "Satoshi Funabashi",
      "Hiroki Mori",
      "Shigeki Sugano"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02445"
  },
  {
    "id": "arXiv:2106.02449",
    "title": "Hypercontracts",
    "abstract": "Contracts (or interface) theories have been proposed to formally support\ndistributed and decentralized system design while ensuring safe system\nintegration. Over the last decades, a number of formalisms were proposed,\nsometimes very different in their form and algebra. This motivated the quest\nfor a unification by some authors, e.g., specifications through contracts by\nBauer et al. and the contract metatheory by Benveniste et al. to cite a few.\nThese generic models establish precise links between the different contract\nframeworks. In this paper we propose hypercontracts, a generic model with a\nricher structure for its underlying model of components, subsuming simulation\npreorders. While this new model remains generic, it provides a much more\nelegant and richer algebra for its key notions of refinement, parallel\ncomposition, and quotient, and it allows considering new operations. On top of\nthese foundations, we propose conic hypercontracts, which are still generic but\ncome with a finite description. We show how to specialize conic hypercontracts\nto Assume-Guarantee contracts as well as to Interface Automata, two known\ncontract frameworks very different in style. We illustrate conic hypercontracts\non specifications involving security and the robustness of machine-learning\ncomponents.",
    "descriptor": "",
    "authors": [
      "Inigo Incer",
      "Albert Benveniste",
      "Alberto Sangiovanni-Vincentelli",
      "Sanjit A. Seshia"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.02449"
  },
  {
    "id": "arXiv:2106.02450",
    "title": "Supervised learning and tree search for real-time storage allocation in  Robotic Mobile Fulfillment Systems",
    "abstract": "A Robotic Mobile Fulfillment System is a robotised parts-to-picker system\nthat is particularly well-suited for e-commerce warehousing. One distinguishing\nfeature of this type of warehouse is its high storage modularity. Numerous\nrobots are moving shelves simultaneously, and the shelves can be returned to\nany open location after the picking operation is completed. This work focuses\non the real-time storage allocation problem to minimise the travel time of the\nrobots. An efficient -- but computationally costly -- Monte Carlo Tree Search\nmethod is used offline to generate high-quality experience. This experience can\nbe learned by a neural network with a proper coordinates-based features\nrepresentation. The obtained neural network is used as an action predictor in\nseveral new storage policies, either as-is or in rollout and supervised tree\nsearch strategies. Resulting performance levels depend on the computing time\navailable at a decision step and are consistently better compared to real-time\ndecision rules from the literature.",
    "descriptor": "\nComments: 22 pages, 7 figures\n",
    "authors": [
      "Adrien Rim\u00e9l\u00e9",
      "Philippe Grangier",
      "Michel Gamache",
      "Michel Gendreau",
      "Louis-Martin Rousseau"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.02450"
  },
  {
    "id": "arXiv:2106.02452",
    "title": "Proving Equivalence Between Complex Expressions Using Graph-to-Sequence  Neural Models",
    "abstract": "We target the problem of provably computing the equivalence between two\ncomplex expression trees. To this end, we formalize the problem of equivalence\nbetween two such programs as finding a set of semantics-preserving rewrite\nrules from one into the other, such that after the rewrite the two programs are\nstructurally identical, and therefore trivially equivalent.We then develop a\ngraph-to-sequence neural network system for program equivalence, trained to\nproduce such rewrite sequences from a carefully crafted automatic example\ngeneration algorithm. We extensively evaluate our system on a rich multi-type\nlinear algebra expression language, using arbitrary combinations of 100+\ngraph-rewriting axioms of equivalence. Our machine learning system guarantees\ncorrectness for all true negatives, and ensures 0 false positive by design. It\noutputs via inference a valid proof of equivalence for 93% of the 10,000\nequivalent expression pairs isolated for testing, using up to 50-term\nexpressions. In all cases, the validity of the sequence produced and therefore\nthe provable assertion of program equivalence is always computable, in\nnegligible time.",
    "descriptor": "\nComments: 10 pages (24 including references and appendices), 8 figures, 17 tables. arXiv admin note: substantial text overlap with arXiv:2002.06799\n",
    "authors": [
      "Steve Kommrusch",
      "Th\u00e9o Barollet",
      "Louis-No\u00ebl Pouchet"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02452"
  },
  {
    "id": "arXiv:2106.02466",
    "title": "Graph Barlow Twins: A self-supervised representation learning framework  for graphs",
    "abstract": "The self-supervised learning (SSL) paradigm is an essential exploration area,\nwhich tries to eliminate the need for expensive data labeling. Despite the\ngreat success of SSL methods in computer vision and natural language\nprocessing, most of them employ contrastive learning objectives that require\nnegative samples, which are hard to define. This becomes even more challenging\nin the case of graphs and is a bottleneck for achieving robust representations.\nTo overcome such limitations, we propose a framework for self-supervised graph\nrepresentation learning -- Graph Barlow Twins, which utilizes a\ncross-correlation-based loss function instead of negative samples. Moreover, it\ndoes not rely on non-symmetric neural network architectures -- in contrast to\nstate-of-the-art self-supervised graph representation learning method BGRL. We\nshow that our method achieves as competitive results as BGRL, best\nself-supervised methods, and fully supervised ones while requiring\nsubstantially fewer hyperparameters and converging in an order of magnitude\ntraining steps earlier.",
    "descriptor": "",
    "authors": [
      "Piotr Bielak",
      "Tomasz Kajdanowicz",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02466"
  },
  {
    "id": "arXiv:2106.02469",
    "title": "Can convolutional ResNets approximately preserve input distances? A  frequency analysis perspective",
    "abstract": "ResNets constrained to be bi-Lipschitz, that is, approximately distance\npreserving, have been a crucial component of recently proposed techniques for\ndeterministic uncertainty quantification in neural models. We show that\ntheoretical justifications for recent regularisation schemes trying to enforce\nsuch a constraint suffer from a crucial flaw -- the theoretical link between\nthe regularisation scheme used and bi-Lipschitzness is only valid under\nconditions which do not hold in practice, rendering existing theory of limited\nuse, despite the strong empirical performance of these models. We provide a\ntheoretical explanation for the effectiveness of these regularisation schemes\nusing a frequency analysis perspective, showing that under mild conditions\nthese schemes will enforce a lower Lipschitz bound on the low-frequency\nprojection of images. We then provide empirical evidence supporting our\ntheoretical claims, and perform further experiments which demonstrate that our\nbroader conclusions appear to hold when some of the mathematical assumptions of\nour proof are relaxed, corresponding to the setup used in prior work. In\naddition, we present a simple constructive algorithm to search for counter\nexamples to the distance preservation condition, and discuss possible\nimplications of our theory for future model design.",
    "descriptor": "\nComments: Main paper 10 pages including references, appendix 10 pages. 7 figures and 6 tables including appendix\n",
    "authors": [
      "Lewis Smith",
      "Joost van Amersfoort",
      "Haiwen Huang",
      "Stephen Roberts",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02469"
  },
  {
    "id": "arXiv:2106.02470",
    "title": "Quantum Synchronizable Codes From Cyclotomic Classes of Order Two over  $\\mathbb{Z}_{2q}$",
    "abstract": "Quantum synchronizable codes are kinds of quantum error-correcting codes that\ncan not only correct the effects of quantum noise on qubits but also the\nmisalignment in block synchronization. In this paper, we construct two classes\nof quantum synchronizable codes which obtained by the cyclotomic classes of\norder two over $\\mathbb{Z}_{2q}$. And the synchronization capabilities reach\nthe upper bound under certain constrains. Moreover, the quantum synchronizable\ncode posses good error-correcting capability towards bit error and phase error,\nsince cyclic codes we employed to construct quantum synchronizable codes are\noptimal or almost optimal.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2105.03619\n",
    "authors": [
      "Tao Wang",
      "Tongjiang Yan",
      "Xueting Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.02470"
  },
  {
    "id": "arXiv:2106.02472",
    "title": "A Database for Research on Detection and Enhancement of Speech  Transmitted over HF links",
    "abstract": "In this paper we present an open database for the development of detection\nand enhancement algorithms of speech transmitted over HF radio channels. It\nconsists of audio samples recorded by various receivers at different locations\nacross Europe, all monitoring the same single-sideband modulated transmission\nfrom a base station in Paderborn, Germany. Transmitted and received speech\nsignals are precisely time aligned to offer parallel data for supervised\ntraining of deep learning based detection and enhancement algorithms. For the\ntask of speech activity detection two exemplary baseline systems are presented,\none based on statistical methods employing a multi-stage Wiener filter with\nminimum statistics noise floor estimation, and the other relying on a deep\nlearning approach.",
    "descriptor": "\nComments: Submitted to ITG 2021\n",
    "authors": [
      "Jens Heitkaemper",
      "Joerg Schmalenstroeer",
      "Joerg Ullmann",
      "Valentin Ion",
      "Reinhold Haeb-Umbach"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.02472"
  },
  {
    "id": "arXiv:2106.02473",
    "title": "A New Gastric Histopathology Subsize Image Database (GasHisSDB) for  Classification Algorithm Test: from Linear Regression to Visual Transformer",
    "abstract": "GasHisSDB is a New Gastric Histopathology Subsize Image Database with a total\nof 245196 images. GasHisSDB is divided into 160*160 pixels sub-database,\n120*120 pixels sub-database and 80*80 pixels sub-database. GasHisSDB is made to\nrealize the function of valuating image classification. In order to prove that\nthe methods of different periods in the field of image classification have\ndiscrepancies on GasHisSDB, we select a variety of classifiers for evaluation.\nSeven classical machine learning classifiers, three CNN classifiers and a novel\ntransformer-based classifier are selected for testing on image classification\ntasks. GasHisSDB is available at the\nURL:https://github.com/NEUhwm/GasHisSDB.git.",
    "descriptor": "",
    "authors": [
      "Weiming Hu",
      "Chen Li",
      "Xiaoyan Li",
      "Haoyuan Chen",
      "Wanli Liu",
      "Changhao Sun",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02473"
  },
  {
    "id": "arXiv:2106.02479",
    "title": "Neural Architecture Search via Bregman Iterations",
    "abstract": "We propose a novel strategy for Neural Architecture Search (NAS) based on\nBregman iterations. Starting from a sparse neural network our gradient-based\none-shot algorithm gradually adds relevant parameters in an inverse scale space\nmanner. This allows the network to choose the best architecture in the search\nspace which makes it well-designed for a given task, e.g., by adding neurons or\nskip connections. We demonstrate that using our approach one can unveil, for\ninstance, residual autoencoders for denoising, deblurring, and classification\ntasks. Code is available at https://github.com/TimRoith/BregmanLearning.",
    "descriptor": "",
    "authors": [
      "Leon Bungert",
      "Tim Roith",
      "Daniel Tenbrinck",
      "Martin Burger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.02479"
  },
  {
    "id": "arXiv:2106.02483",
    "title": "You can't always get what you want: towards user-controlled privacy on  Android",
    "abstract": "Mobile applications (hereafter, apps) collect a plethora of information\nregarding the user behavior and his device through third-party analytics\nlibraries. However, the collection and usage of such data raised several\nprivacy concerns, mainly because the end-user - i.e., the actual owner of the\ndata - is out of the loop in this collection process. Also, the existing\nprivacy-enhanced solutions that emerged in the last years follow an \"all or\nnothing\" approach, leaving the user the sole option to accept or completely\ndeny the access to privacy-related data.\nThis work has the two-fold objective of assessing the privacy implications on\nthe usage of analytics libraries in mobile apps and proposing a data\nanonymization methodology that enables a trade-off between the utility and\nprivacy of the collected data and gives the user complete control over the\nsharing process. To achieve that, we present an empirical privacy assessment on\nthe analytics libraries contained in the 4500 most-used Android apps of the\nGoogle Play Store between November 2020 and January 2021. Then, we propose an\nempowered anonymization methodology, based on MobHide, that gives the end-user\ncomplete control over the collection and anonymization process. Finally, we\nempirically demonstrate the applicability and effectiveness of such\nanonymization methodology thanks to HideDroid, a fully-fledged anonymization\napp for the Android ecosystem.",
    "descriptor": "",
    "authors": [
      "Davide Caputo",
      "Francesco Pagano",
      "Giovanni Bottino",
      "Luca Verderame",
      "Alessio Merlo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.02483"
  },
  {
    "id": "arXiv:2106.02484",
    "title": "NeuraCrypt: Hiding Private Health Data via Random Neural Networks for  Public Training",
    "abstract": "Balancing the needs of data privacy and predictive utility is a central\nchallenge for machine learning in healthcare. In particular, privacy concerns\nhave led to a dearth of public datasets, complicated the construction of\nmulti-hospital cohorts and limited the utilization of external machine learning\nresources. To remedy this, new methods are required to enable data owners, such\nas hospitals, to share their datasets publicly, while preserving both patient\nprivacy and modeling utility. We propose NeuraCrypt, a private encoding scheme\nbased on random deep neural networks. NeuraCrypt encodes raw patient data using\na randomly constructed neural network known only to the data-owner, and\npublishes both the encoded data and associated labels publicly. From a\ntheoretical perspective, we demonstrate that sampling from a sufficiently rich\nfamily of encoding functions offers a well-defined and meaningful notion of\nprivacy against a computationally unbounded adversary with full knowledge of\nthe underlying data-distribution. We propose to approximate this family of\nencoding functions through random deep neural networks. Empirically, we\ndemonstrate the robustness of our encoding to a suite of adversarial attacks\nand show that NeuraCrypt achieves competitive accuracy to non-private baselines\non a variety of x-ray tasks. Moreover, we demonstrate that multiple hospitals,\nusing independent private encoders, can collaborate to train improved x-ray\nmodels. Finally, we release a challenge dataset to encourage the development of\nnew attacks on NeuraCrypt.",
    "descriptor": "",
    "authors": [
      "Adam Yala",
      "Homa Esfahanizadeh",
      "Rafael G. L. D' Oliveira",
      "Ken R. Duffy",
      "Manya Ghobadi",
      "Tommi S. Jaakkola",
      "Vinod Vaikuntanathan",
      "Regina Barzilay",
      "Muriel Medard"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02484"
  },
  {
    "id": "arXiv:2106.02487",
    "title": "Debiasing a First-order Heuristic for Approximate Bi-level Optimization",
    "abstract": "Approximate bi-level optimization (ABLO) consists of (outer-level)\noptimization problems, involving numerical (inner-level) optimization loops.\nWhile ABLO has many applications across deep learning, it suffers from time and\nmemory complexity proportional to the length $r$ of its inner optimization\nloop. To address this complexity, an earlier first-order method (FOM) was\nproposed as a heuristic that omits second derivative terms, yielding\nsignificant speed gains and requiring only constant memory. Despite FOM's\npopularity, there is a lack of theoretical understanding of its convergence\nproperties. We contribute by theoretically characterizing FOM's gradient bias\nunder mild assumptions. We further demonstrate a rich family of examples where\nFOM-based SGD does not converge to a stationary point of the ABLO objective. We\naddress this concern by proposing an unbiased FOM (UFOM) enjoying constant\nmemory complexity as a function of $r$. We characterize the introduced\ntime-variance tradeoff, demonstrate convergence bounds, and find an optimal\nUFOM for a given ABLO problem. Finally, we propose an efficient adaptive UFOM\nscheme.",
    "descriptor": "\nComments: Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021. arXiv admin note: text overlap with arXiv:2006.03631\n",
    "authors": [
      "Valerii Likhosherstov",
      "Xingyou Song",
      "Krzysztof Choromanski",
      "Jared Davis",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02487"
  },
  {
    "id": "arXiv:2106.02488",
    "title": "Evaluation of Local Model-Agnostic Explanations Using Ground Truth",
    "abstract": "Explanation techniques are commonly evaluated using human-grounded methods,\nlimiting the possibilities for large-scale evaluations and rapid progress in\nthe development of new techniques. We propose a functionally-grounded\nevaluation procedure for local model-agnostic explanation techniques. In our\napproach, we generate ground truth for explanations when the black-box model is\nLogistic Regression and Gaussian Naive Bayes and compare how similar each\nexplanation is to the extracted ground truth. In our empirical study,\nexplanations of Local Interpretable Model-agnostic Explanations (LIME), SHapley\nAdditive exPlanations (SHAP), and Local Permutation Importance (LPI) are\ncompared in terms of how similar they are to the extracted ground truth. In the\ncase of Logistic Regression, we find that the performance of the explanation\ntechniques is highly dependent on the normalization of the data. In contrast,\nLocal Permutation Importance outperforms the other techniques on Naive Bayes,\nirrespective of normalization. We hope that this work lays the foundation for\nfurther research into functionally-grounded evaluation methods for explanation\ntechniques.",
    "descriptor": "\nComments: Submitted on May 28 2021, 13 pages, 4 Figures\n",
    "authors": [
      "Amir Hossein Akhavan Rahnama",
      "Judith Butepage",
      "Pierre Geurts",
      "Henrik Bostrom"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02488"
  },
  {
    "id": "arXiv:2106.02489",
    "title": "Long-Horizon Multi-Robot Rearrangement Planning for Construction  Assembly",
    "abstract": "Robotic assembly planning has the potential to profoundly change how\nbuildings can be designed and created. It enables architects to explicitly\naccount for the assembly process already during the design phase, and enables\nefficient building methods that profit from the robots' different capabilities.\nPrevious work has addressed planning of robot assembly sequences and\nidentifying the feasibility of architectural designs. This paper extends\nprevious work by enabling assembly planning with large, heterogeneous teams of\nrobots. We present a scalable planning system which enables parallelization of\ncomplex task and motion planning problems by iteratively solving smaller\nsub-problems. Combining optimization methods to solve for manipulation\nconstraints with a sampling-based bi-directional space-time path planner\nenables us to plan cooperative multi-robot manipulation with unknown\narrival-times. Thus, our solver allows for completing sub-problems and tasks\nwith differing timescales and synchronizes them effectively. We demonstrate the\napproach on multiple case-studies and on two long-horizon building assembly\nscenarios to show the robustness and scalability of our algorithm.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Valentin Noah Hartmann",
      "Andreas Orthey",
      "Danny Driess",
      "Ozgur S. Oguz",
      "Marc Toussaint"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02489"
  },
  {
    "id": "arXiv:2106.02490",
    "title": "Language Model Metrics and Procrustes Analysis for Improved Vector  Transformation of NLP Embeddings",
    "abstract": "Artificial Neural networks are mathematical models at their core. This\ntruismpresents some fundamental difficulty when networks are tasked with\nNatural Language Processing. A key problem lies in measuring the similarity or\ndistance among vectors in NLP embedding space, since the mathematical concept\nof distance does not always agree with the linguistic concept. We suggest that\nthe best way to measure linguistic distance among vectors is by employing the\nLanguage Model (LM) that created them. We introduce Language Model Distance\n(LMD) for measuring accuracy of vector transformations based on the\nDistributional Hypothesis ( LMD Accuracy ). We show the efficacy of this metric\nby applying it to a simple neural network learning the Procrustes algorithm for\nbilingual word mapping.",
    "descriptor": "",
    "authors": [
      "Thomas Conley",
      "Jugal Kalita"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.02490"
  },
  {
    "id": "arXiv:2106.02491",
    "title": "Age of Information in Practice",
    "abstract": "While age of Information (AoI) has gained importance as a metric\ncharacterizing the fresh-ness of information in information-update systems and\ntime-critical applications, most previous studies on AoI have been theoretical.\nIn this chapter, we compile a set of recent works reporting API measurements in\nreal-life networks and experimental testbeds, and investigating practical\nissues such as synchronization, the role of various transport layer protocols,\ncongestion control mechanisms, application of machine learning for adaptation\nto network conditions, and device related bottlenecks such as limited\nprocessing power.",
    "descriptor": "",
    "authors": [
      "Elif Uysal",
      "Onur Kaya",
      "Sajjad Baghaee",
      "Hasan Burhan Beytur"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02491"
  },
  {
    "id": "arXiv:2106.02493",
    "title": "Homological Time Series Analysis of Sensor Signals from Power Plants",
    "abstract": "In this paper, we use topological data analysis techniques to construct a\nsuitable neural network classifier for the task of learning sensor signals of\nentire power plants according to their reference designation system. We use\nrepresentations of persistence diagrams to derive necessary preprocessing steps\nand visualize the large amounts of data. We derive architectures with deep\none-dimensional convolutional layers combined with stacked long short-term\nmemories as residual networks suitable for processing the persistence features.\nWe combine three separate sub-networks, obtaining as input the time series\nitself and a representation of the persistent homology for the zeroth and first\ndimension. We give a mathematical derivation for most of the used\nhyper-parameters. For validation, numerical experiments were performed with\nsensor data from four power plants of the same construction type.",
    "descriptor": "",
    "authors": [
      "Luciano Melodia",
      "Richard Lenz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.02493"
  },
  {
    "id": "arXiv:2106.02494",
    "title": "Network and Physical Layer Attacks and countermeasures to AI-Enabled 6G  O-RAN",
    "abstract": "Artificial intelligence (AI) will play an increasing role in cellular network\ndeployment, configuration and management. This paper examines the security\nimplications of AI-driven 6G radio access networks (RANs). While the expected\ntimeline for 6G standardization is still several years out, pre-standardization\nefforts related to 6G security are already ongoing and will benefit from\nfundamental and experimental research. The Open RAN (O-RAN) describes an\nindustry-driven open architecture and interfaces for building next generation\nRANs with AI control. Considering this architecture, we identify the critical\nthreats to data driven network and physical layer elements, the corresponding\ncountermeasures, and the research directions.",
    "descriptor": "",
    "authors": [
      "Talha F. Rahman",
      "Aly S. Abdalla",
      "Keith Powell",
      "Walaa AlQwider",
      "Vuk Marojevic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02494"
  },
  {
    "id": "arXiv:2106.02495",
    "title": "ADTrack: Target-Aware Dual Filter Learning for Real-Time Anti-Dark UAV  Tracking",
    "abstract": "Prior correlation filter (CF)-based tracking methods for unmanned aerial\nvehicles (UAVs) have virtually focused on tracking in the daytime. However,\nwhen the night falls, the trackers will encounter more harsh scenes, which can\neasily lead to tracking failure. In this regard, this work proposes a novel\ntracker with anti-dark function (ADTrack). The proposed method integrates an\nefficient and effective low-light image enhancer into a CF-based tracker.\nBesides, a target-aware mask is simultaneously generated by virtue of image\nillumination variation. The target-aware mask can be applied to jointly train a\ntarget-focused filter that assists the context filter for robust tracking.\nSpecifically, ADTrack adopts dual regression, where the context filter and the\ntarget-focused filter restrict each other for dual filter learning. Exhaustive\nexperiments are conducted on typical dark sceneries benchmark, consisting of 37\ntypical night sequences from authoritative benchmarks, i.e., UAVDark, and our\nnewly constructed benchmark UAVDark70. The results have shown that ADTrack\nfavorably outperforms other state-of-the-art trackers and achieves a real-time\nspeed of 34 frames/s on a single CPU, greatly extending robust UAV tracking to\nnight scenes.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Bowen Li",
      "Changhong Fu",
      "Fangqiang Ding",
      "Junjie Ye",
      "Fuling Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02495"
  },
  {
    "id": "arXiv:2106.02497",
    "title": "COINS: Dynamically Generating COntextualized Inference Rules for  Narrative Story Completion",
    "abstract": "Despite recent successes of large pre-trained language models in solving\nreasoning tasks, their inference capabilities remain opaque. We posit that such\nmodels can be made more interpretable by explicitly generating interim\ninference rules, and using them to guide the generation of task-specific\ntextual outputs. In this paper we present COINS, a recursive inference\nframework that i) iteratively reads context sentences, ii) dynamically\ngenerates contextualized inference rules, encodes them, and iii) uses them to\nguide task-specific output generation. We apply COINS to a Narrative Story\nCompletion task that asks a model to complete a story with missing sentences,\nto produce a coherent story with plausible logical connections, causal\nrelationships, and temporal dependencies. By modularizing inference and\nsentence generation steps in a recurrent model, we aim to make reasoning steps\nand their effects on next sentence generation transparent. Our automatic and\nmanual evaluations show that the model generates better story sentences than\nSOTA baselines, especially in terms of coherence. We further demonstrate\nimproved performance over strong pre-trained LMs in generating commonsense\ninference rules. The recursive nature of COINS holds the potential for\ncontrolled generation of longer sequences.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Debjit Paul",
      "Anette Frank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02497"
  },
  {
    "id": "arXiv:2106.02498",
    "title": "Towards Fairness Certification in Artificial Intelligence",
    "abstract": "Thanks to the great progress of machine learning in the last years, several\nArtificial Intelligence (AI) techniques have been increasingly moving from the\ncontrolled research laboratory settings to our everyday life. AI is clearly\nsupportive in many decision-making scenarios, but when it comes to sensitive\nareas such as health care, hiring policies, education, banking or justice, with\nmajor impact on individuals and society, it becomes crucial to establish\nguidelines on how to design, develop, deploy and monitor this technology.\nIndeed the decision rules elaborated by machine learning models are data-driven\nand there are multiple ways in which discriminatory biases can seep into data.\nAlgorithms trained on those data incur the risk of amplifying prejudices and\nsocietal stereotypes by over associating protected attributes such as gender,\nethnicity or disabilities with the prediction task. Starting from the extensive\nexperience of the National Metrology Institute on measurement standards and\ncertification roadmaps, and of Politecnico di Torino on machine learning as\nwell as methods for domain bias evaluation and mastering, we propose a first\njoint effort to define the operational steps needed for AI fairness\ncertification. Specifically we will overview the criteria that should be met by\nan AI system before coming into official service and the conformity assessment\nprocedures useful to monitor its functioning for fair decisions.",
    "descriptor": "",
    "authors": [
      "Tatiana Tommasi",
      "Silvia Bucci",
      "Barbara Caputo",
      "Pietro Asinari"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02498"
  },
  {
    "id": "arXiv:2106.02505",
    "title": "New data structure for univariate polynomial approximation and  applications to root isolation, numerical multipoint evaluation, and other  problems",
    "abstract": "We present a new data structure to approximate accurately and efficiently a\npolynomial $f$ of degree $d$ given as a list of coefficients. Its properties\nallow us to improve the state-of-the-art bounds on the bit complexity for the\nproblems of root isolation and approximate multipoint evaluation. This data\nstructure also leads to a new geometric criterion to detect ill-conditioned\npolynomials, implying notably that the standard condition number of the zeros\nof a polynomial is at least exponential in the number of roots of modulus less\nthan $1/2$ or greater than $2$.Given a polynomial $f$ of degree $d$ with\n$\\|f\\|_1 \\leq 2^\\tau$ for $\\tau \\geq 1$, isolating all its complex roots or\nevaluating it at $d$ points can be done with a quasi-linear number of\narithmetic operations. However, considering the bit complexity, the\nstate-of-the-art algorithms require at least $d^{3/2}$ bit operations even for\nwell-conditioned polynomials and when the accuracy required is low. Given a\npositive integer $m$, we can compute our new data structure and evaluate $f$ at\n$d$ points in the unit disk with an absolute error less than $2^{-m}$ in\n$\\widetilde O(d(\\tau+m))$ bit operations, where $\\widetilde O(\\cdot)$ means\nthat we omit logarithmic factors. We also show that if $\\kappa$ is the absolute\ncondition number of the zeros of $f$, then we can isolate all the roots of $f$\nin $\\widetilde O(d(\\tau + \\log \\kappa))$ bit operations. Moreover, our\nalgorithms are simple to implement. For approximating the complex roots of a\npolynomial, we implemented a small prototype in \\verb|Python/NumPy| that is an\norder of magnitude faster than the state-of-the-art solver \\verb/MPSolve/ for\nhigh degree polynomials with random coefficients.",
    "descriptor": "",
    "authors": [
      "Guillaume Moroz"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2106.02505"
  },
  {
    "id": "arXiv:2106.02506",
    "title": "High Order Semi-implicit WENO Schemes for All Mach Full Euler System of  Gas Dynamics",
    "abstract": "In this paper, we propose high order semi-implicit schemes for the all Mach\nfull Euler equations of gas dynamics. Material waves are treated explicitly,\nwhile acoustic waves are treated implicitly, thus avoiding severe CFL\nrestrictions for low Mach flows. High order accuracy in time is obtained by\nsemi-implicit temporal integrator based on the IMEX Runge-Kutta (IMEX-RK)\nframework. High order in space is achieved by finite difference WENO schemes\nwith characteristic-wise reconstructions adapted to the semi-implicit IMEX-RK\ntime discretization. The schemes are proven to be asymptotic preserving and\nasymptotically accurate as the Mach number vanishes. Besides, they can well\ncapture discontinuous solutions in the compressible regime, especially for two\ndimensional Riemann problems. Numerical tests in one and two space dimensions\nwill illustrate the effectiveness of the proposed schemes.",
    "descriptor": "",
    "authors": [
      "Sebastiano Boscarino",
      "Jing-Mei Qiu",
      "Giovanni Russo",
      "Tao Xiong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02506"
  },
  {
    "id": "arXiv:2106.02513",
    "title": "Generative Text Modeling through Short Run Inference",
    "abstract": "Latent variable models for text, when trained successfully, accurately model\nthe data distribution and capture global semantic and syntactic features of\nsentences. The prominent approach to train such models is variational\nautoencoders (VAE). It is nevertheless challenging to train and often results\nin a trivial local optimum where the latent variable is ignored and its\nposterior collapses into the prior, an issue known as posterior collapse.\nVarious techniques have been proposed to mitigate this issue. Most of them\nfocus on improving the inference model to yield latent codes of higher quality.\nThe present work proposes a short run dynamics for inference. It is initialized\nfrom the prior distribution of the latent variable and then runs a small number\n(e.g., 20) of Langevin dynamics steps guided by its posterior distribution. The\nmajor advantage of our method is that it does not require a separate inference\nmodel or assume simple geometry of the posterior distribution, thus rendering\nan automatic, natural and flexible inference engine. We show that the models\ntrained with short run dynamics more accurately model the data, compared to\nstrong language model and VAE baselines, and exhibit no sign of posterior\ncollapse. Analyses of the latent space show that interpolation in the latent\nspace is able to generate coherent sentences with smooth transition and\ndemonstrate improved classification over strong baselines with latent features\nfrom unsupervised pretraining. These results together expose a well-structured\nlatent space of our generative model.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Bo Pang",
      "Erik Nijkamp",
      "Tian Han",
      "Ying Nian Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02513"
  },
  {
    "id": "arXiv:2106.02514",
    "title": "The Image Local Autoregressive Transformer",
    "abstract": "Recently, AutoRegressive (AR) models for the whole image generation empowered\nby transformers have achieved comparable or even better performance to\nGenerative Adversarial Networks (GANs). Unfortunately, directly applying such\nAR models to edit/change local image regions, may suffer from the problems of\nmissing global information, slow inference speed, and information leakage of\nlocal guidance. To address these limitations, we propose a novel model -- image\nLocal Autoregressive Transformer (iLAT), to better facilitate the locally\nguided image synthesis. Our iLAT learns the novel local discrete\nrepresentations, by the newly proposed local autoregressive (LA) transformer of\nthe attention mask and convolution mechanism. Thus iLAT can efficiently\nsynthesize the local image regions by key guidance information. Our iLAT is\nevaluated on various locally guided image syntheses, such as pose-guided person\nimage synthesis and face editing. Both the quantitative and qualitative results\nshow the efficacy of our model.",
    "descriptor": "",
    "authors": [
      "Chenjie Cao",
      "Yuxin Hong",
      "Xiang Li",
      "Chengrong Wang",
      "Chengming Xu",
      "XiangYang Xue",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.02514"
  },
  {
    "id": "arXiv:2106.02516",
    "title": "Improving Computer Generated Dialog with Auxiliary Loss Functions and  Custom Evaluation Metrics",
    "abstract": "Although people have the ability to engage in vapid dialogue without effort,\nthis may not be a uniquely human trait. Since the 1960's researchers have been\ntrying to create agents that can generate artificial conversation. These\nprograms are commonly known as chatbots. With increasing use of neural networks\nfor dialog generation, some conclude that this goal has been achieved. This\nresearch joins the quest by creating a dialog generating Recurrent Neural\nNetwork (RNN) and by enhancing the ability of this network with auxiliary loss\nfunctions and a beam search. Our custom loss functions achieve better cohesion\nand coherence by including calculations of Maximum Mutual Information (MMI) and\nentropy. We demonstrate the effectiveness of this system by using a set of\ncustom evaluation metrics inspired by an abundance of previous research and\nbased on tried-and-true principles of Natural Language Processing.",
    "descriptor": "",
    "authors": [
      "Thomas Conley",
      "Jack St. Clair",
      "Jugal Kalita"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02516"
  },
  {
    "id": "arXiv:2106.02517",
    "title": "Phase Retrieval for $L^2([-\u03c0,\u03c0])$ via the Provably Accurate and  Noise Robust Numerical Inversion of Spectrogram Measurements",
    "abstract": "In this paper, we focus on the approximation of smooth functions $f: [-\\pi,\n\\pi] \\rightarrow \\mathbb{C}$, up to an unresolvable global phase ambiguity,\nfrom a finite set of Short Time Fourier Transform (STFT) magnitude (i.e.,\nspectrogram) measurements. Two algorithms are developed for approximately\ninverting such measurements, each with theoretical error guarantees\nestablishing their correctness. A detailed numerical study also demonstrates\nthat both algorithms work well in practice and have good numerical convergence\nbehavior.",
    "descriptor": "",
    "authors": [
      "Mark Iwen",
      "Michael Perlmutter",
      "Nada Sissouno",
      "Aditya Viswanathan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02517"
  },
  {
    "id": "arXiv:2106.02520",
    "title": "Semantic Correspondence with Transformers",
    "abstract": "We propose a novel cost aggregation network, called Cost Aggregation with\nTransformers (CATs), to find dense correspondences between semantically similar\nimages with additional challenges posed by large intra-class appearance and\ngeometric variations. Compared to previous hand-crafted or CNN-based methods\naddressing the cost aggregation stage, which either lack robustness to severe\ndeformations or inherit the limitation of CNNs that fail to discriminate\nincorrect matches due to limited receptive fields, CATs explore global\nconsensus among initial correlation map with the help of some architectural\ndesigns that allow us to exploit full potential of self-attention mechanism.\nSpecifically, we include appearance affinity modelling to disambiguate the\ninitial correlation maps and multi-level aggregation to benefit from\nhierarchical feature representations within Transformer-based aggregator, and\ncombine with swapping self-attention and residual connections not only to\nenforce consistent matching, but also to ease the learning process. We conduct\nexperiments to demonstrate the effectiveness of the proposed model over the\nlatest methods and provide extensive ablation studies. Code and trained models\nwill be made available at https://github.com/SunghwanHong/CATs.",
    "descriptor": "\nComments: Code and trained models will be made available at this https URL\n",
    "authors": [
      "Seokju Cho",
      "Sunghwan Hong",
      "Sangryul Jeon",
      "Yunsung Lee",
      "Kwanghoon Sohn",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02520"
  },
  {
    "id": "arXiv:2106.02523",
    "title": "Hallucination In Object Detection -- A Study In Visual Part Verification",
    "abstract": "We show that object detectors can hallucinate and detect missing objects;\npotentially even accurately localized at their expected, but non-existing,\nposition. This is particularly problematic for applications that rely on visual\npart verification: detecting if an object part is present or absent. We show\nhow popular object detectors hallucinate objects in a visual part verification\ntask and introduce the first visual part verification dataset: DelftBikes,\nwhich has 10,000 bike photographs, with 22 densely annotated parts per image,\nwhere some parts may be missing. We explicitly annotated an extra object state\nlabel for each part to reflect if a part is missing or intact. We propose to\nevaluate visual part verification by relying on recall and compare popular\nobject detectors on DelftBikes.",
    "descriptor": "\nComments: ICIP 2021\n",
    "authors": [
      "Osman Semih Kayhan",
      "Bart Vredebregt",
      "Jan C. van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02523"
  },
  {
    "id": "arXiv:2106.02524",
    "title": "CLIP: A Dataset for Extracting Action Items for Physicians from Hospital  Discharge Notes",
    "abstract": "Continuity of care is crucial to ensuring positive health outcomes for\npatients discharged from an inpatient hospital setting, and improved\ninformation sharing can help. To share information, caregivers write discharge\nnotes containing action items to share with patients and their future\ncaregivers, but these action items are easily lost due to the lengthiness of\nthe documents. In this work, we describe our creation of a dataset of clinical\naction items annotated over MIMIC-III, the largest publicly available dataset\nof real clinical notes. This dataset, which we call CLIP, is annotated by\nphysicians and covers 718 documents representing 100K sentences. We describe\nthe task of extracting the action items from these documents as multi-aspect\nextractive summarization, with each aspect representing a type of action to be\ntaken. We evaluate several machine learning models on this task, and show that\nthe best models exploit in-domain language model pre-training on 59K\nunannotated documents, and incorporate context from neighboring sentences. We\nalso propose an approach to pre-training data selection that allows us to\nexplore the trade-off between size and domain-specificity of pre-training\ndatasets for this task.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "James Mullenbach",
      "Yada Pruksachatkun",
      "Sean Adler",
      "Jennifer Seale",
      "Jordan Swartz",
      "T. Greg McKelvey",
      "Hui Dai",
      "Yi Yang",
      "David Sontag"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02524"
  },
  {
    "id": "arXiv:2106.02527",
    "title": "RoadMap: A Light-Weight Semantic Map for Visual Localization towards  Autonomous Driving",
    "abstract": "Accurate localization is of crucial importance for autonomous driving tasks.\nNowadays, we have seen a lot of sensor-rich vehicles (e.g. Robo-taxi) driving\non the street autonomously, which rely on high-accurate sensors (e.g. Lidar and\nRTK GPS) and high-resolution map. However, low-cost production cars cannot\nafford such high expenses on sensors and maps. How to reduce costs? How do\nsensor-rich vehicles benefit low-cost cars? In this paper, we proposed a\nlight-weight localization solution, which relies on low-cost cameras and\ncompact visual semantic maps. The map is easily produced and updated by\nsensor-rich vehicles in a crowd-sourced way. Specifically, the map consists of\nseveral semantic elements, such as lane line, crosswalk, ground sign, and stop\nline on the road surface. We introduce the whole framework of on-vehicle\nmapping, on-cloud maintenance, and user-end localization. The map data is\ncollected and preprocessed on vehicles. Then, the crowd-sourced data is\nuploaded to a cloud server. The mass data from multiple vehicles are merged on\nthe cloud so that the semantic map is updated in time. Finally, the semantic\nmap is compressed and distributed to production cars, which use this map for\nlocalization. We validate the performance of the proposed map in real-world\nexperiments and compare it against other algorithms. The average size of the\nsemantic map is $36$ kb/km. We highlight that this framework is a reliable and\npractical localization solution for autonomous driving.",
    "descriptor": "\nComments: IEEE International Conference on Robotics and Automation, 2021\n",
    "authors": [
      "Tong Qin",
      "Yuxin Zheng",
      "Tongqing Chen",
      "Yilun Chen",
      "Qing Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02527"
  },
  {
    "id": "arXiv:2106.02529",
    "title": "Blockchain for Transactive Energy Management of Distributed Energy  Resources in Smart Grid",
    "abstract": "This work presents the design and implementation of a blockchain system that\nenables the trustable transactive energy management for distributed energy\nresources (DERs). We model the interactions among DERs, including energy\ntrading and flexible appliance scheduling, as a cost minimization problem.\nConsidering the dispersed nature and diverse ownership of DERs, we develop a\ndistributed algorithm to solve the optimization problem using the alternating\ndirection method of multipliers (ADMM) method. Furthermore, we develop a\nblockchain system, on which we implement the proposed algorithm with the smart\ncontract, to guarantee the transparency and correctness of the energy\nmanagement. We prototype the blockchain in a small-scale test network and\nevaluate it through experiments using real-world data. The experimental results\nvalidate the feasibility and effectiveness of our design.",
    "descriptor": "\nComments: ACM International Conference on Future Energy Systems (ACM e-Energy) 2021. arXiv admin note: text overlap with arXiv:2105.00174\n",
    "authors": [
      "Qing Yang",
      "Hao Wang",
      "Xiaoxiao Wu",
      "Taotao Wang",
      "Shengli Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02529"
  },
  {
    "id": "arXiv:2106.02531",
    "title": "CAFLOW: Conditional Autoregressive Flows",
    "abstract": "We introduce CAFLOW, a new diverse image-to-image translation model that\nsimultaneously leverages the power of auto-regressive modeling and the modeling\nefficiency of conditional normalizing flows. We transform the conditioning\nimage into a sequence of latent encodings using a multi-scale normalizing flow\nand repeat the process for the conditioned image. We model the conditional\ndistribution of the latent encodings by modeling the auto-regressive\ndistributions with an efficient multi-scale normalizing flow, where each\nconditioning factor affects image synthesis at its respective resolution scale.\nOur proposed framework performs well on a range of image-to-image translation\ntasks. It outperforms former designs of conditional flows because of its\nexpressive auto-regressive structure.",
    "descriptor": "",
    "authors": [
      "Georgios Batzolis",
      "Marcello Carioni",
      "Christian Etmann",
      "Soroosh Afyouni",
      "Zoe Kourtzi",
      "Carola Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02531"
  },
  {
    "id": "arXiv:2106.02533",
    "title": "Graph-based Deep Learning for Communication Networks: A Survey",
    "abstract": "Communication networks are important infrastructures in contemporary society.\nThere are still many challenges that are not fully solved and new solutions are\nproposed continuously in this active research area. In recent years, to model\nthe network topology, graph-based deep learning has achieved state-of-the-art\nperformance in a series of problems in communication networks. In this survey,\nwe review the rapidly growing body of research using different graph-based deep\nlearning models, e.g. graph convolutional and graph attention networks, in\nvarious problems from different communication networks, e.g. wireless networks,\nwired networks, and software-defined networks. We also present a well-organized\nlist of the problem and solution for each study and identify future research\ndirections. To the best of our knowledge, this paper is the first survey that\nfocuses on the application of graph-based deep learning methods in\ncommunication networks. To track the follow-up research, a public GitHub\nrepository is created, where the relevant papers will be updated continuously.",
    "descriptor": "\nComments: Github link: this https URL\n",
    "authors": [
      "Weiwei Jiang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02533"
  },
  {
    "id": "arXiv:2106.02535",
    "title": "Flying with Cartographer: Adapting the Cartographer 3D Graph SLAM Stack  for UAV Navigation",
    "abstract": "This paper describes an application of the Cartographer graph SLAM stack as a\npose sensor in a UAV feedback control loop, with certain application-specific\nchanges in the SLAM stack such as smoothing of the optimized pose. Pose\nestimation is performed by fusing 3D LiDAR/IMU-based proprioception with GPS\nposition measurements by means of pose graph optimisation. Moreover, partial\nenvironment maps built from the LiDAR data (submaps) within the Cartographer\nSLAM stack are marshalled into OctoMap, an Octree-based voxel map\nimplementation. The OctoMap is further used for navigation tasks such as path\nplanning and obstacle avoidance.",
    "descriptor": "\nComments: Submitted to AIRPHARO 2021\n",
    "authors": [
      "Juraj Orsuli\u0107",
      "Robert Milijas",
      "Ana Batinovic",
      "Lovro Markovic",
      "Antun Ivanovic",
      "Stjepan Bogdan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.02535"
  },
  {
    "id": "arXiv:2106.02538",
    "title": "Bottleneck Profiles and Discrete Prokhorov Metrics for Persistence  Diagrams",
    "abstract": "In topological data analysis (TDA), persistence diagrams have been a\nsuccesful tool. To compare them, Wasserstein and Bottleneck distances are\ncommonly used. We address the shortcomings of these metrics and show a way to\ninvestigate them in a systematic way by introducing bottleneck profiles. This\nleads to a notion of discrete Prokhorov metrics for persistence diagrams as a\ngeneralization of the Bottleneck distance. They satisfy a stability result and\nbounds with respect to Wasserstein metrics. We provide algorithms to compute\nthe newly introduced quantities and end with an discussion about experiments.",
    "descriptor": "\nComments: 27 pages, 9 figures\n",
    "authors": [
      "Pawe\u0142 D\u0142otko",
      "Niklas Hellmer"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2106.02538"
  },
  {
    "id": "arXiv:2106.02540",
    "title": "Transferable and Distributed User Association Policies for 5G and Beyond  Networks",
    "abstract": "We study the problem of user association, namely finding the optimal\nassignment of user equipment to base stations to achieve a targeted network\nperformance. In this paper, we focus on the knowledge transferability of\nassociation policies. Indeed, traditional non-trivial user association schemes\nare often scenario-specific or deployment-specific and require a policy\nre-design or re-learning when the number or the position of the users change.\nIn contrast, transferability allows to apply a single user association policy,\ndevised for a specific scenario, to other distinct user deployments, without\nneeding a substantial re-learning or re-design phase and considerably reducing\nits computational and management complexity. To achieve transferability, we\nfirst cast user association as a multi-agent reinforcement learning problem.\nThen, based on a neural attention mechanism that we specifically conceived for\nthis context, we propose a novel distributed policy network architecture, which\nis transferable among users with zero-shot generalization capability i.e.,\nwithout requiring additional training.Numerical results show the effectiveness\nof our solution in terms of overall network communication rate, outperforming\ncentralized benchmarks even when the number of users doubles with respect to\nthe initial training point.",
    "descriptor": "",
    "authors": [
      "Mohamed Sana",
      "Nicola di Pietro",
      "Emilio Calvanese Strinati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.02540"
  },
  {
    "id": "arXiv:2106.02542",
    "title": "Distributional Sliced Embedding Discrepancy for Incomparable  Distributions",
    "abstract": "Gromov-Wasserstein (GW) distance is a key tool for manifold learning and\ncross-domain learning, allowing the comparison of distributions that do not\nlive in the same metric space. Because of its high computational complexity,\nseveral approximate GW distances have been proposed based on entropy\nregularization or on slicing, and one-dimensional GW computation. In this\npaper, we propose a novel approach for comparing two incomparable\ndistributions, that hinges on the idea of distributional slicing, embeddings,\nand on computing the closed-form Wasserstein distance between the sliced\ndistributions. We provide a theoretical analysis of this new divergence, called\ndistributional sliced embedding (DSE) discrepancy, and we show that it\npreserves several interesting properties of GW distance including\nrotation-invariance. We show that the embeddings involved in DSE can be\nefficiently learned. Finally, we provide a large set of experiments\nillustrating the behavior of DSE as a divergence in the context of generative\nmodeling and in query framework.",
    "descriptor": "",
    "authors": [
      "Mokhtar Z. Alaya",
      "Gilles Gasso",
      "Maxime Berar",
      "Alain Rakotomamonjy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02542"
  },
  {
    "id": "arXiv:2106.02543",
    "title": "Contracting Neural-Newton Solver",
    "abstract": "Recent advances in deep learning have set the focus on neural networks (NNs)\nthat can successfully replace traditional numerical solvers in many\napplications, achieving impressive computing gains. One such application is\ntime domain simulation, which is indispensable for the design, analysis and\noperation of many engineering systems. Simulating dynamical systems with\nimplicit Newton-based solvers is a computationally heavy task, as it requires\nthe solution of a parameterized system of differential and algebraic equations\nat each time step. A variety of NN-based methodologies have been shown to\nsuccessfully approximate the dynamical trajectories computed by numerical time\ndomain solvers at a fraction of the time. However, so far no previous NN-based\nmodel has explicitly captured the fact that any predicted point on the time\ndomain trajectory also represents the fixed point of the numerical solver\nitself. As we show, explicitly capturing this property can lead to\nsignificantly increased NN accuracy and much smaller NN sizes. In this paper,\nwe model the Newton solver at the heart of an implicit Runge-Kutta integrator\nas a contracting map iteratively seeking this fixed point. Our primary\ncontribution is to develop a recurrent NN simulation tool, termed the\nContracting Neural-Newton Solver (CoNNS), which explicitly captures the\ncontracting nature of these Newton iterations. To build CoNNS, we train a\nfeedforward NN and mimic this contraction behavior by embedding a series of\ntraining constraints which guarantee the mapping provided by the NN satisfies\nthe Banach fixed-point theorem; thus, we are able to prove that successive\npasses through the NN are guaranteed to converge to a unique, fixed point.",
    "descriptor": "",
    "authors": [
      "Samuel Chevalier",
      "Jochen Stiasny",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02543"
  },
  {
    "id": "arXiv:2106.02545",
    "title": "New Insights into Metric Optimization for Ranking-based Recommendation",
    "abstract": "Direct optimization of IR metrics has often been adopted as an approach to\ndevise and develop ranking-based recommender systems. Most methods following\nthis approach aim at optimizing the same metric being used for evaluation,\nunder the assumption that this will lead to the best performance. A number of\nstudies of this practice bring this assumption, however, into question. In this\npaper, we dig deeper into this issue in order to learn more about the effects\nof the choice of the metric to optimize on the performance of a ranking-based\nrecommender system. We present an extensive experimental study conducted on\ndifferent datasets in both pairwise and listwise learning-to-rank scenarios, to\ncompare the relative merit of four popular IR metrics, namely RR, AP, nDCG and\nRBP, when used for optimization and assessment of recommender systems in\nvarious combinations. For the first three, we follow the practice of loss\nfunction formulation available in literature. For the fourth one, we propose\nnovel loss functions inspired by RBP for both the pairwise and listwise\nscenario. Our results confirm that the best performance is indeed not\nnecessarily achieved when optimizing the same metric being used for evaluation.\nIn fact, we find that RBP-inspired losses perform at least as well as other\nmetrics in a consistent way, and offer clear benefits in several cases.\nInteresting to see is that RBP-inspired losses, while improving the\nrecommendation performance for all uses, may lead to an individual performance\ngain that is correlated with the activity level of a user in interacting with\nitems. The more active the users, the more they benefit. Overall, our results\nchallenge the assumption behind the current research practice of optimizing and\nevaluating the same metric, and point to RBP-based optimization instead as a\npromising alternative when learning to rank in the recommendation context.",
    "descriptor": "\nComments: 10 pages, 5 figures, accepted at SIGIR 2021\n",
    "authors": [
      "Roger Zhe Li",
      "Juli\u00e1n Urbano",
      "Alan Hanjalic"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.02545"
  },
  {
    "id": "arXiv:2106.02547",
    "title": "Flux recovery for Cut finite element method and its application in a  posteriori error estimation",
    "abstract": "In this article, we aim to recover locally conservative and $H(div)$\nconforming fluxes for the linear Cut Finite Element Solution with Nitsche's\nmethod for Poisson problems with Dirichlet boundary condition. The computation\nof the conservative flux in the Raviart-Thomas space is completely local and\ndoes not require to solve any mixed problem. The $L^2$-norm of the difference\nbetween the numerical flux and the recovered flux can then be used as a\nposteriori error estimator in the adaptive mesh refinement procedure.\nTheoretically we are able to prove the global reliability and local efficiency.\nThe theoretical results are verified in the numerical results. Moreover, in the\nnumerical results we also observe optimal convergence rate for the flux error.",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Daniela Capatina",
      "Cuiyu He"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02547"
  },
  {
    "id": "arXiv:2106.02549",
    "title": "Detect the Interactions that Matter in Matter: Geometric Attention for  Many-Body Systems",
    "abstract": "Attention mechanisms are developing into a viable alternative to\nconvolutional layers as elementary building block of NNs. Their main advantage\nis that they are not restricted to capture local dependencies in the input, but\ncan draw arbitrary connections. This unprecedented capability coincides with\nthe long-standing problem of modeling global atomic interactions in molecular\nforce fields and other many-body problems. In its original formulation,\nhowever, attention is not applicable to the continuous domains in which the\natoms live. For this purpose we propose a variant to describe geometric\nrelations for arbitrary atomic configurations in Euclidean space that also\nrespects all relevant physical symmetries. We furthermore demonstrate, how the\nsuccessive application of our learned attention matrices effectively translates\nthe molecular geometry into a set of individual atomic contributions\non-the-fly.",
    "descriptor": "",
    "authors": [
      "Thorben Frank",
      "Stefan Chmiela"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.02549"
  },
  {
    "id": "arXiv:2106.02550",
    "title": "Certified DQBF Solving by Definition Extraction",
    "abstract": "We propose a new decision procedure for dependency quantified Boolean\nformulas (DQBF) that uses interpolation-based definition extraction to compute\nSkolem functions in a counter-example guided inductive synthesis (CEGIS) loop.\nIn each iteration, a family of candidate Skolem functions is tested for\ncorrectness using a SAT solver, which either determines that a model has been\nfound, or returns an assignment of the universal variables as a counterexample.\nFixing a counterexample generally involves changing candidates of multiple\nexistential variables with incomparable dependency sets. Our procedure\nintroduces auxiliary variables -- which we call arbiter variables -- that each\nrepresent the value of an existential variable for a particular assignment of\nits dependency set. Possible repairs are expressed as clauses on these\nvariables, and a SAT solver is invoked to find an assignment that deals with\nall previously seen counterexamples. Adding arbiter variables defines the\nvalues of Skolem functions for assignments where they were previously\nundefined, and may lead to the detection of Skolem functions by definition\nextraction in subsequent iterations. A key feature of the proposed procedure is\nthat it is certifying by design: for true DQBF, models can be returned at\nminimal overhead. Towards certification of false formulas, we prove that\nclauses can be derived in an expansion-based proof system for DQBF. In an\nexperimental evaluation on standard benchmark sets, an implementation was able\nto match (and in some cases, surpass) the performance of state-of-the-art DQBF\nsolvers. Moreover, models could be generated and validated for all true\ninstances that were solved.",
    "descriptor": "",
    "authors": [
      "Franz-Xaver Reichl",
      "Friedrich Slivovsky",
      "Stefan Szeider"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.02550"
  },
  {
    "id": "arXiv:2106.02552",
    "title": "Active Covering",
    "abstract": "We analyze the problem of active covering, where the learner is given an\nunlabeled dataset and can sequentially label query examples. The objective is\nto label query all of the positive examples in the fewest number of total label\nqueries. We show under standard non-parametric assumptions that a classical\nsupport estimator can be repurposed as an offline algorithm attaining an excess\nquery cost of $\\widetilde{\\Theta}(n^{D/(D+1)})$ compared to the optimal\nlearner, where $n$ is the number of datapoints and $D$ is the dimension. We\nthen provide a simple active learning method that attains an improved excess\nquery cost of $\\widetilde{O}(n^{(D-1)/D})$. Furthermore, the proposed\nalgorithms only require access to the positive labeled examples, which in\ncertain settings provides additional computational and privacy benefits.\nFinally, we show that the active learning method consistently outperforms\noffline methods as well as a variety of baselines on a wide range of benchmark\nimage-based datasets.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Heinrich Jiang",
      "Afshin Rostamizadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02552"
  },
  {
    "id": "arXiv:2106.02553",
    "title": "Fair Exploration via Axiomatic Bargaining",
    "abstract": "Motivated by the consideration of fairly sharing the cost of exploration\nbetween multiple groups in learning problems, we develop the Nash bargaining\nsolution in the context of multi-armed bandits. Specifically, the 'grouped'\nbandit associated with any multi-armed bandit problem associates, with each\ntime step, a single group from some finite set of groups. The utility gained by\na given group under some learning policy is naturally viewed as the reduction\nin that group's regret relative to the regret that group would have incurred\n'on its own'. We derive policies that yield the Nash bargaining solution\nrelative to the set of incremental utilities possible under any policy. We show\nthat on the one hand, the 'price of fairness' under such policies is limited,\nwhile on the other hand, regret optimal policies are arbitrarily unfair under\ngeneric conditions. Our theoretical development is complemented by a case study\non contextual bandits for warfarin dosing where we are concerned with the cost\nof exploration across multiple races and age groups.",
    "descriptor": "",
    "authors": [
      "Jackie Baek",
      "Vivek F. Farias"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02553"
  },
  {
    "id": "arXiv:2106.02554",
    "title": "Recovering Multiple Fractional Orders in Time-Fractional Diffusion in an  Unknown Medium",
    "abstract": "In this work, we investigate an inverse problem of recovering multiple orders\nin time-fractional diffusion type problems from the data observed at one single\npoint on the boundary. We prove the unique recovery of the orders together with\ntheir weights, which does not require a full knowledge of the domain or medium\nproperties, e.g., the diffusion and potential coefficients, initial condition\nand source in the model. The proof is based on Laplace transform and asymptotic\nexpansion. Further, inspired by the analysis, we propose a numerical procedure\nfor recovering these parameters based on a nonlinear least-squares fitting with\neither fractional polynomials or rational approximations as the model function,\nand provide numerical experiments to illustrate the approach at small time $t$.",
    "descriptor": "\nComments: 20 pages, 2 figures, comments welcome\n",
    "authors": [
      "Bangti Jin",
      "Yavar Kian"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.02554"
  },
  {
    "id": "arXiv:2106.02556",
    "title": "Musical Prosody-Driven Emotion Classification: Interpreting Vocalists  Portrayal of Emotions Through Machine Learning",
    "abstract": "The task of classifying emotions within a musical track has received\nwidespread attention within the Music Information Retrieval (MIR) community.\nMusic emotion recognition has traditionally relied on the use of acoustic\nfeatures, verbal features, and metadata-based filtering. The role of musical\nprosody remains under-explored despite several studies demonstrating a strong\nconnection between prosody and emotion. In this study, we restrict the input of\ntraditional machine learning algorithms to the features of musical prosody.\nFurthermore, our proposed approach builds upon the prior by classifying\nemotions under an expanded emotional taxonomy, using the Geneva Wheel of\nEmotion. We utilize a methodology for individual data collection from\nvocalists, and personal ground truth labeling by the artist themselves. We\nfound that traditional machine learning algorithms when limited to the features\nof musical prosody (1) achieve high accuracies for a single singer, (2)\nmaintain high accuracy when the dataset is expanded to multiple singers, and\n(3) achieve high accuracies when trained on a reduced subset of the total\nfeatures.",
    "descriptor": "",
    "authors": [
      "Farris Nicholas",
      "Model Brian",
      "Savery Richard",
      "Weinberg Gil"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.02556"
  },
  {
    "id": "arXiv:2106.02558",
    "title": "A Bayesian Risk Approach to MDPs with Parameter Uncertainty",
    "abstract": "We consider Markov Decision Processes (MDPs) where distributional parameters,\nsuch as transition probabilities, are unknown and estimated from data. The\npopular distributionally robust approach to addressing the parameter\nuncertainty can sometimes be overly conservative. In this paper, we propose a\nBayesian risk approach to MDPs with parameter uncertainty, where a risk\nfunctional is applied in nested form to the expected discounted total cost with\nrespect to the Bayesian posterior distributions of the unknown parameters in\neach time stage. The proposed approach provides more flexibility of risk\nattitudes towards parameter uncertainty and takes into account the availability\nof data in future time stages. For the finite-horizon MDPs, we show the dynamic\nprogramming equations can be solved efficiently with an upper confidence bound\n(UCB) based adaptive sampling algorithm. For the infinite-horizon MDPs, we\npropose a risk-adjusted Bellman operator and show the proposed operator is a\ncontraction mapping that leads to the optimal value function to the Bayesian\nrisk formulation. We demonstrate the empirical performance of our proposed\nalgorithms in the finite-horizon case on an inventory control problem and a\npath planning problem.",
    "descriptor": "",
    "authors": [
      "Yifan Lin",
      "Yuxuan Ren",
      "Enlu Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02558"
  },
  {
    "id": "arXiv:2106.02559",
    "title": "Do Syntactic Probes Probe Syntax? Experiments with Jabberwocky Probing",
    "abstract": "Analysing whether neural language models encode linguistic information has\nbecome popular in NLP. One method of doing so, which is frequently cited to\nsupport the claim that models like BERT encode syntax, is called probing;\nprobes are small supervised models trained to extract linguistic information\nfrom another model's output. If a probe is able to predict a particular\nstructure, it is argued that the model whose output it is trained on must have\nimplicitly learnt to encode it. However, drawing a generalisation about a\nmodel's linguistic knowledge about a specific phenomena based on what a probe\nis able to learn may be problematic: in this work, we show that semantic cues\nin training data means that syntactic probes do not properly isolate syntax. We\ngenerate a new corpus of semantically nonsensical but syntactically well-formed\nJabberwocky sentences, which we use to evaluate two probes trained on normal\ndata. We train the probes on several popular language models (BERT, GPT, and\nRoBERTa), and find that in all settings they perform worse when evaluated on\nthese data, for one probe by an average of 15.4 UUAS points absolute. Although\nin most cases they still outperform the baselines, their lead is reduced\nsubstantially, e.g. by 53% in the case of BERT for one probe. This begs the\nquestion: what empirical scores constitute knowing syntax?",
    "descriptor": "",
    "authors": [
      "Rowan Hall Maudslay",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02559"
  },
  {
    "id": "arXiv:2106.02561",
    "title": "Great Service! Fine-grained Parsing of Implicit Arguments",
    "abstract": "Broad-coverage meaning representations in NLP mostly focus on explicitly\nexpressed content. More importantly, the scarcity of datasets annotating\ndiverse implicit roles limits empirical studies into their linguistic nuances.\nFor example, in the web review \"Great service!\", the provider and consumer are\nimplicit arguments of different types. We examine an annotated corpus of\nfine-grained implicit arguments (Cui and Hershcovich, 2020) by carefully\nre-annotating it, resolving several inconsistencies. Subsequently, we present\nthe first transition-based neural parser that can handle implicit arguments\ndynamically, and experiment with two different transition systems on the\nimproved dataset. We find that certain types of implicit arguments are more\ndifficult to parse than others and that the simpler system is more accurate in\nrecovering implicit arguments, despite having a lower overall parsing score,\nattesting current reasoning limitations of NLP models. This work will\nfacilitate a better understanding of implicit and underspecified language, by\nincorporating it holistically into meaning representations.",
    "descriptor": "\nComments: IWPT 2021\n",
    "authors": [
      "Ruixiang Cui",
      "Daniel Hershcovich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02561"
  },
  {
    "id": "arXiv:2106.02562",
    "title": "Recurrent Neural Networks with Mixed Hierarchical Structures for Natural  Language Processing",
    "abstract": "Hierarchical structures exist in both linguistics and Natural Language\nProcessing (NLP) tasks. How to design RNNs to learn hierarchical\nrepresentations of natural languages remains a long-standing challenge. In this\npaper, we define two different types of boundaries referred to as static and\ndynamic boundaries, respectively, and then use them to construct a multi-layer\nhierarchical structure for document classification tasks. In particular, we\nfocus on a three-layer hierarchical structure with static word- and sentence-\nlayers and a dynamic phrase-layer. LSTM cells and two boundary detectors are\nused to implement the proposed structure, and the resulting network is called\nthe {\\em Recurrent Neural Network with Mixed Hierarchical Structures}\n(MHS-RNN). We further add three layers of attention mechanisms to the MHS-RNN\nmodel. Incorporating attention mechanisms allows our model to use more\nimportant content to construct document representation and enhance its\nperformance on document classification tasks. Experiments on five different\ndatasets show that the proposed architecture outperforms previous methods on\nall the five tasks.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Zhaoxin Luo",
      "Michael Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02562"
  },
  {
    "id": "arXiv:2106.02566",
    "title": "Improve the Interpretability of Attention: A Fast, Accurate, and  Interpretable High-Resolution Attention Model",
    "abstract": "The prevalence of employing attention mechanisms has brought along concerns\non the interpretability of attention distributions. Although it provides\ninsights about how a model is operating, utilizing attention as the explanation\nof model predictions is still highly dubious. The community is still seeking\nmore interpretable strategies for better identifying local active regions that\ncontribute the most to the final decision. To improve the interpretability of\nexisting attention models, we propose a novel Bilinear Representative\nNon-Parametric Attention (BR-NPA) strategy that captures the task-relevant\nhuman-interpretable information. The target model is first distilled to have\nhigher-resolution intermediate feature maps. From which, representative\nfeatures are then grouped based on local pairwise feature similarity, to\nproduce finer-grained, more precise attention maps highlighting task-relevant\nparts of the input. The obtained attention maps are ranked according to the\n`active level' of the compound feature, which provides information regarding\nthe important level of the highlighted regions. The proposed model can be\neasily adapted in a wide variety of modern deep models, where classification is\ninvolved. It is also more accurate, faster, and with a smaller memory footprint\nthan usual neural attention modules. Extensive experiments showcase more\ncomprehensive visual explanations compared to the state-of-the-art\nvisualization model across multiple tasks including few-shot classification,\nperson re-identification, fine-grained image classification. The proposed\nvisualization model sheds imperative light on how neural networks `pay their\nattention' differently in different tasks.",
    "descriptor": "",
    "authors": [
      "Tristan Gomez",
      "Suiyi Ling",
      "Thomas Fr\u00e9our",
      "Harold Mouch\u00e8re"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02566"
  },
  {
    "id": "arXiv:2106.02567",
    "title": "AI Driven Road Maintenance Inspection",
    "abstract": "Road infrastructure maintenance inspection is typically a labour-intensive\nand critical task to ensure the safety of all the road users. In this work, we\npropose a detailed methodology to use state-of-the-art techniques in artificial\nintelligence and computer vision to automate a sizeable portion of the\nmaintenance inspection subtasks and reduce the labour costs. The proposed\nmethodology uses state-of-the-art computer vision techniques such as object\ndetection and semantic segmentation to automate inspections on primary road\nstructures such as the road surface, markings, barriers (guardrails) and\ntraffic signs. The models are mostly trained on commercially viable datasets\nand augmented with proprietary data. We demonstrate that our AI models can not\nonly automate and scale maintenance inspections on primary road structures but\nalso result in higher recall compared to traditional manual inspections.",
    "descriptor": "\nComments: accepted at 27th ITS World Congress, 2021\n",
    "authors": [
      "Ratnajit Mukherjee",
      "Haris Iqbal",
      "Shabbir Marzban",
      "Ahmed Badar",
      "Terence Brouns",
      "Shruthi Gowda",
      "Elahe Arani",
      "Bahram Zonooz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02567"
  },
  {
    "id": "arXiv:2106.02568",
    "title": "Training Energy-Efficient Deep Spiking Neural Networks with  Time-to-First-Spike Coding",
    "abstract": "The tremendous energy consumption of deep neural networks (DNNs) has become a\nserious problem in deep learning. Spiking neural networks (SNNs), which mimic\nthe operations in the human brain, have been studied as prominent\nenergy-efficient neural networks. Due to their event-driven and\nspatiotemporally sparse operations, SNNs show possibilities for\nenergy-efficient processing. To unlock their potential, deep SNNs have adopted\ntemporal coding such as time-to-first-spike (TTFS)coding, which represents the\ninformation between neurons by the first spike time. With TTFS coding, each\nneuron generates one spike at most, which leads to a significant improvement in\nenergy efficiency. Several studies have successfully introduced TTFS coding in\ndeep SNNs, but they showed restricted efficiency improvement owing to the lack\nof consideration for efficiency during training. To address the aforementioned\nissue, this paper presents training methods for energy-efficient deep SNNs with\nTTFS coding. We introduce a surrogate DNN model to train the deep SNN in a\nfeasible time and analyze the effect of the temporal kernel on training\nperformance and efficiency. Based on the investigation, we propose\nstochastically relaxed activation and initial value-based regularization for\nthe temporal kernel parameters. In addition, to reduce the number of spikes\neven further, we present temporal kernel-aware batch normalization. With the\nproposed methods, we could achieve comparable training results with\nsignificantly reduced spikes, which could lead to energy-efficient deep SNNs.",
    "descriptor": "",
    "authors": [
      "Seongsik Park",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.02568"
  },
  {
    "id": "arXiv:2106.02569",
    "title": "Neural semi-Markov CRF for Monolingual Word Alignment",
    "abstract": "Monolingual word alignment is important for studying fine-grained editing\noperations (i.e., deletion, addition, and substitution) in text-to-text\ngeneration tasks, such as paraphrase generation, text simplification,\nneutralizing biased language, etc. In this paper, we present a novel neural\nsemi-Markov CRF alignment model, which unifies word and phrase alignments\nthrough variable-length spans. We also create a new benchmark with human\nannotations that cover four different text genres to evaluate monolingual word\nalignment models in more realistic settings. Experimental results show that our\nproposed model outperforms all previous approaches for monolingual word\nalignment as well as a competitive QA-based baseline, which was previously only\napplied to bilingual data. Our model demonstrates good generalizability to\nthree out-of-domain datasets and shows great utility in two downstream\napplications: automatic text simplification and sentence pair classification\ntasks.",
    "descriptor": "\nComments: Accepted to ACL 2021\n",
    "authors": [
      "Wuwei Lan",
      "Chao Jiang",
      "Wei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02569"
  },
  {
    "id": "arXiv:2106.02571",
    "title": "The Inclusion Problem for Forest Languages under Substitutions",
    "abstract": "We consider algorithms and lower bounds for various problems over forest\nlanguages; as input models we allow forest algebras, deterministic forest\nautomata and nondeterministic forest automata. For the equivalence problem, we\ngive an almost-linear-time algorithm for both forest algebras and deterministic\nforest automata; this is complemented by a polynomial time hardness result. The\nemptiness problem is complete for polynomial time over each of the three\nmodels. Additionally, we consider the emptiness of intersection problem for\nforest algebras and deterministic forest automata; this problem turns out to be\ncomplete for exponential time. It is well-known that the corresponding problems\nfor word languages are complete for nondeterministic logarithmic space and for\npolynomial space, respectively.\nEquipped with this toolbox of algorithms and lower bounds, we consider\nvarious inclusion problems for regular forest languages under substitutions.\nThe substitutions in this paper replace leaf variables by forest languages.\nDepending on the direction of the inclusion, the problem for a given\nsubstitution is either complete for polynomial time or for exponential time; in\nparticular, the equivalence problem under substitutions is complete for\nexponential time and, hence, more difficult than the equivalence problem for\nforest languages without substitutions. If we ask whether there exists a\nsubstitution such that a given inclusion holds, then this problem is either\ncomplete for NP or exponential time, depending on whether we consider inclusion\nor equivalence; moreover, the problem is undecidable if the substitution is\napplied on both sides.",
    "descriptor": "",
    "authors": [
      "Marcial Gai\u00dfert",
      "Manfred Kufleitner"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.02571"
  },
  {
    "id": "arXiv:2106.02573",
    "title": "Rewriting Theory for the Life Sciences: A Unifying Theory of CTMC  Semantics (Long version)",
    "abstract": "The Kappa biochemistry and the M{\\O}D organic chemistry frameworks are\namongst the most intensely developed applications of rewriting-based methods in\nthe life sciences to date. A typical feature of these types of rewriting\ntheories is the necessity to implement certain structural constraints on the\nobjects to be rewritten (a protein is empirically found to have a certain\nsignature of sites, a carbon atom can form at most four bonds, ...). In this\npaper, we contribute a number of original developments that permit to implement\na universal theory of continuous-time Markov chains (CTMCs) for stochastic\nrewriting systems. Our core mathematical concepts are a novel rule algebra\nconstruction for the relevant setting of rewriting rules with conditions, both\nin Double- and in Sesqui-Pushout semantics, augmented by a suitable stochastic\nmechanics formalism extension that permits to derive dynamical evolution\nequations for pattern-counting statistics. A second main contribution of our\npaper is a novel framework of restricted rewriting theories, which comprises a\nrule-algebra calculus under the restriction to so-called constraint-preserving\ncompletions of application conditions (for rules considered to act only upon\nobjects of the underlying category satisfying a globally fixed set of\nstructural constraints). This novel framework in turn renders a faithful\nencoding of bio- and organo-chemical rewriting in the sense of Kappa and M{\\O}D\npossible, which allows us to derive a rewriting-based formulation of reaction\nsystems including a full-fledged CTMC semantics as instances of our universal\nCTMC framework. While offering an interesting new perspective and conceptual\nsimplification of this semantics in the setting of Kappa, both the formal\nencoding and the CTMC semantics of organo-chemical reaction systems as\nmotivated by the M{\\O}D framework are the first such results of their kind.",
    "descriptor": "\nComments: 62 pages; long version of arXiv:2003.09395\n",
    "authors": [
      "Nicolas Behr",
      "Jean Krivine",
      "Jakob L. Andersen",
      "Daniel Merkle"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.02573"
  },
  {
    "id": "arXiv:2106.02575",
    "title": "Optimal Rates of (Locally) Differentially Private Heavy-tailed  Multi-Armed Bandits",
    "abstract": "In this paper we study the problem of stochastic multi-armed bandits (MAB) in\nthe (local) differential privacy (DP/LDP) model. Unlike the previous results\nwhich need to assume bounded reward distributions, here we mainly focus on the\ncase the reward distribution of each arm only has $(1+v)$-th moment with some\n$v\\in (0, 1]$. In the first part, we study the problem in the central\n$\\epsilon$-DP model. We first provide a near-optimal result by developing a\nprivate and robust Upper Confidence Bound (UCB) algorithm. Then, we improve the\nresult via a private and robust version of the Successive Elimination (SE)\nalgorithm. Finally, we show that the instance-dependent regret bound of our\nimproved algorithm is optimal by showing its lower bound. In the second part of\nthe paper, we study the problem in the $\\epsilon$-LDP model. We propose an\nalgorithm which could be seen as locally private and robust version of the SE\nalgorithm, and show it could achieve (near) optimal rates for both\ninstance-dependent and instance-independent regrets. All of the above results\ncan also reveal the differences between the problem of private MAB with bounded\nrewards and heavy-tailed rewards. To achieve these (near) optimal rates, we\ndevelop several new hard instances and private robust estimators as byproducts,\nwhich might could be used to other related problems. Finally, experimental\nresults also support our theoretical analysis and show the effectiveness of our\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Youming Tao",
      "Yulian Wu",
      "Peng Zhao",
      "Di Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02575"
  },
  {
    "id": "arXiv:2106.02578",
    "title": "Alexa, Google, Siri: What are Your Pronouns? Gender and Anthropomorphism  in the Design and Perception of Conversational Assistants",
    "abstract": "Technology companies have produced varied responses to concerns about the\neffects of the design of their conversational AI systems. Some have claimed\nthat their voice assistants are in fact not gendered or human-like -- despite\ndesign features suggesting the contrary. We compare these claims to user\nperceptions by analysing the pronouns they use when referring to AI assistants.\nWe also examine systems' responses and the extent to which they generate output\nwhich is gendered and anthropomorphic. We find that, while some companies\nappear to be addressing the ethical concerns raised, in some cases, their\nclaims do not seem to hold true. In particular, our results show that system\noutputs are ambiguous as to the humanness of the systems, and that users tend\nto personify and gender them as a result.",
    "descriptor": "\nComments: To be presented at the 3rd Workshop on Gender Bias in Natural Language Processing (GeBNLP 2021)\n",
    "authors": [
      "Gavin Abercrombie",
      "Amanda Cercas Curry",
      "Mugdha Pandya",
      "Verena Rieser"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02578"
  },
  {
    "id": "arXiv:2106.02581",
    "title": "BERT based sentiment analysis: A software engineering perspective",
    "abstract": "Sentiment analysis can provide a suitable lead for the tools used in software\nengineering along with the API recommendation systems and relevant libraries to\nbe used. In this context, the existing tools like SentiCR, SentiStrength-SE,\netc. exhibited low f1-scores that completely defeats the purpose of deployment\nof such strategies, thereby there is enough scope of performance improvement.\nRecent advancements show that transformer based pre-trained models (e.g., BERT,\nRoBERTa, ALBERT, etc.) have displayed better results in the text classification\ntask. Following this context, the present research explores different\nBERT-based models to analyze the sentences in GitHub comments, Jira comments,\nand Stack Overflow posts. The paper presents three different strategies to\nanalyse BERT based model for sentiment analysis, where in the first strategy\nthe BERT based pre-trained models are fine-tuned; in the second strategy an\nensemble model is developed from BERT variants; and in the third strategy a\ncompressed model (Distil BERT) is used. The experimental results show that the\nBERT based ensemble approach and the compressed BERT model attain improvements\nby 6-12% over prevailing tools for the F1 measure on all three datasets.",
    "descriptor": "",
    "authors": [
      "Himanshu Batra",
      "Narinder Singh Punn",
      "Sanjay Kumar Sonbhadra",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02581"
  },
  {
    "id": "arXiv:2106.02584",
    "title": "Self-Attention Between Datapoints: Going Beyond Individual Input-Output  Pairs in Deep Learning",
    "abstract": "We challenge a common assumption underlying most supervised deep learning:\nthat a model makes a prediction depending only on its parameters and the\nfeatures of a single input. To this end, we introduce a general-purpose deep\nlearning architecture that takes as input the entire dataset instead of\nprocessing one datapoint at a time. Our approach uses self-attention to reason\nabout relationships between datapoints explicitly, which can be seen as\nrealizing non-parametric models using parametric attention mechanisms. However,\nunlike conventional non-parametric models, we let the model learn end-to-end\nfrom the data how to make use of other datapoints for prediction. Empirically,\nour models solve cross-datapoint lookup and complex reasoning tasks unsolvable\nby traditional deep learning models. We show highly competitive results on\ntabular data, early results on CIFAR-10, and give insight into how the model\nmakes use of the interactions between points.",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Jannik Kossen",
      "Neil Band",
      "Clare Lyle",
      "Aidan N. Gomez",
      "Tom Rainforth",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02584"
  },
  {
    "id": "arXiv:2106.02585",
    "title": "A Procedural World Generation Framework for Systematic Evaluation of  Continual Learning",
    "abstract": "Several families of continual learning techniques have been proposed to\nalleviate catastrophic interference in deep neural network training on\nnon-stationary data. However, a comprehensive comparison and analysis of\nlimitations remains largely open due to the inaccessibility to suitable\ndatasets. Empirical examination not only varies immensely between individual\nworks, it further currently relies on contrived composition of benchmarks\nthrough subdivision and concatenation of various prevalent static vision\ndatasets. In this work, our goal is to bridge this gap by introducing a\ncomputer graphics simulation framework that repeatedly renders only upcoming\nurban scene fragments in an endless real-time procedural world generation\nprocess. At its core lies a modular parametric generative model with adaptable\ngenerative factors. The latter can be used to flexibly compose data streams,\nwhich significantly facilitates a detailed analysis and allows for effortless\ninvestigation of various continual learning schemes.",
    "descriptor": "",
    "authors": [
      "Timm Hess",
      "Martin Mundt",
      "Iuliia Pliushch",
      "Visvanathan Ramesh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02585"
  },
  {
    "id": "arXiv:2106.02586",
    "title": "Spectral Non-integer Derivative Representations and the Exact Spectral  Derivative Discretization Finite Difference Method for the Fokker-Planck  Equation",
    "abstract": "Universal difference quotient representations are introduced for the exact\nself-sameness principles (SSP) as rules for rates of change introduced in\n[Clemence-Mkhope, D.P (2021, Preprint). The Exact Spectral Derivative\nDiscretization Finite Difference (ESDDFD) Method for Wave Models. arXiv].\nProperties are presented for the fundamental rule, a generalized derivative\nrepresentation which is shown to yield some known non-integer derivatives as\nlimit cases of such natural derivative measures; this is shown for some local\nderivatives of conformable, fractional, or fractal type and non-local\nderivatives of Caputo and Riemann-Liouville type. The SSP-inspired exact\nspectral derivative discretization finite difference method is presented for\nthe Fokker-Planck non-fractional and time-fractional equations; the resulting\ndiscrete models recover exactly some known behaviors predicted for the\nprocesses modeled, such as the Gibbs-Boltzmann distribution and the\nEinstein-Stokes-Smoluchowski relation; new ones are predicted.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "D.P. Clemence-Mkhope"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.02586"
  },
  {
    "id": "arXiv:2106.02588",
    "title": "Stochastic gradient descent with noise of machine learning type. Part  II: Continuous time analysis",
    "abstract": "The representation of functions by artificial neural networks depends on a\nlarge number of parameters in a non-linear fashion. Suitable parameters of\nthese are found by minimizing a 'loss functional', typically by stochastic\ngradient descent (SGD) or an advanced SGD-based algorithm.\nIn a continuous time model for SGD with noise that follows the 'machine\nlearning scaling', we show that in a certain noise regime, the optimization\nalgorithm prefers 'flat' minima of the objective function in a sense which is\ndifferent from the flat minimum selection of continuous time SGD with\nhomogeneous noise.",
    "descriptor": "",
    "authors": [
      "Stephan Wojtowytsch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02588"
  },
  {
    "id": "arXiv:2106.02594",
    "title": "Self-Supervised Learning of Domain Invariant Features for Depth  Estimation",
    "abstract": "We tackle the problem of unsupervised synthetic-to-realistic domain\nadaptation for single image depth estimation. An essential building block of\nsingle image depth estimation is an encoder-decoder task network that takes RGB\nimages as input and produces depth maps as output. In this paper, we propose a\nnovel training strategy to force the task network to learn domain invariant\nrepresentations in a self-supervised manner. Specifically, we extend\nself-supervised learning from traditional representation learning, which works\non images from a single domain, to domain invariant representation learning,\nwhich works on images from two different domains by utilizing an image-to-image\ntranslation network. Firstly, we use our bidirectional image-to-image\ntranslation network to transfer domain-specific styles between synthetic and\nreal domains. This style transfer operation allows us to obtain similar images\nfrom the different domains. Secondly, we jointly train our task network and\nSiamese network with the same images from the different domains to obtain\ndomain invariance for the task network. Finally, we fine-tune the task network\nusing labeled synthetic and unlabeled real-world data. Our training strategy\nyields improved generalization capability in the real-world domain. We carry\nout an extensive evaluation on two popular datasets for depth estimation, KITTI\nand Make3D. The results demonstrate that our proposed method outperforms the\nstate-of-the-art both qualitatively and quantitatively. The source code and\nmodel weights will be made available.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Hiroyasu Akada",
      "Shariq Farooq Bhat",
      "Ibraheem Alhashim",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02594"
  },
  {
    "id": "arXiv:2106.02596",
    "title": "Understanding and Countering Stereotypes: A Computational Approach to  the Stereotype Content Model",
    "abstract": "Stereotypical language expresses widely-held beliefs about different social\ncategories. Many stereotypes are overtly negative, while others may appear\npositive on the surface, but still lead to negative consequences. In this work,\nwe present a computational approach to interpreting stereotypes in text through\nthe Stereotype Content Model (SCM), a comprehensive causal theory from social\npsychology. The SCM proposes that stereotypes can be understood along two\nprimary dimensions: warmth and competence. We present a method for defining\nwarmth and competence axes in semantic embedding space, and show that the four\nquadrants defined by this subspace accurately represent the warmth and\ncompetence concepts, according to annotated lexicons. We then apply our\ncomputational SCM model to textual stereotype data and show that it compares\nfavourably with survey-based studies in the psychological literature.\nFurthermore, we explore various strategies to counter stereotypical beliefs\nwith anti-stereotypes. It is known that countering stereotypes with\nanti-stereotypical examples is one of the most effective ways to reduce biased\nthinking, yet the problem of generating anti-stereotypes has not been\npreviously studied. Thus, a better understanding of how to generate realistic\nand effective anti-stereotypes can contribute to addressing pressing societal\nconcerns of stereotyping, prejudice, and discrimination.",
    "descriptor": "\nComments: In Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)\n",
    "authors": [
      "Kathleen C. Fraser",
      "Isar Nejadgholi",
      "Svetlana Kiritchenko"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02596"
  },
  {
    "id": "arXiv:2106.02597",
    "title": "Model-agnostic and Scalable Counterfactual Explanations via  Reinforcement Learning",
    "abstract": "Counterfactual instances are a powerful tool to obtain valuable insights into\nautomated decision processes, describing the necessary minimal changes in the\ninput space to alter the prediction towards a desired target. Most previous\napproaches require a separate, computationally expensive optimization procedure\nper instance, making them impractical for both large amounts of data and\nhigh-dimensional data. Moreover, these methods are often restricted to certain\nsubclasses of machine learning models (e.g. differentiable or tree-based\nmodels). In this work, we propose a deep reinforcement learning approach that\ntransforms the optimization procedure into an end-to-end learnable process,\nallowing us to generate batches of counterfactual instances in a single forward\npass. Our experiments on real-world data show that our method i) is\nmodel-agnostic (does not assume differentiability), relying only on feedback\nfrom model predictions; ii) allows for generating target-conditional\ncounterfactual instances; iii) allows for flexible feature range constraints\nfor numerical and categorical attributes, including the immutability of\nprotected features (e.g. gender, race); iv) is easily extended to other data\nmodalities such as images.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Robert-Florian Samoilescu",
      "Arnaud Van Looveren",
      "Janis Klaise"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02597"
  },
  {
    "id": "arXiv:2106.02598",
    "title": "Pose and Semantic Map Based Probabilistic Forecast of Vulnerable Road  Users' Trajectories",
    "abstract": "In this article, an approach for probabilistic trajectory forecasting of\nvulnerable road users (VRUs) is presented, which considers past movements and\nthe surrounding scene. Past movements are represented by 3D poses reflecting\nthe posture and movements of individual body parts. The surrounding scene is\nmodeled in the form of semantic maps showing, e.g., the course of streets,\nsidewalks, and the occurrence of obstacles. The forecasts are generated in\ngrids discretizing the space and in the form of arbitrary discrete probability\ndistributions. The distributions are evaluated in terms of their reliability,\nsharpness, and positional accuracy. We compare our method with an approach that\nprovides forecasts in the form of Gaussian distributions and discuss the\nrespective advantages and disadvantages. Thereby, we investigate the impact of\nusing poses and semantic maps. With a technique called spatial label smoothing,\nour approach achieves reliable forecasts. Overall, the poses have a positive\nimpact on the forecasts. The semantic maps offer the opportunity to adapt the\nprobability distributions to the individual situation, although at the\nconsidered forecasted time horizon of 2.52 s they play a minor role compared to\nthe past movements of the VRU. Our method is evaluated on a dataset recorded in\ninner-city traffic using a research vehicle. The dataset is made publicly\navailable.",
    "descriptor": "",
    "authors": [
      "Viktor Kress",
      "Fabian Jeske",
      "Stefan Zernetsch",
      "Konrad Doll",
      "Bernhard Sick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02598"
  },
  {
    "id": "arXiv:2106.02600",
    "title": "Inferring Granger Causality from Irregularly Sampled Time Series",
    "abstract": "Continuous, automated surveillance systems that incorporate machine learning\nmodels are becoming increasingly more common in healthcare environments. These\nmodels can capture temporally dependent changes across multiple patient\nvariables and can enhance a clinician's situational awareness by providing an\nearly warning alarm of an impending adverse event such as sepsis. However, most\ncommonly used methods, e.g., XGBoost, fail to provide an interpretable\nmechanism for understanding why a model produced a sepsis alarm at a given\ntime. The black-box nature of many models is a severe limitation as it prevents\nclinicians from independently corroborating those physiologic features that\nhave contributed to the sepsis alarm. To overcome this limitation, we propose a\ngeneralized linear model (GLM) approach to fit a Granger causal graph based on\nthe physiology of several major sepsis-associated derangements (SADs). We adopt\na recently developed stochastic monotone variational inequality-based estimator\ncoupled with forwarding feature selection to learn the graph structure from\nboth continuous and discrete-valued as well as regularly and irregularly\nsampled time series. Most importantly, we develop a non-asymptotic upper bound\non the estimation error for any monotone link function in the GLM. We conduct\nreal-data experiments and demonstrate that our proposed method can achieve\ncomparable performance to popular and powerful prediction methods such as\nXGBoost while simultaneously maintaining a high level of interpretability.",
    "descriptor": "\nComments: 33 pages, 10 figures, 4 tables\n",
    "authors": [
      "Song Wei",
      "Yao Xie",
      "Christopher S. Josef",
      "Rishikesan Kamaleswaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.02600"
  },
  {
    "id": "arXiv:2106.02602",
    "title": "Principled change point detection via representation learning",
    "abstract": "Change points are abrupt alterations in the distribution of sequential data.\nA change-point detection (CPD) model aims at quick detection of such changes.\nClassic approaches perform poorly for semi-structured sequential data because\nof the absence of adequate data representation learning. To deal with it, we\nintroduce a principled differentiable loss function that considers the\nspecificity of the CPD task. The theoretical results suggest that this function\napproximates well classic rigorous solutions. For such loss function, we\npropose an end-to-end method for the training of deep representation learning\nCPD models. Our experiments provide evidence that the proposed approach\nimproves baseline results of change point detection for various data types,\nincluding real-world videos and image sequences, and improve representations\nfor them.",
    "descriptor": "",
    "authors": [
      "Evgenia Romanenkova",
      "Alexey Zaytsev",
      "Ramil Zainulin",
      "Matvey Morozov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02602"
  },
  {
    "id": "arXiv:2106.02604",
    "title": "Does Persuasive Technology Make Smartphones More Addictive?",
    "abstract": "With the development of computer hardware, computers with persuasion have\nbecome more powerful and influential than ever. The latest trends show that\nPersuasive Technology integrates with cutting-edge technologies, such as\nNatural Language Processing, Big Data, and Machine Learning algorithms. As\npersuasion is becoming increasingly intelligent and subtle, it is urgent to\nreflect on the dark sides of Persuasive Technology. The study aims to\ninvestigate one of Persuasive Technology's accusations, making smartphones more\naddictive to its users. The study uses questionnaires and in-depth interviews\nto examine the impact of persuasive technologies on young smartphone users. The\nparticipants of the study are 18 to 26 years old Chinese university students.\nQuestionnaires were distributed through a university forum, student group\nchats, and Tencent Survey Service. Ten interviewees were sampled randomly from\nthe survey results. Eight interviewees shared their smartphone screen time for\nthree consecutive weeks after the interview. Among the 183 participants, 84.70%\n(n=155) spend over (or equal to) four hours per day on their smartphone, 44.26%\n(n=81) indicate that smartphones negatively affect their studies or\nprofessional life. Ten interviewees evaluated that they could reduce screen\ntime by 37% if they could avoid all persuasive functions. Five out of eight\ninterviewees reduced their screen time by 16.72% three weeks after the\ninterviews by voluntarily turning off some persuasive functions on their\nsmartphones. This study provides empirical evidence to argue that persuasive\ntechnologies increase users' screen time and contribute to the addictive\nbehaviours of young smartphone users. To sum up, the ethical problems that\nHuman-computer interaction (HCI) designers face and users' neglected rights of\nacknowledgement were discussed.",
    "descriptor": "",
    "authors": [
      "Xiaowei Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.02604"
  },
  {
    "id": "arXiv:2106.02605",
    "title": "A Holistic Approach to Interpretability in Financial Lending: Models,  Visualizations, and Summary-Explanations",
    "abstract": "Lending decisions are usually made with proprietary models that provide\nminimally acceptable explanations to users. In a future world without such\nsecrecy, what decision support tools would one want to use for justified\nlending decisions? This question is timely, since the economy has dramatically\nshifted due to a pandemic, and a massive number of new loans will be necessary\nin the short term. We propose a framework for such decisions, including a\nglobally interpretable machine learning model, an interactive visualization of\nit, and several types of summaries and explanations for any given decision. The\nmachine learning model is a two-layer additive risk model, which resembles a\ntwo-layer neural network, but is decomposable into subscales. In this model,\neach node in the first (hidden) layer represents a meaningful subscale model,\nand all of the nonlinearities are transparent. Our online visualization tool\nallows exploration of this model, showing precisely how it came to its\nconclusion. We provide three types of explanations that are simpler than, but\nconsistent with, the global model: case-based reasoning explanations that use\nneighboring past cases, a set of features that were the most important for the\nmodel's prediction, and summary-explanations that provide a customized sparse\nexplanation for any particular lending decision made by the model. Our\nframework earned the FICO recognition award for the Explainable Machine\nLearning Challenge, which was the first public challenge in the domain of\nexplainable machine learning.",
    "descriptor": "",
    "authors": [
      "Chaofan Chen",
      "Kangcheng Lin",
      "Cynthia Rudin",
      "Yaron Shaposhnik",
      "Sijia Wang",
      "Tong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02605"
  },
  {
    "id": "arXiv:2106.02607",
    "title": "Defending Democracy: Using Deep Learning to Identify and Prevent  Misinformation",
    "abstract": "The rise in online misinformation in recent years threatens democracies by\ndistorting authentic public discourse and causing confusion, fear, and even, in\nextreme cases, violence. There is a need to understand the spread of false\ncontent through online networks for developing interventions that disrupt\nmisinformation before it achieves virality. Using a Deep Bidirectional\nTransformer for Language Understanding (BERT) and propagation graphs, this\nstudy classifies and visualizes the spread of misinformation on a social media\nnetwork using publicly available Twitter data. The results confirm prior\nresearch around user clusters and the virality of false content while improving\nthe precision of deep learning models for misinformation detection. The study\nfurther demonstrates the suitability of BERT for providing a scalable model for\nfalse information detection, which can contribute to the development of more\ntimely and accurate interventions to slow the spread of misinformation in\nonline environments.",
    "descriptor": "",
    "authors": [
      "Anusua Trivedi",
      "Alyssa Suhm",
      "Prathamesh Mahankal",
      "Subhiksha Mukuntharaj",
      "Meghana D. Parab",
      "Malvika Mohan",
      "Meredith Berger",
      "Arathi Sethumadhavan",
      "Ashish Jaiman",
      "Rahul Dodhia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02607"
  },
  {
    "id": "arXiv:2106.02608",
    "title": "Influence Estimation and Maximization via Neural Mean-Field Dynamics",
    "abstract": "We propose a novel learning framework using neural mean-field (NMF) dynamics\nfor inference and estimation problems on heterogeneous diffusion networks. Our\nnew framework leverages the Mori-Zwanzig formalism to obtain an exact evolution\nequation of the individual node infection probabilities, which renders a delay\ndifferential equation with memory integral approximated by learnable time\nconvolution operators. Directly using information diffusion cascade data, our\nframework can simultaneously learn the structure of the diffusion network and\nthe evolution of node infection probabilities. Connections between parameter\nlearning and optimal control are also established, leading to a rigorous and\nimplementable algorithm for training NMF. Moreover, we show that the projected\ngradient descent method can be employed to solve the challenging influence\nmaximization problem, where the gradient is computed extremely fast by\nintegrating NMF forward in time just once in each iteration. Extensive\nempirical studies show that our approach is versatile and robust to variations\nof the underlying diffusion network models, and significantly outperform\nexisting approaches in accuracy and efficiency on both synthetic and real-world\ndata.",
    "descriptor": "\nComments: 26 pages, 6 figures. arXiv admin note: text overlap with arXiv:2006.09449\n",
    "authors": [
      "Shushan He",
      "Hongyuan Zha",
      "Xiaojing Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Social and Information Networks (cs.SI)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.02608"
  },
  {
    "id": "arXiv:2106.02612",
    "title": "Collection and harmonization of system logs and prototypal Analytics  services with the Elastic (ELK) suite at the INFN-CNAF computing centre",
    "abstract": "The distributed Grid infrastructure for High Energy Physics experiments at\nthe Large Hadron Collider (LHC) in Geneva comprises a set of computing centres,\nspread all over the world, as part of the Worldwide LHC Computing Grid (WLCG).\nIn Italy, the Tier-1 functionalities are served by the INFN-CNAF data center,\nwhich provides also computing and storage resources to more than twenty non-LHC\nexperiments. For this reason, a high amount of logs are collected each day from\nvarious sources, which are highly heterogeneous and difficult to harmonize. In\nthis contribution, a working implementation of a system that collects, parses\nand displays the log information from CNAF data sources and the investigation\nof a Machine Learning based predictive maintenance system, is presented.",
    "descriptor": "\nComments: Submitted to proceedings of International Symposium on Grids & Clouds 2019 (ISGC2019)\n",
    "authors": [
      "Tommaso Diotalevi",
      "Antonio Falabella",
      "Barbara Martelli",
      "Diego Michelotto",
      "Lucia Morganti",
      "Daniele Bonacorsi",
      "Luca Giommi",
      "Simone Rossi Tisbeni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.02612"
  },
  {
    "id": "arXiv:2106.02614",
    "title": "Sigma-Delta and Distributed Noise-Shaping Quantization Methods for  Random Fourier Features",
    "abstract": "We propose the use of low bit-depth Sigma-Delta and distributed noise-shaping\nmethods for quantizing the Random Fourier features (RFFs) associated with\nshift-invariant kernels. We prove that our quantized RFFs -- even in the case\nof $1$-bit quantization -- allow a high accuracy approximation of the\nunderlying kernels, and the approximation error decays at least polynomially\nfast as the dimension of the RFFs increases. We also show that the quantized\nRFFs can be further compressed, yielding an excellent trade-off between memory\nuse and accuracy. Namely, the approximation error now decays exponentially as a\nfunction of the bits used. Moreover, we empirically show by testing the\nperformance of our methods on several machine learning tasks that our method\ncompares favorably to other state of the art quantization methods in this\ncontext.",
    "descriptor": "",
    "authors": [
      "Jinjie Zhang",
      "Alexander Cloninger",
      "Rayan Saab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02614"
  },
  {
    "id": "arXiv:2106.02615",
    "title": "Consensus Multiplicative Weights Update: Learning to Learn using  Projector-based Game Signatures",
    "abstract": "Recently, Optimistic Multiplicative Weights Update (OMWU) was proven to be\nthe first constant step-size algorithm in the online no-regret framework to\nenjoy last-iterate convergence to Nash Equilibria in the constrained zero-sum\nbimatrix case, where weights represent the probabilities of playing pure\nstrategies. We introduce the second such algorithm, \\textit{Consensus MWU}, for\nwhich we prove local convergence and show empirically that it enjoys faster and\nmore robust convergence than OMWU. Our algorithm shows the importance of a new\nobject, the \\textit{simplex Hessian}, as well as of the interaction of the game\nwith the (eigen)space of vectors summing to zero, which we believe future\nresearch can build on. As for OMWU, CMWU has convergence guarantees in the\nzero-sum case only, but Cheung and Piliouras (2020) recently showed that OMWU\nand MWU display opposite convergence properties depending on whether the game\nis zero-sum or cooperative. Inspired by this work and the recent literature on\nlearning to optimize for single functions, we extend CMWU to non zero-sum games\nby introducing a new framework for online learning in games, where the update\nrule's gradient and Hessian coefficients along a trajectory are learnt by a\nreinforcement learning policy that is conditioned on the nature of the game:\n\\textit{the game signature}. We construct the latter using a new canonical\ndecomposition of two-player games into eight components corresponding to\ncommutative projection operators, generalizing and unifying recent game\nconcepts studied in the literature. We show empirically that our new learning\npolicy is able to exploit the game signature across a wide range of game types.",
    "descriptor": "",
    "authors": [
      "Nelson Vadori",
      "Rahul Savani",
      "Thomas Spooner",
      "Sumitra Ganesh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02615"
  },
  {
    "id": "arXiv:2106.02617",
    "title": "Be Considerate: Objectives, Side Effects, and Deciding How to Act",
    "abstract": "Recent work in AI safety has highlighted that in sequential decision making,\nobjectives are often underspecified or incomplete. This gives discretion to the\nacting agent to realize the stated objective in ways that may result in\nundesirable outcomes. We contend that to learn to act safely, a reinforcement\nlearning (RL) agent should include contemplation of the impact of its actions\non the wellbeing and agency of others in the environment, including other\nacting agents and reactive processes. We endow RL agents with the ability to\ncontemplate such impact by augmenting their reward based on expectation of\nfuture return by others in the environment, providing different criteria for\ncharacterizing impact. We further endow these agents with the ability to\ndifferentially factor this impact into their decision making, manifesting\nbehavior that ranges from self-centred to self-less, as demonstrated by\nexperiments in gridworld environments.",
    "descriptor": "",
    "authors": [
      "Parand Alizadeh Alamdari",
      "Toryn Q. Klassen",
      "Rodrigo Toro Icarte",
      "Sheila A. McIlraith"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02617"
  },
  {
    "id": "arXiv:2106.02619",
    "title": "Forward Super-Resolution: How Can GANs Learn Hierarchical Generative  Models for Real-World Distributions",
    "abstract": "Generative adversarial networks (GANs) are among the most successful models\nfor learning high-complexity, real-world distributions. However, in theory, due\nto the highly non-convex, non-concave landscape of the minmax training\nobjective, GAN remains one of the least understood deep learning models. In\nthis work, we formally study how GANs can efficiently learn certain\nhierarchically generated distributions that are close to the distribution of\nimages in practice. We prove that when a distribution has a structure that we\nrefer to as Forward Super-Resolution, then simply training generative\nadversarial networks using gradient descent ascent (GDA) can indeed learn this\ndistribution efficiently, both in terms of sample and time complexities. We\nalso provide concrete empirical evidence that not only our assumption \"forward\nsuper-resolution\" is very natural in practice, but also the underlying learning\nmechanisms that we study in this paper (to allow us efficiently train GAN via\nGDA in theory) simulates the actual learning process of GANs in practice on\nreal-world problems.",
    "descriptor": "",
    "authors": [
      "Zeyuan Allen-Zhu",
      "Yuanzhi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02619"
  },
  {
    "id": "arXiv:2106.02623",
    "title": "The Closer You Look, The More You Learn: A Grey-box Approach to Protocol  State Machine Learning",
    "abstract": "In this paper, we propose a new approach to infer state machine models from\nprotocol implementations. Our method, STATEINSPECTOR, learns protocol states by\nusing novel program analyses to combine observations of run-time memory and\nI/O. It requires no access to source code and only lightweight execution\nmonitoring of the implementation under test. We demonstrate and evaluate\nSTATEINSPECTOR's effectiveness on numerous TLS and WPA/2 implementations. In\nthe process, we show STATEINSPECTOR enables deeper state discovery, increased\nlearning efficiency, and more insightful post-mortem analyses than existing\napproaches. Further to improved learning, our method led us to discover several\nconcerning deviations from the standards and a high impact vulnerability in a\nprominent Wi-Fi implementation.",
    "descriptor": "",
    "authors": [
      "Chris McMahon Stone",
      "Sam L. Thomas",
      "Mathy Vanhoef",
      "James Henderson",
      "Nicolas Balluiet",
      "Tom Chothia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.02623"
  },
  {
    "id": "arXiv:2106.02624",
    "title": "ViViT: Curvature access through the generalized Gauss-Newton's low-rank  structure",
    "abstract": "Curvature in form of the Hessian or its generalized Gauss-Newton (GGN)\napproximation is valuable for algorithms that rely on a local model for the\nloss to train, compress, or explain deep networks. Existing methods based on\nimplicit multiplication via automatic differentiation or Kronecker-factored\nblock diagonal approximations do not consider noise in the mini-batch. We\npresent ViViT, a curvature model that leverages the GGN's low-rank structure\nwithout further approximations. It allows for efficient computation of\neigenvalues, eigenvectors, as well as per-sample first- and second-order\ndirectional derivatives. The representation is computed in parallel with\ngradients in one backward pass and offers a fine-grained cost-accuracy\ntrade-off, which allows it to scale. As examples for ViViT's usefulness, we\ninvestigate the directional gradients and curvatures during training, and how\nnoise information can be used to improve the stability of second-order methods.",
    "descriptor": "\nComments: Main text: 11 pages, 3 figures; Supplements: 14 pages, 10 figures, 2 tables\n",
    "authors": [
      "Felix Dangel",
      "Lukas Tatzel",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02624"
  },
  {
    "id": "arXiv:2106.02628",
    "title": "Constraint-based Relational Verification",
    "abstract": "In recent years they have been numerous works that aim to automate relational\nverification. Meanwhile, although Constrained Horn Clauses (CHCs) empower a\nwide range of verification techniques and tools, they lack the ability to\nexpress hyperproperties beyond $k$-safety such as generalized non-interference\nand co-termination.\nThis paper describes a novel and fully automated constraint-based approach to\nrelational verification. We first introduce a new class of predicate Constraint\nSatisfaction Problems called pfwCSP where constraints are represented as\nclauses modulo first-order theories over predicate variables of three kinds:\nordinary, well-founded, or functional. This generalization over CHCs permits\narbitrary (i.e., possibly non-Horn) clauses, well-foundedness constraints,\nfunctionality constraints, and is capable of expressing these relational\nverification problems. Our approach enables us to express and automatically\nverify problem instances that require non-trivial (i.e., non-sequential and\nnon-lock-step) self-composition by automatically inferring appropriate\nschedulers (or alignment) that dictate when and which program copies move. To\nsolve problems in this new language, we present a constraint solving method for\npfwCSP based on stratified CounterExample-Guided Inductive Synthesis (CEGIS) of\nordinary, well-founded, and functional predicates.\nWe have implemented the proposed framework and obtained promising results on\ndiverse relational verification problems that are beyond the scope of the\nprevious verification frameworks.",
    "descriptor": "",
    "authors": [
      "Hiroshi Unno",
      "Tachio Terauchi",
      "Eric Koskinen"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.02628"
  },
  {
    "id": "arXiv:2106.02634",
    "title": "Light Field Networks: Neural Scene Representations with  Single-Evaluation Rendering",
    "abstract": "Inferring representations of 3D scenes from 2D observations is a fundamental\nproblem of computer graphics, computer vision, and artificial intelligence.\nEmerging 3D-structured neural scene representations are a promising approach to\n3D scene understanding. In this work, we propose a novel neural scene\nrepresentation, Light Field Networks or LFNs, which represent both geometry and\nappearance of the underlying 3D scene in a 360-degree, four-dimensional light\nfield parameterized via a neural implicit representation. Rendering a ray from\nan LFN requires only a *single* network evaluation, as opposed to hundreds of\nevaluations per ray for ray-marching or volumetric based renderers in\n3D-structured neural scene representations. In the setting of simple scenes, we\nleverage meta-learning to learn a prior over LFNs that enables multi-view\nconsistent light field reconstruction from as little as a single image\nobservation. This results in dramatic reductions in time and memory complexity,\nand enables real-time rendering. The cost of storing a 360-degree light field\nvia an LFN is two orders of magnitude lower than conventional methods such as\nthe Lumigraph. Utilizing the analytical differentiability of neural implicit\nrepresentations and a novel parameterization of light space, we further\ndemonstrate the extraction of sparse depth maps from LFNs.",
    "descriptor": "\nComments: First two authors contributed equally. Project website: this https URL\n",
    "authors": [
      "Vincent Sitzmann",
      "Semon Rezchikov",
      "William T. Freeman",
      "Joshua B. Tenenbaum",
      "Fredo Durand"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.02634"
  },
  {
    "id": "arXiv:2106.02636",
    "title": "MERLOT: Multimodal Neural Script Knowledge Models",
    "abstract": "As humans, we understand events in the visual world contextually, performing\nmultimodal reasoning across time to make inferences about the past, present,\nand future. We introduce MERLOT, a model that learns multimodal script\nknowledge by watching millions of YouTube videos with transcribed speech -- in\nan entirely label-free, self-supervised manner. By pretraining with a mix of\nboth frame-level (spatial) and video-level (temporal) objectives, our model not\nonly learns to match images to temporally corresponding words, but also to\ncontextualize what is happening globally over time. As a result, MERLOT\nexhibits strong out-of-the-box representations of temporal commonsense, and\nachieves state-of-the-art performance on 12 different video QA datasets when\nfinetuned. It also transfers well to the world of static images, allowing\nmodels to reason about the dynamic context behind visual scenes. On Visual\nCommonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy,\noutperforming state-of-the-art models of similar size by over 3%, even those\nthat make heavy use of auxiliary supervised data (like object bounding boxes).\nAblation analyses demonstrate the complementary importance of: 1) training on\nvideos versus static images; 2) scaling the magnitude and diversity of the\npretraining video corpus; and 3) using diverse objectives that encourage\nfull-stack multimodal reasoning, from the recognition to cognition level.",
    "descriptor": "\nComments: project page at this https URL\n",
    "authors": [
      "Rowan Zellers",
      "Ximing Lu",
      "Jack Hessel",
      "Youngjae Yu",
      "Jae Sung Park",
      "Jize Cao",
      "Ali Farhadi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02636"
  },
  {
    "id": "arXiv:2106.02637",
    "title": "Aligning Pretraining for Detection via Object-Level Contrastive Learning",
    "abstract": "Image-level contrastive representation learning has proven to be highly\neffective as a generic model for transfer learning. Such generality for\ntransfer learning, however, sacrifices specificity if we are interested in a\ncertain downstream task. We argue that this could be sub-optimal and thus\nadvocate a design principle which encourages alignment between the\nself-supervised pretext task and the downstream task. In this paper, we follow\nthis principle with a pretraining method specifically designed for the task of\nobject detection. We attain alignment in the following three aspects: 1)\nobject-level representations are introduced via selective search bounding boxes\nas object proposals; 2) the pretraining network architecture incorporates the\nsame dedicated modules used in the detection pipeline (e.g. FPN); 3) the\npretraining is equipped with object detection properties such as object-level\ntranslation invariance and scale invariance. Our method, called Selective\nObject COntrastive learning (SoCo), achieves state-of-the-art results for\ntransfer performance on COCO detection using a Mask R-CNN framework. Code and\nmodels will be made available.",
    "descriptor": "",
    "authors": [
      "Fangyun Wei",
      "Yue Gao",
      "Zhirong Wu",
      "Han Hu",
      "Stephen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02637"
  },
  {
    "id": "arXiv:2106.02638",
    "title": "Associating Objects with Transformers for Video Object Segmentation",
    "abstract": "This paper investigates how to realize better and more efficient embedding\nlearning to tackle the semi-supervised video object segmentation under\nchallenging multi-object scenarios. The state-of-the-art methods learn to\ndecode features with a single positive object and thus have to match and\nsegment each target separately under multi-object scenarios, consuming multiple\ntimes computing resources. To solve the problem, we propose an Associating\nObjects with Transformers (AOT) approach to match and decode multiple objects\nuniformly. In detail, AOT employs an identification mechanism to associate\nmultiple targets into the same high-dimensional embedding space. Thus, we can\nsimultaneously process the matching and segmentation decoding of multiple\nobjects as efficiently as processing a single object. For sufficiently modeling\nmulti-object association, a Long Short-Term Transformer is designed for\nconstructing hierarchical matching and propagation. We conduct extensive\nexperiments on both multi-object and single-object benchmarks to examine AOT\nvariant networks with different complexities. Particularly, our AOT-L\noutperforms all the state-of-the-art competitors on three popular benchmarks,\ni.e., YouTube-VOS (83.7% J&F), DAVIS 2017 (83.0%), and DAVIS 2016 (91.0%),\nwhile keeping better multi-object efficiency. Meanwhile, our AOT-T can maintain\nreal-time multi-object speed on above benchmarks. We ranked 1st in the 3rd\nLarge-scale Video Object Segmentation Challenge. The code will be publicly\navailable at https://github.com/z-x-yang/AOT.",
    "descriptor": "\nComments: 18 pages, 9 figures, 5 tables\n",
    "authors": [
      "Zongxin Yang",
      "Yunchao Wei",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02638"
  },
  {
    "id": "arXiv:2105.13801",
    "title": "A Probabilistic Forecast-Driven Strategy for a Risk-Aware Participation  in the Capacity Firming Market",
    "abstract": "This paper addresses the energy management of a grid-connected renewable\ngeneration plant coupled with a battery energy storage device in the capacity\nfirming market, designed to promote renewable power generation facilities in\nsmall non-interconnected grids. A recently developed deep learning model known\nas normalizing flows is used to generate quantile forecasts of renewable\ngeneration. They provide a general mechanism for defining expressive\nprobability distributions, only requiring the specification of a base\ndistribution and a series of bijective transformations. Then, a probabilistic\nforecast-driven strategy is designed, modeled as a min-max-min robust\noptimization problem with recourse, and solved using a Benders decomposition.\nThe convergence is improved by building an initial set of cuts derived from\ndomain knowledge. Robust optimization models the generation randomness using an\nuncertainty set that includes the worst-case generation scenario and protects\nthis scenario under the minimal increment of costs. This approach improves the\nresults over a deterministic approach with nominal point forecasts by finding a\ntrade-off between conservative and risk-seeking policies. Finally, a dynamic\nrisk-averse parameters selection strategy based on the quantile forecasts\ndistribution provides an additional gain. The case study uses the photovoltaic\ngeneration monitored on-site at the University of Li\\`ege (ULi\\`ege), Belgium.",
    "descriptor": "",
    "authors": [
      "Jonathan Dumas",
      "Colin Cointe",
      "Antoine Wehenkel",
      "Antonio Sutera",
      "Xavier Fettweis",
      "Bertrand Corn\u00e9lusse"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13801"
  },
  {
    "id": "arXiv:2105.14817",
    "title": "SQUADfps: Integrated Model-Based Machine Safety and Product Quality for  Flexible Production Systems",
    "abstract": "Growing individualization of products up to lot-size-1 and high volatility of\nproduct mixes lead to new challenges in the manufacturing domain, including the\nneed for frequent reconfiguration of the system and reacting to changing\norders. Thus, apart from functional aspects, safety aspects of the production\nsystem as well as product quality assurance aspects must be addressed for\nflexible and reconfigurable manufacturing systems at runtime. To cope with the\nmentioned challenges, we present an integrated model-based approach SQUADfps\n(machine Safety and product QUAlity for flexible proDuction systems) to support\nthe automatic conduct of the risk assessment of flexible production scenarios\nin terms of safety as well as the process-FMEA to ensure that the requirements\nw.r.t. the quality of the production process and the resulting product are met.\nOur approach is based on a meta-model which captures all information needed to\nconduct both risk assessment and process-FMEA dynamically during the runtime,\nand thus enables flexible manufacturing scenarios with frequent changes of the\nproduction system and orders up to a lot-size of one while guaranteeing safety\nand product quality requirements. The automatically generated results will\nassist human in making further decisions. To demonstrate the feasibility of our\napproach, we apply it to a case study.",
    "descriptor": "",
    "authors": [
      "Chee Hung Koo",
      "Stefan Rothbauer",
      "Marian Vorderer",
      "Kai Hoefig",
      "Marc Zeller"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2105.14817"
  },
  {
    "id": "arXiv:2106.02066",
    "title": "Local Problems on Trees from the Perspectives of Distributed Algorithms,  Finitary Factors, and Descriptive Combinatorics",
    "abstract": "We study connections between distributed local algorithms, finitary factors\nof iid processes, and descriptive combinatorics in the context of regular\ntrees.\nWe extend the Borel determinacy technique of Marks coming from descriptive\ncombinatorics and adapt it to the area of distributed computing. Using this\ntechnique, we prove deterministic distributed $\\Omega(\\log n)$-round lower\nbounds for problems from a natural class of homomorphism problems.\nInterestingly, these lower bounds seem beyond the current reach of the powerful\nround elimination technique responsible for all substantial locality lower\nbounds of the last years. Our key technical ingredient is a novel ID graph\ntechnique that we expect to be of independent interest.\nWe prove that a local problem admits a Baire measurable coloring if and only\nif it admits a local algorithm with local complexity $O(\\log n)$, extending the\nclassification of Baire measurable colorings of Bernshteyn. A key ingredient of\nthe proof is a new and simple characterization of local problems that can be\nsolved in $O(\\log n)$ rounds. We complement this result by showing separations\nbetween complexity classes from distributed computing, finitary factors, and\ndescriptive combinatorics. Most notably, the class of problems that allow a\ndistributed algorithm with sublogarithmic randomized local complexity is\nincomparable with the class of problems with a Borel solution.\nWe hope that our treatment will help to view all three perspectives as part\nof a common theory of locality, in which we follow the insightful paper of\n[Bernshteyn -- arXiv 2004.04905].",
    "descriptor": "",
    "authors": [
      "Sebastian Brandt",
      "Yi-Jun Chang",
      "Jan Greb\u00edk",
      "Christoph Grunau",
      "V\u00e1clav Rozho\u0148",
      "Zolt\u00e1n Vidny\u00e1nszky"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Logic (math.LO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.02066"
  },
  {
    "id": "arXiv:2106.02078",
    "title": "Robust Learning via Persistency of Excitation",
    "abstract": "Improving adversarial robustness of neural networks remains a major\nchallenge. Fundamentally, training a network is a parameter estimation problem.\nIn adaptive control theory, maintaining persistency of excitation (PoE) is\nintegral to ensuring convergence of parameter estimates in dynamical systems to\ntheir robust optima. In this work, we show that network training using gradient\ndescent is equivalent to a dynamical system parameter estimation problem.\nLeveraging this relationship, we prove a sufficient condition for PoE of\ngradient descent is achieved when the learning rate is less than the inverse of\nthe Lipschitz constant of the gradient of loss function. We provide an\nefficient technique for estimating the corresponding Lipschitz constant using\nextreme value theory and demonstrate that by only scaling the learning rate\nschedule we can increase adversarial accuracy by up to 15% on benchmark\ndatasets. Our approach also universally increases the adversarial accuracy by\n0.1% to 0.3% in various state-of-the-art adversarially trained models on the\nAutoAttack benchmark, where every small margin of improvement is significant.",
    "descriptor": "",
    "authors": [
      "Kaustubh Sridhar",
      "Oleg Sokolsky",
      "Insup Lee",
      "James Weimer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02078"
  },
  {
    "id": "arXiv:2106.02081",
    "title": "Solving Schr\u00f6dinger Bridges via Maximum Likelihood",
    "abstract": "The Schr\\\"odinger bridge problem (SBP) finds the most likely stochastic\nevolution between two probability distributions given a prior stochastic\nevolution. As well as applications in the natural sciences, problems of this\nkind have important applications in machine learning such as dataset alignment\nand hypothesis testing. Whilst the theory behind this problem is relatively\nmature, scalable numerical recipes to estimate the Schr\\\"odinger bridge remain\nan active area of research. We prove an equivalence between the SBP and maximum\nlikelihood estimation enabling direct application of successful machine\nlearning techniques. We propose a numerical procedure to estimate SBPs using\nGaussian process and demonstrate the practical usage of our approach in\nnumerical simulations and experiments.",
    "descriptor": "\nComments: 9 pages + appendix (total 28 pages)\n",
    "authors": [
      "Francisco Vargas",
      "Pierre Thodoroff",
      "Neil D. Lawrence",
      "Austen Lamacraft"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02081"
  },
  {
    "id": "arXiv:2106.02096",
    "title": "Shape-Preserving Dimensionality Reduction : An Algorithm and Measures of  Topological Equivalence",
    "abstract": "We introduce a linear dimensionality reduction technique preserving\ntopological features via persistent homology. The method is designed to find\nlinear projection $L$ which preserves the persistent diagram of a point cloud\n$\\mathbb{X}$ via simulated annealing. The projection $L$ induces a set of\ncanonical simplicial maps from the Rips (or \\v{C}ech) filtration of\n$\\mathbb{X}$ to that of $L\\mathbb{X}$. In addition to the distance between\npersistent diagrams, the projection induces a map between filtrations, called\nfiltration homomorphism. Using the filtration homomorphism, one can measure the\ndifference between shapes of two filtrations directly comparing simplicial\ncomplexes with respect to quasi-isomorphism $\\mu_{\\operatorname{quasi-iso}}$ or\nstrong homotopy equivalence $\\mu_{\\operatorname{equiv}}$. These\n$\\mu_{\\operatorname{quasi-iso}}$ and $\\mu_{\\operatorname{equiv}}$ measures how\nmuch portion of corresponding simplicial complexes is quasi-isomorphic or\nhomotopy equivalence respectively. We validate the effectiveness of our\nframework with simple examples.",
    "descriptor": "\nComments: 18 pages, 2 figures\n",
    "authors": [
      "Byeongsu Yu",
      "Kisung You"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02096"
  },
  {
    "id": "arXiv:2106.02106",
    "title": "Embedded Deep Regularized Block HSIC Thermomics for Early Diagnosis of  Breast Cancer",
    "abstract": "Thermography has been used extensively as a complementary diagnostic tool in\nbreast cancer detection. Among thermographic methods matrix factorization (MF)\ntechniques show an unequivocal capability to detect thermal patterns\ncorresponding to vasodilation in cancer cases. One of the biggest challenges in\nsuch techniques is selecting the best representation of the thermal basis. In\nthis study, an embedding method is proposed to address this problem and\nDeep-semi-nonnegative matrix factorization (Deep-SemiNMF) for thermography is\nintroduced, then tested for 208 breast cancer screening cases. First, we apply\nDeep-SemiNMF to infrared images to extract low-rank thermal representations for\neach case. Then, we embed low-rank bases to obtain one basis for each patient.\nAfter that, we extract 300 thermal imaging features, called thermomics, to\ndecode imaging information for the automatic diagnostic model. We reduced the\ndimensionality of thermomics by spanning them onto Hilbert space using RBF\nkernel and select the three most efficient features using the block Hilbert\nSchmidt Independence Criterion Lasso (block HSIC Lasso). The preserved thermal\nheterogeneity successfully classified asymptomatic versus symptomatic patients\napplying a random forest model (cross-validated accuracy of 71.36%\n(69.42%-73.3%)).",
    "descriptor": "\nComments: Authors version. arXiv admin note: text overlap with arXiv:2010.06784\n",
    "authors": [
      "Bardia Yousefi",
      "Hossein Memarzadeh Sharifipour",
      "Xavier P.V. Maldague"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02106"
  },
  {
    "id": "arXiv:2106.02110",
    "title": "Influence of cognitive, geographical, and collaborative proximity on  knowledge production of Canadian nanotechnology",
    "abstract": "Incorporating existing knowledge is vital for innovating, discovering, and\ngenerating new ideas. Knowledge production through research and invention is\nthe key to scientific and technological development. As an emerging technology,\nnanotechnology has already proved its great potential for the global economy,\nattracting considerable federal investments. Canada is reported as one of the\nmajor players in producing nanotechnology research. In this paper, we focused\non the main drivers of knowledge production and diffusion by analyzing Canadian\nnanotechnology researchers. We hypothesized that knowledge production in\nCanadian nanotechnology is influenced by three key proximity factors, namely\ncognitive, geographical, and collaborative. Using statistical analysis, social\nnetwork analysis, and machine learning techniques we comprehensively assessed\nthe influence of the proximity factors on academic knowledge production. Our\nresults not only prove a significant impact of the three key proximity factors\nbut also their predictive potential.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Elva Luz Crespo Neira",
      "Ashkan Ebadi",
      "Catherine Beaudry",
      "Andrea Schiffauerova"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02110"
  },
  {
    "id": "arXiv:2106.02111",
    "title": "Efficient $\\mathbb{Z}_2$ synchronization on $\\mathbb{Z}^d$ under  symmetry-preserving side information",
    "abstract": "We consider $\\mathbb{Z}_2$-synchronization on the Euclidean lattice. Every\nvertex of $\\mathbb{Z}^d$ is assigned an independent symmetric random sign\n$\\theta_u$, and for every edge $(u,v)$ of the lattice, one observes the product\n$\\theta_u\\theta_v$ flipped independently with probability $p$. The task is to\nreconstruct products $\\theta_u\\theta_v$ for pairs of vertices $u$ and $v$ which\nare arbitrarily far apart. Abb\\'e, Massouli\\'e, Montanari, Sly and Srivastava\n(2018) showed that synchronization is possible if and only if $p$ is below a\ncritical threshold $\\tilde{p}_c(d)$, and efficiently so for $p$ small enough.\nWe augment this synchronization setting with a model of side information\npreserving the sign symmetry of $\\theta$, and propose an \\emph{efficient}\nalgorithm which synchronizes a randomly chosen pair of far away vertices on\naverage, up to a differently defined critical threshold $p_c(d)$. We conjecture\nthat $ p_c(d)=\\tilde{p}_c(d)$ for all $d \\ge 2$. Our strategy is to\n\\emph{renormalize} the synchronization model in order to reduce the effective\nnoise parameter, and then apply a variant of the multiscale algorithm of AMMSS.\nThe success of the renormalization procedure is conditional on a plausible but\nunproved assumption about the regularity of the free energy of an Ising spin\nglass model on $\\mathbb{Z}^d$.",
    "descriptor": "\nComments: 51 pages, 2 figures\n",
    "authors": [
      "Ahmed El Alaoui"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.02111"
  },
  {
    "id": "arXiv:2106.02118",
    "title": "A Prospective Observational Study to Investigate Performance of a Chest  X-ray Artificial Intelligence Diagnostic Support Tool Across 12 U.S.  Hospitals",
    "abstract": "Importance: An artificial intelligence (AI)-based model to predict COVID-19\nlikelihood from chest x-ray (CXR) findings can serve as an important adjunct to\naccelerate immediate clinical decision making and improve clinical decision\nmaking. Despite significant efforts, many limitations and biases exist in\npreviously developed AI diagnostic models for COVID-19. Utilizing a large set\nof local and international CXR images, we developed an AI model with high\nperformance on temporal and external validation.\nConclusions and Relevance: AI-based diagnostic tools may serve as an adjunct,\nbut not replacement, for clinical decision support of COVID-19 diagnosis, which\nlargely hinges on exposure history, signs, and symptoms. While AI-based tools\nhave not yet reached full diagnostic potential in COVID-19, they may still\noffer valuable information to clinicians taken into consideration along with\nclinical signs and symptoms.",
    "descriptor": "",
    "authors": [
      "Ju Sun",
      "Le Peng",
      "Taihui Li",
      "Dyah Adila",
      "Zach Zaiman",
      "Genevieve B. Melton",
      "Nicholas Ingraham",
      "Eric Murray",
      "Daniel Boley",
      "Sean Switzer",
      "John L. Burns",
      "Kun Huang",
      "Tadashi Allen",
      "Scott D. Steenburg",
      "Judy Wawira Gichoya",
      "Erich Kummerfeld",
      "Christopher Tignanelli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02118"
  },
  {
    "id": "arXiv:2106.02119",
    "title": "A Scalable Second Order Method for Ill-Conditioned Matrix Completion  from Few Samples",
    "abstract": "We propose an iterative algorithm for low-rank matrix completion that can be\ninterpreted as an iteratively reweighted least squares (IRLS) algorithm, a\nsaddle-escaping smoothing Newton method or a variable metric proximal gradient\nmethod applied to a non-convex rank surrogate. It combines the favorable\ndata-efficiency of previous IRLS approaches with an improved scalability by\nseveral orders of magnitude. We establish the first local convergence guarantee\nfrom a minimal number of samples for that class of algorithms, showing that the\nmethod attains a local quadratic convergence rate. Furthermore, we show that\nthe linear systems to be solved are well-conditioned even for very\nill-conditioned ground truth matrices. We provide extensive experiments,\nindicating that unlike many state-of-the-art approaches, our method is able to\ncomplete very ill-conditioned matrices with a condition number of up to\n$10^{10}$ from few samples, while being competitive in its scalability.",
    "descriptor": "\nComments: 45 pages, 8 figures, to be published in ICML 2021. arXiv admin note: text overlap with arXiv:2009.02905\n",
    "authors": [
      "Christian K\u00fcmmerle",
      "Claudio Mayrink Verdun"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02119"
  },
  {
    "id": "arXiv:2106.02151",
    "title": "Single-leader multi-follower games for the regulation of two-sided  Mobility-as-a-Service markets",
    "abstract": "Mobility-as-a-Service (MaaS) is emerging mobility trend driven by the concept\nof \"Everything-as-a-Service\" and enabled through mobile internet technologies.\nIn the context of economic deregulation, a MaaS system consists of a typical\ntwo-sided market, where travelers and transportation service providers (TSPs)\nare two groups of agents interacting with each other through a MaaS platform.\nIn this study, we propose a modeling and optimization framework for the\nregulation of two-sided MaaS markets. We consider a double-auction mechanism\nwhere travelers submit purchase-bids to accommodate their travel demand via\nMaaS, and TSPs submit sell-bids to supply mobility resources for the MaaS\nplatform in exchange for payments. We cast this problem as a single-leader\nmulti-follower game (SLMFG) where the leader is the MaaS regulator and two\ngroups of follower problems represent the travelers and the TSPs. The MaaS\nregulator makes the operating decisions to maximize its profits. In response to\nthe MaaS regulator's decisions, travelers (resp. TSPs) decide the participation\nlevels of joining the MaaS platform to minimize their travel costs (resp.\nmaximize their profits). We formulate SLMFGs without and with network effects\nleading to mixed-integer linear bilevel programming and mixed-integer quadratic\nbilevel programming problems, respectively. We propose customized\nbranch-and-bound algorithms based on strong duality reformulations to solve the\nSLMFGs. Extensive numerical experiments conducted on large scale simulation\ninstances generated from realistic mobility data highlight that the performance\nof the proposed algorithms is significantly superior to a benchmarking approach\nand provide meaningful insights for the regulation of two-sided MaaS markets.",
    "descriptor": "",
    "authors": [
      "Haoning Xi",
      "Didier Aussel",
      "Wei Liu",
      "S Travis Waller",
      "David Rey"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.02151"
  },
  {
    "id": "arXiv:2106.02154",
    "title": "Laplacian-Based Dimensionality Reduction Including Spectral Clustering,  Laplacian Eigenmap, Locality Preserving Projection, Graph Embedding, and  Diffusion Map: Tutorial and Survey",
    "abstract": "This is a tutorial and survey paper for nonlinear dimensionality and feature\nextraction methods which are based on the Laplacian of graph of data. We first\nintroduce adjacency matrix, definition of Laplacian matrix, and the\ninterpretation of Laplacian. Then, we cover the cuts of graph and spectral\nclustering which applies clustering in a subspace of data. Different\noptimization variants of Laplacian eigenmap and its out-of-sample extension are\nexplained. Thereafter, we introduce the locality preserving projection and its\nkernel variant as linear special cases of Laplacian eigenmap. Versions of graph\nembedding are then explained which are generalized versions of Laplacian\neigenmap and locality preserving projection. Finally, diffusion map is\nintroduced which is a method based on Laplacian of data and random walks on the\ndata graph.",
    "descriptor": "\nComments: To appear as a part of an upcoming textbook on dimensionality reduction and manifold learning\n",
    "authors": [
      "Benyamin Ghojogh",
      "Ali Ghodsi",
      "Fakhri Karray",
      "Mark Crowley"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02154"
  },
  {
    "id": "arXiv:2106.02170",
    "title": "Segmental Contrastive Predictive Coding for Unsupervised Word  Segmentation",
    "abstract": "Automatic detection of phoneme or word-like units is one of the core\nobjectives in zero-resource speech processing. Recent attempts employ\nself-supervised training methods, such as contrastive predictive coding (CPC),\nwhere the next frame is predicted given past context. However, CPC only looks\nat the audio signal's frame-level structure. We overcome this limitation with a\nsegmental contrastive predictive coding (SCPC) framework that can model the\nsignal structure at a higher level e.g. at the phoneme level. In this\nframework, a convolutional neural network learns frame-level representation\nfrom the raw waveform via noise-contrastive estimation (NCE). A differentiable\nboundary detector finds variable-length segments, which are then used to\noptimize a segment encoder via NCE to learn segment representations. The\ndifferentiable boundary detector allows us to train frame-level and\nsegment-level encoders jointly. Typically, phoneme and word segmentation are\ntreated as separate tasks. We unify them and experimentally show that our\nsingle model outperforms existing phoneme and word segmentation methods on\nTIMIT and Buckeye datasets. We analyze the impact of boundary threshold and\nwhen is the right time to include the segmental loss in the learning process.",
    "descriptor": "",
    "authors": [
      "Saurabhchand Bhati",
      "Jes\u00fas Villalba",
      "Piotr \u017belasko",
      "Laureano Moro-Velazquez",
      "Najim Dehak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.02170"
  },
  {
    "id": "arXiv:2106.02176",
    "title": "Tensegrity system dynamics based on finite element method",
    "abstract": "This study presents a finite element analysis approach to non-linear and\nlinearized tensegrity dynamics based on the Lagrangian method with nodal\ncoordinate vectors as the generalized coordinates. In this paper, nonlinear\ntensegrity dynamics with and without constraints are first derived. The\nequilibrium equations in three standard forms (in terms of nodal coordinate,\nforce density, and force vectors) and the compatibility equation are also\ngiven. Then, we present the linearized dynamics and modal analysis equations\nwith and without constraints. The developed approach is capable of conducting\nthe following comprehensive dynamics studies for any tensegrity structures\naccurately: 1. Performing rigid body dynamics with acceptable errors, which is\nachieved by setting relatively high stiffness for bars in the simulation. 2.\nSimulating FEM dynamics accurately, where bars and strings can have elastic or\nplastic deformations. 3. Dealing with various kinds of boundary conditions, for\nexample, fixing or applying static/dynamic loads at any nodes in any direction\n(i.e., gravitational force, some specified forces, or arbitrary seismic\nvibrations). 4. Conducting accurate modal analysis, including natural frequency\nand corresponding modes. Three examples, a double pendulum, a cantilever truss\nwith external force, and a double prism tensegrity tower, are carefully\nselected and studied. The results are compared with rigid body dynamics and FEM\nsoftware ANSYS. This study provides a deep insight into structures, materials,\nperformances, as well as an interface towards integrating control theories.",
    "descriptor": "\nComments: 13 pages, 19 figures\n",
    "authors": [
      "Shuo Ma",
      "Muhao Chen",
      "Robert E. Skelton"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.02176"
  },
  {
    "id": "arXiv:2106.02198",
    "title": "CNNs and GANs in MRI-based cross-modality medical image estimation",
    "abstract": "Cross-modality image estimation involves the generation of images of one\nmedical imaging modality from that of another modality. Convolutional neural\nnetworks (CNNs) have been shown to be useful in identifying, characterising and\nextracting image patterns. Generative adversarial networks (GANs) use CNNs as\ngenerators and estimated images are discriminated as true or false based on an\nadditional network. CNNs and GANs within the image estimation framework may be\nconsidered more generally as deep learning approaches, since imaging data tends\nto be large, leading to a larger number of network weights. Almost all research\nin the CNN/GAN image estimation literature has involved the use of MRI data\nwith the other modality primarily being PET or CT. This review provides an\noverview of the use of CNNs and GANs for MRI-based cross-modality medical image\nestimation. We outline the neural networks implemented, and detail network\nconstructs employed for CNN and GAN image-to-image estimators. Motivations\nbehind cross-modality image estimation are provided as well. GANs appear to\nprovide better utility in cross-modality image estimation in comparison with\nCNNs, a finding drawn based on our analysis involving metrics comparing\nestimated and actual images. Our final remarks highlight key challenges faced\nby the cross-modality medical image estimation field, and suggestions for\nfuture research are outlined.",
    "descriptor": "",
    "authors": [
      "Azin Shokraei Fard",
      "David C. Reutens",
      "Viktor Vegh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02198"
  },
  {
    "id": "arXiv:2106.02221",
    "title": "Specular reflections removal in colposcopic images based on neural  networks: Supervised training with no ground truth previous knowledge",
    "abstract": "Cervical cancer is a malignant tumor that seriously threatens women's health,\nand is one of the most common that affects women worldwide. For its early\ndetection, colposcopic images of the cervix are used for searching for possible\ninjuries or abnormalities. An inherent characteristic of these images is the\npresence of specular reflections (brightness) that make it difficult to observe\nsome regions, which might imply a misdiagnosis. In this paper, a new strategy\nbased on neural networks is introduced for eliminating specular reflections and\nestimating the unobserved anatomical cervix portion under the bright zones. We\npresent a supervised learning method, despite not knowing the ground truth from\nthe beginning, based on training a neural network to learn how to restore any\nhidden region of colposcopic images. Once the specular reflections are\nidentified, they are removed from the image and the previously trained network\nis used to fulfill these deleted areas. The quality of the processed images was\nevaluated quantitatively and qualitatively. In 21 of the 22 evaluated images,\nthe detected specular reflections were totally eliminated, whereas, in the\nremaining one, these reflections were almost completely eliminated. The\ndistribution of the colors and the content of the restored images are similar\nto those of the originals. The evaluation carried out by a specialist in Cervix\nPathology concluded that, after eliminating the specular reflections, the\nanatomical and physiological elements of the cervix are observable in the\nrestored images, which facilitates the medical diagnosis of cervical\npathologies. Our method has the potential to improve the early detection of\ncervical cancer.",
    "descriptor": "",
    "authors": [
      "Lauren Jimenez-Martin",
      "Daniel A. Vald\u00e9s P\u00e9rez",
      "Ana M. Solares Asteasuainzarra",
      "Ludwig Leonard",
      "Marta L. Baguer D\u00edaz-Roma\u00f1ach"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02221"
  },
  {
    "id": "arXiv:2106.02226",
    "title": "Maximal antichains of subsets I: The shadow spectrum",
    "abstract": "Extending a classical theorem of Sperner, we investigate the question for\nwhich positive integers $m$ there exists a maximal antichain of size $m$ in the\nBoolean lattice $B_n$, that is, the power set of $[n]:=\\{1,2,\\dots,n\\}$,\nordered by inclusion. We characterize all such integers $m$ in the range\n$\\binom{n}{\\lceil n/2\\rceil}-\\lceil n/2\\rceil^2\\leq m\\leq\\binom{n}{\\lceil\nn/2\\rceil}$. As an important ingredient in the proof, we initiate the study of\nan extension of the Kruskal-Katona theorem which is of independent interest.\nFor given positive integers $t$ and $k$, we ask which integers $s$ have the\nproperty that there exists a family $\\mathcal F$ of $k$-sets with\n$\\lvert\\mathcal F\\rvert=t$ such that the shadow of $\\mathcal F$ has size $s$,\nwhere the shadow of $\\mathcal F$ is the collection of $(k-1)$-sets that are\ncontained in at least one member of $\\mathcal F$. We provide a complete answer\nfor the case $t\\leq k+1$. Moreover, we prove that the largest integer which is\nnot the shadow size of any family of $k$-sets is $\\sqrt\n2k^{3/2}+\\sqrt[4]{8}k^{5/4}+O(k)$.",
    "descriptor": "",
    "authors": [
      "Jerrold R. Griggs",
      "Thomas Kalinowski",
      "Uwe Leck",
      "Ian T. Roberts",
      "Michael Schmitz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.02226"
  },
  {
    "id": "arXiv:2106.02230",
    "title": "Maximal antichains of subsets II: Constructions",
    "abstract": "This is the second in a sequence of three papers investigating the question\nfor which positive integers $m$ there exists a maximal antichain of size $m$ in\nthe Boolean lattice $B_n$ (the power set of $[n]:=\\{1,2,\\dots,n\\}$, ordered by\ninclusion). In the previous paper we characterized those $m$ between the\nmaximum size $\\binom{n}{\\lfloor n/2 \\rfloor}$ and $\\binom{n}{\\lceil\nn/2\\rceil}-\\lceil n/2\\rceil^2$ that are not sizes of maximal antichains. In\nthis paper we show that all smaller $m$ are sizes of maximal antichains.",
    "descriptor": "",
    "authors": [
      "Jerrold R. Griggs",
      "Thomas Kalinowski",
      "Uwe Leck",
      "Ian T. Roberts",
      "Michael Schmitz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.02230"
  },
  {
    "id": "arXiv:2106.02254",
    "title": "State Estimation in Unobservable Power Systems via Graph Signal  Processing Tools",
    "abstract": "We consider the problem of estimating the states and detecting bad data in an\nunobservable power system. To this end, we propose novel graph signal\nprocessing (GSP) methods. The main assumption behind the proposed GSP approach\nis that the grid state vector, which includes the phases of the voltages in the\nsystem, is a smooth graph signal with respect to the system admittance matrix\nthat represents the underlying graph. Thus, the first step in this paper is to\nvalidate the graph-smoothness assumption of the states, both empirically and\ntheoretically. Then, we develop the regularized weighted least squares (WLS)\nstate estimator, which does not require observability of the network. We\npropose a sensor (meter) placement strategy that aims to optimize the\nestimation performance of the proposed GSP-WLS estimator. In addition, we\ndevelop a joint bad-data and false data injected (FDI) attacks detector that\nintegrates the GSP-WLS state estimator into the conventional J(theta)-test with\nan additional smoothness regularization. Numerical results on the IEEE 118-bus\ntest-case system demonstrate that the new GSP methods outperform commonly-used\nestimation and detection approaches in electric networks and are robust to\nmissing data.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Lital Dabush",
      "Ariel Kroizer",
      "Tirza Routtenberg"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02254"
  },
  {
    "id": "arXiv:2106.02261",
    "title": "Out-of-Distribution Generalization in Kernel Regression",
    "abstract": "In real word applications, data generating process for training a machine\nlearning model often differs from what the model encounters in the test stage.\nUnderstanding how and whether machine learning models generalize under such\ndistributional shifts have been a theoretical challenge. Here, we study\ngeneralization in kernel regression when the training and test distributions\nare different using methods from statistical physics. Using the replica method,\nwe derive an analytical formula for the out-of-distribution generalization\nerror applicable to any kernel and real datasets. We identify an overlap matrix\nthat quantifies the mismatch between distributions for a given kernel as a key\ndeterminant of generalization performance under distribution shift. Using our\nanalytical expressions we elucidate various generalization phenomena including\npossible improvement in generalization when there is a mismatch. We develop\nprocedures for optimizing training and test distributions for a given data\nbudget to find best and worst case generalizations under the shift. We present\napplications of our theory to real and synthetic datasets and for many kernels.\nWe compare results of our theory applied to Neural Tangent Kernel with\nsimulations of wide networks and show agreement. We analyze linear regression\nin further depth.",
    "descriptor": "",
    "authors": [
      "Abdulkadir Canatar",
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02261"
  },
  {
    "id": "arXiv:2106.02290",
    "title": "Matrix completion with data-dependent missingness probabilities",
    "abstract": "The problem of completing a large matrix with lots of missing entries has\nreceived widespread attention in the last couple of decades. Two popular\napproaches to the matrix completion problem are based on singular value\nthresholding and nuclear norm minimization. Most of the past works on this\nsubject assume that there is a single number $p$ such that each entry of the\nmatrix is available independently with probability $p$ and missing otherwise.\nThis assumption may not be realistic for many applications. In this work, we\nreplace it with the assumption that the probability that an entry is available\nis an unknown function $f$ of the entry itself. For example, if the entry is\nthe rating given to a movie by a viewer, then it seems plausible that high\nvalue entries have greater probability of being available than low value\nentries. We propose two new estimators, based on singular value thresholding\nand nuclear norm minimization, to recover the matrix under this assumption. The\nestimators are shown to be consistent under a low rank assumption. We also\nprovide a consistent estimator of the unknown function $f$.",
    "descriptor": "\nComments: 24 pages, 7 figures\n",
    "authors": [
      "Sohom Bhattacharya",
      "Sourav Chatterjee"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.02290"
  },
  {
    "id": "arXiv:2106.02297",
    "title": "Fre-GAN: Adversarial Frequency-consistent Audio Synthesis",
    "abstract": "Although recent works on neural vocoder have improved the quality of\nsynthesized audio, there still exists a gap between generated and ground-truth\naudio in frequency space. This difference leads to spectral artifacts such as\nhissing noise or robotic sound, and thus degrades the sample quality. In this\npaper, we propose Fre-GAN which achieves frequency-consistent audio synthesis\nwith highly improved generation quality. Specifically, we first present\nresolution-connected generator and resolution-wise discriminators, which help\nlearn various scales of spectral distributions over multiple frequency bands.\nAdditionally, to reproduce high-frequency components accurately, we leverage\ndiscrete wavelet transform in the discriminators. From our experiments, Fre-GAN\nachieves high-fidelity waveform generation with a gap of only 0.03 MOS compared\nto ground-truth audio while outperforming standard models in quality.",
    "descriptor": "\nComments: Accepted paper in Interspeech 2021\n",
    "authors": [
      "Ji-Hoon Kim",
      "Sang-Hoon Lee",
      "Ji-Hyun Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02297"
  },
  {
    "id": "arXiv:2106.02302",
    "title": "Minimum Word Error Rate Training with Language Model Fusion for  End-to-End Speech Recognition",
    "abstract": "Integrating external language models (LMs) into end-to-end (E2E) models\nremains a challenging task for domain-adaptive speech recognition. Recently,\ninternal language model estimation (ILME)-based LM fusion has shown significant\nword error rate (WER) reduction from Shallow Fusion by subtracting a weighted\ninternal LM score from an interpolation of E2E model and external LM scores\nduring beam search. However, on different test sets, the optimal LM\ninterpolation weights vary over a wide range and have to be tuned extensively\non well-matched validation sets. In this work, we perform LM fusion in the\nminimum WER (MWER) training of an E2E model to obviate the need for LM weights\ntuning during inference. Besides MWER training with Shallow Fusion (MWER-SF),\nwe propose a novel MWER training with ILME (MWER-ILME) where the ILME-based\nfusion is conducted to generate N-best hypotheses and their posteriors.\nAdditional gradient is induced when internal LM is engaged in MWER-ILME loss\ncomputation. During inference, LM weights pre-determined in MWER training\nenable robust LM integrations on test sets from different domains. Experimented\nwith 30K-hour trained transformer transducers, MWER-ILME achieves on average\n8.8% and 5.8% relative WER reductions from MWER and MWER-SF training,\nrespectively, on 6 different test sets",
    "descriptor": "\nComments: 5 pages, Interspeech 2021\n",
    "authors": [
      "Zhong Meng",
      "Yu Wu",
      "Naoyuki Kanda",
      "Liang Lu",
      "Xie Chen",
      "Guoli Ye",
      "Eric Sun",
      "Jinyu Li",
      "Yifan Gong"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.02302"
  },
  {
    "id": "arXiv:2106.02323",
    "title": "Probabilistic forecasting for sizing in the capacity firming framework",
    "abstract": "This paper proposes a strategy to size a grid-connected photovoltaic plant\ncoupled with a battery energy storage device within the \\textit{capacity\nfirming} specifications of the French Energy Regulatory Commission. In this\ncontext, the sizing problem is challenging due to the two-phase engagement\ncontrol with a day-ahead nomination and an intraday control to minimize\ndeviations from the planning. The two-phase engagement control is modeled with\ndeterministic and stochastic approaches. The optimization problems are\nformulated as mixed-integer quadratic problems, using a Gaussian copula\nmethodology to generate PV scenarios, to approximate the mixed-integer\nnon-linear problem of the capacity firming. Then, a grid search is conducted to\napproximate the optimal sizing for a given selling price using both the\ndeterministic and stochastic approaches. The case study is composed of PV\nproduction monitored on-site at the Li\\`ege University (ULi\\`ege), Belgium.",
    "descriptor": "",
    "authors": [
      "Jonathan Dumas",
      "Bertrand Corn\u00e9lusse",
      "Xavier Fettweis",
      "Antonello Giannitrapani",
      "Simone Paoletti",
      "Antonio Vicino"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02323"
  },
  {
    "id": "arXiv:2106.02331",
    "title": "Manifold-Aware Deep Clustering: Maximizing Angles between Embedding  Vectors Based on Regular Simplex",
    "abstract": "This paper presents a new deep clustering (DC) method called manifold-aware\nDC (M-DC) that can enhance hyperspace utilization more effectively than the\noriginal DC. The original DC has a limitation in that a pair of two speakers\nhas to be embedded having an orthogonal relationship due to its use of the\none-hot vector-based loss function, while our method derives a unique loss\nfunction aimed at maximizing the target angle in the hyperspace based on the\nnature of a regular simplex. Our proposed loss imposes a higher penalty than\nthe original DC when the speaker is assigned incorrectly. The change from DC to\nM-DC can be easily achieved by rewriting just one term in the loss function of\nDC, without any other modifications to the network architecture or model\nparameters. As such, our method has high practicability because it does not\naffect the original inference part. The experimental results show that the\nproposed method improves the performances of the original DC and its expansion\nmethod.",
    "descriptor": "\nComments: Accepted by Interspeech 2021\n",
    "authors": [
      "Keitaro Tanaka",
      "Ryosuke Sawata",
      "Shusuke Takahashi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02331"
  },
  {
    "id": "arXiv:2106.02338",
    "title": "Projection-Based Reduced Order Model for Simulations of Nonlinear Flows  with Multiple Moving Objects",
    "abstract": "This paper presents a reduced order approach for transient modeling of\nmultiple moving objects in nonlinear crossflows. The Proper Orthogonal\nDecomposition method and the Galerkin projection are used to construct a\nreduced version of the nonlinear Navier-Stokes equations. The Galerkin\nprojection implemented in OpenFOAM platform allows accurate impositions of\narbitrary time-dependent boundary conditions at the moving boundaries. A\nmodelling technique based on moving domain and immersed boundary techniques is\nproposed to overcome the challenge of handling moving boundaries due to\nmovements of the multiple objects. The model is demonstrated capable to capture\nthe complex flow fields past one and two oscillating cylinders and the forces\nacting on the cylinders. Simulation time could be reduced by more than three\norders for a small case on a fine mesh as compared to an existing method and\ncould be more for large cases. In general, the simulation time of the reduced\nmodel is of order of seconds as compared to hours of the full order\nComputational Fluid Dynamics models.",
    "descriptor": "",
    "authors": [
      "My Ha Dao"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.02338"
  },
  {
    "id": "arXiv:2106.02346",
    "title": "Provably Strict Generalisation Benefit for Invariance in Kernel Methods",
    "abstract": "It is a commonly held belief that enforcing invariance improves\ngeneralisation. Although this approach enjoys widespread popularity, it is only\nvery recently that a rigorous theoretical demonstration of this benefit has\nbeen established. In this work we build on the function space perspective of\nElesedy and Zaidi arXiv:2102.10333 to derive a strictly non-zero generalisation\nbenefit of incorporating invariance in kernel ridge regression when the target\nis invariant to the action of a compact group. We study invariance enforced by\nfeature averaging and find that generalisation is governed by a notion of\neffective dimension that arises from the interplay between the kernel and the\ngroup. In building towards this result, we find that the action of the group\ninduces an orthogonal decomposition of both the reproducing kernel Hilbert\nspace and its kernel, which may be of interest in its own right.",
    "descriptor": "",
    "authors": [
      "Bryn Elesedy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02346"
  },
  {
    "id": "arXiv:2106.02348",
    "title": "A Residual Network based Deep Learning Model for Detection of COVID-19  from Cough Sounds",
    "abstract": "The present work proposes a deep-learning-based approach for the\nclassification of COVID-19 coughs from non-COVID-19 coughs and that can be used\nas a low-resource-based tool for early detection of the onset of such\nrespiratory diseases. The proposed system uses the ResNet-50 architecture, a\npopularly known Convolutional Neural Network (CNN) for image recognition tasks,\nfed with the log-Mel spectrums of the audio data to discriminate between the\ntwo types of coughs. For the training and validation of the proposed deep\nlearning model, this work utilizes the Track-1 dataset provided by the DiCOVA\nChallenge 2021 organizers. Additionally, to increase the number of\nCOVID-positive samples and to enhance variability in the training data, it has\nalso utilized a large open-source database of COVID-19 coughs collected by the\nEPFL CoughVid team. Our developed model has achieved an average validation AUC\nof 98.88%. Also, applying this model on the Blind Test Set released by the\nDiCOVA Challenge, the system has achieved a Test AUC of 75.91%, Test\nSpecificity of 62.50%, and Test Sensitivity of 80.49%. Consequently, this\nsubmission has secured 16th position in the DiCOVA Challenge 2021 leader-board.",
    "descriptor": "",
    "authors": [
      "Annesya Banerjee",
      "Achal Nilhani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.02348"
  },
  {
    "id": "arXiv:2106.02352",
    "title": "COLD: Concurrent Loads Disaggregator for Non-Intrusive Load Monitoring",
    "abstract": "The modern artificial intelligence techniques show the outstanding\nperformances in the field of Non-Intrusive Load Monitoring (NILM). However, the\nproblem related to the identification of a large number of appliances working\nsimultaneously is underestimated. One of the reasons is the absence of a\nspecific data. In this research we propose the Synthesizer of Normalized\nSignatures (SNS) algorithm to simulate the aggregated consumption with up to 10\nconcurrent loads. The results show that the synthetic data provides the models\nwith at least as a powerful identification accuracy as the real-world\nmeasurements. We have developed the neural architecture named Concurrent Loads\nDisaggregator (COLD) which is relatively simple and easy to understand in\ncomparison to the previous approaches. Our model allows identifying from 1 to\n10 appliances working simultaneously with mean F1-score 78.95%. The source code\nof the experiments performed is available at\nhttps://github.com/arx7ti/cold-nilm.",
    "descriptor": "",
    "authors": [
      "Ilia Kamyshev",
      "Dmitrii Kriukov",
      "Elena Gryazina"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02352"
  },
  {
    "id": "arXiv:2106.02356",
    "title": "PCA Initialization for Approximate Message Passing in Rotationally  Invariant Models",
    "abstract": "We study the problem of estimating a rank-$1$ signal in the presence of\nrotationally invariant noise-a class of perturbations more general than\nGaussian noise. Principal Component Analysis (PCA) provides a natural\nestimator, and sharp results on its performance have been obtained in the\nhigh-dimensional regime. Recently, an Approximate Message Passing (AMP)\nalgorithm has been proposed as an alternative estimator with the potential to\nimprove the accuracy of PCA. However, the existing analysis of AMP requires an\ninitialization that is both correlated with the signal and independent of the\nnoise, which is often unrealistic in practice. In this work, we combine the two\nmethods, and propose to initialize AMP with PCA. Our main result is a rigorous\nasymptotic characterization of the performance of this estimator. Both the AMP\nalgorithm and its analysis differ from those previously derived in the Gaussian\nsetting: at every iteration, our AMP algorithm requires a specific term to\naccount for PCA initialization, while in the Gaussian case, PCA initialization\naffects only the first iteration of AMP. The proof is based on a two-phase\nartificial AMP that first approximates the PCA estimator and then mimics the\ntrue AMP. Our numerical simulations show an excellent agreement between AMP\nresults and theoretical predictions, and suggest an interesting open direction\non achieving Bayes-optimal performance.",
    "descriptor": "\nComments: 70 pages, 2 figures\n",
    "authors": [
      "Marco Mondelli",
      "Ramji Venkataramanan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.02356"
  },
  {
    "id": "arXiv:2106.02385",
    "title": "Controlling False Positive/Negative Rates for Deep-Learning-Based  Prostate Cancer Detection on Multiparametric MR images",
    "abstract": "Prostate cancer (PCa) is one of the leading causes of death for men\nworldwide. Multi-parametric magnetic resonance (mpMR) imaging has emerged as a\nnon-invasive diagnostic tool for detecting and localising prostate tumours by\nspecialised radiologists. These radiological examinations, for example, for\ndifferentiating malignant lesions from benign prostatic hyperplasia in\ntransition zones and for defining the boundaries of clinically significant\ncancer, remain challenging and highly skill-and-experience-dependent. We first\ninvestigate experimental results in developing object detection neural networks\nthat are trained to predict the radiological assessment, using these\nhigh-variance labels. We further argue that such a computer-assisted diagnosis\n(CAD) system needs to have the ability to control the false-positive rate (FPR)\nor false-negative rate (FNR), in order to be usefully deployed in a clinical\nworkflow, informing clinical decisions without further human intervention. This\nwork proposes a novel PCa detection network that incorporates a lesion-level\ncost-sensitive loss and an additional slice-level loss based on a\nlesion-to-slice mapping function, to manage the lesion- and slice-level costs,\nrespectively. Our experiments based on 290 clinical patients concludes that 1)\nThe lesion-level FNR was effectively reduced from 0.19 to 0.10 and the\nlesion-level FPR was reduced from 1.03 to 0.66 by changing the lesion-level\ncost; 2) The slice-level FNR was reduced from 0.19 to 0.00 by taking into\naccount the slice-level cost; (3) Both lesion-level and slice-level FNRs were\nreduced with lower FP/FPR by changing the lesion-level or slice-level costs,\ncompared with post-training threshold adjustment using networks without the\nproposed cost-aware training.",
    "descriptor": "\nComments: Accepted by 25th UK Conference on Medical Image Understanding and Analysis(MIUA 2021)\n",
    "authors": [
      "Zhe Min",
      "Fernando J. Bianco",
      "Qianye Yang",
      "Rachael Rodell",
      "Wen Yan",
      "Dean Barratt",
      "Yipeng Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02385"
  },
  {
    "id": "arXiv:2106.02391",
    "title": "Data-Driven Control Design with LMIs and Dynamic Programming",
    "abstract": "The goal of this paper is to develop data-driven control design and\nevaluation strategies based on linear matrix inequalities (LMIs) and dynamic\nprogramming. We consider deterministic discrete-time LTI systems, where the\nsystem model is unknown. We propose efficient data collection schemes from the\nstate-input trajectories together with data-driven LMIs to design\nstate-feedback controllers for stabilization and linear quadratic regulation\n(LQR) problem. In addition, we investigate theoretically guaranteed exploration\nschemes to acquire valid data from the trajectories under different scenarios.\nIn particular, we prove that as more and more data is accumulated, the\ncollected data becomes valid for the proposed algorithms with higher\nprobability. Finally, data-driven dynamic programming algorithms with\nconvergence guarantees are then discussed.",
    "descriptor": "",
    "authors": [
      "Donghwan Lee",
      "Do Wan Kim"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02391"
  },
  {
    "id": "arXiv:2106.02392",
    "title": "Ambulatory blood pressure monitoring versus office blood pressure  measurement: Are there sex differences?",
    "abstract": "The accurate measurement of blood pressure (BP) is an important prerequisite\nfor the reliable diagnosis and efficient management of hypertension and other\nmedical conditions. Office Blood Pressure Measurement (OBP) is a technique\nperformed in-office with the sphygmomanometer, while Ambulatory Blood Pressure\nMonitoring (ABPM) is a technique that measures blood pressure during 24h. The\nBP fluctuations also depend on other factors such as physical activity,\ntemperature, mood, age, sex, any pathologies, a hormonal activity that may\nintrinsically influence the differences between OBP and ABPM. The aim of this\nstudy is to examine the possible influence of sex on the discrepancies between\nOBP and ABPM in 872 subjects with known or suspected hypertension. A\nsignificant correlation was observed between OBP and ABPM mean values\ncalculated during the day, night and 24h (ABPMday, ABPMnight, ABPM24h) in both\ngroups (p<0.0001). The main finding of this study is that no difference between\nsexes was observed in the relation between OBP and mean ABMP values except\nbetween systolic OBP and systolic ABPM during the night. In addition, this\nstudy showed a moderate correlation between BPs obtained with the two\napproaches with a great dispersion around the regression line which suggests\nthat the two approaches cannot be used interchangeably.",
    "descriptor": "",
    "authors": [
      "Aleksandar Miladinovi\u0107",
      "Milo\u0161 Aj\u010devi\u0107",
      "Giulia Siveri",
      "Laura Liguori",
      "Lorenzo Pascazio",
      "Agostino Accardo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02392"
  },
  {
    "id": "arXiv:2106.02417",
    "title": "Approximate Fixed-Points in Recurrent Neural Networks",
    "abstract": "Recurrent neural networks are widely used in speech and language processing.\nDue to dependency on the past, standard algorithms for training these models,\nsuch as back-propagation through time (BPTT), cannot be efficiently\nparallelised. Furthermore, applying these models to more complex structures\nthan sequences requires inference time approximations, which introduce\ninconsistency between inference and training. This paper shows that recurrent\nneural networks can be reformulated as fixed-points of non-linear equation\nsystems. These fixed-points can be computed using an iterative algorithm\nexactly and in as many iterations as the length of any given sequence. Each\niteration of this algorithm adds one additional Markovian-like order of\ndependencies such that upon termination all dependencies modelled by the\nrecurrent neural networks have been incorporated. Although exact fixed-points\ninherit the same parallelization and inconsistency issues, this paper shows\nthat approximate fixed-points can be computed in parallel and used consistently\nin training and inference including tasks such as lattice rescoring.\nExperimental validation is performed in two tasks, Penn Tree Bank and\nWikiText-2, and shows that approximate fixed-points yield competitive\nprediction performance to recurrent neural networks trained using the BPTT\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Zhengxiong Wang",
      "Anton Ragni"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02417"
  },
  {
    "id": "arXiv:2106.02422",
    "title": "Classification of Audio Segments in Call Center Recordings using  Convolutional Recurrent Neural Networks",
    "abstract": "Detailed statistical analysis of call center recordings is critical in the\ncustomer relationship management point of view. With the recent advances in\nartificial intelligence, many tasks regarding the calculation of call\nstatistics are now performed automatically. This work proposes a neural network\nframework where the aim is to correctly identify audio segments and classify\nthem as either customer or agent sections. Accurately identifying these\nsections gives a fair metric for evaluating agents' performances. We inherited\nthe convolutional recurrent neural network (CRNN) architecture commonly used\nfor such problems as music genre classification. We also tested the same\narchitecture's performance, where the previous class information and the gender\ninformation of speakers are also added to the training data labels. We saw that\nCRNN could generalize the training data and perform well on validation data for\nthis problem with and without the gender information. Moreover, even the\ntraining was performed using Turkish speech samples; the trained network was\nproven to achieve high accuracy for call center recordings in other languages\nlike German and English.",
    "descriptor": "",
    "authors": [
      "\u015e\u00fckr\u00fc Ozan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.02422"
  },
  {
    "id": "arXiv:2106.02425",
    "title": "Stochastic and deterministic formulations for capacity firming  nominations",
    "abstract": "This paper addresses the energy management of a grid-connected photovoltaic\nplant coupled with a battery energy storage device, within the capacity firming\nspecifications of the French Energy Regulatory Commission. The paper\ncontributions are positioned in the continuity of the studies adopting\nstochastic models for optimizing the bids of renewable energy sources in a\nday-ahead market by considering a storage device. The proposed deterministic\nand stochastic approaches are optimization problems formulated as quadratic\nproblems with linear constraints. The case study is a real microgrid with PV\nproduction monitored on-site. The results demonstrate the validity of the\nstochastic formulation by using an ideal predictor that produces unbiased PV\nscenarios.",
    "descriptor": "",
    "authors": [
      "Jonathan Dumas",
      "Bertrand Corn\u00e9lusse",
      "Antonello Giannitrapani",
      "Simone Paoletti",
      "Antonio Vicino"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02425"
  },
  {
    "id": "arXiv:2106.02443",
    "title": "Teaching keyword spotters to spot new keywords with limited examples",
    "abstract": "Learning to recognize new keywords with just a few examples is essential for\npersonalizing keyword spotting (KWS) models to a user's choice of keywords.\nHowever, modern KWS models are typically trained on large datasets and\nrestricted to a small vocabulary of keywords, limiting their transferability to\na broad range of unseen keywords. Towards easily customizable KWS models, we\npresent KeySEM (Keyword Speech EMbedding), a speech embedding model pre-trained\non the task of recognizing a large number of keywords. Speech representations\noffered by KeySEM are highly effective for learning new keywords from a limited\nnumber of examples. Comparisons with a diverse range of related work across\nseveral datasets show that our method achieves consistently superior\nperformance with fewer training examples. Although KeySEM was pre-trained only\non English utterances, the performance gains also extend to datasets from four\nother languages indicating that KeySEM learns useful representations well\naligned with the task of keyword spotting. Finally, we demonstrate KeySEM's\nability to learn new keywords sequentially without requiring to re-train on\npreviously learned keywords. Our experimental observations suggest that KeySEM\nis well suited to on-device environments where post-deployment learning and\nease of customization are often desirable.",
    "descriptor": "\nComments: In INTERSPEECH 2021\n",
    "authors": [
      "Abhijeet Awasthi",
      "Kevin Kilgour",
      "Hassan Rom"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.02443"
  },
  {
    "id": "arXiv:2106.02480",
    "title": "Coupling of the phase field approach to the Armstrong-Frederick model  for the simulation of ductile damage under cyclic load",
    "abstract": "The present contribution proposes a thermodynamically consistent model for\nthe simulation of the ductile damage. The model couples the phase field method\nof fracture to the Armstrong-Frederick plasticity model with kinematic\nhardening. The latter is particularly suitable for simulating the material\nbehavior under a cyclic load. The model relies on the minimum principle of the\ndissipation potential. However, the application of this approach is challenging\nsince potentials of coupled methods are defined in different spaces: The\ndissipation potential of the phase field model is expressed in terms of rates\nof internal variables, whereas the Armstrong-Frederick model proposes a\nformulation depending on thermodynamic forces. For this reason, a unique\nformulation requires the Legendre transformation of one of the potentials. The\npresent work performs the transformation of the Armstrong-Frederick potential,\nsuch that final formulation is only expressed in the space of rates of internal\nvariables. With the assumption for the free energy and the joint dissipation\npotential at hand, the derivation of evolution equations is straightforward.\nThe application of the model is illustrated by selected numerical examples\nstudying the material response for different load constellations and sample\ngeometries. The paper provides a comparison with the experimental results as\nwell.",
    "descriptor": "",
    "authors": [
      "Serhat Ayg\u00fcn",
      "Tillmann Wiegold",
      "Sandra Klinge"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Numerical Analysis (math.NA)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.02480"
  },
  {
    "id": "arXiv:2106.02496",
    "title": "Quantum Perceptron Revisited: Computational-Statistical Tradeoffs",
    "abstract": "Quantum machine learning algorithms could provide significant speed-ups over\ntheir classical counterparts; however, whether they could also achieve good\ngeneralization remains unclear. Recently, two quantum perceptron models which\ngive a quadratic improvement over the classical perceptron algorithm using\nGrover's search have been proposed by Wiebe et al. arXiv:1602.04799 . While the\nfirst model reduces the complexity with respect to the size of the training\nset, the second one improves the bound on the number of mistakes made by the\nperceptron. In this paper, we introduce a hybrid quantum-classical perceptron\nalgorithm with lower complexity and better generalization ability than the\nclassical perceptron. We show a quadratic improvement over the classical\nperceptron in both the number of samples and the margin of the data. We derive\na bound on the expected error of the hypothesis returned by our algorithm,\nwhich compares favorably to the one obtained with the classical online\nperceptron. We use numerical experiments to illustrate the trade-off between\ncomputational complexity and statistical accuracy in quantum perceptron\nlearning and discuss some of the key practical issues surrounding the\nimplementation of quantum perceptron models into near-term quantum devices,\nwhose practical implementation represents a serious challenge due to inherent\nnoise. However, the potential benefits make correcting this worthwhile.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Mathieu Roget",
      "Giuseppe Di Molfetta",
      "Hachem Kadri"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02496"
  },
  {
    "id": "arXiv:2106.02512",
    "title": "Interdependence of Growth, Structure, Size and Resource Consumption  During an Economic Growth Cycle",
    "abstract": "All economies require physical resource consumption to grow and maintain\ntheir structure. The modern economy is additionally characterized by private\ndebt. The Human and Resources with MONEY (HARMONEY) economic growth model links\nthese features using a stock and flow consistent framework in physical and\nmonetary units. Via an updated version, we explore the interdependence of\ngrowth and three major structural metrics of an economy. First, we show that\nrelative decoupling of gross domestic product (GDP) from resource consumption\nis an expected pattern that occurs because of physical limits to growth, not a\nresponse to avoid physical limits. While an increase in resource efficiency of\noperating capital does increase the level of relative decoupling, so does a\nchange in pricing from one based on full costs to one based only on marginal\ncosts that neglects depreciation and interest payments leading to higher debt\nratios. Second, if assuming full labor bargaining power for wages, when a\npreviously-growing economy reaches peak resource extraction and GDP, wages\nremain high but profits and debt decline to zero. By removing bargaining power,\nprofits can remain positive at the expense of declining wages. Third, the\ndistribution of intermediate transactions within the input-output table of the\nmodel follows the same temporal pattern as in the post-World War II U.S.\neconomy. These results indicate that the HARMONEY framework enables realistic\ninvestigation of interdependent structural change and trade-offs between\neconomic distribution, size, and resources consumption.",
    "descriptor": "\nComments: 50 pages (26 manuscript, 24 appendix and supporting), 12 figures (8 manuscript, 4 supporting)\n",
    "authors": [
      "Carey W. King"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02512"
  },
  {
    "id": "arXiv:2106.02519",
    "title": "Consensus Based Sampling",
    "abstract": "We propose a novel method for sampling and optimization tasks based on a\nstochastic interacting particle system. We explain how this method can be used\nfor the following two goals: (i) generating approximate samples from a given\ntarget distribution; (ii) optimizing a given objective function. The approach\nis derivative-free and affine invariant, and is therefore well-suited for\nsolving inverse problems defined by complex forward models: (i) allows\ngeneration of samples from the Bayesian posterior and (ii) allows determination\nof the maximum a posteriori estimator. We investigate the properties of the\nproposed family of methods in terms of various parameter choices, both\nanalytically and by means of numerical simulations. The analysis and numerical\nsimulation establish that the method has potential for general purpose\noptimization tasks over Euclidean space; contraction properties of the\nalgorithm are established under suitable conditions, and computational\nexperiments demonstrate wide basins of attraction for various specific\nproblems. The analysis and experiments also demonstrate the potential for the\nsampling methodology in regimes in which the target distribution is unimodal\nand close to Gaussian; indeed we prove that the method recovers a Laplace\napproximation to the measure in certain parametric regimes and provide\nnumerical evidence that this Laplace approximation attracts a large set of\ninitial conditions in a number of examples.",
    "descriptor": "",
    "authors": [
      "J. A. Carrillo",
      "F. Hoffmann",
      "A. M. Stuart",
      "U. Vaes"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02519"
  },
  {
    "id": "arXiv:2106.02522",
    "title": "Price graphs: Utilizing the structural information of financial time  series for stock prediction",
    "abstract": "Stock prediction, with the purpose of forecasting the future price trends of\nstocks, is crucial for maximizing profits from stock investments. While great\nresearch efforts have been devoted to exploiting deep neural networks for\nimproved stock prediction, the existing studies still suffer from two major\nissues. First, the long-range dependencies in time series are not sufficiently\ncaptured. Second, the chaotic property of financial time series fundamentally\nlowers prediction performance. In this study, we propose a novel framework to\naddress both issues regarding stock prediction. Specifically, in terms of\ntransforming time series into complex networks, we convert market price series\ninto graphs. Then, structural information, referring to associations among\ntemporal points and the node weights, is extracted from the mapped graphs to\nresolve the problems regarding long-range dependencies and the chaotic\nproperty. We take graph embeddings to represent the associations among temporal\npoints as the prediction model inputs. Node weights are used as a priori\nknowledge to enhance the learning of temporal attention. The effectiveness of\nour proposed framework is validated using real-world stock data, and our\napproach obtains the best performance among several state-of-the-art\nbenchmarks. Moreover, in the conducted trading simulations, our framework\nfurther obtains the highest cumulative profits. Our results supplement the\nexisting applications of complex network methods in the financial realm and\nprovide insightful implications for investment applications regarding decision\nsupport in financial markets.",
    "descriptor": "",
    "authors": [
      "Junran Wu",
      "Ke Xu",
      "Xueyuan Chen",
      "Shangzhe Li",
      "Jichang Zhao"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02522"
  },
  {
    "id": "arXiv:2106.02528",
    "title": "Neural Network Surrogate Models for Absorptivity and Emissivity Spectra  of Multiple Elements",
    "abstract": "Simulations of high energy density physics are expensive in terms of\ncomputational resources. In particular, the computation of opacities of\nplasmas, which are needed to accurately compute radiation transport in the\nnon-local thermal equilibrium (NLTE) regime, are expensive to the point of\neasily requiring multiple times the sum-total compute time of all other\ncomponents of the simulation. As such, there is great interest in finding ways\nto accelerate NLTE computations. Previous work has demonstrated that a\ncombination of fully-connected autoencoders and a deep jointly-informed neural\nnetwork (DJINN) can successfully replace the standard NLTE calculations for the\nopacity of krypton. This work expands this idea to multiple elements in\ndemonstrating that individual surrogate models can be also be generated for\nother elements with the focus being on creating autoencoders that can\naccurately encode and decode the absorptivity and emissivity spectra.\nFurthermore, this work shows that multiple elements across a large range of\natomic numbers can be combined into a single autoencoder when using a\nconvolutional autoencoder while maintaining accuracy that is comparable to\nindividual fully-connected autoencoders. Lastly, it is demonstrated that DJINN\ncan effectively learn the latent space of a convolutional autoencoder that can\nencode multiple elements allowing the combination to effectively function as a\nsurrogate model.",
    "descriptor": "\nComments: Elsevier Review Format, Double Spaced, 26 pages, 10 figures, 5 tables Michael D. Vander Wal: conceptualization, investigation, writing - original draft, writing - editing and review. Ryan G. McClarren - conceptualization, writing - editing and review. Kelli D. Humbird: conceptualization, writing - editing and review\n",
    "authors": [
      "Michael D. Vander Wal",
      "Ryan G. McClarren",
      "Kelli D. Humbird"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02528"
  },
  {
    "id": "arXiv:2106.02548",
    "title": "Coordination problems on networks revisited: statics and dynamics",
    "abstract": "Simple binary-state coordination models are widely used to study collective\nsocio-economic phenomena such as the spread of innovations or the adoption of\nproducts on social networks. The common trait of these systems is the\noccurrence of large-scale coordination events taking place abruptly, in the\nform of a cascade process, as a consequence of small perturbations of an\napparently stable state. The conditions for the occurrence of cascade\ninstabilities have been largely analysed in the literature, however for the\nsame coordination models no sufficient attention was given to the relation\nbetween structural properties of (Nash) equilibria and possible outcomes of\ndynamical equilibrium selection. Using methods from the statistical physics of\ndisordered systems, the present work investigates both analytically and\nnumerically, the statistical properties of such Nash equilibria on networks,\nfocusing mostly on random graphs. We provide an accurate description of these\nproperties, which is then exploited to shed light on the mechanisms behind the\nonset of coordination/miscoordination on large networks. This is done studying\nthe most common processes of dynamical equilibrium selection, such as best\nresponse, bounded-rational dynamics and learning processes. In particular, we\nshow that well beyond the instability region, full coordination is still\nglobally stochastically stable, however equilibrium selection processes with\nlow stochasticity (e.g. best response) or strong memory effects (e.g.\nreinforcement learning) can be prevented from achieving full coordination by\nbeing trapped into a large (exponentially in number of agents) set of locally\nstable Nash equilibria at low/medium coordination (inefficient equilibria).\nThese results should be useful to allow a better understanding of general\ncoordination problems on complex networks.",
    "descriptor": "\nComments: Revtex style, 56 pages, 21 figures\n",
    "authors": [
      "Luca Dall'Asta"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.02548"
  },
  {
    "id": "arXiv:2106.02599",
    "title": "SOUP-GAN: Super-Resolution MRI Using Generative Adversarial Networks",
    "abstract": "There is a growing demand for high-resolution (HR) medical images in both the\nclinical and research applications. Image quality is inevitably traded off with\nthe acquisition time for better patient comfort, lower examination costs, dose,\nand fewer motion-induced artifacts. For many image-based tasks, increasing the\napparent resolution in the perpendicular plane to produce multi-planar\nreformats or 3D images is commonly used. Single image super-resolution (SR) is\na promising technique to provide HR images based on unsupervised learning to\nincrease resolution of a 2D image, but there are few reports on 3D SR. Further,\nperceptual loss is proposed in the literature to better capture the textual\ndetails and edges than using pixel-wise loss functions, by comparing the\nsemantic distances in the high-dimensional feature space of a pre-trained 2D\nnetwork (e.g., VGG). However, it is not clear how one should generalize it to\n3D medical images, and the attendant implications are still unclear. In this\npaper, we propose a framework called SOUP-GAN: Super-resolution Optimized Using\nPerceptual-tuned Generative Adversarial Network (GAN), in order to produce\nthinner slice (e.g., high resolution in the 'Z' plane) medical images with\nanti-aliasing and deblurring. The proposed method outperforms other\nconventional resolution-enhancement methods and previous SR work on medical\nimages upon both qualitative and quantitative comparisons. Specifically, we\nexamine the model in terms of its generalization for various SR ratios and\nimaging modalities. By addressing those limitations, our model shows promise as\na novel 3D SR interpolation technique, providing potential applications in both\nclinical and research settings.",
    "descriptor": "\nComments: 10 pages, 11 figures\n",
    "authors": [
      "Kuan Zhang",
      "Haoji Hu",
      "Kenneth Philbrick",
      "Gian Marco Conte",
      "Joseph D. Sobek",
      "Pouria Rouzrokh",
      "Bradley J. Erickson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02599"
  },
  {
    "id": "arXiv:2106.02601",
    "title": "Learning Hard Optimization Problems: A Data Generation Perspective",
    "abstract": "Optimization problems are ubiquitous in our societies and are present in\nalmost every segment of the economy. Most of these optimization problems are\nNP-hard and computationally demanding, often requiring approximate solutions\nfor large-scale instances. Machine learning frameworks that learn to\napproximate solutions to such hard optimization problems are a potentially\npromising avenue to address these difficulties, particularly when many closely\nrelated problem instances must be solved repeatedly. Supervised learning\nframeworks can train a model using the outputs of pre-solved instances.\nHowever, when the outputs are themselves approximations, when the optimization\nproblem has symmetric solutions, and/or when the solver uses randomization,\nsolutions to closely related instances may exhibit large differences and the\nlearning task can become inherently more difficult. This paper demonstrates\nthis critical challenge, connects the volatility of the training data to the\nability of a model to approximate it, and proposes a method for producing\n(exact or approximate) solutions to optimization problems that are more\namenable to supervised learning tasks. The effectiveness of the method is\ntested on hard non-linear nonconvex and discrete combinatorial problems.",
    "descriptor": "",
    "authors": [
      "James Kotary",
      "Ferdinando Fioretto",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02601"
  },
  {
    "id": "arXiv:2106.02609",
    "title": "SBML2Modelica: integrating biochemical models within open-standard  simulation ecosystems",
    "abstract": "Motivation: SBML is the most widespread language for the definition of\nbiochemical models. Although dozens of SBML simulators are available, there is\na general lack of support to the integration of SBML models within\nopen-standard general-purpose simulation ecosystems. This hinders co-simulation\nand integration of SBML models within larger model networks, in order to, e.g.\nenable in silico clinical trials of drugs, pharmacological protocols, or\nengineering artefacts such as biomedical devices against Virtual Physiological\nHuman models. Modelica is one of the most popular existing open-standard\ngeneral-purpose simulation languages, supported by many simulators. Modelica\nmodels are especially suited for the definition of complex networks of\nheterogeneous models from virtually all application domains. Models written in\nModelica (and in 100+ other languages) can be readily exported into black-box\nFunctional Mock-Up Units (FMUs), and seamlessly co-simulated and integrated\ninto larger model networks within open-standard language-independent simulation\necosystems.\nResults: In order to enable SBML model integration within heterogeneous model\nnetworks, we present SBML2Modelica, a software system translating SBML models\ninto well-structured, user-intelligible, easily modifiable Modelica models.\nSBML2Modelica is SBML Level 3 Version 2-compliant and succeeds on 96.47% of the\nSBML Test Suite Core (with a few rare, intricate and easily avoidable\ncombinations of constructs unsupported and cleanly signalled to the user). Our\nexperimental campaign on 613 models from the BioModels database (with up to\n5438 variables) shows that the major open-source (general-purpose) Modelica and\nFMU simulators achieve performance comparable to state-of-the-art specialized\nSBML simulators.\nAvailability and implementation: https://bitbucket.org/mclab/sbml2modelica",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Filippo Maggioli",
      "Toni Mancini",
      "Enrico Tronci"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2106.02609"
  },
  {
    "id": "arXiv:2106.02613",
    "title": "Beyond Target Networks: Improving Deep $Q$-learning with Functional  Regularization",
    "abstract": "Target networks are at the core of recent success in Reinforcement Learning.\nThey stabilize the training by using old parameters to estimate the $Q$-values,\nbut this also limits the propagation of newly-encountered rewards which could\nultimately slow down the training. In this work, we propose an alternative\ntraining method based on functional regularization which does not have this\ndeficiency. Unlike target networks, our method uses up-to-date parameters to\nestimate the target $Q$-values, thereby speeding up training while maintaining\nstability. Surprisingly, in some cases, we can show that target networks are a\nspecial, restricted type of functional regularizers. Using this approach, we\nshow empirical improvements in sample efficiency and performance across a range\nof Atari and simulated robotics environments.",
    "descriptor": "",
    "authors": [
      "Alexandre Pich\u00e9",
      "Joseph Marino",
      "Gian Maria Marconi",
      "Christopher Pal",
      "Mohammad Emtiyaz Khan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02613"
  },
  {
    "id": "arXiv:2106.02626",
    "title": "Extreme sparsity gives rise to functional specialization",
    "abstract": "Modularity of neural networks -- both biological and artificial -- can be\nthought of either structurally or functionally, and the relationship between\nthese is an open question. We show that enforcing structural modularity via\nsparse connectivity between two dense sub-networks which need to communicate to\nsolve the task leads to functional specialization of the sub-networks, but only\nat extreme levels of sparsity. With even a moderate number of interconnections,\nthe sub-networks become functionally entangled. Defining functional\nspecialization is in itself a challenging problem without a universally agreed\nsolution. To address this, we designed three different measures of\nspecialization (based on weight masks, retraining and correlation) and found\nthem to qualitatively agree. Our results have implications in both neuroscience\nand machine learning. For neuroscience, it shows that we cannot conclude that\nthere is functional modularity simply by observing moderate levels of\nstructural modularity: knowing the brain's connectome is not sufficient for\nunderstanding how it breaks down into functional modules. For machine learning,\nusing structure to promote functional modularity -- which may be important for\nrobustness and generalization -- may require extremely narrow bottlenecks\nbetween modules.",
    "descriptor": "\nComments: 12 pages, 4 figures, Preprint (submitted to Neurips 2021)\n",
    "authors": [
      "Gabriel B\u00e9na",
      "Dan F. M. Goodman"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.02626"
  },
  {
    "id": "arXiv:2106.02630",
    "title": "Fundamental tradeoffs between memorization and robustness in random  features and neural tangent regimes",
    "abstract": "This work studies the (non)robustness of two-layer neural networks in various\nhigh-dimensional linearized regimes. We establish fundamental trade-offs\nbetween memorization and robustness, as measured by the Sobolev-seminorm of the\nmodel w.r.t the data distribution, i.e the square root of the average squared\n$L_2$-norm of the gradients of the model w.r.t the its input. More precisely,\nif $n$ is the number of training examples, $d$ is the input dimension, and $k$\nis the number of hidden neurons in a two-layer neural network, we prove for a\nlarge class of activation functions that, if the model memorizes even a\nfraction of the training, then its Sobolev-seminorm is lower-bounded by (i)\n$\\sqrt{n}$ in case of infinite-width random features (RF) or neural tangent\nkernel (NTK) with $d \\gtrsim n$; (ii) $\\sqrt{n}$ in case of finite-width RF\nwith proportionate scaling of $d$ and $k$; and (iii) $\\sqrt{n/k}$ in case of\nfinite-width NTK with proportionate scaling of $d$ and $k$. Moreover, all of\nthese lower-bounds are tight: they are attained by the min-norm / least-squares\ninterpolator (when $n$, $d$, and $k$ are in the appropriate interpolating\nregime). All our results hold as soon as data is log-concave isotropic, and\nthere is label-noise, i.e the target variable is not a deterministic function\nof the data / features. We empirically validate our theoretical results with\nexperiments. Accidentally, these experiments also reveal for the first time,\n(iv) a multiple-descent phenomenon in the robustness of the min-norm\ninterpolator.",
    "descriptor": "",
    "authors": [
      "Elvis Dohmatob"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02630"
  },
  {
    "id": "arXiv:1809.08979",
    "title": "Input-tailored system-theoretic model order reduction for  quadratic-bilinear systems",
    "abstract": "Input-tailored system-theoretic model order reduction for  quadratic-bilinear systems",
    "descriptor": "",
    "authors": [
      "Bj\u00f6rn Liljegren-Sailer",
      "Nicole Marheineke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1809.08979"
  },
  {
    "id": "arXiv:1901.03627",
    "title": "Destroying Bicolored $P_3$s by Deleting Few Edges",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Niels Gr\u00fcttemeier",
      "Christian Komusiewicz",
      "Jannik Schestag",
      "Frank Sommer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1901.03627"
  },
  {
    "id": "arXiv:1903.11582",
    "title": "SLOPE for Sparse Linear Regression:Asymptotics and Optimal  Regularization",
    "abstract": "SLOPE for Sparse Linear Regression:Asymptotics and Optimal  Regularization",
    "descriptor": "",
    "authors": [
      "Hong Hu",
      "Yue M. Lu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/1903.11582"
  },
  {
    "id": "arXiv:1905.02515",
    "title": "Guided Visual Exploration of Relations in Data Sets",
    "abstract": "Comments: 32 pages, 13 figures. arXiv admin note: substantial text overlap with arXiv:1805.07725",
    "descriptor": "\nComments: 32 pages, 13 figures. arXiv admin note: substantial text overlap with arXiv:1805.07725\n",
    "authors": [
      "Kai Puolam\u00e4ki",
      "Emilia Oikarinen",
      "Andreas Henelius"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1905.02515"
  },
  {
    "id": "arXiv:1905.04325",
    "title": "Seeding with Costly Network Information",
    "abstract": "Seeding with Costly Network Information",
    "descriptor": "",
    "authors": [
      "Dean Eckles",
      "Hossein Esfandiari",
      "Elchanan Mossel",
      "M. Amin Rahimian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Complexity (cs.CC)",
      "Probability (math.PR)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/1905.04325"
  },
  {
    "id": "arXiv:1905.09997",
    "title": "Painless Stochastic Gradient: Interpolation, Line-Search, and  Convergence Rates",
    "abstract": "Comments: Added a citation to the related work of Paul Tseng, and citations to methods that had previously explored line-searches for deep learning empirically",
    "descriptor": "\nComments: Added a citation to the related work of Paul Tseng, and citations to methods that had previously explored line-searches for deep learning empirically\n",
    "authors": [
      "Sharan Vaswani",
      "Aaron Mishkin",
      "Issam Laradji",
      "Mark Schmidt",
      "Gauthier Gidel",
      "Simon Lacoste-Julien"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.09997"
  },
  {
    "id": "arXiv:1908.04680",
    "title": "Effective Training of Convolutional Neural Networks with Low-bitwidth  Weights and Activations",
    "abstract": "Comments: Accepted to IEEE T. Pattern Analysis and Machine Intelligence (TPAMI). Extended version of arXiv:1711.00205 (CVPR 2018)",
    "descriptor": "\nComments: Accepted to IEEE T. Pattern Analysis and Machine Intelligence (TPAMI). Extended version of arXiv:1711.00205 (CVPR 2018)\n",
    "authors": [
      "Bohan Zhuang",
      "Jing Liu",
      "Mingkui Tan",
      "Lingqiao Liu",
      "Ian Reid",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1908.04680"
  },
  {
    "id": "arXiv:1909.03664",
    "title": "Learning How to Dynamically Route Autonomous Vehicles on Shared Roads",
    "abstract": "Comments: Accepted to Transportation Research Part C",
    "descriptor": "\nComments: Accepted to Transportation Research Part C\n",
    "authors": [
      "Daniel A. Lazar",
      "Erdem B\u0131y\u0131k",
      "Dorsa Sadigh",
      "Ramtin Pedarsani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1909.03664"
  },
  {
    "id": "arXiv:1911.01296",
    "title": "Serverless Computing: A Survey of Opportunities, Challenges and  Applications",
    "abstract": "Comments: 27 pages, 3 figures",
    "descriptor": "\nComments: 27 pages, 3 figures\n",
    "authors": [
      "Hossein Shafiei",
      "Ahmad Khonsari",
      "Payam Mousavi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/1911.01296"
  },
  {
    "id": "arXiv:1912.11375",
    "title": "Diffuse optical tomography by simulated annealing via a spin Hamiltonian",
    "abstract": "Diffuse optical tomography by simulated annealing via a spin Hamiltonian",
    "descriptor": "",
    "authors": [
      "Yu Jiang",
      "Manabu Machida",
      "Norikazu Todoroki"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/1912.11375"
  },
  {
    "id": "arXiv:1912.11603",
    "title": "Image Enhanced Rotation Prediction for Self-Supervised Learning",
    "abstract": "Comments: Accepted to IEEE ICIP 2021. The title has been changed from \"Multiple Pretext-Task for Self-Supervised Learning via Mixing Multiple Image Transformations\"",
    "descriptor": "\nComments: Accepted to IEEE ICIP 2021. The title has been changed from \"Multiple Pretext-Task for Self-Supervised Learning via Mixing Multiple Image Transformations\"\n",
    "authors": [
      "Shin'ya Yamaguchi",
      "Sekitoshi Kanai",
      "Tetsuya Shioda",
      "Shoichiro Takeda"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1912.11603"
  },
  {
    "id": "arXiv:2001.03813",
    "title": "Fundamental Limits of Prediction, Generalization, and Recursion: An  Entropic-Innovations Perspective",
    "abstract": "Comments: Note that this is an extended version of the original submission \"Fundamental Limits of Online Learning: An Entropic-Innovations Viewpoint\"; arXiv admin note: text overlap with arXiv:1912.05541, arXiv:1912.02628",
    "descriptor": "\nComments: Note that this is an extended version of the original submission \"Fundamental Limits of Online Learning: An Entropic-Innovations Viewpoint\"; arXiv admin note: text overlap with arXiv:1912.05541, arXiv:1912.02628\n",
    "authors": [
      "Song Fang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.03813"
  },
  {
    "id": "arXiv:2001.07547",
    "title": "Task-Priority Control of Redundant Robotic Systems using Control  Lyapunov and Control Barrier Function based Quadratic Programs",
    "abstract": "Comments: 21st IFAC World Congress",
    "descriptor": "\nComments: 21st IFAC World Congress\n",
    "authors": [
      "Erlend A. Basso",
      "Kristin Y. Pettersen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2001.07547"
  },
  {
    "id": "arXiv:2001.11628",
    "title": "Domain-Adversarial and Conditional State Space Model for Imitation  Learning",
    "abstract": "Comments: Published at IROS 2020",
    "descriptor": "\nComments: Published at IROS 2020\n",
    "authors": [
      "Ryo Okumura",
      "Masashi Okada",
      "Tadahiro Taniguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.11628"
  },
  {
    "id": "arXiv:2002.02215",
    "title": "A Two-Stage Optimization-based Motion Planner for Safe Urban Driving",
    "abstract": "Comments: IEEE Transactions on Robotics (T-RO), 2021",
    "descriptor": "\nComments: IEEE Transactions on Robotics (T-RO), 2021\n",
    "authors": [
      "Francisco Eiras",
      "Majd Hawasly",
      "Stefano V. Albrecht",
      "Subramanian Ramamoorthy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2002.02215"
  },
  {
    "id": "arXiv:2002.02518",
    "title": "Provably Efficient Online Hyperparameter Optimization with  Population-Based Bandits",
    "abstract": "Comments: Camera-ready version, NeurIPS 2020",
    "descriptor": "\nComments: Camera-ready version, NeurIPS 2020\n",
    "authors": [
      "Jack Parker-Holder",
      "Vu Nguyen",
      "Stephen Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.02518"
  },
  {
    "id": "arXiv:2002.06799",
    "title": "Equivalence of Dataflow Graphs via Rewrite Rules Using a  Graph-to-Sequence Neural Model",
    "abstract": "Comments: 20 pages including references and appendices, 10 figures, updated to include acknowledgement",
    "descriptor": "\nComments: 20 pages including references and appendices, 10 figures, updated to include acknowledgement\n",
    "authors": [
      "Steve Kommrusch",
      "Th\u00e9o Barollet",
      "Louis-No\u00ebl Pouchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.06799"
  },
  {
    "id": "arXiv:2002.08014",
    "title": "Communication-Efficient Distributed SVD via Local Power Iterations",
    "abstract": "Comments: 9 pages, 7 figures, accepted by 2021 ICML",
    "descriptor": "\nComments: 9 pages, 7 figures, accepted by 2021 ICML\n",
    "authors": [
      "Xiang Li",
      "Shusen Wang",
      "Kun Chen",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2002.08014"
  },
  {
    "id": "arXiv:2003.01384",
    "title": "Relevance-Guided Modeling of Object Dynamics for Reinforcement Learning",
    "abstract": "Relevance-Guided Modeling of Object Dynamics for Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "William Agnew",
      "Pedro Domingos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.01384"
  },
  {
    "id": "arXiv:2003.10130",
    "title": "Incomplete Graph Representation and Learning via Partial Graph Neural  Networks",
    "abstract": "Incomplete Graph Representation and Learning via Partial Graph Neural  Networks",
    "descriptor": "",
    "authors": [
      "Bo Jiang",
      "Ziyan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.10130"
  },
  {
    "id": "arXiv:2003.10360",
    "title": "Bayesian Models Applied to Cyber Security Anomaly Detection Problems",
    "abstract": "Bayesian Models Applied to Cyber Security Anomaly Detection Problems",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 A. Perusqu\u00eda",
      "Jim E. Griffin",
      "Cristiano Villa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2003.10360"
  },
  {
    "id": "arXiv:2004.00992",
    "title": "Incorporating travel behavior regularity into passenger flow forecasting",
    "abstract": "Incorporating travel behavior regularity into passenger flow forecasting",
    "descriptor": "",
    "authors": [
      "Zhanhong Cheng",
      "Martin Trepanier",
      "Lijun Sun"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2004.00992"
  },
  {
    "id": "arXiv:2004.03238",
    "title": "Improving the Robustness of QA Models to Challenge Sets with Variational  Question-Answer Pair Generation",
    "abstract": "Comments: ACL-IJCNLP 2021 SRW",
    "descriptor": "\nComments: ACL-IJCNLP 2021 SRW\n",
    "authors": [
      "Kazutoshi Shinoda",
      "Saku Sugawara",
      "Akiko Aizawa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2004.03238"
  },
  {
    "id": "arXiv:2004.07774",
    "title": "Computing all identifiable functions of parameters for ODE models",
    "abstract": "Computing all identifiable functions of parameters for ODE models",
    "descriptor": "",
    "authors": [
      "Alexey Ovchinnikov",
      "Anand Pillay",
      "Gleb Pogudin",
      "Thomas Scanlon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Symbolic Computation (cs.SC)",
      "Logic (math.LO)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2004.07774"
  },
  {
    "id": "arXiv:2004.09424",
    "title": "Learning a Fine-Grained Review-based Transformer Model for Personalized  Product Search",
    "abstract": "Comments: To appear in SIGIR'2021",
    "descriptor": "\nComments: To appear in SIGIR'2021\n",
    "authors": [
      "Keping Bi",
      "Qingyao Ai",
      "W. Bruce Croft"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2004.09424"
  },
  {
    "id": "arXiv:2004.13631",
    "title": "KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization  and Completion",
    "abstract": "Comments: Findings of ACL 2021",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Jie Zhou",
      "Shengding Hu",
      "Xin Lv",
      "Cheng Yang",
      "Zhiyuan Liu",
      "Wei Xu",
      "Jie Jiang",
      "Juanzi Li",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2004.13631"
  },
  {
    "id": "arXiv:2005.02315",
    "title": "Multi-interactive Dual-decoder for RGB-thermal Salient Object Detection",
    "abstract": "Comments: Accepted by IEEE TIP",
    "descriptor": "\nComments: Accepted by IEEE TIP\n",
    "authors": [
      "Zhengzheng Tu",
      "Zhun Li",
      "Chenglong Li",
      "Yang Lang",
      "Jin Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.02315"
  },
  {
    "id": "arXiv:2005.04310",
    "title": "Semi-Supervised Multi-aspect Detection of Misinformation using  Hierarchical Joint Decomposition",
    "abstract": "Semi-Supervised Multi-aspect Detection of Misinformation using  Hierarchical Joint Decomposition",
    "descriptor": "",
    "authors": [
      "Sara Abdali",
      "Neil Shah",
      "Evangelos E. Papalexakis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.04310"
  },
  {
    "id": "arXiv:2005.07107",
    "title": "Natural Way to Overcome the Catastrophic Forgetting in Neural Networks",
    "abstract": "Comments: 9 pages, 3 figures",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Alexey Kutalev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.07107"
  },
  {
    "id": "arXiv:2005.08795",
    "title": "From Symmetric to Asymmetric Asynchronous Byzantine Consensus",
    "abstract": "From Symmetric to Asymmetric Asynchronous Byzantine Consensus",
    "descriptor": "",
    "authors": [
      "Christian Cachin",
      "Luca Zanolini"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2005.08795"
  },
  {
    "id": "arXiv:2005.14674",
    "title": "Maximal Spaces for Approximation Rates in $\\ell^1$-regularization",
    "abstract": "Maximal Spaces for Approximation Rates in $\\ell^1$-regularization",
    "descriptor": "",
    "authors": [
      "Philip Miller",
      "Thorsten Hohage"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2005.14674"
  },
  {
    "id": "arXiv:2006.01350",
    "title": "On the Estimation of Derivatives Using Plug-in KRR Estimators",
    "abstract": "On the Estimation of Derivatives Using Plug-in KRR Estimators",
    "descriptor": "",
    "authors": [
      "Zejian Liu",
      "Meng Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2006.01350"
  },
  {
    "id": "arXiv:2006.01958",
    "title": "Nucleus Decomposition in Probabilistic Graphs: Hardness and Algorithms",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Fatemeh Esfahani",
      "Venkatesh Srinivasan",
      "Alex Thomo",
      "Kui Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2006.01958"
  },
  {
    "id": "arXiv:2006.03340",
    "title": "MANTRA: Memory Augmented Networks for Multiple Trajectory Prediction",
    "abstract": "Comments: Accepted at CVPR20",
    "descriptor": "\nComments: Accepted at CVPR20\n",
    "authors": [
      "Francesco Marchetti",
      "Federico Becattini",
      "Lorenzo Seidenari",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2006.03340"
  },
  {
    "id": "arXiv:2006.05022",
    "title": "Near-Optimal Confidence Sequences for Bounded Random Variables",
    "abstract": "Comments: Accepted to ICML 2021",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Arun Kumar Kuchibhotla",
      "Qinqing Zheng"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05022"
  },
  {
    "id": "arXiv:2006.05982",
    "title": "Representation formulas and pointwise properties for Barron functions",
    "abstract": "Representation formulas and pointwise properties for Barron functions",
    "descriptor": "",
    "authors": [
      "Weinan E",
      "Stephan Wojtowytsch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2006.05982"
  },
  {
    "id": "arXiv:2006.07038",
    "title": "Learning Graph Models for Retrosynthesis Prediction",
    "abstract": "Learning Graph Models for Retrosynthesis Prediction",
    "descriptor": "",
    "authors": [
      "Vignesh Ram Somnath",
      "Charlotte Bunne",
      "Connor W. Coley",
      "Andreas Krause",
      "Regina Barzilay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07038"
  },
  {
    "id": "arXiv:2006.09264",
    "title": "Bonsai-Net: One-Shot Neural Architecture Search via Differentiable  Pruners",
    "abstract": "Comments: Accepted to CVPR-NAS 2020. this https URL",
    "descriptor": "\nComments: Accepted to CVPR-NAS 2020. this https URL\n",
    "authors": [
      "Rob Geada",
      "Dennis Prangle",
      "Andrew Stephen McGough"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.09264"
  },
  {
    "id": "arXiv:2006.12376",
    "title": "A Convergent and Dimension-Independent First-Order Algorithm for Min-Max  Optimization",
    "abstract": "A Convergent and Dimension-Independent First-Order Algorithm for Min-Max  Optimization",
    "descriptor": "",
    "authors": [
      "Vijay Keswani",
      "Oren Mangoubi",
      "Sushant Sachdeva",
      "Nisheeth K. Vishnoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.12376"
  },
  {
    "id": "arXiv:2006.12748",
    "title": "Approximation Algorithms for Sparse Principal Component Analysis",
    "abstract": "Approximation Algorithms for Sparse Principal Component Analysis",
    "descriptor": "",
    "authors": [
      "Agniva Chowdhury",
      "Petros Drineas",
      "David P. Woodruff",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.12748"
  },
  {
    "id": "arXiv:2007.10538",
    "title": "Regularizing Deep Networks with Semantic Data Augmentation",
    "abstract": "Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI). Journal version of arXiv:1909.12220 (NeurIPS 2019). Code is available at this https URL",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI). Journal version of arXiv:1909.12220 (NeurIPS 2019). Code is available at this https URL\n",
    "authors": [
      "Yulin Wang",
      "Gao Huang",
      "Shiji Song",
      "Xuran Pan",
      "Yitong Xia",
      "Cheng Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.10538"
  },
  {
    "id": "arXiv:2008.02071",
    "title": "Persistent Homology in $\\ell_{\\infty}$ Metric",
    "abstract": "Comments: 36 pages, 15 figures",
    "descriptor": "\nComments: 36 pages, 15 figures\n",
    "authors": [
      "Gabriele Beltramo",
      "Primoz Skraba"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2008.02071"
  },
  {
    "id": "arXiv:2008.03309",
    "title": "Alert Classification for the ALeRCE Broker System: The Real-time Stamp  Classifier",
    "abstract": "Comments: Submitted to AAS on Jun 30th. Comments welcome",
    "descriptor": "\nComments: Submitted to AAS on Jun 30th. Comments welcome\n",
    "authors": [
      "Rodrigo Carrasco-Davis",
      "Esteban Reyes",
      "Camilo Valenzuela",
      "Francisco F\u00f6rster",
      "Pablo A. Est\u00e9vez",
      "Giuliano Pignata",
      "Franz E. Bauer",
      "Ignacio Reyes",
      "Paula S\u00e1nchez-S\u00e1ez",
      "Guillermo Cabrera-Vives",
      "Susana Eyheramendy",
      "M\u00e1rcio Catelan",
      "Javier Arredondo",
      "Ernesto Castillo-Navarrete",
      "Diego Rodr\u00edguez-Mancini",
      "Daniela Ruz-Mieres",
      "Alberto Moya",
      "Luis Sabatini-Gacit\u00faa",
      "Crist\u00f3bal Sep\u00falveda-Cobo",
      "Ashish A. Mahabal",
      "Javier Silva-Farf\u00e1n",
      "Ernesto Camacho-I\u00f1iquez",
      "Llu\u00eds Galbany"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.03309"
  },
  {
    "id": "arXiv:2008.05742",
    "title": "SkeletonNet: A Topology-Preserving Solution for Learning Mesh  Reconstruction of Object Surfaces from RGB Images",
    "abstract": "Comments: 17 pages, 13 figures; TPAMI 2021",
    "descriptor": "\nComments: 17 pages, 13 figures; TPAMI 2021\n",
    "authors": [
      "Jiapeng Tang",
      "Xiaoguang Han",
      "Mingkui Tan",
      "Xin Tong",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.05742"
  },
  {
    "id": "arXiv:2008.08264",
    "title": "Intelligent Radio Signal Processing: A Survey",
    "abstract": "Comments: Accepted for publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: Accepted for publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Quoc-Viet Pham",
      "Nhan Thanh Nguyen",
      "Thien Huynh-The",
      "Long Bao Le",
      "Kyungchun Lee",
      "Won-Joo Hwang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2008.08264"
  },
  {
    "id": "arXiv:2008.10460",
    "title": "Online Convex Optimization Perspective for Learning from Dynamically  Revealed Preferences",
    "abstract": "Comments: 34 pages, 9 figures",
    "descriptor": "\nComments: 34 pages, 9 figures\n",
    "authors": [
      "Violet Xinying Chen",
      "Fatma K\u0131l\u0131n\u00e7-Karzan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.10460"
  },
  {
    "id": "arXiv:2008.10715",
    "title": "Certified Robustness of Graph Neural Networks against Adversarial  Structural Perturbation",
    "abstract": "Comments: Accepted by ACM SIGKDD'21",
    "descriptor": "\nComments: Accepted by ACM SIGKDD'21\n",
    "authors": [
      "Binghui Wang",
      "Jinyuan Jia",
      "Xiaoyu Cao",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2008.10715"
  },
  {
    "id": "arXiv:2008.12256",
    "title": "BSF-skeleton: A Template for Parallelization of Iterative Numerical  Algorithms on Cluster Computing Systems",
    "abstract": "Comments: Submitted to MethodsX",
    "descriptor": "\nComments: Submitted to MethodsX\n",
    "authors": [
      "Leonid B. Sokolinsky"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2008.12256"
  },
  {
    "id": "arXiv:2009.02551",
    "title": "Performance Analysis and User Association Optimization for Wireless  Network Aided by Multiple Intelligent Reflecting Surfaces",
    "abstract": "Comments: 16 pages, 10 figures. Accepted for publication by IEEE Transactions on Communications",
    "descriptor": "\nComments: 16 pages, 10 figures. Accepted for publication by IEEE Transactions on Communications\n",
    "authors": [
      "Weidong Mei",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2009.02551"
  },
  {
    "id": "arXiv:2009.04875",
    "title": "Importance Weighted Policy Learning and Adaptation",
    "abstract": "Importance Weighted Policy Learning and Adaptation",
    "descriptor": "",
    "authors": [
      "Alexandre Galashov",
      "Jakub Sygnowski",
      "Guillaume Desjardins",
      "Jan Humplik",
      "Leonard Hasenclever",
      "Rae Jeong",
      "Yee Whye Teh",
      "Nicolas Heess"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.04875"
  },
  {
    "id": "arXiv:2009.04960",
    "title": "Prototype Completion with Primitive Knowledge for Few-Shot Learning",
    "abstract": "Comments: Accepted by CVPR2021",
    "descriptor": "\nComments: Accepted by CVPR2021\n",
    "authors": [
      "Baoquan Zhang",
      "Xutao Li",
      "Yunming Ye",
      "Zhichao Huang",
      "Lisai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.04960"
  },
  {
    "id": "arXiv:2009.09338",
    "title": "When Federated Learning Meets Blockchain: A New Distributed Learning  Paradigm",
    "abstract": "When Federated Learning Meets Blockchain: A New Distributed Learning  Paradigm",
    "descriptor": "",
    "authors": [
      "Chuan Ma",
      "Jun Li",
      "Ming Ding",
      "Long Shi",
      "Taotao Wang",
      "Zhu Han",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2009.09338"
  },
  {
    "id": "arXiv:2009.09818",
    "title": "DeepActsNet: Spatial and Motion features from Face, Hands, and Body  Combined with Convolutional and Graph Networks for Improved Action  Recognition",
    "abstract": "DeepActsNet: Spatial and Motion features from Face, Hands, and Body  Combined with Convolutional and Graph Networks for Improved Action  Recognition",
    "descriptor": "",
    "authors": [
      "Umar Asif",
      "Deval Mehta",
      "Stefan von Cavallar",
      "Jianbin Tang",
      "Stefan Harrer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.09818"
  },
  {
    "id": "arXiv:2009.14653",
    "title": "RTFE: A Recursive Temporal Fact Embedding Framework for Temporal  Knowledge Graph Completion",
    "abstract": "Comments: Accepted as a main conference paper at NAACL-HLT 2021",
    "descriptor": "\nComments: Accepted as a main conference paper at NAACL-HLT 2021\n",
    "authors": [
      "Youri Xu",
      "E Haihong",
      "Meina Song",
      "Wenyu Song",
      "Xiaodong Lv",
      "Wang Haotian",
      "Yang Jinrui"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.14653"
  },
  {
    "id": "arXiv:2010.01179",
    "title": "The Surprising Power of Graph Neural Networks with Random Node  Initialization",
    "abstract": "Comments: Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence (IJCAI-21). Code and data available at this http URL",
    "descriptor": "\nComments: Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence (IJCAI-21). Code and data available at this http URL\n",
    "authors": [
      "Ralph Abboud",
      "\u0130smail \u0130lkan Ceylan",
      "Martin Grohe",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.01179"
  },
  {
    "id": "arXiv:2010.01219",
    "title": "Contraction Theory for Dynamical Systems on Hilbert Spaces",
    "abstract": "Contraction Theory for Dynamical Systems on Hilbert Spaces",
    "descriptor": "",
    "authors": [
      "Pedro Cisneros-Velarde",
      "Saber Jafarpour",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.01219"
  },
  {
    "id": "arXiv:2010.01987",
    "title": "Strong data processing constant is achieved by binary inputs",
    "abstract": "Comments: 1 page",
    "descriptor": "\nComments: 1 page\n",
    "authors": [
      "Or Ordentlich",
      "Yury Polyanskiy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.01987"
  },
  {
    "id": "arXiv:2010.09541",
    "title": "On the Difficulty of Unbiased Alpha Divergence Minimization",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Tomas Geffner",
      "Justin Domke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.09541"
  },
  {
    "id": "arXiv:2010.10035",
    "title": "Elaborative Simplification: Content Addition and Explanation Generation  in Text Simplification",
    "abstract": "Comments: To appear in Findings of ACL 2021",
    "descriptor": "\nComments: To appear in Findings of ACL 2021\n",
    "authors": [
      "Neha Srikanth",
      "Junyi Jessy Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.10035"
  },
  {
    "id": "arXiv:2010.12873",
    "title": "Learning Contextualized Knowledge Structures for Commonsense Reasoning",
    "abstract": "Comments: Accepted to Findings of ACL-IJCNLP 2021. Code and data: this https URL",
    "descriptor": "\nComments: Accepted to Findings of ACL-IJCNLP 2021. Code and data: this https URL\n",
    "authors": [
      "Jun Yan",
      "Mrigank Raman",
      "Aaron Chan",
      "Tianyu Zhang",
      "Ryan Rossi",
      "Handong Zhao",
      "Sungchul Kim",
      "Nedim Lipka",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12873"
  },
  {
    "id": "arXiv:2010.14584",
    "title": "Predicting Themes within Complex Unstructured Texts: A Case Study on  Safeguarding Reports",
    "abstract": "Comments: 10 pages, 5 figures, workshop",
    "descriptor": "\nComments: 10 pages, 5 figures, workshop\n",
    "authors": [
      "Aleksandra Edwards",
      "David Rogers",
      "Jose Camacho-Collados",
      "H\u00e9l\u00e8ne de Ribaupierre",
      "Alun Preece"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.14584"
  },
  {
    "id": "arXiv:2010.15922",
    "title": "A configurable agent-based simulation model for reducing patients'  waiting time in oncology departments",
    "abstract": "Comments: 39 pages, 3 figures, 7 tables",
    "descriptor": "\nComments: 39 pages, 3 figures, 7 tables\n",
    "authors": [
      "R. R. Corsini",
      "A. Costa",
      "S. Fichera",
      "A.Pluchino"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2010.15922"
  },
  {
    "id": "arXiv:2011.00915",
    "title": "At most $3.55^n$ stable matchings",
    "abstract": "Comments: Version v1 is full of mistakes",
    "descriptor": "\nComments: Version v1 is full of mistakes\n",
    "authors": [
      "Cory Palmer",
      "D\u00f6m\u00f6t\u00f6r P\u00e1lv\u00f6lgyi"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2011.00915"
  },
  {
    "id": "arXiv:2011.01023",
    "title": "Learning transition times in event sequences: the Event-Based Hidden  Markov Model of disease progression",
    "abstract": "Comments: Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended Abstract",
    "descriptor": "\nComments: Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended Abstract\n",
    "authors": [
      "Peter A. Wijeratne",
      "Daniel C. Alexander"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.01023"
  },
  {
    "id": "arXiv:2011.02164",
    "title": "An Improved Attention for Visual Question Answering",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Tanzila Rahman",
      "Shih-Han Chou",
      "Leonid Sigal",
      "Giuseppe Carenini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2011.02164"
  },
  {
    "id": "arXiv:2011.03738",
    "title": "Sharp Thresholds in Random Simple Temporal Graphs",
    "abstract": "Sharp Thresholds in Random Simple Temporal Graphs",
    "descriptor": "",
    "authors": [
      "Arnaud Casteigts",
      "Michael Raskin",
      "Malte Renken",
      "Viktor Zamaraev"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2011.03738"
  },
  {
    "id": "arXiv:2011.05234",
    "title": "Testability of relations between permutations",
    "abstract": "Comments: 42 pages; improved presentation and paper organization",
    "descriptor": "\nComments: 42 pages; improved presentation and paper organization\n",
    "authors": [
      "Oren Becker",
      "Alexander Lubotzky",
      "Jonathan Mosheiff"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2011.05234"
  },
  {
    "id": "arXiv:2011.07189",
    "title": "RGBT Tracking via Multi-Adapter Network with Hierarchical Divergence  Loss",
    "abstract": "Comments: Accepted by IEEE TIP",
    "descriptor": "\nComments: Accepted by IEEE TIP\n",
    "authors": [
      "Andong Lu",
      "Chenglong Li",
      "Yuqing Yan",
      "Jin Tang",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.07189"
  },
  {
    "id": "arXiv:2011.08961",
    "title": "Reactive Human-to-Robot Handovers of Arbitrary Objects",
    "abstract": "Comments: Accepted to the International Conference on Robotics and Automation (ICRA) 2021",
    "descriptor": "\nComments: Accepted to the International Conference on Robotics and Automation (ICRA) 2021\n",
    "authors": [
      "Wei Yang",
      "Chris Paxton",
      "Arsalan Mousavian",
      "Yu-Wei Chao",
      "Maya Cakmak",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.08961"
  },
  {
    "id": "arXiv:2011.10471",
    "title": "Online Descriptor Enhancement via Self-Labelling Triplets for Visual  Data Association",
    "abstract": "Comments: Under review for the 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021). This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: Under review for the 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021). This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yorai Shaoul",
      "Katherine Liu",
      "Kyel Ok",
      "Nicholas Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.10471"
  },
  {
    "id": "arXiv:2011.11958",
    "title": "Weakly- and Semi-Supervised Probabilistic Segmentation and  Quantification of Ultrasound Needle-Reverberation Artifacts to Allow Better  AI Understanding of Tissue Beneath Needles",
    "abstract": "Weakly- and Semi-Supervised Probabilistic Segmentation and  Quantification of Ultrasound Needle-Reverberation Artifacts to Allow Better  AI Understanding of Tissue Beneath Needles",
    "descriptor": "",
    "authors": [
      "Alex Ling Yu Hung",
      "Edward Chen",
      "John Galeotti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.11958"
  },
  {
    "id": "arXiv:2011.12635",
    "title": "The Hydrostructure: a Universal Framework for Safe and Complete  Algorithms for Genome Assembly",
    "abstract": "The Hydrostructure: a Universal Framework for Safe and Complete  Algorithms for Genome Assembly",
    "descriptor": "",
    "authors": [
      "Massimo Cairo",
      "Shahbaz Khan",
      "Romeo Rizzi",
      "Sebastian Schmidt",
      "Alexandru I. Tomescu",
      "Elia C. Zirondelli"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2011.12635"
  },
  {
    "id": "arXiv:2011.13147",
    "title": "Generalized Mutual Information-Maximizing Quantized Decoding of LDPC  Codes with Layered Scheduling",
    "abstract": "Comments: 13 pages, 8 figures, journal manuscript",
    "descriptor": "\nComments: 13 pages, 8 figures, journal manuscript\n",
    "authors": [
      "Peng Kang",
      "Kui Cai",
      "Xuan He",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2011.13147"
  },
  {
    "id": "arXiv:2011.13224",
    "title": "Communication, Computing, Caching, and Sensing for Next Generation  Aerial Delivery Networks",
    "abstract": "Comments: 7 pages, 5 figures, 1 table",
    "descriptor": "\nComments: 7 pages, 5 figures, 1 table\n",
    "authors": [
      "Gunes Karabulut Kurt",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2011.13224"
  },
  {
    "id": "arXiv:2012.00573",
    "title": "Multi-level Knowledge Distillation via Knowledge Alignment and  Correlation",
    "abstract": "Comments: 15 pages, 11 tables, 4 figures",
    "descriptor": "\nComments: 15 pages, 11 tables, 4 figures\n",
    "authors": [
      "Fei Ding",
      "Yin Yang",
      "Hongxin Hu",
      "Venkat Krovi",
      "Feng Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.00573"
  },
  {
    "id": "arXiv:2012.00628",
    "title": "Convergence of Gradient Algorithms for Nonconvex C^{1+alpha} Cost  Functions",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Zixuan Wang",
      "Shanjian Tang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.00628"
  },
  {
    "id": "arXiv:2012.01484",
    "title": "Some observations on high-dimensional partial differential equations  with Barron data",
    "abstract": "Some observations on high-dimensional partial differential equations  with Barron data",
    "descriptor": "",
    "authors": [
      "Weinan E",
      "Stephan Wojtowytsch"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.01484"
  },
  {
    "id": "arXiv:2012.05420",
    "title": "On the emergence of simplex symmetry in the final and penultimate layers  of neural network classifiers",
    "abstract": "On the emergence of simplex symmetry in the final and penultimate layers  of neural network classifiers",
    "descriptor": "",
    "authors": [
      "Weinan E",
      "Stephan Wojtowytsch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.05420"
  },
  {
    "id": "arXiv:2012.07042",
    "title": "Efficient Semi-Supervised Gross Target Volume of Nasopharyngeal  Carcinoma Segmentation via Uncertainty Rectified Pyramid Consistency",
    "abstract": "Comments: 13 pages, provisional accept by MICCAI2021,code at:this https URL",
    "descriptor": "\nComments: 13 pages, provisional accept by MICCAI2021,code at:this https URL\n",
    "authors": [
      "Xiangde Luo",
      "Wenjun Liao",
      "Jieneng Chen",
      "Tao Song",
      "Yinan Chen",
      "Shichuan Zhang",
      "Nianyong Chen",
      "Guotai Wang",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.07042"
  },
  {
    "id": "arXiv:2012.07498",
    "title": "Sign-Agnostic Implicit Learning of Surface Self-Similarities for Shape  Modeling and Reconstruction from Raw Point Clouds",
    "abstract": "Sign-Agnostic Implicit Learning of Surface Self-Similarities for Shape  Modeling and Reconstruction from Raw Point Clouds",
    "descriptor": "",
    "authors": [
      "Wenbin Zhao",
      "Jiabao Lei",
      "Yuxin Wen",
      "Jianguo Zhang",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.07498"
  },
  {
    "id": "arXiv:2012.08482",
    "title": "Learning Aggregation Functions",
    "abstract": "Comments: Extended version (with proof appendix) of paper that is to appear in Proceedings of IJCAI 2021",
    "descriptor": "\nComments: Extended version (with proof appendix) of paper that is to appear in Proceedings of IJCAI 2021\n",
    "authors": [
      "Giovanni Pellegrini",
      "Alessandro Tibo",
      "Paolo Frasconi",
      "Andrea Passerini",
      "Manfred Jaeger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.08482"
  },
  {
    "id": "arXiv:2012.11049",
    "title": "Fusing CNNs and statistical indicators to improve image classification",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Javier Huertas-Tato",
      "Alejandro Mart\u00edn",
      "Juli\u00e1n Fierrez",
      "David Camacho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.11049"
  },
  {
    "id": "arXiv:2012.12641",
    "title": "Negation in Cognitive Reasoning",
    "abstract": "Comments: 18 pages, 5 figures, 4 tables",
    "descriptor": "\nComments: 18 pages, 5 figures, 4 tables\n",
    "authors": [
      "Claudia Schon",
      "Sophie Siebert",
      "Frieder Stolzenburg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.12641"
  },
  {
    "id": "arXiv:2012.13048",
    "title": "ProofWriter: Generating Implications, Proofs, and Abductive Statements  over Natural Language",
    "abstract": "Comments: Findings of ACL 2021",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Oyvind Tafjord",
      "Bhavana Dalvi Mishra",
      "Peter Clark"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.13048"
  },
  {
    "id": "arXiv:2012.13317",
    "title": "Concurrency measures in the era of temporal network epidemiology: A  review",
    "abstract": "Comments: 5 figures",
    "descriptor": "\nComments: 5 figures\n",
    "authors": [
      "Naoki Masuda",
      "Joel C. Miller",
      "Petter Holme"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2012.13317"
  },
  {
    "id": "arXiv:2012.13806",
    "title": "Time-Fluid Field-Based Coordination through Programmable Distributed  Schedulers",
    "abstract": "Time-Fluid Field-Based Coordination through Programmable Distributed  Schedulers",
    "descriptor": "",
    "authors": [
      "Danilo Pianini",
      "Roberto Casadei",
      "Mirko Viroli",
      "Stefano Mariani",
      "Franco Zambonelli"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2012.13806"
  },
  {
    "id": "arXiv:2012.15262",
    "title": "Robustness Testing of Language Understanding in Task-Oriented Dialog",
    "abstract": "Comments: ACL 2021 long paper",
    "descriptor": "\nComments: ACL 2021 long paper\n",
    "authors": [
      "Jiexi Liu",
      "Ryuichi Takanobu",
      "Jiaxin Wen",
      "Dazhen Wan",
      "Hongguang Li",
      "Weiran Nie",
      "Cheng Li",
      "Wei Peng",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.15262"
  },
  {
    "id": "arXiv:2101.02486",
    "title": "Deep Learning Methods for Vessel Trajectory Prediction based on  Recurrent Neural Networks",
    "abstract": "Comments: Accepted for publications in IEEE Transactions on Aerospace and Electronic Systems, 17 pages, 9 figures",
    "descriptor": "\nComments: Accepted for publications in IEEE Transactions on Aerospace and Electronic Systems, 17 pages, 9 figures\n",
    "authors": [
      "Samuele Capobianco",
      "Leonardo M. Millefiori",
      "Nicola Forti",
      "Paolo Braca",
      "Peter Willett"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.02486"
  },
  {
    "id": "arXiv:2101.07088",
    "title": "A fast spectral method for electrostatics in doubly-periodic slit  channels",
    "abstract": "Comments: 60 pages, 7 figures",
    "descriptor": "\nComments: 60 pages, 7 figures\n",
    "authors": [
      "Ondrej Maxian",
      "Raul P. Pel\u00e1ez",
      "Leslie Greengard",
      "Aleksandar Donev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.07088"
  },
  {
    "id": "arXiv:2101.07415",
    "title": "ES-ENAS: Controller-Based Architecture Search for Evolutionary  Reinforcement Learning",
    "abstract": "Comments: 17 pages. This is an updated version of a previous submission which can be found at arXiv:1907.06511. See this https URL for associated code",
    "descriptor": "\nComments: 17 pages. This is an updated version of a previous submission which can be found at arXiv:1907.06511. See this https URL for associated code\n",
    "authors": [
      "Xingyou Song",
      "Krzysztof Choromanski",
      "Jack Parker-Holder",
      "Yunhao Tang",
      "Daiyi Peng",
      "Deepali Jain",
      "Wenbo Gao",
      "Aldo Pacchiano",
      "Tamas Sarlos",
      "Yuxiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.07415"
  },
  {
    "id": "arXiv:2101.07947",
    "title": "WeChat AI & ICT's Submission for DSTC9 Interactive Dialogue Evaluation  Track",
    "abstract": "Comments: DSTC9@AAAI2021",
    "descriptor": "\nComments: DSTC9@AAAI2021\n",
    "authors": [
      "Zekang Li",
      "Zongjia Li",
      "Jinchao Zhang",
      "Yang Feng",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.07947"
  },
  {
    "id": "arXiv:2101.09258",
    "title": "Maximum Likelihood Training of Score-Based Diffusion Models",
    "abstract": "Maximum Likelihood Training of Score-Based Diffusion Models",
    "descriptor": "",
    "authors": [
      "Yang Song",
      "Conor Durkan",
      "Iain Murray",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.09258"
  },
  {
    "id": "arXiv:2101.10238",
    "title": "Mismatched decoding reliability function at zero rate",
    "abstract": "Mismatched decoding reliability function at zero rate",
    "descriptor": "",
    "authors": [
      "Marco Bondaschi",
      "Albert Guill\u00e9n i F\u00e0bregas",
      "Marco Dalai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.10238"
  },
  {
    "id": "arXiv:2101.11500",
    "title": "A Deterministic Algorithm for the Discrete Logarithm Problem in a  Semigroup",
    "abstract": "A Deterministic Algorithm for the Discrete Logarithm Problem in a  Semigroup",
    "descriptor": "",
    "authors": [
      "Simran Tinani",
      "Joachim Rosenthal"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2101.11500"
  },
  {
    "id": "arXiv:2102.01678",
    "title": "Learning domain-agnostic visual representation for computational  pathology using medically-irrelevant style transfer augmentation",
    "abstract": "Learning domain-agnostic visual representation for computational  pathology using medically-irrelevant style transfer augmentation",
    "descriptor": "",
    "authors": [
      "Rikiya Yamashita",
      "Jin Long",
      "Snikitha Banda",
      "Jeanne Shen",
      "Daniel L. Rubin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.01678"
  },
  {
    "id": "arXiv:2102.02734",
    "title": "Deep learning-based synthetic-CT generation in radiotherapy and PET: a  review",
    "abstract": "Comments: 59 pages, 4 figures, 5 tables; two first equally contributing authors; provisionally accepted in Medical Physics",
    "descriptor": "\nComments: 59 pages, 4 figures, 5 tables; two first equally contributing authors; provisionally accepted in Medical Physics\n",
    "authors": [
      "Maria Francesca Spadea",
      "Matteo Maspero",
      "Paolo Zaffino",
      "Joao Seco"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2102.02734"
  },
  {
    "id": "arXiv:2102.02805",
    "title": "How do Quadratic Regularizers Prevent Catastrophic Forgetting: The Role  of Interpolation",
    "abstract": "Comments: Substantial rewriting and addition of new experiments",
    "descriptor": "\nComments: Substantial rewriting and addition of new experiments\n",
    "authors": [
      "Ekdeep Singh Lubana",
      "Puja Trivedi",
      "Danai Koutra",
      "Robert P. Dick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02805"
  },
  {
    "id": "arXiv:2102.03034",
    "title": "Hyperparameter Optimization Is Deceiving Us, and How to Stop It",
    "abstract": "Hyperparameter Optimization Is Deceiving Us, and How to Stop It",
    "descriptor": "",
    "authors": [
      "A. Feder Cooper",
      "Yucheng Lu",
      "Jessica Zosa Forde",
      "Christopher De Sa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.03034"
  },
  {
    "id": "arXiv:2102.04944",
    "title": "Optimal Static Mutation Strength Distributions for the $(1+\u03bb)$  Evolutionary Algorithm on OneMax",
    "abstract": "Comments: Submitted for review to GECCO'21",
    "descriptor": "\nComments: Submitted for review to GECCO'21\n",
    "authors": [
      "Maxim Buzdalov",
      "Carola Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2102.04944"
  },
  {
    "id": "arXiv:2102.05441",
    "title": "Capacity Optimality of AMP in Coded Systems",
    "abstract": "Comments: Accepted by IEEE ISIT 2021. arXiv admin note: text overlap with arXiv:1901.09559",
    "descriptor": "\nComments: Accepted by IEEE ISIT 2021. arXiv admin note: text overlap with arXiv:1901.09559\n",
    "authors": [
      "Lei Liu",
      "Chulong Liang",
      "Junjie Ma",
      "Li Ping"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.05441"
  },
  {
    "id": "arXiv:2102.07728",
    "title": "Dynamic Membership for Regular Languages",
    "abstract": "Comments: 34 pages. This is the full version with proofs of the ICALP'21 article",
    "descriptor": "\nComments: 34 pages. This is the full version with proofs of the ICALP'21 article\n",
    "authors": [
      "Antoine Amarilli",
      "Louis Jachiet",
      "Charles Paperman"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.07728"
  },
  {
    "id": "arXiv:2102.07835",
    "title": "Topological Graph Neural Networks",
    "abstract": "Topological Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Max Horn",
      "Edward De Brouwer",
      "Michael Moor",
      "Yves Moreau",
      "Bastian Rieck",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.07835"
  },
  {
    "id": "arXiv:2102.07849",
    "title": "Identifying Misinformation from Website Screenshots",
    "abstract": "Identifying Misinformation from Website Screenshots",
    "descriptor": "",
    "authors": [
      "Sara Abdali",
      "Rutuja Gurav",
      "Siddharth Menon",
      "Daniel Fonseca",
      "Negin Entezari",
      "Neil Shah",
      "Evangelos E. Papalexakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2102.07849"
  },
  {
    "id": "arXiv:2102.08325",
    "title": "All You Need is DAG",
    "abstract": "All You Need is DAG",
    "descriptor": "",
    "authors": [
      "Idit Keidar",
      "Eleftherios Kokoris-Kogias",
      "Oded Naor",
      "Alexander Spiegelman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.08325"
  },
  {
    "id": "arXiv:2102.08360",
    "title": "Interpretable COVID-19 Chest X-Ray Classification via Orthogonality  Constraint",
    "abstract": "Comments: Accepted in the 2021 ACM CHIL Workshop track",
    "descriptor": "\nComments: Accepted in the 2021 ACM CHIL Workshop track\n",
    "authors": [
      "Ella Y. Wang",
      "Anirudh Som",
      "Ankita Shukla",
      "Hongjun Choi",
      "Pavan Turaga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.08360"
  },
  {
    "id": "arXiv:2102.09507",
    "title": "Regular Expressions for Fast-response COVID-19 Text Classification",
    "abstract": "Comments: 10 pages, 7 tables",
    "descriptor": "\nComments: 10 pages, 7 tables\n",
    "authors": [
      "Igor L. Markov",
      "Jacqueline Liu",
      "Adam Vagner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2102.09507"
  },
  {
    "id": "arXiv:2102.11062",
    "title": "On the Effects of Quantisation on Model Uncertainty in Bayesian Neural  Networks",
    "abstract": "Comments: Accepted at UAI2021. Code at: this https URL",
    "descriptor": "\nComments: Accepted at UAI2021. Code at: this https URL\n",
    "authors": [
      "Martin Ferianc",
      "Partha Maji",
      "Matthew Mattina",
      "Miguel Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.11062"
  },
  {
    "id": "arXiv:2102.11448",
    "title": "MUSBO: Model-based Uncertainty Regularized and Sample Efficient Batch  Optimization for Deployment Constrained Reinforcement Learning",
    "abstract": "MUSBO: Model-based Uncertainty Regularized and Sample Efficient Batch  Optimization for Deployment Constrained Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "DiJia Su",
      "Jason D. Lee",
      "John M. Mulvey",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.11448"
  },
  {
    "id": "arXiv:2102.12056",
    "title": "Multi-Slice Low-Rank Tensor Decomposition Based Multi-Atlas  Segmentation: Application to Automatic Pathological Liver CT Segmentation",
    "abstract": "Comments: Submitted to Medical Image Analysis (Revised Manuscript). 9 Figures, 41 pages",
    "descriptor": "\nComments: Submitted to Medical Image Analysis (Revised Manuscript). 9 Figures, 41 pages\n",
    "authors": [
      "Changfa Shi",
      "Min Xian",
      "Xiancheng Zhou",
      "Haotian Wang",
      "Heng-Da Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12056"
  },
  {
    "id": "arXiv:2102.13256",
    "title": "Cybersecurity Threats in Connected and Automated Vehicles based  Federated Learning Systems",
    "abstract": "Cybersecurity Threats in Connected and Automated Vehicles based  Federated Learning Systems",
    "descriptor": "",
    "authors": [
      "Ranwa Al Mallah",
      "Godwin Badu-Marfo",
      "Bilal Farooq"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.13256"
  },
  {
    "id": "arXiv:2102.13268",
    "title": "DRIBO: Robust Deep Reinforcement Learning via Multi-View Information  Bottleneck",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Jiameng Fan",
      "Wenchao Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.13268"
  },
  {
    "id": "arXiv:2102.13451",
    "title": "FjORD: Fair and Accurate Federated Learning under heterogeneous targets  with Ordered Dropout",
    "abstract": "Comments: Updated results, additions in appendix",
    "descriptor": "\nComments: Updated results, additions in appendix\n",
    "authors": [
      "Samuel Horvath",
      "Stefanos Laskaridis",
      "Mario Almeida",
      "Ilias Leontiadis",
      "Stylianos I. Venieris",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.13451"
  },
  {
    "id": "arXiv:2102.13565",
    "title": "Low-Precision Reinforcement Learning: Running Soft Actor-Critic in Half  Precision",
    "abstract": "Low-Precision Reinforcement Learning: Running Soft Actor-Critic in Half  Precision",
    "descriptor": "",
    "authors": [
      "Johan Bjorck",
      "Xiangyu Chen",
      "Christopher De Sa",
      "Carla P. Gomes",
      "Kilian Q. Weinberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.13565"
  },
  {
    "id": "arXiv:2103.00749",
    "title": "SmartON: Just-in-Time Active Event Detection on Energy Harvesting  Systems",
    "abstract": "Comments: Accepted in THE 17TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING IN SENSOR SYSTEMS, DCOSS 2021",
    "descriptor": "\nComments: Accepted in THE 17TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING IN SENSOR SYSTEMS, DCOSS 2021\n",
    "authors": [
      "Yubo Luo",
      "Shahriar Nirjon"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.00749"
  },
  {
    "id": "arXiv:2103.01294",
    "title": "Wide Network Learning with Differential Privacy",
    "abstract": "Wide Network Learning with Differential Privacy",
    "descriptor": "",
    "authors": [
      "Huanyu Zhang",
      "Ilya Mironov",
      "Meisam Hejazinia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2103.01294"
  },
  {
    "id": "arXiv:2103.02214",
    "title": "Optimizing Multi-task Peer Prediction",
    "abstract": "Optimizing Multi-task Peer Prediction",
    "descriptor": "",
    "authors": [
      "Yuqing Kong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2103.02214"
  },
  {
    "id": "arXiv:2103.03939",
    "title": "NF-GNN: Network Flow Graph Neural Networks for Malware Detection and  Classification",
    "abstract": "NF-GNN: Network Flow Graph Neural Networks for Malware Detection and  Classification",
    "descriptor": "",
    "authors": [
      "Julian Busch",
      "Anton Kocheturov",
      "Volker Tresp",
      "Thomas Seidl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.03939"
  },
  {
    "id": "arXiv:2103.05896",
    "title": "Streaming Linear System Identification with Reverse Experience Replay",
    "abstract": "Streaming Linear System Identification with Reverse Experience Replay",
    "descriptor": "",
    "authors": [
      "Prateek Jain",
      "Suhas S Kowshik",
      "Dheeraj Nagaraj",
      "Praneeth Netrapalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.05896"
  },
  {
    "id": "arXiv:2103.06175",
    "title": "Regressive Domain Adaptation for Unsupervised Keypoint Detection",
    "abstract": "Comments: CVPR 2021",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Junguang Jiang",
      "Yifei Ji",
      "Ximei Wang",
      "Yufeng Liu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06175"
  },
  {
    "id": "arXiv:2103.07945",
    "title": "Learning One Representation to Optimize All Rewards",
    "abstract": "Learning One Representation to Optimize All Rewards",
    "descriptor": "",
    "authors": [
      "Ahmed Touati",
      "Yann Ollivier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.07945"
  },
  {
    "id": "arXiv:2103.08041",
    "title": "Safe Controller Synthesis with Tunable Input-to-State Safe Control  Barrier Functions",
    "abstract": "Safe Controller Synthesis with Tunable Input-to-State Safe Control  Barrier Functions",
    "descriptor": "",
    "authors": [
      "Anil Alan",
      "Andrew J. Taylor",
      "Chaozhe R. He",
      "G\u00e1bor Orosz",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.08041"
  },
  {
    "id": "arXiv:2103.08737",
    "title": "Growing 3D Artefacts and Functional Machines with Neural Cellular  Automata",
    "abstract": "Growing 3D Artefacts and Functional Machines with Neural Cellular  Automata",
    "descriptor": "",
    "authors": [
      "Shyam Sudhakaran",
      "Djordje Grbic",
      "Siyan Li",
      "Adam Katona",
      "Elias Najarro",
      "Claire Glanois",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.08737"
  },
  {
    "id": "arXiv:2103.09357",
    "title": "A new framework for the stability analysis of perturbed saddle-point  problems and applications",
    "abstract": "A new framework for the stability analysis of perturbed saddle-point  problems and applications",
    "descriptor": "",
    "authors": [
      "Qingguo Hong",
      "Johannes Kraus",
      "Maria Lymbery",
      "Fadi Philo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.09357"
  },
  {
    "id": "arXiv:2103.09603",
    "title": "DoubleML -- An Object-Oriented Implementation of Double Machine Learning  in R",
    "abstract": "Comments: 40 pages, 7 Figures",
    "descriptor": "\nComments: 40 pages, 7 Figures\n",
    "authors": [
      "Philipp Bach",
      "Victor Chernozhukov",
      "Malte S. Kurz",
      "Martin Spindler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2103.09603"
  },
  {
    "id": "arXiv:2103.10201",
    "title": "The impact of using biased performance metrics on software defect  prediction research",
    "abstract": "Comments: Submitted to the journal Information & Software Technology. It is a greatly extended version of \"Assessing Software Defection Prediction Performance: Why Using the Matthews Correlation Coefficient Matters\" presented at EASE 2020",
    "descriptor": "\nComments: Submitted to the journal Information & Software Technology. It is a greatly extended version of \"Assessing Software Defection Prediction Performance: Why Using the Matthews Correlation Coefficient Matters\" presented at EASE 2020\n",
    "authors": [
      "Jingxiu Yao",
      "Martin Shepperd"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10201"
  },
  {
    "id": "arXiv:2103.10426",
    "title": "Using latent space regression to analyze and leverage compositionality  in GANs",
    "abstract": "Comments: Update to ICLR 2021 camera ready version",
    "descriptor": "\nComments: Update to ICLR 2021 camera ready version\n",
    "authors": [
      "Lucy Chai",
      "Jonas Wulff",
      "Phillip Isola"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10426"
  },
  {
    "id": "arXiv:2103.10897",
    "title": "Bilinear Classes: A Structural Framework for Provable Generalization in  RL",
    "abstract": "Comments: Added further examples, comparisons to concurrent work, and improved the exposition",
    "descriptor": "\nComments: Added further examples, comparisons to concurrent work, and improved the exposition\n",
    "authors": [
      "Simon S. Du",
      "Sham M. Kakade",
      "Jason D. Lee",
      "Shachar Lovett",
      "Gaurav Mahajan",
      "Wen Sun",
      "Ruosong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.10897"
  },
  {
    "id": "arXiv:2103.13355",
    "title": "Bag of Tricks for Node Classification with Graph Neural Networks",
    "abstract": "Bag of Tricks for Node Classification with Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Yangkun Wang",
      "Jiarui Jin",
      "Weinan Zhang",
      "Yong Yu",
      "Zheng Zhang",
      "David Wipf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.13355"
  },
  {
    "id": "arXiv:2103.14862",
    "title": "TS-CAM: Token Semantic Coupled Attention Map for Weakly Supervised  Object Localization",
    "abstract": "Comments: 10 pages, 9 figures. For appendix, 6 pages, 4 figures. arXiv admin note: text overlap with arXiv:2103.04523",
    "descriptor": "\nComments: 10 pages, 9 figures. For appendix, 6 pages, 4 figures. arXiv admin note: text overlap with arXiv:2103.04523\n",
    "authors": [
      "Wei Gao",
      "Fang Wan",
      "Xingjia Pan",
      "Zhiliang Peng",
      "Qi Tian",
      "Zhenjun Han",
      "Bolei Zhou",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14862"
  },
  {
    "id": "arXiv:2104.00734",
    "title": "Next Generation Multitarget Trackers: Random Finite Set Methods vs  Transformer-based Deep Learning",
    "abstract": "Comments: 8 pages, 4 figures",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Juliano Pinto",
      "Georg Hess",
      "William Ljungbergh",
      "Yuxuan Xia",
      "Lennart Svensson",
      "Henk Wymeersch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.00734"
  },
  {
    "id": "arXiv:2104.01954",
    "title": "Reformulating DOVER-Lap Label Mapping as a Graph Partitioning Problem",
    "abstract": "Comments: 5 pages, 3 figures. Acceped at INTERSPEECH 2021",
    "descriptor": "\nComments: 5 pages, 3 figures. Acceped at INTERSPEECH 2021\n",
    "authors": [
      "Desh Raj",
      "Sanjeev Khudanpur"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2104.01954"
  },
  {
    "id": "arXiv:2104.03538",
    "title": "MetricGAN+: An Improved Version of MetricGAN for Speech Enhancement",
    "abstract": "Comments: Accepted by Interspeech 2021",
    "descriptor": "\nComments: Accepted by Interspeech 2021\n",
    "authors": [
      "Szu-Wei Fu",
      "Cheng Yu",
      "Tsun-An Hsieh",
      "Peter Plantinga",
      "Mirco Ravanelli",
      "Xugang Lu",
      "Yu Tsao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.03538"
  },
  {
    "id": "arXiv:2104.06131",
    "title": "Big Communications: Connect the Unconnected",
    "abstract": "Big Communications: Connect the Unconnected",
    "descriptor": "",
    "authors": [
      "Shuping Dang",
      "Chuanting Zhang",
      "Basem Shihada",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.06131"
  },
  {
    "id": "arXiv:2104.08057",
    "title": "Signed Distance Function Computation from an Implicit Surface",
    "abstract": "Comments: Fix typos",
    "descriptor": "\nComments: Fix typos\n",
    "authors": [
      "Pierre-Alain Fayolle"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.08057"
  },
  {
    "id": "arXiv:2104.10762",
    "title": "Image Distribution Estimation with Random Field and Random Cluster  Theories",
    "abstract": "Image Distribution Estimation with Random Field and Random Cluster  Theories",
    "descriptor": "",
    "authors": [
      "Robert A. Murphy"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.10762"
  },
  {
    "id": "arXiv:2104.11430",
    "title": "Learning phylogenetic trees as hyperbolic point configurations",
    "abstract": "Comments: 17 pages, 8 figures",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Benjamin Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.11430"
  },
  {
    "id": "arXiv:2104.12466",
    "title": "Microservice Dynamic Architecture-Level Deployment Orchestration  (Extended Version)",
    "abstract": "Microservice Dynamic Architecture-Level Deployment Orchestration  (Extended Version)",
    "descriptor": "",
    "authors": [
      "Lorenzo Bacchiani",
      "Mario Bravetti",
      "Saverio Giallorenzo",
      "Jacopo Mauro",
      "Iacopo Talevi",
      "Gianluigi Zavattaro"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.12466"
  },
  {
    "id": "arXiv:2104.12695",
    "title": "The Reachability Problem for Petri Nets is Not Primitive Recursive",
    "abstract": "Comments: Version submitted to FOCS 2021",
    "descriptor": "\nComments: Version submitted to FOCS 2021\n",
    "authors": [
      "J\u00e9r\u00f4me Leroux"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.12695"
  },
  {
    "id": "arXiv:2105.00164",
    "title": "Hidden Backdoors in Human-Centric Language Models",
    "abstract": "Hidden Backdoors in Human-Centric Language Models",
    "descriptor": "",
    "authors": [
      "Shaofeng Li",
      "Hui Liu",
      "Tian Dong",
      "Benjamin Zi Hao Zhao",
      "Minhui Xue",
      "Haojin Zhu",
      "Jialiang Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.00164"
  },
  {
    "id": "arXiv:2105.03531",
    "title": "On the Complexity of Verification of Time-Sensitive Distributed Systems:  Technical Report",
    "abstract": "Comments: This Technical Report updates and subsumes the technical report arXiv:1606.07886",
    "descriptor": "\nComments: This Technical Report updates and subsumes the technical report arXiv:1606.07886\n",
    "authors": [
      "Max Kanovich",
      "Tajana Ban Kirigin",
      "Vivek Nigam",
      "Andre Scedrov",
      "Carolyn Talcott"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.03531"
  },
  {
    "id": "arXiv:2105.03773",
    "title": "Adversarially Robust and Sliding Window Streaming Algorithms without the  Overhead",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2011.07471",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2011.07471\n",
    "authors": [
      "David P. Woodruff",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.03773"
  },
  {
    "id": "arXiv:2105.03827",
    "title": "Good Practices and A Strong Baseline for Traffic Anomaly Detection",
    "abstract": "Comments: We rank $1^{st}$ in the CVPR 2021 NVIDIA AI CITY Challenge for Traffic Anomaly detection",
    "descriptor": "\nComments: We rank $1^{st}$ in the CVPR 2021 NVIDIA AI CITY Challenge for Traffic Anomaly detection\n",
    "authors": [
      "Yuxiang Zhao",
      "Wenhao Wu",
      "Yue He",
      "Yingying Li",
      "Xiao Tan",
      "Shifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03827"
  },
  {
    "id": "arXiv:2105.04427",
    "title": "A practical, effective calculation of gamma difference distributions  with open data science tools",
    "abstract": "Comments: 26 pages, 4 figures, 2 tables, 1 box, corrected typos in text and tables, more precise runtimes for MMA and MTB, added references, correct links for online materials",
    "descriptor": "\nComments: 26 pages, 4 figures, 2 tables, 1 box, corrected typos in text and tables, more precise runtimes for MMA and MTB, added references, correct links for online materials\n",
    "authors": [
      "Martina Han\u010dov\u00e1",
      "Andrej Gajdo\u0161",
      "Jozef Han\u010d"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.04427"
  },
  {
    "id": "arXiv:2105.05138",
    "title": "The Smoothed Likelihood of Doctrinal Paradox",
    "abstract": "Comments: 9 pages main text with an appendix",
    "descriptor": "\nComments: 9 pages main text with an appendix\n",
    "authors": [
      "Ao Liu",
      "Lirong Xia"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.05138"
  },
  {
    "id": "arXiv:2105.06422",
    "title": "Causally-motivated Shortcut Removal Using Auxiliary Labels",
    "abstract": "Causally-motivated Shortcut Removal Using Auxiliary Labels",
    "descriptor": "",
    "authors": [
      "Maggie Makar",
      "Ben Packer",
      "Dan Moldovan",
      "Davis Blalock",
      "Yoni Halpern",
      "Alexander D'Amour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.06422"
  },
  {
    "id": "arXiv:2105.06466",
    "title": "Editing Conditional Radiance Fields",
    "abstract": "Comments: Code: this https URL Website: this http URL, v2 updated figure 8 and included additional details",
    "descriptor": "\nComments: Code: this https URL Website: this http URL, v2 updated figure 8 and included additional details\n",
    "authors": [
      "Steven Liu",
      "Xiuming Zhang",
      "Zhoutong Zhang",
      "Richard Zhang",
      "Jun-Yan Zhu",
      "Bryan Russell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.06466"
  },
  {
    "id": "arXiv:2105.07446",
    "title": "Sobolev Norm Learning Rates for Conditional Mean Embeddings",
    "abstract": "Sobolev Norm Learning Rates for Conditional Mean Embeddings",
    "descriptor": "",
    "authors": [
      "Prem Talwai",
      "Ali Shameli",
      "David Simchi-Levi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.07446"
  },
  {
    "id": "arXiv:2105.08791",
    "title": "Value Function is All You Need: A Unified Learning Framework for Ride  Hailing Platforms",
    "abstract": "Comments: KDD 2021; Ride-hailing marketplace open simulation platform: this https URL",
    "descriptor": "\nComments: KDD 2021; Ride-hailing marketplace open simulation platform: this https URL\n",
    "authors": [
      "Xiaocheng Tang",
      "Fan Zhang",
      "Zhiwei Qin",
      "Yansheng Wang",
      "Dingyuan Shi",
      "Bingchen Song",
      "Yongxin Tong",
      "Hongtu Zhu",
      "Jieping Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.08791"
  },
  {
    "id": "arXiv:2105.10375",
    "title": "An Efficient Training Approach for Very Large Scale Face Recognition",
    "abstract": "Comments: This is a very effcient framework for ultra-large-scale classification tasks. Our code is available at this https URL We will keep updating!",
    "descriptor": "\nComments: This is a very effcient framework for ultra-large-scale classification tasks. Our code is available at this https URL We will keep updating!\n",
    "authors": [
      "Kai Wang",
      "Shuo Wang",
      "Zhipeng Zhou",
      "Xiaobo Wang",
      "Xiaojiang Peng",
      "Baigui Sun",
      "Hao Li",
      "Yang You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.10375"
  },
  {
    "id": "arXiv:2105.10869",
    "title": "Insect-Computer Hybrid System for Autonomous Search and Rescue Mission",
    "abstract": "Comments: Download movies from this https URL",
    "descriptor": "\nComments: Download movies from this https URL\n",
    "authors": [
      "P. Thanh Tran-Ngoc",
      "D. Long Le",
      "Bing Sheng Chong",
      "H. Duoc Nguyen",
      "V. Than Dung",
      "Feng Cao",
      "Yao Li",
      "Kazuki Kai",
      "Jia Hui Gan",
      "T. Thang Vo-Doan",
      "T. Luan Nguyen",
      "Hirotaka Sato"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.10869"
  },
  {
    "id": "arXiv:2105.11126",
    "title": "Cascading Bandit under Differential Privacy",
    "abstract": "Cascading Bandit under Differential Privacy",
    "descriptor": "",
    "authors": [
      "Kun Wang",
      "Jing Dong",
      "Baoxiang Wang",
      "Shuai Li",
      "Shuo Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11126"
  },
  {
    "id": "arXiv:2105.11237",
    "title": "SiamRCR: Reciprocal Classification and Regression for Visual Object  Tracking",
    "abstract": "Comments: The 30th International Joint Conference on Artificial Intelligence (IJCAI 2021)",
    "descriptor": "\nComments: The 30th International Joint Conference on Artificial Intelligence (IJCAI 2021)\n",
    "authors": [
      "Jinlong Peng",
      "Zhengkai Jiang",
      "Yueyang Gu",
      "Yang Wu",
      "Yabiao Wang",
      "Ying Tai",
      "Chengjie Wang",
      "Weiyao Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11237"
  },
  {
    "id": "arXiv:2105.11558",
    "title": "Near-optimal Offline and Streaming Algorithms for Learning Non-Linear  Dynamical Systems",
    "abstract": "Near-optimal Offline and Streaming Algorithms for Learning Non-Linear  Dynamical Systems",
    "descriptor": "",
    "authors": [
      "Prateek Jain",
      "Suhas S Kowshik",
      "Dheeraj Nagaraj",
      "Praneeth Netrapalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.11558"
  },
  {
    "id": "arXiv:2105.11578",
    "title": "SHD360: A Benchmark Dataset for Salient Human Detection in 360\u00b0  Videos",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Yi Zhang",
      "Lu Zhang",
      "Jing Zhang",
      "Kang Wang",
      "Wassim Hamidouche",
      "Olivier Deforges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11578"
  },
  {
    "id": "arXiv:2105.11743",
    "title": "Avoiding Dense and Dynamic Obstacles in Enclosed Spaces: Application to  Moving in Crowds",
    "abstract": "Avoiding Dense and Dynamic Obstacles in Enclosed Spaces: Application to  Moving in Crowds",
    "descriptor": "",
    "authors": [
      "Lukas Huber",
      "Jean-Jacques Slotine",
      "Aude Billard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.11743"
  },
  {
    "id": "arXiv:2105.12490",
    "title": "Total, Equitable Total and Neighborhood sum distinguishing Total  Colorings of Some Classes of Circulant Graphs",
    "abstract": "Comments: 13 Pages, 6 Tables",
    "descriptor": "\nComments: 13 Pages, 6 Tables\n",
    "authors": [
      "S. Prajnanaswaroopa",
      "J. Geetha",
      "K. Somasundaram"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.12490"
  },
  {
    "id": "arXiv:2105.13609",
    "title": "A nearly Blackwell-optimal policy gradient method",
    "abstract": "Comments: 26 pages (9-page main content), refined the appendices",
    "descriptor": "\nComments: 26 pages (9-page main content), refined the appendices\n",
    "authors": [
      "Vektor Dewanto",
      "Marcus Gallagher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.13609"
  },
  {
    "id": "arXiv:2105.13889",
    "title": "Equilibrium and non-Equilibrium regimes in the learning of Restricted  Boltzmann Machines",
    "abstract": "Comments: 12 page, 3 figures. submitted to Neurips 2021 Supplementary Material",
    "descriptor": "\nComments: 12 page, 3 figures. submitted to Neurips 2021 Supplementary Material\n",
    "authors": [
      "Aur\u00e9lien Decelle",
      "Cyril Furtlehner",
      "Beatriz Seoane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2105.13889"
  },
  {
    "id": "arXiv:2105.13939",
    "title": "Efficient Online-Bandit Strategies for Minimax Learning Problems",
    "abstract": "Efficient Online-Bandit Strategies for Minimax Learning Problems",
    "descriptor": "",
    "authors": [
      "Christophe Roux",
      "Elias Wirth",
      "Sebastian Pokutta",
      "Thomas Kerdreux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13939"
  },
  {
    "id": "arXiv:2105.14098",
    "title": "Ray-based inversion accounting for scattering for biomedical ultrasound  computed tomography",
    "abstract": "Ray-based inversion accounting for scattering for biomedical ultrasound  computed tomography",
    "descriptor": "",
    "authors": [
      "Ashkan Javaherian",
      "Ben Cox"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14098"
  },
  {
    "id": "arXiv:2105.14106",
    "title": "More Is Better: An Analysis of Instance Quantity/Quality Trade-off in  Rehearsal-based Continual Learning",
    "abstract": "More Is Better: An Analysis of Instance Quantity/Quality Trade-off in  Rehearsal-based Continual Learning",
    "descriptor": "",
    "authors": [
      "Francesco Pelosin",
      "Andrea Torsello"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14106"
  },
  {
    "id": "arXiv:2105.14117",
    "title": "About Explicit Variance Minimization: Training Neural Networks for  Medical Imaging With Limited Data Annotations",
    "abstract": "About Explicit Variance Minimization: Training Neural Networks for  Medical Imaging With Limited Data Annotations",
    "descriptor": "",
    "authors": [
      "Dmitrii Shubin",
      "Danny Eytan",
      "Sebastian D. Goodfellow"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14117"
  },
  {
    "id": "arXiv:2105.14187",
    "title": "Prediction error quantification through probabilistic scaling --  EXTENDED VERSION",
    "abstract": "Comments: 8 pages, 2 figure",
    "descriptor": "\nComments: 8 pages, 2 figure\n",
    "authors": [
      "Victor Mirasierra",
      "Martina Mammarella",
      "Fabrizio Dabbene",
      "Teodoro Alamo"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14187"
  },
  {
    "id": "arXiv:2105.14359",
    "title": "Green Tethered UAVs for EMF-Aware Cellular Networks",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Zhengying Lou",
      "Ahmed Elzanaty",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.14359"
  },
  {
    "id": "arXiv:2105.14629",
    "title": "$\\ell_2$-norm Flow Diffusion in Near-Linear Time",
    "abstract": "$\\ell_2$-norm Flow Diffusion in Near-Linear Time",
    "descriptor": "",
    "authors": [
      "Li Chen",
      "Richard Peng",
      "Di Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14629"
  },
  {
    "id": "arXiv:2105.14817",
    "title": "SQUADfps: Integrated Model-Based Machine Safety and Product Quality for  Flexible Production Systems",
    "abstract": "SQUADfps: Integrated Model-Based Machine Safety and Product Quality for  Flexible Production Systems",
    "descriptor": "",
    "authors": [
      "Chee Hung Koo",
      "Stefan Rothbauer",
      "Marian Vorderer",
      "Kai Hoefig",
      "Marc Zeller"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2105.14817"
  },
  {
    "id": "arXiv:2105.14849",
    "title": "Why does CTC result in peaky behavior?",
    "abstract": "Why does CTC result in peaky behavior?",
    "descriptor": "",
    "authors": [
      "Albert Zeyer",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.14849"
  },
  {
    "id": "arXiv:2105.14917",
    "title": "Measurement placement in electric power transmission and distribution  grids: Review of methods and opportunities",
    "abstract": "Measurement placement in electric power transmission and distribution  grids: Review of methods and opportunities",
    "descriptor": "",
    "authors": [
      "Marcos Netto",
      "Venkat Krishnan",
      "Yingchen Zhang",
      "Lamine Mili"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14917"
  },
  {
    "id": "arXiv:2106.00765",
    "title": "Connectivity constrains quantum codes",
    "abstract": "Connectivity constrains quantum codes",
    "descriptor": "",
    "authors": [
      "Nou\u00e9dyn Baspin",
      "Anirudh Krishna"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.00765"
  },
  {
    "id": "arXiv:2106.00909",
    "title": "The Generalized Mean Densest Subgraph Problem",
    "abstract": "The Generalized Mean Densest Subgraph Problem",
    "descriptor": "",
    "authors": [
      "Nate Veldt",
      "Austin R. Benson",
      "Jon Kleinberg"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.00909"
  },
  {
    "id": "arXiv:2106.01226",
    "title": "Semi-Supervised Semantic Segmentation with Cross Pseudo Supervision",
    "abstract": "Comments: Accepted by CVPR 2021",
    "descriptor": "\nComments: Accepted by CVPR 2021\n",
    "authors": [
      "Xiaokang Chen",
      "Yuhui Yuan",
      "Gang Zeng",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01226"
  },
  {
    "id": "arXiv:2106.01410",
    "title": "Uncertainty Quantification 360: A Holistic Toolkit for Quantifying and  Communicating the Uncertainty of AI",
    "abstract": "Comments: Added references",
    "descriptor": "\nComments: Added references\n",
    "authors": [
      "Soumya Ghosh",
      "Q. Vera Liao",
      "Karthikeyan Natesan Ramamurthy",
      "Jiri Navratil",
      "Prasanna Sattigeri",
      "Kush R. Varshney",
      "Yunfeng Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01410"
  },
  {
    "id": "arXiv:2106.01440",
    "title": "Memory Wrap: a Data-Efficient and Interpretable Extension to Image  Classification Models",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Biagio La Rosa",
      "Roberto Capobianco",
      "Daniele Nardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01440"
  },
  {
    "id": "arXiv:2106.01618",
    "title": "Transferable Adversarial Examples for Anchor Free Object Detection",
    "abstract": "Comments: Accepted as oral in ICME 2021",
    "descriptor": "\nComments: Accepted as oral in ICME 2021\n",
    "authors": [
      "Quanyu Liao",
      "Xin Wang",
      "Bin Kong",
      "Siwei Lyu",
      "Bin Zhu",
      "Youbing Yin",
      "Qi Song",
      "Xi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01618"
  },
  {
    "id": "arXiv:2106.01660",
    "title": "Bandit Phase Retrieval",
    "abstract": "Bandit Phase Retrieval",
    "descriptor": "",
    "authors": [
      "Tor Lattimore",
      "Botao Hao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.01660"
  },
  {
    "id": "arXiv:2106.01700",
    "title": "Machine Learning Based Texture Analysis of Patella from X-Rays for  Detecting Patellofemoral Osteoarthritis",
    "abstract": "Machine Learning Based Texture Analysis of Patella from X-Rays for  Detecting Patellofemoral Osteoarthritis",
    "descriptor": "",
    "authors": [
      "Neslihan Bayramoglu",
      "Miika T. Nieminen",
      "Simo Saarakkala"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01700"
  },
  {
    "id": "arXiv:2106.01735",
    "title": "Auto-tagging of Short Conversational Sentences using Transformer Methods",
    "abstract": "Comments: in Turkish language",
    "descriptor": "\nComments: in Turkish language\n",
    "authors": [
      "D. Emre Ta\u015far",
      "\u015e\u00fckr\u00fc Ozan",
      "Umut \u00d6zdil",
      "M. Fatih Akca",
      "O\u011fuzhan \u00d6lmez",
      "Semih G\u00fcl\u00fcm",
      "Se\u00e7ilay Kutal",
      "Ceren Belhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01735"
  },
  {
    "id": "arXiv:2106.01804",
    "title": "E2E-VLP: End-to-End Vision-Language Pre-training Enhanced by Visual  Learning",
    "abstract": "Comments: ACL2021 main conference",
    "descriptor": "\nComments: ACL2021 main conference\n",
    "authors": [
      "Haiyang Xu",
      "Ming Yan",
      "Chenliang Li",
      "Bin Bi",
      "Songfang Huang",
      "Wenming Xiao",
      "Fei Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01804"
  },
  {
    "id": "arXiv:2106.01883",
    "title": "Learning High-Precision Bounding Box for Rotated Object Detection via  Kullback-Leibler Divergence",
    "abstract": "Comments: 15 pages, 5 figures, 7 tables",
    "descriptor": "\nComments: 15 pages, 5 figures, 7 tables\n",
    "authors": [
      "Xue Yang",
      "Xiaojiang Yang",
      "Jirui Yang",
      "Qi Ming",
      "Wentao Wang",
      "Qi Tian",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01883"
  },
  {
    "id": "arXiv:2106.02026",
    "title": "Breaking the Cubic Barrier for (Unweighted) Tree Edit Distance",
    "abstract": "Comments: Minor update removing accidental attachment of figures from an earlier draft",
    "descriptor": "\nComments: Minor update removing accidental attachment of figures from an earlier draft\n",
    "authors": [
      "Xiao Mao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.02026"
  }
]
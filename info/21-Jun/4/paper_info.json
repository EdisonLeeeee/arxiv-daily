[
  {
    "id": "arXiv:2106.01367",
    "title": "On using distributed representations of source code for the detection of  C security vulnerabilities",
    "abstract": "This paper presents an evaluation of the code representation model Code2vec\nwhen trained on the task of detecting security vulnerabilities in C source\ncode. We leverage the open-source library astminer to extract path-contexts\nfrom the abstract syntax trees of a corpus of labeled C functions. Code2vec is\ntrained on the resulting path-contexts with the task of classifying a function\nas vulnerable or non-vulnerable. Using the CodeXGLUE benchmark, we show that\nthe accuracy of Code2vec for this task is comparable to simple\ntransformer-based methods such as pre-trained RoBERTa, and outperforms more\nnaive NLP-based methods. We achieved an accuracy of 61.43% while maintaining\nlow computational requirements relative to larger models.",
    "descriptor": "\nComments: Submitted to DX 2021\n",
    "authors": [
      "David Coimbra",
      "Sofia Reis",
      "Rui Abreu",
      "Corina P\u0103s\u0103reanu",
      "Hakan Erdogmus"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.01367"
  },
  {
    "id": "arXiv:2106.01370",
    "title": "q-RBFNN:A Quantum Calculus-based RBF Neural Network",
    "abstract": "In this research a novel stochastic gradient descent based learning approach\nfor the radial basis function neural networks (RBFNN) is proposed. The proposed\nmethod is based on the q-gradient which is also known as Jackson derivative. In\ncontrast to the conventional gradient, which finds the tangent, the q-gradient\nfinds the secant of the function and takes larger steps towards the optimal\nsolution. The proposed $q$-RBFNN is analyzed for its convergence performance in\nthe context of least square algorithm. In particular, a closed form expression\nof the Wiener solution is obtained, and stability bounds of the learning rate\n(step-size) is derived. The analytical results are validated through computer\nsimulation. Additionally, we propose an adaptive technique for the time-varying\n$q$-parameter to improve convergence speed with no trade-offs in the steady\nstate performance.",
    "descriptor": "\nComments: Article is under review. This is a preprint version\n",
    "authors": [
      "Syed Saiq Hussain",
      "Muhammad Usman",
      "Taha Hasan Masood Siddique",
      "Imran Naseem",
      "Roberto Togneri",
      "Mohammed Bennamoun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Algebra (math.QA)"
    ],
    "url": "https://arxiv.org/abs/2106.01370"
  },
  {
    "id": "arXiv:2106.01382",
    "title": "Undecidability of Learnability",
    "abstract": "Machine learning researchers and practitioners steadily enlarge the multitude\nof successful learning models. They achieve this through in-depth theoretical\nanalyses and experiential heuristics. However, there is no known\ngeneral-purpose procedure for rigorously evaluating whether newly proposed\nmodels indeed successfully learn from data. We show that such a procedure\ncannot exist. For PAC binary classification, uniform and universal online\nlearning, and exact learning through teacher-learner interactions, learnability\nis in general undecidable, both in the sense of independence of the axioms in a\nformal system and in the sense of uncomputability. Our proofs proceed via\ncomputable constructions of function classes that encode the consistency\nproblem for formal systems and the halting problem for Turing machines into\ncomplexity measures that characterize learnability. Our work shows that\nundecidability appears in the theoretical foundations of machine learning:\nThere is no one-size-fits-all algorithm for deciding whether a machine learning\nmodel can be successful. We cannot in general automatize the process of\nassessing new learning models.",
    "descriptor": "\nComments: 21 pages (main body) + 7 pages (reference and appendix); 1 figure\n",
    "authors": [
      "Matthias C. Caro"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.01382"
  },
  {
    "id": "arXiv:2106.01399",
    "title": "Automatic Assessment of the Design Quality of Python Programs with  Personalized Feedback",
    "abstract": "The assessment of program functionality can generally be accomplished with\nstraight-forward unit tests. However, assessing the design quality of a program\nis a much more difficult and nuanced problem. Design quality is an important\nconsideration since it affects the readability and maintainability of programs.\nAssessing design quality and giving personalized feedback is very time\nconsuming task for instructors and teaching assistants. This limits the scale\nof giving personalized feedback to small class settings. Further, design\nquality is nuanced and is difficult to concisely express as a set of rules. For\nthese reasons, we propose a neural network model to both automatically assess\nthe design of a program and provide personalized feedback to guide students on\nhow to make corrections. The model's effectiveness is evaluated on a corpus of\nstudent programs written in Python. The model has an accuracy rate from 83.67%\nto 94.27%, depending on the dataset, when predicting design scores as compared\nto historical instructor assessment. Finally, we present a study where students\ntried to improve the design of their programs based on the personalized\nfeedback produced by the model. Students who participated in the study improved\ntheir program design scores by 19.58%.",
    "descriptor": "",
    "authors": [
      "J. Walker Orr",
      "Nathaniel Russell"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01399"
  },
  {
    "id": "arXiv:2106.01401",
    "title": "Container: Context Aggregation Network",
    "abstract": "Convolutional neural networks (CNNs) are ubiquitous in computer vision, with\na myriad of effective and efficient variations. Recently, Transformers --\noriginally introduced in natural language processing -- have been increasingly\nadopted in computer vision. While early adopters continue to employ CNN\nbackbones, the latest networks are end-to-end CNN-free Transformer solutions. A\nrecent surprising finding shows that a simple MLP based solution without any\ntraditional convolutional or Transformer components can produce effective\nvisual representations. While CNNs, Transformers and MLP-Mixers may be\nconsidered as completely disparate architectures, we provide a unified view\nshowing that they are in fact special cases of a more general method to\naggregate spatial context in a neural network stack. We present the \\model\n(CONText AggregatIon NEtwoRk), a general-purpose building block for multi-head\ncontext aggregation that can exploit long-range interactions \\emph{a la}\nTransformers while still exploiting the inductive bias of the local convolution\noperation leading to faster convergence speeds, often seen in CNNs. In contrast\nto Transformer-based methods that do not scale well to downstream tasks that\nrely on larger input image resolutions, our efficient network, named\n\\modellight, can be employed in object detection and instance segmentation\nnetworks such as DETR, RetinaNet and Mask-RCNN to obtain an impressive\ndetection mAP of 38.9, 43.8, 45.1 and mask mAP of 41.3, providing large\nimprovements of 6.6, 7.3, 6.9 and 6.6 pts respectively, compared to a ResNet-50\nbackbone with a comparable compute and parameter size. Our method also achieves\npromising results on self-supervised learning compared to DeiT on the DINO\nframework.",
    "descriptor": "",
    "authors": [
      "Peng Gao",
      "Jiasen Lu",
      "Hongsheng Li",
      "Roozbeh Mottaghi",
      "Aniruddha Kembhavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01401"
  },
  {
    "id": "arXiv:2106.01404",
    "title": "Variational Empowerment as Representation Learning for Goal-Based  Reinforcement Learning",
    "abstract": "Learning to reach goal states and learning diverse skills through mutual\ninformation (MI) maximization have been proposed as principled frameworks for\nself-supervised reinforcement learning, allowing agents to acquire broadly\napplicable multitask policies with minimal reward engineering. Starting from a\nsimple observation that the standard goal-conditioned RL (GCRL) is encapsulated\nby the optimization objective of variational empowerment, we discuss how GCRL\nand MI-based RL can be generalized into a single family of methods, which we\nname variational GCRL (VGCRL), interpreting variational MI maximization, or\nvariational empowerment, as representation learning methods that acquire\nfunctionally-aware state representations for goal reaching. This novel\nperspective allows us to: (1) derive simple but unexplored variants of GCRL to\nstudy how adding small representation capacity can already expand its\ncapabilities; (2) investigate how discriminator function capacity and\nsmoothness determine the quality of discovered skills, or latent goals, through\nmodifying latent dimensionality and applying spectral normalization; (3) adapt\ntechniques such as hindsight experience replay (HER) from GCRL to MI-based RL;\nand lastly, (4) propose a novel evaluation metric, named latent goal reaching\n(LGR), for comparing empowerment algorithms with different choices of latent\ndimensionality and discriminator parameterization. Through principled\nmathematical derivations and careful experimental studies, our work lays a\nnovel foundation from which to evaluate, analyze, and develop representation\nlearning techniques in goal-based RL.",
    "descriptor": "\nComments: Accepted at International Conference on Machine Learning (ICML) 2021\n",
    "authors": [
      "Jongwook Choi",
      "Archit Sharma",
      "Honglak Lee",
      "Sergey Levine",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01404"
  },
  {
    "id": "arXiv:2106.01410",
    "title": "Uncertainty Quantification 360: A Holistic Toolkit for Quantifying and  Communicating the Uncertainty of AI",
    "abstract": "In this paper, we describe an open source Python toolkit named Uncertainty\nQuantification 360 (UQ360) for the uncertainty quantification of AI models. The\ngoal of this toolkit is twofold: firstly, to provide a broad range of\ncapabilities to streamline, and hopefully foster the common practices of\nquantifying, evaluating, improving, and communicating uncertainty in the AI\napplication development lifecycle; secondly, to disseminate the latest research\nand educational materials for uncertainty quantification in machine learning,\nand encourage further exploration of its utility and connections to other\npillars of trustworthy AI such as fairness and explainability. Beyond the\nPython package (\\url{https://github.com/IBM/UQ360}), we have developed an\ninteractive experience (\\url{this http URL}) and guidance\nmaterials as educational tools to aid researchers and developers in producing\nand communicating high-quality uncertainties in an effective manner.",
    "descriptor": "",
    "authors": [
      "Soumya Ghosh",
      "Q. Vera Liao",
      "Karthikeyan Natesan Ramamurthy",
      "Jiri Navratil",
      "Prasanna Sattigeri",
      "Kush R. Varshney",
      "Yunfeng Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01410"
  },
  {
    "id": "arXiv:2106.01414",
    "title": "Normalization for multimodal type theory",
    "abstract": "We consider the conversion problem for multimodal type theory (MTT) by\ncharacterizing the normal forms of the type theory and proving normalization.\nNormalization follows from a novel adaptation of Sterling's Synthetic Tait\nComputability which generalizes the framework to accommodate a type theory with\nmodalities and multiple modes. As a corollary of our main result, we reduce the\nconversion problem of MTT to the conversion problem of its mode theory and show\nthe injectivity of type constructors. Finally, we conclude that MTT enjoys\ndecidable type-checking when instantiated with a decidable mode theory.",
    "descriptor": "",
    "authors": [
      "Daniel Gratzer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.01414"
  },
  {
    "id": "arXiv:2106.01415",
    "title": "A Preliminary Study of a Two-Stage Paradigm for Preserving Speaker  Identity in Dysarthric Voice Conversion",
    "abstract": "We propose a new paradigm for maintaining speaker identity in dysarthric\nvoice conversion (DVC). The poor quality of dysarthric speech can be greatly\nimproved by statistical VC, but as the normal speech utterances of a dysarthria\npatient are nearly impossible to collect, previous work failed to recover the\nindividuality of the patient. In light of this, we suggest a novel, two-stage\napproach for DVC, which is highly flexible in that no normal speech of the\npatient is required. First, a powerful parallel sequence-to-sequence model\nconverts the input dysarthric speech into a normal speech of a reference\nspeaker as an intermediate product, and a nonparallel, frame-wise VC model\nrealized with a variational autoencoder then converts the speaker identity of\nthe reference speech back to that of the patient while assumed to be capable of\npreserving the enhanced quality. We investigate several design options.\nExperimental evaluation results demonstrate the potential of our approach to\nimproving the quality of the dysarthric speech while maintaining the speaker\nidentity.",
    "descriptor": "\nComments: Accepted to Interspeech 2021. 5 pages, 3 figures, 1 table\n",
    "authors": [
      "Wen-Chin Huang",
      "Kazuhiro Kobayashi",
      "Yu-Huai Peng",
      "Ching-Feng Liu",
      "Yu Tsao",
      "Hsin-Min Wang",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.01415"
  },
  {
    "id": "arXiv:2106.01416",
    "title": "Ebola Optimization Search Algorithm (EOSA): A new metaheuristic  algorithm based on the propagation model of Ebola virus disease",
    "abstract": "The Ebola virus and the disease in effect tend to randomly move individuals\nin the population around susceptible, infected, quarantined, hospitalized,\nrecovered, and dead sub-population. Motivated by the effectiveness in\npropagating the disease through the virus, a new bio-inspired and\npopulation-based optimization algorithm is proposed. This paper presents a\nnovel metaheuristic algorithm named Ebola optimization algorithm (EOSA). To\ncorrectly achieve this, this study models the propagation mechanism of the\nEbola virus disease, emphasising all consistent states of the propagation. The\nmodel was further represented using a mathematical model based on first-order\ndifferential equations. After that, the combined propagation and mathematical\nmodels were adapted for developing the new metaheuristic algorithm. To evaluate\nthe proposed method's performance and capability compared with other\noptimization methods, the underlying propagation and mathematical models were\nfirst investigated to determine how they successfully simulate the EVD.\nFurthermore, two sets of benchmark functions consisting of forty-seven (47)\nclassical and over thirty (30) constrained IEEE CEC-2017 benchmark functions\nare investigated numerically. The results indicate that the performance of the\nproposed algorithm is competitive with other state-of-the-art optimization\nmethods based on scalability analysis, convergence analysis, and sensitivity\nanalysis. Extensive simulation results indicate that the EOSA outperforms other\nstate-of-the-art popular metaheuristic optimization algorithms such as the\nParticle Swarm Optimization Algorithm (PSO), Genetic Algorithm (GA), and\nArtificial Bee Colony Algorithm (ABC) on some shifted, high dimensional and\nlarge search range problems.",
    "descriptor": "",
    "authors": [
      "Olaide N. Oyelade",
      "Absalom E. Ezugwu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01416"
  },
  {
    "id": "arXiv:2106.01420",
    "title": "Parallelizing Thompson Sampling",
    "abstract": "How can we make use of information parallelism in online decision making\nproblems while efficiently balancing the exploration-exploitation trade-off? In\nthis paper, we introduce a batch Thompson Sampling framework for two canonical\nonline decision making problems, namely, stochastic multi-arm bandit and linear\ncontextual bandit with finitely many arms. Over a time horizon $T$, our\n\\textit{batch} Thompson Sampling policy achieves the same (asymptotic) regret\nbound of a fully sequential one while carrying out only $O(\\log T)$ batch\nqueries. To achieve this exponential reduction, i.e., reducing the number of\ninteractions from $T$ to $O(\\log T)$, our batch policy dynamically determines\nthe duration of each batch in order to balance the exploration-exploitation\ntrade-off. We also demonstrate experimentally that dynamic batch allocation\ndramatically outperforms natural baselines such as static batch allocations.",
    "descriptor": "",
    "authors": [
      "Amin Karbasi",
      "Vahab Mirrokni",
      "Mohammad Shadravan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01420"
  },
  {
    "id": "arXiv:2106.01423",
    "title": "One Representation to Rule Them All: Identifying Out-of-Support Examples  in Few-shot Learning with Generic Representations",
    "abstract": "The field of few-shot learning has made remarkable strides in developing\npowerful models that can operate in the small data regime. Nearly all of these\nmethods assume every unlabeled instance encountered will belong to a handful of\nknown classes for which one has examples. This can be problematic for\nreal-world use cases where one routinely finds 'none-of-the-above' examples. In\nthis paper we describe this challenge of identifying what we term\n'out-of-support' (OOS) examples. We describe how this problem is subtly\ndifferent from out-of-distribution detection and describe a new method of\nidentifying OOS examples within the Prototypical Networks framework using a\nfixed point which we call the generic representation. We show that our method\noutperforms other existing approaches in the literature as well as other\napproaches that we propose in this paper. Finally, we investigate how the use\nof such a generic point affects the geometry of a model's feature space.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Henry Kvinge",
      "Scott Howland",
      "Nico Courts",
      "Lauren A. Phillips",
      "John Buckheit",
      "Zachary New",
      "Elliott Skomski",
      "Jung H. Lee",
      "Sandeep Tiwari",
      "Jessica Hibler",
      "Courtney D. Corley",
      "Nathan O. Hodas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2106.01423"
  },
  {
    "id": "arXiv:2106.01424",
    "title": "Learning to Select: A Fully Attentive Approach for Novel Object  Captioning",
    "abstract": "Image captioning models have lately shown impressive results when applied to\nstandard datasets. Switching to real-life scenarios, however, constitutes a\nchallenge due to the larger variety of visual concepts which are not covered in\nexisting training sets. For this reason, novel object captioning (NOC) has\nrecently emerged as a paradigm to test captioning models on objects which are\nunseen during the training phase. In this paper, we present a novel approach\nfor NOC that learns to select the most relevant objects of an image, regardless\nof their adherence to the training set, and to constrain the generative process\nof a language model accordingly. Our architecture is fully-attentive and\nend-to-end trainable, also when incorporating constraints. We perform\nexperiments on the held-out COCO dataset, where we demonstrate improvements\nover the state of the art, both in terms of adaptability to novel objects and\ncaption quality.",
    "descriptor": "\nComments: ICMR 2021\n",
    "authors": [
      "Marco Cagrandi",
      "Marcella Cornia",
      "Matteo Stefanini",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01424"
  },
  {
    "id": "arXiv:2106.01425",
    "title": "Gradient Assisted Learning",
    "abstract": "In distributed settings, collaborations between different entities, such as\nfinancial institutions, medical centers, and retail markets, are crucial to\nproviding improved service and performance. However, the underlying entities\nmay have little interest in sharing their private data, proprietary models, and\nobjective functions. These privacy requirements have created new challenges for\ncollaboration. In this work, we propose Gradient Assisted Learning (GAL), a new\nmethod for various entities to assist each other in supervised learning tasks\nwithout sharing data, models, and objective functions. In this framework, all\nparticipants collaboratively optimize the aggregate of local loss functions,\nand each participant autonomously builds its own model by iteratively fitting\nthe gradients of the objective function. Experimental studies demonstrate that\nGradient Assisted Learning can achieve performance close to centralized\nlearning when all data, models, and objective functions are fully disclosed.",
    "descriptor": "",
    "authors": [
      "Enmao Diao",
      "Jie Ding",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01425"
  },
  {
    "id": "arXiv:2106.01428",
    "title": "Unsharp Mask Guided Filtering",
    "abstract": "The goal of this paper is guided image filtering, which emphasizes the\nimportance of structure transfer during filtering by means of an additional\nguidance image. Where classical guided filters transfer structures using\nhand-designed functions, recent guided filters have been considerably advanced\nthrough parametric learning of deep networks. The state-of-the-art leverages\ndeep networks to estimate the two core coefficients of the guided filter. In\nthis work, we posit that simultaneously estimating both coefficients is\nsuboptimal, resulting in halo artifacts and structure inconsistencies. Inspired\nby unsharp masking, a classical technique for edge enhancement that requires\nonly a single coefficient, we propose a new and simplified formulation of the\nguided filter. Our formulation enjoys a filtering prior from a low-pass filter\nand enables explicit structure transfer by estimating a single coefficient.\nBased on our proposed formulation, we introduce a successive guided filtering\nnetwork, which provides multiple filtering results from a single network,\nallowing for a trade-off between accuracy and efficiency. Extensive ablations,\ncomparisons and analysis show the effectiveness and efficiency of our\nformulation and network, resulting in state-of-the-art results across filtering\ntasks like upsampling, denoising, and cross-modality filtering. Code is\navailable at \\url{https://github.com/shizenglin/Unsharp-Mask-Guided-Filtering}.",
    "descriptor": "\nComments: IEEE Transactions on Image Processing, 2021\n",
    "authors": [
      "Zenglin Shi",
      "Yunlu Chen",
      "Efstratios Gavves",
      "Pascal Mettes",
      "Cees G.M. Snoek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01428"
  },
  {
    "id": "arXiv:2106.01432",
    "title": "SemiFL: Communication Efficient Semi-Supervised Federated Learning with  Unlabeled Clients",
    "abstract": "Federated Learning allows training machine learning models by using the\ncomputation and private data resources of a large number of distributed clients\nsuch as smartphones and IoT devices. Most existing works on Federated Learning\n(FL) assume the clients have ground-truth labels. However, in many practical\nscenarios, clients may be unable to label task-specific data, e.g., due to lack\nof expertise. In this work, we consider a server that hosts a labeled dataset,\nand wishes to leverage clients with unlabeled data for supervised learning. We\npropose a new Federated Learning framework referred to as SemiFL in order to\naddress the problem of Semi-Supervised Federated Learning (SSFL). In SemiFL,\nclients have completely unlabeled data, while the server has a small amount of\nlabeled data. SemiFL is communication efficient since it separates the training\nof server-side supervised data and client-side unsupervised data. We\ndemonstrate various efficient strategies of SemiFL that enhance learning\nperformance. Extensive empirical evaluations demonstrate that our communication\nefficient method can significantly improve the performance of a labeled server\nwith unlabeled clients. Moreover, we demonstrate that SemiFL can outperform\nmany existing FL results trained with fully supervised data, and perform\ncompetitively with the state-of-the-art centralized Semi-Supervised Learning\n(SSL) methods. For instance, in standard communication efficient scenarios, our\nmethod can perform 93% accuracy on the CIFAR10 dataset with only 4000 labeled\nsamples at the server. Such accuracy is only 2% away from the result trained\nfrom 50000 fully labeled data, and it improves about 30% upon existing SSFL\nmethods in the communication efficient setting.",
    "descriptor": "",
    "authors": [
      "Enmao Diao",
      "Jie Ding",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01432"
  },
  {
    "id": "arXiv:2106.01434",
    "title": "Robot in a China Shop: Using Reinforcement Learning for  Location-Specific Navigation Behaviour",
    "abstract": "Robots need to be able to work in multiple different environments. Even when\nperforming similar tasks, different behaviour should be deployed to best fit\nthe current environment. In this paper, We propose a new approach to\nnavigation, where it is treated as a multi-task learning problem. This enables\nthe robot to learn to behave differently in visual navigation tasks for\ndifferent environments while also learning shared expertise across\nenvironments. We evaluated our approach in both simulated environments as well\nas real-world data. Our method allows our system to converge with a 26%\nreduction in training time, while also increasing accuracy.",
    "descriptor": "\nComments: Published at ICRA 2021\n",
    "authors": [
      "Xihan Bian",
      "Oscar Mendez",
      "Simon Hadfield"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01434"
  },
  {
    "id": "arXiv:2106.01438",
    "title": "A Leader-Follower Game Theoretic Approach to Arrest Cascading Failure in  Smart Grid",
    "abstract": "The Smart Grid System (SGS) is a joint network comprising the power and the\ncommunication network. In this paper, the underlying\nintra-and-interdependencies between entities for a given SGS is captured using\na dependency model called Modified Implicative Interdependency Model (MIIM)\n[1]. Given an integer K, the K-contingency list problem gives the list of\nK-most critical entities, failure of which maximizes the network damage at the\ncurrent time. The problem being NP complete [2] and owing to the higher running\ntime of the given Integer Linear Programming (ILP) based solution [3], a much\nfaster heuristic solution to generate an event driven self-updating\nK-contingency list [4] is also given in this paper. Based on the contingency\nlists obtained from both the solutions, this paper proposes an adaptive entity\nhardening technique based on a leader-follower game theoretic approach that\narrests the cascading failure of entities in the SGS after an initial failure\nof entities. The validation of the work is done by comparing the contingency\nlists using both types of solutions, obtained for different K values using the\nMIIM model on a smart grid of IEEE 14-Bus system with that obtained by\nsimulating the smart grid using a co-simulation system formed by MATPOWER and\nJava Network Simulator (JNS). The K-contingency list obtained for a smart grid\nof IEEE 14-Bus system also indicate that the network damage predicted by both\nthe ILP based solution and heuristic solution using MIIM are more realistic\ncompared to that obtained using another dependency model called Implicative\nInterdependency Model (IIM) [2]. Advantage of using the MIIM based heuristic\nsolution is also shown in this paper when larger SGS of IEEE 118-Bus is\nconsidered. Finally, it is shown how the adaptive hardening helps in improving\nthe network performance.",
    "descriptor": "\nComments: This paper is accepted for publication in American Journal of Science and Engineering. arXiv admin note: text overlap with arXiv:2101.08896\n",
    "authors": [
      "Sohini Roy",
      "Arunabha Sen"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.01438"
  },
  {
    "id": "arXiv:2106.01439",
    "title": "NTIRE 2021 Challenge on High Dynamic Range Imaging: Dataset, Methods and  Results",
    "abstract": "This paper reviews the first challenge on high-dynamic range (HDR) imaging\nthat was part of the New Trends in Image Restoration and Enhancement (NTIRE)\nworkshop, held in conjunction with CVPR 2021. This manuscript focuses on the\nnewly introduced dataset, the proposed methods and their results. The challenge\naims at estimating a HDR image from one or multiple respective low-dynamic\nrange (LDR) observations, which might suffer from under- or over-exposed\nregions and different sources of noise. The challenge is composed by two\ntracks: In Track 1 only a single LDR image is provided as input, whereas in\nTrack 2 three differently-exposed LDR images with inter-frame motion are\navailable. In both tracks, the ultimate goal is to achieve the best objective\nHDR reconstruction in terms of PSNR with respect to a ground-truth image,\nevaluated both directly and with a canonical tonemapping operation.",
    "descriptor": "\nComments: To appear in CVPRW 2021 (NTIRE)\n",
    "authors": [
      "Eduardo P\u00e9rez-Pellitero",
      "Sibi Catley-Chandar",
      "Ale\u0161 Leonardis",
      "Radu Timofte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.01439"
  },
  {
    "id": "arXiv:2106.01440",
    "title": "Memory Wrap: a Data-Efficient and Interpretable Extension to Image  Classification Models",
    "abstract": "Due to their black-box and data-hungry nature, deep learning techniques are\nnot yet widely adopted for real-world applications in critical domains, like\nhealthcare and justice. This paper presents Memory Wrap, a plug-and-play\nextension to any image classification model. Memory Wrap improves both\ndata-efficiency and model interpretability, adopting a content-attention\nmechanism between the input and some memories of past training samples. We show\nthat Memory Wrap outperforms standard classifiers when it learns from a limited\nset of data, and it reaches comparable performance when it learns from the full\ndataset. We discuss how its structure and content-attention mechanisms make\npredictions interpretable, compared to standard classifiers. To this end, we\nboth show a method to build explanations by examples and counterfactuals, based\non the memory content, and how to exploit them to get insights about its\ndecision process. We test our approach on image classification tasks using\nseveral architectures on three different datasets, namely CIFAR10, SVHN, and\nCINIC10.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Biagio La Rosa",
      "Roberto Capobianco",
      "Daniele Nardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01440"
  },
  {
    "id": "arXiv:2106.01441",
    "title": "Optimization of Heterogeneous Systems with AI Planning Heuristics and  Machine Learning: A Performance and Energy Aware Approach",
    "abstract": "Heterogeneous computing systems provide high performance and energy\nefficiency. However, to optimally utilize such systems, solutions that\ndistribute the work across host CPUs and accelerating devices are needed. In\nthis paper, we present a performance and energy aware approach that combines AI\nplanning heuristics for parameter space exploration with a machine learning\nmodel for performance and energy evaluation to determine a near-optimal system\nconfiguration. For data-parallel applications our approach determines a\nnear-optimal host-device distribution of work, number of processing units\nrequired and the corresponding scheduling strategy. We evaluate our approach\nfor various heterogeneous systems accelerated with GPU or the Intel Xeon Phi.\nThe experimental results demonstrate that our approach finds a near-optimal\nsystem configuration by evaluating only about 7% of reasonable configurations.\nFurthermore, the performance per Joule estimation of system configurations\nusing our machine learning model is more than 1000x faster compared to the\nsystem evaluation by program execution.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Suejb Memeti",
      "Sabri Pllana"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01441"
  },
  {
    "id": "arXiv:2106.01444",
    "title": "SMURF: SeMantic and linguistic UndeRstanding Fusion for Caption  Evaluation via Typicality Analysis",
    "abstract": "The open-ended nature of visual captioning makes it a challenging area for\nevaluation. The majority of proposed models rely on specialized training to\nimprove human-correlation, resulting in limited adoption, generalizability, and\nexplainabilty. We introduce \"typicality\", a new formulation of evaluation\nrooted in information theory, which is uniquely suited for problems lacking a\ndefinite ground truth. Typicality serves as our framework to develop a novel\nsemantic comparison, SPARCS, as well as referenceless fluency evaluation\nmetrics. Over the course of our analysis, two separate dimensions of fluency\nnaturally emerge: style, captured by metric SPURTS, and grammar, captured in\nthe form of grammatical outlier penalties. Through extensive experiments and\nablation studies on benchmark datasets, we show how these decomposed dimensions\nof semantics and fluency provide greater system-level insight into captioner\ndifferences. Our proposed metrics along with their combination, SMURF, achieve\nstate-of-the-art correlation with human judgment when compared with other\nrule-based evaluation metrics.",
    "descriptor": "",
    "authors": [
      "Joshua Feinglass",
      "Yezhou Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01444"
  },
  {
    "id": "arXiv:2106.01446",
    "title": "Gender-Specific Patterns in the Artificial Intelligence Scientific  Ecosystem",
    "abstract": "Gender disparity in science is one of the most focused debating points among\nauthorities and the scientific community. Over the last few decades, numerous\ninitiatives have endeavored to accelerate gender equity in academia and\nresearch society. However, despite the ongoing efforts, gaps persist across the\nworld, and more measures need to be taken. Using social network analysis,\nnatural language processing, and machine learning, in this study, we\ncomprehensively analyzed gender-specific patterns in the highly\ninterdisciplinary and evolving field of artificial intelligence for the period\nof 2000-2019. Our findings suggest an overall increasing rate of mixed-gender\ncollaborations. From the observed gender-specific collaborative patterns, the\nexistence of disciplinary homophily at both dyadic and team levels is\nconfirmed. However, a higher preference was observed for female researchers to\nform homophilous collaborative links. Our core-periphery analysis indicated a\nsignificant positive association between having diverse collaboration and\nscientific performance and experience. We found evidence in support of\nexpecting the rise of new female superstar researchers in the artificial\nintelligence field.",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Anahita Hajibabaei",
      "Andrea Schiffauerova",
      "Ashkan Ebadi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.01446"
  },
  {
    "id": "arXiv:2106.01451",
    "title": "Attention-based Contextual Language Model Adaptation for Speech  Recognition",
    "abstract": "Language modeling (LM) for automatic speech recognition (ASR) does not\nusually incorporate utterance level contextual information. For some domains\nlike voice assistants, however, additional context, such as the time at which\nan utterance was spoken, provides a rich input signal. We introduce an\nattention mechanism for training neural speech recognition language models on\nboth text and non-linguistic contextual data. When applied to a large\nde-identified dataset of utterances collected by a popular voice assistant\nplatform, our method reduces perplexity by 7.0% relative over a standard LM\nthat does not incorporate contextual information. When evaluated on utterances\nextracted from the long tail of the dataset, our method improves perplexity by\n9.0% relative over a standard LM and by over 2.8% relative when compared to a\nstate-of-the-art model for contextual LM.",
    "descriptor": "",
    "authors": [
      "Richard Diehl Martinez",
      "Scott Novotney",
      "Ivan Bulyko",
      "Ariya Rastrow",
      "Andreas Stolcke",
      "Ankur Gandhe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01451"
  },
  {
    "id": "arXiv:2106.01452",
    "title": "BERT-Defense: A Probabilistic Model Based on BERT to Combat Cognitively  Inspired Orthographic Adversarial Attacks",
    "abstract": "Adversarial attacks expose important blind spots of deep learning systems.\nWhile word- and sentence-level attack scenarios mostly deal with finding\nsemantic paraphrases of the input that fool NLP models, character-level attacks\ntypically insert typos into the input stream. It is commonly thought that these\nare easier to defend via spelling correction modules. In this work, we show\nthat both a standard spellchecker and the approach of Pruthi et al. (2019),\nwhich trains to defend against insertions, deletions and swaps, perform poorly\non the character-level benchmark recently proposed in Eger and Benz (2020)\nwhich includes more challenging attacks such as visual and phonetic\nperturbations and missing word segmentations. In contrast, we show that an\nuntrained iterative approach which combines context-independent character-level\ninformation with context-dependent information from BERT's masked language\nmodeling can perform on par with human crowd-workers from Amazon Mechanical\nTurk (AMT) supervised via 3-shot learning.",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Yannik Keller",
      "Jan Mackensen",
      "Steffen Eger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01452"
  },
  {
    "id": "arXiv:2106.01459",
    "title": "Comprehensive Energy Footprint Benchmarking Algorithm for Electrified  Powertrains",
    "abstract": "Autonomy and electrification in automotive control systems have made\nmodern-day powertrains one of the most complex cyber-physical systems. This\npaper presents a benchmark algorithm to quantify the performance of complex\nautomotive systems exhibiting mechanical, electrical, and thermal interactions\nat various time-scales. Traditionally Dynamic Programming has been used for\nbenchmarking the performance, however, it fails to deliver results for system\nwith higher number of states and control lever due to curse of dimensionality.\nWe propose \"PS3\", a three-step algorithm for mixed-integer nonlinear optimal\ncontrol problems with application to powertrain energy management. PS3 uses\npseudo-spectral collocation theory for highly accurate modeling of dynamics.\nBased on the validated powertrain component models, we have addressed\nsimultaneous optimization of electrical (SOC), vehicular (eco-driving) and\nthermal (after-treatment and battery temperatures) dynamics along with an\ninteger (gear and engine on/off) control and its corresponding (dwell-time)\nconstraints. PS3 is used to solve such large-scale powertrain problems having\nfast and slow dynamic states, discontinuous behaviors, non-differentiable and\nlinearly interpolated 1-D and 2-D maps, as well as combinatorial constraints.\nFive case study powertrain control problems are given to benchmark the accuracy\nand computational effort against Dynamic Programming. Our analysis shows that\nthis algorithm does not scale computational burden as Dynamic Programming does,\nand can handle highly complex interactions that occur in modern-day\npowertrains, without compromising nonlinear and complex plant modeling.",
    "descriptor": "",
    "authors": [
      "Hamza Anwar",
      "Aashrith Vishwanath",
      "Apurva Chunodkar",
      "Qadeer Ahmed"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01459"
  },
  {
    "id": "arXiv:2106.01463",
    "title": "Lightweight Adapter Tuning for Multilingual Speech Translation",
    "abstract": "Adapter modules were recently introduced as an efficient alternative to\nfine-tuning in NLP. Adapter tuning consists in freezing pretrained parameters\nof a model and injecting lightweight modules between layers, resulting in the\naddition of only a small number of task-specific trainable parameters. While\nadapter tuning was investigated for multilingual neural machine translation,\nthis paper proposes a comprehensive analysis of adapters for multilingual\nspeech translation (ST). Starting from different pre-trained models (a\nmultilingual ST trained on parallel data or a multilingual BART (mBART) trained\non non-parallel multilingual data), we show that adapters can be used to: (a)\nefficiently specialize ST to specific language pairs with a low extra cost in\nterms of parameters, and (b) transfer from an automatic speech recognition\n(ASR) task and an mBART pre-trained model to a multilingual ST task.\nExperiments show that adapter tuning offer competitive results to full\nfine-tuning, while being much more parameter-efficient.",
    "descriptor": "\nComments: Accepted at ACL-IJCNLP 2021\n",
    "authors": [
      "Hang Le",
      "Juan Pino",
      "Changhan Wang",
      "Jiatao Gu",
      "Didier Schwab",
      "Laurent Besacier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01463"
  },
  {
    "id": "arXiv:2106.01465",
    "title": "Ethical-Advice Taker: Do Language Models Understand Natural Language  Interventions?",
    "abstract": "Is it possible to use natural language to intervene in a model's behavior and\nalter its prediction in a desired way? We investigate the effectiveness of\nnatural language interventions for reading-comprehension systems, studying this\nin the context of social stereotypes. Specifically, we propose a new language\nunderstanding task, Linguistic Ethical Interventions (LEI), where the goal is\nto amend a question-answering (QA) model's unethical behavior by communicating\ncontext-specific principles of ethics and equity to it. To this end, we build\nupon recent methods for quantifying a system's social stereotypes, augmenting\nthem with different kinds of ethical interventions and the desired model\nbehavior under such interventions. Our zero-shot evaluation finds that even\ntoday's powerful neural language models are extremely poor ethical-advice\ntakers, that is, they respond surprisingly little to ethical interventions even\nthough these interventions are stated as simple sentences. Few-shot learning\nimproves model behavior but remains far from the desired outcome, especially\nwhen evaluated for various types of generalization. Our new task thus poses a\nnovel language understanding challenge for the community.",
    "descriptor": "\nComments: 9 pages, Findings of ACL-IJCNLP 2021\n",
    "authors": [
      "Jieyu Zhao",
      "Daniel Khashabi",
      "Tushar Khot",
      "Ashish Sabharwal",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01465"
  },
  {
    "id": "arXiv:2106.01467",
    "title": "Domain Adaptation for Facial Expression Classifier via Domain  Discrimination and Gradient Reversal",
    "abstract": "Bringing empathy to a computerized system could significantly improve the\nquality of human-computer communications, as soon as machines would be able to\nunderstand customer intentions and better serve their needs. According to\ndifferent studies (Literature Review), visual information is one of the most\nimportant channels of human interaction and contains significant behavioral\nsignals, that may be captured from facial expressions. Therefore, it is\nconsistent and natural that the research in the field of Facial Expression\nRecognition (FER) has acquired increased interest over the past decade due to\nhaving diverse application area including health-care, sociology, psychology,\ndriver-safety, virtual reality, cognitive sciences, security, entertainment,\nmarketing, etc. We propose a new architecture for the task of FER and examine\nthe impact of domain discrimination loss regularization on the learning\nprocess. With regard to observations, including both classical training\nconditions and unsupervised domain adaptation scenarios, important aspects of\nthe considered domain adaptation approach integration are traced. The results\nmay serve as a foundation for further research in the field.",
    "descriptor": "",
    "authors": [
      "Kamil Akhmetov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01467"
  },
  {
    "id": "arXiv:2106.01478",
    "title": "Evaluating the Efficacy of Summarization Evaluation across Languages",
    "abstract": "While automatic summarization evaluation methods developed for English are\nroutinely applied to other languages, this is the first attempt to\nsystematically quantify their panlinguistic efficacy. We take a summarization\ncorpus for eight different languages, and manually annotate generated summaries\nfor focus (precision) and coverage (recall). Based on this, we evaluate 19\nsummarization evaluation metrics, and find that using multilingual BERT within\nBERTScore performs well across all languages, at a level above that for\nEnglish.",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Fajri Koto",
      "Jey Han Lau",
      "Timothy Baldwin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01478"
  },
  {
    "id": "arXiv:2106.01482",
    "title": "Dagger: Accelerating RPCs in Cloud Microservices Through Tightly-Coupled  Reconfigurable NICs",
    "abstract": "The ongoing shift of cloud services from monolithic designs to microservices\ncreates high demand for efficient and high performance datacenter networking\nstacks, optimized for fine-grained workloads. Commodity networking systems\nbased on software stacks and peripheral NICs introduce high overheads when it\ncomes to delivering small messages.\nWe present Dagger, a hardware acceleration fabric for cloud RPCs based on\nFPGAs, where the accelerator is closely-coupled with the host processor over a\nconfigurable memory interconnect. The three key design principle of Dagger are:\n(1) offloading the entire RPC stack to an FPGA-based NIC, (2) leveraging memory\ninterconnects instead of PCIe buses as the interface with the host CPU, and (3)\nmaking the acceleration fabric reconfigurable, so it can accommodate the\ndiverse needs of microservices. We show that the combination of these\nprinciples significantly improves the efficiency and performance of cloud RPC\nsystems while preserving their generality. Dagger achieves 1.3-3.8x higher\nper-core RPC throughput compared to both highly-optimized software stacks, and\nsystems using specialized RDMA adapters. It also scales up to 84 Mrps with 8\nthreads on 4 CPU cores, while maintaining state-of-the-art us-scale tail\nlatency. We also demonstrate that large third-party applications, like\nmemcached and MICA KVS, can be easily ported on Dagger with minimal changes to\ntheir codebase, bringing their median and tail KVS access latency down to 2.8 -\n3.5us and 5.4 - 7.8us, respectively. Finally, we show that Dagger is beneficial\nfor multi-tier end-to-end microservices with different threading models by\nevaluating it using an 8-tier application implementing a flight check-in\nservice.",
    "descriptor": "",
    "authors": [
      "Nikita Lazarev",
      "Shaojie Xiang",
      "Neil Adit",
      "Zhiru Zhang",
      "Christina Delimitrou"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.01482"
  },
  {
    "id": "arXiv:2106.01483",
    "title": "Multiscale Domain Adaptive YOLO for Cross-Domain Object Detection",
    "abstract": "The area of domain adaptation has been instrumental in addressing the domain\nshift problem encountered by many applications. This problem arises due to the\ndifference between the distributions of source data used for training in\ncomparison with target data used during realistic testing scenarios. In this\npaper, we introduce a novel MultiScale Domain Adaptive YOLO (MS-DAYOLO)\nframework that employs multiple domain adaptation paths and corresponding\ndomain classifiers at different scales of the recently introduced YOLOv4 object\ndetector to generate domain-invariant features. We train and test our proposed\nmethod using popular datasets. Our experiments show significant improvements in\nobject detection performance when training YOLOv4 using the proposed MS-DAYOLO\nand when tested on target data representing challenging weather conditions for\nautonomous driving applications.",
    "descriptor": "\nComments: accepted in 2021 IEEE International Conference on Image Processing (ICIP)\n",
    "authors": [
      "Mazin Hnewa",
      "Hayder Radha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01483"
  },
  {
    "id": "arXiv:2106.01487",
    "title": "LLC: Accurate, Multi-purpose Learnt Low-dimensional Binary Codes",
    "abstract": "Learning binary representations of instances and classes is a classical\nproblem with several high potential applications. In modern settings, the\ncompression of high-dimensional neural representations to low-dimensional\nbinary codes is a challenging task and often require large bit-codes to be\naccurate. In this work, we propose a novel method for Learning Low-dimensional\nbinary Codes (LLC) for instances as well as classes. Our method does not\nrequire any side-information, like annotated attributes or label meta-data, and\nlearns extremely low-dimensional binary codes (~20 bits for ImageNet-1K). The\nlearnt codes are super-efficient while still ensuring nearly optimal\nclassification accuracy for ResNet50 on ImageNet-1K. We demonstrate that the\nlearnt codes capture intrinsically important features in the data, by\ndiscovering an intuitive taxonomy over classes. We further quantitatively\nmeasure the quality of our codes by applying it to the efficient image\nretrieval as well as out-of-distribution (OOD) detection problems. For\nImageNet-100 retrieval problem, our learnt binary codes outperform 16 bit\nHashNet using only 10 bits and also are as accurate as 10 dimensional real\nrepresentations. Finally, our learnt binary codes can perform OOD detection,\nout-of-the-box, as accurately as a baseline that needs ~3000 samples to tune\nits threshold, while we require none. Code and pre-trained models are available\nat https://github.com/RAIVNLab/LLC.",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Aditya Kusupati",
      "Matthew Wallingford",
      "Vivek Ramanujan",
      "Raghav Somani",
      "Jae Sung Park",
      "Krishna Pillutla",
      "Prateek Jain",
      "Sham Kakade",
      "Ali Farhadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01487"
  },
  {
    "id": "arXiv:2106.01488",
    "title": "Minimax Optimization with Smooth Algorithmic Adversaries",
    "abstract": "This paper considers minimax optimization $\\min_x \\max_y f(x, y)$ in the\nchallenging setting where $f$ can be both nonconvex in $x$ and nonconcave in\n$y$. Though such optimization problems arise in many machine learning paradigms\nincluding training generative adversarial networks (GANs) and adversarially\nrobust models, many fundamental issues remain in theory, such as the absence of\nefficiently computable optimality notions, and cyclic or diverging behavior of\nexisting algorithms. Our framework sprouts from the practical consideration\nthat under a computational budget, the max-player can not fully maximize\n$f(x,\\cdot)$ since nonconcave maximization is NP-hard in general. So, we\npropose a new algorithm for the min-player to play against smooth algorithms\ndeployed by the adversary (i.e., the max-player) instead of against full\nmaximization. Our algorithm is guaranteed to make monotonic progress (thus\nhaving no limit cycles), and to find an appropriate \"stationary point\" in a\npolynomial number of iterations. Our framework covers practical settings where\nthe smooth algorithms deployed by the adversary are multi-step stochastic\ngradient ascent, and its accelerated version. We further provide complementing\nexperiments that confirm our theoretical findings and demonstrate the\neffectiveness of the proposed approach in practice.",
    "descriptor": "",
    "authors": [
      "Tanner Fiez",
      "Chi Jin",
      "Praneeth Netrapalli",
      "Lillian J. Ratliff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01488"
  },
  {
    "id": "arXiv:2106.01489",
    "title": "Not All Knowledge Is Created Equal",
    "abstract": "Mutual knowledge distillation (MKD) improves a model by distilling knowledge\nfrom another model. However, not all knowledge is certain and correct,\nespecially under adverse conditions. For example, label noise usually leads to\nless reliable models due to the undesired memorisation [1, 2]. Wrong knowledge\nmisleads the learning rather than helps. This problem can be handled by two\naspects: (i) improving the reliability of a model where the knowledge is from\n(i.e., knowledge source's reliability); (ii) selecting reliable knowledge for\ndistillation. In the literature, making a model more reliable is widely studied\nwhile selective MKD receives little attention. Therefore, we focus on studying\nselective MKD and highlight its importance in this work.\nConcretely, a generic MKD framework, Confident knowledge selection followed\nby Mutual Distillation (CMD), is designed. The key component of CMD is a\ngeneric knowledge selection formulation, making the selection threshold either\nstatic (CMD-S) or progressive (CMD-P). Additionally, CMD covers two special\ncases: zero knowledge and all knowledge, leading to a unified MKD framework. We\nempirically find CMD-P performs better than CMD-S. The main reason is that a\nmodel's knowledge upgrades and becomes confident as the training progresses.\nExtensive experiments are present to demonstrate the effectiveness of CMD and\nthoroughly justify the design of CMD. For example, CMD-P obtains new\nstate-of-the-art results in robustness against label noise.",
    "descriptor": "\nComments: Selective mutual knowledge distillation\n",
    "authors": [
      "Ziyun Li",
      "Xinshao Wang",
      "Haojin Yang",
      "Di Hu",
      "Neil M. Robertson",
      "David A. Clifton",
      "Christoph Meinel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01489"
  },
  {
    "id": "arXiv:2106.01490",
    "title": "What and How long: Prediction of Mobile App Engagement",
    "abstract": "User engagement is crucial to the long-term success of a mobile app. Several\nmetrics, such as dwell time, have been used for measuring user engagement.\nHowever, how to effectively predict user engagement in the context of mobile\napps is still an open research question. For example, do the mobile usage\ncontexts (e.g.,~time of day) in which users access mobile apps impact their\ndwell time? Answers to such questions could help mobile operating system and\npublishers to optimize advertising and service placement. In this paper, we\nfirst conduct an empirical study for assessing how user characteristics,\ntemporal features, and the short/long-term contexts contribute to gains in\npredicting users' app dwell time on the population level. The comprehensive\nanalysis is conducted on large app usage logs collected through a mobile\nadvertising company. The dataset covers more than 12K anonymous users and 1.3\nmillion log events. Based on the analysis, we further investigate a novel\nmobile app engagement prediction problem -- can we predict simultaneously what\napp the user will use next and how long he/she will stay on that app? We\npropose several strategies for this joint prediction problem and demonstrate\nthat our model can improve the performance significantly when compared with the\nstate-of-the-art baselines. Our work can help mobile system developers in\ndesigning a better and more engagement-aware mobile app user experience.",
    "descriptor": "\nComments: 38 pages, to appear in ACM Transactions on Information Systems 2021\n",
    "authors": [
      "Yuan Tian",
      "Ke Zhou",
      "Dan Pelleg"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.01490"
  },
  {
    "id": "arXiv:2106.01491",
    "title": "MedNLI Is Not Immune: Natural Language Inference Artifacts in the  Clinical Domain",
    "abstract": "Crowdworker-constructed natural language inference (NLI) datasets have been\nfound to contain statistical artifacts associated with the annotation process\nthat allow hypothesis-only classifiers to achieve better-than-random\nperformance (Poliak et al., 2018; Gururanganet et al., 2018; Tsuchiya, 2018).\nWe investigate whether MedNLI, a physician-annotated dataset with premises\nextracted from clinical notes, contains such artifacts (Romanov and Shivade,\n2018). We find that entailed hypotheses contain generic versions of specific\nconcepts in the premise, as well as modifiers related to responsiveness,\nduration, and probability. Neutral hypotheses feature conditions and behaviors\nthat co-occur with, or cause, the condition(s) in the premise. Contradiction\nhypotheses feature explicit negation of the premise and implicit negation via\nassertion of good health. Adversarial filtering demonstrates that performance\ndegrades when evaluated on the difficult subset. We provide partition\ninformation and recommendations for alternative dataset construction strategies\nfor knowledge-intensive domains.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Christine Herlihy",
      "Rachel Rudinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01491"
  },
  {
    "id": "arXiv:2106.01492",
    "title": "Nudge: Stochastically Improving upon FCFS",
    "abstract": "The First-Come First-Served (FCFS) scheduling policy is the most popular\nscheduling algorithm used in practice. Furthermore, its usage is theoretically\nvalidated: for light-tailed job size distributions, FCFS has weakly optimal\nasymptotic tail of response time. But what if we don't just care about the\nasymptotic tail? What if we also care about the 99th percentile of response\ntime, or the fraction of jobs that complete in under one second? Is FCFS still\nbest? Outside of the asymptotic regime, only loose bounds on the tail of FCFS\nare known, and optimality is completely open.\nIn this paper, we introduce a new policy, Nudge, which is the first policy to\nprovably stochastically improve upon FCFS. We prove that Nudge simultaneously\nimproves upon FCFS at every point along the tail, for light-tailed job size\ndistributions. As a result, Nudge outperforms FCFS for every moment and every\npercentile of response time. Moreover, Nudge provides a multiplicative\nimprovement over FCFS in the asymptotic tail. This resolves a long-standing\nopen problem by showing that, counter to previous conjecture, FCFS is not\nstrongly asymptotically optimal.",
    "descriptor": "\nComments: 29 pages, 4 figures. To appear in SIGMETRICS 2021\n",
    "authors": [
      "Isaac Grosof",
      "Kunhe Yang",
      "Ziv Scully",
      "Mor Harchol-Balter"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.01492"
  },
  {
    "id": "arXiv:2106.01494",
    "title": "Knowing More About Questions Can Help: Improving Calibration in Question  Answering",
    "abstract": "We study calibration in question answering, estimating whether model\ncorrectly predicts answer for each question. Unlike prior work which mainly\nrely on the model's confidence score, our calibrator incorporates information\nabout the input example (e.g., question and the evidence context). Together\nwith data augmentation via back translation, our simple approach achieves 5-10%\ngains in calibration accuracy on reading comprehension benchmarks. Furthermore,\nwe present the first calibration study in the open retrieval setting, comparing\nthe calibration accuracy of retrieval-based span prediction models and answer\ngeneration models. Here again, our approach shows consistent gains over\ncalibrators relying on the model confidence. Our simple and efficient\ncalibrator can be easily adapted to many tasks and model architectures, showing\nrobust gains in all settings.",
    "descriptor": "\nComments: ACL 2021 (finding)\n",
    "authors": [
      "Shujian Zhang",
      "Chengyue Gong",
      "Eunsol Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01494"
  },
  {
    "id": "arXiv:2106.01496",
    "title": "Stability of Special Graph Classes",
    "abstract": "Frei et al. [6] showed that the problem to decide whether a graph is stable\nwith respect to some graph parameter under adding or removing either edges or\nvertices is $\\Theta_2^{\\text{P}}$-complete. They studied the common graph\nparameters $\\alpha$ (independence number), $\\beta$ (vertex cover number),\n$\\omega$ (clique number), and $\\chi$ (chromatic number) for certain variants of\nthe stability problem. We follow their approach and provide a large number of\npolynomial-time algorithms solving these problems for special graph classes,\nnamely for graphs without edges, complete graphs, paths, trees, forests,\nbipartite graphs, and co-graphs.",
    "descriptor": "",
    "authors": [
      "Robin Weishaupt",
      "J\u00f6rg Rothe"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.01496"
  },
  {
    "id": "arXiv:2106.01499",
    "title": "Personalizing Pre-trained Models",
    "abstract": "Self-supervised or weakly supervised models trained on large-scale datasets\nhave shown sample-efficient transfer to diverse datasets in few-shot settings.\nWe consider how upstream pretrained models can be leveraged for downstream\nfew-shot, multilabel, and continual learning tasks. Our model CLIPPER (CLIP\nPERsonalized) uses image representations from CLIP, a large-scale image\nrepresentation learning model trained using weak natural language supervision.\nWe developed a technique, called Multi-label Weight Imprinting (MWI), for\nmulti-label, continual, and few-shot learning, and CLIPPER uses MWI with image\nrepresentations from CLIP. We evaluated CLIPPER on 10 single-label and 5\nmulti-label datasets. Our model shows robust and competitive performance, and\nwe set new benchmarks for few-shot, multi-label, and continual learning. Our\nlightweight technique is also compute-efficient and enables privacy-preserving\napplications as the data is not sent to the upstream model for fine-tuning.",
    "descriptor": "",
    "authors": [
      "Mina Khan",
      "P Srivatsa",
      "Advait Rane",
      "Shriram Chenniappa",
      "Asadali Hazariwala",
      "Pattie Maes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01499"
  },
  {
    "id": "arXiv:2106.01501",
    "title": "Ember: No-Code Context Enrichment via Similarity-Based Keyless Joins",
    "abstract": "Structured data, or data that adheres to a pre-defined schema, can suffer\nfrom fragmented context: information describing a single entity can be\nscattered across multiple datasets or tables tailored for specific business\nneeds, with no explicit linking keys (e.g., primary key-foreign key\nrelationships or heuristic functions). Context enrichment, or rebuilding\nfragmented context, using keyless joins is an implicit or explicit step in\nmachine learning (ML) pipelines over structured data sources. This process is\ntedious, domain-specific, and lacks support in now-prevalent no-code ML systems\nthat let users create ML pipelines using just input data and high-level\nconfiguration files. In response, we propose Ember, a system that abstracts and\nautomates keyless joins to generalize context enrichment. Our key insight is\nthat Ember can enable a general keyless join operator by constructing an index\npopulated with task-specific embeddings. Ember learns these embeddings by\nleveraging Transformer-based representation learning techniques. We describe\nour core architectural principles and operators when developing Ember, and\nempirically demonstrate that Ember allows users to develop no-code pipelines\nfor five domains, including search, recommendation and question answering, and\ncan exceed alternatives by up to 39% recall, with as little as a single line\nconfiguration change.",
    "descriptor": "",
    "authors": [
      "Sahaana Suri",
      "Ihab F. Ilyas",
      "Christopher R\u00e9",
      "Theodoros Rekatsinas"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01501"
  },
  {
    "id": "arXiv:2106.01503",
    "title": "Towards an Explanation Space to Align Humans and Explainable-AI Teamwork",
    "abstract": "Providing meaningful and actionable explanations to end-users is a\nfundamental prerequisite for implementing explainable intelligent systems in\nthe real world. Explainability is a situated interaction between a user and the\nAI system rather than being static design principles. The content of\nexplanations is context-dependent and must be defined by evidence about the\nuser and its context. This paper seeks to operationalize this concept by\nproposing a formative architecture that defines the explanation space from a\nuser-inspired perspective. The architecture comprises five intertwined\ncomponents to outline explanation requirements for a task: (1) the end-users\nmental models, (2) the end-users cognitive process, (3) the user interface, (4)\nthe human-explainer agent, and the (5) agent process. We first define each\ncomponent of the architecture. Then we present the Abstracted Explanation\nSpace, a modeling tool that aggregates the architecture's components to support\ndesigners in systematically aligning explanations with the end-users work\npractices, needs, and goals. It guides the specifications of what needs to be\nexplained (content - end-users mental model), why this explanation is necessary\n(context - end-users cognitive process), to delimit how to explain it (format -\nhuman-explainer agent and user interface), and when should the explanations be\ngiven. We then exemplify the tool's use in an ongoing case study in the\naircraft maintenance domain. Finally, we discuss possible contributions of the\ntool, known limitations/areas for improvement, and future work to be done.",
    "descriptor": "",
    "authors": [
      "Garrick Cabour",
      "Andr\u00e9s Morales",
      "\u00c9lise Ledoux",
      "Samuel Bassetto"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.01503"
  },
  {
    "id": "arXiv:2106.01504",
    "title": "DeepCompress: Efficient Point Cloud Geometry Compression",
    "abstract": "Point clouds are a basic data type that is increasingly of interest as 3D\ncontent becomes more ubiquitous. Applications using point clouds include\nvirtual, augmented, and mixed reality and autonomous driving. We propose a more\nefficient deep learning-based encoder architecture for point clouds compression\nthat incorporates principles from established 3D object detection and image\ncompression architectures. Through an ablation study, we show that\nincorporating the learned activation function from Computational Efficient\nNeural Image Compression (CENIC) and designing more parameter-efficient\nconvolutional blocks yields dramatic gains in efficiency and performance. Our\nproposed architecture incorporates Generalized Divisive Normalization\nactivations and propose a spatially separable InceptionV4-inspired block. We\nthen evaluate rate-distortion curves on the standard JPEG Pleno 8i Voxelized\nFull Bodies dataset to evaluate our model's performance. Our proposed\nmodifications outperform the baseline approaches by a small margin in terms of\nBjontegard delta rate and PSNR values, yet reduces necessary encoder\nconvolution operations by 8 percent and reduces total encoder parameters by 20\npercent. Our proposed architecture, when considered on its own, has a small\npenalty of 0.02 percent in Chamfer's Distance and 0.32 percent increased bit\nrate in Point to Plane Distance for the same peak signal-to-noise ratio.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Ryan Killea",
      "Yun Li",
      "Saeed Bastani",
      "Paul McLachlan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.01504"
  },
  {
    "id": "arXiv:2106.01505",
    "title": "Barbershop: GAN-based Image Compositing using Segmentation Masks",
    "abstract": "Seamlessly blending features from multiple images is extremely challenging\nbecause of complex relationships in lighting, geometry, and partial occlusion\nwhich cause coupling between different parts of the image. Even though recent\nwork on GANs enables synthesis of realistic hair or faces, it remains difficult\nto combine them into a single, coherent, and plausible image rather than a\ndisjointed set of image patches. We present a novel solution to image blending,\nparticularly for the problem of hairstyle transfer, based on GAN-inversion. We\npropose a novel latent space for image blending which is better at preserving\ndetail and encoding spatial information, and propose a new GAN-embedding\nalgorithm which is able to slightly modify images to conform to a common\nsegmentation mask. Our novel representation enables the transfer of the visual\nproperties from multiple reference images including specific details such as\nmoles and wrinkles, and because we do image blending in a latent-space we are\nable to synthesize images that are coherent. Our approach avoids blending\nartifacts present in other approaches and finds a globally consistent image.\nOur results demonstrate a significant improvement over the current state of the\nart in a user study, with users preferring our blending solution over 95\npercent of the time.",
    "descriptor": "\nComments: Project page: this https URL Video: this https URL\n",
    "authors": [
      "Peihao Zhu",
      "Rameen Abdal",
      "John Femiani",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.01505"
  },
  {
    "id": "arXiv:2106.01506",
    "title": "Transformers are Deep Infinite-Dimensional Non-Mercer Binary Kernel  Machines",
    "abstract": "Despite their ubiquity in core AI fields like natural language processing,\nthe mechanics of deep attention-based neural networks like the Transformer\nmodel are not fully understood. In this article, we present a new perspective\ntowards understanding how Transformers work. In particular, we show that the\n\"dot-product attention\" that is the core of the Transformer's operation can be\ncharacterized as a kernel learning method on a pair of Banach spaces. In\nparticular, the Transformer's kernel is characterized as having an infinite\nfeature dimension. Along the way we consider an extension of the standard\nkernel learning problem to a binary setting, where data come from two input\ndomains and a response is defined for every cross-domain pair. We prove a new\nrepresenter theorem for these binary kernel machines with non-Mercer\n(indefinite, asymmetric) kernels (implying that the functions learned are\nelements of reproducing kernel Banach spaces rather than Hilbert spaces), and\nalso prove a new universal approximation theorem showing that the Transformer\ncalculation can learn any binary non-Mercer reproducing kernel Banach space\npair. We experiment with new kernels in Transformers, and obtain results that\nsuggest the infinite dimensionality of the standard Transformer kernel is\npartially responsible for its performance. This paper's results provide a new\ntheoretical understanding of a very important but poorly understood model in\nmodern machine~learning.",
    "descriptor": "\nComments: Work in progress, comments welcome\n",
    "authors": [
      "Matthew A. Wright",
      "Joseph E. Gonzalez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01506"
  },
  {
    "id": "arXiv:2106.01513",
    "title": "Granger Causality from Quantized Measurements",
    "abstract": "An approach is proposed for inferring Granger causality between jointly\nstationary, Gaussian signals from quantized data. First, a necessary and\nsufficient rank criterion for the equality of two conditional Gaussian\ndistributions is proved. Assuming a partial finite-order Markov property,\nconditions are then derived under which Granger causality between them can be\nreliably inferred from the second order moments of the quantized processes. A\nnecessary and sufficient condition is proposed for Granger causality inference\nunder binary quantization. Furthermore, sufficient conditions are introduced to\ninfer Granger causality between jointly Gaussian signals through measurements\nquantized via non-uniform, uniform or high resolution quantizers. This approach\ndoes not require the statistics of the underlying Gaussian signals to be\nestimated, or a system model to be identified. No assumptions are made on the\nidentifiability of the jointly Gaussian random processes through the quantized\nobservations. The effectiveness of the proposed method is illustrated by\nsimulation results.",
    "descriptor": "",
    "authors": [
      "Salman Ahmadi",
      "Girish N. Nair",
      "Erik Weyer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01513"
  },
  {
    "id": "arXiv:2106.01515",
    "title": "Question Answering Over Temporal Knowledge Graphs",
    "abstract": "Temporal Knowledge Graphs (Temporal KGs) extend regular Knowledge Graphs by\nproviding temporal scopes (start and end times) on each edge in the KG. While\nQuestion Answering over KG (KGQA) has received some attention from the research\ncommunity, QA over Temporal KGs (Temporal KGQA) is a relatively unexplored\narea. Lack of broad coverage datasets has been another factor limiting progress\nin this area. We address this challenge by presenting CRONQUESTIONS, the\nlargest known Temporal KGQA dataset, clearly stratified into buckets of\nstructural complexity. CRONQUESTIONS expands the only known previous dataset by\na factor of 340x. We find that various state-of-the-art KGQA methods fall far\nshort of the desired performance on this new dataset. In response, we also\npropose CRONKGQA, a transformer-based solution that exploits recent advances in\nTemporal KG embeddings, and achieves performance superior to all baselines,\nwith an increase of 120% in accuracy over the next best performing method.\nThrough extensive experiments, we give detailed insights into the workings of\nCRONKGQA, as well as situations where significant further improvements appear\npossible. In addition to the dataset, we have released our code as well.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Apoorv Saxena",
      "Soumen Chakrabarti",
      "Partha Talukdar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01515"
  },
  {
    "id": "arXiv:2106.01516",
    "title": "Hyperbolically-Discounted Reinforcement Learning on Reward-Punishment  Framework",
    "abstract": "This paper proposes a new reinforcement learning with hyperbolic discounting.\nCombining a new temporal difference error with the hyperbolic discounting in\nrecursive manner and reward-punishment framework, a new scheme to learn the\noptimal policy is derived. In simulations, it is found that the proposal\noutperforms the standard reinforcement learning, although the performance\ndepends on the design of reward and punishment. In addition, the averages of\ndiscount factors w.r.t. reward and punishment are different from each other,\nlike a sign effect in animal behaviors.",
    "descriptor": "\nComments: 2 pages, 1 figure, presented as Paper Abstracts in ICDL-EPIROB2019\n",
    "authors": [
      "Taisuke Kobayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01516"
  },
  {
    "id": "arXiv:2106.01518",
    "title": "Dissecting Generation Modes for Abstractive Summarization Models via  Ablation and Attribution",
    "abstract": "Despite the prominence of neural abstractive summarization models, we know\nlittle about how they actually form summaries and how to understand where their\ndecisions come from. We propose a two-step method to interpret summarization\nmodel decisions. We first analyze the model's behavior by ablating the full\nmodel to categorize each decoder decision into one of several generation modes:\nroughly, is the model behaving like a language model, is it relying heavily on\nthe input, or is it somewhere in between? After isolating decisions that do\ndepend on the input, we explore interpreting these decisions using several\ndifferent attribution methods. We compare these techniques based on their\nability to select content and reconstruct the model's predicted token from\nperturbations of the input, thus revealing whether highlighted attributions are\ntruly important for the generation of the next token. While this machinery can\nbe broadly useful even beyond summarization, we specifically demonstrate its\ncapability to identify phrases the summarization model has memorized and\ndetermine where in the training pipeline this memorization happened, as well as\nstudy complex generation phenomena like sentence fusion on a per-instance\nbasis.",
    "descriptor": "\nComments: ACL 2021; 16 pages\n",
    "authors": [
      "Jiacheng Xu",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01518"
  },
  {
    "id": "arXiv:2106.01526",
    "title": "\"You made me feel this way\": Investigating Partners' Influence in  Predicting Emotions in Couples' Conflict Interactions using Speech Data",
    "abstract": "How romantic partners interact with each other during a conflict influences\nhow they feel at the end of the interaction and is predictive of whether the\npartners stay together in the long term. Hence understanding the emotions of\neach partner is important. Yet current approaches that are used include\nself-reports which are burdensome and hence limit the frequency of this data\ncollection. Automatic emotion prediction could address this challenge. Insights\nfrom psychology research indicate that partners' behaviors influence each\nother's emotions in conflict interaction and hence, the behavior of both\npartners could be considered to better predict each partner's emotion. However,\nit is yet to be investigated how doing so compares to only using each partner's\nown behavior in terms of emotion prediction performance. In this work, we used\nBERT to extract linguistic features (i.e., what partners said) and openSMILE to\nextract paralinguistic features (i.e., how they said it) from a data set of 368\nGerman-speaking Swiss couples (N = 736 individuals) which were videotaped\nduring an 8-minutes conflict interaction in the laboratory. Based on those\nfeatures, we trained machine learning models to predict if partners feel\npositive or negative after the conflict interaction. Our results show that\nincluding the behavior of the other partner improves the prediction\nperformance. Furthermore, for men, considering how their female partners spoke\nis most important and for women considering what their male partner said is\nmost important in getting better prediction performance. This work is a step\ntowards automatically recognizing each partners' emotion based on the behavior\nof both, which would enable a better understanding of couples in research,\ntherapy, and the real world.",
    "descriptor": "\nComments: 5 pages, Under review at ICMI 2021\n",
    "authors": [
      "George Boateng",
      "Peter Hilpert",
      "Guy Bodenmann",
      "Mona Neysari",
      "Tobias Kowatsch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01526"
  },
  {
    "id": "arXiv:2106.01532",
    "title": "Noise Doesn't Lie: Towards Universal Detection of Deep Inpainting",
    "abstract": "Deep image inpainting aims to restore damaged or missing regions in an image\nwith realistic contents. While having a wide range of applications such as\nobject removal and image recovery, deep inpainting techniques also have the\nrisk of being manipulated for image forgery. A promising countermeasure against\nsuch forgeries is deep inpainting detection, which aims to locate the inpainted\nregions in an image. In this paper, we make the first attempt towards universal\ndetection of deep inpainting, where the detection network can generalize well\nwhen detecting different deep inpainting methods. To this end, we first propose\na novel data generation approach to generate a universal training dataset,\nwhich imitates the noise discrepancies exist in real versus inpainted image\ncontents to train universal detectors. We then design a Noise-Image\nCross-fusion Network (NIX-Net) to effectively exploit the discriminative\ninformation contained in both the images and their noise patterns. We\nempirically show, on multiple benchmark datasets, that our approach outperforms\nexisting detection methods by a large margin and generalize well to unseen deep\ninpainting techniques. Our universal training dataset can also significantly\nboost the generalizability of existing detection methods.",
    "descriptor": "\nComments: Accepted by IJCAI 2021\n",
    "authors": [
      "Ang Li",
      "Qiuhong Ke",
      "Xingjun Ma",
      "Haiqin Weng",
      "Zhiyuan Zong",
      "Feng Xue",
      "Rui Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01532"
  },
  {
    "id": "arXiv:2106.01534",
    "title": "Deconfounded Video Moment Retrieval with Causal Intervention",
    "abstract": "We tackle the task of video moment retrieval (VMR), which aims to localize a\nspecific moment in a video according to a textual query. Existing methods\nprimarily model the matching relationship between query and moment by complex\ncross-modal interactions. Despite their effectiveness, current models mostly\nexploit dataset biases while ignoring the video content, thus leading to poor\ngeneralizability. We argue that the issue is caused by the hidden confounder in\nVMR, {i.e., temporal location of moments}, that spuriously correlates the model\ninput and prediction. How to design robust matching models against the temporal\nlocation biases is crucial but, as far as we know, has not been studied yet for\nVMR.\nTo fill the research gap, we propose a causality-inspired VMR framework that\nbuilds structural causal model to capture the true effect of query and video\ncontent on the prediction. Specifically, we develop a Deconfounded Cross-modal\nMatching (DCM) method to remove the confounding effects of moment location. It\nfirst disentangles moment representation to infer the core feature of visual\ncontent, and then applies causal intervention on the disentangled multimodal\ninput based on backdoor adjustment, which forces the model to fairly\nincorporate each possible location of the target into consideration. Extensive\nexperiments clearly show that our approach can achieve significant improvement\nover the state-of-the-art methods in terms of both accuracy and generalization\n(Codes:\n\\color{blue}{\\url{https://github.com/Xun-Yang/Causal_Video_Moment_Retrieval}}",
    "descriptor": "\nComments: This work has been accepted by SIGIR 2021\n",
    "authors": [
      "Xun Yang",
      "Fuli Feng",
      "Wei Ji",
      "Meng Wang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01534"
  },
  {
    "id": "arXiv:2106.01536",
    "title": "BERT meets LIWC: Exploring State-of-the-Art Language Models for  Predicting Communication Behavior in Couples' Conflict Interactions",
    "abstract": "Many processes in psychology are complex, such as dyadic interactions between\ntwo interacting partners (e.g. patient-therapist, intimate relationship\npartners). Nevertheless, many basic questions about interactions are difficult\nto investigate because dyadic processes can be within a person and between\npartners, they are based on multimodal aspects of behavior and unfold rapidly.\nCurrent analyses are mainly based on the behavioral coding method, whereby\nhuman coders annotate behavior based on a coding schema. But coding is\nlabor-intensive, expensive, slow, focuses on few modalities. Current approaches\nin psychology use LIWC for analyzing couples' interactions. However, advances\nin natural language processing such as BERT could enable the development of\nsystems to potentially automate behavioral coding, which in turn could\nsubstantially improve psychological research. In this work, we train machine\nlearning models to automatically predict positive and negative communication\nbehavioral codes of 368 German-speaking Swiss couples during an 8-minute\nconflict interaction on a fine-grained scale (10-seconds sequences) using\nlinguistic features and paralinguistic features derived with openSMILE. Our\nresults show that both simpler TF-IDF features as well as more complex BERT\nfeatures performed better than LIWC, and that adding paralinguistic features\ndid not improve the performance. These results suggest it might be time to\nconsider modern alternatives to LIWC, the de facto linguistic features in\npsychology, for prediction tasks in couples research. This work is a further\nstep towards the automated coding of couples' behavior which could enhance\ncouple research and therapy, and be utilized for other dyadic interactions as\nwell.",
    "descriptor": "\nComments: 6 pages. Under review at ICMI 2021\n",
    "authors": [
      "Jacopo Biggiogera",
      "George Boateng",
      "Peter Hilpert",
      "Matthew Vowels",
      "Guy Bodenmann",
      "Mona Neysari",
      "Fridtjof Nussbeck",
      "Tobias Kowatsch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01536"
  },
  {
    "id": "arXiv:2106.01538",
    "title": "PDPGD: Primal-Dual Proximal Gradient Descent Adversarial Attack",
    "abstract": "State-of-the-art deep neural networks are sensitive to small input\nperturbations. Since the discovery of this intriguing vulnerability, many\ndefence methods have been proposed that attempt to improve robustness to\nadversarial noise. Fast and accurate attacks are required to compare various\ndefence methods. However, evaluating adversarial robustness has proven to be\nextremely challenging. Existing norm minimisation adversarial attacks require\nthousands of iterations (e.g. Carlini & Wagner attack), are limited to the\nspecific norms (e.g. Fast Adaptive Boundary), or produce sub-optimal results\n(e.g. Brendel & Bethge attack). On the other hand, PGD attack, which is fast,\ngeneral and accurate, ignores the norm minimisation penalty and solves a\nsimpler perturbation-constrained problem. In this work, we introduce a fast,\ngeneral and accurate adversarial attack that optimises the original non-convex\nconstrained minimisation problem. We interpret optimising the Lagrangian of the\nadversarial attack optimisation problem as a two-player game: the first player\nminimises the Lagrangian wrt the adversarial noise; the second player maximises\nthe Lagrangian wrt the regularisation penalty. Our attack algorithm\nsimultaneously optimises primal and dual variables to find the minimal\nadversarial perturbation. In addition, for non-smooth $l_p$-norm minimisation,\nsuch as $l_{\\infty}$-, $l_1$-, and $l_0$-norms, we introduce primal-dual\nproximal gradient descent attack. We show in the experiments that our attack\noutperforms current state-of-the-art $l_{\\infty}$-, $l_2$-, $l_1$-, and\n$l_0$-attacks on MNIST, CIFAR-10 and Restricted ImageNet datasets against\nunregularised and adversarially trained models.",
    "descriptor": "",
    "authors": [
      "Alexander Matyasko",
      "Lap-Pui Chau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01538"
  },
  {
    "id": "arXiv:2106.01540",
    "title": "Luna: Linear Unified Nested Attention",
    "abstract": "The quadratic computational and memory complexities of the Transformer's\nattention mechanism have limited its scalability for modeling long sequences.\nIn this paper, we propose Luna, a linear unified nested attention mechanism\nthat approximates softmax attention with two nested linear attention functions,\nyielding only linear (as opposed to quadratic) time and space complexity.\nSpecifically, with the first attention function, Luna packs the input sequence\ninto a sequence of fixed length. Then, the packed sequence is unpacked using\nthe second attention function. As compared to a more traditional attention\nmechanism, Luna introduces an additional sequence with a fixed length as input\nand an additional corresponding output, which allows Luna to perform attention\noperation linearly, while also storing adequate contextual information. We\nperform extensive evaluations on three benchmarks of sequence modeling tasks:\nlong-context sequence modeling, neural machine translation and masked language\nmodeling for large-scale pretraining. Competitive or even better experimental\nresults demonstrate both the effectiveness and efficiency of Luna compared to a\nvariety",
    "descriptor": "\nComments: Preprint. 2 figures, 6 tables\n",
    "authors": [
      "Xuezhe Ma",
      "Xiang Kong",
      "Sinong Wang",
      "Chunting Zhou",
      "Jonathan May",
      "Hao Ma",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01540"
  },
  {
    "id": "arXiv:2106.01541",
    "title": "MPC-BERT: A Pre-Trained Language Model for Multi-Party Conversation  Understanding",
    "abstract": "Recently, various neural models for multi-party conversation (MPC) have\nachieved impressive improvements on a variety of tasks such as addressee\nrecognition, speaker identification and response prediction. However, these\nexisting methods on MPC usually represent interlocutors and utterances\nindividually and ignore the inherent complicated structure in MPC which may\nprovide crucial interlocutor and utterance semantics and would enhance the\nconversation understanding process. To this end, we present MPC-BERT, a\npre-trained model for MPC understanding that considers learning who says what\nto whom in a unified model with several elaborated self-supervised tasks.\nParticularly, these tasks can be generally categorized into (1) interlocutor\nstructure modeling including reply-to utterance recognition, identical speaker\nsearching and pointer consistency distinction, and (2) utterance semantics\nmodeling including masked shared utterance restoration and shared node\ndetection. We evaluate MPC-BERT on three downstream tasks including addressee\nrecognition, speaker identification and response selection. Experimental\nresults show that MPC-BERT outperforms previous methods by large margins and\nachieves new state-of-the-art performance on all three downstream tasks at two\nbenchmarks.",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Jia-Chen Gu",
      "Chongyang Tao",
      "Zhen-Hua Ling",
      "Can Xu",
      "Xiubo Geng",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01541"
  },
  {
    "id": "arXiv:2106.01543",
    "title": "Niffler: A Reference Architecture and System Implementation for View  Discovery over Pathless Table Collections by Example",
    "abstract": "Identifying a project-join view (PJ-view) over collections of tables is the\nfirst step of many data management projects, e.g., assembling a dataset to feed\ninto a business intelligence tool, creating a training dataset to fit a machine\nlearning model, and more. When the table collections are large and lack join\ninformation--such as when combining databases, or on data lakes--query by\nexample (QBE) systems can help identify relevant data, but they are designed\nunder the assumption that join information is available in the schema, and do\nnot perform well on pathless table collections that do not have join path\ninformation.\nWe present a reference architecture that explicitly divides the end-to-end\nproblem of discovering PJ-views over pathless table collections into a human\nand a technical problem. We then present Niffler, a system built to address the\ntechnical problem. We introduce algorithms for the main components of Niffler,\nincluding a signal generation component that helps reduce the size of the\ncandidate views that may be large due to errors and ambiguity in both the data\nand input queries. We evaluate Niffler on real datasets to demonstrate the\neffectiveness of the new engine in discovering PJ-views over pathless table\ncollections.",
    "descriptor": "",
    "authors": [
      "Yue Gong",
      "Zhiru Zhu",
      "Sainyam Galhotra",
      "Raul Castro Fernandez"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.01543"
  },
  {
    "id": "arXiv:2106.01544",
    "title": "SSMD: Semi-Supervised Medical Image Detection with Adaptive Consistency  and Heterogeneous Perturbation",
    "abstract": "Semi-Supervised classification and segmentation methods have been widely\ninvestigated in medical image analysis. Both approaches can improve the\nperformance of fully-supervised methods with additional unlabeled data.\nHowever, as a fundamental task, semi-supervised object detection has not gained\nenough attention in the field of medical image analysis. In this paper, we\npropose a novel Semi-Supervised Medical image Detector (SSMD). The motivation\nbehind SSMD is to provide free yet effective supervision for unlabeled data, by\nregularizing the predictions at each position to be consistent. To achieve the\nabove idea, we develop a novel adaptive consistency cost function to regularize\ndifferent components in the predictions. Moreover, we introduce heterogeneous\nperturbation strategies that work in both feature space and image space, so\nthat the proposed detector is promising to produce powerful image\nrepresentations and robust predictions. Extensive experimental results show\nthat the proposed SSMD achieves the state-of-the-art performance at a wide\nrange of settings. We also demonstrate the strength of each proposed module\nwith comprehensive ablation studies.",
    "descriptor": "\nComments: Accepted by Medical Image Analysis\n",
    "authors": [
      "Hong-Yu Zhou",
      "Chengdi Wang",
      "Haofeng Li",
      "Gang Wang",
      "Shu Zhang",
      "Weimin Li",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01544"
  },
  {
    "id": "arXiv:2106.01548",
    "title": "When Vision Transformers Outperform ResNets without Pretraining or  Strong Data Augmentations",
    "abstract": "Vision Transformers (ViTs) and MLPs signal further efforts on replacing\nhand-wired features or inductive biases with general-purpose neural\narchitectures. Existing works empower the models by massive data, such as\nlarge-scale pretraining and/or repeated strong data augmentations, and still\nreport optimization-related problems (e.g., sensitivity to initialization and\nlearning rate). Hence, this paper investigates ViTs and MLP-Mixers from the\nlens of loss geometry, intending to improve the models' data efficiency at\ntraining and generalization at inference. Visualization and Hessian reveal\nextremely sharp local minima of converged models. By promoting smoothness with\na recently proposed sharpness-aware optimizer, we substantially improve the\naccuracy and robustness of ViTs and MLP-Mixers on various tasks spanning\nsupervised, adversarial, contrastive, and transfer learning (e.g., +5.3\\% and\n+11.0\\% top-1 accuracy on ImageNet for ViT-B/16 and Mixer-B/16, respectively,\nwith the simple Inception-style preprocessing). We show that the improved\nsmoothness attributes to sparser active neurons in the first few layers. The\nresultant ViTs outperform ResNets of similar size and throughput when trained\nfrom scratch on ImageNet without large-scale pretraining or strong data\naugmentations. They also possess more perceptive attention maps.",
    "descriptor": "",
    "authors": [
      "Xiangning Chen",
      "Cho-Jui Hsieh",
      "Boqing Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01548"
  },
  {
    "id": "arXiv:2106.01551",
    "title": "Matching-Theory-Based Multi-User Cooperative Computing Framework",
    "abstract": "In this paper, we propose a matching theory based multi-user cooperative\nframework to minimize the overall energy consumption of all the user equipments\n(UEs), where the UEs can be classified into the following roles: resource\ndemander (RD), resource provider (RP), and standalone UE (SU). We first\ndetermine the role of the UE by leveraging the roommate matching method. Then,\nby adopting college admission based algorithm, we divide the UEs into multiple\ncooperation groups, each consisting of one RP and multiple RDs. Next, we\npropose the rotation swap operation to further improve the performance without\ndeteriorating the system stability. Finally, we present an effective task\noffloading algorithm to minimize the energy consumption of all the cooperation\ngroups. The simulation results verify the effectiveness of the proposed scheme.",
    "descriptor": "",
    "authors": [
      "Ya Zhou",
      "Guopeng Zhang",
      "Kezhi Wang",
      "Kun Yang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01551"
  },
  {
    "id": "arXiv:2106.01553",
    "title": "Spline Positional Encoding for Learning 3D Implicit Signed Distance  Fields",
    "abstract": "Multilayer perceptrons (MLPs) have been successfully used to represent 3D\nshapes implicitly and compactly, by mapping 3D coordinates to the corresponding\nsigned distance values or occupancy values. In this paper, we propose a novel\npositional encoding scheme, called Spline Positional Encoding, to map the input\ncoordinates to a high dimensional space before passing them to MLPs, for\nhelping to recover 3D signed distance fields with fine-scale geometric details\nfrom unorganized 3D point clouds. We verified the superiority of our approach\nover other positional encoding schemes on tasks of 3D shape reconstruction from\ninput point clouds and shape space learning. The efficacy of our approach\nextended to image reconstruction is also demonstrated and evaluated.",
    "descriptor": "\nComments: Accepted by IJCAI 2021\n",
    "authors": [
      "Peng-Shuai Wang",
      "Yang Liu",
      "Yu-Qi Yang",
      "Xin Tong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.01553"
  },
  {
    "id": "arXiv:2106.01555",
    "title": "Comparing Acoustic-based Approaches for Alzheimer's Disease Detection",
    "abstract": "In this paper, we study the performance and generalizability of three\napproaches for AD detection from speech on the recent ADReSSo challenge\ndataset: 1) using conventional acoustic features 2) using novel pre-trained\nacoustic embeddings 3) combining acoustic features and embeddings. We find that\nwhile feature-based approaches have a higher precision, classification\napproaches relying on the combination of embeddings and features prove to have\na higher, and more balanced performance across multiple metrics of performance.\nOur best model, using such a combined approach, outperforms the acoustic\nbaseline in the challenge by 2.8\\%.",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2021\n",
    "authors": [
      "Aparna Balagopalan",
      "Jekaterina Novikova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.01555"
  },
  {
    "id": "arXiv:2106.01559",
    "title": "Adjacency List Oriented Relational Fact Extraction via Adaptive  Multi-task Learning",
    "abstract": "Relational fact extraction aims to extract semantic triplets from\nunstructured text. In this work, we show that all of the relational fact\nextraction models can be organized according to a graph-oriented analytical\nperspective. An efficient model, aDjacency lIst oRiented rElational faCT\n(DIRECT), is proposed based on this analytical framework. To alleviate\nchallenges of error propagation and sub-task loss equilibrium, DIRECT employs a\nnovel adaptive multi-task learning strategy with dynamic sub-task loss\nbalancing. Extensive experiments are conducted on two benchmark datasets, and\nresults prove that the proposed model outperforms a series of state-of-the-art\n(SoTA) models for relational triplet extraction.",
    "descriptor": "\nComments: 13 pages, 3 figures, accepted by findings of ACL 2021\n",
    "authors": [
      "Fubang Zhao",
      "Zhuoren Jiang",
      "Yangyang Kang",
      "Changlong Sun",
      "Xiaozhong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01559"
  },
  {
    "id": "arXiv:2106.01560",
    "title": "CitationIE: Leveraging the Citation Graph for Scientific Information  Extraction",
    "abstract": "Automatically extracting key information from scientific documents has the\npotential to help scientists work more efficiently and accelerate the pace of\nscientific progress. Prior work has considered extracting document-level entity\nclusters and relations end-to-end from raw scientific text, which can improve\nliterature search and help identify methods and materials for a given problem.\nDespite the importance of this task, most existing works on scientific\ninformation extraction (SciIE) consider extraction solely based on the content\nof an individual paper, without considering the paper's place in the broader\nliterature. In contrast to prior work, we augment our text representations by\nleveraging a complementary source of document context: the citation graph of\nreferential links between citing and cited papers. On a test set of\nEnglish-language scientific documents, we show that simple ways of utilizing\nthe structure and content of the citation graph can each lead to significant\ngains in different scientific information extraction tasks. When these tasks\nare combined, we observe a sizable improvement in end-to-end information\nextraction over the state-of-the-art, suggesting the potential for future work\nalong this direction. We release software tools to facilitate citation-aware\nSciIE development.",
    "descriptor": "\nComments: ACL-IJCNLP 2021 camera-ready (long paper in main conference)\n",
    "authors": [
      "Vijay Viswanathan",
      "Graham Neubig",
      "Pengfei Liu"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01560"
  },
  {
    "id": "arXiv:2106.01561",
    "title": "Can Generative Pre-trained Language Models Serve as Knowledge Bases for  Closed-book QA?",
    "abstract": "Recent work has investigated the interesting question using pre-trained\nlanguage models (PLMs) as knowledge bases for answering open questions.\nHowever, existing work is limited in using small benchmarks with high\ntest-train overlaps. We construct a new dataset of closed-book QA using SQuAD,\nand investigate the performance of BART. Experiments show that it is\nchallenging for BART to remember training facts in high precision, and also\nchallenging to answer closed-book questions even if relevant knowledge is\nretained. Some promising directions are found, including decoupling the\nknowledge memorizing process and the QA finetune process, forcing the model to\nrecall relevant knowledge when question answering.",
    "descriptor": "\nComments: Accepted By ACL-IJCNLP 2021\n",
    "authors": [
      "Cunxiang Wang",
      "Pai Liu",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01561"
  },
  {
    "id": "arXiv:2106.01562",
    "title": "Discriminative Reasoning for Document-level Relation Extraction",
    "abstract": "Document-level relation extraction (DocRE) models generally use graph\nnetworks to implicitly model the reasoning skill (i.e., pattern recognition,\nlogical reasoning, coreference reasoning, etc.) related to the relation between\none entity pair in a document. In this paper, we propose a novel discriminative\nreasoning framework to explicitly model the paths of these reasoning skills\nbetween each entity pair in this document. Thus, a discriminative reasoning\nnetwork is designed to estimate the relation probability distribution of\ndifferent reasoning paths based on the constructed graph and vectorized\ndocument contexts for each entity pair, thereby recognizing their relation.\nExperimental results show that our method outperforms the previous\nstate-of-the-art performance on the large-scale DocRE dataset. The code is\npublicly available at https://github.com/xwjim/DRN.",
    "descriptor": "\nComments: 11 pages, 4 figures, 5 tables. Findings of ACL 2021\n",
    "authors": [
      "Wang Xu",
      "Kehai Chen",
      "Tiejun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01562"
  },
  {
    "id": "arXiv:2106.01567",
    "title": "Deterministic Weighted Expander Decomposition in Almost-linear Time",
    "abstract": "In this note, we study the expander decomposition problem in a more general\nsetting where the input graph has positively weighted edges and nonnegative\ndemands on its vertices. We show how to extend the techniques of Chuzhoy et al.\n(FOCS 2020) to this wider setting, obtaining a deterministic algorithm for the\nproblem in almost-linear time.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Jason Li",
      "Thatchaphol Saranurak"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.01567"
  },
  {
    "id": "arXiv:2106.01570",
    "title": "Subset Node Representation Learning over Large Dynamic Graphs",
    "abstract": "Dynamic graph representation learning is a task to learn node embeddings over\ndynamic networks, and has many important applications, including knowledge\ngraphs, citation networks to social networks. Graphs of this type are usually\nlarge-scale but only a small subset of vertices are related in downstream\ntasks. Current methods are too expensive to this setting as the complexity is\nat best linear-dependent on both the number of nodes and edges. In this paper,\nwe propose a new method, namely Dynamic Personalized PageRank Embedding\n(\\textsc{DynamicPPE}) for learning a target subset of node representations over\nlarge-scale dynamic networks. Based on recent advances in local node embedding\nand a novel computation of dynamic personalized PageRank vector (PPV),\n\\textsc{DynamicPPE} has two key ingredients: 1) the per-PPV complexity is\n$\\mathcal{O}(m \\bar{d} / \\epsilon)$ where $m,\\bar{d}$, and $\\epsilon$ are the\nnumber of edges received, average degree, global precision error respectively.\nThus, the per-edge event update of a single node is only dependent on $\\bar{d}$\nin average; and 2) by using these high quality PPVs and hash kernels, the\nlearned embeddings have properties of both locality and global consistency.\nThese two make it possible to capture the evolution of graph structure\neffectively. Experimental results demonstrate both the effectiveness and\nefficiency of the proposed method over large-scale dynamic networks. We apply\n\\textsc{DynamicPPE} to capture the embedding change of Chinese cities in the\nWikipedia graph during this ongoing COVID-19 pandemic\n(https://en.wikipedia.org/wiki/COVID-19_pandemic). Our results show that these\nrepresentations successfully encode the dynamics of the Wikipedia graph.",
    "descriptor": "\nComments: 9 pages + 2 pages supplement, accepted to 2021 ACM SIGKDD\n",
    "authors": [
      "Xingzhi Guo",
      "Baojian Zhou",
      "Steven Skiena"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.01570"
  },
  {
    "id": "arXiv:2106.01573",
    "title": "Irregularly Clipped Sparse Regression Codes",
    "abstract": "Recently, it was found that clipping can significantly improve the section\nerror rate (SER) performance of sparse regression (SR) codes if an optimal\nclipping threshold is chosen. In this paper, we propose irregularly clipped SR\ncodes, where multiple clipping thresholds are applied to symbols according to a\ndistribution, to further improve the SER performance of SR codes. Orthogonal\napproximate message passing (OAMP) algorithm is used for decoding. Using state\nevolution, the distribution of irregular clipping thresholds is optimized to\nminimize the SER of OAMP decoding. As a result, optimized irregularly clipped\nSR codes achieve a better tradeoff between clipping distortion and noise\ndistortion than regularly clipped SR codes. Numerical results demonstrate that\nirregularly clipped SR codes achieve 0.4 dB gain in signal-to-noise-ratio (SNR)\nover regularly clipped SR codes at code length$\\,\\approx2.5\\!\\times\\! 10^4$ and\nSER$\\,\\approx10^{-5}$. We further show that irregularly clipped SR codes are\nrobust over a wide range of code rates.",
    "descriptor": "\nComments: 6 pages, 4 figures, submitted to IEEE ITW 2021\n",
    "authors": [
      "Wencong Li",
      "Lei Liu",
      "Brian M. Kurkoski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.01573"
  },
  {
    "id": "arXiv:2106.01577",
    "title": "A Provably-Efficient Model-Free Algorithm for Constrained Markov  Decision Processes",
    "abstract": "This paper presents the first {\\em model-free}, {\\em simulator-free}\nreinforcement learning algorithm for Constrained Markov Decision Processes\n(CMDPs) with sublinear regret and zero constraint violation. The algorithm is\nnamed Triple-Q because it has three key components: a Q-function (also called\naction-value function) for the cumulative reward, a Q-function for the\ncumulative utility for the constraint, and a virtual-Queue that\n(over)-estimates the cumulative constraint violation. Under Triple-Q, at each\nstep, an action is chosen based on the pseudo-Q-value that is a combination of\nthe three Q values. The algorithm updates the reward and utility Q-values with\nlearning rates that depend on the visit counts to the corresponding (state,\naction) pairs and are periodically reset. In the episodic CMDP setting,\nTriple-Q achieves $\\tilde{\\cal O}\\left(\\frac{1 }{\\delta}H^4\nS^{\\frac{1}{2}}A^{\\frac{1}{2}}K^{\\frac{4}{5}} \\right)$ regret, where $K$ is the\ntotal number of episodes, $H$ is the number of steps in each episode, $S$ is\nthe number of states, $A$ is the number of actions, and $\\delta$ is Slater's\nconstant. Furthermore, Triple-Q guarantees zero constraint violation when $K$\nis sufficiently large. Finally, the computational complexity of Triple-Q is\nsimilar to SARSA for unconstrained MDPs and is computationally efficient.",
    "descriptor": "",
    "authors": [
      "Honghao Wei",
      "Xin Liu",
      "Lei Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01577"
  },
  {
    "id": "arXiv:2106.01580",
    "title": "The Limitations of Limited Context for Constituency Parsing",
    "abstract": "Incorporating syntax into neural approaches in NLP has a multitude of\npractical and scientific benefits. For instance, a language model that is\nsyntax-aware is likely to be able to produce better samples; even a\ndiscriminative model like BERT with a syntax module could be used for core NLP\ntasks like unsupervised syntactic parsing. Rapid progress in recent years was\narguably spurred on by the empirical success of the Parsing-Reading-Predict\narchitecture of (Shen et al., 2018a), later simplified by the Order Neuron LSTM\nof (Shen et al., 2019). Most notably, this is the first time neural approaches\nwere able to successfully perform unsupervised syntactic parsing (evaluated by\nvarious metrics like F-1 score).\nHowever, even heuristic (much less fully mathematical) understanding of why\nand when these architectures work is lagging severely behind. In this work, we\nanswer representational questions raised by the architectures in (Shen et al.,\n2018a, 2019), as well as some transition-based syntax-aware language models\n(Dyer et al., 2016): what kind of syntactic structure can current neural\napproaches to syntax represent? Concretely, we ground this question in the\nsandbox of probabilistic context-free-grammars (PCFGs), and identify a key\naspect of the representational power of these approaches: the amount and\ndirectionality of context that the predictor has access to when forced to make\nparsing decision. We show that with limited context (either bounded, or\nunidirectional), there are PCFGs, for which these approaches cannot represent\nthe max-likelihood parse; conversely, if the context is unlimited, they can\nrepresent the max-likelihood parse of any PCFG.",
    "descriptor": "\nComments: To be published in ACL 2021 (this https URL) as a long paper\n",
    "authors": [
      "Yuchen Li",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01580"
  },
  {
    "id": "arXiv:2106.01581",
    "title": "To Point or Not to Point: Understanding How Abstractive Summarizers  Paraphrase Text",
    "abstract": "Abstractive neural summarization models have seen great improvements in\nrecent years, as shown by ROUGE scores of the generated summaries. But despite\nthese improved metrics, there is limited understanding of the strategies\ndifferent models employ, and how those strategies relate their understanding of\nlanguage. To understand this better, we run several experiments to characterize\nhow one popular abstractive model, the pointer-generator model of See et al.\n(2017), uses its explicit copy/generation switch to control its level of\nabstraction (generation) vs extraction (copying). On an extractive-biased\ndataset, the model utilizes syntactic boundaries to truncate sentences that are\notherwise often copied verbatim. When we modify the copy/generation switch and\nforce the model to generate, only simple paraphrasing abilities are revealed\nalongside factual inaccuracies and hallucinations. On an abstractive-biased\ndataset, the model copies infrequently but shows similarly limited abstractive\nabilities. In line with previous research, these results suggest that\nabstractive summarization models lack the semantic understanding necessary to\ngenerate paraphrases that are both abstractive and faithful to the source\ndocument.",
    "descriptor": "\nComments: Findings of ACL 2021\n",
    "authors": [
      "Matt Wilber",
      "William Timkey",
      "Marten Van Schijndel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01581"
  },
  {
    "id": "arXiv:2106.01583",
    "title": "Cross-Network Learning with Partially Aligned Graph Convolutional  Networks",
    "abstract": "Graph neural networks have been widely used for learning representations of\nnodes for many downstream tasks on graph data. Existing models were designed\nfor the nodes on a single graph, which would not be able to utilize information\nacross multiple graphs. The real world does have multiple graphs where the\nnodes are often partially aligned. For examples, knowledge graphs share a\nnumber of named entities though they may have different relation schema;\ncollaboration networks on publications and awarded projects share some\nresearcher nodes who are authors and investigators, respectively; people use\nmultiple web services, shopping, tweeting, rating movies, and some may register\nthe same email account across the platforms. In this paper, I propose partially\naligned graph convolutional networks to learn node representations across the\nmodels. I investigate multiple methods (including model sharing,\nregularization, and alignment reconstruction) as well as theoretical analysis\nto positively transfer knowledge across the (small) set of partially aligned\nnodes. Extensive experiments on real-world knowledge graphs and collaboration\nnetworks show the superior performance of our proposed methods on relation\nclassification and link prediction.",
    "descriptor": "\nComments: 9 pages, 8 figures, KDD 2021\n",
    "authors": [
      "Meng Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01583"
  },
  {
    "id": "arXiv:2106.01586",
    "title": "A Systematic Investigation of KB-Text Embedding Alignment at Scale",
    "abstract": "Knowledge bases (KBs) and text often contain complementary knowledge: KBs\nstore structured knowledge that can support long range reasoning, while text\nstores more comprehensive and timely knowledge in an unstructured way.\nSeparately embedding the individual knowledge sources into vector spaces has\ndemonstrated tremendous successes in encoding the respective knowledge, but how\nto jointly embed and reason with both knowledge sources to fully leverage the\ncomplementary information is still largely an open problem. We conduct a\nlarge-scale, systematic investigation of aligning KB and text embeddings for\njoint reasoning. We set up a novel evaluation framework with two evaluation\ntasks, few-shot link prediction and analogical reasoning, and evaluate an array\nof KB-text embedding alignment methods. We also demonstrate how such alignment\ncan infuse textual information into KB embeddings for more accurate link\nprediction on emerging entities and events, using COVID-19 as a case study.",
    "descriptor": "\nComments: Accepted to ACL-IJCNLP 2021. 11 pages, 2 figures\n",
    "authors": [
      "Vardaan Pahuja",
      "Yu Gu",
      "Wenhu Chen",
      "Mehdi Bahrami",
      "Lei Liu",
      "Wei-Peng Chen",
      "Yu Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01586"
  },
  {
    "id": "arXiv:2106.01587",
    "title": "An Information Theoretic approach to identify Dominant Voltage  Influencers for Unbalanced Distribution Systems",
    "abstract": "Smart distribution grid with multiple renewable energy sources can experience\nrandom voltage fluctuations due to variable generation, which may result in\nvoltage violations. Traditional voltage control algorithms are inadequate to\nhandle fast voltage variations. Therefore, new dynamic control methods are\nbeing developed that can significantly benefit from the knowledge of dominant\nvoltage influencer (DVI) nodes. DVI nodes for a particular node of interest\nrefer to nodes that have a relatively high impact on the voltage fluctuations\nat that node. Conventional power flow-based algorithms to identify DVI nodes\nare computationally complex, which limits their use in real-time applications.\nThis paper proposes a novel information theoretic voltage influencing score\n(VIS) that quantifies the voltage influencing capacity of nodes with\nDERs/active loads in a three phase unbalanced distribution system. VIS is then\nemployed to rank the nodes and identify the DVI set. VIS is derived\nanalytically in a computationally efficient manner and its efficacy to identify\nDVI nodes is validated using the IEEE 37-node test system. It is shown through\nexperiments that KL divergence and Bhattacharyya distance are effective\nindicators of DVI nodes with an identifying accuracy of more than 90%. The\ncomputation burden is also reduced by an order of 5, thus providing the\nfoundation for efficient voltage control.",
    "descriptor": "\nComments: 8 pages, 6 tables\n",
    "authors": [
      "Sai Munikoti",
      "Mohammad Abujubbeh",
      "Kumarsinh Jhala",
      "Balasubramaniam Natarajan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01587"
  },
  {
    "id": "arXiv:2106.01588",
    "title": "Resource-Aware Cost-Sharing Mechanisms with Priors",
    "abstract": "In a decentralized system with $m$ machines, we study the selfish scheduling\nproblem where each user strategically chooses which machine to use. Each\nmachine incurs a cost, which is a function of the total load assigned to it,\nand some cost-sharing mechanism distributes this cost among the machine's\nusers. The users choose a machine aiming to minimize their own share of the\ncost, so the cost-sharing mechanism induces a game among them. We approach this\nproblem from the perspective of a designer who can select which cost-sharing\nmechanism to use, aiming to minimize the price of anarchy (PoA) of the induced\ngames.\nRecent work introduced the class of \\emph{resource-aware} cost-sharing\nmechanisms, whose decisions can depend on the set of machines in the system,\nbut are oblivious to the total number of users. These mechanisms can guarantee\nlow PoA bounds for instances where the cost functions of the machines are all\nconvex or concave, but can suffer from very high PoA for cost functions that\ndeviate from these families.\nIn this paper we show that if we enhance the class of resource-aware\nmechanisms with some prior information regarding the users, then they can\nachieve low PoA for a much more general family of cost functions. We first show\nthat, as long as the mechanism knows just two of the participating users, then\nit can assign special roles to them and ensure a constant PoA. We then extend\nthis idea to settings where the mechanism has access to the probability with\nwhich each user is present in the system. For all these instances, we provide a\nmechanism that achieves an expected PoA that is logarithmic in the expected\nnumber of users.",
    "descriptor": "\nComments: To appear at ACM EC 2021 conference\n",
    "authors": [
      "Vasilis Gkatzelis",
      "Emmanouil Pountourakis",
      "Alkmini Sgouritsa"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01588"
  },
  {
    "id": "arXiv:2106.01589",
    "title": "The Emotion coding and Propagation based on improved Genetic algorithm",
    "abstract": "Computational communication research on information has been prevalent in\nrecent years, as people are progressively inquisitive in social behavior and\npublic opinion. Nevertheless, it is of great significance to analyze the\ndirection of predominant sentiment from the sentiment communication\nperspective. In this paper, the information emotion propagation model is\nestablished by introducing revamp genetic algorithms into information emotion.\nIn the process of information dissemination, both the information emotions and\nthe network emotions are dynamic. For this model, the information emotions and\nthe network nodes emotions are quantified as binary codes. The convergence\neffects, crossover and mutation algorithms are introduced. These factors all\nact on the transmission process via dynamic propagation rate, and the improved\ngenetic algorithm also acts on the emotion transmission. In particular, the\nlatter two algorithms are different from the existing biological domain. Based\non the existing research results in other manuscripts, we perform simulation\ndescribed above on the hybrid network. The simulation results demonstrate that\nthe trend approximate to the actual data. As a result, our work can prove that\nour proposed model is essentially consistent with the actual emotion\ntransmission phenomenon.",
    "descriptor": "",
    "authors": [
      "Hongyuan Diao",
      "Fuzhong Nian",
      "Xuelong Yu",
      "Xirui Liu",
      "Xinhao Liu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.01589"
  },
  {
    "id": "arXiv:2106.01590",
    "title": "SIMLR: Machine Learning inside the SIR model for COVID-19 Forecasting",
    "abstract": "Accurate forecasts of the number of newly infected people during an epidemic\nare critical for making effective timely decisions. This paper addresses this\nchallenge using the SIMLR model, which incorporates machine learning (ML) into\nthe epidemiological SIR model. For each region, SIMLR tracks the changes in the\npolicies implemented at the government level, which it uses to estimate the\ntime-varying parameters of an SIR model for forecasting the number of new\ninfections 1- to 4-weeks in advance.It also forecasts the probability of\nchanges in those government policies at each of these future times, which is\nessential for the longer-range forecasts. We applied SIMLR to data from regions\nin Canada and in the United States,and show that its MAPE (mean average\npercentage error) performance is as good as SOTA forecasting models, with the\nadded advantage of being an interpretable model. We expect that this approach\nwill be useful not only for forecasting COVID-19 infections, but also in\npredicting the evolution of other infectious diseases.",
    "descriptor": "",
    "authors": [
      "Roberto Vega",
      "Leonardo Flores",
      "Russell Greiner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.01590"
  },
  {
    "id": "arXiv:2106.01592",
    "title": "Data-Driven Design-by-Analogy: State of the Art and Future Directions",
    "abstract": "Design-by-Analogy (DbA) is a design methodology wherein new solutions,\nopportunities or designs are generated in a target domain based on inspiration\ndrawn from a source domain; it can benefit designers in mitigating design\nfixation and improving design ideation outcomes. Recently, the increasingly\navailable design databases and rapidly advancing data science and artificial\nintelligence technologies have presented new opportunities for developing\ndata-driven methods and tools for DbA support. In this study, we survey\nexisting data-driven DbA studies and categorize individual studies according to\nthe data, methods, and applications in four categories, namely, analogy\nencoding, retrieval, mapping, and evaluation. Based on both nuanced organic\nreview and structured analysis, this paper elucidates the state of the art of\ndata-driven DbA research to date and benchmarks it with the frontier of data\nscience and AI research to identify promising research opportunities and\ndirections for the field. Finally, we propose a future conceptual data-driven\nDbA system that integrates all propositions.",
    "descriptor": "\nComments: A Preprint Version\n",
    "authors": [
      "Shuo Jiang",
      "Jie Hu",
      "Kristin L. Wood",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.01592"
  },
  {
    "id": "arXiv:2106.01594",
    "title": "Towards Robust GNSS Positioning and Real-time Kinematic Using Factor  Graph Optimization",
    "abstract": "Global navigation satellite systems (GNSS) are one of the utterly popular\nsources for providing globally referenced positioning for autonomous systems.\nHowever, the performance of the GNSS positioning is significantly challenged in\nurban canyons, due to the signal reflection and blockage from buildings. Given\nthe fact that the GNSS measurements are highly environmentally dependent and\ntime-correlated, the conventional filtering-based method for GNSS positioning\ncannot simultaneously explore the time-correlation among historical\nmeasurements. As a result, the filtering-based estimator is sensitive to\nunexpected outlier measurements. In this paper, we present a factor graph-based\nformulation for GNSS positioning and real-time kinematic (RTK). The formulated\nfactor graph framework effectively explores the time-correlation of\npseudorange, carrier-phase, and doppler measurements, and leads to the\nnon-minimal state estimation of the GNSS receiver. The feasibility of the\nproposed method is evaluated using datasets collected in challenging urban\ncanyons of Hong Kong and significantly improved positioning accuracy is\nobtained, compared with the filtering-based estimator.",
    "descriptor": "",
    "authors": [
      "Weisong Wen",
      "Li-Ta Hsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.01594"
  },
  {
    "id": "arXiv:2106.01595",
    "title": "Position Heaps for Cartesian-tree Matching on Strings and Tries",
    "abstract": "The Cartesian-tree pattern matching is a recently introduced scheme of\npattern matching that detects fragments in a sequential data stream which have\na similar structure as a query pattern. Formally, Cartesian-tree pattern\nmatching seeks all substrings $S'$ of the text string $S$ such that the\nCartesian tree of $S'$ and that of a query pattern $P$ coincide. In this paper,\nwe present a new indexing structure for this problem called the Cartesian-tree\nPosition Heap (CPH). Let $n$ be the length of the input text string $S$, $m$\nthe length of a query pattern $P$, and $\\sigma$ the alphabet size. We show that\nthe CPH of $S$, denoted $\\mathsf{CPH}(S)$, supports pattern matching queries in\n$O(m (\\sigma + \\log (\\min\\{h, m\\})) + occ)$ time with $O(n)$ space, where $h$\nis the height of the CPH and $occ$ is the number of pattern occurrences. We\nshow how to build $\\mathsf{CPH}(S)$ in $O(n \\log \\sigma)$ time with $O(n)$\nworking space. Further, we extend the problem to the case where the text is a\nlabeled tree (i.e. a trie). Given a trie $T$ with $N$ nodes, we show that the\nCPH of $T$, denoted $\\mathsf{CPH}(T)$, supports pattern matching queries on the\ntrie in $O(m (\\sigma^2 + \\log (\\min\\{h, m\\})) + occ)$ time with $O(N \\sigma)$\nspace. We also show a construction algorithm for $\\mathsf{CPH}(T)$ running in\n$O(N \\sigma)$ time and $O(N \\sigma)$ working space.",
    "descriptor": "",
    "authors": [
      "Akio Nishimoto",
      "Noriki Fujisato",
      "Yuto Nakashima",
      "Shunsuke Inenaga"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.01595"
  },
  {
    "id": "arXiv:2106.01596",
    "title": "Attention-Guided Supervised Contrastive Learning for Semantic  Segmentation",
    "abstract": "Contrastive learning has shown superior performance in embedding global and\nspatial invariant features in computer vision (e.g., image classification).\nHowever, its overall success of embedding local and spatial variant features is\nstill limited, especially for semantic segmentation. In a per-pixel prediction\ntask, more than one label can exist in a single image for segmentation (e.g.,\nan image contains both cat, dog, and grass), thereby it is difficult to define\n'positive' or 'negative' pairs in a canonical contrastive learning setting. In\nthis paper, we propose an attention-guided supervised contrastive learning\napproach to highlight a single semantic object every time as the target. With\nour design, the same image can be embedded to different semantic clusters with\nsemantic attention (i.e., coerce semantic masks) as an additional input\nchannel. To achieve such attention, a novel two-stage training strategy is\npresented. We evaluate the proposed method on multi-organ medical image\nsegmentation task, as our major task, with both in-house data and BTCV 2015\ndatasets. Comparing with the supervised and semi-supervised training\nstate-of-the-art in the backbone of ResNet-50, our proposed pipeline yields\nsubstantial improvement of 5.53% and 6.09% in Dice score for both medical image\nsegmentation cohorts respectively. The performance of the proposed method on\nnatural images is assessed via PASCAL VOC 2012 dataset, and achieves 2.75%\nsubstantial improvement.",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Ho Hin Lee",
      "Yucheng Tang",
      "Qi Yang",
      "Xin Yu",
      "Shunxing Bao",
      "Bennett A. Landman",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01596"
  },
  {
    "id": "arXiv:2106.01597",
    "title": "ZmBART: An Unsupervised Cross-lingual Transfer Framework for Language  Generation",
    "abstract": "Despite the recent advancement in NLP research, cross-lingual transfer for\nnatural language generation is relatively understudied. In this work, we\ntransfer supervision from high resource language (HRL) to multiple low-resource\nlanguages (LRLs) for natural language generation (NLG). We consider four NLG\ntasks (text summarization, question generation, news headline generation, and\ndistractor generation) and three syntactically diverse languages, i.e.,\nEnglish, Hindi, and Japanese. We propose an unsupervised cross-lingual language\ngeneration framework (called ZmBART) that does not use any parallel or\npseudo-parallel/back-translated data. In this framework, we further pre-train\nmBART sequence-to-sequence denoising auto-encoder model with an auxiliary task\nusing monolingual data of three languages. The objective function of the\nauxiliary task is close to the target tasks which enriches the multi-lingual\nlatent representation of mBART and provides good initialization for target\ntasks. Then, this model is fine-tuned with task-specific supervised English\ndata and directly evaluated with low-resource languages in the Zero-shot\nsetting. To overcome catastrophic forgetting and spurious correlation issues,\nwe applied freezing model component and data argumentation approaches\nrespectively. This simple modeling approach gave us promising results.We\nexperimented with few-shot training (with 1000 supervised data points) which\nboosted the model performance further. We performed several ablations and\ncross-lingual transferability analyses to demonstrate the robustness of ZmBART.",
    "descriptor": "\nComments: Accepted in Findings of ACL-IJCNLP 2021\n",
    "authors": [
      "Kaushal Kumar Maurya",
      "Maunendra Sankar Desarkar",
      "Yoshinobu Kano",
      "Kumari Deepshikha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01597"
  },
  {
    "id": "arXiv:2106.01598",
    "title": "Automatically Detecting Cyberbullying Comments on Online Game Forums",
    "abstract": "Online game forums are popular to most of game players. They use it to\ncommunicate and discuss the strategy of the game, or even to make friends.\nHowever, game forums also contain abusive and harassment speech, disturbing and\nthreatening players. Therefore, it is necessary to automatically detect and\nremove cyberbullying comments to keep the game forum clean and friendly. We use\nthe Cyberbullying dataset collected from World of Warcraft (WoW) and League of\nLegends (LoL) forums and train classification models to automatically detect\nwhether a comment of a player is abusive or not. The result obtains 82.69% of\nmacro F1-score for LoL forum and 83.86% of macro F1-score for WoW forum by the\nToxic-BERT model on the Cyberbullying dataset.",
    "descriptor": "\nComments: Accepted at RIVF 2021 Conference\n",
    "authors": [
      "Hanh Hong-Phuc Vo",
      "Hieu Trung Tran",
      "Son T. Luu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01598"
  },
  {
    "id": "arXiv:2106.01601",
    "title": "Men Are Elected, Women Are Married: Events Gender Bias on Wikipedia",
    "abstract": "Human activities can be seen as sequences of events, which are crucial to\nunderstanding societies. Disproportional event distribution for different\ndemographic groups can manifest and amplify social stereotypes, and potentially\njeopardize the ability of members in some groups to pursue certain goals. In\nthis paper, we present the first event-centric study of gender biases in a\nWikipedia corpus. To facilitate the study, we curate a corpus of career and\npersonal life descriptions with demographic information consisting of 7,854\nfragments from 10,412 celebrities. Then we detect events with a\nstate-of-the-art event detection model, calibrate the results using\nstrategically generated templates, and extract events that have asymmetric\nassociations with genders. Our study discovers that the Wikipedia pages tend to\nintermingle personal life events with professional events for females but not\nfor males, which calls for the awareness of the Wikipedia community to\nformalize guidelines and train the editors to mind the implicit biases that\ncontributors carry. Our work also lays the foundation for future works on\nquantifying and discovering event biases at the corpus level.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Jiao Sun",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01601"
  },
  {
    "id": "arXiv:2106.01603",
    "title": "CT-Net: Channel Tensorization Network for Video Classification",
    "abstract": "3D convolution is powerful for video classification but often computationally\nexpensive, recent studies mainly focus on decomposing it on spatial-temporal\nand/or channel dimensions. Unfortunately, most approaches fail to achieve a\npreferable balance between convolutional efficiency and feature-interaction\nsufficiency. For this reason, we propose a concise and novel Channel\nTensorization Network (CT-Net), by treating the channel dimension of input\nfeature as a multiplication of K sub-dimensions. On one hand, it naturally\nfactorizes convolution in a multiple dimension way, leading to a light\ncomputation burden. On the other hand, it can effectively enhance feature\ninteraction from different channels, and progressively enlarge the 3D receptive\nfield of such interaction to boost classification accuracy. Furthermore, we\nequip our CT-Module with a Tensor Excitation (TE) mechanism. It can learn to\nexploit spatial, temporal and channel attention in a high-dimensional manner,\nto improve the cooperative power of all the feature dimensions in our\nCT-Module. Finally, we flexibly adapt ResNet as our CT-Net. Extensive\nexperiments are conducted on several challenging video benchmarks, e.g.,\nKinetics-400, Something-Something V1 and V2. Our CT-Net outperforms a number of\nrecent SOTA approaches, in terms of accuracy and/or efficiency. The codes and\nmodels will be available on https://github.com/Andy1621/CT-Net.",
    "descriptor": "\nComments: ICLR 2021. Code is available on this https URL\n",
    "authors": [
      "Kunchang Li",
      "Xianhang Li",
      "Yali Wang",
      "Jun Wang",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01603"
  },
  {
    "id": "arXiv:2106.01604",
    "title": "Noisy student-teacher training for robust keyword spotting",
    "abstract": "We propose self-training with noisy student-teacher approach for streaming\nkeyword spotting, that can utilize large-scale unlabeled data and aggressive\ndata augmentation. The proposed method applies aggressive data augmentation\n(spectral augmentation) on the input of both student and teacher and utilize\nunlabeled data at scale, which significantly boosts the accuracy of student\nagainst challenging conditions. Such aggressive augmentation usually degrades\nmodel performance when used with supervised training with hard-labeled data.\nExperiments show that aggressive spec augmentation on baseline supervised\ntraining method degrades accuracy, while the proposed self-training with noisy\nstudent-teacher training improves accuracy of some difficult-conditioned test\nsets by as much as 60%.",
    "descriptor": "",
    "authors": [
      "Hyun-Jin Park",
      "Pai Zhu",
      "Ignacio Lopez Moreno",
      "Niranjan Subrahmanya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01604"
  },
  {
    "id": "arXiv:2106.01606",
    "title": "Exploring Memorization in Adversarial Training",
    "abstract": "It is well known that deep learning models have a propensity for fitting the\nentire training set even with random labels, which requires memorization of\nevery training sample. In this paper, we investigate the memorization effect in\nadversarial training (AT) for promoting a deeper understanding of capacity,\nconvergence, generalization, and especially robust overfitting of adversarially\ntrained classifiers. We first demonstrate that deep networks have sufficient\ncapacity to memorize adversarial examples of training data with completely\nrandom labels, but not all AT algorithms can converge under the extreme\ncircumstance. Our study of AT with random labels motivates further analyses on\nthe convergence and generalization of AT. We find that some AT methods suffer\nfrom a gradient instability issue, and the recently suggested complexity\nmeasures cannot explain robust generalization by considering models trained on\nrandom labels. Furthermore, we identify a significant drawback of memorization\nin AT that it could result in robust overfitting. We then propose a new\nmitigation algorithm motivated by detailed memorization analyses. Extensive\nexperiments on various datasets validate the effectiveness of the proposed\nmethod.",
    "descriptor": "",
    "authors": [
      "Yinpeng Dong",
      "Ke Xu",
      "Xiao Yang",
      "Tianyu Pang",
      "Zhijie Deng",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01606"
  },
  {
    "id": "arXiv:2106.01607",
    "title": "Grounding Complex Navigational Instructions Using Scene Graphs",
    "abstract": "Training a reinforcement learning agent to carry out natural language\ninstructions is limited by the available supervision, i.e. knowing when the\ninstruction has been carried out. We adapt the CLEVR visual question answering\ndataset to generate complex natural language navigation instructions and\naccompanying scene graphs, yielding an environment-agnostic supervised dataset.\nTo demonstrate the use of this data set, we map the scenes to the VizDoom\nenvironment and use the architecture in \\citet{gatedattention} to train an\nagent to carry out these more complex language instructions.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1706.07230 by other authors\n",
    "authors": [
      "Michiel de Jong",
      "Satyapriya Krishna",
      "Anuva Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01607"
  },
  {
    "id": "arXiv:2106.01608",
    "title": "A Discussion On the Validity of Manifold Learning",
    "abstract": "Dimensionality reduction (DR) and manifold learning (ManL) have been applied\nextensively in many machine learning tasks, including signal processing, speech\nrecognition, and neuroinformatics. However, the understanding of whether DR and\nManL models can generate valid learning results remains unclear. In this work,\nwe investigate the validity of learning results of some widely used DR and ManL\nmethods through the chart mapping function of a manifold. We identify a\nfundamental problem of these methods: the mapping functions induced by these\nmethods violate the basic settings of manifolds, and hence they are not\nlearning manifold in the mathematical sense. To address this problem, we\nprovide a provably correct algorithm called fixed points Laplacian mapping\n(FPLM), that has the geometric guarantee to find a valid manifold\nrepresentation (up to a homeomorphism). Combining one additional\ncondition(orientation preserving), we discuss a sufficient condition for an\nalgorithm to be bijective for any d-simplex decomposition result on a\nd-manifold. However, constructing such a mapping function and its computational\nmethod satisfying these conditions is still an open problem in mathematics.",
    "descriptor": "",
    "authors": [
      "Dai Shi",
      "Andi Han",
      "Yi Guo",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01608"
  },
  {
    "id": "arXiv:2106.01609",
    "title": "Tail-to-Tail Non-Autoregressive Sequence Prediction for Chinese  Grammatical Error Correction",
    "abstract": "We investigate the problem of Chinese Grammatical Error Correction (CGEC) and\npresent a new framework named Tail-to-Tail (\\textbf{TtT}) non-autoregressive\nsequence prediction to address the deep issues hidden in CGEC. Considering that\nmost tokens are correct and can be conveyed directly from source to target, and\nthe error positions can be estimated and corrected based on the bidirectional\ncontext information, thus we employ a BERT-initialized Transformer Encoder as\nthe backbone model to conduct information modeling and conveying. Considering\nthat only relying on the same position substitution cannot handle the\nvariable-length correction cases, various operations such substitution,\ndeletion, insertion, and local paraphrasing are required jointly. Therefore, a\nConditional Random Fields (CRF) layer is stacked on the up tail to conduct\nnon-autoregressive sequence prediction by modeling the token dependencies.\nSince most tokens are correct and easily to be predicted/conveyed to the\ntarget, then the models may suffer from a severe class imbalance issue. To\nalleviate this problem, focal loss penalty strategies are integrated into the\nloss functions. Moreover, besides the typical fix-length error correction\ndatasets, we also construct a variable-length corpus to conduct experiments.\nExperimental results on standard datasets, especially on the variable-length\ndatasets, demonstrate the effectiveness of TtT in terms of sentence-level\nAccuracy, Precision, Recall, and F1-Measure on tasks of error Detection and\nCorrection.",
    "descriptor": "\nComments: Accepted in the main conference of ACL 2021. Code: this https URL\n",
    "authors": [
      "Piji Li",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01609"
  },
  {
    "id": "arXiv:2106.01613",
    "title": "NODE-GAM: Neural Generalized Additive Model for Interpretable Deep  Learning",
    "abstract": "Deployment of machine learning models in real high-risk settings (e.g.\nhealthcare) often depends not only on model's accuracy but also on its\nfairness, robustness and interpretability. Generalized Additive Models (GAMs)\nhave a long history of use in these high-risk domains, but lack desirable\nfeatures of deep learning such as differentiability and scalability. In this\nwork, we propose a neural GAM (NODE-GAM) and neural GA$^2$M (NODE-GA$^2$M) that\nscale well to large datasets, while remaining interpretable and accurate. We\nshow that our proposed models have comparable accuracy to other\nnon-interpretable models, and outperform other GAMs on large datasets. We also\nshow that our models are more accurate in self-supervised learning setting when\naccess to labeled data is limited.",
    "descriptor": "",
    "authors": [
      "Chun-Hao Chang",
      "Rich Caruana",
      "Anna Goldenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01613"
  },
  {
    "id": "arXiv:2106.01615",
    "title": "Imperceptible Adversarial Examples for Fake Image Detection",
    "abstract": "Fooling people with highly realistic fake images generated with Deepfake or\nGANs brings a great social disturbance to our society. Many methods have been\nproposed to detect fake images, but they are vulnerable to adversarial\nperturbations -- intentionally designed noises that can lead to the wrong\nprediction. Existing methods of attacking fake image detectors usually generate\nadversarial perturbations to perturb almost the entire image. This is redundant\nand increases the perceptibility of perturbations. In this paper, we propose a\nnovel method to disrupt the fake image detection by determining key pixels to a\nfake image detector and attacking only the key pixels, which results in the\n$L_0$ and the $L_2$ norms of adversarial perturbations much less than those of\nexisting works. Experiments on two public datasets with three fake image\ndetectors indicate that our proposed method achieves state-of-the-art\nperformance in both white-box and black-box attacks.",
    "descriptor": "\nComments: Accepted by ICIP 2021\n",
    "authors": [
      "Quanyu Liao",
      "Yuezun Li",
      "Xin Wang",
      "Bin Kong",
      "Bin Zhu",
      "Siwei Lyu",
      "Youbing Yin",
      "Qi Song",
      "Xi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01615"
  },
  {
    "id": "arXiv:2106.01617",
    "title": "Improving the Transferability of Adversarial Examples with New Iteration  Framework and Input Dropout",
    "abstract": "Deep neural networks(DNNs) is vulnerable to be attacked by adversarial\nexamples. Black-box attack is the most threatening attack. At present,\nblack-box attack methods mainly adopt gradient-based iterative attack methods,\nwhich usually limit the relationship between the iteration step size, the\nnumber of iterations, and the maximum perturbation. In this paper, we propose a\nnew gradient iteration framework, which redefines the relationship between the\nabove three. Under this framework, we easily improve the attack success rate of\nDI-TI-MIM. In addition, we propose a gradient iterative attack method based on\ninput dropout, which can be well combined with our framework. We further\npropose a multi dropout rate version of this method. Experimental results show\nthat our best method can achieve attack success rate of 96.2\\% for defense\nmodel on average, which is higher than the state-of-the-art gradient-based\nattacks.",
    "descriptor": "",
    "authors": [
      "Pengfei Xie",
      "Linyuan Wang",
      "Ruoxi Qin",
      "Kai Qiao",
      "Shuhao Shi",
      "Guoen Hu",
      "Bin Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01617"
  },
  {
    "id": "arXiv:2106.01618",
    "title": "Transferable Adversarial Examples for Anchor Free Object Detection",
    "abstract": "Deep neural networks have been demonstrated to be vulnerable to adversarial\nattacks: subtle perturbation can completely change prediction result. The\nvulnerability has led to a surge of research in this direction, including\nadversarial attacks on object detection networks. However, previous studies are\ndedicated to attacking anchor-based object detectors. In this paper, we present\nthe first adversarial attack on anchor-free object detectors. It conducts\ncategory-wise, instead of previously instance-wise, attacks on object\ndetectors, and leverages high-level semantic information to efficiently\ngenerate transferable adversarial examples, which can also be transferred to\nattack other object detectors, even anchor-based detectors such as Faster\nR-CNN. Experimental results on two benchmark datasets demonstrate that our\nproposed method achieves state-of-the-art performance and transferability.",
    "descriptor": "\nComments: Accepted as oral in ICME 2021\n",
    "authors": [
      "Quanyu Liao",
      "Xin Wang",
      "Bin Kong",
      "Siwei Lyu",
      "Bin Zhu",
      "Youbing Yin",
      "Qi Song",
      "Xi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01618"
  },
  {
    "id": "arXiv:2106.01621",
    "title": "ERANNs: Efficient Residual Audio Neural Networks for Audio Pattern  Recognition",
    "abstract": "We present a new architecture of convolutional neural networks (CNNs) based\non ResNet for audio pattern recognition tasks. The main modification is\nintroducing a new hyper-parameter for decreasing temporal sizes of tensors with\nincreased stride sizes which we call \"the decreasing temporal size parameter\".\nOptimal values of this parameter decrease the number of multi-adds that make\nthe system faster. This approach not only decreases computational complexity\nbut it can save and even increase (for the AudioSet dataset) the performance\nfor audio pattern recognition tasks. This observation can be confirmed by\nexperiments on three datasets: the AudioSet dataset, the ESC-50 dataset, and\nRAVDESS. Our best system achieves the state-of-the-art performance on the\nAudioSet dataset with mAP of 0.450. We also transfer a model pre-trained on the\nAudioSet dataset to the ESC-50 dataset and RAVDESS and obtain the\nstate-of-the-art results with accuracies of 0.961 and 0.748, respectively. We\ncall our system \"ERANN\" (Efficient Residual Audio Neural Network).",
    "descriptor": "",
    "authors": [
      "Sergey Verbitskiy",
      "Viacheslav Vyshegorodtsev"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.01621"
  },
  {
    "id": "arXiv:2106.01623",
    "title": "Few-shot Knowledge Graph-to-Text Generation with Pretrained Language  Models",
    "abstract": "This paper studies how to automatically generate a natural language text that\ndescribes the facts in knowledge graph (KG). Considering the few-shot setting,\nwe leverage the excellent capacities of pretrained language models (PLMs) in\nlanguage understanding and generation. We make three major technical\ncontributions, namely representation alignment for bridging the semantic gap\nbetween KG encodings and PLMs, relation-biased KG linearization for deriving\nbetter input representations, and multi-task learning for learning the\ncorrespondence between KG and text. Extensive experiments on three benchmark\ndatasets have demonstrated the effectiveness of our model on KG-to-text\ngeneration task. In particular, our model outperforms all comparison methods on\nboth fully-supervised and few-shot settings. Our code and datasets are\navailable at https://github.com/RUCAIBox/Few-Shot-KG2Text.",
    "descriptor": "\nComments: Accepted to ACL 2021 Findings\n",
    "authors": [
      "Junyi Li",
      "Tianyi Tang",
      "Wayne Xin Zhao",
      "Zhicheng Wei",
      "Nicholas Jing Yuan",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01623"
  },
  {
    "id": "arXiv:2106.01624",
    "title": "Sleeping Combinatorial Bandits",
    "abstract": "In this paper, we study an interesting combination of sleeping and\ncombinatorial stochastic bandits. In the mixed model studied here, at each\ndiscrete time instant, an arbitrary \\emph{availability set} is generated from a\nfixed set of \\emph{base} arms. An algorithm can select a subset of arms from\nthe \\emph{availability set} (sleeping bandits) and receive the corresponding\nreward along with semi-bandit feedback (combinatorial bandits).\nWe adapt the well-known CUCB algorithm in the sleeping combinatorial bandits\nsetting and refer to it as \\CSUCB. We prove -- under mild smoothness conditions\n-- that the \\CSUCB\\ algorithm achieves an $O(\\log (T))$ instance-dependent\nregret guarantee. We further prove that (i) when the range of the rewards is\nbounded, the regret guarantee of \\CSUCB\\ algorithm is $O(\\sqrt{T \\log (T)})$\nand (ii) the instance-independent regret is $O(\\sqrt[3]{T^2 \\log(T)})$ in a\ngeneral setting. Our results are quite general and hold under general\nenvironments -- such as non-additive reward functions, volatile arm\navailability, a variable number of base-arms to be pulled -- arising in\npractical applications. We validate the proven theoretical guarantees through\nexperiments.",
    "descriptor": "",
    "authors": [
      "Kumar Abhishek",
      "Ganesh Ghalme",
      "Sujit Gujar",
      "Yadati Narahari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01624"
  },
  {
    "id": "arXiv:2106.01625",
    "title": "Generate, Prune, Select: A Pipeline for Counterspeech Generation against  Online Hate Speech",
    "abstract": "Countermeasures to effectively fight the ever increasing hate speech online\nwithout blocking freedom of speech is of great social interest. Natural\nLanguage Generation (NLG), is uniquely capable of developing scalable\nsolutions. However, off-the-shelf NLG methods are primarily\nsequence-to-sequence neural models and they are limited in that they generate\ncommonplace, repetitive and safe responses regardless of the hate speech (e.g.,\n\"Please refrain from using such language.\") or irrelevant responses, making\nthem ineffective for de-escalating hateful conversations. In this paper, we\ndesign a three-module pipeline approach to effectively improve the diversity\nand relevance. Our proposed pipeline first generates various counterspeech\ncandidates by a generative model to promote diversity, then filters the\nungrammatical ones using a BERT model, and finally selects the most relevant\ncounterspeech response using a novel retrieval-based method. Extensive\nExperiments on three representative datasets demonstrate the efficacy of our\napproach in generating diverse and relevant counterspeech.",
    "descriptor": "\nComments: The 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP): Findings\n",
    "authors": [
      "Wanzheng Zhu",
      "Suma Bhat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01625"
  },
  {
    "id": "arXiv:2106.01627",
    "title": "Piercing the Veil: Designs to Support Information Literacy on Social  Platforms",
    "abstract": "In this position paper we approach problems concerning critical digital and\ninformation literacy with ideas to provide more digestible explanations of\nabstract concepts through interface design. In particular, we focus on social\nmedia platforms where we see the possibility of counteracting the spread of\nmisinformation by providing users with more proficiency through our approaches.\nWe argue that the omnipresent trend to abstract away and hide information from\nusers via UI/UX design opposes their ability to self-learn. This leads us to\npropose a different framework in which we unify elegant and simple interfaces\nwith nudges that promote a look behind the curtain. Such designs serve to\nfoster a deeper understanding of employed technologies and aim to increase the\ncritical assessment of content encountered on social platforms. Furthermore, we\nconsider users with an intermediary skill level to be largely ignored in\ncurrent approaches, as they are given no tools to broaden their knowledge\nwithout consultation of expert material. The resulting stagnation is\nexemplified by the tactics of misinformation campaigns, which exploit the\nensuing lack of information literacy and critical thinking. We propose an\napproach to design that sufficiently emancipates users in both aspects by\npromoting a look behind the abstraction of UI/UX so that an autonomous learning\nprocess is given the chance to occur. Furthermore, we name ideas for future\nresearch within this area that take our considerations into account.",
    "descriptor": "\nComments: Originally submitted to and presented at CHI'21 Workshop on Technologies to Support Critical Thinking in an Age of Misinformation\n",
    "authors": [
      "Jan Wolff"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.01627"
  },
  {
    "id": "arXiv:2106.01628",
    "title": "A Coalgebraic Approach to Dualities for Neighborhood Frames",
    "abstract": "We develop a uniform coalgebraic approach to Thomason and J\\'{o}nsson-Tarski\ntype dualities for various classes of neighborhood frames and neighborhood\nalgebras. In the first part of the paper we construct an endofunctor on the\ncategory of complete and atomic Boolean algebras that is dual to the double\npowerset functor on $\\mathsf{Set}$. This allows us to show that Thomason\nduality for neighborhood frames can be viewed as an algebra-coalgebra duality.\nWe generalize this approach to any class of algebras for an endofunctor\npresented by one-step axioms in the language of infinitary modal logic. As a\nconsequence, we obtain a uniform approach to dualities for various classes of\nneighborhood frames, including monotone neighborhood frames, pretopological\nspaces, and topological spaces.\nIn the second part of the paper we develop a coalgebraic approach to\nJ\\'{o}nsson-Tarski duality for neighborhood algebras and descriptive\nneighborhood frames. We introduce an analogue of the Vietoris endofunctor on\nthe category of Stone spaces and show that descriptive neighborhood frames are\nisomorphic to coalgebras for this endofunctor. This allows us to obtain a\ncoalgebraic proof of the duality between descriptive neighborhood frames and\nneighborhood algebras. Using one-step axioms in the language of finitary modal\nlogic, we restrict this duality to other classes of neighborhood algebras\nstudied in the literature, including monotone modal algebras and contingency\nalgebras.\nWe conclude the paper by connecting the two types of dualities via canonical\nextensions, and discuss when these extensions are functorial.",
    "descriptor": "",
    "authors": [
      "Guram Bezhanishvili",
      "Nick Bezhanishvili",
      "Jim de Groot"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.01628"
  },
  {
    "id": "arXiv:2106.01629",
    "title": "Semantic Palette: Guiding Scene Generation with Class Proportions",
    "abstract": "Despite the recent progress of generative adversarial networks (GANs) at\nsynthesizing photo-realistic images, producing complex urban scenes remains a\nchallenging problem. Previous works break down scene generation into two\nconsecutive phases: unconditional semantic layout synthesis and image synthesis\nconditioned on layouts. In this work, we propose to condition layout generation\nas well for higher semantic control: given a vector of class proportions, we\ngenerate layouts with matching composition. To this end, we introduce a\nconditional framework with novel architecture designs and learning objectives,\nwhich effectively accommodates class proportions to guide the scene generation\nprocess. The proposed architecture also allows partial layout editing with\ninteresting applications. Thanks to the semantic control, we can produce\nlayouts close to the real distribution, helping enhance the whole scene\ngeneration process. On different metrics and urban scene benchmarks, our models\noutperform existing baselines. Moreover, we demonstrate the merit of our\napproach for data augmentation: semantic segmenters trained on real\nlayout-image pairs along with additional ones generated by our approach\noutperform models only trained on real pairs.",
    "descriptor": "\nComments: Accepted to IEEE CVPR 2021\n",
    "authors": [
      "Guillaume Le Moing",
      "Tuan-Hung Vu",
      "Himalaya Jain",
      "Patrick P\u00e9rez",
      "Matthieu Cord"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01629"
  },
  {
    "id": "arXiv:2106.01632",
    "title": "Cybersecurity Information Exchange with Privacy (CYBEX-P) and TAHOE -- A  Cyberthreat Language",
    "abstract": "Cybersecurity information sharing (CIS) is envisioned to protect\norganizations more effectively from advanced cyber attacks. However, a\ncompletely automated CIS platform is not widely adopted. The major challenges\nare: (1) the absence of a robust cyber threat language (CTL) and (2) the\nconcerns over data privacy. This work introduces Cybersecurity Information\nExchangewith Privacy (CYBEX-P), as a CIS framework, to tackle these challenges.\nCYBEX-P allows organizations to share heterogeneous data with granular,\nattribute based privacy control. It correlates the data to automatically\ngenerate intuitive reports and defensive rules. To achieve such versatility, we\nhave developed TAHOE - a graph based CTL. TAHOE is a structure for\nstoring,sharing and analyzing threat data. It also intrinsically correlates the\ndata. We have further developed a universal Threat Data Query Language (TDQL).\nIn this paper, we propose the system architecture for CYBEX-P. We then discuss\nits scalability and privacy features along with a use case of CYBEX-P providing\nInfrastructure as a Service (IaaS). We further introduce TAHOE& TDQL as better\nalternatives to existing CTLs and formulate ThreatRank - an algorithm to detect\nnew malicious even",
    "descriptor": "",
    "authors": [
      "Farhan Sadique",
      "Ignacio Astaburuaga",
      "Raghav Kaul",
      "Shamik Sengupta",
      "Shahriar Badsha",
      "James Schnebly",
      "Adam Cassell",
      "Jeff Springer",
      "Nancy Latourrette",
      "Sergiu M. Dascalu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01632"
  },
  {
    "id": "arXiv:2106.01635",
    "title": "Can vectors read minds better than experts? Comparing data augmentation  strategies for the automated scoring of children's mindreading ability",
    "abstract": "In this paper we implement and compare 7 different data augmentation\nstrategies for the task of automatic scoring of children's ability to\nunderstand others' thoughts, feelings, and desires (or \"mindreading\").\nWe recruit in-domain experts to re-annotate augmented samples and determine\nto what extent each strategy preserves the original rating. We also carry out\nmultiple experiments to measure how much each augmentation strategy improves\nthe performance of automatic scoring systems. To determine the capabilities of\nautomatic systems to generalize to unseen data, we create UK-MIND-20 - a new\ncorpus of children's performance on tests of mindreading, consisting of 10,320\nquestion-answer pairs.\nWe obtain a new state-of-the-art performance on the MIND-CA corpus, improving\nmacro-F1-score by 6 points. Results indicate that both the number of training\nexamples and the quality of the augmentation strategies affect the performance\nof the systems. The task-specific augmentations generally outperform\ntask-agnostic augmentations. Automatic augmentations based on vectors (GloVe,\nFastText) perform the worst.\nWe find that systems trained on MIND-CA generalize well to UK-MIND-20. We\ndemonstrate that data augmentation strategies also improve the performance on\nunseen data.",
    "descriptor": "\nComments: The paper will be presented at ACL-IJCNLP 2021\n",
    "authors": [
      "Venelin Kovatchev",
      "Phillip Smith",
      "Mark Lee",
      "Rory Devine"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01635"
  },
  {
    "id": "arXiv:2106.01639",
    "title": "Deceptive Level Generation for Angry Birds",
    "abstract": "The Angry Birds AI competition has been held over many years to encourage the\ndevelopment of AI agents that can play Angry Birds game levels better than\nhuman players. Many different agents with various approaches have been employed\nover the competition's lifetime to solve this task. Even though the performance\nof these agents has increased significantly over the past few years, they still\nshow major drawbacks in playing deceptive levels. This is because most of the\ncurrent agents try to identify the best next shot rather than planning an\neffective sequence of shots. In order to encourage advancements in such agents,\nwe present an automated methodology to generate deceptive game levels for Angry\nBirds. Even though there are many existing content generators for Angry Birds,\nthey do not focus on generating deceptive levels. In this paper, we propose a\nprocedure to generate deceptive levels for six deception categories that can\nfool the state-of-the-art Angry Birds playing AI agents. Our results show that\ngenerated deceptive levels exhibit similar characteristics of human-created\ndeceptive levels. Additionally, we define metrics to measure the stability,\nsolvability, and degree of deception of the generated levels.",
    "descriptor": "",
    "authors": [
      "Chathura Gamage",
      "Matthew Stephenson",
      "Vimukthini Pinto",
      "Jochen Renz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01639"
  },
  {
    "id": "arXiv:2106.01642",
    "title": "Projection-free Graph-based Classifier Learning using Gershgorin Disc  Perfect Alignment",
    "abstract": "In semi-supervised graph-based binary classifier learning, a subset of known\nlabels $\\hat{x}_i$ are used to infer unknown labels, assuming that the label\nsignal $x$ is smooth with respect to a similarity graph specified by a\nLaplacian matrix. When restricting labels $x_i$ to binary values, the problem\nis NP-hard. While a conventional semi-definite programming (SDP) relaxation can\nbe solved in polynomial time using, for example, the alternating direction\nmethod of multipliers (ADMM), the complexity of iteratively projecting a\ncandidate matrix $M$ onto the positive semi-definite (PSD) cone ($M \\succeq 0$)\nremains high. In this paper, leveraging a recent linear algebraic theory called\nGershgorin disc perfect alignment (GDPA), we propose a fast projection-free\nmethod by solving a sequence of linear programs (LP) instead. Specifically, we\nfirst recast the SDP relaxation to its SDP dual, where a feasible solution $H\n\\succeq 0$ can be interpreted as a Laplacian matrix corresponding to a balanced\nsigned graph sans the last node. To achieve graph balance, we split the last\nnode into two that respectively contain the original positive and negative\nedges, resulting in a new Laplacian $\\bar{H}$. We repose the SDP dual for\nsolution $\\bar{H}$, then replace the PSD cone constraint $\\bar{H} \\succeq 0$\nwith linear constraints derived from GDPA -- sufficient conditions to ensure\n$\\bar{H}$ is PSD -- so that the optimization becomes an LP per iteration.\nFinally, we extract predicted labels from our converged LP solution $\\bar{H}$.\nExperiments show that our algorithm enjoyed a $40\\times$ speedup on average\nover the next fastest scheme while retaining comparable label prediction\nperformance.",
    "descriptor": "",
    "authors": [
      "Cheng Yang",
      "Gene Cheung",
      "Wai-tian Tan",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01642"
  },
  {
    "id": "arXiv:2106.01644",
    "title": "Corporate core values and social responsibility: What really matters to  whom",
    "abstract": "This study uses an innovative measure, the Semantic Brand Score, to assess\nthe interest of stakeholders in different company core values. Among others, we\nfocus on corporate social responsibility (CSR) core value statements, and on\nthe attention they receive from five categories of stakeholders (customers,\ncompany communication teams, employees, associations and media). Combining big\ndata methods and tools of Social Network Analysis and Text Mining, we analyzed\nabout 58,000 Italian tweets and found that different stakeholders have\ndifferent prevailing interests. CSR gets much less attention than expected.\nCore values related to customers and employees are in the foreground.",
    "descriptor": "",
    "authors": [
      "M. A. Barchiesi",
      "A. Fronzetti Colladon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.01644"
  },
  {
    "id": "arXiv:2106.01645",
    "title": "R\u00e9nyi Divergence in General Hidden Markov Models",
    "abstract": "In this paper, we examine the existence of the R\\'enyi divergence between two\ntime invariant general hidden Markov models with arbitrary positive initial\ndistributions. By making use of a Markov chain representation of the\nprobability distribution for the general hidden Markov model and eigenvalue for\nthe associated Markovian operator, we obtain, under some regularity conditions,\nconvergence of the R\\'enyi divergence. By using this device, we also\ncharacterize the R\\'enyi divergence, and obtain the Kullback-Leibler divergence\nas {\\alpha} \\rightarrow 1 of the R\\'enyi divergence. Several examples,\nincluding the classical finite state hidden Markov models, Markov switching\nmodels, and recurrent neural networks, are given for illustration. Moreover, we\ndevelop a non-Monte Carlo method that computes the R\\'enyi divergence of\ntwo-state Markov switching models via the underlying invariant probability\nmeasure, which is characterized by the Fredholm integral equation.",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Cheng-Der Fuh",
      "Su-Chi Fuh",
      "Yuan-Chen Liu",
      "Chuan-Ju Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.01645"
  },
  {
    "id": "arXiv:2106.01646",
    "title": "Towards coercive boundary element methods for the wave equation",
    "abstract": "In this note, we discuss the ellipticity of the single layer boundary\nintegral operator for the wave equation in one space dimension. This result not\nonly generalizes the well-known ellipticity of the energetic boundary integral\nformulation in $L^2$, but it also turns out to be a particular case of a recent\nresult on the inf-sup stability of boundary integral operators for the wave\nequation. Instead of the time derivative in the energetic formulation, we use a\nmodified Hilbert transformation, which allows us to stay in Sobolev spaces of\nthe same order. This results in the applicability of standard boundary element\nerror estimates, which are confirmed by numerical results.",
    "descriptor": "",
    "authors": [
      "Olaf Steinbach",
      "Carolina Urz\u00faa-Torres",
      "Marco Zank"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01646"
  },
  {
    "id": "arXiv:2106.01649",
    "title": "LearnDA: Learnable Knowledge-Guided Data Augmentation for Event  Causality Identification",
    "abstract": "Modern models for event causality identification (ECI) are mainly based on\nsupervised learning, which are prone to the data lacking problem.\nUnfortunately, the existing NLP-related augmentation methods cannot directly\nproduce the available data required for this task. To solve the data lacking\nproblem, we introduce a new approach to augment training data for event\ncausality identification, by iteratively generating new examples and\nclassifying event causality in a dual learning framework. On the one hand, our\napproach is knowledge-guided, which can leverage existing knowledge bases to\ngenerate well-formed new sentences. On the other hand, our approach employs a\ndual mechanism, which is a learnable augmentation framework and can\ninteractively adjust the generation process to generate task-related sentences.\nExperimental results on two benchmarks EventStoryLine and Causal-TimeBank show\nthat 1) our method can augment suitable task-related training data for ECI; 2)\nour method outperforms previous methods on EventStoryLine and Causal-TimeBank\n(+2.5 and +2.1 points on F1 value respectively).",
    "descriptor": "\nComments: Accepted to ACL 2021\n",
    "authors": [
      "Xinyu Zuo",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao",
      "Weihua Peng",
      "Yuguang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01649"
  },
  {
    "id": "arXiv:2106.01650",
    "title": "Learning and Executing Re-usable Behaviour Trees from Natural Language  Instruction",
    "abstract": "Domestic and service robots have the potential to transform industries such\nas health care and small-scale manufacturing, as well as the homes in which we\nlive. However, due to the overwhelming variety of tasks these robots will be\nexpected to complete, providing generic out-of-the-box solutions that meet the\nneeds of every possible user is clearly intractable. To address this problem,\nrobots must therefore not only be capable of learning how to complete novel\ntasks at run-time, but the solutions to these tasks must also be informed by\nthe needs of the user. In this paper we demonstrate how behaviour trees, a well\nestablished control architecture in the fields of gaming and robotics, can be\nused in conjunction with natural language instruction to provide a robust and\nmodular control architecture for instructing autonomous agents to learn and\nperform novel complex tasks. We also show how behaviour trees generated using\nour approach can be generalised to novel scenarios, and can be re-used in\nfuture learning episodes to create increasingly complex behaviours. We validate\nthis work against an existing corpus of natural language instructions,\ndemonstrate the application of our approach on both a simulated robot solving a\ntoy problem, as well as two distinct real-world robot platforms which,\nrespectively, complete a block sorting scenario, and a patrol scenario.",
    "descriptor": "",
    "authors": [
      "Gavin Suddrey",
      "Ben Talbot",
      "Frederic Maire"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.01650"
  },
  {
    "id": "arXiv:2106.01651",
    "title": "Timing Configurations Affect the Macro-Properties of Multi-Scale  Feedback Systems",
    "abstract": "Multi-scale feedback systems, where information cycles through micro- and\nmacro-scales leading to adaptation, are ubiquitous across domains, from animal\nsocieties and human organisations to electric grids and neural networks.\nStudies on the effects of timing on system properties are often domain\nspecific. The Multi-Scale Abstraction Feedbacks (MSAF) design pattern aims to\ngeneralise the description and understanding of multi-scale systems where\nfeedback occurs across scales. We expand on MSAF to include timing\nconsiderations. We then apply these considerations to two models: a\nhierarchical oscillator (HO) and a hierarchical cellular automata (HCA).\nResults show how (i) different timing configurations significantly affect\nsystem macro-properties and (ii) different regions of time configurations can\nlead to the same macro-properties. These results contribute to theory, while\nalso providing useful insights for designing and controlling such systems.",
    "descriptor": "\nComments: 10 pages, 11 Figures, submitted to ACSOS 2021\n",
    "authors": [
      "Patricia Mellodge",
      "Ada Diaconescu",
      "Louisa Jane Di Felice"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2106.01651"
  },
  {
    "id": "arXiv:2106.01654",
    "title": "Improving Event Causality Identification via Self-Supervised  Representation Learning on External Causal Statement",
    "abstract": "Current models for event causality identification (ECI) mainly adopt a\nsupervised framework, which heavily rely on labeled data for training.\nUnfortunately, the scale of current annotated datasets is relatively limited,\nwhich cannot provide sufficient support for models to capture useful indicators\nfrom causal statements, especially for handing those new, unseen cases. To\nalleviate this problem, we propose a novel approach, shortly named CauSeRL,\nwhich leverages external causal statements for event causality identification.\nFirst of all, we design a self-supervised framework to learn context-specific\ncausal patterns from external causal statements. Then, we adopt a contrastive\ntransfer strategy to incorporate the learned context-specific causal patterns\ninto the target ECI model. Experimental results show that our method\nsignificantly outperforms previous methods on EventStoryLine and\nCausal-TimeBank (+2.0 and +3.4 points on F1 value respectively).",
    "descriptor": "\nComments: Accepted to Findings of ACL 2021\n",
    "authors": [
      "Xinyu Zuo",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao",
      "Weihua Peng",
      "Yuguang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01654"
  },
  {
    "id": "arXiv:2106.01655",
    "title": "Hierarchical Representation Learning for Markov Decision Processes",
    "abstract": "In this paper we present a novel method for learning hierarchical\nrepresentations of Markov decision processes. Our method works by partitioning\nthe state space into subsets, and defines subtasks for performing transitions\nbetween the partitions. We formulate the problem of partitioning the state\nspace as an optimization problem that can be solved using gradient descent\ngiven a set of sampled trajectories, making our method suitable for\nhigh-dimensional problems with large state spaces. We empirically validate the\nmethod, by showing that it can successfully learn a useful hierarchical\nrepresentation in a navigation domain. Once learned, the hierarchical\nrepresentation can be used to solve different tasks in the given domain, thus\ngeneralizing knowledge across tasks.",
    "descriptor": "",
    "authors": [
      "Lorenzo Steccanella",
      "Simone Totaro",
      "Anders Jonsson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01655"
  },
  {
    "id": "arXiv:2106.01656",
    "title": "Generalized Domain Adaptation",
    "abstract": "Many variants of unsupervised domain adaptation (UDA) problems have been\nproposed and solved individually. Its side effect is that a method that works\nfor one variant is often ineffective for or not even applicable to another,\nwhich has prevented practical applications. In this paper, we give a general\nrepresentation of UDA problems, named Generalized Domain Adaptation (GDA). GDA\ncovers the major variants as special cases, which allows us to organize them in\na comprehensive framework. Moreover, this generalization leads to a new\nchallenging setting where existing methods fail, such as when domain labels are\nunknown, and class labels are only partially given to each domain. We propose a\nnovel approach to the new setting. The key to our approach is self-supervised\nclass-destructive learning, which enables the learning of class-invariant\nrepresentations and domain-adversarial classifiers without using any domain\nlabels. Extensive experiments using three benchmark datasets demonstrate that\nour method outperforms the state-of-the-art UDA methods in the new setting and\nthat it is competitive in existing UDA variations as well.",
    "descriptor": "\nComments: Accepted by CVPR 2021. Code is available at this https URL\n",
    "authors": [
      "Yu Mitsuzumi",
      "Go Irie",
      "Daiki Ikami",
      "Takashi Shibata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01656"
  },
  {
    "id": "arXiv:2106.01666",
    "title": "Discovering Chatbot's Self-Disclosure's Impact on User Trust, Affinity,  and Recommendation Effectiveness",
    "abstract": "In recent years, chatbots have been empowered to engage in social\nconversations with humans and have the potential to elicit people to disclose\ntheir personal experiences, opinions, and emotions. However, how and to what\nextent people respond to chabots' self-disclosure remain less known. In this\nwork, we designed a social chatbot with three self-disclosure levels that\nconducted small talks and provided relevant recommendations to people. 372\nMTurk participants were randomized to one of the four groups with different\nself-disclosure levels to converse with the chatbot on two topics, movies, and\nCOVID-19. We found that people's self-disclosure level was strongly reciprocal\nto a chatbot's self-disclosure level. Chatbots' self-disclosure also positively\nimpacted engagement and users' perception of the bot and led to a more\neffective recommendation such that participants enjoyed and agreed more with\nthe recommendations.",
    "descriptor": "",
    "authors": [
      "Kai-Hui Liang",
      "Weiyan Shi",
      "Yoojung Oh",
      "Jingwen Zhang",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01666"
  },
  {
    "id": "arXiv:2106.01667",
    "title": "APES: Audiovisual Person Search in Untrimmed Video",
    "abstract": "Humans are arguably one of the most important subjects in video streams, many\nreal-world applications such as video summarization or video editing workflows\noften require the automatic search and retrieval of a person of interest.\nDespite tremendous efforts in the person reidentification and retrieval\ndomains, few works have developed audiovisual search strategies. In this paper,\nwe present the Audiovisual Person Search dataset (APES), a new dataset composed\nof untrimmed videos whose audio (voices) and visual (faces) streams are densely\nannotated. APES contains over 1.9K identities labeled along 36 hours of video,\nmaking it the largest dataset available for untrimmed audiovisual person\nsearch. A key property of APES is that it includes dense temporal annotations\nthat link faces to speech segments of the same identity. To showcase the\npotential of our new dataset, we propose an audiovisual baseline and benchmark\nfor person retrieval. Our study shows that modeling audiovisual cues benefits\nthe recognition of people's identities. To enable reproducibility and promote\nfuture research, the dataset annotations and baseline code are available at:\nhttps://github.com/fuankarion/audiovisual-person-search",
    "descriptor": "",
    "authors": [
      "Juan Leon Alcazar",
      "Long Mai",
      "Federico Perazzi",
      "Joon-Young Lee",
      "Pablo Arbelaez",
      "Bernard Ghanem",
      "Fabian Caba Heilbron"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01667"
  },
  {
    "id": "arXiv:2106.01671",
    "title": "Analyzing crosstalk error in the NISQ era",
    "abstract": "Noisy Intermediate-Scale Quantum (NISQ) hardware has unavoidable noises, and\ncrosstalk error is a significant error source. When multiple quantum operations\nare executed simultaneously, the quantum state can be corrupted due to the\ncrosstalk between gates during simultaneous operations, decreasing the circuit\nfidelity. In this work, we first report on several protocols for characterizing\ncrosstalk. Then, we discuss different crosstalk mitigation methods from the\nhardware and software perspectives. Finally, we perform crosstalk injection\nexperiments on the IBM quantum device and demonstrate the fidelity improvement\nwith the crosstalk mitigation method.",
    "descriptor": "",
    "authors": [
      "Siyuan Niu",
      "Aida Todri-Sanial"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.01671"
  },
  {
    "id": "arXiv:2106.01674",
    "title": "JIZHI: A Fast and Cost-Effective Model-As-A-Service System for Web-Scale  Online Inference at Baidu",
    "abstract": "In modern internet industries, deep learning based recommender systems have\nbecame an indispensable building block for a wide spectrum of applications,\nsuch as search engine, news feed, and short video clips. However, it remains\nchallenging to carry the well-trained deep models for online real-time\ninference serving, with respect to the time-varying web-scale traffics from\nbillions of users, in a cost-effective manner. In this work, we present JIZHI -\na Model-as-a-Service system - that per second handles hundreds of millions of\nonline inference requests to huge deep models with more than trillions of\nsparse parameters, for over twenty real-time recommendation services at Baidu,\nInc. In JIZHI, the inference workflow of every recommendation request is\ntransformed to a Staged Event-Driven Pipeline (SEDP), where each node in the\npipeline refers to a staged computation or I/O intensive task processor. With\ntraffics of real-time inference requests arrived, each modularized processor\ncan be run in a fully asynchronized way and managed separately. Besides, JIZHI\nintroduces heterogeneous and hierarchical storage to further accelerate the\nonline inference process by reducing unnecessary computations and potential\ndata access latency induced by ultra-sparse model parameters. Moreover, an\nintelligent resource manager has been deployed to maximize the throughput of\nJIZHI over the shared infrastructure by searching the optimal resource\nallocation plan from historical logs and fine-tuning the load shedding policies\nover intermediate system feedback. Extensive experiments have been done to\ndemonstrate the advantages of JIZHI from the perspectives of end-to-end service\nlatency, system-wide throughput, and resource consumption. JIZHI has helped\nBaidu saved more than ten million US dollars in hardware and utility costs\nwhile handling 200% more traffics without sacrificing inference efficiency.",
    "descriptor": "\nComments: Accepted to SIGKDD 2021 applied data science track\n",
    "authors": [
      "Hao Liu",
      "Qian Gao",
      "Jiang Li",
      "Xiaochao Liao",
      "Hao Xiong",
      "Guangxing Chen",
      "Wenlin Wang",
      "Guobao Yang",
      "Zhiwei Zha",
      "Daxiang Dong",
      "Dejing Dou",
      "Haoyi Xiong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01674"
  },
  {
    "id": "arXiv:2106.01678",
    "title": "Learning Representation over Dynamic Graph using Aggregation-Diffusion  Mechanism",
    "abstract": "Representation learning on graphs that evolve has recently received\nsignificant attention due to its wide application scenarios, such as\nbioinformatics, knowledge graphs, and social networks. The propagation of\ninformation in graphs is important in learning dynamic graph representations,\nand most of the existing methods achieve this by aggregation. However, relying\nonly on aggregation to propagate information in dynamic graphs can result in\ndelays in information propagation and thus affect the performance of the\nmethod. To alleviate this problem, we propose an aggregation-diffusion (AD)\nmechanism that actively propagates information to its neighbor by diffusion\nafter the node updates its embedding through the aggregation mechanism. In\nexperiments on two real-world datasets in the dynamic link prediction task, the\nAD mechanism outperforms the baseline models that only use aggregation to\npropagate information. We further conduct extensive experiments to discuss the\ninfluence of different factors in the AD mechanism.",
    "descriptor": "",
    "authors": [
      "Mingyi Liu",
      "Zhiying Tu",
      "Xiaofei Xu",
      "Zhongjie Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.01678"
  },
  {
    "id": "arXiv:2106.01680",
    "title": "Convergent Graph Solvers",
    "abstract": "We propose the convergent graph solver (CGS), a deep learning method that\nlearns iterative mappings to predict the properties of a graph system at its\nstationary state (fixed point) with guaranteed convergence. CGS systematically\ncomputes the fixed points of a target graph system and decodes them to estimate\nthe stationary properties of the system without the prior knowledge of existing\nsolvers or intermediate solutions. The forward propagation of CGS proceeds in\nthree steps: (1) constructing the input dependent linear contracting iterative\nmaps, (2) computing the fixed-points of the linear maps, and (3) decoding the\nfixed-points to estimate the properties. The contractivity of the constructed\nlinear maps guarantees the existence and uniqueness of the fixed points\nfollowing the Banach fixed point theorem. To train CGS efficiently, we also\nderive a tractable analytical expression for its gradient by leveraging the\nimplicit function theorem. We evaluate the performance of CGS by applying it to\nvarious network-analytic and graph benchmark problems. The results indicate\nthat CGS has competitive capabilities for predicting the stationary properties\nof graph systems, irrespective of whether the target systems are linear or\nnon-linear. CGS also shows high performance for graph classification problems\nwhere the existence or the meaning of a fixed point is hard to be clearly\ndefined, which highlights the potential of CGS as a general graph neural\nnetwork architecture.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Junyoung Park",
      "Jinhyun Choo",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01680"
  },
  {
    "id": "arXiv:2106.01682",
    "title": "Probabilistic Gradient Boosting Machines for Large-Scale Probabilistic  Regression",
    "abstract": "Gradient Boosting Machines (GBM) are hugely popular for solving tabular data\nproblems. However, practitioners are not only interested in point predictions,\nbut also in probabilistic predictions in order to quantify the uncertainty of\nthe predictions. Creating such probabilistic predictions is difficult with\nexisting GBM-based solutions: they either require training multiple models or\nthey become too computationally expensive to be useful for large-scale\nsettings. We propose Probabilistic Gradient Boosting Machines (PGBM), a method\nto create probabilistic predictions with a single ensemble of decision trees in\na computationally efficient manner. PGBM approximates the leaf weights in a\ndecision tree as a random variable, and approximates the mean and variance of\neach sample in a dataset via stochastic tree ensemble update equations. These\nlearned moments allow us to subsequently sample from a specified distribution\nafter training. We empirically demonstrate the advantages of PGBM compared to\nexisting state-of-the-art methods: (i) PGBM enables probabilistic estimates\nwithout compromising on point performance in a single model, (ii) PGBM learns\nprobabilistic estimates via a single model only (and without requiring\nmulti-parameter boosting), and thereby offers a speedup of up to several orders\nof magnitude over existing state-of-the-art methods on large datasets, and\n(iii) PGBM achieves accurate probabilistic estimates in tasks with complex\ndifferentiable loss functions, such as hierarchical time series problems, where\nwe observed up to 10\\% improvement in point forecasting performance and up to\n300\\% improvement in probabilistic forecasting performance.",
    "descriptor": "",
    "authors": [
      "Olivier Sprangers",
      "Sebastian Schelter",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01682"
  },
  {
    "id": "arXiv:2106.01684",
    "title": "Language Independent Speech Emotion and Non-invasive Early Detection of  Neurocognitive Disorder",
    "abstract": "Emotions(like fear,anger,sadness,happiness etc.) are the fundamental features\nof human behavior and governs his/her mental health. The subtlety of emotional\nfluctuations can be examined through perturbation in conversations or speech.\nAnalysis of emotional state of a person from acoustical features of speech\nsignal leads to discovery of vital cues determining his or her mental health.\nHence, it's an important field of research in the area of Human Computer\nInteraction(HCI). In a recent work we have shown that how the contrast in\nHurst-Exponent calculated from the non-stationary and nonlinear aspects of\n\"angry\" and \"sad\" speech(spoken in English language) recordings in the\nToronto-Emotional-Speech-Set(TESS) can be used for early detection and\ndiagnosis of Alzheimer's Disease. In this work we have extended the work and\nextracted Hurst-exponent for the speech-signals of similar emotions but spoken\nin German language. It has been observed that the Hurst-exponent efficiently\nsegregates the contrasting emotions of \"anger\" and \"sadness\" in the speech\nspoken in German language, in similar fashion it has been doing for English\nspeech. Hence it can be concluded that the Hurst-exponent can differentiate\namong speech spoken out of different emotions in language-independent manner.\nWe propose algorithm for a language-independent application for early\nnon-invasive detection of various severe neurocognitive-disorders like\nAlzheimer's Disease, MND(motor-neuron-disorder), ASD(autism-spectrum-disorder),\ndepression, suicidal-tendency etc. which is not possible with the state of the\nart medical science.",
    "descriptor": "",
    "authors": [
      "Susmita Bhaduri",
      "Anirban Bhaduri",
      "Rajib Sarkar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.01684"
  },
  {
    "id": "arXiv:2106.01686",
    "title": "AliCG: Fine-grained and Evolvable Conceptual Graph Construction for  Semantic Search at Alibaba",
    "abstract": "Conceptual graphs, which is a particular type of Knowledge Graphs, play an\nessential role in semantic search. Prior conceptual graph construction\napproaches typically extract high-frequent, coarse-grained, and time-invariant\nconcepts from formal texts. In real applications, however, it is necessary to\nextract less-frequent, fine-grained, and time-varying conceptual knowledge and\nbuild taxonomy in an evolving manner. In this paper, we introduce an approach\nto implementing and deploying the conceptual graph at Alibaba. Specifically, We\npropose a framework called AliCG which is capable of a) extracting fine-grained\nconcepts by a novel bootstrapping with alignment consensus approach, b) mining\nlong-tail concepts with a novel low-resource phrase mining approach, c)\nupdating the graph dynamically via a concept distribution estimation method\nbased on implicit and explicit user behaviors. We have deployed the framework\nat Alibaba UC Browser. Extensive offline evaluation as well as online A/B\ntesting demonstrate the efficacy of our approach.",
    "descriptor": "\nComments: Accepted by KDD 2021 (Applied Data Science Track)\n",
    "authors": [
      "Ningyu Zhang",
      "Qianghuai Jia",
      "Shumin Deng",
      "Xiang Chen",
      "Hongbin Ye",
      "Hui Chen",
      "Huaixiao Tou",
      "Gang Huang",
      "Zhao Wang",
      "Nengwei Hua",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01686"
  },
  {
    "id": "arXiv:2106.01689",
    "title": "Cross-Domain First Person Audio-Visual Action Recognition through  Relative Norm Alignment",
    "abstract": "First person action recognition is an increasingly researched topic because\nof the growing popularity of wearable cameras. This is bringing to light\ncross-domain issues that are yet to be addressed in this context. Indeed, the\ninformation extracted from learned representations suffers from an intrinsic\nenvironmental bias. This strongly affects the ability to generalize to unseen\nscenarios, limiting the application of current methods in real settings where\ntrimmed labeled data are not available during training. In this work, we\npropose to leverage over the intrinsic complementary nature of audio-visual\nsignals to learn a representation that works well on data seen during training,\nwhile being able to generalize across different domains. To this end, we\nintroduce an audio-visual loss that aligns the contributions from the two\nmodalities by acting on the magnitude of their feature norm representations.\nThis new loss, plugged into a minimal multi-modal action recognition\narchitecture, leads to strong results in cross-domain first person action\nrecognition, as demonstrated by extensive experiments on the popular\nEPIC-Kitchens dataset.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Mirco Planamente",
      "Chiara Plizzari",
      "Emanuele Alberti",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01689"
  },
  {
    "id": "arXiv:2106.01693",
    "title": "Bridging the Multiscale Hybrid-Mixed and Multiscale Hybrid High-Order  methods",
    "abstract": "We establish the equivalence between the Multiscale Hybrid-Mixed (MHM) and\nthe Multiscale Hybrid High-Order (MsHHO) methods for a variable diffusion\nproblem with piecewise polynomial source terms. Under the idealized assumption\nthat the local problems defining the multiscale basis functions are exactly\nsolved, we prove that the equivalence holds for general polytopal (coarse)\nmeshes and arbitrary approximation orders. Also, we leverage the interchange of\nproperties to perform a unified convergence analysis, as well as to improve on\nboth methods.",
    "descriptor": "",
    "authors": [
      "T. Chaumont-Frelet",
      "A. Ern",
      "S. Lemaire",
      "F. Valentin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01693"
  },
  {
    "id": "arXiv:2106.01695",
    "title": "From indexation policies through citation networks to normalized  citation impacts: Web of Science, Scopus, and Dimensions as varying resonance  chambers",
    "abstract": "Dimensions was introduced as an alternative bibliometric database to the\nwell-established Web of Science (WoS) and Scopus, however all three databases\nhave fundamental differences in coverage and content, resultant from their\nowners' indexation philosophies. In light of these differences, we explore\nhere, using a citation network analysis and assessment of normalised citation\nimpact of \"duplicate\" publications, whether the three databases offer\nstructurally different perspectives of the bibliometric landscape or if they\nare essentially homogenous substitutes. Our citation network analysis of core\nand exclusive 2016-2018 publications revealed a large set of core publications\nindexed in all three databases that are highly self-referential. In comparison,\neach database selected a set of exclusive publications that appeared to hold\nsimilarly low levels of relevance to the core set and to one another, with\nslightly more internal communication between exclusive publications in Scopus\nand Dimensions than WoS. Our comparison of normalised citations for 41,848\npublications indexed in all three databases found that German sectors were\nvaluated as more impactful in Scopus and Dimensions compared to WoS,\nparticularly for sectors with an applied research focus. We conclude that the\ndatabases do present structurally different perspectives, although Scopus and\nDimensions with their additional circle of applied research vary more from the\nmore base research-focused WoS than they do from one another.",
    "descriptor": "",
    "authors": [
      "Stephan Stahlschmidt",
      "Dimity Stephen"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.01695"
  },
  {
    "id": "arXiv:2106.01702",
    "title": "PsyQA: A Chinese Dataset for Generating Long Counseling Text for Mental  Health Support",
    "abstract": "Great research interests have been attracted to devise AI services that are\nable to provide mental health support. However, the lack of corpora is a main\nobstacle to this research, particularly in Chinese language. In this paper, we\npropose PsyQA, a Chinese dataset of psychological health support in the form of\nquestion and answer pair. PsyQA is crawled from a Chinese mental health service\nplatform, and contains 22K questions and 56K long and well-structured answers.\nBased on the psychological counseling theories, we annotate a portion of answer\ntexts with typical strategies for providing support, and further present\nin-depth analysis of both lexical features and strategy patterns in the\ncounseling answers. We also evaluate the performance of generating counseling\nanswers with the generative pretrained models. Results show that utilizing\nstrategies enhances the fluency and helpfulness of generated answers, but there\nis still a large space for future research.",
    "descriptor": "\nComments: Accepted to Findings of ACL 2021 (Long Paper)\n",
    "authors": [
      "Hao Sun",
      "Zhenru Lin",
      "Chujie Zheng",
      "Siyang Liu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01702"
  },
  {
    "id": "arXiv:2106.01703",
    "title": "Fingerprinting Fine-tuned Language Models in the Wild",
    "abstract": "There are concerns that the ability of language models (LMs) to generate high\nquality synthetic text can be misused to launch spam, disinformation, or\npropaganda. Therefore, the research community is actively working on developing\napproaches to detect whether a given text is organic or synthetic. While this\nis a useful first step, it is important to be able to further fingerprint the\nauthor LM to attribute its origin. Prior work on fingerprinting LMs is limited\nto attributing synthetic text generated by a handful (usually < 10) of\npre-trained LMs. However, LMs such as GPT2 are commonly fine-tuned in a myriad\nof ways (e.g., on a domain-specific text corpus) before being used to generate\nsynthetic text. It is challenging to fingerprinting fine-tuned LMs because the\nuniverse of fine-tuned LMs is much larger in realistic scenarios. To address\nthis challenge, we study the problem of large-scale fingerprinting of\nfine-tuned LMs in the wild. Using a real-world dataset of synthetic text\ngenerated by 108 different fine-tuned LMs, we conduct comprehensive experiments\nto demonstrate the limitations of existing fingerprinting approaches. Our\nresults show that fine-tuning itself is the most effective in attributing the\nsynthetic text generated by fine-tuned LMs.",
    "descriptor": "",
    "authors": [
      "Nirav Diwan",
      "Tanmoy Chakravorty",
      "Zubair Shafiq"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01703"
  },
  {
    "id": "arXiv:2106.01706",
    "title": "EmoDNN: Understanding emotions from short texts through a deep neural  network ensemble",
    "abstract": "The latent knowledge in the emotions and the opinions of the individuals that\nare manifested via social networks are crucial to numerous applications\nincluding social management, dynamical processes, and public security.\nAffective computing, as an interdisciplinary research field, linking artificial\nintelligence to cognitive inference, is capable to exploit emotion-oriented\nknowledge from brief contents. The textual contents convey hidden information\nsuch as personality and cognition about corresponding authors that can\ndetermine both correlations and variations between users. Emotion recognition\nfrom brief contents should embrace the contrast between authors where the\ndifferences in personality and cognition can be traced within emotional\nexpressions. To tackle this challenge, we devise a framework that, on the one\nhand, infers latent individual aspects, from brief contents and, on the other\nhand, presents a novel ensemble classifier equipped with dynamic dropout\nconvnets to extract emotions from textual context. To categorize short text\ncontents, our proposed method conjointly leverages cognitive factors and\nexploits hidden information. We utilize the outcome vectors in a novel\nembedding model to foster emotion-pertinent features that are collectively\nassembled by lexicon inductions. Experimental results show that compared to\nother competitors, our proposed model can achieve a higher performance in\nrecognizing emotion from noisy contents.",
    "descriptor": "",
    "authors": [
      "Sara Kamran",
      "Raziyeh Zall",
      "Mohammad Reza Kangavari",
      "Saeid Hosseini",
      "Sana Rahmani",
      "Wen Hua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.01706"
  },
  {
    "id": "arXiv:2106.01708",
    "title": "Semi-supervised Conditional Density Estimation for Imputation and  Classification of Incomplete Instances",
    "abstract": "Incomplete instances with various missing attributes in many real-world\nscenes have brought challenges to the classification task. There are some\nmissing values imputation methods to fill the missing values with substitute\nvalues before classification. However, the separation between imputation and\nclassification may lead to inferior performance since label information are\nignored during imputation. Moreover, these imputation methods tend to\ninitialize these missing values with strong prior assumptions, while the\nunreliability of such initialization is rarely considered. To tackle these\nproblems, a novel semi-supervised conditional normalizing flow (SSCFlow) is\nproposed in this paper. SSCFlow explicitly utilizes the observed labels to\nfacilitate the imputation and classification simultaneously by employing a\nsemi-supervised algorithm to estimate the conditional probability density of\nmissing values. Moreover, SSCFlow takes the initialized missing values as\ncorrupted initial imputation and iteratively reconstructs their latent\nrepresentations with an overcomplete denoising autoencoder to approximate the\ntrue conditional probability density of missing values. Experiments have been\nconducted with real-world datasets to demonstrate the robustness and efficiency\nof the proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Buliao Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01708"
  },
  {
    "id": "arXiv:2106.01709",
    "title": "SIRE: Separate Intra- and Inter-sentential Reasoning for Document-level  Relation Extraction",
    "abstract": "Document-level relation extraction has attracted much attention in recent\nyears. It is usually formulated as a classification problem that predicts\nrelations for all entity pairs in the document. However, previous works\nindiscriminately represent intra- and inter-sentential relations in the same\nway, confounding the different patterns for predicting them. Besides, they\ncreate a document graph and use paths between entities on the graph as clues\nfor logical reasoning. However, not all entity pairs can be connected with a\npath and have the correct logical reasoning paths in their graph. Thus many\ncases of logical reasoning cannot be covered. This paper proposes an effective\narchitecture, SIRE, to represent intra- and inter-sentential relations in\ndifferent ways. We design a new and straightforward form of logical reasoning\nmodule that can cover more logical reasoning chains. Experiments on the public\ndatasets show SIRE outperforms the previous state-of-the-art methods. Further\nanalysis shows that our predictions are reliable and explainable. Our code is\navailable at https://github.com/DreamInvoker/SIRE.",
    "descriptor": "\nComments: 11 pages, 3 figures, 3 tables, Long paper accepted by Findings of ACL-IJCNLP 2021\n",
    "authors": [
      "Shuang Zeng",
      "Yuting Wu",
      "Baobao Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01709"
  },
  {
    "id": "arXiv:2106.01710",
    "title": "Optimistic Concurrency Control for Real-world Go Programs (Extended  Version with Appendix)",
    "abstract": "We present a source-to-source transformation framework, GOCC, that consumes\nlock-based pessimistic concurrency programs in the Go language and transforms\nthem into optimistic concurrency programs that use Hardware Transactional\nMemory (HTM). The choice of the Go language is motivated by the fact that\nconcurrency is a first-class citizen in Go, and it is widely used in Go\nprograms. GOCC performs rich inter-procedural program analysis to detect and\nfilter lock-protected regions and performs AST-level code transformation of the\nsurrounding locks when profitable. Profitability is driven by both static\nanalyses of critical sections and dynamic analysis via execution profiles. A\ncustom HTM library, using perceptron, learns concurrency behavior and\ndynamically decides whether to use HTM in the rewritten lock/unlock points.\nGiven the rich history of transactional memory research but its lack of\nadoption in any industrial setting, we believe this workflow, which ultimately\nproduces source-code patches, is more apt for industry-scale adoption. Results\non widely adopted Go libraries and applications demonstrate significant (up to\n10x) and scalable performance gains resulting from our automated transformation\nwhile avoiding major performance regressions.",
    "descriptor": "",
    "authors": [
      "Zhizhou Zhang",
      "Milind Chabbi",
      "Adam Welc",
      "Timothy Sherwood"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.01710"
  },
  {
    "id": "arXiv:2106.01711",
    "title": "Lymph Node Graph Neural Networks for Cancer Metastasis Prediction",
    "abstract": "Predicting outcomes, such as survival or metastasis for individual cancer\npatients is a crucial component of precision oncology. Machine learning (ML)\noffers a promising way to exploit rich multi-modal data, including clinical\ninformation and imaging to learn predictors of disease trajectory and help\ninform clinical decision making. In this paper, we present a novel graph-based\napproach to incorporate imaging characteristics of existing cancer spread to\nlocal lymph nodes (LNs) as well as their connectivity patterns in a prognostic\nML model. We trained an edge-gated Graph Convolutional Network (Gated-GCN) to\naccurately predict the risk of distant metastasis (DM) by propagating\ninformation across the LN graph with the aid of soft edge attention mechanism.\nIn a cohort of 1570 head and neck cancer patients, the Gated-GCN achieves AUROC\nof 0.757 for 2-year DM classification and $C$-index of 0.725 for lifetime DM\nrisk prediction, outperforming current prognostic factors as well as previous\napproaches based on aggregated LN features. We also explored the importance of\ngraph structure and individual lymph nodes through ablation experiments and\ninterpretability studies, highlighting the importance of considering individual\nLN characteristics as well as the relationships between regions of cancer\nspread.",
    "descriptor": "\nComments: 9 pages, 3 figures. Preprint, under review\n",
    "authors": [
      "Michal Kazmierski",
      "Benjamin Haibe-Kains"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2106.01711"
  },
  {
    "id": "arXiv:2106.01714",
    "title": "Optimization Variance: Exploring Generalization Properties of DNNs",
    "abstract": "Unlike the conventional wisdom in statistical learning theory, the test error\nof a deep neural network (DNN) often demonstrates double descent: as the model\ncomplexity increases, it first follows a classical U-shaped curve and then\nshows a second descent. Through bias-variance decomposition, recent studies\nrevealed that the bell-shaped variance is the major cause of model-wise double\ndescent (when the DNN is widened gradually). This paper investigates epoch-wise\ndouble descent, i.e., the test error of a DNN also shows double descent as the\nnumber of training epoches increases. By extending the bias-variance analysis\nto epoch-wise double descent of the zero-one loss, we surprisingly find that\nthe variance itself, without the bias, varies consistently with the test error.\nInspired by this result, we propose a novel metric, optimization variance (OV),\nto measure the diversity of model updates caused by the stochastic gradients of\nrandom training batches drawn in the same iteration. OV can be estimated using\nsamples from the training set only but correlates well with the (unknown)\n\\emph{test} error, and hence early stopping may be achieved without using a\nvalidation set.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Xiao Zhang",
      "Dongrui Wu",
      "Haoyi Xiong",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01714"
  },
  {
    "id": "arXiv:2106.01717",
    "title": "Towards urban scenes understanding through polarization cues",
    "abstract": "Autonomous robotics is critically affected by the robustness of its scene\nunderstanding algorithms. We propose a two-axis pipeline based on polarization\nindices to analyze dynamic urban scenes. As robots evolve in unknown\nenvironments, they are prone to encountering specular obstacles. Usually,\nspecular phenomena are rarely taken into account by algorithms which causes\nmisinterpretations and erroneous estimates. By exploiting all the light\nproperties, systems can greatly increase their robustness to events. In\naddition to the conventional photometric characteristics, we propose to include\npolarization sensing.\nWe demonstrate in this paper that the contribution of polarization\nmeasurement increases both the performances of segmentation and the quality of\ndepth estimation. Our polarimetry-based approaches are compared here with other\nstate-of-the-art RGB-centric methods showing interest of using polarization\nimaging.",
    "descriptor": "\nComments: Submitted to Autonomous Robots - Special Issue on Unconventional Sensors in Robotics\n",
    "authors": [
      "Marc Blanchon",
      "D\u00e9sir\u00e9 Sidib\u00e9",
      "Olivier Morel",
      "Ralph Seulin",
      "Fabrice Meriaudeau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01717"
  },
  {
    "id": "arXiv:2106.01720",
    "title": "Hybrid coupling of finite element and boundary integral methods",
    "abstract": "In this paper we discuss a hybridised method for FEM-BEM coupling. The\ncoupling from both sides use a Nitsche type approach to couple to the trace\nvariable. This leads to a formulation that is robust and flexible with respect\nto approximation spaces and can easily be combined as a building block with\nother hybridised methods. Energy error estimates and the convergence of Jacobi\niterations are proved and the performance of the method is illustrated on some\ncomputational examples.",
    "descriptor": "",
    "authors": [
      "Timo Betcke",
      "Micha\u0142 Bosy",
      "Erik Burman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01720"
  },
  {
    "id": "arXiv:2106.01721",
    "title": "Curiosity-based Robot Navigation under Uncertainty in Crowded  Environments",
    "abstract": "Mobile robots have become more and more popular in our daily life. In\nlarge-scale and crowded environments, how to navigate safely with localization\nprecision is a critical problem. To solve this problem, we proposed a\ncuriosity-based framework that can find an effective path with the\nconsideration of human comfort, localization uncertainty, crowds, and the\ncost-to-go to the target. Three parts are involved in the proposed framework:\nthe distance assessment module, the curiosity gain of the information-rich\narea, and the curiosity negative gain of crowded areas. The curiosity gain of\nthe information-rich area was proposed to provoke the robot to approach\nlocalization referenced landmarks. To guarantee human comfort while coexisting\nwith robots, we propose curiosity gain of the spacious area to bypass the crowd\nand maintain an appropriate distance between robots and humans. The evaluation\nis conducted in an unstructured environment. The results show that our method\ncan find a feasible path, which can consider the localization uncertainty while\nsimultaneously avoiding the crowded area.",
    "descriptor": "\nComments: 2021 IEEE International Conference on Robotics and Automation (ICRA) Workshop on Social Intelligence in Humans and Robots\n",
    "authors": [
      "Kuanqi Cai",
      "Weinan Chen",
      "Chaoqun Wang",
      "Shuang Song",
      "Max Q.-H. Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.01721"
  },
  {
    "id": "arXiv:2106.01722",
    "title": "GMAIR: Unsupervised Object Detection Based on Spatial Attention and  Gaussian Mixture",
    "abstract": "Recent studies on unsupervised object detection based on spatial attention\nhave achieved promising results. Models, such as AIR and SPAIR, output \"what\"\nand \"where\" latent variables that represent the attributes and locations of\nobjects in a scene, respectively. Most of the previous studies concentrate on\nthe \"where\" localization performance; however, we claim that acquiring \"what\"\nobject attributes is also essential for representation learning. This paper\npresents a framework, GMAIR, for unsupervised object detection. It incorporates\nspatial attention and a Gaussian mixture in a unified deep generative model.\nGMAIR can locate objects in a scene and simultaneously cluster them without\nsupervision. Furthermore, we analyze the \"what\" latent variables and clustering\nprocess. Finally, we evaluate our model on MultiMNIST and Fruit2D datasets and\nshow that GMAIR achieves competitive results on localization and clustering\ncompared to state-of-the-art methods.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Weijin Zhu",
      "Yao Shen",
      "Linfeng Yu",
      "Lizeth Patricia Aguirre Sanchez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01722"
  },
  {
    "id": "arXiv:2106.01726",
    "title": "Exploiting co-execution with oneAPI: heterogeneity from a modern  perspective",
    "abstract": "Programming efficiently heterogeneous systems is a major challenge, due to\nthe complexity of their architectures. Intel oneAPI, a new and powerful\nstandards-based unified programming model, built on top of SYCL, addresses\nthese issues. In this paper, oneAPI is provided with co-execution strategies to\nrun the same kernel between different devices, enabling the exploitation of\nstatic and dynamic policies. On top of that, static and dynamic load-balancing\nalgorithms are integrated and analyzed.\nThis work evaluates the performance and energy efficiency for a well-known\nset of regular and irregular HPC benchmarks, using an integrated GPU and CPU.\nExperimental results show that co-execution is worthwhile when using dynamic\nalgorithms, improving efficiency even more when using unified shared memory.",
    "descriptor": "\nComments: 14 pages, 9 figures, conference\n",
    "authors": [
      "Ra\u00fal Nozal",
      "Jose Luis Bosque"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.01726"
  },
  {
    "id": "arXiv:2106.01729",
    "title": "DEIS: Dependability Engineering Innovation for Industrial CPS",
    "abstract": "The open and cooperative nature of Cyber-Physical Systems (CPS) poses new\nchallenges in assuring dependability. The DEIS project (Dependability\nEngineering Innovation for automotive CPS. This project has received funding\nfrom the European Union's Horizon 2020 research and innovation programme under\ngrant agreement No 732242, see this http URL) addresses these\nchallenges by developing technologies that form a science of dependable system\nintegration. In the core of these technologies lies the concept of a Digital\nDependability Identity (DDI) of a component or system. DDIs are modular,\ncomposable, and executable in the field facilitating (a) efficient synthesis of\ncomponent and system dependability information over the supply chain and (b)\neffective evaluation of this information in-the-field for safe and secure\ncomposition of highly distributed and autonomous CPS. The paper outlines the\nDDI concept and opportunities for application in four industrial use cases.",
    "descriptor": "",
    "authors": [
      "Erik Armengaud",
      "Georg Macher",
      "Alexander Massoner",
      "Sebastian Frager",
      "Rasmus Adler",
      "Daniel Schneider",
      "Simone Longo",
      "Massimiliano Melis",
      "Riccardo Groppo",
      "Federica Villa",
      "Padraig OLeary",
      "Kevin Bambury",
      "Finnegan Anita",
      "Marc Zeller",
      "Kai Hoefig",
      "Yiannis Papadopoulos",
      "Richard Hawkins",
      "Tim Kelly"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.01729"
  },
  {
    "id": "arXiv:2106.01730",
    "title": "Drivers' Manoeuvre Modelling and Prediction for Safe HRI",
    "abstract": "As autonomous machines such as robots and vehicles start performing tasks\ninvolving human users, ensuring a safe interaction between them becomes an\nimportant issue. Translating methods from human-robot interaction (HRI) studies\nto the interaction between humans and other highly complex machines (e.g.\nsemi-autonomous vehicles) could help advance the use of those machines in\nscenarios requiring human interaction. One method involves understanding human\nintentions and decision-making to estimate the human's present and near-future\nactions whilst interacting with a robot. This idea originates from the\npsychological concept of Theory of Mind, which has been broadly explored for\nrobotics and recently for autonomous and semi-autonomous vehicles. In this\nwork, we explored how to predict human intentions before an action is performed\nby combining data from human-motion, vehicle-state and human inputs (e.g.\nsteering wheel, pedals). A data-driven approach based on Recurrent Neural\nNetwork models was used to classify the current driving manoeuvre and to\npredict the future manoeuvre to be performed. A state-transition model was used\nwith a fixed set of manoeuvres to label data recorded during the trials for\nreal-time applications. Models were trained and tested using drivers of\ndifferent seat preferences, driving expertise and arm-length; precision and\nrecall metrics over 95% for manoeuvre identification and 86% for manoeuvre\nprediction were achieved, with prediction time-windows of up to 1 second for\nboth known and unknown test subjects. Compared to our previous results,\nperformance improved and manoeuvre prediction was possible for unknown test\nsubjects without knowing the current manoeuvre.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Human-Machine Systems on 17-Jul-2020\n",
    "authors": [
      "Erwin Jose Lopez Pulgarin",
      "Guido Herrmann",
      "Ute Leonards"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01730"
  },
  {
    "id": "arXiv:2106.01732",
    "title": "Bilingual Alignment Pre-training for Zero-shot Cross-lingual Transfer",
    "abstract": "Multilingual pre-trained models have achieved remarkable transfer performance\nby pre-trained on rich kinds of languages. Most of the models such as mBERT are\npre-trained on unlabeled corpora. The static and contextual embeddings from the\nmodels could not be aligned very well. In this paper, we aim to improve the\nzero-shot cross-lingual transfer performance by aligning the embeddings better.\nWe propose a pre-training task named Alignment Language Model (AlignLM), which\nuses the statistical alignment information as the prior knowledge to guide\nbilingual word prediction. We evaluate our method on multilingual machine\nreading comprehension and natural language interface tasks. The results show\nAlignLM can improve the zero-shot performance significantly on MLQA and XNLI\ndatasets.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Ziqing Yang",
      "Wentao Ma",
      "Yiming Cui",
      "Jiani Ye",
      "Wanxiang Che",
      "Shijin Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01732"
  },
  {
    "id": "arXiv:2106.01733",
    "title": "A Novel SEPIC-\u0106uk Based High Gain Solar Micro-Inverter for Grid  Integration",
    "abstract": "Solar micro-inverters are becoming increasingly popular as they are modular,\nand they posses the capability of extracting maximum available power from the\nindividual photovoltaic (PV) modules of a solar array. For realizing\nmicro-inverters single stage transformer-less topologies are preferred as they\noffer better power evacuation efficacy. A SEPIC-\\'Cuk based transformer-less\nmicro-inverter, having only one high frequency switch and four line frequency\nswitches, is proposed in this paper. The proposed converter can be employed to\ninterface a 35 V PV module to a 220 V single phase ac grid. As a very high gain\nis required to be achieved for the converter, it is made to operate in\ndiscontinuous conduction mode (DCM) for all possible operating conditions.\nSince the ground of the each PV modules is connected to the ground of the\nutility, there is no possibility of leakage current flow between the module and\nthe utility. Detailed simulation studies are carried out to ascertain the\nefficacy of the proposed micro-inverter. A laboratory prototype of the inverter\nis fabricated, and detailed experimental studies are carried out to confirm the\nviability of the proposed scheme.",
    "descriptor": "",
    "authors": [
      "Arup Ratan Paul",
      "Arghyadip Bhattacharya",
      "Kishore Chatterjee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01733"
  },
  {
    "id": "arXiv:2106.01735",
    "title": "Auto-tagging of Short Conversational Sentences using Transformer Methods",
    "abstract": "The problem of categorizing short speech sentences according to their\nsemantic features with high accuracy is a subject studied in natural language\nprocessing. In this study, a data set created with samples classified in 46\ndifferent categories was used. Examples consist of sentences taken from chat\nconversations between a company's customer representatives and the company's\nwebsite visitors. The primary purpose is to automatically tag questions and\nrequests from visitors in the most accurate way for 46 predetermined categories\nfor use in a chat application to generate meaningful answers to the questions\nasked by the website visitors. For this, different BERT models and one GPT-2\nmodel, pre-trained in Turkish, were preferred. The classification performances\nof the relevant models were analyzed in detail and reported accordingly.",
    "descriptor": "\nComments: in Turkish language\n",
    "authors": [
      "D. Emre Ta\u015far",
      "\u015e\u00fckr\u00fc Ozan",
      "Umut \u00d6zdil",
      "M. Fatih Akca",
      "O\u011fuzhan \u00d6lmez",
      "Semih G\u00fcl\u00fcm",
      "Se\u00e7ilay Kutal",
      "Ceren Belhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01735"
  },
  {
    "id": "arXiv:2106.01737",
    "title": "Optimal sets of questions for Twenty Questions",
    "abstract": "In the distributional Twenty Questions game, Bob chooses a number $x$ from\n$1$ to $n$ according to a distribution $\\mu$, and Alice (who knows $\\mu$)\nattempts to identify $x$ using Yes/No questions, which Bob answers truthfully.\nHer goal is to minimize the expected number of questions.\nThe optimal strategy for the Twenty Questions game corresponds to a Huffman\ncode for $\\mu$, yet this strategy could potentially uses all $2^n$ possible\nquestions. Dagan et al. constructed a set of $1.25^{n+o(n)}$ questions which\nsuffice to construct an optimal strategy for all $\\mu$, and showed that this\nnumber is optimal (up to sub-exponential factors) for infinitely many $n$.\nWe determine the optimal size of such a set of questions for all $n$ (up to\nsub-exponential factors), answering an open question of Dagan et al. In\naddition, we generalize the results of Dagan et al. to the $d$-ary setting,\nobtaining similar results with $1.25$ replaced by $1 + (d-1)/d^{d/(d-1)}$.",
    "descriptor": "",
    "authors": [
      "Yuval Filmus",
      "Idan Mehalel"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.01737"
  },
  {
    "id": "arXiv:2106.01738",
    "title": "Implicit gradients based novel finite volume scheme for compressible  single and multi-component flows",
    "abstract": "This paper introduces a novel approach to compute the numerical fluxes at the\ncell boundaries in the finite volume approach. Explicit gradients used in\nderiving the reconstruction polynomials are replaced by high-order gradients\ncomputed by compact finite differences, referred to as implicit gradients in\nthis paper. The new finite volume scheme has superior dispersion and\ndissipation properties in comparison to the compact reconstruction approach.\nThese implicit gradients are re-used in viscous flux computation and\npost-processing, which further improves efficiency. A problem-independent shock\ncapturing approach via Boundary Variation Diminishing (BVD) algorithm is used\nto suppress oscillations for the simulation of flows with shocks and material\ninterfaces. Several numerical test cases are carried out to verify the proposed\nfinite volume method's capability using the implicit gradient method for single\nand multicomponent flows. Significant improvements are observed by computing\nthe gradients implicitly for the viscous flows.",
    "descriptor": "",
    "authors": [
      "Amareshwara Sainadh Chamarthi",
      "Steven H. Frankel",
      "Abhishek Chintagunta"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01738"
  },
  {
    "id": "arXiv:2106.01741",
    "title": "Lifetime policy reuse and the importance of task capacity",
    "abstract": "A long-standing challenge in artificial intelligence is lifelong learning. In\nlifelong learning, many tasks are presented in sequence and learners must\nefficiently transfer knowledge between tasks while avoiding catastrophic\nforgetting over long lifetimes. On these problems, policy reuse and other\nmulti-policy reinforcement learning techniques can learn many tasks. However,\nthey can generate many temporary or permanent policies, resulting in memory\nissues. Consequently, there is a need for lifetime-scalable methods that\ncontinually refine a policy library of a pre-defined size. This paper presents\na first approach to lifetime-scalable policy reuse. To pre-select the number of\npolicies, a notion of task capacity, the maximal number of tasks that a policy\ncan accurately solve, is proposed. To evaluate lifetime policy reuse using this\nmethod, two state-of-the-art single-actor base-learners are compared: 1) a\nvalue-based reinforcement learner, Deep Q-Network (DQN) or Deep Recurrent\nQ-Network (DRQN); and 2) an actor-critic reinforcement learner, Proximal Policy\nOptimisation (PPO) with or without Long Short-Term Memory layer. By selecting\nthe number of policies based on task capacity, D(R)QN achieves near-optimal\nperformance with 6 policies in a 27-task MDP domain and 9 policies in an\n18-task POMDP domain; with fewer policies, catastrophic forgetting and negative\ntransfer are observed. Due to slow, monotonic improvement, PPO requires fewer\npolicies, 1 policy for the 27-task domain and 4 policies for the 18-task\ndomain, but it learns the tasks with lower accuracy than D(R)QN. These findings\nvalidate lifetime-scalable policy reuse and suggest using D(R)QN for larger and\nPPO for smaller library sizes.",
    "descriptor": "",
    "authors": [
      "David M. Bossens",
      "Adam J. Sobey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01741"
  },
  {
    "id": "arXiv:2106.01744",
    "title": "Multi-Scale Feature Aggregation by Cross-Scale Pixel-to-Region Relation  Operation for Semantic Segmentation",
    "abstract": "Exploiting multi-scale features has shown great potential in tackling\nsemantic segmentation problems. The aggregation is commonly done with sum or\nconcatenation (concat) followed by convolutional (conv) layers. However, it\nfully passes down the high-level context to the following hierarchy without\nconsidering their interrelation. In this work, we aim to enable the low-level\nfeature to aggregate the complementary context from adjacent high-level feature\nmaps by a cross-scale pixel-to-region relation operation. We leverage\ncross-scale context propagation to make the long-range dependency capturable\neven by the high-resolution low-level features. To this end, we employ an\nefficient feature pyramid network to obtain multi-scale features. We propose a\nRelational Semantics Extractor (RSE) and Relational Semantics Propagator (RSP)\nfor context extraction and propagation respectively. Then we stack several RSP\ninto an RSP head to achieve the progressive top-down distribution of the\ncontext. Experiment results on two challenging datasets Cityscapes and COCO\ndemonstrate that the RSP head performs competitively on both semantic\nsegmentation and panoptic segmentation with high efficiency. It outperforms\nDeeplabV3 [1] by 0.7% with 75% fewer FLOPs (multiply-adds) in the semantic\nsegmentation task.",
    "descriptor": "\nComments: Accepted to RA-L 2021\n",
    "authors": [
      "Yechao Bai",
      "Ziyuan Huang",
      "Lyuyu Shen",
      "Hongliang Guo",
      "Marcelo H. Ang Jr",
      "Daniela Rus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01744"
  },
  {
    "id": "arXiv:2106.01750",
    "title": "Modeling Influencer Marketing Campaigns In Social Networks",
    "abstract": "In the present day, more than 3.8 billion people around the world actively\nuse social media. The effectiveness of social media in facilitating quick and\neasy sharing of information has attracted brands and advertizers who wish to\nuse the platform to market products via the influencers in the network.\nInfluencers, owing to their massive popularity, provide a huge potential\ncustomer base generating higher returns of investment in a very short period.\nHowever, it is not straightforward to decide which influencers should be\nselected for an advertizing campaign that can generate maximum returns with\nminimum investment. In this work, we present an agent-based model (ABM) that\ncan simulate the dynamics of influencer advertizing campaigns in a variety of\nscenarios and can help to discover the best influencer marketing strategy. Our\nsystem is a probabilistic graph-based model that incorporates real-world\nfactors such as customers' interest in a product, customer behavior, the\nwillingness to pay, a brand's investment cap, influencers' engagement with\ninfluence diffusion, and the nature of the product being advertized viz. luxury\nand non-luxury.",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Ronak Doshi",
      "Ajay Ramesh Ranganathan",
      "Shrisha Rao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.01750"
  },
  {
    "id": "arXiv:2106.01751",
    "title": "Reordering Examples Helps during Priming-based Few-Shot Learning",
    "abstract": "The ability to learn from limited data, or few-shot learning, is a desirable\nand often critical requirement for NLP systems. While many existing methods do\npoorly at learning from a handful of examples, large pretrained language models\nhave recently been shown to be efficient few-shot learners. One approach to\nfew-shot learning, which does not require finetuning of model parameters, is to\naugment the language model's input with priming text which is typically\nconstructed using task specific descriptions and examples. In this work, we\nfurther explore priming-based few-shot learning, with focus on using examples\nas prompts. We show that presenting examples in the right order is key for\ngeneralization. We introduce PERO (Prompting with Examples in the Right Order),\nwhere we formulate few-shot learning as search over the set of permutations of\nthe training examples. We show that PERO can learn to generalize efficiently\nusing as few as 10 examples, in contrast to existing approaches. While the\nnewline token is a natural choice for separating the examples in the prompt, we\nshow that learning a new separator token can potentially provide further gains\nin performance. We demonstrate the effectiveness of the proposed method on the\ntasks of sentiment classification, natural language inference and fact\nretrieval. Finally, we analyze the learned prompts to reveal novel insights,\nincluding the idea that two training examples in the right order alone can\nprovide competitive performance for sentiment classification and natural\nlanguage inference.",
    "descriptor": "\nComments: 12 pages, 1 figure, Accepted to Findings of ACL 2021\n",
    "authors": [
      "Sawan Kumar",
      "Partha Talukdar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01751"
  },
  {
    "id": "arXiv:2106.01760",
    "title": "Template-Based Named Entity Recognition Using BART",
    "abstract": "There is a recent interest in investigating few-shot NER, where the\nlow-resource target domain has different label sets compared with a\nresource-rich source domain. Existing methods use a similarity-based metric.\nHowever, they cannot make full use of knowledge transfer in NER model\nparameters. To address the issue, we propose a template-based method for NER,\ntreating NER as a language model ranking problem in a sequence-to-sequence\nframework, where original sentences and statement templates filled by candidate\nnamed entity span are regarded as the source sequence and the target sequence,\nrespectively. For inference, the model is required to classify each candidate\nspan based on the corresponding template scores. Our experiments demonstrate\nthat the proposed method achieves 92.55% F1 score on the CoNLL03 (rich-resource\ntask), and significantly better than fine-tuning BERT 10.88%, 15.34%, and\n11.73% F1 score on the MIT Movie, the MIT Restaurant, and the ATIS\n(low-resource task), respectively.",
    "descriptor": "",
    "authors": [
      "Leyang Cui",
      "Yu Wu",
      "Jian Liu",
      "Sen Yang",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01760"
  },
  {
    "id": "arXiv:2106.01763",
    "title": "Internal Shortest Absent Word Queries in Constant Time and Linear Space",
    "abstract": "Given a string $T$ of length $n$ over an alphabet $\\Sigma\\subset\n\\{1,2,\\ldots,n^{O(1)}\\}$ of size $\\sigma$, we are to preprocess $T$ so that\ngiven a range $[i,j]$, we can return a representation of a shortest string over\n$\\Sigma$ that is absent in the fragment $T[i]\\cdots T[j]$ of $T$. We present an\n$O(n)$-space data structure that answers such queries in constant time and can\nbe constructed in $O(n\\log_\\sigma n)$ time.",
    "descriptor": "\nComments: 13 pages, 1 figure, 4 tables\n",
    "authors": [
      "Golnaz Badkobeh",
      "Panagiotis Charalampopoulos",
      "Dmitry Kosolobov",
      "Solon P. Pissis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.01763"
  },
  {
    "id": "arXiv:2106.01764",
    "title": "Less is More: Sparse Sampling for Dense Reaction Predictions",
    "abstract": "Obtaining viewer responses from videos can be useful for creators and\nstreaming platforms to analyze the video performance and improve the future\nuser experience. In this report, we present our method for 2021 Evoked\nExpression from Videos Challenge. In particular, our model utilizes both audio\nand image modalities as inputs to predict emotion changes of viewers. To model\nlong-range emotion changes, we use a GRU-based model to predict one sparse\nsignal with 1Hz. We observe that the emotion changes are smooth. Therefore, the\nfinal dense prediction is obtained via linear interpolating the signal, which\nis robust to the prediction fluctuation. Albeit simple, the proposed method has\nachieved pearson's correlation score of 0.04430 on the final private test set.",
    "descriptor": "\nComments: Code is available at: this https URL\n",
    "authors": [
      "Kezhou Lin",
      "Xiaohan Wang",
      "Zhedong Zheng",
      "Linchao Zhu",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01764"
  },
  {
    "id": "arXiv:2106.01766",
    "title": "Dynamic Analysis of ARINC 653 RTOS with LLVM",
    "abstract": "Existing standards for airborne-embedded software systems impose a number of\nrequirements applicable to the software development cycle of hard real-time\noperating systems found in modern aircraft. The measures taken are meant to\nreduce the risks of undesired consequences, but have strongly varying costs.\nDynamic instrumentation and static analysis are common practices used to\nautomatically find software defects, from strictly non-conforming code\nconstructions to memory corruptions or invalid control flow. LLVM analyser and\nsanitizer infrastructure, while regularly applied to general-purpose software,\noriginally was not thought to be introduced to heavily restricted environments.\nIn this paper we discuss the specifics of airborne systems with regards to\ndynamic instrumentation and provide practical considerations to be taken into\naccount for the effective use of general-purpose instrumentation tools. We\nbring a complete LLVM stack support to JetOS, a prospective onboard real-time\noperating system currently being developed at ISP RAS in collaboration with\nGosNIIAS. As an example, we port AddressSanitizer, MemorySanitizer, and\nUndefinedBehaviorSanitizer and provide the details against the caveats on all\nrelevant sides: a sanitizer, a compiler, and an operating system. In addition\nwe suggest uninvolved optimisations and enhancements to the runtimes to\nmaximise the effects of the tools.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Vitaly Cheptsov",
      "Alexey Khoroshilov"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.01766"
  },
  {
    "id": "arXiv:2106.01768",
    "title": "Homeostasis: Design and Implementation of a Self-Stabilizing Compiler",
    "abstract": "Mainstream compilers perform a multitude of analyses and optimizations on the\ngiven input program. Each analysis pass may generate a program-abstraction.\nEach optimization pass is typically composed of multiple alternating phases of\ninspection of program-abstractions and transformations of the program. Upon\ntransformation of a program, the program-abstractions generated by various\nanalysis passes may become inconsistent with the program's modified state.\nConsequently, the downstream transformations may be considered unsafe until the\nrelevant program-abstractions are stabilized, i.e., the program-abstractions\nare made consistent with the modified program. In general, the existing\ncompiler frameworks do not perform automated stabilization of the\nprogram-abstractions and instead leave it to the optimization writer to deal\nwith the complex task of identifying the relevant program-abstractions to\nstabilize, the points where the stabilization is to be performed, and the exact\nprocedure of stabilization. Similarly, adding new analyses becomes a challenge\nas one has to understand which all existing optimizations may impact the newly\nadded program-abstractions. In this paper, we address these challenges by\nproviding the design and implementation of a novel generalized compiler-design\nframework called Homeostasis.\nHomeostasis can be used to guarantee the trigger of automated stabilization\nof relevant program-abstractions under every possible transformation of the\nprogram. Interestingly, Homeostasis provides such guarantees not only for the\nexisting optimization passes but also for any future optimizations that may be\nadded to the framework. We have implemented our proposed ideas in the IMOP\ncompiler framework, for OpenMP C programs. We present an evaluation which shows\nthat Homeostasis is efficient and easy to use.",
    "descriptor": "\nComments: 33 pages, 16 figures. Patent filed (application no: 202041054066). For associated code, see this https URL\n",
    "authors": [
      "Aman Nougrahiya",
      "V. Krishna Nandivada"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.01768"
  },
  {
    "id": "arXiv:2106.01770",
    "title": "A Normative Model of Classifier Fusion",
    "abstract": "Combining the outputs of multiple classifiers or experts into a single\nprobabilistic classification is a fundamental task in machine learning with\nbroad applications from classifier fusion to expert opinion pooling. Here we\npresent a hierarchical Bayesian model of probabilistic classifier fusion based\non a new correlated Dirichlet distribution. This distribution explicitly models\npositive correlations between marginally Dirichlet-distributed random vectors\nthereby allowing normative modeling of correlations between base classifiers or\nexperts. The proposed model naturally accommodates the classic Independent\nOpinion Pool and other independent fusion algorithms as special cases. It is\nevaluated by uncertainty reduction and correctness of fusion on synthetic and\nreal-world data sets. We show that a change in performance of the fused\nclassifier due to uncertainty reduction can be Bayes optimal even for highly\ncorrelated base classifiers.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Susanne Trick",
      "Constantin A. Rothkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01770"
  },
  {
    "id": "arXiv:2106.01777",
    "title": "LiMIIRL: Lightweight Multiple-Intent Inverse Reinforcement Learning",
    "abstract": "Multiple-Intent Inverse Reinforcement Learning (MI-IRL) seeks to find a\nreward function ensemble to rationalize demonstrations of different but\nunlabelled intents. Within the popular expectation maximization (EM) framework\nfor learning probabilistic MI-IRL models, we present a warm-start strategy\nbased on up-front clustering of the demonstrations in feature space. Our\ntheoretical analysis shows that this warm-start solution produces a\nnear-optimal reward ensemble, provided the behavior modes satisfy mild\nseparation conditions. We also propose a MI-IRL performance metric that\ngeneralizes the popular Expected Value Difference measure to directly assesses\nlearned rewards against the ground-truth reward ensemble. Our metric elegantly\naddresses the difficulty of pairing up learned and ground truth rewards via a\nmin-cost flow formulation, and is efficiently computable. We also develop a\nMI-IRL benchmark problem that allows for more comprehensive algorithmic\nevaluations. On this problem, we find our MI-IRL warm-start strategy helps\navoid poor quality local minima reward ensembles, resulting in a significant\nimprovement in behavior clustering. Our extensive sensitivity analysis\ndemonstrates that the quality of the learned reward ensembles is improved under\nvarious settings, including cases where our theoretical assumptions do not\nnecessarily hold. Finally, we demonstrate the effectiveness of our methods by\ndiscovering distinct driving styles in a large real-world dataset of driver GPS\ntrajectories.",
    "descriptor": "\nComments: Under review for NeurIPS 2021\n",
    "authors": [
      "Aaron J. Snoswell",
      "Surya P. N. Singh",
      "Nan Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.01777"
  },
  {
    "id": "arXiv:2106.01781",
    "title": "A protocol to gather, characterize and analyze incoming citations of  retracted articles",
    "abstract": "In this article, we present a methodology which takes as input a collection\nof retracted articles, gathers the entities citing them, characterizes such\nentities according to multiple dimensions (disciplines, year of publication,\nsentiment, etc.), and applies a quantitative and qualitative analysis on the\ncollected values. The methodology is composed of four phases: (1) identifying,\nretrieving, and extracting basic metadata of the entities which have cited a\nretracted article, (2) extracting and labeling additional features based on the\ntextual content of the citing entities, (3) building a descriptive statistical\nsummary based on the collected data, and finally (4) running a topic modeling\nanalysis. The goal of the methodology is to generate data and visualizations\nthat help understanding possible behaviors related to retraction cases. We\npresent the methodology in a structured step-by-step form following its four\nphases, discuss its limits and possible workarounds, and list the planned\nfuture improvements.",
    "descriptor": "",
    "authors": [
      "Ivan Heibi",
      "Silvio Peroni"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.01781"
  },
  {
    "id": "arXiv:2106.01782",
    "title": "Machine learning models for DOTA 2 outcomes prediction",
    "abstract": "Prediction of the real-time multiplayer online battle arena (MOBA) games'\nmatch outcome is one of the most important and exciting tasks in Esports\nanalytical research. This research paper predominantly focuses on building\npredictive machine and deep learning models to identify the outcome of the Dota\n2 MOBA game using the new method of multi-forward steps predictions. Three\nmodels were investigated and compared: Linear Regression (LR), Neural Networks\n(NN), and a type of recurrent neural network Long Short-Term Memory (LSTM). In\norder to achieve the goals, we developed a data collecting python server using\nGame State Integration (GSI) to track the real-time data of the players. Once\nthe exploratory feature analysis and tuning hyper-parameters were done, our\nmodels' experiments took place on different players with dissimilar backgrounds\nof playing experiences. The achieved accuracy scores depend on the\nmulti-forward prediction parameters, which for the worse case in linear\nregression 69\\% but on average 82\\%, while in the deep learning models hit the\nutmost accuracy of prediction on average 88\\% for NN, and 93\\% for LSTM models.",
    "descriptor": "\nComments: 11 pages, 12 figures, the paper will be published in IEEE Transactions on Games Journal\n",
    "authors": [
      "Kodirjon Akhmedov",
      "Anh Huy Phan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01782"
  },
  {
    "id": "arXiv:2106.01784",
    "title": "The Contestation of Tech Ethics: A Sociotechnical Approach to Ethics and  Technology in Action",
    "abstract": "Recent controversies related to topics such as fake news, privacy, and\nalgorithmic bias have prompted increased public scrutiny of digital\ntechnologies and soul-searching among many of the people associated with their\ndevelopment. In response, the tech industry, academia, civil society, and\ngovernments have rapidly increased their attention to \"ethics\" in the design\nand use of digital technologies (\"tech ethics\"). Yet almost as quickly as\nethics discourse has proliferated across the world of digital technologies, the\nlimitations of these approaches have also become apparent: tech ethics is vague\nand toothless, is subsumed into corporate logics and incentives, and has a\nmyopic focus on individual engineers and technology design rather than on the\nstructures and cultures of technology production. As a result of these\nlimitations, many have grown skeptical of tech ethics and its proponents,\ncharging them with \"ethics-washing\": promoting ethics research and discourse to\ndefuse criticism and government regulation without committing to ethical\nbehavior. By looking at how ethics has been taken up in both science and\nbusiness in superficial and depoliticizing ways, I recast tech ethics as a\nterrain of contestation where the central fault line is not whether it is\ndesirable to be ethical, but what \"ethics\" entails and who gets to define it.\nThis framing highlights the significant limits of current approaches to tech\nethics and the importance of studying the formulation and real-world effects of\ntech ethics. In order to identify and develop more rigorous strategies for\nreforming digital technologies and the social relations that they mediate, I\ndescribe a sociotechnical approach to tech ethics, one that reflexively applies\nmany of tech ethics' own lessons regarding digital technologies to tech ethics\nitself.",
    "descriptor": "",
    "authors": [
      "Ben Green"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01784"
  },
  {
    "id": "arXiv:2106.01786",
    "title": "What Happened Next? Using Deep Learning to Value Defensive Actions in  Football Event-Data",
    "abstract": "Objectively quantifying the value of player actions in football (soccer) is a\nchallenging problem. To date, studies in football analytics have mainly focused\non the attacking side of the game, while there has been less work on\nevent-driven metrics for valuing defensive actions (e.g., tackles and\ninterceptions). Therefore in this paper, we use deep learning techniques to\ndefine a novel metric that values such defensive actions by studying the threat\nof passages of play that preceded them. By doing so, we are able to value\ndefensive actions based on what they prevented from happening in the game. Our\nDefensive Action Expected Threat (DAxT) model has been validated using\nreal-world event-data from the 2017/2018 and 2018/2019 English Premier League\nseasons, and we combine our model outputs with additional features to derive an\noverall rating of defensive ability for players. Overall, we find that our\nmodel is able to predict the impact of defensive actions allowing us to better\nvalue defenders using event-data.",
    "descriptor": "\nComments: 10 pages, 7 figures, Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '21), August 14--18, 2021, Virtual Event, Singapore\n",
    "authors": [
      "Charbel Merhej",
      "Ryan Beal",
      "Sarvapali Ramchurn",
      "Tim Matthews"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01786"
  },
  {
    "id": "arXiv:2106.01793",
    "title": "Three Sentences Are All You Need: Local Path Enhanced Document Relation  Extraction",
    "abstract": "Document-level Relation Extraction (RE) is a more challenging task than\nsentence RE as it often requires reasoning over multiple sentences. Yet, human\nannotators usually use a small number of sentences to identify the relationship\nbetween a given entity pair. In this paper, we present an embarrassingly simple\nbut effective method to heuristically select evidence sentences for\ndocument-level RE, which can be easily combined with BiLSTM to achieve good\nperformance on benchmark datasets, even better than fancy graph neural network\nbased methods. We have released our code at\nhttps://github.com/AndrewZhe/Three-Sentences-Are-All-You-Need.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Quzhe Huang",
      "Shengqi Zhu",
      "Yansong Feng",
      "Yuan Ye",
      "Yuxuan Lai",
      "Dongyan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01793"
  },
  {
    "id": "arXiv:2106.01797",
    "title": "TVDIM: Enhancing Image Self-Supervised Pretraining via Noisy Text Data",
    "abstract": "Among ubiquitous multimodal data in the real world, text is the modality\ngenerated by human, while image reflects the physical world honestly. In a\nvisual understanding application, machines are expected to understand images\nlike human. Inspired by this, we propose a novel self-supervised learning\nmethod, named Text-enhanced Visual Deep InfoMax (TVDIM), to learn better visual\nrepresentations by fully utilizing the naturally-existing multimodal data. Our\ncore idea of self-supervised learning is to maximize the mutual information\nbetween features extracted from multiple views of a shared context to a\nrational degree. Different from previous methods which only consider multiple\nviews from a single modality, our work produces multiple views from different\nmodalities, and jointly optimizes the mutual information for features pairs of\nintra-modality and inter-modality. Considering the information gap between\ninter-modality features pairs from data noise, we adopt a \\emph{ranking-based}\ncontrastive learning to optimize the mutual information. During evaluation, we\ndirectly use the pre-trained visual representations to complete various image\nclassification tasks. Experimental results show that, TVDIM significantly\noutperforms previous visual self-supervised methods when processing the same\nset of images.",
    "descriptor": "",
    "authors": [
      "Pengda Qin",
      "Yuhong Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01797"
  },
  {
    "id": "arXiv:2106.01798",
    "title": "Implicit MLE: Backpropagating Through Discrete Exponential Family  Distributions",
    "abstract": "Integrating discrete probability distributions and combinatorial optimization\nproblems into neural networks has numerous applications but poses several\nchallenges. We propose Implicit Maximum Likelihood Estimation (I-MLE), a\nframework for end-to-end learning of models combining discrete exponential\nfamily distributions and differentiable neural components. I-MLE is widely\napplicable: it only requires the ability to compute the most probable states;\nand does not rely on smooth relaxations. The framework encompasses several\napproaches, such as perturbation-based implicit differentiation and recent\nmethods to differentiate through black-box combinatorial solvers. We introduce\na novel class of noise distributions for approximating marginals via\nperturb-and-MAP. Moreover, we show that I-MLE simplifies to maximum likelihood\nestimation when used in some recently studied learning settings that involve\ncombinatorial solvers. Experiments on several datasets suggest that I-MLE is\ncompetitive with and often outperforms existing approaches which rely on\nproblem-specific relaxations.",
    "descriptor": "",
    "authors": [
      "Mathias Niepert",
      "Pasquale Minervini",
      "Luca Franceschi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01798"
  },
  {
    "id": "arXiv:2106.01801",
    "title": "An Information-oriented Model of Multi-Scale (Feedback) Systems",
    "abstract": "Multi-scale structures are prevalent in both natural and artificial systems,\nas they can handle increasing complexity. Several terms are employed almost\ninterchangeably across various application domains to refer to the multi-scale\nconcept - e.g., hierarchy, holarchy, multi-level, multi-layer, nested,\nembedded, micro-macro or coarse graining. While the concrete meanings behind\nthese terms may differ slightly, several core commonalities persist across all\ncases. In this position paper we aim to highlight these common features of the\nmulti-scale concept, as a preliminary basis for a generic theory of multi-scale\nsystems. We discuss the concepts of scale and multi-scale systems in general,\nand then of multi-scale feedback systems in particular, focusing on the role\nplayed by information in such systems. Our long-term objective is to develop a\ngeneral theory of multi-scale feedback systems, applicable across all domains\ndealing with complex systems.",
    "descriptor": "\nComments: 7 pages, 3 Figures, presented at B-Series #5 online event, to be submitted to SISSY 2021 workshop (with IEEE ACSOS Intl. Conf.)\n",
    "authors": [
      "Ada Diaconescu",
      "Louisa Jane Di Felice",
      "Patricia Mellodge"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01801"
  },
  {
    "id": "arXiv:2106.01804",
    "title": "E2E-VLP: End-to-End Vision-Language Pre-training Enhanced by Visual  Learning",
    "abstract": "Vision-language pre-training (VLP) on large-scale image-text pairs has\nachieved huge success for the cross-modal downstream tasks. The most existing\npre-training methods mainly adopt a two-step training procedure, which firstly\nemploys a pre-trained object detector to extract region-based visual features,\nthen concatenates the image representation and text embedding as the input of\nTransformer to train. However, these methods face problems of using\ntask-specific visual representation of the specific object detector for generic\ncross-modal understanding, and the computation inefficiency of two-stage\npipeline. In this paper, we propose the first end-to-end vision-language\npre-trained model for both V+L understanding and generation, namely E2E-VLP,\nwhere we build a unified Transformer framework to jointly learn visual\nrepresentation, and semantic alignments between image and text. We incorporate\nthe tasks of object detection and image captioning into pre-training with a\nunified Transformer encoder-decoder architecture for enhancing visual learning.\nAn extensive set of experiments have been conducted on well-established\nvision-language downstream tasks to demonstrate the effectiveness of this novel\nVLP paradigm.",
    "descriptor": "",
    "authors": [
      "Haiyang Xu",
      "Ming Yan",
      "Chenliang Li",
      "Bin Bi",
      "Songfang Huang",
      "Wenming Xiao",
      "Fei Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01804"
  },
  {
    "id": "arXiv:2106.01805",
    "title": "Partial Graph Reasoning for Neural Network Regularization",
    "abstract": "Regularizers helped deep neural networks prevent feature co-adaptations.\nDropout,as a commonly used regularization technique, stochastically disables\nneuron ac-tivations during network optimization. However, such complete feature\ndisposal can affect the feature representation and network understanding.\nToward betterdescriptions of latent representations, we present DropGraph that\nlearns regularization function by constructing a stand-alone graph from the\nbackbone features. DropGraph first samples stochastic spatial feature vectors\nand then incorporates graph reasoning methods to generate feature map\ndistortions. This add-on graph regularizes the network during training and can\nbe completely skipped during inference. We provide intuitions on the linkage\nbetween graph reasoning andDropout with further discussions on how partial\ngraph reasoning method reduces feature correlations. To this end, we\nextensively study the modeling of graphvertex dependencies and the utilization\nof the graph for distorting backbone featuremaps. DropGraph was validated on\nfour tasks with a total of 7 different datasets.The experimental results show\nthat our method outperforms other state-of-the-art regularizers while leaving\nthe base model structure unmodified during inference.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Tiange Xiang",
      "Chaoyi Zhang",
      "Yang Song",
      "Siqi Liu",
      "Hongliang Yuan",
      "Weidong Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01805"
  },
  {
    "id": "arXiv:2106.01806",
    "title": "Topological Anomaly Detection in Dynamic Multilayer Blockchain Networks",
    "abstract": "Motivated by the recent surge of criminal activities with\ncross-cryptocurrency trades, we introduce a new topological perspective to\nstructural anomaly detection in dynamic multilayer networks. We postulate that\nanomalies in the underlying blockchain transaction graph that are composed of\nmultiple layers are likely to be also manifested in anomalous patterns of the\nnetwork shape properties. As such, we invoke the machinery of clique persistent\nhomology on graphs to systematically and efficiently track evolution of the\nnetwork shape and, as a result, to detect changes in the underlying network\ntopology and geometry. We develop a new persistence summary for multilayer\nnetworks, called stacked persistence diagram, and prove its stability under\ninput data perturbations. We validate our new topological anomaly detection\nframework in application to dynamic multilayer networks from the Ethereum\nBlockchain and the Ripple Credit Network, and show that our stacked PD approach\nsubstantially outperforms the state-of-art techniques, yielding up to 40% gains\nin precision.",
    "descriptor": "\nComments: 26 pages, 6 figures, 7 tables\n",
    "authors": [
      "Dorcas Ofori-Boateng",
      "Ignacio Segovia Dominguez",
      "Murat Kantarcioglu",
      "Cuneyt G. Akcora",
      "Yulia R. Gel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Algebraic Topology (math.AT)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.01806"
  },
  {
    "id": "arXiv:2106.01808",
    "title": "MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood  Inference from Sampled Trajectories",
    "abstract": "Simulation-based inference enables learning the parameters of a model even\nwhen its likelihood cannot be computed in practice. One class of methods uses\ndata simulated with different parameters to infer an amortized estimator for\nthe likelihood-to-evidence ratio, or equivalently the posterior function. We\nshow that this approach can be formulated in terms of mutual information\nmaximization between model parameters and simulated data. We use this\nequivalence to reinterpret existing approaches for amortized inference, and\npropose two new methods that rely on lower bounds of the mutual information. We\napply our framework to the inference of parameters of stochastic processes and\nchaotic dynamical systems from sampled trajectories, using artificial neural\nnetworks for posterior prediction. Our approach provides a unified framework\nthat leverages the power of mutual information estimators for inference.",
    "descriptor": "",
    "authors": [
      "Giulio Isacchini",
      "Natanael Spisak",
      "Armita Nourmohammad",
      "Thierry Mora",
      "Aleksandra M. Walczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01808"
  },
  {
    "id": "arXiv:2106.01809",
    "title": "Exploring Distantly-Labeled Rationales in Neural Network Models",
    "abstract": "Recent studies strive to incorporate various human rationales into neural\nnetworks to improve model performance, but few pay attention to the quality of\nthe rationales. Most existing methods distribute their models' focus to\ndistantly-labeled rationale words entirely and equally, while ignoring the\npotential important non-rationale words and not distinguishing the importance\nof different rationale words. In this paper, we propose two novel auxiliary\nloss functions to make better use of distantly-labeled rationales, which\nencourage models to maintain their focus on important words beyond labeled\nrationales (PINs) and alleviate redundant training on non-helpful rationales\n(NoIRs). Experiments on two representative classification tasks show that our\nproposed methods can push a classification model to effectively learn crucial\nclues from non-perfect rationales while maintaining the ability to spread its\nfocus to other unlabeled important words, thus significantly outperform\nexisting methods.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Quzhe Huang",
      "Shengqi Zhu",
      "Yansong Feng",
      "Dongyan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01809"
  },
  {
    "id": "arXiv:2106.01810",
    "title": "Defending against Backdoor Attacks in Natural Language Generation",
    "abstract": "The frustratingly fragile nature of neural network models make current\nnatural language generation (NLG) systems prone to backdoor attacks and\ngenerate malicious sequences that could be sexist or offensive. Unfortunately,\nlittle effort has been invested to how backdoor attacks can affect current NLG\nmodels and how to defend against these attacks. In this work, we investigate\nthis problem on two important NLG tasks, machine translation and dialogue\ngeneration. By giving a formal definition for backdoor attack and defense, and\ndeveloping corresponding benchmarks, we design methods to attack NLG models,\nwhich achieve high attack success to ask NLG models to generate malicious\nsequences. To defend against these attacks, we propose to detect the attack\ntrigger by examining the effect of deleting or replacing certain words on the\ngeneration outputs, which we find successful for certain types of attacks. We\nwill discuss the limitation of this work, and hope this work can raise the\nawareness of backdoor risks concealed in deep NLG systems. (Code and data are\navailable at https://github.com/ShannonAI/backdoor_nlg.)",
    "descriptor": "",
    "authors": [
      "Chun Fan",
      "Xiaoya Li",
      "Yuxian Meng",
      "Xiaofei Sun",
      "Xiang Ao",
      "Fei Wu",
      "Jiwei Li",
      "Tianwei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01810"
  },
  {
    "id": "arXiv:2106.01813",
    "title": "Identification of physical networks through structured polynomial models",
    "abstract": "Physical dynamic networks most commonly consist of interconnections of\nphysical components that can be described by diffusive couplings. These\ndiffusive couplings imply that the cause-effect relationships in the\ninterconnections are symmetric and therefore physical dynamic networks can be\nrepresented by undirected graphs. This paper shows how (prediction error)\nidentification methods developed for polynomial linear time-invariant systems\ncan be configured to consistently identify the parameters and the\ninterconnection structure of (undirected) physical networks. Further, a\nmulti-step least squares (convex) optimization algorithm is developed to solve\nthe nonconvex optimization problem that results from the identification method.",
    "descriptor": "",
    "authors": [
      "E.M.M.",
      "Kivits",
      "Paul M.J. Van den Hof"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01813"
  },
  {
    "id": "arXiv:2106.01822",
    "title": "Capturing Corruption with Hybrid Auctions: Social Welfare Loss in  Multi-Unit Auctions",
    "abstract": "Corruption in auctions is a phenomenon that is theoretically still poorly\nunderstood, despite the fact that it occurs rather frequently in practice. In\nthis paper, we initiate the study of the social welfare loss caused by a\ncorrupt auctioneer, both in the single-item and the multi-unit auction setting.\nIn our model, the auctioneer may collude with the winners of the auction by\nletting them lower their bids in exchange for a fixed fraction $\\gamma$ of the\nsurplus. As it turns out, this setting is equivalent to a $\\gamma$-hybrid\nauction in which the payments are a convex combination (parameterized by\n$\\gamma$) of the first-price and the second-price payments. Our goal is thus to\nobtain a precise understanding of the (robust) price of anarchy of\n$\\gamma$-hybrid auctions. If no further restrictions are imposed on the bids,\nwe prove a bound on the robust POA which is tight (over the entire range of\n$\\gamma$) for the single-item and the multi-unit auction setting. On the other\nhand, if the bids satisfy the no-overbidding assumption a more fine-grained\nlandscape of the price of anarchy emerges, depending on the auction setting and\nthe equilibrium notion. We derive tight bounds for single-item auctions up to\nthe correlated price of anarchy and for the pure price of anarchy in multi-unit\nauctions. These results are complemented by nearly tight bounds on the coarse\ncorrelated price of anarchy in both settings.",
    "descriptor": "",
    "authors": [
      "Andries van Beek",
      "Ruben Brokkelkamp",
      "Guido Sch\u00e4fer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01822"
  },
  {
    "id": "arXiv:2106.01826",
    "title": "Towards a Mathematical Theory of Abstraction",
    "abstract": "While the utility of well-chosen abstractions for understanding and\npredicting the behaviour of complex systems is well appreciated, precisely what\nan abstraction $\\textit{is}$ has so far has largely eluded mathematical\nformalization. In this paper, we aim to set out a mathematical theory of\nabstraction. We provide a precise characterisation of what an abstraction is\nand, perhaps more importantly, suggest how abstractions can be learnt directly\nfrom data both for static datasets and for dynamical systems. We define an\nabstraction to be a small set of `summaries' of a system which can be used to\nanswer a set of queries about the system or its behaviour. The difference\nbetween the ground truth behaviour of the system on the queries and the\nbehaviour of the system predicted only by the abstraction provides a measure of\nthe `leakiness' of the abstraction which can be used as a loss function to\ndirectly learn abstractions from data. Our approach can be considered a\ngeneralization of classical statistics where we are not interested in\nreconstructing `the data' in full, but are instead only concerned with\nanswering a set of arbitrary queries about the data. While highly theoretical,\nour results have deep implications for statistical inference and machine\nlearning and could be used to develop explicit methods for learning precise\nkinds of abstractions directly from data.",
    "descriptor": "\nComments: 03/06/21 initial upload\n",
    "authors": [
      "Beren Millidge"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01826"
  },
  {
    "id": "arXiv:2106.01827",
    "title": "A Computer Program for the Numerical Analysis of Economic Cycles Within  the Framework of the Dubovsky Generalized Model",
    "abstract": "The article proposes a computer program for calculating economic crises\naccording to the generalized mathematical model of S.V. Dubovsky. This model is\nrepresented by a system of ordinary nonlinear differential equations with\nfractional derivatives in the sense of Gerasimov-Caputo with initial\nconditions. Furthermore, according to a numerical algorithm based on an\nexplicit nonlocal finite-difference scheme, oscillograms and phase trajectories\nwere constructed. It is shown that changing the orders of fractional\nderivatives in the model can give rise to various modes, for example, damped\nmodes with a steady-state amplitude. It is concluded that the orders of\nfractional derivatives are responsible for the intensity of the process.",
    "descriptor": "",
    "authors": [
      "Danil Makarov",
      "Roman Parovik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2106.01827"
  },
  {
    "id": "arXiv:2106.01834",
    "title": "Continual Learning in Deep Networks: an Analysis of the Last Layer",
    "abstract": "We study how different output layer types of a deep neural network learn and\nforget in continual learning settings. We describe the three factors affecting\ncatastrophic forgetting in the output layer: (1) weights modifications, (2)\ninterferences, and (3) projection drift. Our goal is to provide more insights\ninto how different types of output layers can address (1) and (2). We also\npropose potential solutions and evaluate them on several benchmarks. We show\nthat the best-performing output layer type depends on the data distribution\ndrifts or the amount of data available. In particular, in some cases where a\nstandard linear layer would fail, it is sufficient to change the\nparametrization and get significantly better performance while still training\nwith SGD. Our results and analysis shed light on the dynamics of the output\nlayer in continual learning scenarios and help select the best-suited output\nlayer for a given scenario.",
    "descriptor": "",
    "authors": [
      "Timoth\u00e9e Lesort",
      "Thomas George",
      "Irina Rish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01834"
  },
  {
    "id": "arXiv:2106.01838",
    "title": "Acoustic-based Object Detection for Pedestrian Using Smartphone",
    "abstract": "Walking while using a smartphone is becoming a major pedestrian safety\nconcern as people may unknowingly bump into various obstacles that could lead\nto severe injuries. In this paper, we propose ObstacleWatch, an acoustic-based\nobstacle collision detection system to improve the safety of pedestrians who\nare engaged in smartphone usage while walking. ObstacleWatch leverages the\nadvanced audio hardware of the smartphone to sense the surrounding obstacles\nand infers fine-grained information about the frontal obstacle for collision\ndetection. In particular, our system emits well-designed inaudible beep signals\nfrom the smartphone built-in speaker and listens to the reflections with the\nstereo recording of the smartphone. By analyzing the reflected signals received\nat two microphones, ObstacleWatch is able to extract fine-grained information\nof the frontal obstacle including the distance, angle, and size for detecting\nthe possible collisions and to alert users. Our experimental evaluation under\ntwo real-world environments with different types of phones and obstacles shows\nthat ObstacleWatch achieves over 92% accuracy in predicting obstacle collisions\nwith distance estimation errors at about 2 cm. Results also show that\nObstacleWatch is robust to different sizes of objects and is compatible with\ndifferent phone models with low energy consumption.",
    "descriptor": "",
    "authors": [
      "Zi Wang",
      "Jie Yang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.01838"
  },
  {
    "id": "arXiv:2106.01840",
    "title": "A Continuous Liveness Detection System for Text-independent Speaker  Verification",
    "abstract": "Voice authentication is drawing increasing attention and becomes an\nattractive alternative to passwords for mobile authentication. Recent advances\nin mobile technology further accelerate the adoption of voice biometrics in an\narray of diverse mobile applications. However, recent studies show that voice\nauthentication is vulnerable to replay attacks, where an adversary can spoof a\nvoice authentication system using a pre-recorded voice sample collected from\nthe victim. In this paper, we propose VoiceLive, a liveness detection system\nfor both text-dependent and text-independent voice authentication on\nsmartphones. VoiceLive detects a live user by leveraging the user's unique\nvocal system and the stereo recording of smartphones. In particular, utilizing\nthe built-in gyroscope, loudspeaker, and microphone, VoiceLive first measures\nthe smartphone's distance and angle from the user, then it captures the\nposition-specific time-difference-of-arrival (TDoA) changes in a sequence of\nphoneme sounds to the two microphones of the phone, and uses such unique TDoA\ndynamic which doesn't exist under replay attacks for liveness detection.\nVoiceLive is practical as it doesn't require additional hardware but\ntwo-channel stereo recording that is supported by virtually all smartphones.\nOur experimental evaluation with 12 participants and different types of phones\nshows that VoiceLive achieves over 99% detection accuracy at around 1% Equal\nError Rate (EER) on the text-dependent system and around 99% accuracy and 2%\nEER on the text-independent one. Results also show that VoiceLive is robust to\ndifferent phone positions, i.e. the user is free to hold the smartphone with\ndistinct distances and angles.",
    "descriptor": "",
    "authors": [
      "Linghan Zhang",
      "Jie Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.01840"
  },
  {
    "id": "arXiv:2106.01842",
    "title": "The dynamic effect of mechanical losses of transmissions on the equation  of motion of legged robots",
    "abstract": "Industrial manipulators do not collapse under their own weight when powered\noff due to the friction in their joints. Although these mechanism are effective\nfor stiff position control of pick-and-place, they are inappropriate for legged\nrobots that must rapidly regulate compliant interactions with the environment.\nHowever, no metric exists to quantify the robot's performance degradation due\nto mechanical losses in the actuators and transmissions. This paper provides a\nfundamental formulation that uses the mechanical efficiency of transmissions to\nquantify the effect of power losses in the mechanical transmissions on the\ndynamics of a whole robotic system. We quantitatively demonstrate the intuitive\nfact that the apparent inertia of the robots increase in the presence of joint\nfriction. We also show that robots that employ high gear ratio and low\nefficiency transmissions can statically sustain more substantial external\nloads. We expect that the framework presented here will provide the fundamental\ntools for designing the next generation of legged robots that can effectively\ninteract with the world.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2011.02506\n",
    "authors": [
      "Youngwoo Sim",
      "Joao Ramos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.01842"
  },
  {
    "id": "arXiv:2106.01847",
    "title": "Towards Cost-Optimal Policies for DAGs to Utilize IaaS Clouds with  Online Learning",
    "abstract": "Premier cloud service providers (CSPs) offer two types of purchase options,\nnamely on-demand and spot instances, with time-varying features in availability\nand price. Users like startups have to operate on a limited budget and\nsimilarly others hope to reduce their costs. While interacting with a CSP,\ncentral to their concerns is the process of cost-effectively utilizing\ndifferent purchase options possibly in addition to self-owned instances. A job\nin data-intensive applications is typically represented by a directed acyclic\ngraph which can further be transformed into a chain of tasks. The key to\nachieving cost efficiency is determining the allocation of a specific deadline\nto each task, as well as the allocation of different types of instances to the\ntask. In this paper, we propose a framework that determines the optimal\nallocation of deadlines to tasks. The framework also features an optimal policy\nto determine the allocation of spot and on-demand instances in a predefined\ntime window, and a near-optimal policy for allocating self-owned instances. The\npolicies are designed to be parametric to support the usage of online learning\nto infer the optimal values against the dynamics of cloud markets. Finally,\nseveral intuitive heuristics are used as baselines to validate the cost\nimprovement brought by the proposed solutions. We show that the cost\nimprovement over the state-of-the-art is up to 24.87% when spot and on-demand\ninstances are considered and up to 59.05% when self-owned instances are\nconsidered.",
    "descriptor": "",
    "authors": [
      "Xiaohu Wu",
      "Han Yu",
      "Giuliano Casale",
      "Guanyu Gao"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2106.01847"
  },
  {
    "id": "arXiv:2106.01850",
    "title": "Relational Analysis of Sensor Attacks on Cyber-Physical Systems",
    "abstract": "Cyber-physical systems, such as self-driving cars or autonomous aircraft,\nmust defend against attacks that target sensor hardware. Analyzing system\ndesign can help engineers understand how a compromised sensor could impact the\nsystem's behavior; however, designing security analyses for cyber-physical\nsystems is difficult due to their combination of discrete dynamics, continuous\ndynamics, and nondeterminism.\nThis paper contributes a framework for modeling and analyzing sensor attacks\non cyber-physical systems, using the formalism of hybrid programs. We formalize\nand analyze two relational properties of a system's robustness. These\nrelational properties respectively express (1) whether a system's safety\nproperty can be influenced by sensor attacks, and (2) whether a system's\nhigh-integrity state can be affected by sensor attacks. We characterize these\nrelational properties by defining an equivalence relation between a system\nunder attack and the original unattacked system. That is, the system satisfies\nthe robustness properties if executions of the attacked system are\nappropriately related to executions of the unattacked system.\nWe present two techniques for reasoning about the equivalence relation and\nthus proving the relational properties for a system. One proof technique\ndecomposes large proof obligations to smaller proof obligations. The other\nproof technique adapts the self-composition technique from the literature on\nsecure information-flow, allowing us to reduce reasoning about the equivalence\nof two systems to reasoning about properties of a single system. This technique\nallows us to reuse existing tools for reasoning about properties of hybrid\nprograms, but is challenging due to the combination of discrete dynamics,\ncontinuous dynamics, and nondeterminism.\nTo evaluate, we present three case studies motivated by real design flaws in\nexisting cyber-physical systems.",
    "descriptor": "\nComments: This is an extended version of the paper with the same title that appeared in the 2021 Computer Security Foundations Symposium\n",
    "authors": [
      "Jian Xiang",
      "Nathan Fulton",
      "Stephen Chong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.01850"
  },
  {
    "id": "arXiv:2106.01853",
    "title": "On the Computation of the Algebraic Closure of Finitely Generated Groups  of Matrices",
    "abstract": "We investigate the complexity of computing the Zariski closure of a finitely\ngenerated group of matrices. The Zariski closure was previously shown to be\ncomputable by Derksen, Jeandel and Koiran, but the termination argument for\ntheir algorithm appears not to yield any complexity bound. In this paper we\nfollow a different approach and obtain a bound on the degree of the polynomials\nthat define the closure. Our bound shows that the closure can be computed in\nelementary time. We describe several applications of this result, e.g.,\nconcerning quantum automata and quantum universal gates. We also obtain an\nupper bound on the length of a strictly increasing chain of linear algebraic\ngroups, all of which are generated over a fixed number field.",
    "descriptor": "",
    "authors": [
      "Klara Nosan",
      "Amaury Pouly",
      "Mahsa Shirmohammadi",
      "James Worrell"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.01853"
  },
  {
    "id": "arXiv:2106.01854",
    "title": "Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement  Learning",
    "abstract": "Large sparse linear systems of equations are ubiquitous in science and\nengineering, such as those arising from discretizations of partial differential\nequations. Algebraic multigrid (AMG) methods are one of the most common methods\nof solving such linear systems, with an extensive body of underlying\nmathematical theory. A system of linear equations defines a graph on the set of\nunknowns and each level of a multigrid solver requires the selection of an\nappropriate coarse graph along with restriction and interpolation operators\nthat map to and from the coarse representation. The efficiency of the multigrid\nsolver depends critically on this selection and many selection methods have\nbeen developed over the years. Recently, it has been demonstrated that it is\npossible to directly learn the AMG interpolation and restriction operators,\ngiven a coarse graph selection. In this paper, we consider the complementary\nproblem of learning to coarsen graphs for a multigrid solver. We propose a\nmethod using a reinforcement learning (RL) agent based on graph neural networks\n(GNNs), which can learn to perform graph coarsening on small training graphs\nand then be applied to unstructured large graphs. We demonstrate that this\nmethod can produce better coarse graphs than existing algorithms, even as the\ngraph size increases and other properties of the graph are varied. We also\npropose an efficient inference procedure for performing graph coarsening that\nresults in linear time complexity in graph size.",
    "descriptor": "",
    "authors": [
      "Ali Taghibakhshi",
      "Scott MacLachlan",
      "Luke Olson",
      "Matthew West"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01854"
  },
  {
    "id": "arXiv:2106.01862",
    "title": "Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural  Networks",
    "abstract": "Neuromorphic sensing and computing hold a promise for highly energy-efficient\nand high-bandwidth-sensor processing. A major challenge for neuromorphic\ncomputing is that learning algorithms for traditional artificial neural\nnetworks (ANNs) do not transfer directly to spiking neural networks (SNNs) due\nto the discrete spikes and more complex neuronal dynamics. As a consequence,\nSNNs have not yet been successfully applied to complex, large-scale tasks. In\nthis article, we focus on the self-supervised learning problem of optical flow\nestimation from event-based camera inputs, and investigate the changes that are\nnecessary to the state-of-the-art ANN training pipeline in order to\nsuccessfully tackle it with SNNs. More specifically, we first modify the input\nevent representation to encode a much smaller time slice with minimal explicit\ntemporal information. Consequently, we make the network's neuronal dynamics and\nrecurrent connections responsible for integrating information over time.\nMoreover, we reformulate the self-supervised loss function for event-based\noptical flow to improve its convexity. We perform experiments with various\ntypes of recurrent ANNs and SNNs using the proposed pipeline. Concerning SNNs,\nwe investigate the effects of elements such as parameter initialization and\noptimization, surrogate gradient shape, and adaptive neuronal mechanisms. We\nfind that initialization and surrogate gradient width play a crucial part in\nenabling learning with sparse inputs, while the inclusion of adaptivity and\nlearnable neuronal parameters can improve performance. We show that the\nperformance of the proposed ANNs and SNNs are on par with that of the current\nstate-of-the-art ANNs trained in a self-supervised manner.",
    "descriptor": "",
    "authors": [
      "Federico Paredes-Vall\u00e9s",
      "Jesse Hagenaars",
      "Guido de Croon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01862"
  },
  {
    "id": "arXiv:2106.01863",
    "title": "Robust Reference-based Super-Resolution via C2-Matching",
    "abstract": "Reference-based Super-Resolution (Ref-SR) has recently emerged as a promising\nparadigm to enhance a low-resolution (LR) input image by introducing an\nadditional high-resolution (HR) reference image. Existing Ref-SR methods mostly\nrely on implicit correspondence matching to borrow HR textures from reference\nimages to compensate for the information loss in input images. However,\nperforming local transfer is difficult because of two gaps between input and\nreference images: the transformation gap (e.g. scale and rotation) and the\nresolution gap (e.g. HR and LR). To tackle these challenges, we propose\nC2-Matching in this work, which produces explicit robust matching crossing\ntransformation and resolution. 1) For the transformation gap, we propose a\ncontrastive correspondence network, which learns transformation-robust\ncorrespondences using augmented views of the input image. 2) For the resolution\ngap, we adopt a teacher-student correlation distillation, which distills\nknowledge from the easier HR-HR matching to guide the more ambiguous LR-HR\nmatching. 3) Finally, we design a dynamic aggregation module to address the\npotential misalignment issue. In addition, to faithfully evaluate the\nperformance of Ref-SR under a realistic setting, we contribute the\nWebly-Referenced SR (WR-SR) dataset, mimicking the practical usage scenario.\nExtensive experiments demonstrate that our proposed C2-Matching significantly\noutperforms state of the arts by over 1dB on the standard CUFED5 benchmark.\nNotably, it also shows great generalizability on WR-SR dataset as well as\nrobustness across large scale and rotation transformations.",
    "descriptor": "\nComments: To appear in CVPR2021. The source code is available at this https URL\n",
    "authors": [
      "Yuming Jiang",
      "Kelvin C.K. Chan",
      "Xintao Wang",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.01863"
  },
  {
    "id": "arXiv:2106.01865",
    "title": "Heart Sound Classification Considering Additive Noise and Convolutional  Distortion",
    "abstract": "Cardiac auscultation is an essential point-of-care method used for the early\ndiagnosis of heart diseases. Automatic analysis of heart sounds for abnormality\ndetection is faced with the challenges of additive noise and sensor-dependent\ndegradation. This paper aims to develop methods to address the cardiac\nabnormality detection problem when both types of distortions are present in the\ncardiac auscultation sound. We first mathematically analyze the effect of\nadditive and convolutional noise on short-term filterbank-based features and a\nConvolutional Neural Network (CNN) layer. Based on the analysis, we propose a\ncombination of linear and logarithmic spectrogram-image features. These 2D\nfeatures are provided as input to a residual CNN network (ResNet) for heart\nsound abnormality detection. Experimental validation is performed on an\nopen-access heart sound abnormality detection dataset involving noisy\nrecordings obtained from multiple stethoscope sensors. The proposed method\nachieves significantly improved results compared to the conventional\napproaches, with an area under the ROC (receiver operating characteristics)\ncurve (AUC) of 91.36%, F-1 score of 84.09%, and Macc (mean of sensitivity and\nspecificity) of 85.08%. We also show that the proposed method shows the best\nmean accuracy across different source domains including stethoscope and noise\nvariability, demonstrating its effectiveness in different recording conditions.\nThe proposed combination of linear and logarithmic features along with the\nResNet classifier effectively minimizes the impact of background noise and\nsensor variability for classifying phonocardiogram (PCG) signals. The proposed\nmethod paves the way towards developing computer-aided cardiac auscultation\nsystems in noisy environments using low-cost stethoscopes.",
    "descriptor": "",
    "authors": [
      "Farhat Binte Azam",
      "Md. Istiaq Ansari",
      "Ian Mclane",
      "Taufiq Hasan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.01865"
  },
  {
    "id": "arXiv:2106.01866",
    "title": "Simultaneous Multi-View Object Recognition and Grasping in Open-Ended  Domains",
    "abstract": "A robot working in human-centric environments needs to know which kind of\nobjects exist in the scene, where they are, and how to grasp and manipulate\nvarious objects in different situations to help humans in everyday tasks.\nTherefore, object recognition and grasping are two key functionalities for such\nrobots. Most state-of-the-art tackles object recognition and grasping as two\nseparate problems while both use visual input. Furthermore, the knowledge of\nthe robot is fixed after the training phase. In such cases, if the robot faces\nnew object categories, it must retrain from scratch to incorporate new\ninformation without catastrophic interference. To address this problem, we\npropose a deep learning architecture with augmented memory capacities to handle\nopen-ended object recognition and grasping simultaneously. In particular, our\napproach takes multi-views of an object as input and jointly estimates\npixel-wise grasp configuration as well as a deep scale- and rotation-invariant\nrepresentation as outputs. The obtained representation is then used for\nopen-ended object recognition through a meta-active learning technique. We\ndemonstrate the ability of our approach to grasp never-seen-before objects and\nto rapidly learn new object categories using very few examples on-site in both\nsimulation and real-world settings.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.10997\n",
    "authors": [
      "Hamidreza Kasaei",
      "Sha Luo",
      "Remo Sasso",
      "Mohammadreza Kasaei"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01866"
  },
  {
    "id": "arXiv:2106.01870",
    "title": "Maximizing Extractable Value from Automated Market Makers",
    "abstract": "Automated Market Makers (AMMs) are decentralized applications that allow\nusers to exchange crypto-tokens without the need to find a matching exchange\norder. AMMs are one of the most successful DeFi use case so far, as the main\nAMM platforms UniSwap and Balancer process a daily volume of transactions worth\nbillions of dollars. Despite this success story, AMMs are well-known to suffer\nfrom transaction-ordering issues: indeed, adversaries can frontrun user\ntransactions to increase their gain to the detriment of honest users. Being\nspecifically designated to arrange user transactions into blocks, miners can\neasily play the role of adversary, by suitably selecting and ordering\ntransactions - and possibly inserting their own - to increase their gain. In\nthis paper we formally characterize rational miners as players which follow an\noptimal strategy in the mining game. We identify relevant variants of the game,\ncorresponding to specific real-world constraints that a miner might have. We\ndevise effective procedures to construct solutions to mining game, both in its\nmost general form and in some relevant variants. Most notably, miners can\nexploit these solutions to maximize the value extracted from user transactions.",
    "descriptor": "\nComments: 12 pages. Under submission\n",
    "authors": [
      "Massimo Bartoletti",
      "James Hsin-yu Chiang",
      "Alberto Lluch-Lafuente"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01870"
  },
  {
    "id": "arXiv:2106.01871",
    "title": "Short-term Maintenance Planning of Autonomous Trucks for Minimizing  Economic Risk",
    "abstract": "New autonomous driving technologies are emerging every day and some of them\nhave been commercially applied in the real world. While benefiting from these\ntechnologies, autonomous trucks are facing new challenges in short-term\nmaintenance planning, which directly influences the truck operator's profit. In\nthis paper, we implement a vehicle health management system by addressing the\nmaintenance planning issues of autonomous trucks on a transport mission. We\nalso present a maintenance planning model using a risk-based decision-making\nmethod, which identifies the maintenance decision with minimal economic risk of\nthe truck company. Both availability losses and maintenance costs are\nconsidered when evaluating the economic risk. We demonstrate the proposed model\nby numerical experiments illustrating real-world scenarios. In the experiments,\ncompared to three baseline methods, the expected economic risk of the proposed\nmethod is reduced by up to $47\\%$. We also conduct sensitivity analyses of\ndifferent model parameters. The analyses show that the economic risk\nsignificantly decreases when the estimation accuracy of remaining useful life,\nthe maximal allowed time of delivery delay before order cancellation, or the\nnumber of workshops increases. The experiment results contribute to identifying\nfuture research and development attentions of autonomous trucks from an\neconomic perspective.",
    "descriptor": "\nComments: 22 pages, 13 figures, journal, submitted to Reliability Engineering & System Safety, under review\n",
    "authors": [
      "Xin Tao",
      "Jonas M\u00e5rtensson",
      "H\u00e5kan Warnquist",
      "Anna Pernest\u00e5l"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01871"
  },
  {
    "id": "arXiv:2106.01872",
    "title": "Symmetry-preserving enforcement of low-dissipation method based on  boundary variation diminishing principle",
    "abstract": "A class of high-order shock-capturing schemes, P$_n$T$_m$-BVD (Deng et al.,\nJ. Comp. Phys., 386:323-349, 2019; Comput. & Fluids, 200:104433, 2020.)\nschemes, have been devised to solve the Euler equations with substantially\nreduced numerical dissipation, which enable high-resolution simulations to\nresolve flow structures of wider range scales. In such simulations with low\ndissipation, errors of round-off level might grow and contaminate the numerical\nsolutions. A typical example of such problems is the loss of symmetry in the\nnumerical solutions for physical problems of symmetric configurations even if\nthe schemes are mathematically in line with the symmetry rules. In this study,\nthe mechanisms of symmetry-breaking in a finite volume framework with the\nP$_4$T$_2$-BVD reconstruction scheme are thoroughly examined. Particular\nattention has been paid to remove the possible causes due to the lack of\nassociativity in floating-point arithmetic which is associated with round-off\nerrors. Modifications and new techniques are proposed to completely remove the\npossible causes for symmetry breaking in different components of the\nP$_4$T$_2$-BVD finite volume solver. Benchmark tests that have symmetric\nsolution structures are used to verify the proposed methods. The numerical\nresults demonstrate the perfect symmetric solution structures.",
    "descriptor": "\nComments: 32 pages, 8 figures\n",
    "authors": [
      "Hiro Wakimura",
      "Shinichi Takagi",
      "Feng Xiao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.01872"
  },
  {
    "id": "arXiv:2106.01880",
    "title": "Component Stability in Low-Space Massively Parallel Computation",
    "abstract": "We study the power and limitations of component-stable algorithms in the\nlow-space model of Massively Parallel Computation (MPC). Recently Ghaffari,\nKuhn and Uitto (FOCS 2019) introduced the class of component-stable low-space\nMPC algorithms, which are, informally, defined as algorithms for which the\noutputs reported by the nodes in different connected components are required to\nbe independent. This very natural notion was introduced to capture most (if not\nall) of the known efficient MPC algorithms to date, and it was the first\ngeneral class of MPC algorithms for which one can show non-trivial conditional\nlower bounds. In this paper we enhance the framework of component-stable\nalgorithms and investigate its effect on the complexity of randomized and\ndeterministic low-space MPC. Our key contributions include:\n1) We revise and formalize the lifting approach of Ghaffari, Kuhn and Uitto.\nThis requires a very delicate amendment of the notion of component stability,\nwhich allows us to fill in gaps in the earlier arguments.\n2) We also extend the framework to obtain conditional lower bounds for\ndeterministic algorithms and fine-grained lower bounds that depend on the\nmaximum degree $\\Delta$.\n3) We demonstrate a collection of natural graph problems for which\nnon-component-stable algorithms break the conditional lower bound obtained for\ncomponent-stable algorithms. This implies that, for both deterministic and\nrandomized algorithms, component-stable algorithms are conditionally weaker\nthan the non-component-stable ones.\nAltogether our results imply that component-stability might limit the\ncomputational power of the low-space MPC model, at least in certain contexts,\npaving the way for improved upper bounds that escape the conditional lower\nbound setting of Ghaffari, Kuhn, and Uitto.",
    "descriptor": "\nComments: 45 pages, to appear at PODC 2021\n",
    "authors": [
      "Artur Czumaj",
      "Peter Davies",
      "Merav Parter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.01880"
  },
  {
    "id": "arXiv:2106.01883",
    "title": "Learning High-Precision Bounding Box for Rotated Object Detection via  Kullback-Leibler Divergence",
    "abstract": "Existing rotated object detectors are mostly inherited from the horizontal\ndetection paradigm, as the latter has evolved into a well-developed area.\nHowever, these detectors are difficult to perform prominently in high-precision\ndetection due to the limitation of current regression loss design, especially\nfor objects with large aspect ratios. Taking the perspective that horizontal\ndetection is a special case for rotated object detection, in this paper, we are\nmotivated to change the design of rotation regression loss from induction\nparadigm to deduction methodology, in terms of the relation between rotation\nand horizontal detection. We show that one essential challenge is how to\nmodulate the coupled parameters in the rotation regression loss, as such the\nestimated parameters can influence to each other during the dynamic joint\noptimization, in an adaptive and synergetic way. Specifically, we first convert\nthe rotated bounding box into a 2-D Gaussian distribution, and then calculate\nthe Kullback-Leibler Divergence (KLD) between the Gaussian distributions as the\nregression loss. By analyzing the gradient of each parameter, we show that KLD\n(and its derivatives) can dynamically adjust the parameter gradients according\nto the characteristics of the object. It will adjust the importance (gradient\nweight) of the angle parameter according to the aspect ratio. This mechanism\ncan be vital for high-precision detection as a slight angle error would cause a\nserious accuracy drop for large aspect ratios objects. More importantly, we\nhave proved that KLD is scale invariant. We further show that the KLD loss can\nbe degenerated into the popular $l_{n}$-norm loss for horizontal detection.\nExperimental results on seven datasets using different detectors show its\nconsistent superiority, and codes are available at\nhttps://github.com/yangxue0827/RotationDetection.",
    "descriptor": "\nComments: 14 pages, 3 figures, 7 tables\n",
    "authors": [
      "Xue Yang",
      "Xiaojiang Yang",
      "Jirui Yang",
      "Qi Ming",
      "Wentao Wang",
      "Qi Tian",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01883"
  },
  {
    "id": "arXiv:2106.01885",
    "title": "How does Software Change?",
    "abstract": "Software evolves with changes to its codebase over time. Internally, software\nchanges in response to decisions to include some code change into the codebase\nand discard others. Explaining the mechanism of software evolution, this paper\npresents a theory of software change. Our theory is grounded in multiple\nevidence sources (e.g., GitHub documentation and relevant scientific\nliterature) relating to the pull-based development model in GitHub. The\nresulting theory explains the influence of project-related core concepts (e.g.,\npeople and governance) as well as its ecosystem on the decision of software\nchange.",
    "descriptor": "",
    "authors": [
      "Ayushi Rastogi",
      "Georgios Gousios"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.01885"
  },
  {
    "id": "arXiv:2106.01890",
    "title": "SimCLS: A Simple Framework for Contrastive Learning of Abstractive  Summarization",
    "abstract": "In this paper, we present a conceptually simple while empirically powerful\nframework for abstractive summarization, SimCLS, which can bridge the gap\nbetween the learning objective and evaluation metrics resulting from the\ncurrently dominated sequence-to-sequence learning framework by formulating text\ngeneration as a reference-free evaluation problem (i.e., quality estimation)\nassisted by contrastive learning. Experimental results show that, with minor\nmodification over existing top-scoring systems, SimCLS can improve the\nperformance of existing top-performing models by a large margin. Particularly,\n2.51 absolute improvement against BART and 2.50 over PEGASUS w.r.t ROUGE-1 on\nthe CNN/DailyMail dataset, driving the state-of-the-art performance to a new\nlevel. We have open-sourced our codes and results:\nhttps://github.com/yixinL7/SimCLS. Results of our proposed models have been\ndeployed into ExplainaBoard platform, which allows researchers to understand\nour systems in a more fine-grained way.",
    "descriptor": "\nComments: Published as a short paper at ACL 2021\n",
    "authors": [
      "Yixin Liu",
      "Pengfei Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01890"
  },
  {
    "id": "arXiv:2106.01893",
    "title": "Worst-Case Pointing Performance Analysis for Large Flexible Spacecraft",
    "abstract": "This paper presents a tool, PELIB, developed in MATLAB /SIMULINK environment\nto perform pointing performance analysis based on European pointing standards.\nPELIB is designed as an extension of the Satellite Dynamics Toolbox (SDT),\nwhich derives the Linear Fractional Transformation (LFT) models of flexible\nspace structures. The addition of PELIB will allow the users of SDT to perform\npointing performance analysis of real mission scenarios in the same environment\nused for control synthesis. PELIB offers as well the possibility to take into\naccount uncertainties in the system. This feature represents an enhancement to\nthe current verification tools available in the European space industry\ncommunity by providing the worst-case pointing budget. The capabilities of\nPELIB were demonstrated in a case study involving a spacecraft model with two\nflexible solar arrays. Several error sources, as well as uncertain parameters,\nwere included in this model. The nominal performance has been investigated\nusing PELIB and compared with the current European reference tool. The\nworst-case performance is also investigated with the new feature of PELIB to\nobtain the worst-case performance budget",
    "descriptor": "",
    "authors": [
      "Ilham Courie",
      "Francesco Sanfedino",
      "Daniel Alazard"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01893"
  },
  {
    "id": "arXiv:2106.01894",
    "title": "Low-Congestion Shortcuts in Constant Diameter Graphs",
    "abstract": "Low congestion shortcuts, introduced by Ghaffari and Haeupler (SODA 2016),\nprovide a unified framework for global optimization problems in the congest\nmodel of distributed computing. Roughly speaking, for a given graph $G$ and a\ncollection of vertex-disjoint connected subsets $S_1,\\ldots, S_\\ell \\subseteq\nV(G)$, $(c,d)$ low-congestion shortcuts augment each subgraph $G[S_i]$ with a\nsubgraph $H_i \\subseteq G$ such that: (i) each edge appears on at most $c$\nsubgraphs (congestion bound), and (ii) the diameter of each subgraph $G[S_i]\n\\cup H_i$ is bounded by $d$ (dilation bound). It is desirable to compute\nshortcuts of small congestion and dilation as these quantities capture the\nround complexity of many global optimization problems in the congest model. For\n$n$-vertex graphs with constant diameter $D=O(1)$, Das-Sarma et al. (STOC 2011,\nSIAM J. Comput. 2012) presented an (implicit) shortcuts lower bound with (As\nusual, $\\tilde{O}()$ and $\\tilde{\\Omega}()$ hide poly-logarithmic factors.)\n$c+d=\\widetilde{\\Omega}(n^{(D-2)/(2D-2)})$. A nearly matching upper bound,\nhowever, was only recently obtained for $D \\in \\{3,4\\}$ by Kitamura et al.\n(DISC 2019).\nIn this work, we resolve the long-standing complexity gap of shortcuts in\nconstant diameter graphs, originally posed by Lotker et al. (PODC 2001). We\npresent new shortcut constructions which match, up to poly-logarithmic terms,\nthe lower bounds of Das-Sarma et al. As a result, we provide improved and\nexistentially optimal algorithms for several network optimization tasks in\nconstant diameter graphs, including MST, $(1+\\epsilon)$-approximate minimum\ncuts and more.",
    "descriptor": "\nComments: To appear in PODC 2021\n",
    "authors": [
      "Shimon Kogan",
      "Merav Parter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.01894"
  },
  {
    "id": "arXiv:2106.01895",
    "title": "Three-agent Time-constrained Cooperative Pursuit-Evasion",
    "abstract": "This paper considers a pursuit-evasion scenario among three agents -- an\nevader, a pursuer, and a defender. We design cooperative guidance laws for the\nevader and the defender team to safeguard the evader from an attacking pursuer.\nUnlike differential games, optimal control formulations, and other heuristic\nmethods, we propose a novel perspective on designing effective nonlinear\nfeedback control laws for the evader-defender team using a time-constrained\nguidance approach. The evader lures the pursuer on the collision course by\noffering itself as bait. At the same time, the defender protects the evader\nfrom the pursuer by exercising control over the engagement duration. Depending\non the nature of the mission, the defender may choose to take an aggressive or\ndefensive stance. Such consideration widens the applicability of the proposed\nmethods in various three-agent motion planning scenarios such as aircraft\ndefense, asset guarding, search and rescue, surveillance, and secure\ntransportation. We use a fixed-time sliding mode control strategy to design the\ncontrol laws for the evader-defender team and a nonlinear finite-time\ndisturbance observer to estimate the pursuer's maneuver. Finally, we present\nsimulations to demonstrate favorable performance under various engagement\ngeometries, thus vindicating the efficacy of the proposed designs.",
    "descriptor": "",
    "authors": [
      "Abhinav Sinha",
      "Shashi Ranjan Kumar",
      "Dwaipayan Mukherjee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.01895"
  },
  {
    "id": "arXiv:2106.01899",
    "title": "Adversarially Adaptive Normalization for Single Domain Generalization",
    "abstract": "Single domain generalization aims to learn a model that performs well on many\nunseen domains with only one domain data for training. Existing works focus on\nstudying the adversarial domain augmentation (ADA) to improve the model's\ngeneralization capability. The impact on domain generalization of the\nstatistics of normalization layers is still underinvestigated. In this paper,\nwe propose a generic normalization approach, adaptive standardization and\nrescaling normalization (ASR-Norm), to complement the missing part in previous\nworks. ASR-Norm learns both the standardization and rescaling statistics via\nneural networks. This new form of normalization can be viewed as a generic form\nof the traditional normalizations. When trained with ADA, the statistics in\nASR-Norm are learned to be adaptive to the data coming from different domains,\nand hence improves the model generalization performance across domains,\nespecially on the target domain with large discrepancy from the source domain.\nThe experimental results show that ASR-Norm can bring consistent improvement to\nthe state-of-the-art ADA approaches by 1.6%, 2.7%, and 6.3% averagely on the\nDigits, CIFAR-10-C, and PACS benchmarks, respectively. As a generic tool, the\nimprovement introduced by ASR-Norm is agnostic to the choice of ADA methods.",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Xinjie Fan",
      "Qifei Wang",
      "Junjie Ke",
      "Feng Yang",
      "Boqing Gong",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01899"
  },
  {
    "id": "arXiv:2106.01900",
    "title": "Salp Swarm Optimization: a Critical Review",
    "abstract": "In the crowded environment of bio-inspired population-based meta-heuristics,\nthe Salp Swarm Optimization (SSO) algorithm recently appeared and immediately\ngained a lot of momentum. Inspired by the peculiar spatial arrangement of salp\ncolonies, which are displaced in long chains following a leader, this algorithm\nseems to provide interesting optimization performances. However, the original\nwork was characterized by some conceptual and mathematical flaws, which\ninfluenced all ensuing papers on the subject. In this manuscript, we perform a\ncritical review of SSO, highlighting all the issues present in the literature\nand their negative effects on the optimization process carried out by the\nalgorithm. We also propose a mathematically correct version of SSO, named\nAmended Salp Swarm Optimizer (ASSO) that fixes all the discussed problems.\nFinally, we benchmark the performance of ASSO on a set of tailored experiments,\nshowing it achieves better results than the original SSO.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Mauro Castelli",
      "Luca Manzoni",
      "Luca Mariot",
      "Marco S. Nobile",
      "Andrea Tangherloni"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01900"
  },
  {
    "id": "arXiv:2106.01901",
    "title": "Iterative Empirical Game Solving via Single Policy Best Response",
    "abstract": "Policy-Space Response Oracles (PSRO) is a general algorithmic framework for\nlearning policies in multiagent systems by interleaving empirical game analysis\nwith deep reinforcement learning (Deep RL). At each iteration, Deep RL is\ninvoked to train a best response to a mixture of opponent policies. The\nrepeated application of Deep RL poses an expensive computational burden as we\nlook to apply this algorithm to more complex domains. We introduce two\nvariations of PSRO designed to reduce the amount of simulation required during\nDeep RL training. Both algorithms modify how PSRO adds new policies to the\nempirical game, based on learned responses to a single opponent policy. The\nfirst, Mixed-Oracles, transfers knowledge from previous iterations of Deep RL,\nrequiring training only against the opponent's newest policy. The second,\nMixed-Opponents, constructs a pure-strategy opponent by mixing existing\nstrategy's action-value estimates, instead of their policies. Learning against\na single policy mitigates variance in state outcomes that is induced by an\nunobserved distribution of opponents. We empirically demonstrate that these\nalgorithms substantially reduce the amount of simulation during training\nrequired by PSRO, while producing equivalent or better solutions to the game.",
    "descriptor": "",
    "authors": [
      "Max Olan Smith",
      "Thomas Anthony",
      "Michael P. Wellman"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.01901"
  },
  {
    "id": "arXiv:2106.01904",
    "title": "Representing Syntax and Composition with Geometric Transformations",
    "abstract": "The exploitation of syntactic graphs (SyGs) as a word's context has been\nshown to be beneficial for distributional semantic models (DSMs), both at the\nlevel of individual word representations and in deriving phrasal\nrepresentations via composition. However, notwithstanding the potential\nperformance benefit, the syntactically-aware DSMs proposed to date have huge\nnumbers of parameters (compared to conventional DSMs) and suffer from data\nsparsity. Furthermore, the encoding of the SyG links (i.e., the syntactic\nrelations) has been largely limited to linear maps. The knowledge graphs'\nliterature, on the other hand, has proposed light-weight models employing\ndifferent geometric transformations (GTs) to encode edges in a knowledge graph\n(KG). Our work explores the possibility of adopting this family of models to\nencode SyGs. Furthermore, we investigate which GT better encodes syntactic\nrelations, so that these representations can be used to enhance phrase-level\ncomposition via syntactic contextualisation.",
    "descriptor": "\nComments: to appear in Findings of ACL 2021\n",
    "authors": [
      "Lorenzo Bertolini",
      "Julie Weeds",
      "David Weir",
      "Qiwei Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01904"
  },
  {
    "id": "arXiv:2106.01908",
    "title": "You Never Cluster Alone",
    "abstract": "Recent advances in self-supervised learning with instance-level contrastive\nobjectives facilitate unsupervised clustering. However, a standalone datum is\nnot perceiving the context of the holistic cluster, and may undergo sub-optimal\nassignment. In this paper, we extend the mainstream contrastive learning\nparadigm to a cluster-level scheme, where all the data subjected to the same\ncluster contribute to a unified representation that encodes the context of each\ndata group. Contrastive learning with this representation then rewards the\nassignment of each datum. To implement this vision, we propose twin-contrast\nclustering (TCC). We define a set of categorical variables as clustering\nassignment confidence, which links the instance-level learning track with the\ncluster-level one. On one hand, with the corresponding assignment variables\nbeing the weight, a weighted aggregation along the data points implements the\nset representation of a cluster. We further propose heuristic cluster\naugmentation equivalents to enable cluster-level contrastive learning. On the\nother hand, we derive the evidence lower-bound of the instance-level\ncontrastive objective with the assignments. By reparametrizing the assignment\nvariables, TCC is trained end-to-end, requiring no alternating steps. Extensive\nexperiments show that TCC outperforms the state-of-the-art on challenging\nbenchmarks.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Yuming Shen",
      "Ziyi Shen",
      "Menghan Wang",
      "Jie Qin",
      "Philip H.S. Torr",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01908"
  },
  {
    "id": "arXiv:2106.01917",
    "title": "DeepOpt: Scalable Specification-based Falsification of Neural Networks  using Black-Box Optimization",
    "abstract": "Decisions made by deep neural networks (DNNs) have a tremendous impact on the\ndependability of the systems that they are embedded into, which is of\nparticular concern in the realm of safety-critical systems. In this paper we\nconsider specification-based falsification of DNNs with the aim to support\ndebugging and repair. We propose DeepOpt, a falsification technique based on\nblack-box optimization, which generates counterexamples from a DNN in a\nrefinement loop. DeepOpt can analyze input-output specifications, which makes\nit more general than falsification approaches that only support robustness\nspecifications. The key idea is to algebraically combine the DNN with the input\nand output constraints derived from the specification. We have implemented\nDeepOpt and evaluated it on DNNs of varying sizes and architectures.\nExperimental comparisons demonstrate DeepOpt's precision and scalability; in\nparticular, DeepOpt requires very few queries to the DNN.",
    "descriptor": "",
    "authors": [
      "Fabian Bauer-Marquart",
      "Stefan Leue",
      "Christian Schilling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.01917"
  },
  {
    "id": "arXiv:2106.01920",
    "title": "Convolutional Neural Network(CNN/ConvNet) in Stock Price Movement  Prediction",
    "abstract": "With technological advancements and the exponential growth of data, we have\nbeen unfolding different capabilities of neural networks in different sectors.\nIn this paper, I have tried to use a specific type of Neural Network known as\nConvolutional Neural Network(CNN/ConvNet) in the stock market. In other words,\nI have tried to construct and train a convolutional neural network on past\nstock prices data and then tried to predict the movement of stock price i.e.\nwhether the stock price would rise or fall, in the coming time.",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Kunal Bhardwaj"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01920"
  },
  {
    "id": "arXiv:2106.01925",
    "title": "GL-GIN: Fast and Accurate Non-Autoregressive Model for Joint Multiple  Intent Detection and Slot Filling",
    "abstract": "Multi-intent SLU can handle multiple intents in an utterance, which has\nattracted increasing attention. However, the state-of-the-art joint models\nheavily rely on autoregressive approaches, resulting in two issues: slow\ninference speed and information leakage. In this paper, we explore a\nnon-autoregressive model for joint multiple intent detection and slot filling,\nachieving more fast and accurate. Specifically, we propose a Global-Locally\nGraph Interaction Network (GL-GIN) where a local slot-aware graph interaction\nlayer is proposed to model slot dependency for alleviating uncoordinated slots\nproblem while a global intent-slot graph interaction layer is introduced to\nmodel the interaction between multiple intents and all slots in the utterance.\nExperimental results on two public datasets show that our framework achieves\nstate-of-the-art performance while being 11.5 times faster.",
    "descriptor": "\nComments: Accepted at ACL2021 (main conference)\n",
    "authors": [
      "Libo Qin",
      "Fuxuan Wei",
      "Tianbao Xie",
      "Xiao Xu",
      "Wanxiang Che",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01925"
  },
  {
    "id": "arXiv:2106.01926",
    "title": "A new framework for polynomial approximation to differential equations",
    "abstract": "In this paper we discuss a framework for the polynomial approximation to the\nsolution of initial value problems for differential equations. The framework,\ninitially devised for the approximation of ordinary differential equations, is\nfurther extended to cope with constant delay differential equations. Relevant\nclasses of Runge-Kutta methods can be derived within this framework.",
    "descriptor": "\nComments: 24 pages, 1 figure\n",
    "authors": [
      "Luigi Brugnano",
      "Gianluca Frasca-Caccia",
      "Felice Iavernaro",
      "Vincenzo Vespri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01926"
  },
  {
    "id": "arXiv:2106.01927",
    "title": "A Comparison for Anti-noise Robustness of Deep Learning Classification  Methods on a Tiny Object Image Dataset: from Convolutional Neural Network to  Visual Transformer and Performer",
    "abstract": "Image classification has achieved unprecedented advance with the the rapid\ndevelopment of deep learning. However, the classification of tiny object images\nis still not well investigated. In this paper, we first briefly review the\ndevelopment of Convolutional Neural Network and Visual Transformer in deep\nlearning, and introduce the sources and development of conventional noises and\nadversarial attacks. Then we use various models of Convolutional Neural Network\nand Visual Transformer to conduct a series of experiments on the image dataset\nof tiny objects (sperms and impurities), and compare various evaluation metrics\nin the experimental results to obtain a model with stable performance. Finally,\nwe discuss the problems in the classification of tiny objects and make a\nprospect for the classification of tiny objects in the future.",
    "descriptor": "",
    "authors": [
      "Ao Chen",
      "Chen Li",
      "Haoyuan Chen",
      "Hechen Yang",
      "Peng Zhao",
      "Weiming Hu",
      "Wanli Liu",
      "Shuojia Zou",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01927"
  },
  {
    "id": "arXiv:2106.01939",
    "title": "Graph Intervention Networks for Causal Effect Estimation",
    "abstract": "We address the estimation of conditional average treatment effects (CATEs)\nwhen treatments are graph-structured (e.g., molecular graphs of drugs). Given a\nweak condition on the effect, we propose a plug-in estimator that decomposes\nCATE estimation into separate, simpler optimization problems. Our estimator (a)\nisolates the causal estimands (reducing regularization bias), and (b) allows\none to plug in arbitrary models for learning. In experiments with small-world\nand molecular graphs, we show that our approach outperforms prior approaches\nand is robust to varying selection biases. Our implementation is online.",
    "descriptor": "",
    "authors": [
      "Jean Kaddour",
      "Qi Liu",
      "Yuchen Zhu",
      "Matt J. Kusner",
      "Ricardo Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01939"
  },
  {
    "id": "arXiv:2106.01940",
    "title": "THEMIS: A Decentralized Privacy-Preserving Ad Platform with Reporting  Integrity",
    "abstract": "Online advertising fuels the (seemingly) free internet. However, although\nusers can access most of the web services free of charge, they pay a heavy\ncoston their privacy. They are forced to trust third parties and\nintermediaries, who not only collect behavioral data but also absorb great\namounts of ad revenues. Consequently, more and more users opt out from\nadvertising by resorting to ad blockers, thus costing publishers millions of\ndollars in lost ad revenues. Albeit there are various privacy-preserving\nadvertising proposals (e.g.,Adnostic, Privad, Brave Ads) from both academia and\nindustry, they all rely on centralized management that users have to blindly\ntrust without being able to audit, while they also fail to guarantee the\nintegrity of the per-formance analytics they provide to advertisers.\nIn this paper, we design and deploy THEMIS, a novel, decentralized and\nprivacy-by-design ad platform that requires zero trust by users. THEMIS (i)\nprovides auditability to its participants, (ii) rewards users for viewing ads,\nand (iii) allows advertisers to verify the performance and billing reports of\ntheir ad campaigns. By leveraging smart contracts and zero-knowledge schemes,\nwe implement a prototype of THEMIS and early performance evaluation results\nshow that it can scale linearly on a multi sidechain setup while it supports\nmore than 51M users on a single-sidechain.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2007.05556\n",
    "authors": [
      "Gon\u00e7alo Pestana",
      "I\u00f1igo Querejeta-Azurmendi",
      "Panagiotis Papadopoulos",
      "Benjamin Livshits"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.01940"
  },
  {
    "id": "arXiv:2106.01941",
    "title": "Optimizing Rankings for Recommendation in Matching Markets",
    "abstract": "Based on the success of recommender systems in e-commerce, there is growing\ninterest in their use in matching markets (e.g., labor). While this holds\npotential for improving market fluidity and fairness, we show in this paper\nthat naively applying existing recommender systems to matching markets is\nsub-optimal. Considering the standard process where candidates apply and then\nget evaluated by employers, we present a new recommendation framework to model\nthis interaction mechanism and propose efficient algorithms for computing\npersonalized rankings in this setting. We show that the optimal rankings need\nto not only account for the potentially divergent preferences of candidates and\nemployers, but they also need to account for capacity constraints. This makes\nconventional ranking systems that merely rank by some local score (e.g.,\none-sided or reciprocal relevance) highly sub-optimal -- not only for an\nindividual user, but also for societal goals (e.g., low unemployment). To\naddress this shortcoming, we propose the first method for jointly optimizing\nthe rankings for all candidates in the market to explicitly maximize social\nwelfare. In addition to the theoretical derivation, we evaluate the method both\non simulated environments and on data from a real-world\nnetworking-recommendation system that we built and fielded at a large computer\nscience conference.",
    "descriptor": "",
    "authors": [
      "Yi Su",
      "Magd Bayoumi",
      "Thorsten Joachims"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.01941"
  },
  {
    "id": "arXiv:2106.01950",
    "title": "The Case for Translation-Invariant Self-Attention in Transformer-Based  Language Models",
    "abstract": "Mechanisms for encoding positional information are central for\ntransformer-based language models. In this paper, we analyze the position\nembeddings of existing language models, finding strong evidence of translation\ninvariance, both for the embeddings themselves and for their effect on\nself-attention. The degree of translation invariance increases during training\nand correlates positively with model performance. Our findings lead us to\npropose translation-invariant self-attention (TISA), which accounts for the\nrelative position between tokens in an interpretable fashion without needing\nconventional position embeddings. Our proposal has several theoretical\nadvantages over existing position-representation approaches. Experiments show\nthat it improves on regular ALBERT on GLUE tasks, while only adding orders of\nmagnitude less positional parameters.",
    "descriptor": "\nComments: 11 pages, 8 figures, Accepted to ACL 2021\n",
    "authors": [
      "Ulme Wennberg",
      "Gustav Eje Henter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01950"
  },
  {
    "id": "arXiv:2106.01954",
    "title": "Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2  Benchmark",
    "abstract": "Despite the recent popularity of neural network-based solvers for optimal\ntransport (OT), there is no standard quantitative way to evaluate their\nperformance. In this paper, we address this issue for quadratic-cost transport\n-- specifically, computation of the Wasserstein-2 distance, a commonly-used\nformulation of optimal transport in machine learning. To overcome the challenge\nof computing ground truth transport maps between continuous measures needed to\nassess these solvers, we use input-convex neural networks (ICNN) to construct\npairs of measures whose ground truth OT maps can be obtained analytically. This\nstrategy yields pairs of continuous benchmark measures in high-dimensional\nspaces such as spaces of images. We thoroughly evaluate existing optimal\ntransport solvers using these benchmark measures. Even though these solvers\nperform well in downstream tasks, many do not faithfully recover optimal\ntransport maps. To investigate the cause of this discrepancy, we further test\nthe solvers in a setting of image generation. Our study reveals crucial\nlimitations of existing solvers and shows that increased OT accuracy does not\nnecessarily correlate to better results downstream.",
    "descriptor": "",
    "authors": [
      "Alexander Korotin",
      "Lingxiao Li",
      "Aude Genevay",
      "Justin Solomon",
      "Alexander Filippov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01954"
  },
  {
    "id": "arXiv:2106.01958",
    "title": "Multiplierless MP-Kernel Machine For Energy-efficient Edge Devices",
    "abstract": "We present a novel framework for designing multiplierless kernel machines\nthat can be used on resource-constrained platforms like intelligent edge\ndevices. The framework uses a piecewise linear (PWL) approximation based on a\nmargin propagation (MP) technique and uses only addition/subtraction, shift,\ncomparison, and register underflow/overflow operations. We propose a\nhardware-friendly MP-based inference and online training algorithm that has\nbeen optimized for a Field Programmable Gate Array (FPGA) platform. Our FPGA\nimplementation eliminates the need for DSP units and reduces the number of\nLUTs. By reusing the same hardware for inference and training, we show that the\nplatform can overcome classification errors and local minima artifacts that\nresult from the MP approximation. Using the FPGA platform, we also show that\nthe proposed multiplierless MP-kernel machine demonstrates superior performance\nin terms of power, performance, and area compared to other comparable\nimplementations.",
    "descriptor": "",
    "authors": [
      "Abhishek Ramdas Nair",
      "Pallab Kumar Nath",
      "Shantanu Chakrabartty",
      "Chetan Singh Thakur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.01958"
  },
  {
    "id": "arXiv:2106.01960",
    "title": "LyricJam: A system for generating lyrics for live instrumental music",
    "abstract": "We describe a real-time system that receives a live audio stream from a jam\nsession and generates lyric lines that are congruent with the live music being\nplayed. Two novel approaches are proposed to align the learned latent spaces of\naudio and text representations that allow the system to generate novel lyric\nlines matching live instrumental music. One approach is based on adversarial\nalignment of latent representations of audio and lyrics, while the other\napproach learns to transfer the topology from the music latent space to the\nlyric latent space. A user study with music artists using the system showed\nthat the system was useful not only in lyric composition, but also encouraged\nthe artists to improvise and find new musical expressions. Another user study\ndemonstrated that users preferred the lines generated using the proposed\nmethods to the lines generated by a baseline model.",
    "descriptor": "\nComments: Accepted to International Conference on Computational Creativity (ICCC) 2021 [Oral]\n",
    "authors": [
      "Olga Vechtomova",
      "Gaurav Sahu",
      "Dhruv Kumar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.01960"
  },
  {
    "id": "arXiv:2106.01963",
    "title": "A Survey on Optimal Transport for Machine Learning: Theory and  Applications",
    "abstract": "Optimal Transport (OT) theory has seen an increasing amount of attention from\nthe computer science community due to its potency and relevance in modeling and\nmachine learning. It introduces means that serve as powerful ways to compare\nprobability distributions with each other, as well as producing optimal\nmappings to minimize cost functions. In this survey, we present a brief\nintroduction and history, a survey of previous work and propose directions of\nfuture study. We will begin by looking at the history of optimal transport and\nintroducing the founders of this field. We then give a brief glance into the\nalgorithms related to OT. Then, we will follow up with a mathematical\nformulation and the prerequisites to understand OT. These include Kantorovich\nduality, entropic regularization, KL Divergence, and Wassertein barycenters.\nSince OT is a computationally expensive problem, we then introduce the\nentropy-regularized version of computing optimal mappings, which allowed OT\nproblems to become applicable in a wide range of machine learning problems. In\nfact, the methods generated from OT theory are competitive with the current\nstate-of-the-art methods. We follow this up by breaking down research papers\nthat focus on image processing, graph learning, neural architecture search,\ndocument representation, and domain adaptation. We close the paper with a small\nsection on future research. Of the recommendations presented, three main\nproblems are fundamental to allow OT to become widely applicable but rely\nstrongly on its mathematical formulation and thus are hardest to answer. Since\nOT is a novel method, there is plenty of space for new research, and with more\nand more competitive methods (either on an accuracy level or computational\nspeed level) being created, the future of applied optimal transport is bright\nas it has become pervasive in machine learning.",
    "descriptor": "",
    "authors": [
      "Luis Caicedo Torres",
      "Luiz Manella Pereira",
      "M. Hadi Amini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01963"
  },
  {
    "id": "arXiv:2106.01969",
    "title": "Global Convergence of Multi-Agent Policy Gradient in Markov Potential  Games",
    "abstract": "Potential games are arguably one of the most important and widely studied\nclasses of normal form games. They define the archetypal setting of multi-agent\ncoordination as all agent utilities are perfectly aligned with each other via a\ncommon potential function. Can this intuitive framework be transplanted in the\nsetting of Markov Games? What are the similarities and differences between\nmulti-agent coordination with and without state dependence? We present a novel\ndefinition of Markov Potential Games (MPG) that generalizes prior attempts at\ncapturing complex stateful multi-agent coordination. Counter-intuitively,\ninsights from normal-form potential games do not carry over as MPGs can consist\nof settings where state-games can be zero-sum games. In the opposite direction,\nMarkov games where every state-game is a potential game are not necessarily\nMPGs. Nevertheless, MPGs showcase standard desirable properties such as the\nexistence of deterministic Nash policies. In our main technical result, we\nprove fast convergence of independent policy gradient to Nash policies by\nadapting recent gradient dominance property arguments developed for single\nagent MDPs to multi-agent learning settings.",
    "descriptor": "",
    "authors": [
      "Stefanos Leonardos",
      "Will Overman",
      "Ioannis Panageas",
      "Georgios Piliouras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01969"
  },
  {
    "id": "arXiv:2106.01970",
    "title": "NeRFactor: Neural Factorization of Shape and Reflectance Under an  Unknown Illumination",
    "abstract": "We address the problem of recovering the shape and spatially-varying\nreflectance of an object from posed multi-view images of the object illuminated\nby one unknown lighting condition. This enables the rendering of novel views of\nthe object under arbitrary environment lighting and editing of the object's\nmaterial properties. The key to our approach, which we call Neural Radiance\nFactorization (NeRFactor), is to distill the volumetric geometry of a Neural\nRadiance Field (NeRF) [Mildenhall et al. 2020] representation of the object\ninto a surface representation and then jointly refine the geometry while\nsolving for the spatially-varying reflectance and the environment lighting.\nSpecifically, NeRFactor recovers 3D neural fields of surface normals, light\nvisibility, albedo, and Bidirectional Reflectance Distribution Functions\n(BRDFs) without any supervision, using only a re-rendering loss, simple\nsmoothness priors, and a data-driven BRDF prior learned from real-world BRDF\nmeasurements. By explicitly modeling light visibility, NeRFactor is able to\nseparate shadows from albedo and synthesize realistic soft or hard shadows\nunder arbitrary lighting conditions. NeRFactor is able to recover convincing 3D\nmodels for free-viewpoint relighting in this challenging and underconstrained\ncapture setup for both synthetic and real scenes. Qualitative and quantitative\nexperiments show that NeRFactor outperforms classic and deep learning-based\nstate of the art across various tasks. Our code and data are available at\npeople.csail.mit.edu/xiuming/projects/nerfactor/.",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Xiuming Zhang",
      "Pratul P. Srinivasan",
      "Boyang Deng",
      "Paul Debevec",
      "William T. Freeman",
      "Jonathan T. Barron"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.01970"
  },
  {
    "id": "arXiv:2106.01972",
    "title": "SOCCER: An Information-Sparse Discourse State Tracking Collection in the  Sports Commentary Domain",
    "abstract": "In the pursuit of natural language understanding, there has been a long\nstanding interest in tracking state changes throughout narratives. Impressive\nprogress has been made in modeling the state of transaction-centric dialogues\nand procedural texts. However, this problem has been less intensively studied\nin the realm of general discourse where ground truth descriptions of states may\nbe loosely defined and state changes are less densely distributed over\nutterances. This paper proposes to turn to simplified, fully observable systems\nthat show some of these properties: Sports events. We curated 2,263 soccer\nmatches including time-stamped natural language commentary accompanied by\ndiscrete events such as a team scoring goals, switching players or being\npenalized with cards. We propose a new task formulation where, given paragraphs\nof commentary of a game at different timestamps, the system is asked to\nrecognize the occurrence of in-game events. This domain allows for rich\ndescriptions of state while avoiding the complexities of many other real-world\nsettings. As an initial point of performance measurement, we include two\nbaseline methods from the perspectives of sentence classification with temporal\ndependence and current state-of-the-art generative model, respectively, and\ndemonstrate that even sophisticated existing methods struggle on the state\ntracking task when the definition of state broadens or non-event chatter\nbecomes prevalent.",
    "descriptor": "\nComments: Accepted at NAACL2021\n",
    "authors": [
      "Ruochen Zhang",
      "Carsten Eickhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01972"
  },
  {
    "id": "arXiv:2106.01974",
    "title": "Traversing Steep and Granular Martian Analog Slopes With a Dynamic  Quadrupedal Robot",
    "abstract": "Celestial bodies such as the Moon and Mars are mainly covered by loose,\ngranular soil, a notoriously challenging terrain to traverse with (wheeled)\nrobotic systems. Here, we present experimental work on traversing steep,\ngranular slopes with the dynamically walking quadrupedal robot SpaceBok. To\nadapt to the challenging environment, we developed passive-adaptive planar feet\nand optimized grouser pads to reduce sinkage and increase traction on planar\nand inclined granular soil. Single-foot experiments revealed that a large\nsurface area of 110cm2 per foot reduces sinkage to an acceptable level even on\nhighly collapsible soil (ES-1). Implementing several 12mm grouser blades\nincreases traction by 22% to 66% on granular media compared to grouser-less\ndesigns. Together with a terrain-adapting walking controller, we validate - for\nthe first time - static and dynamic locomotion on Mars analog slopes of up to\n25{\\deg}(the maximum of the testbed). We evaluated the performance between\npoint- and planar feet and static and dynamic gaits regarding stability\n(safety), velocity, and energy consumption. We show that dynamic gaits are\nenergetically more efficient than static gaits but are riskier on steep slopes.\nOur tests also revealed that planar feet's energy consumption drastically\nincreases when the slope inclination approaches the soil's angle of internal\nfriction due to shearing. Point feet are less affected by slippage due to their\nexcessive sinkage, but in turn, are prone to instabilities and tripping. We\npresent and discuss safe and energy-efficient global path-planning strategies\nfor accessing steep topography on Mars based on our findings.",
    "descriptor": "",
    "authors": [
      "Hendrik Kolvenbach",
      "Philip Arm",
      "Elias Hampp",
      "Alexander Dietsche",
      "Valentin Bickel",
      "Benjamin Sun",
      "Christoph Meyer",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.01974"
  },
  {
    "id": "arXiv:2106.01977",
    "title": "Safe RAN control: A Symbolic Reinforcement Learning Approach",
    "abstract": "In this paper, we present a Symbolic Reinforcement Learning (SRL) based\narchitecture for safety control of Radio Access Network (RAN) applications. In\nparticular, we provide a purely automated procedure in which a user can specify\nhigh-level logical safety specifications for a given cellular network topology\nin order for the latter to execute optimal safe performance which is measured\nthrough certain Key Performance Indicators (KPIs). The network consists of a\nset of fixed Base Stations (BS) which are equipped with antennas, which one can\ncontrol by adjusting their vertical tilt angle. The aforementioned process is\ncalled Remote Electrical Tilt (RET) optimization. Recent research has focused\non performing this RET optimization by employing Reinforcement Learning (RL)\nstrategies due to the fact that they have self-learning capabilities to adapt\nin uncertain environments. The term safety refers to particular constraints\nbounds of the network KPIs in order to guarantee that when the algorithms are\ndeployed in a live network, the performance is maintained. In our proposed\narchitecture the safety is ensured through model-checking techniques over\ncombined discrete system models (automata) that are abstracted through the\nlearning process. We introduce a user interface (UI) developed to help a user\nset intent specifications to the system, and inspect the difference in agent\nproposed actions, and those that are allowed and blocked according to the\nsafety specification.",
    "descriptor": "\nComments: Submitted to IEEE Global Communications Conference (GLOBECOM) 2021\n",
    "authors": [
      "Alexandros Nikou",
      "Anusha Mujumdar",
      "Marin Orlic",
      "Aneta Vulgarakis Feljan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01977"
  },
  {
    "id": "arXiv:2106.01978",
    "title": "DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in  Conversations",
    "abstract": "Emotion Recognition in Conversations (ERC) has gained increasing attention\nfor developing empathetic machines. Recently, many approaches have been devoted\nto perceiving conversational context by deep learning models. However, these\napproaches are insufficient in understanding the context due to lacking the\nability to extract and integrate emotional clues. In this work, we propose\nnovel Contextual Reasoning Networks (DialogueCRN) to fully understand the\nconversational context from a cognitive perspective. Inspired by the Cognitive\nTheory of Emotion, we design multi-turn reasoning modules to extract and\nintegrate emotional clues. The reasoning module iteratively performs an\nintuitive retrieving process and a conscious reasoning process, which imitates\nhuman unique cognitive thinking. Extensive experiments on three public\nbenchmark datasets demonstrate the effectiveness and superiority of the\nproposed model.",
    "descriptor": "\nComments: 11 pages, accepted by ACL-IJCNLP 2021 main conference\n",
    "authors": [
      "Dou Hu",
      "Lingwei Wei",
      "Xiaoyong Huai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01978"
  },
  {
    "id": "arXiv:2106.01979",
    "title": "CCPM: A Chinese Classical Poetry Matching Dataset",
    "abstract": "Poetry is one of the most important art forms of human languages. Recently\nmany studies have focused on incorporating some linguistic features of poetry,\nsuch as style and sentiment, into its understanding or generation system.\nHowever, there is no focus on understanding or evaluating the semantics of\npoetry. Therefore, we propose a novel task to assess a model's semantic\nunderstanding of poetry by poem matching. Specifically, this task requires the\nmodel to select one line of Chinese classical poetry among four candidates\naccording to the modern Chinese translation of a line of poetry. To construct\nthis dataset, we first obtain a set of parallel data of Chinese classical\npoetry and modern Chinese translation. Then we retrieve similar lines of poetry\nwith the lines in a poetry corpus as negative choices. We name the dataset\nChinese Classical Poetry Matching Dataset (CCPM) and release it at\nhttps://github.com/THUNLP-AIPoet/CCPM. We hope this dataset can further enhance\nthe study on incorporating deep semantics into the understanding and generation\nsystem of Chinese classical poetry. We also preliminarily run two variants of\nBERT on this dataset as the baselines for this dataset.",
    "descriptor": "",
    "authors": [
      "Wenhao Li",
      "Fanchao Qi",
      "Maosong Sun",
      "Xiaoyuan Yi",
      "Jiarui Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01979"
  },
  {
    "id": "arXiv:2106.01981",
    "title": "ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose",
    "abstract": "Our work focuses on the development of a learnable neural representation of\nhuman pose for advanced AI assisted animation tooling. Specifically, we tackle\nthe problem of constructing a full static human pose based on sparse and\nvariable user inputs (e.g. locations and/or orientations of a subset of body\njoints). To solve this problem, we propose a novel neural architecture that\ncombines residual connections with prototype encoding of a partially specified\npose to create a new complete pose from the learned latent space. We show that\nour architecture outperforms a baseline based on Transformer, both in terms of\naccuracy and computational efficiency. Additionally, we develop a user\ninterface to integrate our neural model in Unity, a real-time 3D development\nplatform. Furthermore, we introduce two new datasets representing the static\nhuman pose modeling problem, based on high-quality human motion capture data,\nwhich will be released publicly along with model code.",
    "descriptor": "",
    "authors": [
      "Boris N. Oreshkin",
      "Florent Bocquelet",
      "F\u00e9lix H. Harvey",
      "Bay Raitt",
      "Dominic Laflamme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01981"
  },
  {
    "id": "arXiv:2106.01987",
    "title": "PRINS: Scalable Model Inference for Component-based System Logs",
    "abstract": "Behavioral software models play a key role in many software engineering\ntasks; unfortunately, these models either are not available during software\ndevelopment or, if available, quickly become outdated as implementations\nevolve. Model inference techniques have been proposed as a viable solution to\nextract finite state models from execution logs. However, existing techniques\ndo not scale well when processing very large logs that can be commonly found in\npractice.\nIn this paper, we address the scalability problem of inferring the model of a\ncomponent-based system from large system logs, without requiring any extra\ninformation. Our model inference technique, called PRINS, follows a divide and\nconquer approach. The idea is to first infer a model of each system component\nfrom the corresponding logs; then, the individual component models are merged\ntogether taking into account the flow of events across components, as reflected\nin the logs. We evaluated PRINS in terms of scalability and accuracy, using\nnine datasets composed of logs extracted from publicly available benchmarks and\na personal computer running desktop business applications. The results show\nthat PRINS can process large logs much faster than a publicly available and\nwell-known state-of-the-art tool, without significantly compromising the\naccuracy of inferred models.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1908.02329\n",
    "authors": [
      "Donghwan Shin",
      "Domenico Bianculli",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.01987"
  },
  {
    "id": "arXiv:2106.01993",
    "title": "Real-time Grid and DER Co-simulation Platform for Validating Large-scale  DER Control Schemes",
    "abstract": "Distributed energy resources (DERs) such as responsive loads and energy\nstorage systems are valuable resources available to grid operators for\nbalancing supply-demand mismatches via load coordination. However, consumer\nacceptance of load coordination schemes depends on ensuring quality of service\n(QoS), which embodies device-level constraints. Since each device has its own\ninternal energy state, the effect of QoS on the fleet can be cast as fleet-wide\nenergy limits within which the aggregate \"state of charge\" (SoC) must be\nactively maintained. This requires coordination of DERs that is cognizant of\nthe SoC, responsive to grid conditions, and depends on fast communication\nnetworks. To that effect, this paper presents a novel real-time grid-and-DER\nco-simulation platform for validating advanced DER coordination schemes and\ncharacterizing the capability of such a DER fleet. In particular, we present\nhow the co-simulation platform is suitable for: i) testing real-time\nperformance of a large fleet of DERs in delivering advanced grid services,\nincluding frequency regulation; ii) online state estimation to characterize the\ncorresponding SoC of a large fleet of DERs; and iii) incorporating practical\nlimitations of DERs and communications and analyzing the effects on fleet-wide\nperformance. To illustrate these benefits of the presented grid-DER\nco-simulation platform, we employ the advanced DER coordination scheme called\npacketized energy management (PEM), which is a novel device-driven,\nasynchronous, and randomizing control paradigm for DERs. A fleet of thousands\nof PEM-enabled DERs are then added to a realistic and dynamical model of the\nVermont transmission system to complete validation of the co-simulation\nplatform.",
    "descriptor": "",
    "authors": [
      "Adil Khurram",
      "Mahraz Amini",
      "Luis A. Duffaut Espinosa",
      "Paul D. H. Hines",
      "Mads Almassalkhi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01993"
  },
  {
    "id": "arXiv:2106.01994",
    "title": "Feedback Capacity of MIMO Gaussian Channels",
    "abstract": "Finding a computable expression for the feedback capacity of additive\nchannels with colored Gaussian noise is a long standing open problem. In this\npaper, we solve this problem in the scenario where the channel has multiple\ninputs and multiple outputs (MIMO) and the noise process is generated as the\noutput of a state-space model (a hidden Markov model). The main result is a\ncomputable characterization of the feedback capacity as a finite-dimensional\nconvex optimization problem. Our solution subsumes all previous solutions to\nthe feedback capacity including the auto-regressive moving-average (ARMA) noise\nprocess of first order, even if it is a non-stationary process. The capacity\nproblem can be viewed as the problem of maximizing the measurements' entropy\nrate of a controlled (policy-dependent) state-space subject to a power\nconstraint. We formulate the finite-block version of this problem as a\n\\emph{sequential convex optimization problem}, which in turn leads to a\nsingle-letter and computable upper bound. By optimizing over a family of\ntime-invariant policies that correspond to the channel inputs distribution, a\ntight lower bound is realized. We show that one of the optimization constraints\nin the capacity characterization boils down to a Riccati equation, revealing an\ninteresting relation between explicit capacity formulae and Riccati equations.",
    "descriptor": "\nComments: This is an extended version (with proofs) of an accepted paper to ISIT 2021\n",
    "authors": [
      "Oron Sabag",
      "Victoria Kostina",
      "Babak Hassibi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.01994"
  },
  {
    "id": "arXiv:2106.01998",
    "title": "Toward Explainable Users: Using NLP to Enable AI to Understand Users'  Perceptions of Cyber Attacks",
    "abstract": "To understand how end-users conceptualize consequences of cyber security\nattacks, we performed a card sorting study, a well-known technique in Cognitive\nSciences, where participants were free to group the given consequences of\nchosen cyber attacks into as many categories as they wished using rationales\nthey see fit. The results of the open card sorting study showed a large amount\nof inter-participant variation making the research team wonder how the\nconsequences of security attacks were comprehended by the participants. As an\nexploration of whether it is possible to explain user's mental model and\nbehavior through Artificial Intelligence (AI) techniques, the research team\ncompared the card sorting data with the outputs of a number of Natural Language\nProcessing (NLP) techniques with the goal of understanding how participants\nperceived and interpreted the consequences of cyber attacks written in natural\nlanguages. The results of the NLP-based exploration methods revealed an\ninteresting observation implying that participants had mostly employed checking\nindividual keywords in each sentence to group cyber attack consequences\ntogether and less considered the semantics behind the description of\nconsequences of cyber attacks. The results reported in this paper are seemingly\nuseful and important for cyber attacks comprehension from user's perspectives.\nTo the best of our knowledge, this paper is the first introducing the use of AI\ntechniques in explaining and modeling users' behavior and their perceptions\nabout a context. The novel idea introduced here is about explaining users using\nAI.",
    "descriptor": "\nComments: 20 pages, 3 figures, COMPSAC'21\n",
    "authors": [
      "Faranak Abri",
      "Luis Felipe Gutierrez",
      "Chaitra T. Kulkarni",
      "Akbar Siami Namin",
      "Keith S. Jones"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.01998"
  },
  {
    "id": "arXiv:2106.02000",
    "title": "Unified Performance Analysis of Reconfigurable Intelligent Surface  Empowered Free Space Optical Communications",
    "abstract": "Reconfigurable intelligent surface (RIS) is an excellent use case for\nline-of-sight (LOS) based technologies such as free-space optical (FSO)\ncommunications. In this paper, we analyze the performance of RIS-empowered FSO\n(RISE-FSO) systems by unifying Fisher-Snedecor (F), Gamma-Gamma (GG), and\nMalaga (M) distributions for atmospheric turbulence with zero-boresight\npointing errors over deterministic as well as random path-loss in foggy\nconditions with heterodyne detection (HD) and intensity modulation/direct\ndetection (IM/DD) methods. By deriving the probability density function (PDF)\nand cumulative distribution function (CDF) of the direct-link (DL) with the\nstatistical effect of atmospheric turbulence, pointing errors, and random fog,\nwe develop exact expressions of PDF and CDF of the resultant channel for the\nRISE-FSO system. Using the derived statistical results, we present exact\nexpressions of outage probability, average bit-error-rate (BER), ergodic\ncapacity, and moments of signal-to-noise ratio (SNR) for both DL-FSO and\nRISE-FSO systems. We also develop an asymptotic analysis of the outage\nprobability and average BER and derive the diversity order of the considered\nsystems. We validate the analytical expressions using Monte-Carlo simulations\nand demonstrate the performance scaling of the FSO system with the number of\nRIS elements for various turbulence channels, detection techniques, and weather\nconditions.",
    "descriptor": "\nComments: 29 pages, 8 figures, 3 tables\n",
    "authors": [
      "Vinay Kumar Chapala",
      "S. M. Zafaruddin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.02000"
  },
  {
    "id": "arXiv:2106.02003",
    "title": "Individual vs. Joint Perception: a Pragmatic Model of Pointing as  Communicative Smithian Helping",
    "abstract": "The simple gesture of pointing can greatly augment ones ability to comprehend\nstates of the world based on observations. It triggers additional inferences\nrelevant to ones task at hand. We model an agents update to its belief of the\nworld based on individual observations using a partially observable Markov\ndecision process (POMDP), a mainstream artificial intelligence (AI) model of\nhow to act rationally according to beliefs formed through observation. On top\nof that, we model pointing as a communicative act between agents who have a\nmutual understanding that the pointed observation must be relevant and\ninterpretable. Our model measures relevance by defining a Smithian Value of\nInformation (SVI) as the utility improvement of the POMDP agent before and\nafter receiving the pointing. We model that agents calculate SVI by using the\ncognitive theory of Smithian helping as a principle of coordinating separate\nbeliefs for action prediction and action evaluation. We then import SVI into\nrational speech act (RSA) as the utility function of an utterance. These lead\nus to a pragmatic model of pointing allowing for contextually flexible\ninterpretations. We demonstrate the power of our Smithian pointing model by\nextending the Wumpus world, a classic AI task where a hunter hunts a monster\nwith only partial observability of the world. We add another agent as a guide\nwho can only help by marking an observation already perceived by the hunter\nwith a pointing or not, without providing new observations or offering any\ninstrumental help. Our results show that this severely limited and overloaded\ncommunication nevertheless significantly improves the hunters performance. The\nadvantage of pointing is indeed due to a computation of relevance based on\nSmithian helping, as it disappears completely when the task is too difficult or\ntoo easy for the guide to help.",
    "descriptor": "\nComments: 7 pages, 3 figures. Accepted to CogSci 2021\n",
    "authors": [
      "Kaiwen Jiang",
      "Stephanie Stacy",
      "Chuyu Wei",
      "Adelpha Chan",
      "Federico Rossano",
      "Yixin Zhu",
      "Tao Gao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02003"
  },
  {
    "id": "arXiv:2106.02006",
    "title": "Cloud-Enabled High-Altitude Platform Systems: Challenges and  Opportunities",
    "abstract": "Augmenting ground-level communications with flying networks, such as the\nhigh-altitude platform system (HAPS), is among the major innovative initiatives\nof the next generation of wireless systems (6G). Given HAPS quasi-static\npositioning at the stratosphere, HAPS-to-ground and HAPS-to-air connectivity\nframeworks are expected to be prolific in terms of data acquisition and\ncomputing, especially given the mild weather and quasi-constant wind speed\ncharacteristics of the stratospheric layer. This paper explores the\nopportunities stemming from the realization of cloud-enabled HAPS in the\ncontext of telecommunications applications and services. The paper first\nadvocates for the potential physical advantages of deploying HAPS as flying\ndata-centers, also known as super-macro base stations. The paper then presents\nthe merits that can be achieved by integrating various cloud services within\nthe HAPS, and the corresponding cloud-type applications that would utilize the\nHAPS for enhancing the quality, range, and types of offered services. The paper\nfurther sheds light on the challenges that need to be addressed for realizing\npractical cloud-enabled HAPS, mainly, those related to the high energy,\nprocessing power, quality of service (QoS), and security considerations.\nFinally, the paper discusses some open issues on the topic, namely, HAPS\nmobility and message routing, HAPS security via blockchain and machine\nlearning, artificial intelligence-based resource allocation in cloud-enabled\nHAPS, and integration with vertical heterogeneous networks.",
    "descriptor": "\nComments: 18 pages, 4 figures, 1 table\n",
    "authors": [
      "Khaleel Mershad",
      "Hayssam Dahrouj",
      "Hadi Sarieddeen",
      "Basem Shihada",
      "Tareq Al-Naffouri",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.02006"
  },
  {
    "id": "arXiv:2106.02009",
    "title": "A Case Study of Spanish Text Transformations for Twitter Sentiment  Analysis",
    "abstract": "Sentiment analysis is a text mining task that determines the polarity of a\ngiven text, i.e., its positiveness or negativeness. Recently, it has received a\nlot of attention given the interest in opinion mining in micro-blogging\nplatforms. These new forms of textual expressions present new challenges to\nanalyze text given the use of slang, orthographic and grammatical errors, among\nothers. Along with these challenges, a practical sentiment classifier should be\nable to handle efficiently large workloads.\nThe aim of this research is to identify which text transformations\n(lemmatization, stemming, entity removal, among others), tokenizers (e.g.,\nwords $n$-grams), and tokens weighting schemes impact the most the accuracy of\na classifier (Support Vector Machine) trained on two Spanish corpus. The\nmethodology used is to exhaustively analyze all the combinations of the text\ntransformations and their respective parameters to find out which\ncharacteristics the best performing classifiers have in common. Furthermore,\namong the different text transformations studied, we introduce a novel approach\nbased on the combination of word based $n$-grams and character based $q$-grams.\nThe results show that this novel combination of words and characters produces a\nclassifier that outperforms the traditional word based combination by $11.17\\%$\nand $5.62\\%$ on the INEGI and TASS'15 dataset, respectively.",
    "descriptor": "",
    "authors": [
      "Eric S. Tellez",
      "Sabino Miranda-Jim\u00e9nez",
      "Mario Graff",
      "Daniela Moctezuma",
      "Oscar S. Siodia",
      "Elio A. Villase\u00f1or"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.02009"
  },
  {
    "id": "arXiv:2106.02011",
    "title": "Provably Secure Generative Linguistic Steganography",
    "abstract": "Generative linguistic steganography mainly utilized language models and\napplied steganographic sampling (stegosampling) to generate high-security\nsteganographic text (stegotext). However, previous methods generally lead to\nstatistical differences between the conditional probability distributions of\nstegotext and natural text, which brings about security risks. In this paper,\nto further ensure security, we present a novel provably secure generative\nlinguistic steganographic method ADG, which recursively embeds secret\ninformation by Adaptive Dynamic Grouping of tokens according to their\nprobability given by an off-the-shelf language model. We not only prove the\nsecurity of ADG mathematically, but also conduct extensive experiments on three\npublic corpora to further verify its imperceptibility. The experimental results\nreveal that the proposed method is able to generate stegotext with nearly\nperfect security.",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021: findings\n",
    "authors": [
      "Siyu Zhang",
      "Zhongliang Yang",
      "Jinshuai Yang",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.02011"
  },
  {
    "id": "arXiv:2106.02012",
    "title": "Attack Prediction using Hidden Markov Model",
    "abstract": "It is important to predict any adversarial attacks and their types to enable\neffective defense systems. Often it is hard to label such activities as\nmalicious ones without adequate analytical reasoning. We propose the use of\nHidden Markov Model (HMM) to predict the family of related attacks. Our\nproposed model is based on the observations often agglomerated in the form of\nlog files and from the target or the victim's perspective. We have built an\nHMM-based prediction model and implemented our proposed approach using Viterbi\nalgorithm, which generates a sequence of states corresponding to stages of a\nparticular attack. As a proof of concept and also to demonstrate the\nperformance of the model, we have conducted a case study on predicting a family\nof attacks called Action Spoofing.",
    "descriptor": "\nComments: 20 pages, 4 figures, COMPSAC'21\n",
    "authors": [
      "Shuvalaxmi Dass",
      "Prerit Datta",
      "Akbar Siami Namin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02012"
  },
  {
    "id": "arXiv:2106.02016",
    "title": "Semantic-WER: A Unified Metric for the Evaluation of ASR Transcript for  End Usability",
    "abstract": "Recent advances in supervised, semi-supervised and self-supervised deep\nlearning algorithms have shown significant improvement in the performance of\nautomatic speech recognition(ASR) systems. The state-of-the-art systems have\nachieved a word error rate (WER) less than 5%. However, in the past,\nresearchers have argued the non-suitability of the WER metric for the\nevaluation of ASR systems for downstream tasks such as spoken language\nunderstanding (SLU) and information retrieval. The reason is that the WER works\nat the surface level and does not include any syntactic and semantic\nknowledge.The current work proposes Semantic-WER (SWER), a metric to evaluate\nthe ASR transcripts for downstream applications in general. The SWER can be\neasily customized for any down-stream task.",
    "descriptor": "",
    "authors": [
      "Somnath Roy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.02016"
  },
  {
    "id": "arXiv:2106.02017",
    "title": "A Dataset and Baselines for Multilingual Reply Suggestion",
    "abstract": "Reply suggestion models help users process emails and chats faster. Previous\nwork only studies English reply suggestion. Instead, we present MRS, a\nmultilingual reply suggestion dataset with ten languages. MRS can be used to\ncompare two families of models: 1) retrieval models that select the reply from\na fixed set and 2) generation models that produce the reply from scratch.\nTherefore, MRS complements existing cross-lingual generalization benchmarks\nthat focus on classification and sequence labeling tasks. We build a generation\nmodel and a retrieval model as baselines for MRS. The two models have different\nstrengths in the monolingual setting, and they require different strategies to\ngeneralize across languages. MRS is publicly available at\nhttps://github.com/zhangmozhi/mrs.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Mozhi Zhang",
      "Wei Wang",
      "Budhaditya Deb",
      "Guoqing Zheng",
      "Milad Shokouhi",
      "Ahmed Hassan Awadallah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02017"
  },
  {
    "id": "arXiv:2106.02018",
    "title": "Nonlinear Matrix Approximation with Radial Basis Function Components",
    "abstract": "We introduce and investigate matrix approximation by decomposition into a sum\nof radial basis function (RBF) components. An RBF component is a generalization\nof the outer product between a pair of vectors, where an RBF function replaces\nthe scalar multiplication between individual vector elements. Even though the\nRBF functions are positive definite, the summation across components is not\nrestricted to convex combinations and allows us to compute the decomposition\nfor any real matrix that is not necessarily symmetric or positive definite. We\nformulate the problem of seeking such a decomposition as an optimization\nproblem with a nonlinear and non-convex loss function. Several modern versions\nof the gradient descent method, including their scalable stochastic\ncounterparts, are used to solve this problem. We provide extensive empirical\nevidence of the effectiveness of the RBF decomposition and that of the\ngradient-based fitting algorithm. While being conceptually motivated by\nsingular value decomposition (SVD), our proposed nonlinear counterpart\noutperforms SVD by drastically reducing the memory required to approximate a\ndata matrix with the same $L_2$-error for a wide range of matrix types. For\nexample, it leads to 2 to 10 times memory save for Gaussian noise, graph\nadjacency matrices, and kernel matrices. Moreover, this proximity-based\ndecomposition can offer additional interpretability in applications that\ninvolve, e.g., capturing the inner low-dimensional structure of the data,\nretaining graph connectivity structure, and preserving the acutance of images.",
    "descriptor": "",
    "authors": [
      "Elizaveta Rebrova",
      "Yu-Hang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02018"
  },
  {
    "id": "arXiv:2106.02019",
    "title": "Neural Actor: Neural Free-view Synthesis of Human Actors with Pose  Control",
    "abstract": "We propose Neural Actor (NA), a new method for high-quality synthesis of\nhumans from arbitrary viewpoints and under arbitrary controllable poses. Our\nmethod is built upon recent neural scene representation and rendering works\nwhich learn representations of geometry and appearance from only 2D images.\nWhile existing works demonstrated compelling rendering of static scenes and\nplayback of dynamic scenes, photo-realistic reconstruction and rendering of\nhumans with neural implicit methods, in particular under user-controlled novel\nposes, is still difficult. To address this problem, we utilize a coarse body\nmodel as the proxy to unwarp the surrounding 3D space into a canonical pose. A\nneural radiance field learns pose-dependent geometric deformations and pose-\nand view-dependent appearance effects in the canonical space from multi-view\nvideo input. To synthesize novel views of high fidelity dynamic geometry and\nappearance, we leverage 2D texture maps defined on the body model as latent\nvariables for predicting residual deformations and the dynamic appearance.\nExperiments demonstrate that our method achieves better quality than the\nstate-of-the-arts on playback as well as novel pose synthesis, and can even\ngeneralize well to new poses that starkly differ from the training poses.\nFurthermore, our method also supports body shape control of the synthesized\nresults.",
    "descriptor": "",
    "authors": [
      "Lingjie Liu",
      "Marc Habermann",
      "Viktor Rudnev",
      "Kripasindhu Sarkar",
      "Jiatao Gu",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02019"
  },
  {
    "id": "arXiv:2106.02022",
    "title": "Single Image Depth Estimation using Wavelet Decomposition",
    "abstract": "We present a novel method for predicting accurate depths from monocular\nimages with high efficiency. This optimal efficiency is achieved by exploiting\nwavelet decomposition, which is integrated in a fully differentiable\nencoder-decoder architecture. We demonstrate that we can reconstruct\nhigh-fidelity depth maps by predicting sparse wavelet coefficients. In contrast\nwith previous works, we show that wavelet coefficients can be learned without\ndirect supervision on coefficients. Instead we supervise only the final depth\nimage that is reconstructed through the inverse wavelet transform. We\nadditionally show that wavelet coefficients can be learned in fully\nself-supervised scenarios, without access to ground-truth depth. Finally, we\napply our method to different state-of-the-art monocular depth estimation\nmodels, in each case giving similar or better results compared to the original\nmodel, while requiring less than half the multiply-adds in the decoder network.\nCode at https://github.com/nianticlabs/wavelet-monodepth",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Micha\u00ebl Ramamonjisoa",
      "Michael Firman",
      "Jamie Watson",
      "Vincent Lepetit",
      "Daniyar Turmukhambetov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02022"
  },
  {
    "id": "arXiv:2106.02023",
    "title": "Slepian Scale-Discretised Wavelets on the Sphere",
    "abstract": "This work presents the construction of a novel spherical wavelet basis\ndesigned for incomplete spherical datasets, i.e. datasets which are missing in\na particular region of the sphere. The eigenfunctions of the Slepian\nspatial-spectral concentration problem (the Slepian functions) are a set of\northogonal basis functions which exist within a defined region. Slepian\nfunctions allow one to compute a convolution on the incomplete sphere by\nleveraging the recently proposed sifting convolution and extending it to any\nset of basis functions. Through a tiling of the Slepian harmonic line one may\nconstruct scale-discretised wavelets. An illustration is presented based on an\nexample region on the sphere defined by the topographic map of the Earth. The\nSlepian wavelets and corresponding wavelet coefficients are constructed from\nthis region, and are used in a straightforward denoising example.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Patrick J. Roddy",
      "Jason D. McEwen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02023"
  },
  {
    "id": "arXiv:2106.02024",
    "title": "Combinatorial Algorithms for Matching Markets via Nash Bargaining:  One-Sided, Two-Sided and Non-Bipartite",
    "abstract": "This paper is an attempt to deal with the recent realization (Vazirani,\nYannakakis 2021) that the Hylland-Zeckhauser mechanism, which has remained a\nclassic in economics for one-sided matching markets, is likely to be highly\nintractable. HZ uses the power of a pricing mechanism, which has endowed it\nwith nice game-theoretic properties.\nHosseini and Vazirani (2021) define a rich collection of\nNash-bargaining-based models for one-sided and two-sided matching markets, in\nboth Fisher and Arrow-Debreu settings, together with implementations using\navailable solvers, and very encouraging experimental results. This naturally\nraises the question of finding efficient combinatorial algorithms for these\nmodels.\nIn this paper, we give efficient combinatorial algorithms based on the\ntechniques of multiplicative weights update (MWU) and conditional gradient\ndescent (CGD) for several one-sided and two-sided models defined in HV 2021.\nAdditionally, we define for the first time a Nash-bargaining-based model for\nnon-bipartite matching markets and solve it using CGD. Furthermore, in every\ncase, we study not only the Fisher but also the Arrow-Debreu version; the\nlatter is also called the exchange version. We give natural applications for\neach model studied. These models inherit the game-theoretic and computational\nproperties of Nash bargaining.\nWe also establish a deep connection between HZ and the Nash-bargaining-based\nmodels, thereby confirming that the alternative to HZ proposed in HV 2021 is a\nprincipled one.",
    "descriptor": "\nComments: 51 pages\n",
    "authors": [
      "Ioannis Panageas",
      "Thorben Tr\u00f6bst",
      "Vijay V. Vazirani"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2106.02024"
  },
  {
    "id": "arXiv:2106.02026",
    "title": "Breaking the Cubic Barrier for (Unweighted) Tree Edit Distance",
    "abstract": "The (unweighted) \\emph{tree edit distance} problem for $n$ node trees asks to\ncompute a measure of dissimilarity between two rooted trees with node labels.\nThe current best algorithm from more than a decade ago runs in $O(n ^ 3)$ time\n[Demaine, Mozes, Rossman, and Weimann, ICALP 2007]. The same paper also showed\nthat $O(n ^ 3)$ is the best possible running time for any algorithm using the\nso-called \\emph{decomposition strategy}, which underlies almost all the known\nalgorithms for this problem. These algorithms would also work for the\n\\emph{weighted} tree edit distance problem, which cannot be solved in truly\nsub-cubic time under the APSP conjecture [Bringmann, Gawrychowski, Mozes, and\nWeimann, SODA 2018].\nIn this paper, we break the cubic barrier by showing an $O(n ^ {2.9546})$\ntime algorithm for the \\emph{unweighted} tree edit distance problem.\nWe consider an equivalent maximization problem and use a dynamic programming\nscheme involving matrices with many special properties. By using a\ndecomposition scheme as well as several combinatorial techniques, we reduce\ntree edit distance to the max-plus product of bounded-difference matrices,\nwhich can be solved in truly sub-cubic time [Bringmann, Grandoni, Saha, and\nVassilevska Williams, FOCS 2016].",
    "descriptor": "",
    "authors": [
      "Xiao Mao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.02026"
  },
  {
    "id": "arXiv:2106.02030",
    "title": "Formally Verified Next-Generation Airborne Collision Avoidance Games in  ACAS X",
    "abstract": "The design of aircraft collision avoidance algorithms is a subtle but\nimportant challenge that merits the need for provable safety guarantees.\nObtaining such guarantees is nontrivial given the unpredictability of the\ninterplay of the intruder aircraft decisions, the ownship pilot reactions, and\nthe subtlety of the continuous motion dynamics of aircraft. Existing collision\navoidance systems, such as TCAS and the Next-Generation Airborne Collision\nAvoidance System ACAS X, have been analyzed assuming severe restrictions on the\nintruder's flight maneuvers, limiting their safety guarantees in real-world\nscenarios where the intruder may also be changing its course. This work takes a\nconceptually significant and practically relevant departure from existing ACAS\nX models by generalizing them to hybrid games with first-class representations\nof the ownship and intruder decisions coming from two independent players. By\nproving the existence of winning strategies for the resulting Adversarial ACAS\nX in differential game logic, collision-freedom is established for the rich\nencounters of ownship and intruder aircraft with independent decisions along\ndifferential equations for flight paths with evolving vertical/horizontal\nvelocities. We present three classes of models of increasing complexity:\nsingle-advisory infinite-time models, bounded time models, and infinite time,\nmulti-advisory models. Within each class of models, we identify symbolic\nconditions and prove that there then always is a possible ownship maneuver that\nwill prevent a collision between the two aircraft.",
    "descriptor": "",
    "authors": [
      "Rachel Cleaveland",
      "Stefan Mitsch",
      "Andr\u00e9 Platzer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02030"
  },
  {
    "id": "arXiv:2106.02034",
    "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token  Sparsification",
    "abstract": "Attention is sparse in vision transformers. We observe the final prediction\nin vision transformers is only based on a subset of most informative tokens,\nwhich is sufficient for accurate image recognition. Based on this observation,\nwe propose a dynamic token sparsification framework to prune redundant tokens\nprogressively and dynamically based on the input. Specifically, we devise a\nlightweight prediction module to estimate the importance score of each token\ngiven the current features. The module is added to different layers to prune\nredundant tokens hierarchically. To optimize the prediction module in an\nend-to-end manner, we propose an attention masking strategy to differentiably\nprune a token by blocking its interactions with other tokens. Benefiting from\nthe nature of self-attention, the unstructured sparse tokens are still hardware\nfriendly, which makes our framework easy to achieve actual speed-up. By\nhierarchically pruning 66% of the input tokens, our method greatly reduces\n31%~37% FLOPs and improves the throughput by over 40% while the drop of\naccuracy is within 0.5% for various vision transformers. Equipped with the\ndynamic token sparsification framework, DynamicViT models can achieve very\ncompetitive complexity/accuracy trade-offs compared to state-of-the-art CNNs\nand vision transformers on ImageNet. Code is available at\nhttps://github.com/raoyongming/DynamicViT",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yongming Rao",
      "Wenliang Zhao",
      "Benlin Liu",
      "Jiwen Lu",
      "Jie Zhou",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02034"
  },
  {
    "id": "arXiv:2106.02036",
    "title": "Anticipative Video Transformer",
    "abstract": "We propose Anticipative Video Transformer (AVT), an end-to-end\nattention-based video modeling architecture that attends to the previously\nobserved video in order to anticipate future actions. We train the model\njointly to predict the next action in a video sequence, while also learning\nframe feature encoders that are predictive of successive future frames'\nfeatures. Compared to existing temporal aggregation strategies, AVT has the\nadvantage of both maintaining the sequential progression of observed actions\nwhile still capturing long-range dependencies--both critical for the\nanticipation task. Through extensive experiments, we show that AVT obtains the\nbest reported performance on four popular action anticipation benchmarks:\nEpicKitchens-55, EpicKitchens-100, EGTEA Gaze+, and 50-Salads, including\noutperforming all submissions to the EpicKitchens-100 CVPR'21 challenge.",
    "descriptor": "\nComments: Ranked #1 on CVPR'21 EPIC-Kitchens Action Anticipation challenge leaderboard. Project page: this http URL\n",
    "authors": [
      "Rohit Girdhar",
      "Kristen Grauman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.02036"
  },
  {
    "id": "arXiv:2106.02039",
    "title": "Reinforcement Learning as One Big Sequence Modeling Problem",
    "abstract": "Reinforcement learning (RL) is typically concerned with estimating\nsingle-step policies or single-step models, leveraging the Markov property to\nfactorize the problem in time. However, we can also view RL as a sequence\nmodeling problem, with the goal being to predict a sequence of actions that\nleads to a sequence of high rewards. Viewed in this way, it is tempting to\nconsider whether powerful, high-capacity sequence prediction models that work\nwell in other domains, such as natural-language processing, can also provide\nsimple and effective solutions to the RL problem. To this end, we explore how\nRL can be reframed as \"one big sequence modeling\" problem, using\nstate-of-the-art Transformer architectures to model distributions over\nsequences of states, actions, and rewards. Addressing RL as a sequence modeling\nproblem significantly simplifies a range of design decisions: we no longer\nrequire separate behavior policy constraints, as is common in prior work on\noffline model-free RL, and we no longer require ensembles or other epistemic\nuncertainty estimators, as is common in prior work on model-based RL. All of\nthese roles are filled by the same Transformer sequence model. In our\nexperiments, we demonstrate the flexibility of this approach across\nlong-horizon dynamics prediction, imitation learning, goal-conditioned RL, and\noffline RL.",
    "descriptor": "",
    "authors": [
      "Michael Janner",
      "Qiyang Li",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02039"
  },
  {
    "id": "arXiv:2106.02040",
    "title": "Towards Learning to Play Piano with Dexterous Hands and Touch",
    "abstract": "The virtuoso plays the piano with passion, poetry and extraordinary technical\nability. As Liszt said (a virtuoso)must call up scent and blossom, and breathe\nthe breath of life. The strongest robots that can play a piano are based on a\ncombination of specialized robot hands/piano and hardcoded planning algorithms.\nIn contrast to that, in this paper, we demonstrate how an agent can learn\ndirectly from machine-readable music score to play the piano with dexterous\nhands on a simulated piano using reinforcement learning (RL) from scratch. We\ndemonstrate the RL agents can not only find the correct key position but also\ndeal with various rhythmic, volume and fingering, requirements. We achieve this\nby using a touch-augmented reward and a novel curriculum of tasks. We conclude\nby carefully studying the important aspects to enable such learning algorithms\nand that can potentially shed light on future research in this direction.",
    "descriptor": "",
    "authors": [
      "Huazhe Xu",
      "Yuping Luo",
      "Shaoxiong Wang",
      "Trevor Darrell",
      "Roberto Calandra"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02040"
  },
  {
    "id": "arXiv:2106.00215",
    "title": "Necessary conditions for feedback stabilization and safety",
    "abstract": "Brockett's necessary condition yields a test to determine whether a system\ncan be made to stabilize about some operating point via continuous, purely\nstate-dependent feedback. For many real-world systems, however, one wants to\nstabilize sets which are more general than a single point. One also wants to\ncontrol such systems to operate safely by making obstacles and other\n\"dangerous\" sets repelling.\nWe generalize Brockett's necessary condition to the case of stabilizing\ngeneral compact subsets having a nonzero Euler characteristic. Using this\ngeneralization, we also formulate a necessary condition for the existence of\n\"safe\" control laws. We illustrate the theory in concrete examples and for some\ngeneral classes of systems including a broad class of nonholonomically\nconstrained Lagrangian systems. We also show that, for the special case of\nstabilizing a point, the specialization of our general stabilizability test is\nstronger than Brockett's.",
    "descriptor": "\nComments: 28 pages, 4 figures\n",
    "authors": [
      "Matthew D. Kvalheim",
      "Daniel E. Koditschek"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Mathematical Physics (math-ph)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00215"
  },
  {
    "id": "arXiv:2106.00949",
    "title": "Should We Always Separate?: Switching Between Enhanced and Observed  Signals for Overlapping Speech Recognition",
    "abstract": "Although recent advances in deep learning technology improved automatic\nspeech recognition (ASR), it remains difficult to recognize speech when it\noverlaps other people's voices. Speech separation or extraction is often used\nas a front-end to ASR to handle such overlapping speech. However, deep neural\nnetwork-based speech enhancement can generate `processing artifacts' as a side\neffect of the enhancement, which degrades ASR performance. For example, it is\nwell known that single-channel noise reduction for non-speech noise\n(non-overlapping speech) often does not improve ASR. Likewise, the processing\nartifacts may also be detrimental to ASR in some conditions when processing\noverlapping speech with a separation/extraction method, although it is usually\nbelieved that separation/extraction improves ASR. In order to answer the\nquestion `Do we always have to separate/extract speech from mixtures?', we\nanalyze ASR performance on observed and enhanced speech at various noise and\ninterference conditions, and show that speech enhancement degrades ASR under\nsome conditions even for overlapping speech. Based on these findings, we\npropose a simple switching algorithm between observed and enhanced speech based\non the estimated signal-to-interference ratio and signal-to-noise ratio. We\ndemonstrated experimentally that such a simple switching mechanism can improve\nrecognition performance when processing artifacts are detrimental to ASR.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Hiroshi Sato",
      "Tsubasa Ochiai",
      "Marc Delcroix",
      "Keisuke Kinoshita",
      "Takafumi Moriya",
      "Naoyuki Kamo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.00949"
  },
  {
    "id": "arXiv:2106.01388",
    "title": "Single-component gradient rules for variational quantum algorithms",
    "abstract": "Many near-term quantum computing algorithms are conceived as variational\nquantum algorithms, in which parameterized quantum circuits are optimized in a\nhybrid quantum-classical setup. Examples are variational quantum eigensolvers,\nquantum approximate optimization algorithms as well as various algorithms in\nthe context of quantum-assisted machine learning. A common bottleneck of any\nsuch algorithm is constituted by the optimization of the variational\nparameters. A popular set of optimization methods work on the estimate of the\ngradient, obtained by means of circuit evaluations. We will refer to the way in\nwhich one can combine these circuit evaluations as gradient rules. This work\nprovides a comprehensive picture of the family of gradient rules that vary\nparameters of quantum gates individually. The most prominent known members of\nthis family are the parameter shift rule and the finite differences method. To\nunite this family, we propose a generalized parameter shift rule that expresses\nall members of the aforementioned family as special cases, and discuss how all\nof these can be seen as providing access to a linear combination of exact\nfirst- and second-order derivatives. We further prove that a parameter shift\nrule with one non-shifted evaluation and only one shifted circuit evaluation\ncan not exist does not exist, and introduce a novel perspective for approaching\nnew gradient rules.",
    "descriptor": "\nComments: 9 pages, 0 figures\n",
    "authors": [
      "Thomas Hubregtsen",
      "Frederik Wilde",
      "Shozab Qasim",
      "Jens Eisert"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01388"
  },
  {
    "id": "arXiv:2106.01400",
    "title": "Dual Script E2E framework for Multilingual and Code-Switching ASR",
    "abstract": "India is home to multiple languages, and training automatic speech\nrecognition (ASR) systems for languages is challenging. Over time, each\nlanguage has adopted words from other languages, such as English, leading to\ncode-mixing. Most Indian languages also have their own unique scripts, which\nposes a major limitation in training multilingual and code-switching ASR\nsystems.\nInspired by results in text-to-speech synthesis, in this work, we use an\nin-house rule-based phoneme-level common label set (CLS) representation to\ntrain multilingual and code-switching ASR for Indian languages. We propose two\nend-to-end (E2E) ASR systems. In the first system, the E2E model is trained on\nthe CLS representation, and we use a novel data-driven back-end to recover the\nnative language script. In the second system, we propose a modification to the\nE2E model, wherein the CLS representation and the native language characters\nare used simultaneously for training. We show our results on the multilingual\nand code-switching tasks of the Indic ASR Challenge 2021. Our best results\nachieve 6% and 5% improvement (approx) in word error rate over the baseline\nsystem for the multilingual and code-switching tasks, respectively, on the\nchallenge development data.",
    "descriptor": "\nComments: Accepted for publication at Interspeech 2021\n",
    "authors": [
      "Mari Ganesh Kumar",
      "Jom Kuriakose",
      "Anand Thyagachandran",
      "Arun Kumar A",
      "Ashish Seth",
      "Lodagala Durga Prasad",
      "Saish Jaiswal",
      "Anusha Prakash",
      "Hema Murthy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.01400"
  },
  {
    "id": "arXiv:2106.01413",
    "title": "Rectangular Flows for Manifold Learning",
    "abstract": "Normalizing flows are invertible neural networks with tractable\nchange-of-volume terms, which allows optimization of their parameters to be\nefficiently performed via maximum likelihood. However, data of interest is\ntypically assumed to live in some (often unknown) low-dimensional manifold\nembedded in high-dimensional ambient space. The result is a modelling mismatch\nsince -- by construction -- the invertibility requirement implies\nhigh-dimensional support of the learned distribution. Injective flows, mapping\nfrom low- to high-dimensional space, aim to fix this discrepancy by learning\ndistributions on manifolds, but the resulting volume-change term becomes more\nchallenging to evaluate. Current approaches either avoid computing this term\nentirely using various heuristics, or assume the manifold is known beforehand\nand therefore are not widely applicable. Instead, we propose two methods to\ntractably calculate the gradient of this term with respect to the parameters of\nthe model, relying on careful use of automatic differentiation and techniques\nfrom numerical linear algebra. Both approaches perform end-to-end nonlinear\nmanifold learning and density estimation for data projected onto this manifold.\nWe study the trade-offs between our proposed methods, empirically verify that\nwe outperform approaches ignoring the volume-change term by more accurately\nlearning manifolds and the corresponding distributions on them, and show\npromising results on out-of-distribution detection.",
    "descriptor": "",
    "authors": [
      "Anthony L. Caterini",
      "Gabriel Loaiza-Ganem",
      "Geoff Pleiss",
      "John P. Cunningham"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01413"
  },
  {
    "id": "arXiv:2106.01429",
    "title": "Smooth Bilevel Programming for Sparse Regularization",
    "abstract": "Iteratively reweighted least square (IRLS) is a popular approach to solve\nsparsity-enforcing regression problems in machine learning. State of the art\napproaches are more efficient but typically rely on specific coordinate pruning\nschemes. In this work, we show how a surprisingly simple reparametrization of\nIRLS, coupled with a bilevel resolution (instead of an alternating scheme) is\nable to achieve top performances on a wide range of sparsity (such as Lasso,\ngroup Lasso and trace norm regularizations), regularization strength (including\nhard constraints), and design matrices (ranging from correlated designs to\ndifferential operators). Similarly to IRLS, our method only involves linear\nsystems resolutions, but in sharp contrast, corresponds to the minimization of\na smooth function. Despite being non-convex, we show that there is no spurious\nminima and that saddle points are \"ridable\", so that there always exists a\ndescent direction. We thus advocate for the use of a BFGS quasi-Newton solver,\nwhich makes our approach simple, robust and efficient. We perform a numerical\nbenchmark of the convergence speed of our algorithm against state of the art\nsolvers for Lasso, group Lasso, trace norm and linearly constrained problems.\nThese results highlight the versatility of our approach, removing the need to\nuse different solvers depending on the specificity of the ML problem under\nstudy.",
    "descriptor": "",
    "authors": [
      "Clarice Poon",
      "Gabriel Peyr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.01429"
  },
  {
    "id": "arXiv:2106.01435",
    "title": "Real-Time COVID-19 Diagnosis from X-Ray Images Using Deep CNN and  Extreme Learning Machines Stabilized by Chimp Optimization Algorithm",
    "abstract": "Real-time detection of COVID-19 using radiological images has gained priority\ndue to the increasing demand for fast diagnosis of COVID-19 cases. This paper\nintroduces a novel two-phase approach for classifying chest X-ray images. Deep\nLearning (DL) methods fail to cover these aspects since training and\nfine-tuning the model's parameters consume much time. In this approach, the\nfirst phase comes to train a deep CNN working as a feature extractor, and the\nsecond phase comes to use Extreme Learning Machines (ELMs) for real-time\ndetection. The main drawback of ELMs is to meet the need of a large number of\nhidden-layer nodes to gain a reliable and accurate detector in applying image\nprocessing since the detective performance remarkably depends on the setting of\ninitial weights and biases. Therefore, this paper uses Chimp Optimization\nAlgorithm (ChOA) to improve results and increase the reliability of the network\nwhile maintaining real-time capability. The designed detector is to be\nbenchmarked on the COVID-Xray-5k and COVIDetectioNet datasets, and the results\nare verified by comparing it with the classic DCNN, Genetic Algorithm optimized\nELM (GA-ELM), Cuckoo Search optimized ELM (CS-ELM), and Whale Optimization\nAlgorithm optimized ELM (WOA-ELM). The proposed approach outperforms other\ncomparative benchmarks with 98.25% and 99.11% as ultimate accuracy on the\nCOVID-Xray-5k and COVIDetectioNet datasets, respectively, and it led relative\nerror to reduce as the amount of 1.75% and 1.01% as compared to a convolutional\nCNN. More importantly, the time needed for training deep ChOA-ELM is only\n0.9474 milliseconds, and the overall testing time for 3100 images is 2.937\nseconds.",
    "descriptor": "\nComments: 17 pages. arXiv admin note: text overlap with arXiv:2105.14192\n",
    "authors": [
      "Hu Tianqing",
      "Mohammad Khishe",
      "Mokhtar Mohammadi",
      "Gholam-Reza Parvizi",
      "Sarkhel H. Taher Karim",
      "Tarik A. Rashid"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01435"
  },
  {
    "id": "arXiv:2106.01450",
    "title": "Inferring Black Hole Properties from Astronomical Multivariate Time  Series with Bayesian Attentive Neural Processes",
    "abstract": "Among the most extreme objects in the Universe, active galactic nuclei (AGN)\nare luminous centers of galaxies where a black hole feeds on surrounding\nmatter. The variability patterns of the light emitted by an AGN contain\ninformation about the physical properties of the underlying black hole.\nUpcoming telescopes will observe over 100 million AGN in multiple broadband\nwavelengths, yielding a large sample of multivariate time series with long gaps\nand irregular sampling. We present a method that reconstructs the AGN time\nseries and simultaneously infers the posterior probability density distribution\n(PDF) over the physical quantities of the black hole, including its mass and\nluminosity. We apply this method to a simulated dataset of 11,000 AGN and\nreport precision and accuracy of 0.4 dex and 0.3 dex in the inferred black hole\nmass. This work is the first to address probabilistic time series\nreconstruction and parameter inference for AGN in an end-to-end fashion.",
    "descriptor": "\nComments: 6 pages, 4 figures, 1 table, written for non-astronomers, submitted to the ICML 2021 Time Series and Uncertainty and Robustness in Deep Learning Workshops. Comments welcome!\n",
    "authors": [
      "Ji Won Park",
      "Ashley Villar",
      "Yin Li",
      "Yan-Fei Jiang",
      "Shirley Ho",
      "Joshua Yao-Yu Lin",
      "Philip J. Marshall",
      "Aaron Roodman"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01450"
  },
  {
    "id": "arXiv:2106.01474",
    "title": "Testing Directed Acyclic Graph via Structural, Supervised and Generative  Adversarial Learning",
    "abstract": "In this article, we propose a new hypothesis testing method for directed\nacyclic graph (DAG). While there is a rich class of DAG estimation methods,\nthere is a relative paucity of DAG inference solutions. Moreover, the existing\nmethods often impose some specific model structures such as linear models or\nadditive models, and assume independent data observations. Our proposed test\ninstead allows the associations among the random variables to be nonlinear and\nthe data to be time-dependent. We build the test based on some highly flexible\nneural networks learners. We establish the asymptotic guarantees of the test,\nwhile allowing either the number of subjects or the number of time points for\neach subject to diverge to infinity. We demonstrate the efficacy of the test\nthrough simulations and a brain connectivity network analysis.",
    "descriptor": "",
    "authors": [
      "Chengchun Shi",
      "Yunzhe Zhou",
      "Lexin Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01474"
  },
  {
    "id": "arXiv:2106.01481",
    "title": "Quantifying language changes surrounding mental health on Twitter",
    "abstract": "Mental health challenges are thought to afflict around 10% of the global\npopulation each year, with many going untreated due to stigma and limited\naccess to services. Here, we explore trends in words and phrases related to\nmental health through a collection of 1- , 2-, and 3-grams parsed from a data\nstream of roughly 10% of all English tweets since 2012. We examine temporal\ndynamics of mental health language, finding that the popularity of the phrase\n'mental health' increased by nearly two orders of magnitude between 2012 and\n2018. We observe that mentions of 'mental health' spike annually and reliably\ndue to mental health awareness campaigns, as well as unpredictably in response\nto mass shootings, celebrities dying by suicide, and popular fictional stories\nportraying suicide. We find that the level of positivity of messages containing\n'mental health', while stable through the growth period, has declined recently.\nFinally, we use the ratio of original tweets to retweets to quantify the\nfraction of appearances of mental health language due to social amplification.\nSince 2015, mentions of mental health have become increasingly due to retweets,\nsuggesting that stigma associated with discussion of mental health on Twitter\nhas diminished with time.",
    "descriptor": "\nComments: 12 pages, 5 figures, 1 table\n",
    "authors": [
      "Anne Marie Stupinski",
      "Thayer Alshaabi",
      "Michael V. Arnold",
      "Jane Lydia Adams",
      "Joshua R. Minot",
      "Matthew Price",
      "Peter Sheridan Dodds",
      "Christopher M. Danforth"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.01481"
  },
  {
    "id": "arXiv:2106.01484",
    "title": "An Equational Logical Framework for Type Theories",
    "abstract": "A wide range of intuitionistic type theories may be presented as equational\ntheories within a logical framework. This method was formulated by Per\nMartin-L\\\"{o}f in the mid-1980's and further developed by Uemura, who used it\nto prove an initiality result for a class of models. Herein is presented a\nlogical framework for type theories that includes an extensional equality type\nso that a type theory may be given by a signature of constants. The framework\nis illustrated by a number of examples of type-theoretic concepts, including\nidentity and equality types, and a hierarchy of universes.",
    "descriptor": "",
    "authors": [
      "Robert Harper"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.01484"
  },
  {
    "id": "arXiv:2106.01485",
    "title": "Weakly Supervised Learning Creates a Fusion of Modeling Cultures",
    "abstract": "The past two decades have witnessed the great success of the algorithmic\nmodeling framework advocated by Breiman et al. (2001). Nevertheless, the\nexcellent prediction performance of these black-box models rely heavily on the\navailability of strong supervision, i.e. a large set of accurate and exact\nground-truth labels. In practice, strong supervision can be unavailable or\nexpensive, which calls for modeling techniques under weak supervision. In this\ncomment, we summarize the key concepts in weakly supervised learning and\ndiscuss some recent developments in the field. Using algorithmic modeling alone\nunder a weak supervision might lead to unstable and misleading results. A\npromising direction would be integrating the data modeling culture into such a\nframework.",
    "descriptor": "",
    "authors": [
      "Chengliang Tang",
      "Gan Yuan",
      "Tian Zheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.01485"
  },
  {
    "id": "arXiv:2106.01497",
    "title": "IoT Solutions with Multi-Sensor Fusion and Signal-Image Encoding for  Secure Data Transfer and Decision Making",
    "abstract": "Deployment of Internet of Things (IoT) devices and Data Fusion techniques\nhave gained popularity in public and government domains. This usually requires\ncapturing and consolidating data from multiple sources. As datasets do not\nnecessarily originate from identical sensors, fused data typically results in a\ncomplex data problem. Because military is investigating how heterogeneous IoT\ndevices can aid processes and tasks, we investigate a multi-sensor approach.\nMoreover, we propose a signal to image encoding approach to transform\ninformation (signal) to integrate (fuse) data from IoT wearable devices to an\nimage which is invertible and easier to visualize supporting decision making.\nFurthermore, we investigate the challenge of enabling an intelligent\nidentification and detection operation and demonstrate the feasibility of the\nproposed Deep Learning and Anomaly Detection models that can support future\napplication that utilizes hand gesture data from wearable devices.",
    "descriptor": "\nComments: Advances in Mass Data Analysis of Images and Signals in Artificial Intelligence and Pattern Recognition 15th International Conference, MDA 2020 Amsterdam, The Netherlands, July 20-21, 2020. this http URL&PR_2020.pdf\n",
    "authors": [
      "Piyush K. Sharma",
      "Mark Dennison",
      "Adrienne Raglin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01497"
  },
  {
    "id": "arXiv:2106.01498",
    "title": "Efficient computation of statistical properties of intermittent dynamics",
    "abstract": "Intermittent maps of the interval are simple and widely-studied models for\nchaos with slow mixing rates, but have been notoriously resistant to numerical\nstudy. In this paper we present an effective framework to compute many ergodic\nproperties of these systems, in particular invariant measures and mean return\ntimes. The framework combines three ingredients that each harness the smooth\nstructure of these systems' induced maps: Abel functions to compute the action\nof the induced maps, Euler-Maclaurin summation to compute the pointwise action\nof their transfer operators, and Chebyshev Galerkin discretisations to compute\nthe spectral data of the transfer operators. The combination of these\ntechniques allows one to obtain exponential convergence of estimates for\npolynomially growing computational outlay, independent of the order of the\nmap's neutral fixed point. This enables numerical exploration of intermittent\ndynamics in all parameter regimes, including in the infinite ergodic regime.",
    "descriptor": "\nComments: Extract from PhD thesis\n",
    "authors": [
      "Caroline L. Wormell"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2106.01498"
  },
  {
    "id": "arXiv:2106.01524",
    "title": "Combinatorial Conditions for Directed Collapsing",
    "abstract": "The purpose of this article is to study directed collapsibility of directed\nEuclidean cubical complexes. One application of this is in the nontrivial task\nof verifying the execution of concurrent programs. The classical definition of\ncollapsibility involves certain conditions on a pair of cubes of the complex.\nThe direction of the space can be taken into account by requiring that the past\nlinks of vertices remain homotopy equivalent after collapsing. We call this\ntype of collapse a link-preserving directed collapse. In this paper, we give\ncombinatorially equivalent conditions for preserving the topology of the links,\nallowing for the implementation of an algorithm for collapsing a directed\nEuclidean cubical complex. Furthermore, we give conditions for when\nlink-preserving directed collapses preserve the contractability and\nconnectedness of directed path spaces, as well as examples when link-preserving\ndirected collapses do not preserve the number of connected components of the\npath space between the minimum and a given vertex.",
    "descriptor": "\nComments: 22 pages, 11 figures\n",
    "authors": [
      "Robin Belton",
      "Robyn Brooks",
      "Stefania Ebli",
      "Lisbeth Fajstrup",
      "Brittany Terese Fasy",
      "Nicole Sanderson",
      "Elizabeth Vidaurre"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2106.01524"
  },
  {
    "id": "arXiv:2106.01528",
    "title": "Normalizing Flows for Knockoff-free Controlled Feature Selection",
    "abstract": "The goal of controlled feature selection is to discover the features a\nresponse depends on while limiting the proportion of false discoveries to a\npredefined level. Recently, multiple methods have been proposed that use deep\nlearning to generate knockoffs for controlled feature selection through the\nModel-X knockoff framework. We demonstrate, however, that these methods often\nfail to control the false discovery rate (FDR). There are two reasons for this\nshortcoming. First, these methods often learn inaccurate models of features.\nSecond, the \"swap\" property, which is required for knockoffs to be valid, is\noften not well enforced. We propose a new procedure called FlowSelect that\nremedies both of these problems. To more accurately model the features,\nFlowSelect uses normalizing flows, the state-of-the-art method for density\nestimation. To circumvent the need to enforce the swap property, FlowSelect\nuses a novel MCMC-based procedure to directly compute p-values for each\nfeature. Asymptotically, FlowSelect controls the FDR exactly. Empirically,\nFlowSelect controls the FDR well on both synthetic and semi-synthetic\nbenchmarks, whereas competing knockoff-based approaches fail to do so.\nFlowSelect also demonstrates greater power on these benchmarks. Additionally,\nusing data from a genome-wide association study of soybeans, FlowSelect\ncorrectly infers the genetic variants associated with specific soybean traits.",
    "descriptor": "\nComments: 17 pages, 4 figures. Under review at Neurips 2021\n",
    "authors": [
      "Derek Hansen",
      "Brian Manzo",
      "Jeffrey Regier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01528"
  },
  {
    "id": "arXiv:2106.01660",
    "title": "Bandit Phase Retrieval",
    "abstract": "We study a bandit version of phase retrieval where the learner chooses\nactions $(A_t)_{t=1}^n$ in the $d$-dimensional unit ball and the expected\nreward is $\\langle A_t, \\theta_\\star\\rangle^2$ where $\\theta_\\star \\in \\mathbb\nR^d$ is an unknown parameter vector. We prove that the minimax cumulative\nregret in this problem is $\\smash{\\tilde \\Theta(d \\sqrt{n})}$, which improves\non the best known bounds by a factor of $\\smash{\\sqrt{d}}$. We also show that\nthe minimax simple regret is $\\smash{\\tilde \\Theta(d / \\sqrt{n})}$ and that\nthis is only achievable by an adaptive algorithm. Our analysis shows that an\napparently convincing heuristic for guessing lower bounds can be misleading and\nthat uniform bounds on the information ratio for information-directed sampling\nare not sufficient for optimal regret.",
    "descriptor": "",
    "authors": [
      "Tor Lattimore",
      "Botao Hao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.01660"
  },
  {
    "id": "arXiv:2106.01683",
    "title": "Rich dynamics caused by known biological brain network features  resulting in stateful networks",
    "abstract": "The mammalian brain could contain dense and sparse network connectivity\nstructures, including both excitatory and inhibitory neurons, but is without\nany clearly defined output layer. The neurons have time constants, which mean\nthat the integrated network structure has state memory. The network structure\ncontains complex mutual interactions between the neurons under different\nconditions, which depend on the internal state of the network. The internal\nstate can be defined as the distribution of activity across all individual\nneurons across the network. Therefore, the state of a neuron/network becomes a\ndefining factor for how information is represented within the network. Towards\nthis study, we constructed a fully connected (with dense/sparse coding\nstrategies) recurrent network comprising of both excitatory and inhibitory\nneurons, driven by pseudo-random inputs of varying frequencies. In this study\nwe assessed the impact of varying specific intrinsic parameters of the neurons\nthat enriched network state dynamics, such as initial neuron activity, amount\nof inhibition in combination with thresholded neurons and conduction delays.\nThe impact was assessed by quantifying the changes in mutual interactions\nbetween the neurons within the network for each given input. We found such\neffects were more profound in sparsely connected networks than in densely\nconnected networks. However, also densely connected networks could make use of\nsuch dynamic changes in the mutual interactions between neurons, as a given\ninput could induce multiple different network states.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Udaya B. Rongala",
      "Henrik J\u00f6rntell"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01683"
  },
  {
    "id": "arXiv:2106.01700",
    "title": "Machine Learning Based Texture Analysis of Patella from X-Rays for  Detecting Patellofemoral Osteoarthritis",
    "abstract": "Objective is to assess the ability of texture features for detecting\nradiographic patellofemoral osteoarthritis (PFOA) from knee lateral view\nradiographs. We used lateral view knee radiographs from MOST public use\ndatasets (n = 5507 knees). Patellar region-of-interest (ROI) was automatically\ndetected using landmark detection tool (BoneFinder). Hand-crafted features,\nbased on LocalBinary Patterns (LBP), were then extracted to describe the\npatellar texture. First, a machine learning model (Gradient Boosting Machine)\nwas trained to detect radiographic PFOA from the LBP features. Furthermore, we\nused end-to-end trained deep convolutional neural networks (CNNs) directly on\nthe texture patches for detecting the PFOA. The proposed classification models\nwere eventually compared with more conventional reference models that use\nclinical assessments and participant characteristics such as age, sex, body\nmass index(BMI), the total WOMAC score, and tibiofemoral Kellgren-Lawrence (KL)\ngrade. Atlas-guided visual assessment of PFOA status by expert readers provided\nin the MOST public use datasets was used as a classification outcome for the\nmodels. Performance of prediction models was assessed using the area under the\nreceiver operating characteristic curve (ROC AUC), the area under the\nprecision-recall (PR) curve-average precision (AP)-, and Brier score in the\nstratified 5-fold cross validation setting.Of the 5507 knees, 953 (17.3%) had\nPFOA. AUC and AP for the strongest reference model including age, sex, BMI,\nWOMAC score, and tibiofemoral KL grade to predict PFOA were 0.817 and 0.487,\nrespectively. Textural ROI classification using CNN significantly improved the\nprediction performance (ROC AUC= 0.889, AP= 0.714). We present the first study\nthat analyses patellar bone texture for diagnosing PFOA. Our results\ndemonstrates the potential of using texture features of patella to predict\nPFOA.",
    "descriptor": "",
    "authors": [
      "Neslihan Bayramoglu",
      "Miika T. Nieminen",
      "Simo Saarakkala"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01700"
  },
  {
    "id": "arXiv:2106.01718",
    "title": "Fast improvement of TEM image with low-dose electrons by deep learning",
    "abstract": "Low-electron-dose observation is indispensable for observing various samples\nusing a transmission electron microscope; consequently, image processing has\nbeen used to improve transmission electron microscopy (TEM) images. To apply\nsuch image processing to in situ observations, we here apply a convolutional\nneural network to TEM imaging. Using a dataset that includes short-exposure\nimages and long-exposure images, we develop a pipeline for processed\nshort-exposure images, based on end-to-end training. The quality of images\nacquired with a total dose of approximately 5 e- per pixel becomes comparable\nto that of images acquired with a total dose of approximately 1000 e- per\npixel. Because the conversion time is approximately 8 ms, in situ observation\nat 125 fps is possible. This imaging technique enables in situ observation of\nelectron-beam-sensitive specimens.",
    "descriptor": "\nComments: 8 pages, 7 figures, 3 tables\n",
    "authors": [
      "Hiroyasu Katsuno",
      "Yuki Kimura",
      "Tomoya Yamazaki",
      "Ichigaku Takigawa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01718"
  },
  {
    "id": "arXiv:2106.01723",
    "title": "Risk Minimization from Adaptively Collected Data: Guarantees for  Supervised and Policy Learning",
    "abstract": "Empirical risk minimization (ERM) is the workhorse of machine learning,\nwhether for classification and regression or for off-policy policy learning,\nbut its model-agnostic guarantees can fail when we use adaptively collected\ndata, such as the result of running a contextual bandit algorithm. We study a\ngeneric importance sampling weighted ERM algorithm for using adaptively\ncollected data to minimize the average of a loss function over a hypothesis\nclass and provide first-of-their-kind generalization guarantees and fast\nconvergence rates. Our results are based on a new maximal inequality that\ncarefully leverages the importance sampling structure to obtain rates with the\nright dependence on the exploration rate in the data. For regression, we\nprovide fast rates that leverage the strong convexity of squared-error loss.\nFor policy learning, we provide rate-optimal regret guarantees that close an\nopen gap in the existing literature whenever exploration decays to zero, as is\nthe case for bandit-collected data. An empirical investigation validates our\ntheory.",
    "descriptor": "",
    "authors": [
      "Aur\u00e9lien Bibaut",
      "Antoine Chambaz",
      "Maria Dimakopoulou",
      "Nathan Kallus",
      "Mark van der Laan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.01723"
  },
  {
    "id": "arXiv:2106.01739",
    "title": "Advances in Classifying the Stages of Diabetic Retinopathy Using  Convolutional Neural Networks in Low Memory Edge Devices",
    "abstract": "Diabetic Retinopathy (DR) is a severe complication that may lead to retinal\nvascular damage and is one of the leading causes of vision impairment and\nblindness. DR broadly is classified into two stages - non-proliferative (NPDR),\nwhere there are almost no symptoms, except a few microaneurysms, and\nproliferative (PDR) involving a huge number of microaneurysms and hemorrhages,\nsoft and hard exudates, neo-vascularization, macular ischemia or a combination\nof these, making it easier to detect. More specifically, DR is usually\nclassified into five levels, labeled 0-4, from 0 indicating no DR to 4 which is\nmost severe. This paper firstly presents a discussion on the risk factors of\nthe disease, then surveys the recent literature on the topic followed by\nexamining certain techniques which were found to be highly effective in\nimproving the prognosis accuracy. Finally, a convolutional neural network model\nis proposed to detect all the stages of DR on a low-memory edge\nmicrocontroller. The model has a size of just 5.9 MB, accuracy and F1 score\nboth of 94% and an inference speed of about 20 frames per second.",
    "descriptor": "\nComments: This paper is currently under review at IEEE MASCON 2021. this http URL\n",
    "authors": [
      "Aditya Jyoti Paul"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01739"
  },
  {
    "id": "arXiv:2106.01761",
    "title": "Near Optimal Stochastic Algorithms for Finite-Sum Unbalanced  Convex-Concave Minimax Optimization",
    "abstract": "This paper considers stochastic first-order algorithms for convex-concave\nminimax problems of the form $\\min_{\\bf x}\\max_{\\bf y}f(\\bf x, \\bf y)$, where\n$f$ can be presented by the average of $n$ individual components which are\n$L$-average smooth. For $\\mu_x$-strongly-convex-$\\mu_y$-strongly-concave\nsetting, we propose a new method which could find a $\\varepsilon$-saddle point\nof the problem in $\\tilde{\\mathcal O}\n\\big(\\sqrt{n(\\sqrt{n}+\\kappa_x)(\\sqrt{n}+\\kappa_y)}\\log(1/\\varepsilon)\\big)$\nstochastic first-order complexity, where $\\kappa_x\\triangleq L/\\mu_x$ and\n$\\kappa_y\\triangleq L/\\mu_y$. This upper bound is near optimal with respect to\n$\\varepsilon$, $n$, $\\kappa_x$ and $\\kappa_y$ simultaneously. In addition, the\nalgorithm is easily implemented and works well in practical. Our methods can be\nextended to solve more general unbalanced convex-concave minimax problems and\nthe corresponding upper complexity bounds are also near optimal.",
    "descriptor": "",
    "authors": [
      "Luo Luo",
      "Guangzeng Xie",
      "Tong Zhang",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01761"
  },
  {
    "id": "arXiv:2106.01779",
    "title": "Preparation of Many-body Ground States by Time Evolution with  Variational Microscopic Magnetic Fields and Incomplete Interactions",
    "abstract": "State preparation is of fundamental importance in quantum physics, which can\nbe realized by constructing the quantum circuit as a unitary that transforms\nthe initial state to the target, or implementing a quantum control protocol to\nevolve to the target state with a designed Hamiltonian. In this work, we study\nthe latter on quantum many-body systems by the time evolution with fixed\ncouplings and variational magnetic fields. In specific, we consider to prepare\nthe ground states of the Hamiltonians containing certain interactions that are\nmissing in the Hamiltonians for the time evolution. An optimization method is\nproposed to optimize the magnetic fields by \"fine-graining\" the discretization\nof time, in order to gain high precision and stability. The back propagation\ntechnique is utilized to obtain the gradients of the fields against the\nlogarithmic fidelity. Our method is tested on preparing the ground state of\nHeisenberg chain with the time evolution by the XY and Ising interactions, and\nits performance surpasses two baseline methods that use local and global\noptimization strategies, respectively. Our work can be applied and generalized\nto other quantum models such as those defined on higher dimensional lattices.\nIt enlightens to reduce the complexity of the required interactions for\nimplementing quantum control or other tasks in quantum information and\ncomputation by means of optimizing the magnetic fields.",
    "descriptor": "",
    "authors": [
      "Ying Lu",
      "Yue-Min Li",
      "Peng-Fei Zhou",
      "Shi-Ju Ran"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01779"
  },
  {
    "id": "arXiv:2106.01789",
    "title": "Speaker verification-derived loss and data augmentation for DNN-based  multispeaker speech synthesis",
    "abstract": "Building multispeaker neural network-based text-to-speech synthesis systems\ncommonly relies on the availability of large amounts of high quality recordings\nfrom each speaker and conditioning the training process on the speaker's\nidentity or on a learned representation of it. However, when little data is\navailable from each speaker, or the number of speakers is limited, the\nmultispeaker TTS can be hard to train and will result in poor speaker\nsimilarity and naturalness.\nIn order to address this issue, we explore two directions: forcing the\nnetwork to learn a better speaker identity representation by appending an\nadditional loss term; and augmenting the input data pertaining to each speaker\nusing waveform manipulation methods. We show that both methods are efficient\nwhen evaluated with both objective and subjective measures. The additional loss\nterm aids the speaker similarity, while the data augmentation improves the\nintelligibility of the multispeaker TTS system.",
    "descriptor": "\nComments: Accepted at EUSIPCO 2021\n",
    "authors": [
      "Beata Lorincz",
      "Adriana Stan",
      "Mircea Giurgiu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.01789"
  },
  {
    "id": "arXiv:2106.01812",
    "title": "An objective evaluation of the effects of recording conditions and  speaker characteristics in multi-speaker deep neural speech synthesis",
    "abstract": "Multi-speaker spoken datasets enable the creation of text-to-speech synthesis\n(TTS) systems which can output several voice identities. The multi-speaker\n(MSPK) scenario also enables the use of fewer training samples per speaker.\nHowever, in the resulting acoustic model, not all speakers exhibit the same\nsynthetic quality, and some of the voice identities cannot be used at all.\nIn this paper we evaluate the influence of the recording conditions, speaker\ngender, and speaker particularities over the quality of the synthesised output\nof a deep neural TTS architecture, namely Tacotron2. The evaluation is possible\ndue to the use of a large Romanian parallel spoken corpus containing over 81\nhours of data. Within this setup, we also evaluate the influence of different\ntypes of text representations: orthographic, phonetic, and phonetic extended\nwith syllable boundaries and lexical stress markings.\nWe evaluate the results of the MSPK system using the objective measures of\nequal error rate (EER) and word error rate (WER), and also look into the\ndistances between natural and synthesised t-SNE projections of the embeddings\ncomputed by an accurate speaker verification network. The results show that\nthere is indeed a large correlation between the recording conditions and the\nspeaker's synthetic voice quality. The speaker gender does not influence the\noutput, and that extending the input text representation with syllable\nboundaries and lexical stress information does not equally enhance the\ngenerated audio across all speaker identities. The visualisation of the t-SNE\nprojections of the natural and synthesised speaker embeddings show that the\nacoustic model shifts some of the speakers' neural representation, but not all\nof them. As a result, these speakers have lower performances of the output\nspeech.",
    "descriptor": "\nComments: Accepted at 25th International Conference on Knowledge-Based and Intelligent Information & Engineering Systems (KES 2021)\n",
    "authors": [
      "Beata Lorincz",
      "Adriana Stan",
      "Mircea Giurgiu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.01812"
  },
  {
    "id": "arXiv:2106.01830",
    "title": "Effort-free Automated Skeletal Abnormality Detection of Rat Fetuses on  Whole-body Micro-CT Scans",
    "abstract": "Machine Learning-based fast and quantitative automated screening plays a key\nrole in analyzing human bones on Computed Tomography (CT) scans. However,\ndespite the requirement in drug safety assessment, such research is rare on\nanimal fetus micro-CT scans due to its laborious data collection and\nannotation. Therefore, we propose various bone feature engineering techniques\nto thoroughly automate the skeletal localization/labeling/abnormality detection\nof rat fetuses on whole-body micro-CT scans with minimum effort. Despite\nlimited training data of 49 fetuses, in skeletal labeling and abnormality\ndetection, we achieve accuracy of 0.900 and 0.810, respectively.",
    "descriptor": "\nComments: 5 pages, 5 figures, accepted to ICIP 2021\n",
    "authors": [
      "Akihiro Fukuda",
      "Changhee Han",
      "Kazumi Hakamada"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01830"
  },
  {
    "id": "arXiv:2106.01835",
    "title": "Deep Learning Based Analysis of Prostate Cancer from MP-MRI",
    "abstract": "The diagnosis of prostate cancer faces a problem with overdiagnosis that\nleads to damaging side effects due to unnecessary treatment. Research has shown\nthat the use of multi-parametric magnetic resonance images to conduct biopsies\ncan drastically help to mitigate the overdiagnosis, thus reducing the side\neffects on healthy patients. This study aims to investigate the use of deep\nlearning techniques to explore computer-aid diagnosis based on MRI as input.\nSeveral diagnosis problems ranging from classification of lesions as being\nclinically significant or not to the detection and segmentation of lesions are\naddressed with deep learning based approaches.\nThis thesis tackled two main problems regarding the diagnosis of prostate\ncancer. Firstly, XmasNet was used to conduct two large experiments on the\nclassification of lesions. Secondly, detection and segmentation experiments\nwere conducted, first on the prostate and afterward on the prostate cancer\nlesions. The former experiments explored the lesions through a two-dimensional\nspace, while the latter explored models to work with three-dimensional inputs.\nFor this task, the 3D models explored were the 3D U-Net and a pretrained 3D\nResNet-18. A rigorous analysis of all these problems was conducted with a total\nof two networks, two cropping techniques, two resampling techniques, two crop\nsizes, five input sizes and data augmentations experimented for lesion\nclassification. While for segmentation two models, two input sizes and data\naugmentations were experimented. However, while the binary classification of\nthe clinical significance of lesions and the detection and segmentation of the\nprostate already achieve the desired results (0.870 AUC and 0.915 dice score\nrespectively), the classification of the PIRADS score and the segmentation of\nlesions still have a large margin to improve (0.664 accuracy and 0.690 dice\nscore respectively).",
    "descriptor": "",
    "authors": [
      "Pedro C. Neto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01835"
  },
  {
    "id": "arXiv:2106.01836",
    "title": "DNA-GCN: Graph convolutional networks for predicting DNA-protein binding",
    "abstract": "Predicting DNA-protein binding is an important and classic problem in\nbioinformatics. Convolutional neural networks have outperformed conventional\nmethods in modeling the sequence specificity of DNA-protein binding. However,\nnone of the studies has utilized graph convolutional networks for motif\ninference. In this work, we propose to use graph convolutional networks for\nmotif inference. We build a sequence k-mer graph for the whole dataset based on\nk-mer co-occurrence and k-mer sequence relationship and then learn DNA Graph\nConvolutional Network (DNA-GCN) for the whole dataset. Our DNA-GCN is\ninitialized with a one-hot representation for all nodes, and it then jointly\nlearns the embeddings for both k-mers and sequences, as supervised by the known\nlabels of sequences. We evaluate our model on 50 datasets from ENCODE. DNA-GCN\nshows its competitive performance compared with the baseline model. Besides, we\nanalyze our model and design several different architectures to help fit\ndifferent datasets.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Yuhang Guo",
      "Xiao Luo",
      "Liang Chen",
      "Minghua Deng"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01836"
  },
  {
    "id": "arXiv:2106.01858",
    "title": "Statistical embedding: Beyond principal components",
    "abstract": "There has been an intense recent activity in embedding of very high\ndimensional and nonlinear data structures, much of it in the data science and\nmachine learning literature. We survey this activity in four parts. In the\nfirst part we cover nonlinear methods such as principal curves,\nmultidimensional scaling, local linear methods, ISOMAP, graph based methods and\nkernel based methods. The second part is concerned with topological embedding\nmethods, in particular mapping topological properties into persistence\ndiagrams. Another type of data sets with a tremendous growth is very\nhigh-dimensional network data. The task considered in part three is how to\nembed such data in a vector space of moderate dimension to make the data\namenable to traditional techniques such as cluster and classification\ntechniques. The final part of the survey deals with embedding in\n$\\mathbb{R}^2$, which is visualization. Three methods are presented: $t$-SNE,\nUMAP and LargeVis based on methods in parts one, two and three, respectively.\nThe methods are illustrated and compared on two simulated data sets; one\nconsisting of a triple of noisy Ranunculoid curves, and one consisting of\nnetworks of increasing complexity and with two types of nodes.",
    "descriptor": "",
    "authors": [
      "Dag Tj\u00f8stheim",
      "Martin Jullum",
      "Anders L\u00f8land"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.01858"
  },
  {
    "id": "arXiv:2106.01860",
    "title": "Noisy Labels are Treasure: Mean-Teacher-Assisted Confident Learning for  Hepatic Vessel Segmentation",
    "abstract": "Manually segmenting the hepatic vessels from Computer Tomography (CT) is far\nmore expertise-demanding and laborious than other structures due to the\nlow-contrast and complex morphology of vessels, resulting in the extreme lack\nof high-quality labeled data. Without sufficient high-quality annotations, the\nusual data-driven learning-based approaches struggle with deficient training.\nOn the other hand, directly introducing additional data with low-quality\nannotations may confuse the network, leading to undesirable performance\ndegradation. To address this issue, we propose a novel mean-teacher-assisted\nconfident learning framework to robustly exploit the noisy labeled data for the\nchallenging hepatic vessel segmentation task. Specifically, with the adapted\nconfident learning assisted by a third party, i.e., the weight-averaged teacher\nmodel, the noisy labels in the additional low-quality dataset can be\ntransformed from \"encumbrance\" to \"treasure\" via progressive pixel-wise\nsoft-correction, thus providing productive guidance. Extensive experiments\nusing two public datasets demonstrate the superiority of the proposed framework\nas well as the effectiveness of each component.",
    "descriptor": "\nComments: 11 pages, to appear in MICCAI 2021\n",
    "authors": [
      "Zhe Xu",
      "Donghuan Lu",
      "Yixin Wang",
      "Jie Luo",
      "Jayender Jagadeesan",
      "Kai Ma",
      "Yefeng Zheng",
      "Xiu Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01860"
  },
  {
    "id": "arXiv:2106.01861",
    "title": "Separated-Spectral-Distribution Estimation Based on Bayesian Inference  with Single RGB Camera",
    "abstract": "In this paper, we propose a novel method for separately estimating spectral\ndistributions from images captured by a typical RGB camera. The proposed method\nallows us to separately estimate a spectral distribution of illumination,\nreflectance, or camera sensitivity, while recent hyperspectral cameras are\nlimited to capturing a joint spectral distribution from a scene. In addition,\nthe use of Bayesian inference makes it possible to take into account prior\ninformation of both spectral distributions and image noise as probability\ndistributions. As a result, the proposed method can estimate spectral\ndistributions in a unified way, and it can enhance the robustness of the\nestimation against noise, which conventional spectral-distribution estimation\nmethods cannot. The use of Bayesian inference also enables us to obtain the\nconfidence of estimation results. In an experiment, the proposed method is\nshown not only to outperform conventional estimation methods in terms of RMSE\nbut also to be robust against noise.",
    "descriptor": "\nComments: to appear in IEEE ICIP 2021\n",
    "authors": [
      "Yuma Kinoshita",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.01861"
  },
  {
    "id": "arXiv:2106.01896",
    "title": "Denoising and Optical and SAR Image Classifications Based on Feature  Extraction and Sparse Representation",
    "abstract": "Optical image data have been used by the Remote Sensing workforce to study\nland use and cover since such data is easily interpretable. Synthetic Aperture\nRadar (SAR) has the characteristic of obtaining images during all-day,\nall-weather and provides object information that is different from visible and\ninfrared sensors. However, SAR images have more speckle noise and fewer\ndimensions. This paper presents a method for denoising, feature extraction and\ncompares classifications of Optical and SAR images. The image was denoised\nusing K-Singular Value Decomposition (K-SVD) algorithm. A method to map the\nextraordinary goal signatures to be had withinside the SAR or Optical image\nusing support vector machine (SVM) through offering given the enter facts to\nthe supervised classifier. Initially, the Gray Level Histogram (GLH) and Gray\nLevel Co-occurrence Matrix (GLCM) are used for feature extraction. Secondly,\nthe extracted feature vectors from the first step were combined using\ncorrelation analysis to reduce the dimensionality of the feature spaces.\nThirdly, the Classification of SAR images was done in Sparse Representations\nClassification (SRC). The above-mentioned classifications techniques were\ndeveloped and performance parameters are accuracy and Kappa Coefficient\ncalculated using MATLAB 2018a.",
    "descriptor": "",
    "authors": [
      "Battula Balnarsaiah",
      "G Rajitha"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01896"
  },
  {
    "id": "arXiv:2106.01902",
    "title": "Joint Multi-Channel Dereverberation and Noise Reduction Using a Unified  Convolutional Beamformer With Sparse Priors",
    "abstract": "Recently, the convolutional weighted power minimization distortionless\nresponse (WPD) beamformer was proposed, which unifies multi-channel weighted\nprediction error dereverberation and minimum power distortionless response\nbeamforming. To optimize the convolutional filter, the desired speech component\nis modeled with a time-varying Gaussian model, which promotes the sparsity of\nthe desired speech component in the short-time Fourier transform domain\ncompared to the noisy microphone signals. In this paper we generalize the\nconvolutional WPD beamformer by using an lp-norm cost function, introducing an\nadjustable shape parameter which enables to control the sparsity of the desired\nspeech component. Experiments based on the REVERB challenge dataset show that\nthe proposed method outperforms the conventional convolutional WPD beamformer\nin terms of objective speech quality metrics.",
    "descriptor": "\nComments: ITG Conference on Speech Communication\n",
    "authors": [
      "Henri Gode",
      "Marvin Tammen",
      "Simon Doclo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.01902"
  },
  {
    "id": "arXiv:2106.01907",
    "title": "Robotic Inspection and 3D GPR-based Reconstruction for Underground  Utilities",
    "abstract": "Ground Penetrating Radar (GPR) is an effective non-destructive evaluation\n(NDE) device for inspecting and surveying subsurface objects (i.e., rebars,\nutility pipes) in complex environments. However, the current practice for GPR\ndata collection requires a human inspector to move a GPR cart along pre-marked\ngrid lines and record the GPR data in both X and Y directions for\npost-processing by 3D GPR imaging software. It is time-consuming and tedious\nwork to survey a large area. Furthermore, identifying the subsurface targets\ndepends on the knowledge of an experienced engineer, who has to make manual and\nsubjective interpretation that limits the GPR applications, especially in\nlarge-scale scenarios. In addition, the current GPR imaging technology is not\nintuitive, and not for normal users to understand, and not friendly to\nvisualize. To address the above challenges, this paper presents a novel robotic\nsystem to collect GPR data, interpret GPR data, localize the underground\nutilities, reconstruct and visualize the underground objects' dense point cloud\nmodel in a user-friendly manner. This system is composed of three modules: 1) a\nvision-aided Omni-directional robotic data collection platform, which enables\nthe GPR antenna to scan the target area freely with an arbitrary trajectory\nwhile using a visual-inertial-based positioning module tags the GPR\nmeasurements with positioning information; 2) a deep neural network (DNN)\nmigration module to interpret the raw GPR B-scan image into a cross-section of\nobject model; 3) a DNN-based 3D reconstruction method, i.e., GPRNet, to\ngenerate underground utility model represented as fine 3D point cloud.\nComparative studies on synthetic and field GPR raw data with various\nincompleteness and noise are performed.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2011.02635\n",
    "authors": [
      "Jinglun Feng",
      "Liang Yang",
      "Jiang Biao",
      "Jizhong Xiao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01907"
  },
  {
    "id": "arXiv:2106.01915",
    "title": "Pathology-Aware Generative Adversarial Networks for Medical Image  Augmentation",
    "abstract": "Convolutional Neural Networks (CNNs) can play a key role in Medical Image\nAnalysis under large-scale annotated datasets. However, preparing such massive\ndataset is demanding. In this context, Generative Adversarial Networks (GANs)\ncan generate realistic but novel samples, and thus effectively cover the real\nimage distribution. In terms of interpolation, the GAN-based medical image\naugmentation is reliable because medical modalities can display the human\nbody's strong anatomical consistency at fixed position while clearly reflecting\ninter-subject variability; thus, we propose to use noise-to-image GANs (e.g.,\nrandom noise samples to diverse pathological images) for (i) medical Data\nAugmentation (DA) and (ii) physician training. Regarding the DA, the\nGAN-generated images can improve Computer-Aided Diagnosis based on supervised\nlearning. For the physician training, the GANs can display novel desired\npathological images and help train medical trainees despite\ninfrastructural/legal constraints. This thesis contains four GAN projects\naiming to present such novel applications' clinical relevance in collaboration\nwith physicians. Whereas the methods are more generally applicable, this thesis\nonly explores a few oncological applications.",
    "descriptor": "\nComments: Ph.D. Thesis (The University of Tokyo) defended in February, 2020. Based on GAN-based synthetic brain MR image generation (ISBI 2018), arXiv:1902.09856, arXiv:1903.12564, arXiv:1905.13456, arXiv:1906.04962, arXiv:2001.03923\n",
    "authors": [
      "Changhee Han"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01915"
  },
  {
    "id": "arXiv:2106.01921",
    "title": "Sample Selection Bias in Evaluation of Prediction Performance of Causal  Models",
    "abstract": "Causal models are notoriously difficult to validate because they make\nuntestable assumptions regarding confounding. New scientific experiments offer\nthe possibility of evaluating causal models using prediction performance.\nPrediction performance measures are typically robust to violations in causal\nassumptions. However prediction performance does depend on the selection of\ntraining and test sets. In particular biased training sets can lead to\noptimistic assessments of model performance. In this work, we revisit the\nprediction performance of several recently proposed causal models tested on a\ngenetic perturbation data set of Kemmeren [Kemmeren et al., 2014]. We find that\nsample selection bias is likely a key driver of model performance. We propose\nusing a less-biased evaluation set for assessing prediction performance on\nKemmeren and compare models on this new set. In this setting, the causal model\ntested have similar performance to standard association based estimators such\nas Lasso. Finally we compare the performance of causal estimators in simulation\nstudies which reproduce the Kemmeren structure of genetic knockout experiments\nbut without any sample selection bias. These results provide an improved\nunderstanding of the performance of several causal models and offer guidance on\nhow future studies should use Kemmeren.",
    "descriptor": "\nComments: 10 pages, 4 figures, 2 tables\n",
    "authors": [
      "James P. Long",
      "Min Jin Ha"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.01921"
  },
  {
    "id": "arXiv:2106.01930",
    "title": "Tropical linear regression and mean payoff games: or, how to measure the  distance to equilibria",
    "abstract": "We study a tropical linear regression problem consisting in finding the best\napproximation of a set of points by a tropical hyperplane. We establish a\nstrong duality theorem, showing that the value of this problem coincides with\nthe maximal radius of a Hilbert's ball included in a tropical polyhedron. We\nalso show that this regression problem is polynomial-time equivalent to mean\npayoff games. We illustrate our results by solving an inverse problem from\nauction theory. In this setting, a tropical hyperplane represents the set of\nequilibrium prices. Tropical linear regression allows us to quantify the\ndistance of a market to the set of equilibria, and infer secret preferences of\na decision maker.",
    "descriptor": "",
    "authors": [
      "Marianne Akian",
      "St\u00e9phane Gaubert",
      "Yang Qi",
      "Omar Saadi"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.01930"
  },
  {
    "id": "arXiv:2106.01933",
    "title": "An Improved Model for Voicing Silent Speech",
    "abstract": "In this paper, we present an improved model for voicing silent speech, where\naudio is synthesized from facial electromyography (EMG) signals. To give our\nmodel greater flexibility to learn its own input features, we directly use EMG\nsignals as input in the place of hand-designed features used by prior work. Our\nmodel uses convolutional layers to extract features from the signals and\nTransformer layers to propagate information across longer distances. To provide\nbetter signal for learning, we also introduce an auxiliary task of predicting\nphoneme labels in addition to predicting speech audio features. On an open\nvocabulary intelligibility evaluation, our model improves the state of the art\nfor this task by an absolute 25.8%.",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "David Gaddy",
      "Dan Klein"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.01933"
  },
  {
    "id": "arXiv:2106.01946",
    "title": "Convex optimization",
    "abstract": "This textbook is based on lectures given by the authors at MIPT (Moscow), HSE\n(Moscow), FEFU (Vladivostok), V.I. Vernadsky KFU (Simferopol), ASU (Republic of\nAdygea), and the University of Grenoble-Alpes (Grenoble, France). First of all,\nthe authors focused on the program of a two-semester course of lectures on\nconvex optimization, which is given to students of MIPT. The first chapter of\nthis book contains the materials of the first semester (\"Fundamentals of convex\nanalysis and optimization\"), the second and third chapters contain the\nmaterials of the second semester (\"Numerical methods of convex optimization\").\nThe textbook has a number of features. First, in contrast to the classic\nmanuals, this book does not provide proofs of all the theorems mentioned. This\nallowed, on one side, to describe more themes, but on the other side, made the\npresentation less self-sufficient. The second important point is that part of\nthe material is advanced and is published in the Russian educational\nliterature, apparently for the first time. Third, the accents that are given do\nnot always coincide with the generally accepted accents in the textbooks that\nare now popular. First of all, we talk about a sufficiently advanced\npresentation of conic optimization, including robust optimization, as a vivid\ndemonstration of the capabilities of modern convex analysis.",
    "descriptor": "\nComments: 364 pages, in Russian\n",
    "authors": [
      "Evgeniya Vorontsova",
      "Roland Hildebrand",
      "Alexander Gasnikov",
      "Fedor Stonyakin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01946"
  },
  {
    "id": "arXiv:2106.01947",
    "title": "The Smoothed Satisfaction of Voting Axioms",
    "abstract": "We initiate the work towards a comprehensive picture of the smoothed\nsatisfaction of voting axioms, to provide a finer and more realistic foundation\nfor comparing voting rules. We adopt the smoothed social choice framework,\nwhere an adversary chooses arbitrarily correlated \"ground truth\" preferences\nfor the agents, on top of which random noises are added. We focus on\ncharacterizing the smoothed satisfaction of two well-studied voting axioms:\nCondorcet criterion and participation. We prove that for any fixed number of\nalternatives, when the number of voters $n$ is sufficiently large, the smoothed\nsatisfaction of the Condorcet criterion under a wide range of voting rules is\n$1$, $1-\\exp(-\\Theta(n))$, $\\Theta(n^{-0.5})$, $ \\exp(-\\Theta(n))$, or being\n$\\Theta(1)$ and $1-\\Theta(1)$ at the same time; and the smoothed satisfaction\nof participation is $1-\\Theta(n^{-0.5})$. Our results address open questions by\nBerg and Lepelley in 1994 for these rules, and also confirm the following\nhigh-level message: the Condorcet criterion is a bigger concern than\nparticipation under realistic models.",
    "descriptor": "",
    "authors": [
      "Lirong Xia"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01947"
  },
  {
    "id": "arXiv:2106.01975",
    "title": "Machine Learning and Variational Algorithms for Lattice Field Theory",
    "abstract": "In lattice quantum field theory studies, parameters defining the lattice\ntheory must be tuned toward criticality to access continuum physics. Commonly\nused Markov chain Monte Carlo (MCMC) methods suffer from critical slowing down\nin this limit, restricting the precision of continuum extrapolations. Further\ndifficulties arise when measuring correlation functions of operators widely\nseparated in spacetime: for most correlation functions, an exponentially severe\nsignal-to-noise problem is encountered as the operators are taken to be widely\nseparated. This dissertation details two new techniques to address these\nissues. First, we define a novel MCMC algorithm based on generative flow-based\nmodels. Such models utilize machine learning methods to describe efficient\napproximate samplers for distributions of interest. Independently drawn\nflow-based samples are then used as proposals in an asymptotically exact\nMetropolis-Hastings Markov chain. We address incorporating symmetries of\ninterest, including translational and gauge symmetries. We secondly introduce\nan approach to \"deform\" Monte Carlo estimators based on contour deformations\napplied to the domain of the path integral. The deformed estimators associated\nwith an observable give equivalent unbiased measurements of that observable,\nbut generically have different variances. We define families of deformed\nmanifolds for lattice gauge theories and introduce methods to efficiently\noptimize the choice of manifold (the \"observifold\"), minimizing the deformed\nobservable variance. Finally, we demonstrate that flow-based MCMC can mitigate\ncritical slowing down and observifolds can exponentially reduce variance in\nproof-of-principle applications to scalar $\\phi^4$ theory and $\\mathrm{U}(1)$\nand $\\mathrm{SU}(N)$ lattice gauge theories.",
    "descriptor": "\nComments: PhD Thesis, MIT (June 2021). Based on work appearing in arXiv:2101.12668, arXiv:2008.05456, arXiv:2003.06413, arXiv:2003.05914, arXiv:1904.12072, arXiv:1806.01832, arXiv:2101.08176, arXiv:2002.02428, and arXiv:1811.03944\n",
    "authors": [
      "Gurtej Kanwar"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01975"
  },
  {
    "id": "arXiv:2106.01982",
    "title": "Gaussian Processes on Hypergraphs",
    "abstract": "We derive a Matern Gaussian process (GP) on the vertices of a hypergraph.\nThis enables estimation of regression models of observed or latent values\nassociated with the vertices, in which the correlation and uncertainty\nestimates are informed by the hypergraph structure. We further present a\nframework for embedding the vertices of a hypergraph into a latent space using\nthe hypergraph GP. Finally, we provide a scheme for identifying a small number\nof representative inducing vertices that enables scalable inference through\nsparse GPs. We demonstrate the utility of our framework on three challenging\nreal-world problems that concern multi-class classification for the political\nparty affiliation of legislators on the basis of voting behaviour,\nprobabilistic matrix factorisation of movie reviews, and embedding a hypergraph\nof animals into a low-dimensional latent space.",
    "descriptor": "\nComments: 25 pages, 6 figures\n",
    "authors": [
      "Thomas Pinder",
      "Kathryn Turnbull",
      "Christopher Nemeth",
      "David Leslie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01982"
  },
  {
    "id": "arXiv:2106.01986",
    "title": "Gradient Boosted Binary Histogram Ensemble for Large-scale Regression",
    "abstract": "In this paper, we propose a gradient boosting algorithm for large-scale\nregression problems called \\textit{Gradient Boosted Binary Histogram Ensemble}\n(GBBHE) based on binary histogram partition and ensemble learning. From the\ntheoretical perspective, by assuming the H\\\"{o}lder continuity of the target\nfunction, we establish the statistical convergence rate of GBBHE in the space\n$C^{0,\\alpha}$ and $C^{1,0}$, where a lower bound of the convergence rate for\nthe base learner demonstrates the advantage of boosting. Moreover, in the space\n$C^{1,0}$, we prove that the number of iterations to achieve the fast\nconvergence rate can be reduced by using ensemble regressor as the base\nlearner, which improves the computational efficiency. In the experiments,\ncompared with other state-of-the-art algorithms such as gradient boosted\nregression tree (GBRT), Breiman's forest, and kernel-based methods, our GBBHE\nalgorithm shows promising performance with less running time on large-scale\ndatasets.",
    "descriptor": "",
    "authors": [
      "Hanyuan Hang",
      "Tao Huang",
      "Yuchao Cai",
      "Hanfang Yang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01986"
  },
  {
    "id": "arXiv:2106.02005",
    "title": "Limits of quantum speed-ups for computational geometry and other  problems: Fine-grained complexity via quantum walks",
    "abstract": "Many computational problems are subject to a quantum speed-up: one might find\nthat a problem having an O(n^3)-time or O(n^2)-time classic algorithm can be\nsolved by a known O(n^1.5)-time or O(n)-time quantum algorithm. The question\nnaturally arises: how much quantum speed-up is possible?\nThe area of fine-grained complexity allows us to prove optimal lower-bounds\non the complexity of various computational problems, based on the conjectured\nhardness of certain natural, well-studied problems. This theory has recently\nbeen extended to the quantum setting, in two independent papers by Buhrman,\nPatro, and Speelman (arXiv:1911.05686), and by Aaronson, Chia, Lin, Wang, and\nZhang (arXiv:1911.01973).\nIn this paper, we further extend the theory of fine-grained complexity to the\nquantum setting. A fundamental conjecture in the classical setting states that\nthe 3SUM problem cannot be solved by (classical) algorithms in time O(n^{2-a}),\nfor any a>0. We formulate an analogous conjecture, the Quantum-3SUM-Conjecture,\nwhich states that there exist no sublinear O(n^{1-b})-time quantum algorithms\nfor the 3SUM problem.\nBased on the Quantum-3SUM-Conjecture, we show new lower-bounds on the time\ncomplexity of quantum algorithms for several computational problems. Most of\nour lower-bounds are optimal, in that they match known upper-bounds, and hence\nthey imply tight limits on the quantum speedup that is possible for these\nproblems.",
    "descriptor": "",
    "authors": [
      "Harry Buhrman",
      "Bruno Loff",
      "Subhasree Patro",
      "Florian Speelman"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.02005"
  },
  {
    "id": "arXiv:2106.02029",
    "title": "Off-Policy Evaluation via Adaptive Weighting with Data from Contextual  Bandits",
    "abstract": "It has become increasingly common for data to be collected adaptively, for\nexample using contextual bandits. Historical data of this type can be used to\nevaluate other treatment assignment policies to guide future innovation or\nexperiments. However, policy evaluation is challenging if the target policy\ndiffers from the one used to collect data, and popular estimators, including\ndoubly robust (DR) estimators, can be plagued by bias, excessive variance, or\nboth. In particular, when the pattern of treatment assignment in the collected\ndata looks little like the pattern generated by the policy to be evaluated, the\nimportance weights used in DR estimators explode, leading to excessive\nvariance.\nIn this paper, we improve the DR estimator by adaptively weighting\nobservations to control its variance. We show that a t-statistic based on our\nimproved estimator is asymptotically normal under certain conditions, allowing\nus to form confidence intervals and test hypotheses. Using synthetic data and\npublic benchmarks, we provide empirical evidence for our estimator's improved\naccuracy and inferential properties relative to existing alternatives.",
    "descriptor": "",
    "authors": [
      "Ruohan Zhan",
      "Vitor Hadad",
      "David A. Hirshberg",
      "Susan Athey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2106.02029"
  },
  {
    "id": "arXiv:1701.01055",
    "title": "Estimation of block sparsity in compressive sensing",
    "abstract": "Estimation of block sparsity in compressive sensing",
    "descriptor": "",
    "authors": [
      "Zhiyong Zhou",
      "Jun Yu"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1701.01055"
  },
  {
    "id": "arXiv:1901.09559",
    "title": "Capacity Optimality of AMP in Coded Systems",
    "abstract": "Comments: Accepted by IEEE Trans. on Information Theory, 16 pages, 17 figures. [A low-complexity capacity optimal AMP is designed for large random linear systems with arbitrary input distributions based on matched FEC coding.]",
    "descriptor": "\nComments: Accepted by IEEE Trans. on Information Theory, 16 pages, 17 figures. [A low-complexity capacity optimal AMP is designed for large random linear systems with arbitrary input distributions based on matched FEC coding.]\n",
    "authors": [
      "Lei Liu",
      "Chulong Liang",
      "Junjie Ma",
      "Li Ping"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1901.09559"
  },
  {
    "id": "arXiv:1903.06519",
    "title": "Spectroscopic Approach to Correction and Visualisation of Bright-Field  Light Transmission Microscopy Biological Data",
    "abstract": "Comments: 16 pages, 10 figures",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Ganna Platonova",
      "Dalibor Stys",
      "Pavel Soucek",
      "Kirill Lonhus",
      "Jan Valenta",
      "Renata Rychtarikova"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1903.06519"
  },
  {
    "id": "arXiv:1905.04629",
    "title": "Efficient Low-Rank Semidefinite Programming with Robust Loss Functions",
    "abstract": "Comments: Preprint version. Final version is accepted to \"IEEE Transactions on Pattern Analysis and Machine Intelligence\"",
    "descriptor": "\nComments: Preprint version. Final version is accepted to \"IEEE Transactions on Pattern Analysis and Machine Intelligence\"\n",
    "authors": [
      "Quanming Yao",
      "Hangsi Yang",
      "En-Liang Hu",
      "James Kwok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.04629"
  },
  {
    "id": "arXiv:1905.12629",
    "title": "A New Multilabel System for Automatic Music Emotion Recognition",
    "abstract": "Comments: 2 tables. Research supported by the EU through the MUSICAL-MOODS project funded by the Marie Sklodowska-Curie Actions Individual Fellowships Global Fellowships (MSCA-IF-GF) of the Horizon 2020 Programme H2020/2014-2020, REA grant agreement n.659434",
    "descriptor": "\nComments: 2 tables. Research supported by the EU through the MUSICAL-MOODS project funded by the Marie Sklodowska-Curie Actions Individual Fellowships Global Fellowships (MSCA-IF-GF) of the Horizon 2020 Programme H2020/2014-2020, REA grant agreement n.659434\n",
    "authors": [
      "Fabio Paolizzo",
      "Natalia Pichierri",
      "Daniele Casali",
      "Daniele Giardino",
      "Marco Matta",
      "Giovanni Costantini"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.12629"
  },
  {
    "id": "arXiv:1906.09505",
    "title": "Error Tolerant Path Planning for Swarms of Micro Aerial Vehicles with  Quality Amplification",
    "abstract": "Comments: An early version of this paper appeared in the proceedings of IEEE GLOBECOM 2019, Waikoloa, Hawaii, Dec 9-14, 2019",
    "descriptor": "\nComments: An early version of this paper appeared in the proceedings of IEEE GLOBECOM 2019, Waikoloa, Hawaii, Dec 9-14, 2019\n",
    "authors": [
      "Michel Barbeau",
      "Joaquin Garcia-Alfaro",
      "Evangelos Kranakis",
      "Fillipe Santos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1906.09505"
  },
  {
    "id": "arXiv:1907.08228",
    "title": "TED-On: A Total Error Framework for Digital Traces of Human Behavior on  Online Platforms",
    "abstract": "Comments: 20 pages, 2 figures, Longer version of paper set to appear in Public Opinion Quarterly. Updating terminology",
    "descriptor": "\nComments: 20 pages, 2 figures, Longer version of paper set to appear in Public Opinion Quarterly. Updating terminology\n",
    "authors": [
      "Indira Sen",
      "Fabian Floeck",
      "Katrin Weller",
      "Bernd Weiss",
      "Claudia Wagner"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1907.08228"
  },
  {
    "id": "arXiv:1909.00257",
    "title": "Mapping Firms' Locations in Technological Space: A Topological Analysis  of Patent Statistics",
    "abstract": "Comments: 31 pages (main text), 10 pages (Appendix), 9 tables and 14 figures",
    "descriptor": "\nComments: 31 pages (main text), 10 pages (Appendix), 9 tables and 14 figures\n",
    "authors": [
      "Emerson G. Escolar",
      "Yasuaki Hiraoka",
      "Mitsuru Igami",
      "Yasin Ozcan"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Discrete Mathematics (cs.DM)",
      "Algebraic Topology (math.AT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1909.00257"
  },
  {
    "id": "arXiv:1910.14657",
    "title": "Stochastic Transport with L\u00e9vy Noise -- Fully Discrete Numerical  Approximation",
    "abstract": "Stochastic Transport with L\u00e9vy Noise -- Fully Discrete Numerical  Approximation",
    "descriptor": "",
    "authors": [
      "Andrea Barth",
      "Andreas Stein"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1910.14657"
  },
  {
    "id": "arXiv:1911.03070",
    "title": "Interactive Refinement of Cross-Lingual Word Embeddings",
    "abstract": "Comments: EMNLP 2020; first two authors contribute equally",
    "descriptor": "\nComments: EMNLP 2020; first two authors contribute equally\n",
    "authors": [
      "Michelle Yuan",
      "Mozhi Zhang",
      "Benjamin Van Durme",
      "Leah Findlater",
      "Jordan Boyd-Graber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.03070"
  },
  {
    "id": "arXiv:1911.04436",
    "title": "Nonconvex Low-Rank Tensor Completion from Noisy Data",
    "abstract": "Comments: Accepted to Operations Research",
    "descriptor": "\nComments: Accepted to Operations Research\n",
    "authors": [
      "Changxiao Cai",
      "Gen Li",
      "H. Vincent Poor",
      "Yuxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.04436"
  },
  {
    "id": "arXiv:1912.01875",
    "title": "3D Hand Pose Estimation via Regularized Graph Representation Learning",
    "abstract": "3D Hand Pose Estimation via Regularized Graph Representation Learning",
    "descriptor": "",
    "authors": [
      "Yiming He",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1912.01875"
  },
  {
    "id": "arXiv:2002.02620",
    "title": "Gaussian Variational State Estimation for Nonlinear State-Space Models",
    "abstract": "Gaussian Variational State Estimation for Nonlinear State-Space Models",
    "descriptor": "",
    "authors": [
      "Jarrad Courts",
      "Adrian Wills",
      "Thomas B. Sch\u00f6n"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.02620"
  },
  {
    "id": "arXiv:2002.03375",
    "title": "Stochastic tree ensembles for regularized nonlinear regression",
    "abstract": "Stochastic tree ensembles for regularized nonlinear regression",
    "descriptor": "",
    "authors": [
      "Jingyu He",
      "P. Richard Hahn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2002.03375"
  },
  {
    "id": "arXiv:2002.05120",
    "title": "Parameterizing Branch-and-Bound Search Trees to Learn Branching Policies",
    "abstract": "Comments: AAAI 2021 camera-ready version with supplementary materials, improved readability of figures in main article. Code, data and trained models are available at this https URL",
    "descriptor": "\nComments: AAAI 2021 camera-ready version with supplementary materials, improved readability of figures in main article. Code, data and trained models are available at this https URL\n",
    "authors": [
      "Giulia Zarpellon",
      "Jason Jo",
      "Andrea Lodi",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.05120"
  },
  {
    "id": "arXiv:2002.08014",
    "title": "Communication-Efficient Distributed SVD via Local Power Iterations",
    "abstract": "Comments: 9 pages, 7 figures, accepted by 2021 ICML",
    "descriptor": "\nComments: 9 pages, 7 figures, accepted by 2021 ICML\n",
    "authors": [
      "Xiang Li",
      "Shusen Wang",
      "Kun Chen",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2002.08014"
  },
  {
    "id": "arXiv:2002.10451",
    "title": "Neural Lyapunov Model Predictive Control: Learning Safe Global  Controllers from Sub-optimal Examples",
    "abstract": "Neural Lyapunov Model Predictive Control: Learning Safe Global  Controllers from Sub-optimal Examples",
    "descriptor": "",
    "authors": [
      "Mayank Mittal",
      "Marco Gallieri",
      "Alessio Quaglino",
      "Seyed Sina Mirrazavi Salehian",
      "Jan Koutn\u00edk"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2002.10451"
  },
  {
    "id": "arXiv:2003.00865",
    "title": "Exposing Backdoors in Robust Machine Learning Models",
    "abstract": "Exposing Backdoors in Robust Machine Learning Models",
    "descriptor": "",
    "authors": [
      "Ezekiel Soremekun",
      "Sakshi Udeshi",
      "Sudipta Chattopadhyay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.00865"
  },
  {
    "id": "arXiv:2003.04696",
    "title": "TorchIO: a Python library for efficient loading, preprocessing,  augmentation and patch-based sampling of medical images in deep learning",
    "abstract": "Comments: Submitted to Computer Methods and Programs in Biomedicine. 27 pages, 7 figures. Documentation for TorchIO can be found at this http URL",
    "descriptor": "\nComments: Submitted to Computer Methods and Programs in Biomedicine. 27 pages, 7 figures. Documentation for TorchIO can be found at this http URL\n",
    "authors": [
      "Fernando P\u00e9rez-Garc\u00eda",
      "Rachel Sparks",
      "S\u00e9bastien Ourselin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.04696"
  },
  {
    "id": "arXiv:2004.02023",
    "title": "Towards Query Logs for Privacy Studies: On Deriving Search Queries from  Questions",
    "abstract": "Comments: ECIR 2020 Short Paper",
    "descriptor": "\nComments: ECIR 2020 Short Paper\n",
    "authors": [
      "Asia J. Biega",
      "Jana Schmidt",
      "Rishiraj Saha Roy"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2004.02023"
  },
  {
    "id": "arXiv:2004.09810",
    "title": "A Graph Joining Greedy Approach to Binary de Bruijn Sequences",
    "abstract": "Comments: in submission",
    "descriptor": "\nComments: in submission\n",
    "authors": [
      "Zuling Chang",
      "Martianus Frederic Ezerman",
      "Adamas Aqsa Fahreza",
      "Qiang Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2004.09810"
  },
  {
    "id": "arXiv:2005.00123",
    "title": "Unsupervised Learning of KB Queries in Task-Oriented Dialogs",
    "abstract": "Comments: Presented at ACL 2021",
    "descriptor": "\nComments: Presented at ACL 2021\n",
    "authors": [
      "Dinesh Raghu",
      "Nikhil Gupta",
      "Mausam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.00123"
  },
  {
    "id": "arXiv:2005.01993",
    "title": "Automatic Generation of RAMS Analyses from Model-based Functional  Descriptions using UML State Machines",
    "abstract": "Automatic Generation of RAMS Analyses from Model-based Functional  Descriptions using UML State Machines",
    "descriptor": "",
    "authors": [
      "Christof Kaukewitsch",
      "Henrik Papist",
      "Marc Zeller",
      "Martin Rothfelder"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2005.01993"
  },
  {
    "id": "arXiv:2005.03355",
    "title": "Quantum correlation alignment for unsupervised domain adaptation",
    "abstract": "Comments: 11 pages, 9 figures",
    "descriptor": "\nComments: 11 pages, 9 figures\n",
    "authors": [
      "Xi He"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.03355"
  },
  {
    "id": "arXiv:2005.11516",
    "title": "Frontal Attack: Leaking Control-Flow in SGX via the CPU Frontend",
    "abstract": "Comments: Accepted for publication at the 30th USENIX Security Symposium (USENIX Security 21)",
    "descriptor": "\nComments: Accepted for publication at the 30th USENIX Security Symposium (USENIX Security 21)\n",
    "authors": [
      "Ivan Puddu",
      "Moritz Schneider",
      "Miro Haller",
      "Srdjan \u010capkun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2005.11516"
  },
  {
    "id": "arXiv:2005.14296",
    "title": "An Analytical Model for Molecular Communication over a Non-linear  Reaction-Diffusion Medium",
    "abstract": "An Analytical Model for Molecular Communication over a Non-linear  Reaction-Diffusion Medium",
    "descriptor": "",
    "authors": [
      "Hamidreza Abin",
      "Amin Gohari",
      "Masoumeh Nasiri-Kenari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2005.14296"
  },
  {
    "id": "arXiv:2005.14356",
    "title": "Adjustable reach in a network centrality based on current flows",
    "abstract": "Adjustable reach in a network centrality based on current flows",
    "descriptor": "",
    "authors": [
      "Aleks J. Gurfinkel",
      "Per Arne Rikvold"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2005.14356"
  },
  {
    "id": "arXiv:2006.00262",
    "title": "Data Augmentation with Unsupervised Machine Translation Improves the  Structural Similarity of Cross-lingual Word Embeddings",
    "abstract": "Comments: Accepted to ACL-IJCNLP 2021 SRW",
    "descriptor": "\nComments: Accepted to ACL-IJCNLP 2021 SRW\n",
    "authors": [
      "Sosuke Nishikawa",
      "Ryokan Ri",
      "Yoshimasa Tsuruoka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2006.00262"
  },
  {
    "id": "arXiv:2006.05656",
    "title": "Why Attentions May Not Be Interpretable?",
    "abstract": "Comments: Proceedings of the 27th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
    "descriptor": "\nComments: Proceedings of the 27th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining\n",
    "authors": [
      "Bing Bai",
      "Jian Liang",
      "Guanhua Zhang",
      "Hao Li",
      "Kun Bai",
      "Fei Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.05656"
  },
  {
    "id": "arXiv:2006.13820",
    "title": "Designing Resilient Linear Driftless Systems",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Jean-Baptiste Bouvier",
      "Melkior Ornik"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.13820"
  },
  {
    "id": "arXiv:2007.03248",
    "title": "A Constraint-Based Algorithm for the Structural Learning of  Continuous-Time Bayesian Networks",
    "abstract": "A Constraint-Based Algorithm for the Structural Learning of  Continuous-Time Bayesian Networks",
    "descriptor": "",
    "authors": [
      "Alessandro Bregoli",
      "Marco Scutari",
      "Fabio Stella"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.03248"
  },
  {
    "id": "arXiv:2007.06421",
    "title": "Thirty-seven years of relational Hoare logic: remarks on its principles  and history",
    "abstract": "Comments: A version appears in proceedings of ISOLA 2020. Version2: fix typos, minor clarifications, add a citation. Version3: copy edits, add citations on completeness. Version 4: minor corrections. Version 5: restore missing precond in loop rule",
    "descriptor": "\nComments: A version appears in proceedings of ISOLA 2020. Version2: fix typos, minor clarifications, add a citation. Version3: copy edits, add citations on completeness. Version 4: minor corrections. Version 5: restore missing precond in loop rule\n",
    "authors": [
      "David A. Naumann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2007.06421"
  },
  {
    "id": "arXiv:2007.09075",
    "title": "Efficient Linear and Affine Codes for Correcting Insertions/Deletions",
    "abstract": "Efficient Linear and Affine Codes for Correcting Insertions/Deletions",
    "descriptor": "",
    "authors": [
      "Kuan Cheng",
      "Venkatesan Guruswami",
      "Bernhard Haeupler",
      "Xin Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2007.09075"
  },
  {
    "id": "arXiv:2007.13125",
    "title": "A parallel-in-time algorithm for high-order BDF methods for diffusion  and subdiffusion equations",
    "abstract": "A parallel-in-time algorithm for high-order BDF methods for diffusion  and subdiffusion equations",
    "descriptor": "",
    "authors": [
      "Shuonan Wu",
      "Zhi Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2007.13125"
  },
  {
    "id": "arXiv:2007.13333",
    "title": "Covert Identification over Binary-Input Discrete Memoryless Channels",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Information Theory",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Information Theory\n",
    "authors": [
      "Qiaosheng Zhang",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2007.13333"
  },
  {
    "id": "arXiv:2008.02101",
    "title": "Structure Preserving Stain Normalization of Histopathology Images Using  Self-Supervised Semantic Guidance",
    "abstract": "Structure Preserving Stain Normalization of Histopathology Images Using  Self-Supervised Semantic Guidance",
    "descriptor": "",
    "authors": [
      "Dwarikanath Mahapatra",
      "Behzad Bozorgtabar",
      "Jean-Philippe Thiran",
      "Ling Shao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.02101"
  },
  {
    "id": "arXiv:2008.03587",
    "title": "A note on deterministic zombies",
    "abstract": "Comments: 4 pages",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Valentin Bartier",
      "Laurine B\u00e9n\u00e9teau",
      "Marthe Bonamy",
      "Hoang La",
      "Jonathan Narboni"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2008.03587"
  },
  {
    "id": "arXiv:2008.03945",
    "title": "Does BERT Solve Commonsense Task via Commonsense Knowledge?",
    "abstract": "Does BERT Solve Commonsense Task via Commonsense Knowledge?",
    "descriptor": "",
    "authors": [
      "Leyang Cui",
      "Sijie Cheng",
      "Yu Wu",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2008.03945"
  },
  {
    "id": "arXiv:2008.04262",
    "title": "Progress on a perimeter surveillance problem",
    "abstract": "Progress on a perimeter surveillance problem",
    "descriptor": "",
    "authors": [
      "Jeremy Avigad",
      "Floris van Doorn"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2008.04262"
  },
  {
    "id": "arXiv:2008.06167",
    "title": "Ariadne: An algorithm for computing a maximum clique in polynomial time",
    "abstract": "Ariadne: An algorithm for computing a maximum clique in polynomial time",
    "descriptor": "",
    "authors": [
      "Ioannis Avramopoulos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2008.06167"
  },
  {
    "id": "arXiv:2008.08198",
    "title": "BraggNN: Fast X-ray Bragg Peak Analysis Using Deep Learning",
    "abstract": "BraggNN: Fast X-ray Bragg Peak Analysis Using Deep Learning",
    "descriptor": "",
    "authors": [
      "Zhengchun Liu",
      "Hemant Sharma",
      "Jun-Sang Park",
      "Peter Kenesei",
      "Antonino Miceli",
      "Jonathan Almer",
      "Rajkumar Kettimuthu",
      "Ian Foster"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.08198"
  },
  {
    "id": "arXiv:2008.08808",
    "title": "BGC: Multi-Agent Group Belief with Graph Clustering",
    "abstract": "Comments: 7 pages, 5 figures",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Tianze Zhou",
      "Fubiao Zhang",
      "Pan Tang",
      "Chenfei Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.08808"
  },
  {
    "id": "arXiv:2008.11448",
    "title": "Haystack Hunting Hints and Locker Room Communication",
    "abstract": "Comments: 27 pages, 1 figure",
    "descriptor": "\nComments: 27 pages, 1 figure\n",
    "authors": [
      "Artur Czumaj",
      "George Kontogeorgiou",
      "Mike Paterson"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2008.11448"
  },
  {
    "id": "arXiv:2008.11700",
    "title": "Safe Active Dynamics Learning and Control: A Sequential  Exploration-Exploitation Framework",
    "abstract": "Safe Active Dynamics Learning and Control: A Sequential  Exploration-Exploitation Framework",
    "descriptor": "",
    "authors": [
      "Thomas Lew",
      "Apoorva Sharma",
      "James Harrison",
      "Andrew Bylard",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.11700"
  },
  {
    "id": "arXiv:2009.02551",
    "title": "Performance Analysis and User Association Optimization for Wireless  Network Aided by Multiple Intelligent Reflecting Surfaces",
    "abstract": "Comments: 16 pages, 10 figures. Accepted for publication by IEEE Transactions on Communications",
    "descriptor": "\nComments: 16 pages, 10 figures. Accepted for publication by IEEE Transactions on Communications\n",
    "authors": [
      "Weidong Mei",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2009.02551"
  },
  {
    "id": "arXiv:2009.06628",
    "title": "A fully-coupled framework for solving Cahn-Hilliard Navier-Stokes  equations: Second-order, energy-stable numerical methods on adaptive octree  based meshes",
    "abstract": "Comments: 48 pages, 18 figures, submitted to Computer Methods in Applied Mechanics and Engineering",
    "descriptor": "\nComments: 48 pages, 18 figures, submitted to Computer Methods in Applied Mechanics and Engineering\n",
    "authors": [
      "Makrand A Khanwale",
      "Kumar Saurabh",
      "Milinda Fernando",
      "Victor M. Calo",
      "James A. Rossmanith",
      "Hari Sundar",
      "Baskar Ganapathysubramanian"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2009.06628"
  },
  {
    "id": "arXiv:2009.07625",
    "title": "Distributed formation maneuver control by manipulating the complex  Laplacian",
    "abstract": "Comments: Automatica, 8 pages",
    "descriptor": "\nComments: Automatica, 8 pages\n",
    "authors": [
      "Hector Garcia de Marina"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2009.07625"
  },
  {
    "id": "arXiv:2009.14180",
    "title": "Learning to Play against Any Mixture of Opponents",
    "abstract": "Learning to Play against Any Mixture of Opponents",
    "descriptor": "",
    "authors": [
      "Max Olan Smith",
      "Thomas Anthony",
      "Yongzhao Wang",
      "Michael P. Wellman"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2009.14180"
  },
  {
    "id": "arXiv:2010.04525",
    "title": "Uncertainty-Aware Few-Shot Image Classification",
    "abstract": "Comments: Accepted by IJCAI2021",
    "descriptor": "\nComments: Accepted by IJCAI2021\n",
    "authors": [
      "Zhizheng Zhang",
      "Cuiling Lan",
      "Wenjun Zeng",
      "Zhibo Chen",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.04525"
  },
  {
    "id": "arXiv:2010.09055",
    "title": "Large-Scale Maintenance and Unit Commitment: A Decentralized Subgradient  Approach",
    "abstract": "Large-Scale Maintenance and Unit Commitment: A Decentralized Subgradient  Approach",
    "descriptor": "",
    "authors": [
      "Paritosh Ramanan",
      "Murat Yildirim",
      "Nagi Gebraeel",
      "Edmond Chow"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2010.09055"
  },
  {
    "id": "arXiv:2010.09322",
    "title": "Reduce and Reconstruct: ASR for Low-Resource Phonetic Languages",
    "abstract": "Comments: 5 pages, 1 figure. Accepted at INTERSPEECH 2021",
    "descriptor": "\nComments: 5 pages, 1 figure. Accepted at INTERSPEECH 2021\n",
    "authors": [
      "Anuj Diwan",
      "Preethi Jyothi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2010.09322"
  },
  {
    "id": "arXiv:2010.09895",
    "title": "Multi-Window Data Augmentation Approach for Speech Emotion Recognition",
    "abstract": "Multi-Window Data Augmentation Approach for Speech Emotion Recognition",
    "descriptor": "",
    "authors": [
      "Sarala Padi",
      "Dinesh Manocha",
      "Ram D.Sriram"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2010.09895"
  },
  {
    "id": "arXiv:2010.10391",
    "title": "UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual  Embeddings Using the Unified Medical Language System Metathesaurus",
    "abstract": "Comments: 10 pages, 3 figures, accepted in NAACL 2021",
    "descriptor": "\nComments: 10 pages, 3 figures, accepted in NAACL 2021\n",
    "authors": [
      "George Michalopoulos",
      "Yuanxin Wang",
      "Hussam Kaka",
      "Helen Chen",
      "Alexander Wong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.10391"
  },
  {
    "id": "arXiv:2010.11929",
    "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at  Scale",
    "abstract": "Comments: Fine-tuning code and pre-trained models are available at this https URL ICLR camera-ready version with 2 small modifications: 1) Added a discussion of CLS vs GAP classifier in the appendix, 2) Fixed an error in exaFLOPs computation in Figure 5 and Table 6 (relative performance of models is basically not affected)",
    "descriptor": "\nComments: Fine-tuning code and pre-trained models are available at this https URL ICLR camera-ready version with 2 small modifications: 1) Added a discussion of CLS vs GAP classifier in the appendix, 2) Fixed an error in exaFLOPs computation in Figure 5 and Table 6 (relative performance of models is basically not affected)\n",
    "authors": [
      "Alexey Dosovitskiy",
      "Lucas Beyer",
      "Alexander Kolesnikov",
      "Dirk Weissenborn",
      "Xiaohua Zhai",
      "Thomas Unterthiner",
      "Mostafa Dehghani",
      "Matthias Minderer",
      "Georg Heigold",
      "Sylvain Gelly",
      "Jakob Uszkoreit",
      "Neil Houlsby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.11929"
  },
  {
    "id": "arXiv:2010.12461",
    "title": "Multi-UAV Path Planning for Wireless Data Harvesting with Deep  Reinforcement Learning",
    "abstract": "Comments: Modifications: final formatting; Code available under this https URL, article extends on arXiv:2007.00544",
    "descriptor": "\nComments: Modifications: final formatting; Code available under this https URL, article extends on arXiv:2007.00544\n",
    "authors": [
      "Harald Bayerlein",
      "Mirco Theile",
      "Marco Caccamo",
      "David Gesbert"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.12461"
  },
  {
    "id": "arXiv:2010.15120",
    "title": "Gender Bias in Depression Detection Using Audio Features",
    "abstract": "Comments: 5 pages, 2 figures, to be published at EUSIPCO 2021",
    "descriptor": "\nComments: 5 pages, 2 figures, to be published at EUSIPCO 2021\n",
    "authors": [
      "Andrew Bailey",
      "Mark D. Plumbley"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2010.15120"
  },
  {
    "id": "arXiv:2011.00032",
    "title": "Multi-Layered Safety for Legged Robots via Control Barrier Functions and  Model Predictive Control",
    "abstract": "Multi-Layered Safety for Legged Robots via Control Barrier Functions and  Model Predictive Control",
    "descriptor": "",
    "authors": [
      "Ruben Grandia",
      "Andrew J. Taylor",
      "Aaron D. Ames",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.00032"
  },
  {
    "id": "arXiv:2011.00382",
    "title": "A Policy Gradient Algorithm for Learning to Learn in Multiagent  Reinforcement Learning",
    "abstract": "Comments: Accepted to ICML 2021",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Dong-Ki Kim",
      "Miao Liu",
      "Matthew Riemer",
      "Chuangchuang Sun",
      "Marwa Abdulhai",
      "Golnaz Habibi",
      "Sebastian Lopez-Cot",
      "Gerald Tesauro",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2011.00382"
  },
  {
    "id": "arXiv:2011.00454",
    "title": "Dynamic radiomics: a new methodology to extract quantitative  time-related features from tomographic images",
    "abstract": "Dynamic radiomics: a new methodology to extract quantitative  time-related features from tomographic images",
    "descriptor": "",
    "authors": [
      "Fengying Che",
      "Ruichuan Shi",
      "Jian Wu",
      "Haoran Li",
      "Shuqin Li",
      "Weixing Chen",
      "Hao Zhang",
      "Zhi Li",
      "Xiaoyu Cui"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.00454"
  },
  {
    "id": "arXiv:2011.01880",
    "title": "Intrinsic Robotic Introspection: Learning Internal States From Neuron  Activations",
    "abstract": "Comments: Paper accepted at the International Conference on Development and Learning (ICDL) 2021",
    "descriptor": "\nComments: Paper accepted at the International Conference on Development and Learning (ICDL) 2021\n",
    "authors": [
      "Nikos Pitsillos",
      "Ameya Pore",
      "Bjorn Sand Jensen",
      "Gerardo Aragon-Camarasa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.01880"
  },
  {
    "id": "arXiv:2011.02593",
    "title": "Detecting Hallucinated Content in Conditional Neural Sequence Generation",
    "abstract": "Comments: Accepted by ACL-Finding 2021",
    "descriptor": "\nComments: Accepted by ACL-Finding 2021\n",
    "authors": [
      "Chunting Zhou",
      "Graham Neubig",
      "Jiatao Gu",
      "Mona Diab",
      "Paco Guzman",
      "Luke Zettlemoyer",
      "Marjan Ghazvininejad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.02593"
  },
  {
    "id": "arXiv:2011.03778",
    "title": "A Gap-ETH-Tight Approximation Scheme for Euclidean TSP",
    "abstract": "Comments: 43 pages, faster algorithms for Euclidean and Rectilinear Steiner Tree",
    "descriptor": "\nComments: 43 pages, faster algorithms for Euclidean and Rectilinear Steiner Tree\n",
    "authors": [
      "S\u00e1ndor Kisfaludi-Bak",
      "Jesper Nederlof",
      "Karol W\u0119grzycki"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.03778"
  },
  {
    "id": "arXiv:2011.04820",
    "title": "Decentralized Structural-RNN for Robot Crowd Navigation with Deep  Reinforcement Learning",
    "abstract": "Comments: Published as a conference paper in IEEE International Conference on Robotics and Automation (ICRA), 2021",
    "descriptor": "\nComments: Published as a conference paper in IEEE International Conference on Robotics and Automation (ICRA), 2021\n",
    "authors": [
      "Shuijing Liu",
      "Peixin Chang",
      "Weihang Liang",
      "Neeloy Chakraborty",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.04820"
  },
  {
    "id": "arXiv:2011.09545",
    "title": "MOFA: Modular Factorial Design for Hyperparameter Optimization",
    "abstract": "Comments: 13 pages, 6 figures",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Bo Xiong",
      "Yimin Huang",
      "Hanrong Ye",
      "Steffen Staab",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.09545"
  },
  {
    "id": "arXiv:2011.09641",
    "title": "On the geometry of symmetry breaking inequalities",
    "abstract": "On the geometry of symmetry breaking inequalities",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Verschae",
      "Mat\u00edas Villagra",
      "L\u00e9onard von Niederh\u00e4usern"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2011.09641"
  },
  {
    "id": "arXiv:2011.09821",
    "title": "Metaheuristics \"In the Large\"",
    "abstract": "Metaheuristics \"In the Large\"",
    "descriptor": "",
    "authors": [
      "Jerry Swan",
      "Steven Adriaensen",
      "Alexander E. I. Brownlee",
      "Kevin Hammond",
      "Colin G. Johnson",
      "Ahmed Kheiri",
      "Faustyna Krawiec",
      "J. J. Merelo",
      "Leandro L. Minku",
      "Ender \u00d6zcan",
      "Gisele L. Pappa",
      "Pablo Garc\u00eda-S\u00e1nchez",
      "Kenneth S\u00f6rensen",
      "Stefan Vo\u00df",
      "Markus Wagner",
      "David R. White"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.09821"
  },
  {
    "id": "arXiv:2011.14062",
    "title": "Unsupervised Spoken Term Discovery Based on Re-clustering of  Hypothesized Speech Segments with Siamese and Triplet Networks",
    "abstract": "Unsupervised Spoken Term Discovery Based on Re-clustering of  Hypothesized Speech Segments with Siamese and Triplet Networks",
    "descriptor": "",
    "authors": [
      "Man-Ling Sung",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2011.14062"
  },
  {
    "id": "arXiv:2011.14858",
    "title": "A Tiny CNN Architecture for Medical Face Mask Detection for  Resource-Constrained Endpoints",
    "abstract": "Comments: 11 pages, Published in Springer LNEE at this http URL",
    "descriptor": "\nComments: 11 pages, Published in Springer LNEE at this http URL\n",
    "authors": [
      "Puranjay Mohan",
      "Aditya Jyoti Paul",
      "Abhay Chirania"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2011.14858"
  },
  {
    "id": "arXiv:2011.15069",
    "title": "Graph convolutions that can finally model local structure",
    "abstract": "Graph convolutions that can finally model local structure",
    "descriptor": "",
    "authors": [
      "R\u00e9my Brossard",
      "Oriel Frigo",
      "David Dehaene"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.15069"
  },
  {
    "id": "arXiv:2012.00533",
    "title": "Wireless Image Transmission Using Deep Source Channel Coding With  Attention Modules",
    "abstract": "Comments: 13 pages, 13 figures, journal paper",
    "descriptor": "\nComments: 13 pages, 13 figures, journal paper\n",
    "authors": [
      "Jialong Xu",
      "Bo Ai",
      "Wei Chen",
      "Ang Yang",
      "Peng Sun",
      "Miguel Rodrigues"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.00533"
  },
  {
    "id": "arXiv:2012.01417",
    "title": "Cycloidal Trajectory Realization on Staircase with Optimal Trajectory  Tracking Control based on Neural Network Temporal Quantized Lagrange Dynamics  (NNTQLD)",
    "abstract": "Cycloidal Trajectory Realization on Staircase with Optimal Trajectory  Tracking Control based on Neural Network Temporal Quantized Lagrange Dynamics  (NNTQLD)",
    "descriptor": "",
    "authors": [
      "Gaurav Bhardwaj",
      "Utkarsh A. Mishra",
      "N. Sukavanam",
      "R. Balasubramanian"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.01417"
  },
  {
    "id": "arXiv:2012.01764",
    "title": "Optimal labelling schemes for adjacency, comparability, and reachability",
    "abstract": "Comments: 17 pages - to appear in the proceedings of STOC 2021",
    "descriptor": "\nComments: 17 pages - to appear in the proceedings of STOC 2021\n",
    "authors": [
      "Marthe Bonamy",
      "Louis Esperet",
      "Carla Groenland",
      "Alex Scott"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.01764"
  },
  {
    "id": "arXiv:2012.03129",
    "title": "Simultaneous Corn and Soybean Yield Prediction from Remote Sensing Data  Using Deep Transfer Learning",
    "abstract": "Comments: 14 pages, 8 figures, 7 tables",
    "descriptor": "\nComments: 14 pages, 8 figures, 7 tables\n",
    "authors": [
      "Saeed Khaki",
      "Hieu Pham",
      "Lizhi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2012.03129"
  },
  {
    "id": "arXiv:2012.03929",
    "title": "Benchmarking Commercial Intent Detection Services with Practice-Driven  Evaluations",
    "abstract": "Comments: Accepted at NAACL2021 Industry Track",
    "descriptor": "\nComments: Accepted at NAACL2021 Industry Track\n",
    "authors": [
      "Haode Qi",
      "Lin Pan",
      "Atin Sood",
      "Abhishek Shah",
      "Ladislav Kunc",
      "Mo Yu",
      "Saloni Potdar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.03929"
  },
  {
    "id": "arXiv:2012.05471",
    "title": "Securing the EDK II Image Loader",
    "abstract": "Comments: 10 pages, 2 tables",
    "descriptor": "\nComments: 10 pages, 2 tables\n",
    "authors": [
      "Marvin H\u00e4user",
      "Vitaly Cheptsov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2012.05471"
  },
  {
    "id": "arXiv:2012.06881",
    "title": "Transmit Power Pool Design for Grant-Free NOMA-IoT Networks via Deep  Reinforcement Learning",
    "abstract": "Transmit Power Pool Design for Grant-Free NOMA-IoT Networks via Deep  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Muhammad Fayaz",
      "Wenqiang Yi",
      "Yuanwei Liu",
      "Arumugam Nallanathan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.06881"
  },
  {
    "id": "arXiv:2012.08890",
    "title": "Self-Supervised Person Detection in 2D Range Data using a Calibrated  Camera",
    "abstract": "Comments: 2021 IEEE International Conference on Robotics and Automation (ICRA)",
    "descriptor": "\nComments: 2021 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Dan Jia",
      "Mats Steinweg",
      "Alexander Hermans",
      "Bastian Leibe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.08890"
  },
  {
    "id": "arXiv:2012.10584",
    "title": "List-decodability with large radius for Reed-Solomon codes",
    "abstract": "List-decodability with large radius for Reed-Solomon codes",
    "descriptor": "",
    "authors": [
      "Asaf Ferber",
      "Matthew Kwan",
      "Lisa Sauermann"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2012.10584"
  },
  {
    "id": "arXiv:2012.10861",
    "title": "Memory AMP",
    "abstract": "Comments: 30 pages, 9 figures, submitted to IEEE Trans. on Information Theory for possible publication. [Memory AMP inherits the strengths of AMP and OAMP/VAMP such as low complexity, Bayes optimality and applicability to unitarily-inavariant matrices, while avoiding the weakness of AMP (e.g. limited to IID matrices) and OAMP/VAMP (e.g. needs high-complexity LMMSE).]",
    "descriptor": "\nComments: 30 pages, 9 figures, submitted to IEEE Trans. on Information Theory for possible publication. [Memory AMP inherits the strengths of AMP and OAMP/VAMP such as low complexity, Bayes optimality and applicability to unitarily-inavariant matrices, while avoiding the weakness of AMP (e.g. limited to IID matrices) and OAMP/VAMP (e.g. needs high-complexity LMMSE).]\n",
    "authors": [
      "Lei Liu",
      "Shunqi Huang",
      "Brian M. Kurkoski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2012.10861"
  },
  {
    "id": "arXiv:2012.14898",
    "title": "Exponential Communication Separations between Notions of Selfishness",
    "abstract": "Exponential Communication Separations between Notions of Selfishness",
    "descriptor": "",
    "authors": [
      "Aviad Rubinstein",
      "Raghuvansh R. Saxena",
      "Clayton Thomas",
      "S. Mathew Weinberg",
      "Junyao Zhao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2012.14898"
  },
  {
    "id": "arXiv:2012.15761",
    "title": "Learning from the Worst: Dynamically Generated Datasets to Improve  Online Hate Detection",
    "abstract": "Learning from the Worst: Dynamically Generated Datasets to Improve  Online Hate Detection",
    "descriptor": "",
    "authors": [
      "Bertie Vidgen",
      "Tristan Thrush",
      "Zeerak Waseem",
      "Douwe Kiela"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.15761"
  },
  {
    "id": "arXiv:2012.15832",
    "title": "Shortformer: Better Language Modeling using Shorter Inputs",
    "abstract": "Comments: To appear at ACL 2021",
    "descriptor": "\nComments: To appear at ACL 2021\n",
    "authors": [
      "Ofir Press",
      "Noah A. Smith",
      "Mike Lewis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15832"
  },
  {
    "id": "arXiv:2101.00178",
    "title": "UnitedQA: A Hybrid Approach for Open Domain Question Answering",
    "abstract": "Comments: ACL 2021 camera-ready",
    "descriptor": "\nComments: ACL 2021 camera-ready\n",
    "authors": [
      "Hao Cheng",
      "Yelong Shen",
      "Xiaodong Liu",
      "Pengcheng He",
      "Weizhu Chen",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.00178"
  },
  {
    "id": "arXiv:2101.00345",
    "title": "Modeling Fine-Grained Entity Types with Box Embeddings",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Yasumasa Onoe",
      "Michael Boratko",
      "Andrew McCallum",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.00345"
  },
  {
    "id": "arXiv:2101.02285",
    "title": "TryOnGAN: Body-Aware Try-On via Layered Interpolation",
    "abstract": "TryOnGAN: Body-Aware Try-On via Layered Interpolation",
    "descriptor": "",
    "authors": [
      "Kathleen M Lewis",
      "Srivatsan Varadharajan",
      "Ira Kemelmacher-Shlizerman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2101.02285"
  },
  {
    "id": "arXiv:2101.02854",
    "title": "Almost Optimal Inapproximability of Multidimensional Packing Problems",
    "abstract": "Almost Optimal Inapproximability of Multidimensional Packing Problems",
    "descriptor": "",
    "authors": [
      "Sai Sandeep"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2101.02854"
  },
  {
    "id": "arXiv:2101.04108",
    "title": "Controllable Guarantees for Fair Outcomes via Contrastive Information  Estimation",
    "abstract": "Comments: This version fixes an error in Theorem 2 of the original manuscript that appeared at the Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI-21). Code is available at this https URL",
    "descriptor": "\nComments: This version fixes an error in Theorem 2 of the original manuscript that appeared at the Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI-21). Code is available at this https URL\n",
    "authors": [
      "Umang Gupta",
      "Aaron M Ferber",
      "Bistra Dilkina",
      "Greg Ver Steeg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.04108"
  },
  {
    "id": "arXiv:2101.09469",
    "title": "Training Multilingual Pre-trained Language Model with Byte-level  Subwords",
    "abstract": "Training Multilingual Pre-trained Language Model with Byte-level  Subwords",
    "descriptor": "",
    "authors": [
      "Junqiu Wei",
      "Qun Liu",
      "Yinpeng Guo",
      "Xin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.09469"
  },
  {
    "id": "arXiv:2101.09877",
    "title": "TSO-DSO Operational Planning Coordination through \"$l_1$-Proximal\"  Surrogate Lagrangian Relaxation",
    "abstract": "TSO-DSO Operational Planning Coordination through \"$l_1$-Proximal\"  Surrogate Lagrangian Relaxation",
    "descriptor": "",
    "authors": [
      "Mikhail Bragin",
      "Yury Dvorkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.09877"
  },
  {
    "id": "arXiv:2102.01373",
    "title": "An Improved Baseline for Sentence-level Relation Extraction",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Wenxuan Zhou",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.01373"
  },
  {
    "id": "arXiv:2102.01547",
    "title": "WeNet: Production oriented Streaming and Non-streaming End-to-End Speech  Recognition Toolkit",
    "abstract": "Comments: 5 pages, 2 figures, 4 tables",
    "descriptor": "\nComments: 5 pages, 2 figures, 4 tables\n",
    "authors": [
      "Zhuoyuan Yao",
      "Di Wu",
      "Xiong Wang",
      "Binbin Zhang",
      "Fan Yu",
      "Chao Yang",
      "Zhendong Peng",
      "Xiaoyu Chen",
      "Lei Xie",
      "Xin Lei"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2102.01547"
  },
  {
    "id": "arXiv:2102.03183",
    "title": "Last iterate convergence of SGD for Least-Squares in the Interpolation  regime",
    "abstract": "Comments: 23 pages, 1 figure, 1 Appendix",
    "descriptor": "\nComments: 23 pages, 1 figure, 1 Appendix\n",
    "authors": [
      "Aditya Varre",
      "Loucas Pillaud-Vivien",
      "Nicolas Flammarion"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.03183"
  },
  {
    "id": "arXiv:2102.03347",
    "title": "Frontrunner Jones and the Raiders of the Dark Forest: An Empirical Study  of Frontrunning on the Ethereum Blockchain",
    "abstract": "Frontrunner Jones and the Raiders of the Dark Forest: An Empirical Study  of Frontrunning on the Ethereum Blockchain",
    "descriptor": "",
    "authors": [
      "Christof Ferreira Torres",
      "Ramiro Camino",
      "Radu State"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.03347"
  },
  {
    "id": "arXiv:2102.03567",
    "title": "Standard and Event Cameras Fusion for Dense Mapping",
    "abstract": "Comments: 4 pages, 2 figures, 6 references",
    "descriptor": "\nComments: 4 pages, 2 figures, 6 references\n",
    "authors": [
      "Yan Dong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.03567"
  },
  {
    "id": "arXiv:2102.05221",
    "title": "Early Abandoning and Pruning for Elastic Distances including Dynamic  Time Warping",
    "abstract": "Comments: Updated taking reviewers' comments into account",
    "descriptor": "\nComments: Updated taking reviewers' comments into account\n",
    "authors": [
      "Matthieu Herrmann",
      "Geoffrey I. Webb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05221"
  },
  {
    "id": "arXiv:2102.05378",
    "title": "Origami spring-inspired shape morphing for flexible robotics",
    "abstract": "Origami spring-inspired shape morphing for flexible robotics",
    "descriptor": "",
    "authors": [
      "Qianying Chen",
      "Fan Feng",
      "Pengyu Lv",
      "Huiling Duan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Soft Condensed Matter (cond-mat.soft)"
    ],
    "url": "https://arxiv.org/abs/2102.05378"
  },
  {
    "id": "arXiv:2102.05431",
    "title": "Dompteur: Taming Audio Adversarial Examples",
    "abstract": "Comments: Accepted at USENIX Security Symposium 2021",
    "descriptor": "\nComments: Accepted at USENIX Security Symposium 2021\n",
    "authors": [
      "Thorsten Eisenhofer",
      "Lea Sch\u00f6nherr",
      "Joel Frank",
      "Lars Speckemeier",
      "Dorothea Kolossa",
      "Thorsten Holz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2102.05431"
  },
  {
    "id": "arXiv:2102.07944",
    "title": "Deep Equilibrium Architectures for Inverse Problems in Imaging",
    "abstract": "Deep Equilibrium Architectures for Inverse Problems in Imaging",
    "descriptor": "",
    "authors": [
      "Davis Gilton",
      "Gregory Ongie",
      "Rebecca Willett"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.07944"
  },
  {
    "id": "arXiv:2102.09041",
    "title": "Reaching Consensus for Asynchronous Distributed Key Generation",
    "abstract": "Reaching Consensus for Asynchronous Distributed Key Generation",
    "descriptor": "",
    "authors": [
      "Ittai Abraham",
      "Philipp Jovanovic",
      "Mary Maller",
      "Sarah Meiklejohn",
      "Gilad Stern",
      "Alin Tomescu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.09041"
  },
  {
    "id": "arXiv:2102.09194",
    "title": "Maximum weighted induced forests and trees: New formulations and a  computational comparative review",
    "abstract": "Maximum weighted induced forests and trees: New formulations and a  computational comparative review",
    "descriptor": "",
    "authors": [
      "Rafael A. Melo",
      "Celso C. Ribeiro"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2102.09194"
  },
  {
    "id": "arXiv:2102.09290",
    "title": "On MPC without terminal conditions for dynamic non-holonomic robots",
    "abstract": "Comments: 6 pages, 2 figures, Submitted to NMPC for possible publication",
    "descriptor": "\nComments: 6 pages, 2 figures, Submitted to NMPC for possible publication\n",
    "authors": [
      "Franz Ru\u00dfwurm",
      "Willem Esterhuizen",
      "Karl Worthmann",
      "Stefan Streif"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.09290"
  },
  {
    "id": "arXiv:2102.09703",
    "title": "Randomized Exploration is Near-Optimal for Tabular MDP",
    "abstract": "Comments: The current version of this paper contains some technical issues. In particular, the Lemma 9 on page 20 does not hold in general because $s_h^k$ is not generated by $\\pi^*$. The Lemma 15 on page 27 does not hold in general because $\\overline{V}$ and $\\hat{P}$ are dependent",
    "descriptor": "\nComments: The current version of this paper contains some technical issues. In particular, the Lemma 9 on page 20 does not hold in general because $s_h^k$ is not generated by $\\pi^*$. The Lemma 15 on page 27 does not hold in general because $\\overline{V}$ and $\\hat{P}$ are dependent\n",
    "authors": [
      "Zhihan Xiong",
      "Ruoqi Shen",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09703"
  },
  {
    "id": "arXiv:2102.10395",
    "title": "On Calibration and Out-of-domain Generalization",
    "abstract": "Comments: 24 pages, 6 figures",
    "descriptor": "\nComments: 24 pages, 6 figures\n",
    "authors": [
      "Yoav Wald",
      "Amir Feder",
      "Daniel Greenfeld",
      "Uri Shalit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.10395"
  },
  {
    "id": "arXiv:2102.11619",
    "title": "Lower Bounds on the State Complexity of Population Protocols",
    "abstract": "Comments: Various minor revisions",
    "descriptor": "\nComments: Various minor revisions\n",
    "authors": [
      "Philipp Czerner",
      "Javier Esparza"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.11619"
  },
  {
    "id": "arXiv:2102.12668",
    "title": "Learning-based Robust Motion Planning with Guaranteed Stability: A  Contraction Theory Approach",
    "abstract": "Comments: IEEE Robotics and Automation Letters (RA-L), Accepted June 2021",
    "descriptor": "\nComments: IEEE Robotics and Automation Letters (RA-L), Accepted June 2021\n",
    "authors": [
      "Hiroyasu Tsukamoto",
      "Soon-Jo Chung"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.12668"
  },
  {
    "id": "arXiv:2102.12827",
    "title": "Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints",
    "abstract": "Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints",
    "descriptor": "",
    "authors": [
      "Maura Pintor",
      "Fabio Roli",
      "Wieland Brendel",
      "Battista Biggio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.12827"
  },
  {
    "id": "arXiv:2102.13068",
    "title": "Truncated Log-concave Sampling with Reflective Hamiltonian Monte Carlo",
    "abstract": "Comments: Preprint version",
    "descriptor": "\nComments: Preprint version\n",
    "authors": [
      "Apostolos Chalkis",
      "Vissarion Fisikopoulos",
      "Marios Papachristou",
      "Elias Tsigaridas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2102.13068"
  },
  {
    "id": "arXiv:2102.13400",
    "title": "Panoramic annular SLAM with loop closure and global optimization",
    "abstract": "Comments: Accepted to Applied Optics. 12 pages, 11 figures, 3 tables",
    "descriptor": "\nComments: Accepted to Applied Optics. 12 pages, 11 figures, 3 tables\n",
    "authors": [
      "Hao Chen",
      "Weijian Hu",
      "Kailun Yang",
      "Jian Bai",
      "Kaiwei Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2102.13400"
  },
  {
    "id": "arXiv:2103.00006",
    "title": "Electrocardiogram synthesis",
    "abstract": "Comments: temporary version",
    "descriptor": "\nComments: temporary version\n",
    "authors": [
      "Yong-Yeon Jo",
      "Joon-Myoung Kwon"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00006"
  },
  {
    "id": "arXiv:2103.00737",
    "title": "Meta-Learning an Inference Algorithm for Probabilistic Programs",
    "abstract": "Comments: (1) Improved related work; (2) improved the empirical evaluation with additional experiments and analyses for extrapolation and comparisons with HMC; and (3) explained the rationale for the choice of the probabilistic programming language",
    "descriptor": "\nComments: (1) Improved related work; (2) improved the empirical evaluation with additional experiments and analyses for extrapolation and comparisons with HMC; and (3) explained the rationale for the choice of the probabilistic programming language\n",
    "authors": [
      "Gwonsoo Che",
      "Hongseok Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00737"
  },
  {
    "id": "arXiv:2103.02136",
    "title": "Toward a Scalable Upper Bound for a CVaR-LQ Problem",
    "abstract": "Comments: accepted by IEEE Control Systems Letters, June 2021",
    "descriptor": "\nComments: accepted by IEEE Control Systems Letters, June 2021\n",
    "authors": [
      "Margaret P. Chapman",
      "Laurent Lessard"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.02136"
  },
  {
    "id": "arXiv:2103.04656",
    "title": "Will You Come Back to Contribute? Investigating the Inactivity of OSS  Core Developers in GitHub",
    "abstract": "Comments: Empirical Software Engineering, under review",
    "descriptor": "\nComments: Empirical Software Engineering, under review\n",
    "authors": [
      "Fabio Calefato",
      "Marco Aurelio Gerosa",
      "Giuseppe Iaffaldano",
      "Filippo Lanubile",
      "Igor Steinmacher"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2103.04656"
  },
  {
    "id": "arXiv:2103.04722",
    "title": "Sparse Kronecker-Product Coding for Unsourced Multiple Access",
    "abstract": "Comments: Submitted to IEEE Wireless Communications Letters",
    "descriptor": "\nComments: Submitted to IEEE Wireless Communications Letters\n",
    "authors": [
      "Zeyu Han",
      "Xiaojun Yuan",
      "Chongbin Xu",
      "Shuchao Jiang",
      "Xin Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2103.04722"
  },
  {
    "id": "arXiv:2103.08394",
    "title": "Local Problems on Grids from the Perspective of Distributed Algorithms,  Finitary Factors, and Descriptive Combinatorics",
    "abstract": "Local Problems on Grids from the Perspective of Distributed Algorithms,  Finitary Factors, and Descriptive Combinatorics",
    "descriptor": "",
    "authors": [
      "Jan Greb\u00edk",
      "V\u00e1clav Rozho\u0148"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)",
      "Logic (math.LO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2103.08394"
  },
  {
    "id": "arXiv:2103.10315",
    "title": "Lorentz Quantum Computer",
    "abstract": "Lorentz Quantum Computer",
    "descriptor": "",
    "authors": [
      "Wenhao He",
      "Zhenduo Wang",
      "Biao Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Other Condensed Matter (cond-mat.other)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2103.10315"
  },
  {
    "id": "arXiv:2103.10997",
    "title": "MVGrasp: Real-Time Multi-View 3D Object Grasping in Highly Cluttered  Environments",
    "abstract": "MVGrasp: Real-Time Multi-View 3D Object Grasping in Highly Cluttered  Environments",
    "descriptor": "",
    "authors": [
      "Hamidreza Kasaei",
      "Mohammadreza Kasaei"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.10997"
  },
  {
    "id": "arXiv:2103.11595",
    "title": "Approximate Equivalence Checking of Noisy Quantum Circuits",
    "abstract": "Approximate Equivalence Checking of Noisy Quantum Circuits",
    "descriptor": "",
    "authors": [
      "Xin Hong",
      "Mingsheng Ying",
      "Yuan Feng",
      "Xiangzhen Zhou",
      "Sanjiang Li"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2103.11595"
  },
  {
    "id": "arXiv:2103.12212",
    "title": "CFPNet: Channel-wise Feature Pyramid for Real-Time Semantic Segmentation",
    "abstract": "Comments: Accepted by ICIP 2021",
    "descriptor": "\nComments: Accepted by ICIP 2021\n",
    "authors": [
      "Ange Lou",
      "Murray Loew"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12212"
  },
  {
    "id": "arXiv:2103.12862",
    "title": "On Counting Propositional Logic",
    "abstract": "On Counting Propositional Logic",
    "descriptor": "",
    "authors": [
      "Melissa Antonelli",
      "Ugo Dal Lago",
      "Paolo Pistone"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2103.12862"
  },
  {
    "id": "arXiv:2103.12891",
    "title": "Robust BPX Preconditioner for Fractional Laplacians on Bounded Lipschitz  Domains",
    "abstract": "Robust BPX Preconditioner for Fractional Laplacians on Bounded Lipschitz  Domains",
    "descriptor": "",
    "authors": [
      "Juan Pablo Borthagaray",
      "Ricardo H. Nochetto",
      "Shuonan Wu",
      "Jinchao Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.12891"
  },
  {
    "id": "arXiv:2103.13956",
    "title": "Shadoks Approach to Low-Makespan Coordinated Motion Planning",
    "abstract": "Shadoks Approach to Low-Makespan Coordinated Motion Planning",
    "descriptor": "",
    "authors": [
      "Lo\u00efc Crombez",
      "Guilherme D. da Fonseca",
      "Yan Gerard",
      "Aldo Gonzalez-Lorenzo",
      "Pascal Lafourcade",
      "Luc Libralesso"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.13956"
  },
  {
    "id": "arXiv:2103.16858",
    "title": "SpecAugment++: A Hidden Space Data Augmentation Method for Acoustic  Scene Classification",
    "abstract": "Comments: Submitted to Interspeech 2021",
    "descriptor": "\nComments: Submitted to Interspeech 2021\n",
    "authors": [
      "Helin Wang",
      "Yuexian Zou",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2103.16858"
  },
  {
    "id": "arXiv:2104.02095",
    "title": "Deep neural network approximation of analytic functions",
    "abstract": "Deep neural network approximation of analytic functions",
    "descriptor": "",
    "authors": [
      "Aleksandr Beknazaryan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.02095"
  },
  {
    "id": "arXiv:2104.06131",
    "title": "Big Communications: Connect the Unconnected",
    "abstract": "Big Communications: Connect the Unconnected",
    "descriptor": "",
    "authors": [
      "Shuping Dang",
      "Chuanting Zhang",
      "Basem Shihada",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.06131"
  },
  {
    "id": "arXiv:2104.06993",
    "title": "Unsupervised Learning in Next-Generation Networks: Real-Time Performance  Self-Diagnosis",
    "abstract": "Comments: 5 pages, 5 figures. Submitted to IEEE Communications Letters",
    "descriptor": "\nComments: 5 pages, 5 figures. Submitted to IEEE Communications Letters\n",
    "authors": [
      "Faris B. Mismar",
      "Jakob Hoydis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.06993"
  },
  {
    "id": "arXiv:2104.07070",
    "title": "Self-Supervised Learning of Remote Sensing Scene Representations Using  Contrastive Multiview Coding",
    "abstract": "Comments: EarthVision 2021 paper",
    "descriptor": "\nComments: EarthVision 2021 paper\n",
    "authors": [
      "Vladan Stojni\u0107",
      "Vladimir Risojevi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.07070"
  },
  {
    "id": "arXiv:2104.07463",
    "title": "A Single-Exponential Time 2-Approximation Algorithm for Treewidth",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Tuukka Korhonen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.07463"
  },
  {
    "id": "arXiv:2104.08453",
    "title": "Attacking Text Classifiers via Sentence Rewriting Sampler",
    "abstract": "Attacking Text Classifiers via Sentence Rewriting Sampler",
    "descriptor": "",
    "authors": [
      "Lei Xu",
      "Kalyan Veeramachaneni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08453"
  },
  {
    "id": "arXiv:2104.08570",
    "title": "Crossing the Conversational Chasm: A Primer on Natural Language  Processing for Multilingual Task-Oriented Dialogue Systems",
    "abstract": "Crossing the Conversational Chasm: A Primer on Natural Language  Processing for Multilingual Task-Oriented Dialogue Systems",
    "descriptor": "",
    "authors": [
      "Evgeniia Razumovskaia",
      "Goran Glava\u0161",
      "Olga Majewska",
      "Edoardo M. Ponti",
      "Anna Korhonen",
      "Ivan Vuli\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08570"
  },
  {
    "id": "arXiv:2104.14392",
    "title": "COSCO: Container Orchestration using Co-Simulation and Gradient Based  Optimization for Fog Computing Environments",
    "abstract": "Comments: Accepted in IEEE Transactions on Parallel and Distributed Systems, 2021",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Parallel and Distributed Systems, 2021\n",
    "authors": [
      "Shreshth Tuli",
      "Shivananda Poojara",
      "Satish N. Srirama",
      "Giuliano Casale",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2104.14392"
  },
  {
    "id": "arXiv:2104.14840",
    "title": "On Stochastic Moving-Average Estimators for Non-Convex Optimization",
    "abstract": "On Stochastic Moving-Average Estimators for Non-Convex Optimization",
    "descriptor": "",
    "authors": [
      "Zhishuai Guo",
      "Yi Xu",
      "Wotao Yin",
      "Rong Jin",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14840"
  },
  {
    "id": "arXiv:2105.00795",
    "title": "RetCL: A Selection-based Approach for Retrosynthesis via Contrastive  Learning",
    "abstract": "Comments: Accepted to IJCAI 2021. Short version was accepted to Machine Learning for Molecules Workshop at NeurIPS 2020",
    "descriptor": "\nComments: Accepted to IJCAI 2021. Short version was accepted to Machine Learning for Molecules Workshop at NeurIPS 2020\n",
    "authors": [
      "Hankook Lee",
      "Sungsoo Ahn",
      "Seung-Woo Seo",
      "You Young Song",
      "Eunho Yang",
      "Sung-Ju Hwang",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00795"
  },
  {
    "id": "arXiv:2105.02135",
    "title": "UVIP: Model-Free Approach to Evaluate Reinforcement Learning Algorithms",
    "abstract": "UVIP: Model-Free Approach to Evaluate Reinforcement Learning Algorithms",
    "descriptor": "",
    "authors": [
      "D. Belomestny",
      "I. Levin",
      "E. Moulines",
      "A. Naumov",
      "S. Samsonov",
      "V. Zorina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.02135"
  },
  {
    "id": "arXiv:2105.02866",
    "title": "Membership Inference Attacks on Deep Regression Models for Neuroimaging",
    "abstract": "Comments: To appear at Medical Imaging with Deep Learning 2021 (MIDL 2021)",
    "descriptor": "\nComments: To appear at Medical Imaging with Deep Learning 2021 (MIDL 2021)\n",
    "authors": [
      "Umang Gupta",
      "Dimitris Stripelis",
      "Pradeep K. Lam",
      "Paul M. Thompson",
      "Jos\u00e9 Luis Ambite",
      "Greg Ver Steeg"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.02866"
  },
  {
    "id": "arXiv:2105.03023",
    "title": "DExperts: Decoding-Time Controlled Text Generation with Experts and  Anti-Experts",
    "abstract": "Comments: ACL 2021 camera-ready",
    "descriptor": "\nComments: ACL 2021 camera-ready\n",
    "authors": [
      "Alisa Liu",
      "Maarten Sap",
      "Ximing Lu",
      "Swabha Swayamdipta",
      "Chandra Bhagavatula",
      "Noah A. Smith",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03023"
  },
  {
    "id": "arXiv:2105.03081",
    "title": "Bounded Synthesis and Reinforcement Learning of Supervisors for  Stochastic Discrete Event Systems with LTL Specifications",
    "abstract": "Comments: 15 pages, 4 figures, 2 tables, submitted to a journal",
    "descriptor": "\nComments: 15 pages, 4 figures, 2 tables, submitted to a journal\n",
    "authors": [
      "Ryohei Oura",
      "Toshimitsu Ushio",
      "Ami Sakakibara"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.03081"
  },
  {
    "id": "arXiv:2105.03095",
    "title": "Learning Shared Semantic Space for Speech-to-Text Translation",
    "abstract": "Comments: 9 pages, 5 figures, Accepted by Findings of ACL 2021",
    "descriptor": "\nComments: 9 pages, 5 figures, Accepted by Findings of ACL 2021\n",
    "authors": [
      "Chi Han",
      "Mingxuan Wang",
      "Heng Ji",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.03095"
  },
  {
    "id": "arXiv:2105.03842",
    "title": "FastCorrect: Fast Error Correction with Edit Alignment for Automatic  Speech Recognition",
    "abstract": "FastCorrect: Fast Error Correction with Edit Alignment for Automatic  Speech Recognition",
    "descriptor": "",
    "authors": [
      "Yichong Leng",
      "Xu Tan",
      "Linchen Zhu",
      "Jin Xu",
      "Renqian Luo",
      "Linquan Liu",
      "Tao Qin",
      "Xiang-Yang Li",
      "Ed Lin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.03842"
  },
  {
    "id": "arXiv:2105.04054",
    "title": "Societal Biases in Language Generation: Progress and Challenges",
    "abstract": "Comments: ACL 2021 camera-ready",
    "descriptor": "\nComments: ACL 2021 camera-ready\n",
    "authors": [
      "Emily Sheng",
      "Kai-Wei Chang",
      "Premkumar Natarajan",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.04054"
  },
  {
    "id": "arXiv:2105.04447",
    "title": "SCTN: Sparse Convolution-Transformer Network for Scene Flow Estimation",
    "abstract": "SCTN: Sparse Convolution-Transformer Network for Scene Flow Estimation",
    "descriptor": "",
    "authors": [
      "Bing Li",
      "Cheng Zheng",
      "Silvio Giancola",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04447"
  },
  {
    "id": "arXiv:2105.04949",
    "title": "BERT is to NLP what AlexNet is to CV: Can Pre-Trained Language Models  Identify Analogies?",
    "abstract": "Comments: Accepted by ACL 2021 main conference",
    "descriptor": "\nComments: Accepted by ACL 2021 main conference\n",
    "authors": [
      "Asahi Ushio",
      "Luis Espinosa-Anke",
      "Steven Schockaert",
      "Jose Camacho-Collados"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04949"
  },
  {
    "id": "arXiv:2105.06202",
    "title": "Deciding FO-definability of Regular Languages",
    "abstract": "Deciding FO-definability of Regular Languages",
    "descriptor": "",
    "authors": [
      "Agi Kurucz",
      "Vladislav Ryzhikov",
      "Yury Savateev",
      "Michael Zakharyaschev"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.06202"
  },
  {
    "id": "arXiv:2105.06597",
    "title": "Joint Retrieval and Generation Training for Grounded Text Generation",
    "abstract": "Joint Retrieval and Generation Training for Grounded Text Generation",
    "descriptor": "",
    "authors": [
      "Yizhe Zhang",
      "Siqi Sun",
      "Xiang Gao",
      "Yuwei Fang",
      "Chris Brockett",
      "Michel Galley",
      "Jianfeng Gao",
      "Bill Dolan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.06597"
  },
  {
    "id": "arXiv:2105.06990",
    "title": "BERT Busters: Outlier Dimensions that Disrupt Transformers",
    "abstract": "Comments: Accepted as long paper at Findings of ACL 2021",
    "descriptor": "\nComments: Accepted as long paper at Findings of ACL 2021\n",
    "authors": [
      "Olga Kovaleva",
      "Saurabh Kulshreshtha",
      "Anna Rogers",
      "Anna Rumshisky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.06990"
  },
  {
    "id": "arXiv:2105.07144",
    "title": "A Cognitive Regularizer for Language Modeling",
    "abstract": "Comments: ACL 2021 Camera-ready",
    "descriptor": "\nComments: ACL 2021 Camera-ready\n",
    "authors": [
      "Jason Wei",
      "Clara Meister",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.07144"
  },
  {
    "id": "arXiv:2105.07535",
    "title": "Adaptive Interference Coordination over Channels with Unknown State at  the Encoder and the Decoder",
    "abstract": "Adaptive Interference Coordination over Channels with Unknown State at  the Encoder and the Decoder",
    "descriptor": "",
    "authors": [
      "Michail Mylonakis",
      "Photios A. Stavrou",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.07535"
  },
  {
    "id": "arXiv:2105.07566",
    "title": "Exploring Self-Supervised Representation Ensembles for COVID-19 Cough  Classification",
    "abstract": "Comments: Accepted to ACM KDD 2021",
    "descriptor": "\nComments: Accepted to ACM KDD 2021\n",
    "authors": [
      "Hao Xue",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.07566"
  },
  {
    "id": "arXiv:2105.07660",
    "title": "Global Wheat Head Dataset 2021: more diversity to improve the  benchmarking of wheat head localization methods",
    "abstract": "Comments: 8 pages, 2 figures, 1 table",
    "descriptor": "\nComments: 8 pages, 2 figures, 1 table\n",
    "authors": [
      "Etienne David",
      "Mario Serouart",
      "Daniel Smith",
      "Simon Madec",
      "Kaaviya Velumani",
      "Shouyang Liu",
      "Xu Wang",
      "Francisco Pinto Espinosa",
      "Shahameh Shafiee",
      "Izzat S. A. Tahir",
      "Hisashi Tsujimoto",
      "Shuhei Nasuda",
      "Bangyou Zheng",
      "Norbert Kichgessner",
      "Helge Aasen",
      "Andreas Hund",
      "Pouria Sadhegi-Tehran",
      "Koichi Nagasawa",
      "Goro Ishikawa",
      "S\u00e9bastien Dandrifosse",
      "Alexis Carlier",
      "Benoit Mercatoris",
      "Ken Kuroki",
      "Haozhou Wang",
      "Masanori Ishii",
      "Minhajul A. Badhon",
      "Curtis Pozniak",
      "David Shaner LeBauer",
      "Morten Lilimo",
      "Jesse Poland",
      "Scott Chapman",
      "Benoit de Solan",
      "Fr\u00e9d\u00e9ric Baret",
      "Ian Stavness",
      "Wei Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07660"
  },
  {
    "id": "arXiv:2105.09497",
    "title": "Bayesian Calibration for Large-Scale Fluid Structure Interaction  Problems Under Embedded/Immersed Boundary Framework",
    "abstract": "Comments: 23pages, 14 figures",
    "descriptor": "\nComments: 23pages, 14 figures\n",
    "authors": [
      "Shunxiang Cao",
      "Daniel Zhengyu Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.09497"
  },
  {
    "id": "arXiv:2105.10362",
    "title": "Functionals in the Clouds: An abstract architecture of serverless  Cloud-Native Apps",
    "abstract": "Comments: Work in progress. Three figures (related to functionals) were added",
    "descriptor": "\nComments: Work in progress. Three figures (related to functionals) were added\n",
    "authors": [
      "Stanislaw Ambroszkiewicz",
      "Waldemar Bartyna",
      "Stanislaw Bylka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.10362"
  },
  {
    "id": "arXiv:2105.10375",
    "title": "An Efficient Training Approach for Very Large Scale Face Recognition",
    "abstract": "Comments: This is a very effcient framework for ultra-large-scale classification tasks. Our code is available at this https URL We will keep updating!!",
    "descriptor": "\nComments: This is a very effcient framework for ultra-large-scale classification tasks. Our code is available at this https URL We will keep updating!!\n",
    "authors": [
      "Kai Wang",
      "Shuo Wang",
      "Zhipeng Zhou",
      "Xiaobo Wang",
      "Xiaojiang Peng",
      "Baigui Sun",
      "Hao Li",
      "Yang You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.10375"
  },
  {
    "id": "arXiv:2105.10500",
    "title": "Feature Encoding with AutoEncoders for Weakly-supervised Anomaly  Detection",
    "abstract": "Comments: 12pages,4 figures, accepted by 2021 IEEE Transactions on Neural Networks and Learning Systems",
    "descriptor": "\nComments: 12pages,4 figures, accepted by 2021 IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Yingjie Zhou",
      "Xucheng Song",
      "Yanru Zhang",
      "Fanxing Liu",
      "Ce Zhu",
      "Lingqiao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.10500"
  },
  {
    "id": "arXiv:2105.11108",
    "title": "Pre-trained Language Model based Ranking in Baidu Search",
    "abstract": "Comments: 9-pages, 3 figures, 7 tables, SIGKDD 2021 accepted paper",
    "descriptor": "\nComments: 9-pages, 3 figures, 7 tables, SIGKDD 2021 accepted paper\n",
    "authors": [
      "Lixin Zou",
      "Shengqiang Zhang",
      "Hengyi Cai",
      "Dehong Ma",
      "Suqi Cheng",
      "Daiting Shi",
      "Shuaiqiang Wang",
      "Zhicong Cheng",
      "Dawei Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.11108"
  },
  {
    "id": "arXiv:2105.11675",
    "title": "An Upper Limit of Decaying Rate with Respect to Frequency in Deep Neural  Network",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2012.03238",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.03238\n",
    "authors": [
      "Tao Luo",
      "Zheng Ma",
      "Zhiwei Wang",
      "Zhi-Qin John Xu",
      "Yaoyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.11675"
  },
  {
    "id": "arXiv:2105.11989",
    "title": "Graph Based Link Prediction between Human Phenotypes and Genes",
    "abstract": "Graph Based Link Prediction between Human Phenotypes and Genes",
    "descriptor": "",
    "authors": [
      "Rushabh Patel",
      "Yanhui Guo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.11989"
  },
  {
    "id": "arXiv:2105.12228",
    "title": "INSPIRE: The Entry Point to Europe's Big Geospatial Data Infrastructure",
    "abstract": "Comments: 21 pages, 6 figures",
    "descriptor": "\nComments: 21 pages, 6 figures\n",
    "authors": [
      "Marco Minghini",
      "Vlado Cetl",
      "Alexander Kotsev",
      "Robert Tomas",
      "Michael Lutz"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2105.12228"
  },
  {
    "id": "arXiv:2105.12400",
    "title": "Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger",
    "abstract": "Comments: Accepted by ACL-IJCNLP 2021 as a long paper. Camera-ready version",
    "descriptor": "\nComments: Accepted by ACL-IJCNLP 2021 as a long paper. Camera-ready version\n",
    "authors": [
      "Fanchao Qi",
      "Mukai Li",
      "Yangyi Chen",
      "Zhengyan Zhang",
      "Zhiyuan Liu",
      "Yasheng Wang",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.12400"
  },
  {
    "id": "arXiv:2105.12585",
    "title": "Automatic Construction of Sememe Knowledge Bases via Dictionaries",
    "abstract": "Comments: Accepted by Findings of ACL at ACL-IJCNLP 2021. Camera-ready version",
    "descriptor": "\nComments: Accepted by Findings of ACL at ACL-IJCNLP 2021. Camera-ready version\n",
    "authors": [
      "Fanchao Qi",
      "Yangyi Chen",
      "Fengyu Wang",
      "Zhiyuan Liu",
      "Xiao Chen",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.12585"
  },
  {
    "id": "arXiv:2105.13010",
    "title": "An error analysis of generative adversarial networks for learning  distributions",
    "abstract": "An error analysis of generative adversarial networks for learning  distributions",
    "descriptor": "",
    "authors": [
      "Jian Huang",
      "Yuling Jiao",
      "Zhen Li",
      "Shiao Liu",
      "Yang Wang",
      "Yunfei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13010"
  },
  {
    "id": "arXiv:2105.13189",
    "title": "Sparse recovery based on the generalized error function",
    "abstract": "Sparse recovery based on the generalized error function",
    "descriptor": "",
    "authors": [
      "Zhiyong Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13189"
  },
  {
    "id": "arXiv:2105.13262",
    "title": "A Microarchitecture Implementation Framework for Online Learning with  Temporal Neural Networks",
    "abstract": "Comments: To be published in ISVLSI 2021. arXiv admin note: substantial text overlap with arXiv:2009.00457",
    "descriptor": "\nComments: To be published in ISVLSI 2021. arXiv admin note: substantial text overlap with arXiv:2009.00457\n",
    "authors": [
      "Harideep Nair",
      "John Paul Shen",
      "James E. Smith"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.13262"
  },
  {
    "id": "arXiv:2105.13351",
    "title": "Tracking Without Re-recognition in Humans and Machines",
    "abstract": "Tracking Without Re-recognition in Humans and Machines",
    "descriptor": "",
    "authors": [
      "Drew Linsley",
      "Girik Malik",
      "Junkyung Kim",
      "Lakshmi N Govindarajan",
      "Ennio Mingolla",
      "Thomas Serre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.13351"
  },
  {
    "id": "arXiv:2105.13538",
    "title": "Two-level overlapping Schwarz methods based on local generalized  eigenproblems for Hermitian variational problems",
    "abstract": "Two-level overlapping Schwarz methods based on local generalized  eigenproblems for Hermitian variational problems",
    "descriptor": "",
    "authors": [
      "Qing Lu",
      "Junxian Wang",
      "Shi Shu",
      "Jie Peng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13538"
  },
  {
    "id": "arXiv:2105.13718",
    "title": "Voice Activity Detection for Ultrasound-based Silent Speech Interfaces  using Convolutional Neural Networks",
    "abstract": "Comments: 12 pages, 7 tables, 4 figures",
    "descriptor": "\nComments: 12 pages, 7 tables, 4 figures\n",
    "authors": [
      "Amin Honarmandi Shandiz",
      "L\u00e1szl\u00f3 T\u00f3th"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.13718"
  },
  {
    "id": "arXiv:2105.13913",
    "title": "Simple steps are all you need: Frank-Wolfe and generalized  self-concordant functions",
    "abstract": "Simple steps are all you need: Frank-Wolfe and generalized  self-concordant functions",
    "descriptor": "",
    "authors": [
      "Alejandro Carderera",
      "Mathieu Besan\u00e7on",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13913"
  },
  {
    "id": "arXiv:2105.14064",
    "title": "Controllable Abstractive Dialogue Summarization with Sketch Supervision",
    "abstract": "Comments: ACL-Findings 2021. Code is released at this https URL",
    "descriptor": "\nComments: ACL-Findings 2021. Code is released at this https URL\n",
    "authors": [
      "Chien-Sheng Wu",
      "Linqing Liu",
      "Wenhao Liu",
      "Pontus Stenetorp",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14064"
  },
  {
    "id": "arXiv:2105.14136",
    "title": "Towards a modeling and analysis environment for industrial IoT systems",
    "abstract": "Comments: 7 figures, 10 pages",
    "descriptor": "\nComments: 7 figures, 10 pages\n",
    "authors": [
      "Felicien Ihirwe",
      "Davide Di Ruscio",
      "Silvia Mazzini",
      "Alfonso Pierantonio"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.14136"
  },
  {
    "id": "arXiv:2105.14202",
    "title": "Universal Adder Neural Networks",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1912.13200",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1912.13200\n",
    "authors": [
      "Hanting Chen",
      "Yunhe Wang",
      "Chang Xu",
      "Chao Xu",
      "Chunjing Xu",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14202"
  },
  {
    "id": "arXiv:2105.14240",
    "title": "Analysis and Applications of Class-wise Robustness in Adversarial  Training",
    "abstract": "Analysis and Applications of Class-wise Robustness in Adversarial  Training",
    "descriptor": "",
    "authors": [
      "Qi Tian",
      "Kun Kuang",
      "Kelu Jiang",
      "Fei Wu",
      "Yisen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14240"
  },
  {
    "id": "arXiv:2105.14508",
    "title": "Secret sharing schemes from hypersurfaces over finite fields",
    "abstract": "Comments: 19 pages; version revised after feedback on the original preprint",
    "descriptor": "\nComments: 19 pages; version revised after feedback on the original preprint\n",
    "authors": [
      "Angela Aguglia",
      "Michela Ceria",
      "Luca Giuzzi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.14508"
  },
  {
    "id": "arXiv:2105.14739",
    "title": "Controllable Person Image Synthesis with Spatially-Adaptive Warped  Normalization",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Jichao Zhang",
      "Aliaksandr Siarohin",
      "Hao Tang",
      "Jingjing Chen",
      "Enver Sangineto",
      "Wei Wang",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2105.14739"
  },
  {
    "id": "arXiv:2105.14995",
    "title": "Choose a Transformer: Fourier or Galerkin",
    "abstract": "Choose a Transformer: Fourier or Galerkin",
    "descriptor": "",
    "authors": [
      "Shuhao Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14995"
  },
  {
    "id": "arXiv:2105.15034",
    "title": "A remark on a paper of Krotov and Hopfield [arXiv:2008.06996]",
    "abstract": "Comments: 1 page, 8 formulae",
    "descriptor": "\nComments: 1 page, 8 formulae\n",
    "authors": [
      "Fei Tang",
      "Michael Kopp"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15034"
  },
  {
    "id": "arXiv:2105.15076",
    "title": "Large-Scale Spatio-Temporal Person Re-identification: Algorithm and  Benchmark",
    "abstract": "Large-Scale Spatio-Temporal Person Re-identification: Algorithm and  Benchmark",
    "descriptor": "",
    "authors": [
      "Xiujun Shu",
      "Xiao Wang",
      "Shiliang Zhang",
      "Xianghao Zhang",
      "Yuanqi Chen",
      "Ge Li",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.15076"
  },
  {
    "id": "arXiv:2106.00306",
    "title": "Understanding peacefulness through the world news",
    "abstract": "Comments: 19 pages, 19 figures",
    "descriptor": "\nComments: 19 pages, 19 figures\n",
    "authors": [
      "Vasiliki Voukelatou",
      "Ioanna Miliou",
      "Fosca Giannotti",
      "Luca Pappalardo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00306"
  },
  {
    "id": "arXiv:2106.00315",
    "title": "Ordering regular languages: a danger zone",
    "abstract": "Comments: 23 pages, 6 figures",
    "descriptor": "\nComments: 23 pages, 6 figures\n",
    "authors": [
      "Giovanna D'Agostino",
      "Davide Martincigh",
      "Alberto Policriti"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.00315"
  },
  {
    "id": "arXiv:2106.00517",
    "title": "Cooperative Multi-Agent Transfer Learning with Level-Adaptive Credit  Assignment",
    "abstract": "Comments: 12 pages, 9 figures",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Tianze Zhou",
      "Fubiao Zhang",
      "Kun Shao",
      "Kai Li",
      "Wenhan Huang",
      "Jun Luo",
      "Weixun Wang",
      "Yaodong Yang",
      "Hangyu Mao",
      "Bin Wang",
      "Dong Li",
      "Wulong Liu",
      "Jianye Hao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00517"
  },
  {
    "id": "arXiv:2106.00647",
    "title": "Mapping the NFT revolution: market trends, trade networks and visual  features",
    "abstract": "Comments: Working paper, comments welcome",
    "descriptor": "\nComments: Working paper, comments welcome\n",
    "authors": [
      "Matthieu Nadini",
      "Laura Alessandretti",
      "Flavio Di Giacinto",
      "Mauro Martino",
      "Luca Maria Aiello",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00647"
  },
  {
    "id": "arXiv:2106.00652",
    "title": "Comprehensive Validation of Automated Whole Body Skeletal Muscle,  Adipose Tissue, and Bone Segmentation from 3D CT images for Body Composition  Analysis: Towards Extended Body Composition",
    "abstract": "Comments: This paper is based on concepts presented at the NIH Body Composition and Cancer Outcomes Research Webinar Series on December 17th, 2020 by Mirza Faisal Beg titled \"Automating Body Composition from Routinely Acquired CT images - towards 3D measurements\". The talk is archived [here](this https URL)",
    "descriptor": "\nComments: This paper is based on concepts presented at the NIH Body Composition and Cancer Outcomes Research Webinar Series on December 17th, 2020 by Mirza Faisal Beg titled \"Automating Body Composition from Routinely Acquired CT images - towards 3D measurements\". The talk is archived [here](this https URL)\n",
    "authors": [
      "Da Ma",
      "Vincent Chow",
      "Karteek Popuri",
      "Mirza Faisal Beg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2106.00652"
  },
  {
    "id": "arXiv:2106.00745",
    "title": "Part of Speech and Universal Dependency effects on English Arabic  Machine Translation",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Ofek Rafaeli",
      "Omri Abend",
      "Leshem Choshen",
      "Dmitry Nikolaev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00745"
  },
  {
    "id": "arXiv:2106.00761",
    "title": "Motif Prediction with Graph Neural Networks",
    "abstract": "Motif Prediction with Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Maciej Besta",
      "Raphael Grob",
      "Cesare Miglioli",
      "Nicola Bernold",
      "Grzegorz Kwasniewski",
      "Gabriel Gjini",
      "Raghavendra Kanakagiri",
      "Saleh Ashkboos",
      "Lukas Gianinazzi",
      "Nikoli Dryden",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00761"
  },
  {
    "id": "arXiv:2106.00764",
    "title": "HisVA: A Visual Analytics System for Studying History",
    "abstract": "HisVA: A Visual Analytics System for Studying History",
    "descriptor": "",
    "authors": [
      "Dongyun Han",
      "Gorakh Parsad",
      "Hwiyeon Kim",
      "Jaekyom Shim",
      "Oh-Sang Kwon",
      "Kyung A Son",
      "Jooyoung Lee",
      "Isaac Cho",
      "Sungahn Ko"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.00764"
  },
  {
    "id": "arXiv:2106.00787",
    "title": "Image-Audio Encoding to Improve C2 Decision-Making in Multi-Domain  Environment",
    "abstract": "Comments: Published in: The 25th International Command and Control Research and Technology Symposium (ICCRTS - 2020)",
    "descriptor": "\nComments: Published in: The 25th International Command and Control Research and Technology Symposium (ICCRTS - 2020)\n",
    "authors": [
      "Piyush K. Sharma",
      "Adrienne Raglin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.00787"
  },
  {
    "id": "arXiv:2106.00874",
    "title": "Conversational Question Answering: A Survey",
    "abstract": "Conversational Question Answering: A Survey",
    "descriptor": "",
    "authors": [
      "Munazza Zaib",
      "Wei Emma Zhang",
      "Quan Z. Sheng",
      "Adnan Mahmood",
      "Yang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.00874"
  },
  {
    "id": "arXiv:2106.00880",
    "title": "Rotation Equivariant Feature Image Pyramid Network for Object Detection  in Optical Remote Sensing Imagery",
    "abstract": "Comments: We submitted the old version of the manuscript",
    "descriptor": "\nComments: We submitted the old version of the manuscript\n",
    "authors": [
      "Pourya Shamsolmoali",
      "Masoumeh Zareapoor",
      "Jocelyn Chanussot",
      "Huiyu Zhou",
      "Jie Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00880"
  },
  {
    "id": "arXiv:2106.00885",
    "title": "Robustifying Algorithms of Learning Latent Trees with Vector Variables",
    "abstract": "Robustifying Algorithms of Learning Latent Trees with Vector Variables",
    "descriptor": "",
    "authors": [
      "Fengzhuo Zhang",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00885"
  },
  {
    "id": "arXiv:2106.00901",
    "title": "A Differentiable Point Process with Its Application to Spiking Neural  Networks",
    "abstract": "Comments: Accepted to ICML 2021",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Hiroshi Kajino"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00901"
  },
  {
    "id": "arXiv:2106.00933",
    "title": "OntoGUM: Evaluating Contextualized SOTA Coreference Resolution on 12  More Genres",
    "abstract": "Comments: ACL 2021",
    "descriptor": "\nComments: ACL 2021\n",
    "authors": [
      "Yilun Zhu",
      "Sameer Pradhan",
      "Amir Zeldes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00933"
  },
  {
    "id": "arXiv:2106.01028",
    "title": "A Hypergraph Convolutional Neural Network for Molecular Properties  Prediction using Functional Group",
    "abstract": "Comments: 9 pages, 9 figures",
    "descriptor": "\nComments: 9 pages, 9 figures\n",
    "authors": [
      "Fangying Chen",
      "Junyoung Park",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.01028"
  },
  {
    "id": "arXiv:2106.01084",
    "title": "Asymptotic Characterisation of Regularised Zero-Forcing Receiver for  Imperfect and Correlated Massive MIMO Systems with Optimal Power Allocation",
    "abstract": "Asymptotic Characterisation of Regularised Zero-Forcing Receiver for  Imperfect and Correlated Massive MIMO Systems with Optimal Power Allocation",
    "descriptor": "",
    "authors": [
      "Ayed M. Alrashdi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.01084"
  },
  {
    "id": "arXiv:2106.01112",
    "title": "DynaEval: Unifying Turn and Dialogue Level Evaluation",
    "abstract": "Comments: ACL-IJCNLP 2021 (Main conference, Long paper)",
    "descriptor": "\nComments: ACL-IJCNLP 2021 (Main conference, Long paper)\n",
    "authors": [
      "Chen Zhang",
      "Yiming Chen",
      "Luis Fernando D'Haro",
      "Yan Zhang",
      "Thomas Friedrichs",
      "Grandee Lee",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01112"
  },
  {
    "id": "arXiv:2106.01127",
    "title": "Towards Robust Classification Model by Counterfactual and Invariant Data  Generation",
    "abstract": "Comments: Accepted in 2021 CVPR",
    "descriptor": "\nComments: Accepted in 2021 CVPR\n",
    "authors": [
      "Chun-Hao Chang",
      "George Alexandru Adam",
      "Anna Goldenberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01127"
  },
  {
    "id": "arXiv:2106.01140",
    "title": "semopy 2: A Structural Equation Modeling Package with Random Effects in  Python",
    "abstract": "semopy 2: A Structural Equation Modeling Package with Random Effects in  Python",
    "descriptor": "",
    "authors": [
      "Georgy Meshcheryakov",
      "Anna A. Igolkina",
      "Maria G. Samsonova"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2106.01140"
  },
  {
    "id": "arXiv:2106.01195",
    "title": "Figurative Language in Recognizing Textual Entailment",
    "abstract": "Comments: ACL 2021 (Findings)",
    "descriptor": "\nComments: ACL 2021 (Findings)\n",
    "authors": [
      "Tuhin Chakrabarty",
      "Debanjan Ghosh",
      "Adam Poliak",
      "Smaranda Muresan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01195"
  },
  {
    "id": "arXiv:2106.01336",
    "title": "Improved Rates for Differentially Private Stochastic Convex Optimization  with Heavy-Tailed Data",
    "abstract": "Improved Rates for Differentially Private Stochastic Convex Optimization  with Heavy-Tailed Data",
    "descriptor": "",
    "authors": [
      "Gautam Kamath",
      "Xingtu Liu",
      "Huanyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01336"
  },
  {
    "id": "arXiv:2106.01350",
    "title": "On Efficiently Explaining Graph-Based Classifiers",
    "abstract": "On Efficiently Explaining Graph-Based Classifiers",
    "descriptor": "",
    "authors": [
      "Xuanxiang Huang",
      "Yacine Izza",
      "Alexey Ignatiev",
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01350"
  }
]